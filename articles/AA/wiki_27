<doc id="3981" url="https://en.wikipedia.org/wiki?curid=3981" title="Blackjack">
Blackjack

Blackjack is the American version of a popular global banking game known as Twenty-One, whose relatives include Pontoon and Vingt-et-Un. It is a comparing card game between one or more players and a dealer, where each player in turn competes against the dealer. Players do not compete against each other. It is played with one or more decks of 52 cards, and is the most widely played casino banking game in the world. 

Players are each dealt two cards, face up or down depending on the casino and the table. In the U.S., the dealer is also dealt two cards, normally one up (exposed) and one down (hidden). In most other countries, the dealer only receives one card face up. The value of cards two through ten is their pip value (2 through 10). Face cards (Jack, Queen, and King) are all worth ten. Aces can be worth one or eleven. A hand's value is the sum of the card values. Players are allowed to draw additional cards to improve their hands. A hand with an ace valued as 11 is called "soft", meaning that the hand will not bust by taking an additional card. The value of the ace will become one to prevent the hand from exceeding 21. Otherwise, the hand is called "hard".

Once all the players have completed their hands, it is the dealer's turn. The dealer hand will not be completed if all players have either busted or received blackjacks. The dealer then reveals the hidden card and must hit until the cards total up to 17 points. At 17 points or higher the dealer must stay. (At most tables the dealer also hits on a "soft" 17, i.e. a hand containing an ace and one or more other cards totaling six.) You are betting that you have a better hand than the dealer. The better hand is the hand where the sum of the card values is closer to 21 without exceeding 21. The detailed outcome of the hand follows:


Blackjack has over 100 rule variations. Since the 1960s, blackjack has been a high-profile target of advantage players, particularly card counters, who track the profile of cards that have been dealt and adapt their wagers and playing strategies accordingly. In response, casinos have introduced counter-measures that can increase the difficulty of advantage play.

Blackjack has inspired other casino games, including Spanish 21 and pontoon.

Blackjack's precursor was "twenty-one", a game of unknown origin. The first written reference is found in a book by the Spanish author Miguel de Cervantes, most famous for writing "Don Quixote". Cervantes was a gambler, and the main characters of his tale "Rinconete y Cortadillo", from "Novelas Ejemplares", are a couple of cheats working in Seville. They are proficient at cheating at "veintiuna" (Spanish for twenty-one), and state that the object of the game is to reach 21 points without going over and that the ace values 1 or 11. The game is played with the Spanish "baraja" deck. This short story was written between 1601 and 1602, implying that "ventiuna" was played in Castile since the beginning of the 17th century or earlier. Later references to this game are found in France and Spain.

When twenty-one was introduced in the United States, gambling houses offered bonus payouts to stimulate players' interest. One such bonus was a ten-to-one payout if the player's hand consisted of the ace of spades and a black jack (either the jack of clubs or the jack of spades). This hand was called a "blackjack", and the name stuck to the game even though the ten-to-one bonus was soon withdrawn. In the modern game, a "blackjack" refers to any hand of an ace plus a ten or face card regardless of suits or colors.

The first scientific and mathematically sound attempt to devise an optimal blackjack playing strategy was revealed in September 1956. Roger Baldwin, Wilbert Cantey, Herbert Maisel and James McDermott published a paper titled "The Optimum Strategy in Blackjack" in the Journal of the American Statistical Association. This paper would become the foundation of future sound efforts to beat the game of blackjack. Ed Thorp would use Baldwin's hand calculations to verify the basic strategy and later publish (in 1963) his famous book "Beat the Dealer".

At a casino blackjack table, the dealer faces five to seven playing positions from behind a semicircular table. Between one and eight standard 52-card decks are shuffled together. At the beginning of each round, up to three players can place their bets in the "betting box" at each position in play. That is, there could be up to three players at each position at a table in jurisdictions that allow back betting. The player whose bet is at the front of the betting box is deemed to have control over the position, and the dealer will consult the controlling player for playing decisions regarding the hand; the other players of that box are said to "play behind". Any player is usually allowed to control or bet in as many boxes as desired at a single table, but it is prohibited for an individual to play on more than one table at a time or to place multiple bets within a single box. In many U.S. casinos, however, players are limited to playing two or three positions at a table and often only one person is allowed to bet on each position.

The dealer deals cards from their left (the position on the dealer's far left is often referred to as "first base") to their far right ("third base"). Each box is dealt an initial hand of two cards visible to the people playing on it, and often to any other players. The dealer's hand receives its first card face up, and in "hole card" games immediately receives its second card face down (the hole card), which the dealer peeks at but does not reveal unless it makes the dealer's hand a blackjack. Hole card games are sometimes played on tables with a small mirror or electronic sensor that is used to peek securely at the hole card. In European casinos, "no hole card" games are prevalent; the dealer's second card is neither drawn nor consulted until the players have all played their hands.

Cards are dealt either from one or two handheld decks, from a dealer's shoe, or from a shuffling machine. Single cards are dealt to each wagered-on position clockwise from the dealer's left, followed by a single card to the dealer, followed by an additional card to each of the positions in play. The players' initial cards may be dealt face up or face down (more common in single-deck games).

The object of the game from the player's perspective is to win money by creating card totals that are higher than those of the dealer's hand, but do not exceed 21 ("busting"/"breaking"), or alternatively, by "standing" (not taking a card) at any total in the hope that dealer will bust. On their turn, players must choose whether to "hit" (take a card), "stand" (end their turn), "double" (double wager, take a single card and finish), "split" (if the two cards have the same value, separate them to make two hands) or "surrender" (give up a half-bet and retire from the game). Number cards count as their natural value; the jack, queen, and king (also known as "face cards" or "pictures") count as 10; aces are valued as either 1 or 11 according to the player's choice. If the hand value exceeds 21 points, it busts, and all bets on it are immediately forfeit. After all boxes have finished playing, the dealer's hand is resolved by drawing cards until the hand busts or achieves a value of 17 or higher (a dealer total of 17 including an ace valued as 11, also known as a "soft 17", must be drawn to in some games and must stand in others). The dealer never doubles, splits, or surrenders. If the dealer busts, all remaining player hands win. If the dealer does not bust, each remaining bet wins if its hand is higher than the dealer's, and loses if it is lower. If a player receives 21 on the 1st and 2nd card it is considered a "natural" or "blackjack" and the player is paid out immediately unless dealer also has a natural, in which case the hand ties. In the case of a tied score, known as "push" or "standoff", bets are normally returned without adjustment; however, a blackjack beats any hand that is not a blackjack, even one with a value of 21. Wins are paid out at 1:1, or equal to the wager, except for player blackjacks which are traditionally paid at 3:2 (meaning the player receives three dollars for every two bet) or one-and-a-half times the wager. Many casinos today pay blackjacks at less than 3:2 at some tables; for instance, single-deck blackjack tables often pay 6:5 for a blackjack instead of 3:2.

Blackjack games almost always provide a side bet called insurance, which may be played when dealer's upcard is an ace. Additional side bets, such as "Dealer Match" which pays when the player's cards match the dealer's up card, are sometimes available.

After receiving an initial two cards, the player has up to four standard options: "hit", "stand", "double down", or "split". Each option has a corresponding hand signal. Some games give the player a fifth option, "surrender".

Hand signals are used to assist the "eye in the sky", a person or video camera located above the table and sometimes concealed behind one-way glass. The eye in the sky usually makes a video recording of the table, which helps in resolving disputes and identifying dealer mistakes, and is also used to protect the casino against dealers who steal chips or players who cheat. The recording can further be used to identify advantage players whose activities, while legal, make them undesirable customers. In the event of a disagreement between a player's hand signals and their words, the hand signal takes precedence.
Each hand may normally "hit" as many times as desired so long as the total is not above hard 20. On reaching 21 (including soft 21), the hand is normally required to stand; busting is an irrevocable loss and the players' wagers are immediately forfeited to the house. After a bust or a stand, play proceeds to the next hand clockwise around the table. When the last hand has finished being played, the dealer reveals the hole card, and stands or draws further cards according to the rules of the game for dealer drawing. When the outcome of the dealer's hand is established, any hands with bets remaining on the table are resolved (usually in counterclockwise order): bets on losing hands are forfeited, the bet on a push is left on the table, and winners are paid out.

If the dealer's upcard is an ace, the player is offered the option of taking "insurance" before the dealer checks the hole card.

Insurance is a side bet that the dealer has blackjack and is treated independently of the main wager. It pays 2:1 (meaning that the player receives two dollars for every dollar bet) and is available when the dealer's exposed card is an ace. The idea is that the dealer's second card has a fairly high probability (nearly one-third) to be ten-valued, giving the dealer blackjack and disappointment for the player. It is attractive (although not necessarily wise) for the player to insure against the possibility of a dealer blackjack by making a maximum "insurance" bet, in which case the "insurance proceeds" will make up for the concomitant loss on the original bet. The player may add up to half the value of their original bet to the insurance and these extra chips are placed on a portion of the table usually marked "Insurance pays 2 to 1".

Players with a blackjack may also take insurance, and in taking maximum insurance they commit themselves to winning an amount exactly equal to their main wager, regardless of the dealer's outcome. Fully insuring a blackjack against blackjack is thus referred to as "taking even money", and paid out immediately, before the dealer's hand is resolved; the players do not need to place more chips for the insurance wager.

Insurance bets are expected to lose money in the long run, because the dealer is likely to have blackjack less than one-third of the time. However the insurance outcome is strongly anti-correlated with that of the main wager, and if the player's priority is to reduce variation, they might choose to pay for this.

Furthermore, the insurance bet is susceptible to advantage play. It is advantageous to make an insurance bet whenever the hole card has more than a chance of one in three of being a ten. Advantage play techniques can sometimes identify such situations. In a multi-hand, face-up, single deck game, it is possible to establish whether insurance is a good bet simply by observing the other cards on the table after the deal; even if there are just 2 player hands exposed, and neither of their two initial cards is a ten, then 16 in 47 of the remaining cards are tens, which is larger than 1 in 3, so insurance is a profitable bet. This is an elementary example of the family of advantage play techniques known as card counting.

Bets to insure against blackjack are slightly less likely to be advantageous than insurance bets in general, since the ten in the player's blackjack makes it less likely that the dealer has blackjack too.

"Note: where changes in the house edge due to changes in the rules are stated in percentage terms, the difference is usually stated here in percentage points, not percentage; strictly speaking if, say, an edge of 10% is reduced to 9%, the amount is reduced by ten percent, or by one percentage point."

The rules of casino blackjack are generally determined by law or regulation, which establishes certain rule variations allowed at the discretion of the casino. The rules of any particular game are generally posted on or near the table, failing which there is an expectation that casino staff will provide them on request. Over 100 variations of blackjack have been documented.

As with all casino games, blackjack incorporates a "house edge", a statistical advantage for the casino that is built into the game. The advantage of the dealer's position in blackjack relative to the player comes from the fact that if the player busts, the player loses, regardless of whether the dealer subsequently busts. Nonetheless, blackjack players using basic strategy will lose less than 1% of their total wagered amount with strictly average luck; this is very favorable to the player compared to other casino games. The loss rate of players who deviate from basic strategy through ignorance is generally expected to be greater.




Surrender, for those games that allow it, is usually not permitted against a dealer blackjack; if the dealer's first card is an ace or ten, the hole card is checked to make sure there is no blackjack before surrender is offered. This rule protocol is consequently known as "late" surrender. The alternative, "early" surrender, gives player the option to surrender "before" the dealer checks for blackjack, or in a no-hole-card game. Early surrender is much more favorable to the player than late surrender. Most medium-strength hands should be surrendered against a dealer Ace if the hole card has not been checked.

For late surrender, however, while it is tempting to opt for surrender on any hand which will probably lose, the correct strategy is to only surrender on the very worst hands, because having even a one in four chance of winning the full bet is better than losing half the bet and pushing the other half, as entailed by surrendering.


In most non-U.S. casinos, a 'no hole card' game is played, meaning that the dealer does not draw nor consult his or her second card until after all players have finished making decisions. With no hole card, it is almost never correct basic strategy to double or split against a dealer ten or ace, since a dealer blackjack will result in the loss of the split and double bets; the only exception is with a pair of aces against a dealer 10, where it is still correct to split. In all other cases, a stand, hit or surrender is called for. For instance, holding 11 against a dealer 10, the correct strategy is to double in a hole card game (where the player knows the dealer's second card is not an ace), but to hit in a no hole card game. The no hole card rule adds approximately 0.11% to the house edge.

The "original bets only" rule variation appearing in certain no hole card games states that if the player's hand loses to a dealer blackjack, only the mandatory initial bet ("original") is forfeited, and all optional bets, meaning doubles and splits, are pushed. "Original bets only" is also known by the acronym OBO; it has the same effect on basic strategy and house edge as reverting to a hole card game.


Each blackjack game has a "basic strategy", which prescribes the optimal method of playing any hand against any dealer up-card so that the long-term house advantage (the expected loss of the player) is minimized.

An example of a basic strategy is shown in the table below, which applies to a game with the following specifications: 

Key:

The bulk of basic strategy is common to all blackjack games, with most rule variations calling for changes in only a few situations. For example, to use the table above on a game with the stand on soft 17 rule (which favors the player, and is typically found only at higher-limit tables today) only 6 cells would need to be changed: hit on 11 "vs." A, hit on 15 "vs." A, stand on 17 "vs." A, stand on A,7 "vs." 2, stand on A,8 "vs." 6, and split on 8,8 "vs." A. Regardless of the specific rule variations, taking insurance or "even money" is never the correct play under basic strategy.

Estimates of the house edge for blackjack games quoted by casinos and gaming regulators are generally based on the assumption that the players follow basic strategy and do not systematically change their bet size.

Most blackjack games have a house edge of between 0.5% and 1%, placing blackjack among the cheapest casino table games from the perspective of the player. Casino promotions such as complimentary match play vouchers or 2:1 blackjack payouts allow the player to acquire an advantage without deviating from basic strategy.

Basic strategy is based upon a player's point total and the dealer's visible card. Players may be able to improve on this decision by considering the precise composition of their hand, not just the point total. For example, players should ordinarily stand when holding 12 against a dealer 4. However, in a single deck game, players should hit if their 12 consists of a 10 and a 2. The presence of a 10 in the player's hand has two consequences:

However, even when basic and composition-dependent strategy lead to different actions, the difference in expected reward is small, and it becomes even smaller with more decks. Using a composition-dependent strategy rather than basic strategy in a single deck game reduces the house edge by 4 in 10,000, which falls to 3 in 100,000 for a six-deck game.

Blackjack has been a high-profile target for advantage players since the 1960s. Advantage play is the attempt to win more using skills such as memory, computation, and observation. These techniques, while generally legal, can be powerful enough to give the player a long-term edge in the game, making them an undesirable customer for the casino and potentially leading to ejection or blacklisting if they are detected. The main techniques of advantage play in blackjack are as follows:

During the course of a blackjack shoe, the dealer exposes the dealt cards. Careful accounting of the exposed cards allows a player to make inferences about the cards which remain to be dealt. These inferences can be used in the following ways:

A card counting system assigns a point score to each rank of card (e.g., 1 point for 2–6, 0 points for 7–9 and −1 point for 10–A). When a card is exposed, a counter adds the score of that card to a running total, the 'count'. A card counter uses this count to make betting and playing decisions according to a table which they have learned. The count starts at 0 for a freshly shuffled deck for "balanced" counting systems. Unbalanced counts are often started at a value which depends on the number of decks used in the game.

Blackjack's house edge is usually between 0.5%–1% when players use basic strategy. Card counting can give the player an edge of up to 2% over the house.

Card counting is most rewarding near the end of a complete shoe when as few as possible cards remain. Single-deck games are therefore particularly advantageous to the card counting player. As a result, casinos are more likely to insist that players do not reveal their cards to one another in single-deck games. In games with more decks of cards, casinos limit penetration by ending the shoe and reshuffling when one or more decks remain undealt. Casinos also sometimes use a shuffling machine to reintroduce the exhausted cards every time a deck has been played.

Card counting is legal and is not considered cheating as long as the counter is not using an external device, but if a casino realizes a player is counting, the casino might inform them that they are no longer welcome to play blackjack. Sometimes a casino might ban a card counter from the property.

The use of external devices to help counting cards is illegal in all US states that license blackjack card games.

Techniques other than card counting can swing the advantage of casino blackjack toward the player. All such techniques are based on the value of the cards to the player and the casino as originally conceived by Edward O. Thorp. One technique, mainly applicable in multi-deck games, involves tracking groups of cards (also known as slugs, clumps, or packs) during the play of the shoe, following them through the shuffle, and then playing and betting accordingly when those cards come into play from the new shoe. Shuffle tracking requires excellent eyesight and powers of visual estimation but is more difficult to detect since the player's actions are largely unrelated to the composition of the cards in the shoe.

Arnold Snyder's articles in "Blackjack Forum" magazine brought shuffle tracking to the general public. His book, "The Shuffle Tracker's Cookbook," mathematically analyzed the player edge available from shuffle tracking based on the actual size of the tracked slug. Jerry L. Patterson also developed and published a shuffle-tracking method for tracking favorable clumps of cards and cutting them into play and tracking unfavorable clumps of cards and cutting them out of play.

The player can also gain an advantage by identifying cards from distinctive wear markings on their backs, or by hole carding (observing during the dealing process the front of a card dealt face down). These methods are generally legal although their status in particular jurisdictions may vary.

Many blackjack tables offer a side bet on various outcomes including:

The side wager is typically placed in a designated area next to the box for the main wager. A player wishing to wager on a side bet is usually required to place a wager on blackjack. Some games require that the blackjack wager should equal or exceed any side bet wager. A non-controlling player of a blackjack hand is usually permitted to place a side bet regardless of whether the controlling player does so.

The house edge for side bets is generally far higher than for the blackjack game itself. Nonetheless side bets can be susceptible to card counting. A side count, designed specifically for a particular side bet, can improve the player edge. Only a few side bets, like "Lucky Ladies", offer a sufficient win rate to justify the effort of advantage play.

In team play it is common for team members to be dedicated toward counting only a sidebet using a specialized count.

Blackjack can be played in tournament form. Players start with an equal numbers of chips; the goal is to finish among the top chip-holders. Depending on the number of competitors, tournaments may be held over several rounds, with one or two players qualifying from each table after a set number of deals to meet the qualifiers from the other tables in the next round. Another tournament format, Elimination Blackjack, drops the lowest-stacked player from the table at pre-determined points in the tournament. Good strategy for blackjack tournaments can differ from non-tournament strategy because of the added dimension of choosing the amount to be wagered. As in poker tournaments, players pay the casino an initial entry fee to participate in a tournament, and re-buys are sometimes permitted.

Some casinos, as well as general betting outlets, provide blackjack among a selection of casino-style games at electronic consoles. Video blackjack game rules are generally more favorable to the house; e.g., paying out only even money for winning blackjacks. Video and online blackjack games generally deal each round from a fresh shoe, rendering card counting ineffective in most situations.

Blackjack is a member of a large family of traditional card games played recreationally all around the world. Most of these games have not been adapted for casino play. Furthermore, the casino game development industry is very active in producing blackjack variants, most of which are ultimately not adopted for widespread use in casinos. The following are the prominent twenty-one themed comparing card games which have been adapted or invented for use in casinos and have become established in the gambling industry.


Examples of the many local traditional and recreational blackjack-like games include French/German Blackjack, called "Vingt-et-un" (French: Twenty-one) or "Siebzehn und Vier" (German: Seventeen and Four). The French/German game does not allow splitting. An ace can only count as eleven, but two aces count as a blackjack. It is mostly played in private circles and barracks. A British variation is called "Pontoon", the name being probably a corruption of "Vingt-et-un".

Blackjack is also featured in various television shows. Here are a few shows inspired by the game.


In 2002, professional gamblers around the world were invited to nominate great blackjack players for admission into the Blackjack Hall of Fame. Seven members were inducted in 2002, with new people inducted every year after. The Hall of Fame is at the Barona Casino in San Diego. Members include Edward O. Thorp, author of the 1960s book "Beat the Dealer" which proved that the game could be beaten with a combination of basic strategy and card counting; Ken Uston, who popularized the concept of team play; Arnold Snyder, author and editor of the "Blackjack Forum" trade journal; Stanford Wong, author and popularizer of the "Wonging" technique of only playing at a positive count, and several others.

Novels have been written around blackjack and the possibility of winning games via some kind of method. Among these were "The Blackjack Hijack" (Charles Einstein, 1976), later produced as the TV movie "Nowhere to Run", and "Bringing Down the House" (Ben Mezrich), also filmed as "21". An almost identical theme was shown in the 2004 Canadian film "The Last Casino".

In "The Hangover", an American comedy, four friends try to count cards to win back enough money to secure the release of their friend from the clutches of a notorious criminal they stole from the previous night while blacked out. A central part of the plot of "Rain Man" is that Raymond (Dustin Hoffman), an autistic savant, is able to win at blackjack by counting cards. In the 2014 film "The Gambler" we see Jim Bennett (Mark Wahlberg) playing high stakes Blackjack in order to win large sums of money. This movie displays different blackjack lingo and risky moves that have high rewards.


Regulation in the United Kingdom



</doc>
<doc id="3982" url="https://en.wikipedia.org/wiki?curid=3982" title="Bicarbonate">
Bicarbonate

In inorganic chemistry, bicarbonate (IUPAC-recommended nomenclature: hydrogencarbonate) is an intermediate form in the deprotonation of carbonic acid. It is a polyatomic anion with the chemical formula .

Bicarbonate serves a crucial biochemical role in the physiological pH buffering system.

The term "bicarbonate" was coined in 1814 by the English chemist William Hyde Wollaston. The prefix "bi" in "bicarbonate" comes from an outdated naming system and is based on the observation that there is twice as much carbonate () per sodium ion in sodium bicarbonate (NaHCO) and other bicarbonates than in sodium carbonate (NaCO) and other carbonates. The name lives on as a trivial name.

According to the Wikipedia article IUPAC nomenclature of inorganic chemistry, the prefix bi– is a deprecated way of indicating the presence of a single hydrogen ion. The recommended nomenclature today mandates explicit referencing of the presence of the single hydrogen ion: sodium hydrogen carbonate or sodium hydrogencarbonate. A parallel example is sodium bisulfite (NaHSO).

The bicarbonate ion (hydrogencarbonate ion) is an anion with the empirical formula and a molecular mass of 61.01 daltons; it consists of one central carbon atom surrounded by three oxygen atoms in a trigonal planar arrangement, with a hydrogen atom attached to one of the oxygens. It is isoelectronic with nitric acid . The bicarbonate ion carries a negative one formal charge and is an amphiprotic species which has both acidic and basic properties. It is both the conjugate base of carbonic acid ; and the conjugate acid of , the carbonate ion, as shown by these equilibrium reactions:

A bicarbonate salt forms when a positively charged ion attaches to the negatively charged oxygen atoms of the ion, forming an ionic compound. Many bicarbonates are soluble in water at standard temperature and pressure; in particular, sodium bicarbonate contributes to total dissolved solids, a common parameter for assessing water quality.

Bicarbonate () is a vital component of the pH buffering system of the human body (maintaining acid–base homeostasis). 70%–75% of CO in the body is converted into carbonic acid (HCO), which is the conjugate acid of and can quickly turn into it.

With carbonic acid as the central intermediate species, bicarbonate – in conjunction with water, hydrogen ions, and carbon dioxide – forms this buffering system, which is maintained at the volatile equilibrium required to provide prompt resistance to pH changes in both the acidic and basic directions. This is especially important for protecting tissues of the central nervous system, where pH changes too far outside of the normal range in either direction could prove disastrous (see acidosis or alkalosis).

Bicarbonate also serves much in the digestive system. It raises the internal pH of the stomach, after highly acidic digestive juices have finished in their digestion of food. Bicarbonate also acts to regulate pH in the small intestine. It is released from the pancreas in response to the hormone secretin to neutralize the acidic chyme entering the duodenum from the stomach.

Bicarbonate is the dominant form of dissolved inorganic carbon in sea water, and in most fresh waters. As such it is an important sink in the carbon cycle.

In freshwater ecology, strong photosynthetic activity by freshwater plants in daylight releases gaseous oxygen into the water and at the same time produces bicarbonate ions. These shift the pH upward until in certain circumstances the degree of alkalinity can become toxic to some organisms or can make other chemical constituents such as ammonia toxic. In darkness, when no photosynthesis occurs, respiration processes release carbon dioxide, and no new bicarbonate ions are produced, resulting in a rapid fall in pH.

The most common salt of the bicarbonate ion is sodium bicarbonate, NaHCO, which is commonly known as baking soda. When heated or exposed to an acid such as acetic acid (vinegar), sodium bicarbonate releases carbon dioxide. This is used as a leavening agent in baking.

The flow of bicarbonate ions from rocks weathered by the carbonic acid in rainwater is an important part of the carbon cycle.

Ammonium bicarbonate is used in digestive biscuit manufacture.

In diagnostic medicine, the blood value of bicarbonate is one of several indicators of the state of acid–base physiology in the body. It is measured, along with carbon dioxide, chloride, potassium, and sodium, to assess electrolyte levels in an electrolyte panel test (which has Current Procedural Terminology, CPT, code 80051).

The parameter "standard bicarbonate concentration" (SBC) is the bicarbonate concentration in the blood at a PCO of , full oxygen saturation and 36 °C.




</doc>
<doc id="3984" url="https://en.wikipedia.org/wiki?curid=3984" title="Bernie Federko">
Bernie Federko

Bernard Allan "Bernie" Federko (born May 12, 1956) is a Canadian retired professional ice hockey centre of Ukrainian ancestry who played fourteen seasons in the National Hockey League from 1976 through 1990.

Federko began playing hockey at a young age in his home town of Foam Lake, Saskatchewan. He was captain of the 1971 Bantam provincial champions. He also played Senior hockey with the local Foam Lake Flyers of the Fishing Lake Hockey League, winning the league scoring title as a bantam-aged player. Federko continued his career with the Saskatoon Blades of the WHL where he set and still holds the team record for assists. He played three seasons with the Blades, and in his final year with the club he led the league in assists and points in both the regular season "and" playoffs. As a reward, Federko was drafted 7th overall by the St. Louis Blues in the 1976 NHL Amateur Draft. He started the next season with the Kansas City Blues of the Central Hockey League and was leading the league in points when he was called up mid-season to play 31 games with St. Louis. He scored three hat tricks in those 31 games. In the 1978–79 NHL season, Federko developed into a bona fide star, as he scored 95 points.

Federko scored 100 points in a season four times, and was a consistent and underrated performer for the Blues. Federko scored at least 90 points in seven of the eight seasons between 1978 and 1986, and became the first player in NHL history to record at least 50 assists in 10 consecutive seasons. However, in an era when Wayne Gretzky was scoring 200 points a season, Federko never got the attention many felt he deserved. In 1986, in a poll conducted by GOAL magazine, he was named the most overlooked talent in hockey. His General Manager Ron Caron said he was "A great playmaker. He makes the average or above average player look like a star at times. He's such an unselfish player."

On March 19, 1988, Federko became the 22nd NHL player to record 1000 career points. After a poor season for Federko in 1988–89, he was traded to the Detroit Red Wings with Tony McKegney for future Blues star Adam Oates, and Paul MacLean. In Detroit, Federko re-united with former Blues head coach Jacques Demers, but he had to play behind Steve Yzerman and did not get his desired ice time. After his lowest point output since his rookie season, Federko decided to retire after the 1989–90 season, having played exactly 1,000 NHL games with his final game on April 1, 1990.

Less than a year after retiring as a player, the Blues retired number 24 in his honor on March 16, 1991. Federko was eventually inducted into the Hockey Hall of Fame in 2002. Currently, Federko is a television color commentator for Fox Sports Midwest during Blues broadcasts. Federko was the head coach/general manager of the St. Louis Vipers roller hockey team of the Roller Hockey International for the 1993 and 1994 seasons.


- First player to get 50 assists in 10 consecutive seasons in NHL history.




 


</doc>
<doc id="3985" url="https://en.wikipedia.org/wiki?curid=3985" title="Buffalo, New York">
Buffalo, New York

Buffalo is the second largest city in the U.S. state of New York and the largest city in Western New York. , the population was 256,304. The city is the county seat of Erie County and a major gateway for commerce and travel across the Canada–United States border, forming part of the bi-national Buffalo Niagara Region. As of the April 1, 2010, the metropolitan statistical area (MSA) had a population of 1,135,509; the combined statistical area (CSA), which adds Cattaraugus County, had a population of 1,215,826 inhabitants.

The Buffalo area was inhabited before the 17th century by the Native American Iroquois tribe and later by French colonizers. The city grew significantly in the 19th and 20th centuries as a result of immigration, the construction of the Erie Canal and rail transportation, and its close proximity to Lake Erie. This growth provided an abundance of fresh water and an ample trade route to the Midwestern United States while grooming its economy for the grain, steel and automobile industries that dominated the city's economy in the 20th century. Since the city's economy relied heavily on manufacturing, deindustrialization in the latter half of the 20th century led to a steady decline in population. While some manufacturing activity remains, Buffalo's economy has transitioned to service industries with a greater emphasis on healthcare, research and higher education, which emerged following the Great Recession.

Buffalo is on the eastern shore of Lake Erie, at the head of the Niagara River, 16 miles south of Niagara Falls. Its early embrace of electric power led to the nickname "The City of Light". The city is also famous for its urban planning and layout by Joseph Ellicott, an extensive system of parks designed by Frederick Law Olmsted, as well as significant architectural works. Its culture blends Northeastern and Midwestern traditions, with annual festivals including Taste of Buffalo and Allentown Art Festival, two professional sports teams (Buffalo Bills and Buffalo Sabres), and a thriving and progressive music and arts scene.

The city of Buffalo received its name from a nearby creek called Buffalo Creek. British military engineer Captain John Montresor made reference to "Buffalo Creek" in his 1764 journal, which may be the earliest recorded appearance of the name.

There are several theories regarding how Buffalo Creek received its name. While it is possible its name originated from French fur traders and Native Americans calling the creek "Beau Fleuve" (French for "Beautiful River"), it is also possible Buffalo Creek was named after the American buffalo, whose historical range may have extended into Western New York.

The first inhabitants of the State of New York are believed to have been nomadic Paleo-Indians, who migrated after the disappearance of Pleistocene glaciers during or before 7000 BCE.

Around 1000 CE, 1,000 years ago, the Woodland period began, marked by the rise of the Iroquois Confederacy and its tribes throughout the state.

During French exploration of the region in 1620, the region was occupied simultaneously by the agrarian Erie people, a tribe outside of the Five Nations of the Iroquois southwest of Buffalo Creek, and the Wenro people or "Wenrohronon", an Iroquoian-speaking tribal offshoot of the large Neutral Nation who lived along the inland south shore of Lake Ontario and at the east end of Lake Erie and a bit of its northern shore. For trading, the Neutral people made a living by growing tobacco and hemp to trade with the Iroquois, using animal paths or warpaths to travel and move goods across the state. These paths were later paved, and now function as major roads.

Later, during the Beaver Wars of the 1640s-1650s, the combined warriors of the Five Nations of the Iroquois Confederacy conquered the populous Neutrals and their peninsular territory, while the Senecas alone took out the Wenro and their territory, c. 1651–1653. Soon after, the Iroquois destroyed Erie nation and territory over their assistance to Huron people during the Beaver Wars.

Louis Hennepin and Sieur de La Salle made the earliest European discoveries of the upper Niagara and Ontario regions in the late 1600s. On August 7, 1679, La Salle launched a vessel, Le Griffon, that became the first full-sized ship to sail across the Great Lakes before it disappeared in Green Bay, Wisconsin.

After the American Revolution, the colony of New York—now a state—began westward expansion, looking for habitable land by following trends of the Iroquois. Land near fresh water was of considerable importance. New York and Massachusetts were fighting for the territory Buffalo lies on, and Massachusetts had the right to purchase all but a one-mile (1600-meter) wide portion of land. The rights to the Massachusetts' territories were sold to Robert Morris in 1791, and two years later to the Holland Land Company.

As a result of the war, in which the Iroquois tribe sided with the British Army, Iroquois territory was gradually reduced in the mid-to-late-1700s by European settlers through successive treaties statewide, such as the Treaty of Fort Stanwix (1784), the First Treaty of Buffalo Creek (1788), and the Treaty of Geneseo (1797). The Iroquois were corralled onto reservations, including Buffalo Creek. By the end of the 18th century, only of reservation territory remained.

Former slave Joseph "Black Joe" Hodges, and Cornelius Winney, a Dutch trader from Albany who arrived in 1789, were early settlers along the mouth of Buffalo Creek. The first white settlers along the creek were prisoners captured during the Revolutionary War. The first resident and landowner of Buffalo with a permanent presence was Captain William Johnston, a white Iroquois interpreter who had been in the area since the days after the Revolutionary War and who the Senecas granted creekside land as a gift of appreciation. His house stood at present-day Washington and Seneca streets.

On July 20, 1793, the Holland Land Purchase was completed, containing the land of present-day Buffalo, brokered by Dutch investors from Holland. The Treaty of Big Tree removed Iroquois title to lands west of the Genesee River in 1797. In the fall of 1797, Joseph Ellicott, the architect who helped survey Washington D.C. with brother Andrew, was appointed as the Chief of Survey for the Holland Land Company. Over the next year, he began to survey the tract of land at the mouth of Buffalo Creek. This was completed in 1803, and the new village boundaries extended from the creekside in the south to present-day Chippewa Street in the north and Carolina Street to the west, which is where most settlers remained for the first decade of the 19th century. Although the company named the settlement "New Amsterdam," the name did not catch on, reverting to Buffalo within ten years. Buffalo had the first road to Pennsylvania built in 1802 for migrants passing through to the Connecticut Western Reserve in Ohio.

In 1804, Ellicott designed a radial grid plan that would branch out from the village forming bicycle-like spokes, interrupted by diagonals, like the system used in the nation's capital. In the middle of the village was the intersection of eight streets, in what would become Niagara Square. Several blocks to the southeast he designed a semicircle fronting Main Street with an elongated park green, formerly his estate. This would be known as Shelton Square, at that time the center of the city (which would be dramatically altered in the mid-20th century), with the intersecting streets bearing the names of Dutch Holland Land Company members, today Erie, Church and Niagara streets. Lafayette Square also lies one block to the north, which was then bounded by streets bearing Iroquois names.

According to an early resident, the village had sixteen residences, a schoolhouse and two stores in 1806, primarily near Main, Swan and Seneca streets. There were also blacksmith shops, a tavern and a drugstore. The streets were small at 40 feet wide, and the village was still surrounded by woods. The first lot sold by the Holland Land Company was on September 11, 1806, to Zerah Phelps. By 1808, lots would sell from $25 to $50.

In 1804, Buffalo's population was estimated at 400, similar to Batavia, but Erie County's growth was behind Chautauqua, Genesee and Wyoming counties. Neighboring village Black Rock to the northwest (today a Buffalo neighborhood) was also an important center. Horatio J. Spafford noted in "A Gazetteer of the State of New York" that in fact, despite the growth the village of Buffalo had, Black Rock "is deemed a better trading site for a great trading town than that of Buffalo," especially when considering the regional profile of mundane roads extending eastward. Before the east-to-west turnpike was completed, travelling from Albany to Buffalo would take a week, while even a trip from nearby Williamsville to Batavia could take upwards of three days.

Although slavery was rare in the state, limited instances of slavery had taken place in Buffalo during the early part of the 19th century. General Peter Buell Porter is said to have had five slaves during his time in Black Rock, and several news ads also advertised slaves for sale.

In 1810, a courthouse was built. By 1811, the population was 500, with many people farming or doing manual labor. The first newspaper to be published was the "Buffalo Gazette" in October that same year.

On December 31, 1813, Buffalo and the village of Black Rock were burned by the British after the Battle of Buffalo. The battle and subsequent fire was in response to the unprovoked destruction of Niagara-on-the-Lake, then known as "Newark," by American forces. On August4, 1814, British forces under Lt. Colonel John Tucker and Lt. Colonel William Drummond, General Gordon Drummond's nephew, attempted to raid Black Rock and Buffalo as part of a diversion to force an early surrender at Fort Erie the next day, but were defeated by a small force of American riflemen under Major Lodwick Morgan at the Battle of Conjocta Creek, and withdrew back into Canada. Consequently, Fort Erie's siege under Gordon Drummond later failed, and British forces withdrew. Though only three buildings remained in the village, rebuilding was swift, finishing in 1815.

The population in 1840 was 18,213. The village of Buffalo was part of and the seat of Niagara County until the legislature passed an act separating the two on April 2, 1861.

On October 26, 1825, the Erie Canal was completed, formed from part of Buffalo Creek, with Buffalo a port-of-call for settlers heading westward. At the time, the population was about 2,400. By 1826, the 130 sq. mile Buffalo Creek Reservation at the western border of the village was transferred to Buffalo. The Erie Canal brought a surge in population and commerce, which led Buffalo to incorporate as a city in 1832. The canal area was mature by 1847, with passenger and cargo ship activity leading to congestion in the harbor.

The mid-1800s saw a population boom, with the city doubling in size from 1845 to 1855. In 1855, almost two-thirds of the city's population were foreign-born immigrants, largely a mix of unskilled or educated Irish and Germans Catholics, who began self-segregating in different parts of the city. The Irish immigrants planted their roots along the railroad-heavy Buffalo River and Erie Canal to the southeast, to which there is still a heavy presence today; German immigrants found their way to the East Side, living a more laid-back, residential life. Some immigrants were apprehensive about the change of environment and left the city for the western region, while others tried to stay behind in the hopes of expanding their native cultures.

Fugitive black slaves began to make their way northward to Buffalo in the 1840s, and many of them settled on the city's East Side. In 1845, construction began on the Macedonia Baptist Church, a meeting spot in the Michigan and William Street neighborhood where blacks first settled. It was also an important meeting place for the abolitionist movement. Buffalo was a terminus point of the Underground Railroad with many fugitive slaves crossing the Niagara River to Fort Erie, Ontario in search of freedom.

During the 1840s, Buffalo's port continued to develop. Both passenger and commercial traffic expanded with some 93,000 passengers heading west from the port of Buffalo. Grain and commercial goods shipments led to repeated expansion of the harbor. In 1843, the world's first steam-powered grain elevator was constructed by local merchant Joseph Dart and engineer Robert Dunbar. "Dart's Elevator" enabled faster unloading of lake freighters along with the transshipment of grain in bulk from barges, canal boats, and rail cars. By 1850, the city's population was 81,000.

In 1860, many railway companies and lines crossed through and terminated in Buffalo. Major ones were the Buffalo, Bradford and Pittsburgh Railroad (1859), Buffalo and Erie Railroad and the New York Central Railroad (1853). During this time, Buffalonians controlled a quarter of all shipping traffic on Lake Erie, and shipbuilding was a thriving industry for the city.

Later, the Lehigh Valley Railroad would have its line terminate at Buffalo in 1867.

At the dawn of the 20th century, local mills were among the first to benefit from hydroelectric power generated by the Niagara River. The city got the nickname "City of Light" at this time due to the widespread electric lighting. It was also part of the automobile revolution, hosting the brass era car builders Pierce Arrow and the Seven Little Buffaloes early in the century. At the same time, an exit of local entrepreneurs and industrial titans brought about a nascent stage that would see the city lose its competitiveness against Pittsburgh, Cleveland and Detroit.

President William McKinley was shot and mortally wounded by an anarchist at the Pan-American Exposition in Buffalo on September 6, 1901. McKinley died in the city eight days later and Theodore Roosevelt was sworn in at the Wilcox Mansion. The Great Depression of 1929–39 saw severe unemployment, especially among working-class men. The New Deal relief programs operated full force. The city became a stronghold of labor unions and the Democratic Party.

During World War II, Buffalo saw the return of prosperity and full employment due to its position as a manufacturing center. As one of the most populous cities of the 1950s, Buffalo's economy revolved almost entirely on its manufacturing base. Major companies such as Republic Steel and Lackawanna Steel employed tens of thousands of Buffalonians. Integrated national shipping routes would use the Soo Locks near Lake Superior and a vast network of railroads and yards that crossed the city.

Lobbying by local businesses and interest groups against the St. Lawrence Seaway began in the 1920s, long before its construction in 1957, which cut the city off from valuable trade routes. Its approval was reinforced by legislation shortly before its construction. Shipbuilding in Buffalo, such as the American Ship Building Company, shut down in 1962, ending an industry that had been a sector of the city's economy since 1812, and a direct result of reduced waterfront activity. With deindustrialization, and the nationwide trend of suburbanization; the city's economy began to deteriorate. Like much of the Rust Belt, Buffalo, home to more than half a million people in the 1950s, has seen its population decline as heavy industries shut down and people left for the suburbs or other cities.

Buffalo is on Lake Erie's eastern end, opposite Fort Erie, Ontario, Canada. It is at the origin of the Niagara River, which flows northward over Niagara Falls and into Lake Ontario. The city is south-southeast from Toronto.

Relative to downtown, the city is generally flat with the exception of area surrounding North and High streets, where a hill of 90 feet gradually develops approaching from the south and north. The Southtowns include the Boston Hills, while the Appalachian Mountains sit in the Southern Tier below them. To the north and east, the region maintains a flatter profile descending to Lake Ontario. Various types of shale, limestone and lagerstätten are prevalent in the geographic makeup of Buffalo and surrounding areas, which line the waterbeds within and bordering the city.

Although there have not been any recent or significant earthquakes, Buffalo sits atop of the Southern Great Lakes Seismic Zone, which is part of the Great Lakes tectonic zone.

Buffalo has four channels that flow through its boundaries: the Niagara River, Buffalo River and Creek, Scajaquada Creek, and the Black Rock Canal, which is adjacent to the Niagara River.

According to the United States Census Bureau, the city has an area of , of which is land and the rest water. The total area is 22.66% water.

Buffalo's architecture is diverse, with a collection of buildings from the 19th and 20th centuries. Most structures and works are still standing, such as the country's largest intact parks system designed by Frederick Law Olmsted and Calvert Vaux. At the end of the 19th century, the Guaranty Building—constructed by Louis Sullivan—was a prominent example of an early high-rise skyscraper. The Darwin D. Martin House designed by Frank Lloyd Wright and built between 1903 and 1905, is considered to be one of the most important projects from Wright's Prairie School era. The Larkin Administration Building, now demolished, was Frank Lloyd Wright's first commercial commission. The 20th century saw works such as the Art Deco-style Buffalo City Hall and Buffalo Central Terminal, Electric Tower, the Richardson Olmsted Complex, and the Rand Building. Urban renewal from the 1950s–1970s gave way to the construction of the Brutalist-style Buffalo City Court Building and One Seneca Tower—formerly the HSBC Center, the city's tallest building.

Buffalo has a humid continental climate (Köppen "Dfb" bordering on "Dfa"), which is common in the Great Lakes region. Buffalo has snowy winters, but it is rarely the snowiest city in New York state. The Blizzard of 1977 resulted from a combination of high winds and snow accumulated on land and on frozen Lake Erie. Snow does not typically impair the city's operation, but can cause significant damage during the autumn as with the October 2006 storm. In November 2014, the region had a record-breaking storm, producing over of snow; this storm was named "Snowvember".

Buffalo has the sunniest and driest summers of any major city in the Northeast, but still has enough rain to keep vegetation green and lush. Summers are marked by plentiful sunshine and moderate humidity and temperature. Obscured by the notoriety of Buffalo's winter snow is the fact Buffalo benefits from other lake effects such as the cooling southwest breezes off Lake Erie in summer that gently temper the warmest days. As a result, temperatures only rise above three times in the average year, and the Buffalo station of the National Weather Service has never recorded an official temperature of or more. Rainfall is moderate but typically occurs at night. Lake Erie's stabilizing effect continues to inhibit thunderstorms and enhance sunshine in the immediate Buffalo area through most of July. August usually has more showers and is hotter and more humid as the warmer lake loses its temperature-stabilizing influence. The highest recorded temperature in Buffalo was on August 27, 1948 and the lowest recorded temperature was , which occurred twice, on February 9, 1934 and February 2, 1961.

In his 2019 State of the City address, Mayor Byron Brown dubbed Buffalo a “Climate Refuge City” because the city is unusually well-insulated against climate change. Experts say the region’s cool climate and ample fresh water could make it an attractive destination as the planet heats up.

Like most former industrial cities of the Great Lakes region in the United States, Buffalo is recovering from an economic depression from suburbanization and the loss of its industrial base. The city's population peaked in 1950 when it was the 15th largest city in the United States, down from the 8th largest city in America in 1900, and its population has been spreading out to the suburbs every census since then.

At the 2010 Census, the city's population was 50.4% White (45.8% non-Hispanic White alone), 38.6% Black or African-American, 0.8% American Indian and Alaska Native, 3.2% Asian, 3.9% from some other race and 3.1% from two or more races, while 10.5% of the population was Hispanic or Latino of any race. Since 2003, there has been an ever-growing number of Burmese refugees, mostly of the Karen ethnicity, with an estimated 4,665 now residing in Buffalo as of 2016.

The city's median household income is $24,536 and the median family income is $30,614. Males have a median income of $30,938 versus $23,982 for females. The city's per capita income is $14,991. Of the population 26.6%, and 23% of families, are below the poverty line. Of the total population, 38.4% of those under the age of 18 and 14% of those 65 and older live below the poverty line.

Buffalo's economic sectors include industrial, light manufacturing, high technology and services. The State of New York, with over 15,000 employees, is the city's largest employer. Other major employers include the United States government, Kaleida Health, M&T Bank (which is headquartered in Buffalo), the University at Buffalo, General Motors, Time Warner Cable and Tops Friendly Markets. Buffalo is home to Rich Products, Canadian brewer Labatt, cheese company Sorrento Lactalis, Delaware North Companies and New Era Cap Company. More recently, the Tesla Gigafactory 2 opened in South Buffalo in summer 2017, as a result of the Buffalo Billion program.

The loss of traditional jobs in manufacturing, rapid suburbanization and high labor costs have led to economic decline and made Buffalo one of the poorest U.S. cities with populations of more than 250,000 people. An estimated 28.7–29.9% of Buffalo residents live below the poverty line, behind either only Detroit, or only Detroit and Cleveland. Buffalo's median household income of $27,850 is third-lowest among large cities, behind only Miami and Cleveland; however the metropolitan area's median household income is $57,000. This, in part, has led to the Buffalo-Niagara Falls metropolitan area having the most affordable housing market in the U.S. The quarterly NAHB/Wells Fargo Housing Opportunity Index (HOI) noted nearly 90% of the new and existing homes sold in the metropolitan area during the second quarter were affordable to families making the area's median income of $57,000. , the median home price in the city was $95,000.

Buffalo's economy has begun to see significant improvements since the early 2010s. Money from New York State Governor Andrew Cuomo through a program known locally as "Buffalo Billion" has brought new construction, increased economic development, and hundreds of new jobs to the area. As of March 2015, Buffalo's unemployment rate was 5.9%, slightly above the national average of 5.5%. In 2016, the U.S. Bureau of Economic Analysis valued the Buffalo area's economy at $54.9 billion.

Buffalo's crime rate is higher than the national average. In 2015, there were 41 murders, 1,033 robberies, and 1,640 assaults. In 2016, bizjournals.com published an article including an FBI report that ranked Buffalo's violent crime rate as the 15th-worst in the nation.

Buffalo's cuisine encompasses a variety of cultural contributions, including Sicilian, Italian, Irish, Jewish, German, Polish, African-American, Greek and American influences. In 2015, the National Geographic Society ranked Buffalo third on their list of "The World's Top Ten Food Cities". Locally owned restaurants offer Chinese, German, Japanese, Korean, Vietnamese, Thai, Mexican, Sicilian, Italian, Arab, Indian, Myanmar, Caribbean, soul food and French cuisine. Buffalo's local pizzerias differ from the thin-crust New York–style pizzerias and deep-dish Chicago-style pizzerias and is locally known for being a midpoint between the two. The Beef on weck sandwich, kielbasa, sponge candy, pastry hearts, pierogi and haddock fish fries are local favorites, as is a loganberry-flavored beverage that remains relatively obscure outside of Western New York and Southern Ontario. Teressa Bellissimo first prepared the now widespread Chicken Wings at the Anchor Bar in October 1964.

Buffalo has several well-known food companies. Non-dairy whipped topping was invented in Buffalo in 1945 by Robert E. Rich, Sr. His company, Rich Products, is one of the city's largest private employers. General Mills was organized in Buffalo and Gold Medal brand flour, Wheaties, Cheerios and other General Mills brand cereals are manufactured here. Archer Daniels Midland operates its largest flour mill in the city. Buffalo is home to one of the world's largest privately held food companies, Delaware North Companies, which operates concessions in sports arenas, stadiums, resorts and many state and federal parks. The Taste of Buffalo and National Buffalo Wing Festival showcase food from the Buffalo area. These are two of the many festivals that take place in Buffalo during the summer.

Buffalo is home to over 50 private and public art galleries, most notably the Albright-Knox Art Gallery, home to a collection of modern and contemporary art, and the Burchfield-Penney Art Center. In 2012, "AmericanStyle" ranked Buffalo twenty-fifth in its list of top mid-sized cities for art. It is also home to many independent media and literary arts organizations like Squeaky Wheel Film and Media Arts Center. The Buffalo area's largest theater is Shea's Performing Arts Center, designed to accommodate 4,000 people with interiors by Louis Comfort Tiffany. Built in 1926, the theater presents Broadway musicals and concerts. The theater community in the Buffalo Theater District includes over 20 professional companies.

The Allentown Art Festival showcases local and national artists every summer, in Buffalo's Allentown district. Buffalo is also home to the Freedom Wall, which is at the corner of Michigan Avenue and East Ferry Street. The Albright-Knox Art Gallery Public Art Initiative commissioned the Freedom Wall with support from the Niagara Frontier Transportation Authority.

The Buffalo Philharmonic Orchestra, which performs at Kleinhans Music Hall, is one of the city's most prominent performing arts institutions. During the 1960s and 1970s, under the musical leadership of Lukas Foss and Michael Tilson Thomas, the Philharmonic collaborated with Grateful Dead and toured with the Boston Pops Orchestra.

Buffalo has the roots of many jazz and classical musicians, and it is also the founding city for several mainstream bands and musicians, Jazz fusion band Spyro Gyra and jazz saxophonists Grover Washington Jr. also got their starts in Buffalo. Composer Harold Arlen, who wrote “Somewhere over the Rainbow”, was born and started his career in Buffalo. Pianist and composer Leonard Pennario was born in Buffalo in 1924 and made his debut concert at Carnegie Hall in 1943. Buffalo's "Colored Musicians Club", an extension of what was long ago a separate musicians' union local, is thriving today and maintains a significant jazz history within its walls. Well-known indie artist Ani DiFranco hails from Buffalo.

Although the region's primary tourism destination is Niagara Falls to the north, Buffalo's tourism relies on historical attractions and outdoor recreation. The city's points of interest include the Edward M. Cotter fireboat, considered the world's oldest active fireboat and is a United States National Historic Landmark, Buffalo and Erie County Botanical Gardens, the Buffalo and Erie County Historical Society, Buffalo Museum of Science, the Buffalo Zoo—the third oldest in the United States—Forest Lawn Cemetery, Buffalo and Erie County Naval & Military Park, the Anchor Bar and Darwin D. Martin House.

Redeveloped historical neighborhoods have also attracted tourism. The site of the former Erie Canal Harbor, Canalside has become a popular destination for tourists and residents since 2007 when Buffalo and the New York Power Authority began to redevelop the former site of the Buffalo Memorial Auditorium into historically accurate canals. Larkin Square, in the former "Hydraulics" neighborhood and headquarters for the Larkin Company, has also become popular, featuring food trucks, concerts, and other events during the summer.

Buffalo is one of the largest Polish-American centers in the United States. As a result, many aspects of Polish culture have found a home in the city from food to festivals. One of the best examples is the yearly celebration of Easter Monday, known to many Eastern Europeans as Dyngus Day.

Buffalo and the surrounding region is home to three major leagues professional sports teams. The NHL's Buffalo Sabres and the NLL’s Buffalo Bandits both play in KeyBank Center, while the NFL's Buffalo Bills play in suburban Orchard Park, New York, where they have been since 1973.

The Bills, established in 1959, played in War Memorial Stadium until 1973, when Rich Stadium, now New Era Field, opened. The city of Buffalo brought home its two major league sports titles when the Bills won the American Football League Championship in both 1964 and 1965. The team competes in the AFC East division. The Bills currently have 10 Division Titles to their name. Since the AFL–NFL merger in 1970, the Bills have won the AFC Championship four times (1990, 1991, 1992, 1993), resulting in four lost Super Bowls (Super Bowl XXV, Super Bowl XXVI, Super Bowl XXVII and Super Bowl XXVIII). 

The Sabres, established in 1970, played in Buffalo Memorial Auditorium until 1996, when Marine Midland Arena, now KeyBank Center opened. The team plays in the Atlantic Division of the NHL. The team has won one Presidents' Trophy (2006–2007) and three Prince of Wales Trophies (conference championships) (1974–1975, 1979–1980 and 1998–1999). However, unlike the Bills, the Sabres don't have a league championship, having lost the 1975 Stanley Cup to the Philadelphia Flyers and the 1999 Stanley Cup to the Dallas Stars. Since 2014, both the Bills and Sabres have been owned by Terrence Pegula, a key investor in Buffalo's revitalization efforts.

The Buffalo Bandits where established in 1992 and played their home games in Buffalo Memorial Auditorium until 1996 when they followed the Sabres to Marine Midland Arena. They have won eight division championships and four league championships (1991–1992, 1992–1993, 1995–1996 and 2007–2008)

The Buffalo Braves played in the National Basketball Association from 1970 to 1978, with their home games held at the Buffalo Memorial Auditorium. After the team struggled financially, it relocated to California and became the San Diego Clippers.

Buffalo is also home to several minor sports teams, including the Buffalo Bisons (baseball; an affiliate of the MLB's Toronto Blue Jays since 2014), FC Buffalo (soccer) as well as a professional women's team, the Buffalo Beauts (hockey). The Buffalo Beauts were the NWHL Champions in 2016-2017 and have appeared in all four NWHL finals.

The Buffalo Bulls are a Division I college team representing the State University of New York at Buffalo. The Bulls are the winners of the 2008 MAC Football Championship, as well as three MAC East Championships (2007, 2008, 2018), and the 2019 Bahamas Bowl Title. The Bulls Men's Basketball Team has won 4 MAC Championships in 5 years (2015, 2016, 2018, 2019) as well as 4 Regular Season Championships (2009, 2015, 2018, 2019), and 5 Divisions Titles (2009, 2014, 2015, 2018, 2019).
The Bulls Women's Basketball team has won two MAC Championships (2016, 2019) and has advanced to the round of 32 twice (2018, 2019) as well as the Sweet Sixteen in 2018.

<nowiki>*</nowiki> American Football League (AFL) championships were earned prior to the NFL merging with the AFL in 1970.
† Date refers to current incarnation; Buffalo Bisons previously operated from the 1870s until 1970 and the current Bisons count this team as part of their history.

The Buffalo parks system has over 20 parks with several parks accessible from any part of the city. The Olmsted Park and Parkway System is the hallmark of Buffalo's many green spaces. Three-fourths of city parkland is part of the system, which comprises six major parks, eight connecting parkways, nine circles and seven smaller spaces. Constructed in 1868 by Frederick Law Olmsted and his partner Calvert Vaux, the system was integrated into the city and marks the first attempt in America to lay out a coordinated system of public parks and parkways. The Olmsted-designed portions of the Buffalo park system are listed on the National Register of Historic Places and are maintained by the Buffalo Olmsted Parks Conservancy (BOPC), a non-profit, for public benefit corporation which serves as the city's parks department. It is the first non-governmental organization of its kind to serve in such a capacity in the United States.

Situated at the confluence of Lake Erie and the Buffalo and Niagara rivers, Buffalo is a waterfront city. Its rise to economic power came through its waterways in the form of transshipment, manufacturing, and an endless source of energy. Buffalo's waterfront remains, though to a lesser degree, a hub of commerce, trade and industry. Beginning in 2009, a significant portion of Buffalo's waterfront began to be transformed into a focal point for social and recreational activity. To this end, Buffalo Harbor State Park, nicknamed "Outer Harbor", was opened in 2014. Buffalo's intent was to stress its architectural and historical heritage to create a tourism destination, and early data indicates they were successful.

At the municipal level, the City of Buffalo has a mayor and a council of nine councilmembers. Buffalo also serves as the seat of Erie County with some of the 11 members of county legislature representing at least a portion of Buffalo. At the state level, there are three states assemblymembers and two state senators representing parts of the city proper. At the federal level, Buffalo is the heart of in the House of Representatives, represented by Democrat Brian Higgins.

In a trend common to northern "Rust Belt" regions, the Democratic Party has dominated Buffalo's political life for the last half-century. The last time anyone other than a Democrat held the position of Mayor in Buffalo was Chester A. Kowal in 1965. In 1977, Democratic Mayor James D. Griffin was elected as the nominee of two minor parties, the Conservative Party and the Right to Life Party, after he lost the Democratic primary for Mayor to then Deputy State Assembly Speaker Arthur Eve. Griffin switched political allegiances several times during his 16 years as Mayor, generally hewing to socially conservative platforms.

Griffin's successor, Democrat Anthony M. Masiello (elected in 1993) continued to campaign on social conservatism, often crossing party lines in his endorsements and alliances. However, in 2005, Democrat Byron Brown was elected the city's first African-American mayor in a landslide (64%–27%) over Republican Kevin Helfer, who ran on a conservative platform. In 2013, the Conservative Party endorsed Brown for a third term because of his pledge to cut taxes. This change in local politics was preceded by a fiscal crisis in 2003 when years of economic decline, a diminishing tax-base and civic mismanagement left the city deep in debt and on the edge of bankruptcy. At New York State Comptroller Alan Hevesi's urging, the state took over the management of Buffalo's finances, appointing the Buffalo Fiscal Stability Authority, a New York State public-benefit corporation. Mayor Tony Masiello began conversations about merging the city with the larger Erie County government the following year, but they came to nought.

The offices of the Buffalo District, US Army Corps of Engineers are next to the Black Rock Lock in the Erie Canal's Black Rock channel. In addition to maintaining and operating the lock, the District plans, designs, constructs and maintains water resources projects from Toledo, Ohio to Massena, New York. These include the flood-control dam at Mount Morris, New York, oversight of the lower Great Lakes (Lake Erie and Lake Ontario), review and permitting of wetlands construction, and remedial action for hazardous waste sites. Buffalo is also the home of a major office of the National Weather Service (NOAA), which serves all of western and much of central New York State. Buffalo is home to one of the 56 national FBI field offices. The field office covers all of Western New York and parts of the Southern Tier and Central New York. The field office operates several task forces in conjunction with local agencies to help combat issues such as gang violence, terrorism threats and health care fraud. Buffalo is also the location of the chief judge, United States Attorney and administrative offices for the United States District Court for the Western District of New York.

Buffalo's major newspaper is "The Buffalo News". Established in 1880 as the "Buffalo Evening News", the newspaper has 181,540 in daily circulation and 266,123 on Sundays. With the radio stations WBEN (later WBEN-AM), WBEN-FM, and television station WBEN-TV, Buffalo's first and for several years only television station, the Buffalo Evening News dominated the local media market until 1977, when the newspaper and the stations were separated. The stations showed their affiliation with the newspaper in their call sign: WBEN. Other newspapers in the Buffalo area include "The Public", "The Challenger Community News", and "Buffalo Business First."

According to Nielsen Media Research, the Buffalo television market is the 52nd largest in the United States .

Movies shot with significant footage of Buffalo include: "Hide in Plain Sight" (1980), "Tuck Everlasting" (1981), "Best Friends" (1982), "The Natural" (1984), "Vamping" (1984), "Canadian Bacon" (1995), "Buffalo '66" (1998), "Manna from Heaven" (2002), "Bruce Almighty "(2003), "The Savages" (2007), "Henry's Crime" (2011), "" (2014), "Teenage Mutant Ninja Turtles: Out of The Shadows" (2016), "Marshall" (2016), "Accidental Switch" (2016), and "The American Side" (2017). Although additional movies, such as "Promised Land" (2012), have used Buffalo as a setting, filming often takes place in other locations such as Pittsburgh or Canada. High production costs are blamed for filmmakers shooting all or most of their Buffalo-based scenes elsewhere. The Buffalo History Museum has compiled a lengthy and comprehensive filmography of feature films, documentary films, and television productions filmed or set in the Buffalo area.

Buffalo Public Schools serve most of the city of Buffalo. The city has 78 public schools, including a growing number of charter schools. , the total enrollment was 41,089 students with a student-teacher ratio of 13.5 to 1. The graduation rate is up to 52% in 2008, up from 45% in 2007, and 50% in 2006. More than 27% of teachers have a master's degree or higher and the median amount of experience in the field is 15 years. The metropolitan area has 292 schools with 172,854 students.

Buffalo's magnet school system attracts students with special interests, such as science, bilingual studies, and Native American studies. Specialized facilities include the Buffalo Elementary School of Technology; the Dr Martin Luther King Jr., Multicultural Institute; the International School; the Dr. Charles R. Drew Science Magnet; BUILD Academy; Leonardo da Vinci High School; PS 32 Bennett Park Montessori; the Buffalo Academy for Visual and Performing Arts, BAVPA; the Riverside Institute of Technology; Lafayette High School/Buffalo Academy of Finance; Hutchinson Central Technical High School; Burgard Vocational High School; South Park High School; and the Emerson School of Hospitality.

The city is home to 47 private schools and the metropolitan region has 150 institutions. Most private schools, such as Bishop Timon – St. Jude High School, Canisius High School (the city's only Jesuit school), Mount Mercy Academy, and Nardin Academy have a Catholic affiliation. In addition, there are two Islamic schools, Darul Uloom Al-Madania and Universal School of Buffalo. There are also nonsectarian options including The Buffalo Seminary (the only private, nonsectarian, all-girls school in Western New York state), Nichols School and numerous Charter Schools.

Private school tuition is approximately 40% less than Buffalo Public Schools' per student spending. Private schools graduate nearly 100% of students, public schools only approximately 30%.

Complementing its standard function, the Buffalo Public Schools Adult and Continuing Education Division provides education and services to adults throughout the community. In addition, the Career and Technical Education Department offers more than 20 academic programs, and is attended by about 6,000 students each year.

The State University of New York (SUNY) operates three institutions within the city of Buffalo. The State University of New York at Buffalo is known as "Buffalo" or "UB" and is the largest public university in New York. The University at Buffalo is the only university in Buffalo and is a nationally ranked tier 1 research university. Buffalo State College and Erie Community College are a college and a community college, respectively. Additionally, the private institutions Canisius College and D'Youville College are within the city.
The city is home to two private healthcare systems, which combined operate eight hospitals and countless clinics in the greater metropolitan area, as well as three public hospitals operated by Erie County and the State of New York. Oishei Children's Hospital opened in November 2017 and is the only long-standing children's hospital in New York. Buffalo General Medical Center and the Gates Vascular Institute have earned top rankings in the US for their cutting-edge research and treatment into the stroke and neurological care. Erie County Medical Center has been accredited as a Level One Trauma Center and serves as the trauma and burn care center for Western New York, much of the Southern Tier, and portions of Northwestern Pennsylvania and Ontario, Canada. Roswell Park has also become recognized as one of the United States' leading cancer treatment and research centers, and it recruits physicians and researchers from across the world to come live and work in the Buffalo area.


The Niagara Frontier Transportation Authority (NFTA) operates Buffalo Niagara International Airport, reconstructed in 1997, in the suburb of Cheektowaga. The airport serves Western New York and much of the Finger Lakes and Southern Tier Regions.

The Buffalo Metro Rail, also operated by the NFTA, is a long, single line light rail system that extends from Erie Canal Harbor in downtown Buffalo to the University Heights district (specifically, the South Campus of University at Buffalo) in the city's northeastern part. The line's downtown section runs above ground and is free of charge to passengers. North of Fountain Plaza Station, at the northern end of downtown, the line moves underground until it reaches its northern terminus at University Heights. Passengers pay a fare to ride this section of the rail.

Two train stations, Buffalo-Depew and Buffalo-Exchange Street, serve the city and are operated by Amtrak. Historically, the city was a major stop on through routes between Chicago and New York City through the lower Ontario peninsula.

Buffalo is at the Lake Erie's eastern end and serves as a playground for many personal yachts, sailboats, power boats and watercraft. The city's extensive breakwall system protects its inner and outer harbors, which are maintained at commercial navigation depths for Great Lakes freighters. A Lake Erie tributary that flows through south Buffalo is the Buffalo River and Buffalo Creek.

Eight New York State highways, one three-digit Interstate Highway and one U.S. Highway traverse the city of Buffalo. New York State Route 5, commonly referred to as Main Street within the city, enters through Lackawanna as a limited-access highway and intersects with Interstate 190, a north-south highway connecting Interstate 90 in the southeastern suburb of Cheektowaga with Niagara Falls. NY 354 (Clinton Street) and NY 130 (Broadway) are east to west highways connecting south and downtown Buffalo to the eastern suburbs of West Seneca and Depew. NY 265 (Delaware Avenue) and NY 266 (Niagara Street and River Road) both start in downtown Buffalo and end in the city of Tonawanda. One of three U.S. highways in Erie County, the other two being U.S. 20 (Transit Road) and U.S. 219 (Southern Expressway), U.S. 62 (Bailey Avenue) is a north to south trunk road that enters the city through Lackawanna and exits at the Amherst town border at a junction with NY 5. Within the city, the route passes by light industrial developments and high-density areas of the city. Bailey Avenue has major intersections with Interstate 190 and the Kensington Expressway.

Three major expressways serve Buffalo. The Scajaquada Expressway (NY 198) is primarily a limited access highway connecting Interstate 190 near Unity Island to New York State Route 33, which starts at the edge of downtown and the city's East Side, continues through heavily populated areas of the city, intersects with Interstate 90 in Cheektowaga and ends at the airport. The Peace Bridge is a major international crossing near the city's Black Rock district that connects Buffalo with Fort Erie and Toronto via the Queen Elizabeth Way.

The city of Buffalo has a higher than average percentage of households without a car. In 2015, 30 percent of Buffalo households lacked a car, and decreased slightly to 28.2 percent in 2016. The national average was 8.7 percent in 2016. Buffalo averaged 1.03 cars per household in 2016, compared to a national average of 1.8.
Buffalo's water system is operated by Veolia Water. To reduce large-scale ice blockage in the Niagara River—with resultant flooding, ice damage to docks and other waterfront structures, as well as blockage of the water intakes for the hydro-electric power plants at Niagara Falls—the New York Power Authority and Ontario Power Generation have jointly operated the Lake Erie-Niagara River Ice Boom since 1964. The boom is installed on December 16, or when the water temperature reaches , whichever happens first. The boom is opened on April 1 unless there is more than of ice remaining in Eastern Lake Erie. When in place, the boom stretches from the outer breakwall at Buffalo Harbor almost to the Canadian shore near the ruins of the pier at Erie Beach in Fort Erie. The boom was originally made of wooden timbers, but these have been replaced by steel pontoons.

Buffalo has 15 of sister cities:




</doc>
<doc id="3986" url="https://en.wikipedia.org/wiki?curid=3986" title="Benjamin Franklin">
Benjamin Franklin

Benjamin Franklin ( April 17, 1790) was an American polymath and one of the Founding Fathers of the United States. Franklin was a leading writer, printer, political philosopher, politician, Freemason, postmaster, scientist, inventor, humorist, civic activist, statesman, and diplomat. As a scientist, he was a major figure in the American Enlightenment and the history of physics for his discoveries and theories regarding electricity. As an inventor, he is known for the lightning rod, bifocals, and the Franklin stove, among other inventions. He founded many civic organizations, including the Library Company, Philadelphia's first fire department and the University of Pennsylvania.

Franklin earned the title of "The First American" for his early and indefatigable campaigning for colonial unity, initially as an author and spokesman in London for several colonies. As the first United States Ambassador to France, he exemplified the emerging American nation. Franklin was foundational in defining the American ethos as a marriage of the practical values of thrift, hard work, education, community spirit, self-governing institutions, and opposition to authoritarianism both political and religious, with the scientific and tolerant values of the Enlightenment. In the words of historian Henry Steele Commager, "In a Franklin could be merged the virtues of Puritanism without its defects, the illumination of the Enlightenment without its heat." To Walter Isaacson, this makes Franklin "the most accomplished American of his age and the most influential in inventing the type of society America would become."

Franklin became a successful newspaper editor and printer in Philadelphia, the leading city in the colonies, publishing the "Pennsylvania Gazette" at the age of 23. He became wealthy publishing this and "Poor Richard's Almanack", which he authored under the pseudonym "Richard Saunders". After 1767, he was associated with the "Pennsylvania Chronicle", a newspaper that was known for its revolutionary sentiments and criticisms of British policies.

He pioneered and was the first president of Academy and College of Philadelphia which opened in 1751 and later became the University of Pennsylvania. He organized and was the first secretary of the American Philosophical Society and was elected president in 1769. Franklin became a national hero in America as an agent for several colonies when he spearheaded an effort in London to have the Parliament of Great Britain repeal the unpopular Stamp Act. An accomplished diplomat, he was widely admired among the French as American minister to Paris and was a major figure in the development of positive Franco-American relations. His efforts proved vital for the American Revolution in securing shipments of crucial munitions from France.

He was promoted to deputy postmaster-general for the British colonies in 1753, having been Philadelphia postmaster for many years, and this enabled him to set up the first national communications network. During the revolution, he became the first United States Postmaster General. He was active in community affairs and colonial and state politics, as well as national and international affairs. From 1785 to 1788, he served as governor of Pennsylvania. He initially owned and dealt in slaves but, by the late 1750s, he began arguing against slavery and became an abolitionist.

His life and legacy of scientific and political achievement, and his status as one of America's most influential Founding Fathers, have seen Franklin honored more than two centuries after his death on coinage and the $100 bill, warships, and the names of many towns, counties, educational institutions, and corporations, as well as countless cultural references.

Benjamin Franklin's father, Josiah Franklin, was a tallow chandler, a soaper and candlemaker. Josiah was born at Ecton, Northamptonshire, England on December 23, 1657, the son of a blacksmith and farmer Thomas Franklin, and Jane White. Benjamin's father and all four of his grandparents were born in England. Josiah had seventeen children with his two wives. He married his first wife, Anne Child, in about 1677 in Ecton and emmigrated with her to Boston in 1683; they had three children before emmigration, and four after. Following her death, Josiah was married to Abiah Folger on July 9, 1689, in the Old South Meeting House by Samuel Willard. Benjamin, their eighth child, was Josiah Franklin's fifteenth child and tenth and last son.

Abiah Folger was born in Nantucket, Massachusetts, on August 15, 1667, to Peter Folger, a miller and schoolteacher, and his wife, Mary Morrell Folger, a former indentured servant. She came from a Puritan family that was among the first Pilgrims to flee to Massachusetts for religious freedom, when King Charles I of England began persecuting Puritans. They sailed for Boston in 1635. Her father was "the sort of rebel destined to transform colonial America." As clerk of the court, he was jailed for disobeying the local magistrate in defense of middle-class shopkeepers and artisans in conflict with wealthy landowners. Ben Franklin followed in his grandfather's footsteps in his battles against the wealthy Penn family that owned the Pennsylvania Colony.

Benjamin Franklin was born on Milk Street, in Boston, Massachusetts, on January 17, 1706, and baptized at Old South Meeting House. He was one of seventeen children born to Josiah Franklin, and one of ten born by Josiah's second wife, Abiah Folger; the daughter of Peter Foulger and Mary Morrill. Among Benjamin's siblings were his older brother James and his younger sister Jane.

Josiah wanted Ben to attend school with the clergy but only had enough money to send him to school for two years. He attended Boston Latin School but did not graduate; he continued his education through voracious reading. Although "his parents talked of the church as a career" for Franklin, his schooling ended when he was ten. He worked for his father for a time, and at 12 he became an apprentice to his brother James, a printer, who taught Ben the printing trade. When Ben was 15, James founded "The New-England Courant", which was the first truly independent newspaper in the colonies.

When denied the chance to write a letter to the paper for publication, Franklin adopted the pseudonym of "Silence Dogood", a middle-aged widow. Mrs. Dogood's letters were published and became a subject of conversation around town. Neither James nor the "Courant"'s readers were aware of the ruse, and James was unhappy with Ben when he discovered the popular correspondent was his younger brother. Franklin was an advocate of free speech from an early age. When his brother was jailed for three weeks in 1722 for publishing material unflattering to the governor, young Franklin took over the newspaper and had Mrs. Dogood (quoting "Cato's Letters") proclaim: "Without freedom of thought there can be no such thing as wisdom and no such thing as public liberty without freedom of speech." Franklin left his apprenticeship without his brother's permission, and in so doing became a fugitive.

At age 17, Franklin ran away to Philadelphia, Pennsylvania, seeking a new start in a new city. When he first arrived, he worked in several printer shops around town, but he was not satisfied by the immediate prospects. After a few months, while working in a printing house, Franklin was convinced by Pennsylvania Governor Sir William Keith to go to London, ostensibly to acquire the equipment necessary for establishing another newspaper in Philadelphia. Finding Keith's promises of backing a newspaper empty, Franklin worked as a typesetter in a printer's shop in what is now the Church of St Bartholomew-the-Great in the Smithfield area of London. Following this, he returned to Philadelphia in 1726 with the help of Thomas Denham, a merchant who employed Franklin as clerk, shopkeeper, and bookkeeper in his business.

In 1727, Benjamin Franklin, then 21, created the Junto, a group of "like minded aspiring artisans and tradesmen who hoped to improve themselves while they improved their community." The Junto was a discussion group for issues of the day; it subsequently gave rise to many organizations in Philadelphia. The Junto was modeled after English coffeehouses that Franklin knew well, and which had become the center of the spread of Enlightenment ideas in Britain.

Reading was a great pastime of the Junto, but books were rare and expensive. The members created a library initially assembled from their own books after Franklin wrote:

This did not suffice, however. Franklin conceived the idea of a subscription library, which would pool the funds of the members to buy books for all to read. This was the birth of the Library Company of Philadelphia: its charter was composed by Franklin in 1731. In 1732, Franklin hired the first American librarian, Louis Timothee. The Library Company is now a great scholarly and research library.

Upon Denham's death, Franklin returned to his former trade. In 1728, Franklin had set up a printing house in partnership with Hugh Meredith; the following year he became the publisher of a newspaper called "The Pennsylvania Gazette". The "Gazette" gave Franklin a forum for agitation about a variety of local reforms and initiatives through printed essays and observations. Over time, his commentary, and his adroit cultivation of a positive image as an industrious and intellectual young man, earned him a great deal of social respect. But even after Franklin had achieved fame as a scientist and statesman, he habitually signed his letters with the unpretentious 'B. Franklin, Printer.'

In 1732, Ben Franklin published the first German-language newspaper in America – "Die Philadelphische Zeitung" – although it failed after only one year because four other newly founded German papers quickly dominated the newspaper market. Franklin printed Moravian religious books in German. Franklin often visited Bethlehem, Pennsylvania staying at the Moravian Sun Inn. In a 1751 pamphlet on demographic growth and its implications for the colonies, he called the Pennsylvania Germans "Palatine Boors" who could never acquire the "Complexion" of the English settlers and referred to "Blacks and Tawneys" as weakening the social structure of the colonies. Although Franklin apparently reconsidered shortly thereafter, and the phrases were omitted from all later printings of the pamphlet, his views may have played a role in his political defeat in 1764.

Franklin saw the printing press as a device to instruct colonial Americans in moral virtue. In "Benjamin Franklin's Journalism", Ralph Frasca argues he saw this as a service to God, because he understood moral virtue in terms of actions, thus, doing good provides a service to God. Despite his own moral lapses, Franklin saw himself as uniquely qualified to instruct Americans in morality. He tried to influence American moral life through the construction of a printing network based on a chain of partnerships from the Carolinas to New England. Franklin thereby invented the first newspaper chain. It was more than a business venture, for like many publishers since he believed that the press had a public-service duty.

When Franklin established himself in Philadelphia, shortly before 1730, the town boasted two "wretched little" news sheets, Andrew Bradford's "The American Weekly Mercury", and Samuel Keimer's "Universal Instructor in all Arts and Sciences, and Pennsylvania Gazette". This instruction in all arts and sciences consisted of weekly extracts from "Chambers's Universal Dictionary". Franklin quickly did away with all this when he took over the "Instructor" and made it "The Pennsylvania Gazette". The "Gazette" soon became Franklin's characteristic organ, which he freely used for satire, for the play of his wit, even for sheer excess of mischief or of fun. From the first, he had a way of adapting his models to his own uses. The series of essays called "The Busy-Body", which he wrote for Bradford's "American Mercury" in 1729, followed the general Addisonian form, already modified to suit homelier conditions. The thrifty Patience, in her busy little shop, complaining of the useless visitors who waste her valuable time, is related to the ladies who address Mr. Spectator. The Busy-Body himself is a true Censor Morum, as Isaac Bickerstaff had been in the "Tatler". And a number of the fictitious characters, Ridentius, Eugenius, Cato, and Cretico, represent traditional 18th-century classicism. Even this Franklin could use for contemporary satire, since Cretico, the "sowre Philosopher", is evidently a portrait of Franklin's rival, Samuel Keimer.

The "Pennsylvania Gazette", like most other newspapers of the period, was often poorly printed. Franklin was busy with matters outside of his printing office, and never seriously attempted to raise the mechanical standards of his trade. Nor did he ever properly edit or collate the chance medley of stale items that passed for news in the "Gazette." His influence on the practical side of journalism was minimal. On the other hand, his advertisements of books show his very great interest in popularizing secular literature. Undoubtedly his paper contributed to the broader culture that distinguished Pennsylvania from her neighbors before the Revolution. Like many publishers, Franklin built up a book shop in his printing office; he took the opportunity to read new books before selling them. 

Franklin had mixed success in his plan to establish an inter-colonial network of newspapers that would produce a profit for him and disseminate virtue. He began in Charleston, South Carolina, in 1731. After the second editor died, his widow Elizabeth Timothy took over and made it a success, 1738–1746. She was one of the colonial era's first woman printers. For three decades Franklin maintained a close business relationship with her and her son Peter who took over in 1746. The "Gazette" had a policy of impartiality in political debates, while creating the opportunity for public debate, which encouraged others to challenge authority. Editor Peter Timothy avoided blandness and crude bias, and after 1765 increasingly took a patriotic stand in the growing crisis with Great Britain. However, Franklin's "Connecticut Gazette" (1755–68) proved unsuccessful.

In 1730 or 1731, Franklin was initiated into the local Masonic lodge. He became a Grand Master in 1734, indicating his rapid rise to prominence in Pennsylvania. The same year, he edited and published the first Masonic book in the Americas, a reprint of James Anderson's "Constitutions of the Free-Masons". He was the Secretary of St. John's Lodge in Philadelphia from 1735 to 1738. Franklin remained a Freemason for the rest of his life.

At age 17 in 1723, Franklin proposed to 15-year-old Deborah Read while a boarder in the Read home. At that time, Read's mother was wary of allowing her young daughter to marry Franklin, who was on his way to London at Governor Sir William Keith’s request, and also because of his financial instability. Her own husband had recently died, and she declined Franklin's request to marry her daughter.

While Franklin was in London, his trip was extended, and there were problems with Sir William's promises of support. Perhaps because of the circumstances of this delay, Deborah married a man named John Rodgers. This proved to be a regrettable decision. Rodgers shortly avoided his debts and prosecution by fleeing to Barbados with her dowry, leaving her behind. Rodgers's fate was unknown, and because of bigamy laws, Deborah was not free to remarry.

Franklin established a common-law marriage with Deborah Read on September 1, 1730. They took in Franklin's recently acknowledged young illegitimate son, William, and raised him in their household. They had two children together. Their son, Francis Folger Franklin, was born in October 1732 and died of smallpox in 1736. Their daughter, Sarah "Sally" Franklin, was born in 1743 and grew up to marry Richard Bache, have seven children, and look after her father in his old age.

Deborah's fear of the sea meant that she never accompanied Franklin on any of his extended trips to Europe, and another possible reason why they spent so much time apart is that he may have blamed her for possibly preventing their son Francis from being inoculated against the disease that subsequently killed him. Deborah wrote to him in November 1769 saying she was ill due to "dissatisfied distress" from his prolonged absence, but he did not return until his business was done. Deborah Read Franklin died of a stroke in 1774, while Franklin was on an extended mission to England; he returned in 1775.

In 1730, 24-year-old Franklin publicly acknowledged the existence of his son William, who was deemed "illegitimate," as he was born out of wedlock, and raised him in his household. His mother's identity is unknown. He was educated in Philadelphia. Beginning at about age 30, William studied law in London in the early 1760s. He fathered an illegitimate son, William Temple Franklin, born February 22, 1762. The boy's mother was never identified, and he was placed in foster care. Later in 1762, William married Elizabeth Downes, daughter of a planter from Barbados. After William passed the bar, his father helped him gain an appointment in 1763 as the last Royal Governor of New Jersey.

A Loyalist, William and his father eventually broke relations over their differences about the American Revolutionary War. The elder Franklin could never accept William's position. Deposed in 1776 by the revolutionary government of New Jersey, William was arrested at his home in Perth Amboy at the Proprietary House and imprisoned for a time. The younger Franklin went to New York in 1782, which was still occupied by British troops. He became leader of the Board of Associated Loyalists—a quasi-military organization, headquartered in New York City. They initiated guerrilla forays into New Jersey, southern Connecticut, and New York counties north of the city. When British troops evacuated from New York, William Franklin left with them and sailed to England. He settled in London, never to return to North America. In the preliminary peace talks in 1782 with Britain, "... Benjamin Franklin insisted that loyalists who had borne arms against the United States would be excluded from this plea (that they be given a general pardon). He was undoubtedly thinking of William Franklin."

In 1733, Franklin began to publish the noted "Poor Richard's Almanack" (with content both original and borrowed) under the pseudonym Richard Saunders, on which much of his popular reputation is based. Franklin frequently wrote under pseudonyms. Although it was no secret that Franklin was the author, his Richard Saunders character repeatedly denied it. "Poor Richard's Proverbs", adages from this almanac, such as "A penny saved is twopence dear" (often misquoted as "A penny saved is a penny earned") and "Fish and visitors stink in three days", remain common quotations in the modern world. Wisdom in folk society meant the ability to provide an apt adage for any occasion, and Franklin's readers became well prepared. He sold about ten thousand copies per year—it became an institution. In 1741, Franklin began publishing "The General Magazine and Historical Chronicle for all the British Plantations in America", the first such monthly magazine of this type published in America.

In 1758, the year he ceased writing for the Almanack, he printed "Father Abraham's Sermon", also known as "The Way to Wealth". Franklin's autobiography, begun in 1771 but published after his death, has become one of the classics of the genre.

Daylight saving time (DST) is often erroneously attributed to a 1784 satire that Franklin published anonymously. Modern DST was first proposed by George Vernon Hudson in 1895.

Franklin was a prodigious inventor. Among his many creations were the lightning rod, glass harmonica (a glass instrument, not to be confused with the metal harmonica), Franklin stove, bifocal glasses and the flexible urinary catheter. Franklin never patented his inventions; in his autobiography he wrote, "... as we enjoy great advantages from the inventions of others, we should be glad of an opportunity to serve others by any invention of ours; and this we should do freely and generously."

Franklin started exploring the phenomenon of electricity in 1746 when he saw some of Archibald Spencer's lectures using static electricity for illustrations. Franklin proposed that "vitreous" and "resinous" electricity were not different types of "electrical fluid" (as electricity was called then), but the same "fluid" under different pressures. (The same proposal was made independently that same year by William Watson.) Franklin was the first to label them as positive and negative respectively, and he was the first to discover the principle of conservation of charge. In 1748, he constructed a multiple plate capacitor, that he called an "electrical battery" (not to be confused with Volta's pile) by placing eleven panes of glass sandwiched between lead plates, suspended with silk cords and connected by wires.

In pursuit of more pragmatic uses for electricity, remarking in spring 1749 that he felt "chagrin'd a little" that his experiments had heretofore resulted in "Nothing in this Way of Use to Mankind," Franklin planned a practical demonstration. He proposed a dinner party where a turkey was to be killed with electric shock and roasted on an electrical spit. After having prepared several turkeys this way, Franklin noted that "the birds kill'd in this manner eat uncommonly tender." Franklin recounted that in the process of one of these experiments, he was shocked by a pair of Leyden jars, resulting in numbness in his arms that persisted for one evening, noting "I am Ashamed to have been Guilty of so Notorious a Blunder."

In recognition of his work with electricity, Franklin received the Royal Society's Copley Medal in 1753, and in 1756, he became one of the few 18th-century Americans elected as a Fellow of the Society. He received honorary degrees from Harvard and Yale universities (his first). The CGS unit of electric charge has been named after him: one "franklin" (Fr) is equal to one statcoulomb.

Franklin advised Harvard University in its acquisition of new electrical laboratory apparatus after the complete loss of its original collection, in a fire that destroyed the original Harvard Hall in 1764. The collection he assembled would later become part of the Harvard Collection of Historical Scientific Instruments, now on public display in its Science Center.

Franklin briefly investigated electrotherapy, including the use of the electric bath. This work led to the field becoming widely known.

Franklin published a proposal for an experiment to prove that lightning is electricity by flying a kite in a storm that appeared capable of becoming a lightning storm. On May 10, 1752, Thomas-François Dalibard of France conducted Franklin's experiment using a iron rod instead of a kite, and he extracted electrical sparks from a cloud. On June 15, 1752, Franklin may possibly have conducted his well-known kite experiment in Philadelphia, successfully extracting sparks from a cloud. Franklin described the experiment in the "Pennsylvania Gazette" on October 19, 1752, without mentioning that he himself had performed it. This account was read to the Royal Society on December 21 and printed as such in the "Philosophical Transactions". Joseph Priestley published an account with additional details in his 1767 "History and Present Status of Electricity". Franklin was careful to stand on an insulator, keeping dry under a roof to avoid the danger of electric shock. Others, such as Prof. Georg Wilhelm Richmann in Russia, were indeed electrocuted in performing lightning experiments during the months immediately following Franklin's experiment.

In his writings, Franklin indicates that he was aware of the dangers and offered alternative ways to demonstrate that lightning was electrical, as shown by his use of the concept of electrical ground. Franklin did not perform this experiment in the way that is often pictured in popular literature, flying the kite and waiting to be struck by lightning, as it would have been dangerous. Instead he used the kite to collect some electric charge from a storm cloud, showing that lightning was electrical. On October 19 in a letter to England with directions for repeating the experiment, Franklin wrote:

Franklin's electrical experiments led to his invention of the lightning rod. He said that conductors with a sharp rather than a smooth point could discharge silently, and at a far greater distance. He surmised that this could help protect buildings from lightning by attaching "upright Rods of Iron, made sharp as a Needle and gilt to prevent Rusting, and from the Foot of those Rods a Wire down the outside of the Building into the Ground; ... Would not these pointed Rods probably draw the Electrical Fire silently out of a Cloud before it came nigh enough to strike, and thereby secure us from that most sudden and terrible Mischief!" Following a series of experiments on Franklin's own house, lightning rods were installed on the Academy of Philadelphia (later the University of Pennsylvania) and the Pennsylvania State House (later Independence Hall) in 1752.

Franklin had a major influence on the emerging science of demography, or population studies.

In the 1730s and 1740s, Franklin began taking notes on population growth, finding that the American population had the fastest growth rate on earth. Emphasizing that population growth depended on food supplies, Franklin emphasized the abundance of food and available farmland in America. He calculated that America's population was doubling every twenty years and would surpass that of England in a century. In 1751, he drafted "Observations concerning the Increase of Mankind, Peopling of Countries, etc." Four years later, it was anonymously printed in Boston, and it was quickly reproduced in Britain, where it influenced the economist Adam Smith and later the demographer Thomas Malthus, who credited Franklin for discovering a rule of population growth. Franklin's predictions how British mercantilism was unsustainable alarmed British leaders who did not want to be surpassed by the colonies, so they became more willing to impose restrictions on the colonial economy.

Kammen (1990) and Drake (2011) say Franklin's "Observations concerning the Increase of Mankind" (1755) stands alongside Ezra Stiles' "Discourse on Christian Union" (1760) as the leading works of eighteenth-century Anglo-American demography; Drake credits Franklin's "wide readership and prophetic insight." Franklin was also a pioneer in the study of slave demography, as shown in his 1755 essay.

Benjamin Franklin, in his capacity as a farmer, wrote at least one critique about the negative consequences of price controls, trade restrictions, and subsidy of the poor. This is succinctly preserved in his letter to the London Chronicle published November 29, 1766, titled 'On the Price of Corn, and Management of the poor'.

As deputy postmaster, Franklin became interested in the North Atlantic Ocean circulation patterns. While in England in 1768, he heard a complaint from the Colonial Board of Customs: Why did it take British packet ships carrying mail several weeks longer to reach New York than it took an average merchant ship to reach Newport, Rhode Island? The merchantmen had a longer and more complex voyage because they left from London, while the packets left from Falmouth in Cornwall.

Franklin put the question to his cousin Timothy Folger, a Nantucket whaler captain, who told him that merchant ships routinely avoided a strong eastbound mid-ocean current. The mail packet captains sailed dead into it, thus fighting an adverse current of . Franklin worked with Folger and other experienced ship captains, learning enough to chart the current and name it the Gulf Stream, by which it is still known today.

Franklin published his Gulf Stream chart in 1770 in England, where it was completely ignored. Subsequent versions were printed in France in 1778 and the U.S. in 1786. The British edition of the chart, which was the original, was so thoroughly ignored that everyone assumed it was lost forever until Phil Richardson, a Woods Hole oceanographer and Gulf Stream expert, discovered it in the Bibliothèque Nationale in Paris in 1980. This find received front-page coverage in "The New York Times".

It took many years for British sea captains to adopt Franklin's advice on navigating the current; once they did, they were able to trim two weeks from their sailing time. In 1853, the oceanographer and cartographer Matthew Fontaine Maury noted that while Franklin charted and codified the Gulf Stream, he did not discover it:

Franklin was, along with his contemporary Leonhard Euler, the only major scientist who supported Christiaan Huygens's wave theory of light, which was basically ignored by the rest of the scientific community. In the 18th century, Newton's corpuscular theory was held to be true; only after Young's well-known slit experiment in 1803 were most scientists persuaded to believe Huygens's theory.

On October 21, 1743, according to the popular myth, a storm moving from the southwest denied Franklin the opportunity of witnessing a lunar eclipse. Franklin was said to have noted that the prevailing winds were actually from the northeast, contrary to what he had expected. In correspondence with his brother, Franklin learned that the same storm had not reached Boston until after the eclipse, despite the fact that Boston is to the northeast of Philadelphia. He deduced that storms do not always travel in the direction of the prevailing wind, a concept that greatly influenced meteorology.

After the Icelandic volcanic eruption of Laki in 1783, and the subsequent harsh European winter of 1784, Franklin made observations connecting the causal nature of these two separate events. He wrote about them in a lecture series.

Though Benjamin Franklin has been most noted kite-wise for his lightning experiments, he has also been noted by many for his using kites to pull humans and ships across waterways. The George Pocock in the book "A TREATISE on The Aeropleustic Art, or Navigation in the Air, by means of Kites, or Buoyant Sails" noted being inspired by Benjamin Franklin's traction of his body by kite power across a waterway. In his later years, he suggested using the technique for pulling ships.

Franklin noted a principle of refrigeration by observing that on a very hot day, he stayed cooler in a wet shirt in a breeze than he did in a dry one. To understand this phenomenon more clearly Franklin conducted experiments. In 1758 on a warm day in Cambridge, England, Franklin and fellow scientist John Hadley experimented by continually wetting the ball of a mercury thermometer with ether and using bellows to evaporate the ether. With each subsequent evaporation, the thermometer read a lower temperature, eventually reaching . Another thermometer showed that the room temperature was constant at . In his letter "Cooling by Evaporation", Franklin noted that, "One may see the possibility of freezing a man to death on a warm summer's day."

According to Michael Faraday, Franklin's experiments on the non-conduction of ice are worth mentioning, although the law of the general effect of liquefaction on electrolytes is not attributed to Franklin. However, as reported in 1836 by Prof. A. D. Bache of the University of Pennsylvania, the law of the effect of heat on the conduction of bodies otherwise non-conductors, for example, glass, could be attributed to Franklin. Franklin writes, "... A certain quantity of heat will make some bodies good conductors, that will not otherwise conduct ..." and again, "... And water, though naturally a good conductor, will not conduct well when frozen into ice."

An aging Franklin accumulated all his oceanographic findings in "Maritime Observations", published by the Philosophical Society's "transactions" in 1786. It contained ideas for sea anchors, catamaran hulls, watertight compartments, shipboard lightning rods and a soup bowl designed to stay stable in stormy weather.

In a 1772 letter to Joseph Priestley, Franklin lays out the earliest known description of the Pro & Con list, a common decision-making technique, now sometimes called a decisional balance sheet:

While traveling on a ship, Franklin had observed that the wake of a ship was diminished when the cooks scuttled their greasy water. He studied the effects on a large pond in Clapham Common, London. "I fetched out a cruet of oil and dropt a little of it on the water ... though not more than a teaspoon full, produced an instant calm over a space of several yards square." He later used the trick to "calm the waters" by carrying "a little oil in the hollow joint of my cane".

Franklin is known to have played the violin, the harp, and the guitar. He also composed music, notably a string quartet in early classical style. While he was in London, he developed a much-improved version of the glass harmonica, in which the glasses rotate on a shaft, with the player's fingers held steady, instead of the other way around. He worked with the London glassblower Charles James to create it, and instruments based on his mechanical version soon found their way to other parts of Europe. Joesph Haydn (a fan of Franklin's enlightened ideas) had a glass harmonica in his instrument collection. Beethoven wrote a sonata for the glass harmonica.

Franklin was an avid chess player. He was playing chess by around 1733, making him the first chess player known by name in the American colonies. His essay on "The Morals of Chess" in "Columbian" magazine in December 1786 is the second known writing on chess in America. This essay in praise of chess and prescribing a code of behavior for the game has been widely reprinted and translated. He and a friend also used chess as a means of learning the Italian language, which both were studying; the winner of each game between them had the right to assign a task, such as parts of the Italian grammar to be learned by heart, to be performed by the loser before their next meeting.

Franklin was able to play chess more frequently against stronger opposition during his many years as a civil servant and diplomat in England, where the game was far better established than in America. He was able to improve his playing standard by facing more experienced players during this period. He regularly attended Old Slaughter's Coffee House in London for chess and socializing, making many important personal contacts. While in Paris, both as a visitor and later as ambassador, he visited the famous Café de la Régence, which France's strongest players made their regular meeting place. No records of his games have survived, so it is not possible to ascertain his playing strength in modern terms.

Franklin was inducted into the U.S. Chess Hall of Fame in 1999. The Franklin Mercantile Chess Club in Philadelphia, the second oldest chess club in the U.S., is named in his honor.

In 1736, Franklin created the Union Fire Company, one of the first volunteer firefighting companies in America. In the same year, he printed a new currency for New Jersey based on innovative anti-counterfeiting techniques he had devised. Throughout his career, Franklin was an advocate for paper money, publishing "A Modest Enquiry into the Nature and Necessity of a Paper Currency" in 1729, and his printer printed money. He was influential in the more restrained and thus successful monetary experiments in the Middle Colonies, which stopped deflation without causing excessive inflation. In 1766 he made a case for paper money to the British House of Commons.

As he matured, Franklin began to concern himself more with public affairs. In 1743, he first devised a scheme for The Academy, Charity School, and College of Philadelphia. However, the person he had in mind to run the academy, Rev. Richard Peters, refused and Franklin put his ideas away until 1749 when he printed his own pamphlet, "Proposals Relating to the Education of Youth in Pensilvania." He was appointed president of the Academy on November 13, 1749; the Academy and the charity school opened on August 13, 1751.

In 1743, Franklin founded the American Philosophical Society to help scientific men discuss their discoveries and theories. He began the electrical research that, along with other scientific inquiries, would occupy him for the rest of his life, in between bouts of politics and moneymaking.

During King George's War (1744–1748), Franklin raised a militia called the Association for General Defense, because the legislators of the city decided to take no action to defend Philadelphia "either by erecting fortifications or building Ships of War". He raised money to create earthwork defenses and buy artillery. The largest of these was the "Association Battery" or "Grand Battery" of 50 guns.

In 1747, Franklin (already a very wealthy man) retired from printing and went into other businesses. He created a partnership with his foreman, David Hall, which provided Franklin with half of the shop's profits for 18 years. This lucrative business arrangement provided leisure time for study, and in a few years he had made discoveries that gave him a reputation with educated persons throughout Europe and especially in France.

Franklin became involved in Philadelphia politics and rapidly progressed. In October 1748, he was selected as a councilman, in June 1749 he became a Justice of the Peace for Philadelphia, and in 1751 he was elected to the Pennsylvania Assembly. On August 10, 1753, Franklin was appointed deputy postmaster-general of British North America, (see below). His most notable service in domestic politics was his reform of the postal system, with mail sent out every week.

In 1751, Franklin and Thomas Bond obtained a charter from the Pennsylvania legislature to establish a hospital. Pennsylvania Hospital was the first hospital in what was to become the United States of America.

In 1752, Franklin organized the Philadelphia Contributionship, the first homeowner's insurance company in what would become the United States.

Between 1750 and 1753, the "educational triumvirate" of Benjamin Franklin, the American Samuel Johnson of Stratford, Connecticut, and the immigrant Scottish schoolteacher William Smith built on Franklin's initial scheme and created what Bishop James Madison, president of the College of William & Mary, called a "new-model" plan or style of American college. Franklin solicited, printed in 1752, and promoted an American textbook of moral philosophy by Samuel Johnson, titled "Elementa Philosophica", to be taught in the new colleges to replace courses in denominational divinity.

In June 1753, Johnson, Franklin, and Smith met in Stratford. They decided the new-model college would focus on the professions, with classes taught in English instead of Latin, have subject matter experts as professors instead of one tutor leading a class for four years, and there would be no religious test for admission. Johnson went on to found King's College (now Columbia University) in New York City in 1754, while Franklin hired Smith as Provost of the College of Philadelphia, which opened in 1755. At its first commencement, on May 17, 1757, seven men graduated; six with a Bachelor of Arts and one as Master of Arts. It was later merged with the University of the State of Pennsylvania to become the University of Pennsylvania. The College was to become influential in guiding : in the Continental Congress, for example, over one-third of the college-affiliated men who contributed the "Declaration of Independence" between September 4, 1774, and July 4, 1776, was affiliated with the College.

In 1753, both Harvard and Yale awarded him honorary master of arts degrees.

In 1754, he headed the Pennsylvania delegation to the Albany Congress. This meeting of several colonies had been requested by the Board of Trade in England to improve relations with the Indians and defense against the French. Franklin proposed a broad Plan of Union for the colonies. While the plan was not adopted, elements of it found their way into the Articles of Confederation and the Constitution.

In 1756, Franklin received an honorary master of arts degree from the College of William & Mary. Later in 1756, Franklin organized the Pennsylvania Militia (see "Associated Regiment of Philadelphia" under heading of Pennsylvania's 103rd Artillery and 111th Infantry Regiment at Continental Army). He used Tun Tavern as a gathering place to recruit a regiment of soldiers to go into battle against the Native American uprisings that beset the American colonies. Reportedly Franklin was elected "Colonel" of the Associated Regiment but declined the honor.

From the mid-1750s to the mid-1770s, Franklin spent much of his time in London. Officially he was there on a political mission, but he used his time to further his scientific explorations as well, meeting many notable people.

In 1757, he was sent to England by the Pennsylvania Assembly as a colonial agent to protest against the political influence of the Penn family, the proprietors of the colony. He remained there for five years, striving to end the proprietors' prerogative to overturn legislation from the elected Assembly, and their exemption from paying taxes on their land. His lack of influential allies in Whitehall led to the failure of this mission.

At this time, many members of the Pennsylvania Assembly were feuding with William Penn's heirs, who controlled the colony as proprietors. After his return to the colony, Franklin led the "anti-proprietary party" in the struggle against the Penn family, and was elected Speaker of the Pennsylvania House in May 1764. His call for a change from proprietary to royal government was a rare political miscalculation, however: Pennsylvanians worried that such a move would endanger their political and religious freedoms. Because of these fears, and because of political attacks on his character, Franklin lost his seat in the October 1764 Assembly elections. The anti-proprietary party dispatched Franklin to England again to continue the struggle against the Penn family proprietorship. During this trip, events drastically changed the nature of his mission.

In London, Franklin opposed the 1765 Stamp Act. Unable to prevent its passage, he made another political miscalculation and recommended a friend to the post of stamp distributor for Pennsylvania. Pennsylvanians were outraged, believing that he had supported the measure all along, and threatened to destroy his home in Philadelphia. Franklin soon learned of the extent of colonial resistance to the Stamp Act, and he testified during the House of Commons proceedings that led to its repeal.

With this, Franklin suddenly emerged as the leading spokesman for American interests in England. He wrote popular essays on behalf of the colonies. Georgia, New Jersey, and Massachusetts also appointed him as their agent to the Crown.

Franklin lodged in a house in Craven Street, just off The Strand in central London. During his stays there, he developed a close friendship with his landlady, Margaret Stevenson, and her circle of friends and relations, in particular, her daughter Mary, who was more often known as Polly. Their house, which he used on various lengthy missions from 1757 to 1775, is the only one of his residences to survive. It opened to the public as the Benjamin Franklin House museum in 2006.

Whilst in London, Franklin became involved in radical politics. He belonged to a gentleman's club (which he called "the honest Whigs"), which held stated meetings, and included members such as Richard Price, the minister of Newington Green Unitarian Church who ignited the Revolution Controversy, and Andrew Kippis.

Franklin also managed to secure an appointed post for his illegitimate son, William Franklin, by then an attorney, as Colonial Governor of New Jersey.

In 1756, Franklin had become a member of the Society for the Encouragement of Arts, Manufactures & Commerce (now the Royal Society of Arts or RSA), which had been founded in 1754 and whose early meetings took place in Covent Garden coffee shops. After his return to the United States in 1775, Franklin became the Society's Corresponding Member, continuing a close connection. The RSA instituted a Benjamin Franklin Medal in 1956 to commemorate the 250th anniversary of his birth and the 200th anniversary of his membership of the RSA.

The study of natural philosophy (what we would call science) drew him into overlapping circles of acquaintance. Franklin was, for example, a corresponding member of the Lunar Society of Birmingham, which included such other scientific and industrial luminaries as Matthew Boulton, James Watt, Josiah Wedgwood and Erasmus Darwin; on occasion he visited them.

In 1759, the University of St Andrews awarded Franklin an honorary doctorate in recognition of his accomplishments. He was also awarded an honorary doctorate by Oxford University in 1762. Because of these honors, Franklin was often addressed as " Franklin."

While living in London in 1768, he developed a phonetic alphabet in "A Scheme for a new Alphabet and a Reformed Mode of Spelling". This reformed alphabet discarded six letters Franklin regarded as redundant (c, j, q, w, x, and y), and substituted six new letters for sounds he felt lacked letters of their own. This alphabet never caught on, and he eventually lost interest.

Franklin used London as a base to travel. In 1771, he made short journeys through different parts of England, staying with Joseph Priestley at Leeds, Thomas Percival at Manchester and Erasmus Darwin at Lichfield.

In Scotland, he spent five days with Lord Kames near Stirling and stayed for three weeks with David Hume in Edinburgh. In 1759, he visited Edinburgh with his son, and recalled his conversations there as "the "densest" happiness of my life". In February 1759, the University of St Andrews awarded him an honorary Doctor of Laws degree. From then he was known as "Doctor Franklin". In October of the same year he was granted Freedom of the Borough of St Andrews.

He had never been to Ireland before, and met and stayed with Lord Hillsborough, who he believed was especially attentive. Franklin noted of him that "all the plausible behaviour I have described is meant only, by patting and stroking the horse, to make him more patient, while the reins are drawn tighter, and the spurs set deeper into his sides." In Dublin, Franklin was invited to sit with the members of the Irish Parliament rather than in the gallery. He was the first American to receive this honor. While touring Ireland, he was moved by the level of poverty he saw. Ireland's economy was affected by the same trade regulations and laws of Britain that governed America. Franklin feared that America could suffer the same effects should Britain's "colonial exploitation" continue.

Franklin spent two months in German lands in 1766, but his connections to the country stretched across a lifetime. He declared a debt of gratitude to German scientist Otto von Guericke for his early studies of electricity. Franklin also co-authored the first treaty of friendship between Prussia and America in 1785.

In September 1767, Franklin visited Paris with his usual traveling partner, Sir John Pringle, 1st Baronet. News of his electrical discoveries was widespread in France. His reputation meant that he was introduced to many influential scientists and politicians, and also to King Louis XV.

One line of argument in Parliament was that Americans should pay a share of the costs of the French and Indian War, and that therefore taxes should be levied on them. Franklin became the American spokesman in highly publicized testimony in Parliament in 1766. He stated that Americans already contributed heavily to the defense of the Empire. He said local governments had raised, outfitted and paid 25,000 soldiers to fight France—as many as Britain itself sent—and spent many millions from American treasuries doing so in the French and Indian War alone.

In 1773, Franklin published two of his most celebrated pro-American satirical essays: , and "An Edict by the King of Prussia".

In 1772, Franklin obtained private letters of Thomas Hutchinson and Andrew Oliver, governor and lieutenant governor of the Province of Massachusetts Bay, proving that they had encouraged the Crown to crack down on Bostonians. Franklin sent them to America, where they escalated the tensions. The letters were finally leaked to the public in the "Boston Gazette" in mid-June 1773, causing a political firestorm in Massachusetts and raising significant questions in England. The British began to regard him as the fomenter of serious trouble. Hopes for a peaceful solution ended as he was systematically ridiculed and humiliated by Solicitor-General Alexander Wedderburn, before the Privy Council on January 29, 1774. He returned to Philadelphia in March 1775, and abandoned his accommodationist stance.

Franklin is known to have occasionally attended the Hellfire Club's meetings during 1758 as a non-member during his time in England. However, some authors and historians would argue Benjamin Franklin was in fact a British spy. As there are no records left (having been burned in 1774), many of these members are just assumed or linked by letters sent to each other. One early proponent that Franklin was a member of the Hellfire Club and a double agent was the historian Donald McCormick, who has a history of making controversial claims.

In 1763, soon after Franklin returned to Pennsylvania from England for the first time, the western frontier was engulfed in a bitter war known as Pontiac's Rebellion. The Paxton Boys, a group of settlers convinced that the Pennsylvania government was not doing enough to protect them from American Indian raids, murdered a group of peaceful Susquehannock Indians and marched on Philadelphia. Franklin helped to organize a local militia to defend the capital against the mob. He met with the Paxton leaders and persuaded them to disperse. Franklin wrote a scathing attack against the racial prejudice of the Paxton Boys. "If an "Indian" injures me", he asked, "does it follow that I may revenge that Injury on all "Indians"?"

He provided an early response to British surveillance through his own network of counter-surveillance and manipulation. "He waged a public relations campaign, secured secret aid, played a role in privateering expeditions, and churned out effective and inflammatory propaganda."

By the time Franklin arrived in Philadelphia on May 5, 1775, after his second mission to Great Britain, the American Revolution had begun—with fighting between colonials and British at Lexington and Concord. The New England militia had trapped the main British army in Boston. The Pennsylvania Assembly unanimously chose Franklin as their delegate to the Second Continental Congress. In June 1776, he was appointed a member of the Committee of Five that drafted the Declaration of Independence. Although he was temporarily disabled by gout and unable to attend most meetings of the Committee, Franklin made several "small but important" changes to the draft sent to him by Thomas Jefferson.

At the signing, he is quoted as having replied to a comment by John Hancock that they must all hang together: "Yes, we must, indeed, all hang together, or most assuredly we shall all hang separately."

Well known as a printer and publisher, Franklin was appointed postmaster of Philadelphia in 1737, holding the office until 1753, when he and publisher William Hunter were named deputy postmasters–general of British North America, the first to hold the office. (Joint appointments were standard at the time, for political reasons.) Franklin was responsible for the British colonies from Pennsylvania north and east, as far as the island of Newfoundland. A post office for local and outgoing mail had been established in Halifax, Nova Scotia, by local stationer Benjamin Leigh, on April 23, 1754, but service was irregular. Franklin opened the first post office to offer regular, monthly mail in what would later become Canada, at Halifax, on December 9, 1755. Meantime, Hunter became postal administrator in Williamsburg, Virginia and oversaw areas south of Annapolis, Maryland. Franklin reorganized the service's accounting system, then improved speed of delivery between Philadelphia, New York and Boston. By 1761, efficiencies led to the first profits for the colonial post office.

When the lands of New France were ceded to the British under the Treaty of Paris in 1763, the new British province of Quebec was created among them, and Franklin saw mail service expanded between Montreal, Trois-Rivières, Quebec City, and New York. For the greater part of his appointment, Franklin lived in England (from 1757 to 1762, and again from 1764 to 1774)—about three-quarters of his term. Eventually, his sympathies for the rebel cause in the American Revolution led to his dismissal on January 31, 1774.

On July 26, 1775, the Second Continental Congress established the United States Post Office and named Benjamin Franklin as the first United States Postmaster General. Franklin had been a postmaster for decades and was a natural choice for the position. He had just returned from England and was appointed chairman of a Committee of Investigation to establish a postal system. The report of the Committee, providing for the appointment of a postmaster general for the 13 American colonies, was considered by the Continental Congress on July 25 and 26. On July 26, 1775, Franklin was appointed Postmaster General, the first appointed under the Continental Congress. It established a postal system that became the United States Post Office, a system that continues to operate today.

In December 1776, Franklin was dispatched to France as commissioner for the United States. He took with him as secretary his 16-year-old grandson, William Temple Franklin. They lived in a home in the Parisian suburb of Passy, donated by Jacques-Donatien Le Ray de Chaumont, who supported the United States. Franklin remained in France until 1785. He conducted the affairs of his country toward the French nation with great success, which included securing a critical military alliance in 1778 and negotiating the Treaty of Paris (1783).

Among his associates in France was Honoré Gabriel Riqueti, comte de Mirabeau—a French Revolutionary writer, orator and statesman who in early 1791 would be elected president of the National Assembly. In July 1784, Franklin met with Mirabeau and contributed anonymous materials that the Frenchman used in his first signed work: "Considerations sur l'ordre de Cincinnatus". The publication was critical of the Society of the Cincinnati, established in the United States. Franklin and Mirabeau thought of it as a "noble order", inconsistent with the egalitarian ideals of the new republic.

During his stay in France, Benjamin Franklin was active as a Freemason, serving as Venerable Master of the Lodge Les Neuf Sœurs from 1779 until 1781. He was the 106th member of the Lodge. In 1784, when Franz Mesmer began to publicize his theory of "animal magnetism" which was considered offensive by many, Louis XVI appointed a commission to investigate it. These included the chemist Antoine Lavoisier, the physician Joseph-Ignace Guillotin, the astronomer Jean Sylvain Bailly, and Benjamin Franklin. In 1781, he was elected a Fellow of the American Academy of Arts and Sciences.

Franklin's advocacy for religious tolerance in France contributed to arguments made by French philosophers and politicians that resulted in Louis XVI's signing of the Edict of Versailles in November 1787. This edict effectively nullified the Edict of Fontainebleau, which had denied non-Catholics civil status and the right to openly practice their faith.

Franklin also served as American minister to Sweden, although he never visited that country. He negotiated a treaty that was signed in April 1783. On August 27, 1783, in Paris, Franklin witnessed the world's first hydrogen balloon flight. "Le Globe", created by professor Jacques Charles and Les Frères Robert, was watched by a vast crowd as it rose from the Champ de Mars (now the site of the Eiffel Tower). Franklin became so enthusiastic that he subscribed financially to the next project to build a manned hydrogen balloon. On December 1, 1783, Franklin was seated in the special enclosure for honoured guests when "La Charlière" took off from the Jardin des Tuileries, piloted by Jacques Charles and Nicolas-Louis Robert.

When he returned home in 1785, Franklin occupied a position only second to that of George Washington as the champion of American independence. Franklin returned from France with an unexplained shortage of 100,000 pounds in Congressional funds. In response to a question from a member of Congress about this, Franklin, quoting the Bible, quipped: "Muzzle not the ox that treadeth out his master's grain." The missing funds were never again mentioned in Congress.

Le Ray honored him with a commissioned portrait painted by Joseph Duplessis, which now hangs in the National Portrait Gallery of the Smithsonian Institution in Washington, D.C. After his return, Franklin became an abolitionist and freed his two slaves. He eventually became president of the Pennsylvania Abolition Society.

In 1787, Franklin served as a delegate to the Philadelphia Convention. He held an honorary position and seldom engaged in debate. He is the only Founding Father who is a signatory of all four of the major documents of the founding of the United States: the Declaration of Independence, the Treaty of Alliance with France, the Treaty of Paris and the United States Constitution.

In 1787, a group of prominent ministers in Lancaster, Pennsylvania, proposed the foundation of a new college named in Franklin's honor. Franklin donated £200 towards the development of Franklin College (now called Franklin & Marshall College).

Between 1771 and 1788, he finished his autobiography. While it was at first addressed to his son, it was later completed for the benefit of mankind at the request of a friend.

Franklin strongly supported the right to freedom of speech:

Special balloting conducted October 18, 1785, unanimously elected Franklin the sixth president of the Supreme Executive Council of Pennsylvania, replacing John Dickinson. The office was practically that of governor. Franklin held that office for slightly over three years, longer than any other, and served the constitutional limit of three full terms. Shortly after his initial election, he was re-elected to a full term on October 29, 1785, and again in the fall of 1786 and on October 31, 1787. In that capacity he served as host to the Constitutional Convention of 1787 in Philadelphia.

Like the other advocates of republicanism, Franklin emphasized that the new republic could survive only if the people were virtuous. All his life he explored the role of civic and personal virtue, as expressed in "Poor Richard's" aphorisms. Franklin felt that organized religion was necessary to keep men good to their fellow men, but rarely attended religious services himself. When Franklin met Voltaire in Paris and asked his fellow member of the Enlightenment vanguard to bless his grandson, Voltaire said in English, "God and Liberty", and added, "this is the only appropriate benediction for the grandson of Monsieur Franklin."

Franklin's parents were both pious Puritans. The family attended the Old South Church, the most liberal Puritan congregation in Boston, where Benjamin Franklin was baptized in 1706. Franklin's father, a poor chandler, owned a copy of a book, "Bonifacius: Essays to Do Good", by the Puritan preacher and family friend Cotton Mather, which Franklin often cited as a key influence on his life. Franklin's first pen name, Silence Dogood, paid homage both to the book and to a widely known sermon by Mather. The book preached the importance of forming voluntary associations to benefit society. Franklin learned about forming do-good associations from Cotton Mather, but his organizational skills made him the most influential force in making voluntarism an enduring part of the American ethos.

Franklin formulated a presentation of his beliefs and published it in 1728. It did not mention many of the Puritan ideas regarding salvation, the divinity of Jesus, or indeed much religious dogma. He clarified himself as a deist in his 1771 autobiography, although still considered himself a Christian. He retained a strong faith in a God as the wellspring of morality and goodness in man, and as a Providential actor in history responsible for American independence.
It was Ben Franklin who, at a critical impasse during the Constitutional Convention in June 1787, attempted to introduce the practice of daily common prayer with these words:

The motion met with resistance and was never brought to a vote.

Franklin was an enthusiastic supporter of the evangelical minister George Whitefield during the First Great Awakening. Franklin did not subscribe to Whitefield's theology, but he admired Whitefield for exhorting people to worship God through good works. Franklin published all of Whitefield's sermons and journals, thereby earning a lot of money and boosting the Great Awakening.

When he stopped attending church, Franklin wrote in his autobiography:
Franklin retained a lifelong commitment to the Puritan virtues and political values he had grown up with, and through his civic work and publishing, he succeeded in passing these values into the American culture permanently. He had a "passion for virtue". These Puritan values included his devotion to egalitarianism, education, industry, thrift, honesty, temperance, charity and community spirit.

The classical authors read in the Enlightenment period taught an abstract ideal of republican government based on hierarchical social orders of king, aristocracy and commoners. It was widely believed that English liberties relied on their balance of power, but also hierarchal deference to the privileged class. "Puritanism ... and the epidemic evangelism of the mid-eighteenth century, had created challenges to the traditional notions of social stratification" by preaching that the Bible taught all men are equal, that the true value of a man lies in his moral behavior, not his class, and that all men can be saved. Franklin, steeped in Puritanism and an enthusiastic supporter of the evangelical movement, rejected the salvation dogma, but embraced the radical notion of egalitarian democracy.

Franklin's commitment to teach these values was itself something he gained from his Puritan upbringing, with its stress on "inculcating virtue and character in themselves and their communities." These Puritan values and the desire to pass them on, were one of Franklin's quintessentially American characteristics, and helped shape the character of the nation. Franklin's writings on virtue were derided by some European authors, such as Jackob Fugger in his critical work "Portrait of American Culture". Max Weber considered Franklin's ethical writings a culmination of the Protestant ethic, which ethic created the social conditions necessary for the birth of capitalism.

One of Franklin's notable characteristics was his respect, tolerance and promotion of all churches. Referring to his experience in Philadelphia, he wrote in his autobiography, "new Places of worship were continually wanted, and generally erected by voluntary Contribution, my Mite for such purpose, whatever might be the Sect, was never refused." "He helped create a new type of nation that would draw strength from its religious pluralism." The evangelical revivalists who were active mid-century, such as Franklin's friend and preacher, George Whitefield, were the greatest advocates of religious freedom, "claiming liberty of conscience to be an 'inalienable right of every rational creature.'" Whitefield's supporters in Philadelphia, including Franklin, erected "a large, new hall, that ... could provide a pulpit to anyone of any belief." Franklin's rejection of dogma and doctrine and his stress on the God of ethics and morality and civic virtue made him the "prophet of tolerance." Franklin composed "A Parable Against Persecution", an apocryphal 51st chapter of Genesis in which God teaches Abraham the duty of tolerance. While he was living in London in 1774, he was present at the birth of British Unitarianism, attending the inaugural session of the Essex Street Chapel, at which Theophilus Lindsey drew together the first avowedly Unitarian congregation in England; this was somewhat politically risky, and pushed religious tolerance to new boundaries, as a denial of the doctrine of the Trinity was illegal until the 1813 Act.

Although Franklin's parents had intended for him to have a career in the Church, Franklin as a young man adopted the Enlightenment religious belief in deism, that God's truths can be found entirely through nature and reason. "I soon became a thorough Deist." As a young man he rejected Christian dogma in a 1725 pamphlet "A Dissertation on Liberty and Necessity, Pleasure and Pain", which he later saw as an embarrassment, while simultaneously asserting that God is "all wise, all good, all powerful." He defended his rejection of religious dogma with these words: "I think opinions should be judged by their influences and effects; and if a man holds none that tend to make him less virtuous or more vicious, it may be concluded that he holds none that are dangerous, which I hope is the case with me." After the disillusioning experience of seeing the decay in his own moral standards, and those of two friends in London whom he had converted to Deism, Franklin turned back to a belief in the importance of organized religion, on the pragmatic grounds that without God and organized churches, man will not be good. Moreover, because of his proposal that prayers be said in the Constitutional Convention of 1787, many have contended that in his later life Franklin became a pious Christian.

According to David Morgan, Franklin was a proponent of religion in general. He prayed to "Powerful Goodness" and referred to God as "the infinite". John Adams noted that Franklin was a mirror in which people saw their own religion: "The Catholics thought him almost a Catholic. The Church of England claimed him as one of them. The Presbyterians thought him half a Presbyterian, and the Friends believed him a wet Quaker." Whatever else Franklin was, concludes Morgan, "he was a true champion of generic religion." In a letter to Richard Price, Franklin stated that he believed that religion should support itself without help from the government, claiming, "When a Religion is good, I conceive that it will support itself; and, when it cannot support itself, and God does not take care to support, so that its Professors are oblig'd to call for the help of the Civil Power, it is a sign, I apprehend, of its being a bad one."

In 1790, just about a month before he died, Franklin wrote a letter to Ezra Stiles, president of Yale University, who had asked him his views on religion:

On July 4, 1776, Congress appointed a three-member committee composed of Franklin, Thomas Jefferson, and John Adams to design the Great Seal of the United States. Franklin's proposal (which was not adopted) featured the motto: "Rebellion to Tyrants is Obedience to God" and a scene from the Book of Exodus, with Moses, the Israelites, the pillar of fire, and George III depicted as pharaoh. The design that was produced was never acted upon by Congress, and the Great Seal's design was not finalized until a third committee was appointed in 1782.

Franklin sought to cultivate his character by a plan of 13 virtues, which he developed at age 20 (in 1726) and continued to practice in some form for the rest of his life. His autobiography lists his 13 virtues as:


Franklin did not try to work on them all at once. Instead, he would work on one and only one each week "leaving all others to their ordinary chance." While Franklin did not live completely by his virtues, and by his own admission he fell short of them many times, he believed the attempt made him a better man contributing greatly to his success and happiness, which is why in his autobiography, he devoted more pages to this plan than to any other single point; in his autobiography Franklin wrote, "I hope, therefore, that some of my descendants may follow the example and reap the benefit."

Franklin owned as many as seven slaves, two males who worked in his household and his shop. Franklin posted paid ads for the sale of slaves and for the capture of runaway slaves and allowed the sale of slaves in his general store. Franklin profited from both the international and domestic slave trade, even criticizing slaves who had run off to join the British Army during the colonial wars of the 1740s and 1750s. Franklin, however, later became a "cautious abolitionist" and became an outspoken critic of landed gentry slavery. In 1758, Franklin advocated the opening of a school for the education of black slaves in Philadelphia. Franklin took two slaves to England with him, Peter and King, and King left his service there in 1756: by 1758 he was working for "a lady in Suffolk". Whether Franklin could have compelled King's return is open to doubt in the light of earlier English Common Law decisions and the subsequent case of Shanley v Harvey, but in any case he did not attempt to do so.

After returning from England in 1762, Franklin became more anti-slavery. By 1770, Franklin had freed his slaves and attacked the system of slavery and the international slave trade. Franklin, however, refused to publicly debate the issue of slavery at the 1787 Constitutional Convention. Franklin tended to take both sides of the issue of slavery, never fully divesting himself from the institution.

In his later years, as Congress was forced to deal with the issue of slavery, Franklin wrote several essays that stressed the importance of the abolition of slavery and of the integration of blacks into American society. These writings included:

In 1790, Quakers from New York and Pennsylvania presented their petition for abolition to Congress. Their argument against slavery was backed by the Pennsylvania Abolitionist Society and its president, Benjamin Franklin.

Franklin suffered from obesity throughout his middle-aged and later years, which resulted in multiple health problems, particularly gout, which worsened as he aged. In poor health during the signing of the US Constitution in 1787, he was rarely seen in public from then until his death.

Benjamin Franklin died from pleuritic attack at his home in Philadelphia on April 17, 1790. He was aged 84 at the time of his death. His last words were reportedly, "a dying man can do nothing easy", to his daughter after she suggested that he change position in bed and lay on his side so he could breathe more easily. Franklin's death is described in the book "The Life of Benjamin Franklin", quoting from the account of John Jones:

Approximately 20,000 people attended his funeral. He was interred in Christ Church Burial Ground in Philadelphia. In 1728, aged 22, Franklin wrote what he hoped would be his own epitaph:

Franklin's actual grave, however, as he specified in his final will, simply reads "Benjamin and Deborah Franklin".

A signer of both the Declaration of Independence and the Constitution, Franklin is considered one of the Founding Fathers of the United States. His pervasive influence in the early history of the nation has led to his being jocularly called "the only President of the United States who was never President of the United States." Franklin's likeness is ubiquitous. Since 1928, it has adorned American $100 bills, which are sometimes referred to in slang as "Benjamins" or "Franklins." From 1948 to 1963, Franklin's portrait was on the half dollar. He has appeared on a $50 bill and on several varieties of the $100 bill from 1914 and 1918. Franklin appears on the $1,000 Series EE Savings bond. Philadelphia's Benjamin Franklin Parkway (a major thoroughfare) and Benjamin Franklin Bridge (the first major bridge to connect Philadelphia with New Jersey) are named in his honor.

In 1976, as part of a bicentennial celebration, Congress dedicated a marble statue in Philadelphia's Franklin Institute as the Benjamin Franklin National Memorial. Many of Franklin's personal possessions are also on display at the Institute, one of the few national memorials located on private property.

In London, his house at 36 Craven Street, which is the only surviving former residence of Benjamin Franklin, was first marked with a blue plaque and has since been opened to the public as the Benjamin Franklin House. In 1998, workmen restoring the building dug up the remains of six children and four adults hidden below the home. "The Times" reported on February 11, 1998:

The Friends of Benjamin Franklin House (the organization responsible for the restoration) note that the bones were likely placed there by William Hewson, who lived in the house for two years and who had built a small anatomy school at the back of the house. They note that while Franklin likely knew what Hewson was doing, he probably did not participate in any dissections because he was much more of a physicist than a medical man.

Franklin bequeathed £1,000 (about $4,400 at the time, or about $125,000 in 2018 dollars) each to the cities of Boston and Philadelphia, in trust to gather interest for 200 years. The trust began in 1785 when the French mathematician Charles-Joseph Mathon de la Cour, who admired Franklin greatly, wrote a friendly parody of Franklin's "Poor Richard's Almanack" called "Fortunate Richard". The main character leaves a smallish amount of money in his will, five lots of 100 "livres", to collect interest over one, two, three, four or five full centuries, with the resulting astronomical sums to be spent on impossibly elaborate utopian projects. Franklin, who was 79 years old at the time, wrote thanking him for a great idea and telling him that he had decided to leave a bequest of 1,000 pounds each to his native Boston and his adopted Philadelphia. By 1990, more than $2,000,000 had accumulated in Franklin's Philadelphia trust, which had loaned the money to local residents. From 1940 to 1990, the money was used mostly for mortgage loans. When the trust came due, Philadelphia decided to spend it on scholarships for local high school students. Franklin's Boston trust fund accumulated almost $5,000,000 during that same time; at the end of its first 100 years a portion was allocated to help establish a trade school that became the Franklin Institute of Boston, and the whole fund was later dedicated to supporting this institute.

Benjamin Franklin is a prominent figure in American history comparable to Washington, Jefferson and Lincoln, and as such he has been honored on U.S. postage stamps many times. The image of Franklin, the first Postmaster General of the United States, occurs on the face of U.S. postage more than any other notable American save that of George Washington.

Franklin appeared on the first U.S. postage stamp (displayed above) issued in 1847. From 1908 through 1923, the U.S. Post Office issued a series of postage stamps commonly referred to as the Washington-Franklin Issues where, along with George Washington, Franklin was depicted many times over a 14-year period, the longest run of any one series in U.S. postal history. Along with the regular issue stamps Franklin however only appears on a few . Some of the finest portrayals of Franklin on record can be found on the engravings inscribed on the face of U.S. postage.

"Advice to a Friend on Choosing a Mistress" is a letter written by Benjamin Franklin, dated June 25, 1745, in which Franklin gives advice to a young man about channeling sexual urges. Due to its licentious nature, the letter was not published in collections of Franklin's papers during the nineteenth century. Federal court decisions from the mid-to-late twentieth century cited the document as a reason for overturning obscenity laws, using it to make a case against censorship.

"The Princess and the Patriot: Ekaterina Dashkova, Benjamin Franklin and the Age of Enlightenment" exhibition opened in Philadelphia in February 2006 and ran through December 2006. Benjamin Franklin and Dashkova met only once, in Paris in 1781. Franklin was 75, and Dashkova was 37. Franklin invited Dashkova to become the first woman to join the American Philosophical Society; she was the only woman so honored for another 80 years. Later, Dashkova reciprocated by making him the first American member of the Russian Academy of Sciences.

As a founding father of the United States, Franklin's name has been attached to many things. Among these are:

Biographies

For young readers

Scholarly studies

Historiography

Primary sources

Biographical and guides

Online writings

Autobiography

In the arts


</doc>
<doc id="3989" url="https://en.wikipedia.org/wiki?curid=3989" title="Banach space">
Banach space

In mathematics, more specifically in functional analysis, a Banach space (pronounced ) is a complete normed vector space. Thus, a Banach space is a vector space with a metric that allows the computation of vector length and distance between vectors and is complete in the sense that a Cauchy sequence of vectors always converges to a well defined limit that is within the space.

Banach spaces are named after the Polish mathematician Stefan Banach, who introduced this concept and studied it systematically in 1920–1922 along with Hans Hahn and Eduard Helly. Banach spaces originally grew out of the study of function spaces by Hilbert, Fréchet, and Riesz earlier in the century. Banach spaces play a central role in functional analysis. In other areas of analysis, the spaces under study are often Banach spaces.

A Banach space is a vector space over any scalar field K, which is equipped with a norm formula_1 and which is complete with respect to the distance function induced by the norm, that is to say, for every Cauchy sequence in , there exists an element in such that

or equivalently:

The vector space structure allows one to relate the behavior of Cauchy sequences to that of converging series of vectors. A normed space is a Banach space if and only if each absolutely convergent series in converges in ,

Completeness of a normed space is preserved if the given norm is replaced by an equivalent one.

All norms on a finite-dimensional vector space are equivalent. Every finite-dimensional normed space over or is a Banach space.

If and are normed spaces over the same ground field , the set of all continuous -linear maps is denoted by . In infinite-dimensional spaces, not all linear maps are continuous. A linear mapping from a normed space to another normed space is continuous if and only if it is bounded on the closed unit ball of . Thus, the vector space can be given the operator norm

For a Banach space, the space is a Banach space with respect to this norm.

If is a Banach space, the space forms a unital Banach algebra; the multiplication operation is given by the composition of linear maps.

If and are normed spaces, they are isomorphic normed spaces if there exists a linear bijection such that and its inverse are continuous. If one of the two spaces or is complete (or reflexive, separable, etc.) then so is the other space. Two normed spaces and are isometrically isomorphic if in addition, is an isometry, i.e., for every in . The Banach–Mazur distance between two isomorphic but not isometric spaces and gives a measure of how much the two spaces and differ.

Every normed space can be isometrically embedded in a Banach space. More precisely, for every normed space , there exist a Banach space and a mapping such that T is an isometric mapping and is dense in . If is another Banach space such that there is an isometric isomorphism from onto a dense subset of , then is isometrically isomorphic to .

This Banach space is the completion of the normed space . The underlying metric space for is the same as the metric completion of , with the vector space operations extended from to . The completion of is often denoted by formula_6.

The cartesian product of two normed spaces is not canonically equipped with a norm. However, several equivalent norms are commonly used, such as

and give rise to isomorphic normed spaces. In this sense, the product (or the direct sum ) is complete if and only if the two factors are complete.

If is a closed linear subspace of a normed space , there is a natural norm on the quotient space ,

The quotient is a Banach space when is complete. The quotient map from onto , sending in to its class , is linear, onto and has norm , except when , in which case the quotient is the null space.

The closed linear subspace of is said to be a complemented subspace of if is the range of a bounded linear projection from onto . In this case, the space is isomorphic to the direct sum of and , the kernel of the projection .

Suppose that and are Banach spaces and that . There exists a canonical factorization of as

where the first map is the quotient map, and the second map sends every class in the quotient to the image in . This is well defined because all elements in the same class have the same image. The mapping is a linear bijection from onto the range , whose inverse need not be bounded.

Basic examples of Banach spaces include: the spaces and their special cases, the sequence spaces that consist of scalar sequences indexed by ; among them, the space of absolutely summable sequences and the space of square summable sequences; the space of sequences tending to zero and the space of bounded sequences; the space of continuous scalar functions on a compact Hausdorff space , equipped with the max norm,

According to the Banach–Mazur theorem, every Banach space is isometrically isomorphic to a subspace of some . For every separable Banach space , there is a closed subspace of such that .

Any Hilbert space serves as an example of a Banach space. A Hilbert space on is complete for a norm of the form

where

is the inner product, linear in its first argument that satisfies the following:

For example, the space is a Hilbert space.

The Hardy spaces, the Sobolev spaces are examples of Banach spaces that are related to spaces and have additional structure. They are important in different branches of analysis, Harmonic analysis and Partial differential equations among others.

A Banach algebra is a Banach space over or , together with a structure of algebra over, such that the product map "A" × "A" ∋ is continuous. An equivalent norm on can be found so that for all .


If is a normed space and the underlying field (either the real or the complex numbers), the continuous dual space is the space of continuous linear maps from into , or continuous linear functionals. The notation for the continuous dual is in this article. Since is a Banach space (using the absolute value as norm), the dual is a Banach space, for every normed space .

The main tool for proving the existence of continuous linear functionals is the Hahn–Banach theorem.

In particular, every continuous linear functional on a subspace of a normed space can be continuously extended to the whole space, without increasing the norm of the functional. An important special case is the following: for every vector in a normed space , there exists a continuous linear functional on such that

When is not equal to the vector, the functional must have norm one, and is called a norming functional for .

The Hahn–Banach separation theorem states that two disjoint non-empty convex sets in a real Banach space, one of them open, can be separated by a closed affine hyperplane. The open convex set lies strictly on one side of the hyperplane, the second convex set lies on the other side but may touch the hyperplane.

A subset in a Banach space is total if the linear span of is dense in . The subset is total in if and only if the only continuous linear functional that vanishes on is the functional: this equivalence follows from the Hahn–Banach theorem.

If is the direct sum of two closed linear subspaces and , then the dual of is isomorphic to the direct sum of the duals of and . If is a closed linear subspace in , one can associate the "orthogonal of" in the dual,

The orthogonal is a closed linear subspace of the dual. The dual of is isometrically isomorphic to . The dual of is isometrically isomorphic to .

The dual of a separable Banach space need not be separable, but:

When is separable, the above criterion for totality can be used for proving the existence of a countable total subset in .

The weak topology on a Banach space is the coarsest topology on for which all elements in the continuous dual space are continuous. The norm topology is therefore finer than the weak topology. It follows from the Hahn–Banach separation theorem that the weak topology is Hausdorff, and that a norm-closed convex subset of a Banach space is also weakly closed. A norm-continuous linear map between two Banach spaces and is also weakly continuous, i.e., continuous from the weak topology of to that of .

If is infinite-dimensional, there exist linear maps which are not continuous. The space of all linear maps from to the underlying field (this space is called the algebraic dual space, to distinguish it from ) also induces a topology on which is finer than the weak topology, and much less used in functional analysis.

On a dual space , there is a topology weaker than the weak topology of , called weak* topology. It is the coarsest topology on for which all evaluation maps , are continuous. Its importance comes from the Banach–Alaoglu theorem.

The Banach–Alaoglu theorem depends on Tychonoff's theorem about infinite products of compact spaces. When is separable, the unit ball of the dual is a metrizable compact in the weak* topology.

The dual of is isometrically isomorphic to : for every bounded linear functional on , there is a unique element such that

The dual of is isometrically isomorphic to . The dual of is isometrically isomorphic to when and .

For every vector in a Hilbert space , the mapping

defines a continuous linear functional on . The Riesz representation theorem states that every continuous linear functional on is of the form for a uniquely defined vector in . The mapping is an antilinear isometric bijection from onto its dual . When the scalars are real, this map is an isometric isomorphism.

When is a compact Hausdorff topological space, the dual of is the space of Radon measures in the sense of Bourbaki. The subset of consisting of non-negative measures of mass 1 (probability measures) is a convex w*-closed subset of the unit ball of . The extreme points of are the Dirac measures on . The set of Dirac measures on , equipped with the w*-topology, is homeomorphic to .

The result has been extended by Amir and Cambern to the case when the multiplicative Banach–Mazur distance between and is . The theorem is no longer true when the distance is .

In the commutative Banach algebra , the maximal ideals are precisely kernels of Dirac mesures on ,

More generally, by the Gelfand–Mazur theorem, the maximal ideals of a unital commutative Banach algebra can be identified with its characters—not merely as sets but as topological spaces: the former with the hull-kernel topology and the latter with the w*-topology. In this identification, the maximal ideal space can be viewed as a w*-compact subset of the unit ball in the dual .

Not every unital commutative Banach algebra is of the form for some compact Hausdorff space . However, this statement holds if one places in the smaller category of commutative C*-algebras. Gelfand's representation theorem for commutative C*-algebras states that every commutative unital "C"*-algebra is isometrically isomorphic to a space. The Hausdorff compact space here is again the maximal ideal space, also called the spectrum of in the C*-algebra context.

If is a normed space, the (continuous) dual of the dual is called bidual, or second dual of . For every normed space , there is a natural map,

This defines as a continuous linear functional on , i.e., an element of . The map is a linear map from to . As a consequence of the existence of a norming functional for every in , this map is isometric, thus injective.

For example, the dual of is identified with , and the dual of is identified with , the space of bounded scalar sequences. Under these identifications, is the inclusion map from to . It is indeed isometric, but not onto.

If is surjective, then the normed space is called reflexive (see below). Being the dual of a normed space, the bidual is complete, therefore, every reflexive normed space is a Banach space.

Using the isometric embedding , it is customary to consider a normed space as a subset of its bidual. When is a Banach space, it is viewed as a closed linear subspace of . If is not reflexive, the unit ball of is a proper subset of the unit ball of . The Goldstine theorem states that the unit ball of a normed space is weakly*-dense in the unit ball of the bidual. In other words, for every in the bidual, there exists a net in so that

The net may be replaced by a weakly*-convergent sequence when the dual is separable. On the other hand, elements of the bidual of that are not in cannot be weak*-limit of "sequences" in , since is weakly sequentially complete.

Here are the main general results about Banach spaces that go back to the time of Banach's book () and are related to the Baire category theorem. According to this theorem, a complete metric space (such as a Banach space, a Fréchet space or an F-space) cannot be equal to a union of countably many closed subsets with empty interiors. Therefore, a Banach space cannot be the union of countably many closed subspaces, unless it is already equal to one of them; a Banach space with a countable Hamel basis is finite-dimensional.

The Banach–Steinhaus theorem is not limited to Banach spaces. It can be extended for example to the case where is a Fréchet space, provided the conclusion is modified as follows: under the same hypothesis, there exists a neighborhood of in such that all in are uniformly bounded on ,

This result is a direct consequence of the preceding "Banach isomorphism theorem" and of the canonical factorization of bounded linear maps.

This is another consequence of Banach's isomorphism theorem, applied to the continuous bijection from onto sending to the sum .

The normed space is called reflexive when the natural map

is surjective. Reflexive normed spaces are Banach spaces.

This is a consequence of the Hahn–Banach theorem. Further, by the open mapping theorem, if there is a bounded linear operator from the Banach space onto the Banach space , then is reflexive.

Indeed, if the dual of a Banach space is separable, then is separable. If is reflexive and separable, then the dual of is separable, so is separable.

Hilbert spaces are reflexive. The spaces are reflexive when . More generally, uniformly convex spaces are reflexive, by the Milman–Pettis theorem. The spaces are not reflexive. In these examples of non-reflexive spaces , the bidual is "much larger" than . Namely, under the natural isometric embedding of into given by the Hahn–Banach theorem, the quotient is infinite-dimensional, and even nonseparable. However, Robert C. James has constructed an example of a non-reflexive space, usually called ""the James space"" and denoted by "J", such that the quotient is one-dimensional. Furthermore, this space is isometrically isomorphic to its bidual.

When is reflexive, it follows that all closed and bounded convex subsets of are weakly compact. In a Hilbert space , the weak compactness of the unit ball is very often used in the following way: every bounded sequence in has weakly convergent subsequences.

Weak compactness of the unit ball provides a tool for finding solutions in reflexive spaces to certain optimization problems. For example, every convex continuous function on the unit ball of a reflexive space attains its minimum at some point in .

As a special case of the preceding result, when is a reflexive space over , every continuous linear functional in attains its maximum on the unit ball of . The following theorem of Robert C. James provides a converse statement.

The theorem can be extended to give a characterization of weakly compact convex sets.

On every non-reflexive Banach space , there exist continuous linear functionals that are not "norm-attaining". However, the Bishop–Phelps theorem states that norm-attaining functionals are norm dense in the dual of .

A sequence in a Banach space is weakly convergent to a vector if converges to for every continuous linear functional in the dual . The sequence is a weakly Cauchy sequence if converges to a scalar limit , for every in . A sequence in the dual is weakly* convergent to a functional if converges to for every in . Weakly Cauchy sequences, weakly convergent and weakly* convergent sequences are norm bounded, as a consequence of the Banach–Steinhaus theorem.

When the sequence in is a weakly Cauchy sequence, the limit above defines a bounded linear functional on the dual , i.e., an element of the bidual of , and is the limit of in the weak*-topology of the bidual. The Banach space is weakly sequentially complete if every weakly Cauchy sequence is weakly convergent in . It follows from the preceding discussion that reflexive spaces are weakly sequentially complete.

An orthonormal sequence in a Hilbert space is a simple example of a weakly convergent sequence, with limit equal to the vector. The unit vector basis of , or of , is another example of a weakly null sequence, i.e., a sequence that converges weakly to . For every weakly null sequence in a Banach space, there exists a sequence of convex combinations of vectors from the given sequence that is norm-converging to .

The unit vector basis of is not weakly Cauchy. Weakly Cauchy sequences in are weakly convergent, since -spaces are weakly sequentially complete. Actually, weakly convergent sequences in are norm convergent. This means that satisfies Schur's property.

Weakly Cauchy sequences and the basis are the opposite cases of the dichotomy established in the following deep result of H. P. Rosenthal.

A complement to this result is due to Odell and Rosenthal (1975).

By the Goldstine theorem, every element of the unit ball of is weak*-limit of a net in the unit ball of . When does not contain , every element of is weak*-limit of a "sequence" in the unit ball of .

When the Banach space is separable, the unit ball of the dual , equipped with the weak*-topology, is a metrizable compact space , and every element in the bidual defines a bounded function on :

This function is continuous for the compact topology of if and only if is actually in , considered as subset of . Assume in addition for the rest of the paragraph that does not contain . By the preceding result of Odell and Rosenthal, the function is the pointwise limit on of a sequence of continuous functions on , it is therefore a first Baire class function on . The unit ball of the bidual is a pointwise compact subset of the first Baire class on .

When is separable, the unit ball of the dual is weak*-compact by Banach–Alaoglu and metrizable for the weak* topology, hence every bounded sequence in the dual has weakly* convergent subsequences. This applies to separable reflexive spaces, but more is true in this case, as stated below.

The weak topology of a Banach space is metrizable if and only if is finite-dimensional. If the dual is separable, the weak topology of the unit ball of is metrizable. This applies in particular to separable reflexive Banach spaces. Although the weak topology of the unit ball is not metrizable in general, one can characterize weak compactness using sequences.

A Banach space is reflexive if and only if each bounded sequence in has a weakly convergent subsequence.

A weakly compact subset in is norm-compact. Indeed, every sequence in has weakly convergent subsequences by Eberlein–Šmulian, that are norm convergent by the Schur property of .

A Schauder basis in a Banach space is a sequence of vectors in "X" with the property that for every vector in , there exist "uniquely" defined scalars depending on , such that

Banach spaces with a Schauder basis are necessarily separable, because the countable set of finite linear combinations with rational coefficients (say) is dense.

It follows from the Banach–Steinhaus theorem that the linear mappings are uniformly bounded by some constant . Let denote the coordinate functionals which assign to every in the coordinate of in the above expansion. They are called biorthogonal functionals. When the basis vectors have norm , the coordinate functionals have norm in the dual of .

Most classical separable spaces have explicit bases. The Haar system is a basis for . The trigonometric system is a basis in when . The Schauder system is a basis in the space . The question of whether the disk algebra has a basis remained open for more than forty years, until Bočkarev showed in 1974 that admits a basis constructed from the Franklin system.

Since every vector in a Banach space with a basis is the limit of , with of finite rank and uniformly bounded, the space satisfies the bounded approximation property. The first example by Enflo of a space failing the approximation property was at the same time the first example of a separable Banach space without a Schauder basis.

Robert C. James characterized reflexivity in Banach spaces with a basis: the space with a Schauder basis is reflexive if and only if the basis is both shrinking and boundedly complete. In this case, the biorthogonal functionals form a basis of the dual of .

Let and be two -vector spaces. The tensor product of and is a -vector space with a bilinear mapping which has the following universal property:

The image under of a couple in is denoted by , and called a simple tensor. Every element in is a finite sum of such simple tensors.

There are various norms that can be placed on the tensor product of the underlying vector spaces, amongst others the projective cross norm and injective cross norm introduced by A. Grothendieck in 1955.

In general, the tensor product of complete spaces is not complete again. When working with Banach spaces, it is customary to say that the projective tensor product of two Banach spaces and is the "completion" formula_26 of the algebraic tensor product equipped with the projective tensor norm, and similarly for the injective tensor product formula_27. Grothendieck proved in particular that

where is a compact Hausdorff space, the Banach space of continuous functions from to and the space of Bochner-measurable and integrable functions from to , and where the isomorphisms are isometric. The two isomorphisms above are the respective extensions of the map sending the tensor to the vector-valued function .

Let be a Banach space. The tensor product formula_29 is identified isometrically with the closure in of the set of finite rank operators. When has the approximation property, this closure coincides with the space of compact operators on .

For every Banach space , there is a natural norm linear map

obtained by extending the identity map of the algebraic tensor product. Grothendieck related the approximation problem to the question of whether this map is one-to-one when is the dual of . Precisely, for every Banach space , the map

is one-to-one if and only if has the approximation property.

Grothendieck conjectured that formula_26 and formula_27 must be different whenever and are infinite-dimensional Banach spaces. This was disproved by Gilles Pisier in 1983. Pisier constructed an infinite-dimensional Banach space such that formula_34 and formula_35 are equal. Furthermore, just as Enflo's example, this space is a "hand-made" space that fails to have the approximation property. On the other hand, Szankowski proved that the classical space does not have the approximation property.

A necessary and sufficient condition for the norm of a Banach space to be associated to an inner product is the parallelogram identity:

It follows, for example, that the Lebesgue space is a Hilbert space only when . If this identity is satisfied, the associated inner product is given by the polarization identity. In the case of real scalars, this gives:

For complex scalars, defining the inner product so as to be -linear in , antilinear in , the polarization identity gives:

To see that the parallelogram law is sufficient, one observes in the real case that is symmetric, and in the complex case, that it satisfies the Hermitian symmetry property and . The parallelogram law implies that is additive in . It follows that it is linear over the rationals, thus linear by continuity.

Several characterizations of spaces isomorphic (rather than isometric) to Hilbert spaces are available. The parallelogram law can be extended to more than two vectors, and weakened by the introduction of a two-sided inequality with a constant : Kwapień proved that if

for every integer and all families of vectors , then the Banach space is isomorphic to a Hilbert space. Here, denotes the average over the possible choices of signs . In the same article, Kwapień proved that the validity of a Banach-valued Parseval's theorem for the Fourier transform characterizes Banach spaces isomorphic to Hilbert spaces.

Lindenstrauss and Tzafriri proved that a Banach space in which every closed linear subspace is complemented (that is, is the range of a bounded linear projection) is isomorphic to a Hilbert space. The proof rests upon Dvoretzky's theorem about Euclidean sections of high-dimensional centrally symmetric convex bodies. In other words, Dvoretzky's theorem states that for every integer , any finite-dimensional normed space, with dimension sufficiently large compared to , contains subspaces nearly isometric to the -dimensional Euclidean space.

The next result gives the solution of the so-called "homogeneous space problem". An infinite-dimensional Banach space is said to be homogeneous if it is isomorphic to all its infinite-dimensional closed subspaces. A Banach space isomorphic to is homogeneous, and Banach asked for the converse.

An infinite-dimensional Banach space is hereditarily indecomposable when no subspace of it can be isomorphic to the direct sum of two infinite-dimensional Banach spaces. The Gowers dichotomy theorem asserts that every infinite-dimensional Banach space contains, either a subspace with unconditional basis, or a hereditarily indecomposable subspace , and in particular, is not isomorphic to its closed hyperplanes. If is homogeneous, it must therefore have an unconditional basis. It follows then from the partial solution obtained by Komorowski and Tomczak–Jaegermann, for spaces with an unconditional basis, that is isomorphic to .

If formula_40 is an isometry from the Banach space formula_41 onto the Banach space formula_42 (where both formula_41 and formula_42 are vector spaces over formula_45), then the Mazur-Ulam theorem states that formula_46 must be an affine transformation. In particular, if formula_47, this is formula_46 maps the zero of formula_41 to the zero of formula_42, then formula_46 must be linear. This result implies that the metric in Banach spaces, and more generally in normed spaces, completely captures their linear structure.

Finite dimensional Banach spaces are homeomorphic as topological spaces, if and only if they have the same dimension as real vector spaces.

Anderson–Kadec theorem (1965–66) proves that any two infinite-dimensional separable Banach spaces are homeomorphic as topological spaces. Kadec's theorem was extended by Torunczyk, who proved that any two Banach spaces are homeomorphic if and only if they have the same density character, the minimum cardinality of a dense subset.

When two compact Hausdorff spaces and are homeomorphic, the Banach spaces and are isometric. Conversely, when is not homeomorphic to , the (multiplicative) Banach–Mazur distance between and must be greater than or equal to , see above the results by Amir and Cambern. Although uncountable compact metric spaces can have different homeomorphy types, one has the following result due to Milutin:

The situation is different for countably infinite compact Hausdorff spaces. Every countably infinite compact is homeomorphic to some closed interval of ordinal numbers

equipped with the order topology, where is a countably infinite ordinal. The Banach space is then isometric to . When are two countably infinite ordinals, and assuming , the spaces and are isomorphic if and only if .
For example, the Banach spaces

are mutually non-isomorphic.

A glossary of symbols:

Several concepts of a derivative may be defined on a Banach space. See the articles on the Fréchet derivative and the Gateaux derivative for details. The Fréchet derivative allows for an extension of the concept of a directional derivative to Banach spaces. The Gateaux derivative allows for an extension of a directional derivative to locally convex topological vector spaces. Fréchet differentiability is a stronger condition than Gateaux differentiability. The quasi-derivative is another generalization of directional derivative that implies a stronger condition than Gateaux differentiability, but a weaker condition than Fréchet differentiability.

Several important spaces in functional analysis, for instance the space of all infinitely often differentiable functions R → R, or the space of all distributions on R, are complete but are not normed vector spaces and hence not Banach spaces. In Fréchet spaces one still has a complete metric, while LF-spaces are complete uniform vector spaces arising as limits of Fréchet spaces.





</doc>
<doc id="3992" url="https://en.wikipedia.org/wiki?curid=3992" title="Bram Stoker">
Bram Stoker

Abraham "Bram" Stoker (8 November 1847 – 20 April 1912) was an Irish author, best known today for his 1897 Gothic Horror novel "Dracula". During his lifetime, he was better known as the personal assistant of actor Sir Henry Irving, and business manager of the Lyceum Theatre in London, which Irving owned.

Stoker was born on 8 November 1847 at 15 Marino Crescent, Clontarf, on the northside of Dublin, Ireland. His parents were Abraham Stoker (1799–1876) from Dublin and Charlotte Mathilda Blake Thornley (1818–1901), who was raised in County Sligo. Stoker was the third of seven children, the eldest of whom was Sir Thornley Stoker, 1st Bt.. Abraham and Charlotte were members of the Church of Ireland Parish of Clontarf and attended the parish church with their children, who were baptised there, and Abraham was a senior civil servant.

Stoker was bedridden with an unknown illness until he started school at the age of seven, when he made a complete recovery. Of this time, Stoker wrote, "I was naturally thoughtful, and the leisure of long illness gave opportunity for many thoughts which were fruitful according to their kind in later years." He was educated in a private school run by the Rev. William Woods.

After his recovery, he grew up without further serious illnesses, even excelling as an athlete (he was named University Athlete, participating in multiple sports) at Trinity College, Dublin, which he attended from 1864 to 1870. He graduated with a BA in 1870, and pursued his MA in 1875. Though he later in life recalled graduating "with honours in mathematics," this appears to have been a mistake. He was auditor of the College Historical Society ("the Hist") and president of the University Philosophical Society, where his first paper was on "Sensationalism in Fiction and Society".

Stoker became interested in the theatre while a student through his friend Dr. Maunsell. While working for the Irish Civil Service, he became the theatre critic for the "Dublin Evening Mail", which was co-owned by Sheridan Le Fanu, an author of Gothic tales. Theatre critics were held in low esteem, but he attracted notice by the quality of his reviews. In December 1876, he gave a favourable review of Henry Irving's "Hamlet" at the Theatre Royal in Dublin. Irving invited Stoker for dinner at the Shelbourne Hotel where he was staying, and they became friends. Stoker also wrote stories, and "The Crystal Cup" was published by the London Society in 1872, followed by "The Chain of Destiny" in four parts in "The Shamrock". In 1876 while a civil servant in Dublin, Stoker wrote the non-fiction book "The Duties of Clerks of Petty Sessions in Ireland" (published 1879) which remained a standard work. Furthermore, he possessed an interest in art, and was a founder of the Dublin Sketching Club in 1879.

In 1878 Stoker married Florence Balcombe, daughter of Lieutenant-Colonel James Balcombe of 1 Marino Crescent. She was a celebrated beauty whose former suitor had been Oscar Wilde. Stoker had known Wilde from his student days, having proposed him for membership of the university's Philosophical Society while he was president. Wilde was upset at Florence's decision, but Stoker later resumed the acquaintanceship, and after Wilde's fall visited him on the Continent.

The Stokers moved to London, where Stoker became acting manager and then business manager of Irving's Lyceum Theatre, London, a post he held for 27 years. On 31 December 1879, Bram and Florence's only child was born, a son whom they christened Irving Noel Thornley Stoker. The collaboration with Henry Irving was important for Stoker and through him he became involved in London's high society, where he met James Abbott McNeill Whistler and Sir Arthur Conan Doyle (to whom he was distantly related). Working for Irving, the most famous actor of his time, and managing one of the most successful theatres in London made Stoker a notable if busy man. He was dedicated to Irving and his memoirs show he idolised him. In London, Stoker also met Hall Caine, who became one of his closest friends – he dedicated "Dracula" to him.

In the course of Irving's tours, Stoker travelled the world, although he never visited Eastern Europe, a setting for his most famous novel. Stoker enjoyed the United States, where Irving was popular. With Irving he was invited twice to the White House, and knew William McKinley and Theodore Roosevelt. Stoker set two of his novels in America, and used Americans as characters, the most notable being Quincey Morris. He also met one of his literary idols, Walt Whitman.

Stoker was a regular visitor to Cruden Bay in Scotland between 1893 and 1910. His month-long holidays to the Aberdeenshire coastal village provided a large portion of available time for writing his books. Two novels were set in Cruden Bay: "The Watter's Mou' "(1895) and "The Mystery of the Sea" (1902). He started writing "Dracula" here in 1895 while in residence at the Kilmarnock Arms Hotel. The guest book with his signatures from 1894 and 1895 still survives. The nearby Slains Castle (also known as New Slains Castle) is linked with Bram Stoker and plausibly provided the visual palette for the descriptions of Castle Dracula during the writing phase. A distinctive room in Slains Castle, the octagonal hall, matches the description of the octagonal room in Castle Dracula.

Stoker visited the English coastal town of Whitby in 1890, and that visit was said to be part of the inspiration for "Dracula". He began writing novels while working as manager for Henry Irving and secretary and director of London's Lyceum Theatre, beginning with "The Snake's Pass" in 1890 and "Dracula" in 1897. During this period, Stoker was part of the literary staff of "The Daily Telegraph" in London, and he wrote other fiction, including the horror novels "The Lady of the Shroud" (1909) and "The Lair of the White Worm" (1911). He published his "Personal Reminiscences of Henry Irving" in 1906, after Irving's death, which proved successful, and managed productions at the Prince of Wales Theatre.

Before writing "Dracula", Stoker met Ármin Vámbéry, a Hungarian-Jewish writer and traveller (born in Szent-György, Kingdom of Hungary now Svätý Jur, Slovakia). Dracula likely emerged from Vámbéry's dark stories of the Carpathian mountains. Stoker then spent several years researching Central and East European folklore and mythological stories of vampires.

The 1972 book "In Search of Dracula" by Radu Florescu and Raymond McNally claimed that the Count in Stoker's novel was based on Vlad III Dracula. At most however, Stoker borrowed only the name and "scraps of miscellaneous information" about Romanian history, according to one expert, Elizabeth Miller; further, there are no comments about Vlad III in the author's working notes.

"Dracula" is an epistolary novel, written as a collection of realistic but completely fictional diary entries, telegrams, letters, ship's logs, and newspaper clippings, all of which added a level of detailed realism to the story, a skill which Stoker had developed as a newspaper writer. At the time of its publication, "Dracula" was considered a "straightforward horror novel" based on imaginary creations of supernatural life. "It gave form to a universal fantasy ... and became a part of popular culture."

Stoker was a deeply private man, but his almost sexless marriage, intense adoration of Walt Whitman, Henry Irving and Hall Caine, and shared interests with Oscar Wilde, as well as the homoerotic aspects of "Dracula" have led to scholarly speculation that he was a repressed homosexual who used his fiction as an outlet for his sexual frustrations. In 1912, he demanded imprisonment of all homosexual authors in Britain: it has been suggested that this was due to self-loathing and to disguise his own vulnerability. Possibly fearful, and inspired by the monstrous image and threat of otherness that the press coverage of his friend Oscar's trials generated, Stoker began writing "Dracula" only weeks after Wilde's conviction.

According to the "Encyclopedia of World Biography", Stoker's stories are today included in the categories of "horror fiction", "romanticized Gothic" stories, and "melodrama." They are classified alongside other "works of popular fiction" such as Mary Shelley's "Frankenstein", which also used the "myth-making" and story-telling method of having multiple narrators telling the same tale from different perspectives. According to historian Jules Zanger, this leads the reader to the assumption that "they can't all be lying".

The original 541-page typescript of "Dracula" was believed to have been lost until it was found in a barn in northwestern Pennsylvania in the early 1980s. It consisted of typed sheets with many emendations and handwritten on the title page was "THE UN-DEAD." The author's name was shown at the bottom as Bram Stoker. Author Robert Latham remarked: "the most famous horror novel ever published, its title changed at the last minute." The typescript was purchased by Microsoft co-founder Paul Allen.

Stoker's inspirations for the story, in addition to Whitby, may have included a visit to Slains Castle in Aberdeenshire, a visit to the crypts of St. Michan's Church in Dublin, and the novella "Carmilla" by Sheridan Le Fanu.

Stoker's original research notes for the novel are kept by the Rosenbach Museum and Library in Philadelphia. A facsimile edition of the notes was created by Elizabeth Miller and Robert Eighteen-Bisang in 1998.

Stoker was a member of The London Library and it is here that he conducted much of the research for "Dracula." In 2018 the Library discovered some of the books that Stoker used for his research, complete with notes and marginalia.

After suffering a number of strokes, Stoker died at No. 26 St George's Square, London on 20 April 1912. Some biographers attribute the cause of death to tertiary syphilis, others to overwork. He was cremated, and his ashes were placed in a display urn at Golders Green Crematorium in north London. The ashes of Irving Noel Stoker, the author's son, were added to his father's urn following his death in 1961. The original plan had been to keep his parents' ashes together, but after Florence Stoker's death, her ashes were scattered at the Gardens of Rest.

Stoker was raised a Protestant in the Church of Ireland. He was a strong supporter of the Liberal Party and took a keen interest in Irish affairs. As a "philosophical home ruler," he supported Home Rule for Ireland brought about by peaceful means. He remained an ardent monarchist who believed that Ireland should remain within the British Empire, an entity that he saw as a force for good. He was an admirer of Prime Minister William Ewart Gladstone, whom he knew personally, and supported his plans for Ireland.

Stoker believed in progress and took a keen interest in science and science-based medicine. Some Stoker novels represent early examples of science fiction, such as "The Lady of the Shroud" (1909). He had a writer's interest in the occult, notably mesmerism, but despised fraud and believed in the superiority of the scientific method over superstition. Stoker counted among his friends J.W. Brodie-Innis, a member of the Hermetic Order of the Golden Dawn, and hired member Pamela Colman Smith as an artist for the Lyceum Theatre, but no evidence suggests that Stoker ever joined the Order himself. Although Irving was an active Freemason, no evidence has been found of Stoker taking part in Masonic activities in London. The Grand Lodge of Ireland also has no record of his membership.

The short story collection "Dracula's Guest and Other Weird Stories" was published in 1914 by Stoker's widow, Florence Stoker, who was also his literary executrix. The first film adaptation of "Dracula" was F. W. Murnau's "Nosferatu", released in 1922, with Max Schreck starring as Count Orlok. Florence Stoker eventually sued the filmmakers, and was represented by the attorneys of the British Incorporated Society of Authors. Her chief legal complaint was that she had neither been asked for permission for the adaptation nor paid any royalty. The case dragged on for some years, with Mrs. Stoker demanding the destruction of the negative and all prints of the film. The suit was finally resolved in the widow's favour in July 1925. A single print of the film survived, however, and it has become well known. The first authorised film version of "Dracula" did not come about until almost a decade later when Universal Studios released Tod Browning's "Dracula" starring Bela Lugosi.

Canadian writer Dacre Stoker, a great-grandnephew of Bram Stoker, decided to write "a sequel that bore the Stoker name" to "reestablish creative control over" the original novel, with encouragement from screenwriter Ian Holt, because of the Stokers' frustrating history with "Dracula's" copyright. In 2009, "Dracula: The Un-Dead" was released, written by Dacre Stoker and Ian Holt. Both writers "based [their work] on Bram Stoker's own handwritten notes for characters and plot threads excised from the original edition" along with their own research for the sequel. This also marked Dacre Stoker's writing debut.

In spring 2012, Dacre Stoker (in collaboration with Prof. Elizabeth Miller) presented the "lost" Dublin Journal written by Bram Stoker, which had been kept by his great-grandson Noel Dobbs. Stoker's diary entries shed a light on the issues that concerned him before his London years. A remark about a boy who caught flies in a bottle might be a clue for the later development of the Renfield character in "Dracula".

On 8 November 2012, Stoker was honoured with a Google Doodle on Google's homepage commemorating the 165th anniversary of his birth.

An annual festival takes place in Dublin, the birthplace of Bram Stoker, in honour of his literary achievements. The 2014 Bram Stoker Festival encompassed literary, film, family, street, and outdoor events, and ran from 24–27 October in Dublin. The festival is supported by the Bram Stoker Estate and funded by Dublin City Council and Fáilte Ireland.










</doc>
<doc id="3993" url="https://en.wikipedia.org/wiki?curid=3993" title="Billion (disambiguation)">
Billion (disambiguation)

Billion is a name for a large number. It may refer specifically to:


Billion may also refer to: 



</doc>
<doc id="3995" url="https://en.wikipedia.org/wiki?curid=3995" title="Contract bridge">
Contract bridge

Contract bridge, or simply bridge, is a trick-taking card game using a standard 52-card deck. In its basic format, it is played by four players in two competing partnerships, with partners sitting opposite each other around a table. Millions of people play bridge worldwide in clubs, tournaments, online and with friends at home, making it one of the world's most popular card games, particularly among seniors. The World Bridge Federation (WBF) is the governing body for international competitive bridge, with numerous other bodies governing bridge at the regional level.

The game consists of several , each progressing through four phases. The cards are dealt to the players, and then the players ‘’call’’ (or ‘’bid’’) in an auction to take the , specifying how many tricks the partnership receiving the contract (the declaring side) needs to take to receive points for the deal. During the auction, partners communicate information about their hand, including its overall strength and the length of its suits, although conventions for use during play also exist. The cards are then played, the trying to fulfill the contract, and the trying to stop the declaring side from achieving its goal. The deal is scored based on the number of tricks taken, the contract, and various other factors which depend to some extent on the variation of the game being played.

Rubber bridge is the most popular variation for casual play, but most club and tournament play involves some variant of duplicate bridge, in which the cards are not re-dealt on each occasion, but the same deal is played by two or more sets of players (or "tables") to enable comparative scoring. For competition level, so called IMP score is of high significance.

Bridge is a member of the family of trick-taking games and is a development of Whist, which had become the dominant such game and enjoyed a loyal following for centuries. The idea of a trick-taking 52-card game has its first documented origins in Italy and France. The French physician and author Rabelais (1493–1553) mentions a game called "La Triomphe" in one of his works. In 1526 the Italian Francesco Berni wrote the oldest known (as of 1960) textbook on a game very similar to Whist, known as "Triomfi". Also, a Spanish textbook in Latin from the first half of the 16th century, "Triumphens Historicus", deals with the same subject.

Bridge departed from whist with the creation of "Biritch" in the 19th century, and evolved through the late 19th and early 20th centuries to form the present game. The first rule book for bridge, dated 1886, is "" written by John Collinson, an English financier working in Ottoman Istanbul. It and his subsequent letter to "The Saturday Review" dated May 28, 1906, document the origin of "Biritch" as being the Russian community in Istanbul. The word "biritch" is thought to be a transliteration of the Russian word Бирюч (бирчий, бирич), an occupation of a diplomatic clerk or an announcer. Another theory is that British soldiers invented the game bridge while serving in the Crimean War, and named it after the Galata Bridge, which they crossed on their way to a coffeehouse to play cards.

Biritch had many significant bridge-like developments: dealer chose the trump suit, or nominated his partner to do so; there was a call of no trumps ("biritch"); dealer's partner's hand became dummy; points were scored above and below the line; game was 3NT, 4 and 5 (although 8 club odd tricks and 15 spade odd tricks were needed); the score could be doubled and redoubled; and there were slam bonuses. It has some features in common with Solo Whist. This game, and variants of it known as "bridge" and "bridge-whist", became popular in the United States and the United Kingdom in the 1890s despite the long-established dominance of whist. Its breakthrough had been its acceptance at London's Portland Club by Lord Brougham in 1894.

In 1904 auction bridge was developed, in which the players bid in a competitive auction to decide the contract and declarer. The object became to make at least as many tricks as were contracted for, and penalties were introduced for failing to do so. Auction bridge bidding beyond winning the auction is pointless. If taking all 13 tricks, there is no difference in score between a 1 and a 7 final bid, as no bonus for game, small slam or grand slam exists.
The modern game of contract bridge was the result of innovations to the scoring of auction bridge by Harold Stirling Vanderbilt and others. The most significant change was that only the tricks contracted for were scored below the line toward game or a slam bonus, a change that resulted in bidding becoming much more challenging and interesting. Also new was the concept of "vulnerability", making sacrifices to protect the lead in a rubber more expensive. The various scores were adjusted to produce a more balanced and interesting game. Vanderbilt set out his rules in 1925, and within a few years contract bridge had so supplanted other forms of the game that "bridge" became synonymous with "contract bridge".

In the US and many other countries, most of the bridge played today is duplicate bridge, which is played at clubs, in tournaments and online. The number of people playing contract bridge has declined since its peak in the 1940s, when a survey found it was played in 44% of US households. The game is still widely played, especially amongst retirees, and in 2005 the ACBL estimated there were 25 million players in the US.

Bridge is a four-player partnership trick-taking game with thirteen tricks per deal. The dominant variations of the game are rubber bridge, more common in social play; and duplicate bridge, which enables comparative scoring in tournament play. Each player is dealt thirteen cards from a standard 52-card deck. A starts when a player leads, i.e. plays the first card. The leader to the first trick is determined by the auction; the leader to each subsequent trick is the player who won the preceding trick. Each player, in a clockwise order, plays one card on the trick. Players must play a card of the same suit as the original card led, unless they have none (said to be "void"), in which case they may play any card.

The player who played the highest-ranked card wins the trick. Within a suit, the ace is ranked highest followed by the king, queen and jack and then the ten through to the two. In a deal where the auction has determined that there is no trump suit, the trick must be won by a card of the suit led. However, in a deal where there is a trump suit, cards of that suit are superior in rank to any of the cards of any other suit. If one or more players plays a trump to a trick when void in the suit led, the highest trump wins. For example, if the trump suit is spades and a player is void in the suit led and plays a spade card, he wins the trick if no other player plays a higher spade. If a trump suit is led, the usual rule for trick-taking applies.

Unlike its predecessor Whist, the goal of bridge is not simply to take the most tricks in a deal. Instead, the goal is to successfully estimate how many tricks one's partnership can take. To illustrate this, the simpler partnership trick-taking game of Spades has a similar mechanism: the usual trick-taking rules apply with the trump suit being spades, but in the beginning of the game, players "bid" or estimate how many tricks they can win, and the number of tricks bid by both players in a partnership are added. If a partnership takes at least that many number of tricks, they receive points for the round; otherwise, they receive penalty points.

Bridge extends the concept of bidding into an , where partnerships compete to take a , specifying how many tricks they will need to take in order to receive points, and also specifying the trump suit (or no trump, meaning that there will be no trump suit). Players take turns to call in a clockwise order: each player in turn either passes, doubleswhich increases the penalties for not making the contract specified by the opposing partnership's last bid, but also increases the reward for making itor redoubles, or states a contract that their partnership will adopt, which must be higher than the previous highest bid (if any). Eventually, the player who bid the highest contractwhich is determined by the contract's level as well as the trump suit or no trumpwins the contract for their partnership.

In the example auction below, the East-West pair secures the contract of 6; the auction concludes when there have been three successive passes. Note that six tricks are added to contract values, so the six-level contract would actually be a contract of twelve tricks. In practice, establishing a contract without enough information on the other partner's hand is difficult, so there exist many bidding systems assigning meanings to bids, with common ones including Standard American, Acol, and 2/1 game forcing. Contrast with Spades, where players only have to bid their own hand.

After the contract is decided, and the first lead is made, the declarer's partner (dummy) lays his cards face up on the table, and the declarer plays the dummy's cards as well as their own. The opposing partnership is called the , and their goal is to stop the declarer from fulfilling his contract. Once all the cards have been played, the hand is scored: if the declaring side make their contract, they receive points based on the level of the contract, with some trump suits being worth more points than others and no trump being the highest, as well as bonus points for . But if the declarer fails to fulfil the contract, the defenders receive points depending on the declaring side's undertricks (the number of tricks short of the contract) and whether the contract was doubled by the defenders.

The four players sit in two partnerships, with each player sitting opposite his partner. A cardinal direction is assigned to each seat, so that one partnership sits in North and South, while the other sits in West and East. The cards may be freshly dealt or, in duplicate bridge games, pre-dealt. All that is needed in basic games are the cards and a method of keeping score, but there is often other equipment on the table, such as a board containing the cards to be played (in duplicate bridge), bidding boxes, or screens.

In rubber bridge, each player draws a card at the start of the game: the two players who drew the highest cards are partners, and play against the other two. The deck is shuffled and cut, usually by the player to the left of the dealer, before dealing. Players take turns to deal, in a clockwise order. The dealer deals the cards clockwise, one card at a time.

In duplicate bridge, the cards are pre-dealt, either by hand or by a computerized dealing machine, in order to allow for competitive scoring. Once dealt, the cards are placed in a device called a "board", having slots designated for each player's cardinal direction seating position. After a deal has been played, players return their cards to the appropriate slot in the board, ready to be played by the next table.

The dealer opens the auction and can make the first call, and the auction proceeds clockwise. When it is their turn to call, a player may passbut can enter into the bidding lateror bid a contract, specifying the level of their contract and either the trump suit or no trump (the denomination), provided that it is higher than the last bid by any player, including their partner. All bids promise to take a number of tricks in excess of six, so a bid must be between one (seven tricks) and seven (thirteen tricks). A bid is higher than another bid if either the level is greater (e.g., 2 over 1NT) or the denomination is higher, with the order being in ascending order: , , , , and NT (no trump). Calls may be made orally, or with a bidding box, or digitally in online bridge.

If the last bid was by the opposing partnership, one may also the opponents' bid, increasing the penalties for undertricks, but also increasing the reward for making the contract. Doubling does not carry to future bids by the opponents unless future bids are doubled again. A player on the opposing partnership being doubled may also , which increases the penalties and rewards further. Players may not see their partner's hand during the auction, only their own. There exist many bidding conventions that assign agreed meanings to various calls to assist players in reaching an optimal contract (or obstruct the opponents).

The auction ends when, after a player bids, doubles, or redoubles, every other player has passed, in which case the action proceeds to the play; or every player has passed and no bid has been made, in which case the round is considered to be "passed out" and not played.

The player from the declaring side who first bid the denomination named in the final contract becomes declarer. The player left to the declarer leads to the first trick. Dummy then lays his or her cards face up on the table, organized in columns by suit. Play proceeds clockwise, with each player required to follow suit if possible. Tricks are won by the highest trump, or if there were none played, the highest card of the led suit. The player who won the previous trick leads to the next trick. The declarer has control of the dummy's cards and tells his partner which card to play at dummy's turn. There also exist conventions that communicate further information between defenders about their hands during the play.

At any time, a player may , stating that their side will win a specific number of the remaining tricks. The claiming player lays his cards down on the table and explains the order in which he intends to play the remaining cards. The opponents can either accept the claim and the round is scored accordingly, or dispute the claim. If the claim is disputed, play continues with the claiming player's cards face up in rubber games, or in duplicate games, play ceases and the tournament director is called to adjudicate the hand.

At the end of the hand, points are awarded to the declaring side if they make the contract, or else to the defenders. Partnerships can be , increasing the rewards for making the contract, but also increasing the penalties for undertricks. In rubber bridge, if a side has won 100 contract points, they have won a and are vulnerable for the remaining rounds, but in duplicate bridge, vulnerability is predetermined based on the number of each board.

If the declaring side makes their contract, they receive points for , or tricks bid and made in excess of six. In both rubber and duplicate bridge, the declaring side is awarded 20 points per odd trick for a contract in clubs or diamonds, and 30 points per odd trick for a contract in hearts or spades. For a contract in notrump, the declaring side is awarded 40 points for the first odd trick and 30 points for the remaining odd tricks. Contract points are doubled or quadrupled if the contract is respectively doubled or redoubled.

In rubber bridge, a partnership wins one game once it has accumulated 100 contract points; excess contract points do not carry over to the next game. A partnership that wins two games wins the rubber, receiving a bonus of 500 points if the opponents have won a game, and 700 points if they have not.

Overtricks score the same number of points per odd trick, although their doubled and redoubled values differ. Bonuses vary between the two bridge variations both in score and in type (for example, rubber bridge awards a bonus for holding a certain combination of high cards), although some are common between the two.

A larger bonus is awarded if the declaring side makes a small slam or grand slam, a contract of 12 or 13 tricks respectively. If the declaring side is not vulnerable, a small slam gets 500 points, and a grand slam 1000 points. If the declaring side is vulnerable, a small slam is 750 points and a grand slam is 1,500.

In rubber bridge, the rubber finishes when a partnership has won two games, but the partnership receiving the most "overall" points wins the rubber. Duplicate bridge is scored comparatively, meaning that the score for the hand is compared to other tables playing the same cards and match points are scored according to the comparative results: usually either "matchpoint scoring", where each partnership receives 2 points (or 1 point) for each pair that they beat, and 1 point (or point) for each tie; or IMPs (international matchpoint) scoring, where the number of IMPs varies (but less than proportionately) with the points difference between the teams.

Undertricks are scored in both variations as follows:
The rules of the game are referred to as the "laws" as promulgated by various bridge organizations.

The official rules of duplicate bridge are promulgated by the WBF as "The Laws of Duplicate Bridge 2017". The Laws Committee of the WBF, composed of world experts, updates the Laws every 10 years; it also issues a Laws Commentary advising on interpretations it has rendered.

In addition to the basic rules of play, there are many additional rules covering playing conditions and the rectification of irregularities, which are primarily for use by tournament directors who act as referees and have overall control of procedures during competitions. But various details of procedure are left to the discretion of the zonal bridge organisation for tournaments under their aegis and some (for example, the choice of "movement") to the sponsoring organisation (for example, the club).

Some zonal organisations of the WBF also publish editions of the Laws. For example, the American Contract Bridge League (ACBL) publishes the "Laws of Duplicate Bridge" and additional documentation for club and tournament directors.

There are no universally accepted rules for rubber bridge, but some zonal organisations have published their own. An example for those wishing to abide by a published standard is "The Laws of Rubber Bridge" as published by the American Contract Bridge League.

The majority of rules mirror those of duplicate bridge in the bidding and play and differ primarily in procedures for dealing and scoring.

In 2001, the WBF promulgated a set of Laws for online play.

Bridge is a game of skill played with randomly dealt cards, which makes it also a game of chance, or more exactly, a tactical game with inbuilt randomness, imperfect knowledge and restricted communication. The chance element is in the deal of the cards; in duplicate bridge some of the chance element is eliminated by comparing results of multiple pairs in identical situations. This is achievable when there are eight or more players, sitting at two or more tables, and the deals from each table are preserved and passed to the next table, thereby "duplicating" them for the other table(s) of players. At the end of a session, the scores for each deal are compared, and the most points are awarded to the players doing the best with each particular deal. This measures relative skill (but still with an element of luck) because each pair or team is being judged only on the ability to bid with, and play, the same cards as other players.

Duplicate bridge is played in clubs and tournaments, which can gather as many as several hundred players. Duplicate bridge is a mind sport, and its popularity gradually became comparable to that of chess, with which it is often compared for its complexity and the mental skills required for high-level competition. Bridge and chess are the only "mind sports" recognized by the International Olympic Committee, although they were not found eligible for the main Olympic program. In October 2017 the British High Court ruled against the English Bridge Union, finding that Bridge is not a sport under a definition of sport as involving physical activity, but did not rule on the "broad, somewhat philosophical question" as to whether or not bridge is a sport.

The basic premise of duplicate bridge had previously been used for whist matches as early as 1857. Initially, bridge was not thought to be suitable for duplicate competition; it was not until the 1920s that (auction) bridge tournaments became popular.

In 1925 when contract bridge first evolved, bridge tournaments were becoming popular, but the rules were somewhat in flux, and several different organizing bodies were involved in tournament sponsorship: the American Bridge League (formerly the "American Auction Bridge League", which changed its name in 1929), the American Whist League, and the United States Bridge Association. In 1935, the first officially recognized world championship was held. By 1937, however, the American Contract Bridge League (ACBL) had come to power (a union of the ABL and the USBA), and it remains the sanctioning body for bridge tournaments in North America. In 1958, the World Bridge Federation (WBF) was founded to promote bridge worldwide, coordinate periodic revision to the Laws (each ten years, next in 2027) and conduct world championships.

In tournaments, "bidding boxes" are frequently used, as noted above. These avoid the possibility of players at other tables hearing any spoken bids. The bidding cards are laid out in sequence as the auction progresses. Although it is not a formal rule, many clubs adopt a protocol that the bidding cards stay revealed until the first playing card is tabled, after which point the bidding cards are put away.

In top national and international events, "bidding screens" are used. These are placed diagonally across the table, preventing partners from seeing each other during the game; often the screen is removed after the auction is complete.

Much of the complexity in bridge arises from the difficulty of arriving at a good final contract in the auction (or deciding to let the opponents declare the contract). This is a difficult problem: the two players in a partnership must try to communicate enough information about their hands to arrive at a makeable contract, but the information they can exchange is restricted – information may be passed only by the calls made and later by the cards played, not by other means; in addition, the agreed-upon meaning of each call and play must be available to the opponents.

Since a partnership that has freedom to bid gradually at leisure can exchange more information, and since a partnership that can interfere with the opponents' bidding (as by raising the bidding level rapidly) can cause difficulties for their opponents, bidding systems are both informational and strategic. It is this mixture of information exchange and evaluation, deduction, and tactics that is at the heart of bidding in bridge.

A number of basic rules of thumb in bridge bidding and play are summarized as bridge maxims.

A "bidding system" is a set of partnership agreements on the meanings of bids. A partnership's bidding system is usually made up of a core system, modified and complemented by specific conventions (optional customizations incorporated into the main system for handling specific bidding situations) which are pre-chosen between the partners prior to play. The line between a well-known convention and a part of a system is not always clear-cut: some bidding systems include specified conventions by default. Bidding systems can be divided into mainly natural systems such as Acol and Standard American, and mainly artificial systems such as the Precision Club and Polish Club.

Calls are usually considered to be either "natural" or "conventional" (artificial). A natural call carries a meaning that reflects the call; a natural bid intuitively showing hand or suit strength based on the level or suit of the bid, and a natural double expressing that the player believes that the opposing partnership will not make their contract. By contrast, a conventional (artificial) call offers and/or asks for information by means of pre-agreed coded interpretations, in which some calls convey very specific information or requests that are not part of the natural meaning of the call. Thus in response to 4NT, a 'natural' bid of 5 would state a preference towards a diamond suit or a desire to play the contract in 5 diamonds, whereas if the partners have agreed to use the common Blackwood convention, a bid of 5 in the same situation would say nothing about the diamond suit, but tell the partner that the hand in question contains exactly one ace.

Conventions are valuable in bridge because of the need to pass information beyond a simple like or dislike of a particular suit, and because the limited bidding space can be used more efficiently by adopting a conventional (artificial) meaning for a given call where a natural meaning would have less utility, because the information it would convey is not valuable or because the desire to convey that information would arise only rarely. The conventional meaning conveys more useful (or more frequently useful) information. There are a very large number of conventions from which players can choose; many books have been written detailing bidding conventions. Well-known conventions include Stayman (to ask the opening 1NT bidder to show any four-card major suit), Jacoby transfers (a request by (usually) the weak hand for the partner to bid a particular suit first, and therefore to become the declarer), and the Blackwood convention (to ask for information on the number of aces and kings held, used in slam bidding situations).

The term "preempt" refers to a high-level tactical bid by a weak hand, relying upon a very long suit rather than high cards for tricks. Preemptive bids serve a double purpose – they allow players to indicate they are bidding on the basis of a long suit in an otherwise weak hand, which is important information to share, and they also consume substantial bidding space which prevents a possibly strong opposing pair from exchanging information on their cards. Several systems include the use of opening bids or other early bids with weak hands including long (usually six to eight card) suits at the 2, 3 or even 4 or 5 levels as preempts.

As a rule, a natural suit bid indicates a holding of at least four (or more, depending on the situation and the system) cards in that suit as an opening bid, or a lesser number when supporting partner; a natural NT bid indicates a balanced hand.

Most systems use a count of high card points as the basic evaluation of the strength of a hand, refining this by reference to shape and distribution if appropriate. In the most commonly used point count system, aces are counted as 4 points, kings as 3, queens as 2, and jacks as 1 point; therefore, the deck contains 40 points. In addition, the "distribution" of the cards in a hand into suits may also contribute to the strength of a hand and be counted as distribution points. A better than average hand, containing 12 or 13 points, is usually considered sufficient to "open" the bidding, i.e., to make the first bid in the auction. A combination of two such hands (i.e., 25 or 26 points shared between partners) is often sufficient for a partnership to bid, and generally to make, game in a major suit or notrump (more are usually needed for a minor suit game, as the level is higher).

In natural systems, a 1NT opening bid usually reflects a hand that has a relatively balanced shape (usually between two and four (or less often five) cards in each suit) and a sharply limited number of high card points, usually somewhere between 12 and 18 – the most common ranges use a span of exactly three points (for example, 12–14, 15–17 or 16–18), but some systems use a four-point range, usually 15–18.

Opening bids of three or higher are preemptive bids, i.e., bids made with weak hands that especially favor a particular suit, opened at a high level in order to define the hand's value quickly and to frustrate the opposition. For example, a hand of would be a candidate for an opening bid of 3, designed to make it difficult for the opposing team to bid and find their optimum contract even if they have the bulk of the points, as it is nearly valueless unless spades are trumps, it contains good enough spades that the penalty for being set should not be higher than the value of an opponent game, and the high card weakness makes it more likely that the opponents have enough strength to make game themselves.

Openings at the 2 level are either unusually strong (2NT, natural, and 2, artificial) or preemptive, depending on the system. Unusually strong bids communicate an especially high number of points (normally 20 or more) or a high trick-taking potential (normally 8 or more). Also 2 as the strongest (by HCP and by DP+HCP) has become more common, perhaps especially at websites that offer duplicate bridge. Here the 2 opening is used for either hands with a good 6-card suit or longer (max one losing card) and a total of 18 HCP up to 23 total points – or "NT", like 2NT but with 22–23 HCP. Whilst the 2 opening bid takes care of all hands with 24 points (HCP or with distribution points included) with the only exception of "Gambling 3NT".

Opening bids at the one level are made with hands containing 12–13 points or more and which are not suitable for one of the preceding bids. Using Standard American with 5-card majors, opening hearts or spades usually promises a 5-card suit. Partnerships who agree to play 5-card majors open a minor suit with 4-card majors and then bid their major suit at the next opportunity. This means that an opening bid of 1 or 1 will sometimes be made with only 3 cards in that suit.

Doubles are sometimes given conventional meanings in otherwise mostly natural systems. A natural, or "penalty" double, is one used to try to gain extra points when the defenders are confident of setting (defeating) the contract. The most common example of a conventional double is the takeout double of a low-level suit bid, implying support for the unbid suits or the unbid major suits and asking partner to choose one of them.

Bidding systems depart from these basic ideas in varying degrees. Standard American, for instance, is a collection of conventions designed to bolster the accuracy and power of these basic ideas, while Precision Club is a system that uses the 1 opening bid for all or almost all strong hands (but sets the threshold for "strong" rather lower than most other systems – usually 16 high card points) and may include other artificial calls to handle other situations (but it may contain natural calls as well). Many experts today use a system called 2/1 game forcing (enunciated as two over one game forcing), which amongst other features adds some complexity to the treatment of the one notrump response as used in Standard American. In the UK, Acol is the most common system; its main features are a weak one notrump opening with 12–14 high card points and several variations for 2-level openings.

There are also a variety of advanced techniques used for hand evaluation. The most basic is the Milton Work point count, (the 4-3-2-1 system detailed above) but this is sometimes modified in various ways, or either augmented or replaced by other approaches such as losing trick count, honor point count, law of total tricks, or Zar Points.

Common conventions and variations within natural systems include:

Within play, it is also commonly agreed what systems of opening leads, signals and discards will be played:

Every call (including "pass", also sometimes called "no bid") serves two purposes. It confirms or passes some information to a partner, and also denies by implication any other kind of hand which would have tended to support an alternative call. For example, a bid of 2NT immediately after partner's 1NT not only shows a balanced hand of a certain point range, but also would almost always deny possession of a five-card major suit (otherwise the player would have bid it) or even a four card major suit (in that case, the player would probably have used the Stayman convention).

Likewise, in some partnerships the bid of 2 in the sequence 1NT–2–2–2 between partners (opponents passing throughout) explicitly shows five hearts but also confirms four cards in spades: the bidder must hold at least five hearts to make it worth looking for a heart fit after 2 denied a four card major, and with at least five hearts, a Stayman bid must have been justified by having exactly four spades, the other major (since Stayman (as used by this partnership) is not useful with anything except a four card major suit). Thus an astute partner can read much more than the surface meaning into the bidding. Alternatively, many partnerships play this same bidding sequence as "Crawling Stayman" by which the responder shows a weak hand (less than eight high card points) with shortness in diamonds but at least four hearts and four spades; the opening bidder may correct to spades if that appears to be the better contract.

The situations detailed here are extremely simple examples; many instances of advanced bidding involve specific agreements related to very specific situations and subtle inferences regarding entire sequences of calls.

Terence Reese, a prolific author of bridge books, points out that there are only four ways of taking a trick by force, two of which are very easy:

Nearly all trick-taking techniques in bridge can be reduced to one of these four methods. The optimum play of the cards can require much thought and experience and is the subject of whole books on bridge.

The cards are dealt as shown in the bridge hand diagram; North is the dealer and starts the auction which proceeds as shown in the bidding table.
As neither North nor East have sufficient strength to "open" the bidding, they each pass, denying such strength. South, next in turn, opens with the bid of 1, which denotes a reasonable heart suit (at least 4 or 5 cards long, depending on the bidding system) and at least 12 high card points. On this hand, South has 14 high card points. West "overcalls" with 1, since he has a long spade suit of reasonable quality and 10 high card points (an overcall can be made on a hand that is not quite strong enough for an opening bid). North "supports" partner's suit with 2, showing heart support and about points. East supports spades with 2. South inserts a "game try" of 3, "inviting" the partner to bid the "game" of 4 with good club support and overall values. North complies, as North is at the higher end of the range for his 2 bid, and has a fourth trump (the 2 bid promised only three), and the "doubleton" queen of clubs to fit with partner's strength there. (North could instead have bid 3, indicating not enough strength for game, asking South to pass and so play 3.)

In the auction, North-South are trying to investigate whether their cards are sufficient to make a game (nine tricks at notrump, ten tricks in hearts or spades, 11 tricks in clubs or diamonds), which yields bonus points if bid and made. East-West are "competing" in spades, hoping to play a contract in spades at a low level. 4 is the final contract, 10 tricks being required for to make with hearts as trump.

South is the "declarer", having been first to bid hearts, and the player to South's left, West, has to choose the first card in the play, known as the "opening lead". West chooses the spade king because spades is the suit the partnership has shown strength in, and because they have agreed that when they hold two "touching honors" (or "adjacent honors") they will play the higher one first. West plays the card face down, to give their partner and the declarer (but not dummy) a chance to ask any last questions about the bidding or to object if they believe West is not the correct hand to lead. After that, North's cards are laid on the table and North becomes "dummy", as both the North and South hands will be controlled by the declarer. West turns the lead card face up, and the declarer studies the two hands to make a plan for the play. On this hand, the trump ace, a spade, and a diamond trick must be lost, so declarer must not lose a trick in clubs.

If the K is held by West, South will find it very hard to prevent it from making a trick (unless West leads a club). However, there is an almost-equal chance that it is held by East, in which case it can be 'trapped' against the ace, and will be beaten, using a tactic known as a "finesse".

After considering the cards, the declarer directs dummy (North) to play a small spade. East plays "low" (small card) and South takes the A, gaining the "lead". (South may also elect to "duck", but for the purpose of this example, let us assume South wins the A at trick 1). South proceeds by "drawing trump", leading the K. West decides there is no benefit to holding back, and so wins the trick with the ace, and then cashes the Q. For fear of conceding a "ruff and discard", West plays the 2 instead of another spade. Declarer plays low from the table, and East scores the Q. Not having anything better to do, East returns the remaining trump, taken in South's hand. The trumps now accounted for, South can now execute the finesse, perhaps trapping the king as planned. South "enters" the dummy (i.e. wins a trick in the dummy's hand) by leading a low diamond, using dummy's A to win the trick, and leads the Q from dummy to the next trick. East "covers" the queen with the king, and South takes the trick with the ace, and proceeds by "cashing" the remaining "master" J. (If East doesn't play the king, then South will play a low club from South's hand and the queen will win anyway, this being the essence of the finesse). The game is now safe: South "ruffs" a small club with a dummy's trump, then ruffs a diamond in hand for an "entry" back, and ruffs the last club in dummy (sometimes described as a "crossruff"). Finally, South "claims" the remaining tricks by showing his or her hand, as it now contains only high trumps and there's no need to play the hand out to prove they are all winners.

(The trick-by-trick notation used above can be also expressed in tabular form, but a textual explanation is usually preferred in practice, for reader's convenience. Plays of small cards or "discards" are often omitted from such a description, unless they were important for the outcome).

North-South score the required 10 tricks, and their opponents take the remaining three. The contract is fulfilled, and North enters the pair numbers, the contract, and the score of +420 for the winning side (North is in charge of bookkeeping in duplicate tournaments) on the traveling sheet. North asks East to check the score entered on the traveller. All players return their own cards to the board, and the next deal is played.

On the prior hand, it is quite possible that the K is held by West. For example, by swapping the K and A between the defending hands. Then the 4 contract would fail by one trick (unless West had led a club early in the play). However the failure of the contract would not mean that 4 is a bad contract on this hand. The contract depends on the club finesse working, or a mis-defense. The bonus points awarded for making a game contract far outweigh the penalty for going one off, so it is best strategy in the long run to bid game contracts such as this one.

Similarly, there is a minuscule chance that the K is in the west hand, but the west hand has no other clubs. In that case, declarer can succeed by simply cashing the A, felling the K and setting up the Q as a winner. However the chance of this is far lower than the simple chance of approximately 50% that East started with the K. Therefore, the superior "percentage" play is to take the club finesse, as described above.

After many years of little progress, computer bridge made great progress at the end of the 20th century. In 1996, the ACBL initiated official World Championships Computer Bridge, to be held annually along with a major bridge event. The first Computer Bridge Championship took place in 1997 at the North American Bridge Championships in Albuquerque, New Mexico.

Strong bridge playing programs such as Jack (World Champion in 2001, 2002, 2003, 2004, 2006, 2009, 2010, 2012, 2013 and 2015), Wbridge5 (World Champion in 2005, 2007, 2008, 2016, 2017 and 2018), RoboBridge and many-time finalist Bridge Baron, would probably rank among the top few thousand human pairs worldwide. A series of articles published in 2005 and 2006 in the Dutch bridge magazine IMP describes matches between Jack and seven top Dutch pairs. A total of 196 boards were played. Overall, the program Jack lost, but by a small margin (359 versus 385 IMPs).

There are several free and subscription-based services available for playing bridge on the internet. For example:

Some national contract bridge organizations now offer online bridge play to their members, including the English Bridge Union, the Dutch Bridge Federation and the Australian Bridge Federation. MSN and Yahoo! Games have several online rubber bridge rooms. In 2001, the WBF issued a special edition of the lawbook adapted for internet and other electronic forms of the game.




</doc>
<doc id="3996" url="https://en.wikipedia.org/wiki?curid=3996" title="Boat">
Boat

A boat is a watercraft of a large range of types and sizes, but generally smaller than a ship, which is distinguished by its larger size, shape, cargo or passenger capacity, or its ability to carry boats.

Small boats are typically found on inland waterways such as rivers and lakes, or in protected coastal areas. However, some boats, such as the whaleboat, were intended for use in an offshore environment. In modern naval terms, a boat is a vessel small enough to be carried aboard a ship. Anomalous definitions exist, as lake freighters long on the Great Lakes are called "boats".

Boats vary in proportion and construction methods with their intended purpose, available materials, or local traditions. Canoes have been used since prehistoric times and remain in use throughout the world for transportation, fishing, and sport. Fishing boats vary widely in style partly to match local conditions. Pleasure craft used in recreational boating include ski boats, pontoon boats, and sailboats. House boats may be used for vacationing or long-term residence. Lighters are used to convey cargo to and from large ships unable to get close to shore. Lifeboats have rescue and safety functions.

Boats can be propelled by manpower (e.g. rowboats and paddle boats), wind (e.g. sailboats), and motor (including gasoline, diesel, and electric).

Boats have served as transportation since the earliest times. Circumstantial evidence, such as the early settlement of Australia over 40,000 years ago, findings in Crete dated 130,000 years ago, and in Flores dated to 900,000 years ago, suggest that boats have been used since prehistoric times. The earliest boats are thought to have been dugouts, and the oldest boats found by archaeological excavation date from around 7,000–10,000 years ago. The oldest recovered boat in the world, the Pesse canoe, found in the Netherlands, is a dugout made from the hollowed tree trunk of a "Pinus sylvestris" that was constructed somewhere between 8200 and 7600 BC. This canoe is exhibited in the Drents Museum in Assen, Netherlands. Other very old dugout boats have also been recovered.
Rafts have operated for at least 8,000 years.
A 7,000-year-old seagoing reed boat has been found in Kuwait.
Boats were used between 4000 and 3000 BC in Sumer, ancient Egypt and in the Indian Ocean.

Boats played an important role in the commerce between the Indus Valley Civilization and Mesopotamia. Evidence of varying models of boats has also been discovered at various Indus Valley archaeological sites.
Uru craft originate in Beypore, a village in south Calicut, Kerala, in southwestern India. This type of mammoth wooden ship was constructed solely of teak, with a transport capacity of 400 tonnes. The ancient Arabs and Greeks used such boats as trading vessels.

The historians Herodotus, Pliny the Elder and Strabo record the use of boats for commerce, travel, and military purposes.

Boats can be categorized into three main types:

The hull is the main, and in some cases only, structural component of a boat. It provides both capacity and buoyancy. The keel is a boat's "backbone", a lengthwise structural member to which the perpendicular frames are fixed. On most boats a deck covers the hull, in part or whole. While a ship often has several decks, a boat is unlikely to have more than one. Above the deck are often lifelines connected to stanchions, bulwarks perhaps topped by gunnels, or some combination of the two. A cabin may protrude above the deck forward, aft, along the centerline, or covering much of the length of the boat. Vertical structures dividing the internal spaces are known as bulkheads.

The forward end of a boat is called the bow, the aft end the stern. Facing forward the right side is referred to as starboard and the left side as port.

Until the mid-19th century most boats were made of natural materials, primarily wood, although reed, bark and animal skins were also used. Early boats include the bound-reed style of boat seen in Ancient Egypt, the birch bark canoe, the animal hide-covered kayak and coracle and the dugout canoe made from a single log.

By the mid-19th century, many boats had been built with iron or steel frames but still planked in wood. In 1855 ferro-cement boat construction was patented by the French, who coined the name "ferciment". This is a system by which a steel or iron wire framework is built in the shape of a boat's hull and covered over with cement. Reinforced with bulkheads and other internal structure it is strong but heavy, easily repaired, and, if sealed properly, will not leak or corrode. These materials and methods were copied all over the world and have faded in and out of popularity to the present time.

As the forests of Britain and Europe continued to be over-harvested to supply the keels of larger wooden boats, and the Bessemer process (patented in 1855) cheapened the cost of steel, steel ships and boats began to be more common. By the 1930s boats built entirely of steel from frames to plating were seen replacing wooden boats in many industrial uses and fishing fleets. Private recreational boats of steel remain uncommon. In 1895 WH Mullins produced steel boats of galvanized iron and by 1930 became the world's largest producer of pleasure boats.

Mullins also offered boats in aluminum from 1895 through 1899 and once again in the 1920s, but it wasn't until the mid-20th century that aluminium gained widespread popularity. Though much more expensive than steel, aluminum alloys exist that do not corrode in salt water, allowing a similar load carrying capacity to steel at much less weight.

Around the mid-1960s, boats made of fiberglass (aka "glassfibre") became popular, especially for recreational boats. Fiberglass is also known as "GRP" (glass-reinforced plastic) in the UK, and "FRP" (for fiber-reinforced plastic) in the US. Fiberglass boats are strong, and do not rust, corrode, or rot. Instead, they are susceptible to structural degradation from sunlight and extremes in temperature over their lifespan. Fiberglass structures can be made stiffer with sandwich panels, where the fiberglass encloses a lightweight core such as balsa or foam.

Cold moulding is a modern construction method, using wood as the structural component. In cold moulding very thin strips of wood are layered over a form. Each layer is coated with resin, followed by another directionally alternating layer laid on top. Subsequent layers may be stapled or otherwise mechanically fastened to the previous, or weighted or vacuum bagged to provide compression and stabilization until the resin sets.

The most common means of boat propulsion are as follows:

A boat displaces its weight in water, regardless whether it is made of wood, steel, fiberglass, or even concrete. If weight is added to the boat, the volume of the hull drawn below the waterline will increase to keep the balance above and below the surface equal. Boats have a natural or designed level of buoyancy. Exceeding it will cause the boat first to ride lower in the water, second to take on water more readily than when properly loaded, and ultimately, if overloaded by any combination of structure, cargo, and water, sink.



</doc>
<doc id="3997" url="https://en.wikipedia.org/wiki?curid=3997" title="Blood">
Blood

Blood is a body fluid in humans and other animals that delivers necessary substances such as nutrients and oxygen to the cells and transports metabolic waste products away from those same cells.

In vertebrates, it is composed of blood cells suspended in blood plasma. Plasma, which constitutes 55% of blood fluid, is mostly water (92% by volume), and contains proteins, glucose, mineral ions, hormones, carbon dioxide (plasma being the main medium for excretory product transportation), and blood cells themselves. Albumin is the main protein in plasma, and it functions to regulate the colloidal osmotic pressure of blood. The blood cells are mainly red blood cells (also called RBCs or erythrocytes), white blood cells (also called WBCs or leukocytes) and platelets (also called thrombocytes). The most abundant cells in vertebrate blood are red blood cells. These contain hemoglobin, an iron-containing protein, which facilitates oxygen transport by reversibly binding to this respiratory gas and greatly increasing its solubility in blood. In contrast, carbon dioxide is mostly transported extracellularly as bicarbonate ion transported in plasma.

Vertebrate blood is bright red when its hemoglobin is oxygenated and dark red when it is deoxygenated. Some animals, such as crustaceans and mollusks, use hemocyanin to carry oxygen, instead of hemoglobin. Insects and some mollusks use a fluid called hemolymph instead of blood, the difference being that hemolymph is not contained in a closed circulatory system. In most insects, this "blood" does not contain oxygen-carrying molecules such as hemoglobin because their bodies are small enough for their tracheal system to suffice for supplying oxygen.

Jawed vertebrates have an adaptive immune system, based largely on white blood cells. White blood cells help to resist infections and parasites. Platelets are important in the clotting of blood. Arthropods, using hemolymph, have hemocytes as part of their immune system.

Blood is circulated around the body through blood vessels by the pumping action of the heart. In animals with lungs, arterial blood carries oxygen from inhaled air to the tissues of the body, and venous blood carries carbon dioxide, a waste product of metabolism produced by cells, from the tissues to the lungs to be exhaled.

Medical terms related to blood often begin with hemo- or hemato- (also spelled haemo- and haemato-) from the Greek word ("haima") for "blood". In terms of anatomy and histology, blood is considered a specialized form of connective tissue, given its origin in the bones and the presence of potential molecular fibers in the form of fibrinogen.

Blood performs many important functions within the body, including:

Blood accounts for 7% of the human body weight, with an average density around 1060 kg/m, very close to pure water's density of 1000 kg/m. The average adult has a blood volume of roughly or 1.3 gallons, which is composed of plasma and several kinds of cells. These blood cells (which are also called corpuscles or "formed elements") consist of erythrocytes (red blood cells, RBCs), leukocytes (white blood cells), and thrombocytes (platelets). By volume, the red blood cells constitute about 45% of whole blood, the plasma about 54.3%, and white cells about 0.7%.

Whole blood (plasma and cells) exhibits non-Newtonian fluid dynamics. If all human hemoglobin were free in the plasma rather than being contained in RBCs, the circulatory fluid would be too viscous for the cardiovascular system to function effectively.

One microliter of blood contains:

About 55% of blood is blood plasma, a fluid that is the blood's liquid medium, which by itself is straw-yellow in color. The blood plasma volume totals of 2.7–3.0 liters (2.8–3.2 quarts) in an average human. It is essentially an aqueous solution containing 92% water, 8% blood plasma proteins, and trace amounts of other materials. Plasma circulates dissolved nutrients, such as glucose, amino acids, and fatty acids (dissolved in the blood or bound to plasma proteins), and removes waste products, such as carbon dioxide, urea, and lactic acid.

Other important components include:

The term serum refers to plasma from which the clotting proteins have been removed. Most of the proteins remaining are albumin and immunoglobulins.

Blood pH is regulated to stay within the narrow range of 7.35 to 7.45, making it slightly basic. Blood that has a pH below 7.35 is too acidic, whereas blood pH above 7.45 is too basic. Blood pH, partial pressure of oxygen (pO), partial pressure of carbon dioxide (pCO), and bicarbonate (HCO) are carefully regulated by a number of homeostatic mechanisms, which exert their influence principally through the respiratory system and the urinary system to control the acid-base balance and respiration. An arterial blood gas test measures these. Plasma also circulates hormones transmitting their messages to various tissues. The list of normal reference ranges for various blood electrolytes is extensive.

Human blood is typical of that of mammals, although the precise details concerning cell numbers, size, protein structure, and so on, vary somewhat between species. In non-mammalian vertebrates, however, there are some key differences:

Blood is circulated around the body through blood vessels by the pumping action of the heart. In humans, blood is pumped from the strong left ventricle of the heart through arteries to peripheral tissues and returns to the right atrium of the heart through veins. It then enters the right ventricle and is pumped through the pulmonary artery to the lungs and returns to the left atrium through the pulmonary veins. Blood then enters the left ventricle to be circulated again. Arterial blood carries oxygen from inhaled air to all of the cells of the body, and venous blood carries carbon dioxide, a waste product of metabolism by cells, to the lungs to be exhaled. However, one exception includes pulmonary arteries, which contain the most deoxygenated blood in the body, while the pulmonary veins contain oxygenated blood.

Additional return flow may be generated by the movement of skeletal muscles, which can compress veins and push blood through the valves in veins toward the right atrium.

The blood circulation was famously described by William Harvey in 1628.

In vertebrates, the various cells of blood are made in the bone marrow in a process called hematopoiesis, which includes erythropoiesis, the production of red blood cells; and myelopoiesis, the production of white blood cells and platelets. During childhood, almost every human bone produces red blood cells; as adults, red blood cell production is limited to the larger bones: the bodies of the vertebrae, the breastbone (sternum), the ribcage, the pelvic bones, and the bones of the upper arms and legs. In addition, during childhood, the thymus gland, found in the mediastinum, is an important source of T lymphocytes.
The proteinaceous component of blood (including clotting proteins) is produced predominantly by the liver, while hormones are produced by the endocrine glands and the watery fraction is regulated by the hypothalamus and maintained by the kidney.

Healthy erythrocytes have a plasma life of about 120 days before they are degraded by the spleen, and the Kupffer cells in the liver. The liver also clears some proteins, lipids, and amino acids. The kidney actively secretes waste products into the urine.

About 98.5% of the oxygen in a sample of arterial blood in a healthy human breathing air at sea-level pressure is chemically combined with the hemoglobin. About 1.5% is physically dissolved in the other blood liquids and not connected to hemoglobin. The hemoglobin molecule is the primary transporter of oxygen in mammals and many other species (for exceptions, see below). Hemoglobin has an oxygen binding capacity between 1.36 and 1.40 ml O per gram hemoglobin, which increases the total blood oxygen capacity seventyfold, compared to if oxygen solely were carried by its solubility of 0.03 ml O per liter blood per mm Hg partial pressure of oxygen (about 100 mm Hg in arteries).

With the exception of pulmonary and umbilical arteries and their corresponding veins, arteries carry oxygenated blood away from the heart and deliver it to the body via arterioles and capillaries, where the oxygen is consumed; afterwards, venules and veins carry deoxygenated blood back to the heart.

Under normal conditions in adult humans at rest, hemoglobin in blood leaving the lungs is about 98–99% saturated with oxygen, achieving an oxygen delivery between 950 and 1150 ml/min to the body. In a healthy adult at rest, oxygen consumption is approximately 200–250 ml/min, and deoxygenated blood returning to the lungs is still roughly 75% (70 to 78%) saturated. Increased oxygen consumption during sustained exercise reduces the oxygen saturation of venous blood, which can reach less than 15% in a trained athlete; although breathing rate and blood flow increase to compensate, oxygen saturation in arterial blood can drop to 95% or less under these conditions. Oxygen saturation this low is considered dangerous in an individual at rest (for instance, during surgery under anesthesia). Sustained hypoxia (oxygenation less than 90%), is dangerous to health, and severe hypoxia (saturations less than 30%) may be rapidly fatal.

A fetus, receiving oxygen via the placenta, is exposed to much lower oxygen pressures (about 21% of the level found in an adult's lungs), so fetuses produce another form of hemoglobin with a much higher affinity for oxygen (hemoglobin F) to function under these conditions.

CO is carried in blood in three different ways. (The exact percentages vary depending whether it is arterial or venous blood). Most of it (about 70%) is converted to bicarbonate ions by the enzyme carbonic anhydrase in the red blood cells by the reaction CO + HO → HCO → H + ; about 7% is dissolved in the plasma; and about 23% is bound to hemoglobin as carbamino compounds.

Hemoglobin, the main oxygen-carrying molecule in red blood cells, carries both oxygen and carbon dioxide. However, the CO bound to hemoglobin does not bind to the same site as oxygen. Instead, it combines with the N-terminal groups on the four globin chains. However, because of allosteric effects on the hemoglobin molecule, the binding of CO decreases the amount of oxygen that is bound for a given partial pressure of oxygen. The decreased binding to carbon dioxide in the blood due to increased oxygen levels is known as the Haldane effect, and is important in the transport of carbon dioxide from the tissues to the lungs. A rise in the partial pressure of CO or a lower pH will cause offloading of oxygen from hemoglobin, which is known as the Bohr effect.

Some oxyhemoglobin loses oxygen and becomes deoxyhemoglobin. Deoxyhemoglobin binds most of the hydrogen ions as it has a much greater affinity for more hydrogen than does oxyhemoglobin.

In mammals, blood is in equilibrium with lymph, which is continuously formed in tissues from blood by capillary ultrafiltration. Lymph is collected by a system of small lymphatic vessels and directed to the thoracic duct, which drains into the left subclavian vein, where lymph rejoins the systemic blood circulation.

Blood circulation transports heat throughout the body, and adjustments to this flow are an important part of thermoregulation. Increasing blood flow to the surface (e.g., during warm weather or strenuous exercise) causes warmer skin, resulting in faster heat loss. In contrast, when the external temperature is low, blood flow to the extremities and surface of the skin is reduced and to prevent heat loss and is circulated to the important organs of the body, preferentially.

Rate of blood flow varies greatly between different organs. Liver has the most abundant blood supply with an approximate flow of 1350 ml/min. Kidney and brain are the second and the third most supplied organs, with 1100 ml/min and ~700 ml/min, respectively.

Relative rates of blood flow per 100 g of tissue are different, with kidney, adrenal gland and thyroid being the first, second and third most supplied tissues, respectively.

The restriction of blood flow can also be used in specialized tissues to cause engorgement, resulting in an erection of that tissue; examples are the erectile tissue in the penis and clitoris.

Another example of a hydraulic function is the jumping spider, in which blood forced into the legs under pressure causes them to straighten for a powerful jump, without the need for bulky muscular legs.

In insects, the blood (more properly called hemolymph) is not involved in the transport of oxygen. (Openings called tracheae allow oxygen from the air to diffuse directly to the tissues.) Insect blood moves nutrients to the tissues and removes waste products in an open system.

Other invertebrates use respiratory proteins to increase the oxygen-carrying capacity. Hemoglobin is the most common respiratory protein found in nature. Hemocyanin (blue) contains copper and is found in crustaceans and mollusks. It is thought that tunicates (sea squirts) might use vanabins (proteins containing vanadium) for respiratory pigment (bright-green, blue, or orange).

In many invertebrates, these oxygen-carrying proteins are freely soluble in the blood; in vertebrates they are contained in specialized red blood cells, allowing for a higher concentration of respiratory pigments without increasing viscosity or damaging blood filtering organs like the kidneys.

Giant tube worms have unusual hemoglobins that allow them to live in extraordinary environments. These hemoglobins also carry sulfides normally fatal in other animals.

The coloring matter of blood (hemochrome) is largely due to the protein in the blood responsible for oxygen transport. Different groups of organisms use different proteins.

Hemoglobin is the principal determinant of the color of blood in vertebrates. Each molecule has four heme groups, and their interaction with various molecules alters the exact color. In vertebrates and other hemoglobin-using creatures, arterial blood and capillary blood are bright red, as oxygen imparts a strong red color to the heme group. Deoxygenated blood is a darker shade of red; this is present in veins, and can be seen during blood donation and when venous blood samples are taken. This is because the spectrum of light absorbed by hemoglobin differs between the oxygenated and deoxygenated states.

Blood in carbon monoxide poisoning is bright red, because carbon monoxide causes the formation of carboxyhemoglobin. In cyanide poisoning, the body cannot utilize oxygen, so the venous blood remains oxygenated, increasing the redness. There are some conditions affecting the heme groups present in hemoglobin that can make the skin appear blue – a symptom called cyanosis. If the heme is oxidized, methemoglobin, which is more brownish and cannot transport oxygen, is formed. In the rare condition sulfhemoglobinemia, arterial hemoglobin is partially oxygenated, and appears dark red with a bluish hue.

Veins close to the surface of the skin appear blue for a variety of reasons. However, the factors that contribute to this alteration of color perception are related to the light-scattering properties of the skin and the processing of visual input by the visual cortex, rather than the actual color of the venous blood.

Skinks in the genus "Prasinohaema" have green blood due to a buildup of the waste product biliverdin.

The blood of most mollusks – including cephalopods and gastropods – as well as some arthropods, such as horseshoe crabs, is blue, as it contains the copper-containing protein hemocyanin at concentrations of about 50 grams per liter. Hemocyanin is colorless when deoxygenated and dark blue when oxygenated. The blood in the circulation of these creatures, which generally live in cold environments with low oxygen tensions, is grey-white to pale yellow, and it turns dark blue when exposed to the oxygen in the air, as seen when they bleed. This is due to change in color of hemocyanin when it is oxidized. Hemocyanin carries oxygen in extracellular fluid, which is in contrast to the intracellular oxygen transport in mammals by hemoglobin in RBCs.

The blood of most annelid worms and some marine polychaetes use chlorocruorin to transport oxygen. It is green in color in dilute solutions.

Hemerythrin is used for oxygen transport in the marine invertebrates sipunculids, priapulids, brachiopods, and the annelid worm, magelona. Hemerythrin is violet-pink when oxygenated.

The blood of some species of ascidians and tunicates, also known as sea squirts, contains proteins called vanadins. These proteins are based on vanadium, and give the creatures a concentration of vanadium in their bodies 100 times higher than the surrounding sea water. Unlike hemocyanin and hemoglobin, hemovanadin is not an oxygen carrier. When exposed to oxygen, however, vanadins turn a mustard yellow.



Substances other than oxygen can bind to hemoglobin; in some cases this can cause irreversible damage to the body. Carbon monoxide, for example, is extremely dangerous when carried to the blood via the lungs by inhalation, because carbon monoxide irreversibly binds to hemoglobin to form carboxyhemoglobin, so that less hemoglobin is free to bind oxygen, and fewer oxygen molecules can be transported throughout the blood. This can cause suffocation insidiously. A fire burning in an enclosed room with poor ventilation presents a very dangerous hazard, since it can create a build-up of carbon monoxide in the air. Some carbon monoxide binds to hemoglobin when smoking tobacco.

Blood for transfusion is obtained from human donors by blood donation and stored in a blood bank. There are many different blood types in humans, the ABO blood group system, and the Rhesus blood group system being the most important. Transfusion of blood of an incompatible blood group may cause severe, often fatal, complications, so crossmatching is done to ensure that a compatible blood product is transfused.

Other blood products administered intravenously are platelets, blood plasma, cryoprecipitate, and specific coagulation factor concentrates.

Many forms of medication (from antibiotics to chemotherapy) are administered intravenously, as they are not readily or adequately absorbed by the digestive tract.

After severe acute blood loss, liquid preparations, generically known as plasma expanders, can be given intravenously, either solutions of salts (NaCl, KCl, CaCl etc.) at physiological concentrations, or colloidal solutions, such as dextrans, human serum albumin, or fresh frozen plasma. In these emergency situations, a plasma expander is a more effective life-saving procedure than a blood transfusion, because the metabolism of transfused red blood cells does not restart immediately after a transfusion.

In modern evidence-based medicine, bloodletting is used in management of a few rare diseases, including hemochromatosis and polycythemia. However, bloodletting and leeching were common unvalidated interventions used until the 19th century, as many diseases were incorrectly thought to be due to an excess of blood, according to Hippocratic medicine.

According to the "Oxford English Dictionary", the word "blood" dates to the oldest English, circa 1000 CE. The word is derived from Middle English, which is derived from the Old English word "blōd", which is akin to the Old High German word "bluot", meaning blood. The modern German word is "(das) Blut."

 (a Swedish physician who devised the erythrocyte sedimentation rate) suggested that the Ancient Greek system of humorism, wherein the body was thought to contain four distinct bodily fluids (associated with different temperaments), were based upon the observation of blood clotting in a transparent container. When blood is drawn in a glass container and left undisturbed for about an hour, four different layers can be seen. A dark clot forms at the bottom (the "black bile"). Above the clot is a layer of red blood cells (the "blood"). Above this is a whitish layer of white blood cells (the "phlegm"). The top layer is clear yellow serum (the "yellow bile").

The ABO blood group system was discovered in the year 1900 by Karl Landsteiner. Jan Janský is credited with the first classification of blood into the four types (A, B, AB, and O) in 1907, which remains in use today. In 1907 the first blood transfusion was performed that used the ABO system to predict compatibility. The first non-direct transfusion was performed on March 27, 1914. The Rhesus factor was discovered in 1937.

Due to its importance to life, blood is associated with a large number of beliefs. One of the most basic is the use of blood as a symbol for family relationships through birth/parentage; to be "related by blood" is to be related by ancestry or descendence, rather than marriage. This bears closely to bloodlines, and sayings such as "blood is thicker than water" and "bad blood", as well as "Blood brother".

Blood is given particular emphasis in the Jewish and Christian religions, because Leviticus 17:11 says "the life of a creature is in the blood." This phrase is part of the Levitical law forbidding the drinking of blood or eating meat with the blood still intact instead of being poured off.

Mythic references to blood can sometimes be connected to the life-giving nature of blood, seen in such events as childbirth, as contrasted with the blood of injury or death.

In many indigenous Australian Aboriginal peoples' traditions, ochre (particularly red) and blood, both high in iron content and considered Maban, are applied to the bodies of dancers for ritual. As Lawlor states:
In many Aboriginal rituals and ceremonies, red ochre is rubbed all over the naked bodies of the dancers. In secret, sacred male ceremonies, blood extracted from the veins of the participant's arms is exchanged and rubbed on their bodies. Red ochre is used in similar ways in less-secret ceremonies. Blood is also used to fasten the feathers of birds onto people's bodies. Bird feathers contain a protein that is highly magnetically sensitive. Lawlor comments that blood employed in this fashion is held by these peoples to attune the dancers to the invisible energetic realm of the Dreamtime. Lawlor then connects these invisible energetic realms and magnetic fields, because iron is magnetic.

Among the Germanic tribes, blood was used during their sacrifices; the "Blóts". The blood was considered to have the power of its originator, and, after the butchering, the blood was sprinkled on the walls, on the statues of the gods, and on the participants themselves. This act of sprinkling blood was called "blóedsian" in Old English, and the terminology was borrowed by the Roman Catholic Church becoming "to bless" and "blessing". The Hittite word for blood, "ishar" was a cognate to words for "oath" and "bond", see Ishara.
The Ancient Greeks believed that the blood of the gods, "ichor", was a substance that was poisonous to mortals.

As a relic of Germanic Law, the cruentation, an ordeal where the corpse of the victim was supposed to start bleeding in the presence of the murderer, was used until the early 17th century.

In Genesis 9:4, God prohibited Noah and his sons from eating blood (see Noahide Law). This command continued to be observed by the Eastern Orthodox.

It is also found in the Bible that when the Angel of Death came around to the Hebrew house that the first-born child would not die if the angel saw lamb's blood wiped across the doorway.

At the Council of Jerusalem, the apostles prohibited certain Christians from consuming blood – this is documented in Acts 15:20 and 29. This chapter specifies a reason (especially in verses 19–21): It was to avoid offending Jews who had become Christians, because the Mosaic Law Code prohibited the practice.

Christ's blood is the means for the atonement of sins. Also, ″... the blood of Jesus Christ his [God] Son cleanseth us from all sin." (1 John 1:7), “… Unto him [God] that loved us, and washed us from our sins in his own blood." (Revelation 1:5), and "And they overcame him (Satan) by the blood
of the Lamb [Jesus the Christ], and by the word of their testimony ...” (Revelation 12:11).

Some Christian churches, including Roman Catholicism, Eastern Orthodoxy, Oriental Orthodoxy, and the Assyrian Church of the East teach that, when consecrated, the Eucharistic wine actually becomes the blood of Jesus for worshippers to drink. Thus in the consecrated wine, Jesus becomes spiritually and physically present. This teaching is rooted in the Last Supper, as written in the four gospels of the Bible, in which Jesus stated to his disciples that the bread that they ate was his body, and the wine was his blood. ""This cup is the new testament in my blood, which is shed for you." ()".

Most forms of Protestantism, especially those of a Methodist or Presbyterian lineage, teach that the wine is no more than a symbol of the blood of Christ, who is spiritually but not physically present. Lutheran theology teaches that the body and blood is present together "in, with, and under" the bread and wine of the Eucharistic feast.

In Judaism, animal blood may not be consumed even in the smallest quantity (Leviticus 3:17 and elsewhere); this is reflected in Jewish dietary laws (Kashrut). Blood is purged from meat by rinsing and soaking in water (to loosen clots), salting and then rinsing with water again several times. Eggs must also be checked and any blood spots removed before consumption. Although blood from fish is biblically kosher, it is rabbinically forbidden to consume fish blood to avoid the appearance of breaking the Biblical prohibition.

Another ritual involving blood involves the covering of the blood of fowl and game after slaughtering (Leviticus 17:13); the reason given by the Torah is: "Because the life of the animal is [in] its blood" (ibid 17:14). In relation to human beings, Kabbalah expounds on this verse that the animal soul of a person is in the blood, and that physical desires stem from it.

Likewise, the mystical reason for salting temple sacrifices and slaughtered meat is to remove the blood of animal-like passions from the person. By removing the animal's blood, the animal energies and life-force contained in the blood are removed, making the meat fit for human consumption.

Consumption of food containing blood is forbidden by Islamic dietary laws. This is derived from the statement in the Qur'an, sura Al-Ma'ida (5:3): "Forbidden to you (for food) are: dead meat, blood, the flesh of swine, and that on which has been invoked the name of other than Allah."

Blood is considered unclean, hence there are specific methods to obtain physical and ritual status of cleanliness once bleeding has occurred. Specific rules and prohibitions apply to menstruation, postnatal bleeding and irregular vaginal bleeding. When an animal has been slaughtered, the animal's neck is cut in a way to ensure that the spine is not severed, hence the brain may send commands to the heart to pump blood to it for oxygen. In this way, blood is removed from the body, and the meat is generally now safe to cook and eat. In modern times, blood transfusions are generally not considered against the rules.

Based on their interpretation of scriptures such as Acts 15:28, 29 ("Keep abstaining...from blood."), many Jehovah's Witnesses neither consume blood nor accept transfusions of whole blood or its major components: red blood cells, white blood cells, platelets (thrombocytes), and plasma. Members may personally decide whether they will accept medical procedures that involve their own blood or substances that are further fractionated from the four major components.

In south East Asian popular culture, it is often said that if a man's nose produces a small flow of blood, he is experiencing sexual desire. This often appears in Chinese-language and Hong Kong films as well as in Japanese and Korean culture parodied in anime, manga, and drama. Characters, mostly males, will often be shown with a nosebleed if they have just seen someone nude or in little clothing, or if they have had an erotic thought or fantasy; this is based on the idea that a male's blood pressure will spike dramatically when aroused.

Vampires are mythical creatures that drink blood directly for sustenance, usually with a preference for human blood. Cultures all over the world have myths of this kind; for example the 'Nosferatu' legend, a human who achieves damnation and immortality by drinking the blood of others, originates from Eastern European folklore. Ticks, leeches, female mosquitoes, vampire bats, and an assortment of other natural creatures do consume the blood of other animals, but only bats are associated with vampires. This has no relation to vampire bats, which are new world creatures discovered well after the origins of the European myths.

Blood residue can help forensic investigators identify weapons, reconstruct a criminal action, and link suspects to the crime. Through bloodstain pattern analysis, forensic information can also be gained from the spatial distribution of bloodstains.

Blood residue analysis is also a technique used in archeology.

Blood is one of the body fluids that has been used in art. In particular, the performances of Viennese Actionist Hermann Nitsch, Istvan Kantor, Franko B, Lennie Lee, Ron Athey, Yang Zhichao, Lucas Abela and Kira O' Reilly, along with the photography of Andres Serrano, have incorporated blood as a prominent visual element. Marc Quinn has made sculptures using frozen blood, including a cast of his own head made using his own blood.

The term "blood" is used in genealogical circles to refer to one's ancestry, origins, and ethnic background as in the word "bloodline". Other terms where blood is used in a family history sense are "blue-blood", "royal blood", "mixed-blood" and "blood relative".



</doc>
<doc id="3999" url="https://en.wikipedia.org/wiki?curid=3999" title="Benoit Mandelbrot">
Benoit Mandelbrot

Benoit B.  Mandelbrot  (20 November 1924 – 14 October 2010) was a Polish-born, French and American mathematician and polymath with broad interests in the practical sciences, especially regarding what he labeled as "the art of roughness" of physical phenomena and "the uncontrolled element in life". He referred to himself as a "fractalist" and is recognized for his contribution to the field of fractal geometry, which included coining the word "fractal", as well as developing a theory of "roughness and self-similarity" in nature.

In 1936, while he was a child, Mandelbrot's family emigrated to France from Warsaw, Poland. After World War II ended, Mandelbrot studied mathematics, graduating from universities in Paris and the United States and receiving a master's degree in aeronautics from the California Institute of Technology. He spent most of his career in both the United States and France, having dual French and American citizenship. In 1958, he began a 35-year career at IBM, where he became an IBM Fellow, and periodically took leaves of absence to teach at Harvard University. At Harvard, following the publication of his study of U.S. commodity markets in relation to cotton futures, he taught economics and applied sciences.

Because of his access to IBM's computers, Mandelbrot was one of the first to use computer graphics to create and display fractal geometric images, leading to his discovery of the Mandelbrot set in 1980. He showed how visual complexity can be created from simple rules. He said that things typically considered to be "rough", a "mess" or "chaotic", like clouds or shorelines, actually had a "degree of order". His math and geometry-centered research career included contributions to such fields as statistical physics, meteorology, hydrology, geomorphology, anatomy, taxonomy, neurology, linguistics, information technology, computer graphics, economics, geology, medicine, physical cosmology, engineering, chaos theory, econophysics, metallurgy and the social sciences.

Toward the end of his career, he was Sterling Professor of Mathematical Sciences at Yale University, where he was the oldest professor in Yale's history to receive tenure. Mandelbrot also held positions at the Pacific Northwest National Laboratory, Université Lille Nord de France, Institute for Advanced Study and Centre National de la Recherche Scientifique. During his career, he received over 15 honorary doctorates and served on many science journals, along with winning numerous awards. His autobiography, "The Fractalist: Memoir of a Scientific Maverick", was published posthumously in 2012.

Mandelbrot was born in a Jewish family, in Warsaw during the Second Polish Republic. His father made his living trading clothing; his mother was a dental surgeon. During his first two school years, he was tutored privately by an uncle who despised rote learning: "Most of my time was spent playing chess, reading maps and learning how to open my eyes to everything around me." Later, the family’s move to France, the war, and his acquaintance with his father’s brother, the mathematician Szolem Mandelbrojt who had moved to Paris around 1920, further prevented a standard education.

The family emigrated from Poland to France in 1936, when he was 11. "The fact that my parents, as economic and political refugees, joined Szolem in France saved our lives," he writes. Mandelbrot attended the Lycée Rolin in Paris until the start of World War II, when his family moved to Tulle, France. He was helped by Rabbi David Feuerwerker, the Rabbi of Brive-la-Gaillarde, to continue his studies. Much of France was occupied by the Nazis at the time, and Mandelbrot recalls this period:

In 1944, Mandelbrot returned to Paris, studied at the Lycée du Parc in Lyon, and in 1945 to 1947 attended the École Polytechnique, where he studied under Gaston Julia and Paul Lévy. From 1947 to 1949 he studied at California Institute of Technology, where he earned a master's degree in aeronautics. Returning to France, he obtained his PhD degree in Mathematical Sciences at the University of Paris in 1952.

From 1949 to 1958, Mandelbrot was a staff member at the Centre National de la Recherche Scientifique. During this time he spent a year at the Institute for Advanced Study in Princeton, New Jersey, where he was sponsored by John von Neumann. In 1955 he married Aliette Kagan and moved to Geneva, Switzerland (to collaborate with Jean Piaget at the International Centre for Genetic Epistemology) and later to the Université Lille Nord de France. In 1958 the couple moved to the United States where Mandelbrot joined the research staff at the IBM Thomas J. Watson Research Center in Yorktown Heights, New York. He remained at IBM for 35 years, becoming an IBM Fellow, and later Fellow Emeritus.
From 1951 onward, Mandelbrot worked on problems and published papers not only in mathematics but in applied fields such as information theory, economics, and fluid dynamics.

Mandelbrot saw financial markets as an example of "wild randomness", characterized by concentration and long range dependence. He developed several original approaches for modelling financial fluctuations.
In his early work, he found that the price changes in financial markets did not follow a Gaussian distribution, but rather Lévy stable distributions having infinite variance. He found, for example, that cotton prices followed a Lévy stable distribution with parameter "α" equal to 1.7 rather than 2 as in a Gaussian distribution. "Stable" distributions have the property that the sum of many instances of a random variable follows the same distribution but with a larger scale parameter.

As a visiting professor at Harvard University, Mandelbrot began to study fractals called Julia sets that were invariant under certain transformations of the complex plane. Building on previous work by Gaston Julia and Pierre Fatou, Mandelbrot used a computer to plot images of the Julia sets. While investigating the topology of these Julia sets, he studied the Mandelbrot set which was introduced by him in 1979. In 1982, Mandelbrot expanded and updated his ideas in "The Fractal Geometry of Nature". This influential work brought fractals into the mainstream of professional and popular mathematics, as well as silencing critics, who had dismissed fractals as "program artifacts".

In 1975, Mandelbrot coined the term "fractal" to describe these structures and first published his ideas, and later translated, "Fractals: Form, Chance and Dimension". According to computer scientist and physicist Stephen Wolfram, the book was a "breakthrough" for Mandelbrot, who until then would typically "apply fairly straightforward mathematics … to areas that had barely seen the light of serious mathematics before". Wolfram adds that as a result of this new research, he was no longer a "wandering scientist", and later called him "the father of fractals":

Wolfram briefly describes fractals as a form of geometric repetition, "in which smaller and smaller copies of a pattern are successively nested inside each other, so that the same intricate shapes appear no matter how much you zoom in to the whole. Fern leaves and Romanesco broccoli are two examples from nature." He points out an unexpected conclusion:

Mandelbrot used the term "fractal" as it derived from the Latin word "fractus", defined as broken or shattered glass. Using the newly developed IBM computers at his disposal, Mandelbrot was able to create fractal images using graphic computer code, images that an interviewer described as looking like "the delirious exuberance of the 1960s psychedelic art with forms hauntingly reminiscent of nature and the human body". He also saw himself as a "would-be Kepler", after the 17th-century scientist Johannes Kepler, who calculated and described the orbits of the planets.
Mandelbrot, however, never felt he was inventing a new idea. He describes his feelings in a documentary with science writer Arthur C. Clarke:

According to Clarke, "the Mandelbrot set is indeed one of the most astonishing discoveries in the entire history of mathematics. Who could have dreamed that such an incredibly simple equation could have generated images of literally "infinite" complexity?" Clarke also notes an "odd coincidencethe name Mandelbrot, and the word "mandala"—for a religious symbol—which I'm sure is a pure coincidence, but indeed the Mandelbrot set does seem to contain an enormous number of mandalas.

Mandelbrot left IBM in 1987, after 35 years and 12 days, when IBM decided to end pure research in his division. He joined the Department of Mathematics at Yale, and obtained his first tenured post in 1999, at the age of 75. At the time of his retirement in 2005, he was Sterling Professor of Mathematical Sciences.

Mandelbrot created the first-ever "theory of roughness", and he saw "roughness" in the shapes of mountains, coastlines and river basins; the structures of plants, blood vessels and lungs; the clustering of galaxies. His personal quest was to create some mathematical formula to measure the overall "roughness" of such objects in nature. He began by asking himself various kinds of questions related to nature:
In his paper titled How Long Is the Coast of Britain? Statistical Self-Similarity and Fractional Dimension published in "Science" in 1967 Mandelbrot discusses self-similar curves that have Hausdorff dimension that are examples of "fractals", although Mandelbrot does not use this term in the paper, as he did not coin it until 1975. The paper is one of Mandelbrot's first publications on the topic of fractals.

Mandelbrot emphasized the use of fractals as realistic and useful models for describing many "rough" phenomena in the real world. He concluded that "real roughness is often fractal and can be measured." Although Mandelbrot coined the term "fractal", some of the mathematical objects he presented in "The Fractal Geometry of Nature" had been previously described by other mathematicians. Before Mandelbrot, however, they were regarded as isolated curiosities with unnatural and non-intuitive properties. Mandelbrot brought these objects together for the first time and turned them into essential tools for the long-stalled effort to extend the scope of science to explaining non-smooth, "rough" objects in the real world. His methods of research were both old and new:
Fractals are also found in human pursuits, such as music, painting, architecture, and stock market prices. Mandelbrot believed that fractals, far from being unnatural, were in many ways more intuitive and natural than the artificially smooth objects of traditional Euclidean geometry: Clouds are not spheres, mountains are not cones, coastlines are not circles, and bark is not smooth, nor does lightning travel in a straight line.  —Mandelbrot, in his introduction to "The Fractal Geometry of Nature"
Mandelbrot has been called a work of art, and a visionary and a maverick. His informal and passionate style of writing and his emphasis on visual and geometric intuition (supported by the inclusion of numerous illustrations) made "The Fractal Geometry of Nature" accessible to non-specialists. The book sparked widespread popular interest in fractals and contributed to chaos theory and other fields of science and mathematics.

Mandelbrot also put his ideas to work in cosmology. He offered in 1974 a new explanation of Olbers' paradox (the "dark night sky" riddle), demonstrating the consequences of fractal theory as a sufficient, but not necessary, resolution of the paradox. He postulated that if the stars in the universe were fractally distributed (for example, like Cantor dust), it would not be necessary to rely on the Big Bang theory to explain the paradox. His model would not rule out a Big Bang, but would allow for a dark sky even if the Big Bang had not occurred.

Mandelbrot's awards include the Wolf Prize for Physics in 1993, the Lewis Fry Richardson Prize of the European Geophysical Society in 2000, the Japan Prize in 2003, and the Einstein Lectureship of the American Mathematical Society in 2006.

The small asteroid 27500 Mandelbrot was named in his honor. In November 1990, he was made a Chevalier in France's Legion of Honour. In December 2005, Mandelbrot was appointed to the position of Battelle Fellow at the Pacific Northwest National Laboratory. Mandelbrot was promoted to an Officer of the Legion of Honour in January 2006. An honorary degree from Johns Hopkins University was bestowed on Mandelbrot in the May 2010 commencement exercises.

A partial list of awards received by Mandelbrot:

Mandelbrot died from pancreatic cancer at the age of 85 in a hospice in Cambridge, Massachusetts on 14 October 2010. Reacting to news of his death, mathematician Heinz-Otto Peitgen said: "[I]f we talk about impact inside mathematics, and applications in the sciences, he is one of the most important figures of the last fifty years."

Chris Anderson, TED conference curator, described Mandelbrot as "an icon who changed how we see the world". Nicolas Sarkozy, President of France at the time of Mandelbrot's death, said Mandelbrot had "a powerful, original mind that never shied away from innovating and shattering preconceived notions [… h]is work, developed entirely outside mainstream research, led to modern information theory." Mandelbrot's obituary in "The Economist" points out his fame as "celebrity beyond the academy" and lauds him as the "father of fractal geometry".

Best-selling essayist-author Nassim Nicholas Taleb has remarked that Mandelbrot's book "The (Mis)Behavior of Markets" is in his opinion "The deepest and most realistic finance book ever published".







</doc>
<doc id="4001" url="https://en.wikipedia.org/wiki?curid=4001" title="Benedict of Nursia">
Benedict of Nursia

Saint Benedict of Nursia (; ; ; ; – ) is a Christian saint venerated in the Catholic Church, the Eastern Orthodox Church, the Oriental Orthodox Churches, the Anglican Communion and Old Catholic Churches. He is a patron saint of Europe.

Benedict founded twelve communities for monks at Subiaco, Lazio, Italy (about to the east of Rome), before moving to Monte Cassino in the mountains of southern Italy. The Order of Saint Benedict is of later origin and, moreover, not an "order" as commonly understood but merely a confederation of autonomous congregations.

Benedict's main achievement, his "Rule of Saint Benedict", contains a set of rules for his monks to follow. Heavily influenced by the writings of John Cassian, it shows strong affinity with the Rule of the Master, but it also has a unique spirit of balance, moderation and reasonableness (, "epieíkeia"), which persuaded most Christian religious communities founded throughout the Middle Ages to adopt it. As a result, his Rule became one of the most influential religious rules in Western Christendom. For this reason, Giuseppe Carletti regarded Benedict as the founder of Western Christian monasticism.

Apart from a short poem attributed to Mark of Monte Cassino, the only ancient account of Benedict is found in the second volume of Pope Gregory I's four-book "Dialogues", thought to have been written in 593, although the authenticity of this work has been disputed.

Gregory's account of this saint's life is not, however, a biography in the modern sense of the word. It provides instead a spiritual portrait of the gentle, disciplined abbot. In a letter to Bishop Maximilian of Syracuse, Gregory states his intention for his "Dialogues", saying they are a kind of "floretum" (an "anthology", literally, 'flowers') of the most striking miracles of Italian holy men.

Gregory did not set out to write a chronological, historically anchored story of Saint Benedict, but he did base his anecdotes on direct testimony. To establish his authority, Gregory explains that his information came from what he considered the best sources: a handful of Benedict's disciples who lived with the saint and witnessed his various miracles. These followers, he says, are Constantinus, who succeeded Benedict as Abbot of Monte Cassino; Valentinianus; Simplicius; and Honoratus, who was abbot of Subiaco when St Gregory wrote his "Dialogues".

In Gregory's day, history was not recognised as an independent field of study; it was a branch of grammar or rhetoric, and "historia" was an account that summed up the findings of the learned when they wrote what was, at that time, considered 'history.' Gregory's "Dialogues" Book Two, then, an authentic medieval hagiography cast as a conversation between the Pope and his deacon Peter, is designed to teach spiritual lessons.

He was the son of a Roman noble of Nursia, the modern Norcia, in Umbria. A tradition which Bede accepts makes him a twin with his sister Scholastica. If 480 is accepted as the year of his birth, the year of his abandonment of his studies and leaving home would be about 500. Saint Gregory's narrative makes it impossible to suppose him younger than 20 at the time. He was old enough to be in the midst of his literary studies, to understand the real meaning and worth of the dissolute and licentious lives of his companions, and to have been deeply affected by the love of a woman. He was at the beginning of life, and he had at his disposal the means to a career as a Roman noble; clearly he was not a child.

Benedict was sent to Rome to study, but was disappointed by the life he found there. He does not seem to have left Rome for the purpose of becoming a hermit, but only to find some place away from the life of the great city. He took his old nurse with him as a servant and they settled down to live in Enfide. Enfide, which the tradition of Subiaco identifies with the modern Affile, is in the Simbruini mountains, about forty miles from Rome and two from Subiaco.

A short distance from Enfide is the entrance to a narrow, gloomy valley, penetrating the mountains and leading directly to Subiaco. The path continues to ascend, and the side of the ravine, on which it runs, becomes steeper, until a cave is reached above which the mountain now rises almost perpendicularly; while on the right, it strikes in a rapid descent down to where, in Saint Benedict's day, below, lay the blue waters of the lake. The cave has a large triangular-shaped opening and is about ten feet deep.
On his way from Enfide, Benedict met a monk, Romanus of Subiaco, whose monastery was on the mountain above the cliff overhanging the cave. Romanus had discussed with Benedict the purpose which had brought him to Subiaco, and had given him the monk's habit. By his advice Benedict became a hermit and for three years, unknown to men, lived in this cave above the lake.

Gregory tells us little of these years. He now speaks of Benedict no longer as a youth ("puer"), but as a man ("vir") of God. Romanus, Gregory tells us, served the saint in every way he could. The monk apparently visited him frequently, and on fixed days brought him food.

During these three years of solitude, broken only by occasional communications with the outer world and by the visits of Romanus, Benedict matured both in mind and character, in knowledge of himself and of his fellow-man, and at the same time he became not merely known to, but secured the respect of, those about him; so much so that on the death of the abbot of a monastery in the neighbourhood (identified by some with Vicovaro), the community came to him and begged him to become its abbot. Benedict was acquainted with the life and discipline of the monastery, and knew that "their manners were diverse from his and therefore that they would never agree together: yet, at length, overcome with their entreaty, he gave his consent" (ibid., 3). The experiment failed; the monks tried to poison him. The legend goes that they first tried to poison his drink. He prayed a blessing over the cup and the cup shattered. Thus he left the group and went back to his cave at Subiaco. There lived in the neighborhood a priest called Florentius who, moved by envy, tried to ruin him. He tried to poison him with poisoned bread. When he prayed a blessing over the bread, a raven swept in and took the loaf away. From this time his miracles seem to have become frequent, and many people, attracted by his sanctity and character, came to Subiaco to be under his guidance. Having failed by sending him poisonous bread, Florentius tried to seduce his monks with some prostitutes. To avoid further temptations, in about 530 Benedict left Subiaco. He founded 12 monasteries in the vicinity of Subiaco, and, eventually, in 530 he founded the great Benedictine monastery of Monte Cassino, which lies on a hilltop between Rome and Naples.

During the invasion of Italy, Totila, King of the Goths, ordered a general to wear his kingly robes and to see whether Benedict would discover the truth. Immediately the Saint detected the impersonation, and Totila came to pay him due respect.

He is believed to have died of a fever at Monte Cassino not long after his twin sister, Saint Scholastica, and was buried in the same place as his sister. According to tradition, this occurred on 21 March 547. He was named patron protector of Europe by Pope Paul VI in 1964. In 1980, Pope John Paul II declared him co-patron of Europe, together with Saints Cyril and Methodius.

In the pre-1970 General Roman Calendar, his feast is kept on 21 March, the day of his death according to some manuscripts of the "Martyrologium Hieronymianum" and that of Bede. Because on that date his liturgical memorial would always be impeded by the observance of Lent, the 1969 revision of the General Roman Calendar moved his memorial to 11 July, the date that appears in some Gallic liturgical books of the end of the 8th century as the feast commemorating his birth ("Natalis S. Benedicti"). There is some uncertainty about the origin of this feast. Accordingly, on 21 March the Roman Martyrology mentions in a line and a half that it is Benedict's day of death and that his memorial is celebrated on 11 July, while on 11 July it devotes seven lines to speaking of him, and mentions the tradition that he died on 21 March.

The Eastern Orthodox Church commemorates Saint Benedict on 14 March.

The Anglican Communion has no single universal calendar, but a provincial calendar of saints is published in each province. In almost all of these, Saint Benedict is commemorated on 11 July.

Benedict wrote the "Rule" in 516 for monks living communally under the authority of an abbot. Seventy-three short chapters comprise the "Rule". Its wisdom is twofold: spiritual (how to live a Christocentric life on earth) and administrative (how to run a monastery efficiently). More than half of the chapters describe how to be obedient and humble, and what to do when a member of the community is not. About one-fourth regulate the work of God (the Opus Dei). One-tenth outline how, and by whom, the monastery should be managed.

Following the golden rule of "Ora et Labora - pray and work", the monks each day devoted eight hours to prayer, eight hours to sleep, and eight hours to manual work, sacred reading and/or works of charity.

This devotional medal originally came from a cross in honour of Saint Benedict. On one side, the medal has an image of Saint Benedict, holding the Holy Rule in his left hand and a cross in his right. There is a raven on one side of him, with a cup on the other side of him. Around the medal's outer margin are the words ""Eius in obitu nostro praesentia muniamur"" ("May we be strengthened by his presence in the hour of our death"). The other side of the medal has a cross with the initials CSSML on the vertical bar which signify ""Crux Sacra Sit Mihi Lux"" ("May the Holy Cross be my light") and on the horizontal bar are the initials NDSMD which stand for ""Non Draco Sit Mihi Dux"" ("Let not the dragon be my guide"). The initials CSPB stand for ""Crux Sancti Patris Benedicti"" ("The Cross of the Holy Father Benedict") and are located on the interior angles of the cross. Either the inscription ""PAX"" (Peace) or the Christogram ""IHS"" may be found at the top of the cross in most cases. Around the medal's margin on this side are the "Vade Retro Satana" initials VRSNSMV which stand for ""Vade Retro Satana, Nonquam Suade Mihi Vana"" ("Begone Satan, do not suggest to me thy vanities") then a space followed by the initials SMQLIVB which signify ""Sunt Mala Quae Libas, Ipse Venena Bibas"" ("Evil are the things thou profferest, drink thou thy own poison").

This medal was first struck in 1880 to commemorate the fourteenth centenary of Saint Benedict's birth and is also called the Jubilee Medal; its exact origin, however, is unknown. In 1647, during a witchcraft trial at Natternberg near Metten Abbey in Bavaria, the accused women testified they had no power over Metten, which was under the protection of the cross. An investigation found a number of painted crosses on the walls of the abbey with the letters now found on St Benedict medals, but their meaning had been forgotten. A manuscript written in 1415 was eventually found that had a picture of Saint Benedict holding a scroll in one hand and a staff which ended in a cross in the other. On the scroll and staff were written the full words of the initials contained on the crosses. Medals then began to be struck in Germany, which then spread throughout Europe. This medal was first approved by Pope Benedict XIV in his briefs of 23 December 1741, and 12 March 1742.

Saint Benedict has been also the motive of many collector's coins around the world. The Austria 50 euro 'The Christian Religious Orders', issued on 13 March 2002 is one of them.

The early Middle Ages have been called "the Benedictine centuries." In April 2008, Pope Benedict XVI discussed the influence St Benedict had on Western Europe. The pope said that "with his life and work St Benedict exercised a fundamental influence on the development of European civilization and culture" and helped Europe to emerge from the "dark night of history" that followed the fall of the Roman empire.

Saint Benedict contributed more than anyone else to the rise of monasticism in the West. His Rule was the foundational document for thousands of religious communities in the Middle Ages. To this day, The Rule of St. Benedict is the most common and influential Rule used by monasteries and monks, more than 1,400 years after its writing. Today the Benedictine family is represented by two branches: the Benedictine Federation and the Cistercians.

The influence of Saint Benedict produced "a true spiritual ferment" in Europe, and over the coming decades his followers spread across the continent to establish a new cultural unity based on Christian faith.

A basilica was built upon the birthplace of Saints Benedict and Scholastica in the 1400s. Ruins of their familial home were excavated from beneath the church and preserved. The earthquake of 30 October 2016 completely devastated the structure of the basilica, leaving only the front facade and altar standing.







</doc>
<doc id="4005" url="https://en.wikipedia.org/wiki?curid=4005" title="Battle of Pharsalus">
Battle of Pharsalus

The Battle of Pharsalus was the decisive battle of Caesar's Civil War. On 9 August 48 BC at Pharsalus in central Greece, Gaius Julius Caesar and his allies formed up opposite the army of the republic under the command of Gnaeus Pompeius Magnus ("Pompey the Great"). Pompey had the backing of a majority of the senators, of whom many were optimates, and his army significantly outnumbered the veteran Caesarian legions.

The two armies confronted each other over several months of uncertainty, Caesar being in a much weaker position than Pompey.
The former found himself isolated in a hostile country with only 22,000 men and short of provisions, while on the other side of the river he was faced by Pompey with an army about twice as large in number. Pompey wanted to delay, knowing the enemy would eventually surrender from hunger and exhaustion. Pressured by the senators present and by his officers, he reluctantly engaged in battle and suffered an overwhelming defeat, ultimately fleeing the camp and his men, disguised as an ordinary citizen. However, Pompey was later assassinated in Ptolemaic Egypt by orders of Ptolemy XIII.

A dispute between Caesar and the "optimates" faction in the Senate of Rome culminated in Caesar marching his army on Rome and forcing Pompey, accompanied by much of the Roman Senate, to flee in 49 BC from Italy to Greece, where he could better conscript an army to face his former ally. Caesar, lacking a fleet to immediately give chase, solidified his control over the western Mediterranean – Spain specifically – before assembling ships to follow Pompey. Marcus Calpurnius Bibulus, whom Pompey had appointed to command his 600-ship fleet, set up a massive blockade to prevent Caesar from crossing to Greece and to prevent any aid to Italy. Caesar, defying convention, chose to cross the Adriatic during the winter, with only half his fleet at a time. As Pontifex Maximus, Caesar was responsible for adjusting the Roman calendar at the end of each year to align it with the rotation of the Earth around the sun. As Caesar had been in Gaul and then occupied by the civil war for years, he had not been able to make this yearly change and over time, the difference between the Earth's rotation and the calendar that Rome operated on had grown to such an extent that Bibulus, along with the others who had fled to Greece, believed that it was months later than when Caesar knew it was. As such, this move surprised Bibulus, who believed it was winter, and the first wave of ships managed to run the blockade easily. Now prepared, Bibulus managed to prevent any further ships from crossing, but died soon afterwards.

Caesar was now in a precarious position, holding a beachhead at Epirus with only half his army, no ability to supply his troops by sea, and limited local support, as the Greek cities were mostly loyal to Pompey. Caesar's only choice was to fortify his position, forage what supplies he could, and wait on his remaining army to attempt another crossing. Pompey by now had a massive international army; however, his troops were mostly untested raw recruits, while Caesar's troops were hardened veterans. Realizing Caesar's difficulty in keeping his troops supplied, Pompey decided to simply mirror Caesar's forces and let hunger do the fighting for him. Caesar began to despair and used every channel he could think of to pursue peace with Pompey. When this was rebuffed he made an attempt to cross back to Italy to collect his missing troops, but was turned back by a storm. Finally, Mark Antony rallied the remaining forces in Italy, fought through the blockade and made the crossing, reinforcing Caesar's forces in both men and spirit. Now at full strength, Caesar felt confident to take the fight to Pompey.

Pompey was camped in a strong position just south of Dyrrhachium with the sea to his back and surrounded by hills, making a direct assault impossible. Caesar ordered a wall to be built around Pompey's position in order to cut off water and pasture land for his horses. Pompey built a parallel wall and in between a kind of no man's land was created, with fighting comparable to the trench warfare of World War I. Ultimately the standoff was broken when a traitor in Caesar's army informed Pompey of a weakness in Caesar's wall. Pompey immediately exploited this information and forced Caesar's army into a full retreat, but ordered his army not to pursue, fearing Caesar's reputation for setting elaborate traps. This caused Caesar to remark, "Today the victory had been the enemy's, had there been any one among them to gain it." Pompey continued his strategy of mirroring Caesar's forces and avoiding any direct engagements. After trapping Caesar in Thessaly, the prominent senators in Pompey's camp began to argue loudly for a more decisive victory. Although Pompey was strongly against it — he wanted to surround and starve Caesar's army instead — he eventually gave in and accepted battle from Caesar on a field near Pharsalus.

Excerpt from Cassius Dio's "Roman History" gives a more ancient flavor of his take on the prelude to the "Battle of Pharsalus": [41.56] "As a result of these circumstances and of the very cause and purpose of the war a most notable struggle took place. For the city of Rome and its entire empire, even then great and mighty, lay before them as the prize, since it was clear to all that it would be the slave of him who then conquered. When they reflected on this fact and furthermore thought of their former deeds [...41.57] they were wrought up to the highest pitch of excitement...they now, led by their insatiable lust of power, hastened to break, tear, and rend asunder. Because of them Rome was being compelled to fight both in her own defense and against herself, so that even if victorious she would be vanquished."

The date of the actual decisive battle is given as 9 August 48 BC according to the republican calendar. According to the Julian calendar however, the date was either 29 June (according to Le Verrier's chronological reconstruction) or possibly 7 June (according to Drumann/Groebe). As Pompey was assassinated on 3 September 48 BC, the battle must have taken place in the true month of August, when the harvest was becoming ripe (or Pompey's strategy of starving Caesar would not be plausible).

The location of the battlefield was for a long time the subject of controversy among scholars. Caesar himself, in his Commentarii de Bello Civili, mentions few place-names; and although the battle is called after Pharsalos by modern authors, four ancient writers – the author of the "Bellum Alexandrinum" (48.1), Frontinus ("Strategemata" 2.3.22), Eutropius (20), and Orosius (6.15.27) – place it specifically at "Palae"pharsalus ("Old" Pharsalus). Strabo in his "Geographica" ("Γεωγραφικά") mentions both old and new Pharsaloi, and notes that the Thetideion, the temple to Thetis south of Scotoussa, was near both. In 198 BC, in the Second Macedonian War, Philip V of Macedon sacked Palaepharsalos (Livy, "Ab Urbe Condita" 32.13.9), but left new Pharsalos untouched. These two details perhaps imply that the two cities were not close neighbours. Many scholars, therefore, unsure of the site of Palaepharsalos, followed Appian (2.75) and located the battle of 48 BC south of the Enipeus or close to Pharsalos (today's Pharsala). Among the scholars arguing for the south side are Béquignon (1928), Bruère (1951), and Gwatkin (1956).

An increasing number of scholars, however, have argued for a location on the north side of the river. These include Perrin (1885), Holmes (1908), Lucas (1921), Rambaud (1955), Pelling (1973), Morgan (1983), and Sheppard (2006). John D. Morgan in his definitive “Palae-pharsalus – the Battle and the Town”, shows that Palaepharsalus cannot have been at Palaiokastro, as Béquignon thought (a site abandoned c. 500 BC), nor the hill of Fatih-Dzami within the walls of Pharsalus itself, as Kromayer (1903, 1931) and Gwatkin thought; and Morgan argues that it is probably also not the hill of Khtouri (Koutouri), some 7 miles north-west of Pharsalus on the south bank of the Enipeus, as Lucas and Holmes thought, although that remains a possibility. However, Morgan believes it is most likely to have been the hill just east of the village of Krini (formerly Driskoli) very close to the ancient highway from Larisa to Pharsalus. This site is some six miles (10km) north of Pharsalus, and three miles north of the river Enipeus, and not only has remains dating back to neolithic times but also signs of habitation in the 1st century BC and later. The identification seems to be confirmed by the location of a place misspelled "Palfari" or "Falaphari" shown on a medieval route map of the road just north of Pharsalus. Morgan places Pompey's camp a mile to the west of Krini, just north of the village of Avra (formerly Sarikayia), and Caesar's camp some four miles to the east-south-east of Pompey's. According to this reconstruction, therefore, the battle took place not between Pharsalus and the river, as Appian wrote, but between Old Pharsalus and the river.

An interesting side-note on Palaepharsalus is that it was sometimes identified in ancient sources with Phthia, the home of Achilles. Near Old and New Pharsalus was a "Thetideion", or temple dedicated to Thetis, the mother of Achilles. However, Phthia, the kingdom of Achilles and his father Peleus, is more usually identified with the lower valley of the Spercheios river, much further south.

Although it is often called the Battle of Pharsalus by modern historians, this name was rarely used in the ancient sources. Caesar merely calls it the "proelium in Thessaliā" ("battle in Thessalia"); Cicero and Hirtius call it the "Pharsālicum proelium" ("Pharsalic battle") or "pugna Pharsālia" ("Pharsalian battle"), and similar expressions are also used in other authors. But Hirtius (if he is the author of the de Bello Alexandrino) also refers to the battle as having taken place at "Palaepharsalus", and this name also occurs in Strabo, Frontinus, Eutropius, and Orosius. Lucan in his poem about the Civil War regularly uses the name "Pharsālia", and this term is also used by the epitomiser of Livy and by Tacitus. The only ancient sources to refer to the battle as being at Pharsalus are a certain calendar known as the Fasti Amiternini and the Greek authors Plutarch, Appian, and Polyaenus. It has therefore been argued by some scholars that "Pharsalia" would be a more accurate name for the battle than Pharsalus.

Caesar gives his own numbers as 22,000 men in eighty cohorts (it should be remembered that these numbers refer to legionaries, and do not include non-Roman infantry) and 1,000 cavalry (mainly Germanic and Gallic auxiliaries). 

Caesar had the following legions with him:


However, all of these legions were understrength. Some only had about a thousand men at the time of Pharsalus, due partly to losses at Dyrrhachium and partly to Caesar's wish to rapidly advance with a picked body as opposed to a ponderous movement with a large army.

In total, Caesar counted 110 cohorts in the Pompeian army, 11 legions consisting of about 47,000 men, although Orosius, following Livy and Pollio, only counted 38,000 men in 88 cohorts, and Hans Delbrück suggests that Caesar's count includes detachments at Dyrrhachium and elsewhere, leaving only 90 cohorts in the Pompeian army, counting naval support. Caesar also mentions 7,000 cavalry for Pompeian side.

On the Pharsalian plain, Pompey deployed his infantry in the traditional three lines of 10 men deep, thusly: Legions I and III were on the left with Pompey himself; at his center were the legions from Syria commanded by Scipio, and on the right, against the Enipeus River, were legions from Cilicia and Spanish auxiliaries. Pompey's cavalry, which greatly outnumbered Caesar's, were commanded by Labienus, a brilliant cavalry commander and Caesar's old lieutenant during the Gallic Wars. They were massed in a single body on Pompey's left flank, together with his auxiliary archers and slingers. Pompey's tactical plan was to allow Caesar's legions to charge while his own stood their ground, reasoning that the enemy would fatigue by charging the double distance, and that his own men would better withstand the pilum toss while stationary. Simultaneously his cavalry would overwhelm the enemy's and then take the legions in the flank and rear — a classic hammer and anvil tactic.

Caesar also deployed his men in three lines, but, being outnumbered, had to thin his ranks to a depth of only six men, in order to match the frontage presented by Pompey. His left flank, resting on the Enipeus River, consisted of his battle worn IX legion supplemented by the VIII legion, these commanded by Mark Antony. The center was commanded by Domitius and upon his right he placed his favored X legion, giving Sulla command of this flank — Caesar himself took his stand on the right, across from Pompey. Upon seeing the disposition of Pompey's army Caesar grew discomforted, and further thinned his third line in order to form a fourth line on his right: this to counter the onslaught of the enemy cavalry, which he knew his numerically inferior cavalry could not withstand. He gave this new line detailed instructions for the role they would play, hinting that upon them would rest the fortunes of the day, and gave strict orders to his third line not to charge until specifically ordered.

There was significant distance between the two armies, according to Caesar. Pompey ordered his men not to charge, but to wait until Caesar's legions came into close quarters; Pompey's adviser Gaius Triarius believed that Caesar's infantry would be fatigued and fall into disorder if they were forced to cover twice the expected distance of a battle march. Also, stationary troops were expected to be able to defend better against pila throws. Seeing that Pompey's army was not advancing, Caesar's infantry under Mark Antony and Gnaeus Domitius Calvinus started the advance. As Caesar's men neared throwing distance, without orders, they stopped to rest and regroup before continuing the charge; Pompey's right and centre line held as the two armies collided.

As Pompey's infantry fought, Labienus ordered the Pompeian cavalry on his left flank to attack Caesar's cavalry; as expected they successfully pushed back Caesar's cavalry. Caesar then revealed his hidden fourth line of infantry and surprised Pompey's cavalry charge; Caesar's men were ordered to leap up and use their pila to thrust at Pompey's cavalry instead of throwing them. Pompey's cavalry panicked and suffered hundreds of casualties. After failing to reform, the rest of the cavalry retreated to the hills, leaving the left wing of Pompey's legions exposed. Caesar then ordered in his third line, containing his most battle-hardened veterans, to attack. This broke Pompey's left wing troops, who fled the battlefield.

After routing Pompey's cavalry, Caesar threw in his last line of reserves —a move which at this point meant that the battle was more or less decided. Pompey lost the will to fight as he watched both cavalry and legions under his command break formation and flee from battle, and he retreated to his camp, leaving the rest of his troops at the centre and right flank to their own devices. He ordered the garrisoned auxiliaries to defend the camp as he gathered his family, loaded up gold, and threw off his general's cloak to make a quick escape. As the rest of Pompey's army were left confused, Caesar urged his men to end the day by routing the rest of Pompey's troops and capturing the Pompeian camp. They complied with his wishes; after finishing off the remains of Pompey's men, they furiously attacked the camp walls. The Thracians and the other auxiliaries who were left in the Pompeian camp, in total seven cohorts, defended bravely, but were not able to fend off the assault.

Caesar had won his greatest victory, claiming to have only lost about 200 soldiers and 30 centurions. In his history of the war, Caesar would praise his own men's discipline and experience, and remembered each of his centurions by name. He also questioned Pompey's decision not to charge.

Pompey fled from Pharsalus to Egypt, where he was assassinated on the order of Ptolemy XIII. Ptolemy XIII sent Pompey's head to Caesar in an effort to win his favor, but instead secured him as a furious enemy. Ptolemy, advised by his regent, the eunuch Pothinus, and his rhetoric tutor Theodotus of Chios, had failed to take into account that Caesar was granting amnesty to a great number of those of the senatorial faction in their defeat. Even men who had been bitter enemies were allowed not only to return to Rome but to assume their previous positions in Roman society.

Pompey's assassination had deprived Caesar of his ultimate public relations moment — pardoning his most ardent rival. The Battle of Pharsalus ended the wars of the First Triumvirate. The Roman Civil War, however, was not ended. Pompey's two sons, Gnaeus Pompeius and Sextus Pompey, and the Pompeian faction, led now by Metellus Scipio and Cato, survived and fought for their cause in the name of Pompey the Great. Caesar spent the next few years 'mopping up' remnants of the senatorial faction. After seemingly vanquishing all his enemies and bringing peace to Rome, he was assassinated in 44 BC by friends, in a conspiracy organized by Marcus Junius Brutus and Gaius Cassius Longinus.

Paul K. Davis wrote that "Caesar's victory took him to the pinnacle of power, effectively ending the Republic." The battle itself did not end the civil war but it was decisive and gave Caesar a much needed boost in legitimacy. Until then much of the Roman world outside Italy supported Pompey and his allies due to the extensive list of clients he held in all corners of the Republic. After Pompey's defeat former allies began to align themselves with Caesar as some came to believe the gods favored him, while for others it was simple self-preservation. The ancients took great stock in success as a sign of favoritism by the gods. This is especially true of success in the face of almost certain defeat — as Caesar experienced at Pharsalus. This allowed Caesar to parlay this single victory into a huge network of willing clients to better secure his hold over power and force the Optimates into near exile in search for allies to continue the fight against Caesar.

The battle gives its name to the following artistic, geographical, and business concerns:


In Alexander Dumas' "The Three Musketeers", the author makes reference to Caesar's purported order that his men try to cut the faces of their opponents - their vanity supposedly being of more value to them than their lives.



</doc>
<doc id="4009" url="https://en.wikipedia.org/wiki?curid=4009" title="Bigfoot">
Bigfoot

In North American folklore, Bigfoot or Sasquatch are said to be hairy, upright-walking, ape-like creatures that dwell in the wilderness and leave footprints. Depictions often portray them as a missing link between humans and human ancestors or other great apes. They are strongly associated with the Pacific Northwest (particularly Oregon, Washington and British Columbia), Northern California, and individuals claim to see the creatures across North America. Over the years, these creatures have inspired numerous commercial ventures and hoaxes. The plural nouns 'Bigfoots' and 'Bigfeet' are both in use.

Folklorists trace the figure of Bigfoot to a combination of factors and sources, including folklore surrounding the European wild man figure, folk belief among Native Americans and loggers, and a cultural increase in environmental concerns.

A majority of scientists have historically discounted the existence of Bigfoot, considering it to be a combination of folklore, misidentification, and hoax, rather than living animals.

People who claim to have seen it describe Bigfoot as large, muscular, bipedal ape-like creatures, roughly tall, covered in hair described as black, dark brown, or dark reddish.

The enormous footprints for which the creatures are named are claimed to be as large as long and wide. Some footprint casts have also contained claw marks, making it likely that they came from known animals such as bears, which have five toes and claws.

According to David Daegling, the legends predate the name "Bigfoot". They differ in their details both regionally and between families in the same community.

Ecologist Robert Pyle says that most cultures have accounts of human-like giants in their folk history, expressing a need for "some larger-than-life creature." Each language had its own name for the creatures featured in the local version of such legends. Many names meant something along the lines of "wild man" or "hairy man", although other names described common actions that it was said to perform, such as eating clams or shaking trees. Chief Mischelle of the Nlaka'pamux at Lytton, British Columbia told such a story to Charles Hill-Tout in 1898; he named the creature by a Salishan variant meaning "the benign-faced-one".

Members of the Lummi tell tales about "Ts'emekwes", the local version of Bigfoot. The stories are similar to each other in the general descriptions of "Ts'emekwes", but details differed among various family accounts concerning the creatures' diet and activities. Some regional versions tell of more threatening creatures. The "stiyaha" or "kwi-kwiyai" were a nocturnal race. Children were warned against saying the names, lest the monsters hear and come to carry off a person, sometimes to be killed. In 1847 Paul Kane reported stories by the Indians about "skoocooms", a race of cannibalistic wildmen living on the peak of Mount St. Helens in southern Washington state.

Less-menacing versions have also been recorded, such as one in 1840 by Elkanah Walker, a Protestant missionary who recorded stories of giants among the Indians living near Spokane, Washington. The Indians said that these giants lived on and around the peaks of nearby mountains and stole salmon from the fishermen's nets.

In the 1920s, Indian Agent J. W. Burns compiled local stories and published them in a series of Canadian newspaper articles. They were accounts told to him by the Sts'Ailes people of Chehalis and others. The Sts'Ailes and other regional tribes maintained that the Sasquatch were real. They were offended by people telling them that the figures were legendary. According to Sts'Ailes accounts, the Sasquatch preferred to avoid white men and spoke the Lillooet language of the people at Port Douglas, British Columbia at the head of Harrison Lake. These accounts were published again in 1940. Burns borrowed the term Sasquatch from the Halkomelem "sásq'ets" () and used it in his articles to describe a hypothetical single type of creature portrayed in the local stories.

About one-third of all claims of Bigfoot sightings are located in the Pacific Northwest, with the remaining reports spread throughout the rest of North America.

Bigfoot has become better known and a phenomenon in popular culture, and sightings have spread throughout North America. Rural areas of the Great Lakes region and the Southeastern United States have been sources of numerous reports of Bigfoot sightings, in addition to the Pacific Northwest. In the "Bigfoot Casebook", authors Janet and Colin Bord, document the sightings from 1818 to 1980, listing over 1,000 sightings. The debate over the legitimacy of Bigfoot sightings reached a peak in the 1970s, and Bigfoot has been regarded as the first widely popularized example of pseudoscience in American culture, so much so that, according to an Associated Press 2014 poll, more Americans believe in Bigfoot than the Big Bang Theory.

Various explanations have been suggested for the sightings and to offer conjecture on what type of creature Bigfoot might be. Some scientists typically attribute sightings either to hoaxes or to misidentification of known animals and their tracks, particularly black bears.

In 2007 the Bigfoot Field Researchers Organization put forward some photos which they claimed showed a juvenile Bigfoot. The Pennsylvania Game Commission, however, said that the photos were of a bear with mange. However, anthropologist Jeffrey Meldrum, and Ohio scientist Jason Jarvis said that the limb proportions of the creature were not bear-like, they were "more like a chimpanzee."

Both Bigfoot believers and non-believers agree that many of the reported sightings are hoaxes or misidentified animals. Author Jerome Clark argues that the Jacko Affair was a hoax, involving an 1884 newspaper report of an apelike creature captured in British Columbia. He cites research by John Green, who found that several contemporaneous British Columbia newspapers regarded the alleged capture as highly dubious, and notes that the "Mainland Guardian" of New Westminster, British Columbia wrote, "Absurdity is written on the face of it."

Tom Biscardi is a long-time Bigfoot enthusiast and CEO of Searching for Bigfoot Inc. He appeared on the "Coast to Coast AM" paranormal radio show on July 14, 2005 and said that he was "98% sure that his group will be able to capture a Bigfoot which they had been tracking in the Happy Camp, California area." A month later, he announced on the same radio show that he had access to a captured Bigfoot and was arranging a pay-per-view event for people to see it. He appeared on "Coast to Coast AM" again a few days later to announce that there was no captive Bigfoot. He blamed an unnamed woman for misleading him, and said that the show's audience was gullible.

On July 9, 2008, Rick Dyer and Matthew Whitton posted a video to YouTube, claiming that they had discovered the body of a dead Sasquatch in a forest in northern Georgia. Tom Biscardi was contacted to investigate. Dyer and Whitton received US$50,000 from Searching for Bigfoot, Inc. as a good faith gesture. The story was covered by many major news networks, including BBC, CNN, ABC News, and Fox News. Soon after a press conference, the alleged Bigfoot body was delivered in a block of ice in a freezer with the Searching for Bigfoot team. When the contents were thawed, observers found that the hair was not real, the head was hollow, and the feet were rubber. Dyer and Whitton admitted that it was a hoax after being confronted by Steve Kulls, executive director of SquatchDetective.com.

In August 2012, a man in Montana was killed by a car while perpetrating a Bigfoot hoax using a ghillie suit.

In January 2014, Rick Dyer, perpetrator of a previous Bigfoot hoax, said that he had killed a Bigfoot creature in September 2012 outside San Antonio, Texas. He said that he had scientific tests performed on the body, "from DNA tests to 3D optical scans to body scans. It is the real deal. It's Bigfoot, and Bigfoot's here, and I shot it, and now I'm proving it to the world." He said that he had kept the body in a hidden location, and he intended to take it on tour across North America in 2014. He released photos of the body and a video showing a few individuals' reactions to seeing it, but never released any of the tests or scans. He refused to disclose the test results or to provide biological samples. He said that the DNA results were done by an undisclosed lab and could not be matched to identify any known animal. Dyer said that he would reveal the body and tests on February 9, 2014 at a news conference at Washington University, but he never made the test results available. After the Phoenix tour, the Bigfoot body was taken to Houston. On March 28, 2014, Dyer admitted on his Facebook page that his "Bigfoot corpse" was another hoax. He had paid Chris Russel of Twisted Toy Box to manufacture the prop, which he nicknamed "Hank", from latex, foam, and camel hair. Dyer earned approximately $60,000 from the tour of this second fake Bigfoot corpse. He said that he did kill a Bigfoot, but did not take the real body on tour for fear that it would be stolen.

Bigfoot proponents Grover Krantz and Geoffrey H. Bourne believed that Bigfoot could be a relict population of "Gigantopithecus". All "Gigantopithecus" fossils were found in Asia, but according to Bourne, many species of animals migrated across the Bering land bridge and he suggested that "Gigantopithecus" might have done so, as well. "Gigantopithecus" fossils have not been found in the Americas. The only recovered fossils are of mandibles and teeth, leaving uncertainty about "Gigantopithecus"'s locomotion. Krantz has argued that "Gigantopithecus blacki" could have been bipedal, based on his extrapolation of the shape of its mandible. However, the relevant part of the mandible is not present in any fossils. An alternative view is that "Gigantopithecus" was quadrupedal; its enormous mass would have made it difficult for it to adopt a bipedal gait.

Matt Cartmill criticizes the "Gigantopithecus" hypothesis:

Bernard G. Campbell writes: "That "Gigantopithecus" is in fact extinct has been questioned by those who believe it survives as the Yeti of the Himalayas and the Sasquatch of the north-west American coast. But the evidence for these creatures is not convincing."

Primatologist John R. Napier and anthropologist Gordon Strasenburg have suggested a species of "Paranthropus" as a possible candidate for Bigfoot's identity, such as "Paranthropus robustus", with its gorilla-like crested skull and bipedal gait —despite the fact that fossils of "Paranthropus" are found only in Africa.

Michael Rugg of the Bigfoot Discovery Museum presented a comparison between human, "Gigantopithecus," and "Meganthropus" skulls (reconstructions made by Grover Krantz) in episodes 131 and 132 of the Bigfoot Discovery Museum Show. He favorably compares a modern tooth suspected of coming from a Bigfoot to the "Meganthropus" fossil teeth, noting the worn enamel on the occlusal surface. The "Meganthropus" fossils originated from Asia, and the tooth was found near Santa Cruz, California.

Some suggest Neanderthal, "Homo erectus", or "Homo heidelbergensis" to be the creature, but no remains of any of those species have been found in the Americas.

Scientists do not consider the subject of Bigfoot to be a fertile area for credible science and there have been a limited number of formal scientific studies of Bigfoot.

Evidence such as the 1967 Patterson–Gimlin film has provided "no supportive data of any scientific value".

Great apes have not been found in the fossil record in the Americas, and no Bigfoot remains are known to have been found. Phillips Stevens, a cultural anthropologist at the University at Buffalo, summarized the scientific consensus as follows:

In the 1970s, when Bigfoot "experts" were frequently given high-profile media coverage, Mcleod writes that the scientific community generally avoided lending credence to the theories by debating them.

The first scientific study of available evidence was conducted by John Napier and published in his book, "Bigfoot: The Yeti and Sasquatch in Myth and Reality," in 1973. Napier wrote that if a conclusion is to be reached based on scant extant "'hard' evidence," science must declare "Bigfoot does not exist." However, he found it difficult to entirely reject thousands of alleged tracks, "scattered over 125,000 square miles" (325,000 km²) or to dismiss all "the many hundreds" of eyewitness accounts. Napier concluded, "I am convinced that Sasquatch exists, but whether it is all it is cracked up to be is another matter altogether. There must be "something" in north-west America that needs explaining, and that something leaves man-like footprints." However, anthropologists such as George Gaylord Simpson rejected Napier's conclusion noting that much of the data cited by Napier were hoaxes and since his book had been published, no evidence for Bigfoot was found.

In 1974, the National Wildlife Federation funded a field study seeking Bigfoot evidence. No formal federation members were involved and the study made no notable discoveries.

Few qualified anthropologists have written on the subject. The few that did have included Grover Krantz, Carleton S. Coon, George Allen Agogino and William Charles Osman Hill, although they came to no definite conclusions and later drifted from this research. Beginning in the late 1970s, physical anthropologist Grover Krantz published several articles and four book-length treatments of Sasquatch. However, his work was found to contain multiple scientific failings including falling for hoaxes.

A study published in the "Journal of Biogeography" in 2009 by J.D. Lozier et al. used ecological niche modeling on reported sightings of Bigfoot, using their locations to infer Bigfoot's preferred ecological parameters. They found a very close match with the ecological parameters of the American black bear, "Ursus americanus". They also note that an upright bear looks much like Bigfoot's purported appearance and consider it highly improbable that two species should have very similar ecological preferences, concluding that Bigfoot sightings are likely sightings of black bears.

In the first systematic genetic analysis of 30 hair samples that were suspected to be from Bigfoot, yeti, sasquatch, almasty or other anomalous primates, only one was found to be primate in origin, and that was identified as human. A joint study by the University of Oxford and Lausanne's Cantonal Museum of Zoology and published in the "Proceedings of the Royal Society B" in 2014, the team used a previously published cleaning method to remove all surface contamination and the ribosomal mitochondrial DNA 12S fragment of the sample was sequenced and then compared to GenBank to identify the species origin. The samples submitted were from different parts of the world, including the United States, Russia, the Himalayas, and Sumatra. Other than one sample of human origin, all but two are from common animals. Black and brown bear accounted for most of the samples, other animals include cow, horse, dog/wolf/coyote, sheep, goat, raccoon, porcupine, deer and tapir. The last two samples were thought to match a fossilized genetic sample of a 40,000 year old polar bear of the Pleistocene epoch; however, a later study disputes this finding. In the second paper, tests identified the hairs as being from a rare type of brown bear.

After what "The Huffington Post" described as "a five-year study of purported Bigfoot (also known as Sasquatch) DNA samples", but prior to peer review of the work, DNA Diagnostics, a veterinary laboratory headed by veterinarian Melba Ketchum, issued a press release on November 24, 2012, claiming that they had found proof that the Sasquatch "is a human relative that arose approximately 15,000 years ago as a hybrid cross of modern "Homo sapiens" with an unknown primate species." Ketchum called for this to be recognized officially, saying that "Government at all levels must recognize them as an indigenous people and immediately protect their human and Constitutional rights against those who would see in their physical and cultural differences a 'license' to hunt, trap, or kill them."

In 2012, Ketchum registered the name "Homo sapiens cognatus" to be used for the reputed hominid more familiarly known as Bigfoot or Sasquatch with ZooBank, a non-governmental organization adjunct to the International Commission on Zoological Nomenclature (ICZN). According to Ari Grossman of Midwestern University, the lack of formal differential diagnosis, type specimen, or designated location of a type specimen to verify the organism named, leaves the registered name open to challenge.

Failing to find a scientific journal that would publish their results, Ketchum announced on February 13, 2013, that their research had been published in the "DeNovo Journal of Science". "The Huffington Post" discovered that the journal's domain had been registered anonymously only nine days before the announcement. This was the only edition of "DeNovo" and was listed as Volume 1, Issue 1, with its only content being the Ketchum paper.

Shortly after publication, the paper was analyzed and outlined by Sharon Hill of Doubtful News for the Committee for Skeptical Inquiry. Hill reported on the questionable journal, mismanaged DNA testing and poor quality paper, stating that "The few experienced geneticists who viewed the paper reported a dismal opinion of it noting it made little sense."

"The Scientist" magazine also analyzed the paper, reporting that:

Claims about the origins and characteristics of Bigfoot have crossed over with other paranormal claims, including that Bigfoot and UFOs are related or that Bigfoot creatures are psychic or even completely supernatural. The evidence advanced supporting the existence of such a large, ape-like creature has often been attributed to hoaxes or delusion rather than to sightings of a genuine creature. In a 1996 "USA Today" article, Washington State zoologist John Crane said, "There is no such thing as Bigfoot. No data other than material that's clearly been fabricated has ever been presented." In addition, scientists cite the fact that Bigfoot is alleged to live in regions unusual for a large, nonhuman primate, i.e., temperate latitudes in the northern hemisphere; all recognized apes are found in the tropics of Africa and Asia.

There are several organizations dedicated to the research and investigation of Bigfoot sightings in the United States. The oldest and largest is the Bigfoot Field Researchers Organization (BFRO). The BFRO also provides a free database to individuals and other organizations. Their website includes reports from across North America that have been investigated by researchers to determine credibility.

In February 2016, the University of New Mexico at Gallup held a two-day Bigfoot conference, at a cost of $7,000 in university funds.

Bigfoot has had a demonstrable impact as a popular culture phenomenon.

When asked for her opinion of Bigfoot in a September 27, 2002, interview on National Public Radio's "Science Friday", Jane Goodall said "I'm sure they exist", and later said, chuckling, "Well, I'm a romantic, so I always wanted them to exist", and finally, "You know, why isn't there a body? I can't answer that, and maybe they don't exist, but I want them to." In 2012, when asked again by "The Huffington Post", Goodall said, "I'm fascinated and would actually love them to exist," adding, "Of course, it's strange that there has never been a single authentic hide or hair of the Bigfoot, but I've read all the accounts."




</doc>
<doc id="4010" url="https://en.wikipedia.org/wiki?curid=4010" title="Bing Crosby">
Bing Crosby

Harold Lillis "Bing" Crosby Jr. (; May 3, 1903 – October 14, 1977) was an American singer, comedian and actor. The first multimedia star, Crosby was a leader in record sales, radio ratings, and motion picture grosses from 1931 to 1954. His early career coincided with recording innovations that allowed him to develop an intimate singing style that influenced many male singers who followed him, including Perry Como, Frank Sinatra, Dick Haymes, and Dean Martin. "Yank" magazine said that he was "the person who had done the most for the morale of overseas servicemen" during World War II. In 1948, American polls declared him the "most admired man alive", ahead of Jackie Robinson and Pope Pius XII. Also in 1948, "Music Digest" estimated that his recordings filled more than half of the 80,000 weekly hours allocated to recorded radio music.

Crosby won an Oscar for Best Actor for his role as Father Chuck O'Malley in the 1944 motion picture "Going My Way" and was nominated for his reprise of the role in "The Bells of St. Mary's" opposite Ingrid Bergman the next year, becoming the first of six actors to be nominated twice for playing the same character. In 1963, Crosby received the first Grammy Global Achievement Award. He is one of 33 people to have three stars on the Hollywood Walk of Fame, in the categories of motion pictures, radio, and audio recording. He was also known for his collaborations with longtime friend Bob Hope, starring in the "Road to..." films from 1940 to 1962.

Crosby influenced the development of the postwar recording industry. After seeing a demonstration of a German broadcast quality reel-to-reel tape recorder brought to America by John T. Mullin, he invested $50,000 in a California electronics company called Ampex to build copies. He then convinced ABC to allow him to tape his shows. He became the first performer to pre-record his radio shows and master his commercial recordings onto magnetic tape. Through the medium of recording, he constructed his radio programs with the same directorial tools and craftsmanship (editing, retaking, rehearsal, time shifting) used in motion picture production, a practice that became an industry standard. In addition to his work with early audio tape recording, he helped to finance the development of videotape, bought television stations, bred racehorses, and co-owned the Pittsburgh Pirates baseball team.

Crosby was born on May 3, 1903 in Tacoma, Washington, in a house his father built at 1112 North J Street. In 1906, his family moved to Spokane in eastern Washington state, where he was raised. In 1913, his father built a house at 508 E. Sharp Avenue. The house sits on the campus of his alma mater, Gonzaga University. It functions today as a museum housing over 200 artifacts from his life and career, including his Oscar.

He was the fourth of seven children: brothers Laurence Earl (Larry) (1895–1975), Everett Nathaniel (1896–1966), Edward John (Ted) (1900–1973), and George Robert (Bob) (1913–1993); and two sisters, Catherine Cordelia (1904–1974) and Mary Rose (1906–1990). His parents were Harry Lowe Crosby (1870–1950), a bookkeeper, and Catherine Helen "Kate" (née Harrigan; 1873–1964). His mother was a second generation Irish-American. His father was of Scottish and English descent; an ancestor, Simon Crosby, emigrated from Scotland to New England in the 1630s during the Puritan migration to New England. Through another line, also on his father's side, Crosby is descended from "Mayflower" passenger William Brewster (c. 1567 – April 10, 1644). On November 8, 1937, after Lux Radio Theatre's adaptation of "She Loves Me Not", Joan Blondell asked Crosby how he got his nickname:

Crosby: "Well, I'll tell you, back in the knee-britches day, when I was a wee little tyke, a mere broth of a lad, as we say in Spokane, I used to totter around the streets, with a gun on each hip, my favorite after school pastime was a game known as "Cops and Robbers", I didn't care which side I was on, when a cop or robber came into view, I would haul out my trusty six-shooters, made of wood, and loudly exclaim "bing"! "bing"!, as my luckless victim fell clutching his side, I would shout "bing"! "bing"!, and I would let him have it again, and then as his friends came to his rescue, shooting as they came, I would shout "bing"! "bing"! "bing"! "bing"! "bing"! "bing"! "bing"! "bing"!"Blondell: "I'm surprised they didn't call you "Killer" Crosby! Now tell me another story, Grandpa!Crosby: "No, so help me, it's the truth, ask Mister De Mille."De Mille: "I'll vouch for it, Bing."

That story was pure whimsy for dramatic effect and the truth is that a neighbor – Valentine Hobart – named him "Bingo from Bingville" after a comic feature in the local paper called "The Bingville Bugle" which the young Harry liked. In time, Bingo got shortened to Bing.

In 1917, Crosby took a summer job as property boy at Spokane's "Auditorium," where he witnessed some of the finest acts of the day, including Al Jolson, who held him spellbound with ad libbing and parodies of Hawaiian songs. He later described Jolson's delivery as "electric."

Crosby graduated from Gonzaga High School (today's Gonzaga Prep) in 1920 and enrolled at Gonzaga University. He attended Gonzaga for three years but did not earn a degree. As a freshman, he played on the university's baseball team. The university granted him an honorary doctorate in 1937. Today, Gonzaga University houses a large collection of photographs, correspondence, and other material related to Crosby.

In 1923, Crosby was invited to join a new band composed of high-school students a few years younger than himself. Al Rinker, Miles Rinker, James Heaton, Claire Pritchard and Robert Pritchard, along with drummer Crosby, formed the Musicaladers, who performed at dances both for high-school students and club-goers. The group performed on Spokane radio station KHQ, but disbanded after two years. Crosby and Al Rinker then obtained work at the Clemmer Theatre in Spokane (now known as the Bing Crosby Theater). Crosby was initially a member of a vocal trio called 'The Three Harmony Aces' with Al Rinker accompanying on piano from the pit, to entertain between the films. Bing and Al continued at the Clemmer Theatre for several months often with three other men – Wee Georgie Crittenden, Frank McBride and Lloyd Grinnell – and they were billed The Clemmer Trio or The Clemmer Entertainers depending who performed.

In October 1925, Crosby and his partner Al Rinker, brother of singer Mildred Bailey, decided to seek fame in California. They traveled to Los Angeles where they met Bailey. She introduced them to her show business contacts. The Fanchon and Marco Time Agency hired them for thirteen weeks for the revue "The Syncopation Idea" starting at the Boulevard Theater in Los Angeles and then on the Loew's circuit. They each earned $75 a week. As minor parts of "The Syncopation Idea" Crosby and Rinker started to develop as entertainers. They had a lively style that was popular with college students. After "The Syncopation Idea" closed, they worked in the Will Morrissey Music Hall Revue. They honed their skills with Morrissey. When they got a chance to present an independent act, they were spotted by the Paul Whiteman organization. Whiteman needed something different to break up his musical selections, and Crosby and Rinker filled this requirement. After less than a year in show business, they were attached to one of the biggest names. Hired for $150 a week in 1926, they debuted with Whiteman on December 6 at the Tivoli Theatre in Chicago. Their first recording, in October 1926, was "I've Got the Girl" with Don Clark's Orchestra, but the Columbia-issued record was inadvertently recorded at a slow speed, which increased the singers' pitch when played at 78 rpm. Throughout his career, Crosby often credited Bailey for getting him his first important job in the entertainment business.

Success with Whiteman was followed by disaster when they reached New York. Whiteman considered letting them go. However, the addition of pianist and aspiring songwriter Harry Barris made the difference, and "The Rhythm Boys" were born. The additional voice meant they could be heard more easily in large New York theaters. Crosby gained valuable experience on tour for a year with Whiteman and performing and recording with Bix Beiderbecke, Jack Teagarden, Tommy Dorsey, Jimmy Dorsey, Eddie Lang, and Hoagy Carmichael. He matured as a performer and was in demand as a solo singer.

Crosby became the star attraction of the Rhythm Boys. In 1928 he had his first number one hit, a jazz-influenced rendition of "Ol' Man River". In 1929, the Rhythm Boys appeared in the film "King of Jazz" with Whiteman, but Crosby's growing dissatisfaction with Whiteman led to the Rhythm Boys leaving his organization. They joined the Gus Arnheim Orchestra, performing nightly in the Cocoanut Grove of the Ambassador Hotel. Singing with the Arnheim Orchestra, Crosby's solos began to steal the show while the Rhythm Boys act gradually became redundant. Harry Barris wrote several of Crosby's hits, including "At Your Command", "I Surrender Dear", and "Wrap Your Troubles in Dreams". When Mack Sennett signed Crosby to a solo recording contract in 1931, a break with the Rhythm Boys became almost inevitable. Crosby married Dixie Lee in September 1930. After a threat of divorce in March 1931, he applied himself to his career.

On September 2, 1931, Crosby made his nationwide solo radio debut. Before the end of the year, he signed with both Brunswick and CBS Radio. Doing a weekly 15-minute radio broadcast, Crosby became a hit. "Out of Nowhere", "Just One More Chance", "At Your Command" and "I Found a Million Dollar Baby (in a Five and Ten Cent Store)" were among the best selling songs of 1931.

Ten of the top 50 songs of 1931 included Crosby with others or as a solo act. A "Battle of the Baritones" with singer Russ Columbo proved short-lived, replaced with the slogan "Bing Was King". Crosby played the lead in a series of musical comedy short films for Mack Sennett, signed with Paramount, and starred in his first full-length film 1932's "The Big Broadcast" (1932), the first of 55 films in which he received top billing. He would appear in 79 pictures. He signed a contract with Jack Kapp's new record company, Decca, in late 1934.

His first commercial sponsor on radio was Cremo Cigars and his fame spread nationwide. After a long run in New York, he went back to Hollywood to film "The Big Broadcast". His appearances, records, and radio work substantially increased his impact. The success of his first film brought him a contract with Paramount, and he began a pattern of making three films a year. He led his radio show for Woodbury Soap for two seasons while his live appearances dwindled. His records produced hits during the Depression when sales were down. Audio engineer Steve Hoffman stated, "By the way, Bing actually saved the record business in 1934 when he agreed to support Decca founder Jack Kapp's crazy idea of lowering the price of singles from a dollar to 35 cents and getting a royalty for records sold instead of a flat fee. Bing's name and his artistry saved the recording industry. All the other artists signed to Decca after Bing did. Without him, Jack Kapp wouldn't have had a chance in hell of making Decca work and the Great Depression would have wiped out phonograph records for good."

His social life was frantic. His first son Gary was born in 1933 with twin boys following in 1934. By 1936, he replaced his former boss, Paul Whiteman, as host of the weekly NBC radio program "Kraft Music Hall", where he remained for the next ten years. "Where the Blue of the Night (Meets the Gold of the Day)", with his trademark whistling, became his theme song and signature tune.

Crosby's vocal style helped take popular singing beyond the "belting" associated with Al Jolson and Billy Murray, who had been obligated to reach the back seats in New York theaters without the aid of the microphone. As music critic Henry Pleasants noted in "The Great American Popular Singers", something new had entered American music, a style that might be called "singing in American" with conversational ease. This new sound led to the popular epithet "crooner".

Crosby admired Louis Armstrong for his musical ability, and the trumpet maestro was a formative influence on Crosby's singing style. When the two met, they immediately became friends. In 1936, Crosby exercised an option in his Paramount contract to regularly star in an out-of-house film. Signing an agreement with Columbia for a single motion picture, Crosby wanted Armstrong to appear in a screen adaptation of "The Peacock Feather" that eventually became "Pennies from Heaven". Crosby asked Harry Cohn, but Cohn had no desire to pay for the flight or to meet Armstrong's "crude, mob-linked but devoted manager, Joe Glaser." Crosby threatened to leave the film and refused to discuss the matter. Cohn gave in; Armstrong's musical scenes and comic dialogue extended his influence to the silver screen, creating more opportunities for him and other African Americans to appear in future films. Crosby also ensured behind the scenes that Armstrong received equal billing with his white co-stars. Armstrong appreciated Crosby's progressive attitudes on race, and often expressed gratitude for the role in later years.

During the Second World War, Crosby made live appearances before American troops who had been fighting in the European Theater. He learned how to pronounce German from written scripts and read propaganda broadcasts intended for German forces. The nickname "Der Bingle" was common among Crosby's German listeners and came to be used by his English-speaking fans. In a poll of U.S. troops at the close of World War II, Crosby topped the list as the person who had done the most for G.I. morale, ahead of President Franklin Delano Roosevelt, General Dwight Eisenhower, and Bob Hope.

The June 18, 1945, issue of "Life" magazine stated, "America's number one star, Bing Crosby, has won more fans, made more money than any entertainer in history. Today he is a kind of national institution." "In all, 60,000,000 Crosby discs have been marketed since he made his first record in 1931. His biggest best seller is 'White Christmas', 2,000,000 impressions of which have been sold in the U.S. and 250,000 in Great Britain." "Nine out of ten singers and bandleaders listen to Crosby's broadcasts each Thursday night and follow his lead. The day after he sings a song over the air – any song – some 50,000 copies of it are sold throughout the U.S. Time and again Crosby has taken some new or unknown ballad, has given it what is known in trade circles as the 'big goose' and made it a hit single-handed and overnight...Precisely what the future holds for Crosby neither his family nor his friends can conjecture. He has achieved greater popularity, made more money, attracted vaster audiences than any other entertainer in history. And his star is still in the ascendant. His contract with Decca runs until 1955. His contract with Paramount runs until 1954. Records which he made ten years ago are selling better than ever before. The nation's appetite for Crosby's voice and personality appears insatiable. To soldiers overseas and to foreigners he has become a kind of symbol of America, of the amiable, humorous citizen of a free land. Crosby, however, seldom bothers to contemplate his future. For one thing, he enjoys hearing himself sing, and if ever a day should dawn when the public wearies of him, he will complacently go right on singing—to himself."

The biggest hit song of Crosby's career was his recording of Irving Berlin's "White Christmas", which he introduced on a Christmas Day radio broadcast in 1941. (A copy of the recording from the radio program is owned by the estate of Bing Crosby and was loaned to "CBS Sunday Morning" for their December 25, 2011, program.) The song then appeared in his movie "Holiday Inn" (1942). His record hit the charts on October 3, 1942, and rose to No. 1 on October 31, where it stayed for 11 weeks. A holiday perennial, the song was repeatedly re-released by Decca, charting another sixteen times. It topped the charts again in 1945 and a third time in January 1947. The song remains the bestselling single of all time. According to "Guinness World Records", his recording of "White Christmas" has sold over 100 million copies around the world, with at least 50 million sales as singles. His recording was so popular that he was obliged to re-record it in 1947 using the same musicians and backup singers; the original 1942 master had become damaged due to its frequent use in pressing additional singles. Although the two versions are similar, the 1947 recording is more familiar today. In 1977, after Crosby died, the song was re-released and reached No. 5 in the UK Singles Chart. Crosby was dismissive of his role in the song's success, saying "a jackdaw with a cleft palate could have sung it successfully."

In the wake of a solid decade of headlining mainly smash hit musical comedy films in the 1930s, Crosby starred with Bob Hope and Dorothy Lamour in seven "Road to" musical comedies between 1940 and 1962, cementing Crosby and Hope as an on-and-off duo, despite never officially declaring themselves a "team" in the sense that Laurel and Hardy or Martin and Lewis (Dean Martin and Jerry Lewis) were teams. The series consists of "Road to Singapore" (1940), "Road to Zanzibar" (1941), "Road to Morocco" (1942), "Road to Utopia" (1946), "Road to Rio" (1947), "Road to Bali" (1952), and "The Road to Hong Kong" (1962). When they appeared solo, Crosby and Hope frequently made note of the other in a comically insulting fashion. They performed together countless times on stage, radio, film, and television, and made numerous brief and not so brief appearances together in movies aside from the "Road" pictures, "Variety Girl" (1947) being an example of lengthy scenes and songs together along with billing.

In the 1949 Disney animated film "The Adventures of Ichabod and Mr. Toad", Crosby provided the narration and song vocals for "The Legend of Sleepy Hollow" segment. In 1960, he starred in "High Time", a collegiate comedy with Fabian Forte and Tuesday Weld that predicted the emerging gap between him and the new young generation of musicians and actors who had begun their careers after WWII. The following year, Crosby and Hope reunited for one more "Road" movie, "The Road to Hong Kong", which teamed them up with the much younger Joan Collins and Peter Sellers. Collins was used in place of their longtime partner Dorothy Lamour, whom Crosby felt was getting too old for the role, though Hope refused to do the movie without her, and she instead made a lengthy and elaborate cameo appearance. Shortly before his death in 1977, he had planned another "Road" film in which he, Hope, and Lamour search for the Fountain of Youth.

He won an Academy Award for Best Actor for "Going My Way" in 1944 and was nominated for the 1945 sequel, "The Bells of St. Mary's". He received critical acclaim for his performance as an alcoholic entertainer in "The Country Girl" and received his third Academy Award nomination.

"The Fireside Theater" (1950) was his first television production. The series of 26-minute shows was filmed at Hal Roach Studios rather than performed live on the air. The "telefilms" were syndicated to individual television stations. He was a frequent guest on the musical variety shows of the 1950s and 1960s, appearing literally countless times on various variety shows as well as numerous late-night talk shows and his own highly rated specials. Bob Hope memorably devoted one of his monthly NBC specials to his long intermittent partnership with Crosby titled "On the Road With Bing." Crosby was associated with ABC's "The Hollywood Palace" as the show's first and most frequent guest host and appeared annually on its Christmas edition with his wife Kathryn and his younger children, and continued after "The Hollywood Palace" was eventually canceled. In the early 1970s, he made two late appearances on the "Flip Wilson Show", singing duets with the comedian. His last TV appearance was a Christmas special taped in London in September 1977 and aired weeks after his death. It was on this special that he recorded a duet of "The Little Drummer Boy" and "Peace on Earth" with rock star David Bowie. Their duet was released in 1982 as a single 45-rpm record and reached No. 3 in the UK singles charts. It has since become a staple of holiday radio and the final popular hit of Crosby's career. At the end of the 20th century, "TV Guide" listed the Crosby-Bowie duet one of the 25 most memorable musical moments of 20th-century television.

Bing Crosby Productions, affiliated with Desilu Studios and later CBS Television Studios, produced a number of television series, including Crosby's own unsuccessful ABC sitcom "The Bing Crosby Show" in the 1964–1965 season (with co-stars Beverly Garland and Frank McHugh). The company produced two ABC medical dramas, "Ben Casey" (1961–1966) and "Breaking Point" (1963–1964), the popular "Hogan's Heroes" (1965–1971) military comedy on CBS, as well as the lesser-known show "Slattery's People" (1964–1965).

Crosby was one of the first singers to exploit the intimacy of the microphone rather than use the deep, loud vaudeville style associated with Al Jolson. He was, by his own definition, a "phraser", a singer who placed equal emphasis on both the lyrics and the music. His love for jazz helped bring the genre to a wider audience. In the framework of the novelty-singing style of the Rhythm Boys, he bent notes and added off-tune phrasing, an approach that was rooted in jazz. He had already been introduced to Louis Armstrong and Bessie Smith before his first appearance on record. Crosby and Armstrong remained friends for decades. They sang "Now You Has Jazz" in the film "High Society" (1956).

During the early portion of his solo career (about 1931–1934), Crosby's emotional, often pleading style of crooning was popular. But Jack Kapp, manager of Brunswick and later Decca, talked him into dropping many of his jazzier mannerisms in favor of a clear vocal style. Crosby credited Kapp for choosing hit songs, working with many other musicians, and most importantly, diversifying his repertoire into several styles and genres. Kapp helped Crosby have number one hits in Christmas music, Hawaiian, and country music, and top-thirty hits in Irish music, French music, rhythm and blues, and ballads.

Crosby elaborated on an idea of Al Jolson's: phrasing, or the art of making a song's lyric ring true. "I used to tell Sinatra over and over," said Tommy Dorsey, "there's only one singer you ought to listen to and his name is Crosby. All that matters to him is the words, and that's the only thing that ought to for you, too."

Critic Henry Pleasants wrote:

Crosby's was among the most popular and successful musical acts of the 20th century. "Billboard" magazine used different methodologies during his career. But his chart success remains impressive: 396 chart singles, including roughly 25 No. 1 hits. Crosby had separate charting singles every year between 1931 and 1954; the annual re-release of "White Christmas" extended that streak to 1957. He had 24 separate popular singles in 1939 alone. He may have been the best selling recording artist with up to 1 billion units sold. Statistician Joel Whitburn at "Billboard" determined that Crosby was America's most successful recording act of the 1930s and again in the 1940s.

For fifteen years (1934, 1937, 1940, 1943–1954), Crosby was among the top top ten acts in box-office sales, and for five of those years (1944–1948) he topped the world. He sang four Academy Award-winning songs – "Sweet Leilani" (1937), "White Christmas" (1942), "Swinging on a Star" (1944), "In the Cool, Cool, Cool of the Evening" (1951) – and won the Academy Award for Best Actor for his role in "Going My Way" (1944).

A survey in 2000 found that with 1,077,900,000 movie tickets sold, Crosby was the third most popular actor of all time, behind Clark Gable (1,168,300,000) and John Wayne (1,114,000,000). The "International Motion Picture Almanac" lists him in a tie for second on the All Time Number One Stars List with Clint Eastwood, Tom Hanks, and Burt Reynolds. His most popular film, "White Christmas", grossed $30 million in 1954 ($ million in current value).

He received 23 gold and platinum records, according to the book "Million Selling Records". The Recording Industry Association of America did not institute its gold record certification program until 1958 when Crosby's record sales were low. Before 1958, gold records were awarded by record companies. Universal Music, owner of Crosby's Decca catalog, has never requested RIAA certification for any of his hit singles.

Crosby charted 23 "Billboard" hits from 47 recorded songs with the Andrews Sisters, whose Decca record sales were second only to Crosby's throughout the 1940s. They were his most frequent collaborators on disc from 1939 to 1952, a partnership that produced four million-selling singles: "Pistol Packin' Mama", "Jingle Bells", "Don't Fence Me In", and "South America, Take it Away". They made one film appearance together in "Road to Rio" singing "You Don't Have to Know the Language", and sang together on radio throughout the 1940s and 1950s. They appeared as guests on each other's shows and on Armed Forces Radio Service during and after World War II. The quartet's Top-10 "Billboard" hits from 1943 to 1945 include "The Vict'ry Polka", "There'll Be a Hot Time in the Town of Berlin (When the Yanks Go Marching In)", and "Is You Is or Is You Ain't (Ma' Baby?)" and helped morale of the American public.

In 1962, Crosby was given the Grammy Lifetime Achievement Award. He has been inducted into the halls of fame for both radio and popular music. In 2007 he was inducted into the Hit Parade Hall of Fame and in 2008 the Western Music Hall of Fame.

During the Golden Age of Radio, performers had to create their shows live, sometimes even redoing the program a second time for the west coast time zone. Crosby had to do two live radio shows on the same day, three hours apart, for the East and West Coasts. Crosby's radio career took a significant turn in 1945, when he clashed with NBC over his insistence that he be allowed to pre-record his radio shows. (The live production of radio shows was also reinforced by the musicians' union and ASCAP, which wanted to ensure continued work for their members.) In "On the Air: The Encyclopedia of Old-Time Radio", John Dunning wrote about German engineers having developed a tape recorder with a near-professional broadcast quality standard:
Crosby's insistence eventually factored into the further development of magnetic tape sound recording and the radio industry's widespread adoption of it. He used his clout, both professional and financial, for innovations in audio. But NBC and CBS refused to broadcast prerecorded radio programs. Crosby left the network and remained off the air for seven months, creating a legal battle with his sponsor Kraft that was settled out of court. He returned to broadcasting for the last 13 weeks of the 1945–1946 season.

The Mutual network, on the other hand, pre-recorded some of its programs as early as 1938 for "The Shadow" with Orson Welles. ABC was formed from the sale of the NBC Blue Network in 1943 after a federal antitrust suit and was willing to join Mutual in breaking the tradition. ABC offered Crosby $30,000 per week to produce a recorded show every Wednesday that would be sponsored by Philco. He would get an additional $40,000 from 400 independent stations for the rights to broadcast the 30-minute show, which was sent to them every Monday on three 16-inch (40-cm) lacquer discs that played ten minutes per side at 33 rpm.

Crosby wanted to change to recorded production for several reasons. The legend that has been most often told is that it would give him more time for golf. He did record his first "Philco Radio Time" program in August 1947 so he could enter the Jasper National Park Invitational Golf Tournament in September when the radio season was to start. But golf was not the most important reason. He wanted better quality recording, the ability to eliminate mistakes and the need to perform a second live show for the West Coast, and to control the timing of his performances. Because Bing Crosby Enterprises produced the show, he could purchase the best audio equipment and arrange the microphones his way; microphone placement had been debated in studios since the beginning of the electrical era. He would no longer have to wear the toupee that CBS and NBC required for his live audience shows—he preferred a hat. He could also record short promotions for his latest investment, the world's first frozen orange juice, sold under the brand name Minute Maid. This investment allowed him to make more money by finding a loophole where the IRS couldn't tax him at a 77% rate.

Murdo MacKenzie of Bing Crosby Enterprises had seen a demonstration of the German Magnetophon in June 1947—the same device that Jack Mullin had brought back from Radio Frankfurt with 50 reels of tape, at the end of the war. It was one of the magnetic tape recorders that BASF and AEG had built in Germany starting in 1935. The 6.5mm ferric-oxide-coated tape could record 20 minutes per reel of high-quality sound. Alexander M. Poniatoff ordered Ampex, which he founded in 1944, to manufacture an improved version of the Magnetophone.

Crosby hired Mullin to start recording his "Philco Radio Time" show on his German-made machine in August 1947 using the same 50 reels of I.G. Farben magnetic tape that Mullin had found at a radio station at Bad Nauheim near Frankfurt while working for the U.S. Army Signal Corps. The advantage was editing. As Crosby wrote in his autobiography:
Mullin's 1976 memoir of these early days of experimental recording agrees with Crosby's account:
Crosby invested US$50,000 in Ampex with the intent to produce more machines. In 1948, the second season of Philco shows was recorded with the Ampex Model 200A and Scotch 111 tape from 3M. Mullin explained how one new broadcasting technique was invented on the Crosby show with these machines:

Crosby started the tape recorder revolution in America. In his 1950 film "Mr. Music", he is seen singing into an Ampex tape recorder that reproduced his voice better than anything else. Also quick to adopt tape recording was his friend Bob Hope. He gave one of the first Ampex Model 300 recorders to his friend, guitarist Les Paul, which led to Paul's invention of multitrack recording. His organization, the Crosby Research Foundation, held tape recording patents and developed equipment and recording techniques such as the laugh track that are still in use today.

With Frank Sinatra, Crosby was of the principal backers for the United Western Recorders studio complex in Los Angeles.

Mullin continued to work for Crosby to develop a videotape recorder (VTR). Television production was mostly live television in its early years, but Crosby wanted the same ability to record that he had achieved in radio. "The Fireside Theater" (1950) sponsored by Procter & Gamble, was his first television production. Mullin had not yet succeeded with videotape, so Crosby filmed the series of 26-minute shows at the Hal Roach Studios, and the "telefilms" were syndicated to individual television stations.

Crosby continued to finance the development of videotape. Bing Crosby Enterprises gave the world's first demonstration of videotape recording in Los Angeles on November 11, 1951. Developed by John T. Mullin and Wayne R. Johnson since 1950, the device aired what were described as "blurred and indistinct" images, using a modified Ampex 200 tape recorder and standard quarter-inch (6.3 mm) audio tape moving at 360 inches (9.1 m) per second.

A Crosby-led group purchased station KCOP-TV, in Los Angeles, California, in 1954. NAFI Corporation and Crosby purchased television station KPTV in Portland, Oregon, for $4 million on September 1, 1959. In 1960, NAFI purchased KCOP from Crosby's group. In the early 1950s, Crosby helped establish the CBS television affiliate in his hometown of Spokane, Washington. He partnered with Ed Craney, who owned the CBS radio affiliate KXLY (AM) and built a television studio west of Crosby's alma mater, Gonzaga University. After it began broadcasting, the station was sold within a year to Northern Pacific Radio and Television Corporation.

Crosby was a fan of thoroughbred horse racing and bought his first racehorse in 1935. In 1937, he became a founding partner of the Del Mar Thoroughbred Club and a member of its board of directors. Operating from the Del Mar Racetrack at Del Mar, California, the group included millionaire businessman Charles S. Howard, who owned a successful racing stable that included Seabiscuit. Charles' son, Lindsay C. Howard, became one of Crosby's closest friends; Crosby named his son Lindsay after him, and would purchase his 40-room Hillsborough, California estate from Lindsay in 1965.

Crosby and Lindsay Howard formed Binglin Stable to race and breed thoroughbred horses at a ranch in Moorpark in Ventura County, California. They also established the Binglin stock farm in Argentina, where they raced horses at Hipódromo de Palermo in Palermo, Buenos Aires. A number of Argentine-bred horses were purchased and shipped to race in the United States. On August 12, 1938, the Del Mar Thoroughbred Club hosted a $25,000 winner-take-all match race won by Charles S. Howard's Seabiscuit over Binglin's horse Ligaroti. In 1943, Binglin's horse Don Bingo won the Suburban Handicap at Belmont Park in Elmont, New York.

The Binglin Stable partnership came to an end in 1953 as a result of a liquidation of assets by Crosby, who needed to raise enough funds to pay the hefty federal and state inheritance taxes on his deceased wife's estate. The Bing Crosby Breeders' Cup Handicap at Del Mar Racetrack is named in his honor.

Crosby had an interest in sports. In the 1930s, his friend and former college classmate, Gonzaga head coach Mike Pecarovich appointed Crosby as an assistant football coach. From 1946 until his death, he owned a 25% share of the Pittsburgh Pirates. Although he was passionate about the team, he was too nervous to watch the deciding Game 7 of the 1960 World Series, choosing to go to Paris with Kathryn and listen to its radio broadcast. Crosby had arranged for Ampex, another of his financial investments, to record the NBC telecast on kinescope. The game was one of the most famous in baseball history, capped off by Bill Mazeroski's walk-off home run. He apparently viewed the complete film just once, and then stored it in his wine cellar, where it remained undisturbed until it was discovered in December 2009. The restored broadcast was shown on MLB Network in December 2010.

Crosby was also an avid golfer, and in 1978, he and Bob Hope were voted the Bob Jones Award, the highest honor given by the United States Golf Association in recognition of distinguished sportsmanship. He is a member of the World Golf Hall of Fame. In 1937, Crosby hosted the first 'Crosby Clambake' as it was popularly known, at Rancho Santa Fe Golf Club in Rancho Santa Fe, California, the event's location prior to World War II. Sam Snead won the first tournament, in which the first place check was for $500. After the war, the event resumed play in 1947 on golf courses in Pebble Beach, where it has been played ever since. Now the AT&T Pebble Beach Pro-Am, it has been a leading event in the world of professional golf.

Crosby first took up golf at 12 as a caddy, dropped it, and started again in 1930 with some fellow cast members in Hollywood during the filming of "The King of Jazz". Crosby was accomplished at the sport, with a two handicap. He competed in both the British and U.S. Amateur championships, was a five-time club champion at Lakeside Golf Club in Hollywood, and once made a hole-in-one on the 16th at Cypress Point.

Crosby was a keen fisherman especially in his younger days but it was a pastime that he enjoyed throughout his life. In the summer of 1966 he spent a week as the guest of Lord Egremont, staying in Cockermouth and fishing on the River Derwent. His trip was filmed for "The American Sportsman" on ABC, although all did not go well at first as the salmon were not running. He did make up for it at the end of the week by catching a number of sea trout.

Crosby was married twice. His first wife was actress and nightclub singer Dixie Lee to whom he was married from 1930 until her death from ovarian cancer in 1952. They had four sons: Gary, twins Dennis and Phillip, and Lindsay. The "" (1947) is based on Lee's life. The Crosby family lived at 10500 Camarillo Street in North Hollywood for over five years. After his wife died, Crosby had relationships with model Pat Sheehan (who married his son Dennis in 1958) and actresses Inger Stevens and Grace Kelly before marrying actress Kathryn Grant, who converted to Catholicism, in 1957. They had three children: Harry Lillis III (who played Bill in "Friday the 13th"), Mary (best known for portraying Kristin Shepard on TV's "Dallas"), and Nathaniel (the 1981 U.S. Amateur champion in golf).

Crosby reportedly had an alcohol problem in his youth, and may have been dismissed from Paul Whiteman's orchestra because of it, but he later got a handle on his drinking. According to Giddins, Crosby told his son Gary to stay away from alcohol, adding, "It killed your mother" and suggesting he smoke marijuana instead. Crosby told Barbara Walters in a 1977 televised interview that he thought marijuana should be legalized.

After Crosby's death, his eldest son, Gary, wrote a highly critical memoir, "Going My Own Way", depicting his father as cruel, cold, remote, and physically and psychologically abusive.

Crosby's younger son Phillip vociferously disputed his brother Gary's claims about their father. Around the time Gary made his claims, Phillip stated to the press that "Gary is a whining, bitching crybaby, walking around with a two-by-four on his shoulder and just daring people to nudge it off." Nevertheless, Phillip did not deny that Crosby believed in corporal punishment. In an interview with "People", Phillip stated that "we never got an extra whack or a cuff we didn't deserve." During an interview in 1999 by the "Globe", Phillip said:

However, Dennis and Lindsay Crosby confirmed that Bing sometimes subjected his sons to harsh physical discipline and verbal put-downs. Regarding the writing of Gary's memoir, Lindsay said, "I'm glad [Gary] did it. I hope it clears up a lot of the old lies and rumors." Unlike Gary, though, Lindsay stated that he preferred to remember "all the good things I did with my dad and forget the times that were rough." When the book was published, Dennis distanced himself by calling it "Gary's business" but did not publicly deny its claims. Bing's younger brother, singer and jazz bandleader Bob Crosby, recalled at the time of Gary's revelations that Bing was a "disciplinarian," as their mother and father had been. He added, "We were brought up that way." In an interview for the same article, Gary clarified that Bing "was like a lot of fathers of that time. He was not out to be vicious, to beat children for his kicks."

Crosby's will established a blind trust in which none of the sons received an inheritance until they reached the age of 65.

Lindsay Crosby died in 1989 at age 51, and Dennis Crosby died in 1991 at age 56, both by suicide from self-inflicted gunshot wounds. Gary Crosby died of lung cancer in 1995 at age 62, and Phillip Crosby died of a heart attack in 2004 at age 69.

Widow Kathryn Crosby dabbled in local theater productions intermittently and appeared in television tributes to her late husband.

Nathaniel Crosby, Crosby's younger son from his second marriage, is a former high-level golfer who won the U.S. Amateur in 1981 at age 19, becoming the youngest winner in the history of that event at the time. Harry Crosby is an investment banker who occasionally makes singing appearances.

Denise Crosby, Dennis Crosby's daughter, is also an actress and is known for her role as Tasha Yar on "" and for the recurring role of the Romulan Sela after her withdrawal from the series as a regular cast member. She also appeared in the film adaptation of Stephen King's novel "Pet Sematary".

In 2006, Crosby's niece through his sister Mary Rose, Carolyn Schneider, published the laudatory book "Me and Uncle Bing".

There have been disputes between Crosby's two families beginning in the late 1990s. When Dixie died in 1952, her will provided that her share of the community property be distributed in trust to her sons. After Crosby's death in 1977, he left the residue of his estate to a marital trust for the benefit of his widow, Kathryn, and HLC Properties, Ltd., was formed for the purpose of managing his interests, including his right of publicity. In 1996, Dixie's trust sued HLC and Kathryn for declaratory relief as to the trust's entitlement to interest, dividends, royalties, and other income derived from the community property of Crosby and Dixie. In 1999, the parties settled for approximately $1.5 million. Relying on a retroactive amendment to the California Civil Code, Dixie's trust brought suit again, in 2010, alleging that Crosby's right of publicity was community property, and that Dixie's trust was entitled to a share of the revenue it produced. The trial court granted Dixie's trust's claim. The California Court of Appeal reversed, however, holding that the 1999 settlement barred the claim. In light of the court's ruling, it was unnecessary for the court to decide whether a right of publicity can be characterized as community property under California law.

Following his recovery from a life-threatening fungal infection of his right lung in January 1974, Crosby emerged from semi-retirement to start a new spate of albums and concerts. In March 1977, after videotaping a concert at the Ambassador Auditorium in Pasadena for CBS to commemorate his 50th anniversary in show business, and with Bob Hope looking on, Crosby fell off the stage into an orchestra pit, rupturing a disc in his back requiring a month in the hospital. His first performance after the accident was his last American concert, on August 16, 1977 (the day singer Elvis Presley died). When the electric power failed during his performance, he continued singing without amplification.

In September, Crosby, his family and singer Rosemary Clooney began a concert tour of Britain that included two weeks at the London Palladium. While in the UK, Crosby recorded his final album, "Seasons", and his final TV Christmas special with guest David Bowie on September 11 (which aired a little over a month after Crosby's death). His last concert was in the Brighton Centre on October 10, four days before his death, with British entertainer Dame Gracie Fields in attendance. The following day he made his final appearance in a recording studio and sang eight songs at the BBC Maida Vale studios for a radio program, which also included an interview with Alan Dell. Accompanied by the Gordon Rose Orchestra, Crosby's last recorded performance was of the song "Once in a While". Later that afternoon, he met with Chris Harding to take photographs for the "Seasons" album jacket.
On October 13, 1977, Crosby flew alone to Spain to play golf and hunt partridge. On October 14, at the La Moraleja Golf Course near Madrid, Crosby played 18 holes of golf. His partner was World Cup champion Manuel Piñero; their opponents were club president César de Zulueta and Valentín Barrios. According to Barrios, Crosby was in good spirits throughout the day, and was photographed several times during the round. At the ninth hole, construction workers building a house nearby recognized him, and when asked for a song, Crosby sang "Strangers in the Night". Crosby, who had a 13 handicap, lost to his partner by one stroke. As Crosby and his party headed back to the clubhouse, Crosby said, "That was a great game of golf, fellas." However his last words were reportedly, "That was a great game of golf, fellas" and then "Let's get a Coke." At about 6:30 pm, Crosby collapsed about 20 yards from the clubhouse entrance and died instantly from a massive heart attack. At the clubhouse and later in the ambulance, house physician Dr. Laiseca tried to revive him, but was unsuccessful. At Reina Victoria Hospital he was administered the last rites of the Catholic Church and was pronounced dead. On October 18, following a private funeral Mass at St. Paul's Catholic Church in Westwood, Crosby was buried at Holy Cross Cemetery in Culver City, California. A plaque was placed at the golf course in his memory.

He is a member of the National Association of Broadcasters Hall of Fame in the radio division.

The family created an official website on October 14, 2007, the 30th anniversary of Crosby's death.

In his autobiography "Don't Shoot, It's Only Me!" (1990), Bob Hope wrote, "Dear old Bing. As we called him, the "Economy-sized Sinatra". And what a voice. God I miss that voice. I can't even turn on the radio around Christmas time without crying anymore."

Calypso musician Roaring Lion wrote a tribute song in 1939 titled "Bing Crosby", in which he wrote: "Bing has a way of singing with his very heart and soul / Which captivates the world / His millions of listeners never fail to rejoice / At his golden voice ..."

Bing Crosby Stadium in Front Royal, Virginia, was named after Crosby in honor of his fundraising and cash contributions for its construction from 1948 to 1950.

In 2006, the former Metropolitan Theater of Performing Arts ('The Met') in Spokane, Washington was renamed to The Bing Crosby Theater.

On June 25, 2019, "The New York Times Magazine" listed Bing Crosby among hundreds of artists whose material was reportedly destroyed in the 2008 Universal fire.

Crosby wrote or co-wrote lyrics to 22 songs. His composition "At Your Command" was no. 1 for three weeks on the U.S. pop singles chart beginning on August 8, 1931. "I Don't Stand a Ghost of a Chance With You" was his most successful composition, recorded by Duke Ellington, Frank Sinatra, Thelonious Monk, Billie Holiday, and Mildred Bailey, among others. Songs co-written by Crosby include:


Four performances by Bing Crosby have been inducted into the Grammy Hall of Fame, which is a special Grammy award established in 1973 to honor recordings that are at least 25 years old and that have "qualitative or historical significance".






</doc>
<doc id="4011" url="https://en.wikipedia.org/wiki?curid=4011" title="Base">
Base

Base or BASE may refer to:










</doc>
<doc id="4012" url="https://en.wikipedia.org/wiki?curid=4012" title="Basel Convention">
Basel Convention

The Basel Convention on the Control of Transboundary Movements of Hazardous Wastes and Their Disposal, usually known as the Basel Convention, is an international treaty that was designed to reduce the movements of hazardous waste between nations, and specifically to prevent transfer of hazardous waste from developed to less developed countries (LDCs). It does not, however, address the movement of radioactive waste. The Convention is also intended to minimize the amount and toxicity of wastes generated, to ensure their environmentally sound management as closely as possible to the source of generation, and to assist LDCs in environmentally sound management of the hazardous and other wastes they generate.

The Convention was opened for signature on 22 March 1989, and entered into force on 5 May 1992. As of October 2018, 186 states and the European Union are parties to the Convention. Haiti and the United States have signed the Convention but not ratified it.

With the tightening of environmental laws (for example, RCRA) in developed nations in the 1970s, disposal costs for hazardous waste rose dramatically. At the same time, globalization of shipping made transboundary movement of waste more accessible, and many LDCs were desperate for foreign currency. Consequently, the trade in hazardous waste, particularly to LDCs, grew rapidly.

One of the incidents which led to the creation of the Basel Convention was the "Khian Sea" waste disposal incident, in which a ship carrying incinerator ash from the city of Philadelphia in the United States dumped half of its load on a beach in Haiti before being forced away. It sailed for many months, changing its name several times. Unable to unload the cargo in any port, the crew was believed to have dumped much of it at sea.

Another is the 1988 Koko case in which five ships transported 8,000 barrels of hazardous waste from Italy to the small town of Koko in Nigeria in exchange for $100 monthly rent which was paid to a Nigerian for the use of his farmland.

These practices have been deemed "Toxic Colonialism" by many developing countries.

At its meeting that took place from 27 November to 1 December 2006, the Conference of the parties of the Basel Agreement focused on issues of electronic waste and the dismantling of ships.

According to Maureen Walsh, only around 4% of hazardous wastes that come from OECD countries are actually shipped across international borders. These wastes include, among others, chemical waste, radioactive waste, municipal solid waste, asbestos, incinerator ash, and old tires. Of internationally shipped waste that comes from developed countries, more than half is shipped for recovery and the remainder for final disposal.

Increased trade in recyclable materials has led to an increase in a market for used products such as computers. This market is valued in billions of dollars. At issue is the distinction when used computers stop being a "commodity" and become a "waste".

As of October 2018, there are 187 parties to the treaty, which includes 184 UN member states, the Cook Islands, the European Union, and the State of Palestine. The nine UN member states that are not party to the treaty are East Timor, Fiji, Grenada, Haiti, San Marino, Solomon Islands, South Sudan, Tuvalu, and United States.

A waste falls under the scope of the Convention if it is within the category of wastes listed in Annex I of the Convention and it exhibits one of the hazardous characteristics contained in Annex III. 
In other words, it must both be listed and possess a characteristic such as being explosive, flammable, toxic, or corrosive. The other way that a waste may fall under the scope of the Convention is if it is defined as or considered to be a hazardous waste under the laws of either the exporting country, the importing country, or any of the countries of transit.

The definition of the term disposal is made in Article 2 al 4 and just refers to annex IV, which gives a list of operations which are understood as disposal or recovery. Examples of disposal are broad, including recovery and recycling.

Alternatively, to fall under the scope of the Convention, it is sufficient for waste to be included in Annex II, which lists other wastes, such as household wastes and residue that comes from incinerating household waste.

Radioactive waste that is covered under other international control systems and wastes from the normal operation of ships are not covered.

Annex IX attempts to define "commodities" which are not considered wastes and which would be excluded.

In addition to conditions on the import and export of the above wastes, there are stringent requirements for notice, consent and tracking for movement of wastes across national boundaries. It is of note that the Convention places a general prohibition on the exportation or importation of wastes between Parties and non-Parties. The exception to this rule is where the waste is subject to another treaty that does not take away from the Basel Convention. The United States is a notable non-Party to the Convention and has a number of such agreements for allowing the shipping of hazardous wastes to Basel Party countries.

The OECD Council also has its own control system that governs the trans-boundary movement of hazardous materials between OECD member countries. This allows, among other things, the OECD countries to continue trading in wastes with countries like the United States that have not ratified the Basel Convention.

Parties to the Convention must honor import bans of other Parties.

Article 4 of the Basel Convention calls for an overall reduction of waste generation. By encouraging countries to keep wastes within their boundaries and as close as possible to its source of generation, the internal pressures should provide incentives for waste reduction and pollution prevention. Parties are generally prohibited from exporting covered wastes to, or import covered waste from, non-parties to the convention.

The Convention states that illegal hazardous waste traffic is criminal but contains no enforcement provisions.

According to Article 12, Parties are directed to adopt a protocol that establishes liability rules and procedures that are appropriate for damage that comes from the movement of hazardous waste across borders.

Current consensus is that as space is not classed as a "country" under the specific definition, export of e-waste to non terrestrial locations would not be covered. This has been suggested (somewhat laughably) as a way to deal with the "Fridge Mountain" and related deposits of waste in the UK and elsewhere in the event of a way to cheaply access space such as an orbital tether being built.

After the initial adoption of the Convention, some least developed countries and environmental organizations argued that it did not go far enough. Many nations and NGOs argued for a total ban on shipment of all hazardous waste to LDCs. In particular, the original Convention did not prohibit waste exports to any location except Antarctica but merely required a notification and consent system known as "prior informed consent" or PIC. Further, many waste traders sought to exploit the good name of recycling and begin to justify all exports as moving to recycling destinations. Many believed a full ban was needed including exports for recycling. These concerns led to several regional waste trade bans, including the Bamako Convention.

Lobbying at 1995 Basel conference by LDCs, Greenpeace and several European countries such as Denmark, led to the adoption of an amendment to the convention in 1995 termed the Basel Ban Amendment to the Basel Convention. The amendment has been accepted by 86 countries and the European Union, but has not entered into force (as that requires ratification by 3/4 of the member states to the Convention). On September 6, 2019, Croatia became the 97th country to ratify the Amendment which will enter into force after 90 days on December 5, 2019. The Amendment prohibits the export of hazardous waste from a list of developed (mostly OECD) countries to developing countries. The Basel Ban applies to export for any reason, including recycling. An area of special concern for advocates of the Amendment was the sale of ships for salvage, shipbreaking. The Ban Amendment was strenuously opposed by a number of industry groups as well as nations including Australia and Canada. The number of ratification for the entry-into force of the Ban Amendment is under debate: Amendments to the convention enter into force after ratification of "three-fourths of the Parties who accepted them" [Art. 17.5]; so far, the Parties of the Basel Convention could not yet agree whether this would be three fourth of the Parties that were Party to the Basel Convention when the Ban was adopted, or three fourth of the current Parties of the Convention [see Report of COP 9 of the Basel Convention]. The status of the amendment ratifications can be found on the Basel Secretariat's web page. The European Union fully implemented the Basel Ban in its Waste Shipment Regulation (EWSR), making it legally binding in all EU member states. Norway and Switzerland have similarly fully implemented the Basel Ban in their legislation.

In the light of the blockage concerning the entry into force of the Ban amendment, Switzerland and Indonesia have launched a "Country-led Initiative" (CLI) to discuss in an informal manner a way forward to ensure that the trans boundary movements of hazardous wastes, especially to developing countries and countries with economies in the transition, do not lead to an unsound management of hazardous wastes. This discussion aims at identifying and finding solutions to the reasons why hazardous wastes are still brought to countries that are not able to treat them in a safe manner. It is hoped that the CLI will contribute to the realization of the objectives of the Ban Amendment. The Basel Convention's website informs about the progress of this initiative.





</doc>
<doc id="4013" url="https://en.wikipedia.org/wiki?curid=4013" title="Bar Kokhba (album)">
Bar Kokhba (album)

Bar Kokhba is a double album by John Zorn, recorded between 1994 and 1996. It features music from Zorn's "Masada" project, rearranged for small ensembles. It also features the original soundtrack from "The Art of Remembrance – Simon Wiesenthal", a film by Hannah Heer and Werner Schmiedel (1994–95).

The AllMusic review by Marc Gilman awarded the album 4½ stars noting that "While some compositions retain their original structure and sound, some are expanded and probed by Zorn's arrangements, and resemble avant-garde classical music more than jazz. But this is the beauty of the album; the ensembles provide a forum for Zorn to expand his compositions. The album consistently impresses."
"All compositions by John Zorn"



</doc>
<doc id="4015" url="https://en.wikipedia.org/wiki?curid=4015" title="BASIC">
BASIC

BASIC (Beginners' All-purpose Symbolic Instruction Code) is a family of general-purpose, high-level programming languages whose design philosophy emphasizes ease of use. The original version was designed by John G. Kemeny and Thomas E. Kurtz and released at Dartmouth College in 1964. They wanted to enable students in fields other than science and mathematics to use computers. At the time, nearly all use of computers required writing custom software, which was something only scientists and mathematicians tended to learn.

In addition to the language itself, Kemeny and Kurtz developed the Dartmouth Time Sharing System (DTSS), which allowed multiple users to edit and run BASIC programs at the same time. This general model became very popular on minicomputer systems like the PDP-11 and Data General Nova in the late 1960s and early 1970s. Hewlett-Packard produced an entire computer line for this method of operation, introducing the HP2000 series in the late 1960s and continuing sales into the 1980s. Many early video games trace their history to one of these versions of BASIC.

The emergence of early microcomputers in the mid-1970s led to the development of the original Microsoft BASIC in 1975. Due to the tiny main memory available on these machines, often 4 kB, a variety of Tiny BASIC dialects was also created. BASIC was available for almost any system of the era, and naturally became the "de facto" programming language for the home computer systems that emerged in the late 1970s. These machines almost always had a BASIC installed by default, often in the machine's firmware or sometimes on a ROM cartridge.

BASIC fell from use during the later 1980s as newer machines with far greater capabilities came to market and other programming languages (such as Pascal and C) became tenable. In 1991, Microsoft released Visual Basic, combining a greatly updated version of BASIC with a visual forms builder. This reignited use of the language and "VB" remains a major programming language in the form of VB.NET.

John G. Kemeny was the math department chairman at Dartmouth College. Based largely on his reputation as an innovator in math teaching, in 1959 the school won an Alfred P. Sloan Foundation award for $500,000 to build a new department building. Thomas E. Kurtz had joined the department in 1956, and from the 1960s Kemeny and Kurtz agreed on the need for programming literacy among students outside the traditional STEM fields. Kemeny later noted that "Our vision was that every student on campus should have access to a computer, and any faculty member should be able to use a computer in the classroom whenever appropriate. It was as simple as that."

Kemeny and Kurtz had made two previous experiments with simplified languages, DARSIMCO (Dartmouth Simplified Code) and DOPE (Dartmouth Oversimplified Programming Experiment). These did not progress past a single freshman class. New experiments using Fortran and ALGOL followed, but Kurtz concluded these languages were too tricky for what they desired. As Kurtz noted, Fortran had numerous oddly-formed commands, notably an "almost impossible-to-memorize convention for specifying a loop: 'DO 100, I = 1, 10, 2'. Is it '1, 10, 2' or '1, 2, 10', and is the comma after the line number required or not?"

Moreover, the lack of any sort of immediate feedback was a key problem; the machines of the era used batch processing and took a long time to complete a run of a program. Kurtz suggested that time-sharing offered a solution; a single machine could divide up its processing time among many users, giving them the illusion of having a slow computer to themselves. Small programs would return results in a few seconds. This led to increasing interest in a system using time-sharing and a new language specifically for use by non-STEM students.

Kemeny wrote the first version of BASIC. The acronym "BASIC" comes from the name of an unpublished paper by Thomas Kurtz. The new language was heavily patterned on FORTRAN II; statements were one-to-a-line, numbers were used to indicate the target of loops and branches, and many of the commands were similar or identical. However, the syntax was changed wherever it could be improved. For instance, the difficult to remember codice_1 loop was replaced by the much easier to remember codice_2, and the line number used in the DO was instead indicated by the codice_3. Likewise, the cryptic codice_4 statement of Fortran, whose syntax matched a particular instruction of the machine on which it was originally written, became the simpler codice_5. These changes made the language much less idiosyncratic while still having an overall structure and feel similar to the original FORTRAN.

The project received a $300,000 grant from the National Science Foundation, which was used to purchase a GE-225 computer for processing, and a Datanet-30 realtime processor to handle the Teletype Model 33 teleprinters used for input and output. A team of a dozen undergraduates worked on the project for about a year, writing both the DTSS system and the BASIC compiler. The main CPU was later replaced by a GE-235, and still later by a GE-635.

The first version BASIC language was released on 1 May 1964.

One of the graduate students on the implementation team was Mary Kenneth Keller, one of the first people in the United States to earn a Ph.D. in computer science and the first woman to do so.

Initially, BASIC concentrated on supporting straightforward mathematical work, with matrix arithmetic support from its initial implementation as a batch language, and character string functionality being added by 1965.
Wanting use of the language to become widespread, its designers made the compiler available free of charge. (In the 1960s, software became a chargeable commodity; until then, it was provided without charge as a service with the very expensive computers, usually available only to lease.) They also made it available to high schools in the Hanover, New Hampshire area and put considerable effort into promoting the language. In the following years, as other dialects of BASIC appeared, Kemeny and Kurtz's original BASIC dialect became known as "Dartmouth BASIC".

New Hampshire recognized the accomplishment in 2019 when it erected a highway historical marker recognizing the creation of BASIC.

Knowledge of the relatively simple BASIC became widespread for a computer language, and it was implemented by a number of manufacturers, becoming fairly popular on newer minicomputers, such as the DEC PDP series, where BASIC-PLUS was an extended dialect for use on the RSTS/E time-sharing operating system. The BASIC language was available for the Data General Nova, and also central to the HP Time-Shared BASIC system in the late 1960s and early 1970s, where the language was implemented as an interpreter. A version was a core part of the Pick operating system from 1973 onward, where a compiler renders it into bytecode, able to be interpreted by a virtual machine.

During this period a number of simple text-based games were written in BASIC, most notably Mike Mayfield's "Star Trek". A number of these were collected by DEC employee David H. Ahl and published in a newsletter he compiled. He later collected a number of these into book form, "101 BASIC Computer Games", published in 1973. During the same period, Ahl was involved in the creation of a small computer for education use, an early personal computer. When management refused to support the concept, Ahl left DEC in 1974 to found the seminal computer magazine, "Creative Computing". The book remained popular, and was re-published on several occasions.

The introduction of the first microcomputers in the mid-1970s was the start of explosive growth for BASIC. It had the advantage that it was fairly well known to the young designers and computer hobbyists who took an interest in microcomputers. Despite Dijkstra's famous judgement in 1975, "It is practically impossible to teach good programming to students that have had a prior exposure to BASIC: as potential programmers they are mentally mutilated beyond hope of regeneration", BASIC was one of the few languages that was both high-level enough to be usable by those without training and small enough to fit into the microcomputers of the day, making it the de facto standard programming language on early microcomputers.

The first microcomputer version of BASIC was co-written by Gates, Allen, and Monte Davidoff for their newly-formed company, Micro-Soft. This was released by MITS in punch tape format for the Altair 8800 shortly after the machine itself, immediately cementing BASIC as the primary language of early microcomputers. Members of the Homebrew Computer Club began circulating copies of the program, causing Gates to write his Open Letter to Hobbyists, complaining about this early example of software piracy.

Partially in response, Bob Albrecht urged Dennis Allison to write their own variation of the language. Albrecht had seen BASIC on minicomputers and felt it would be the perfect match for new machines. How to design and implement a stripped-down version of an interpreter for the BASIC language was covered in articles by Allison in the first three quarterly issues of the "People's Computer Company" newsletter published in 1975 and implementations with source code published in "". This led to a wide variety of versions with added features or other improvements, with versions from Tom Pittman and Li-Chen Wang becoming particularly well known.

Micro-Soft, by this time Microsoft, ported their interpreter for the MOS 6502, which quickly become one of the most popular microprocessors of the 8-bit era. When new microcomputers began to appear, notably the "1977 trinity" of the TRS-80, Commodore PET and Apple II, they either included a version of the MS code, or quickly introduced new models with it. By 1978, MS BASIC was a "de facto" standard and practically every home computer of the 1980s included it in ROM. Upon boot, a BASIC interpreter in direct mode was presented.

Commodore Business Machines included Commodore BASIC, based on Microsoft BASIC. The Apple II and TRS-80 each had two versions of BASIC, a smaller introductory version introduced with the initial releases of the machines and a more advanced version developed as interest in the platforms increased. As new companies entered the field, additional versions were added that subtly changed the BASIC family. The Atari 8-bit family had its own Atari BASIC that was modified in order to fit on an 8 kB ROM cartridge. Sinclair BASIC was introduced in 1980 with the Sinclair ZX-80, and was later extended for the Sinclair ZX-81 and the Sinclair ZX Spectrum. The BBC published BBC BASIC, developed by Acorn Computers Ltd, incorporating many extra structured programming keywords and advanced floating-point operation features.

As the popularity of BASIC grew in this period, computer magazines published complete source code in BASIC for video games, utilities, and other programs. Given BASIC's straightforward nature, it was a simple matter to type in the code from the magazine and execute the program. Different magazines were published featuring programs for specific computers, though some BASIC programs were considered universal and could be used in machines running any variant of BASIC (sometimes with minor adaptations). Many books of type-in programs were also available, and in particular, Ahl published versions of the original 101 BASIC games converted into the Microsoft dialect and published it from "Creative Computing" as "BASIC Computer Games". This book, and its sequels, provided hundreds of ready-to-go programs that could be easily converted to practically any BASIC-running platform. The book reached the stores in 1978, just as the home computer market was starting off, and it became the first million-selling computer book. Later packages, such as Learn to Program BASIC would also have gaming as an introductory focus. On the business-focused CP/M computers which soon became widespread in small business environments, Microsoft BASIC (MBASIC) was one of the leading applications.

When IBM was designing the IBM PC they followed the paradigm of existing home computers in wanting to have a built-in BASIC. They sourced this from Microsoft – IBM Cassette BASIC – but Microsoft also produced several other versions of BASIC for MS-DOS/PC DOS including IBM Disk BASIC (BASIC D), IBM BASICA (BASIC A), GW-BASIC (a BASICA-compatible version that did not need IBM's ROM) and QBasic, all typically bundled with the machine. In addition they produced the Microsoft BASIC Compiler aimed at professional programmers. Turbo Pascal-publisher Borland published Turbo Basic 1.0 in 1985 (successor versions are still being marketed by the original author under the name PowerBASIC). Microsoft wrote the windowed AmigaBASIC that was supplied with version 1.1 of the pre-emptive multitasking GUI Amiga computers (late 1985 / early 1986), although the product unusually did not bear any Microsoft marks. 

These later variations introduced many extensions, such as improved string manipulation and graphics support, access to the file system and additional data types. More important were the facilities for structured programming, including additional control structures and proper subroutines supporting local variables. However, by the latter half of the 1980s, users were increasingly using pre-made applications written by others rather than learning programming themselves; while professional programmers now had a wide range of more advanced languages available on small computers. C and later C++ became the languages of choice for professional "shrink wrap" application development.

In 1991 Microsoft introduced Visual Basic, an evolutionary development of QuickBasic. It included constructs from that language such as block-structured control statements, parameterized subroutines, and optional static typing, as well as object-oriented constructs from other languages such as "With" and "For Each". The language retained some compatibility with its predecessors, such as the Dim keyword for declarations, "Gosub"/Return statements, and optional line numbers which could be used to locate errors. An important driver for the development of Visual Basic was as the new macro language for Microsoft Excel, a spreadsheet program. To the surprise of many at Microsoft who still initially marketed it as a language for hobbyists, the language came into widespread use for small custom business applications shortly after the release of VB version 3.0, which is widely considered the first relatively stable version. 

While many advanced programmers still scoffed at its use, VB met the needs of small businesses efficiently as by that time, computers running Windows 3.1 had become fast enough that many business-related processes could be completed "in the blink of an eye" even using a "slow" language, as long as large amounts of data were not involved. Many small business owners found they could create their own small, yet useful applications in a few evenings to meet their own specialized needs. Eventually, during the lengthy lifetime of VB3, knowledge of Visual Basic had become a marketable job skill. Microsoft also produced VBScript in 1996 and Visual Basic .NET in 2001. The latter has essentially the same power as C# and Java but with syntax that reflects the original Basic language.

Many other BASIC dialects have also sprung up since 1990, including the open source QB64 and FreeBASIC, inspired by QBasic, and the Visual Basic-styled RapidQ, Basic For Qt and Gambas. Modern commercial incarnations include PureBasic, PowerBASIC, Xojo, Monkey X and True BASIC (the direct successor to Dartmouth BASIC from a company controlled by Kurtz). 

Several web-based simple BASIC interpreters also now exist, including Quite BASIC and Microsoft's Small Basic. Many versions of BASIC are also now available for smartphones and tablets via the Apple App Store, or Google Play store for Android. On game consoles, an application for the Nintendo 3DS and Nintendo DSi called "Petit Computer" allows for programming in a slightly modified version of BASIC with DS button support.

Variants of BASIC are available on graphing and otherwise programmable calculators made by Texas Instruments, HP, Casio, and others.

QBasic, a version of Microsoft QuickBASIC without the linker to make EXE files, is present in the Windows NT and DOS-Windows 95 streams of operating systems and can be obtained for more recent releases like Windows 7 which do not have them. Prior to DOS 5, the Basic interpreter was GW-Basic. QuickBasic is part of a series of three languages issued by Microsoft for the home and office power user and small-scale professional development; QuickC and QuickPascal are the other two. For Windows 95 and 98, which do not have QBasic installed by default, they can be copied from the installation disc, which will have a set of directories for old and optional software; other missing commands like Exe2Bin and others are in these same directories.

The various Microsoft, Lotus, and Corel office suites and related products are programmable with Visual Basic in one form or another, including LotusScript, which is very similar to VBA 6. The Host Explorer terminal emulator uses WWB as a macro language; or more recently the programme and the suite in which it is contained is programmable in an in-house Basic variant known as Hummingbird Basic. The VBScript variant is used for programming web content, Outlook 97, Internet Explorer, and the Windows Script Host. WSH also has a Visual Basic for Applications (VBA) engine installed as the third of the default engines along with VBScript, JScript, and the numerous proprietary or open source engines which can be installed like PerlScript, a couple of Rexx-based engines, Python, Ruby, Tcl, Delphi, XLNT, PHP, and others; meaning that the two versions of Basic can be used along with the other mentioned languages, as well as LotusScript, in a WSF file, through the component object model, and other WSH and VBA constructions. VBScript is one of the languages that can be accessed by the 4Dos, 4NT, and Take Command enhanced shells. SaxBasic and WWB are also very similar to the Visual Basic line of Basic implementations. The pre-Office 97 macro language for Microsoft Word is known as WordBASIC. Excel 4 and 5 use Visual Basic itself as a macro language. Chipmunk Basic, an old school interpreter similar to BASICs of the 1970s, is available for Linux, Microsoft Windows and macOS.

The ubiquity of BASIC interpreters on personal computers was such that textbooks once included simple "Try It In BASIC" exercises that encouraged students to experiment with mathematical and computational concepts on classroom or home computers. Popular computer magazines of the day typically included type-in programs.

Futurist and sci-fi writer David Brin mourned the loss of ubiquitous BASIC in a 2006 "Salon" article as have others who first used computers during this era. In turn, the article prompted Microsoft to develop and release Small Basic. Dartmouth held a 50th anniversary celebration for BASIC on 1 May 2014, as did other organisations; at least one organisation of VBA programmers organised a 35th anniversary observance in 1999.

Dartmouth College celebrated the 50th anniversary of the BASIC language with a day of events on April 30, 2014. A short documentary film was produced for the event.






Minimal versions of BASIC had only integer variables and one- or two-letter variable names, which minimized requirements of limited and expensive memory (RAM). More powerful versions had floating-point arithmetic, and variables could be labelled with names six or more characters long. There were some problems and restrictions in early implementations; for example, Applesoft allowed variable names to be several characters long, but only the first two were significant, thus it was possible to inadvertently write a program with variables "LOSS" and "LOAN", which would be treated as being the same; assigning a value to "LOAN" would silently overwrite the value intended as "LOSS". Keywords could not be used in variables in many early BASICs; "SCORE" would be interpreted as "SC" OR "E", where OR was a keyword. String variables are usually distinguished in many microcomputer dialects by having $ suffixed to their name, and values are often identified as strings by being delimited by "double quotation marks". Arrays in BASIC could contain integers, floating point or string variables.

Some dialects of BASIC supported matrices and matrix operations, useful for the solution of sets of simultaneous linear algebraic equations. These dialects would directly support matrix operations such as assignment, addition, multiplication (of compatible matrix types), and evaluation of a determinant. Many microcomputer BASICs did not support this data type; matrix operations were still possible, but had to be programmed explicitly on array elements.

The original Dartmouth Basic was unusual in having a matrix keyword, MAT. Although not implemented by most later microprocessor derivatives, it is used in this example from the 1968 manual which averages the numbers that are input:
5 LET S = 0
10 MAT INPUT V 
20 LET N = NUM 
30 IF N = 0 THEN 99 
40 FOR I = 1 TO N 
45 LET S = S + V(I) 
50 NEXT I 
60 PRINT S/N 
70 GO TO 5 
99 END
New BASIC programmers on a home computer might start with a simple program, perhaps using the language's PRINT statement to display a message on the screen; a well-known and often-replicated example is Kernighan and Ritchie's "Hello, World!" program:
10 PRINT "Hello, World!"
20 END
An infinite loop could be used to fill the display with the message.

Most first-generation BASIC versions, such as MSX BASIC and GW-BASIC, supported simple data types, loop cycles, and arrays. The following example is written for GW-BASIC, but will work in most versions of BASIC with minimal changes:
10 INPUT "What is your name: "; U$
20 PRINT "Hello "; U$
30 INPUT "How many stars do you want: "; N
40 S$ = ""
50 FOR I = 1 TO N
60 S$ = S$ + "*"
70 NEXT I
80 PRINT S$
90 INPUT "Do you want more stars? "; A$
100 IF LEN(A$) = 0 THEN GOTO 90
110 A$ = LEFT$(A$, 1)
120 IF A$ = "Y" OR A$ = "y" THEN GOTO 30
130 PRINT "Goodbye "; U$
140 END

The resulting dialog might resemble:

Second-generation BASICs (for example, VAX Basic, SuperBASIC, True BASIC, QuickBASIC, BBC BASIC, Pick BASIC, PowerBASIC and (arguably) COMAL introduced a number of features into the language, primarily related to structured and procedure-oriented programming. Usually, line numbering is omitted from the language and replaced with labels (for GOTO) and procedures to encourage easier and more flexible design. In addition keywords and structures to support repetition, selection and procedures with local variables were introduced.

The following example is in Microsoft QuickBASIC:
REM QuickBASIC example

REM Forward declaration - allows the main code to call a
REM subroutine that is declared later in the source code
DECLARE SUB PrintSomeStars (StarCount!)

REM Main program follows
INPUT "What is your name: ", UserName$
PRINT "Hello "; UserName$
DO
LOOP WHILE UCASE$(Answer$) = "Y"
PRINT "Goodbye "; UserName$
END

REM subroutine declaration
SUB PrintSomeStars (StarCount)
END SUB
Third-generation BASIC dialects such as Visual Basic, Xojo, StarOffice Basic and BlitzMax introduced features to support object-oriented and event-driven programming paradigm. Most built-in procedures and functions are now represented as "methods" of standard objects rather than "operators". Also, the operating system became increasingly accessible to the BASIC language.

The following example is in Visual Basic .NET:

Public Module StarsProgram

End Module





</doc>
<doc id="4016" url="https://en.wikipedia.org/wiki?curid=4016" title="List of Byzantine emperors">
List of Byzantine emperors

This is a list of the Byzantine emperors from the foundation of Constantinople in 330 AD, which marks the conventional start of the Byzantine Empire (or the Eastern Roman Empire), to its fall to the Ottoman Empire in 1453 AD. Only the emperors who were recognized as legitimate rulers and exercised sovereign authority are included, to the exclusion of junior co-emperors ("symbasileis") who never attained the status of sole or senior ruler, as well as of the various usurpers or rebels who claimed the imperial title.

Traditionally, the line of Byzantine emperors is held to begin with the Roman Emperor Constantine the Great, the first Christian emperor, who rebuilt the city of Byzantium as an imperial capital, Constantinople, and who was regarded by the later emperors as the model ruler. It was under Constantine that the major characteristics of what is considered the Byzantine state emerged: a Roman polity centered at Constantinople and culturally dominated by the Greek East, with Christianity as the state religion.

The Byzantine Empire was the direct legal continuation of the eastern half of the Roman Empire following the division of the Roman Empire in 395. Emperors listed below up to Theodosius I in 395 were sole or joint rulers of the entire Roman Empire. The Western Roman Empire continued until 476. Byzantine emperors considered themselves to be rightful Roman emperors in direct succession from Augustus; the term "Byzantine" was coined by Western historiography only in the 16th century. The use of the title "Roman Emperor" by those ruling from Constantinople was not contested until after the Papal coronation of the Frankish Charlemagne as Holy Roman Emperor (25 December 800 AD), done partly in response to the Byzantine coronation of Empress Irene, whose claim, as a woman, was not recognized by Pope Leo III.

The title of all Emperors preceding Heraclius was officially ""Augustus"", although other titles such as "Dominus" were also used. Their names were preceded by "Imperator Caesar" and followed by "Augustus". Following Heraclius, the title commonly became the Greek "Basileus" (Gr. Βασιλεύς), which had formerly meant sovereign, though "Augustus" continued to be used in a reduced capacity. Following the establishment of the rival Holy Roman Empire in Western Europe, the title ""Autokrator"" (Gr. Αὐτοκράτωρ) was increasingly used. In later centuries, the Emperor could be referred to by Western Christians as the "Emperor of the Greeks". Towards the end of the Empire, the standard imperial formula of the Byzantine ruler was "[Emperor's name] in Christ, Emperor and Autocrat of the Romans" (cf. Ῥωμαῖοι and Rûm). When on occasion rendering their names and titles in Latin in the centuries following the adoption of "Basileus" and Greek language, Byzantine rulers used "Imperator" for senior emperors and "Rex" for junior emperors, as seen in coins of Michael III and his junior emperor Basil I.

In the medieval period, dynasties were common, but the principle of hereditary succession was never formalized in the Empire, and hereditary succession was a custom rather than an inviolable principle.

Although there were no formal succession laws in place within the empire which would designate a legitimate successor of Constantine XI as emperor, some of his relatives claimed the title after his death.



</doc>
<doc id="4024" url="https://en.wikipedia.org/wiki?curid=4024" title="Butterfly effect">
Butterfly effect

In chaos theory, the butterfly effect is the sensitive dependence on initial conditions in which a small change in one state of a deterministic nonlinear system can result in large differences in a later state.

The term, closely associated with the work of Edward Lorenz, is derived from the metaphorical example of the details of a tornado (the exact time of formation, the exact path taken) being influenced by minor perturbations such as the flapping of the wings of a distant butterfly several weeks earlier. Lorenz discovered the effect when he observed that runs of his weather model with initial condition data that was rounded in a seemingly inconsequential manner would fail to reproduce the results of runs with the unrounded initial condition data. A very small change in initial conditions had created a significantly different outcome.

The idea that small causes may have large effects in general and in weather specifically was earlier recognized by French mathematician and engineer Henri Poincaré and American mathematician and philosopher Norbert Wiener. Edward Lorenz's work placed the concept of "instability" of the Earth's atmosphere onto a quantitative base and linked the concept of instability to the properties of large classes of dynamic systems which are undergoing nonlinear dynamics and deterministic chaos.

In "The Vocation of Man" (1800), Johann Gottlieb Fichte says "you could not remove a single grain of sand from its place without thereby ... changing something throughout all parts of the immeasurable whole".

Chaos theory and the sensitive dependence on initial conditions were described in the literature in a particular case of the three-body problem by Henri Poincaré in 1890. He later proposed that such phenomena could be common, for example, in meteorology.

In 1898, Jacques Hadamard noted general divergence of trajectories in spaces of negative curvature. Pierre Duhem discussed the possible general significance of this in 1908.

The idea that the death of one butterfly could eventually have a far-reaching ripple effect on subsequent historical events made its earliest known appearance in "A Sound of Thunder", a 1952 short story by Ray Bradbury about time travel.

In 1961, Lorenz was running a numerical computer model to redo a weather prediction from the middle of the previous run as a shortcut. He entered the initial condition 0.506 from the printout instead of entering the full precision 0.506127 value. The result was a completely different weather scenario.

Lorenz wrote:
In 1963, Lorenz published a theoretical study of this effect in a highly cited, seminal paper called "Deterministic Nonperiodic Flow" (the calculations were performed on a Royal McBee LGP-30 computer). Elsewhere he stated: Following suggestions from colleagues, in later speeches and papers Lorenz used the more poetic butterfly. According to Lorenz, when he failed to provide a title for a talk he was to present at the 139th meeting of the American Association for the Advancement of Science in 1972, Philip Merrilees concocted "Does the flap of a butterfly’s wings in Brazil set off a tornado in Texas?" as a title. Although a butterfly flapping its wings has remained constant in the expression of this concept, the location of the butterfly, the consequences, and the location of the consequences have varied widely.

The phrase refers to the idea that a butterfly's wings might create tiny changes in the atmosphere that may ultimately alter the path of a tornado or delay, accelerate or even prevent the occurrence of a tornado in another location. The butterfly does not power or directly create the tornado, but the term is intended to imply that the flap of the butterfly's wings can "cause" the tornado: in the sense that the flap of the wings is a part of the initial conditions of an inter-connected complex web; one set of conditions leads to a tornado while the other set of conditions doesn't. The flapping wing represents a small change in the initial condition of the system, which cascades to large-scale alterations of events (compare: domino effect). Had the butterfly not flapped its wings, the trajectory of the system might have been vastly different—but it's also equally possible that the set of conditions without the butterfly flapping its wings is the set that leads to a tornado.

The butterfly effect presents an obvious challenge to prediction, since initial conditions for a system such as the weather can never be known to complete accuracy. This problem motivated the development of ensemble forecasting, in which a number of forecasts are made from perturbed initial conditions.

Some scientists have since argued that the weather system is not as sensitive to initial conditions as previously believed. David Orrell argues that the major contributor to weather forecast error is model error, with sensitivity to initial conditions playing a relatively small role. Stephen Wolfram also notes that the Lorenz equations are highly simplified and do not contain terms that represent viscous effects; he believes that these terms would tend to damp out small perturbations.

While the "butterfly effect" is often explained as being synonymous with sensitive dependence on initial conditions of the kind described by Lorenz in his 1963 paper (and previously observed by Poincaré), the butterfly metaphor was originally applied to work he published in 1969 which took the idea a step further. Lorenz proposed a mathematical model for how tiny motions in the atmosphere scale up to affect larger systems. He found that the systems in that model could only be predicted up to a specific point in the future, and beyond that, reducing the error in the initial conditions would not increase the predictability (as long as the error is not zero). This demonstrated that a deterministic system could be "observationally indistinguishable" from a non-deterministic one in terms of predictability. Recent re-examinations of this paper suggest that it offered a significant challenge to the idea that our universe is deterministic, comparable to the challenges offered by quantum physics.

Recurrence, the approximate return of a system towards its initial conditions, together with sensitive dependence on initial conditions, are the two main ingredients for chaotic motion. They have the practical consequence of making complex systems, such as the weather, difficult to predict past a certain time range (approximately a week in the case of weather) since it is impossible to measure the starting atmospheric conditions completely accurately.

A dynamical system displays sensitive dependence on initial conditions if points arbitrarily close together separate over time at an exponential rate. The definition is not topological, but essentially metrical.

If "M" is the state space for the map formula_1, then formula_1 displays sensitive dependence to initial conditions if for any x in "M" and any δ > 0, there are y in "M", with distance "d"(. , .) such that formula_3 and such that

for some positive parameter "a". The definition does not require that all points from a neighborhood separate from the base point "x", but it requires one positive Lyapunov exponent.

The simplest mathematical framework exhibiting sensitive dependence on initial conditions is provided by a particular parametrization of the logistic map:

which, unlike most chaotic maps, has a closed-form solution:

where the initial condition parameter formula_7 is given by formula_8. For rational formula_7, after a finite number of iterations formula_10 maps into a periodic sequence. But almost all formula_7 are irrational, and, for irrational formula_7, formula_10 never repeats itself – it is non-periodic. This solution equation clearly demonstrates the two key features of chaos – stretching and folding: the factor 2 shows the exponential growth of stretching, which results in sensitive dependence on initial conditions (the butterfly effect), while the squared sine function keeps formula_10 folded within the range [0, 1].

The butterfly effect is most familiar in terms of weather; it can easily be demonstrated in standard weather prediction models, for example. The climate scientists James Annan and William Connolley explain that chaos is important in the development of weather prediction methods; models are sensitive to initial conditions. They add the caveat: "Of course the existence of an unknown butterfly flapping its wings has no direct bearing on weather forecasts, since it will take far too long for such a small perturbation to grow to a significant size, and we have many more immediate uncertainties to worry about. So the direct impact of this phenomenon on weather prediction is often somewhat wrong."

The potential for sensitive dependence on initial conditions (the butterfly effect) has been studied in a number of cases in semiclassical and quantum physics including atoms in strong fields and the anisotropic Kepler problem. Some authors have argued that extreme (exponential) dependence on initial conditions is not expected in pure quantum treatments; however, the sensitive dependence on initial conditions demonstrated in classical motion is included in the semiclassical treatments developed by Martin Gutzwiller and Delos and co-workers.

Other authors suggest that the butterfly effect can be observed in quantum systems. Karkuszewski et al. consider the time evolution of quantum systems which have slightly different Hamiltonians. They investigate the level of sensitivity of quantum systems to small changes in their given Hamiltonians. Poulin et al. presented a quantum algorithm to measure fidelity decay, which "measures the rate at which identical initial states diverge when subjected to slightly different dynamics". They consider fidelity decay to be "the closest quantum analog to the (purely classical) butterfly effect". Whereas the classical butterfly effect considers the effect of a small change in the position and/or velocity of an object in a given Hamiltonian system, the quantum butterfly effect considers the effect of a small change in the Hamiltonian system with a given initial position and velocity. This quantum butterfly effect has been demonstrated experimentally. Quantum and semiclassical treatments of system sensitivity to initial conditions are known as quantum chaos.

The journalist Peter Dizikes, writing in "The Boston Globe" in 2008, notes that popular culture likes the idea of the butterfly effect, but gets it wrong. Whereas Lorenz suggested correctly with his butterfly metaphor that predictability "is inherently limited", popular culture supposes that each event can be explained by finding the small reasons that caused it. Dizikes explains: "It speaks to our larger expectation that the world should be comprehensible – that everything happens for a reason, and that we can pinpoint all those reasons, however small they may be. But nature itself defies this expectation."





</doc>
<doc id="4027" url="https://en.wikipedia.org/wiki?curid=4027" title="Borland">
Borland

Borland Software Corporation was a software company that facilitated software deployment projects. Borland was first headquartered in Scotts Valley, California, then in Cupertino, California, and now in Austin, Texas. It is now a Micro Focus International subsidiary. It was founded in 1983 by Niels Jensen, Ole Henriksen, Mogens Glad and Philippe Kahn.

Three Danish citizens, Niels Jensen, Ole Henriksen, and Mogens Glad, founded Borland Ltd. in August 1981 to develop products like Word Index for the CP/M operating system using an off-the-shelf company. However, response to the company's products at the CP/M-82 show in San Francisco showed that a U.S. company would be needed to reach the American market. They met Philippe Kahn, who had just moved to Silicon Valley, and who had been a key developer of the Micral. The three Danes had embarked, at first successfully, on marketing software first from Denmark, and later from Ireland, before running into some challenges at the time when they met Philippe Kahn. Kahn was chairman, president, and CEO of Borland Inc. from its inception in 1983 until 1995. Main shareholders at the incorporation of Borland were Niels Jensen (250,000 shares), Ole Henriksen (160,000), Mogens Glad (100,000), and Kahn (80,000).

Borland developed a series of well-regarded software development tools. Its first product was Turbo Pascal in 1983, developed by Anders Hejlsberg (who later developed .NET and C# for Microsoft) and before Borland acquired the product sold in Scandinavia under the name of Compas Pascal. 1984 saw the launch of Borland Sidekick, a time organization, notebook, and calculator utility that was an early and popular terminate and stay resident program (TSR) for DOS operating systems.

By the mid-1980s the company had become so successful that it had the largest exhibit at the 1985 West Coast Computer Faire other than IBM or AT&T. Bruce Webster reported that "the legend of Turbo Pascal has by now reached mythic proportions, as evidenced by the number of firms that, in marketing meetings, make plans to become 'the next Borland'". After Turbo Pascal and Sidekick the company successfully launched other applications such as SuperKey and Lightning, all developed in Denmark. While the Danes remained majority shareholders, board members included Kahn, Tim Berry, John Nash, and David Heller. With the assistance of John Nash and David Heller, both British members of the Borland Board, the company was taken public on London's Unlisted Securities Market (USM) in 1986. Schroders was the lead investment banker. According to the London IPO filings, the management team was Philippe Kahn as President, Spencer Ozawa as VP of Operations, Marie Bourget as CFO, and Spencer Leyton as VP of sales and business development, while all software development was continuing to take place in Denmark and later London as the Danish co-founders moved there. A first US IPO followed in 1989 after Ben Rosen joined the Borland board with Goldman Sachs as the lead banker and a second offering in 1991 with Lazard as the lead banker. All offerings were very successful and over-subscribed.

In 1985 Borland acquired Analytica and its Reflex database product. The engineering team of Analytica, managed by Brad Silverberg and including Reflex co-founder Adam Bosworth, became the core of Borland's engineering team in the USA. Brad Silverberg was VP of engineering until he left in early 1990 to head up the Personal Systems division at Microsoft. Adam Bosworth initiated and headed up the Quattro project until moving to Microsoft later in 1990 to take over the project which eventually became Access.

In 1987 Borland purchased Wizard Systems and incorporated portions of the Wizard C technology into Turbo C. Bob Jervis, the author of Wizard C became a Borland employee. Turbo C was released on May 18, 1987, and an estimated 100,000 copies were shipped in the first month of its release. This apparently drove a wedge between Borland and Niels Jensen and the other members of his team who had been working on a brand new series of compilers at their London development centre. An agreement was reached and they spun off a company called Jensen & Partners International(JPI), later TopSpeed. JPI first launched a MS-DOS compiler named JPI Modula-2, that later became TopSpeed Modula-2, and followed up with TopSpeed C, TopSpeed C++ and TopSpeed Pascal compilers for both the MS-DOS and OS/2 operating systems. The TopSpeed compiler technology exists today as the underlying technology of the Clarion 4GL programming language, a Windows development tool.

In September 1987 Borland purchased Ansa-Software, including their Paradox (version 2.0) database management tool. Richard Schwartz, a cofounder of Ansa, became Borland's CTO and Ben Rosen joined the Borland board.

The Quattro Pro spreadsheet was launched in 1989 with, at the time, a notable improvement and charting capabilities. Lotus Development, under the leadership of Jim Manzi sued Borland for copyright infringement (see Look and feel). The litigation, "Lotus Dev. Corp. v. Borland Int'l, Inc.", brought forward Borland's open standards position as opposed to Lotus' closed approach. Borland, under Kahn's leadership took a position of principle and announced that they would defend against Lotus' legal position and "fight for programmer's rights". After a decision in favor of Borland by the First Circuit Court of Appeals, the case went to the United States Supreme Court. Because Justice John Paul Stevens had recused himself, only eight Justices heard the case, and it ended in a 4–4 tie. As a result, the First Circuit decision remained standing, but the Supreme Court result, being a tie, did not bind any other court and set no national precedent.

Additionally, Borland was known for its practical and creative approach towards software piracy and intellectual property (IP), introducing its "Borland no-nonsense license agreement". This allowed the developer/user to utilize its products "just like a book"; he or she was allowed to make multiple copies of a program, as long as only one copy was in use at any point in time.

In September 1991 Borland purchased Ashton-Tate, bringing the dBase and InterBase databases to the house, in an all-stock transaction. Competition with Microsoft was fierce. Microsoft launched the competing database Microsoft Access and bought the dBase clone FoxPro in 1992, undercutting Borland's prices. During the early 1990s Borland's implementation of C and C++ outsold Microsoft's. Borland survived as a company, but no longer had the dominance in software tools that it once had. It has gone through a radical transition in products, financing, and staff, now a very different company from the one which challenged Microsoft and Lotus in the early 1990s.

The internal problems that arose with the Ashton-Tate merger were a large part of the fall. Ashton-Tate's product portfolio proved to be weak, with no provision for evolution into the GUI environment of Windows. Almost all product lines were discontinued. The consolidation of duplicate support and development offices was costly and disruptive. Worst of all, the highest revenue earner of the combined company was dBASE with no Windows version ready. Borland had an internal project to clone dBASE which was intended to run on Windows and was part of the strategy of the acquisition, but by late 1992 this was abandoned due to technical flaws and the company had to constitute a replacement team (the ObjectVision team, redeployed) headed by Bill Turpin to redo the job. Borland lacked the financial strength to project its marketing and move internal resources off other products to shore up the dBASE/W effort. Layoffs occurred in 1993 to keep the company afloat, the third instance of this in five years. By the time dBASE for Windows eventually shipped, the developer community had moved on to other products such as Clipper or FoxBase, and dBASE never regained significant share of Ashton-Tate's former market. This happened against the backdrop of the rise in Microsoft's combined Office product marketing.

A change in market conditions also contributed to Borland's fall from prominence. In the 1980s, companies had few people who understood the growing personal computer phenomenon, and so most technical people were given free rein to purchase whatever software they thought they needed. Borland had done an excellent job marketing to those with a highly technical bent. By the mid-1990s, however, companies were beginning to ask what the return was on the investment they had made in this loosely controlled PC software buying spree. Company executives were starting to ask questions that were hard for technically minded staff to answer, and so corporate standards began to be created. This required new kinds of marketing and support materials from software vendors, but Borland remained focused on the technical side of its products.

During 1993 Borland explored ties with WordPerfect as a possible way to form a suite of programs to rival Microsoft's nascent integration strategy. WordPerfect itself was struggling with a late and troubled transition to Windows. The eventual joint company effort, named Borland Office for Windows (a combination of the WordPerfect word processor, Quattro Pro spreadsheet and Paradox database) was introduced at the 1993 Comdex computer show. Borland Office never made significant in-roads against Microsoft Office. WordPerfect was then bought by Novell. In October 1994, Borland sold Quattro Pro and rights to sell up to million copies of Paradox to Novell for $140 million in cash, repositioning the company on its core software development tools and the Interbase database engine and shifting toward client-server scenarios in corporate applications. This later proved a good foundation for the shift to web development tools.

Philippe Kahn and the Borland board disagreed on how to focus the company, and Kahn resigned as chairman, CEO and president, after 12 years, in January 1995. Kahn remained on the board until November 7, 1996. Borland named Gary Wetsel as CEO, but he resigned in July 1996. William F. Miller was interim CEO until September of that year, when Whitney G. Lynn became interim president and CEO (along with other executive changes), followed by a succession of CEOs including Dale Fuller and Tod Nielsen.

The Delphi 1 rapid application development (RAD) environment was launched in 1995, under the leadership of Anders Hejlsberg.

In 1996 Borland acquired Open Environment Corporation, a Cambridge-based company founded by John J. Donovan.

On November 25, 1996, Del Yocam was hired as Borland CEO and chairman.

In 1997, Borland sold Paradox to Corel, but retained all development rights for the core BDE. In November 1997, Borland acquired Visigenic, a middleware company that was focused on implementations of CORBA.

On April 29, 1998, Borland refocused its efforts on targeting enterprise applications development. Borland hired marketing firm Lexicon Branding to come up with a new name for the company. Yocam explained that the new name, Inprise, was meant to evoke "integrating the enterprise". The idea was to integrate Borland's tools, Delphi, C++ Builder, and JBuilder with enterprise environment software, including Visigenic's implementations of CORBA, Visibroker for C++ and Java, and the new product, Application Server.

For a number of years (both before and during the Inprise name) Borland suffered from serious financial losses and poor public image. When the name was changed to Inprise, many thought Borland had gone out of business. In March 1999, dBase was sold to KSoft, Inc. which was soon renamed to dBASE Inc. (In 2004 dBASE Inc. was renamed to DataBased Intelligence, Inc.).

In 1999, Dale L. Fuller replaced Yocam. At this time Fuller's title was "interim president and CEO." The "interim" was dropped in December 2000. Keith Gottfried served in senior executive positions with the company from 2000 to 2004.

A proposed merger between Inprise and Corel was announced in February 2000, aimed at producing Linux-based products. The scheme was abandoned when Corel's shares fell and it became clear that there was really no strategic fit.

InterBase 6.0 was made available as open-source software in July 2000.

In January 2001, the Inprise name was abandoned and the company became "Borland" once more.

Under the Borland name and a new management team headed by president and CEO Dale L. Fuller, a now-smaller and profitable Borland refocused on Delphi, and created a version of Delphi and C++ Builder for Linux, both under the name Kylix. This brought Borland's expertise in integrated development environments to the Linux platform for the first time. Kylix was launched in 2001.

Plans to spin off the InterBase division as a separate company were abandoned after Borland and the people who were to run the new company could not agree on terms for the separation. Borland stopped open-source releases of InterBase and has developed and sold new versions at a fast pace.

In 2001 Delphi 6 became the first integrated development environment to support web services. All of the company's development platforms now support web services.

C#Builder was released in 2003 as a native C# development tool, competing with Visual Studio .NET. As of the 2005 release, C#Builder, Delphi for Win32, and Delphi for .NET have been combined into a single IDE called "Borland Developer Studio" (though the combined IDE is still popularly known as "Delphi"). In late 2002 Borland purchased design tool vendor TogetherSoft and tool publisher Starbase, makers of the StarTeam configuration management tool and the CaliberRM requirements management tool (eventually, CaliberRM was renamed as "Caliber"). The latest releases of JBuilder and Delphi integrate these tools to give developers a broader set of tools for development.

Former CEO Dale Fuller quit in July 2005, but remained on the board of directors. Former COO Scott Arnold took the title of interim president and chief executive officer until November 8, 2005, when it was announced that Tod Nielsen would take over as CEO effective November 9, 2005. Nielsen remained with the company until January 2009, when he accepted the position of chief operating officer at VMware; CFO Erik Prusch then took over as acting president and CEO.

In early 2007 Borland announced new branding for its focus around open application life-cycle management. In April 2007 Borland announced that it would relocate its headquarters and development facilities to Austin, Texas. It also has development centers at Singapore, Santa Ana, California, and Linz, Austria.

On May 6, 2009, the company announced it was to be acquired by Micro Focus for $75 million. The transaction was approved by Borland shareholders on July 22, 2009, with Micro Focus acquiring the company for $1.50/share. Following Micro Focus shareholder approval and the required corporate filings, the transaction was completed in late July 2009. It was estimated to have 750 employees at the time.


The products acquired from Segue Software include Silk Central, Silk Performer, and Silk Test. The Silk line was first announced in 1997. Other programs are:



Frank Borland is a mascot character for Borland products. According to Philippe Kahn, the mascot first appeared in advertisements and cover of Borland Sidekick 1.0 manual, which was in 1984 during Borland International, Inc. era. Frank Borland also appeared in Turbo Tutor - A Turbo Pascal Tutorial, Borland JBuilder 2.

A live action version of Frank Borland was made after Micro Focus plc had acquired Borland Software Corporation. This version was created by True Agency Limited. An introductory film was also made about the mascot.




</doc>
<doc id="4031" url="https://en.wikipedia.org/wiki?curid=4031" title="Buckminster Fuller">
Buckminster Fuller

Richard Buckminster Fuller (; July 12, 1895 – July 1, 1983) was an American architect, systems theorist, author, designer, inventor, and futurist.
Fuller published more than 30 books, coining or popularizing terms such as "Spaceship Earth", "Dymaxion" (house, car, map...), ephemeralization, synergetic, and "tensegrity". He also developed numerous inventions, mainly architectural designs, and popularized the widely known geodesic dome. Carbon molecules known as fullerenes were later named by scientists for their structural and mathematical resemblance to geodesic spheres.

Fuller was the second World President of Mensa from 1974 to 1983.

Fuller was born on July 12, 1895, in Milton, Massachusetts, the son of Richard Buckminster Fuller and Caroline Wolcott Andrews, and grand-nephew of Margaret Fuller, an American journalist, critic, and women's rights advocate associated with the American transcendentalism movement. The unusual middle name, Buckminster, was an ancestral family name. As a child, Richard Buckminster Fuller tried numerous variations of his name. He used to sign his name differently each year in the guest register of his family summer vacation home at Bear Island, Maine. He finally settled on R. Buckminster Fuller.

Fuller spent much of his youth on Bear Island, in Penobscot Bay off the coast of Maine. He attended Froebelian Kindergarten. He disagreed with the way geometry was taught in school, being unable to experience for himself that a chalk dot on the blackboard represented an "empty" mathematical point, or that a line could stretch off to infinity. To him these were illogical, and led to his work on synergetics. He often made items from materials he found in the woods, and sometimes made his own tools. He experimented with designing a new apparatus for human propulsion of small boats. By age 12, he had invented a 'push pull' system for propelling a rowboat by use of an inverted umbrella connected to the transom with a simple oar lock which allowed the user to face forward to point the boat toward its destination. Later in life, Fuller took exception to the term "invention".

Years later, he decided that this sort of experience had provided him with not only an interest in design, but also a habit of being familiar with and knowledgeable about the materials that his later projects would require. Fuller earned a machinist's certification, and knew how to use the press brake, stretch press, and other tools and equipment used in the sheet metal trade.

Fuller attended Milton Academy in Massachusetts, and after that began studying at Harvard College, where he was affiliated with Adams House. He was expelled from Harvard twice: first for spending all his money partying with a vaudeville troupe, and then, after having been readmitted, for his "irresponsibility and lack of interest". By his own appraisal, he was a non-conforming misfit in the fraternity environment.

Between his sessions at Harvard, Fuller worked in Canada as a mechanic in a textile mill, and later as a laborer in the meat-packing industry. He also served in the U.S. Navy in World War I, as a shipboard radio operator, as an editor of a publication, and as commander of the crash rescue boat USS "Inca". After discharge, he worked again in the meat packing industry, acquiring management experience. In 1917, he married Anne Hewlett. During the early 1920s, he and his father-in-law developed the Stockade Building System for producing light-weight, weatherproof, and fireproof housing—although the company would ultimately fail in 1927.

Buckminster Fuller recalled 1927 as a pivotal year of his life. His daughter Alexandra had died in 1922 of complications from polio and spinal meningitis just before her fourth birthday. Stanford historian, Barry Katz, found signs that around this time in his life Fuller was suffering from depression and anxiety. Fuller dwelled on his daughter's death, suspecting that it was connected with the Fullers' damp and drafty living conditions. This provided motivation for Fuller's involvement in Stockade Building Systems, a business which aimed to provide affordable, efficient housing.

In 1927, at age 32, Fuller lost his job as president of Stockade. The Fuller family had no savings, and the birth of their daughter Allegra in 1927 added to the financial challenges. Fuller drank heavily and reflected upon the solution to his family's struggles on long walks around Chicago. During the autumn of 1927, Fuller contemplated suicide by drowning in Lake Michigan, so that his family could benefit from a life insurance payment.

Fuller said that he had experienced a profound incident which would provide direction and purpose for his life. He felt as though he was suspended several feet above the ground enclosed in a white sphere of light. A voice spoke directly to Fuller, and declared:

Fuller stated that this experience led to a profound re-examination of his life. He ultimately chose to embark on "an experiment, to find what a single individual could contribute to changing the world and benefiting all humanity".

Speaking to audiences later in life, Fuller would regularly recount the story of his Lake Michigan experience, and its transformative impact on his life. Historians have been unable to identify direct evidence for this experience within the 1927 papers of Fuller's Chronofile archives, housed at Stanford University. Stanford historian Barry Katz suggests that the suicide story may be a myth which Fuller constructed later in life, to summarize this formative period of his career.

In 1927 Fuller resolved to think independently which included a commitment to "the search for the principles governing the universe and help advance the evolution of humanity in accordance with them ... finding ways of "doing more with less" to the end that all people everywhere can have more and more". By 1928, Fuller was living in Greenwich Village and spending much of his time at the popular café Romany Marie's, where he had spent an evening in conversation with Marie and Eugene O'Neill several years earlier. Fuller accepted a job decorating the interior of the café in exchange for meals, giving informal lectures several times a week, and models of the Dymaxion house were exhibited at the café. Isamu Noguchi arrived during 1929—Constantin Brâncuși, an old friend of Marie's, had directed him there—and Noguchi and Fuller were soon collaborating on several projects, including the modeling of the Dymaxion car based on recent work by Aurel Persu. It was the beginning of their lifelong friendship.

Fuller taught at Black Mountain College in North Carolina during the summers of 1948 and 1949, serving as its Summer Institute director in 1949. Fuller had been shy and withdrawn, but he was persuaded to participate in a theatrical performance of Erik Satie's The Ruse of Medusa, put on by John Cage, who was also teaching at Black Mountain. During rehearsals, under the tutelage of Arthur Penn, then a student at Black Mountain, Fuller broke through his inhibitions to become confident as a performer and speaker.

At Black Mountain, with the support of a group of professors and students, he began reinventing a project that would make him famous: the geodesic dome. Although the geodesic dome had been created 26 years earlier by Dr. Walther Bauersfeld, Fuller was awarded United States patents, even though he neglected to cite Bauersfeld's prior art in his patent applications. He is credited for popularizing this type of structure.

One of his early models was first constructed in 1945 at Bennington College in Vermont, where he lectured often. In 1949, he erected his first geodesic dome building that could sustain its own weight with no practical limits. It was in diameter and constructed of aluminium aircraft tubing and a vinyl-plastic skin, in the form of an icosahedron. To prove his design, Fuller suspended from the structure's framework several students who had helped him build it. The U.S. government recognized the importance of his work, and employed his firm Geodesics, Inc. in Raleigh, North Carolina to make small domes for the Marines. Within a few years, there were thousands of such domes around the world.

Fuller's first "continuous tension – discontinuous compression" geodesic dome (full sphere in this case) was constructed at the University of Oregon Architecture School in 1959 with the help of students. These continuous tension – discontinuous compression structures featured single force compression members (no flexure or bending moments) that did not touch each other and were 'suspended' by the tensional members.

For half of a century, Fuller developed many ideas, designs and inventions, particularly regarding practical, inexpensive shelter and transportation. He documented his life, philosophy and ideas scrupulously by a daily diary (later called the "Dymaxion Chronofile"), and by twenty-eight publications. Fuller financed some of his experiments with inherited funds, sometimes augmented by funds invested by his collaborators, one example being the Dymaxion car project.

International recognition began with the success of huge geodesic domes during the 1950s. Fuller lectured at North Carolina State University in Raleigh in 1949, where he met James Fitzgibbon, who would become a close friend and colleague. Fitzgibbon was director of Geodesics, Inc. and Synergetics, Inc. the first licensees to design geodesic domes. Thomas C. Howard was lead designer, architect and engineer for both companies. Richard Lewontin, a new faculty member in population genetics at North Carolina State University, provided Fuller with computer calculations for the lengths of the domes' edges.

Fuller began working with architect Shoji Sadao in 1954, and in 1964 they co-founded the architectural firm Fuller & Sadao Inc., whose first project was to design the large geodesic dome for the U.S. Pavilion at Expo 67 in Montreal. This building is now the "Montreal Biosphère".
In 1962, the artist and searcher John McHale wrote the first monograph on Fuller, published by George Braziller in New York.

From 1959 to 1970, Fuller taught at Southern Illinois University Carbondale (SIU). Beginning as an assistant professor, he gained full professorship in 1968, in the School of Art and Design. Working as a designer, scientist, developer, and writer, he lectured for many years around the world. He collaborated at SIU with John McHale. In 1965, they inaugurated the World Design Science Decade (1965 to 1975) at the meeting of the International Union of Architects in Paris, which was, in Fuller's own words, devoted to "applying the principles of science to solving the problems of humanity". Later in his SIU tenure, Fuller was also a visiting professor at SIU Edwardsville, where he designed the dome for the campus Religious Center.

Fuller believed human societies would soon rely mainly on renewable sources of energy, such as solar- and wind-derived electricity. He hoped for an age of "omni-successful education and sustenance of all humanity". Fuller referred to himself as "the property of universe" and during one radio interview he gave later in life, declared himself and his work "the property of all humanity". For his lifetime of work, the American Humanist Association named him the 1969 Humanist of the Year.

In 1976, Fuller was a key participant at UN Habitat I, the first UN forum on human settlements.

Fuller was awarded 28 United States patents and many honorary doctorates. In 1960, he was awarded the Frank P. Brown Medal from The Franklin Institute. Fuller was elected as an honorary member of Phi Beta Kappa in 1967, on the occasion of the 50th year reunion of his Harvard class of 1917 (from which he was expelled in his first year). He was elected a Fellow of the American Academy of Arts and Sciences in 1968. In 1968, he was elected into the National Academy of Design as an Associate member, and became a full Academician in 1970. In 1970, he received the Gold Medal award from the American Institute of Architects. In 1976, he received the St. Louis Literary Award from the Saint Louis University Library Associates. He also received numerous other awards, including the Presidential Medal of Freedom presented to him on February 23, 1983, by President Ronald Reagan.

Fuller's last filmed interview took place on June 21, 1983, in which he spoke at Norman Foster's Royal Gold Medal for architecture ceremony. His speech can be watched in the archives of the AA School of Architecture, in which he spoke after Sir Robert Sainsbury's introductory speech and Foster's keynote address.

Fuller died on July 1, 1983, 11 days before his 88th birthday. During the period leading up to his death, his wife had been lying comatose in a Los Angeles hospital, dying of cancer. It was while visiting her there that he exclaimed, at a certain point: "She is squeezing my hand!" He then stood up, suffered a heart attack, and died an hour later, at age 87. His wife of 66 years died 36 hours later. They are buried in Mount Auburn Cemetery in Cambridge, Massachusetts.

Buckminster Fuller was a Unitarian, like his grandfather Arthur Buckminster Fuller, a Unitarian minister. Fuller was also an early environmental activist, aware of the Earth's finite resources, and promoted a principle he termed "ephemeralization", which, according to futurist and Fuller disciple Stewart Brand, was defined as "doing more with less". Resources and waste from crude, inefficient products could be recycled into making more valuable products, thus increasing the efficiency of the entire process. Fuller also coined the word synergetics, a catch-all term used broadly for communicating experiences using geometric concepts, and more specifically, the empirical study of systems in transformation; his focus was on total system behavior unpredicted by the behavior of any isolated components.

Fuller was a pioneer in thinking globally, and explored energy and material efficiency in the fields of architecture, engineering and design. Citing François de Chardenèdes' opinion that petroleum, from the standpoint of its replacement cost in our current energy "budget" (essentially, the net incoming solar flux), had cost nature "over a million dollars" per U.S. gallon (US$300,000 per litre) to produce. From this point of view, its use as a transportation fuel by people commuting to work represents a huge net loss compared to their actual earnings. An encapsulation quotation of his views might best be summed up as: "There is no energy crisis, only a crisis of ignorance."

Though Fuller was concerned about sustainability and human survival under the existing socio-economic system, he remained optimistic about humanity's future. Defining wealth in terms of knowledge, as the "technological ability to protect, nurture, support, and accommodate all growth needs of life," his analysis of the condition of "Spaceship Earth" caused him to conclude that at a certain time during the 1970s, humanity had attained an unprecedented state. He was convinced that the accumulation of relevant knowledge, combined with the quantities of major recyclable resources that had already been extracted from the earth, had attained a critical level, such that competition for necessities had become unnecessary. Cooperation had become the optimum survival strategy. He declared: "selfishness is unnecessary and hence-forth unrationalizable ... War is obsolete." He criticized previous utopian schemes as too exclusive, and thought this was a major source of their failure. To work, he thought that a utopia needed to include everyone.

Fuller was influenced by Alfred Korzybski's idea of general semantics. In the 1950s, Fuller attended seminars and workshops organized by the Institute of General Semantics, and he delivered the annual Alfred Korzybski Memorial Lecture in 1955. Korzybski is mentioned in the Introduction of his book "Synergetics". The two shared a remarkable amount of similarity in their formulations of general semantics.

In his 1970 book "I Seem To Be a Verb", he wrote: "I live on Earth at present, and I don't know what I am. I know that I am not a category. I am not a thing—a noun. I seem to be a verb, an evolutionary process—an integral function of the universe."

Fuller wrote that the natural analytic geometry of the universe was based on arrays of tetrahedra. He developed this in several ways, from the close-packing of spheres and the number of compressive or tensile members required to stabilize an object in space. One confirming result was that the strongest possible homogeneous truss is cyclically tetrahedral.

He had become a guru of the design, architecture, and 'alternative' communities, such as Drop City, the community of experimental artists to whom he awarded the 1966 "Dymaxion Award" for "poetically economic" domed living structures.

Fuller was most famous for his lattice shell structures – geodesic domes, which have been used as parts of military radar stations, civic buildings, environmental protest camps and exhibition attractions. An examination of the geodesic design by Walther Bauersfeld for the Zeiss-Planetarium, built some 28 years prior to Fuller's work, reveals that Fuller's Geodesic Dome patent (U.S. 2,682,235; awarded in 1954) is the same design as Bauersfeld's.

Their construction is based on extending some basic principles to build simple "tensegrity" structures (tetrahedron, octahedron, and the closest packing of spheres), making them lightweight and stable. The geodesic dome was a result of Fuller's exploration of nature's constructing principles to find design solutions. The Fuller Dome is referenced in the Hugo Award-winning novel "Stand on Zanzibar" by John Brunner, in which a geodesic dome is said to cover the entire island of Manhattan, and it floats on air due to the hot-air balloon effect of the large air-mass under the dome (and perhaps its construction of lightweight materials).

The Dymaxion car was a vehicle designed by Fuller, featured prominently at Chicago's 1933-1934 Century of Progress World's Fair. During the Great Depression, Fuller formed the "Dymaxion Corporation" and built three prototypes with noted naval architect Starling Burgess and a team of 27 workmen — using donated money as well as a family inheritance.

Fuller associated the word "Dymaxion" with much of his work, a portmanteau of the words dynamic", maximum", and "tension" to sum up the goal of his study, "maximum gain of advantage from minimal energy input".

The Dymaxion was not an automobile "per se", but rather the 'ground-taxying mode' of a vehicle that might one day be designed to fly, land and drive — an "Omni-Medium Transport" for air, land and water. Fuller focused on the landing and taxiing qualities, and noted severe limitations in its handling. The team made constant improvements and refinements to the platform, and Fuller noted the Dymaxion "was an invention that could not be made available to the general public without considerable improvements".

The bodywork was aerodynamically designed for increased fuel efficiency and speed as well as light weight, and its platform featured a lightweight cromoly-steel hinged chassis, rear-mounted V8 engine, front-drive and three-wheels. The vehicle was steered via the third wheel at the rear, capable of 90° steering lock. Thus able to steer in a tight circle, the Dymaxion often caused a sensation, bringing nearby traffic to a halt.

Shortly after launch, a prototype crashed after being hit by another car, killing the Dymaxion's driver. The other car was driven by a local politician and was illegally removed from the accident scene, leaving reporters who arrived subsequently to blame the Dymaxion's unconventional design — though investigations exonerated the prototype. Fuller would himself later crash another prototype with his young daughter aboard.

Despite courting the interest of important figures from the auto industry, Fuller used his family inheritance to finish the second and third prototypes — eventually selling all three, dissolving "Dymaxion Corporation" and maintaining the Dymaxion was never intended as a commercial venture. One of the three original prototypes survives.

Fuller's energy-efficient and inexpensive Dymaxion house garnered much interest, but only two prototypes were ever produced. Here the term "Dymaxion" is used in effect to signify a "radically strong and light tensegrity structure". One of Fuller's Dymaxion Houses is on display as a permanent exhibit at the Henry Ford Museum in Dearborn, Michigan. Designed and developed during the mid-1940s, this prototype is a round structure (not a dome), shaped something like the flattened "bell" of certain jellyfish. It has several innovative features, including revolving dresser drawers, and a fine-mist shower that reduces water consumption. According to Fuller biographer Steve Crooks, the house was designed to be delivered in two cylindrical packages, with interior color panels available at local dealers. A circular structure at the top of the house was designed to rotate around a central mast to use natural winds for cooling and air circulation.

Conceived nearly two decades earlier, and developed in Wichita, Kansas, the house was designed to be lightweight, adapted to windy climates, cheap to produce and easy to assemble. Because of its light weight and portability, the Dymaxion House was intended to be the ideal housing for individuals and families who wanted the option of easy mobility. The design included a "Go-Ahead-With-Life Room" stocked with maps, charts, and helpful tools for travel "through time and space". It was to be produced using factories, workers, and technologies that had produced World War II aircraft. It looked ultramodern at the time, built of metal, and sheathed in polished aluminum. The basic model enclosed of floor area. Due to publicity, there were many orders during the early Post-War years, but the company that Fuller and others had formed to produce the houses failed due to management problems.

In 1967, Fuller developed a concept for an offshore floating city named Triton City and published a report on the design the following year. Models of the city aroused the interest of President Lyndon B. Johnson who, after leaving office, had them placed in the Lyndon Baines Johnson Library and Museum.

In 1969, Fuller began the Otisco Project, named after its location in Otisco, New York. The project developed and demonstrated concrete spray with mesh-covered wireforms for producing large-scale, load-bearing spanning structures built on-site, without the use of pouring molds, other adjacent surfaces or hoisting. The initial method used a circular concrete footing in which anchor posts were set. Tubes cut to length and with ends flattened were then bolted together to form a duodeca-rhombicahedron (22-sided hemisphere) geodesic structure with spans ranging to . The form was then draped with layers of ¼-inch wire mesh attached by twist ties. Concrete was sprayed onto the structure, building up a solid layer which, when cured, would support additional concrete to be added by a variety of traditional means. Fuller referred to these buildings as monolithic ferroconcrete geodesic domes. However, the tubular frame form proved problematic for setting windows and doors. It was replaced by an iron rebar set vertically in the concrete footing and then bent inward and welded in place to create the dome's wireform structure and performed satisfactorily. Domes up to three stories tall built with this method proved to be remarkably strong. Other shapes such as cones, pyramids and arches proved equally adaptable.

The project was enabled by a grant underwritten by Syracuse University and sponsored by U.S. Steel (rebar), the Johnson Wire Corp, (mesh) and Portland Cement Company (concrete). The ability to build large complex load bearing concrete spanning structures in free space would open many possibilities in architecture, and is considered as one of Fuller's greatest contributions.

Fuller, along with co-cartographer Shoji Sadao, also designed an alternative projection map, called the Dymaxion map. This was designed to show Earth's continents with minimum distortion when projected or printed on a flat surface.

In the 1960s, Fuller developed the World Game, a collaborative simulation game played on a 70-by-35-foot Dymaxion map, in which players attempt to solve world problems. The object of the simulation game is, in Fuller's words, to "make the world work, for 100% of humanity, in the shortest possible time, through spontaneous cooperation, without ecological offense or the disadvantage of anyone".

Buckminster Fuller wore thick-lensed spectacles to correct his extreme hyperopia, a condition that went undiagnosed for the first five years of his life. Fuller's hearing was damaged during his Naval service in World War I and deteriorated during the 1960s. After experimenting with bullhorns as hearing aids during the mid-1960s, Fuller adopted electronic hearing aids from the 1970s onward.

In public appearances, Fuller always wore dark-colored suits, appearing like "an alert little clergyman". Previously, he had experimented with unconventional clothing immediately after his 1927 epiphany, but found that breaking social fashion customs made others devalue or dismiss his ideas. Fuller learned the importance of physical appearance as part of one's credibility, and decided to become "the invisible man" by dressing in clothes that would not draw attention to himself. With self-deprecating humor, Fuller described this black-suited appearance as resembling a "second-rate bank clerk".

Writer Guy Davenport met him in 1965 and described him thus:

He's a dwarf, with a worker's hands, all callouses and squared fingers. He carries an ear trumpet, of green plastic, with WORLD SERIES 1965 printed on it. His smile is golden and frequent; the man's temperament is angelic, and his energy is just a touch more than that of [Robert] Gallway (champeen runner, footballeur, and swimmer). One leg is shorter than the other, and the prescription shoe worn to correct the imbalance comes from a country doctor deep in the wilderness of Maine. Blue blazer, Khrushchev trousers, and a briefcase full of Japanese-made wonderments; ...

Following his global prominence from the 1960s onward, Fuller became a frequent flier, often crossing time zones to lecture. In the 1960s and 1970s, he wore three watches simultaneously; one for the time zone of his office in Carbondale, one for the time zone of the location he would next visit, and one for the time zone he was currently in. In the 1970s, Fuller was only in 'homely' locations (his personal home in Carbondale, Illinois; his holiday retreat in Bear Island, Maine; his daughter's home in Pacific Palisades, California) roughly 65 nights per year—the other 300 nights were spent in hotel beds in the locations he visited on his lecturing and consulting circuits.

In the 1920s, Fuller experimented with polyphasic sleep, which he called "Dymaxion sleep". Inspired by the sleep habits of animals such as dogs and cats, Fuller worked until he was tired, and then slept short naps. This generally resulted in Fuller sleeping 30-minute naps every 6 hours. This allowed him "twenty-two thinking hours a day", which aided his work productivity. Fuller reportedly kept this Dymaxion sleep habit for two years, before quitting the routine because it conflicted with his business associates' sleep habits. Despite no longer personally partaking in the habit, in 1943 Fuller suggested Dymaxion sleep as a strategy that the United States could adopt to win World War II.

Despite only practicing true polyphasic sleep for a period during the 1920s, Fuller was known for his stamina throughout his life. He was described as "tireless" by Barry Farrell in "Life" magazine, who noted that Fuller stayed up all night replying to mail during Farrell's 1970 trip to Bear Island. In his seventies, Fuller generally slept for 5–8 hours per night.

Fuller documented his life copiously from 1915 to 1983, approximately of papers in a collection called the Dymaxion Chronofile. He also kept copies of all incoming and outgoing correspondence. The enormous Fuller Collection is currently housed at Stanford University.

In his youth, Fuller experimented with several ways of presenting himself: R. B. Fuller, Buckminster Fuller, but as an adult finally settled on R. Buckminster Fuller, and signed his letters as such. However, he preferred to be addressed as simply "Bucky".

Buckminster Fuller spoke and wrote in a unique style and said it was important to describe the world as accurately as possible. Fuller often created long run-on sentences and used unusual compound words (omniwell-informed, intertransformative, omni-interaccommodative, omniself-regenerative) as well as terms he himself invented.

Fuller used the word "Universe" without the definite or indefinite articles ("the" or "a") and always capitalized the word. Fuller wrote that "by Universe I mean: the aggregate of all humanity's consciously apprehended and communicated (to self or others) Experiences".

The words "down" and "up", according to Fuller, are awkward in that they refer to a planar concept of direction inconsistent with human experience. The words "in" and "out" should be used instead, he argued, because they better describe an object's relation to a gravitational center, the Earth. "I suggest to audiences that they say, 'I'm going "outstairs" and "instairs."' At first that sounds strange to them; They all laugh about it. But if they try saying in and out for a few days in fun, they find themselves beginning to realize that they are indeed going inward and outward in respect to the center of Earth, which is our Spaceship Earth. And for the first time they begin to feel real 'reality.'"

"World-around" is a term coined by Fuller to replace "worldwide". The general belief in a flat Earth died out in classical antiquity, so using "wide" is an anachronism when referring to the surface of the Earth—a spheroidal surface has area and encloses a volume but has no width. Fuller held that unthinking use of obsolete scientific ideas detracts from and misleads intuition. Other neologisms collectively invented by the Fuller family, according to Allegra Fuller Snyder, are the terms "sunsight" and "sunclipse", replacing "sunrise" and "sunset" to overturn the geocentric bias of most pre-Copernican celestial mechanics.

Fuller also invented the word "livingry," as opposed to weaponry (or "killingry"), to mean that which is in support of all human, plant, and Earth life. "The architectural profession—civil, naval, aeronautical, and astronautical—has always been the place where the most competent thinking is conducted regarding livingry, as opposed to weaponry."

As well as contributing significantly to the development of tensegrity technology, Fuller invented the term "tensegrity", a portmanteau of "tensional integrity". "Tensegrity describes a structural-relationship principle in which structural shape is guaranteed by the finitely closed, comprehensively continuous, tensional behaviors of the system and not by the discontinuous and exclusively local compressional member behaviors. Tensegrity provides the ability to yield increasingly without ultimately breaking or coming asunder."

"Dymaxion" is a portmanteau of "dynamic maximum tension". It was invented around 1929 by two admen at Marshall Field's department store in Chicago to describe Fuller's concept house, which was shown as part of a house of the future store display. They created the term utilizing three words that Fuller used repeatedly to describe his design – dynamic, maximum, and tension.

Fuller also helped to popularize the concept of Spaceship Earth: "The most important fact about Spaceship Earth: an instruction manual didn't come with it."

His concepts and buildings include:

Among the many people who were influenced by Buckminster Fuller are:
Constance Abernathy,
Ruth Asawa,
J. Baldwin,
Michael Ben-Eli,
Pierre Cabrol,
John Cage,
Joseph Clinton,
Peter Floyd,
Medard Gabel,
Michael Hays,
Ted Nelson,
David Johnston,
Peter Jon Pearce,
Shoji Sadao,
Edwin Schlossberg,
Kenneth Snelson,
Robert Anton Wilson and Stewart Brand.

An allotrope of carbon, fullerene—and a particular molecule of that allotrope C (buckminsterfullerene or buckyball) has been named after him. The Buckminsterfullerene molecule, which consists of 60 carbon atoms, very closely resembles a spherical version of Fuller's geodesic dome. The 1996 Nobel prize in chemistry was given to Kroto, Curl, and Smalley for their discovery of the fullerene.

He is quoted in the lyric of "The Tower of Babble" in the musical "Godspell": "Man is a complex of patterns and processes."

The indie band Driftless Pony Club named their 2011 album, "Buckminster", after him. All the songs within the album are based upon his life and works.

On July 12, 2004, the United States Post Office released a new commemorative stamp honoring R. Buckminster Fuller on the 50th anniversary of his patent for the geodesic dome and by the occasion of his 109th birthday. The stamp's design replicated the January 10, 1964 cover of "Time Magazine".

Fuller was the subject of two documentary films: "The World of Buckminster Fuller" (1971) and "" (1996). Additionally, filmmaker Sam Green and the band Yo La Tengo collaborated on a 2012 "live documentary" about Fuller, "The Love Song of R. Buckminster Fuller".

In June 2008, the Whitney Museum of American Art presented "Buckminster Fuller: Starting with the Universe", the most comprehensive retrospective to date of his work and ideas. The exhibition traveled to the Museum of Contemporary Art, Chicago in 2009. It presented a combination of models, sketches, and other artifacts, representing six decades of the artist's integrated approach to housing, transportation, communication, and cartography. It also featured the extensive connections with Chicago from his years spent living, teaching, and working in the city.

In 2009, a number of US companies decided to repackage spherical magnets and sell them as toys. One company, Maxfield & Oberton, told "The New York Times" that they saw the product on YouTube and decided to repackage them as ""Buckyballs"", because the magnets could self-form and hold together in shapes reminiscent of the Fuller inspired buckyballs. The buckyball toy launched at New York International Gift Fair in 2009 and sold in the hundreds of thousands, but by 2010 began to experience problems with toy safety issues and the company was forced to recall the packages that were labelled as toys.

Robert Kiyosaki's 2015 book "Second Chance" is largely about Kiyosaki's interactions with Fuller, and Fuller's unusual final book "Grunch of Giants".

In 2012, the San Francisco Museum of Modern Art hosted "The Utopian Impulse" – a show about Buckminster Fuller's influence in the Bay Area. Featured were concepts, inventions and designs for creating "free energy" from natural forces, and for sequestering carbon from the atmosphere. The show ran January through July.

Fuller is briefly mentioned in the 2014 superhero film, "", when Kitty Pride is giving a lecture to a group of students regarding utopian architecture.

In a different note, Fuller's quote "Those who play with the Devil's toys, will be brought by degree to wield his sword" was used and referenced as the first display seen in the strategy sci-fi video game "" developed by Firaxis Games.

"The House of Tomorrow", is a 2017 American independent drama film written and directed by Peter Livolsi, based on Peter Bognanni's 2010 novel of the same name, featuring Asa Butterfield, Alex Wolff, Nick Offerman, Maude Apatow, and Ellen Burstyn. Burstyn's character is obsessed by all things Buckminster Fuller providing retro-futurist tours of her geodesic home, including authentic video of Buckminster Fuller talking and sailing with Ellen Burstyn, who'd actually befriended him in real life.











</doc>
<doc id="4032" url="https://en.wikipedia.org/wiki?curid=4032" title="Bill Watterson">
Bill Watterson

William Boyd Watterson II (born July 5, 1958) is an American former cartoonist and the author of the comic strip "Calvin and Hobbes", which was syndicated from 1985 to 1995. Watterson stopped drawing "Calvin and Hobbes" at the end of 1995 with a short statement to newspaper editors and his readers that he felt he had achieved all he could in the medium. Watterson is known for his negative views on licensing and comic syndication, his efforts to expand and elevate the newspaper comic as an art-form, and his move back into private life after he stopped drawing "Calvin and Hobbes". Watterson was born in Washington, D.C., and grew up in Chagrin Falls, Ohio. The suburban Midwestern United States setting of Ohio was part of the inspiration for "Calvin and Hobbes".

Watterson was born in Washington, D.C., where his father James G. Watterson (1932–2016) worked as a patent attorney. The family relocated to Chagrin Falls, Ohio in 1965 when Watterson was six because his mother Kathryn wanted to be closer to her family and felt that the small town was a good place to raise children.

Watterson drew his first cartoon at age eight, and spent much time in childhood alone, drawing and cartooning. This continued through his school years, during which time he discovered comic strips such as "Pogo", "Krazy Kat", and Charles Schulz' "Peanuts" which subsequently inspired and influenced his desire to become a professional cartoonist. On one occasion when he was in fourth grade, he wrote a letter to Charles Schulz, who responded — to Watterson's surprise — making a big impression on him at the time. His parents encouraged him in his artistic pursuits. Later, they recalled him as a "conservative child" — imaginative, but "not in a fantasy way", and certainly nothing like the character of Calvin that he later created. Watterson found avenues for his cartooning talents throughout primary and secondary school, creating high school-themed super hero comics with his friends and contributing cartoons and art to the school newspaper and yearbook.

From 1976 to 1980, Watterson attended Kenyon College and graduated with a Bachelor of Arts degree in political science. He had already decided on a career in cartooning, but he felt his studies would help him move into editorial cartooning. At college, he continued to develop his art skills; during his sophomore year, he painted Michelangelo's "Creation of Adam" on the ceiling of his dorm room. He also contributed cartoons to the college newspaper, some of which included the original "Spaceman Spiff" cartoons.

Later, when Watterson was creating names for the characters in his comic strip, he decided on Calvin (after the Protestant reformer John Calvin) and Hobbes (after the social philosopher Thomas Hobbes), allegedly as a "tip of the hat" to Kenyon's political science department. In "The Complete Calvin and Hobbes", Watterson stated that Calvin was named for "a 16th-century theologian who believed in predestination," and Hobbes for "a 17th-century philosopher with a dim view of human nature."

Watterson wrote a brief, tongue-in-cheek autobiography in the late 1980s.

Watterson was inspired by the work of "Cincinnati Enquirer" political cartoonist Jim Borgman, a 1976 graduate of Kenyon College, who currently draws "Zits", and decided to try to follow the same career path as Borgman, who in turn offered support and encouragement to the aspiring artist. Watterson graduated in 1980 and was hired on a trial basis at the "Cincinnati Post", a competing paper of the "Enquirer". Watterson quickly discovered that the job was full of unexpected challenges which prevented him from performing his duties to the standards set for him. Not the least of these challenges was his unfamiliarity with the Cincinnati political scene, as he had never resided in or near the city, having grown up in the Cleveland area and attending college in central Ohio. The "Post" abruptly fired Watterson before his contract was up.

He then joined a small advertising agency and worked there for four years as a designer, creating grocery advertisements while also working on his own projects, including development of his own cartoon strip and contributions to "Target: The Political Cartoon Quarterly".

As a freelance artist, Watterson has drawn other works for various merchandise, including album art for his brother's band, calendars, clothing graphics, educational books, magazine covers, posters, and post cards.

Watterson has said that he works for personal fulfillment. As he told the graduating class of 1990 at Kenyon College, "It's surprising how hard we'll work when the work is done just for ourselves." "Calvin and Hobbes" was first published on November 18, 1985. In "Calvin and Hobbes Tenth Anniversary Book", he wrote that his influences included Charles Schulz's "Peanuts", Walt Kelly's "Pogo", and George Herriman's "Krazy Kat". Watterson wrote the introduction to the first volume of "The Komplete Kolor Krazy Kat". Watterson's style also reflects the influence of Winsor McCay's "Little Nemo in Slumberland".

Like many artists, Watterson incorporated elements of his life, interests, beliefs, and values into his work—for example, his hobby as a cyclist, memories of his own father's speeches about "building character", and his views on merchandising and corporations. Watterson's cat Sprite very much inspired the personality and physical features of Hobbes.

Watterson spent much of his career trying to change the climate of newspaper comics. He believed that the artistic value of comics was being undermined, and that the space which they occupied in newspapers continually decreased, subject to arbitrary whims of shortsighted publishers. Furthermore, he opined that art should not be judged by the medium for which it is created (i.e., there is no "high" art or "low" art—just art).

For years, Watterson battled against pressure from publishers to merchandise his work, something that he felt would cheapen his comic. He refused to merchandise his creations on the grounds that displaying "Calvin and Hobbes" images on commercially sold mugs, stickers, and T-shirts would devalue the characters and their personalities. Watterson said that Universal kept putting pressure on him and said that he had signed his contract without fully perusing it because, as a new artist, he was happy to find a syndicate willing to give him a chance (two syndicates had denied Watterson). He added that the contract was so one-sided that, if Universal really wanted to, they could license his characters against his will, and could even fire him but continue "Calvin and Hobbes" with a new artist. Watterson's position eventually won out and he was able to renegotiate his contract so that he would receive all rights to his work, but later added that the licensing fight exhausted him and contributed to the need for a nine-month sabbatical in 1991.

Despite Watterson's efforts, many unofficial knockoffs have been found, including items that depict Calvin and Hobbes consuming alcohol or Calvin urinating on a logo. Watterson has said, "Only thieves and vandals have made money on "Calvin and Hobbes" merchandise."

Watterson was critical of the prevailing format for the Sunday comic strip that was in place when he began drawing (and still is, to varying degrees). The typical layout consists of three rows with eight total squares, which take up half a page if published with its normal size. (In this context, half-page is an absolute sizeapproximately half a nominal page sizeand not related to the actual page size on which a cartoon might eventually be printed for distribution.) Some newspapers are restricted with space for their Sunday features and reduce the size of the strip. One of the more common ways is to cut out the top two panels, which Watterson believed forced him to waste the space on throwaway jokes that did not always fit the strip. While he was set to return from his first sabbatical (a second took place during 1994), Watterson discussed with his syndicate a new format for "Calvin and Hobbes" that would enable him to use his space more efficiently and would almost require the papers to publish it as a half-page. Universal agreed that they would sell the strip as the half-page and nothing else, which garnered anger from papers and criticism for Watterson from both editors and some of his fellow cartoonists (whom he described as "unnecessarily hot-tempered"). Eventually, Universal compromised and agreed to offer papers a choice between the full half-page or a reduced-sized version to alleviate concerns about the size issue. Watterson conceded that this caused him to lose space in many papers, but he said that, in the end, it was a benefit because he felt that he was giving the papers' readers a better strip for their money and editors were free not to run "Calvin and Hobbes" at their own risk. He added that he was not going to apologize for drawing a popular feature.

Watterson announced the end of "Calvin and Hobbes" on November 9, 1995, with the following letter to newspaper editors:

The last strip of "Calvin and Hobbes" was published on December 31, 1995.

Since the conclusion of "Calvin and Hobbes", Watterson has taken up painting, at one point drawing landscapes of the woods with his father. He has kept away from the public eye and has given no indication of resuming the strip, creating new works based on the strip's characters, or embarking on new commercial projects, though he has published several "Calvin and Hobbes" anthologies. He does not sign autographs or license his characters, staying true to his stated principles. In previous years, Watterson was known to sneak autographed copies of his books onto the shelves of the Fireside Bookshop, a family-owned bookstore in his hometown of Chagrin Falls, Ohio. He ended this practice after discovering that some of the autographed books were being sold online for high prices.

Watterson rarely gives interviews or makes public appearances. His lengthiest interviews include the cover story in "The Comics Journal" No. 127 in February 1989, an interview that appeared in a 1987 issue of "Honk Magazine", and one in a 2015 Watterson exhibition catalogue.

On December 21, 1999, a short piece was published in the "Los Angeles Times", written by Watterson to mark the forthcoming retirement of iconic "Peanuts" creator Charles Schulz.

In the years that followed the end of "Calvin and Hobbes", many attempts were made to locate Watterson in his hometown of Chagrin Falls. Both "The Plain Dealer" and the "Cleveland Scene" sent reporters in 1998 and 2003, respectively, but were unable to locate him.

In 2004, Watterson and his wife Melissa bought a home in the Cleveland suburb of Cleveland Heights, Ohio. In 2005, they completed the move from their home in Chagrin Falls to their new residence.

In or around 2003, Gene Weingarten of "The Washington Post" sent Watterson the first edition of the "Barnaby" book as an incentive, hoping to land an interview. Weingarten passed the book to Watterson's parents, along with a message, and declared that he would wait in his hotel for as long as it took Watterson to contact him. Watterson's editor Lee Salem called the next day to tell Weingarten that the cartoonist would not be coming.

In October 2005, Watterson answered 15 questions submitted by readers. In October 2007, he wrote a review of "Schulz and Peanuts", a biography of Charles Schulz, in "The Wall Street Journal".

In early 2010, Watterson was interviewed by "The Plain Dealer" on the 15th anniversary of the end of "Calvin and Hobbes". Explaining his decision to discontinue the strip, he said,

In 2008, he provided a foreword for the first book collection of Richard Thompson's "Cul de Sac" comic strip. In April 2011, a representative for Andrews McMeel received a package from a "William Watterson in Cleveland Heights, Ohio" which contained a oil-on-board painting of "Cul de Sac" character Petey Otterloop, done by Watterson for the "Team Cul de Sac" fundraising project for Parkinson's disease in honor of Richard Thompson who was diagnosed in 2009. Watterson's syndicate has since become Universal Uclick, and they said that the painting was the first new artwork of his that the syndicate has seen since "Calvin and Hobbes" ended in 1995.

In October 2013, the magazine "Mental Floss" published an interview with Watterson, only the second since the strip ended. Watterson again confirmed that he would not be revisiting "Calvin and Hobbes", and that he was satisfied with his decision. He also gave his opinion on the changes in the comic-strip industry and where it would be headed in the future:

In 2013 the documentary "Dear Mr. Watterson", exploring the cultural impact of "Calvin and Hobbes", was released.

On February 26, 2014, Watterson published his first cartoon since the end of "Calvin and Hobbes": a poster for the documentary "Stripped".

In 2014, Watterson co-authored "The Art of Richard Thompson" with Washington Post cartoonist Nick Galifianakis and David Apatoff.

In June 2014, three strips of "Pearls Before Swine" (published June 4, June 5, and June 6, 2014) featured guest illustrations by Watterson after mutual friend Nick Galifianakis connected him and cartoonist Stephan Pastis, who communicated via e-mail. Pastis likened this unexpected collaboration to getting "a glimpse of Bigfoot". "I thought maybe Stephan and I could do this goofy collaboration and then use the result to raise some money for Parkinson's research in honor of Richard Thompson. It seemed like a perfect convergence", Watterson told the "Washington Post". The day that Stephan Pastis returned to his own strip, he paid tribute to Watterson by alluding to the final strip of Calvin and Hobbes from December 31, 1995.

On November 5, 2014, a poster was unveiled, drawn by Watterson for the 2015 Angoulême International Comics Festival where he was awarded the Grand Prix in 2014.

On April 1, 2016, for April Fools' Day, Berkeley Breathed posted on Facebook that Watterson had signed "the franchise over to my 'administration'". He then posted a comic with Calvin, Hobbes, and Opus all featured. The comic is signed by Watterson, though it remains to be seen how involved he actually was. Breathed posted another "Calvin County" strip featuring Calvin and Hobbes, also "signed" by Watterson on April 1, 2017, along with a fake "The New York Times" story ostensibly detailing the "merger" of the two strips. Berkeley Breathed included Hobbes in a November 27, 2017, strip as a stand-in for the character Steve Dallas.

In 2001, Billy Ireland Cartoon Library & Museum at Ohio State University mounted an exhibition of Watterson's Sunday strips. He chose thirty-six of his favorites, displaying them with both the original drawing and the colored finished product, with most pieces featuring personal annotations. Watterson also wrote an accompanying essay that served as the foreword for the exhibit, called "Calvin and Hobbes: Sunday Pages 1985–1995", which opened on September 10, 2001. It was taken down in January 2002. The accompanying published catalog had the same title.

From March 22 to August 3, 2014, Watterson exhibited again at the Billy Ireland Cartoon Library & Museum at Ohio State University. In conjunction with this exhibition, Watterson also participated in an interview with the school. An exhibition catalog named "Exploring Calvin and Hobbes" was released with the exhibit. The book contained a lengthy interview with Bill Watterson, conducted by Jenny Robb, the curator of the museum.

Watterson was awarded the National Cartoonists Society's Reuben Award in both 1986 and 1988. Watterson's second Reuben win made him the youngest cartoonist to be so honored, and only the sixth person to win twice, following Milton Caniff, Charles Schulz, Dik Browne, Chester Gould, and Jeff MacNelly. (Gary Larson is the only cartoonist to win a second Reuben since Watterson.) In 2014, Watterson was awarded the Grand Prix at the Angoulême International Comics Festival for his body of work, becoming just the fourth non-European cartoonist to be so honored in the first 41 years of the event.


Bill Watterson has been heavily influenced by Charles M. Schulz, Walt Kelly, and George Herriman. Schulz and Kelly in particular were big influences when it came to his outlook of the comic strip format.






</doc>
<doc id="4035" url="https://en.wikipedia.org/wiki?curid=4035" title="Black">
Black

Black is the darkest color, the result of the absence or complete absorption of visible light. It is an achromatic color, a color without hue, like white and gray. It is often used symbolically or figuratively to represent darkness, while white represents light. Black and white have often been used to describe opposites such as good and evil, the Dark Ages versus Age of Enlightenment, and night versus day. Since the Middle Ages, black has been the symbolic color of solemnity and authority, and for this reason is still commonly worn by judges and magistrates, including the justices of the U.S. Supreme Court. 

Black was one of the first colors used by artists in neolithic cave paintings. In the 14th century, it was worn by royalty, clergy, judges and government officials in much of Europe. It became the color worn by English romantic poets, businessmen and statesmen in the 19th century, and a high fashion color in the 20th century. In the Roman Empire, it became the color of mourning, and over the centuries it was frequently associated with death, evil, witches and magic. According to surveys in Europe and North America, it is the color most commonly associated with mourning, the end, secrets, magic, force, violence, evil, and elegance.

Black ink is the most common color used for printing books, newspapers and documents, as it provides the highest contrast with white paper and thus the easiest color to read. Similarly, black text on a white screen is the most common format used on computer screens. 

The word "black" comes from Old English "blæc" ("black, dark", "also", "ink"), from Proto-Germanic *"blakkaz" ("burned"), from Proto-Indo-European *"bhleg-" ("to burn, gleam, shine, flash"), from base *"bhel-" ("to shine"), related to Old Saxon "blak" ("ink"), Old High German "blach" ("black"), Old Norse "blakkr" ("dark"), Dutch "blaken" ("to burn"), and Swedish "bläck" ("ink"). More distant cognates include Latin "flagrare" ("to blaze, glow, burn"), and Ancient Greek "phlegein" ("to burn, scorch").

The Ancient Greeks sometimes used the same word to name different colors, if they had the same intensity. "Kuanos"' could mean both dark blue and black.

The Ancient Romans had two words for black: "ater" was a flat, dull black, while "niger" was a brilliant, saturated black. "Ater" has vanished from the vocabulary, but "niger" was the source of the country name "Nigeria," the English word "Negro", and the word for "black" in most modern Romance languages (French: "noir"; Spanish and Portuguese: "negro"; Italian: "nero" ).

Old High German also had two words for black: "swartz" for dull black and "blach" for a luminous black. These are parallelled in Middle English by the terms "swart" for dull black and "blaek" for luminous black. "Swart" still survives as the word "swarthy", while "blaek" became the modern English "black".

In heraldry, the word used for the black color is sable, named for the black fur of the sable, an animal.

Black was one of the first colors used in art. The Lascaux Cave in France contains drawings of bulls and other animals drawn by paleolithic artists between 18,000 and 17,000 years ago. They began by using charcoal, and then made more vivid black pigments by burning bones or grinding a powder of manganese oxide.

For the ancient Egyptians, black had positive associations; being the color of fertility and the rich black soil flooded by the Nile. It was the color of Anubis, the god of the underworld, who took the form of a black jackal, and offered protection against evil to the dead.

For the ancient Greeks, black was also the color of the underworld, separated from the world of the living by the river Acheron, whose water was black. Those who had committed the worst sins were sent to Tartarus, the deepest and darkest level. In the center was the palace of Hades, the king of the underworld, where he was seated upon a black ebony throne. Black was one of the most important colors used by ancient Greek artists. In the 6th century BC, they began making black-figure pottery and later red figure pottery, using a highly original technique. In black-figure pottery, the artist would paint figures with a glossy clay slip on a red clay pot. When the pot was fired, the figures painted with the slip would turn black, against a red background. Later they reversed the process, painting the spaces between the figures with slip. This created magnificent red figures against a glossy black background.

In the social hierarchy of ancient Rome, purple was the color reserved for the Emperor; red was the color worn by soldiers (red cloaks for the officers, red tunics for the soldiers); white the color worn by the priests, and black was worn by craftsmen and artisans. The black they wore was not deep and rich; the vegetable dyes used to make black were not solid or lasting, so the blacks often turned out faded gray or brown.

In Latin, the word for black, "ater" and to darken, "atere", were associated with cruelty, brutality and evil. They were the root of the English words "atrocious" and "atrocity". Black was also the Roman color of death and mourning. In the 2nd century BC Roman magistrates began to wear a dark toga, called a "toga pulla", to funeral ceremonies. Later, under the Empire, the family of the deceased also wore dark colors for a long period; then, after a banquet to mark the end of mourning, exchanged the black for a white toga. In Roman poetry, death was called the "hora nigra", the black hour.

The German and Scandinavian peoples worshipped their own goddess of the night, Nótt, who crossed the sky in a chariot drawn by a black horse. They also feared Hel, the goddess of the kingdom of the dead, whose skin was black on one side and red on the other. They also held sacred the raven. They believed that Odin, the king of the Nordic pantheon, had two black ravens, Huginn and Muninn, who served as his agents, traveling the world for him, watching and listening.
In the early Middle Ages, black was commonly associated with darkness and evil. In Medieval paintings, the devil was usually depicted as having human form, but with wings and black skin or hair.

In fashion, black did not have the prestige of red, the color of the nobility. It was worn by Benedictine monks as a sign of humility and penitence. In the 12th century a famous theological dispute broke out between the Cistercian monks, who wore white, and the Benedictines, who wore black. A Benedictine abbot, Pierre the Venerable, accused the Cistercians of excessive pride in wearing white instead of black. Saint Bernard of Clairvaux, the founder of the Cistercians responded that black was the color of the devil, hell, "of death and sin," while white represented "purity, innocence and all the virtues".

Black symbolized both power and secrecy in the medieval world. The emblem of the Holy Roman Empire of Germany was a black eagle. The black knight in the poetry of the Middle Ages was an enigmatic figure, hiding his identity, usually wrapped in secrecy.

Black ink, invented in China, was traditionally used in the Middle Ages for writing, for the simple reason that black was the darkest color and therefore provided the greatest contrast with white paper or parchment, making it the easiest color to read. It became even more important in the 15th century, with the invention of printing. A new kind of ink, printer's ink, was created out of soot, turpentine and walnut oil. The new ink made it possible to spread ideas to a mass audience through printed books, and to popularize art through black and white engravings and prints. Because of its contrast and clarity, black ink on white paper continued to be the standard for printing books, newspapers and documents; and for the same reason black text on a white background is the most common format used on computer screens.

In the early Middle Ages, princes, nobles and the wealthy usually wore bright colors, particularly scarlet cloaks from Italy. Black was rarely part of the wardrobe of a noble family. The one exception was the fur of the sable. This glossy black fur, from an animal of the marten family, was the finest and most expensive fur in Europe. It was imported from Russia and Poland and used to trim the robes and gowns of royalty.

In the 14th century, the status of black began to change. First, high-quality black dyes began to arrive on the market, allowing garments of a deep, rich black. Magistrates and government officials began to wear black robes, as a sign of the importance and seriousness of their positions. A third reason was the passage of sumptuary laws in some parts of Europe which prohibited the wearing of costly clothes and certain colors by anyone except members of the nobility. The famous bright scarlet cloaks from Venice and the peacock blue fabrics from Florence were restricted to the nobility. The wealthy bankers and merchants of northern Italy responded by changing to black robes and gowns, made with the most expensive fabrics.

The change to the more austere but elegant black was quickly picked up by the kings and nobility. It began in northern Italy, where the Duke of Milan and the Count of Savoy and the rulers of Mantua, Ferrara, Rimini and Urbino began to dress in black. It then spread to France, led by Louis I, Duke of Orleans, younger brother of King Charles VI of France. It moved to England at the end of the reign of King Richard II (1377–1399), where all the court began to wear black. In 1419–20, black became the color of the powerful Duke of Burgundy, Philip the Good. It moved to Spain, where it became the color of the Spanish Habsburgs, of Charles V and of his son, Philip II of Spain (1527–1598). European rulers saw it as the color of power, dignity, humility and temperance. By the end of the 16th century, it was the color worn by almost all the monarchs of Europe and their courts.

While black was the color worn by the Catholic rulers of Europe, it was also the emblematic color of the Protestant Reformation in Europe and the Puritans in England and America. John Calvin, Philip Melanchthon and other Protestant theologians denounced the richly colored and decorated interiors of Roman Catholic churches. They saw the color red, worn by the Pope and his Cardinals, as the color of luxury, sin, and human folly. In some northern European cities, mobs attacked churches and cathedrals, smashed the stained glass windows and defaced the statues and decoration. In Protestant doctrine, clothing was required to be sober, simple and discreet. Bright colors were banished and replaced by blacks, browns and grays; women and children were recommended to wear white.

In the Protestant Netherlands, Rembrandt used this sober new palette of blacks and browns to create portraits whose faces emerged from the shadows expressing the deepest human emotions. The Catholic painters of the Counter-Reformation, like Rubens, went in the opposite direction; they filled their paintings with bright and rich colors. The new Baroque churches of the Counter-Reformation were usually shining white inside and filled with statues, frescoes, marble, gold and colorful paintings, to appeal to the public. But European Catholics of all classes, like Protestants, eventually adopted a sober wardrobe that was mostly black, brown and gray.
In the second part of the 17th century, Europe and America experienced an epidemic of fear of witchcraft. People widely believed that the devil appeared at midnight in a ceremony called a Black Mass or black sabbath, usually in the form of a black animal, often a goat, a dog, a wolf, a bear, a deer or a rooster, accompanied by their familiar spirits, black cats, serpents and other black creatures. This was the origin of the widespread superstition about black cats and other black animals. In medieval Flanders, in a ceremony called "Kattenstoet," black cats were thrown from the belfry of the Cloth Hall of Ypres to ward off witchcraft.

Witch trials were common in both Europe and America during this period. During the notorious Salem witch trials in New England in 1692–93, one of those on trial was accused of being able turn into a "black thing with a blue cap," and others of having familiars in the form of a black dog, a black cat and a black bird. Nineteen women and men were hanged as witches.
In the 18th century, during the European Age of Enlightenment, black receded as a fashion color. Paris became the fashion capital, and pastels, blues, greens, yellow and white became the colors of the nobility and upper classes. But after the French Revolution, black again became the dominant color.

Black was the color of the industrial revolution, largely fueled by coal, and later by oil. Thanks to coal smoke, the buildings of the large cities of Europe and America gradually turned black. By 1846 the industrial area of the West Midlands of England was "commonly called 'the Black Country'”. Charles Dickens and other writers described the dark streets and smoky skies of London, and they were vividly illustrated in the engravings of French artist Gustave Doré.

A different kind of black was an important part of the romantic movement in literature. Black was the color of melancholy, the dominant theme of romanticism. The novels of the period were filled with castles, ruins, dungeons, storms, and meetings at midnight. The leading poets of the movement were usually portrayed dressed in black, usually with a white shirt and open collar, and a scarf carelessly over their shoulder, Percy Bysshe Shelley and Lord Byron helped create the enduring stereotype of the romantic poet.

The invention of new, inexpensive synthetic black dyes and the industrialization of the textile industry meant that good-quality black clothes were available for the first time to the general population. In the 19th century gradually black became the most popular color of business dress of the upper and middle classes in England, the Continent, and America.

Black dominated literature and fashion in the 19th century, and played a large role in painting. James McNeil Whistler made the color the subject of his most famous painting, "Arrangement in grey and black number one" (1871), better known as "Whistler's Mother".

Some 19th-century French painters had a low opinion of black: "Reject black," Paul Gauguin said, "and that mix of black and white they call gray. Nothing is black, nothing is gray." But Édouard Manet used blacks for their strength and dramatic effect. Manet's portrait of painter Berthe Morisot was a study in black which perfectly captured her spirit of independence. The black gave the painting power and immediacy; he even changed her eyes, which were green, to black to strengthen the effect. Henri Matisse quoted the French impressionist Pissarro telling him, "Manet is stronger than us all – he made light with black."

Pierre-Auguste Renoir used luminous blacks, especially in his portraits. When someone told him that black was not a color, Renoir replied: "What makes you think that? Black is the queen of colors. I always detested Prussian blue. I tried to replace black with a mixture of red and blue, I tried using cobalt blue or ultramarine, but I always came back to ivory black."

Vincent van Gogh used black lines to outline many of the objects in his paintings, such as the bed in the famous painting of his bedroom. making them stand apart. His painting of black crows over a cornfield, painted shortly before he died, was particularly agitated and haunting.

In the late 19th century, black also became the color of anarchism. (See the section political movements.)

In the 20th century, black was the color of Italian and German fascism. (See the section political movements.)

In art, black regained some of the territory that it had lost during the 19th century. The Russian painter Kasimir Malevich, a member of the Suprematist movement, created the "Black Square" in 1915, is widely considered the first purely abstract painting. He wrote, "The painted work is no longer simply the imitation of reality, but is this very reality ... It is not a demonstration of ability, but the materialization of an idea."

Black was also appreciated by Henri Matisse. "When I didn't know what color to put down, I put down black," he said in 1945. "Black is a force: I used black as ballast to simplify the construction ... Since the impressionists it seems to have made continuous progress, taking a more and more important part in color orchestration, comparable to that of the double bass as a solo instrument."

In the 1950s, black came to be a symbol of individuality and intellectual and social rebellion, the color of those who didn't accept established norms and values. In Paris, it was worn by Left-Bank intellectuals and performers such as Juliette Gréco, and by some members of the Beat Movement in New York and San Francisco. Black leather jackets were worn by motorcycle gangs such as the Hells Angels and street gangs on the fringes of society in the United States. Black as a color of rebellion was celebrated in such films as "The Wild One", with Marlon Brando. By the end of the 20th century, black was the emblematic color of the punk subculture punk fashion, and the goth subculture. Goth fashion, which emerged in England in the 1980s, was inspired by Victorian era mourning dress.

In men's fashion, black gradually ceded its dominance to navy blue, particularly in business suits. Black evening dress and formal dress in general were worn less and less. In 1960, John F. Kennedy was the last American President to be inaugurated wearing formal dress; President Lyndon Johnson and all his successors were inaugurated wearing business suits.

Women's fashion was revolutionized and simplified in 1926 by the French designer Coco Chanel, who published a drawing of a simple black dress in "Vogue" magazine. She famously said, "A woman needs just three things; a black dress, a black sweater, and, on her arm, a man she loves." French designer Jean Patou also followed suit by creating a black collection in 1929. Other designers contributed to the trend of the little black dress. The Italian designer Gianni Versace said, "Black is the quintessence of simplicity and elegance," and French designer Yves Saint Laurent said, "black is the liaison which connects art and fashion. One of the most famous black dresses of the century was designed by Hubert de Givenchy and was worn by Audrey Hepburn in the 1961 film "Breakfast at Tiffany's".

The American civil rights movement in the 1950s was a struggle for the political equality of African Americans. It developed into the Black Power movement in the late 1960s and 1970s, and popularized the slogan "Black is Beautiful".

In the 1990s, the Black Standard became the banner of several Islamic extremist, jihadist groups. (See the section political movements.)

In the visible spectrum, black is the absorption of all colors. Black can be defined as the visual impression experienced when no visible light reaches the eye. Pigments or dyes that absorb light rather than reflect it back to the eye "look black". A black pigment can, however, result from a "combination" of several pigments that collectively absorb all colors. If appropriate proportions of three primary pigments are mixed, the result reflects so little light as to be called "black". This provides two superficially opposite but actually complementary descriptions of black. Black is the absorption of all colors of light, or an exhaustive combination of multiple colors of pigment.

In physics, a black body is a perfect absorber of light, but, by a thermodynamic rule, it is also the best emitter. Thus, the best radiative cooling, out of sunlight, is by using black paint, though it is important that it be black (a nearly perfect absorber) in the infrared as well. In elementary science, far ultraviolet light is called "black light" because, while itself unseen, it causes many minerals and other substances to fluoresce.

On January 16, 2008, researchers from Troy, New York's Rensselaer Polytechnic Institute announced the creation of the then darkest material on the planet. The material, which reflected only 0.045 percent of light, was created from carbon nanotubes stood on end. This is 1/30 of the light reflected by the current standard for blackness, and one third the light reflected by the previous record holder for darkest substance. As of February 2016, the current darkest material known is claimed to be Vantablack.

Absorption of light is contrasted by transmission, reflection and diffusion, where the light is only redirected, causing objects to appear transparent, reflective or white respectively. A material is said to be black if most incoming light is absorbed equally in the material. Light (electromagnetic radiation in the visible spectrum) interacts with the atoms and molecules, which causes the energy of the light to be converted into other forms of energy, usually heat. This means that black surfaces can act as thermal collectors, absorbing light and generating heat (see Solar thermal collector). 

The earliest pigments used by Neolithic man were charcoal, red ocher and yellow ocher. The black lines of cave art were drawn with the tips of burnt torches made of a wood with resin. Different charcoal pigments were made by burning different woods and animal products, each of which produced a different tone. The charcoal would be ground and then mixed with animal fat to make the pigment.

The 15th-century painter Cennino Cennini described how this pigment was made during the Renaissance in his famous handbook for artists: "...there is a black which is made from the tendrils of vines. And these tendrils need to be burned. And when they have been burned, throw some water onto them and put them out and then mull them in the same way as the other black. And this is a lean and black pigment and is one of the perfect pigments that we use."

Cennini also noted that "There is another black which is made from burnt almond shells or peaches and this is a perfect, fine black." Similar fine blacks were made by burning the pits of the peach, cherry or apricot. The powdered charcoal was then mixed with gum arabic or the yellow of an egg to make a paint.

Different civilizations burned different plants to produce their charcoal pigments. The Inuit of Alaska used wood charcoal mixed with the blood of seals to paint masks and wooden objects. The Polynesians burned coconuts to produce their pigment.

Good-quality black dyes were not known until the middle of the 14th century. The most common early dyes were made from bark, roots or fruits of different trees; usually the walnut, chestnut, or certain oak trees. The blacks produced were often more gray, brown or bluish. The cloth had to be dyed several times to darken the color. One solution used by dyers was add to the dye some iron filings, rich in iron oxide, which gave a deeper black. Another was to first dye the fabric dark blue, and then to dye it black.

A much richer and deeper black dye was eventually found made from the Oak apple or gall-nut. The gall-nut is a small round tumor which grows on oak and other varieties of trees. They range in size from 2–5 cm, and are caused by chemicals injected by the larva of certain kinds of gall wasp in the family Cynipidae. The dye was very expensive; a great quantity of gall-nuts were needed for a very small amount of dye. The gall-nuts which made the best dye came from Poland, eastern Europe, the near east and North Africa. Beginning in about the 14th century, dye from gall-nuts was used for clothes of the kings and princes of Europe.

Another important source of natural black dyes from the 17th century onwards was the logwood tree, or Haematoxylum campechianum, which also produced reddish and bluish dyes. It is a species of flowering tree in the legume family, Fabaceae, that is native to southern Mexico and northern Central America. The modern nation of Belize grew from 17th century English logwood logging camps.

Since the mid-19th century, synthetic black dyes have largely replaced natural dyes. One of the important synthetic blacks is Nigrosin, a mixture of synthetic black dyes (CI 50415, Solvent black 5) made by heating a mixture of nitrobenzene, aniline and aniline hydrochloride in the presence of a copper or iron catalyst. Its main industrial uses are as a colorant for lacquers and varnishes and in marker-pen inks.

The first known inks were made by the Chinese, and date back to the 23rd century B.C. They used natural plant dyes and minerals such as graphite ground with water and applied with an ink brush. Early Chinese inks similar to the modern inkstick have been found dating to about 256 BC at the end of the Warring States period. They were produced from soot, usually produced by burning pine wood, mixed with animal glue. To make ink from an inkstick, the stick is continuously ground against an inkstone with a small quantity of water to produce a dark liquid which is then applied with an ink brush. Artists and calligraphists could vary the thickness of the resulting ink by reducing or increasing the intensity and time of ink grinding. These inks produced the delicate shading and subtle or dramatic effects of Chinese brush painting.

India ink (or Indian ink in British English) is a black ink once widely used for writing and printing and now more commonly used for drawing, especially when inking comic books and comic strips. The technique of making it probably came from China. India ink has been in use in India since at least the 4th century BC, where it was called "masi". In India, the black color of the ink came from bone char, tar, pitch and other substances.

The Ancient Romans had a black writing ink they called "atramentum librarium". Its name came from the Latin word "atrare", which meant to make something black. (This was the same root as the English word "atrocious".) It was usually made, like India ink, from soot, although one variety, called "atramentum elephantinum", was made by burning the ivory of elephants.

Gall-nuts were also used for making fine black writing ink. Iron gall ink (also known as iron gall nut ink or oak gall ink) was a purple-black or brown-black ink made from iron salts and tannic acids from gall nut. It was the standard writing and drawing ink in Europe, from about the 12th century to the 19th century, and remained in use well into the 20th century.


The fact that outer space is black is sometimes called Olbers' paradox. In theory, because the universe is full of stars, and is believed to be infinitely large, it would be expected that the light of an infinite number of stars would be enough to brilliantly light the whole universe all the time. However, the background color of outer space is black. This contradiction was first noted in 1823 by German astronomer Heinrich Wilhelm Matthias Olbers, who posed the question of why the night sky was black.

The current accepted answer is that, although the universe is infinitely large, it is not infinitely old. It is thought to be about 13.8 billion years old, so we can only see objects as far away as the distance light can travel in 13.8 billion years. Light from stars farther away has not reached Earth, and cannot contribute to making the sky bright. Furthermore, as the universe is expanding, many stars are moving away from Earth. As they move, the wavelength of their light becomes longer, through the Doppler effect, and shifts toward red, or even becomes invisible. As a result of these two phenomena, there is not enough starlight to make space anything but black.

The daytime sky on Earth is blue because light from the Sun strikes molecules in Earth's atmosphere scattering light in all directions. Blue light is scattered more than other colors, and reaches the eye in greater quantities, making the daytime sky appear blue. This is known as Rayleigh scattering.

The nighttime sky on Earth is black because the part of Earth experiencing night is facing away from the Sun, the light of the Sun is blocked by Earth itself, and there is no other bright nighttime source of light in the vicinity. Thus, there is not enough light to undergo Rayleigh scattering and make the sky blue. On the Moon, on the other hand, because there is no atmosphere to scatter the light, the sky is black both day and night. This phenomenon also holds true for other locations without an atmosphere.

In China, the color black is associated with water, one of the five fundamental elements believed to compose all things; and with winter, cold, and the direction north, usually symbolized by a black tortoise. It is also associated with disorder, including the positive disorder which leads to change and new life. When the first Emperor of China Qin Shi Huang seized power from the Zhou Dynasty, he changed the Imperial color from red to black, saying that black extinguished red. Only when the Han Dynasty appeared in 206 BC was red restored as the imperial color.

The Chinese and Japanese character for black ("kuro" in Japanese), can, depending upon the context, also mean dark or evil.

In Japan, black is associated with mystery, the night, the unknown, the supernatural, the invisible and death. Combined with white, it can symbolize intuition. In 10th and 11th century Japan, it was believed that wearing black could bring misfortune. It was worn at court by those who wanted to set themselves apart from the established powers or who had renounced material possessions.

In Japan black can also symbolize experience, as opposed to white, which symbolizes naiveté. The black belt in martial arts symbolizes experience, while a white belt is worn by novices. Japanese men traditionally wear a black kimono with some white decoration on their wedding day.

In Indonesia black is associated with depth, the subterranean world, demons, disaster, and the left hand. When black is combined with white, however, it symbolizes harmony and equilibrium.

Anarchism is a political philosophy, most popular in the late 19th and early 20th centuries, which holds that governments and capitalism are harmful and undesirable. The symbols of anarchism was usually either a black flag or a black letter A. More recently it is usually represented with a bisected red and black flag, to emphasise the movement's socialist roots in the First International. Anarchism was most popular in Spain, France, Italy, Ukraine and Argentina. There were also small but influential movements in the United States and Russia. In the latter, the movement initially allied itself with the Bolsheviks.

The Black Army was a collection of anarchist military units which fought in the Russian Civil War, sometimes on the side of the Bolshevik Red Army, and sometimes for the opposing White Army. It was officially known as the Revolutionary Insurrectionary Army of Ukraine, and it was under the command of the famous anarchist Nestor Makhno.

Fascism. The Blackshirts () were Fascist paramilitary groups in Italy during the period immediately following World War I and until the end of World War II. The Blackshirts were officially known as the Voluntary Militia for National Security ("Milizia Volontaria per la Sicurezza Nazionale", or MVSN).

Inspired by the black uniforms of the Arditi, Italy's elite storm troops of World War I, the Fascist Blackshirts were organized by Benito Mussolini as the military tool of his political movement. They used violence and intimidation against Mussolini's opponents. The emblem of the Italian fascists was a black flag with fasces, an axe in a bundle of sticks, an ancient Roman symbol of authority. Mussolini came to power in 1922 through his March on Rome with the blackshirts.

Black was also adopted by Adolf Hitler and the Nazis in Germany. Red, white and black were the colors of the flag of the German Empire from 1870 to 1918. In "Mein Kampf", Hitler explained that they were "revered colors expressive of our homage to the glorious past." Hitler also wrote that "the new flag ... should prove effective as a large poster" because "in hundreds of thousands of cases a really striking emblem may be the first cause of awakening interest in a movement." The black swastika was meant to symbolize the Aryan race, which, according to the Nazis, "was always anti-Semitic and will always be anti-Semitic." Several designs by a number of different authors were considered, but the one adopted in the end was Hitler's personal design. Black became the color of the uniform of the SS, the "Schutzstaffel" or "defense corps", the paramilitary wing of the Nazi Party, and was worn by SS officers from 1932 until the end of World War II.

The Nazis used a black triangle to symbolize anti-social elements. The symbol originates from Nazi concentration camps, where every prisoner had to wear one of the Nazi concentration camp badges on their jacket, the color of which categorized them according to "their kind." Many Black Triangle prisoners were either mentally disabled or mentally ill. The homeless were also included, as were alcoholics, the Romani people, the habitually "work-shy," prostitutes, draft dodgers and pacifists. More recently the black triangle has been adopted as a symbol in lesbian culture and by disabled activists.

Black shirts were also worn by the British Union of Fascists before World War II, and members of fascist movements in the Netherlands.

Patriotic resistance. The Lützow Free Corps, composed of volunteer German students and academics fighting against Napoleon in 1813, could not afford to make special uniforms and therefore adopted black, as the only color that could be used to dye their civilian clothing without the original color showing. In 1815 the students began to carry a red, black and gold flag, which they believed (incorrectly) had been the colors of the Holy Roman Empire (the imperial flag had actually been gold and black). In 1848, this banner became the flag of the German confederation. In 1866, Prussia unified Germany under its rule, and imposed the red, white and black of its own flag, which remained the colors of the German flag until the end of the Second World War. In 1949 the Federal Republic of Germany returned to the original flag and colors of the students and professors of 1815, which is the flag of Germany today.

Islamism. The Black Standard ( , also known as "banner of the eagle" or simply as "the banner") is the historical flag flown by Muhammad in Islamic tradition, an eschatological symbol in Shi'a Islam (heralding the advent of the Mahdi), and a symbol used in Islamism and Jihadism.

Black has been a traditional color of cavalry and armoured or mechanized troops. German armoured troops (Panzerwaffe) traditionally wore black uniforms, and even in others, a black beret is common. In Finland, black is the symbolic color for both armoured troops and combat engineers, and military units of these specialities have black flags and unit insignia.

The black beret and the color black is also a symbol of special forces in many countries. Soviet and Russian OMON special police and Russian naval infantry wear a black beret. A black beret is also worn by military police in the Canadian, Czech, Croatian, Portuguese, Spanish and Serbian armies.

The silver-on-black skull and crossbones symbol or Totenkopf and a black uniform were used by Hussars and Black Brunswickers, the German Panzerwaffe and the Nazi Schutzstaffel, and U.S. 400th Missile Squadron (crossed missiles), and continues in use with the Estonian Kuperjanov Battalion.


In Christianity, the devil is often called the "prince of darkness." The term was used in John Milton's poem "Paradise Lost", published in 1667, referring to Satan, who is viewed as the embodiment of evil. It is an English translation of the Latin phrase "princeps tenebrarum", which occurs in the "Acts of Pilate", written in the fourth century, in the 11th-century hymn "Rhythmus de die mortis" by Pietro Damiani, and in a sermon by Bernard of Clairvaux from the 12th century. The phrase also occurs in "King Lear" by William Shakespeare (c. 1606), Act III, Scene IV, l. 14:
'The prince of darkness is a gentleman."

Priests and pastors of the Roman Catholic, Eastern Orthodox and Protestant churches commonly wear black, as do monks of the Benedictine Order, who consider it the color of humility and penitence.



In Europe and America, black is commonly associated with mourning and bereavement, and usually worn at funerals and memorial services. In some traditional societies, for example in Greece and Italy, some widows wear black for the rest of their lives. In contrast, across much of Africa and parts of Asia like Vietnam, white is a color of mourning.

In Victorian England, the colors and fabrics of mourning were specified in an unofficial dress code: "non-reflective black paramatta and crape for the first year of deepest mourning, followed by nine months of dullish black silk, heavily trimmed with crape, and then three months when crape was discarded. Paramatta was a fabric of combined silk and wool or cotton; crape was a harsh black silk fabric with a crimped appearance produced by heat. Widows were allowed to change into the colors of half-mourning, such as gray and lavender, black and white, for the final six months."

A "black day" (or week or month) usually refers to tragic date. The Romans marked "fasti" days with white stones and "nefasti" days with black. The term is often used to remember massacres. Black months include the Black September in Jordan, when large numbers of Palestinians were killed, and Black July in Sri Lanka, the killing of members of the Tamil population by the Sinhalese government.

In the financial world, the term often refers to a dramatic drop in the stock market. For example, the Wall Street Crash of 1929, the stock market crash on October 29, 1929, which marked the start of the Great Depression, is nicknamed Black Tuesday, and was preceded by Black Thursday, a downturn on October 24 the previous week.
In western popular culture, black has long been associated with evil and darkness. It is the traditional color of witchcraft and black magic.

In the Book of Revelation, the last book in the New Testament of the Bible, the Four Horsemen of the Apocalypse are supposed to announce the Apocalypse before the Last Judgment. The horseman representing famine rides a black horse. The vampire of literature and films, such as Count Dracula of the Bram Stoker novel, dressed in black, and could only move at night. The Wicked Witch of the West in the 1939 film "The Wizard of Oz" became the archetype of witches for generations of children. Whereas witches and sorcerers inspired real fear in the 17th century, in the 21st century children and adults dressed as witches for Halloween parties and parades.

Black is frequently used as a color of power, law and authority. In many countries judges and magistrates wear black robes. That custom began in Europe in the 13th and 14th centuries. Jurists, magistrates and certain other court officials in France began to wear long black robes during the reign of Philip IV of France (1285–1314), and in England from the time of Edward I (1271–1307). The custom spread to the cities of Italy at about the same time, between 1300 and 1320. The robes of judges resembled those worn by the clergy, and represented the law and authority of the King, while those of the clergy represented the law of God and authority of the church.

Until the 20th century most police uniforms were black, until they were largely replaced by a less menacing blue in France, the U.S. and other countries. In the United States, police cars are frequently Black and white. The riot control units of the Basque Autonomous Police in Spain are known as "beltzak" ("blacks") after their uniform.

Black today is the most common color for limousines and the official cars of government officials.

Black formal attire is still worn at many solemn occasions or ceremonies, from graduations to formal balls. Graduation gowns are copied from the gowns worn by university professors in the Middle Ages, which in turn were copied from the robes worn by judges and priests, who often taught at the early universities. The mortarboard hat worn by graduates is adapted from a square cap called a biretta worn by Medieval professors and clerics
In the 19th and 20th centuries, many machines and devices, large and small, were painted black, to stress their functionality. These included telephones, sewing machines, steamships, railroad locomotives, and automobiles. The Ford Model T, the first mass-produced car, was available only in black from 1914 to 1926. Of means of transportation, only airplanes were rarely ever painted black.
Black house paint is becoming more popular with Sherwin-Williams reporting that the color, Tricorn Black, was the 6th most popular exterior house paint color in Canada and the 12th most popular paint in the United States in 2018.


Black is also commonly used as a racial description in the United Kingdom, since ethnicity was first measured in the 2001 census. The 2011 British census asked residents to describe themselves, and categories offered included Black, African, Caribbean, or Black British. Other possible categories were African British, African Scottish, Caribbean British and Caribbean Scottish. Of the total UK population in 2001, 1.0 percent identified themselves as Black Caribbean, 0.8 percent as Black African, and 0.2 percent as Black (others).

In Canada, census respondents can identify themselves as Black. In the 2006 census, 2.5 percent of the population identified themselves as black.

In Australia, the term black is not used in the census. In the 2006 census, 2.3 percent of Australians identified themselves as Aboriginal and/or Torres Strait Islanders.

In Brazil, the Brazilian Institute of Geography and Statistics (IBGE) asks people to identify themselves as "branco" (white), "pardo" (brown), "preto" (black), or "amarelo" (yellow). In 2008 6.8 percent of the population identified themselves as "preto".

Black is commonly associated with secrecy.

Black is the color most commonly associated with elegance in Europe and the United States, followed by silver, gold, and white.

Black first became a fashionable color for men in Europe in the 17th century, in the courts of Italy and Spain. (See history above.) In the 19th century, it was the fashion for men both in business and for evening wear, in the form of a black coat whose tails came down the knees. In the evening it was the custom of the men to leave the women after dinner to go to a special smoking room to enjoy cigars or cigarettes. This meant that their tailcoats eventually smelled of tobacco. According to the legend, in 1865 Edward VII, then the Prince of Wales, had his tailor make a special short smoking jacket. The smoking jacket then evolved into the dinner jacket. Again according to legend, the first Americans to wear the jacket were members of the Tuxedo Club in New York State. Thereafter the jacket became known as a tuxedo in the U.S. The term "smoking" is still used today in Russia and other countries.
The tuxedo was always black until the 1930s, when the Duke of Windsor began to wear a tuxedo that was a very dark midnight blue. He did so because a black tuxedo looked greenish in artificial light, while a dark blue tuxedo looked blacker than black itself.

For women's fashion, the defining moment was the invention of the simple black dress by Coco Chanel in 1926. (See history.) Thereafter, a long black gown was used for formal occasions, while the simple black dress could be used for everything else. The designer Karl Lagerfeld, explaining why black was so popular, said: "Black is the color that goes with everything. If you're wearing black, you're on sure ground." Skirts have gone up and down and fashions have changed, but the black dress has not lost its position as the essential element of a woman's wardrobe. The fashion designer Christian Dior said, "elegance is a combination of distinction, naturalness, care and simplicity," and black exemplified elegance.

The expression "X is the new black" is a reference to the latest trend or fad that is considered a wardrobe basic for the duration of the trend, on the basis that black is always fashionable. The phrase has taken on a life of its own and has become a cliché.

Many performers of both popular and European classical music, including French singers Edith Piaf and Juliette Greco, and violinist Joshua Bell have traditionally worn black on stage during performances. A black costume was usually chosen as part of their image or stage persona, or because it did not distract from the music, or sometimes for a political reason. Country-western singer Johnny Cash always wore black on stage. In 1971, Cash wrote the song "Man in Black" to explain why he dressed in that color: "We're doing mighty fine I do suppose / In our streak of lightning cars and fancy clothes / But just so we're reminded of the ones who are held back / Up front there ought to be a man in black."



</doc>
<doc id="4036" url="https://en.wikipedia.org/wiki?curid=4036" title="Black Flag">
Black Flag

Black Flag or black flag may refer to:






</doc>
<doc id="4037" url="https://en.wikipedia.org/wiki?curid=4037" title="Bletchley Park">
Bletchley Park

Bletchley Park is a 19th-century mansion and estate in Milton Keynes (Buckinghamshire) that became the principal centre of Allied code-breaking during the Second World War. The mansion was constructed during the years following 1883 for the English financier and politician Sir Herbert Leon in the Victorian Gothic, Tudor, and Dutch Baroque styles, on the site of older buildings of the same name. During World War II, the estate housed the British Government Code and Cypher School (GC&CS), which regularly penetrated the secret communications of the Axis Powersmost importantly the German Enigma and Lorenz ciphers; among its most notable early personnel the GC&CS team of codebreakers included Alan Turing, Gordon Welchman, Hugh Alexander and Stuart Milner-Barry. The nature of the work there was secret until many years after the war.

According to the official historian of British Intelligence, the "Ultra" intelligence produced at Bletchley shortened the war by two to four years, and without it the outcome of the war would have been uncertain. The team at Bletchley Park devised automatic machinery to help with decryption, culminating in the development of Colossus, the world's first programmable digital electronic computer. Codebreaking operations at Bletchley Park came to an end in 1946 and all information about the wartime operations was classified until the mid 1970s. After the war, the Post Office took over the site and used it as a management school, but by 1990 the huts in which the codebreakers worked were being considered for demolition and redevelopment, and the Bletchley Park Trust formed in 1991 to save large portions of the site from developers. More recently, Bletchley Park has been open to the public and houses interpretive exhibits and rebuilt huts as they would have appeared during their wartime operations, as well as The National Museum of Computing, established on the site which includes a rebuilt Colossus machine, and receives hundreds of thousands of visitors annually.

The site appears in the Domesday Book as part of the Manor of Eaton. Browne Willis built a mansion there in 1711, but after Thomas Harrison purchased the property in 1793 this was pulled down. It was first known as Bletchley Park after its purchase by Samuel Lipscomb Seckham in 1877. The estate of was bought in 1883 by Sir Herbert Samuel Leon, who expanded the then-existing farmhouse into what architect Landis Gores called a "maudlin and monstrous pile" combining Victorian Gothic, Tudor, and Dutch Baroque styles. At his Christmas family gatherings there was a horse meet on Boxing Day with glasses of sloe gin from the butler, and the house was always "humming with servants". With 40 gardeners, a flower bed of yellow daffodils could become a sea of red tulips overnight.

In 1938, the mansion and much of the site was bought by a builder for a housing estate, but in May 1938 Admiral Sir Hugh Sinclair, head of the Secret Intelligence Service (SIS or MI6), bought the mansion and of land for £6,000 (£ today), using his own money after the Government said they did not have the budget to do so, for use by GC&CS and SIS in the event of war.

A key advantage seen by Sinclair and his colleagues (inspecting the site under the cover of "Captain Ridley's shooting party") was Bletchley's geographical centrality. It was almost immediately adjacent to Bletchley railway station, where the "Varsity Line" between Oxford and Cambridgewhose universities were expected to supply many of the code-breakersmet the main West Coast railway line connecting London, Birmingham, Manchester, Liverpool, Glasgow and Edinburgh. Watling Street, the main road linking London to the north-west (subsequently the A5) was close by, and high-volume communication links were available at the telegraph and telephone repeater station in nearby Fenny Stratford.

Bletchley Park was known as "B.P." to those who worked there.
"Station X" (X = Roman numeral ten), "London Signals Intelligence Centre", and "Government Communications Headquarters" were all cover names used during the war.
The formal posting of the many "Wrens"members of the Women's Royal Naval Serviceworking there, was to HMS Pembroke V. Royal Air Force names of Bletchley Park and its outstations included RAF Eastcote, RAF Lime Grove and RAF Church Green. The postal address that staff had to use was "Room 47, Foreign Office".

After the war, the Government Code & Cypher School became the Government Communications Headquarters (GCHQ), moving to Eastcote in 1946 and to Cheltenham in the 1950s. The site was used by various government agencies, including the GPO and the Civil Aviation Authority. One large building, block F, was demolished in 1987 by which time the site was being run down with tenants leaving. In 1990 the site was at risk of being sold for housing development. However, Milton Keynes Council made it into a conservation area. Bletchley Park Trust was set up in 1991 by a group of people who recognised the site's importance. The initial trustees included Roger Bristow, Ted Enever, Peter Wescombe, Dr Peter Jarvis of the Bletchley Archaeological & Historical Society, and Tony Sale who in 1994 became the first director of the Bletchley Park Museums.

Commander Alastair Denniston was operational head of GC&CS from 1919 to 1942, beginning with its formation from the Admiralty's Room 40 (NID25) and the War Office's MI1b. Key GC&CS cryptanalysts who moved from London to Bletchley Park included John Tiltman, Dillwyn "Dilly" Knox, Josh Cooper, and Nigel de Grey. These people had a variety of backgroundslinguists and chess champions were common, and in Knox's case papyrology. The British War Office recruited top solvers of cryptic crossword puzzles, as these individuals had strong lateral thinking skills.

On the day Britain declared war on Germany, Denniston wrote to the Foreign Office about recruiting "men of the professor type". Personal networking drove early recruitments, particularly of men from the universities of Cambridge and Oxford. Trustworthy women were similarly recruited for administrative and clerical jobs. In one 1941 recruiting stratagem, "The Daily Telegraph" was asked to organise a crossword competition, after which promising contestants were discreetly approached about "a particular type of work as a contribution to the war effort".

Denniston recognised, however, that the enemy's use of electromechanical cipher machines meant that formally trained mathematicians would also be needed; Oxford's Peter Twinn joined GC&CS in February 1939; Cambridge's Alan Turing and Gordon Welchman began training in 1938 and reported to Bletchley the day after war was declared, along with John Jeffreys. Later-recruited cryptanalysts included the mathematicians Derek Taunt, Jack Good, Bill Tutte, and Max Newman; historian Harry Hinsley, and chess champions Hugh Alexander and Stuart Milner-Barry. Joan Clarke (eventually deputy head of Hut 8) was one of the few women employed at Bletchley as a full-fledged cryptanalyst.

This eclectic staff of "Boffins and Debs" (scientists and debutantes, young women of high society) caused GC&CS to be whimsically dubbed the "Golf, Cheese and Chess Society". During a September 1941 morale-boosting visit, Winston Churchill reportedly remarked to Denniston: "I told you to leave no stone unturned to get staff, but I had no idea you had taken me so literally." Six weeks later, having failed to get sufficient typing and unskilled staff to achieve the productivity that was possible, Turing, Welchman, Alexander and Milner-Barry wrote directly to Churchill. His response was "Action this day make sure they have all they want on extreme priority and report to me that this has been done." The Army CIGS Alan Brooke wrote that on 16 April 1942 ""Took lunch in car and went to see the organization for breaking down ciphers – a wonderful set of professors and genii! I marvel at the work they succeed in doing."" 

After initial training at the Inter-Service Special Intelligence School set up by John Tiltman (initially at an RAF depot in Buckingham and later in Bedfordwhere it was known locally as "the Spy School") staff worked a six-day week, rotating through three shifts: 4p.m. to midnight, midnight to 8a.m. (the most disliked shift), and 8a.m. to 4p.m., each with a half-hour meal break. At the end of the third week, a worker went off at 8a.m. and came back at 4p.m., thus putting in sixteen hours on that last day. The irregular hours affected workers' health and social life, as well as the routines of the nearby homes at which most staff lodged. The work was tedious and demanded intense concentration; staff got one week's leave four times a year, but some "girls" collapsed and required extended rest. Recruitment took place to combat a shortage of experts in Morse code and German.

In January 1945, at the peak of codebreaking efforts, some 10,000 personnel were working at Bletchley and its outstations. About three-quarters of these were women. Many of the women came from middle-class backgrounds and held degrees in the areas of mathematics, physics and engineering; they were given entry into STEM programs due to the lack of men, who had been sent to war. They performed complex calculations and coding and hence were integral to the computing processes. For example, Eleanor Ireland worked on the Colossus computers.

The female staff in Dilwyn Knox's section were sometimes termed "Dilly's Fillies". "Dilly's girls" included Jean Perrin, Clare Harding, Rachel Ronald, and Elisabeth Granger. Jane Hughes processed information leading to the last battle of the "Bismarck". Mavis Lever (who married mathematician and fellow code-breaker Keith Batey) made the first break into the Italian naval traffic. She and Margaret Rock solved a German code, the Abwehr break.

Many of the women had backgrounds in languages, particularly French and German. Rozanne Colchester was a translator who worked at Bletchley from April 1942 until January 1945, mainly for the Italian air forces Section. Like most of the 'Bletchleyettes', she came from the higher middle class, her father, Air Vice-Marshal Sir Charles Medhurst, being an air attaché in Rome. Before joining Bletchley, Colchester was moving in high circles: “she had met Hitler and been flirted with by Mussolini at an embassy party”, writes Sarah Rainey. She joined the Park because she found it thrilling to fight for her country.

Cicely Mayhew was recruited straight from university, having graduated from Lady Margaret Hall, Oxford in 1944 with a First in French and German, after only two years. She worked in Hut 8, translating decoded German Navy signals.

Ruth Briggs, a German scholar, worked within the Naval Section and was known as one of the best cryptographers; she married Oliver Churchill of the SOE.

For a long time, the British Government didn't recognize the contributions the personnel at Bletchley Park made. Their work achieved official recognition only in 2009.

Properly used, the German Enigma and Lorenz ciphers should have been virtually unbreakable, but flaws in German cryptographic procedures, and poor discipline among the personnel carrying them out, created vulnerabilities that made Bletchley's attacks just barely feasible. These vulnerabilities, however, could have been remedied by relatively simple improvements in enemy procedures, and such changes would certainly have been implemented had Germany had any hint of Bletchley's success. Thus the intelligence Bletchley produced was considered wartime Britain's "Ultra secret"higher even than the normally highest classification and security was paramount.

All staff signed the Official Secrets Act (1939) and a 1942 security warning emphasised the importance of discretion even within Bletchley itself: "Do not talk at meals. Do not talk in the transport. Do not talk travelling. Do not talk in the billet. Do not talk by your own fireside. Be careful even in your Hut..."

Nevertheless, there were security leaks. Jock Colville, the Assistant Private Secretary to Winston Churchill, recorded in his diary on 31 July 1941, that the newspaper proprietor Lord Camrose had discovered Ultra and that security leaks "increase in number and seriousness". Without doubt, the most serious of these was that Bletchley Park had been infiltrated by John Cairncross, the notorious Soviet mole and member of the Cambridge Spy Ring, who leaked Ultra material to Moscow.

The first personnel of the Government Code and Cypher School (GC&CS) moved to Bletchley Park on 15 August 1939. The Naval, Military, and Air Sections were on the ground floor of the mansion, together with a telephone exchange, teleprinter room, kitchen, and dining room; the top floor was allocated to MI6. Construction of the wooden huts began in late 1939, and Elmers School, a neighbouring boys' boarding school in a Victorian Gothic redbrick building by a church, was acquired for the Commercial and Diplomatic Sections.

After the United States joined World War II, a number of American cryptographers were posted to Hut 3, and from May 1943 onwards there was close co-operation between British and American intelligence. (See 1943 BRUSA Agreement.) In contrast, the Soviet Union was never officially told of Bletchley Park and its activities a reflection of Churchill's distrust of the Soviets even during the US-UK-USSR alliance imposed by the Nazi threat.

The only direct enemy damage to the site was done 2021 November 1940 by three bombs probably intended for Bletchley railway station; Hut4, shifted two feet off its foundation, was winched back into place as
work inside continued.

Hut 3 functions moved into Block D early in 1942, but retained the name. It contained a number of sections: Air Section "3A", Military Section "3M", a small Naval Section "3N", a multi-service Research Section "3G" and a large liaison section "3L". It also housed the Traffic Analysis Section, SIXTA.

Non-naval Enigma messages were deciphered in Hut 6, and passed to Hut 3 for translation, indexing, and cross-referencing. Military intelligence reports were produced by synthesising information from a multiplicity of sources. The reports were sent out to the Secret Intelligence Service, the intelligence chiefs in the relevant ministries, and later on to high-level commanders in the field. 

Naval Enigma deciphering was in Hut 8, with translation in Hut 4. Verbatim translations were sent to the Naval Intelligence Division (NID) of the Admiralty's Operational Intelligence Centre (OIC), supplemented by information from indexes as to the meaning of technical terms and cross-references from a knowledge store of German naval technology. Where relevant to non-naval matters, they would also be passed to Hut 3. Hut 4 also decoded a manual system known as the dockyard cipher, which sometimes carried messages that were also sent on an Enigma network. Feeding these back to Hut8 provided excellent "cribs" for Known-plaintext attacks on the daily naval Enigma key.

Initially, a wireless room was established at Bletchley Park.
It was set up in the mansion's water tower under the code name "Station X", a term now sometimes applied to the codebreaking efforts at Bletchley as a whole. The "X" is the Roman numeral "ten", this being the Secret Intelligence Service's tenth such station. Due to the long radio aerials stretching from the wireless room, the radio station was moved from Bletchley Park to nearby Whaddon Hall to avoid drawing attention to the site.

Subsequently, other listening stationsthe Y-stations, such as the ones at Chicksands in Bedfordshire, Beaumanor Hall, Leicestershire (where the headquarters of the War Office "Y" Group was located) and Beeston Hill Y Station in Norfolkgathered raw signals for processing at Bletchley. Coded messages were taken down by hand and sent to Bletchley on paper by motorcycle despatch riders or (later) by teleprinter.

The wartime needs required the building of additional accommodation.

Often a hut's number became so strongly associated with the work performed inside that even when the work was moved to another building it was still referred to by the original "Hut" designation.


In addition to the wooden huts, there were a number of brick-built "blocks".

Most German messages decrypted at Bletchley were produced by one or another version of the Enigma cipher machine, but an important minority were produced by the even more complicated twelve-rotor Lorenz SZ42 on-line teleprinter cipher machine.

Five weeks before the outbreak of war, Warsaw's Cipher Bureau revealed its achievements in breaking Enigma to astonished French and British personnel. The British used the Poles' information and techniques, and the Enigma clone sent to them in August 1939, which greatly increased their (previously very limited) success in decrypting Enigma messages.

The bombe was an electromechanical device whose function was to discover some of the daily settings of the Enigma machines on the various German military networks. Its pioneering design was developed by Alan Turing (with an important contribution from Gordon Welchman) and the machine was engineered by Harold 'Doc' Keen of the British Tabulating Machine Company. Each machine was about high and wide, deep and weighed about a ton.

At its peak, GC&CS was reading approximately 4,000 messages per day. As a hedge against enemy attack most bombes were dispersed to installations at Adstock and Wavendon (both later supplanted by installations at Stanmore and Eastcote), and Gayhurst.

Luftwaffe messages were the first to be read in quantity. The German navy had much tighter procedures, and the capture of code books was needed before they could be broken. When, in February 1942, the German navy introduced the four-rotor Enigma for communications with its Atlantic U-boats, this traffic became unreadable for a period of ten months. Britain produced modified bombes, but it was the success of the US Navy bombe that was the main source of reading messages from this version of Enigma for the rest of the war. Messages were sent to and fro across the Atlantic by enciphered teleprinter links.

The Lorenz messages were codenamed "Tunny" at Bletchley Park. They were only sent in quantity from mid-1942. The Tunny networks were used for high-level messages between German High Command and field commanders. With the help of German operator errors, the cryptanalysts in the Testery (named after Ralph Tester, its head) worked out the logical structure of the machine despite not knowing its physical form. They devised automatic machinery to help with decryption, which culminated in Colossus, the world's first programmable digital electronic computer. This was designed and built by Tommy Flowers and his team at the Post Office Research Station at Dollis Hill. The prototype first worked in December 1943, was delivered to Bletchley Park in January and first worked operationally on 5 February 1944. Enhancements were developed for the Mark 2 Colossus, the first of which was working at Bletchley Park on the morning of 1 June in time for D-day. Flowers then produced one Colossus a month for the rest of the war, making a total of ten with an eleventh part-built. The machines were operated mainly by Wrens in a section named the Newmanry after its head Max Newman.

Bletchley's work was essential to defeating the U-boats in the Battle of the Atlantic, and to the British naval victories in the Battle of Cape Matapan and the Battle of North Cape. In 1941, Ultra exerted a powerful effect on the North African desert campaign against German forces under General Erwin Rommel. General Sir Claude Auchinleck wrote that were it not for Ultra, "Rommel would have certainly got through to Cairo". While not changing the events, "Ultra" decrypts featured prominently in the story of Operation SALAM, László Almásy's mission across the desert behind Allied lines in 1942. Prior to the Normandy landings on D-Day in June 1944, the Allies knew the locations of all but two of Germany's fifty-eight Western-front divisions.

Italian signals had been of interest since Italy's attack on Abyssinia in 1935.
During the Spanish Civil War the Italian Navy used the K model of the commercial Enigma without a plugboard; this was solved by Knox in 1937.
When Italy entered the war in 1940 an improved version of the machine was used, though little traffic was sent by it and there were "wholesale changes" in Italian codes and cyphers.

Knox was given a new section for work on Enigma variations, which he staffed with women ("Dilly's girls"), who included Margaret Rock, Jean Perrin, Clare Harding, Rachel Ronald, Elisabeth Granger; and Mavis Lever.
Mavis Lever solved the signals revealing the Italian Navy's operational plans before the Battle of Cape Matapan in 1941, leading to a British victory.

Although most Bletchley staff did not know the results of their work, Admiral Cunningham visited Bletchley in person a few weeks later to congratulate them.

On entering World War II in June 1940, the Italians were using book codes for most of their military messages. The exception was the Italian Navy, which after the Battle of Cape Matapan started using the C-38 version of the Boris Hagelin rotor-based cipher machine, particularly to route their navy and merchant marine convoys to the conflict in North Africa.
As a consequence, JRM Butler recruited his former student Bernard Willson to join a team with two others in Hut4. In June 1941, Willson became the first of the team to decode the Hagelin system, thus enabling military commanders to direct the Royal Navy and Royal Air Force to sink enemy ships carrying supplies from Europe to Rommel's Afrika Korps. This led to increased shipping losses and, from reading the intercepted traffic, the team learnt that between May and September 1941 the stock of fuel for the Luftwaffe in North Africa reduced by 90 percent.
After an intensive language course, in March 1944 Willson switched to Japanese language-based codes.

A Middle East Intelligence Centre (MEIC) was set up in Cairo in 1939. When Italy entered the war in June 1940, delays in forwarding intercepts to Bletchley via congested radio links resulted in cryptanalysts being sent to Cairo. A Combined Bureau Middle East (CBME) was set up in November, though the Middle East authorities made "increasingly bitter complaints" that GC&CS was giving too little priority to work on Italian cyphers. However, the principle of concentrating high-grade cryptanalysis at Bletchley was maintained. John Chadwick started cryptanalysis work in 1942 on Italian signals at the naval base 'HMS Nile' in Alexandria. Later, he was with GC&CS; in the Heliopolis Museum, Cairo and then in the Villa Laurens, Alexandria.

Soviet signals had been studied since the 1920s. In 193940, John Tiltman (who had worked on Russian Army traffic from 1930) set up two Russian sections at Wavendon (a country house near Bletchley) and at Sarafand in Palestine. Two Russian high-grade army and navy systems were broken early in 1940. Tiltman spent two weeks in Finland, where he obtained Russian traffic from Finland and Estonia in exchange for radio equipment. In June 1941, when the Soviet Union became an ally, Churchill ordered a halt to intelligence operations against it. In December 1941, the Russian section was closed down, but in late summer 1943 or late 1944, a small GC&CS Russian cypher section was set up in London overlooking Park Lane, then in Sloane Square.

An outpost of the Government Code and Cypher School had been set up in Hong Kong in 1935, the Far East Combined Bureau (FECB). The FECB naval staff moved in 1940 to Singapore, then Colombo, Ceylon, then Kilindini, Mombasa, Kenya. They succeeded in deciphering Japanese codes with a mixture of skill and good fortune. The Army and Air Force staff went from Singapore to the Wireless Experimental Centre at Delhi, India.

In early 1942, a six-month crash course in Japanese, for 20 undergraduates from Oxford and Cambridge, was started by the Inter-Services Special Intelligence School in Bedford, in a building across from the main Post Office. This course was repeated every six months until war's end. Most of those completing these courses worked on decoding Japanese naval messages in Hut 7, under John Tiltman.

By mid-1945, well over 100 personnel were involved with this operation, which co-operated closely with the FECB and the US Signal intelligence Service at Arlington Hall, Virginia. In 1999, Michael Smith wrote that: "Only now are the British codebreakers (like John Tiltman, Hugh Foss, and Eric Nave) beginning to receive the recognition they deserve for breaking Japanese codes and cyphers".

After the War, the secrecy imposed on Bletchley staff remained in force, so that most relatives never knew more than that a child, spouse, or parent had done some kind of secret war work. Churchill referred to the Bletchley staff as "the geese that laid the golden eggs and never cackled". That said, occasional mentions of the work performed at Bletchley Park slipped the censor's net and appeared in print.

With the publication of F.W. Winterbotham's "The Ultra Secret" (1974) public discussion of Bletchley's work finally became possible (though even today some former staff still consider themselves bound to silence) and in July 2009 the British government announced that Bletchley personnel would be recognised with a commemorative badge.

After the war, the site passed through a succession of hands and saw a number of uses, including as a teacher-training college and local GPO headquarters. By 1991, the site was nearly empty and the buildings were at risk of demolition for redevelopment.

In February 1992, the Milton Keynes Borough Council declared most of the Park a conservation area, and the Bletchley Park Trust was formed to maintain the site as a museum. The site opened to visitors in 1993, and was formally inaugurated by the Duke of Kent as Chief Patron in July 1994. In 1999 the land owners, the Property Advisors to the Civil Estate and BT, granted a lease to the Trust giving it control over most of the site.

June 2014 saw the completion of an £8 million restoration project by museum design specialist, Event Communications, which was marked by a visit from Catherine, Duchess of Cambridge. The Duchess' paternal grandmother, Valerie, and Valerie's twin sister, Mary (née Glassborow), both worked at Bletchley Park during the war. The twin sisters worked as Foreign Office Civilians in Hut 6, where they managed the interception of enemy and neutral diplomatic signals for decryption. Valerie married Catherine's grandfather, Captain Peter Middleton. A memorial at Bletchley Park commemorates Mary and Valerie Middleton's work as code-breakers.


The Bletchley Park Learning Department offers educational group visits with active learning activities for schools and universities. Visits can be booked in advance during term time, where students can engage with the history of Bletchley Park and understand its wider relevance for computer history and national security. Their workshops cover introductions to codebreaking, cyber security and the story of Enigma and Lorenz.

In October 2005, American billionaire Sidney Frank donated £500,000 to Bletchley Park Trust to fund a new Science Centre dedicated to Alan Turing. Simon Greenish joined as Director in 2006 to lead the fund-raising effort in a post he held until 2012 when Iain Standen took over the leadership role. In July 2008, a letter to "The Times" from more than a hundred academics condemned the neglect of the site. In September 2008, PGP, IBM, and other technology firms announced a fund-raising campaign to repair the facility. On 6 November 2008 it was announced that English Heritage would donate £300,000 to help maintain the buildings at Bletchley Park, and that they were in discussions regarding the donation of a further £600,000.

In October 2011, the Bletchley Park Trust received a £4.6m Heritage Lottery Fund grant to be used "to complete the restoration of the site, and to tell its story to the highest modern standards" on the condition that £1.7m of 'match funding' is raised by the Bletchley Park Trust. Just weeks later, Google contributed £550k and by June 2012 the trust had successfully raised £2.4m to unlock the grants to restore Huts 3 and 6, as well as develop its exhibition centre in Block C.

Additional income is raised by renting Block H to the National Museum of Computing, and some office space in various parts of the park to private firms.

The National Museum of Computing is housed in Block H, which is rented from the Bletchley Park Trust. Its Colossus and Tunny galleries tell an important part of allied breaking of German codes during World War II. There is a working reconstruction of a Bombe and a rebuilt Colossus computer which was used on the high-level Lorenz cipher, codenamed "Tunny" by the British.

The museum, which opened in 2007, is an independent voluntary organisation that is governed by its own board of trustees. Its aim is "To collect and restore computer systems particularly those developed in Britain and to enable people to explore that collection for inspiration, learning and enjoyment." Through its many exhibits, the museum displays the story of computing through the mainframes of the 1960s and 1970s, and the rise of personal computing in the 1980s. It has a policy of having as many of the exhibits as possible in full working order.

This consists of serviced office accommodation housed in Bletchley Park's Blocks A and E, and the upper floors of the Mansion. Its aim is to foster the growth and development of dynamic knowledge-based start-ups and other businesses.

The National Museum of Computing is working with four other organisations – but not Bletchley Park Trust – in a group called Qufaro, to create the National College of Cyber Security. This will be for students between 16 and 19 years of age. It will be located in Block G which is being renovated with funding from the Bletchley Park Science and Innovation Centre.

The Radio Society of Great Britain's National Radio Centre (including a library, radio station, museum and bookshop) are in a newly constructed building close to the main Bletchley Park entrance.






Bletchley Park is opposite Bletchley railway station. It is close to junctions 13 and 14 of the M1, about northwest of London.




</doc>
<doc id="4041" url="https://en.wikipedia.org/wiki?curid=4041" title="Bede">
Bede

Bede ( ; ; 672/3 – 26 May 735), also known as Saint Bede, Venerable Bede, and Bede the Venerable (), was an English Benedictine monk at the monastery of St. Peter and its companion monastery of St. Paul in the Kingdom of Northumbria of the Angles (contemporarily Monkwearmouth–Jarrow Abbey in Tyne and Wear, England). Born on lands likely belonging to the Monkwearmouth monastery in present-day Sunderland, Bede was sent there at the age of seven and later joined Abbot Ceolfrith at the Jarrow monastery, both of whom survived a plague that struck in 686, an outbreak that killed a majority of the population there. While he spent most of his life in the monastery, Bede travelled to several abbeys and monasteries across the British Isles, even visiting the archbishop of York and King Ceolwulf of Northumbria. He is well known as an author, teacher (a student of one of his pupils was Alcuin), and scholar, and his most famous work, "Ecclesiastical History of the English People", gained him the title "The Father of English History". His ecumenical writings were extensive and included a number of Biblical commentaries and other theological works of exegetical erudition. Another important area of study for Bede was the academic discipline of "computus", otherwise known to his contemporaries as the science of calculating calendar dates. One of the more important dates Bede tried to compute was Easter, an effort that was mired with controversy. He also helped establish the practice of dating forward from the birth of Christ ("Anno Domini" – in the year of our Lord), a practice which eventually became commonplace in medieval Europe. Bede was one of the greatest teachers and writers of the Early Middle Ages and is considered by many historians to be the single most important scholar of antiquity for the period between the death of Pope Gregory I in 604 and the coronation of Charlemagne in 800.

In 1899, Pope Leo XIII declared him a Doctor of the Church. He is the only native of Great Britain to achieve this designation; Anselm of Canterbury, also a Doctor of the Church, was originally from Italy. Bede was moreover a skilled linguist and translator, and his work made the Latin and Greek writings of the early Church Fathers much more accessible to his fellow Anglo-Saxons, which contributed significantly to English Christianity. Bede's monastery had access to an impressive library which included works by Eusebius, Orosius, and many others.

Almost everything that is known of Bede's life is contained in the last chapter of his "Ecclesiastical History of the English People", a history of the church in England. It was completed in about 731, and Bede implies that he was then in his fifty-ninth year, which would give a birth date in 672 or 673. A minor source of information is the letter by his disciple Cuthbert (not to be confused with the saint, Cuthbert, who is mentioned in Bede's work) which relates Bede's death. Bede, in the "Historia", gives his birthplace as "on the lands of this monastery". He is referring to the twinned monasteries of Monkwearmouth and Jarrow, in modern-day Wearside and Tyneside respectively; there is also a tradition that he was born at Monkton, two miles from the monastery at Jarrow, although at the time of his birth the Jarrow Monastery did not exist. Bede says nothing of his origins, but his connections with men of noble ancestry suggest that his own family was well-to-do. Bede's first abbot was Benedict Biscop, and the names "Biscop" and "Beda" both appear in a king list of the kings of Lindsey from around 800, further suggesting that Bede came from a noble family.

Bede's name reflects West Saxon "Bīeda" (Northumbrian "Bǣda", Anglian "Bēda"). It is an Anglo-Saxon short name formed on the root of "bēodan" "to bid, command".
The name also occurs in the "Anglo-Saxon Chronicle", s.a. 501, as "Bieda", one of the sons of the Saxon founder of Portsmouth. The "Liber Vitae" of Durham Cathedral names two priests with this name, one of whom is presumably Bede himself. Some manuscripts of the "Life of Cuthbert", one of Bede's works, mention that Cuthbert's own priest was named Bede; it is possible that this priest is the other name listed in the "Liber Vitae".

At the age of seven, Bede was sent, as a "puer oblatus", to the monastery of Monkwearmouth by his family to be educated by Benedict Biscop and later by Ceolfrith. Bede does not say whether it was already intended at that point that he would be a monk. It was fairly common in Ireland at this time for young boys, particularly those of noble birth, to be fostered out as an oblate; the practice was also likely to have been common among the Germanic peoples in England. Monkwearmouth's sister monastery at Jarrow was founded by Ceolfrith in 682, and Bede probably transferred to Jarrow with Ceolfrith that year. The dedication stone for the church has survived to the present day; it is dated 23 April 685, and as Bede would have been required to assist with menial tasks in his day-to-day life it is possible that he helped in building the original church. In 686, plague broke out at Jarrow. The "Life of Ceolfrith", written in about 710, records that only two surviving monks were capable of singing the full offices; one was Ceolfrith and the other a young boy, who according to the anonymous writer had been taught by Ceolfrith. The two managed to do the entire service of the liturgy until others could be trained. The young boy was almost certainly Bede, who would have been about 14.

When Bede was about 17 years old, Adomnán, the abbot of Iona Abbey, visited Monkwearmouth and Jarrow. Bede would probably have met the abbot during this visit, and it may be that Adomnan sparked Bede's interest in the Easter dating controversy. In about 692, in Bede's nineteenth year, Bede was ordained a deacon by his diocesan bishop, John, who was bishop of Hexham. The canonical age for the ordination of a deacon was 25; Bede's early ordination may mean that his abilities were considered exceptional, but it is also possible that the minimum age requirement was often disregarded. There might have been minor orders ranking below a deacon; but there is no record of whether Bede held any of these offices. In Bede's thirtieth year (about 702), he became a priest, with the ordination again performed by Bishop John.

In about 701 Bede wrote his first works, the "De Arte Metrica" and "De Schematibus et Tropis"; both were intended for use in the classroom. He continued to write for the rest of his life, eventually completing over 60 books, most of which have survived. Not all his output can be easily dated, and Bede may have worked on some texts over a period of many years. His last-surviving work is a letter to Ecgbert of York, a former student, written in 734. A 6th-century Greek and Latin manuscript of "Acts of the Apostles" that is believed to have been used by Bede survives and is now in the Bodleian Library at University of Oxford; it is known as the Codex Laudianus. Bede may also have worked on some of the Latin Bibles that were copied at Jarrow, one of which, the Codex Amiatinus, is now held by the Laurentian Library in Florence. Bede was a teacher as well as a writer; he enjoyed music, and was said to be accomplished as a singer and as a reciter of poetry in the vernacular. It is possible that he suffered a speech impediment, but this depends on a phrase in the introduction to his verse life of Saint Cuthbert. Translations of this phrase differ, and it is uncertain whether Bede intended to say that he was cured of a speech problem, or merely that he was inspired by the saint's works.
In 708, some monks at Hexham accused Bede of having committed heresy in his work "De Temporibus". The standard theological view of world history at the time was known as the Six Ages of the World; in his book, Bede calculated the age of the world for himself, rather than accepting the authority of Isidore of Seville, and came to the conclusion that Christ had been born 3,952 years after the creation of the world, rather than the figure of over 5,000 years that was commonly accepted by theologians. The accusation occurred in front of the bishop of Hexham, Wilfrid, who was present at a feast when some drunken monks made the accusation. Wilfrid did not respond to the accusation, but a monk present relayed the episode to Bede, who replied within a few days to the monk, writing a letter setting forth his defence and asking that the letter also be read to Wilfrid. Bede had another brush with Wilfrid, for the historian himself says that he met Wilfrid, sometime between 706 and 709, and discussed Æthelthryth, the abbess of Ely. Wilfrid had been present at the exhumation of her body in 695, and Bede questioned the bishop about the exact circumstances of the body and asked for more details of her life, as Wilfrid had been her advisor.

In 733, Bede travelled to York to visit Ecgbert, who was then bishop of York. The See of York was elevated to an archbishopric in 735, and it is likely that Bede and Ecgbert discussed the proposal for the elevation during his visit. Bede hoped to visit Ecgbert again in 734, but was too ill to make the journey. Bede also travelled to the monastery of Lindisfarne, and at some point visited the otherwise-unknown monastery of a monk named , a visit that is mentioned in a letter to that monk. Because of his widespread correspondence with others throughout the British Isles, and due to the fact that many of the letters imply that Bede had met his correspondents, it is likely that Bede travelled to some other places, although nothing further about timing or locations can be guessed. It seems certain that he did not visit Rome, however, as he would have mentioned it in the autobiographical chapter of his "Historia Ecclesiastica". Nothhelm, a correspondent of Bede's who assisted him by finding documents for him in Rome, is known to have visited Bede, though the date cannot be determined beyond the fact that it was after Nothhelm's visit to Rome.

Except for a few visits to other monasteries, his life was spent in a round of prayer, observance of the monastic discipline and study of the Sacred Scriptures. He was considered the most learned man of his time, and wrote excellent biblical and historical books.
Bede died on the Feast of the Ascension, Thursday, 26 May 735, on the floor of his cell, singing "Glory be to the Father and to the Son and to the Holy Spirit" and was buried at Jarrow. Cuthbert, a disciple of Bede's, wrote a letter to a Cuthwin (of whom nothing else is known), describing Bede's last days and his death. According to Cuthbert, Bede fell ill, "with frequent attacks of breathlessness but almost without pain", before Easter. On the Tuesday, two days before Bede died, his breathing became worse and his feet swelled. He continued to dictate to a scribe, however, and despite spending the night awake in prayer he dictated again the following day. At three o'clock, according to Cuthbert, he asked for a box of his to be brought, and distributed among the priests of the monastery "a few treasures" of his: "some pepper, and napkins, and some incense". That night he dictated a final sentence to the scribe, a boy named Wilberht, and died soon afterwards. The account of Cuthbert does not make entirely clear whether Bede died before midnight or after. However, by the reckoning of Bede's time, passage from the old day to the new occurred at sunset, not midnight, and Cuthbert is clear that he died after sunset. Thus, while his box was brought at three o'clock Wednesday afternoon the 25th, by the time of the final dictation it might be considered already Thursday in that ecclesiastical sense, although the 25th in the ordinary sense.

Cuthbert's letter also relates a five-line poem in the vernacular that Bede composed on his deathbed, known as "Bede's Death Song". It is the most-widely copied Old English poem, and appears in 45 manuscripts, but its attribution to Bede is not certain—not all manuscripts name Bede as the author, and the ones that do are of later origin than those that do not. Bede's remains may have been transferred to Durham Cathedral in the 11th century; his tomb there was looted in 1541, but the contents were probably re-interred in the Galilee chapel at the cathedral.

One further oddity in his writings is that in one of his works, the "Commentary on the Seven Catholic Epistles", he writes in a manner that gives the impression he was married. The section in question is the only one in that work that is written in first-person view. Bede says: "Prayers are hindered by the conjugal duty because as often as I perform what is due to my wife I am not able to pray." Another passage, in the "Commentary on Luke", also mentions a wife in the first person: "Formerly I possessed a wife in the lustful passion of desire and now I possess her in honourable sanctification and true love of Christ." The historian Benedicta Ward argues that these passages are Bede employing a rhetorical device.

Bede wrote scientific, historical and theological works, reflecting the range of his writings from music and metrics to exegetical Scripture commentaries. He knew patristic literature, as well as Pliny the Elder, Virgil, Lucretius, Ovid, Horace and other classical writers. He knew some Greek.

Bede's scriptural commentaries employed the allegorical method of interpretation and his history includes accounts of miracles, which to modern historians has seemed at odds with his critical approach to the materials in his history. Modern studies have shown the important role such concepts played in the world-view of Early Medieval scholars.

He dedicated his work on the Apocalypse and the "De Temporum Ratione" to the successor of Ceolfrid as abbot, Hwaetbert.

Although Bede is mainly studied as an historian now, in his time his works on grammar, chronology, and biblical studies were as important as his historical and hagiographical works. The non-historical works contributed greatly to the Carolingian renaissance. He has been credited with writing a penitential, though his authorship of this work is still very much disputed.

Bede's best-known work is the "Historia ecclesiastica gentis Anglorum", or "An Ecclesiastical History of the English People", completed in about 731. Bede was aided in writing this book by Albinus, abbot of St Augustine's Abbey, Canterbury. The first of the five books begins with some geographical background, and then sketches the history of England, beginning with Caesar's invasion in 55 BC. A brief account of Christianity in Roman Britain, including the martyrdom of St Alban, is followed by the story of Augustine's mission to England in 597, which brought Christianity to the Anglo-Saxons. The second book begins with the death of Gregory the Great in 604, and follows the further progress of Christianity in Kent and the first attempts to evangelise Northumbria. These ended in disaster when Penda, the pagan king of Mercia, killed the newly Christian Edwin of Northumbria at the Battle of Hatfield Chase in about 632. The setback was temporary, and the third book recounts the growth of Christianity in Northumbria under kings Oswald of Northumbria and Oswy. The climax of the third book is the account of the Council of Whitby, traditionally seen as a major turning point in English history. The fourth book begins with the consecration of Theodore as Archbishop of Canterbury, and recounts Wilfrid's efforts to bring Christianity to the kingdom of Sussex. The fifth book brings the story up to Bede's day, and includes an account of missionary work in Frisia, and of the conflict with the British church over the correct dating of Easter. Bede wrote a preface for the work, in which he dedicates it to Ceolwulf, king of Northumbria. The preface mentions that Ceolwulf received an earlier draft of the book; presumably Ceolwulf knew enough Latin to understand it, and he may even have been able to read it. The preface makes it clear that Ceolwulf had requested the earlier copy, and Bede had asked for Ceolwulf's approval; this correspondence with the king indicates that Bede's monastery had excellent connections among the Northumbrian nobility.

The monastery at Wearmouth-Jarrow had an excellent library. Both Benedict Biscop and Ceolfrith had acquired books from the Continent, and in Bede's day the monastery was a renowned centre of learning. It has been estimated that there were about 200 books in the monastic library.

For the period prior to Augustine's arrival in 597, Bede drew on earlier writers, including Solinus. He had access to two works of Eusebius: the "Historia Ecclesiastica", and also the "Chronicon", though he had neither in the original Greek; instead he had a Latin translation of the "Historia", by Rufinus, and Saint Jerome's translation of the "Chronicon". He also knew Orosius's "Adversus Paganus", and Gregory of Tours' "Historia Francorum", both Christian histories, as well as the work of Eutropius, a pagan historian. He used Constantius's "Life of Germanus" as a source for Germanus's visits to Britain. Bede's account of the invasion of the Anglo-Saxons is drawn largely from Gildas's "De Excidio et Conquestu Britanniae". Bede would also have been familiar with more recent accounts such as Eddius Stephanus's "Life of Wilfrid", and anonymous "Lives" of Gregory the Great and Cuthbert. He also drew on Josephus's "Antiquities", and the works of Cassiodorus, and there was a copy of the "Liber Pontificalis" in Bede's monastery. Bede quotes from several classical authors, including Cicero, Plautus, and Terence, but he may have had access to their work via a Latin grammar rather than directly. However, it is clear he was familiar with the works of Virgil and with Pliny the Elder's "Natural History", and his monastery also owned copies of the works of Dionysius Exiguus. He probably drew his account of St. Alban from a life of that saint which has not survived. He acknowledges two other lives of saints directly; one is a life of Fursa, and the other of St. Æthelburh; the latter no longer survives. He also had access to a life of Ceolfrith. Some of Bede's material came from oral traditions, including a description of the physical appearance of Paulinus of York, who had died nearly 90 years before Bede's "Historia Ecclesiastica" was written.

Bede also had correspondents who supplied him with material. Albinus, the abbot of the monastery in Canterbury, provided much information about the church in Kent, and with the assistance of Nothhelm, at that time a priest in London, obtained copies of Gregory the Great's correspondence from Rome relating to Augustine's mission. Almost all of Bede's information regarding Augustine is taken from these letters. Bede acknowledged his correspondents in the preface to the "Historia Ecclesiastica"; he was in contact with Daniel, the Bishop of Winchester, for information about the history of the church in Wessex, and also wrote to the monastery at Lastingham for information about Cedd and Chad. Bede also mentions an Abbot Esi as a source for the affairs of the East Anglian church, and Bishop Cynibert for information about Lindsey.

The historian Walter Goffart argues that Bede based the structure of the "Historia" on three works, using them as the framework around which the three main sections of the work were structured. For the early part of the work, up until the Gregorian mission, Goffart feels that Bede used Gildas's "De excidio". The second section, detailing the Gregorian mission of Augustine of Canterbury was framed on the anonymous "Life of Gregory the Great" written at Whitby. The last section, detailing events after the Gregorian mission, Goffart feels were modelled on Stephen of Ripon's "Life of Wilfrid". Most of Bede's informants for information after Augustine's mission came from the eastern part of Britain, leaving significant gaps in the knowledge of the western areas, which were those areas likely to have a native Briton presence.

Bede's stylistic models included some of the same authors from whom he drew the material for the earlier parts of his history. His introduction imitates the work of Orosius, and his title is an echo of Eusebius's "Historia Ecclesiastica". Bede also followed Eusebius in taking the "Acts of the Apostles" as the model for the overall work: where Eusebius used the "Acts" as the theme for his description of the development of the church, Bede made it the model for his history of the Anglo-Saxon church. Bede quoted his sources at length in his narrative, as Eusebius had done. Bede also appears to have taken quotes directly from his correspondents at times. For example, he almost always uses the terms "Australes" and "Occidentales" for the South and West Saxons respectively, but in a passage in the first book he uses "Meridiani" and "Occidui" instead, as perhaps his informant had done. At the end of the work, Bede added a brief autobiographical note; this was an idea taken from Gregory of Tours' earlier "History of the Franks".

Bede's work as a hagiographer, and his detailed attention to dating, were both useful preparations for the task of writing the "Historia Ecclesiastica". His interest in computus, the science of calculating the date of Easter, was also useful in the account he gives of the controversy between the British and Anglo-Saxon church over the correct method of obtaining the Easter date.

Bede is described by Michael Lapidge as "without question the most accomplished Latinist produced in these islands in the Anglo-Saxon period". His Latin has been praised for its clarity, but his style in the "Historia Ecclesiastica" is not simple. He knew rhetoric, and often used figures of speech and rhetorical forms which cannot easily be reproduced in translation, depending as they often do on the connotations of the Latin words. However, unlike contemporaries such as Aldhelm, whose Latin is full of difficulties, Bede's own text is easy to read. In the words of Charles Plummer, one of the best-known editors of the "Historia Ecclesiastica", Bede's Latin is "clear and limpid ... it is very seldom that we have to pause to think of the meaning of a sentence ... Alcuin rightly praises Bede for his unpretending style."

Bede's primary intention in writing the "Historia Ecclesiastica" was to show the growth of the united church throughout England. The native Britons, whose Christian church survived the departure of the Romans, earn Bede's ire for refusing to help convert the Saxons; by the end of the "Historia" the English, and their Church, are dominant over the Britons. This goal, of showing the movement towards unity, explains Bede's animosity towards the British method of calculating Easter: much of the "Historia" is devoted to a history of the dispute, including the final resolution at the Synod of Whitby in 664. Bede is also concerned to show the unity of the English, despite the disparate kingdoms that still existed when he was writing. He also wants to instruct the reader by spiritual example, and to entertain, and to the latter end he adds stories about many of the places and people about which he wrote.

N.J. Higham argues that Bede designed his work to promote his reform agenda to Ceolwulf, the Northumbrian king. Bede painted a highly optimistic picture of the current situation in the Church, as opposed to the more pessimistic picture found in his private letters.

Bede's extensive use of miracles can prove difficult for readers who consider him a more or less reliable historian, but do not accept the possibility of miracles.
Yet both reflect an inseparable integrity and regard for accuracy and truth, expressed in terms both of historical events and of a tradition of Christian faith that continues to the present day. Bede, like Gregory the Great whom Bede quotes on the subject in the "Historia", felt that faith brought about by miracles was a stepping stone to a higher, truer faith, and that as a result miracles had their place in a work designed to instruct.

Bede is somewhat reticent about the career of Wilfrid, a contemporary and one of the most prominent clerics of his day. This may be because Wilfrid's opulent lifestyle was uncongenial to Bede's monastic mind; it may also be that the events of Wilfrid's life, divisive and controversial as they were, simply did not fit with Bede's theme of the progression to a unified and harmonious church.

Bede's account of the early migrations of the Angles and Saxons to England omits any mention of a movement of those peoples across the channel from Britain to Brittany described by Procopius, who was writing in the sixth century. Frank Stenton describes this omission as "a scholar's dislike of the indefinite"; traditional material that could not be dated or used for Bede's didactic purposes had no interest for him.

Bede was a Northumbrian, and this tinged his work with a local bias. The sources to which he had access gave him less information about the west of England than for other areas. He says relatively little about the achievements of Mercia and Wessex, omitting, for example, any mention of Boniface, a West Saxon missionary to the continent of some renown and of whom Bede had almost certainly heard, though Bede does discuss Northumbrian missionaries to the continent. He also is parsimonious in his praise for Aldhelm, a West Saxon who had done much to convert the native Britons to the Roman form of Christianity. He lists seven kings of the Anglo-Saxons whom he regards as having held "imperium", or overlordship; only one king of Wessex, Ceawlin, is listed, and none from Mercia, though elsewhere he acknowledges the secular power several of the Mercians held. Historian Robin Fleming states that he was so hostile to Mercia because Northumbria had been diminished by Mercian power that he consulted no Mercian informants and included no stories about its saints.

Bede relates the story of Augustine's mission from Rome, and tells how the British clergy refused to assist Augustine in the conversion of the Anglo-Saxons. This, combined with Gildas's negative assessment of the British church at the time of the Anglo-Saxon invasions, led Bede to a very critical view of the native church. However, Bede ignores the fact that at the time of Augustine's mission, the history between the two was one of warfare and conquest, which, in the words of Barbara Yorke, would have naturally "curbed any missionary impulses towards the Anglo-Saxons from the British clergy."

At the time Bede wrote the "Historia Ecclesiastica", there were two common ways of referring to dates. One was to use indictions, which were 15-year cycles, counting from 312 AD. There were three different varieties of indiction, each starting on a different day of the year. The other approach was to use regnal years—the reigning Roman emperor, for example, or the ruler of whichever kingdom was under discussion. This meant that in discussing conflicts between kingdoms, the date would have to be given in the regnal years of all the kings involved. Bede used both these approaches on occasion, but adopted a third method as his main approach to dating: the "Anno Domini" method invented by Dionysius Exiguus. Although Bede did not invent this method, his adoption of it, and his promulgation of it in "De Temporum Ratione", his work on chronology, is the main reason it is now so widely used. Beda Venerabilis' Easter cycle, contained in "De Temporum Ratione", was developed from Dionysius Exiguus’ famous Easter table.

The "Historia Ecclesiastica" was copied often in the Middle Ages, and about 160 manuscripts containing it survive. About half of those are located on the European continent, rather than in the British Isles. Most of the 8th- and 9th-century texts of Bede's "Historia" come from the northern parts of the Carolingian Empire. This total does not include manuscripts with only a part of the work, of which another 100 or so survive. It was printed for the first time between 1474 and 1482, probably at Strasbourg, France. Modern historians have studied the "Historia" extensively, and a number of editions have been produced. For many years, early Anglo-Saxon history was essentially a retelling of the "Historia", but recent scholarship has focused as much on what Bede did not write as what he did. The belief that the "Historia" was the culmination of Bede's works, the aim of all his scholarship, a belief common among historians in the past, is no longer accepted by most scholars.

Modern historians and editors of Bede have been lavish in their praise of his achievement in the "Historia Ecclesiastica". Stenton regarded it as one of the "small class of books which transcend all but the most fundamental conditions of time and place", and regarded its quality as dependent on Bede's "astonishing power of co-ordinating the fragments of information which came to him through tradition, the relation of friends, or documentary evidence ... In an age where little was attempted beyond the registration of fact, he had reached the conception of history." Patrick Wormald described him as "the first and greatest of England's historians".

The "Historia Ecclesiastica" has given Bede a high reputation, but his concerns were different from those of a modern writer of history. His focus on the history of the organisation of the English church, and on heresies and the efforts made to root them out, led him to exclude the secular history of kings and kingdoms except where a moral lesson could be drawn or where they illuminated events in the church. Besides the "Anglo-Saxon Chronicle", the medieval writers William of Malmesbury, Henry of Huntingdon, and Geoffrey of Monmouth used his works as sources and inspirations. Early modern writers, such as Polydore Vergil and Matthew Parker, the Elizabethan Archbishop of Canterbury, also utilised the "Historia", and his works were used by both Protestant and Catholic sides in the Wars of Religion.

Some historians have questioned the reliability of some of Bede's accounts. One historian, Charlotte Behr, thinks that the "Historia's" account of the arrival of the Germanic invaders in Kent should not be considered to relate what actually happened, but rather relates myths that were current in Kent during Bede's time.

It is likely that Bede's work, because it was so widely copied, discouraged others from writing histories and may even have led to the disappearance of manuscripts containing older historical works.

As Chapter 66 of his "On the Reckoning of Time", in 725 Bede wrote the "Greater Chronicle" ("chronica maiora"), which sometimes circulated as a separate work. For recent events the "Chronicle", like his "Ecclesiastical History", relied upon Gildas, upon a version of the "Liber Pontificalis" current at least to the papacy of Pope Sergius I (687–701), and other sources. For earlier events he drew on Eusebius's "Chronikoi Kanones." The dating of events in the "Chronicle" is inconsistent with his other works, using the era of creation, the "Anno Mundi".

His other historical works included lives of the abbots of Wearmouth and Jarrow, as well as verse and prose lives of Saint Cuthbert of Lindisfarne, an adaptation of Paulinus of Nola's "Life of St Felix", and a translation of the Greek "Passion of St Anastasius". He also created a listing of saints, the "Martyrology".

In his own time, Bede was as well known for his biblical commentaries and exegetical, as well as other theological, works. The majority of his writings were of this type, and covered the Old Testament and the New Testament. Most survived the Middle Ages, but a few were lost. It was for his theological writings that he earned the title of "Doctor Anglorum", and why he was declared a saint.

Bede synthesised and transmitted the learning from his predecessors, as well as made careful, judicious innovation in knowledge (such as recalculating the age of the earth—for which he was censured before surviving the heresy accusations and eventually having his views championed by Archbishop Ussher in the sixteenth century—see below) that had theological implications. In order to do this, he learned Greek, and attempted to learn Hebrew. He spent time reading and rereading both the Old and the New Testaments. He mentions that he studied from a text of Jerome's Vulgate, which itself was from the Hebrew text. He also studied both the Latin and the Greek Fathers of the Church. In the monastic library at Jarrow were a number of books by theologians, including works by Basil, Cassian, John Chrysostom, Isidore of Seville, Origen, Gregory of Nazianzus, Augustine of Hippo, Jerome, Pope Gregory I, Ambrose of Milan, Cassiodorus, and Cyprian. He used these, in conjunction with the Biblical texts themselves, to write his commentaries and other theological works. He had a Latin translation by Evagrius of Athanasius's "Life of Antony", and a copy of Sulpicius Severus' "Life of St. Martin". He also used lesser known writers, such as Fulgentius, Julian of Eclanum, Tyconius, and Prosper of Aquitaine. Bede was the first to refer to Jerome, Augustine, Pope Gregory and Ambrose as the four Latin Fathers of the Church. It is clear from Bede's own comments that he felt his calling was to explain to his students and readers the theology and thoughts of the Church Fathers.

Bede also wrote homilies, works written to explain theology used in worship services. Bede wrote homilies not only on the major Christian seasons such as Advent, Lent, or Easter, but on other subjects such as anniversaries of significant events.

Both types of Bede's theological works circulated widely in the Middle Ages. A number of his biblical commentaries were incorporated into the "Glossa Ordinaria", an 11th-century collection of biblical commentaries. Some of Bede's homilies were collected by Paul the Deacon, and they were used in that form in the Monastic Office. Saint Boniface used Bede's homilies in his missionary efforts on the continent.

Bede sometimes included in his theological books an acknowledgement of the predecessors on whose works he drew. In two cases he left instructions that his marginal notes, which gave the details of his sources, should be preserved by the copyist, and he may have originally added marginal comments about his sources to others of his works. Where he does not specify, it is still possible to identify books to which he must have had access by quotations that he uses. A full catalogue of the library available to Bede in the monastery cannot be reconstructed, but it is possible to tell, for example, that Bede was very familiar with the works of Virgil. There is little evidence that he had access to any other of the pagan Latin writers—he quotes many of these writers but the quotes are almost all to be found in the Latin grammars that were common in his day, one or more of which would certainly have been at the monastery. Another difficulty is that manuscripts of early writers were often incomplete: it is apparent that Bede had access to Pliny's "Encyclopedia", for example, but it seems that the version he had was missing book xviii, as he would almost certainly have quoted from it in his "De temporum ratione".

The works dealing with the Old Testament included "Commentary on Samuel", "Commentary on Genesis", "Commentaries on Ezra and Nehemiah", "On the Temple", "On the Tabernacle", "Commentaries on Tobit", "Commentaries on Proverbs", "Commentaries on the Song of Songs", "Commentaries on the Canticle of Habakkuk", The works on Ezra, the Tabernacle and the Temple were especially influenced by Gregory the Great's writings.

Bede's works included "Commentary on Revelation", "Commentary on the Catholic Epistles", "Commentary on Acts", "Reconsideration on the Books of Acts", "On the Gospel of Mark", "On the Gospel of Luke", and "Homilies on the Gospels". At the time of his death he was working on a translation of the Gospel of St. John into English (Early Old English). He did this for the last 40 days of his life. When the last passage had been translated he said: "All is finished."

"De temporibus", or "On Time", written in about 703, provides an introduction to the principles of Easter computus. This was based on parts of Isidore of Seville's "Etymologies", and Bede also included a chronology of the world which was derived from Eusebius, with some revisions based on Jerome's translation of the bible. In about 723, Bede wrote a longer work on the same subject, "On the Reckoning of Time", which was influential throughout the Middle Ages. He also wrote several shorter letters and essays discussing specific aspects of computus.

"On the Reckoning of Time" ("De temporum ratione") included an introduction to the traditional ancient and medieval view of the cosmos, including an explanation of how the spherical earth influenced the changing length of daylight, of how the seasonal motion of the Sun and Moon influenced the changing appearance of the New Moon at evening twilight. Bede also records the effect of the moon on tides. He shows that the twice-daily timing of tides is related to the Moon, and that the lunar monthly cycle of spring and neap tides is related also related to the Moon's position. He goes on to note that the times of tides vary along the same coast, and that the water movements cause low tide at one place when there is high tide elsewhere. Since the focus of his book was the computus, Bede gave instructions for computing the date of Easter and the related time of the Easter Full Moon, for calculating the motion of the Sun and Moon through the zodiac, and for many other calculations related to the calendar. He gives some information about the months of the Anglo-Saxon calendar in chapter XV. Any codex of Bede's Easter cycle is normally found together with a codex of his "De temporum ratione".

For calendric purposes, Bede made a new calculation of the age of the world since the creation, which he dated as 3952 BC. Due to his innovations in computing the age of the world, he was accused of heresy at the table of Bishop Wilfrid, his chronology being contrary to accepted calculations. Once informed of the accusations of these "lewd rustics," Bede refuted them in his Letter to Plegwin.

In addition to these works on astronomical timekeeping, he also wrote "De natura rerum", or "On the Nature of Things", modelled in part after the work of the same title by Isidore of Seville. His works were so influential that late in the ninth century Notker the Stammerer, a monk of the Monastery of St. Gall in Switzerland, wrote that "God, the orderer of natures, who raised the Sun from the East on the fourth day of Creation, in the sixth day of the world has made Bede rise from the West as a new Sun to illuminate the whole Earth".

Bede wrote some works designed to help teach grammar in the abbey school. One of these was his "De arte metrica", a discussion of the composition of Latin verse, drawing on previous grammarians work. It was based on Donatus' "De pedibus" and Servius' "De finalibus", and used examples from Christian poets as well as Virgil. It became a standard text for the teaching of Latin verse during the next few centuries. Bede dedicated this work to Cuthbert, apparently a student, for he is named "beloved son" in the dedication, and Bede says "I have laboured to educate you in divine letters and ecclesiastical statutes" Another textbook of Bede's is the "De orthographia", a work on orthography, designed to help a medieval reader of Latin with unfamiliar abbreviations and words from classical Latin works. Although it could serve as a textbook, it appears to have been mainly intended as a reference work. The exact date of composition for both of these works is unknown.

Another educational work is "De schematibus et tropis sacrae scripturae", which discusses the Bible's use of rhetoric. Bede was familiar with pagan authors such as Virgil, but it was not considered appropriate to teach biblical grammar from such texts, and in "De schematibus ..." Bede argues for the superiority of Christian texts in understanding Christian literature. Similarly, his text on poetic metre uses only Christian poetry for examples.

According to his disciple Cuthbert, Bede was also "doctus in nostris carminibus" ("learned in our songs"). Cuthbert's letter on Bede's death, the "Epistola Cuthberti de obitu Bedae", moreover, commonly is understood to indicate that Bede also composed a five line vernacular poem known to modern scholars as "Bede's Death Song"
As Opland notes, however, it is not entirely clear that Cuthbert is attributing this text to Bede: most manuscripts of the latter do not use a finite verb to describe Bede's presentation of the song, and the theme was relatively common in Old English and Anglo-Latin literature. The fact that Cuthbert's description places the performance of the Old English poem in the context of a series of quoted passages from Sacred Scripture, indeed, might be taken as evidence simply that Bede also cited analogous vernacular texts. On the other hand, the inclusion of the Old English text of the poem in Cuthbert's Latin letter, the observation that Bede "was learned in our song," and the fact that Bede composed a Latin poem on the same subject all point to the possibility of his having written it. By citing the poem directly, Cuthbert seems to imply that its particular wording was somehow important, either since it was a vernacular poem endorsed by a scholar who evidently frowned upon secular entertainment or because it is a direct quotation of Bede's last original composition.

There is no evidence for cult being paid to Bede in England in the 8th century. One reason for this may be that he died on the feast day of Augustine of Canterbury. Later, when he was venerated in England, he was either commemorated after Augustine on 26 May, or his feast was moved to 27 May. However, he was venerated outside England, mainly through the efforts of Boniface and Alcuin, both of whom promoted the cult on the Continent. Boniface wrote repeatedly back to England during his missionary efforts, requesting copies of Bede's theological works. Alcuin, who was taught at the school set up in York by Bede's pupil Egbert, praised Bede as an example for monks to follow and was instrumental in disseminating Bede's works to all of Alcuin's friends. Bede's cult became prominent in England during the 10th-century revival of monasticism, and by the 14th century had spread to many of the cathedrals of England. Wulfstan, Bishop of Worcester (c. 1008–1095) was a particular devotee of Bede's, dedicating a church to him in 1062, which was Wulfstan's first undertaking after his consecration as bishop.

His body was 'translated' (the ecclesiastical term for relocation of relics) from Jarrow to Durham Cathedral around 1020, where it was placed in the same tomb with Saint Cuthbert of Lindisfarne. Later Bede's remains were moved to a shrine in the Galilee Chapel at Durham Cathedral in 1370. The shrine was destroyed during the English Reformation, but the bones were reburied in the chapel. In 1831 the bones were dug up and then reburied in a new tomb, which is still there. Other relics were claimed by York, Glastonbury and Fulda.

His scholarship and importance to Catholicism were recognised in 1899 when he was declared a Doctor of the Church. He is the only Englishman named a Doctor of the Church. He is also the only Englishman in Dante's "Paradise" ("Paradiso" X.130), mentioned among theologians and doctors of the church in the same canto as Isidore of Seville and the Scot Richard of St. Victor.

His feast day was included in the General Roman Calendar in 1899, for celebration on 27 May rather than on his date of death, 26 May, which was then the feast day of Pope Gregory VII. He is venerated in both the Anglican and Catholic Church, with a feast day of 25 May, and in the Eastern Orthodox Church, with a feast day on 27 May (Βεδέα του Ομολογητού).

Bede became known as "Venerable Bede" (Lat.: Beda Venerabilis) by the 9th century because of his holiness, but this was not linked to consideration for sainthood by the Catholic Church. According to a legend the epithet was miraculously supplied by angels, thus completing his unfinished epitaph. It is first utilised in connection with Bede in the 9th century, where Bede was grouped with others who were called "venerable" at two ecclesiastical councils held at Aachen in 816 and 836. Paul the Deacon then referred to him as venerable consistently. By the 11th and 12th century, it had become commonplace. However, there are no descriptions of Bede by that term right after his death.

Bede's reputation as a historian, based mostly on the "Historia Ecclesiastica", remains strong; historian Walter Goffart says of Bede that he "holds a privileged and unrivalled place among first historians of Christian Europe". His life and work have been celebrated with the annual Jarrow Lecture, held at St. Paul's Church, Jarrow, since 1958. Jarrow Hall – Anglo-Saxon Farm, Village and Bede Museum (previously known as Bede's World), is a museum that celebrates the history of Bede and other parts of English heritage, on the site where he lived.



</doc>
<doc id="4045" url="https://en.wikipedia.org/wiki?curid=4045" title="Bubble tea">
Bubble tea

Bubble tea (also known as pearl milk tea, bubble milk tea, or boba) (, ) is a Taiwanese tea-based drink invented in Tainan and Taichung in the 1980s. Recipes contain tea of some kind, flavors of milk, and sugar (optional). Toppings, known as "pearls", such as chewy tapioca balls (also known as pearls or boba), popping boba, fruit jelly, grass jelly, agar jelly, alovera jelly, sago and puddings are often added. Ice-blended versions are frozen and put into a blender, resulting in a slushy consistency. There are many varieties of the drink with a wide range of flavors. The two most popular varieties are black pearl milk tea and green pearl milk tea.

Bubble teas fall under two categories: teas (without milk) and milk teas. Both varieties come with a choice of black, green, or oolong tea, and come in many flavors (both fruit and non-fruit). Milk teas include condensed milk, powdered milk, almond milk, coconut milk, 2% milk, skim milk, or fresh milk. Some shops offer non-dairy creamer options as well (many milk tea drinks in North America are made with non-dairy creamer). In addition, many boba shops sell Asian style smoothies, which include a dairy base and either fresh fruit or fruit-flavored powder, creating fruity flavours, such as honeydew, lemon, and many more (but no tea). Now, there are hot versions available at most shops as well.

The oldest known bubble tea consisted of a mixture of hot Taiwanese black tea, small tapioca pearls (粉圓), condensed milk, and syrup (糖漿) or honey. Many variations followed; the most common are served cold rather than hot. The most prevalent varieties of tea have changed frequently.

Bubble tea first became popular in Taiwan in the 1980s, but the original inventor is unknown. Larger tapioca pearls (波霸/黑珍珠) were adapted and quickly replaced the small pearls. Soon after, different flavors, especially fruit flavors, became popular. Flavors may be added in the form of powder, pulp, or syrup to oolong, black or green tea, which is then shaken with ice in a cocktail shaker. The tea mixture is then poured into a cup with the toppings in it.

Today, there are stores that specialize in bubble tea. Some cafés use plastic lids, but more authentic bubble tea shops serve drinks using a machine to seal the top of the cup with plastic cellophane. The latter method allows the tea to be shaken in the serving cup and makes it spill-free until one is ready to drink it. The cellophane is then pierced with an oversize straw large enough to allow the toppings to pass through. Today, in Taiwan, it is most common for people to refer to the drink as pearl milk tea (zhēn zhū nǎi chá, or zhēn nǎi for short).

Each of the ingredients of bubble tea can have many variations depending on the tea store. Typically, different types of black tea, green tea, oolong tea, and sometimes white tea are used. Another variation called yuenyeung (鴛鴦, named after the Mandarin duck) originated in Hong Kong and consists of black tea, coffee, and milk. Decaffeinated versions of teas are sometimes available when the tea house freshly brews the tea base.

Other varieties of the drink can include blended tea drinks. Some may be blended with ice cream. There are also smoothies that contain both tea and fruit.

Although bubble tea originated in Taiwan, some bubble tea shops are starting to add in flavors which originate from other countries. For example, hibiscus flowers, saffron, cardamom, and rosewater are becoming popular.

Tapioca balls (boba) are the prevailing chewy spheres in bubble tea, but a wide range of other options can be used to add similar texture to the drink. These are usually black due to the brown sugar mixed in with the tapioca. Green pearls have a small hint of green tea flavor and are chewier than the traditional tapioca balls. Jelly comes in different shapes: small cubes, stars, or rectangular strips, and flavors such as coconut jelly, konjac, lychee, grass jelly, mango, coffee and green tea available at some shops. Azuki bean or mung bean paste, typical toppings for Taiwanese shaved ice desserts, give the drinks an added subtle flavor as well as texture. Aloe, egg pudding (custard), and sago can be found in most tea houses.

Popping Boba are spheres and have fruit juices or syrups inside of them. They are also popular toppings. The many flavors include mango, lychee, strawberry, green apple, passion fruit, pomegranate, orange, cantaloupe, blueberry, coffee, chocolate, yogurt, kiwi, peach, banana, lime, cherry, pineapple, red guava, etc.

Some shops offer milk or cheese foam top off the drink too, which has a thicker consistency similar to that of whipped cream.

Bubble tea cafés will frequently offer drinks without coffee or tea in them. The dairy base for these drinks is flavoring blended with ice, often called snow bubble. All mix-ins that can be added to the bubble tea can be added to these slushie-like drinks. One drawback is that the coldness of the iced drink may cause the tapioca balls to harden, making them difficult to suck up through a straw and chew. To prevent this from happening, these slushies must be consumed more quickly than bubble tea.

Bubble tea stores often give customers the option of choosing the amount of ice or sugar, usually using percentages. Bubble tea is also offered in some restaurants, like the Michelin-awarded Din Tai Fung.

There are two competing stories for the origin of bubble tea. The Hanlin Tea Room of Tainan, Taiwan, claims that it was invented in 1986 when teahouse owner Tu Tsong-he was inspired by white tapioca balls he saw in the Ya Mu Liao market. He then made tea using the tapioca balls, resulting in the so-called "pearl tea". Shortly after, Hanlin changed the white tapioca balls to the black version, mixed with brown sugar or honey, that is seen today. At many locations, one can purchase both black tapioca balls and white tapioca balls.

The other claim is from the Chun Shui Tang tearoom in Taichung, Taiwan. Its founder, Liu Han-Chieh, observed how the Japanese served cold coffee (while on a visit in the 1980s) and applied this method to tea. The new style of serving tea propelled his business, and multiple chains were established. This expansion began the rapid expansion of bubble tea. The creator of bubble tea is Lin Hsiu Hui, the teahouse's product development manager, who randomly poured her fen yuan into the iced tea drink during a boring meeting in 1988. The beverage was well received at the meeting, leading to its inclusion on the menu. It ultimately became the franchise's top-selling product.

The drink became popular in most parts of East and Southeast Asia during the 1990s, especially Vietnam. In Malaysia, the number of brands selling the beverage has grown to over 50. The drink is well received by foreign consumers in North America, specifically around areas with high populations of Chinese and Taiwanese expatriates. Notably, in the San Francisco Bay Area of California, bubble tea is very popular and is consumed by many consumers from various backgrounds. Bubble tea has a very large presence in the Bay Area, which is populated by many of those from Chinese and Vietnamese backgrounds. Jollibee, a Filipino fast food chain, once established in Daly City, California in 1998, introduced boba on a wider scale with their semi-discontinued "Pearl Coolers", which included the tapioca in popular flavors such as ube and Buko Pandan (coconut). In contemporary times, bubble tea has achieved cultural significance outside of Taiwan in some areas for major East Asian diaspora populations.

In May 2011, occurred in Taiwan when DEHP (a chemical plasticizer) was found as a stabilizer in drinks and juice syrups. In June the Health Minister of Malaysia, Liow Tiong Lai, instructed companies selling "Strawberry Syrup", a material used in some bubble teas, to stop selling them after chemical tests showed they were tainted with DEHP.

In August 2012, scientists from the Technical University of Aachen (RWTH) in Germany analyzed bubble tea samples in a research project to look for allergenic substances. The result indicated that the products contain styrene, acetophenone, and brominated substances, which can negatively affect health. The report was published by German newspaper "Rheinische Post" and caused Taiwan's representative office in Germany to issue a statement, saying food items in Taiwan are monitored. Taiwan's Food and Drug Administration confirmed in September that, in a second round of tests conducted by German authorities, Taiwanese bubble tea was found to be free of cancer-causing chemicals. The products were also found to contain no excessive levels of heavy-metal contaminants or other health-threatening agents.

In May 2013, the Taiwan Food and Drug Administration issued an alert on the detection of maleic acid, an unapproved food additive, in some food products, including tapioca pearls. The Agri-Food & Veterinary Authority of Singapore conducted its own tests and found additional brands of tapioca pearls and some other starch-based products sold in Singapore were similarly affected.

In May 2019, around 100 undigested tapioca pearls were found in the abdomen of a 14-year-old girl in Zhejiang province, China after she complained of constipation. However, physicians believe that consuming tapioca pearls should not be a concern as it is made from starch-based cassava root which is easily digested by the body, similarly to fibre.

In July 2019, Singapore's Mount Alvernia Hospital warned against the sugar content of bubble tea since the drink had become extremely popular in Singapore in recent years. While it recognises the benefits of drinking green tea and black tea in reducing risk of cardiovascular disease, diabetes, arthritis and cancer, the hospital cautions the addition of other ingredients like non-dairy creamer and toppings in the tea, which raises the fat and sugar content of the tea and increases the risk of chronic diseases. Non-dairy creamer is a milk substitute that contains trans fat in the form of hydrogenated palm oil. The hospital warns that this oil has been strongly correlated with an increased risk of heart disease and stroke.

Bubble tea has become an icon for Asian Americans in Los Angeles and is commonly known as simply "boba" in California. Although the symbolism has also been criticised for its superficiality and lack of inclusiveness, and it is used in the pejorative "boba liberal".




</doc>
<doc id="4049" url="https://en.wikipedia.org/wiki?curid=4049" title="Battle of Blenheim">
Battle of Blenheim

The Battle of Blenheim (German: "Zweite Schlacht bei Höchstädt"; French "Bataille de Höchstädt"), fought on 13 August 1704, was a major battle of the War of the Spanish Succession. The overwhelming Allied victory ensured the safety of Vienna from the Franco-Bavarian army, thus preventing the collapse of the Grand Alliance.

Louis XIV of France sought to knock the Holy Roman Emperor, Leopold out of the war by seizing Vienna, the Habsburg capital, and gain a favourable peace settlement. The dangers to Vienna were considerable: the Elector of Bavaria and Marshal Marsin's forces in Bavaria threatened from the west, and Marshal Vendôme's large army in northern Italy posed a serious danger with a potential offensive through the Brenner Pass. Vienna was also under pressure from Rákóczi's Hungarian revolt from its eastern approaches. Realising the danger, the Duke of Marlborough resolved to alleviate the peril to Vienna by marching his forces south from Bedburg to help maintain Emperor Leopold within the Grand Alliance.

A combination of deception and skilled administration – designed to conceal his true destination from friend and foe alike – enabled Marlborough to march unhindered from the Low Countries to the River Danube in five weeks. After securing Donauwörth on the Danube, Marlborough sought to engage the Elector's and Marsin's army before Marshal Tallard could bring reinforcements through the Black Forest. However, with the Franco-Bavarian commanders reluctant to fight until their numbers were deemed sufficient, the Duke enacted a policy of plundering in Bavaria designed to force the issue. The tactic proved unsuccessful, but when Tallard arrived to bolster the Elector's army, and Prince Eugene arrived with reinforcements for the Allies, the two armies finally met on the banks of the Danube in and around the small village of Blindheim, from which the English "Blenheim" is derived.

Blenheim was one of the battles that altered the course of the war, which until then was leaning for Louis' coalition, and ended French plans of knocking the Emperor out of the war. France suffered as many as 38,000 casualties including the commander-in-chief, Marshal Tallard, who was taken captive to England. Before the 1704 campaign ended, the Allies had taken Landau, and the towns of Trier and Trarbach on the Moselle in preparation for the following year's campaign into France itself. The offensive never materialised as the Grand Alliance's army had to depart the Moselle to defend Liège from a French counteroffensive. The war would rage on for another decade.

By 1704, the War of the Spanish Succession was in its fourth year. The previous year had been one of success for France and her allies, most particularly on the Danube, where Marshal Villars and the Elector of Bavaria had created a direct threat to Vienna, the Habsburg capital. Vienna had been saved by dissension between the two commanders, leading to the brilliant Villars being replaced by the less dynamic Marshal Marsin. Nevertheless, by 1704, the threat was still real: Rákóczi's Hungarian revolt was already threatening the Empire's eastern approaches, and Marshal Vendôme's forces threatened an invasion from northern Italy. In the courts of Versailles and Madrid, Vienna's fall was confidently anticipated, an event which would almost certainly have led to the collapse of the Grand Alliance.

To isolate the Danube from any Allied intervention, Marshal Villeroi's 46,000 troops were expected to pin the 70,000 Dutch and English troops around Maastricht in the Low Countries, while General de Coigny protected Alsace against surprise with a further corps. The only forces immediately available for Vienna's defence were Prince Louis of Baden's force of 36,000 stationed in the Lines of Stollhofen to watch Marshal Tallard at Strasbourg; there was also a weak force of 10,000 men under Field Marshal Count Limburg Styrum observing Ulm.

Both the Imperial Austrian Ambassador in London, Count Wratislaw, and the Duke of Marlborough realised the implications of the situation on the Danube. The Dutch, however, who clung to their troops for their country's protection, were against any adventurous military operation as far south as the Danube and would never willingly permit any major weakening of the forces in the Spanish Netherlands. Marlborough, realising the only way to ignore Dutch wishes was by the use of secrecy and guile, set out to deceive his Dutch allies by pretending to simply move his troops to the Moselle – a plan approved of by The Hague – but once there, he would slip the Dutch leash and link up with Austrian forces in southern Germany. "My intentions", wrote the Duke from The Hague on 29 April to his governmental confidant, Sidney Godolphin, "are to march with the English to Coblenz and declare that I intend to campaign on the Moselle. But when I come there, to write to the Dutch States that I think it absolutely necessary for the saving of the Empire to march with the troops under my command and to join with those that are in Germany ... in order to make measures with Prince Lewis of Baden for the speedy reduction of the Elector of Bavaria."

Marlborough's march started on 19 May from Bedburg, north-west of Cologne. The army (assembled by the Duke's brother, General Charles Churchill) consisted of 66 squadrons, 31 battalions and 38 guns and mortars totalling 21,000 men (16,000 of whom were English troops). This force was to be augmented "en route" such that by the time Marlborough reached the Danube, it would number 40,000 (47 battalions, 88 squadrons). Whilst Marlborough led his army, General Overkirk would maintain a defensive position in the Dutch Republic in case Villeroi mounted an attack. The Duke had assured the Dutch that if the French were to launch an offensive he would return in good time, but Marlborough calculated that as he marched south, the French commander would be drawn after him. In this assumption Marlborough proved correct: Villeroi shadowed the Duke with 30,000 men in 60 squadrons and 42 battalions.

The military dangers in such an enterprise were numerous: Marlborough's lines of communication along the Rhine would be hopelessly exposed to French interference, for Louis' generals controlled the left bank of the river and its central reaches. Such a long march would almost certainly involve a high wastage of men and horses through exhaustion and disease. However, Marlborough was convinced of the urgency – "I am very sensible that I take a great deal upon me", he had earlier written to Godolphin, "but should I act otherwise, the Empire would be undone ..."
Whilst Allied preparations had progressed, the French were striving to maintain and re-supply Marshal Marsin. Marsin had been operating with the Elector of Bavaria against the Imperial commander, Prince Louis of Baden, and was somewhat isolated from France: his only lines of communication lay through the rocky passes of the Black Forest. However, on 14 May, with considerable skill Marshal Tallard managed to bring 10,000 reinforcements and vast supplies and munitions through the difficult terrain, whilst outmanoeuvring Baron Thüngen, the Imperial general who sought to block his path. Tallard then returned with his own force to the Rhine, once again side-stepping Thüngen's efforts to intercept him. The whole operation was an outstanding military achievement.

On 26 May, Marlborough reached Coblenz, where the Moselle meets the Rhine. If he intended an attack along the Moselle the Duke must now turn west, but, instead, the following day the army crossed to the right bank of the Rhine, (pausing to add 5,000 waiting Hanoverians and Prussians). "There will be no campaign on the Moselle", wrote Villeroi who had taken up a defensive position on the river, "the English have all gone up into Germany." A second possible objective now occurred to the French – an Allied incursion into Alsace and an attack on the city of Strasbourg. Marlborough skilfully encouraged this apprehension by constructing bridges across the Rhine at Philippsburg, a ruse that not only encouraged Villeroi to come to Tallard's aid in the defence of Alsace, but one that ensured the French plan to march on Vienna remained paralysed by uncertainty.

With Villeroi shadowing Marlborough's every move, Marlborough's gamble that the French would not move against the weakened Dutch position in the Netherlands paid off. In any case, Marlborough had promised to return to the Netherlands if a French attack developed there, transferring his troops down the Rhine on barges at a rate of a day. Encouraged by this promise (whatever it was worth) the States General agreed to release the Danish contingent of seven battalions and 22 squadrons as a reinforcement. Marlborough reached Ladenburg, in the plain of the Neckar and the Rhine, and there halted for three days to rest his cavalry and allow the guns and infantry to close up. On 6 June he arrived at Wiesloch, south of Heidelberg. The following day, the Allied army swung away from the Rhine towards the hills of the Swabian Jura and the Danube beyond. At last Marlborough's destination was established without doubt.

On 10 June, the Duke met for the first time the President of the Imperial War Council, Prince Eugene – accompanied by Count Wratislaw – at the village of Mundelsheim, halfway between the Danube and the Rhine. By 13 June, the Imperial Field Commander, Prince Louis of Baden, had joined them in Großheppach. The three generals commanded a force of nearly 110,000 men. At conference it was decided that Eugene would return with 28,000 men to the Lines of Stollhofen on the Rhine to keep an eye on Villeroi and Tallard and prevent them going to the aid of the Franco-Bavarian army on the Danube. Meanwhile, Marlborough's and Baden's forces would combine, totalling 80,000 men, for the march on the Danube to seek out the Elector and Marsin before they could be reinforced.

Knowing Marlborough's destination, Tallard and Villeroi met at Landau in the Palatinate on 13 June to rapidly construct a plan to save Bavaria but the rigidity of the French command system was such that any variations from the original plan had to be sanctioned by Versailles. The Count of Mérode-Westerloo, commander of the Flemish troops in Tallard's army wrote – "One thing is certain: we delayed our march from Alsace for far too long and quite inexplicably." Approval from Louis arrived on 27 June: Tallard was to reinforce Marsin and the Elector on the Danube via the Black Forest, with 40 battalions and 50 squadrons; Villeroi was to pin down the Allies defending the Lines of Stollhofen, or, if the Allies should move all their forces to the Danube, he was to join with Marshal Tallard; and General de Coignies with 8,000 men, would protect Alsace. On 1 July Tallard's army of 35,000 re-crossed the Rhine at Kehl and began its march.

On 22 June, Marlborough's forces linked up with Baden's Imperial forces at Launsheim. A distance of had been covered in five weeks. Thanks to a carefully planned time-table, the effects of wear and tear had been kept to a minimum. Captain Parker described the march discipline – "As we marched through the country of our Allies, commissars were appointed to furnish us with all manner of necessaries for man and horse ... the soldiers had nothing to do but pitch their tents, boil kettles and lie down to rest." In response to Marlborough's manoeuvres, the Elector and Marsin, conscious of their numerical disadvantage with only 40,000 men, moved their forces to the entrenched camp at Dillingen on the north bank of the Danube. Marlborough could not attack Dillingen because of a lack of siege guns – he was unable to bring any from the Low Countries, and Baden had failed to supply any despite assurances to the contrary.
The Allies, nevertheless, needed a base for provisions and a good river crossing. On 2 July, therefore, Marlborough at the Battle of Schellenberg stormed the fortress of Schellenberg on the heights above the town of Donauwörth. Count Jean d'Arco had been sent with 12,000 men from the Franco-Bavarian camp to hold the town and grassy hill but after a ferocious and bloody battle, inflicting enormous casualties on both sides, Schellenberg finally succumbed, forcing Donauwörth to surrender shortly afterwards. The Elector, knowing his position at Dillingen was now not tenable, took up a position behind the strong fortifications of Augsburg.

Tallard's march presented a dilemma for Eugene. If the Allies were not to be outnumbered on the Danube, Eugene realised he must either try to cut Tallard off before he could get there or he must hasten to reinforce Marlborough. if he withdrew from the Rhine to the Danube, Villeroi might also make a move south to link up with the Elector and Marsin. Eugene compromised: leaving 12,000 troops behind guarding the Lines of Stollhofen, he marched off with the rest of his army to forestall Tallard.

Lacking in numbers, Eugene could not seriously disrupt Tallard's march but the French Marshal's progress was proving pitifully slow. Tallard's force had suffered considerably more than Marlborough's troops on their march – many of his cavalry horses were suffering from glanders and the mountain passes were proving tough for the 2,000 wagons of provisions. Local German peasants, angry at French plundering, compounded Tallard's problems, leading Mérode-Westerloo to bemoan – "the enraged peasantry killed several thousand of our men before the army was clear of the Black Forest." Tallard had insisted on besieging the little town of Villingen for six days (16–22 July) but abandoned the enterprise on discovering the approach of Eugene.

The Elector in Augsburg was informed on 14 July that Tallard was on his way through the Black Forest. This good news bolstered the Elector's policy of inaction, further encouraging him to wait for the reinforcements. But this reticence to fight induced Marlborough to undertake a controversial policy of spoliation in Bavaria, burning buildings and crops throughout the rich lands south of the Danube. This had two aims: firstly to put pressure on the Elector to fight or come to terms before Tallard arrived with reinforcements; and secondly, to ruin Bavaria as a base from which the French and Bavarian armies could attack Vienna, or pursue the Duke into Franconia if, at some stage, he had to withdraw northwards. But this destruction, coupled with a protracted siege of Rain (9–16 July), caused Prince Eugene to lament "... since the Donauwörth action I cannot admire their performances", and later to conclude "If he has to go home without having achieved his objective, he will certainly be ruined." Nevertheless, strategically the Duke had been able to place his numerically stronger forces between the Franco-Bavarian army and Vienna.

Marshal Tallard, with 34,000 men, reached Ulm, joining with the Elector and Marsin in Augsburg on 5 August (although Tallard was not impressed to find that the Elector had dispersed his army in response to Marlborough's campaign of ravaging the region). Also on 5 August, Eugene reached Höchstädt, riding that same night to meet with Marlborough at Schrobenhausen. Marlborough knew it was necessary that another crossing point over the Danube would be required in case Donauwörth fell to the enemy. On 7 August, therefore, the first of Baden's 15,000 Imperial troops (the remainder following two days later) left Marlborough's main force to besiege the heavily defended city of Ingolstadt, farther down the Danube.

With Eugene's forces at Höchstädt on the north bank of the Danube, and Marlborough's at Rain on the south bank, Tallard and the Elector debated their next move. Tallard preferred to bide his time, replenish supplies and allow Marlborough's Danube campaign to flounder in the colder weeks of Autumn; the Elector and Marsin, however, newly reinforced, were keen to push ahead. The French and Bavarian commanders eventually agreed on a plan and decided to attack Eugene's smaller force. On 9 August, the Franco-Bavarian forces began to cross to the north bank of the Danube.

On 10 August, Eugene sent an urgent dispatch reporting that he was falling back to Donauwörth – "The enemy have marched. It is almost certain that the whole army is crossing the Danube at Lauingen ... The plain of Dillingen is crowded with troops ... Everything, milord, consists in speed and that you put yourself forthwith in movement to join me tomorrow, without which I fear it will be too late." By a series of brilliant marches Marlborough concentrated his forces on Donauwörth and, by noon 11 August, the link-up was complete.

During 11 August, Tallard pushed forward from the river crossings at Dillingen; by 12 August, the Franco-Bavarian forces were encamped behind the small river Nebel near the village of Blenheim on the plain of Höchstädt. That same day Marlborough and Eugene carried out their own reconnaissance of the French position from the church spire at Tapfheim, and moved their combined forces to Münster – from the French camp. A French reconnaissance under the Marquis de Silly went forward to probe the enemy, but were driven off by Allied troops who had deployed to cover the pioneers of the advancing army, labouring to bridge the numerous streams in the area and improve the passage leading westwards to Höchstädt. Marlborough quickly moved forward two brigades under the command of General Wilkes and Brigadier Rowe to secure the narrow strip of land between the Danube and the wooded Fuchsberg hill, at the Schwenningen defile.

Tallard's army numbered 56,000 men and 90 guns; the army of the Grand Alliance, 52,000 men and 66 guns. Some Allied officers who were acquainted with the superior numbers of the enemy, and aware of their strong defensive position, ventured to remonstrate with Marlborough about the hazards of attacking; but the Duke was resolute – "I know the danger, yet a battle is absolutely necessary, and I rely on the bravery and discipline of the troops, which will make amends for our disadvantages". Marlborough and Eugene decided to risk everything, and agreed to attack on the following day.

The battlefield stretched for nearly . The extreme right flank of the Franco-Bavarian army was covered by the Danube; to the extreme left flank lay the undulating pine-covered hills of the Swabian Jura. A small stream, the Nebel, (the ground either side of which was soft and marshy and only fordable intermittently), fronted the French line. The French right rested on the village of Blenheim near where the Nebel flows into the Danube; the village itself was surrounded by hedges, fences, enclosed gardens, and meadows. Between Blenheim and the next village of Oberglauheim the fields of wheat had been cut to stubble and were now ideal to deploy troops. From Oberglauheim to the next hamlet of Lutzingen the terrain of ditches, thickets and brambles was potentially difficult ground for the attackers.

At 02:00 on 13 August 40 squadrons were sent forward towards the enemy, followed at 03:00, in eight columns, by the main Allied force pushing over the Kessel. At about 06:00 they reached Schwenningen, from Blenheim. The English and German troops who had held Schwenningen through the night joined the march, making a ninth column on the left of the army. Marlborough and Eugene made their final plans. The Allied commanders agreed that Marlborough would command 36,000 troops and attack Tallard's force of 33,000 on the left (including capturing the village of Blenheim), whilst Eugene, commanding 16,000 men would attack the Elector and Marsin's combined forces of 23,000 troops on the right wing; if this attack was pressed hard the Elector and Marsin would have no troops to send to aid Tallard on their right. Lieutenant-General John Cutts would attack Blenheim in concert with Eugene's attack. With the French flanks busy, Marlborough could cross the Nebel and deliver the fatal blow to the French at their centre. However, Marlborough would have to wait until Eugene was in position before the general engagement could begin.

The last thing Tallard expected that morning was to be attacked by the Allies – deceived by intelligence gathered from prisoners taken by de Silly the previous day, and assured in their strong natural position, Tallard and his colleagues were convinced that Marlborough and Eugene were about to retreat north-eastwards towards Nördlingen. Tallard wrote a report to this effect to King Louis that morning, but hardly had he sent the messenger when the Allied army began to appear opposite his camp. "I could see the enemy advancing ever closer in nine great columns", wrote Mérode-Westerloo, " ... filling the whole plain from the Danube to the woods on the horizon." Signal guns were fired to bring in the foraging parties and pickets as the French and Bavarian troops tried to draw into battle-order to face the unexpected threat.

At about 08:00 the French artillery on their right wing opened fire, answered by Colonel Blood's batteries. The guns were heard by Baden in his camp before Ingolstadt, "The Prince and the Duke are engaged today to the westward", he wrote to the Emperor. "Heaven bless them." An hour later Tallard, the Elector, and Marsin climbed Blenheim's church tower to finalise their plans. It was settled that the Elector and Marsin would hold the front from the hills to Oberglauheim, whilst Tallard would defend the ground between Oberglauheim and the Danube. The French commanders were, however, divided as to how to utilise the Nebel: Tallard's tactic – opposed by Marsin and the Elector who felt it better to close their infantry right up to the stream itself – was to lure the allies across before unleashing their cavalry upon them, causing panic and confusion; whilst the enemy was struggling in the marshes, they would be caught in crossfire from Blenheim and Oberglauheim. The plan was sound if all its parts were implemented, but it allowed Marlborough to cross the Nebel without serious interference and fight the battle he had in mind.

The Franco-Bavarian commanders deployed their forces. In the village of Lutzingen, Count Maffei positioned five Bavarian battalions with a great battery of 16 guns at the village's edge. In the woods to the left of Lutzingen, seven French battalions under the Marquis de Rozel moved into place. Between Lutzingen and Oberglauheim the Elector placed 27 squadrons of cavalry – Count d'Arco commanded 14 Bavarian squadrons and Count Wolframsdorf had 13 more in support nearby. To their right stood Marsin's 40 French squadrons and 12 battalions. The village of Oberglauheim was packed with 14 battalions commanded by the Marquis de Blainville (including the effective Irish Brigade known as the 'Wild Geese'). Six batteries of guns were ranged alongside the village. On the right of these French and Bavarian positions, between Oberglauheim and Blenheim, Tallard deployed 64 French and Walloon squadrons (16 drawn from Marsin) supported by nine French battalions standing near the Höchstädt road. In the cornfield next to Blenheim stood three battalions from the Regiment de Roi. Nine battalions occupied the village itself, commanded by the Marquis de Clérambault. Four battalions stood to the rear and a further 11 were in reserve. These battalions were supported by Hautefeuille's 12 squadrons of dismounted dragoons. By 11:00 Tallard, the Elector, and Marsin were in place. Many of the Allied generals were hesitant to attack such a relatively strong position. The Earl of Orkney later confessed that, "had I been asked to give my opinion, I had been against it."

Prince Eugene was expected to be in position by 11:00, but due to the difficult terrain and enemy fire, progress was slow. Lord Cutts' column – who by 10:00 had expelled the enemy from two water mills upon the Nebel – had already deployed by the river against Blenheim, enduring over the next three hours severe fire from a heavy six-gun battery posted near the village. The rest of Marlborough's army, waiting in their ranks on the forward slope, were also forced to bear the cannonade from the French artillery, suffering 2,000 casualties before the attack could even start. Meanwhile, engineers repaired a stone bridge across the Nebel, and constructed five additional bridges or causeways across the marsh between Blenheim and Oberglauheim. Marlborough's anxiety was finally allayed when, just past noon, Colonel Cadogan reported that Eugene's Prussian and Danish infantry were in place – the order for the general advance was given. At 13:00, Cutts was ordered to attack the village of Blenheim whilst Prince Eugene was requested to assault Lutzingen on the Allied right flank.

Cutts ordered Brigadier-General Archibald Rowe's brigade to attack. The English infantry rose from the edge of the Nebel, and silently marched towards Blenheim, a distance of some . John Ferguson's Scottish brigade supported Rowe's left, and moved in perfect order towards the barricades between the village and the river, defended by Hautefeuille's dragoons. As the range closed to within , the French fired a deadly volley. Rowe had ordered that there should be no firing from his men until he struck his sword upon the palisades, but as he stepped forward to give the signal, he fell mortally wounded. The survivors of the leading companies closed up the gaps in their torn ranks and rushed forward. Small parties penetrated the defences, but repeated French volleys forced the English back towards the Nebel, sustaining heavy casualties. As the attack faltered, eight squadrons of elite Gens d'Armes, commanded by the veteran Swiss officer, Beat-Jacques von Zurlauben, fell upon the English troops, cutting at the exposed flank of Rowe's own regiment. However, Wilkes' Hessian brigade, lying nearby in the marshy grass at the water's edge, stood firm and repulsed the Gens d'Armes with steady fire, enabling the English and Hessians to re-order and launch another attack.

Although the Allies were again repulsed, these persistent attacks on Blenheim eventually bore fruit, panicking Clérambault into making the worst French error of the day. Without consulting Tallard, Clérambault ordered his reserve battalions into the village, upsetting the balance of the French position and nullifying the French numerical superiority. "The men were so crowded in upon one another", wrote Mérode-Westerloo, "that they couldn't even fire – let alone receive or carry out any orders." Marlborough, spotting this error, now countermanded Cutts' intention to launch a third attack, and ordered him simply to contain the enemy within Blenheim; no more than 5,000 Allied soldiers were able to pen in twice the number of French infantry and dragoons.

On the Allied right, Eugene's Prussian and Danish forces were desperately fighting the numerically superior forces of the Elector and Marsin. The Prince of Anhalt-Dessau led forward four brigades across the Nebel to assault the well-fortified position of Lutzingen. Here, the Nebel was less of an obstacle, but the great battery positioned on the edge of the village enjoyed a good field of fire across the open ground stretching to the hamlet of Schwennenbach. As soon as the infantry crossed the stream, they were struck by Maffei's infantry, and salvoes from the Bavarian guns positioned both in front of the village and in enfilade on the wood-line to the right. Despite heavy casualties the Prussians attempted to storm the great battery, whilst the Danes, under Count Scholten, attempted to drive the French infantry out of the copses beyond the village.

With the infantry heavily engaged, Eugene's cavalry picked its way across the Nebel. After an initial success, his first line of cavalry, under the Imperial General of Horse, Prince Maximilian of Hanover, were pressed by the second line of Marsin's cavalry, and were forced back across the Nebel in confusion. Nevertheless, the exhausted French were unable to follow up their advantage, and the two cavalry forces tried to regroup and reorder their ranks. However, without cavalry support, and threatened with envelopment, the Prussian and Danish infantry were in turn forced to pull back across the Nebel. Panic gripped some of Eugene's troops as they crossed the stream. Ten infantry colours were lost to the Bavarians, and hundreds of prisoners taken; it was only through the leadership of Eugene and the Prussian Prince that the imperial infantry were prevented from abandoning the field.

After rallying his troops near Schwennenbach – well beyond their starting point – Eugene prepared to launch a second attack, led by the second-line squadrons under the Duke of Württemberg-Teck. Yet again they were caught in the murderous cross-fire from the artillery in Lutzingen and Oberglauheim, and were once again thrown back in disarray. The French and Bavarians, however, were almost as disordered as their opponents, and they too were in need of inspiration from their commander, the Elector, who was seen " ... riding up and down, and inspiring his men with fresh courage." Anhalt-Dessau's Danish and Prussian infantry attacked a second time but could not sustain the advance without proper support. Once again they fell back across the stream.

Whilst these events around Blenheim and Lutzingen were taking place, Marlborough was preparing to cross the Nebel. The centre, commanded by the Duke's brother, General Charles Churchill, consisted of 18 battalions of infantry arranged in two lines: seven battalions in the front line to secure a foothold across the Nebel, and 11 battalions in the rear providing cover from the Allied side of the stream. Between the infantry were placed two lines, 72 squadrons of cavalry. The first line of foot was to pass the stream first and march as far to the other side as could be conveniently done. This line would then form and cover the passage of the horse, leaving gaps in the line of infantry large enough for the cavalry to pass through and take their position in front.

Marlborough ordered the formation forward. Once again Zurlauben's Gens d'Armes charged, looking to rout Lumley's English cavalry who linked Cutts' column facing Blenheim with Churchill's infantry. As these elite French cavalry attacked, they were faced by five English squadrons under Colonel Francis Palmes. To the consternation of the French, the Gens d'Armes were pushed back in terrible confusion, pursued well beyond the Maulweyer stream that flows through Blenheim. "What? Is it possible?" exclaimed the Elector, "the gentlemen of France fleeing?" Palmes, however, attempted to follow up his success but was repulsed in some confusion by other French cavalry, and musket fire from the edge of Blenheim.

Nevertheless, Tallard was alarmed by the repulse of the elite Gens d'Armes and urgently rode across the field to ask Marsin for reinforcements; but on the basis of being hard pressed by Eugene – whose second attack was in full flood – Marsin refused. As Tallard consulted with Marsin, more of his infantry was being taken into Blenheim by Clérambault. Fatally, Tallard, aware of the situation, did nothing to rectify this grave mistake, leaving him with just the nine battalions of infantry near the Höchstädt road
to oppose the massed enemy ranks in the centre. Zurlauben tried several more times to disrupt the Allies forming on Tallard's side of the stream; his front-line cavalry darting forward down the gentle slope towards the Nebel. But the attacks lacked co-ordination, and the Allied infantry's steady volleys disconcerted the French horsemen. During these skirmishes Zurlauben fell mortally wounded, and died two days later. The time was just after 15:00.

The Danish cavalry, under the Duke of Württemberg-Neuenstadt (not to be confused with the Duke of Württemberg who fought with Eugene), had made slow work of crossing the Nebel near Oberglau; harassed by Marsin's infantry near the village, the Danes were driven back across the stream. Count Horn's Dutch infantry managed to push the French back from the water's edge, but it was apparent that before Marlborough could launch his main effort against Tallard, Oberglauheim would have to be secured.

Count Horn directed the Prince of Holstein-Beck to take the village, but his two Dutch brigades were cut down by the French and Irish troops, capturing and badly wounding the Prince during the action. The battle was now in the balance. If Holstein-Beck's Dutch column were destroyed, the Allied army would be split in two: Eugene's wing would be isolated from Marlborough's, passing the initiative to the Franco-Bavarian forces now engaged across the whole plain. Seeing the opportunity, Marsin ordered his cavalry to change from facing Eugene, and turn towards their right and the open flank of Churchill's infantry drawn up in front of Unterglau. Marlborough (who had crossed the Nebel on a makeshift bridge to take personal control), ordered Hulsen's Hanoverian battalions to support the Dutch infantry. A Dutch cavalry brigade under Averock was also called forward but soon came under pressure from Marsin's more numerous squadrons.

Marlborough now requested Eugene to release Count Hendrick Fugger and his Imperial Cuirassier brigade to help repel the French cavalry thrust. Despite his own desperate struggle, the Imperial Prince at once complied, demonstrating the high degree of confidence and mutual co-operation between the two generals. Although the Nebel stream lay between Fugger's and Marsin's squadrons, the French were forced to change front to meet this new threat, thus forestalling the chance for Marsin to strike at Marlborough's infantry. Fugger's cuirassiers charged and, striking at a favourable angle, threw back Marsin's squadrons in disorder. With support from Colonel Blood's batteries, the Hessian, Hanoverian and Dutch infantry – now commanded by Count Berensdorf – succeeded in pushing the French and Irish infantry back into Oberglauheim so that they could not again threaten Churchill's flank as he moved against Tallard. The French commander in the village, the Marquis de Blainville, numbered amongst the heavy casualties.

By 16:00, with the Franco-Bavarian troops besieged in Blenheim and Oberglau, the Allied centre of 81 squadrons (nine squadrons had been transferred from Cutts' column), supported by 18 battalions was firmly planted amidst the French line of 64 squadrons and nine battalions of raw recruits. There was now a pause in the battle: Marlborough wanted to concert the attack upon the whole front, and Eugene, after his second repulse, needed time to reorganise.

Just after 17:00 all was ready along the Allied front. Marlborough's two lines of cavalry had now moved to the front of the Duke's line of battle, with the two supporting lines of infantry behind them. Mérode-Westerloo attempted to extricate some French infantry crowded in Blenheim, but Clérambault ordered the troops back into the village. The French cavalry exerted themselves once more against the first line – Lumley's English and Scots on the Allied left, and Hompesch's Dutch and German squadrons on the Allied right. Tallard's squadrons, lacking infantry support, were tired and ragged but managed to push the Allied first line back to their infantry support. With the battle still not won, Marlborough had to rebuke one of his cavalry officers who was attempting to leave the field – "Sir, you are under a mistake, the enemy lies that way ..." Now, at the Duke's command, the second Allied line under Cuno Josua von Bülow and Bothmer was ordered forward, and, driving through the centre, the Allies finally put Tallard's tired horse to rout, though not without cost. The Prussian Life Dragoons' Colonel, Ludwig von Blumenthal, and his 2nd in command, Lt. Col. von Hacke, fell next to each other. But the charge succeeded and with their cavalry in headlong flight, the remaining nine French infantry battalions fought with desperate valour, trying to form square. But it was futile. The French battalions were overwhelmed by Colonel Blood's close-range artillery and platoon fire. Mérode-Westerloo later wrote – "[They] died to a man where they stood, stationed right out in the open plain – supported by nobody."

The majority of Tallard's retreating troops headed for Höchstädt but most did not make the safety of the town, plunging instead into the Danube where upwards of 3,000 French horsemen drowned; others were cut down by the pursuing cavalry. The Marquis de Gruignan attempted a counter-attack, but he was easily brushed aside by the triumphant Allies. After a final rally behind his camp's tents, shouting entreaties to stand and fight, Marshal Tallard was caught up in the rout and pushed towards Sonderheim. Surrounded by a squadron of Hessian troops, Tallard surrendered to Lieutenant-Colonel de Boinenburg, the Prince of Hesse-Kassel's "aide-de-camp", and was sent under escort to Marlborough. The Duke welcomed the French commander – "I am very sorry that such a cruel misfortune should have fallen upon a soldier for whom I have the highest regard." With salutes and courtesies, the Marshal was escorted to Marlborough's coach.

Meanwhile, the Allies had once again attacked the Bavarian stronghold at Lutzingen.
Eugene, however, became exasperated with the performance of his Imperial cavalry whose third attack had failed: he had already shot two of his troopers to prevent a general flight. Then, declaring in disgust that he wished to "fight among brave men and not among cowards", Eugene went into the attack with the Prussian and Danish infantry, as did the Dessauer, waving a regimental colour to inspire his troops. This time the Prussians were able to storm the great Bavarian battery, and overwhelm the guns' crews. Beyond the village, Scholten's Danes defeated the French infantry in a desperate hand-to-hand bayonet struggle. When they saw that the centre had broken, the Elector and Marsin decided the battle was lost and, like the remnants of Tallard's army, fled the battlefield (albeit in better order than Tallard's men). Attempts to organise an Allied force to prevent Marsin's withdrawal failed owing to the exhaustion of the cavalry, and the growing confusion in the field.
Marlborough now had to turn his attention from the fleeing enemy to direct Churchill to detach more infantry to storm Blenheim. Orkney's infantry, Hamilton's English brigade and St Paul's Hanoverians moved across the trampled wheat to the cottages. Fierce hand-to-hand fighting gradually forced the French towards the village centre, in and around the walled churchyard which had been prepared for defence. Hay and Ross's dismounted dragoons were also sent, but suffered under a counter-charge delivered by the regiments of Artois and Provence under command of Colonel de la Silvière. Colonel Belville's Hanoverians were fed into the battle to steady the resolve of the dragoons, and once more went to the attack. The Allied progress was slow and hard, and like the defenders, they suffered many casualties.

Many of the cottages were now burning, obscuring the field of fire and driving the defenders out of their positions. Hearing the din of battle in Blenheim, Tallard sent a message to Marlborough offering to order the garrison to withdraw from the field.
"Inform Monsieur Tallard", replied the Duke, "that, in the position in which he is now, he has no command." Nevertheless, as dusk came the Allied commander was anxious for a quick conclusion. The French infantry fought tenaciously to hold on to their position in Blenheim, but their commander was nowhere to be found. Clérambault's insistence on confining his huge force in the village was to seal his fate that day. Realising his tactical mistake had contributed to Tallard's defeat in the centre, Clérambault deserted Blenheim and the 27 battalions defending the village, and reportedly drowned in the Danube while attempting to make his escape.

By now Blenheim was under assault from every side by three British generals: Cutts, Churchill, and Orkney. The French had repulsed every attack with heavy slaughter, but many had seen what had happened on the plain and what its consequences to them would be; their army was routed and they were cut off. Orkney, attacking from the rear, now tried a different tactic – "... it came into my head to beat parley", he later wrote, "which they accepted of and immediately their Brigadier de Nouville capitulated with me to be prisoner at discretion and lay down their arms." Threatened by Allied guns, other units followed their example. However, it was not until 21:00 that the Marquis de Blanzac, who had taken charge in Clérambault's absence, reluctantly accepted the inevitability of defeat, and some 10,000 of France's best infantry had laid down their arms.

During these events Marlborough was still in the saddle conducting the pursuit of the broken enemy. Pausing for a moment he scribbled on the back of an old tavern bill a note addressed to his wife, Sarah: "I have no time to say more but to beg you will give my duty to the Queen, and let her know her army has had a glorious victory."

French losses were immense, with over 27,000 killed, wounded and captured. Moreover, the myth of French invincibility had been destroyed and Louis's hopes of an early and victorious peace had been wrenched from his grasp. Mérode-Westerloo summarised the case against Tallard's army: "The French lost this battle for a wide variety of reasons. For one thing they had too good an opinion of their own ability ... Another point was their faulty field dispositions, and in addition there was rampant indiscipline and inexperience displayed ... It took all these faults to lose so celebrated a battle." It was a hard-fought contest, leading Prince Eugene to observe – "I have not a squadron or battalion which did not charge four times at least."

Although the war dragged on for years, the Battle of Blenheim was probably its most decisive victory; Marlborough and Eugene, working indivisibly together, had saved the Habsburg Empire and thereby preserved the Grand Alliance from collapse. Munich, Augsburg, Ingolstadt, Ulm and all remaining territory of Bavaria soon fell to the Allies. By the Treaty of Ilbersheim, signed 7 November 1704, Bavaria was placed under Austrian military rule, allowing the Habsburgs to use its resources for the rest of the conflict.

The remnants of the Elector of Bavaria's and Marshal Marsin's wing limped back to Strasbourg, losing another 7,000 men through desertion. Despite being offered the chance to remain as ruler of Bavaria (under strict terms of an alliance with Austria), the Elector left his country and family in order to continue the war against the Allies from the Spanish Netherlands where he still held the post of governor-general. Their commander-in-chief that day, Marshal Tallard – who, unlike his subordinates, had not been ransomed or exchanged – was taken to England and imprisoned in Nottingham until his release in 1711.

The 1704 campaign lasted considerably longer than usual as the Allies sought to wring out maximum advantage. Realising that France was too powerful to be forced to make peace by a single victory, however, Eugene, Marlborough and Baden met to plan their next moves. For the following year the Duke proposed a campaign along the valley of the River Moselle to carry the war deep into France. This required the capture of the major fortress of Landau which guarded the Rhine, and the towns of Trier and Trarbach on the Moselle itself. Trier was taken on 27 October and Landau fell on 23 November to the Margrave of Baden and Prince Eugene; with the fall of Trarbach on 20 December, the campaign season for 1704 came to an end.

Marlborough returned to England on 14 December (O.S) to the acclamation of Queen Anne and the country. In the first days of January the 110 cavalry standards and the 128 infantry colours that were taken during the battle were borne in procession to Westminster Hall. In February 1705, Queen Anne, who had made Marlborough a Duke in 1702, granted him the Park of Woodstock and promised a sum of £240,000 to build a suitable house as a gift from a grateful crown in recognition of his victory – a victory which British historian Sir Edward Shepherd Creasy considered one of the pivotal battles in history, writing – "Had it not been for Blenheim, all Europe might at this day suffer under the effect of French conquests resembling those of Alexander in extent and those of the Romans in durability." However, military historian John A. Lynn consider this claim unjustified as Louis XIV never laboured such objective, as the campaign in Bavaria was intended to bring only a favourable peace settlement and not domination over Europe.

The famous Lake poet Robert Southey scathingly criticised the Battle of Blenheim in his anti war poem After Blenheim. However Robert Southey himself is said to have later praised the victory. The poem points out the complacency of the public and lack of curiosity



</doc>
<doc id="4050" url="https://en.wikipedia.org/wiki?curid=4050" title="Battle of Ramillies">
Battle of Ramillies

The Battle of Ramillies (), fought on 23 May 1706, was a battle of the War of the Spanish Succession. For the Grand Alliance – Austria, England, and the Dutch Republic – the battle had followed an indecisive campaign against the Bourbon armies of King Louis XIV of France in 1705. Although the Allies had captured Barcelona that year, they had been forced to abandon their campaign on the Moselle, had stalled in the Spanish Netherlands and suffered defeat in northern Italy. Yet despite his opponents' setbacks Louis XIV wanted peace, but on reasonable terms. Because of this, as well as to maintain their momentum, the French and their allies took the offensive in 1706.

The campaign began well for Louis XIV's generals: in Italy Marshal Vendôme defeated the Austrians at the Battle of Calcinato in April, while in Alsace Marshal Villars forced the Margrave of Baden back across the Rhine. Encouraged by these early gains Louis XIV urged Marshal Villeroi to go over to the offensive in the Spanish Netherlands and, with victory, gain a 'fair' peace. Accordingly, the French Marshal set off from Leuven ("Louvain") at the head of 60,000 men and marched towards Tienen ("Tirlemont"), as if to threaten Zoutleeuw ("Léau"). Also determined to fight a major engagement, the Duke of Marlborough, commander-in-chief of Anglo-Dutch forces, assembled his army – some 62,000 men – near Maastricht, and marched past Zoutleeuw. With both sides seeking battle, they soon encountered each other on the dry ground between the Mehaigne and Petite Gheete rivers, close to the small village of Ramillies.

In less than four hours Marlborough's Dutch, English, and Danish forces overwhelmed Villeroi's and Max Emanuel's Franco-Spanish-Bavarian army. The Duke's subtle moves and changes in emphasis during the battle – something his opponents failed to realise until it was too late – caught the French in a tactical vice. With their foe broken and routed, the Allies were able to fully exploit their victory. Town after town fell, including Brussels, Bruges and Antwerp; by the end of the campaign Villeroi's army had been driven from most of the Spanish Netherlands. With Prince Eugene's subsequent success at the Battle of Turin in northern Italy, the Allies had imposed the greatest loss of territory and resources that Louis XIV would suffer during the war. Thus, the year 1706 proved, for the Allies, to be an "annus mirabilis".

After their disastrous defeat at Blenheim in 1704, the next year brought the French some respite. The Duke of Marlborough had intended the 1705 campaign – an invasion of France through the Moselle valley – to complete the work of Blenheim and persuade King Louis XIV to make peace but the plan had been thwarted by friend and foe alike. The reluctance of his Dutch allies to see their frontiers denuded of troops for another gamble in Germany had denied Marlborough the initiative but of far greater importance was the Margrave of Baden’s pronouncement that he could not join the Duke in strength for the coming offensive. This was in part due to the sudden switching of troops from the Rhine to reinforce Prince Eugene in Italy and part due to the deterioration of Baden's health brought on by the re-opening of a severe foot wound he had received at the storming of the Schellenberg the previous year. Marlborough had to cope with the death of Emperor Leopold I in May and the accession of Joseph I, which unavoidably complicated matters for the Grand Alliance.

The resilience of the French King and the efforts of his generals, also added to Marlborough's problems. Marshal Villeroi, exerting considerable pressure on the Dutch commander, Count Overkirk, along the Meuse, took Huy on 10 June before pressing on towards Liège. With Marshal Villars sitting strong on the Moselle, the Allied commander – whose supplies had by now become very short – was forced to call off his campaign on 16 June. "What a disgrace for Marlborough," exulted Villeroi, "to have made false movements without any result!" With Marlborough's departure north, the French transferred troops from the Moselle valley to reinforce Villeroi in Flanders, while Villars marched off to the Rhine.

The Anglo-Dutch forces gained minor compensation for the failed Moselle campaign with the success at Elixheim and the crossing of the Lines of Brabant in the Spanish Netherlands (Huy was also retaken on 11 July) but a chance to bring the French to a decisive engagement eluded Marlborough. The year 1705 proved almost entirely barren for the Duke, whose military disappointments were only partly compensated by efforts on the diplomatic front where, at the courts of Düsseldorf, Frankfurt, Vienna, Berlin and Hanover, Marlborough sought to bolster support for the Grand Alliance and extract promises of prompt assistance for the following year's campaign.

On 11 January 1706, Marlborough finally reached London at the end of his diplomatic tour but he had already been planning his strategy for the coming season. The first option (although it is debatable to what extent the Duke was committed to such an enterprise) was a plan to transfer his forces from the Spanish Netherlands to northern Italy; once there, he intended linking up with Prince Eugene in order to defeat the French and safeguard Savoy from being overrun. Savoy would then serve as a gateway into France by way of the mountain passes or an invasion with naval support along the Mediterranean coast via Nice and Toulon, in connexion with redoubled Allied efforts in Spain. It seems that the Duke's favoured scheme was to return to the Moselle valley (where Marshal Marsin had recently taken command of French forces) and once more attempt an advance into the heart of France. But these decisions soon became academic. Shortly after Marlborough landed in the Dutch Republic on 14 April, news arrived of big Allied setbacks in the wider war.

Determined to show the Grand Alliance that France was still resolute, Louis XIV prepared to launch a double surprise in Alsace and northern Italy. On the latter front Marshal Vendôme defeated the Imperial army at Calcinato on 19 April, pushing the Imperialists back in confusion (French forces were now in a position to prepare for the long-anticipated siege of Turin). In Alsace, Marshal Villars took Baden by surprise and captured Haguenau, driving him back across the Rhine in some disorder, thus creating a threat on Landau. With these reverses, the Dutch refused to contemplate Marlborough's ambitious march to Italy or any plan that denuded their borders of the Duke and their army. In the interest of coalition harmony, Marlborough prepared to campaign in the Low Countries.

The Duke left The Hague on 9 May. "God knows I go with a heavy heart," he wrote six days later to his friend and political ally in England, Lord Godolphin, "for I have no hope of doing anything considerable, unless the French do what I am very confident they will not … " – in other words, court battle. On 17 May the Duke concentrated his Dutch and English troops at Tongeren, near Maastricht. The Hanoverians, Hessians and Danes, despite earlier undertakings, found, or invented, pressing reasons for withholding their support. Marlborough wrote an appeal to the Duke of Württemberg, the commander of the Danish contingent – "I send you this express to request your Highness to bring forward by a double march your cavalry so as to join us at the earliest moment …" Additionally, the King "in" Prussia, Frederick I, had kept his troops in quarters behind the Rhine while his personal disputes with Vienna and the States General at The Hague remained unresolved. Nevertheless, the Duke could think of no circumstances why the French would leave their strong positions and attack his army, even if Villeroi was first reinforced by substantial transfers from Marsin's command. But in this he had miscalculated. Although Louis XIV wanted peace he wanted it on reasonable terms; for that, he needed victory in the field and to convince the Allies that his resources were by no means exhausted.

Following the successes in Italy and along the Rhine, Louis XIV was now hopeful of similar results in Flanders. Far from standing on the defensive therefore – and unbeknown to Marlborough – Louis XIV was persistently goading his marshal into action. "[Villeroi] began to imagine," wrote St Simon, "that the King doubted his courage, and resolved to stake all at once in an effort to vindicate himself." Accordingly, on 18 May, Villeroi set off from Leuven at the head of 70 battalions, 132 squadrons and 62 cannon – comprising an overall force of some 60,000 troops – and crossed the river Dyle to seek battle with the enemy. Spurred on by his growing confidence in his ability to out-general his opponent, and by Versailles’ determination to avenge Blenheim, Villeroi and his generals anticipated success.

Neither opponent expected the clash at the exact moment or place where it occurred. The French moved first to Tienen, (as if to threaten Zoutleeuw, abandoned by the French in October 1705), before turning southwards, heading for Jodoigne – this line of march took Villeroi's army towards the narrow aperture of dry ground between the Mehaigne and Petite Gheete rivers close to the small villages of Ramillies and Taviers; but neither commander quite appreciated how far his opponent had travelled. Villeroi still believed (on 22 May) the Allies were a full day's march away when in fact they had camped near Corswaren waiting for the Danish squadrons to catch up; for his part, Marlborough deemed Villeroi still at Jodoigne when in reality he was now approaching the plateau of Mont St. André with the intention of pitching camp near Ramillies (see map at right). However, the Prussian infantry was not there. Marlborough wrote to Lord Raby, the English resident at Berlin: "If it should please God to give us victory over the enemy, the Allies will be little obliged to the King [Frederick] for the success."

The following day, at 01:00, Marlborough dispatched Cadogan, his Quartermaster-General, with an advanced guard to reconnoitre the same dry ground that Villeroi's army was now heading toward, country that was well known to the Duke from previous campaigns. Two hours later the Duke followed with the main body: 74 battalions, 123 squadrons, 90 pieces of artillery and 20 mortars, totalling 62,000 troops. At about 08:00, after Cadogan had just passed Merdorp, his force made brief contact with a party of French hussars gathering forage on the edge of the plateau of Jandrenouille. After a brief exchange of shots the French retired and Cadogan's dragoons pressed forward. With a short lift in the mist, Cadogan soon discovered the smartly ordered lines of Villeroi's advance guard some off; a galloper hastened back to warn Marlborough. Two hours later the Duke, accompanied by the Dutch field commander Field Marshal Overkirk, General Daniel Dopff, and the Allied staff, rode up to Cadogan where on the horizon to the westward he could discern the massed ranks of the French army deploying for battle along the front. Marlborough later told Bishop Burnet that, ‘the French army looked the best of any he had ever seen’.

The battlefield of Ramillies is very similar to that of Blenheim, for here too there is an immense area of arable land unimpeded by woods or hedges. Villeroi's right rested on the villages of Franquenée and Taviers, with the river Mehaigne protecting his flank. A large open plain, about wide, lay between Taviers and Ramillies, but unlike Blenheim, there was no stream to hinder the cavalry. His centre was secured by Ramillies itself, lying on a slight eminence which gave distant views to the north and east. The French left flank was protected by broken country, and by a stream, the Petite Gheete, which runs deep between steep and slippery slopes. On the French side of the stream the ground rises to Offus, the village which, together with Autre-Eglise farther north, anchored Villeroi's left flank. To the west of the Petite Gheete rises the plateau of Mont St. André; a second plain, the plateau of Jandrenouille – upon which the Anglo-Dutch army amassed – rises to the east.

At 11:00, the Duke ordered the army to take standard battle formation. On the far right, towards Foulz, the British battalions and squadrons took up their posts in a double line near the Jeuche stream. The centre was formed by the mass of Dutch, German, Protestant Swiss and Scottish infantry – perhaps 30,000 men – facing Offus and Ramillies. Also facing Ramillies Marlborough placed a powerful battery of thirty 24-pounders, dragged into position by a team of oxen; further batteries were positioned overlooking the Petite Gheete. On their left, on the broad plain between Taviers and Ramillies – and where Marlborough thought the decisive encounter must take place – Overkirk drew the 69 squadrons of the Dutch and Danish horse, supported by 19 battalions of Dutch infantry and two artillery pieces.

Meanwhile, Villeroi deployed his forces. In Taviers on his right, he placed two battalions of the Greder Suisse Régiment, with a smaller force forward in Franquenée; the whole position was protected by the boggy ground of the Mehaigne river, thus preventing an Allied flanking movement. In the open country between Taviers and Ramillies, he placed 82 squadrons under General de Guiscard supported by several interleaved brigades of French, Swiss and Bavarian infantry. Along the Ramillies–Offus–Autre Eglise ridge-line, Villeroi positioned Walloon and Bavarian infantry, supported by the Elector of Bavaria's 50 squadrons of Bavarian and Walloon cavalry placed behind on the plateau of Mont St. André. Ramillies, Offus and Autre-Eglise were all packed with troops and put in a state of defence, with alleys barricaded and walls loop-holed for muskets. Villeroi also positioned powerful batteries near Ramillies. These guns (some of which were of the three barrelled kind first seen at Elixheim the previous year) enjoyed good arcs of fire, able to fully cover the approaches of the plateau of Jandrenouille over which the Allied infantry would have to pass.

Marlborough, however, noticed several important weaknesses in the French dispositions. Tactically, it was imperative for Villeroi to occupy Taviers on his right and Autre-Eglise on his left, but by adopting this posture he had been forced to over-extend his forces. Moreover, this disposition – concave in relation to the Allied army – gave Marlborough the opportunity to form a more compact line, drawn up in a shorter front between the ‘horns’ of the French crescent; when the Allied blow came it would be more concentrated and carry more weight. Additionally, the Duke's disposition facilitated the transfer of troops across his front far more easily than his foe, a tactical advantage that would grow in importance as the events of the afternoon unfolded. Although Villeroi had the option of enveloping the flanks of the Allied army as they deployed on the plateau of Jandrenouille – threatening to encircle their army – the Duke correctly gauged that the characteristically cautious French commander was intent on a defensive battle along the ridge-line.

At 13:00 the batteries went into action; a little later two Allied columns set out from the extremities of their line and attacked the flanks of the Franco-Bavarian army. To the south the Dutch Guards, under the command of Colonel Wertmüller, came forward with their two field guns to seize the hamlet of Franquenée. The small Swiss garrison in the village, shaken by the sudden onslaught and unsupported by the battalions to their rear, were soon compelled back towards the village of Taviers. Taviers was of particular importance to the Franco-Bavarian position: it protected the otherwise unsupported flank of General de Guiscard's cavalry on the open plain, while at the same time, it allowed the French infantry to pose a threat to the flanks of the Dutch and Danish squadrons as they came forward into position. But hardly had the retreating Swiss rejoined their comrades in that village when the Dutch Guards renewed their attack. The fighting amongst the alleys and cottages soon deteriorated into a fierce bayonet and clubbing "mêlée", but the superiority in Dutch firepower soon told. The accomplished French officer, Colonel de la Colonie, standing on the plain nearby remembered – "this village was the opening of the engagement, and the fighting there was almost as murderous as the rest of the battle put together." By about 15:00 the Swiss had been pushed out of the village into the marshes beyond.

Villeroi's right flank fell into chaos and was now open and vulnerable. Alerted to the situation de Guiscard ordered an immediate attack with 14 squadrons of French dragoons currently stationed in the rear. Two other battalions of the Greder Suisse Régiment were also sent, but the attack was poorly co-ordinated and consequently went in piecemeal. The Anglo-Dutch commanders now sent dismounted Dutch dragoons into Taviers, which, together with the Guards and their field guns, poured concentrated musketry- and canister-fire into the advancing French troops. Colonel d’Aubigni, leading his regiment, fell mortally wounded.

As the French ranks wavered, the leading squadrons of Württemberg's Danish horse – now unhampered by enemy fire from either village – were also sent into the attack and fell upon the exposed flank of the Franco-Swiss infantry and dragoons. De la Colonie, with his Grenadiers Rouge regiment, together with the Cologne Guards who were brigaded with them, was now ordered forward from his post south of Ramillies to support the faltering counter-attack on the village. But on his arrival, all was chaos – "Scarcely had my troops got over when the dragoons and Swiss who had preceded us, came tumbling down upon my battalions in full flight … My own fellows turned about and fled along with them." De La Colonie managed to rally some of his grenadiers, together with the remnants of the French dragoons and Greder Suisse battalions, but it was an entirely peripheral operation, offering only fragile support for Villeroi's right flank.

While the attack on Taviers went on the Earl of Orkney launched his first line of English across the Petite Gheete in a determined attack against the barricaded villages of Offus and Autre-Eglise on the Allied right. Villeroi, posting himself near Offus, watched anxiously the redcoats' advance, mindful of the counsel he had received on 6 May from Louis XIV – "Have particular care to that part of the line which will endure the first shock of the English troops." Heeding this advice the French commander began to transfer battalions from his centre to reinforce the left, drawing more foot from the already weakened right to replace them.

As the English battalions descended the gentle slope of the Petite Gheete valley, struggling through the boggy stream, they were met by Major General de la Guiche's disciplined Walloon infantry sent forward from around Offus. After concentrated volleys, exacting heavy casualties on the redcoats, the Walloons reformed back to the ridgeline in good order. The English took some time to reform their ranks on the dry ground beyond the stream and press on up the slope towards the cottages and barricades on the ridge. The vigour of the English assault, however, was such that they threatened to break through the line of the villages and out onto the open plateau of Mont St André beyond. This was potentially dangerous for the Allied infantry who would then be at the mercy of the Elector's Bavarian and Walloon squadrons patiently waiting on the plateau for the order to move.

Although Henry Lumley’s English cavalry had managed to cross the marshy ground around the Petite Gheete, it was soon evident to Marlborough that sufficient cavalry support would not be practicable and that the battle could not be won on the Allied right. The Duke, therefore, called off the attack against Offus and Autre-Eglise. To make sure that Orkney obeyed his order to withdraw, Marlborough sent his Quartermaster-General in person with the command. Despite Orkney's protestations, Cadogan insisted on compliance and, reluctantly, Orkney gave the word for his troops to fall back to their original positions on the edge of the plateau of Jandrenouille. It is still not clear how far Orkney's advance was planned only as a feint; according to historian David Chandler it is probably more accurate to surmise that Marlborough launched Orkney in a serious probe with a view to sounding out the possibilities of the sector. Nevertheless, the attack had served its purpose. Villeroi had given his personal attention to that wing and strengthened it with large bodies of horse and foot that ought to have been taking part in the decisive struggle south of Ramillies.

Meanwhile, the Dutch assault on Ramillies was gaining pace. Marlborough's younger brother, General of Infantry, Charles Churchill, ordered four brigades of foot to attack the village. The assault consisted of 12 battalions of Dutch infantry commanded by Major Generals Schultz and Spaar; two brigades of Saxons under Count Schulenburg; a Scottish brigade in Dutch service led by the 2nd Duke of Argyle; and a small brigade of Protestant Swiss. The 20 French and Bavarian battalions in Ramillies, supported by the Irish dragoons who had left Ireland in the Flight of the Wild Geese to join Clare's Dragoons and a small brigade of Cologne and Bavarian Guards under the Marquis de Maffei, put up a determined defence, initially driving back the attackers with severe losses as commemorated in the song "Clare's Dragoons":
<poem>
When on Ramillies' bloody field
The baffled French were forced to yield,
The victor Saxon backward reeled
Before the charge of Clare's Dragoons.

"Viva là, the new brigade!"
"Viva là the old one too!"
"Viva là, the Rose shall fade"
"The Shamrock shine forever new!"
</poem>
Seeing that Schultz and Spaar were faltering, Marlborough now ordered Orkney's second-line British and Danish battalions (who had not been used in the assault on Offus and Autre-Eglise) to move south towards Ramillies. Shielded as they were from observation by a slight fold in the land, their commander, Brigadier-General Van Pallandt, ordered the regimental colours to be left in place on the edge of the plateau to convince their opponents they were still in their initial position. Therefore, unbeknown to the French who remained oblivious to the Allies’ real strength and intentions on the opposite side of the Petite Gheete, Marlborough was throwing his full weight against Ramillies and the open plain to the south. Villeroi meanwhile, was still moving more reserves of infantry in the opposite direction towards his left flank; crucially, it would be some time before the French commander noticed the subtle change in emphasis of the Allied dispositions.

At around 15:30, Overkirk advanced his massed squadrons on the open plain in support of the infantry attack on Ramillies. Overkirk's squadrons – 48 Dutch, supported on their left by 21 Danish – steadily advanced towards the enemy (taking care not to prematurely tire the horses), before breaking into a trot to gain the impetus for their charge. The Marquis de Feuquières writing after the battle described the scene – "They advanced in four lines … As they approached they advanced their second and fourth lines into the intervals of their first and third lines; so that when they made their advance upon us, they formed only one front, without any intermediate spaces."

The initial clash favoured the Dutch and Danish squadrons. The disparity of numbers – exacerbated by Villeroi stripping their ranks of infantry to reinforce his left flank – enabled Overkirk's cavalry to throw the first line of French horse back in some disorder towards their second-line squadrons. This line also came under severe pressure and, in turn, was forced back to their third-line of cavalry and the few battalions still remaining on the plain. But these French horsemen were amongst the best in Louis XIV's army – the "Maison du Roi", supported by four elite squadrons of Bavarian Cuirassiers. Ably led by de Guiscard, the French cavalry rallied, thrusting back the Allied squadrons in successful local counterattacks. On Overkirk's right flank, close to Ramillies, ten of his squadrons suddenly broke ranks and were scattered, riding headlong to the rear to recover their order, leaving the left flank of the Allied assault on Ramillies dangerously exposed. Notwithstanding the lack of infantry support, de Guiscard threw his cavalry forward in an attempt to split the Allied army in two.

A crisis threatened the centre, but from his vantage point Marlborough was at once aware of the situation. The Allied commander now summoned the cavalry on the right wing to reinforce his centre, leaving only the English squadrons in support of Orkney. Thanks to a combination of battle-smoke and favourable terrain, his redeployment went unnoticed by Villeroi who made no attempt to transfer any of his own 50 unused squadrons. While he waited for the fresh reinforcements to arrive, Marlborough flung himself into the "mêlée", rallying some of the Dutch cavalry who were in confusion. But his personal involvement nearly led to his undoing. A number of French horsemen, recognising the Duke, came surging towards his party. Marlborough's horse tumbled and the Duke was thrown – "Milord Marlborough was rid over," wrote Orkney some time later. It was a critical moment of the battle. "Major-General Murray," recalled one eyewitness, " … seeing him fall, marched up in all haste with two Swiss battalions to save him and stop the enemy who were hewing all down in their way." Fortunately Marlborough's newly appointed aide-de-camp, Richard Molesworth, galloped to the rescue, mounted the Duke on his horse and made good their escape, before Murray's disciplined ranks threw back the pursuing French troopers.

After a brief pause, Marlborough's equerry, Colonel Bringfield (or Bingfield), led up another of the Duke's spare horses; but while assisting him onto his mount, the unfortunate Bringfield was hit by an errant cannonball that sheared off his head. One account has it that the cannonball flew between the Captain-General's legs before hitting the unfortunate colonel, whose torso fell at Marlborough's feet – a moment subsequently depicted in a lurid set of contemporary playing cards. Nevertheless, the danger passed, enabling the Duke to attend to the positioning of the cavalry reinforcements feeding down from his right flank – a change of which Villeroi remained blissfully unaware.

The time was about 16:30, and the two armies were in close contact across the whole front, from the skirmishing in the marshes in the south, through the vast cavalry battle on the open plain; to the fierce struggle for Ramillies at the centre, and to the north, where, around the cottages of Offus and Autre-Eglise, Orkney and de la Guiche faced each other across the Petite Gheete ready to renew hostilities.

The arrival of the transferring squadrons now began to tip the balance in favour of the Allies. Tired, and suffering a growing list of casualties, the numerical inferiority of Guiscard's squadrons battling on the plain at last began to tell. After earlier failing to hold or retake Franquenée and Taviers, Guiscard's right flank had become dangerously exposed and a fatal gap had opened on the right of their line. Taking advantage of this breach, Württemberg's Danish cavalry now swept forward, wheeling to penetrate the flank of the Maison du Roi whose attention was almost entirely fixed on holding back the Dutch. Sweeping forwards, virtually without resistance, the 21 Danish squadrons reformed behind the French around the area of the Tomb of Ottomond, facing north across the plateau of Mont St André towards the exposed flank of Villeroi's army.

The final Allied reinforcements for the cavalry contest to the south were at last in position; Marlborough's superiority on the left could no longer be denied, and his fast-moving plan took hold of the battlefield. Now, far too late, Villeroi tried to redeploy his 50 unused squadrons, but a desperate attempt to form line facing south, stretching from Offus to Mont St André, floundered amongst the baggage and tents of the French camp carelessly left there after the initial deployment. The Allied commander ordered his cavalry forward against the now heavily outnumbered French and Bavarian horsemen. De Guiscard's right flank, without proper infantry support, could no longer resist the onslaught and, turning their horses northwards, they broke and fled in complete disorder. Even the squadrons currently being scrambled together by Villeroi behind Ramillies could not withstand the onslaught. "We had not got forty yards on our retreat," remembered Captain Peter Drake, an Irishmen serving with the French – "when the words "sauve qui peut" went through the great part, if not the whole army, and put all to confusion"

In Ramillies the Allied infantry, now reinforced by the English troops brought down from the north, at last broke through. The Régiment de Picardie stood their ground but were caught between Colonel Borthwick's Scots-Dutch regiment and the English reinforcements. Borthwick was killed, as was Charles O’Brien, the Irish Viscount Clare in French service, fighting at the head of his regiment. The Marquis de Maffei attempted one last stand with his Bavarian and Cologne Guards, but it proved in vain. Noticing a rush of horsemen fast approaching from the south, he later recalled – " … I went towards the nearest of these squadrons to instruct their officer, but instead of being listened to [I] was immediately surrounded and called upon to ask for quarter."

The roads leading north and west were choked with fugitives. Orkney now sent his English troops back across the Petite Gheete stream to once again storm Offus where de la Guiche's infantry had begun to drift away in the confusion. To the right of the infantry Lord John Hay's ‘Scots Greys’ also picked their way across the stream and charged the Régiment du Roi within Autre-Eglise. "Our dragoons," wrote John Deane, "pushing into the village … made terrible slaughter of the enemy." The Bavarian Horse Grenadiers and the Electoral Guards withdrew and formed a shield about Villeroi and the Elector but were scattered by Lumley's cavalry. Stuck in the mass of fugitives fleeing the battlefield, the French and Bavarian commanders narrowly escaped capture by General Cornelius Wood who, unaware of their identity, had to content himself with the seizure of two Bavarian Lieutenant-Generals. Far to the south, the remnants of de la Colonie's brigade headed in the opposite direction towards the French held fortress of Namur."

The retreat became a rout. Individual Allied commanders drove their troops forward in pursuit, allowing their beaten enemy no chance to recover. Soon the Allied infantry could no longer keep up, but their cavalry were off the leash, heading through the gathering night for the crossings on the Dyle river. At last, however, Marlborough called a halt to the pursuit shortly after midnight near Meldert, from the field. "It was indeed a truly shocking sight to see the miserable remains of this mighty army," wrote Captain Drake, "… reduced to a handful."

What was left of Villeroi's army was now broken in spirit; the imbalance of the casualty figures amply demonstrates the extent of the disaster for Louis XIV's army: ("see below"). In addition, hundreds of French soldiers were fugitives, many of whom would never remuster to the colours. Villeroi also lost 52 artillery pieces and his entire engineer pontoon train. In the words of Marshal Villars, the French defeat at Ramillies was – "The most shameful, humiliating and disastrous of routs."

Town after town now succumbed to the Allies. Leuven fell on 25 May 1706; three days later, the Allies entered Brussels, the capital of the Spanish Netherlands. Marlborough realised the great opportunity created by the early victory of Ramillies: "We now have the whole summer before us," wrote the Duke from Brussels to Robert Harley, "and with the blessing of God I shall make the best use of it." Malines, Lierre, Ghent, Alost, Damme, Oudenaarde, Bruges, and on 6 June Antwerp, all subsequently fell to Marlborough's victorious army and, like Brussels, proclaimed the Austrian candidate for the Spanish throne, the Archduke Charles, as their sovereign. Villeroi was helpless to arrest the process of collapse. When Louis XIV learnt of the disaster he recalled Marshal Vendôme from northern Italy to take command in Flanders; but it would be weeks before the command changed hands.

As news spread of the Allies’ triumph, the Prussians, Hessians and Hanoverian contingents, long delayed by their respective rulers, eagerly joined the pursuit of the broken French and Bavarian forces. "This," wrote Marlborough wearily, "I take to be owing to our late success." Meanwhile, Overkirk took the port of Ostend on 4 July thus opening a direct route to the English Channel for communication and supply, but the Allies were making scant progress against Dendermonde whose governor, the Marquis de Valée, was stubbornly resisting. Only later when Cadogan and Churchill went to take charge did the town's defences begin to fail.

Vendôme formally took over command in Flanders on 4 August; Villeroi would never again receive a major command – "I cannot foresee a happy day in my life save only that of my death." Louis XIV was more forgiving to his old friend – "At our age, Marshal, we must no longer expect good fortune." In the meantime, Marlborough invested the elaborate fortress of Menin which, after a costly siege, capitulated on 22 August. Dendermonde finally succumbed on 6 September followed by Ath – the last conquest of 1706 – on 2 October. By the time Marlborough had closed down the Ramillies campaign he had denied the French most of the Spanish Netherlands west of the Meuse and north of the Sambre – it was an unsurpassed operational triumph for the English Duke but once again it was not decisive as these gains did not defeat France.

The immediate question for the Allies was how to deal with the Spanish Netherlands, a subject on which the Austrians and the Dutch were diametrically opposed. Emperor Joseph I, acting on behalf of his younger brother King ’Charles III’, absent in Spain, claimed that reconquered Brabant and Flanders should be put under immediate possession of a governor named by himself. The Dutch, however, who had supplied the major share of the troops and money to secure the victory (the Austrians had produced nothing of either) claimed the government of the region till the war was over, and that after the peace they should continue to garrison Barrier Fortresses stronger than those which had fallen so easily to Louis XIV's forces in 1701. Marlborough mediated between the two parties but favoured the Dutch position. To sway the Duke's opinion, the Emperor offered Marlborough the governorship of the Spanish Netherlands. It was a tempting offer, but in the name of Allied unity, it was one he refused. In the end England and the Dutch Republic took control of the newly won territory for the duration of the war; after which it was to be handed over to the direct rule of ‘Charles III’, subject to the reservation of a Dutch Barrier, the extent and nature of which had yet to be settled.

Meanwhile, on the Upper Rhine, Villars had been forced onto the defensive as battalion after battalion had been sent north to bolster collapsing French forces in Flanders; there was now no possibility of his undertaking the re-capture of Landau. Further good news for the Allies arrived from northern Italy where, on 7 September, Prince Eugene had routed a French army before the Piedmontese capital, Turin, driving the Franco-Spanish forces from northern Italy. Only from Spain did Louis XIV receive any good news where Das Minas and Galway had been forced to retreat from Madrid towards Valencia, allowing Philip V to re-enter his capital on 4 October. All in all though, the situation had changed considerably and Louis XIV began to look for ways to end what was fast becoming a ruinous war for France. For Queen Anne also, the Ramillies campaign had one overriding significance – "Now we have God be thanked so hopeful a prospect of peace." Instead of continuing the momentum of victory, however, cracks in Allied unity would enable Louis XIV to reverse some of the major setbacks suffered at Turin and Ramillies.

The total number of French casualties cannot be calculated precisely, so complete was the collapse of the Franco-Bavarian army that day. David G. Chandler’s "Marlborough as Military Commander" and "A Guide to the Battlefields of Europe" are consistent with regards to French casualty figures i.e., 12,000 dead and wounded plus some 7,000 taken prisoner. James Falkner, in "Ramillies 1706: Year of Miracles," also notes 12,000 dead and wounded and states ‘up to 10,000’ taken prisoner. In "The Collins Encyclopaedia of Military History", Dupuy puts Villeroi's dead and wounded at 8,000, with a further 7,000 captured. Neil Litten, using French archives, suggests 7,000 killed and wounded and 6,000 captured, with a further 2,000 choosing to desert. John Millner's memoirs – "Compendious Journal" (1733) – is more specific, recording 12,087 of Villeroi's army were killed or wounded, with another 9,729 taken prisoner. In "Marlborough", however, Correlli Barnett puts the total casualty figure as high as 30,000 – 15,000 dead and wounded with an additional 15,000 taken captive. Trevelyan estimates Villeroi's casualties at 13,000, but adds, ‘his losses by desertion may have doubled that number’. La Colonie omits a casualty figure in his "Chronicles of an old Campaigner"; but Saint-Simon in his "Memoirs" states 4,000 killed, adding 'many others were wounded and many important persons were taken prisoner'. Voltaire, however, in "Histoire du siècle du Louis XIV" records, 'the French lost there twenty thousand men'.





</doc>
<doc id="4051" url="https://en.wikipedia.org/wiki?curid=4051" title="Brian Kernighan">
Brian Kernighan

Brian Wilson Kernighan (; born January 1, 1942) is a Canadian computer scientist.

He worked at Bell Labs and contributed to the development of Unix alongside Unix creators Ken Thompson and Dennis Ritchie.

Kernighan's name became widely known through co-authorship of the first book on the C programming language with Dennis Ritchie. Kernighan affirmed that he had no part in the design of the C language ("it's entirely Dennis Ritchie's work"). He authored many Unix programs, including ditroff.

Kernighan is coauthor of the AWK and AMPL programming languages. The "K" of K&R C and the "K" in AWK both stand for "Kernighan". 

In collaboration with Shen Lin he devised well-known heuristics for two NP-complete optimization problems: graph partitioning and the travelling salesman problem. In a display of authorial equity, the former is usually called the Kernighan–Lin algorithm, while the latter is known as the Lin–Kernighan heuristic.

Kernighan has been a Professor in the Computer Science Department of Princeton University since 2000. He is also the Undergraduate Department Representative.

Kernighan was born in Toronto. He attended the University of Toronto between 1960 and 1964, earning his Bachelor's degree in engineering physics. He received his PhD in electrical engineering from Princeton University in 1969 for research supervised by Peter Weiner.

Kernighan has held a professorship in the Department of Computer Science at Princeton since 2000. Each fall he teaches a course called "Computers in Our World", which introduces the fundamentals of computing to non-majors. 

Kernighan was the software editor for Prentice Hall International. His "Software Tools" series spread the essence of "C/Unix thinking" with makeovers for BASIC, FORTRAN, and Pascal, and most notably his "Ratfor" (rational FORTRAN) was put in the public domain.

He has said that if stranded on an island with only one programming language it would have to be C.

Kernighan coined the term Unix and helped popularize Thompson's Unix philosophy. Kernighan is also known as a coiner of the expression "What You See Is All You Get" (WYSIAYG), which is a sarcastic variant of the original "What You See Is What You Get" (WYSIWYG). Kernighan's term is used to indicate that WYSIWYG systems might throw away information in a document that could be useful in other contexts.

Kernighan's original 1978 implementation of Hello, World! was sold at The Algorithm Auction, the world's first auction of computer algorithms.

In 1996, Kernighan taught CS50 which is the Harvard University introductory course in Computer Science.

Other achievements during his career include:



</doc>
<doc id="4052" url="https://en.wikipedia.org/wiki?curid=4052" title="BCPL">
BCPL

BCPL ("Basic Combined Programming Language") is a procedural, imperative, and structured computer programming language. Originally intended for writing compilers for other languages, BCPL is no longer in common use. However, its influence is still felt because a stripped down and syntactically changed version of BCPL, called B, was the language on which the C programming language was based. BCPL introduced several features of many modern programming languages, including using curly braces to delimit code blocks. BCPL was first implemented by Martin Richards of the University of Cambridge in 1967.

BCPL was designed so that small and simple compilers could be written for it; reputedly some compilers could be run in 16 kilobytes. Further, the original compiler, itself written in BCPL, was easily portable. BCPL was thus a popular choice for bootstrapping a system. A major reason for the compiler's portability lay in its structure. It was split into two parts: the front end parsed the source and generated O-code, an intermediate language. The back end took the O-code and translated it into the machine code for the target machine. Only of the compiler's code needed to be rewritten to support a new machine, a task that usually took between 2 and 5 man-months. This approach became common practice later (e.g. Pascal, Java).

The language is unusual in having only one data type: a word, a fixed number of bits, usually chosen to align with the architecture's machine word and of adequate capacity to represent any valid storage address. For many machines of the time, this data type was a 16-bit word. This choice later proved to be a significant problem when BCPL was used on machines in which the smallest addressable item was not a word but a byte or on machines with larger word sizes such as 32-bit or 64-bit.

The interpretation of any value was determined by the operators used to process the values. (For example, codice_1 added two values together, treating them as integers; codice_2 indirected through a value, effectively treating it as a pointer.) In order for this to work, the implementation provided no type checking. Hungarian notation was developed to help programmers avoid inadvertent type errors.

The mismatch between BCPL's word orientation and byte-oriented hardware was addressed in several ways. One was by providing standard library routines for packing and unpacking words into byte strings. Later, two language features were added: the bit-field selection operator and the infix byte indirection operator (denoted by codice_3).

BCPL handles bindings spanning separate compilation units in a unique way. There are no user-declarable global variables; instead there is a global vector, similar to "blank common" in Fortran. All data shared between different compilation units comprises scalars and pointers to vectors stored in a pre-arranged place in the global vector. Thus the header files (files included during compilation using the "GET" directive) become the primary means of synchronizing global data between compilation units, containing "GLOBAL" directives that present lists of symbolic names, each paired with a number that associates the name with the corresponding numerically addressed word in the global vector. As well as variables, the global vector contains bindings for external procedures. This makes dynamic loading of compilation units very simple to achieve. Instead of relying on the link loader of the underlying implementation, effectively BCPL gives the programmer control of the linking process.

The global vector also made it very simple to replace or augment standard library routines. A program could save the pointer from the global vector to the original routine and replace it with a pointer to an alternative version. The alternative might call the original as part of its processing. This could be used as a quick "ad hoc" debugging aid.

BCPL was the first brace programming language and the braces survived the syntactical changes and have become a common means of denoting program source code statements. In practice, on limited keyboards of the day, source programs often used the sequences codice_4 and codice_5 in place of the symbols codice_6 and codice_7. The single-line codice_8 comments of BCPL, which were not adopted by C, reappeared in C++ and later in C99.

The book "BCPL: The language and its compiler" describes the philosophy of BCPL as follows:
BCPL was first implemented by Martin Richards of the University of Cambridge in 1967. BCPL was a response to difficulties with its predecessor, Cambridge Programming Language, later renamed Combined Programming Language (CPL), which was designed during the early 1960s. Richards created BCPL by "removing those features of the full language which make compilation difficult". The first compiler implementation, for the IBM 7094 under Compatible Time-Sharing System (CTSS), was written while Richards was visiting Project MAC at the Massachusetts Institute of Technology (MIT) in the spring of 1967. The language was first described in a paper presented to the 1969 Spring Joint Computer Conference.

BCPL has been rumored to have originally stood for "Bootstrap Cambridge Programming Language", but CPL was never created since development stopped at BCPL, and the acronym was later reinterpreted for the BCPL book.

BCPL is the language in which the original hello world program was written. The first MUD was also written in BCPL (MUD1).

Several operating systems were written partially or wholly in BCPL (for example, TRIPOS and the earliest versions of AmigaDOS). BCPL was also the initial language used in the seminal Xerox PARC Alto project, the first modern personal computer; among other projects, the Bravo document preparation system was written in BCPL.

An early compiler, bootstrapped in 1969, by starting with a paper tape of the O-code of Martin Richards's Atlas 2 compiler, targeted the ICT 1900 series. The two machines had different word-lengths (48 vs 24 bits), different character encodings, and different packed string representations—and the successful bootstrapping increased confidence in the practicality of the method.

By late 1970, implementations existed for the Honeywell 635 and Honeywell 645, the IBM 360, the PDP-10, the TX-2, the CDC 6400, the UNIVAC 1108, the PDP-9, the KDF 9 and the Atlas 2. In 1974 a dialect of BCPL was implemented at BBN without using the intermediate O-code. The initial implementation was a cross-compiler hosted on BBN's TENEX PDP-10s, and directly targeted the PDP-11s used in BBN's implementation of the second generation IMPs used in the Arpanet.

There was also a version produced for the BBC Micro in the mid-1980s, by Richards Computer Products, a company started by John Richards, the brother of Dr. Martin Richards. The BBC Domesday Project made use of the language. Versions of BCPL for the Amstrad CPC and Amstrad PCW computers were also released in 1986 by UK software house Arnor Ltd. MacBCPL was released for the Apple Macintosh in 1985 by Topexpress Ltd, of Kensington, England.

Both the design and philosophy of BCPL strongly influenced B, which in turn influenced C. Programmers at the time debated whether an eventual successor to C would be called "D", the next letter in the alphabet, or "P", the next letter in the parent language name. The language most accepted as being C's successor is C++ (with codice_9 being C's increment operator), although a D programming language also exists.

In 1979, implementations of BCPL existed for at least 25 architectures; the language gradually fell out of favour as C became popular on non-Unix systems.

Martin Richards maintains a modern version of BCPL on his website, last updated in 2018. This can be set up to run on various systems including Linux, FreeBSD, Mac OS X and Raspberry Pi. The latest distribution includes Graphics and Sound libraries and there is a comprehensive manual in PDF format. He continues to program in it, including for his research on musical automated score following.

A common informal MIME type for BCPL is .

If these programs are run using Martin Richards' current version of Cintsys (December 2018), LIBHDR, START and WRITEF must be changed to lower case to avoid errors.

Print factorials:
Count solutions to the N queens problem:



</doc>
<doc id="4054" url="https://en.wikipedia.org/wiki?curid=4054" title="Battleship">
Battleship

A battleship is a large armored warship with a main battery consisting of large caliber guns. During the late 19th and early 20th centuries the battleship was the most powerful type of warship, and a fleet of battleships was considered vital for any nation that desired to maintain command of the sea.

The term "battleship" came into formal use in the late 1880s to describe a type of ironclad warship, now referred to by historians as pre-dreadnought battleships. In 1906, the commissioning of into the United Kingdom's Royal Navy heralded a revolution in battleship design. Subsequent battleship designs, influenced by HMS "Dreadnought", were referred to as "dreadnoughts", though the term eventually became obsolete as they became the only type of battleship in common use.

Battleships were a symbol of naval dominance and national might, and for decades the battleship was a major factor in both diplomacy and military strategy. A global arms race in battleship construction began in Europe in the 1890s and culminated at the decisive Battle of Tsushima in 1905, the outcome of which significantly influenced the design of HMS "Dreadnought". The launch of "Dreadnought" in 1906 commenced a new naval arms race. Three major fleet actions between steel battleships took place: the long range gunnery duel at the Battle of the Yellow Sea in 1904, the decisive Battle of Tsushima in 1905, both, during the Russo-Japanese War, and the inconclusive Battle of Jutland (1916) during the First World War. Jutland was the largest naval battle and the only full-scale clash of dreadnoughts of the war, it was the last major battle in naval history fought primarily by battleships.

The Naval Treaties of the 1920s and 1930s limited the number of battleships, though technical innovation in battleship design continued. Both the Allied and Axis powers built battleships during World War II, though the increasing importance of the aircraft carrier meant that the battleship played a less important role than had been expected.

The value of the battleship has been questioned, even during their heyday. There were few of the decisive fleet battles that battleship proponents expected, and used to justify the vast resources spent on building battlefleets. Even in spite of their huge firepower and protection, battleships were increasingly vulnerable to much smaller and relatively inexpensive weapons: initially the torpedo and the naval mine, and later aircraft and the guided missile. The growing range of naval engagements led to the aircraft carrier replacing the battleship as the leading capital ship during World War II, with the last battleship to be launched being in 1944. Four battleships were retained by the United States Navy until the end of the Cold War for fire support purposes and were last used in combat during the Gulf War in 1991. The last battleships were stricken from the U.S. Naval Vessel Register in the 2000s.

A ship of the line was the dominant warship of its age. It was a large, unarmored wooden sailing ship which mounted a battery of up to 120 smoothbore guns and carronades. The ship of the line developed gradually over centuries and, apart from growing in size, it changed little between the adoption of line of battle tactics in the early 17th century and the end of the sailing battleship's heyday in the 1830s. From 1794, the alternative term 'line of battle ship' was contracted (informally at first) to 'battle ship' or 'battleship'.

The sheer number of guns fired broadside meant a ship of the line could wreck any wooden enemy, holing her hull, knocking down masts, wrecking her rigging, and killing her crew. However, the effective range of the guns was as little as a few hundred yards, so the battle tactics of sailing ships depended in part on the wind.

The first major change to the ship of the line concept was the introduction of steam power as an auxiliary propulsion system. Steam power was gradually introduced to the navy in the first half of the 19th century, initially for small craft and later for frigates. The French Navy introduced steam to the line of battle with the 90-gun in 1850—the first true steam battleship. "Napoléon" was armed as a conventional ship-of-the-line, but her steam engines could give her a speed of , regardless of the wind condition. This was a potentially decisive advantage in a naval engagement. The introduction of steam accelerated the growth in size of battleships. France and the United Kingdom were the only countries to develop fleets of wooden steam screw battleships although several other navies operated small numbers of screw battleships, including Russia (9), the Ottoman Empire (3), Sweden (2), Naples (1), Denmark (1) and Austria (1).

The adoption of steam power was only one of a number of technological advances which revolutionized warship design in the 19th century. The ship of the line was overtaken by the ironclad: powered by steam, protected by metal armor, and armed with guns firing high-explosive shells.

Guns that fired explosive or incendiary shells were a major threat to wooden ships, and these weapons quickly became widespread after the introduction of 8-inch shell guns as part of the standard armament of French and American line-of-battle ships in 1841. In the Crimean War, six line-of-battle ships and two frigates of the Russian Black Sea Fleet destroyed seven Turkish frigates and three corvettes with explosive shells at the Battle of Sinop in 1853. Later in the war, French ironclad floating batteries used similar weapons against the defenses at the Battle of Kinburn.

Nevertheless, wooden-hulled ships stood up comparatively well to shells, as shown in the 1866 Battle of Lissa, where the modern Austrian steam two-decker ranged across a confused battlefield, rammed an Italian ironclad and took 80 hits from Italian ironclads, many of which were shells, but including at least one 300-pound shot at point-blank range. Despite losing her bowsprit and her foremast, and being set on fire, she was ready for action again the very next day.

The development of high-explosive shells made the use of iron armor plate on warships necessary. In 1859 France launched , the first ocean-going ironclad warship. She had the profile of a ship of the line, cut to one deck due to weight considerations. Although made of wood and reliant on sail for most journeys, "Gloire" was fitted with a propeller, and her wooden hull was protected by a layer of thick iron armor. "Gloire" prompted further innovation from the Royal Navy, anxious to prevent France from gaining a technological lead.

The superior armored frigate followed "Gloire" by only 14 months, and both nations embarked on a program of building new ironclads and converting existing screw ships of the line to armored frigates. Within two years, Italy, Austria, Spain and Russia had all ordered ironclad warships, and by the time of the famous clash of the and the at the Battle of Hampton Roads at least eight navies possessed ironclad ships.
Navies experimented with the positioning of guns, in turrets (like the USS "Monitor"), central-batteries or barbettes, or with the ram as the principal weapon. As steam technology developed, masts were gradually removed from battleship designs. By the mid-1870s steel was used as a construction material alongside iron and wood. The French Navy's , laid down in 1873 and launched in 1876, was a central battery and barbette warship which became the first battleship in the world to use steel as the principal building material.

The term "battleship" was officially adopted by the Royal Navy in the re-classification of 1892. By the 1890s, there was an increasing similarity between battleship designs, and the type that later became known as the 'pre-dreadnought battleship' emerged. These were heavily armored ships, mounting a mixed battery of guns in turrets, and without sails. The typical first-class battleship of the pre-dreadnought era displaced 15,000 to 17,000 tons, had a speed of , and an armament of four guns in two turrets fore and aft with a mixed-caliber secondary battery amidships around the superstructure. An early design with superficial similarity to the pre-dreadnought is the British of 1871.

The slow-firing main guns were the principal weapons for battleship-to-battleship combat. The intermediate and secondary batteries had two roles. Against major ships, it was thought a 'hail of fire' from quick-firing secondary weapons could distract enemy gun crews by inflicting damage to the superstructure, and they would be more effective against smaller ships such as cruisers. Smaller guns (12-pounders and smaller) were reserved for protecting the battleship against the threat of torpedo attack from destroyers and torpedo boats.

The beginning of the pre-dreadnought era coincided with Britain reasserting her naval dominance. For many years previously, Britain had taken naval supremacy for granted. Expensive naval projects were criticised by political leaders of all inclinations. However, in 1888 a war scare with France and the build-up of the Russian navy gave added impetus to naval construction, and the British Naval Defence Act of 1889 laid down a new fleet including eight new battleships. The principle that Britain's navy should be more powerful than the two next most powerful fleets combined was established. This policy was designed to deter France and Russia from building more battleships, but both nations nevertheless expanded their fleets with more and better pre-dreadnoughts in the 1890s.
In the last years of the 19th century and the first years of the 20th, the escalation in the building of battleships became an arms race between Britain and Germany. The German naval laws of 1890 and 1898 authorised a fleet of 38 battleships, a vital threat to the balance of naval power. Britain answered with further shipbuilding, but by the end of the pre-dreadnought era, British supremacy at sea had markedly weakened. In 1883, the United Kingdom had 38 battleships, twice as many as France and almost as many as the rest of the world put together. By 1897, Britain's lead was far smaller due to competition from France, Germany, and Russia, as well as the development of pre-dreadnought fleets in Italy, the United States and Japan. The Ottoman Empire, Spain, Sweden, Denmark, Norway, the Netherlands, Chile and Brazil all had second-rate fleets led by armored cruisers, coastal defence ships or monitors.

Pre-dreadnoughts continued the technical innovations of the ironclad. Turrets, armor plate, and steam engines were all improved over the years, and torpedo tubes were also introduced. A small number of designs, including the American and es, experimented with all or part of the 8-inch intermediate battery superimposed over the 12-inch primary. Results were poor: recoil factors and blast effects resulted in the 8-inch battery being completely unusable, and the inability to train the primary and intermediate armaments on different targets led to significant tactical limitations. Even though such innovative designs saved weight (a key reason for their inception), they proved too cumbersome in practice.

In 1906, the British Royal Navy launched the revolutionary . Created as a result of pressure from Admiral Sir John ("Jackie") Fisher, HMS "Dreadnought" made existing battleships obsolete. Combining an "all-big-gun" armament of ten 12-inch (305 mm) guns with unprecedented speed (from steam turbine engines) and protection, she prompted navies worldwide to re-evaluate their battleship building programs. While the Japanese had laid down an all-big-gun battleship, , in 1904 and the concept of an all-big-gun ship had been in circulation for several years, it had yet to be validated in combat. "Dreadnought" sparked a new arms race, principally between Britain and Germany but reflected worldwide, as the new class of warships became a crucial element of national power.

Technical development continued rapidly through the dreadnought era, with steep changes in armament, armor and propulsion. Ten years after "Dreadnought"s commissioning, much more powerful ships, the super-dreadnoughts, were being built.

In the first years of the 20th century, several navies worldwide experimented with the idea of a new type of battleship with a uniform armament of very heavy guns.

Admiral Vittorio Cuniberti, the Italian Navy's chief naval architect, articulated the concept of an all-big-gun battleship in 1903. When the "Regia Marina" did not pursue his ideas, Cuniberti wrote an article in "Janes" proposing an "ideal" future British battleship, a large armored warship of 17,000 tons, armed solely with a single calibre main battery (twelve 12-inch [305 mm] guns), carrying belt armor, and capable of 24 knots (44 km/h).

The Russo-Japanese War provided operational experience to validate the "all-big-gun" concept. During the Battle of the Yellow Sea on August 10, 1904 "Admiral Togo" commenced deliberate 12 inch gun fire at the Russian flagship "Tzesarevich" at 14,200 yards (13,000 meters). At the Battle of Tsushima on May 27, 1905 "Admiral Rozhestvensky's" flagship fired the first 12-inch guns at the Japanese flagship "Mikasa" at 7,000 meters. It is often held that these engagements demonstrated the importance of the gun over its smaller counterparts, though some historians take the view that secondary batteries were just as important as the larger weapons when dealing with smaller fast moving torpedo craft. Such was the case, albeit unsuccessfully, when the Russian flagship Suvorov at "Tsushima" had been sent to the bottom by destroyer launched torpedoes.

When dealing with a mixed 10- and 12-inch armament. The 1903–04 design also retained traditional triple-expansion steam engines.
As early as 1904, Jackie Fisher had been convinced of the need for fast, powerful ships with an all-big-gun armament. If Tsushima influenced his thinking, it was to persuade him of the need to standardise on guns. Fisher's concerns were submarines and destroyers equipped with torpedoes, then threatening to outrange battleship guns, making speed imperative for capital ships. Fisher's preferred option was his brainchild, the battlecruiser: lightly armored but heavily armed with eight 12-inch guns and propelled to by steam turbines.

It was to prove this revolutionary technology that "Dreadnought" was designed in January 1905, laid down in October 1905 and sped to completion by 1906. She carried ten 12-inch guns, had an 11-inch armor belt, and was the first large ship powered by turbines. She mounted her guns in five turrets; three on the centerline (one forward, two aft) and two on the wings, giving her at her launch twice the broadside of any other warship. She retained a number of 12-pound (3-inch, 76 mm) quick-firing guns for use against destroyers and torpedo-boats. Her armor was heavy enough for her to go head-to-head with any other ship in a gun battle, and conceivably win.
"Dreadnought" was to have been followed by three s, their construction delayed to allow lessons from "Dreadnought" to be used in their design. While Fisher may have intended "Dreadnought" to be the last Royal Navy battleship, the design was so successful he found little support for his plan to switch to a battlecruiser navy. Although there were some problems with the ship (the wing turrets had limited arcs of fire and strained the hull when firing a full broadside, and the top of the thickest armor belt lay below the waterline at full load), the Royal Navy promptly commissioned another six ships to a similar design in the and es.

An American design, , authorized in 1905 and laid down in December 1906, was another of the first dreadnoughts, but she and her sister, , were not launched until 1908. Both used triple-expansion engines and had a superior layout of the main battery, dispensing with "Dreadnought"s wing turrets. They thus retained the same broadside, despite having two fewer guns.

In 1897, before the revolution in design brought about by HMS "Dreadnought", the Royal Navy had 62 battleships in commission or building, a lead of 26 over France and 50 over Germany. From the 1906 launching of "Dreadnought", an arms race with major strategic consequences was prompted. Major naval powers raced to build their own dreadnoughts. Possession of modern battleships was not only seen as vital to naval power, but also, as with nuclear weapons after WWII, represented a nation's standing in the world. Germany, France, Japan, Italy, Austria, and the United States all began dreadnought programmes; while Ottoman Turkey, Argentina, Russia, Brazil, and Chile commissioned dreadnoughts to be built in British and American yards.

By virtue of geography, the Royal Navy was able to use her imposing battleship and battlecruiser fleet to impose a strict and successful naval blockade of Germany and kept Germany's smaller battleship fleet bottled up in the North Sea: only narrow channels led to the Atlantic Ocean and these were guarded by British forces. Both sides were aware that, because of the greater number of British dreadnoughts, a full fleet engagement would be likely to result in a British victory. The German strategy was therefore to try to provoke an engagement on their terms: either to induce a part of the Grand Fleet to enter battle alone, or to fight a pitched battle near the German coastline, where friendly minefields, torpedo-boats and submarines could be used to even the odds. This did not happen however, due in large part to the necessity to keep submarines for the Atlantic campaign. Submarines were the only vessels in the Imperial German Navy able to break out and raid British commerce in force, but even though they sank many merchant ships, they could not successfully counter-blockade the United Kingdom; the Royal Navy successfully adopted convoy tactics to combat Germany's submarine counter-blockade and eventually defeated it. This was in stark contrast to Britain's successful blockade of Germany.
The first two years of war saw the Royal Navy's battleships and battlecruisers regularly "sweep" the North Sea making sure that no German ships could get in or out. Only a few German surface ships that were already at sea, such as the famous light cruiser , were able to raid commerce. Even some of those that did manage to get out were hunted down by battlecruisers, as in the Battle of the Falklands, December 7, 1914. The results of sweeping actions in the North Sea were battles including the Heligoland Bight and Dogger Bank and German raids on the English coast, all of which were attempts by the Germans to lure out portions of the Grand Fleet in an attempt to defeat the Royal Navy in detail. On May 31, 1916, a further attempt to draw British ships into battle on German terms resulted in a clash of the battlefleets in the Battle of Jutland. The German fleet withdrew to port after two short encounters with the British fleet. Less than two months later, the Germans once again attempted to draw portions of the Grand Fleet into battle. The resulting Action of 19 August 1916 proved inconclusive. This reinforced German determination not to engage in a fleet to fleet battle.
In the other naval theatres there were no decisive pitched battles. In the Black Sea, engagement between Russian and Ottoman battleships was restricted to skirmishes. In the Baltic Sea, action was largely limited to the raiding of convoys, and the laying of defensive minefields; the only significant clash of battleship squadrons there was the Battle of Moon Sound at which one Russian pre-dreadnought was lost. The Adriatic was in a sense the mirror of the North Sea: the Austro-Hungarian dreadnought fleet remained bottled up by the British and French blockade. And in the Mediterranean, the most important use of battleships was in support of the amphibious assault on Gallipoli.

In September 1914, the threat posed to surface ships by German U-boats was confirmed by successful attacks on British cruisers, including the sinking of three British armored cruisers by the German submarine in less than an hour. The British Super-dreadnought soon followed suit as she struck a mine laid by a German U-boat in October 1914 and sank. The threat that German U-boats posed to British dreadnoughts was enough to cause the Royal Navy to change their strategy and tactics in the North Sea to reduce the risk of U-boat attack. Further near-misses from submarine attacks on battleships and casualties amongst cruisers led to growing concern in the Royal Navy about the vulnerability of battleships.

As the war wore on however, it turned out that whilst submarines did prove to be a very dangerous threat to older pre-dreadnought battleships, as shown by examples such as the sinking of , which was caught in the Dardanelles by a British submarine and and were torpedoed by "U-21" as well as , , etc., the threat posed to dreadnought battleships proved to have been largely a false alarm. HMS "Audacious" turned out to be the only dreadnought sunk by a submarine in World War I. While battleships were never intended for anti-submarine warfare, there was one instance of a submarine being sunk by a dreadnought battleship. HMS "Dreadnought" rammed and sank the German submarine "U-29" on March 18, 1915 off the Moray Firth.
Whilst the escape of the German fleet from the superior British firepower at Jutland was effected by the German cruisers and destroyers successfully turning away the British battleships, the German attempt to rely on U-boat attacks on the British fleet failed.

Torpedo boats did have some successes against battleships in World War I, as demonstrated by the sinking of the British pre-dreadnought by during the Dardanelles Campaign and the destruction of the Austro-Hungarian dreadnought by Italian motor torpedo boats in June 1918. In large fleet actions, however, destroyers and torpedo boats were usually unable to get close enough to the battleships to damage them. The only battleship sunk in a fleet action by either torpedo boats or destroyers was the obsolescent German pre-dreadnought . She was sunk by destroyers during the night phase of the Battle of Jutland.

The German High Seas Fleet, for their part, were determined not to engage the British without the assistance of submarines; and since the submarines were needed more for raiding commercial traffic, the fleet stayed in port for much of the war.

For many years, Germany simply had no battleships. The Armistice with Germany required that most of the High Seas Fleet be disarmed and interned in a neutral port; largely because no neutral port could be found, the ships remained in British custody in Scapa Flow, Scotland. The Treaty of Versailles specified that the ships should be handed over to the British. Instead, most of them were scuttled by their German crews on June 21, 1919 just before the signature of the peace treaty. The treaty also limited the German Navy, and prevented Germany from building or possessing any capital ships.
The inter-war period saw the battleship subjected to strict international limitations to prevent a costly arms race breaking out.
While the victors were not limited by the Treaty of Versailles, many of the major naval powers were crippled after the war. Faced with the prospect of a naval arms race against the United Kingdom and Japan, which would in turn have led to a possible Pacific war, the United States was keen to conclude the Washington Naval Treaty of 1922. This treaty limited the number and size of battleships that each major nation could possess, and required Britain to accept parity with the U.S. and to abandon the British alliance with Japan. The Washington treaty was followed by a series of other naval treaties, including the First Geneva Naval Conference (1927), the First London Naval Treaty (1930), the Second Geneva Naval Conference (1932), and finally the Second London Naval Treaty (1936), which all set limits on major warships. These treaties became effectively obsolete on September 1, 1939 at the beginning of World War II, but the ship classifications that had been agreed upon still apply. The treaty limitations meant that fewer new battleships were launched in 1919–1939 than in 1905–1914. The treaties also inhibited development by imposing upper limits on the weights of ships. Designs like the projected British , the first American , and the Japanese —all of which continued the trend to larger ships with bigger guns and thicker armor—never got off the drawing board. Those designs which were commissioned during this period were referred to as treaty battleships.

As early as 1914, the British Admiral Percy Scott predicted that battleships would soon be made irrelevant by aircraft. By the end of World War I, aircraft had successfully adopted the torpedo as a weapon. In 1921 the Italian general and air theorist Giulio Douhet completed a hugely influential treatise on strategic bombing titled "The Command of the Air", which foresaw the dominance of air power over naval units.

In the 1920s, General Billy Mitchell of the United States Army Air Corps, believing that air forces had rendered navies around the world obsolete, testified in front of Congress that "1,000 bombardment airplanes can be built and operated for about the price of one battleship" and that a squadron of these bombers could sink a battleship, making for more efficient use of government funds. This infuriated the U.S. Navy, but Mitchell was nevertheless allowed to conduct a careful series of bombing tests alongside Navy and Marine bombers. In 1921, he bombed and sank numerous ships, including the "unsinkable" German World War I battleship and the American pre-dreadnought .

Although Mitchell had required "war-time conditions", the ships sunk were obsolete, stationary, defenseless and had no damage control. The sinking of "Ostfriesland" was accomplished by violating an agreement that would have allowed Navy engineers to examine the effects of various munitions: Mitchell's airmen disregarded the rules, and sank the ship within minutes in a coordinated attack. The stunt made headlines, and Mitchell declared, "No surface vessels can exist wherever air forces acting from land bases are able to attack them." While far from conclusive, Mitchell's test was significant because it put proponents of the battleship against naval aviation on the back foot. Rear Admiral William A. Moffett used public relations against Mitchell to make headway toward expansion of the U.S. Navy's nascent aircraft carrier program.

The Royal Navy, United States Navy, and Imperial Japanese Navy extensively upgraded and modernized their World War I–era battleships during the 1930s. Among the new features were an increased tower height and stability for the optical rangefinder equipment (for gunnery control), more armor (especially around turrets) to protect against plunging fire and aerial bombing, and additional anti-aircraft weapons. Some British ships received a large block superstructure nicknamed the "Queen Anne's castle", such as in and , which would be used in the new conning towers of the fast battleships. External bulges were added to improve both buoyancy to counteract weight increase and provide underwater protection against mines and torpedoes. The Japanese rebuilt all of their battleships, plus their battlecruisers, with distinctive "pagoda" structures, though the received a more modern bridge tower that would influence the new . Bulges were fitted, including steel tube arrays to improve both underwater and vertical protection along the waterline. The U.S. experimented with cage masts and later tripod masts, though after the Japanese attack on Pearl Harbor some of the most severely damaged ships (such as and ) were rebuilt with tower masts, for an appearance similar to their contemporaries. Radar, which was effective beyond visual range and effective in complete darkness or adverse weather, was introduced to supplement optical fire control.

Even when war threatened again in the late 1930s, battleship construction did not regain the level of importance it had held in the years before World War I. The "building holiday" imposed by the naval treaties meant the capacity of dockyards worldwide had shrunk, and the strategic position had changed.

In Germany, the ambitious Plan Z for naval rearmament was abandoned in favor of a strategy of submarine warfare supplemented by the use of battlecruisers and commerce raiding (in particular by s). In Britain, the most pressing need was for air defenses and convoy escorts to safeguard the civilian population from bombing or starvation, and re-armament construction plans consisted of five ships of the . It was in the Mediterranean that navies remained most committed to battleship warfare. France intended to build six battleships of the and es, and the Italians four ships. Neither navy built significant aircraft carriers. The U.S. preferred to spend limited funds on aircraft carriers until the . Japan, also prioritising aircraft carriers, nevertheless began work on three mammoth "Yamato"s (although the third, , was later completed as a carrier) and a planned fourth was cancelled.

At the outbreak of the Spanish Civil War, the Spanish navy included only two small dreadnought battleships, and . "España" (originally named "Alfonso XIII"), by then in reserve at the northwestern naval base of El Ferrol, fell into Nationalist hands in July 1936. The crew aboard "Jaime I" remained loyal to the Republic, killed their officers, who apparently supported Franco's attempted coup, and joined the Republican Navy. Thus each side had one battleship; however, the Republican Navy generally lacked experienced officers. The Spanish battleships mainly restricted themselves to mutual blockades, convoy escort duties, and shore bombardment, rarely in direct fighting against other surface units. In April 1937, "España" ran into a mine laid by friendly forces, and sank with little loss of life. In May 1937, "Jaime I" was damaged by Nationalist air attacks and a grounding incident. The ship was forced to go back to port to be repaired. There she was again hit by several aerial bombs. It was then decided to tow the battleship to a more secure port, but during the transport she suffered an internal explosion that caused 300 deaths and her total loss. Several Italian and German capital ships participated in the non-intervention blockade. On May 29, 1937, two Republican aircraft managed to bomb the German pocket battleship outside Ibiza, causing severe damage and loss of life. retaliated two days later by bombarding Almería, causing much destruction, and the resulting "Deutschland" incident meant the end of German and Italian participation in non-intervention.

The —an obsolete pre-dreadnought—fired the first shots of World War II with the bombardment of the Polish garrison at Westerplatte; and the final surrender of the Japanese Empire took place aboard a United States Navy battleship, . Between those two events, it had become clear that aircraft carriers were the new principal ships of the fleet and that battleships now performed a secondary role.

Battleships played a part in major engagements in Atlantic, Pacific and Mediterranean theaters; in the Atlantic, the Germans used their battleships as independent commerce raiders. However, clashes between battleships were of little strategic importance. The Battle of the Atlantic was fought between destroyers and submarines, and most of the decisive fleet clashes of the Pacific war were determined by aircraft carriers.

In the first year of the war, armored warships defied predictions that aircraft would dominate naval warfare. and surprised and sank the aircraft carrier off western Norway in June 1940. This engagement marked the only time a fleet carrier was sunk by surface gunnery. In the attack on Mers-el-Kébir, British battleships opened fire on the French battleships in the harbor near Oran in Algeria with their heavy guns. The fleeing French ships were then pursued by planes from aircraft carriers.

The subsequent years of the war saw many demonstrations of the maturity of the aircraft carrier as a strategic naval weapon and its potential against battleships. The British air attack on the Italian naval base at Taranto sank one Italian battleship and damaged two more. The same Swordfish torpedo bombers played a crucial role in sinking the German battleship .
On December 7, 1941, the Japanese launched a surprise attack on Pearl Harbor. Within a short time, five of eight U.S. battleships were sunk or sinking, with the rest damaged. All three American aircraft carriers were out to sea, however, and evaded destruction. The sinking of the British battleship and battlecruiser , demonstrated the vulnerability of a battleship to air attack while at sea without sufficient air cover, settling the argument begun by Mitchell in 1921. Both warships were under way and en route to attack the Japanese amphibious force that had invaded Malaya when they were caught by Japanese land-based bombers and torpedo bombers on December 10, 1941.

At many of the early crucial battles of the Pacific, for instance Coral Sea and Midway, battleships were either absent or overshadowed as carriers launched wave after wave of planes into the attack at a range of hundreds of miles. In later battles in the Pacific, battleships primarily performed shore bombardment in support of amphibious landings and provided anti-aircraft defense as escort for the carriers. Even the largest battleships ever constructed, Japan's , which carried a main battery of nine 18-inch (46 cm) guns and were designed as a principal strategic weapon, were never given a chance to show their potential in the decisive battleship action that figured in Japanese pre-war planning.

The last battleship confrontation in history was the Battle of Surigao Strait, on October 25, 1944, in which a numerically and technically superior American battleship group destroyed a lesser Japanese battleship group by gunfire after it had already been devastated by destroyer torpedo attacks. All but one of the American battleships in this confrontation had previously been sunk during the attack on Pearl Harbor and subsequently raised and repaired. When fired the last salvo of this battle, the last salvo fired by a battleship against another heavy ship, she was "firing a funeral salute to a finished era of naval warfare". In April 1945, during the battle for Okinawa, the world's most powerful battleship, the "Yamato", was sent out on a suicide mission against a massive U.S. force and sunk by overwhelming pressure from carrier aircraft with nearly all hands lost.

After World War II, several navies retained their existing battleships, but they were no longer strategically dominant military assets. Indeed, it soon became apparent that they were no longer worth the considerable cost of construction and maintenance and only one new battleship was commissioned after the war, . During the war it had been demonstrated that battleship-on-battleship engagements like Leyte Gulf or the sinking of were the exception and not the rule, and with the growing role of aircraft engagement ranges were becoming longer and longer, making heavy gun armament irrelevant. The armor of a battleship was equally irrelevant in the face of a nuclear attack as tactical missiles with a range of or more could be mounted on the Soviet and s. By the end of the 1950s, smaller vessel classes such as destroyers, which formerly offered no noteworthy opposition to battleships, now were capable of eliminating battleships from outside the range of the ship's heavy guns.

The remaining battleships met a variety of ends. and were sunk during the testing of nuclear weapons in Operation Crossroads in 1946. Both battleships proved resistant to nuclear air burst but vulnerable to underwater nuclear explosions. The was taken by the Soviets as reparations and renamed "Novorossiysk"; she was sunk by a leftover German mine in the Black Sea on October 29, 1955. The two ships were scrapped in 1956. The French was scrapped in 1954, in 1968, and in 1970.
The United Kingdom's four surviving ships were scrapped in 1957, and followed in 1960. All other surviving British battleships had been sold or broken up by 1949. The Soviet Union's was scrapped in 1953, in 1957 and (back under her original name, , since 1942) in 1956-7. Brazil's was scrapped in Genoa in 1953, and her sister ship sank during a storm in the Atlantic "en route" to the breakers in Italy in 1951.

Argentina kept its two ships until 1956 and Chile kept (formerly ) until 1959. The Turkish battlecruiser (formerly , launched in 1911) was scrapped in 1976 after an offer to sell her back to Germany was refused. Sweden had several small coastal-defense battleships, one of which, , survived until 1970. The Soviets scrapped four large incomplete cruisers in the late 1950s, whilst plans to build a number of new s were abandoned following the death of Joseph Stalin in 1953. The three old German battleships , , and all met similar ends. "Hessen" was taken over by the Soviet Union and renamed "Tsel". She was scrapped in 1960. "Schleswig-Holstein" was renamed "Borodino", and was used as a target ship until 1960. "Schlesien", too, was used as a target ship. She was broken up between 1952 and 1957.
The s gained a new lease of life in the U.S. Navy as fire support ships. Radar and computer-controlled gunfire could be aimed with pinpoint accuracy to target. The U.S. recommissioned all four "Iowa"-class battleships for the Korean War and the for the Vietnam War. These were primarily used for shore bombardment, "New Jersey" firing nearly 6,000 rounds of 16 inch shells and over 14,000 rounds of 5 inch projectiles during her tour on the gunline, seven times more rounds against shore targets in Vietnam than she had fired in the Second World War.

As part of Navy Secretary John F. Lehman's effort to build a 600-ship Navy in the 1980s, and in response to the commissioning of "Kirov" by the Soviet Union, the United States recommissioned all four "Iowa"-class battleships. On several occasions, battleships were support ships in carrier battle groups, or led their own battleship battle group. These were modernized to carry Tomahawk (TLAM) missiles, with "New Jersey" seeing action bombarding Lebanon in 1983 and 1984, while and fired their 16-inch (406 mm) guns at land targets and launched missiles during Operation Desert Storm in 1991. "Wisconsin" served as the TLAM strike commander for the Persian Gulf, directing the sequence of launches that marked the opening of "Desert Storm", firing a total of 24 TLAMs during the first two days of the campaign. The primary threat to the battleships were Iraqi shore-based surface-to-surface missiles; "Missouri" was targeted by two Iraqi Silkworm missiles, with one missing and another being intercepted by the British destroyer .

After "Indiana" was stricken in 1962, the four "Iowa-class" ships were the only battleships in commission or reserve anywhere in the world. There was an extended debate when the four "Iowa" ships were finally decommissioned in the early 1990s. and were maintained to a standard where they could be rapidly returned to service as fire support vessels, pending the development of a superior fire support vessel. These last two battleships were finally stricken from the U.S. Naval Vessel Register in 2006. The Military Balance and Russian states the U.S. Navy listed one battleship in the reserve (Naval Inactive Fleet/Reserve 2nd Turn) in 2010. The Military Balance states the U.S. Navy listed no battleships in the reserve in 2014.

When the last "Iowa"-class ship was finally stricken from the Naval Vessel Registry, no battleships remained in service or in reserve with any navy worldwide. A number are preserved as museum ships, either afloat or in drydock. The U.S. has eight battleships on display: , , , , , , , and . "Missouri" and "New Jersey" are museums at Pearl Harbor and Camden, New Jersey, respectively. "Iowa" is on display as an educational attraction at the Los Angeles Waterfront in San Pedro, California. "Wisconsin" now serves as a museum ship in Norfolk, Virginia. "Massachusetts", which has the distinction of never having lost a man during service, is on display at the Battleship Cove naval museum in Fall River, Massachusetts. "Texas", the first battleship turned into a museum, is on display at the San Jacinto Battleground State Historic Site, near Houston. "North Carolina" is on display in Wilmington, North Carolina. "Alabama" is on display in Mobile, Alabama. The wreck of the , sunk during the Pearl Harbor attack in 1941, is designated a historical landmark and national gravesite.

The only other 20th-century battleship on display is the Japanese pre-dreadnought . A replica of the Chinese ironclad Dingyuan was built by the Weihai Port Bureau in 2003 and is on display in Weihai, China.

Battleships were the embodiment of sea power. For Alfred Thayer Mahan and his followers, a strong navy was vital to the success of a nation, and control of the seas was vital for the projection of force on land and overseas. Mahan's theory, proposed in "The Influence of Sea Power Upon History, 1660–1783" of 1890, dictated the role of the battleship was to sweep the enemy from the seas. While the work of escorting, blockading, and raiding might be done by cruisers or smaller vessels, the presence of the battleship was a potential threat to any convoy escorted by any vessels other than capital ships. This concept of "potential threat" can be further generalized to the mere existence (as opposed to presence) of a powerful fleet tying the opposing fleet down. This concept came to be known as a "fleet in being" – an idle yet mighty fleet forcing others to spend time, resource and effort to actively guard against it.

Mahan went on to say victory could only be achieved by engagements between battleships, which came to be known as the "decisive battle" doctrine in some navies, while targeting merchant ships (commerce raiding or "guerre de course", as posited by the "Jeune École") could never succeed.

Mahan was highly influential in naval and political circles throughout the age of the battleship, calling for a large fleet of the most powerful battleships possible. Mahan's work developed in the late 1880s, and by the end of the 1890s it had acquired much international influence on naval strategy; in the end, it was adopted by many major navies (notably the British, American, German, and Japanese). The strength of Mahanian opinion was important in the development of the battleships arms races, and equally important in the agreement of the Powers to limit battleship numbers in the interwar era.

The "fleet in being" suggested battleships could simply by their existence tie down superior enemy resources. This in turn was believed to be able to tip the balance of a conflict even without a battle. This suggested even for inferior naval powers a battleship fleet could have important strategic effect.

While the role of battleships in both World Wars reflected Mahanian doctrine, the details of battleship deployment were more complex. Unlike ships of the line, the battleships of the late 19th and early 20th centuries had significant vulnerability to torpedoes and mines—because efficient mines and torpedoes did not exist before that—which could be used by relatively small and inexpensive craft. The "Jeune École" doctrine of the 1870s and 1880s recommended placing torpedo boats alongside battleships; these would hide behind the larger ships until gun-smoke obscured visibility enough for them to dart out and fire their torpedoes. While this tactic was vitiated by the development of smokeless propellant, the threat from more capable torpedo craft (later including submarines) remained. By the 1890s, the Royal Navy had developed the first destroyers, which were initially designed to intercept and drive off any attacking torpedo boats. During the First World War and subsequently, battleships were rarely deployed without a protective screen of destroyers.

Battleship doctrine emphasised the concentration of the battlegroup. In order for this concentrated force to be able to bring its power to bear on a reluctant opponent (or to avoid an encounter with a stronger enemy fleet), battlefleets needed some means of locating enemy ships beyond horizon range. This was provided by scouting forces; at various stages battlecruisers, cruisers, destroyers, airships, submarines and aircraft were all used. (With the development of radio, direction finding and traffic analysis would come into play, as well, so even shore stations, broadly speaking, joined the battlegroup.) So for most of their history, battleships operated surrounded by squadrons of destroyers and cruisers. The North Sea campaign of the First World War illustrates how, despite this support, the threat of mine and torpedo attack, and the failure to integrate or appreciate the capabilities of new techniques, seriously inhibited the operations of the Royal Navy Grand Fleet, the greatest battleship fleet of its time.

The presence of battleships had a great psychological and diplomatic impact. Similar to possessing nuclear weapons today, the ownership of battleships served to enhance a nation's force projection.

Even during the Cold War, the psychological impact of a battleship was significant. In 1946, USS "Missouri" was dispatched to deliver the remains of the ambassador from Turkey, and her presence in Turkish and Greek waters staved off a possible Soviet thrust into the Balkan region. In September 1983, when Druze militia in Lebanon's Shouf Mountains fired upon U.S. Marine peacekeepers, the arrival of USS "New Jersey" stopped the firing. Gunfire from "New Jersey" later killed militia leaders.

Battleships were the largest and most complex, and hence the most expensive warships of their time; as a result, the value of investment in battleships has always been contested. As the French politician Etienne Lamy wrote in 1879, "The construction of battleships is so costly, their effectiveness so uncertain and of such short duration, that the enterprise of creating an armored fleet seems to leave fruitless the perseverance of a people". The "Jeune École" school of thought of the 1870s and 1880s sought alternatives to the crippling expense and debatable utility of a conventional battlefleet. It proposed what would nowadays be termed a sea denial strategy, based on fast, long-ranged cruisers for commerce raiding and torpedo boat flotillas to attack enemy ships attempting to blockade French ports. The ideas of the "Jeune École" were ahead of their time; it was not until the 20th century that efficient mines, torpedoes, submarines, and aircraft were available that allowed similar ideas to be effectively implemented. The determination of powers such as Germany to build battlefleets with which to confront much stronger rivals has been criticised by historians, who emphasise the futility of investment in a battlefleet that has no chance of matching its opponent in an actual battle.






</doc>
<doc id="4055" url="https://en.wikipedia.org/wiki?curid=4055" title="Bifröst">
Bifröst

In Norse mythology, Bifröst ( or sometimes Bilröst or Bivrost) is a burning rainbow bridge that reaches between Midgard (Earth) and Asgard, the realm of the gods. The bridge is attested as "Bilröst" in the "Poetic Edda"; compiled in the 13th century from earlier traditional sources, and as "Bifröst" in the "Prose Edda"; written in the 13th century by Snorri Sturluson, and in the poetry of skalds. Both the "Poetic Edda" and the "Prose Edda" alternately refer to the bridge as Ásbrú (Old Norse "Æsir's bridge").

According to the "Prose Edda", the bridge ends in heaven at Himinbjörg, the residence of the god Heimdallr, who guards it from the jötnar. The bridge's destruction during Ragnarök by the forces of Muspell is foretold. Scholars have proposed that the bridge may have originally represented the Milky Way and have noted parallels between the bridge and another bridge in Norse mythology, Gjallarbrú.

Scholar Andy Orchard posits that "Bifröst" may mean "shimmering path." He notes that the first element of "Bilröst"—"bil" (meaning "a moment")—"suggests the fleeting nature of the rainbow," which he connects to the first element of "Bifröst"—the Old Norse verb "bifa" (meaning "to shimmer" or "to shake")—noting that the element evokes notions of the "lustrous sheen" of the bridge. Austrian Germanist Rudolf Simek says that "Bifröst" either means "the swaying road to heaven" (also citing "bifa") or, if "Bilröst" is the original form of the two (which Simek says is likely), "the fleetingly glimpsed rainbow" (possibly connected to "bil", perhaps meaning "moment, weak point").

Two poems in the "Poetic Edda" and two books in the "Prose Edda" provide information about the bridge:

In the "Poetic Edda", the bridge is mentioned in the poems "Grímnismál" and "Fáfnismál", where it is referred to as "Bilröst". In one of two stanzas in the poem "Grímnismál" that mentions the bridge, Grímnir (the god Odin in disguise) provides the young Agnarr with cosmological knowledge, including that Bilröst is the best of bridges. Later in "Grímnismál", Grímnir notes that Asbrú "burns all with flames" and that, every day, the god Thor wades through the waters of Körmt and Örmt and the two Kerlaugar:

In "Fáfnismál", the dying wyrm Fafnir tells the hero Sigurd that, during the events of Ragnarök, bearing spears, gods will meet at Óskópnir. From there, the gods will cross Bilröst, which will break apart as they cross over it, causing their horses to dredge through an immense river.

The bridge is mentioned in the "Prose Edda" books "Gylfaginning" and "Skáldskaparmál", where it is referred to as "Bifröst". In chapter 13 of "Gylfaginning", Gangleri (King Gylfi in disguise) asks the enthroned figure of High what way exists between heaven and earth. Laughing, High replies that the question isn't an intelligent one, and goes on to explain that the gods built a bridge from heaven and earth. He incredulously asks Gangleri if he has not heard the story before. High says that Gangleri must have seen it, and notes that Gangleri may call it a rainbow. High says that the bridge consists of three colors, has great strength, "and is built with art and skill to a greater extent than other constructions."

High notes that, although the bridge is strong, it will break when "Muspell's lads" attempt to cross it, and their horses will have to make do with swimming over "great rivers." Gangleri says that it doesn't seem that the gods "built the bridge in good faith if it is liable to break, considering that they can do as they please." High responds that the gods do not deserve blame for the breaking of the bridge, for "there is nothing in this world that will be secure when Muspell's sons attack."

In chapter 15 of "Gylfaginning", Just-As-High says that Bifröst is also called "Asbrú", and that every day the gods ride their horses across it (with the exception of Thor, who instead wades through the boiling waters of the rivers Körmt and Örmt) to reach Urðarbrunnr, a holy well where the gods have their court. As a reference, Just-As-High quotes the second of the two stanzas in "Grímnismál" that mention the bridge (see above). Gangleri asks if fire burns over Bifröst. High says that the red in the bridge is burning fire, and, without it, the frost jotnar and mountain jotnar would "go up into heaven" if anyone who wanted could cross Bifröst. High adds that, in heaven, "there are many beautiful places" and that "everywhere there has divine protection around it."

In chapter 17, High tells Gangleri that the location of Himinbjörg "stands at the edge of heaven where Bifrost reaches heaven." While describing the god Heimdallr in chapter 27, High says that Heimdallr lives in Himinbjörg by Bifröst, and guards the bridge from mountain jotnar while sitting at the edge of heaven. In chapter 34, High quotes the first of the two "Grímnismál" stanzas that mention the bridge. In chapter 51, High foretells the events of Ragnarök. High says that, during Ragnarök, the sky will split open, and from the split will ride forth the "sons of Muspell". When the "sons of Muspell" ride over Bifröst it will break, "as was said above."

In the "Prose Edda" book "Skáldskaparmál", the bridge receives a single mention. In chapter 16, a work by the 10th century skald Úlfr Uggason is provided, where Bifröst is referred to as "the powers' way."

In his translation of the "Prose Edda", Henry Adams Bellows comments that the "Grímnismál" stanza mentioning Thor and the bridge stanza may mean that "Thor has to go on foot in the last days of the destruction, when the bridge is burning. Another interpretation, however, is that when Thor leaves the heavens (i.e., when a thunder-storm is over) the rainbow-bridge becomes hot in the sun."

John Lindow points to a parallel between Bifröst, which he notes is "a bridge between earth and heaven, or earth and the world of the gods", and the bridge Gjallarbrú, "a bridge between earth and the underworld, or earth and the world of the dead." Several scholars have proposed that Bifröst may represent the Milky Way.

The Bifröst appears in comic books associated with the Marvel Comics character Thor and in subsequent adaptations of those comic books. In the Marvel Cinematic Universe film "Thor", Jane Foster describes the Bifröst as an Einstein–Rosen bridge, which functions as a means of transportation across space in a short period of time.



</doc>
<doc id="4057" url="https://en.wikipedia.org/wiki?curid=4057" title="Battlecruiser">
Battlecruiser

The battlecruiser, or battle-cruiser, was a type of capital ship of the first half of the 20th century. They were similar in displacement, armament and cost to battleships, but differed slightly in form and balance of attributes. Battlecruisers typically had slightly thinner armour and a lighter main gun battery than contemporary battleships, installed on a longer hull with much higher engine power in order to attain greater speeds. The first battlecruisers were designed in the United Kingdom in the first decade of the century, as a development of the armoured cruiser, at the same time as the dreadnought succeeded the pre-dreadnought battleship. The goal of the design was to outrun any ship with similar armament, and chase down any ship with lesser armament; they were intended to hunt down slower, older armoured cruisers and destroy them with heavy gunfire while avoiding combat with the more powerful but slower battleships. However, as more and more battlecruisers were built, they were increasingly used alongside the better-protected battleships.

Battlecruisers served in the navies of the UK, Germany, the Ottoman Empire, Australia and Japan during World War I, most notably at the Battle of the Falkland Islands and in the several raids and skirmishes in the North Sea which culminated in a pitched fleet battle, the Battle of Jutland. British battlecruisers in particular suffered heavy losses at Jutland, where poor fire safety and ammunition handling practices left them vulnerable to catastrophic magazine explosions following hits to their main turrets from large-calibre shells. This dismal showing led to a persistent general belief that battlecruisers were too thinly armoured to function successfully. By the end of the war, capital ship design had developed, with battleships becoming faster and battlecruisers becoming more heavily armoured, blurring the distinction between a battlecruiser and a fast battleship. The Washington Naval Treaty, which limited capital ship construction from 1922 onwards, treated battleships and battlecruisers identically, and the new generation of battlecruisers planned was scrapped under the terms of the treaty.

Improvements in armor design and propulsion created the 1930s "fast battleship" with the speed of a battlecruiser and armor of a battleship, making the battlecruiser in the traditional sense effectively an obsolete concept. Thus from the 1930s on, only the Royal Navy continued to use "battlecruiser" as a classification for the World War I–era capital ships that remained in the fleet; while Japan's battlecruisers remained in service, they had been significantly reconstructed and were re-rated as full-fledged fast battleships.

Battlecruisers were put into action again during World War II, and only one survived to the end. There was also renewed interest in large "cruiser-killer" type warships, but few were ever begun, as construction of battleships and battlecruisers was curtailed in favor of more-needed convoy escorts, aircraft carriers, and cargo ships. In the post–Cold War era, the Soviet of large guided missile cruisers have also been termed "battlecruisers".

The battlecruiser was developed by the Royal Navy in the first years of the 20th century as an evolution of the armoured cruiser.

The first armoured cruisers had been built in the 1870s, as an attempt to give armour protection to ships fulfilling the typical cruiser roles of patrol, trade protection and power projection. However, the results were rarely satisfactory, as the weight of armour required for any meaningful protection usually meant that the ship became almost as slow as a battleship. As a result, navies preferred to build protected cruisers with an armoured deck protecting their engines, or simply no armour at all.

In the 1890s, technology began to change this balance. New Krupp steel armour meant that it was now possible to give a cruiser side armour which would protect it against the quick-firing guns of enemy battleships and cruisers alike. In 1896–97 France and Russia, who were regarded as likely allies in the event of war, started to build large, fast armoured cruisers taking advantage of this. In the event of a war between Britain and France or Russia, or both, these cruisers threatened to cause serious difficulties for the British Empire's worldwide trade.

Britain, which had concluded in 1892 that it needed twice as many cruisers as any potential enemy to adequately protect its empire's sea lanes, responded to the perceived threat by laying down its own large armoured cruisers. Between 1899 and 1905, it completed or laid down seven classes of this type, a total of 35 ships. This building program, in turn, prompted the French and Russians to increase their own construction. The Imperial German Navy began to build large armoured cruisers for use on their overseas stations, laying down eight between 1897 and 1906.

The cost of this cruiser arms race was significant. In the period 1889–1896, the Royal Navy spent £7.3 million on new large cruisers. From 1897 to 1904, it spent £26.9 million. Many armoured cruisers of the new kind were just as large and expensive as the equivalent battleship.

The increasing size and power of the armoured cruiser led to suggestions in British naval circles that cruisers should displace battleships entirely. The battleship's main advantage was its 12-inch heavy guns, and heavier armour designed to protect from shells of similar size. However, for a few years after 1900 it seemed that those advantages were of little practical value. The torpedo now had a range of 2,000 yards, and it seemed unlikely that a battleship would engage within torpedo range. However, at ranges of more than 2,000 yards it became increasingly unlikely that the heavy guns of a battleship would score any hits, as the heavy guns relied on primitive aiming techniques. The secondary batteries of 6-inch quick-firing guns, firing more plentiful shells, were more likely to hit the enemy. As naval expert Fred T. Jane wrote in June 1902,Is there anything outside of 2,000 yards that the big gun in its hundreds of tons of medieval castle can effect, that its weight in 6-inch guns without the castle could not effect equally well? And inside 2,000, what, in these days of gyros, is there that the torpedo cannot effect with far more certainty?

In 1904, Admiral John "Jacky" Fisher became First Sea Lord, the senior officer of the Royal Navy. He had for some time thought about the development of a new fast armoured ship. He was very fond of the "second-class battleship" , a faster, more lightly armoured battleship. As early as 1901, there is confusion in Fisher's writing about whether he saw the battleship or the cruiser as the model for future developments. This did not stop him from commissioning designs from naval architect W. H. Gard for an armoured cruiser with the heaviest possible armament for use with the fleet. The design Gard submitted was for a ship between , capable of , armed with four 9.2-inch and twelve guns in twin gun turrets and protected with six inches of armour along her belt and 9.2-inch turrets, on her 7.5-inch turrets, 10 inches on her conning tower and up to on her decks. However, mainstream British naval thinking between 1902 and 1904 was clearly in favour of heavily armoured battleships, rather than the fast ships that Fisher favoured.

The Battle of Tsushima proved conclusively the effectiveness of heavy guns over intermediate ones and the need for a uniform main caliber on a ship for fire control. Even before this, the Royal Navy had begun to consider a shift away from the mixed-calibre armament of the 1890s pre-dreadnought to an "all-big-gun" design, and preliminary designs circulated for battleships with all 12-inch or all 10-inch guns and armoured cruisers with all 9.2-inch guns. In late 1904, not long after the Royal Navy had decided to use 12-inch guns for its next generation of battleships because of their superior performance at long range, Fisher began to argue that big-gun cruisers could replace battleships altogether. The continuing improvement of the torpedo meant that submarines and destroyers would be able to destroy battleships; this in Fisher's view heralded the end of the battleship or at least compromised the validity of heavy armour protection. Nevertheless, armoured cruisers would remain vital for commerce protection.

Fisher's views were very controversial within the Royal Navy, and even given his position as First Sea Lord, he was not in a position to insist on his own approach. Thus he assembled a "Committee on Designs", consisting of a mixture of civilian and naval experts, to determine the approach to both battleship and armoured cruiser construction in the future. While the stated purpose of the committee was to investigate and report on future requirements of ships, Fisher and his associates had already made key decisions. The terms of reference for the committee were for a battleship capable of with 12-inch guns and no intermediate calibres, capable of docking in existing drydocks; and a cruiser capable of , also with 12-inch guns and no intermediate armament, armoured like , the most recent armoured cruiser, and also capable of using existing docks.

Under the Selborne plan of 1902, the Royal Navy intended to start three new battleships and four armoured cruisers each year. However, in late 1904 it became clear that the 1905–1906 programme would have to be considerably smaller, because of lower than expected tax revenue and the need to buy out two Chilean battleships under construction in British yards, lest they be purchased by the Russians for use against the Japanese, Britain's ally. These economies meant that the 1905–1906 programme consisted only of one battleship, but three armoured cruisers. The battleship became the revolutionary battleship , and the cruisers became the three ships of the . Fisher later claimed, however, that he had argued during the committee for the cancellation of the remaining battleship.

The construction of the new class was begun in 1906 and completed in 1908, delayed perhaps to allow their designers to learn from any problems with "Dreadnought". The ships fulfilled the design requirement quite closely. On a displacement similar to "Dreadnought", the "Invincible"s were longer to accommodate additional boilers and more powerful turbines to propel them at . Moreover, the new ships could maintain this speed for days, whereas pre-dreadnought battleships could not generally do so for more than an hour. Armed with eight 12-inch Mk X guns, compared to ten on "Dreadnought", they had of armour protecting the hull and the gun turrets. ("Dreadnought"s armour, by comparison, was at its thickest.) The class had a very marked increase in speed, displacement and firepower compared to the most recent armoured cruisers but no more armour.

While the "Invincible"s were to fill the same role as the armoured cruisers they succeeded, they were expected to do so more effectively. Specifically their roles were:
Confusion about how to refer to these new battleship-size armoured cruisers set in almost immediately. Even in late 1905, before work was begun on the "Invincible"s, a Royal Navy memorandum refers to "large armoured ships" meaning both battleships and large cruisers. In October 1906, the Admiralty began to classify all post-Dreadnought battleships and armoured cruisers as "capital ships", while Fisher used the term "dreadnought" to refer either to his new battleships or the battleships and armoured cruisers together. At the same time, the "Invincible" class themselves were referred to as "cruiser-battleships", "dreadnought cruisers"; the term "battlecruiser" was first used by Fisher in 1908. Finally, on 24 November 1911, Admiralty Weekly Order No. 351 laid down that "All cruisers of the “Invincible” and later types are for the future to be described and classified as “battle cruisers” to distinguish them from the armoured cruisers of earlier date."

Along with questions over the new ships' nomenclature came uncertainty about their actual role due to their lack of protection. If they were primarily to act as scouts for the battle fleet and hunter-killers of enemy cruisers and commerce raiders, then the seven inches of belt armour with which they had been equipped would be adequate. If, on the other hand, they were expected to reinforce a battle line of dreadnoughts with their own heavy guns, they were too thin-skinned to be safe from an enemy's heavy guns. The "Invincible"s were essentially extremely large, heavily armed, fast armoured cruisers. However, the viability of the armoured cruiser was already in doubt. A cruiser that could have worked with the Fleet might have been a more viable option for taking over that role.

Because of the "Invincible"s size and armament, naval authorities considered them capital ships almost from their inception—an assumption that might have been inevitable. Complicating matters further was that many naval authorities, including Lord Fisher, had made overoptimistic assessments from the Battle of Tsushima in 1905 about the armoured cruiser's ability to survive in a battle line against enemy capital ships due to their superior speed. These assumptions had been made without taking into account the Russian Baltic Fleet's inefficiency and tactical ineptitude. By the time the term "battlecruiser" had been given to the "Invincible"s, the idea of their parity with battleships had been fixed in many people's minds.

Not everyone was so convinced. "Brasseys Naval Annual", for instance, stated that with vessels as large and expensive as the "Invincible"s, an admiral "will be certain to put them in the line of battle where their comparatively light protection will be a disadvantage and their high speed of no value." Those in favor of the battlecruiser countered with two points—first, since all capital ships were vulnerable to new weapons such as the torpedo, armour had lost some of its validity; and second, because of its greater speed, the battlecruiser could control the range at which it engaged an enemy.

Between the launching of the "Invincible"s to just after the outbreak of the First World War, the battlecruiser played a junior role in the developing dreadnought arms race, as it was never wholeheartedly adopted as the key weapon in British imperial defence, as Fisher had presumably desired. The biggest factor for this lack of acceptance was the marked change in Britain's strategic circumstances between their conception and the commissioning of the first ships. The prospective enemy for Britain had shifted from a Franco-Russian alliance with many armoured cruisers to a resurgent and increasingly belligerent Germany. Diplomatically, Britain had entered the Entente cordiale in 1904 and the Anglo-Russian Entente. Neither France nor Russia posed a particular naval threat; the Russian navy had largely been sunk or captured in the Russo-Japanese War of 1904–1905, while the French were in no hurry to adopt the new dreadnought-type design. Britain also boasted very cordial relations with two of the significant new naval powers: Japan (bolstered by the Anglo-Japanese Alliance, signed in 1902 and renewed in 1905), and the US. These changed strategic circumstances, and the great success of the "Dreadnought" ensured that she rather than the "Invincible" became the new model capital ship. Nevertheless, battlecruiser construction played a part in the renewed naval arms race sparked by the "Dreadnought".
For their first few years of service, the "Invincible"s entirely fulfilled Fisher's vision of being able to sink any ship fast enough to catch them, and run from any ship capable of sinking them. An "Invincible" would also, in many circumstances, be able to take on an enemy pre-dreadnought battleship. Naval circles concurred that the armoured cruiser in its current form had come to the logical end of its development and the "Invincible"s were so far ahead of any enemy armoured cruiser in firepower and speed that it proved difficult to justify building more or bigger cruisers. This lead was extended by the surprise both "Dreadnought" and "Invincible" produced by having been built in secret; this prompted most other navies to delay their building programmes and radically revise their designs. This was particularly true for cruisers, because the details of the "Invincible" class were kept secret for longer; this meant that the last German armoured cruiser, , was armed with only guns, and was no match for the new battlecruisers.

The Royal Navy's early superiority in capital ships led to the rejection of a 1905–1906 design that would, essentially, have fused the battlecruiser and battleship concepts into what would eventually become the fast battleship. The 'X4' design combined the full armour and armament of "Dreadnought" with the 25-knot speed of "Invincible". The additional cost could not be justified given the existing British lead and the new Liberal government's need for economy; the slower and cheaper , a relatively close copy of "Dreadnought", was adopted instead. The X4 concept would eventually be fulfilled in the and later by other navies.

The next British battlecruisers were the three , slightly improved "Invincible"s built to fundamentally the same specification, partly due to political pressure to limit costs and partly due to the secrecy surrounding German battlecruiser construction, particularly about the heavy armour of . This class came to be widely seen as a mistake and the next generation of British battlecruisers were markedly more powerful. By 1909–1910 a sense of national crisis about rivalry with Germany outweighed cost-cutting, and a naval panic resulted in the approval of a total of eight capital ships in 1909–1910. Fisher pressed for all eight to be battlecruisers, but was unable to have his way; he had to settle for six battleships and two battlecruisers of the . The "Lion"s carried eight 13.5-inch guns, the now-standard caliber of the British "super-dreadnought" battleships. Speed increased to and armour protection, while not as good as in German designs, was better than in previous British battlecruisers, with armour belt and barbettes. The two "Lion"s were followed by the very similar .
By 1911 Germany had built battlecruisers of her own, and the superiority of the British ships could no longer be assured. Moreover, the German Navy did not share Fisher's view of the battlecruiser. In contrast to the British focus on increasing speed and firepower, Germany progressively improved the armour and staying power of their ships to better the British battlecruisers. "Von der Tann", begun in 1908 and completed in 1910, carried eight 11.1-inch guns, but with 11.1-inch (283 mm) armour she was far better protected than the "Invincible"s. The two s were quite similar but carried ten 11.1-inch guns of an improved design. , designed in 1909 and finished in 1913, was a modified "Moltke"; speed increased by one knot to , while her armour had a maximum thickness of 12 inches, equivalent to the s of a few years earlier. "Seydlitz" was Germany's last battlecruiser completed before World War I.

The next step in battlecruiser design came from Japan. The Imperial Japanese Navy had been planning the ships from 1909, and was determined that, since the Japanese economy could support relatively few ships, each would be more powerful than its likely competitors. Initially the class was planned with the "Invincible"s as the benchmark. On learning of the British plans for "Lion", and the likelihood that new U.S. Navy battleships would be armed with guns, the Japanese decided to radically revise their plans and go one better. A new plan was drawn up, carrying eight 14-inch guns, and capable of , thus marginally having the edge over the "Lion"s in speed and firepower. The heavy guns were also better-positioned, being superfiring both fore and aft with no turret amidships. The armour scheme was also marginally improved over the "Lion"s, with nine inches of armour on the turrets and on the barbettes. The first ship in the class was built in Britain, and a further three constructed in Japan. The Japanese also re-classified their powerful armoured cruisers of the "Tsukuba" and "Ibuki" classes, carrying four 12-inch guns, as battlecruisers; nonetheless, their armament was weaker and they were slower than any battlecruiser.
The next British battlecruiser, , was intended initially as the fourth ship in the "Lion" class, but was substantially redesigned. She retained the eight 13.5-inch guns of her predecessors, but they were positioned like those of "Kongō" for better fields of fire. She was faster (making on sea trials), and carried a heavier secondary armament. "Tiger" was also more heavily armoured on the whole; while the maximum thickness of armour was the same at nine inches, the height of the main armour belt was increased. Not all the desired improvements for this ship were approved, however. Her designer, Sir Eustace Tennyson d'Eyncourt, had wanted small-bore water-tube boilers and geared turbines to give her a speed of , but he received no support from the authorities and the engine makers refused his request.

1912 saw work begin on three more German battlecruisers of the , the first German battlecruisers to mount 12-inch guns. These ships, like "Tiger" and the "Kongō"s, had their guns arranged in superfiring turrets for greater efficiency. Their armour and speed was similar to the previous "Seydlitz" class. In 1913, the Russian Empire also began the construction of the four-ship , which were designed for service in the Baltic Sea. These ships were designed to carry twelve 14-inch guns, with armour up to 12 inches thick, and a speed of . The heavy armour and relatively slow speed of these ships made them more similar to German designs than to British ships; construction of the "Borodino"s was halted by the First World War and all were scrapped after the end of the Russian Civil War.

For most of the combatants, capital ship construction was very limited during the war. Germany finished the "Derfflinger" class and began work on the . The "Mackensen"s were a development of the "Derfflinger" class, with 13.8-inch guns and a broadly similar armour scheme, designed for .

In Britain, Jackie Fisher returned to the office of First Sea Lord in October 1914. His enthusiasm for big, fast ships was unabated, and he set designers to producing a design for a battlecruiser with 15-inch guns. Because Fisher expected the next German battlecruiser to steam at 28 knots, he required the new British design to be capable of 32 knots. He planned to reorder two s, which had been approved but not yet laid down, to a new design. Fisher finally received approval for this project on 28 December 1914 and they became the . With six 15-inch guns but only 6-inch armour they were a further step forward from "Tiger" in firepower and speed, but returned to the level of protection of the first British battlecruisers.

At the same time, Fisher resorted to subterfuge to obtain another three fast, lightly armoured ships that could use several spare gun turrets left over from battleship construction. These ships were essentially light battlecruisers, and Fisher occasionally referred to them as such, but officially they were classified as "large light cruisers". This unusual designation was required because construction of new capital ships had been placed on hold, while there were no limits on light cruiser construction. They became and her sisters and , and there was a bizarre imbalance between their main guns of 15 inches (or in "Furious") and their armour, which at thickness was on the scale of a light cruiser. The design was generally regarded as a failure (nicknamed in the Fleet "Outrageous", "Uproarious" and "Spurious"), though the later conversion of the ships to aircraft carriers was very successful. Fisher also speculated about a new mammoth, but lightly built battlecruiser, that would carry guns, which he termed ; this never got beyond the concept stage.

It is often held that the "Renown" and "Courageous" classes were designed for Fisher's plan to land troops (possibly Russian) on the German Baltic coast. Specifically, they were designed with a reduced draught, which might be important in the shallow Baltic. This is not clear-cut evidence that the ships were designed for the Baltic: it was considered that earlier ships had too much draught and not enough freeboard under operational conditions. Roberts argues that the focus on the Baltic was probably unimportant at the time the ships were designed, but was inflated later, after the disastrous Dardanelles Campaign.

The final British battlecruiser design of the war was the , which was born from a requirement for an improved version of the "Queen Elizabeth" battleship. The project began at the end of 1915, after Fisher's final departure from the Admiralty. While initially envisaged as a battleship, senior sea officers felt that Britain had enough battleships, but that new battlecruisers might be required to combat German ships being built (the British overestimated German progress on the "Mackensen" class as well as their likely capabilities). A battlecruiser design with eight 15-inch guns, 8 inches of armour and capable of 32 knots was decided on. The experience of battlecruisers at the Battle of Jutland meant that the design was radically revised and transformed again into a fast battleship with armour up to 12 inches thick, but still capable of . The first ship in the class, , was built according to this design to counter the possible completion of any of the Mackensen-class ship. The plans for her three sisters, on which little work had been done, were revised once more later in 1916 and in 1917 to improve protection.

The Admiral class would have been the only British ships capable of taking on the German "Mackensen" class; nevertheless, German shipbuilding was drastically slowed by the war, and while two "Mackensen"s were launched, none were ever completed. The Germans also worked briefly on a further three ships, of the , which were modified versions of the "Mackensen"s with 15-inch guns. Work on the three additional Admirals was suspended in March 1917 to enable more escorts and merchant ships to be built to deal with the new threat from U-boats to trade. They were finally cancelled in February 1919.

The first combat involving battlecruisers during World War I was the Battle of Heligoland Bight in August 1914. A force of British light cruisers and destroyers entered the Heligoland Bight (the part of the North Sea closest to Hamburg) to attack German destroyer patrols. When they met opposition from light cruisers, Vice Admiral David Beatty took his squadron of five battlecruisers into the Bight and turned the tide of the battle, ultimately sinking three German light cruisers and killing their commander, Rear Admiral Leberecht Maass.

The German battlecruiser perhaps made the most impact early in the war. Stationed in the Mediterranean, she and the escorting light cruiser evaded British and French ships on the outbreak of war, and steamed to Constantinople (Istanbul) with two British battlecruisers in hot pursuit. The two German ships were handed over to the Ottoman Navy, and this was instrumental in bringing the Ottoman Empire into the war as one of the Central Powers. "Goeben" herself, renamed "Yavuz Sultan Selim", fought engagements against the Imperial Russian Navy in the Black Sea before being knocked out of the action for the remainder of the war after the Battle of Imbros against British forces in the Aegean Sea in January 1918.

The original battlecruiser concept proved successful in December 1914 at the Battle of the Falkland Islands. The British battlecruisers and did precisely the job for which they were intended when they chased down and annihilated the German East Asia Squadron, centered on the armoured cruisers and , along with three light cruisers, commanded by Admiral Maximilian Graf Von Spee, in the South Atlantic Ocean. Prior to the battle, the Australian battlecruiser had unsuccessfully searched for the German ships in the Pacific.
During the Battle of Dogger Bank in 1915, the aftermost barbette of the German flagship "Seydlitz" was struck by a British 13.5-inch shell from HMS "Lion". The shell did not penetrate the barbette, but it dislodged a piece of the barbette armour that allowed the flame from the shell's detonation to enter the barbette. The propellant charges being hoisted upwards were ignited, and the fireball flashed up into the turret and down into the magazine, setting fire to charges removed from their brass cartridge cases. The gun crew tried to escape into the next turret, which allowed the flash to spread into that turret as well, killing the crews of both turrets. "Seydlitz" was saved from near-certain destruction only by emergency flooding of her after magazines, which had been effected by Wilhelm Heidkamp. This near-disaster was due to the way that ammunition handling was arranged and was common to both German and British battleships and battlecruisers, but the lighter protection on the latter made them more vulnerable to the turret or barbette being penetrated. The Germans learned from investigating the damaged "Seydlitz" and instituted measures to ensure that ammunition handling minimised any possible exposure to flash.

Apart from the cordite handling, the battle was mostly inconclusive, though both the British flagship "Lion" and "Seydlitz" were severely damaged. "Lion" lost speed, causing her to fall behind the rest of the battleline, and Beatty was unable to effectively command his ships for the remainder of the engagement. A British signalling error allowed the German battlecruisers to withdraw, as most of Beatty's squadron mistakenly concentrated on the crippled armoured cruiser "Blücher", sinking her with great loss of life. The British blamed their failure to win a decisive victory on their poor gunnery and attempted to increase their rate of fire by stockpiling unprotected cordite charges in their ammunition hoists and barbettes.
At the Battle of Jutland on 31 May 1916, both British and German battlecruisers were employed as fleet units. The British battlecruisers became engaged with both their German counterparts, the battlecruisers, and then German battleships before the arrival of the battleships of the British Grand Fleet. The result was a disaster for the Royal Navy's battlecruiser squadrons: "Invincible", "Queen Mary", and exploded with the loss of all but a handful of their crews. The exact reason why the ships' magazines detonated is not known, but the plethora of exposed cordite charges stored in their turrets, ammunition hoists and working chambers in the quest to increase their rate of fire undoubtedly contributed to their loss. Beatty's flagship "Lion" herself was almost lost in a similar manner, save for the heroic actions of Major Francis Harvey.

The better-armoured German battlecruisers fared better, in part due to the poor performance of British fuzes (the British shells tended to explode or break up on impact with the German armour). —the only German battlecruiser lost at Jutland—had only 128 killed, for instance, despite receiving more than thirty hits. The other German battlecruisers, , "Von der Tann", "Seydlitz", and , were all heavily damaged and required extensive repairs after the battle, "Seydlitz" barely making it home, for they had been the focus of British fire for much of the battle.

In the years immediately after World War I, Britain, Japan and the US all began design work on a new generation of ever more powerful battleships and battlecruisers. The new burst of shipbuilding that each nation's navy desired was politically controversial and potentially economically crippling. This nascent arms race was prevented by the Washington Naval Treaty of 1922, where the major naval powers agreed to limits on capital ship numbers. The German navy was not represented at the talks; under the terms of the Treaty of Versailles, Germany was not allowed any modern capital ships at all.

Through the 1920s and 1930s only Britain and Japan retained battlecruisers, often modified and rebuilt from their original designs. The line between the battlecruiser and the modern fast battleship became blurred; indeed, the Japanese "Kongō"s were formally redesignated as battleships after their very comprehensive reconstruction in the 1930s.

"Hood", launched in 1918, was the last World War I battlecruiser to be completed. Owing to lessons from Jutland, the ship was modified during construction; the thickness of her belt armour was increased by an average of 50 percent and extended substantially, she was given heavier deck armour, and the protection of her magazines was improved to guard against the ignition of ammunition. This was hoped to be capable of resisting her own weapons—the classic measure of a "balanced" battleship. "Hood" was the largest ship in the Royal Navy when completed; thanks to her great displacement, in theory she combined the firepower and armour of a battleship with the speed of a battlecruiser, causing some to refer to her as a fast battleship. However, her protection was markedly less than that of the British battleships built immediately after World War I, the .
The navies of Japan and the United States, not being affected immediately by the war, had time to develop new heavy guns for their latest designs and to refine their battlecruiser designs in light of combat experience in Europe. The Imperial Japanese Navy began four s. These vessels would have been of unprecedented size and power, as fast and well armoured as "Hood" whilst carrying a main battery of ten 16-inch guns, the most powerful armament ever proposed for a battlecruiser. They were, for all intents and purposes, fast battleships—the only differences between them and the s which were to precede them were less side armour and a increase in speed. The United States Navy, which had worked on its battlecruiser designs since 1913 and watched the latest developments in this class with great care, responded with the . If completed as planned, they would have been exceptionally fast and well armed with eight 16-inch guns, but carried armour little better than the "Invincible"s—this after an increase in protection following Jutland. The final stage in the post-war battlecruiser race came with the British response to the "Amagi" and "Lexington" types: four G3 battlecruisers. Royal Navy documents of the period often described any battleship with a speed of over about as a battlecruiser, regardless of the amount of protective armour, although the G3 was considered by most to be a well-balanced fast battleship.

The Washington Naval Treaty meant that none of these designs came to fruition. Ships that had been started were either broken up on the slipway or converted to aircraft carriers. In Japan, "Amagi" and were selected for conversion. "Amagi" was damaged beyond repair by the 1923 Great Kantō earthquake and was broken up for scrap; the hull of one of the proposed "Tosa"-class battleships, , was converted in her stead. The United States Navy also converted two battlecruiser hulls into aircraft carriers in the wake of the Washington Treaty: and , although this was only considered marginally preferable to scrapping the hulls outright (the remaining four: "Constellation", "Ranger", "Constitution" and "United States" were scrapped). In Britain, Fisher's "large light cruisers," were converted to carriers. "Furious" had already been partially converted during the war and "Glorious" and "Courageous" were similarly converted.

In total, nine battlecruisers survived the Washington Naval Treaty, although HMS "Tiger" later became a victim of the London Naval Conference 1930 and was scrapped. Because their high speed made them valuable surface units in spite of their weaknesses, most of these ships were significantly updated before World War II. and were modernized significantly in the 1920s and 1930s. Between 1934 and 1936, "Repulse" was partially modernized and had her bridge modified, an aircraft hangar, catapult and new gunnery equipment added and her anti-aircraft armament increased. "Renown" underwent a more thorough reconstruction between 1937 and 1939. Her deck armour was increased, new turbines and boilers were fitted, an aircraft hangar and catapult added and she was completely rearmed aside from the main guns which had their elevation increased to +30 degrees. The bridge structure was also removed and a large bridge similar to that used in the battleships installed in its place. While conversions of this kind generally added weight to the vessel, "Renown"s tonnage actually decreased due to a substantially lighter power plant. Similar thorough rebuildings planned for "Repulse" and "Hood" were cancelled due to the advent of World War II.

Unable to build new ships, the Imperial Japanese Navy also chose to improve its existing battlecruisers of the "Kongō" class (initially the , , and —the only later as it had been disarmed under the terms of the Washington treaty) in two substantial reconstructions (one for "Hiei"). During the first of these, elevation of their main guns was increased to +40 degrees, anti-torpedo bulges and of horizontal armour added, and a "pagoda" mast with additional command positions built up. This reduced the ships' speed to . The second reconstruction focused on speed as they had been selected as fast escorts for aircraft carrier task forces. Completely new main engines, a reduced number of boilers and an increase in hull length by allowed them to reach up to 30 knots once again. They were reclassified as "fast battleships," although their armour and guns still fell short compared to surviving World War I–era battleships in the American or the British navies, with dire consequences during the Pacific War, when "Hiei" and "Kirishima" were easily crippled by US gunfire during actions off Guadalcanal, forcing their scuttling shortly afterwards. Perhaps most tellingly, "Hiei" was crippled by medium-caliber gunfire from heavy and light cruisers in a close-range night engagement.

There were two exceptions: Turkey's "Yavuz Sultan Selim" and the Royal Navy's "Hood". The Turkish Navy made only minor improvements to the ship in the interwar period, which primarily focused on repairing wartime damage and the installation of new fire control systems and anti-aircraft batteries. "Hood" was in constant service with the fleet and could not be withdrawn for an extended reconstruction. She received minor improvements over the course of the 1930s, including modern fire control systems, increased numbers of anti-aircraft guns, and in March 1941, radar.

In the late 1930s navies began to build capital ships again, and during this period a number of large commerce raiders and small, fast battleships were built that are sometimes referred to as battlecruisers. Germany and Russia designed new battlecruisers during this period, though only the latter laid down two of the 35,000-ton . They were still on the slipways when the Germans invaded in 1941 and construction was suspended. Both ships were scrapped after the war.

The Germans planned three battlecruisers of the as part of the expansion of the Kriegsmarine (Plan Z). With six 15-inch guns, high speed, excellent range, but very thin armour, they were intended as commerce raiders. Only one was ordered shortly before World War II; no work was ever done on it. No names were assigned, and they were known by their contract names: 'O', 'P', and 'Q'. The new class was not universally welcomed in the Kriegsmarine. Their abnormally-light protection gained it the derogatory nickname "Ohne Panzer Quatsch" (without armour nonsense) within certain circles of the Navy.

The Royal Navy deployed some of its battlecruisers during the Norwegian Campaign in April 1940. The and the were engaged during the Action off Lofoten by "Renown" in very bad weather and disengaged after "Gneisenau" was damaged. One of "Renown"s 15-inch shells passed through "Gneisenau"s director-control tower without exploding, severing electrical and communication cables as it went and destroyed the rangefinders for the forward 150 mm (5.9 in) turrets. Main-battery fire control had to be shifted aft due to the loss of electrical power. Another shell from "Renown" knocked out "Gneisenau"s aft turret. The British ship was struck twice by German shells that failed to inflict any significant damage. She was the only pre-war battlecruiser to survive the war.

In the early years of the war various German ships had a measure of success hunting merchant ships in the Atlantic. Allied battlecruisers such as "Renown", "Repulse", and the fast battleships "Dunkerque" and were employed on operations to hunt down the commerce-raiding German ships. The one stand-up fight occurred when the battleship and the heavy cruiser sortied into the North Atlantic to attack British shipping and were intercepted by "Hood" and the battleship in May 1941 in the Battle of the Denmark Strait. The elderly British battlecruiser was no match for the modern German battleship: within minutes, the "Bismarck"s 15-inch shells caused a magazine explosion in "Hood" reminiscent of the Battle of Jutland. Only three men survived.

The first battlecruiser to see action in the Pacific War was "Repulse" when she was sunk by Japanese torpedo bombers north of Singapore on 10 December 1941 whilst in company with "Prince of Wales". She was lightly damaged by a single bomb and near-missed by two others in the first Japanese attack. Her speed and agility enabled her to avoid the other attacks by level bombers and dodge 33 torpedoes. The last group of torpedo bombers attacked from multiple directions and "Repulse" was struck by five torpedoes. She quickly capsized with the loss of 27 officers and 486 crewmen; 42 officers and 754 enlisted men were rescued by the escorting destroyers. The loss of "Repulse" and "Prince of Wales" conclusively proved the vulnerability of capital ships to aircraft without air cover of their own.

The Japanese "Kongō"-class battlecruisers were extensively used as carrier escorts for most of their wartime career due to their high speed. Their World War I–era armament was weaker and their upgraded armour was still thin compared to contemporary battleships. On 13 November 1942, during the First Naval Battle of Guadalcanal, "Hiei" stumbled across American cruisers and destroyers at point-blank range. The ship was badly damaged in the encounter and had to be towed by her sister ship "Kirishima". Both were spotted by American aircraft the following morning and "Kirishima" was forced to cast off her tow because of repeated aerial attacks. "Hiei"s captain ordered her crew to abandon ship after further damage and scuttled "Hiei" in the early evening of 14 November. On the night of 14/15 November during the Second Naval Battle of Guadalcanal, "Kirishima" returned to Ironbottom Sound, but encountered the American battleships and . While failing to detect "Washington", "Kirishima" engaged "South Dakota" with some effect. "Washington" opened fire a few minutes later at short range and badly damaged "Kirishima", knocking out her aft turrets, jamming her rudder, and hitting the ship below the waterline. The flooding proved to be uncontrollable and "Kirishima" capsized three and a half hours later.

Returning to Japan after the Battle of Leyte Gulf, "Kongō" was torpedoed and sunk by the American submarine on 21 November 1944. "Haruna" was moored at Kure, Japan when the naval base was attacked by American carrier aircraft on 24 and 28 July. The ship was only lightly damaged by a single bomb hit on 24 July, but was hit a dozen more times on 28 July and sank at her pier. She was refloated after the war and scrapped in early 1946.

A late renaissance in popularity of ships between battleships and cruisers in size occurred on the eve of World War II. Described by some as battlecruisers, but never classified as capital ships, they were variously described as "super cruisers", "large cruisers" or even "unrestricted cruisers". The Dutch, American, and Japanese navies all planned these new classes specifically to counter the heavy cruisers, or their counterparts, being built by their naval rivals.

The first such battlecruisers were the Dutch Design 1047, designed to protect their colonies in the East Indies in the face of Japanese aggression. Never officially assigned names, these ships were designed with German and Italian assistance. While they broadly resembled the German "Scharnhorst" class and had the same main battery, they would have been more lightly armoured and only protected against eight-inch gunfire. Although the design was mostly completed, work on the vessels never commenced as the Germans overran the Netherlands in May 1940. The first ship would have been laid down in June of that year.

The only class of these late battlecruisers actually built were the United States Navy's "large cruisers". Two of them were completed, and ; a third, , was cancelled while under construction and three others, to be named "Philippines", "Puerto Rico" and "Samoa", were cancelled before they were laid down. They were classified as "large cruisers" instead of battlecruisers, and their status as non-capital ships evidenced by their being named for territories or protectorates. (Battleships, in contrast, were named after states and cruisers after cities.) With a main armament of nine 12-inch guns in three triple turrets and a displacement of , the "Alaska"s were twice the size of s and had guns some 50% larger in diameter. They lacked the thick armoured belt and intricate torpedo defence system of true capital ships. However, unlike most battlecruisers, they were considered a balanced design according to cruiser standards as their protection could withstand fire from their own caliber of gun, albeit only in a very narrow range band. They were designed to hunt down Japanese heavy cruisers, though by the time they entered service most Japanese cruisers had been sunk by American aircraft or submarines. Like the contemporary fast battleships, their speed ultimately made them more useful as carrier escorts and bombardment ships than as the surface combatants they were developed to be.

The Japanese started designing the B64 class, which was similar to the "Alaska" but with guns. News of the "Alaska"s led them to upgrade the design, creating Design B-65. Armed with 356 mm guns, the B65s would have been the best armed of the new breed of battlecruisers, but they still would have had only sufficient protection to keep out eight-inch shells. Much like the Dutch, the Japanese got as far as completing the design for the B65s, but never laid them down. By the time the designs were ready the Japanese Navy recognized that they had little use for the vessels and that their priority for construction should lie with aircraft carriers. Like the "Alaska"s, the Japanese did not call these ships battlecruisers, referring to them instead as super-heavy cruisers.

In spite of the fact that most navies abandoned the battleship and battlecruiser concepts after World War II, Joseph Stalin's fondness for big-gun-armed warships caused the Soviet Union to plan a large cruiser class in the late 1940s. In the Soviet Navy, they were termed "heavy cruisers" ("tjazholyj krejser"). The fruits of this program were the Project 82 ("Stalingrad") cruisers, of standard load, nine guns and a speed of . Three ships were laid down in 1951–1952, but they were cancelled in April 1953 after Stalin's death. Only the central armoured hull section of the first ship, "Stalingrad", was launched in 1954 and then used as a target.

The Soviet is sometimes referred to as a battlecruiser. This description arises from their over displacement, which is roughly equal to that of a First World War battleship and more than twice the displacement of contemporary cruisers; upon entry into service, "Kirov" was the largest surface ship (aside from aircraft carriers and amphibious assault ships) to be built since World War II. The "Kirov" class lacks the armour that distinguishes battlecruisers from ordinary cruisers and they are classified as heavy nuclear-powered missile cruisers ("tyazholyy atomnyy raketny kreyser") by Russia, with their primary surface armament consisting of twenty P-700 Granit surface to surface missiles. Four members of the class were completed during the 1980s and 1990s, but due to budget constraints only the is operational with the Russian Navy, though plans were announced in 2010 to return the other three ships to service. As of 2012 one ship was being refitted, but the other two ships are reportedly beyond economical repair.





</doc>
<doc id="4059" url="https://en.wikipedia.org/wiki?curid=4059" title="Bob Hawke">
Bob Hawke

Robert James Lee Hawke, (9 December 1929 – 16 May 2019) was an Australian politician who served as Prime Minister of Australia and Leader of the Labor Party from 1983 to 1991. He was also Member of Parliament (MP) for Wills from 1980 to 1992.

Hawke was born in Bordertown, South Australia. He attended the University of Western Australia and went on to study at University College, Oxford as a Rhodes Scholar. In 1956, Hawke joined the Australian Council of Trade Unions (ACTU) as a research officer. Having risen to become responsible for wage arbitration, he was elected ACTU President in 1969, where he achieved a high public profile.

After a decade serving in that role, Hawke announced his intention to enter politics, and was subsequently elected to the House of Representatives as the Labor MP for Wills in Victoria. Three years later, he led Labor to a landslide victory at the 1983 election and was sworn in as Australia's 23rd Prime Minister. He went on to lead Labor to victory three more times, in 1984, 1987 and 1990, making him the most electorally successful Labor Leader in history.

The Hawke Government created Medicare and Landcare, brokered the Prices and Incomes Accord, established APEC, floated the Australian dollar, deregulated the financial sector, introduced the Family Assistance Scheme, announced "Advance Australia Fair" as the official national anthem, initiated superannuation pension schemes for all workers and oversaw passage of the Australia Act that removed all remaining jurisdiction by the United Kingdom from Australia. During his time as Prime Minister, Hawke recorded the highest popularity rating ever measured by an Australian opinion poll, reaching 75% approval in 1984.

In June 1991, Treasurer Paul Keating unsuccessfully challenged for the leadership, believing that Hawke had reneged on the Kirribilli Agreement. Keating mounted a second challenge six months later, this time narrowly succeeding. Hawke subsequently retired from Parliament, pursuing both a business career and a number of charitable causes, until his death in 2019, aged 89. Hawke remains Labor's longest-serving and Australia's third-longest-serving Prime Minister; he is also the only Prime Minister to be born in South Australia and the only one raised in Western Australia.

Bob Hawke was born on 9 December 1929 in Bordertown, South Australia, the second child of Arthur Hawke (1898–1989) (known as Clem), a Congregationalist minister, and his wife Edith Emily (Lee) (1897–1979) (known as Ellie), a schoolteacher. His uncle, Albert, was the Labor Premier of Western Australia between 1953 and 1959.

Hawke's brother Neil, who was seven years his senior, died at the age of seventeen after contracting meningitis, for which there was no cure at the time. Ellie Hawke subsequently developed an almost messianic belief in her son's destiny, and this contributed to Hawke's supreme self-confidence throughout his career. At the age of fifteen, he presciently boasted to friends that he would one day become the Prime Minister of Australia.

At the age of seventeen, the same age that his brother Neil had died, Hawke had a serious accident while riding his Panther motorcycle that left him in a critical condition for several days. This near-death experience acted as his catalyst, driving him to make the most of his talents and not let his abilities go to waste. He joined the Labor Party in 1947 at the age of eighteen.

Hawke was educated at Perth Modern School and the University of Western Australia, graduating in 1952 with a Bachelor of Arts and Bachelor of Laws. He was also president of the university's guild during the same year. The following year, Hawke won a Rhodes Scholarship to attend University College, Oxford, where he undertook a Bachelor of Arts in philosophy, politics and economics (PPE). He soon found he was covering much the same ground as he did in his education at the University of Western Australia, and transferred to a Bachelor of Letters. He wrote his thesis on wage-fixing in Australia and successfully presented it in January 1956.

His academic achievements were complemented by setting a new world record for beer drinking; he downed —equivalent to a yard of ale—from a sconce pot in 11 seconds as part of a college penalty. In his memoirs, Hawke suggested that this single feat may have contributed to his political success more than any other, by endearing him to an electorate with a strong beer culture.

In 1956, Hawke accepted a scholarship to undertake doctoral studies in the area of arbitration law in the law department at the Australian National University in Canberra. Soon after his arrival at ANU, Hawke became the students' representative on the University Council. A year later, Hawke was recommended to the President of the Australian Council of Trade Unions (ACTU) to become a research officer, replacing Harold Souter who had become ACTU Secretary. The recommendation was made by Hawke's mentor at ANU, H.P. Brown, who for a number of years had assisted the ACTU in national wage cases. Hawke decided to abandon his doctoral studies and accept the offer, moving to Melbourne with his wife Hazel.

 Not long after Hawke began work at the ACTU, he became responsible for the presentation of its annual case for higher wages to the national wages tribunal, the Conciliation and Arbitration Commission. He was first appointed as an ACTU advocate in 1959. The 1958 case, under previous advocate R.L. Eggleston, had yielded only a five-shilling increase. The 1959 case found for a fifteen-shilling increase, and was regarded as a personal triumph for Hawke. He went on to attain such success and prominence in his role as an ACTU advocate that, in 1969, he was encouraged to run for the position of ACTU President, despite the fact that he had never held elected office in a trade union.

He was elected ACTU President in 1969 on a modernising platform by the narrow margin of 399 to 350, with the support of the left of the union movement, including some associated with the Communist Party. He later credited Ray Gietzelt, General Secretary of the FMWU, as the single most significant union figure in helping him achieve this outcome.

Hawke declared publicly that "socialist is not a word I would use to describe myself", and his approach to government was pragmatic. His commitment to the cause of Jewish Refuseniks which purportedly led to a planned assassination attempt on Hawke by the Popular Front for the Liberation of Palestine, and its Australian operative Munif Mohammed Abou Rish.

In 1971, Hawke along with other members of the ACTU requested that South Africa send a non-racially biased team for the Rugby Union tour, with the intention of unions agreeing not to serve the team in Australia. Prior to arrival, the Western Australian branch of the Transport Workers Union, and the Barmaids' and Barmens' Union, announced that they would serve the team, which allowed the Springboks to land in Perth. The tour commenced on 26 June and riots occurred as anti-apartheid protesters disrupted games. Hawke and his family started to receive malicious mail and phone calls from people who thought that sport and politics should not mix. Hawke remained committed to the ban on apartheid teams and later that year, the South African cricket team was successfully denied and no apartheid team was to ever come to Australia again. It was this ongoing dedication to racial equality in South Africa that would later earn Hawke the respect and friendship of Nelson Mandela.

In industrial matters, Hawke continued to demonstrate a preference for, and considerable skill at, negotiation, and was generally liked and respected by employers as well as the unions he advocated for. As early as 1972, speculation began that he would seek to enter Parliament and eventually run to become the Leader of the Labor Party. But while his professional career continued successfully, his heavy drinking and womanising placed considerable strains on his family life.

In 1973, Hawke was elected as the Federal President of the Labor Party. Two years later, when the Whitlam Government was controversially dismissed by the Governor-General, Hawke showed an initial keenness to enter Parliament at the ensuing election. Harry Jenkins, the MP for Scullin, came under pressure to step down to allow Hawke to stand in his place, but he strongly resisted this push. Hawke eventually decided not to attempt to enter Parliament at that time, a decision he soon regretted. After Labor was defeated at the election, Whitlam initially offered the leadership to Hawke, although it was not within Whitlam's power to decide who would succeed him. Despite not taking on the offer, Hawke remained influential, playing a key role in averting national strike action.

The strain of this period, serving as both ACTU President and Labor Party President, took its toll on Hawke and in 1979 he suffered a physical collapse. This shock led Hawke to publicly announce his alcoholism in a television interview, and that he would make a concerted—and ultimately successful—effort to overcome it. He was helped through this period by the relationship that he had established with writer Blanche d'Alpuget, who, in 1982, published a biography of Hawke. His popularity with the public was, if anything, enhanced by this period of rehabilitation, and opinion polling suggested that he was a far more popular public figure than either Labor leader Bill Hayden or Liberal prime minister Malcolm Fraser.

Hawke's first attempt to enter Parliament came during the 1963 federal election. He stood in the seat of Corio in Geelong and managed to achieve a 3.1% swing against the national trend, although he fell short of ousting longtime Liberal incumbent Hubert Opperman.

Hawke passed up several opportunities to enter Parliament throughout the 1970s, something he later wrote that he "regretted". He eventually stood for election to the House of Representatives at the 1980 election for the safe Melbourne seat of Wills, winning it comfortably. Immediately upon his election to Parliament, Hawke was appointed to the Shadow Cabinet by Labor Leader Bill Hayden as Shadow Minister for Industrial Relations.

Hayden, after having lost (albeit narrowly) the 1980 election, was increasingly subject to criticism from ALP figures concerning his leadership. In order to quell speculation over his position, Hayden eventually called a leadership ballot for 16 July 1982, believing that if he won he would be able to lead Labor into the next election. Hawke duly challenged Hayden, but Hayden was able to defeat him and remain in position, although his five-vote victory over the former ACTU President was not large enough to dispel doubts that he could lead the Labor Party to victory at an election.

Despite being defeated, Hawke continued to agitate behind the scenes for a change in leadership, with opinion polls continuing to show that Hawke was a far more popular figure than both Hayden and the prime minister, Malcolm Fraser. Hayden was further weakened after the ALP's unexpectedly poor performance at a by-election in December 1982 for the Victorian seat of Flinders, following the resignation of the former Liberal minister Phillip Lynch. Labor needed a swing of 5.5% to win the seat and had been predicted by the media to win, but could only achieve a swing of 3%.

Labor Party power-brokers, such as Graham Richardson and Barrie Unsworth, now openly switched their allegiance from Hayden to Hawke. More significantly, Hayden's staunch friend and political ally, Labor's Senate Leader John Button, had become convinced that Hawke's chances of victory at an election were greater than Hayden's. Initially Hayden believed that he could remain in his job, but Button's defection proved to be the final straw in convincing Hayden that he would have to resign as Labor Leader.

Less than two months after the poor result at the Flinders by-election, Hayden announced his resignation as Leader of the Labor Party to the caucus on 3 February 1983. Hawke was subsequently named as leader—and hence became Leader of the Opposition—pending a party-room ballot at which he was elected unopposed. Having learned about the impending change, on the same day Fraser called a snap election for 5 March 1983, hoping to capitalise on Labor's feuding before it could replace Hayden with Hawke. However, he was unable to have the Governor-General confirm the election before Labor announced the change. In the election held a month later, Hawke led Labor to a landslide election victory, achieving a 24-seat swing—still the worst defeat that a sitting non-Labor Government has ever suffered—and ending seven years of Liberal Party rule.

After Labor's landslide victory, Hawke was sworn in as the 23rd Prime Minister of Australia by the governor-general on 11 March 1983. The inaugural days of the Hawke Government were distinctly different from those of the Whitlam Government. Rather than immediately initiating extensive reform programs as Whitlam had, Hawke announced that Malcolm Fraser's pre-election concealment of the budget deficit meant that many of Labor's election commitments would have to be deferred. As part of his internal reforms package, Hawke divided the government into two tiers, with only the most senior ministers sitting in the cabinet. The Labor caucus was still given the authority to determine who would make up the ministry, but gave Hawke unprecedented powers for a Labor prime minister to select which individual ministers would comprise the 13-strong Cabinet.

Hawke said that he did this in order to avoid what he viewed as the unwieldy nature of the Whitlam cabinet, which had 27 members. Caucus under Hawke also exhibited a much more formalised system of parliamentary factions, which significantly altered the dynamics of caucus operations.

Unlike his predecessor, Hawke's authority within the Labor Party was absolute. This enabled him to persuade his MPs to support a substantial set of policy changes. Individual accounts from ministers indicate that while Hawke was not usually the driving force behind individual reforms, he took on the role of achieving consensus and providing political guidance on what was electorally feasible and how best to sell it to the public, tasks at which he proved highly successful. Hawke took on a very public role as prime minister, proving to be incredibly popular with the Australian electorate; to this date he still holds the highest ever AC Nielsen approval rating.

According to political commentator Paul Kelly, "the most influential economic decisions of the 1980s were the floating of the Australian dollar and the deregulation of the financial system". Although the Fraser Government had played a part in the process of financial deregulation by commissioning the 1981 Campbell Report, opposition from Fraser himself had stalled the deregulation process. When the Hawke Government implemented a comprehensive program of financial deregulation and reform, it "transformed economics and politics in Australia". The Australian economy became significantly more integrated with the global economy as a result, which completely transformed its relationship with Asia, Europe and the United States. Both Hawke and Keating would claim the credit for being the driving force behind the success of the Australian Dollar float. That year the economy was seen to be in crisis with a 40% devaluation of the Australian dollar, a marked increase in the current account deficit and the loss of the Federal Government's triple A rating.

Among other reforms, the Hawke Government dismantled the tariff system, privatised state sector industries, ended the subsidisation of loss-making industries, and sold off the state-owned Commonwealth Bank of Australia, Aussat, Qantas and CSL Limited. The tax system was reformed, with the introduction of a fringe benefits tax and a capital gains tax, reforms strongly opposed by the Liberal Party at the time, but not ones that they reversed when they eventually returned to office. Partially offsetting these imposts upon the business community—the "main loser" from the 1985 Tax Summit according to Paul Kelly—was the introduction of full dividend imputation, a reform insisted upon by Keating. Funding for schools was also considerably increased, while financial assistance was provided for students to enable them to stay at school longer. Considerable progress was also made in directing assistance "to the most disadvantaged recipients over the whole range of welfare benefits."

The political partnership between Hawke and his Treasurer, Paul Keating, proved essential to Labor's success in government. The two men proved a study in contrasts: Hawke was a Rhodes Scholar; Keating left high school early. Hawke's enthusiasms were cigars, horse racing and all forms of sport; Keating preferred classical architecture, Mahler symphonies and collecting British Regency and French Empire antiques.

In spite of the criticisms levelled against the Hawke Government, it succeeded in enacting a wide range of social reforms during its time in office. Deflecting arguments that the Hawke Government had failed as a reform government, Neville Wran, John Dawkins, Bill Hayden and Paul Keating made a number of speeches throughout the 1980s arguing that the Hawke Government had been a recognisably reformist government, drawing attention to Hawke's achievements as prime minister during his first five years in office. As well as the reintroduction of Medibank, under the new name Medicare, these included the doubling of the number of childcare places, the introduction of occupational superannuation, a boost in school retention rates, a focus on young people's job skills, a doubling of subsidised homecare services, the elimination of poverty traps in the welfare system, a 50% increase in public housing funds, an increase in the real value of the old-age pension, the development of a new youth support program, the reintroduction of six-monthly indexation of single-person unemployment benefits, and significant improvements in social security provisions.

As pointed out by John Dawkins, the proportion of total government outlays allocated to families, the sick, single parents, widows, the handicapped, and veterans was significantly higher under the Hawke Government than under the Whitlam Government. In 1989, the Hawke Labor Government gradually re-introduced fees for university study. It set up the Higher Education Contributions Scheme (HECS), which was first proposed by Professor Murray Wells and subsequently developed by economist and lecturer at the Australian National University, Bruce Chapman and championed by Education Minister John Dawkins (see Dawkins Revolution). Under the original HECS, a $1,800 fee was charged to all university students, and the Commonwealth paid the balance. A student could defer payment of this HECS amount (in which case it was called a HECS debt) and repay the debt through the tax system, when the student's income exceeds a threshold level. As part of the reforms, Colleges of Advanced Education entered the University sector by various means. The HECS system was accepted by both federal political parties and has survived until today, though with a number of changes.

Another notable success for which Hawke's response is given considerable credit was Australia's public health campaign regarding HIV/AIDS. In the later years of the Hawke Government, Aboriginal affairs also saw considerable attention, with an investigation of the idea of a treaty between Aborigines and the Government, although this idea would be overtaken by events, notably the Mabo court decision.

The Hawke Government also made some notable environmental decisions. In its first months in office, it halted the construction of the Franklin Dam in Tasmania, responding to a groundswell of protest about the issue. In 1990, with an election looming, tough political operator Graham Richardson was appointed Environment Minister, and was given the task of attracting second-preference votes from the Australian Democrats and other environmental parties. Richardson claimed this as a major factor in the government's narrow re-election at the 1990 election. Richardson felt that the importance of his contribution to Labor's victory would automatically entitle him to the ministerial portfolio of his choice, which was Transport and Communications. He was shocked, however, at what he perceived as Hawke's ingratitude in allocating him Social Security instead. He later vowed in a telephone conversation with Peter Barron, a former Hawke staffer, to do "whatever it takes" to "get" Hawke. He immediately transferred his allegiance to Paul Keating, who after seven years as Treasurer was openly coveting the leadership.

Under his leadership Hawke initiated large changes to the industrial relations system in Australia. Hawke negotiated with trade unions to initiate the Prices and Incomes Accord in 1983, an agreement whereby unions agreed to restrict wage demands and the government pledged to minimise inflation and promote an increased social wage. In 1984, the Hawke Government passed legislation to de-register the Builders Labourers Federation union.

Hawke benefited greatly from the disarray into which the Liberal Party fell after the resignation of Malcolm Fraser. The Liberals were divided between supporters of the dour, socially conservative John Howard and the more liberal, urbane Andrew Peacock. The arch-conservative Premier of Queensland, Joh Bjelke-Petersen, added to the Liberals' problems with his "Joh for Canberra" campaign, which proved highly damaging. Exploiting these divisions, Hawke led the Labor Party to landslide election victories in a snap 1984 election and the 1987 election.

Hawke's tenure as prime minister saw considerable friction develop between himself and the grassroots of the Labor Party, who were unhappy at what they viewed as Hawke's iconoclasm and willingness to cooperate with business interests. All Labor prime ministers have at times engendered the hostility of the organisational wing of the party, but none more so than Hawke, who regularly expressed his willingness to cull Labor's "sacred cows". The Socialist Left faction, as well as prominent Labor figure Barry Jones, offered severe criticism of a number of government decisions. He also received criticism for his "confrontationalist style" in siding with the airlines in the 1989 Australian pilots' strike.

The late 1980s recession and accompanying high interest rates had seen the government in considerable polling trouble, with many doubting if Hawke could win in 1990. Although Keating was the main architect of the government's economic policies, he took advantage of Hawke's declining popularity to plan a leadership challenge. In 1988, in the wake of poorer opinion polls, Keating put pressure on Hawke to step down immediately. Hawke responded by agreeing a secret deal with Keating, the so-called "Kirribilli agreement", that he would stand down in Keating's favour shortly after the 1990 election, which he convinced Keating he could win. Hawke duly won the 1990 election, albeit by a very tight margin, and subsequently appointed Keating as deputy prime minister to replace the retiring Lionel Bowen.

Not long after becoming deputy prime minister, frustrated at the lack of any indication from Hawke as to when he might step down, Keating made a provocative speech to the Federal Parliamentary Press Gallery. Hawke considered the speech extremely disloyal, and subsequently indicated to Keating that he would renege on the Kirribilli Agreement as a result. After this disagreement, tensions between the two men reached an all-time high, and after a turbulent year, Keating finally resigned as deputy prime minister and treasurer in June 1991, to challenge Hawke for the leadership. Hawke comfortably defeated Keating, and in a press conference after the result Keating declared that with regards the leadership, he had fired his "one shot". Hawke appointed John Kerin to replace Keating as treasurer, but Kerin quickly proved to be unfit for the job.

Despite his convincing victory over Keating, Hawke was seen after the result as a "wounded" leader; he had now lost his long-term political partner, his rating in opinion polls began to decrease, and after nearly nine years as prime minister, many were openly speculating that he was "tired", and that it was time for somebody new.

Hawke's leadership was finally irrevocably damaged towards the end of 1991, as new Liberal Leader John Hewson released 'Fightback!', a detailed proposal for sweeping economic change, including the introduction of a goods and services tax and deep cuts to government spending and personal income tax. The package appeared to take Hawke by complete surprise, and his response to it was judged to be extremely ineffective. Many within the Labor Party appeared to lose faith in him over this, and Keating duly challenged for the leadership a second time on 19 December 1991, this time narrowly defeating Hawke by 56 votes to 51.

In a speech to the House of Representatives the following day, Hawke declared that his nine years as prime minister had left Australia a better country than he found, and he was given a standing ovation by those present. He subsequently tendered his resignation as prime minister to the governor-general. Hawke briefly returned to the backbenches before resigning from Parliament on 20 February 1992, sparking a by-election which was won by the independent candidate Phil Cleary from a record field of 22 candidates.

Hawke wrote that he had very few regrets over his time in office. His bitterness towards Keating surfaced in his earlier memoirs; by 2008, Hawke claimed that he and Keating had long since buried their differences, and that they regularly dined together and considered each other friends. The publication of the book "Hawke: The Prime Minister", by Hawke's second wife, Blanche d'Alpuget, in 2010, reignited conflict between the two. In an open letter to Hawke published in "The Australian" newspapers, Keating bitterly accused Hawke and d'Alpuget of spreading falsehoods about his role in Hawke's premiership. The two subsequently reunited to campaign together for Labor several times, including at the 2019 election, where they released their first joint article for nearly three decades; Craig Emerson, who worked for both men, said that they had again reconciled.

After leaving Parliament, Hawke entered the business world, taking on a number of directorships and consultancy positions which enabled him to achieve considerable financial success. He deliberately had little involvement with the Labor Party during Keating's tenure as prime minister, not wanting to overshadow his successor, although he did occasionally criticise some of Keating's policies publicly.

After Keating's defeat and the election of the Howard Government at the 1996 election, he began to be more involved with Labor, regularly appearing at a number of Labor election launches and campaigns, often alongside Keating. In 2002, Hawke was named an honorary member of South Australia's Economic Development Board during Rann's Labor government.

In the run up to the 2007 election, Hawke made a considerable personal effort to support Kevin Rudd, making speeches at a large number of campaign office openings across Australia. As well as campaigning against WorkChoices, Hawke also attacked John Howard's record as Treasurer, stating "it was the judgement of every economist and international financial institution that it was the restructuring reforms undertaken by my government, with the full cooperation of the trade union movement, which created the strength of the Australian economy today".

Similarly, in the 2010 and 2013 campaigns, Hawke lent considerable support to Julia Gillard and Kevin Rudd respectively. Hawke also maintained an involvement in Labor politics at a state level; in 2011, Hawke publicly supported New South Wales Premier Kristina Keneally, who was facing almost certain defeat, in her campaign against Liberal Barry O'Farrell, describing her campaign as "gutsy".

In February 2008, Hawke joined former prime ministers Gough Whitlam, Malcolm Fraser and Paul Keating in Parliament House to witness the then prime minister, Kevin Rudd, deliver the long anticipated apology to the Stolen Generations.

In 2009, Hawke helped establish the Centre for Muslim and Non-Muslim Understanding at the University of South Australia. Interfaith dialogue was an important issue for Hawke, who told the "Adelaide Review" that he is "convinced that one of the great potential dangers confronting the world is the lack of understanding in regard to the Muslim world. Fanatics have misrepresented what Islam is. They give a false impression of the essential nature of Islam."

In 2016, after taking part in Andrew Denton's Better Off Dead podcast, Hawke added his voice to calls for voluntary euthanasia to be legalised. Hawke labelled as 'absurd' the lack of political will to fix the problem. He revealed that he had such an arrangement with his wife Blanche should such a devastating medical situation occur. He also publicly advocated for nuclear power and the importation of international spent nuclear fuel to Australia for storage and disposal.

In late December 2018, Hawke revealed that he was in "terrible health". While predicting a Labor win in the upcoming 2019 election, Hawke said he "may not witness the party's success".

In May 2019, in the lead-up to the 2019 Australian federal election, Hawke made a joint statement with Keating. They endorsed Labor's economic plan and condemned the Liberal Party for "completely [giving] up the economic reform agenda". They stated that "Shorten's Labor is the only party of government focused on the need to modernise the economy to deal with the major challenge of our time: human induced climate change".

Hawke married Hazel Masterson in 1956 at Perth Trinity Church. They had three children: Susan (born 1957), Stephen (born 1959) and Roslyn (born 1960). Their fourth child, Robert Jr, died in his early infancy in 1963. Hawke was named Victorian Father of the Year in 1971, an honour which his wife disputed due to his heavy drinking and womanising. The couple divorced in 1995, after he left her for the writer Blanche d'Alpuget, and the two lived together in Northbridge, a suburb of the North Shore of Sydney.

Throughout his marriage to his first wife, Hazel, Hawke was a heavy drinker and suffered from alcohol poisoning following the death of their infant son. He had an extramarital affair with his biographer d'Alpuget and left his wife for her, a move which left him estranged from some of his family for a time. Hawke and his family reconciled by the 2010s.

On the subject of his religion, Hawke previously wrote, while attending the 1952 World Christian Youth Conference in India, that "there were all these poverty stricken kids at the gate of this palatial place where we were feeding our face and I just (was) struck by this enormous sense of irrelevance of religion to the needs of people". He subsequently abandoned his Christian beliefs. By the time he entered politics he was a self-described agnostic. Hawke told Andrew Denton in 2008 that his father's Christian faith had continued to influence his outlook, saying "My father said if you believe in the fatherhood of God you must necessarily believe in the brotherhood of man, it follows necessarily, and even though I left the church and was not religious, that truth remained with me."

Hawke died on 16 May 2019, aged 89, of natural causes, two days before the 2019 federal election, at his home in Northbridge. Hawke's family held a private cremation on 27 May at Macquarie Park Cemetery and Crematorium where he will be interred. A state memorial was held at the Sydney Opera House on 14 June; speakers included Craig Emerson as master of ceremonies and Kim Beazley reading the eulogy; Paul Keating, Bill Kelty, Ross Garnaut and incumbent Prime Minister Scott Morrison and Opposition Leader Anthony Albanese.

Orders


Foreign honours

 2008 Grand Companion of the Order of Logohu, Papua New Guinean prime minister Sir Michael Somare informed Hawke that he was being honoured for his "support for Papua New Guinea ... from the time you assisted us in the development of our trade union movement, and basic workplace conditions, to the strong support you gave us during your term as Prime Minister of Australia".

Fellowships


Honorary degrees



A biographical television film, "Hawke", premiered on the Ten Network in Australia on 18 July 2010, with Richard Roxburgh playing the title character. Rachael Blake and Felix Williamson portrayed Hazel Hawke and Paul Keating, respectively.




</doc>
<doc id="4060" url="https://en.wikipedia.org/wiki?curid=4060" title="Baldr">
Baldr

Baldr (also Balder, Baldur) is a god in Norse mythology, and a son of the god Odin and the goddess Frigg. He has numerous brothers, such as Thor and Váli.

During the 12th century, Danish accounts by Saxo Grammaticus and other Danish Latin chroniclers recorded a euhemerized account of his story. Compiled in Iceland during the 13th century, but based on much older Old Norse poetry, the "Poetic Edda" and the "Prose Edda" contain numerous references to the death of Baldr as both a great tragedy to the Æsir and a harbinger of Ragnarök.

According to "Gylfaginning", a book of Snorri Sturluson's Prose Edda, Baldr's wife is Nanna and their son is Forseti. Baldr had the greatest ship ever built, Hringhorni, and there is no place more beautiful than his hall, Breidablik.

Jacob Grimm, in his "Teutonic Mythology" (ch. 11), identifies Old Norse "Baldr" with the Old High German "Baldere" (2nd Merseburg Charm, Thuringia), "Palter" (theonym, Bavaria), "Paltar" (personal name) and with Old English "bealdor, baldor" "lord, prince, king" (used always with a genitive plural, as in "gumena baldor" "lord of men", "wigena baldor" "lord of warriors", et cetera). Old Norse shows this usage of the word as an honorific in a few cases, as in "baldur î brynju" (Sæm. 272b) and "herbaldr" (Sæm. 218b), epithets of heroes in general.

Grimm traces the etymology of the name to *"balþaz", whence Gothic "balþs", Old English "bald", Old High German "pald", all meaning "bold, brave".

But the interpretation of Baldr as "the brave god" may be secondary. Baltic (cf. Lithuanian "baltas", Latvian "balts") has a word meaning "the white, the good", and Grimm speculates that the name may originate as a Baltic loan into Proto-Germanic.
In continental Saxon and Anglo-Saxon tradition, the son of Woden is called not "Bealdor" but "Baldag" (Saxon) and "Bældæg, Beldeg" (Anglo-Saxon), which shows association with "day", possibly with Day personified as a deity. This, as Grimm points out, would agree with the meaning "shining one, white one, a god" derived from the meaning of Baltic "baltas", further adducing Slavic "Belobog" and German "Berhta".

Grimm's etymology is endorsed by modern research. According to Rudolf Simek, the original name for Baldr must be understood as 'shining day'.

One of the two Merseburg Incantations names "Baldere", but also mentions a figure named "Phol", considered to be a byname for Baldr (as in Scandinavian "Falr", "Fjalarr"; (in Saxo) "Balderus" : "Fjallerus").

In the Poetic Edda the tale of Baldr's death is referred to rather than recounted at length. Among the visions which the Völva sees and describes in the prophecy known as the "Völuspá" is one of the fatal mistletoe, the birth of Váli and the weeping of Frigg (stanzas 31–33). Yet looking far into the future the Völva sees a brighter vision of a new world, when both Höðr and Baldr will come back (stanza 62). The Eddic poem "Baldr's Dreams" mentions that Baldr has bad dreams which the gods then discuss. Odin rides to Hel and awakens a seeress, who tells him Höðr will kill Baldr but Vali will avenge him (stanzas 9, 11).

In "Gylfaginning", Baldur is described as follows:

Apart from this description, Baldr is known primarily for the story of his death, which is seen as the first in a chain of events that will ultimately lead to the destruction of the gods at Ragnarök. According to "Völuspá", Baldr will be reborn in the new world.

He had a dream of his own death and his mother had the same dreams. Since dreams were usually prophetic, this depressed him, so his mother Frigg made every object on earth vow never to hurt Baldr. All objects made this vow except mistletoe—a detail which has traditionally been explained with the idea that it was too unimportant and nonthreatening to bother asking it to make the vow, but which Merrill Kaplan has instead argued echoes the fact that young people were not eligible to swear legal oaths, which could make them a threat later in life.
When Loki, the mischief-maker, heard of this, he made a magical spear from this plant (in some later versions, an arrow). He hurried to the place where the gods were indulging in their new pastime of hurling objects at Baldr, which would bounce off without harming him. Loki gave the spear to Baldr's brother, the blind god Höðr, who then inadvertently killed his brother with it (other versions suggest that Loki guided the arrow himself). For this act, Odin and the asynja Rindr gave birth to Váli, who grew to adulthood within a day and slew Höðr.

Baldr was ceremonially burnt upon his ship, Hringhorni, the largest of all ships. As he was carried to the ship, Odin whispered in his ear. This was to be a key riddle asked by Odin (in disguise) of the giant Vafthrudnir (and which was unanswerable) in the poem "Vafthrudnismal". The riddle also appears in the riddles of Gestumblindi in "Hervarar saga".

The dwarf Litr was kicked by Thor into the funeral fire and burnt alive. Nanna, Baldr's wife, also threw herself on the funeral fire to await Ragnarök when she would be reunited with her husband (alternatively, she died of grief). Baldr's horse with all its trappings was also burned on the pyre. The ship was set to sea by Hyrrokin, a giantess, who came riding on a wolf and gave the ship such a push that fire flashed from the rollers and all the earth shook.

Upon Frigg's entreaties, delivered through the messenger Hermod, Hel promised to release Baldr from the underworld if all objects alive and dead would weep for him. All did, except a giantess, Þökk (often presumed to be the god Loki in disguise), who refused to mourn the slain god. Thus Baldr had to remain in the underworld, not to emerge until after Ragnarök, when he and his brother Höðr would be reconciled and rule the new earth together with Thor's sons.

Writing during the end of the 12th century, the Danish historian Saxo Grammaticus tells the story of Baldr (recorded as "Balderus") in a form that professes to be historical. According to him, Balderus and Høtherus were rival suitors for the hand of Nanna, daughter of Gewar, King of Norway. Balderus was a demigod and common steel could not wound his sacred body. The two rivals encountered each other in a terrific battle. Though Odin and Thor and the other gods fought for Balderus, he was defeated and fled away, and Høtherus married the princess.

Nevertheless, Balderus took heart of grace and again met Høtherus in a stricken field. But he fared even worse than before. Høtherus dealt him a deadly wound with a magic sword, named Mistletoe, which he had received from Mimir, the satyr of the woods; after lingering three days in pain Balderus died of his injury and was buried with royal honours in a barrow.

There are also two lesser known Danish Latin chronicles, the "Chronicon Lethrense" and the "Annales Lundenses" of which the latter is included in the former. These two sources provide a second euhemerized account of Höðr's slaying of Baldr.

It relates that Hother was the king of the Saxons and son of Hothbrodd and Hadding. Hother first slew Othen's (i.e. Odin) son Balder in battle and then chased Othen and Thor. Finally, Othen's son Both killed Hother. Hother, Balder, Othen and Thor were incorrectly considered to be gods.

A Latin votive inscription from Utrecht, from the 3rd or 4th century C.E., has been theorized as containing the dative form "Baldruo", pointing to a Latin nominative singular *"Baldruus", which some have identified with the Norse/Germanic god, although both the reading and this interpretation have been questioned.

In the Anglo Saxon Chronicles Baldr is named as the ancestor of the monarchy of Kent, Bernicia, Deira, and Wessex through his supposed son Brond.

As referenced in "Gylfaginning", in Sweden and Norway, the scentless mayweed ("Matricaria perforata") and the similar sea mayweed ("Matricaria maritima") are both called "baldursbrá" "Balder's brow" and regionally in northern England ("baldeyebrow"). In Iceland only the former is found. In Germany lily-of-the-valley is known as "weisser Baldrian"; variations using or influenced by reflexes of "Phol" include "Faltrian" (upper Austria), Villum"fallum" (Salzburg), and "Fildron" or "Faldron" (Tyrol).

There are a few old place names in Scandinavia that contain the name "Baldr". The most certain and notable one is the (former) parish name Balleshol in Hedmark county, Norway: "a Balldrshole" 1356 (where the last element is "hóll" m "mound; small hill"). Others may be (in Norse forms) "Baldrsberg" in Vestfold county, "Baldrsheimr" in Hordaland county "Baldrsnes" in Sør-Trøndelag county—and (very uncertain) the Balsfjorden fjord and Balsfjord municipality in Troms county.

In Copenhagen, there is also a Baldersgade, or "Balder's Street". A street in downtown Reykjavík is called Baldursgata (Baldur's Street).

In Sweden there is a Baldersgatan (Balder's Street) in Stockholm. There is also Baldersnäs (Balder's isthmus), Baldersvik (Balder's bay), Balders udde (Balder's headland) and Baldersberg (Balder's mountain) at various places.




</doc>
<doc id="4061" url="https://en.wikipedia.org/wiki?curid=4061" title="Breidablik">
Breidablik

In Norse mythology, Breiðablik ("Broad-gleaming") is the home of Baldr. It is briefly described in Snorri Sturluson's "Gylfaginning" as one of the halls of Asgard:

Later in the work, when Snorri describes Baldr, he gives a longer description, citing "Grímnismál", though he does not name the poem:

Breiðablik is not otherwise mentioned in the Eddic sources.





</doc>
<doc id="4062" url="https://en.wikipedia.org/wiki?curid=4062" title="Bilskirnir">
Bilskirnir

Bilskirnir (Old Norse "lightning-crack") is the hall of the god Thor in Norse mythology. Here he lives with his wife Sif and their children. According to "Grímnismál", the hall is the greatest of buildings and contains 540 rooms, located in Asgard, as are all the dwellings of the gods, in the kingdom of Þrúðheimr (or Þrúðvangar according to "Gylfaginning" and "Ynglinga saga").




</doc>
<doc id="4063" url="https://en.wikipedia.org/wiki?curid=4063" title="Brísingamen">
Brísingamen

In Norse mythology, Brísingamen (or Brísinga men) is the torc or necklace of the goddess Freyja. The name is an Old Norse compound "brísinga-men" whose second element is "men" "(ornamental) neck-ring (of precious metal), torc". The etymology of the first element is uncertain. It has been derived from Old Norse "brísingr", a poetic term for "fire" or "amber" mentioned in the anonymous versified word-lists ("þulur") appended to many manuscripts of the Prose Edda, making Brísingamen "gleaming torc", "sunny torc", or the like. However, "Brísingr" can also be an ethnonym, in which case "Brísinga men" is "torque of the Brísings"; the Old English parallel in "Beowulf" supports this derivation, though who the Brísings (Old Norse "Brísingar") may have been remains unknown.

Brísingamen is referred to in the Anglo-Saxon epic "Beowulf" as "Brosinga mene". The brief mention in "Beowulf" is as follows (trans. by Howell Chickering, 1977):

This seems to confuse
different stories as the "Beowulf" poet is clearly referring to the legends about Theoderic the Great. The "Þiðrekssaga" tells that the warrior Heime ("Háma" in Old English) takes sides against Ermanaric ("Eormanric"), king of the Goths, and has to flee his kingdom after robbing him; later in life, Hama enters a monastery and gives them all his stolen treasure. However, this saga makes no mention of the great necklace. Possibly the "Beowulf" poet was confused, or invented the addition of the necklace to give him an excuse to drag in a mention of Eormanric. In any case, the necklace given to Beowulf in the story is not the Brísingamen itself; it is only being compared to it.

In the poem "Þrymskviða" of the "Poetic Edda", Þrymr, the king of the jǫtnar, steals Thor's hammer, Mjölnir. Freyja lends Loki her falcon cloak to search for it; but upon returning, Loki tells Freyja that Þrymr has hidden the hammer and demanded to marry her in return. Freyja is so wrathful that all the Æsir’s halls beneath her are shaken and the necklace Brísingamen breaks off from her neck. Later Thor borrows Brísingamen when he dresses up as Freyja to go to the wedding at Jǫtunheimr.

"Húsdrápa", a skaldic poem partially preserved in the "Prose Edda", relates the story of the theft of Brísingamen by Loki. One day when Freyja wakes up and finds Brísingamen missing, she enlists the help of Heimdallr to help her search for it. Eventually they find the thief, who turns out to be Loki who has transformed himself into a seal. Heimdallr turns into a seal as well and fights Loki. After a lengthy battle at Singasteinn, Heimdallr wins and returns Brísingamen to Freyja.

Snorri Sturluson quoted this old poem in "Skáldskaparmál", saying that because of this legend Heimdallr is called "Seeker of Freyja's Necklace" ("Skáldskaparmál", section 8) and Loki is called "Thief of Brísingamen" ("Skáldskaparmál", section 16). A similar story appears in the later "Sörla þáttr", where Heimdallr does not appear.

Sörla þáttr is a short story in the later and extended version of the "Saga of Olaf Tryggvason" in the manuscript of the "Flateyjarbók", which was written and compiled by two Christian priests, Jon Thordson and Magnus Thorhalson, in the late 14th century. In the end of the story, the arrival of Christianity dissolves the old curse that traditionally was to endure until Ragnarök.
The battle of Högni and Heðinn is recorded in several medieval sources, including the skaldic poem "Ragnarsdrápa", "Skáldskaparmál" (section 49), and "Gesta Danorum": king Högni's daughter, Hildr, is kidnapped by king Heðinn. When Högni comes to fight Heðinn on an island, Hildr comes to offer her father a necklace on behalf of Heðinn for peace; but the two kings still battle, and Hildr resurrects the fallen to make them fight until Ragnarök. None of these earlier sources mentions Freyja or king Olaf Tryggvason, the historical figure who Christianized Norway and Iceland in the 10th Century.

Völva was buried with considerable splendour in Hagebyhöga in Östergötland. In addition to being buried with her wand, she had received great riches which included horses, a wagon and an Arabian bronze pitcher. There was also a silver pendant, which represents a woman with a broad necklace around her neck. This kind of necklace was only worn by the most prominent women during the Iron Age and some have interpreted it as Freyja's necklace Brísingamen. The pendant may represent Freyja herself.

Alan Garner wrote a children's fantasy novel called "The Weirdstone of Brisingamen" about an enchanted teardrop bracelet.

Diana Paxson's novel "Brisingamen" features Freyja and her bracelet.

Black Phoenix Alchemy Lab has a perfumed oil scent named Brisingamen.

Freyja's necklace Brisingamen features prominently in Betsy Tobin's novel "Iceland", where the necklace is seen to have significant protective powers.

J. R. R. Tolkien's "The Silmarillion" includes a treasure called the Nauglamír, which was made by the dwarves of Eriador for the elvish king Finrod Felagund. However, the necklace was brought out a dragon's hoard by Túrin Turambar and given to King Thingol of Doriath. This king asks a group of dwarves to set a Silmaril into the necklace for his wife Melian to wear. The dwarves fall under the spell of the Silmaril and they claim the Nauglamir as their own – with the Silmaril attached. They kill Thingol and make off with the necklace. It is eventually recovered and is an heirloom of Thingol's descendants, eventually leading Eärendil to Valinor and resulting in the return of the Valar into the affairs of Middle-earth. This is clearly intended to be the equivalent in his mythology to the Brísingamen.

The Brisingamen feature as a major item in Joel Rosenberg's Keepers of the Hidden Ways series of books. In it, there are seven jewels that were created for the necklace by the Dwarfs and given to the Norse goddess. She in turn eventually split them up into the seven separate jewels and hid them throughout the realm, as together they hold the power to shape the universe by its holder. The book's plot is about discovering one of them and deciding what to do with the power they allow while avoiding Loki and other Norse characters.

In Christopher Paolini's "Inheritance Cycle", the word "brisingr" means fire. This is probably a distillation of the word "brisinga".

Ursula Le Guin's short story "Semley's Necklace", the first part of her novel "Rocannon's World", is a retelling of the Brisingamen story on an alien planet.

Brisingamen is represented as a card in the "Yu-Gi-Oh!" Trading Card Game, "Nordic Relic Brisingamen".

Brisingamen was part of MMORPG "Ragnarok Online" lore, which is ranked as "God item". The game is heavily based from Norse mythology.

In the "Firefly Online" game, one of the planets of the Himinbjörg system (which features planets named after figures from Germanic mythology) is named Brisingamen. It is third from the star, and has moons named Freya, Beowulf, and Alberich.

The Brisingamen is an item that can be found and equipped in the game "".



</doc>
<doc id="4064" url="https://en.wikipedia.org/wiki?curid=4064" title="Borsuk–Ulam theorem">
Borsuk–Ulam theorem

In mathematics, the Borsuk–Ulam theorem states that every continuous function from an "n"-sphere into Euclidean "n"-space maps some pair of antipodal points to the same point. Here, two points on a sphere are called antipodal if they are in exactly opposite directions from the sphere's center.

Formally: if formula_1 is continuous then there exists an formula_2 such that: formula_3.

The case formula_4 can be illustrated by saying that there always exist a pair of opposite points on the Earth's equator with the same temperature. The same is true for any circle. This assumes the temperature varies continuously.

The case formula_5 is often illustrated by saying that at any moment, there is always a pair of antipodal points on the Earth's surface with equal temperatures and equal barometric pressures.

The Borsuk–Ulam theorem has several equivalent statements in terms of odd functions. Recall that formula_6 is the "n"-sphere and formula_7 is the "n"-ball:

According to , the first historical mention of the statement of the Borsuk–Ulam theorem appears in . The first proof was given by , where the formulation of the problem was attributed to Stanislaw Ulam. Since then, many alternative proofs have been found by various authors, as collected by .

The following statements are equivalent to the Borsuk–Ulam theorem.

A function formula_16 is called "odd" (aka "antipodal" or "antipode-preserving") if for every formula_17: formula_18.

The Borsuk–Ulam theorem is equivalent to the following statement: A continuous odd function from an "n"-sphere into Euclidean "n"-space has a zero. PROOF: 

Define a "retraction" as a function formula_25 The Borsuk–Ulam theorem is equivalent to the following claim: there is no continuous odd retraction.

Proof: If the theorem is correct, then every continuous odd function from formula_6 must include 0 in its range. However, formula_27 so there cannot be a continuous odd function whose range is formula_12.

Conversely, if it is incorrect, then there is a continuous odd function formula_29 with no zeroes. Then we can construct another odd function formula_30 by:

since formula_16 has no zeroes, formula_33 is well-defined and continuous. Thus we have a continuous odd retraction.

The 1-dimensional case can easily be proved using the intermediate value theorem (IVT).

Let formula_16 be an odd real-valued continuous function on a circle. Pick an arbitrary formula_17. If formula_10 then we are done. Otherwise, without loss of generality, formula_37 But formula_38 Hence, by the IVT, there is a point formula_39 between formula_17 and formula_41 at which formula_42

Assume that formula_30 is an odd continuous function with formula_44 (the case formula_45 is treated above, the case formula_46 can be handled using basic covering theory). By passing to orbits under the antipodal action, we then get an induced function formula_47 which induces an isomorphism on fundamental groups. By the Hurewicz theorem, the induced map on cohomology with formula_48 coefficients, 

sends formula_50 to formula_51. But then we get that formula_52 is sent to formula_53, a contradiction.

One can also show the stronger statement that any odd map formula_54 has odd degree and then deduce the theorem from this result.

The Borsuk–Ulam theorem can be proved from Tucker's lemma.

Let formula_8 be a continuous odd function. Because "g" is continuous on a compact domain, it is uniformly continuous. Therefore, for every formula_56, there is a formula_57 such that, for every two points of formula_58 which are within formula_59 of each other, their images under "g" are within formula_60 of each other.

Define a triangulation of formula_58 with edges of length at most formula_59. Label each vertex formula_63 of the triangulation with a label formula_64 in the following way:


Because "g" is odd, the labeling is also odd: formula_67. Hence, by Tucker's lemma, there are two adjacent vertices formula_68 with opposite labels. Assume w.l.o.g. that the labels are formula_69. By the definition of "l", this means that in both formula_70 and formula_71, coordinate #1 is the largest coordinate: in formula_70 this coordinate is positive while in formula_71 it is negative. By the construction of the triangulation, the distance between formula_70 and formula_71 is at most formula_60, so in particular formula_77 (since formula_78 and formula_79 have opposite signs) and so formula_80. But since the largest coordinate of formula_70 and formula_71 is coordinate #1, this means that formula_83 for each formula_84. So formula_85, where formula_86 is some constant depending on formula_87 and the norm formula_88 which you have chosen.

The above is true for every formula_60; hence there must be a point "u" in which formula_90.


Above we showed how to prove the Borsuk–Ulam theorem from Tucker's lemma. The converse is also true: it is possible to prove Tucker's lemma from the Borsuk–Ulam theorem. Therefore, these two theorems are equivalent.





</doc>
<doc id="4067" url="https://en.wikipedia.org/wiki?curid=4067" title="Bragi">
Bragi

Bragi is the skaldic god of poetry in Norse mythology.

"Bragi" is generally associated with "bragr", the Norse word for poetry. The name of the god may have been derived from "bragr", or the term "bragr" may have been formed to describe 'what Bragi does'. A connection between the name Bragi and Old English "brego" 'chieftain' has been suggested but is generally now discounted. A connection between Bragi and the "bragarfull" 'promise cup' is sometimes suggested, as "bragafull", an alternate form of the word, might be translated as 'Bragi's cup'. See Bragarfull.

Snorri Sturluson writes in the "Gylfaginning" after describing Odin, Thor, and Baldr:
In "Skáldskaparmál" Snorri writes:
That Bragi is Odin's son is clearly mentioned only here and in some versions of a list of the sons of Odin (see Sons of Odin). But "wish-son" in stanza 16 of the "Lokasenna" could mean "Odin's son" and is translated by Hollander as "Odin's kin". Bragi's mother is possibly the giantess Gunnlod. If Bragi's mother is Frigg, then Frigg is somewhat dismissive of Bragi in the "Lokasenna" in stanza 27 when Frigg complains that if she had a son in Ægir's hall as brave as Baldr then Loki would have to fight for his life.

In that poem Bragi at first forbids Loki to enter the hall but is overruled by Odin. Loki then gives a greeting to all gods and goddesses who are in the hall save to Bragi. Bragi generously offers his sword, horse, and an arm ring as peace gift but Loki only responds by accusing Bragi of cowardice, of being the most afraid to fight of any of the Æsir and Elves within the hall. Bragi responds that if they were outside the hall, he would have Loki's head, but Loki only repeats the accusation. When Bragi's wife Iðunn attempts to calm Bragi, Loki accuses her of embracing her brother's slayer, a reference to matters that have not survived. It may be that Bragi had slain Iðunn's brother.

A passage in the "Poetic Edda" poem "Sigrdrífumál" describes runes being graven on the sun, on the ear of one of the sun-horses and on the hoofs of the other, on Sleipnir's teeth, on bear's paw, on eagle's beak, on wolf's claw, and on several other things including on Bragi's tongue. Then the runes are shaved off and the shavings are mixed with mead and sent abroad so that Æsir have some, Elves have some, Vanir have some, and Men have some, these being speech runes and birth runes, ale runes, and magic runes. The meaning of this is obscure.

The first part of Snorri Sturluson's "Skáldskaparmál" is a dialogue between Ægir and Bragi about the nature of poetry, particularly skaldic poetry. Bragi tells the origin of the mead of poetry from the blood of Kvasir and how Odin obtained this mead. He then goes on to discuss various poetic metaphors known as "kennings".

Snorri Sturluson clearly distinguishes the god Bragi from the mortal skald Bragi Boddason, whom he often mentions separately. The appearance of Bragi in the "Lokasenna" indicates that if these two Bragis were originally the same, they have become separated for that author also, or that chronology has become very muddled and Bragi Boddason has been relocated to mythological time. Compare the appearance of the Welsh Taliesin in the second branch of the Mabinogi. Legendary chronology sometimes does become muddled. Whether Bragi the god originally arose as a deified version of Bragi Boddason was much debated in the 19th century, especially by the scholars Eugen Mogk and Sophus Bugge. The debate remains undecided.

In the poem "Eiríksmál" Odin, in Valhalla, hears the coming of the dead Norwegian king Eric Bloodaxe and his host, and bids the heroes Sigmund and Sinfjötli rise to greet him. Bragi is then mentioned, questioning how Odin knows that it is Eric and why Odin has let such a king die. In the poem "Hákonarmál", Hákon the Good is taken to Valhalla by the valkyrie Göndul and Odin sends Hermóðr and Bragi to greet him. In these poems Bragi could be either a god or a dead hero in Valhalla. Attempting to decide is further confused because "Hermóðr" also seems to be sometimes the name of a god and sometimes the name of a hero. That Bragi was also the first to speak to Loki in the "Lokasenna" as Loki attempted to enter the hall might be a parallel. It might have been useful and customary that a man of great eloquence and versed in poetry should greet those entering a hall. He is also depicted in tenth-century court poetry of helping to prepare Valhalla for new arrivals and welcoming the kings who have been slain in battle to the hall of Odin.

In the "Prose Edda" Snorri Sturluson quotes many stanzas attributed to Bragi Boddason the old ("Bragi Boddason inn gamli"), a Norwegian court poet who served several Swedish kings, Ragnar Lodbrok, Östen Beli and Björn at Hauge who reigned in the first half of the 9th century. This Bragi was reckoned as the first skaldic poet, and was certainly the earliest skaldic poet then remembered by name whose verse survived in memory.

Snorri especially quotes passages from Bragi's "Ragnarsdrápa", a poem supposedly composed in honor of the famous legendary Viking Ragnar Lodbrók ('Hairy-breeches') describing the images on a decorated shield which Ragnar had given to Bragi. The images included Thor's fishing for Jörmungandr, Gefjun's ploughing of Zealand from the soil of Sweden, the attack of Hamdir and Sorli against King Jörmunrekk, and the never-ending battle between Hedin and Högni.

Bragi son of Hálfdan the Old is mentioned only in the "Skjáldskaparmál". This Bragi is the sixth of the second of two groups of nine sons fathered by King Hálfdan the Old on Alvig the Wise, daughter of King Eymund of Hólmgard. This second group of sons are all eponymous ancestors of legendary families of the north. Snorri says:

Bragi, from whom the Bragnings are sprung (that is the race of Hálfdan the Generous).

Of the Bragnings as a race and of Hálfdan the Generous nothing else is known. However, "Bragning" is often, like some others of these dynastic names, used in poetry as a general word for 'king' or 'ruler'.

In the eddic poem "Helgakviða Hundingsbana II", Bragi Högnason, his brother Dag, and his sister Sigrún were children of Högne, the king of East Götaland. The poem relates how Sigmund's son Helgi Hundingsbane agreed to take Sigrún daughter of Högni as his wife against her unwilling betrothal to Hodbrodd son of Granmar the king of Södermanland. In the subsequent battle of Frekastein (probably one of the 300 hill forts of Södermanland, as "stein" meant "hill fort") against Högni and Grammar, all the chieftains on Granmar's side are slain, including Bragi, except for Bragi's brother Dag.



</doc>
<doc id="4068" url="https://en.wikipedia.org/wiki?curid=4068" title="Blaise Pascal">
Blaise Pascal

Blaise Pascal ( , , , ; 19 June 1623 – 19 August 1662) was a French mathematician, physicist, inventor, writer and Catholic theologian. He was a child prodigy who was educated by his father, a tax collector in Rouen. Pascal's earliest work was in the natural and applied sciences, where he made important contributions to the study of fluids, and clarified the concepts of pressure and vacuum by generalising the work of Evangelista Torricelli. Pascal also wrote in defence of the scientific method.

In 1642, while still a teenager, he started some pioneering work on calculating machines. After three years of effort and 50 prototypes, he built 20 finished machines (called Pascal's calculators and later Pascalines) over the following 10 years, establishing him as one of the first two inventors of the mechanical calculator.

Pascal was an important mathematician, helping create two major new areas of research: he wrote a significant treatise on the subject of projective geometry at the age of 16, and later corresponded with Pierre de Fermat on probability theory, strongly influencing the development of modern economics and social science. Following Galileo Galilei and Torricelli, in 1647, he rebutted Aristotle's followers who insisted that nature abhors a vacuum. Pascal's results caused many disputes before being accepted.

In 1646, he and his sister Jacqueline identified with the religious movement within Catholicism known by its detractors as Jansenism. Following a religious experience in late 1654, he began writing influential works on philosophy and theology. His two most famous works date from this period: the "Lettres provinciales" and the "Pensées", the former set in the conflict between Jansenists and Jesuits. In that year, he also wrote an important treatise on the arithmetical triangle. Between 1658 and 1659, he wrote on the cycloid and its use in calculating the volume of solids.

Throughout his life, Pascal was in frail health, especially after the age of 18; he died just two months after his 39th birthday.

Pascal was born in Clermont-Ferrand, which is in France's Auvergne region. He lost his mother, Antoinette Begon, at the age of three. His father, Étienne Pascal (1588–1651), who also had an interest in science and mathematics, was a local judge and member of the "Noblesse de Robe". Pascal had two sisters, the younger Jacqueline and the elder Gilberte.

In 1631, five years after the death of his wife, Étienne Pascal moved with his children to Paris. The newly arrived family soon hired Louise Delfault, a maid who eventually became an instrumental member of the family. Étienne, who never remarried, decided that he alone would educate his children, for they all showed extraordinary intellectual ability, particularly his son Blaise. The young Pascal showed an amazing aptitude for mathematics and science.

Particularly of interest to Pascal was a work of Desargues on conic sections. Following Desargues' thinking, the 16-year-old Pascal produced, as a means of proof, a short treatise on what was called the "Mystic Hexagram", "Essai pour les coniques" ("Essay on Conics") and sent it—his first serious work of mathematics—to Père Mersenne in Paris; it is known still today as Pascal's theorem. It states that if a hexagon is inscribed in a circle (or conic) then the three intersection points of opposite sides lie on a line (called the Pascal line).

Pascal's work was so precocious that Descartes was convinced that Pascal's father had written it. When assured by Mersenne that it was, indeed, the product of the son and not the father, Descartes dismissed it with a sniff: "I do not find it strange that he has offered demonstrations about conics more appropriate than those of the ancients," adding, "but other matters related to this subject can be proposed that would scarcely occur to a 16-year-old child."

In France at that time offices and positions could be—and were—bought and sold. In 1631, Étienne sold his position as second president of the "Cour des Aides" for 65,665 livres. The money was invested in a government bond which provided, if not a lavish, then certainly a comfortable income which allowed the Pascal family to move to, and enjoy, Paris. But in 1638 Richelieu, desperate for money to carry on the Thirty Years' War, defaulted on the government's bonds. Suddenly Étienne Pascal's worth had dropped from nearly 66,000 livres to less than 7,300.

Like so many others, Étienne was eventually forced to flee Paris because of his opposition to the fiscal policies of Cardinal Richelieu, leaving his three children in the care of his neighbour Madame Sainctot, a great beauty with an infamous past who kept one of the most glittering and intellectual salons in all France. It was only when Jacqueline performed well in a children's play with Richelieu in attendance that Étienne was pardoned. In time, Étienne was back in good graces with the cardinal and in 1639 had been appointed the king's commissioner of taxes in the city of Rouen—a city whose tax records, thanks to uprisings, were in utter chaos.

In 1642, in an effort to ease his father's endless, exhausting calculations, and recalculations, of taxes owed and paid (into which work the young Pascal had been recruited), Pascal, not yet 19, constructed a mechanical calculator capable of addition and subtraction, called "Pascal's calculator" or the "Pascaline". Of the eight Pascalines known to have survived, four are held by the Musée des Arts et Métiers in Paris and one more by the Zwinger museum in Dresden, Germany, exhibit two of his original mechanical calculators. Although these machines are pioneering forerunners to a further 400 years of development of mechanical methods of calculation, and in a sense to the later field of computer engineering, the calculator failed to be a great commercial success. Partly because it was still quite cumbersome to use in practice, but probably primarily because it was extraordinarily expensive, the Pascaline became little more than a toy, and a status symbol, for the very rich both in France and elsewhere in Europe. Pascal continued to make improvements to his design through the next decade, and he refers to some 50 machines that were built to his design.

Pascal continued to influence mathematics throughout his life. His "Traité du triangle arithmétique" ("Treatise on the Arithmetical Triangle") of 1654 described a convenient tabular presentation for binomial coefficients, now called Pascal's triangle. The triangle can also be represented:
He defines the numbers in the triangle by recursion: Call the number in the ("m" + 1)th row and ("n" + 1)th column "t". Then "t" = "t" + "t", for "m" = 0, 1, 2, ... and "n" = 0, 1, 2, ... The boundary conditions are "t" = 0, "t" = 0 for "m" = 1, 2, 3, ... and "n" = 1, 2, 3, ... The generator "t" = 1. Pascal concludes with the proof,

In 1654, he proved "Pascal's identity" relating the sums of the "p"-th powers of the first "n" positive integers for "p" = 0, 1, 2, ..., "k".

In 1654, prompted by his friend the Chevalier de Méré, he corresponded with Pierre de Fermat on the subject of gambling problems, and from that collaboration was born the mathematical theory of probabilities. The specific problem was that of two players who want to finish a game early and, given the current circumstances of the game, want to divide the stakes fairly, based on the chance each has of winning the game from that point. From this discussion, the notion of expected value was introduced. Pascal later (in the "Pensées") used a probabilistic argument, Pascal's Wager, to justify belief in God and a virtuous life. The work done by Fermat and Pascal into the calculus of probabilities laid important groundwork for Leibniz' formulation of the calculus.

After a religious experience in 1654, Pascal mostly gave up work in mathematics.

Pascal's major contribution to the philosophy of mathematics came with his "De l'Esprit géométrique" ("Of the Geometrical Spirit"), originally written as a preface to a geometry textbook for one of the famous ""Petites-Ecoles de Port-Royal" ("Little Schools of Port-Royal")". The work was unpublished until over a century after his death. Here, Pascal looked into the issue of discovering truths, arguing that the ideal of such a method would be to found all propositions on already established truths. At the same time, however, he claimed this was impossible because such established truths would require other truths to back them up—first principles, therefore, cannot be reached. Based on this, Pascal argued that the procedure used in geometry was as perfect as possible, with certain principles assumed and other propositions developed from them. Nevertheless, there was no way to know the assumed principles to be true.

Pascal also used "De l'Esprit géométrique" to develop a theory of definition. He distinguished between definitions which are conventional labels defined by the writer and definitions which are within the language and understood by everyone because they naturally designate their referent. The second type would be characteristic of the philosophy of essentialism. Pascal claimed that only definitions of the first type were important to science and mathematics, arguing that those fields should adopt the philosophy of formalism as formulated by Descartes.

In "De l'Art de persuader" ("On the Art of Persuasion"), Pascal looked deeper into geometry's axiomatic method, specifically the question of how people come to be convinced of the axioms upon which later conclusions are based. Pascal agreed with Montaigne that achieving certainty in these axioms and conclusions through human methods is impossible. He asserted that these principles can be grasped only through intuition, and that this fact underscored the necessity for submission to God in searching out truths.

Pascal's work in the fields of the study of hydrodynamics and hydrostatics centered on the principles of hydraulic fluids. His inventions include the hydraulic press (using hydraulic pressure to multiply force) and the syringe. He proved that hydrostatic pressure depends not on the weight of the fluid but on the elevation difference. He demonstrated this principle by attaching a thin tube to a barrel full of water and filling the tube with water up to the level of the third floor of a building. This caused the barrel to leak, in what became known as Pascal's barrel experiment.

By 1647, Pascal had learned of Evangelista Torricelli's experimentation with barometers. Having replicated an experiment that involved placing a tube filled with mercury upside down in a bowl of mercury, Pascal questioned what force kept some mercury in the tube and what filled the space above the mercury in the tube. At the time, most scientists contended that, rather than a vacuum, some invisible matter was present. This was based on the Aristotelian notion that creation was a thing of substance, whether visible or invisible; and that this substance was forever in motion. Furthermore, "Everything that is in motion must be moved by something," Aristotle declared. Therefore, to the Aristotelian trained scientists of Pascal's time, a vacuum was an impossibility. How so? As proof it was pointed out:

Following more experimentation in this vein, in 1647 Pascal produced "Experiences nouvelles touchant le vide" ("New experiments with the vacuum"), which detailed basic rules describing to what degree various liquids could be supported by air pressure. It also provided reasons why it was indeed a vacuum above the column of liquid in a barometer tube. This work was followed by "Récit de la grande expérience de l'équilibre des liqueurs" ("Account of the great experiment on equilibrium in liquids") published in 1648.

The Torricellian vacuum found that air pressure is equal to the weight of 30 inches of mercury. If air has a finite weight, Earth's atmosphere must have a maximum height. Pascal reasoned that if true, air pressure on a high mountain must be less than at a lower altitude. He lived near the Puy de Dôme mountain, tall, but his health was poor so could not climb it. On 19 September 1648, after many months of Pascal's friendly but insistent prodding, Florin Périer, husband of Pascal's elder sister Gilberte, was finally able to carry out the fact-finding mission vital to Pascal's theory. The account, written by Périer, reads:

Pascal replicated the experiment in Paris by carrying a barometer up to the top of the bell tower at the church of Saint-Jacques-de-la-Boucherie, a height of about 50 metres. The mercury dropped two lines.

In the face of criticism that some invisible matter must exist in Pascal's empty space, Pascal, in his reply to Estienne Noel, gave one of the 17th century's major statements on the scientific method, which is a striking anticipation of the idea popularised by Karl Popper that scientific theories are characterised by their falsifiability: "In order to show that a hypothesis is evident, it does not suffice that all the phenomena follow from it; instead, if it leads to something contrary to a single one of the phenomena, that suffices to establish its falsity." His insistence on the existence of the vacuum also led to conflict with other prominent scientists, including Descartes.

Pascal introduced a primitive form of roulette and the roulette wheel in his search for a perpetual motion machine.

In the winter of 1646, Pascal's 58-year-old father broke his hip when he slipped and fell on an icy street of Rouen; given the man's age and the state of medicine in the 17th century, a broken hip could be a very serious condition, perhaps even fatal. Rouen was home to two of the finest doctors in France: Monsieur Doctor Deslandes and Monsieur Doctor de La Bouteillerie. The elder Pascal "would not let anyone other than these men attend him...It was a good choice, for the old man survived and was able to walk again..." But treatment and rehabilitation took three months, during which time La Bouteillerie and Deslandes had become regular visitors.

Both men were followers of Jean Guillebert, proponent of a splinter group from Catholic teaching known as Jansenism. This still fairly small sect was making surprising inroads into the French Catholic community at that time. It espoused rigorous Augustinism. Blaise spoke with the doctors frequently, and after their successful treatment of his father, borrowed from them works by Jansenist authors. In this period, Pascal experienced a sort of "first conversion" and began to write on theological subjects in the course of the following year.

Pascal fell away from this initial religious engagement and experienced a few years of what some biographers have called his "worldly period" (1648–54). His father died in 1651 and left his inheritance to Pascal and his sister Jacqueline, for whom Pascal acted as conservator. Jacqueline announced that she would soon become a postulant in the Jansenist convent of Port-Royal. Pascal was deeply affected and very sad, not because of her choice, but because of his chronic poor health; he needed her just as she had needed him.

By the end of October in 1651, a truce had been reached between brother and sister. In return for a healthy annual stipend, Jacqueline signed over her part of the inheritance to her brother. Gilberte had already been given her inheritance in the form of a dowry. In early January, Jacqueline left for Port-Royal. On that day, according to Gilberte concerning her brother, "He retired very sadly to his rooms without seeing Jacqueline, who was waiting in the little parlor..."
In early June 1653, after what must have seemed like endless badgering from Jacqueline,
Pascal formally signed over the whole of his sister's inheritance to Port-Royal, which, to him, "had begun to smell like a cult." With two-thirds of his father's estate now gone, the 29-year-old Pascal was now consigned to genteel poverty.

For a while, Pascal pursued the life of a bachelor. During visits to his sister at Port-Royal in 1654, he displayed contempt for affairs of the world but was not drawn to God.

On 23 November 1654, between 10:30 and 12:30 at night, Pascal had an intense religious vision and immediately recorded the experience in a brief note to himself which began: "Fire. God of Abraham, God of Isaac, God of Jacob, not of the philosophers and the scholars..." and concluded by quoting Psalm 119:16: "I will not forget thy word. Amen." He seems to have carefully sewn this document into his coat and always transferred it when he changed clothes; a servant discovered it only by chance after his death. This piece is now known as the "Memorial". The story of a carriage accident as having led to the experience described in the "Memorial" is disputed by some scholars.
His belief and religious commitment revitalized, Pascal visited the older of two convents at Port-Royal for a two-week retreat in January 1655. For the next four years, he regularly travelled between Port-Royal and Paris. It was at this point immediately after his conversion when he began writing his first major literary work on religion, the "Provincial Letters".

Beginning in 1656–57, Pascal published his memorable attack on casuistry, a popular ethical method used by Catholic thinkers in the early modern period (especially the Jesuits, and in particular Antonio Escobar). Pascal denounced casuistry as the mere use of complex reasoning to justify moral laxity and all sorts of sins. The 18-letter series was published between 1656 and 1657 under the pseudonym Louis de Montalte and incensed Louis XIV. The king ordered that the book be shredded and burnt in 1660. In 1661, in the midsts of the formulary controversy, the Jansenist school at Port-Royal was condemned and closed down; those involved with the school had to sign a 1656 papal bull condemning the teachings of Jansen as heretical. The final letter from Pascal, in 1657, had defied Alexander VII himself. Even Pope Alexander, while publicly opposing them, nonetheless was persuaded by Pascal's arguments.

Aside from their religious influence, the "Provincial Letters" were popular as a literary work. Pascal's use of humor, mockery, and vicious satire in his arguments made the letters ripe for public consumption, and influenced the prose of later French writers like Voltaire and Jean-Jacques Rousseau.

It is in the Provincial Letters that Pascal coined his oft-quoted apology for writing a long letter, as he hadn't had time to write a shorter one.
From Letter XVI, as translated by Thomas M'Crie:
'Reverend fathers, my letters were not wont either to be so prolix, or to follow so closely on
one another. Want of time must plead my excuse for both of these faults. The present letter is
a very long one, simply because I had no leisure to make it shorter.'

Charles Perrault wrote of the "Letters": "Everything is there—purity of language, nobility of thought, solidity in reasoning, finesse in raillery, and throughout an "agrément" not to be found anywhere else."

Pascal's most influential theological work, referred to posthumously as the "Pensées" ("Thoughts"), was not completed before his death. It was to have been a sustained and coherent examination and defense of the Christian faith, with the original title "Apologie de la religion Chrétienne" ("Defense of the Christian Religion"). The first version of the numerous scraps of paper found after his death appeared in print as a book in 1669 titled "Pensées de M. Pascal sur la religion, et sur quelques autres sujets" ("Thoughts of M. Pascal on religion, and on some other subjects") and soon thereafter became a classic. One of the "Apologie"s main strategies was to use the contradictory philosophies of Pyrrhonism and Stoicism, personalized by Montaigne on one hand, and Epictetus on the other, in order to bring the unbeliever to such despair and confusion that he would embrace God.

Pascal's "Pensées" is widely considered to be a masterpiece, and a landmark in "French prose". When commenting on one particular section (Thought #72), Sainte-Beuve praised it as the finest pages in the French language. Will Durant hailed the Pensées as "the most eloquent book in French prose".

T. S. Eliot described him during this phase of his life as "a man of the world among ascetics, and an ascetic among men of the world." Pascal's ascetic lifestyle derived from a belief that it was natural and necessary for a person to suffer. In 1659, Pascal fell seriously ill. During his last years, he frequently tried to reject the ministrations of his doctors, saying, "Sickness is the natural state of Christians."

Louis XIV suppressed the Jansenist movement at Port-Royal in 1661. In response, Pascal wrote one of his final works, "Écrit sur la signature du formulaire" ("Writ on the Signing of the Form"), exhorting the Jansenists not to give in. Later that year, his sister Jacqueline died, which convinced Pascal to cease his polemics on Jansenism. Pascal's last major achievement, returning to his mechanical genius, was inaugurating perhaps the first bus line, the carrosses à cinq sols, moving passengers within Paris in a carriage with many seats.

In 1662, Pascal's illness became more violent, and his emotional condition had severely worsened since his sister's death. Aware that his health was fading quickly, he sought a move to the hospital for incurable diseases, but his doctors declared that he was too unstable to be carried. In Paris on 18 August 1662, Pascal went into convulsions and received extreme unction. He died the next morning, his last words being "May God never abandon me," and was buried in the cemetery of Saint-Étienne-du-Mont.

An autopsy performed after his death revealed grave problems with his stomach and other organs of his abdomen, along with damage to his brain. Despite the autopsy, the cause of his poor health was never precisely determined, though speculation focuses on tuberculosis, stomach cancer, or a combination of the two. The headaches which afflicted Pascal are generally attributed to his brain lesion.

In honour of his scientific contributions, the name "Pascal" has been given to the SI unit of pressure, to a programming language, and Pascal's law (an important principle of hydrostatics), and as mentioned above, Pascal's triangle and Pascal's wager still bear his name.

Pascal's development of probability theory was his most influential contribution to mathematics. Originally applied to gambling, today it is extremely important in economics, especially in actuarial science. John Ross writes, "Probability theory and the discoveries following it changed the way we regard uncertainty, risk, decision-making, and an individual's and society's ability to influence the course of future events." However, Pascal and Fermat, though doing important early work in probability theory, did not develop the field very far. Christiaan Huygens, learning of the subject from the correspondence of Pascal and Fermat, wrote the first book on the subject. Later figures who continued the development of the theory include Abraham de Moivre and Pierre-Simon Laplace.

In literature, Pascal is regarded as one of the most important authors of the French Classical Period and is read today as one of the greatest masters of French prose. His use of satire and wit influenced later polemicists. The content of his literary work is best remembered for its strong opposition to the rationalism of René Descartes and simultaneous assertion that the main countervailing philosophy, empiricism, was also insufficient for determining major truths.

In France, prestigious annual awards, Blaise Pascal Chairs are given to outstanding international scientists to conduct their research in the Ile de France region. One of the Universities of Clermont-Ferrand, France – Université Blaise Pascal – is named after him. The University of Waterloo, Ontario, Canada, holds an annual math contest named in his honour.

Pascalian theology has grown out of his perspective that we are, according to Wood, "born into a duplicitous world that shapes us into duplicitous subjects and so we find it easy to reject God continually and deceive ourselves about our own sinfulness".

Roberto Rossellini directed a filmed biopic, "Blaise Pascal", which originally aired on Italian television in 1971. Pascal was a subject of the first edition of the 1984 BBC Two documentary, "Sea of Faith", presented by Don Cupitt.

In 2014, Nvidia announced its new Pascal microarchitecture, which is named for Pascal. The first graphics cards featuring Pascal were released in 2016.

The 2017 game "" has multiple characters named after famous philosophers; one of these is a sentient pacifistic machine named Pascal, who serves as a major supporting character. Pascal creates a village for machines to live peacefully with the androids they're at war with and acts as a parental figure for other machines trying to adapt to their newly-found individuality.





</doc>
<doc id="4069" url="https://en.wikipedia.org/wiki?curid=4069" title="Brittonic languages">
Brittonic languages

The Brittonic, Brythonic or British Celtic languages (; ; ) form one of the two branches of the Insular Celtic language family; the other is Goidelic. The name "Brythonic" was derived by Welsh Celticist John Rhys from the Welsh word , meaning an indigenous Briton as opposed to an Anglo-Saxon or Gael. The name "Brittonic" derives ultimately from the native Brittonic word for the island or its people.

The Brittonic languages derive from the Common Brittonic language, spoken throughout Great Britain south of the Firth of Forth during the Iron Age and Roman period. In addition, North of the Forth, the Pictish language is considered to be related; it is possible it was a Brittonic language, but it may have been a sister language. In the 5th and 6th centuries emigrating Britons also took Brittonic speech to the continent, most significantly in Brittany and Britonia. During the next few centuries the language began to split into several dialects, eventually evolving into Welsh, Cornish, Breton and Cumbric. Welsh and Breton continue to be spoken as native languages, while a revival in Cornish has led to an increase in speakers of that language. Cumbric is extinct, having been replaced by Goidelic and English speech. The Isle of Man and Orkney may also have originally spoken a Brittonic language, later replaced with a Goidelic one. Due to emigration, there is also a community of Brittonic language speakers in (the Welsh settlement in Patagonia).

The names "Brittonic" and "Brythonic" are scholarly conventions referring to the Celtic languages of Britain and to the ancestral language they originated from, designated Common Brittonic, in contrast to the Goidelic languages originating in Ireland. Both were created in the 19th century to avoid the ambiguity of earlier terms such as "British" and "Cymric". "Brythonic" was coined in 1879 by the Celticist John Rhys from the Welsh word . "Brittonic", derived from "Briton" and also earlier spelled "Britonic" and "Britonnic", emerged later in the 19th century. It became more prominent through the 20th century, and was used in Kenneth H. Jackson's highly influential 1953 work on the topic, "Language and History in Early Britain". Jackson noted that by that time "Brythonic" had become a dated term, and that "of late there has been an increasing tendency to use Brittonic instead." Today, "Brittonic" often replaces "Brythonic" in the literature. Rudolf Thurneysen used "Britannic" in his influential "A Grammar of Old Irish", though this never became popular among subsequent scholars.

Comparable historical terms include the Medieval Latin and and the Welsh . Some writers use "British" for the language and its descendants, though due to the risk of confusion, others avoid it or use it only in a restricted sense. Jackson, and later John T. Koch, use "British" only for the early phase of the Common Brittonic language.

Prior to Jackson's work, "Brittonic" (and "Brythonic") were often used for all the P-Celtic languages, including not just the varieties in Britain but those Continental Celtic languages that similarly experienced the evolution of the Proto-Celtic language element to . However, subsequent writers have tended to follow Jackson's scheme, rendering this use obsolete.

The name "Britain" itself comes from , via Old French ' and Middle English ', possibly influenced by Old English "", probably also from Latin "Brittania", ultimately an adaptation of the native word for the island, "*Pritanī".

An early written reference to the British Isles may derive from the works of the Greek explorer Pytheas of Massalia; later Greek writers such as Diodorus of Sicily and Strabo who quote Pytheas' use of variants such as (), "The Britannic [land, island]", and , "Britannic islands", with "" being a Celtic word that might mean "the painted ones" or "the tattooed folk", referring to body decoration (see below).

Knowledge of the Brittonic languages comes from a variety of sources. For the early languages information is obtained from coins, inscriptions and comments by classical writers as well as place names and personal names recorded by them. For later languages there is information from medieval writers and modern native speakers, together with place names. The names recorded in the Roman period are given in Rivet and Smith.

The Brittonic branch is also referred to as "P-Celtic" because linguistic reconstruction of the Brittonic reflex of the Proto-Indo-European phoneme *"kʷ" is "p" as opposed to Goidelic "c". Such nomenclature usually implies an acceptance of the P-Celtic and Q-Celtic hypothesis rather than the Insular Celtic hypothesis because the term includes certain Continental Celtic languages as well. (For a discussion, see Celtic languages.)

Other major characteristics include:
Initial "s-":
Lenition:
Voiceless spirants:
Nasal assimilation:

The family tree of the Brittonic languages is as follows:


Brittonic languages in use today are Welsh, Cornish and Breton. Welsh and Breton have been spoken continuously since they formed. For all practical purposes Cornish died out during the 18th or 19th centuries, but a revival movement has more recently created small numbers of new speakers. Also notable are the extinct language Cumbric, and possibly the extinct Pictish. One view, advanced in the 1950s and based on apparently unintelligible ogham inscriptions, was that the Picts may have also used a non-Indo-European language. This view, while attracting broad popular appeal, has virtually no following in contemporary linguistic scholarship.

The modern Brittonic languages are generally considered to all derive from a common ancestral language termed "Brittonic", "British", "Common Brittonic", "Old Brittonic" or "Proto-Brittonic", which is thought to have developed from Proto-Celtic or early Insular Celtic by the 6th century BC.

Brittonic languages were probably spoken prior to the Roman invasion at least in the majority of Great Britain south of the rivers Forth and Clyde, though the Isle of Man later had a Goidelic language, Manx. Northern Scotland mainly spoke Pritennic, which became the Pictish language, which may have been a Brittonic language like that of its neighbors. The theory has been advanced (notably by T. F. O'Rahilly) that part of Ireland spoke a Brittonic language, usually termed "Ivernic", before it was displaced by Primitive Irish, although the authors Dillon and Chadwick reject this theory as being implausible.

During the period of the Roman occupation of what are now England and Wales (AD 43 to c. 410), Common Brittonic borrowed a large stock of Latin words, both for concepts unfamiliar in the pre-urban society of Celtic Britain such as urbanisation and new tactics of warfare as well as for rather more mundane words which displaced native terms (most notably, the word for "fish" in all the Brittonic languages derives from the Latin "piscis" rather than the native *"ēskos" - which may survive, however, in the Welsh name of the River Usk, ). Approximately 800 of these Latin loan-words have survived in the three modern Brittonic languages.

It is probable that at the start of the Post-Roman period "Common Brittonic" was differentiated into at least two major dialect groups – Southwestern and Western (in addition we may posit additional dialects, such as Eastern Brittonic, spoken in what is now the East of England, which have left little or no evidence). Between the end of the Roman occupation and the mid 6th century the two dialects began to diverge into recognisably separate varieties, the Western into Cumbric and Welsh and the Southwestern into Cornish and its closely related sister language Breton, which was carried to continental Armorica. Jackson showed that a few of the dialect distinctions between West and Southwest Brittonic go back a long way. New divergencies began around AD 500 but other changes which were shared occurred in the 6th century. Other common changes occurred in the 7th century onward and are possibly due to inherent tendencies. Thus the concept of a common Brittonic language ends by AD 600. Substantial numbers of Britons certainly remained in the expanding area controlled by Anglo-Saxons, but over the fifth and sixth centuries they mostly adopted the English language.

The Brittonic languages spoken in what is now Scotland, the Isle of Man and what is now England began to be displaced in the 5th century through the settlement of Irish-speaking Gaels and Germanic peoples. The displacement of the languages of Brittonic descent was probably complete in all of Britain except Cornwall and Wales and the English counties bordering these areas such as Devon by the 11th century. Western Herefordshire continued to speak Welsh until the late nineteenth century, and isolated pockets of Shropshire speak Welsh today.

The regular consonantal sound changes from Proto-Celtic to Welsh, Cornish and Breton are summarised in the following table. Where the graphemes have a different value from the corresponding IPA symbols, the IPA equivalent is indicated between slashes. V represents a vowel; C represents a consonant.

The principal legacy left behind in those territories from which the Brittonic languages were displaced is that of toponyms (place names) and hydronyms (river names). There are many Brittonic place names in lowland Scotland and in the parts of England where it is agreed that substantial Brittonic speakers remained (Brittonic names, apart from those of the former Romano-British towns, are scarce over most of England). Names derived (sometimes indirectly) from Brittonic include London, Penicuik, Perth, Aberdeen, York, Dorchester, Dover and Colchester. Brittonic elements found in England include "bre-" and "bal-" for hills, while some such as combe or coomb(e) for a small deep valley and tor for a hill are examples of Brittonic words that were borrowed into English. Others reflect the presence of Britons such as Dumbarton – from the Scottish Gaelic "Dùn Breatainn" meaning "Fort of the Britons", or Walton meaning a "tun" or settlement where the "Wealh" "Britons" still lived.

The number of Celtic river names in England generally increases from east to west, a map showing these being given by Jackson. These names include ones such as Avon, Chew, Frome, Axe, Brue and Exe, but also river names containing the elements "der-/dar-/dur-" and "-went" e.g. "Derwent, Darwen, Deer, Adur, Dour, Darent, Went". In fact these names exhibit multiple different Celtic roots. One is *dubri- "water" [Bret. "dour", C. "dowr", W. "dŵr"], also found in the place-name "Dover" (attested in the Roman period as "Dubrīs"); this is the original source of rivers named "Dour". Another is *deru̯o- "oak" or "true" [Bret. "derv", C. "derow", W. "derw"], coupled with two agent suffixes, *-ent- and *-iū; this is the origin of "Derwent", " Darent" and "Darwen" (attested in the Roman period as "Deru̯entiō"). The final root to be examined is "went". In Roman Britain there were three tribal capitals named "U̯entā" (modern Winchester, Caerwent and Caistor St Edmunds), whose meaning was 'place, town'.

Some, including J. R. R. Tolkien, have argued that Celtic has acted as a substrate to English for both the lexicon and syntax. It is generally accepted that linguistic effects on English were lexically rather poor aside from toponyms, consisting of a few domestic words, which may include hubbub, dad, peat, bucket, crock, crumpet (cf. Br. krampouz), noggin, gob (cf. Gaelic gob), nook; and the dialectal term for a badger, i.e. "brock" (cf. Welsh broch, C. brogh and Gaelic broc). Another legacy may be the sheep-counting system Yan Tan Tethera in the west, in the traditionally Celtic areas of England such as Cumbria. Several Cornish mining words are still in use in English language mining terminology, such as costean, gunnies, and vug.

Those who argue against the theory of a Brittonic substratum and heavy influence point out that many toponyms have no semantic continuation from the Brittonic language. A notable example is Avon which comes from the Celtic term for river abona or the Welsh term for river, afon, but was used by the English as a personal name. Likewise the River Ouse, Yorkshire contains the word usa which merely means 'water' and the name of the river Trent simply comes from the Welsh word for a trespasser "(an over-flowing river)".

It has been argued that the use of periphrastic constructions (using auxiliary verbs such as "do" and "be" in the continuous/progressive) in the English verb, which is more widespread than in the other Germanic languages, is traceable to Brittonic influence. Some however find this very unlikely and claim a native English development rather than Celtic influence, though Roberts postulates Northern Germanic influence, despite such constructions not existing in Norse. Literary Welsh has the simple present Caraf = "I love" and the present stative (al. continuous/progressive) Yr wyf yn caru = "I am loving", where the Brittonic syntax is partly mirrored in English (Note that "I am loving" comes from older "I am a-loving", from still older ich am on luvende "I am in the process of loving"). In the Germanic sister languages of English there is only one form, for example ich liebe in German, though in "colloquial" usage in some German dialects, a progressive aspect form has evolved which is formally similar to those found in Celtic languages, and somewhat less similar to the Modern English form, e.g. "I am working" is ich bin am Arbeiten, literally: "I am on the working". The same structure is also found in modern Dutch (ik ben aan het werk), alongside other structures (e.g. ik zit te werken, lit. "I sit to working"). These parallel developments suggest that the English progressive is not necessarily due to Celtic influence; moreover, the native English development of the structure can be traced over 1000 years and more of English literature.

Some researchers (Filppula "et al.", 2001) argue that English syntax reflects more extensive Brittonic influences. For instance, in English tag questions, the form of the tag depends on the verb form in the main statement ("aren't I?", "isn't he?", "won't we?" etc.). The German nicht wahr? and the French n'est-ce pas?, by contrast, are fixed forms which can be used with almost any main statement. It has been claimed that the English system has been borrowed from Brittonic, since Welsh tag questions vary in almost exactly the same way.

Far more notable, but less well known, are Brittonic influences on Scottish Gaelic, though Scottish and Irish Gaelic, with their wider range of preposition-based periphastic constructions, suggest that such constructions descend from their common Celtic heritage. Scottish Gaelic contains a number of apparently P-Celtic loanwords, but as there is a far greater overlap in terms of Celtic vocabulary, than with English, it is not always possible to disentangle P- and Q-Celtic words. However some common words such as monadh = Welsh mynydd, Cumbric *monidh are particularly evident.

Often the Brittonic influence on Scots Gaelic is indicated by considering Irish language usage, which is not likely to have been influenced so much by Brittonic. In particular, the word srath (anglicised as "Strath") is a native Goidelic word, but its usage appears to have been modified by the Brittonic cognate ystrad whose meaning is slightly different. The effect on Irish has been the loan from British of many Latin-derived words. This has been associated with the Christianisation of Ireland from Britain.




</doc>
<doc id="4071" url="https://en.wikipedia.org/wiki?curid=4071" title="Bronski Beat">
Bronski Beat

Bronski Beat were an English synthpop trio which achieved success in the mid-1980s, particularly with the 1984 chart hit "Smalltown Boy", from their debut album "The Age of Consent", which was their only US Billboard Hot 100 single. All members of the band were openly gay and their songs reflected this, often containing political commentary on gay-related issues. The initial line-up, which recorded the majority of the band's hits, consisted of Jimmy Somerville (vocals), Steve Bronski (born Steven William Forrest, keyboards, percussion) and the missing Larry Steinbachek (keyboards, percussion).

Somerville left Bronski Beat in 1985, and went on to have success as lead singer of The Communards and as a solo artist. He was replaced by new vocalist John Foster, with whom the band continued to have hits in the UK and Europe through 1986. Foster left Bronski Beat after their second album, and the band used a series of vocalists before dissolving in 1996.

Steve Bronski, the only remaining original member, now leads a revived touring version of the band, and has recorded new material alongside 1990s member Ian Donaldson. Larry Steinbachek died in 2016.

Bronski Beat formed in 1983 when Somerville, Bronski (both from Glasgow), and Steinbachek (from Southend) shared a three-bedroom flat at Lancaster House in Brixton. Steinbachek had heard Somerville singing during the making of "" and suggested they make some music. They first performed publicly at an arts festival "September in the Pink". The trio were unhappy with the inoffensive nature of contemporary gay performers and sought to be more outspoken and political.

Bronski Beat signed a recording contract with London Records in 1984 after doing only nine live gigs. The band's debut single, "Smalltown Boy" (about a gay teenager leaving his family and fleeing his hometown) was a hit, peaking at No 3 in the UK Singles Chart, and topping charts in Belgium and the Netherlands. The single was accompanied by a promotional video directed by Bernard Rose, showing Somerville trying to befriend an attractive diver at a swimming pool, then being attacked by the diver's homophobic associates, being returned to his family by the police and having to leave home. (The police officer was played by Colin Bell, then the marketing manager of London Records). "Smalltown Boy" reached 48 in the U.S. chart and peaked at 7 in Australia.

The follow-up single, "Why?", adopted a Hi-NRG sound and was more lyrically focused on anti-gay prejudice. It also achieved Top 10 status in the UK, reaching 6, and was another Top 10 hit for the band in Australia, Switzerland, Germany, France and the Netherlands.

At the end of 1984, the trio released an album titled "The Age of Consent". The inner sleeve listed the varying ages of consent for consensual gay sex in different nations around the world. At the time, the age of consent for sexual acts between men in the UK was 21 compared with 16 for heterosexual acts, with several other countries having more liberal laws on gay sex. The album peaked at 4 in the UK Albums Chart, 36 in the U.S., and 12 in Australia.

Around the same time, the band headlined "Pits and Perverts", a concert at the Electric Ballroom in London to raise funds for the Lesbians and Gays Support the Miners campaign. This event is featured in the film "Pride".

The third single, released before Christmas 1984, was a revival of "It Ain't Necessarily So", the George and Ira Gershwin classic (from "Porgy and Bess"). The song questions the accuracy of biblical tales. It also reached the UK Top 20.

In 1985, the trio joined up with Marc Almond to record a version of Donna Summer's "I Feel Love". The full version was actually a medley that also incorporated snippets of Summer's "Love to Love You Baby" and John Leyton's "Johnny Remember Me". It was a big success, reaching 3 in the UK and equalling the chart achievement of "Smalltown Boy". Although the original had been one of Marc Almond's all-time favourite songs, he had never read the lyrics and thus incorrectly sang "What’ll it be, what’ll it be, you and me" instead of "Falling free, falling free, falling free" on the finished record.

The band and their producer Mike Thorne had gone back into the studio in early 1985 to record a new single, "Run From Love", and PolyGram (London Records' parent company at that time) had pressed a number of promo singles and 12" versions of the song and sent them to radio and record stores in the UK. However, the single was shelved as tensions in the band, both personal and political, resulted in Somerville leaving Bronski Beat in the summer of that year.

"Run From Love" was subsequently released in a remix form on the Bronski Beat album "Hundreds & Thousands", a collection of mostly remixes (LP) and B-sides (as bonus tracks on the CD version) as well as the hit "I Feel Love". Somerville went on to form The Communards with Richard Coles while the remaining members of Bronski Beat searched for a new vocalist.

Bronski Beat recruited John Foster as Somerville's replacement (Foster is credited as "Jon Jon"). A single, "Hit That Perfect Beat", was released in November 1985, reaching 3 in the UK. It repeated this success on the Australian chart and was also featured in the film "Letter to Brezhnev". A second single, "C'mon C'mon", also charted in the UK Top 20 and an album, "Truthdare Doubledare", released in May 1986, peaked at 18. The film "Parting Glances" (1986) included Bronski Beat songs "Love and Money", "Smalltown Boy" and "Why?". During this period, the band teamed up with producer Mark Cunningham on the first-ever BBC Children In Need single, a cover of David Bowie's "Heroes", released in 1986 under the name of The County Line.

Foster left the band in 1987. Following Foster's departure, Bronski Beat began work on their next album, "Out and About". The tracks were recorded at Berry Street studios in London with engineer Brian Pugsley. Some of the song titles were "The Final Spin" and "Peace And Love". The latter track featured Strawberry Switchblade vocalist Rose McDowall and appeared on several internet sites in 2006. One of the other songs from the project called "European Boy" was recorded in 1987 by disco group Splash. The lead singer of Splash was former Tight Fit singer Steve Grant. Steinbachek and Bronski toured extensively with the new material with positive reviews, however the project was abandoned as the group was dropped by London Records. Also in 1987, Bronski Beat and Somerville performed at a reunion concert for "International AIDS Day", supported by New Order, at the Brixton Academy, London.

In 1989, Jonathan Hellyer became lead singer, and the band extensively toured the U.S. and Europe with back-up vocalist Annie Conway. They achieved one minor hit with the song "Cha Cha Heels", a one-off collaboration sung by American actress and singer Eartha Kitt, which peaked at 32 in the UK. The song was originally written for movie and recording star Divine, who was unable to record the song before his death in 1988. 1990–91 saw Bronski Beat release three further singles on the Zomba record label, "I'm Gonna Run Away", "One More Chance" and "What More Can I Say". The singles were produced by Mike Thorne.

Foster and Bronski Beat teamed up again in 1994, and released a techno "Tell Me Why '94" and an acoustic "Smalltown Boy '94" on the German record label, ZYX Music. The album "Rainbow Nation" was released the following year with Hellyer returning as lead vocalist, as Foster had dropped out of the project and Ian Donaldson was brought on board to do keyboards and programming. After a few years of touring, Bronski Beat then dissolved, with Steve Bronski going on to become a producer for other artists and Ian Donaldson becoming a successful DJ (Sordid Soundz). Larry Steinbachek became the musical director for Michael Laub's theatre company, 'Remote Control Productions'.

In 2007, Steve Bronski remixed the song "Stranger to None" by the UK alternative rock band, All Living Fear. Four different mixes were made, with one appearing on their retrospective album, "Fifteen Years After". Bronski also remixed the track "Flowers in the Morning" by Northern Irish electronic band Electrobronze in 2007, changing the style of the song from classical to Hi-NRG disco.

In 2015, Steve Bronski teamed up as a one-off with Jessica James (aka Barbara Bush) and said that she reminded him of Divine, because of her look and Eartha Kitt-like sound. The one-off project was to cover the track he made in 1989.

In 2016, Steve Bronski again teamed up with Ian Donaldson, with the aim of bringing Bronski Beat back, enlisting a new singer, Stephen Granville. In 2017, the new Bronski Beat released a reworked version of "Age of Consent" entitled "Age of Reason".

"Out & About", the unreleased Bronski Beat album from 1987, was released digitally via Steve Bronski's website. The album features the original tracks plus remixes by Bronski.

On 12 January 2017, Larry Steinbachek's sister Louise Jones told BBC News he had died the previous month after a short battle with cancer, with his family and friends at his bedside.

The original member set of Bronski Beat was Jimmy Somerville, Steve Bronski and Larry Steinbachek . Following Somerville leaving to form pop group The Communards with Richard Coles, he was replaced by John Foster and later by Jonathan Hellyer. The band set-up has seen a number of changes.



! Year !! Awards !! Work !! Category !! Result




</doc>
<doc id="4074" url="https://en.wikipedia.org/wiki?curid=4074" title="Barrel (disambiguation)">
Barrel (disambiguation)

A barrel is a cylindrical container, traditionally made with wooden material.

Barrel may also refer to:




</doc>
<doc id="4077" url="https://en.wikipedia.org/wiki?curid=4077" title="Binary prefix">
Binary prefix

A binary prefix is a unit prefix for multiples of units in data processing, data transmission, and digital information, notably the bit and the byte, to indicate multiplication by a power of 2.

The computer industry has historically used the units "kilobyte", "megabyte", and "gigabyte", and the corresponding symbols KB, MB, and GB, in at least two slightly different measurement systems. In citations of main memory (RAM) capacity, "gigabyte" customarily means bytes. As this is a power of 1024, and 1024 is a power of two (2), this usage is referred to as a binary measurement.

In most other contexts, the industry uses the multipliers "kilo", "mega", "giga", etc., in a manner consistent with their meaning in the International System of Units (SI), namely as powers of 1000. For example, a 500 gigabyte hard disk holds bytes, and a 1 Gbit/s (gigabit per second) Ethernet connection transfers data at nominal speed of bit/s. In contrast with the "binary prefix" usage, this use is described as a "decimal prefix", as 1000 is a power of 10 (10).

The use of the same unit prefixes with two different meanings has caused confusion. Starting around 1998, the International Electrotechnical Commission (IEC) and several other standards and trade organizations addressed the ambiguity by publishing standards and recommendations for a set of binary prefixes that refer exclusively to powers of 1024. Accordingly, the US National Institute of Standards and Technology (NIST) requires that SI prefixes only be used in the decimal sense: kilobyte and megabyte denote one thousand bytes and one million bytes respectively (consistent with SI), while new terms such as kibibyte, mebibyte and gibibyte, having the symbols KiB, MiB, and GiB, denote 1024 bytes, bytes, and bytes, respectively. In 2008, the IEC prefixes were incorporated into the international standard system of units used alongside the International System of Quantities (see ISO/IEC 80000).

Early computers used one of two addressing methods to access the system memory; binary (base 2) or decimal (base 10).
For example, the IBM 701 (1952) used binary and could address 2048 words of 36 bits each, while the IBM 702 (1953) used decimal and could address ten thousand 7-bit words.

By the mid-1960s, binary addressing had become the standard architecture in most computer designs, and main memory sizes were most commonly powers of two. This is the most natural configuration for memory, as all combinations of their address lines map to a valid address, allowing easy aggregation into a larger block of memory with contiguous addresses.

Early computer system documentation would specify the memory size with an exact number such as 4096, 8192, or 16384 words of storage. These are all powers of two, and furthermore are small multiples of 2, or 1024. As storage capacities increased, several different methods were developed to abbreviate these quantities.

The method most commonly used today uses prefixes such as kilo, mega, giga, and corresponding symbols K, M, and G, which the computer industry originally adopted from the metric system. The prefixes "kilo-" and "mega-", meaning 1000 and respectively, were commonly used in the electronics industry before World War II. 
Along with "giga-" or G-, meaning , they are now known as SI prefixes after the International System of Units (SI), introduced in 1960 to formalize aspects of the metric system.

The International System of Units does not define units for digital information but notes that the SI prefixes may be applied outside the contexts where base units or derived units would be used. But as computer main memory in a 
binary-addressed system is manufactured in sizes that were easily expressed as multiples of 1024, "kilobyte", when applied to computer memory, came to be used to mean 1024 bytes instead of 1000. This usage is not consistent with the SI. Compliance with the SI requires that the prefixes take their 1000-based meaning, and that they are not to be used as placeholders for other numbers, like 1024.

The use of K in the binary sense as in a "32K core" meaning words, i.e., words, can be found as early as 1959.
Gene Amdahl's seminal 1964 article on IBM System/360 used "1K" to mean 1024.
This style was used by other computer vendors, the CDC 7600 "System Description" (1968) made extensive use of K as 1024.
Thus the first binary prefix was born.

Another style was to truncate the last three digits and append K, essentially using K as a decimal prefix similar to SI, but always truncating to the next lower whole number instead of rounding to the nearest. The exact values words, words and words would then be described as "32K", "65K" and "131K".
This style was used from about 1965 to 1975.

These two styles (K = 1024 and truncation) were used loosely around the same time, sometimes by the same company. In discussions of binary-addressed memories, the exact size was evident from context. (For memory sizes of "41K" and below, there is no difference between the two styles.) The HP 21MX real-time computer (1974) denoted (which is 192×1024) as "196K" and as "1M",
while the HP 3000 business computer (1973) could have "64K", "96K", or "128K" bytes of memory.

The "truncation" method gradually waned. Capitalization of the letter K became the "de facto" standard for binary notation, although this could not be extended to higher powers, and use of the lowercase k did persist. Nevertheless, the practice of using the SI-inspired "kilo" to indicate 1024 was later extended to "megabyte" meaning 1024 () bytes, and later "gigabyte" for 1024 () bytes. For example, a "512 megabyte" RAM module is 512×1024 bytes (512 × , or ), rather than .

The symbols Kbit, Kbyte, Mbit and Mbyte started to be used as "binary units"—"bit" or "byte" with a multiplier that is a power of 1024—in the early 1970s.
For a time, memory capacities were often expressed in K, even when M could have been used: The IBM System/370 Model 158 brochure (1972) had the following: "Real storage capacity is available in 512K increments ranging from 512K to 2,048K bytes."

Megabyte was used to describe the 22-bit addressing of DEC PDP-11/70 (1975)
and gigabyte the 30-bit addressing DEC VAX-11/780 (1977).

In 1998, the International Electrotechnical Commission IEC introduced the binary prefixes kibi, mebi, gibi ... to mean 1024, 1024, 1024 etc., so that 1048576 bytes could be referred to unambiguously as 1 mebibyte. The IEC prefixes were defined for use alongside the International System of Quantities (ISQ) in 2009.

The disk drive industry has followed a different pattern. Disk drive capacity is generally specified with unit prefixes with decimal meaning, in accordance to SI practices. Unlike computer main memory, disk architecture or construction does not mandate or make it convenient to use binary multiples. Drives can have any practical number of platters or surfaces, and the count of tracks, as well as the count of sectors per track may vary greatly between designs.

The first commercially sold disk drive, the IBM 350, had fifty physical disk platters containing a total of 50,000 sectors of 100 characters each, for a total quoted capacity of 5 million characters. It was introduced in September 1956.

In the 1960s most disk drives used IBM's variable block length format, called Count Key Data (CKD).
Any block size could be specified up to the maximum track length. Since the block headers occupied space, the usable capacity of the drive was dependent on the block size. Blocks ("records" in IBM's terminology) of 88, 96, 880 and 960 were often used because they related to the fixed block size of 80- and 96-character punch cards. The drive capacity was usually stated under conditions of full track record blocking. For example, the 100-megabyte 3336 disk pack only achieved that capacity with a full track block size of 13,030 bytes.

Floppy disks for the IBM PC and compatibles quickly standardized on 512-byte sectors, so two sectors were easily referred to as "1K". The 3.5-inch "360 KB" and "720 KB" had 720 (single-sided) and 1440 sectors (double-sided) respectively. When the High Density "1.44 MB" floppies came along, with 2880 of these 512-byte sectors, that terminology represented a hybrid binary-decimal definition of "1 MB" = 2 × 10 = 1 024 000 bytes.

In contrast, hard disk drive manufacturers used "megabytes" or "MB", meaning 10 bytes, to characterize their products as early as 1974. By 1977, in its first edition, Disk/Trend, a leading hard disk drive industry marketing consultancy segmented the industry according to MBs (decimal sense) of capacity.

One of the earliest hard disk drives in personal computing history, the Seagate ST-412, was specified as "Formatted: 10.0 Megabytes". The drive contains four heads and active surfaces (tracks per cylinder), 306 cylinders. When formatted with a sector size of 256 bytes and 32 sectors/track it has a capacity of . This drive was one of several types installed in the IBM PC/XT and extensively advertised and reported as a "10 MB" (formatted) hard disk drive.
The cylinder count of 306 is not conveniently close to any power of 1024; operating systems and programs using the customary binary prefixes show this as 9.5625 MB. Many later drives in the personal computer market used 17 sectors per track; still later, zone bit recording was introduced, causing the number of sectors per track to vary from the outer track to the inner.

The hard drive industry continues to use decimal prefixes for drive capacity, as well as for transfer rate. For example, a "300 GB" hard drive offers slightly more than , or , bytes, not (which would be about ). Operating systems such as Microsoft Windows that display hard drive sizes using the customary binary prefix "GB" (as it is used for RAM) would display this as "279.4 GB" (meaning bytes, or ). On the other hand, macOS has since version 10.6 shown hard drive size using decimal prefixes (thus matching the drive makers' packaging). (Previous versions of Mac OS X used binary prefixes.)

However, other usages still occur. Seagate has specified data transfer rates in select manuals of some hard drives in "both" IEC and decimal units. 
"Advanced Format" drives using 4096-byte sectors are described as having "4K sectors."

Computer clock frequencies are always quoted using SI prefixes in their decimal sense. For example, the internal clock frequency of the original IBM PC was 4.77 MHz, that is .
Similarly, digital information transfer rates are quoted using decimal prefixes:

By the mid-1970s it was common to see K meaning 1024 and the occasional M meaning for words or bytes of main memory (RAM) while K and M were commonly used with their decimal meaning for disk storage. In the 1980s, as capacities of both types of devices increased, the SI prefix G, with SI meaning, was commonly applied to disk storage, while M in its binary meaning, became common for computer memory. In the 1990s, the prefix G, in its binary meaning, became commonly used for computer memory capacity. The first terabyte (SI prefix, bytes) hard disk drive was introduced in 2007.

The dual usage of the kilo (K), mega (M), and giga (G) prefixes as both powers of 1000 and powers of 1024 has been recorded in standards and dictionaries. For example, the 1986 ANSI/IEEE Std 1084-1986
defined dual uses for kilo and mega.

Many dictionaries have noted the practice of using traditional prefixes to indicate binary multiples.
Oxford online dictionary defines, for example, megabyte as: "Computing: a unit of information equal to one million or (strictly) bytes."

The units Kbyte, Mbyte, and Gbyte are found in the trade press and in IEEE journals. Gigabyte was formally defined in IEEE Std 610.10-1994 as either or 2 bytes.
Kilobyte, Kbyte, and KB are equivalent units and all are defined in the obsolete standard, IEEE 100-2000.

The hardware industry measures system memory (RAM) using the binary meaning while magnetic disk storage uses the SI definition. However, many exceptions exist. Labeling of diskettes uses the megabyte to denote 1024×1000 bytes. In the optical disks market, compact discs use "MB" to mean 1024 bytes while DVDs use "GB" to mean 1000 bytes.

Computer storage has become cheaper per unit and thereby larger, by many orders of magnitude since "K" was first used to mean 1024. 
Because both the SI and "binary" meanings of kilo, mega, etc., are based on powers of 1000 or 1024 rather than simple multiples, the difference between 1M "binary" and 1M "decimal" is proportionally larger than that between 1K "binary" and 1k "decimal," and so on up the scale.
The relative difference between the values in the binary and decimal interpretations increases, when using the SI prefixes as the base, from 2.4% for kilo to nearly 21% for the yotta prefix.

In the early days of computers (roughly, prior to the advent of personal computers) there was little or no consumer confusion because of the technical sophistication of the buyers and their familiarity with the products. In addition, it was common for computer manufacturers to specify their products with capacities in full precision.

In the personal computing era, one source of consumer confusion is the difference in the way many operating systems display hard drive sizes, compared to the way hard drive manufacturers describe them. Hard drives are specified and sold using "GB" and "TB" in their decimal meaning: one billion and one trillion bytes. Many operating systems and other software, however, display hard drive and file sizes using "MB", "GB" or other SI-looking prefixes in their binary sense, just as they do for displays of RAM capacity. For example, many such systems display a hard drive marketed as "160 GB" as "149.05 GB". The earliest known presentation of hard disk drive capacity by an operating system using "KB" or "MB" in a binary sense is 1984; earlier operating systems generally presented the hard disk drive capacity as an exact number of bytes, with no prefix of any sort, for example, in the output of the MS-DOS or PC DOS CHKDSK command.

The different interpretations of disk size prefixes has led to class action lawsuits against digital storage manufacturers.
These cases involved both flash memory and hard disk drives.

The most recent cases (2019+) did not settle and ended in favor of the manufacturers, with courts holding that the legal definition of gigabyte or GB is 1 GB = 1,000,000,000 (10^9) bytes (the decimal definition) rather than the binary definition (2^30) for commercial transactions. Specifically, the courts held that "the U.S. Congress has deemed the decimal definition of gigabyte to be the 'preferred' one for the purposes of 'U.S. trade and commerce' ... The California Legislature has likewise adopted the decimal system for all 'transactions in this state.'”

Earlier cases (2004-2007) were settled prior to any court ruling with the manufacturers admitting no wrongdoing but agreeing to clarify the storage capacity of their products on the consumer packaging.
Accordingly, many flash memory and hard disk manufacturers have disclosures on their packaging and web sites clarifying the formatted capacity of the devices
or defining MB as 1 million bytes and 1 GB as 1 billion bytes.

On 20 February 2004, Willem Vroegh filed a lawsuit against Lexar Media, Dane–Elec Memory, Fuji Photo Film USA, Eastman Kodak Company, Kingston Technology Company, Inc., Memorex Products, Inc.; PNY Technologies Inc., SanDisk Corporation, Verbatim Corporation, and Viking Interworks alleging that their descriptions of the capacity of their flash memory cards were false and misleading.

Vroegh claimed that a 256 MB Flash Memory Device had only 244 MB of accessible memory. "Plaintiffs allege that Defendants marketed the memory capacity of their products by assuming that one megabyte equals one million bytes and one gigabyte equals one billion bytes."
The plaintiffs wanted the defendants to use the traditional values of 1024 for megabyte and 1024 for gigabyte.
The plaintiffs acknowledged that the IEC and IEEE standards define a MB as one million bytes but stated that the industry has largely ignored the IEC standards.

The parties agreed that manufacturers could continue to use the decimal definition so long as the definition was added to the packaging and web sites. The consumers could apply for "a discount of ten percent off a future online purchase from Defendants' Online Stores Flash Memory Device".

On 7 July 2005, an action entitled "Orin Safier v. Western Digital Corporation, et al." was filed in the Superior Court for the City and County of San Francisco, Case No. CGC-05-442812.
The case was subsequently moved to the Northern District of California, Case No. 05-03353 BZ.

Although Western Digital maintained that their usage of units is consistent with "the indisputably correct industry standard for measuring and describing storage capacity", and that they "cannot be expected to reform the software industry", they agreed to settle in March 2006 with 14 June 2006 as the Final Approval hearing date.

Western Digital offered to compensate customers with a free download of backup and recovery software valued at US$30. They also paid $500,000 in fees and expenses to San Francisco lawyers Adam Gutride and Seth Safier, who filed the suit.
The settlement called for Western Digital to add a disclaimer to their later packaging and advertising.

A lawsuit (Cho v. Seagate Technology (US) Holdings, Inc., San Francisco Superior Court, Case No. CGC-06-453195) was filed against Seagate Technology, alleging that Seagate overrepresented the amount of usable storage by 7% on hard drives sold between March 22, 2001 and September 26, 2007. The case was settled without Seagate admitting wrongdoing, but agreeing to supply those purchasers with free backup software or a 5% refund on the cost of the drives.

While early computer scientists typically used k to mean 1000, some recognized the convenience that would result from working with multiples of 1024 and the confusion that resulted from using the same prefixes for two different meanings.

Several proposals for unique binary prefixes were made in 1968. Donald Morrison proposed to use the Greek letter kappa (κ) to denote 1024, κ to denote 1024, and so on.
Wallace Givens responded with a proposal to use bK as an abbreviation for 1024 and bK2 or bK for 1024, though he noted that neither the Greek letter nor lowercase letter b would be easy to reproduce on computer printers of the day.
Bruce Alan Martin of Brookhaven National Laboratory further proposed that the prefixes be abandoned altogether, and the letter B be used for base-2 exponents, similar to E in decimal scientific notation, to create shorthands like 3B20 for 3×2, a convention still used on some calculators to present binary floating point-numbers today.

None of these gained much acceptance, and capitalization of the letter K became the "de facto" standard for indicating a factor of 1024 instead of 1000, although this could not be extended to higher powers.

As the discrepancy between the two systems increased in the higher-order powers, more proposals for unique prefixes were made.
In 1996, Markus Kuhn proposed a system with "di" prefixes, like the "dikilobyte" (K₂B or K2B). Donald Knuth, who uses decimal notation like 1 MB = 1000 kB, expressed "astonishment" that the IEC proposal was adopted, calling them "funny-sounding" and opining that proponents were assuming "that standards are automatically adopted just because they are there." Knuth proposed that the powers of 1024 be designated as "large kilobytes" and "large megabytes" (abbreviated KKB and MMB, as "doubling the letter connotes both binary-ness and large-ness"). Double prefixes were already abolished from SI, however, having a multiplicative meaning ("MMB" would be equivalent to "TB"), and this proposed usage never gained any traction.

The set of binary prefixes that were eventually adopted, now referred to as the "IEC prefixes", were first proposed by the International Union of Pure and Applied Chemistry's (IUPAC) Interdivisional Committee on Nomenclature and Symbols (IDCNS) in 1995. At that time, it was proposed that the terms kilobyte and megabyte be used only for 10 bytes and 10 bytes, respectively. The new prefixes "kibi" (kilobinary), "mebi" (megabinary), "gibi" (gigabinary) and "tebi" (terabinary) were also proposed at the time, and the proposed symbols for the prefixes were kb, Mb, Gb and Tb respectively, rather than Ki, Mi, Gi and Ti. The proposal was not accepted at the time.

The Institute of Electrical and Electronics Engineers (IEEE) began to collaborate with the International Organization for Standardization (ISO) and International Electrotechnical Commission (IEC) to find acceptable names for binary prefixes. IEC proposed "kibi", "mebi", "gibi" and "tebi", with the symbols Ki, Mi, Gi and Ti respectively, in 1996.

The names for the new prefixes are derived from the original SI prefixes combined with the term "binary", but contracted, by taking the first two letters of the SI prefix and "bi" from binary. The first letter of each such prefix is therefore identical to the corresponding SI prefixes, except for "K", which is used interchangeably with "k", whereas in SI, only the lower-case k represents 1000.

The IEEE decided that their standards would use the prefixes "kilo", etc. with their metric definitions, but allowed the binary definitions to be used in an interim period as long as such usage was explicitly pointed out on a case-by-case basis.

In January 1999, the IEC published the first international standard (IEC 60027-2 Amendment 2) with the new prefixes, extended up to "pebi" (Pi) and "exbi" (Ei).

The IEC 60027-2 Amendment 2 also states that the IEC position is the same as that of BIPM (the body that regulates the SI system); the SI prefixes retain their definitions in powers of 1000 and are never used to mean a power of 1024.

In usage, products and concepts typically described using powers of 1024 would continue to be, but with the new IEC prefixes. For example, a memory module of bytes () would be referred to as 512 MiB or 512 mebibytes instead of 512 MB or 512 megabytes. Conversely, since hard drives have historically been marketed using the SI convention that "giga" means , a "500 GB" hard drive would still be labeled as such. According to these recommendations, operating systems and other software would also use binary and SI prefixes in the same way, so the purchaser of a "500 GB" hard drive would find the operating system reporting either "500 GB" or "466 GiB", while bytes of RAM would be displayed as "512 MiB".

The second edition of the standard, published in 2000, defined them only up to "exbi", but in 2005, the third edition added prefixes "zebi" and "yobi", thus matching all SI prefixes with binary counterparts.

The harmonized ISO/IEC IEC 80000-13:2008 standard cancels and replaces subclauses 3.8 and 3.9 of IEC 60027-2:2005 (those defining prefixes for binary multiples). The only significant change is the addition of explicit definitions for some quantities. In 2009, the prefixes kibi-, mebi-, etc. were defined by ISO 80000-1 in their own right, independently of the kibibyte, mebibyte, and so on.

The BIPM standard JCGM 200:2012 "International vocabulary of metrology – Basic and general concepts and associated terms (VIM), 3rd edition" lists the IEC binary prefixes and states "SI prefixes refer strictly to powers of 10, and should not be used for powers of 2. For example, 1 kilobit should not be used to represent bits (2 bits), which is 1 kibibit."

The IEC standard binary prefixes are now supported by other standardization bodies and technical organizations.

The United States National Institute of Standards and Technology (NIST) supports the ISO/IEC standards for
"Prefixes for binary multiples" and has a web site documenting them, describing and justifying their use. NIST suggests that in English, the first syllable of the name of the binary-multiple prefix should be pronounced in the same way as the first syllable of the name of the corresponding SI prefix, and that the second syllable should be pronounced as "bee". NIST has stated the SI prefixes "refer strictly to powers of 10" and that the binary definitions "should not be used" for them.

The microelectronics industry standards body JEDEC describes the IEC prefixes in its online dictionary. The JEDEC standards for semiconductor memory use the customary prefix symbols K, M, G and T in the binary sense.

On 19 March 2005, the IEEE standard IEEE 1541-2002 ("Prefixes for Binary Multiples") was elevated to a full-use standard by the IEEE Standards Association after a two-year trial period. However, , the IEEE Publications division does not require the use of IEC prefixes in its major magazines such as "Spectrum" or "Computer". 

The International Bureau of Weights and Measures (BIPM), which maintains the International System of Units (SI), expressly prohibits the use of SI prefixes to denote binary multiples, and recommends the use of the IEC prefixes as an alternative since units of information are not included in SI.

The Society of Automotive Engineers (SAE) prohibits the use of SI prefixes with anything but a power-of-1000 meaning, but does not recommend or otherwise cite the IEC binary prefixes.

The European Committee for Electrotechnical Standardization (CENELEC) adopted the IEC-recommended binary prefixes via the harmonization document HD 60027-2:2003-03.
The European Union (EU) has required the use of the IEC binary prefixes since 2007.

Most computer hardware uses SI prefixes to state capacity and define other performance parameters such as data rate. Main and cache memories are notable exceptions.

Capacities of main memory and cache memory are usually expressed with customary binary prefixes
On the other hand, flash memory, like that found in solid state drives, mostly uses SI prefixes to state capacity.

Some operating systems and other software continue to use the customary binary prefixes in displays of memory, disk storage capacity, and file size, but SI prefixes in other areas such as network communication speeds and processor speeds.

In the following subsections, unless otherwise noted, examples are first given using the common prefixes used in each case, and then followed by interpretation using other notation where appropriate.

Prior to the release of Macintosh System Software (1984), file sizes were typically reported by the operating system without any prefixes. Today, most operating systems report file sizes with prefixes.


, most software does not distinguish symbols for binary and decimal prefixes.
The IEC binary naming convention has been adopted by a few, but this is not used universally.

One of the stated goals of the introduction of the IEC prefixes was "to preserve the SI prefixes as unambiguous decimal multipliers." Programs such as fdisk/cfdisk, parted, and apt-get use SI prefixes with their decimal meaning.

Example of the use of IEC binary prefixes in the Linux operating system displaying traffic volume on a network interface in kibibytes (KiB) and mebibytes (MiB), as obtained with the ifconfig utility:
Software that uses standard SI prefixes for powers of 1000, but "not" IEC binary prefixes for powers of 1024, includes:


Software that supports decimal prefixes for powers of 1000 "and" binary prefixes for powers of 1024 (but does not follow SI or IEC nomenclature for this) includes:


Software that uses IEC binary prefixes for powers of 1024 "and" uses standard SI prefixes for powers of 1000 includes:



Hardware types that use powers-of-1024 multipliers, such as memory, continue to be marketed with customary binary prefixes.

Measurements of most types of electronic memory such as RAM and ROM are given using customary binary prefixes (kilo, mega, and giga). This includes some flash memory, like EEPROMs. For example, a "512-megabyte" memory module is 512×2 bytes (512 × , or ).

JEDEC Solid State Technology Association, the semiconductor engineering standardization body of the Electronic Industries Alliance (EIA), continues to include the customary binary definitions of kilo, mega and giga in their "Terms, Definitions, and Letter Symbols" document,
and uses those definitions in later memory standards

Many computer programming tasks reference memory in terms of powers of two because of the inherent binary design of current hardware addressing systems. For example, a 16-bit processor register can reference at most 65,536 items (bytes, words, or other objects); this is conveniently expressed as "64K" items. An operating system might map memory as 4096-byte pages, in which case exactly 8192 pages could be allocated within bytes of memory: "8K" (8192) pages of "4 kilobytes" (4096 bytes) each within "32 megabytes" (32 MiB) of memory.

All hard disk drive manufacturers state capacity using SI prefixes.

USB flash drives, flash-based memory cards like CompactFlash or Secure Digital, and flash-based SSDs use SI prefixes;
for example, a "256 MB" flash card provides at least 256 million bytes (), not 256×1024×1024 ().
The flash memory chips inside these devices contain considerably more than the quoted capacities, but much like a traditional hard drive, some space is reserved for internal functions of the flash drive. These include wear leveling, error correction, sparing, and metadata needed by the device's internal firmware.

Floppy disks have existed in numerous physical and logical formats, and have been sized inconsistently. In part, this is because the end user capacity of a particular disk is a function of the controller hardware, so that the same disk could be formatted to a variety of capacities. In many cases, the media are marketed without any indication of the end user capacity, as for example, DSDD, meaning double-sided double-density.

The last widely adopted diskette was the 3½-inch high density. This has a formatted capacity of bytes or 1440 KB (1440 × 1024, using "KB" in the customary binary sense). These are marketed as "HD", or "1.44 MB" or both. This usage creates a third definition of "megabyte" as 1000×1024 bytes.

Most operating systems display the capacity using "MB" in the customary binary sense, resulting in a display of "1.4 MB" (). Some users have noticed the missing 0.04 MB and both Apple and Microsoft have support bulletins referring to them as 1.4 MB.

The earlier "1200 KB" (1200×1024 bytes) 5¼-inch diskette sold with the IBM PC AT was marketed as "1.2 MB" (). The largest 8-inch diskette formats could contain more than a megabyte, and the capacities of those devices were often irregularly specified in megabytes, also without controversy.

Older and smaller diskette formats were usually identified as an accurate number of (binary) KB, for example the Apple Disk II described as "140KB" had a 140×1024-byte capacity, and the original "360KB" double sided, double density disk drive used on the IBM PC had a 360×1024-byte capacity.

In many cases diskette hardware was marketed based on unformatted capacity, and the overhead required to format sectors on the media would reduce the nominal capacity as well (and this overhead typically varied based on the size of the formatted sectors), leading to more irregularities.

The capacities of most optical disc storage media like DVD, Blu-ray Disc, HD DVD and magneto-optical (MO) are given using SI decimal prefixes.
A "4.7 GB" DVD has a nominal capacity of about 4.38 GiB. However, CD capacities are always given using customary binary prefixes. Thus a "700-MB" (or "80-minute") CD has a nominal capacity of about 700 MiB (approx 730 MB).

Tape drive and media manufacturers use SI decimal prefixes to identify capacity.

Certain units are always used with SI decimal prefixes even in computing contexts.
Two examples are hertz (Hz), which is used to measure the clock rates of electronic components, and bit/s, used to measure data transmission speed.

Bus clock speeds and therefore bandwidths are both quoted using SI decimal prefixes.


IEC prefixes are used by Toshiba, IBM, HP to advertise or describe some of their products. According to one HP brochure, "[t]o reduce confusion, vendors are pursuing one of two remedies: they are changing SI prefixes to the new binary prefixes, or they are recalculating the numbers as powers of ten." The IBM Data Center also uses IEC prefixes to reduce confusion. The IBM Style Guide reads To help avoid inaccuracy (especially with the larger prefixes) and potential ambiguity, the International Electrotechnical Commission (IEC) in 2000 adopted a set of prefixes specifically for binary multipliers (See IEC 60027-2). Their use is now supported by the United States National Institute of Standards and Technology (NIST) and incorporated into ISO 80000. They are also required by EU law and in certain contexts in the US.

However, most documentation and products in the industry continue to use SI prefixes when referring to binary multipliers. In product documentation, follow the same standard that is used in the product itself (for example, in the interface or firmware). Whether you choose to use IEC prefixes for powers of 2 and SI prefixes for powers of 10, or use SI prefixes for a dual purpose ... be consistent in your usage and explain to the user your adopted system. 





</doc>
<doc id="4078" url="https://en.wikipedia.org/wiki?curid=4078" title="National Baseball Hall of Fame and Museum">
National Baseball Hall of Fame and Museum

The National Baseball Hall of Fame and Museum is an American history museum and hall of fame, located in Cooperstown, New York, and operated by private interests. It serves as the central point for the study of the history of baseball in the United States and beyond, displays baseball-related artifacts and exhibits, honoring those who have excelled in playing, managing, and serving the sport. The Hall's motto is "Preserving History, Honoring Excellence, Connecting Generations." The word Cooperstown is often used as shorthand (or a metonym) for the National Baseball Hall of Fame and Museum, similar to "Canton" for the Pro Football Hall of Fame in Canton, Ohio.

The Hall of Fame was established in 1939 by Stephen Carlton Clark, an heir to the Singer Sewing Machine fortune. Clark sought to bring tourists to a city hurt by the Great Depression, which reduced the local tourist trade, and Prohibition, which devastated the local hops industry. Clark constructed the Hall of Fame's building, and it was dedicated on June 12, 1939. (His granddaughter, Jane Forbes Clark, is the current chairman of the Board of Directors.) The erroneous claim that Civil War hero Abner Doubleday invented baseball in Cooperstown was instrumental in the early marketing of the Hall.

An expanded library and research facility opened in 1994. Dale Petroskey became the organization's president in 1999. In 2002, the Hall launched "Baseball As America", a traveling exhibit that toured ten American museums over six years. The Hall of Fame has since also sponsored educational programming on the Internet to bring the Hall of Fame to schoolchildren who might not visit. The Hall and Museum completed a series of renovations in spring 2005. The Hall of Fame also presents an annual exhibit at FanFest at the Major League Baseball All-Star Game.

Jeff Idelson replaced Petroskey as president on April 16, 2008. He had been acting as president since March 25, 2008, when Petroskey was forced to resign for having "failed to exercise proper fiduciary responsibility" and making "judgments that were not in the best interest of the National Baseball Hall of Fame and Museum."

Among baseball fans, "Hall of Fame" means not only the museum and facility in Cooperstown, New York, but the pantheon of players, managers, umpires, executives, and pioneers who have been enshrined in the Hall. The first five men elected were Ty Cobb, Babe Ruth, Honus Wagner, Christy Mathewson and Walter Johnson, chosen in 1936; roughly 20 more were selected before the entire group was inducted at the Hall's 1939 opening. , 329 people had been elected to the Hall of Fame, including 232 former Major League Baseball players, 35 Negro league baseball players and executives, 22 managers, 10 umpires, and 30 pioneers, executives, and organizers. 114 members of the Hall of Fame have been inducted posthumously, including four who died after their selection was announced. Of the 35 Negro league members, 29 were inducted posthumously, including all 24 selected since the 1990s. The Hall of Fame includes one female member, Effa Manley.

The newest members inducted on July 21, 2019, are players Harold Baines, Roy Halladay, Edgar Martínez, Mike Mussina, Mariano Rivera, and Lee Smith. Rivera was the first player ever to be elected unanimously. 

Players are currently inducted into the Hall of Fame through election by either the Baseball Writers' Association of America (or BBWAA), or the Veterans Committee, which now consists of four subcommittees, each of which considers and votes for candidates from a separate era of baseball. Five years after retirement, any player with 10 years of major league experience who passes a screening committee (which removes from consideration players of clearly lesser qualification) is eligible to be elected by BBWAA members with 10 years' membership or more who also have been actively covering MLB at any time in the 10 years preceding the election (the latter requirement was added for the 2016 election). From a final ballot typically including 25–40 candidates, each writer may vote for up to 10 players; until the late 1950s, voters were advised to cast votes for the maximum 10 candidates. Any player named on 75% or more of all ballots cast is elected. A player who is named on fewer than 5% of ballots is dropped from future elections. In some instances, the screening committee had restored their names to later ballots, but in the mid-1990s, dropped players were made permanently ineligible for Hall of Fame consideration, even by the Veterans Committee. A 2001 change in the election procedures restored the eligibility of these dropped players; while their names will not appear on future BBWAA ballots, they may be considered by the Veterans Committee. Players receiving 5% or more of the votes but fewer than 75% are reconsidered annually until a maximum of ten years of eligibility (lowered from fifteen years for the 2015 election).
Under special circumstances, certain players may be deemed eligible for induction even though they have not met all requirements. Addie Joss was elected in 1978, despite only playing nine seasons before he died of meningitis. Additionally, if an otherwise eligible player dies before his fifth year of retirement, then that player may be placed on the ballot at the first election at least six months after his death. Roberto Clemente's induction in 1973 set the precedent when the writers chose to put him up for consideration after his death on New Year's Eve, 1972.

The five-year waiting period was established in 1954 after an evolutionary process. In 1936 all players were eligible, including active ones. From the 1937 election until the 1945 election, there was no waiting period, so any retired player was eligible, but writers were discouraged from voting for current major leaguers. Since there was no formal rule preventing a writer from casting a ballot for an active player, the scribes did not always comply with the informal guideline; Joe DiMaggio received a vote in 1945, for example. From the 1946 election until the 1954 election, an official one-year waiting period was in effect. (DiMaggio, for example, retired after the 1951 season and was first eligible in the 1953 election.) The modern rule establishing a wait of five years was passed in 1954, although an exception was made for Joe DiMaggio because of his high level of previous support, thus permitting him to be elected within four years of his retirement.
Contrary to popular belief, no formal exception was made for Lou Gehrig (other than to hold a special one-man election for him): there was no waiting period at that time, and Gehrig met all other qualifications, so he would have been eligible for the next regular election after he retired during the 1939 season. However, the BBWAA decided to hold a special election at the 1939 Winter Meetings in Cincinnati, specifically to elect Gehrig (most likely because it was known that he was terminally ill, making it uncertain that he would live long enough to see another election). Nobody else was on that ballot, and the numerical results have never been made public. Since no elections were held in 1940 or 1941, the special election permitted Gehrig to enter the Hall while still alive.

If a player fails to be elected by the BBWAA within 10 years of his retirement from active play, he may be selected by the Veterans Committee. Following changes to the election process for that body made in 2010 and 2016, it is now responsible for electing all otherwise eligible candidates who are not eligible for the BBWAA ballot—both long-retired players and non-playing personnel (managers, umpires, and executives). From 2011 through 2016, each candidate could be considered once every three years; now, the frequency depends on the era in which an individual made his greatest contributions. A more complete discussion of the new process is available below.

From 2008 to 2010, following changes made by the Hall in July 2007, the main Veterans Committee, then made up of living Hall of Famers, voted only on players whose careers began in 1943 or later. These changes also established three separate committees to select other figures:
Players of the Negro Leagues have also been considered at various times, beginning in 1971. In 2005 the Hall completed a study on African American players between the late 19th century and the integration of the major leagues in 1947, and conducted a special election for such players in February 2006; seventeen figures from the Negro Leagues were chosen in that election, in addition to the eighteen previously selected. Following the 2010 changes, Negro Leagues figures were primarily considered for induction alongside other figures from the 1871–1946 era, called the "Pre-Integration Era" by the Hall; since 2016, Negro Leagues figures are primarily considered alongside other figures from what the Hall calls the "Early Baseball" era (1871–1949).

Predictably, the selection process catalyzes endless debate among baseball fans over the merits of various candidates. Even players elected years ago remain the subjects of discussions as to whether they deserved election. For example, Bill James' 1994 book "Whatever Happened to the Hall of Fame?" goes into detail about who he believes does and does not belong in the Hall of Fame.

Following the banning of Pete Rose from MLB, the selection rules for the Baseball Hall of Fame were modified to prevent the induction of anyone on Baseball's "permanently ineligible" list, such as Rose or "Shoeless Joe" Jackson. Many others have been barred from participation in MLB, but none have Hall of Fame qualifications on the level of Jackson or Rose.

Jackson and Rose were both banned from MLB for life for actions related to gambling on their own teams—Jackson was determined to have cooperated with those who conspired to intentionally lose the 1919 World Series, and for accepting payment for losing, and Rose voluntarily accepted a permanent spot on the ineligible list in return for MLB's promise to make no official finding in relation to alleged betting on the Cincinnati Reds when he was their manager in the 1980s. (Baseball's Rule 21, prominently posted in every clubhouse locker room, mandates permanent banishment from the MLB for having a gambling interest of any sort on a game in which a player or manager is directly involved.) Rose later admitted that he bet on the Reds in his 2004 autobiography. Baseball fans are deeply split on the issue of whether these two should remain banned or have their punishment revoked. Writer Bill James, though he advocates Rose eventually making it into the Hall of Fame, compared the people who want to put Jackson in the Hall of Fame to "those women who show up at murder trials wanting to marry the cute murderer".

The actions and composition of the Veterans Committee have been at times controversial, with occasional selections of contemporaries and teammates of the committee members over seemingly more worthy candidates.

In 2001, the Veterans Committee was reformed to comprise the living Hall of Fame members and other honorees. The revamped Committee held three elections, in 2003 and 2007, for both players and non-players, and in 2005 for players only. No individual was elected in that time, sparking criticism among some observers who expressed doubt whether the new Veterans Committee would ever elect a player. The Committee members, most of whom were Hall members, were accused of being reluctant to elect new candidates in the hope of heightening the value of their own selection. After no one was selected for the third consecutive election in 2007, Hall of Famer Mike Schmidt noted, "The same thing happens every year. The current members want to preserve the prestige as much as possible, and are unwilling to open the doors." In 2007, the committee and its selection processes were again reorganized; the main committee then included all living members of the Hall, and voted on a reduced number of candidates from among players whose careers began in 1943 or later. Separate committees, including sportswriters and broadcasters, would select umpires, managers and executives, as well as players from earlier eras.

In the first election to be held under the 2007 revisions, two managers and three executives were elected in December 2007 as part of the 2008 election process. The next Veterans Committee elections for players were held in December 2008 as part of the 2009 election process; the main committee did not select a player, while the panel for pre–World War II players elected Joe Gordon in its first and ultimately only vote. The main committee voted as part of the election process for inductions in odd-numbered years, while the pre-World War II panel would vote every five years, and the panel for umpires, managers, and executives voted as part of the election process for inductions in even-numbered years.

Further changes to the Veterans Committee process were announced by the Hall on July 26, 2010, effective with the 2011 election.

All individuals eligible for induction but not eligible for BBWAA consideration were considered on a single ballot, grouped by the following eras in which they made their greatest contributions:

The Hall used the BBWAA's Historical Overview Committee to formulate the ballots for each era, consisting of 12 individuals for the Expansion Era and 10 for the other eras. The Hall's board of directors selected a committee of 16 voters for each era, made up of Hall of Famers, executives, baseball historians, and media members. Each committee met and voted at the Baseball Winter Meetings once every three years. The Expansion Era committee held its first vote in 2010 for 2011 induction, with longtime general manager Pat Gillick becoming the first individual elected under the new procedure. The Golden Era committee voted in 2011 for the induction class of 2012, with Ron Santo becoming the first player elected under the new procedure. The Pre-Integration Era committee voted in 2012 for the induction class of 2013, electing three figures. Subsequent elections rotated among the three committees in that order through the 2016 election.

In July 2016, however, the Hall of Fame announced a restructuring of the timeframes to be considered, with a much greater emphasis on modern eras. Four new committees were established:

All committees' ballots now include 10 candidates. At least one committee convenes each December as part of the election process for the following calendar year's induction ceremony. The Early Baseball committee convenes only in years ending in 0 (2020, 2030). The Golden Days committee convenes only in years ending in 0 and 5 (2020, 2025). The remaining two committees convene twice every 5 years. More specifically, the Today's Game and Modern Baseball committees alternate their meetings in that order, skipping years in which either the Early Baseball or Golden Days committee meets. This means that the Today's Game committee (having first met in 2016) will meet in 2021, 2023 and 2026, while the Modern Baseball committee (which first met in 2017) will meet in 2019, 2022 and 2024.

The eligibility criteria for Era Committee consideration differ between players, managers, and executives.

While the text on a player's or manager's plaque lists all teams for which the inductee was a member in that specific role, inductees are usually depicted wearing the cap of a specific team, though in a few cases, like umpires, they wear caps without logos. (Executives are not depicted wearing caps.) Additionally, as of 2015, inductee biographies on the Hall's website for all players and managers, and executives who were associated with specific teams, list a "primary team", which does not necessarily match the cap logo. The Hall selects the logo "based on where that player makes his most indelible mark."

Although the Hall always made the final decision on which logo was shown, until 2001 the Hall deferred to the wishes of players or managers whose careers were linked with multiple teams. Some examples of inductees associated with multiple teams are the following:

In all of the above cases, the "primary team" is the team for which the inductee spent the largest portion of his career except for Ryan, whose primary team is listed as the Angels despite playing one fewer season for that team than for the Astros.

In 2001, the Hall of Fame decided to change the policy on cap logo selection, as a result of rumors that some teams were offering compensation, such as number retirement, money, or organizational jobs, in exchange for the cap designation. (For example, though Wade Boggs denied the claims, some media reports had said that his contract with the Tampa Bay Devil Rays required him to request depiction in the Hall of Fame as a Devil Ray.) The Hall decided that it would no longer defer to the inductee, though the player's wishes would be considered, when deciding on the logo to appear on the plaque. Newly elected members affected by the change include the following:

According to the Hall of Fame, approximately 260,000 visitors enter the museum each year, and the running total has surpassed 17 million. These visitors see only a fraction of its 40,000 artifacts, 3 million library items (such as newspaper clippings and photos) and 140,000 baseball cards.

The Hall has seen a noticeable decrease in attendance in recent years. A 2013 story on "ESPN.com" about the village of Cooperstown and its relation to the game partially linked the reduced attendance with Cooperstown Dreams Park, a youth baseball complex about away in the town of Hartwick. The 22 fields at Dreams Park currently draw 17,000 players each summer for a week of intensive play; while the complex includes housing for the players, their parents and grandparents must stay elsewhere. According to the story,Prior to Dreams Park, a room might be filled for a week by several sets of tourists. Now, that room will be taken by just one family for the week, and that family may only go into Cooperstown and the Hall of Fame once. While there are other contributing factors (the recession and high gas prices among them), the Hall's attendance has tumbled since Dreams Park opened. The Hall drew 383,000 visitors in 1999. It drew 262,000 last year.




A controversy erupted in 1982, when it emerged that some historic items given to the Hall had been sold on the collectibles market. The items had been lent to the Baseball Commissioner's office, gotten mixed up with other property owned by the Commissioner's office and employees of the office, and moved to the garage of Joe Reichler, an assistant to Commissioner Bowie Kuhn, who sold the items to resolve his personal financial difficulties. Under pressure from the New York Attorney General, the Commissioner's Office made reparations, but the negative publicity damaged the Hall of Fame's reputation, and made it more difficult for it to solicit donations.

In 2012, Congress passed and President Barack Obama signed a law ordering the United States Mint to produce and sell commemorative, non-circulating coins to benefit the private, non-profit Hall. The bill, , was introduced in the United States House of Representatives by Rep. Richard Hanna, a Republican from New York, and passed the House on October 26, 2011. The coins, which depict baseball gloves and balls, are the first concave designs produced by the Mint. The mintage included 50,000 gold coins, 400,000 silver coins, and 750,000 clad (Nickel-Copper) coins. The Mint released them on March 27, 2014, and the gold and silver editions quickly sold out. The Hall receives money from surcharges included in the sale price: a total of $9.5 million if all the coins are sold.


Notes



</doc>
<doc id="4079" url="https://en.wikipedia.org/wiki?curid=4079" title="BPP (complexity)">
BPP (complexity)

In computational complexity theory, bounded-error probabilistic polynomial time (BPP) is the class of decision problems solvable by a probabilistic Turing machine in polynomial time with an error probability bounded away from 1/3 for all instances.
BPP is one of the largest "practical" classes of problems, meaning most problems of interest in BPP have efficient probabilistic algorithms that can be run quickly on real modern machines. BPP also contains P, the class of problems solvable in polynomial time with a deterministic machine, since a deterministic machine is a special case of a probabilistic machine.

Informally, a problem is in BPP if there is an algorithm for it that has the following properties:

A language "L" is in BPP if and only if there exists a probabilistic Turing machine "M", such that
Unlike the complexity class ZPP, the machine "M" is required to run for polynomial time on all inputs, regardless of the outcome of the random coin flips.

Alternatively, BPP can be defined using only deterministic Turing machines. A language "L" is in BPP if and only if there exists a polynomial "p" and deterministic Turing machine "M", such that
In this definition, the string "y" corresponds to the output of the random coin flips that the probabilistic Turing machine would have made. For some applications this definition is preferable since it does not mention probabilistic Turing machines.

In practice, an error probability of might not be acceptable, however, the choice of in the definition is arbitrary. It can be any constant between 0 and (exclusive) and the set BPP will be unchanged. It does not even have to be constant: the same class of problems is defined by allowing error as high as − "n" on the one hand, or requiring error as small as 2 on the other hand, where "c" is any positive constant, and "n" is the length of input. The idea is that there is a probability of error, but if the algorithm is run many times, the chance that the majority of the runs are wrong drops off exponentially as a consequence of the Chernoff bound. This makes it possible to create a highly accurate algorithm by merely running the algorithm several times and taking a "majority vote" of the answers. For example, if one defined the class with the restriction that the algorithm can be wrong with probability at most , this would result in the same class of problems.

All problems in P are obviously also in BPP. However, many problems have been known to be in BPP but not known to be in P. The number of such problems is decreasing, and it is conjectured that P = BPP.

For a long time, one of the most famous problems known to be in BPP but not known to be in P was the problem of determining whether a given number is prime. However, in the 2002 paper "PRIMES is in P", Manindra Agrawal and his students Neeraj Kayal and Nitin Saxena found a deterministic polynomial-time algorithm for this problem, thus showing that it is in P.

An important example of a problem in BPP (in fact in co-RP) still not known to be in P is polynomial identity testing, the problem of determining whether a polynomial is identically equal to the zero polynomial, when you have access to the value of the polynomial for any given input, but not to the coefficients. In other words, is there an assignment of values to the variables such that when a nonzero polynomial is evaluated on these values, the result is nonzero? It suffices to choose each variable's value uniformly at random from a finite subset of at least "d" values to achieve bounded error probability, where "d" is the total degree of the polynomial.

If the access to randomness is removed from the definition of BPP, we get the complexity class P. In the definition of the class, if we replace the ordinary Turing machine with a quantum computer, we get the class BQP.

Adding postselection to BPP, or allowing computation paths to have different lengths, gives the class BPP. BPP is known to contain NP, and it is contained in its quantum counterpart PostBQP.

A Monte Carlo algorithm is a randomized algorithm which is likely to be correct. Problems in the class BPP have Monte Carlo algorithms with polynomial bounded running time. This is compared to a Las Vegas algorithm which is a randomized algorithm which either outputs the correct answer, or outputs "fail" with low probability. Las Vegas algorithms with polynomial bound running times are used to define the class ZPP. Alternatively, ZPP contains probabilistic algorithms that are always correct and have expected polynomial running time. This is weaker than saying it is a polynomial time algorithm, since it may run for super-polynomial time, but with very low probability.

It is known that BPP is closed under complement; that is, BPP = co-BPP. BPP is low for itself, meaning that a BPP machine with the power to solve BPP problems instantly (a BPP oracle machine) is not any more powerful than the machine without this extra power. In symbols, BPP = BPP.

The relationship between BPP and NP is unknown: it is not known whether BPP is a subset of NP, NP is a subset of BPP or neither. If NP is contained in BPP, which is considered unlikely since it would imply practical solutions for NP-complete problems, then NP = RP and PH ⊆ BPP.

It is known that RP is a subset of BPP, and BPP is a subset of PP. It is not known whether those two are strict subsets, since we don't even know if P is a strict subset of PSPACE. BPP is contained in the second level of the polynomial hierarchy and therefore it is contained in PH. More precisely, the Sipser–Lautemann theorem states that formula_1. As a result, P = NP leads to P = BPP since PH collapses to P in this case. Thus either P = BPP or P ≠ NP or both.

Adleman's theorem states that membership in any language in BPP can be determined by a family of polynomial-size Boolean circuits, which means BPP is contained in P/poly. Indeed, as a consequence of the proof of this fact, every BPP algorithm operating on inputs of bounded length can be derandomized into a deterministic algorithm using a fixed string of random bits. Finding this string may be expensive, however.
Some weak separation results for Monte Carlo time classes were proven by , see also 

The class BPP is closed under complementation, union and intersection.

Relative to oracles, we know that there exist oracles A and B, such that P = BPP and P ≠ BPP. Moreover, relative to a random oracle with probability 1, P = BPP and BPP is strictly contained in NP and co-NP.

There is even an oracle in which BPP=EXP (and hence P<NP<BPP=EXP=NEXP), which can be iteratively constructed as follows. For a fixed E (relativized) complete problem, the oracle will give correct answers with high probability if queried with the problem instance followed by a random string of length "kn" ("n" is instance length; "k" is an appropriate small constant). Start with "n"=1. For every instance of the problem of length "n" fix oracle answers (see lemma below) to fix the instance output. Next, provide the instance outputs for queries consisting of the instance followed by "kn"-length string, and then treat output for queries of length ≤("k"+1)"n" as fixed, and proceed with instances of length "n"+1.

Lemma: Given a problem (specifically, an oracle machine code and time constraint) in relativized E, for every partially constructed oracle and input of length "n", the output can be fixed by specifying 2 oracle answers.
Proof: The machine is simulated, and the oracle answers (that are not already fixed) are fixed step-by-step. There is at most one oracle query per deterministic computation step. For the relativized NP oracle, if possible fix the output to be yes by choosing a computation path and fixing the answers of the base oracle; otherwise no fixing is necessary, and either way there is at most 1 answer of the base oracle per step. Since there are 2 steps, the lemma follows.

The lemma ensures that (for a large enough "k"), it is possible to do the construction while leaving enough strings for the relativized E answers. Also, we can ensure that for the relativized E, linear time suffices, even for function problems (if given a function oracle and linear output size) and with exponentially small (with linear exponent) error probability. Also, this construction is effective in that given an arbitrary oracle A we can arrange the oracle B to have P≤P and EXP=EXP=BPP. Also, for a ZPP=EXP oracle (and hence ZPP=BPP=EXP<NEXP), one would fix the answers in the relativized E computation to a special nonanswer, thus ensuring that no fake answers are given.

The existence of certain strong pseudorandom number generators is conjectured by most experts of the field. This conjecture implies that randomness does not give additional computational power to polynomial time computation, that is, P = RP = BPP. Note that ordinary generators are not sufficient to show this result; any probabilistic algorithm implemented using a typical random number generator will always produce incorrect results on certain inputs irrespective of the seed (though these inputs might be rare).

László Babai, Lance Fortnow, Noam Nisan, and Avi Wigderson showed that unless EXPTIME collapses to MA, BPP is contained in 
The class i.o.-SUBEXP, which stands for infinitely often SUBEXP, contains problems which have sub-exponential time algorithms for infinitely many input sizes. They also showed that P = BPP if the exponential-time hierarchy, which is defined in terms of the polynomial hierarchy and E as E, collapses to E; however, note that the exponential-time hierarchy is usually conjectured "not" to collapse.

Russell Impagliazzo and Avi Wigderson showed that if any problem in E, where 
has circuit complexity 2 then P = BPP.





</doc>
<doc id="4080" url="https://en.wikipedia.org/wiki?curid=4080" title="BQP">
BQP

In computational complexity theory, bounded-error quantum polynomial time (BQP) is the class of decision problems solvable by a quantum computer in polynomial time, with an error probability of at most 1/3 for all instances. It is the quantum analogue of the complexity class BPP.

A decision problem is a member of BQP if there exists a quantum algorithm (an algorithm that runs on a quantum computer) that solves the decision problem with high probability and is guaranteed to run in polynomial time. A run of the algorithm will correctly solve the decision problem with a probability of at least 2/3.

BQP can be viewed as the languages associated with certain bounded-error uniform families of quantum circuits. A language "L" is in BQP if and only if there exists a polynomial-time uniform family of quantum circuits formula_1, such that

Alternatively, one can define BQP in terms of quantum Turing machines. A language "L" is in BQP if and only if there exists a polynomial quantum Turing machine that accepts "L" with an error probability of at most 1/3 for all instances.

Similarly to other "bounded error" probabilistic classes the choice of 1/3 in the definition is arbitrary. We can run the algorithm a constant number of times and take a majority vote to achieve any desired probability of correctness less than 1, using the Chernoff bound. The complexity class is unchanged by allowing error as high as 1/2 − "n" on the one hand, or requiring error as small as 2 on the other hand, where "c" is any positive constant, and "n" is the length of input.

The number of qubits in the computer is allowed to be a polynomial function of the instance size. For example, algorithms are known for factoring an "n"-bit integer using just over 2"n" qubits (Shor's algorithm).

Usually, computation on a quantum computer ends with a measurement. This leads to a collapse of quantum state to one of the basis states. It can be said that the quantum state is measured to be in the correct state with high probability.

Quantum computers have gained widespread interest because some problems of practical interest are known to be in BQP, but suspected to be outside P. Some prominent examples are:

This class is defined for a quantum computer and its natural corresponding class for an ordinary computer (or a Turing machine plus a source of randomness) is BPP. Just like P and BPP, BQP is low for itself, which means BQP = BQP. Informally, this is true because polynomial time algorithms are closed under composition. If a polynomial time algorithm calls as a subroutine polynomially many polynomial time algorithms, the resulting algorithm is still polynomial time.

BQP contains P and BPP and is contained in AWPP, PP and PSPACE.
In fact, BQP is low for PP, meaning that a PP machine achieves no benefit from being able to solve BQP problems instantly, an indication of the possible difference in power between these similar classes. The known relationships with classic complexity classes are:

As the problem of P ≟ PSPACE has not yet been solved, the proof of inequality between BQP and classes mentioned above is supposed to be difficult. The relation between BQP and NP is not known. In May 2018, computer scientists Ran Raz of Princeton University and Avishay Tal of Stanford University published a paper which showed that, relative to an oracle, BQP was not contained in PH.

Adding postselection to BQP results in the complexity class PostBQP which is equal to PP.




</doc>
<doc id="4081" url="https://en.wikipedia.org/wiki?curid=4081" title="Blade Runner 3: Replicant Night">
Blade Runner 3: Replicant Night

Blade Runner 3: Replicant Night is a science fiction novel by American writer K. W. Jeter published in 1996. It is a continuation of Jeter's novel "", which was itself a sequel to both the film "Blade Runner" and the novel upon which the film was based, Philip K. Dick's "Do Androids Dream of Electric Sheep?"

Living on Mars, Deckard is acting as a consultant to a movie crew filming the story of his days as a blade runner. He finds himself drawn into a mission on behalf of the replicants he was once assigned to kill. Meanwhile, the mystery surrounding the beginnings of the Tyrell Corporation is being exposed.


The plot element of a replicant giving birth served as the basis for the 2017 film "Blade Runner 2049".



</doc>
<doc id="4082" url="https://en.wikipedia.org/wiki?curid=4082" title="Blade Runner 2: The Edge of Human">
Blade Runner 2: The Edge of Human

Blade Runner 2: The Edge of Human (1995) is a science fiction novel by American writer K. W. Jeter. It is a continuation of both the film "Blade Runner" and the novel upon which the film was based, Philip K. Dick's "Do Androids Dream of Electric Sheep?"

Several months after the events depicted in "Blade Runner", Deckard has retired to an isolated shack outside the city, taking the replicant Rachael with him in a Tyrell transport container, which slows down the replicant aging process. He is approached by a woman who explains she is Sarah Tyrell, niece of Eldon Tyrell, heiress to the Tyrell Corporation and the human template ("templant") for the Rachael replicant. She asks Deckard to hunt down the "missing" sixth replicant. At the same time, the templant for Roy Batty hires Dave Holden, the blade runner attacked by Leon, to help him hunt down the man he believes is the sixth replicant—Deckard.

Deckard and Holden's investigations lead them to re-visit Sebastian, Bryant, and John Isidore (from the book "Do Androids Dream Of Electric Sheep?"), learning more about the nature of the blade runners and the replicants.

When Deckard, Batty, and Holden finally clash, Batty's super-human fighting prowess leads Holden to believe he has been duped all along and that Batty is the sixth replicant. He shoots him. Deckard returns to Sarah with his suspicion: there is "no" sixth replicant. Sarah, speaking via a remote camera, confesses that she invented and maintained the rumor herself in order to deliberately discredit and eventually destroy the Tyrell Corporation because her uncle Eldon had based Rachel on her and then abandoned the real Sarah. Sarah brings Rachael back to the Corporation to meet with Deckard, and they escape.

However, Holden, recovering from his injuries during the fight, later uncovers the truth: Rachael has been killed by Tyrell agents, and the "Rachael" who escaped with Deckard was actually Sarah. She has completed her revenge by both destroying Tyrell and taking back Rachael's place.


The book's plot draws from other material related to "Blade Runner" in a number of ways:

However, it also contradicts material in some ways:

Michael Giltz of "Entertainment Weekly" gave the book a "C-", feeling that "only hardcore fans will be satisfied by this tale" and saying that Jeter's "habit of echoing dialogue and scenes from the film is annoying and begs comparisons he would do well to avoid." Tal Cohen of "Tal Cohen's Bookshelf" called "The Edge of Human" "a good book", praising Jeter's "further, and deeper, investigation of the questions Philip K. Dick originally asked", but criticized the book for its "needless grandioseness" and for "rel[ying] on "Blade Runner" too heavily, [as] the number of new characters introduced is extremely small..."

Ian Kaplan of BearCave.com gave the book three stars out of five, saying that while he was "not entirely satisfied" and felt that the "story tends to be shallow", "Jeter does deal with the moral dilemma of the Blade Runners who hunt down beings that are virtually human in every way." J. Patton of "The Bent Cover" praised Jeter for "[not] try[ing] to emulate Philip K. Dick", adding, "This book also has all the grittiness and dark edges that the movie showed off so well, along with a very fast pace that will keep you reading into the wee hours of the night."

In the late 1990s, "Edge of Human" had been adapted into a screenplay by Stuart Hazeldine, "Blade Runner Down", that was to be filmed as the sequel to the 1982 film "Blade Runner".

Ultimately neither this script nor the Jeter novel was used for the eventual sequel, "Blade Runner 2049", which uses a different story.



</doc>
<doc id="4086" url="https://en.wikipedia.org/wiki?curid=4086" title="Brainfuck">
Brainfuck

Brainfuck is an esoteric programming language created in 1993 by Urban Müller, and is notable for its extreme minimalism.

The language consists of only eight simple commands and an instruction pointer. While it is fully Turing complete, it is not intended for practical use, but to challenge and amuse programmers. Brainfuck simply requires one to break commands into microscopic steps.

The language's name is a reference to the slang term "brainfuck", which refers to things so complicated or unusual that they exceed the limits of one's understanding.
In 1992, Urban Müller, a Swiss physics student, took over a small online archive for Amiga software. The archive grew more popular, and was soon mirrored around the world. Today, it is the world's largest Amiga archive, known as Aminet.

Müller designed Brainfuck with the goal of implementing it with the smallest possible compiler, inspired by the 1024-byte compiler for the FALSE programming language. Müller's original compiler was implemented in machine language and compiled to a binary with a size of 296 bytes. He uploaded the first Brainfuck compiler to Aminet in 1993. The program came with a "Readme" file, which briefly described the language, and challenged the reader "Who can program anything useful with it? :)". Müller also included an interpreter and some quite elaborate examples. A second version of the compiler used only 240 bytes.

As Aminet grew, the compiler became popular among the Amiga community, and in time it was implemented for other platforms. Several brainfuck compilers have been made smaller than 200 bytes, and one is only 100 bytes.

Except for its two I/O commands, Brainfuck is a minor variation of the formal programming language P′′ created by Corrado Böhm in 1964, which in turn is explicitly based on the Turing machine. In fact, using six symbols equivalent to the respective Brainfuck commands codice_1, codice_2, codice_3, codice_4, codice_5, codice_6, Böhm provided an explicit program for each of the basic functions that together serve to compute any computable function. So the first "Brainfuck" programs appear in Böhm's 1964 paper – and they were programs sufficient to prove Turing completeness.

A version with explicit memory addressing rather without stack and a conditional jump was introduced by Joachim Lambek in 1961 under the name of the Infinite Abacus, consisting of an infinite number of cells and two instructions:
He proves the Infinite Abacus can compute any computable recursive function by programming Kleene set of basic μ-recursive function.

His machine was simulated by Melzac's machine modeling computation via arithmetic rather than logic mimicking a human operator moving pebbles on an abacus, hence the requirement that all numbers must be positive. Melzac, whose one instruction set computer is equivalent to an Infinite Abacus, gives programs for multiplication, gcd, n prime number, representation in base b, sorting by magnitude, and shows how to simulate an arbitrary Turing machine.

The language consists of eight commands, listed below. A brainfuck program is a sequence of these commands, possibly interspersed with other characters (which are ignored). The commands are executed sequentially, with some exceptions: an instruction pointer begins at the first command, and each command it points to is executed, after which it normally moves forward to the next command. The program terminates when the instruction pointer moves past the last command.

The brainfuck language uses a simple machine model consisting of the program and instruction pointer, as well as an array of at least 30,000 byte cells initialized to zero; a movable data pointer (initialized to point to the leftmost byte of the array); and two streams of bytes for input and output (most often connected to a keyboard and a monitor respectively, and using the ASCII character encoding).

The eight language commands each consist of a single character:

codice_5 and codice_6 match as parentheses usually do: each codice_5 matches exactly one codice_6 and vice versa, the codice_5 comes first, and there can be no unmatched codice_5 or codice_6 between the two.

Brainfuck programs can be translated into C using the following substitutions, assuming codice_18 is of type codice_19 and has been initialized to point to an array of zeroed bytes:
As the name suggests, Brainfuck programs tend to be difficult to comprehend. This is partly because any mildly complex task requires a long sequence of commands, and partly it is because the program's text gives no direct indications of the program's state. These, as well as Brainfuck's inefficiency and its limited input/output capabilities, are some of the reasons it is not used for serious programming. Nonetheless, like any Turing complete language, Brainfuck is theoretically capable of computing any computable function or simulating any other computational model, if given access to an unlimited amount of memory. A variety of Brainfuck programs have been written. Although Brainfuck programs, especially complicated ones, are difficult to write, it is quite trivial to write an interpreter for Brainfuck in a more typical language such as C due to its simplicity. There even exist Brainfuck interpreters written in the Brainfuck language itself.

Brainfuck is an example of a so-called Turing tarpit: It can be used to write "any" program, but it is not practical to do so, because Brainfuck provides so little abstraction that the programs get very long or complicated.

As a first, simple example, the following code snippet will add the current cell's value to the next cell: Each time the loop is executed, the current cell is decremented, the data pointer moves to the right, that next cell is incremented, and the data pointer moves left again. This sequence is repeated until the starting cell is 0.

This can be incorporated into a simple addition program as follows:

The following program prints "Hello World!" and a newline to the screen:

For "readability", this code has been spread across many lines, and blanks and comments have been added. Brainfuck ignores all characters except the eight commands codice_20 so no special syntax for comments is needed (as long as the comments do not contain the command characters). The code could just as well have been written as:
This program enciphers its input with the ROT13 cipher. To do this, it must map characters A-M (ASCII 65-77) to N-Z (78-90), and vice versa. Also it must map a-m (97-109) to n-z (110-122) and vice versa. It must map all other characters to themselves; it reads characters one at a time and outputs their enciphered equivalents until it reads an EOF (here assumed to be represented as either -1 or "no change"), at which point the program terminates.

The basic approach used is as follows. Calling the input character "x", divide "x"-1 by 32, keeping quotient and remainder. Unless the quotient is 2 or 3, just output "x", having kept a copy of it during the division. If the quotient is 2 or 3, divide the remainder (("x"-1) modulo 32) by 13; if the quotient here is 0, output "x"+13; if 1, output "x"-13; if 2, output "x".

Regarding the division algorithm, when dividing "y" by "z" to get a quotient "q" and remainder "r", there is an outer loop which sets "q" and "r" first to the quotient and remainder of 1/"z", then to those of 2/"z", and so on; after it has executed "y" times, this outer loop terminates, leaving "q" and "r" set to the quotient and remainder of "y"/"z". (The dividend "y" is used as a diminishing counter that controls how many times this loop is executed.) Within the loop, there is code to increment "r" and decrement "y", which is usually sufficient; however, every "z"th time through the outer loop, it is necessary to zero "r" and increment "q". This is done with a diminishing counter set to the divisor "z"; each time through the outer loop, this counter is decremented, and when it reaches zero, it is refilled by moving the value from "r" back into it.

Partly because Urban Müller did not write a thorough language specification, the many subsequent brainfuck interpreters and compilers have come to use slightly different dialects of brainfuck.

In the classic distribution, the cells are of 8-bit size (cells are bytes), and this is still the most common size. However, to read non-textual data, a brainfuck program may need to distinguish an end-of-file condition from any possible byte value; thus 16-bit cells have also been used. Some implementations have used 32-bit cells, 64-bit cells, or bignum cells with practically unlimited range, but programs that use this extra range are likely to be slow, since storing the value formula_1 into a cell requires formula_2 time as a cell's value may only be changed by incrementing and decrementing.

In all these variants, the codice_21 and codice_22 commands still read and write data in bytes. In most of them, the cells wrap around, i.e. incrementing a cell which holds its maximal value (with the codice_1 command) will bring it to its minimal value and vice versa. The exceptions are implementations which are distant from the underlying hardware, implementations that use bignums, and implementations that try to enforce portability.

It is usually easy to write brainfuck programs that do not ever cause integer wraparound or overflow, and therefore don't depend on cell size. Generally this means avoiding increment of +255 (unsigned 8-bit wraparound), or avoiding overstepping the boundaries of [-128, +127] (signed 8-bit wraparound) (since there are no comparison operators, a program cannot distinguish between a signed and unsigned two's complement fixed-bit-size cell and negativeness of numbers is a matter of interpretation). For more details on integer wraparound, see the Integer overflow article.

In the classic distribution, the array has 30,000 cells, and the pointer begins at the leftmost cell. Even more cells are needed to store things like the millionth Fibonacci number, and the easiest way to make the language Turing complete is to make the array unlimited on the right.

A few implementations extend the array to the left as well; this is an uncommon feature, and therefore portable brainfuck programs do not depend on it.

When the pointer moves outside the bounds of the array, some implementations will give an error message, some will try to extend the array dynamically, some will not notice and will produce undefined behavior, and a few will move the pointer to the opposite end of the array. Some tradeoffs are involved: expanding the array dynamically to the right is the most user-friendly approach and is good for memory-hungry programs, but it carries a speed penalty. If a fixed-size array is used it is helpful to make it very large, or better yet let the user set the size. Giving an error message for bounds violations is very useful for debugging but even that carries a speed penalty unless it can be handled by the operating system's memory protections.

Different operating systems (and sometimes different programming environments) use subtly different versions of ASCII. The most important difference is in the code used for the end of a line of text. MS-DOS and Microsoft Windows use a CRLF, i.e. a 13 followed by a 10, in most contexts. UNIX and its descendants (including GNU/Linux and Mac OS X) and Amigas use just 10, and older Macs use just 13. It would be difficult if brainfuck programs had to be rewritten for different operating systems. However, a unified standard was easy to create. Urban Müller's compiler and his example programs use 10, on both input and output; so do a large majority of existing brainfuck programs; and 10 is also more convenient to use than CRLF. Thus, brainfuck implementations should make sure that brainfuck programs that assume newline = 10 will run properly; many do so, but some do not.

This assumption is also consistent with most of the world's sample code for C and other languages, in that they use '\n', or 10, for their newlines. On systems that use CRLF line endings, the C standard library transparently remaps "\n" to "\r\n" on output and "\r\n" to "\n" on input for streams not opened in binary mode.

The behavior of the codice_21 command when an end-of-file condition has been encountered varies. Some implementations set the cell at the pointer to 0, some set it to the C constant EOF (in practice this is usually -1), some leave the cell's value unchanged. There is no real consensus; arguments for the three behaviors are as follows.

Setting the cell to 0 avoids the use of negative numbers, and makes it marginally more concise to write a loop that reads characters until EOF occurs. This is a language extension devised by Panu Kalliokoski.

Setting the cell to -1 allows EOF to be distinguished from any byte value (if the cells are larger than bytes), which is necessary for reading non-textual data; also, it is the behavior of the C translation of codice_21 given in Müller's readme file. However, it is not obvious that those C translations are to be taken as normative.

Leaving the cell's value unchanged is the behavior of Urban Müller's brainfuck compiler. This behavior can easily coexist with either of the others; for instance, a program that assumes EOF = 0 can set the cell to 0 before each codice_21 command, and will then work correctly on implementations that do either EOF = 0 or EOF = "no change". It is so easy to accommodate the "no change" behavior that any brainfuck programmer interested in portability should do so.

Tyler Holewinski developed a C# .NET Framework, BrainF.NET, which by default runs brainfuck, but can also be used to derive various forms of the language, as well as add new commands, or modify the behavior of existing ones. BrainF.NET thereby allows for development of programs such as an IDE.

Many people have created brainfuck equivalents (languages with commands that directly map to brainfuck) or brainfuck derivatives (languages that extend its behavior or map it into new semantic territory).

Some examples:




</doc>
<doc id="4091" url="https://en.wikipedia.org/wiki?curid=4091" title="Bartolomeo Ammannati">
Bartolomeo Ammannati

Bartolomeo Ammannati (18 June 151113 April 1592) was an Italian architect and sculptor, born at Settignano, near Florence. He studied under Baccio Bandinelli and Jacopo Sansovino (assisting on the design of the Library of St. Mark's, the "Biblioteca Marciana", Venice) and closely imitated the style of Michelangelo.

He was more distinguished in architecture than in sculpture. He worked in Rome in collaboration with Vignola and Vasari), including designs for the Villa Giulia, but also for works and at Lucca. He labored during 1558–1570, in the refurbishment and enlargement of Pitti Palace, creating the courtyard consisting of three wings with rusticated facades, and one lower portico leading to the amphitheatre in the Boboli Gardens. His design mirrored the appearance of the main external façade of Pitti. He was also named "Consul" of Accademia delle Arti del Disegno of Florence, which had been founded by the Duke Cosimo I in 1563.
In 1569, Ammanati was commissioned to build the Ponte Santa Trinita, a bridge over the Arno River. The three arches are elliptic, and though very light and elegant, has survived, when floods had damaged other Arno bridges at different times. Santa Trinita was destroyed in 1944, during World War II, and rebuilt in 1957.

Ammannati designed what is considered a prototypic mannerist sculptural ensemble in the "Fountain of Neptune" ("Fontana del Nettuno"), prominently located in the Piazza della Signoria in the center of Florence. The assignment was originally given to the aged Bartolommeo Bandinelli; however when Bandinelli died, Ammannati's design, bested the submissions of Benvenuto Cellini and Vincenzo Danti, to gain the commission. From 1563 and 1565, Ammannati and his assistants, among them Giambologna, sculpted the block of marble that had been chosen by Bandinelli. He took Grand Duke Cosimo I as model for Neptune's face. The statue was meant to highlight Cosimo's goal of establishing a Florentine Naval force. The ungainly sea god was placed at the corner of the Palazzo Vecchio within sight of Michelangelo’s David statue, and the then 87-year-old sculptor is said to have scoffed at Ammannati— saying that he had ruined a beautiful piece of marble— with the ditty: "Ammannati, Ammanato, che bel marmo hai rovinato!" Ammannati continued work on this fountain for a decade, adding around the perimeter a cornucopia of demigod figures: bronze reclining river gods, laughing satyrs and marble sea horses emerging from the water. 

In 1550 Ammannati married Laura Battiferri, an elegant poet and an accomplished woman. Later in his life he had a religious crisis, influenced by Counter-Reformation piety, which resulted in condemning his own works depicting nudity, and he left all his possessions to the Jesuits.

He died in Florence in 1592.




</doc>
