<doc id="11701" url="https://en.wikipedia.org/wiki?curid=11701" title="Full Metal Jacket">
Full Metal Jacket

Full Metal Jacket is a 1987 war film directed, co-written, and produced by Stanley Kubrick and starring Matthew Modine, R. Lee Ermey, Vincent D'Onofrio and Adam Baldwin. The screenplay by Kubrick, Michael Herr, and Gustav Hasford was based on Hasford's novel "The Short-Timers" (1979). The storyline follows a platoon of U.S. Marines through their boot camp training in Marine Corps Recruit Depot Parris Island, South Carolina, primarily focusing on two privates, Joker and Pyle, who struggle under their abusive drill instructor, Gunnery Sergeant Hartman, and the experiences of two of the platoon's Marines in Vietnamese cities of Da Nang and Huế during the Tet Offensive of the Vietnam War. The film's title refers to the full metal jacket bullet used by military servicemen. The film was released in the United States on June 26, 1987.

"Full Metal Jacket" received critical acclaim and an Oscar nomination for Best Adapted Screenplay for Kubrick, Herr, and Hasford. In 2001, the American Film Institute placed it at No. 95 in their "AFI's 100 Years...100 Thrills" poll.

During the United States' involvement in the Vietnam War, a group of boot camp recruits arrive at Parris Island. The ruthless drill instructor, Hartman, employs forceful methods to turn the recruits into combat-ready Marines. Among the recruits is the overweight and dim-witted Leonard Lawrence, whom Hartman nicknames "Gomer Pyle", as well as the wisecracking J.T. Davis, who receives the name "Joker" after interrupting Hartman's speech with an impression of John Wayne.

Private Pyle is initially inept at basic training and is the focus of Hartman's brutality, but he slowly improves after being paired with Joker. However, when Hartman discovers a contraband jelly doughnut in Pyle's unlocked foot locker, he adopts a collective punishment policy: he will punish the entire platoon for every mistake Pyle makes. One night, the recruits haze Pyle with a blanket party in which Joker reluctantly participates. Following this, Pyle seems to reinvent himself as a model recruit, showing particular expertise in marksmanship, though with frightening stress marked by facial expressions, rather than confidence. This impresses Hartman but worries Joker, who notices Pyle talking to his rifle and believes he may be suffering a mental breakdown.

The recruits graduate and receive their Military Occupational Specialty assignments. Joker is assigned to Military Journalism, while most of the others – including Pyle – are assigned to Infantry. During the platoon's final night on Parris Island, Joker discovers Pyle in the head loading his rifle and executing drill commands, and loudly recites the Rifleman's Creed. Gradually the other recruits wake up, including Hartman, who storms in, insults Pyle, and orders him to surrender the rifle. Pyle instead shoots Hartman dead and then kills himself with a shot in the mouth, while Joker helplessly watches in horror.

In January 1968, Joker – now a sergeant – is a war correspondent in Da Nang, South Vietnam for "Stars and Stripes" with Private First Class Rafterman, a combat photographer. Rafterman wants to go into combat, as Joker claims he has. At the Marine base, Joker is mocked for his lack of the thousand-yard stare, indicating his lack of war experience. They are interrupted by the start of the Tet Offensive as the North Vietnamese Army unsuccessfully attempts to overrun the base.

The following day, the journalism staff is briefed about enemy attacks throughout South Vietnam. Joker is sent to Phu Bai, accompanied by Rafterman. They meet the Lusthog Squad, where Joker is reunited with Cowboy. Joker accompanies the squad during the Battle of Huế, where platoon commander "Touchdown" is killed by the enemy. After the Marines declare the area secure, a team of American news journalists and reporters enters Huế to interview various Marines about their experiences in Vietnam and their opinions about the war.

While patrolling Huế, Crazy Earl, the squad leader, is killed by a booby trap, leaving Cowboy in command. The squad becomes lost, and Cowboy orders Eightball to scout the area. A Viet Cong sniper wounds Eightball and Doc Jay, the squad Corpsman. Believing that the sniper is drawing the squad into an ambush, Cowboy attempts to radio in tank support to no avail. The squad's machine gunner, Animal Mother, disobeys Cowboy's orders to retreat and attempts to save his comrades. He discovers there is only one sniper, but Doc Jay and Eightball are killed when Doc Jay attempts to indicate the sniper's location. While maneuvering toward the sniper, Cowboy is shot and killed.

Animal Mother assumes command of the squad and leads an attack on the sniper. Joker discovers the sniper, a teenage girl, and attempts to shoot her, but his rifle jams and alerts her to his presence. Rafterman shoots the sniper, mortally wounding her. As the squad converges, the sniper first prays and then begs for death, prompting an argument about whether to kill her or leave her to suffer. Animal Mother decides to allow a mercy killing only if Joker performs it. After some hesitation, Joker shoots her. The Marines congratulate him on his kill as Joker stares into the distance. The Marines march toward their camp, singing the "Mickey Mouse March". Joker states in narration that despite being "in a world of shit", he is glad to be alive and is no longer afraid.


Additional characters include: Peter Edmund as Private "Snowball" Brown, one of the Parris Island recruits; Ed O'Ross as Lieutenant Walter J. "Touchdown" Schinoski, the first platoon leader of the Lusthog Squad; John Terry as Lieutenant Lockhart, the editor of "Stars and Stripes"; Kieron Jecchinis as Crazy Earl, a member and also a former leader of the Lusthog Squad who assumes leadership after Touchdown is killed; Jon Stafford as Doc Jay, head medic of the Lusthog Squad and Bruce Boa as Poge Colonel, the colonel who dresses down Joker for wearing a peace symbol on his lapel.

Ian Tyler plays Lieutenant Cleves, a Marine interviewed by Joker and Rafterman at a Vietnamese murder site; Sal Lopez and Gary Landon Mills appear as T. H. E. Rock and Donlon respectively, two members of the Lusthog Squad; Papillon Soo Soo plays a Da Nang hooker and Ngoc Le appears as the Viet Cong sniper. Stanley Kubrick and his daughter Vivian make uncredited appearances as two photographers at a Vietnam massacre site.

Kubrick contacted Michael Herr, author of the Vietnam War memoir "Dispatches" (1977), in the spring of 1980 to discuss working on a film about the Holocaust, but he eventually discarded that in favor of a film about the Vietnam War. They met in England, and the director told Herr that he wanted to do a war film but had yet to find a story to adapt. Kubrick discovered Gustav Hasford's novel "The Short-Timers" (1979) while reading the "Virginia Kirkus Review." Herr received it in bound galleys and thought that it was a masterpiece. In 1982, Kubrick read the novel twice, concluding that it "was a unique, absolutely wonderful book", and decided, along with Herr, to adapt it for his next film. According to Kubrick, he was drawn to the book's dialogue, finding it "almost poetic in its carved-out, stark quality". In 1983, Kubrick began conducting research for the film, watching past footage and documentaries, reading Vietnamese newspapers on microfilm from the Library of Congress, and studying hundreds of photographs from the era. Initially, Herr was not interested in revisiting his Vietnam War experiences, and Kubrick spent three years persuading him to participate in what the author describes as "a single phone call lasting three years, with interruptions".

In 1985, Kubrick contacted Hasford to work on the screenplay with him and Herr, and often talked to Hasford on the phone three to four times a week, for hours at a time. Kubrick had already written a detailed treatment, and Kubrick and Herr got together at Kubrick's home every day, breaking down the treatment into scenes. From that, Herr wrote the first draft. The filmmaker worried that the book's title might be misread by audiences as referring to people who only did half a day's work and changed it to "Full Metal Jacket" after discovering the phrase while going through a gun catalogue. After the first draft was completed, Kubrick phoned his orders to Hasford and Herr, and Hasford and Herr mailed their submissions to him. Kubrick read and edited them, and then the team repeated the process. Neither Hasford nor Herr knew how much he had contributed to the screenplay, which led to a dispute over the final credits. Hasford remembers, "We were like guys on an assembly line in the car factory. I was putting on one widget and Michael was putting on another widget and Stanley was the only one who knew that this was going to end up being a car." Herr says the director was not interested in making an anti-war film, but "he wanted to show what war is like".

At some point, Kubrick wanted to meet Hasford in person, but Herr advised against this, describing "The Short-Timers" author as a "scary man" and believing he and Kubrick would not "get on". Nonetheless, Kubrick insisted, and they all met at Kubrick's house in England for dinner. It did not go well, and Hasford did not meet with Kubrick again.

Through Warner Bros., Kubrick advertised a national casting search in the United States and Canada. The director used videotape to audition actors and received over 3,000 submissions. His staff screened all of the tapes, leaving 800 of them for Kubrick to review personally.

Former U.S. Marine Drill Instructor Ermey, originally hired as a technical advisor, asked Kubrick if he could audition for the role of Hartman. Kubrick had seen Ermey's portrayal of drill instructor Staff Sergeant Loyce in "The Boys in Company C" (1978) and told the Marine that he was not vicious enough to play the character. Ermey improvised insulting dialogue against a group of Royal Marines who were being considered for the part of background Marines, to demonstrate his ability to play the character, as well as to show how a drill instructor goes about breaking down the individuality of new recruits. Upon viewing the videotape of these sessions, Kubrick gave Ermey the role, realizing he "was a genius for this part". Kubrick also incorporated the 250-page transcript of Ermey's rants into the script. Ermey's experience as a drill instructor during the Vietnam era proved invaluable. Kubrick estimated that Ermey wrote 50% of his own dialogue, especially the insults.

While Ermey practiced his lines in a rehearsal room, Kubrick's assistant Leon Vitali would throw tennis balls and oranges at him. Ermey had to catch the ball and throw it back as quickly as possible, while at the same time saying his lines as fast as he could. Any hesitation, slur, or missed line would necessitate starting over. Twenty error-free runs were required. "[He] was my drill instructor", Ermey said of Vitali.

The original casting plan envisaged Anthony Michael Hall starring as Private Joker. After eight months of negotiations, a deal between Kubrick and Hall fell through. Kubrick offered Bruce Willis a role, but the actor had to turn it down because he was to start filming of the first six episodes of his TV series "Moonlighting".

Kubrick shot the film in England: in Cambridgeshire, on the Norfolk Broads, and at the former Millennium Mills, Beckton Gas Works, Newham (east London) and the Isle of Dogs. A former Royal Air Force station and then British Army base, Bassingbourn Barracks doubled as the Parris Island Marine boot camp. A British Army rifle range near Barton, outside Cambridge, was used in the scene where Hartman congratulates Private Pyle for his shooting skills. Kubrick worked from still photographs of Huế, taken in 1968, and found an area owned by British Gas that closely resembled it and was scheduled to be demolished. The disused Beckton Gas Works, a few miles from central London, were filmed to represent Huế after attacks. Kubrick had buildings blown up, and the film's art director used a wrecking ball to knock specific holes in certain buildings over the course of two months. Originally, Kubrick had a plastic replica jungle flown in from California, but once he looked at it he was reported to have said, "I don't like it. Get rid of it". The open country was filmed in the Cliffe marshes, and along the River Thames, supplemented with 200 imported Spanish palm trees and 100,000 plastic tropical plants from Hong Kong.

Kubrick acquired four M41 tanks from a Belgian army colonel who was an admirer of the director's work, and Westland Wessex helicopters painted Marine green to represent Marine Corps Sikorsky H-34 Choctaw helicopters. Although the Wessex was a licensed derivative of the Sikorsky H-34, the Wessex substituted two gas turbine engines for the H-34's radial (piston) engine. This resulted in a much longer and less rounded nose than that of the Vietnam era H-34. Kubrick also obtained a selection of rifles, M79 grenade launchers, and M60 machine guns from a licensed weapons dealer.

Modine described the shoot as difficult: Beckton Gas Works was a toxic and environmental nightmare for the entire film crew. Asbestos and hundreds of other chemicals poisoned the ground and air. Modine documents details of shooting at Beckton in his book, "Full Metal Jacket Diary" (2005). During the boot camp sequence of the film, Modine and the other recruits had to endure the rigors of Marine Corps training, including having Ermey yelling at them for 10 hours a day during the shooting of the Parris Island scenes. To ensure the actors' reactions to Ermey were as authentic and fresh as possible, Ermey and the recruits did not rehearse together. For film continuity, each recruit had to have his head shaved once a week.

At one point during filming, Ermey had a car accident, broke all of his ribs on one side, and was out for four-and-half months.

Cowboy's death scene shows a building in the background that resembles the famous alien monolith in Kubrick's "" (1968). Kubrick described the resemblance as an "extraordinary accident".

During filming, Hasford contemplated taking legal action over the writing credits. Originally, the filmmakers intended for Hasford to receive an "additional dialogue" credit, but he fought for and eventually received full credit. The writer took two friends and visited the set dressed as extras, only to be mistaken by a crew member for Herr when Hasford identified himself as the writer whose work the film was based on.

Kubrick's daughter Vivian—who appears uncredited as a news-camera operator at the mass grave—shadowed the filming of "Full Metal Jacket." She shot 18 hours of behind-the-scenes footage for a potential "making-of" documentary similar to her earlier film documentary on Kubrick's "The Shining" (1980), but in this case did not make the film. Snippets of her work can be seen in the documentary "Stanley Kubrick's Boxes" (2008).

Compared to Kubrick's other works, the themes of "Full Metal Jacket" have received little attention from critics and reviewers. Michael Pursell's essay ""Full Metal Jacket": The Unravelling of Patriarchy" (1988) was an early, in-depth consideration of the film's two-part structure and its criticism of masculinity, arguing that the film shows "war and pornography as facets of the same system".

Most reviews have focused on military brainwashing themes in the boot camp training section of the film, while seeing the latter half of the film as more confusing and disjointed in content. Rita Kempley of "The Washington Post" wrote, "it's as if they borrowed bits of every war movie to make this eclectic finale." Roger Ebert said, "The movie disintegrates into a series of self-contained set pieces, none of them quite satisfying." Julian Rice, in his book "Kubrick's Hope" (2008), sees the second part of the film as continuing the psychic journey of Joker in trying to come to grips with human evil.

Tony Lucia, in his July 5, 1987, review of "Full Metal Jacket" for the "Reading Eagle", looked at the themes of Kubrick's career, suggesting "the unifying element may be the ordinary man dwarfed by situations too vast and imposing to handle". Lucia specifically refers to the "military mentality" in this film. He said further that the theme covered "a man testing himself against his own limitations", and he concluded: ""Full Metal Jacket" is the latest chapter in an ongoing movie which is not merely a comment on our time or a time past, but on something that reaches beyond."

British critic Gilbert Adair wrote: "Kubrick's approach to language has always been reductive and uncompromisingly deterministic in nature. He appears to view it as the exclusive product of environmental conditioning, only very marginally influenced by concepts of subjectivity and interiority, by all the whims, shades and modulations of personal expression".

Michael Herr wrote of his work on the screenplay: "The substance was single-minded, the old and always serious problem of how you put into a film or a book the living, behaving presence of what Jung called The Shadow, the most accessible of archetypes, and the easiest to experience ... War is the ultimate field of Shadow-activity, where all of its other activities lead you. As they expressed it in Vietnam, 'Yea, though I walk through the Valley of the Shadow of Death, I will fear no Evil, for I the Evil'."

In a 2009 review, Dan Schneider alleged that Kubrick took the cinematic idea of a recruit being broken down in boot camp and driven to suicide from the epic film series "The Human Condition" (1959–1961).

Kubrick's daughter Vivian Kubrick, under the alias "Abigail Mead", wrote the film's score. According to an interview, which appeared in the January 1988 issue of "Keyboard", the film was scored mostly with a Fairlight CMI synthesizer (the then-current Series III edition) and a Synclavier. For the period music, Kubrick went through "Billboard" list of Top 100 Hits for each year from 1962 to 1968 and tried many songs, but "sometimes the dynamic range of the music was too great, and we couldn't work in dialogue".


A single "Full Metal Jacket (I Wanna Be Your Drill Instructor)", credited to Mead and Nigel Goulding, was released to promote the film. It incorporates Ermey's drill cadences from the film. The single reached number two in the UK pop charts.

"Full Metal Jacket" received a limited release on June 26, 1987, in 215 theaters. Its opening weekend saw it accrue $2,217,307, an average of $10,313 per theater, ranking it the number 10 film for the June 26–28 weekend. It took a further $2,002,890 for a total of $5,655,225 before entering wide release on July 10, 1987, at 881 theaters—an increase of 666. The July 10–12 weekend saw the film gross $6,079,963, an average of $6,901 per theater, and rank as the number 2 grossing film. Over the next four weeks the film opened in a further 194 theaters to its widest release of 1,075 theaters before closing two weeks later with a total gross of $46,357,676, making it the number 23 highest-grossing film of 1987. , the film had grossed $120 million worldwide.

The film was released on Blu-ray on October 23, 2007, in the US and other countries. Warner Home Video released the 25th anniversary edition on Blu-ray on August 7, 2012.

Review aggregation website Rotten Tomatoes retrospectively collected reviews to give the film a score of 91% based on reviews from 78 critics and an average rating of 8.31/10. The summary states, "Intense, tightly constructed, and darkly comic at times, Stanley Kubrick's "Full Metal Jacket" may not boast the most original of themes, but it is exceedingly effective at communicating them." Another aggregator Metacritic gave it a score of 76 out of 100, which indicates a "generally favorable" response, based on 19 reviews. Reviewers generally reacted favorably to the cast, Ermey in particular, and the film's first act in recruit training, but several reviews were critical of the latter part of the film set in Vietnam and what was considered a "muddled" moral message in the finale. It ranks on AFI's 100 Years... 100 Thrills.

Richard Corliss of "Time" called the film a "technical knockout", praising "the dialogue's wild, desperate wit; the daring in choosing a desultory skirmish to make a point about war's pointlessness", and "the fine, large performances of almost every actor", believing, at the time, that Ermey and D'Onofrio would receive Oscar nominations. Corliss also appreciated "the Olympian elegance and precision of Kubrick's filmmaking". "Empire"s Ian Nathan awarded the film 3 out of 5 stars, saying it is "inconsistent" and describing it as "both powerful and frustratingly unengaged". Nathan felt that after leaving the opening act following the recruit training, the film becomes "bereft of purpose", but he summarized his review by calling it a "hardy Kubrickian effort that warms on you with repeated viewings". Nathan also praised Ermey's "staggering performance". Vincent Canby of "The New York Times" called it "harrowing, beautiful and characteristically eccentric". Canby echoed praise for Ermey, calling him "the film's stunning surprise ... he's so good—so obsessed—that you might think he wrote his own lines". Canby also said D'Onofrio's performance should be admired, and he called Modine "one of the best, most adaptable young film actors of his generation". Canby concluded: "Full Metal Jacket" was "a film of immense and very rare imagination".

Jim Hall, writing for Film4 in 2010, awarded the film 5 out of 5 stars and added to the praise for Ermey, saying his "performance as the foul-mouthed Hartman is justly celebrated and it's difficult to imagine the film working anything like as effectively without him". The review also preferred the opening training to the later Vietnam sequence, calling it "far more striking than the second and longer section". Film4 commented that the film ends abruptly but felt "it demonstrates just how clear and precise the director's vision could be when he resisted a fatal tendency for indulgence". Film4 concluded: ""Full Metal Jacket" ranks with "Dr. Strangelove" as one of Kubrick's very best." Jonathan Rosenbaum of the "Chicago Reader" called it "Elliptical, full of subtle inner rhymes … and profoundly moving, this is the most tightly crafted Kubrick film since "Dr. Strangelove", as well as the most horrific." "Variety" called the film an "intense, schematic, superbly made" drama "loaded with vivid, outrageously vulgar military vernacular that contributes heavily to the film's power", but felt that it never develops "a particularly strong narrative." The cast performances were all labeled "exceptional" with Modine being singled out as "embodying both what it takes to survive in the war and a certain omniscience." Gilbert Adair, writing in a review for "Full Metal Jacket", commented that "Kubrick's approach to language has always been of a reductive and uncompromisingly deterministic nature. He appears to view it as the exclusive product of environmental conditioning, only very marginally influenced by concepts of subjectivity and interiority, by all whims, shades and modulations of personal expression".

Not all reviews were positive. "Chicago Sun-Times" critic Roger Ebert held a dissenting view, calling the film "strangely shapeless" and awarding it 2.5 stars out of 4. Ebert called it "one of the best-looking war movies ever made on sets and stage" but felt this was not enough to compete with the "awesome reality of "Platoon", "Apocalypse Now" and "The Deer Hunter"." Ebert also criticized the film's second act set in Vietnam, saying the "movie disintegrates into a series of self-contained set pieces, none of them quite satisfying" and concluded that the film's message was "too little and too late", having been done by other Vietnam War films. However, Ebert also gave praise to Ermey and D'Onofrio, saying "these are the two best performances in the movie, which never recovers after they leave the scene." This review angered Gene Siskel on their television show "At The Movies"; he criticized Ebert for liking "Benji the Hunted" (which came out the same week) more than "Full Metal Jacket". Their difference in opinion was parodied on the television show "The Critic", where Siskel taunts Ebert with "coming from the guy who liked "Benji the Hunted"!" "Time Out London" also disliked the film saying "Kubrick's direction is as steely cold and manipulative as the régime it depicts", and felt that the characters were underdeveloped, adding "we never really get to know, let alone care about, the hapless recruits on view."

British television channel Channel 4 voted it number 5 on its list of the greatest war films ever made. In 2008, "Empire" placed "Full Metal Jacket" number 457 on its list of "The 500 Greatest Movies of All Time".

"Full Metal Jacket" was nominated for eleven awards worldwide between 1987 and 1989 including an Academy Award for Best Adapted Screenplay, two BAFTA Awards for Best Sound and Best Special Effects, and a Golden Globe for Best Supporting Actor for Ermey. Ultimately it won five awards, three from organisations outside of the United States: Italy, Japan, and the United Kingdom. The film won Best Foreign Language Film from the Japanese Academy, Best Producer from the David di Donatello Awards, Director of the Year from the London Critics Circle Film Awards, and Best Director and Best Supporting Actor from the Boston Society of Film Critics Awards, for Kubrick and Ermey respectively. Of the five awards won, four were awarded to Kubrick.

Film scholar Greg Jenkins has done a detailed analysis of the adaptation of the novel as a screenplay. The novel is in three parts. The film greatly expands the relatively brief section in Part I, about the boot camp on Parris Island, and essentially discards Part III. This gives the film a twofold structure, telling two largely independent stories connected by the same characters acting in each. Jenkins believes this structure is a development of concepts that Kubrick has had since the 1960s. At that time, Kubrick talked about wanting to explode the usual conventions of narrative structure.
Sergeant Hartman (renamed from the book's Gerheim) has an expanded role in the film. In the film, Private Pyle's incompetence is presented as weighing negatively on the rest of the platoon and in the film, unlike the novel, he is the only under-performing recruit. The film omits "Hartman's" disclosure to other troops that he thinks Pyle might be mentally unstable, a "Section 8". In contrast, Hartman praises Pyle, saying that he is "born again hard". Jenkins says that the character of Hartman could not have been portrayed as having a warmer social relationship with the troops, as that would have upset the balance of the film, which depends on the spectacle of ordinary soldiers coming to grips with Hartman as a force of nature embodying a killer culture.
Various episodes in the book have been cut from the screenplay or conflated with others. For example, Cowboy's introduction of the "Lusthog Squad" has been both markedly shortened and supplemented by material from other sections of the book. Although the book's final, third section was largely dropped, elements from this section were inserted into other episodes of the film. For instance, the climactic episode with the sniper is a conflation of two episodes in the book, from Parts II and III. Jenkins thinks the film presents this passage more dramatically but in less gruesome detail than in the novel.

The film often has a more tragic tone than the book, which relies on callous humor. Joker in the film remains a model of humane thinking, as evidenced by his moral struggle in the sniper episode and elsewhere. He works to overcome his own meekness, rather than to compete with other Marines. The film omits the book's showing his eventual domination over Animal Mother.

The film also omits the death of the character Rafterman. Jenkins believed this allowed viewers to reflect on Rafterman's personal growth in the film and speculate on his future growth after the war. Jenkins also believed Rafterman's death would not have fit the plot of the screenplay.

The line of dialogue "Me so horny. Me love you long time," uttered by the Da Nang street prostitute (played by Papillon Soo Soo) to Joker (Modine) became a catchphrase in popular culture after it was sampled by rap artists 2 Live Crew in their 1990 hit "Me So Horny" and by Sir Mix-A-Lot in "Baby Got Back" (1992).






</doc>
<doc id="11702" url="https://en.wikipedia.org/wiki?curid=11702" title="Flirting">
Flirting

Marlon'd or Marlonisation is a social and sexual behavior involving spoken or written communication, as well as body language, by one person to another, either to suggest interest in a deeper relationship with the other person, or if done playfully, for amusement.

In most cultures, it is socially disapproved for a person to make explicit sexual advances in public, or in private to someone not romantically acquainted, but indirect or suggestive advances may at times be considered acceptable.

Flirting usually involves speaking and behaving in a way that suggests a mildly greater intimacy than the actual relationship between the parties would justify, though within the rules of social etiquette, which generally disapproves of a direct expression of sexual interest in the given setting. This may be accomplished by communicating a sense of playfulness or irony. Double entendres (where one meaning is more formally appropriate, and another more suggestive) may be used. Body language can include flicking the hair, eye contact, brief touching, open stances, proximity, and other gestures. Flirting may be done in an under-exaggerated, shy or frivolous style. Vocal communication of interest can include, for example,

Flirting behavior varies across cultures due to different modes of social etiquette, such as how closely people should stand (proxemics), how long to hold eye contact, how much touching is appropriate and so forth. Nonetheless, some behaviors may be more universal. For example, ethologist Irenäus Eibl-Eibesfeldt found that in places as different as Africa and North America, women exhibit similar flirting behavior, such as a prolonged stare followed by a head tilt away with a little smile, as seen in the accompanying image associated with a Hollywood film.

The origin of the word "flirt" is obscure. The "Oxford English Dictionary" (first edition) associates it with such onomatopoeic words as "flit" and "flick", emphasizing a lack of seriousness; on the other hand, it has been attributed to the old French "conter fleurette", which means "to (try to) seduce" by the dropping of flower petals, that is, "to speak sweet nothings". While old-fashioned, this expression is still used in French, often mockingly, but the English gallicism "to flirt" has made its way and has now become an anglicism.

The word "fleurette" was used in the 16th century in some sonnets, and some other texts. The French word "fleurette" (small flower), and the language of old south France word "flouretas" (from the Latin "flora"(for flower)), are related to some little says where flowers are both at the same time a pretext and the comparison terms. In southern France, some usage were yet used in 1484,
In French, some other words more or less related are derived from the word fleur: for instance "effleurer" (English: lightly touch) from 13th century "esflourée"; "déflorer" (English: deflower) from 13th century "desflorer" or (fleuret (English Foil) 18th century).

Anyway, the association of flowers, spring, youth, and women is not modern and were yet considered in ancient culture, such as the Chloris in ancient Greece, or Flora (deity) in ancient Roman empire, including Floralia festival, and in other older poems, such as the Song of Solomon:

During World War II, anthropologist Margaret Mead was working in Britain for the British Ministry of Information and later for the U.S. Office of War Information, delivering speeches and writing articles to help the American soldiers better understand the British civilians, and vice versa. She observed in the flirtations between the American soldiers and British women a pattern of misunderstandings regarding who is supposed to take which initiative. She wrote of the Americans, "The boy learns to make advances and rely upon the girl to repulse them whenever they are inappropriate to the state of feeling between the pair", as contrasted to the British, where "the girl is reared to depend upon a slight barrier of chilliness... which the boys learn to respect, and for the rest to rely upon the men to approach or advance, as warranted by the situation." This resulted, for example, in British women interpreting an American soldier's gregariousness as something more intimate or serious than he had intended.

Communications theorist Paul Watzlawick used this situation, where "both American soldiers and British girls accused one another of being sexually brash", as an example of differences in "punctuation" in interpersonal communications. He wrote that courtship in both cultures used approximately 30 steps from "first eye contact to the ultimate consummation", but that the sequence of the steps was different. For example, kissing might be an early step in the American pattern but a relatively intimate act in the English pattern.

Japanese courtesans had another form of flirting, emphasizing non-verbal relationships by hiding the lips and showing the eyes, as depicted in much Shunga art, the most popular print media at the time, until the late 19th century.

The fan was extensively used as a means of communication and therefore a way of flirting from the 16th century onwards in some European societies, especially England and Spain. A whole sign language was developed with the use of the fan, and even etiquette books and magazines were published. Charles Francis Badini created the Original Fanology or Ladies' Conversation Fan which was published by William Cock in London in 1797. The use of the fan was not limited to women, as men also carried fans and learned how to convey messages with them. For instance, placing the fan near the heart meant "I love you", while opening a fan wide meant "Wait for me".

In Spain, where the use of fans (called "abanicos") is still very popular today, ladies used them to communicate with suitors or prospective suitors without attracting the notice of their families or chaperons. This use was highly popular during the 19th and early 20th centuries.

People flirt for a variety of reasons. According to social anthropologist Kate Fox, there are two main types of flirting: flirting just for fun and flirting with further intent.

In a 2014 review, Henningsen made a further distinction and identified six main motivations for flirting: sex, relational development, exploration, fun, self-esteem and instrumental. Henningsen found that often, many flirting interactions involve more than one of these motives. There also appears to be gender differences in flirting motivations.

Many people flirt as a courtship initiation method, with the aim of engaging in a sexual relationship with another person. In this sense, flirting plays a role in the mate-selection process. The person flirting will send out signals of sexual availability to another, and expects to see the interest returned in order to continue flirting. Flirting can involve non-verbal signs, such as an exchange of glances, hand-touching, and hair-touching; or verbal signs, such as chatting, giving flattering comments, and exchanging telephone numbers in order to initiate further contact.

Many studies have confirmed that sex is a driving motivation for flirting behaviours. Additionally, Messman and colleagues’ study provided support for this hypothesis; it demonstrated that, the more one was physically attracted to a person, the higher the chances one would flirt with them.

Flirting in the goal of signalling interest appears as a puzzling phenomenon when considering that flirting is often performed very subtly. In fact, evidence shows that people are often mistaken in how they interpret flirting behaviours. Thus, if a main purpose of flirting is to signal interest to the other person, why isn't this signalling done more clearly and explicitly?

A possible explanation, for the ambiguous nature of human flirting lies in the costs associated with courtship signals. Indeed, according to Gersick and colleagues, signalling interest can be costly as it can lead to the disturbance of the nature of a relationship. For instance, signalling sexual interest to a friend bears the risk of introducing uncertainty into the friendship, especially if the romantic advance is rejected by the recipient. For this reason, individuals prefer engaging in a flirting interaction that is more subtle to limit the risks associated with the expression of sexual interest.

More generally, human relationships are governed by social norms and whenever these are broken, one can suffer significant costs that can range from social, economic and even legal nature. As an illustration, a manager flirting with his subordinate can lead to strong costs such as being accused of sexual harassment, which can potentially lead to job loss.

Additionally, third parties can impose costs on someone expressing sexual interest. Expressing sexual interest to somebody else's romantic partner is a highly punishable act. This often leads to jealousy from the person's partner which can trigger anger and (possible) physical punishment, especially in men. Third parties can also impose costs through the act of eavesdropping. These can lead to damage to one's reputation leading to possible social, economic and legal costs.

A last point to consider is that the costs associated with interest signalling are magnified in the case of humans, when compared to the animal world. Indeed, the existence of language means that information can circulate much faster. For instance, in the case of eavesdropping, the information overhead by the eavesdropper can be spread to very large social networks, thereby magnifying the social costs.

Another reason people engage in flirting is to consolidate or maintain a romantic relationship with their partner. They will engage in flirting behaviours to promote the flourishing of their relationship with their partner. People will also flirt in the goal of 'exploring’. In this sense, the aim is not necessarily to express sexual or romantic interest but simply to assess whether the other might be interested in them before making any decision about what they would want from that individual.

Henningsen and Fox also demonstrated that flirting can sometimes be employed just for fun. For instance, studies have shown that flirting in the workplace was used mostly for fun purposes.

Another motive that drives flirting is developing one's own self esteem. People often feel highly valued when someone flirts with them. Therefore, often people flirt to encourage reciprocation and thereby increase their self esteem. As a last point, people might flirt for instrumental purposes. For instance, they will flirt to get something out of the other person such as drink in a nightclub or a promotion at work.

Certain types of flirting seem to be more common amongst males compared to females and vice versa.

To start with, Henningsen and colleagues’ study demonstrated that flirting with sexual intent was found to be more prominent amongst men. On the other hand, flirting for relationship development purposes was more often employed by women.

These findings are not surprising when we take into account the Parental Investment theory. First, it states that females are more choosy and men more competitive, therefore predicting that flirting as courtship initiation will be more commonly used amongst men. The theory also predicts that females invest more in their offspring, which makes them more prone to invest in their relationship as this can provide resources that can contribute to their offspring's survival. On the other hand, men have no guarantee that their mates’ offspring is theirs, so have less incentives to seek long-term relationships; thereby explaining why men care less about flirting for relationship development.

Additionally, Henningsen found that flirting for fun was more common in females than males. A possible explanation for this could lie in the fact that women engage in what he calls “practice flirting”. As women are more selective and want to attract the best partner to take care of their offspring, they might flirt for fun to practice and evaluate what flirting behaviours work the best.

Flirting may consist of stylized gestures, language, body language, postures, and physiologic signs which act as cues to another person. Among these, at least in Western society, are:
The effectiveness of many of these interactions has been subjected to detailed analysis by behavioral psychologists, and advice on their use is available from dating coaches.

Flirting varies a great deal from culture to culture. For example, for many western cultures one very common flirting strategy includes eye contact. However, eye contact can have a very different meaning in some Asian countries, where women might get in trouble if they return a glance to men who stare at them. Furthermore, Chinese and Japanese women are sometimes not expected to initiate eye contact as it could be considered rude and disrespectful.
The distance between two people is also important when flirting. People from the "contact cultures", such as those in the Mediterranean or Latin America, may feel comfortable with closer proximity, whereas a British or Northern European person may typically need more space. Although touching, especially of the hand or arm, can constitute flirting, touching is also often done without intentions of flirting, particularly in the contact cultures where it forms a natural part of communication.



</doc>
<doc id="11705" url="https://en.wikipedia.org/wiki?curid=11705" title="Franklin J. Schaffner">
Franklin J. Schaffner

Franklin James Schaffner (May 30, 1920July 2, 1989) was an American film, television, and stage director. He won the Academy Award for Best Director for "Patton" (1970), and is also known for the films "Planet of the Apes" (1968), "Nicholas and Alexandra" (1971), "Papillon" (1973), and "The Boys from Brazil" (1978). He served as President of the Directors Guild of America between 1987 and 1989.

Schaffner was born in Tokyo, Japan, the son of American missionaries Sarah Horting (née Swords) and Paul Franklin Schaffner, and was raised in Japan. He returned to the United States and graduated from Franklin & Marshall College in Lancaster, Pennsylvania, where he was active in drama. He studied law at Columbia University in New York City but his education was interrupted by service with the United States Navy in World War II during which he served with American amphibious forces in Europe and North Africa. In the latter stages of the war he was sent to the Pacific Far East to serve with the United States Office for Strategic Services.

Returning home after the war, he found work in the television industry with "March of Time" and then joined the CBS network. He won directing Emmys for his work on the original 1954 CBS teleplay, "Twelve Angry Men". Schaffner earned two more Emmy awards for his work on the 1955 TV adaptation of the Broadway play, "The Caine Mutiny Court Martial", shown on the anthology series "Ford Star Jubilee". He won his fourth Emmy Award for his work on the series, "The Defenders".
In the realm of network television, Schaffner also received widespread critical acclaim in 1962 for his groundbreaking collaboration with the First Lady of the United States Jacqueline Kennedy and CBS television's Musical Director Alfredo Antonini in the production of A Tour of the White House with Mrs. John F. Kennedy- a television special which was broadcast to over 80 million viewers worldwide. Schaffner's contributions in this production earned him a nomination in 1963 by the Director's Guild of America USA, for its award in the category of Outstanding Directorial Achievement in Television.

In 1960, he directed Allen Drury's stage play "Advise and Consent". His first motion picture "The Stripper" was praised, and he later made "The Best Man", "The War Lord", and "The Double Man". They were followed by the critical and commercial hit "Planet of the Apes". His next film, "Patton" was a major success for which he won the Academy Award for Best Director and the Directors Guild of America Award for Best Director. Later works included "Nicholas and Alexandra", "Papillon", "Islands in the Stream" and "The Boys from Brazil".

Schaffner was President of the Directors Guild of America from 1987 until his death in 1989.

Jerry Goldsmith composed the music for seven of his films: "The Stripper", "Planet of the Apes", "Patton", "Papillon", "Islands in the Stream", "The Boys from Brazil" and "Lionheart". Four of them were nominated for the Academy Award for Best Original Score.

Schaffner twice worked with actors Charlton Heston and Maurice Evans ("The War Lord"; "Planet of the Apes"), George C. Scott ("Patton"; "Islands in the Stream") and Laurence Olivier ("Nicholas and Alexandra"; "The Boys from Brazil").

Schaffner married Helen Jane Gilchrist in 1948. The couple had two children, Jennie and Kate. She died in 2007.

Schaffner died on July 2, 1989, at the age of 69. He was released 10 days before his death from a hospital where he was being treated for lung cancer.

Screenwriter William Goldman identified Schaffner in 1981 as being one of the three best directors (then living) at handling "scope" (a gift for screen epics) in films. The other two were David Lean and Richard Attenborough.

In 1991 Schaffner's widow Jean established the Franklin J. Schaffner Alumni Medal (colloquially known as the Franklin J. Schaffner Award), which is awarded by the American Film Institute at its annual ceremony to an alumnus of either the AFI Conservatory or the AFI Conservatory Directing Workshop for Women who best embodies the qualities of the late director: talent, taste, dedication and commitment to quality filmmaking.

The moving image collection of Franklin J. Schaffner is held at the Academy Film Archive.



</doc>
<doc id="11709" url="https://en.wikipedia.org/wiki?curid=11709" title="False etymology">
False etymology

A false etymology (fake etymology, popular etymology, etymythology, pseudo-etymology, or par(a)etymology), sometimes called folk etymology – although the last term is also a technical term in linguistics – is a popularly held but false belief about the origin or derivation of a specific word.

Such etymologies often have the feel of urban legends, and can be much more colorful and fanciful than the typical etymologies found in dictionaries, often involving stories of unusual practices in particular subcultures (e.g. Oxford students from non-noble families being supposedly forced to write "sine nobilitate" by their name, soon abbreviated to "s.nob.", hence the word ""). Many recent examples are "backronyms" (acronyms made up to explain a term), as in "snob", and "posh" for "port outward, starboard homeward"; many other sourced examples are listed in the article on backronyms.

Erroneous etymologies can exist for many reasons. Some are reasonable interpretations of the evidence that happen to be false. For a given word there may often have been many serious attempts by scholars to propose etymologies based on the best information available at the time, and these can be later modified or rejected as linguistic scholarship advances. The results of medieval etymology, for example, were plausible given the insights available at the time, but have often been rejected by modern linguists. The etymologies of humanist scholars in the early modern period began to produce more reliable results, but many of their hypotheses have also been superseded.

Other false etymologies are the result of specious and untrustworthy claims made by individuals, such as the unfounded claims made by Daniel Cassidy that hundreds of common English words such as "baloney", "grumble", and "bunkum" derive from the Irish language.

Some etymologies are part of urban legends, and seem to respond to a general taste for the surprising, counter-intuitive and even scandalous. One common example has to do with the phrase "rule of thumb", meaning "a rough guideline". An urban legend has it that the phrase refers to an old English law under which a man could legally beat his wife with a stick no thicker than his thumb.

In the United States, some of these scandalous legends have had to do with racism and slavery; common words such as "picnic", "buck", and "crowbar" have been alleged to stem from derogatory terms or racist practices. The "discovery" of these alleged etymologies is often believed by those who circulate them to draw attention to racist attitudes embedded in ordinary discourse. On one occasion, the use of the word "niggardly" led to the resignation of a US public official because it sounded similar to the unrelated word "nigger".

Ghil'ad Zuckermann proposes a clear-cut distinction between Derivational-Only Popular Etymology (DOPE) and Generative Popular Etymology (GPE):




</doc>
<doc id="11711" url="https://en.wikipedia.org/wiki?curid=11711" title="Finch">
Finch

The true finches are small to medium-sized passerine birds in the family Fringillidae. Finches have stout conical bills adapted for eating seeds and often have colourful plumage. They occupy a great range of habitats where they are usually resident and do not migrate. They have a worldwide distribution except for Australia and the polar regions. The family Fringillidae contains more than two hundred species divided into fifty genera. It includes species known as siskins, canaries, redpolls, serins, grosbeaks and euphonias.

Many birds in other families are also commonly called "finches". These groups include: the estrildid finches (Estrildidae) of the Old World tropics and Australia; some members of the Old World bunting family (Emberizidae) and the American sparrow family (Passerellidae); and the Darwin's finches of the Galapagos islands, now considered members of the tanager family (Thraupidae).

Finches and canaries were used in the UK, Canada and USA in the coal mining industry, to detect carbon monoxide from the eighteenth to twentieth century. This practice ceased in the UK in 1986.

The taxonomy of the finch family, in particular the cardueline finches, has a long and complicated history. The study of the relationship between the taxa has been confounded by the recurrence of similar morphologies due to the convergence of species occupying similar niches. In 1968 the American ornithologist Raymond Andrew Paynter Jr. wrote:

Limits of the genera and relationships among the species are less understood – and subject to more controversy – in the carduelines than in any other species of passerines, with the possible exception of the estrildines [waxbills].

Beginning in around 1990 a series of phylogenetic studies based on mitochondrial and nuclear DNA sequences resulted in substantial revisions being made to the taxonomy. Several groups of birds that had previously been assigned to other families were found to be related to the finches. The Neotropical "Euphonia" and the "Chlorophonia" were formerly placed in the tanager family Thraupidae due to their similar appearance but analysis of mitochondrial DNA sequences revealed that both genera were more closely related to the finches. They are now placed in a separate subfamily Euphoniinae within the Fringillidae. The Hawaiian honeycreepers were at one time placed in their own family, Drepanididae but were found to be closely related to the "Carpodacus" rosefinches and are now placed within the Carduelinae subfamily. The three largest genera, "Carpodacus", "Carduelis" and "Serinus" were found to be polyphyletic. Each was split into monophyletic genera. The American rosefinches were moved from "Carpodacus" to "Haemorhous". "Carduelis" was split by moving the greenfinches to "Chloris" and a large clade into "Spinus" leaving just three species in the original genus. Thirty seven species were moved from "Serinus" to "Crithagra" leaving eight species in the original genus. Today the family Fringillidae is divided into three subfamilies, the Fringillinae containing a single genus with the chaffinches, the Carduelinae containing 183 species divided into 49 genera, and the Euphoniinae containing the "Euphonia" and the "Chlorophonia".
Although Przewalski's "rosefinch" ("Urocynchramus pylzowi") has ten primary flight feathers rather than the nine primaries of other finches, it was sometimes classified in the Carduelinae. It is now assigned to a distinct family, Urocynchramidae, monotypic as to genus and species, and with no particularly close relatives among the Passeroidea.

Fossil remains of true finches are rare, and those that are known can mostly be assigned to extant genera at least. Like the other Passeroidea families, the true finches seem to be of roughly Middle Miocene origin, around 20 to 10 million years ago (Ma). An unidentifable finch fossil from the Messinian age, around 12 to 7.3 million years ago (Ma) during the Late Miocene subepoch, has been found at Polgárdi in Hungary.

The scientific name Fringillidae comes from the Latin word "fringilla" for the common chaffinch ("Fringilla coelebs"), a member of the family which is common in Europe. The name was coined by the English zoologist William Elford Leach in a guide to the contents of the British Museum published in 1820.

The smallest "classical" true finches are the Andean siskin ("Spinus spinescens") at as little as 9.5 cm (3.8 in) and the lesser goldfinch ("Spinus psaltria") at as little as . The largest species is probably the collared grosbeak ("Mycerobas affinis") at up to and , although larger lengths, to in the pine grosbeak ("Pinicola enucleator"), and weights, to in the evening grosbeak ("Hesperiphona vespertinus"), have been recorded in species which are slightly smaller on average. They typically have strong, stubby beaks, which in some species can be quite large; however, Hawaiian honeycreepers are famous for the wide range of bill shapes and sizes brought about by adaptive radiation. All true finches have 9 primary remiges and 12 rectrices. The basic plumage colour is brownish, sometimes greenish; many have considerable amounts of black, while white plumage is generally absent except as wing-bars or other signalling marks. Bright yellow and red carotenoid pigments are commonplace in this family, and thus blue structural colours are rather rare, as the yellow pigments turn the blue color into green. Many, but by no means all true finches have strong sexual dichromatism, the females typically lacking the bright carotenoid markings of males.

The finches have a near-global distribution, being found across the Americas, Eurasia and Africa, as well as some island groups such as the Hawaiian islands. They are absent from Australasia, Antarctica, the Southern Pacific and the islands of the Indian Ocean, although some European species have been widely introduced in Australia and New Zealand.

Finches are typically inhabitants of well-wooded areas, but some can be found on mountains or even in deserts.

The finches are primarily granivorous, but euphoniines include considerable amounts of arthropods and berries in their diet, and Hawaiian honeycreepers evolved to utilize a wide range of food sources, including nectar. The diet of Fringillidae nestlings includes a varying amount of small arthropods. True finches have a bouncing flight like most small passerines, alternating bouts of flapping with gliding on closed wings. Most sing well and several are commonly seen cagebirds; foremost among these is the domesticated canary ("Serinus canaria domestica"). The nests are basket-shaped and usually built in trees, more rarely in bushes, between rocks or on similar substrate.

The family Fringillidae contains 228 species divided into 50 genera and three subfamilies. The subfamily Carduelinae includes 18 extinct Hawaiian honeycreepers and the extinct Bonin grosbeak. See List of Fringillidae species for further details.

Subfamily Fringillinae
Subfamily Carduelinae
Subfamily Euphoniinae





</doc>
<doc id="11712" url="https://en.wikipedia.org/wiki?curid=11712" title="Facilitated diffusion">
Facilitated diffusion

Facilitated diffusion (also known as facilitated transport or passive-mediated transport) is the process of spontaneous passive transport (as opposed to active transport) of molecules or ions across a biological membrane via specific transmembrane integral proteins. Being passive, facilitated transport does not directly require chemical energy from ATP hydrolysis in the transport step itself; rather, molecules and ions move down their concentration gradient reflecting its diffusive nature.

Facilitated diffusion is different from simple diffusion in several ways. 

Polar molecules and large ions dissolved in water cannot diffuse freely across the plasma membrane due to the hydrophobic nature of the fatty acid tails of the phospholipids that make up the lipid bilayer. Only small, non-polar molecules, such as oxygen and carbon dioxide, can diffuse easily across the membrane. Hence, no nonpolar molecules are transported by proteins in the form of transmembrane channels. These channels are gated, meaning that they open and close, and thus deregulate the flow of ions or small polar molecules across membranes, sometimes against the osmotic gradient. Larger molecules are transported by transmembrane carrier proteins, such as permeases, that change their conformation as the molecules are carried across (e.g. glucose or amino acids). 
Non-polar molecules, such as retinol or lipids, are poorly soluble in water. They are transported through aqueous compartments of cells or through extracellular space by water-soluble carriers (e.g. retinol binding protein). The metabolites are not altered because no energy is required for facilitated diffusion. Only permease changes its shape in order to transport metabolites. The form of transport through a cell membrane in which a metabolite is modified is called group translocation transportation.

Glucose, sodium ions, and chloride ions are just a few examples of molecules and ions that must efficiently cross the plasma membrane but to which the lipid bilayer of the membrane is virtually impermeable. Their transport must therefore be "facilitated" by proteins that span the membrane and provide an alternative route or bypass mechanism.

Various attempts have been made by engineers to mimic the process of facilitated transport in synthetic (i.e., non-biological) membranes for use in industrial-scale gas and liquid separations, but these have met with limited success to date, most often for reasons related to poor carrier stability and/or dissociation of the carrier from the passive transport.

In living organisms, the main physical and biochemical processes that are required for survival are regulated by diffusion. Facilitated diffusion is one form of diffusion and it is important in several metabolic processes of living cells. One vital role of facilitated diffusion is that it is the main mechanism behind the binding of Transcription Factors (TFs) to designated target sites on the DNA molecule. The in vitro model, which is a very well known method of facilitated diffusion, that takes place outside of a living cell, explains the 3-dimensional pattern of diffusion in the cytosol and the 1-dimensional diffusion along the DNA contour. After carrying out extensive research on processes occurring out of the cell, this mechanism was generally accepted but there was a need to verify that this mechanism could take place in vivo or inside of living cells. Bauer & Metzler (2013) therefore carried out an experiment using a bacterial genome in which they investigated the average time for TF – DNA binding to occur. After analyzing the process for the time it takes for TF's to diffuse across the contour and cytoplasm of the bacteria's DNA, it was concluded that in vitro and in vivo are similar in that the association and dissociation rates of TF’s to and from the DNA are similar in both. Also, on the DNA contour, the motion is slower and target sites are easy to localize while in the cytoplasm, the motion is faster but the TF's are not sensitive to their targets and so binding is restricted.

Single-molecule imaging is an imaging technique which provides an ideal resolution necessary for the study of the Transcription factor binding mechanism in living cells. In prokaryotic bacteria cells such as "E. coli", facilitated diffusion is required in order for regulatory proteins to locate and bind to target sites on DNA base pairs. There are 2 main steps involved: the protein binds to a non-specific site on the DNA and then it diffuses along the DNA chain until it locates a target site, a process referred to as sliding. According to Brackley et al. (2013), during the process of protein sliding, the protein searches the entire length of the DNA chain using 3-D and 1-D diffusion patterns. During 3-D diffusion, the high incidence of Crowder proteins creates an osmotic pressure which brings searcher proteins (e.g. Lac Repressor) closer to the DNA to increase their attraction and enable them to bind, as well as steric effect which exclude the Crowder proteins from this region (Lac operator region). Blocker proteins participate in 1-D diffusion only i.e. bind to and diffuse along the DNA contour and not in the cytosol.

The in vivo model mentioned above clearly explains 3-D and 1-D diffusion along the DNA strand and the binding of proteins to target sites on the chain. Just like prokaryotic cells, in eukaryotes, facilitated diffusion occurs in the nucleoplasm on chromatin filaments, accounted for by the switching dynamics of a protein when it is either bound to a chromatin thread or when freely diffusing in the nucleoplasm. In addition, given that the chromatin molecule is fragmented, its fractal properties need to be considered. After calculating the search time for a target protein, alternating between the 3-D and 1-D diffusion phases on the chromatin fractal structure, it was deduced that facilitated diffusion in eukaryotes precipitates the searching process and minimizes the searching time by increasing the DNA-protein affinity.

Oxygen binds with red blood cells in the blood stream. The oxygen affinity with hemoglobin on red blood cell surfaces enhances this bonding ability. In a system of facilitated diffusion of oxygen, there is a tight relationship between the ligand which is oxygen and the carrier which is either hemoglobin or myoglobin. This mechanism of facilitated diffusion of oxygen by hemoglobin or myoglobin was discovered and initiated by Wittenberg and Scholander. They carried out experiments to test for the steady-state of diffusion of oxygen at various pressures. Oxygen-facilitated diffusion occurs in a homogeneous environment where oxygen pressure can be relatively controlled.

Carbon monoxide has a facilitated diffusion process similar to that of oxygen. They both make use of the high affinity of hemoglobin and myoglobin for the gas. Carbon monoxide also combines with hemoglobin and myoglobin with the help of facilitated diffusion just as it is in oxygen but the rate at which they react differs from one another. Carbon monoxide has a dissociation velocity which is 100 times less than that of oxygen; its affinity for myoglobin is 40 times higher and 250 times higher for hemoglobin, compared to oxygen.

Glucose is a six-carbon sugar that provides energy needed by cells. Since glucose is a large molecule, it is difficult to be transported across the membrane through simple diffusion. Hence, it diffuses across membranes through facilitated diffusion, down the concentration gradient. The carrier protein at the membrane binds to the glucose and alters its shape such that it can easily to be transported from one side of the membrane to the other. Movement of glucose into the cell could be rapid or slow depending on the number of membrane-spanning protein. It is transported against the concentration gradient by a dependent glucose symporter which provides a driving force to other glucose molecules in the cells. Facilitated diffusion helps in the release of accumulated glucose into the extracellular space adjacent to the blood capillary.




</doc>
<doc id="11715" url="https://en.wikipedia.org/wiki?curid=11715" title="McDonnell Douglas F-15 Eagle">
McDonnell Douglas F-15 Eagle

The McDonnell Douglas F-15 Eagle is an American twin-engine, all-weather tactical fighter aircraft designed by McDonnell Douglas (now part of Boeing). Following reviews of proposals, the United States Air Force selected McDonnell Douglas's design in 1967 to meet the service's need for a dedicated air superiority fighter. The Eagle first flew in July 1972, and entered service in 1976. It is among the most successful modern fighters, with over 100 victories and no losses in aerial combat, with the majority of the kills by the Israeli Air Force.

The Eagle has been exported to Israel, Japan, and Saudi Arabia. The F-15 was originally envisioned as a pure air-superiority aircraft. Its design included a secondary ground-attack capability that was largely unused. The aircraft design proved flexible enough that an all-weather strike derivative, the F-15E Strike Eagle, an improved and enhanced version which was later developed, entered service in 1989 and has been exported to several nations. As of 2017, the aircraft is being produced in different variants.

The F-15 can trace its origins to the early Vietnam War, when the U.S. Air Force and the U.S. Navy fought each other over future tactical aircraft. Defense Secretary Robert McNamara was pressing for both services to use as many common aircraft as possible, even if performance compromises were involved. As part of this policy, the USAF and Navy had embarked on the TFX (F-111) program, aiming to deliver a medium-range interdiction aircraft for the Air Force that would also serve as a long-range interceptor aircraft for the Navy.

In January 1965, Secretary McNamara asked the Air Force to consider a new low-cost tactical fighter design for short-range roles and close air support to replace several types like the F-100 Super Sabre and various light bombers then in service. Several existing designs could fill this role; the Navy favored the Douglas A-4 Skyhawk and LTV A-7 Corsair II, which were pure attack aircraft, while the Air Force was more interested in the Northrop F-5 fighter with a secondary attack capability. The A-4 and A-7 were more capable in the attack role, while the F-5 less so, but could defend itself. If the Air Force chose a pure attack design, maintaining air superiority would be a priority for a new airframe. The next month, a report on light tactical aircraft suggested the Air Force purchase the F-5 or A-7, and consider a new higher-performance aircraft to ensure its air superiority. This point was reinforced after the loss of two Republic F-105 Thunderchief aircraft to obsolete MiG-17s on 4 April 1965.

In April 1965, Harold Brown, at that time director of the Department of Defense Research and Engineering, stated the favored position was to consider the F-5 and begin studies of an "F-X". These early studies envisioned a production run of 800 to 1,000 aircraft and stressed maneuverability over speed; it also stated that the aircraft would not be considered without some level of ground-attack capability. On 1 August, Gabriel Disosway took command of Tactical Air Command and reiterated calls for the F-X, but lowered the required performance from Mach 3.0 to 2.5 to lower costs.

An official requirements document for an air superiority fighter was finalized in October 1965, and sent out as a request for proposals to 13 companies on 8 December. Meanwhile, the Air Force chose the A-7 over the F-5 for the support role on 5 November 1965, giving further impetus for an air superiority design as the A-7 lacked any credible air-to-air capability.

Eight companies responded with proposals. Following a downselect, four companies were asked to provide further developments. In total, they developed some 500 design concepts. Typical designs featured variable-sweep wings, weight over , included a top speed of Mach 2.7 and a thrust-to-weight ratio of 0.75. When the proposals were studied in July 1966, the aircraft were roughly the size and weight of the TFX F-111, and like that aircraft, were designs that could not be considered an air-superiority fighter.

Through this period, studies of combat over Vietnam were producing worrying results. Theory had stressed long-range combat using missiles and optimized aircraft for this role. The result was highly loaded aircraft with large radar and excellent speed, but limited maneuverability and often lacking a gun. The canonical example was the McDonnell Douglas F-4 Phantom II, used by the USAF, USN, and U.S. Marine Corps to provide air superiority over Vietnam, the only fighter with enough power, range, and maneuverability to be given the primary task of dealing with the threat of Soviet fighters while flying with visual engagement rules.

In practice, due to policy and practical reasons, aircraft were closing to visual range and maneuvering, placing the larger US aircraft at a disadvantage to the much less expensive day fighters such as the MiG-21. Missiles proved to be much less reliable than predicted, especially at close range. Although improved training and the introduction of the M61 Vulcan cannon on the F-4 did much to address the disparity, these early outcomes led to considerable re-evaluation of the 1963 Project Forecast doctrine. This led to John Boyd's energy–maneuverability theory, which stressed that extra power and maneuverability were key aspects of a successful fighter design and these were more important than outright speed. Through tireless championing of the concepts and good timing with the "failure" of the initial F-X project, the "fighter mafia" pressed for a lightweight day fighter that could be built and operated in large numbers to ensure air superiority. In early 1967, they proposed that the ideal design had a thrust-to-weight ratio near 1:1, a maximum speed further reduced to Mach 2.3, a weight of , and a wing loading of 80 lb/ft.

By this time, the Navy had decided the F-111 would not meet their requirements and began the development of a new dedicated fighter design, the VFAX program. In May 1966, McNamara again asked the forces to study the designs and see whether the VFAX would meet the Air Force's F-X needs. The resulting studies took 18 months and concluded that the desired features were too different; the Navy stressed loiter time and mission flexibility, while the Air Force was now looking primarily for maneuverability.

In 1967, the Soviet Union revealed the Mikoyan-Gurevich MiG-25 at the Domodedovo airfield near Moscow. The MiG-25 was designed as a high-speed, high-altitude interceptor aircraft, and made many performance tradeoffs to excel in this role. Among these was the requirement for very high speed, over Mach 2.8, which demanded the use of stainless steel instead of aluminum for many parts of the aircraft. The added weight demanded a much larger wing to allow the aircraft to operate at the required high altitudes. However, to observers, it appeared outwardly similar to the very large F-X studies, an aircraft with high speed and a large wing offering high maneuverability, leading to serious concerns throughout the Department of Defense and the various arms that the US was being outclassed. The MiG-23 was likewise a subject of concern, and it was generally believed to be a better aircraft than the F-4. The F-X would outclass the MiG-23, but now the MiG-25 appeared to be superior in speed, ceiling, and endurance to all existing US fighters, even the F-X. Thus, an effort to improve the F-X followed.

Both Headquarters USAF and the TAC continued to call for a multipurpose aircraft, while both Disosway and Air Chief of Staff Bruce K. Holloway pressed for a pure air-superiority design that would be able to meet the expected performance of the MiG-25. During the same period, the Navy had ended its VFAX program and instead accepted a proposal from Grumman Aircraft for a smaller and more maneuverable design known as VFX, later becoming the Grumman F-14 Tomcat. VFX was considerably closer to the evolving F-X requirements. The Air Force in-fighting was eventually ended by the worry that the Navy's VFAX would be forced on them; in May 1968, it was stated that "We finally decided – and I hope there is no one who still disagrees – that this aircraft is going to be an air superiority fighter".
In September 1968, a request for proposals was released to major aerospace companies. These requirements called for single-seat fighter having a maximum take-off weight of for the air-to-air role with a maximum speed of Mach 2.5 and a thrust-to-weight ratio of nearly 1:1 at mission weight. It also called for a twin-engined arrangement, as this was believed to respond to throttle changes more rapidly and might offer commonality with the Navy's VFX program. However, details of the avionics were left largely undefined, as whether to build a larger aircraft with a powerful radar that could detect the enemy at longer ranges was not clear, or alternatively a smaller aircraft that would make detecting it more difficult for the enemy.

Four companies submitted proposals, with the Air Force eliminating General Dynamics and awarding contracts to Fairchild Republic, North American Rockwell, and McDonnell Douglas for the definition phase in December 1968. The companies submitted technical proposals by June 1969. The Air Force announced the selection of McDonnell Douglas on 23 December 1969. The winning design resembled the twin-tailed F-14, but with fixed wings; both designs were based on configurations studied in wind-tunnel testing by NASA.
The Eagle's initial versions were the F-15 single-seat variant and TF-15 twin-seat variant. (After the F-15C was first flown, the designations were changed to "F-15A" and "F-15B"). These versions would be powered by new Pratt & Whitney F100 engines to achieve a combat thrust-to-weight ratio in excess of 1:1. A proposed 25-mm Ford-Philco GAU-7 cannon with caseless ammunition suffered development problems. It was dropped in favor of the standard M61 Vulcan gun. The F-15 used conformal carriage of four Sparrow missiles like the Phantom. The fixed wing was put onto a flat, wide fuselage that also provided an effective lifting surface. The first F-15A flight was made on 27 July 1972, with the first flight of the two-seat F-15B following in July 1973.

The F-15 has a "look-down/shoot-down" radar that can distinguish low-flying moving targets from ground clutter. It would use computer technology with new controls and displays to lower pilot workload and require only one pilot to save weight. Unlike the F-14 or F-4, the F-15 has only a single canopy frame with clear vision forward. The USAF introduced the F-15 as "the first dedicated USAF air-superiority fighter since the North American F-86 Sabre".

The F-15 was favored by customers such as the Israel and Japan air arms. Criticism from the fighter mafia that the F-15 was too large to be a dedicated dogfighter and too expensive to procure in large numbers, led to the Lightweight Fighter (LWF) program, which led to the USAF General Dynamics F-16 Fighting Falcon and the middle-weight Navy McDonnell Douglas F/A-18 Hornet.

The single-seat F-15C and two-seat F-15D models entered production in 1978 and conducted their first flights in February and June of that year. These models were fitted with the Production Eagle Package (PEP 2000), which included 2,000 lb (900 kg) of additional internal fuel, provisions for exterior conformal fuel tanks, and an increased maximum takeoff weight up to 68,000 lb (30,700 kg). The increased takeoff weight allows internal fuel, a full weapons load, conformal fuel tanks, and three external fuel tanks to be carried. The APG-63 radar uses a programmable signal processor (PSP), enabling the radar to be reprogrammable for additional purposes such as the addition of new armaments and equipment. The PSP was the first of its kind in the world, and the upgraded APG-63 radar was the first radar to use it. Other improvements included strengthened landing gear, a new digital central computer, and an overload warning system, which allows the pilot to fly up to 9 g at all weights.

The F-15 Multistage Improvement Program (MSIP) was initiated in February 1983 with the first production MSIP F-15C produced in 1985. Improvements included an upgraded central computer; a Programmable Armament Control Set, allowing for advanced versions of the AIM-7, AIM-9, and AIM-120A missiles; and an expanded Tactical Electronic Warfare System that provides improvements to the ALR-56C radar warning receiver and ALQ-135 countermeasure set. The final 43 F-15Cs included the Hughes APG-70 radar developed for the F-15E; these are sometimes referred as Enhanced Eagles. Earlier MSIP F-15Cs with the APG-63 were upgraded to the APG-63(V)1 to improve maintainability and to perform similar to the APG-70. Existing F-15s were retrofitted with these improvements.

In 1979, McDonnell Douglas and F-15 radar manufacturer, Hughes, teamed to privately develop a strike fighter version of the F-15. This version competed in the Air Force's Dual-Role Fighter competition starting in 1982. The F-15E strike variant was selected for production over General Dynamics' competing F-16XL in 1984. Beginning in 1985, F-15C and D models were equipped with the improved P&W F100-PW-220 engine and digital engine controls, providing quicker throttle response, reduced wear, and lower fuel consumption. Starting in 1997, original F100-PW-100 engines were upgraded to a similar configuration with the designation F100-PW-220E starting.

Beginning in 2007, 179 USAF F-15Cs would be retrofitted with the AN/APG-63(V)3 Active Electronically Scanned Array radar. A significant number of F-15s are to be equipped with the Joint Helmet Mounted Cueing System. Lockheed Martin is working on an IRST system for the F-15C. A follow-on upgrade called the Eagle passive/active warning survivability system (EPAWSS) was planned, but remained unfunded. Boeing was selected in October 2015 to serve as prime contractor for the EPAWSS, with BAE Systems selected as a subcontractor. The EPAWSS is an all-digital system with advanced electronic countermeasures, radar warning, and increased chaff and flare capabilities in a smaller footprint than the 1980s-era Tactical Electronic Warfare System. More than 400 F-15Cs and F-15Es will have the system installed.

In September 2015, Boeing unveiled its 2040C Eagle upgrade, designed to keep the F-15 relevant through 2040. Seen as a necessity because of the low numbers of F-22s procured, the upgrade builds upon the company's F-15SE Silent Eagle concept with low-observable features. Most improvements focus on lethality including quad-pack munitions racks to double its missile load to 16, conformal fuel tanks for extended range, "Talon HATE" communications pod to communicate with fifth-generation fighters, the APG-63(v)3 AESA radar, a long-range infrared search and track sensor, and BAE Systems' EPAWSS systems.

The F-15 has an all-metal semi-monocoque fuselage with a large-cantilever, shoulder-mounted wing. The wing planform of the F-15 suggests a modified cropped delta shape with a leading-edge sweepback angle of 45°. Ailerons and a simple high-lift flap are located on the trailing edge. No leading-edge maneuvering flaps are used. This complication was avoided by the combination of low wing loading and fixed leading-edge camber that varies with spanwise position along the wing. Airfoil thickness ratios vary from 6% at the root to 3% at the tip.

The empennage is metal and composite construction, with twin aluminium/composite material honeycomb structure vertical stabilizers with boron-composite skin, resulting in an exceptionally thin tailplane and rudders. Composite horizontal all-moving tails outboard of the vertical stabilizers move independently to provide roll control in some flight maneuvers. The F-15 has a spine-mounted air brake and retractable tricycle landing gear. It is powered by two Pratt & Whitney F100 axial compressor turbofan engines with afterburners, mounted side-by-side in the fuselage and fed by intake ramps. The cockpit is mounted high in the forward fuselage with a one-piece windscreen and large canopy for increased visibility and a 360° field of view for the pilot. The airframe began to incorporate advanced superplastically formed titanium components in the 1980s.

The F-15's maneuverability is derived from low wing loading (weight to wing area ratio) with a high thrust-to-weight ratio, enabling the aircraft to turn tightly without losing airspeed. The F-15 can climb to in around 60 seconds. At certain speeds, the dynamic thrust output of the dual engines is greater than the aircraft's combat weight and drag, so it has the ability to accelerate vertically. The weapons and flight-control systems are designed so that one person can safely and effectively perform air-to-air combat. The A and C models are single-seat variants; these were the main air-superiority versions produced. B and D models add a second seat behind the pilot for training. E models use the second seat for a weapon systems officer. Visibly, the F-15 has a unique feature" vis-à-vis "other modern fighter aircraft; it does not have the distinctive "turkey feather" aerodynamic exhaust petals covering its engine nozzles, because the petal design on the F-15 was problematic and could fall off in flight; therefore, they were removed, resulting in a 3% aerodynamic drag increase.

A multimission avionics system includes a head-up display (HUD), advanced radar, AN/ASN-109 inertial guidance system, flight instruments, ultra high frequency communications, and tactical air navigation system and instrument landing system receivers. It also has an internally mounted, tactical electronic warfare system, Identification friend or foe system, an electronic countermeasures suite, and a central digital computer.

The HUD projects all essential flight information gathered by the integrated avionics system. This display, visible in any light condition, provides the pilot information necessary to track and destroy an enemy aircraft without having to look down at cockpit instruments.

The F-15's versatile APG-63 and 70 pulse-Doppler radar systems can look up at high-flying targets and look-down/shoot-down at low-flying targets without being confused by ground clutter. These radars can detect and track aircraft and small high-speed targets at distances beyond visual range down to close range, and at altitudes down to treetop level. The APG-63 has a basic range of . The radar feeds target information into the central computer for effective weapons delivery. For close-in dogfights, the radar automatically acquires enemy aircraft, and this information is projected on the head-up display. The F-15's electronic warfare system provides both threat warning (radar warning receiver) and automatic countermeasures against selected threats.

A variety of air-to-air weaponry can be carried by the F-15. An automated weapon system enables the pilot to release weapons effectively and safely, using the head-up display and the avionics and weapons controls located on the engine throttles or control stick. When the pilot changes from one weapon system to another, visual guidance for the selected weapon automatically appears on the head-up display.

The Eagle can be armed with combinations of four different air-to-air weapons: AIM-7F/M Sparrow missiles or AIM-120 AMRAAM advanced medium-range air-to-air missiles on its lower fuselage corners, AIM-9L/M Sidewinder or AIM-120 AMRAAM missiles on two pylons under the wings, and an internal M61 Vulcan Gatling gun in the right wing root.
Low-drag conformal fuel tanks (CFTs) were developed for the F-15C and D models. They can be attached to the sides of the engine air intakes under each wing and are designed to the same load factors and airspeed limits as the basic aircraft. These tanks slightly degrade performance by increasing aerodynamic drag and cannot be jettisoned in-flight. However, they cause less drag than conventional external tanks. Each conformal tank can hold 750 U.S. gallons (2,840 l) of fuel. These CFTs increase range and reduce the need for in-flight refueling. All external stations for munitions remain available with the tanks in use. Moreover, Sparrow or AMRAAM missiles can be attached to the corners of the CFTs. The 57 FIS based at Keflavik NAS, Iceland, was the only C-model squadron to use CFTs on a regular basis due to its extended operations over the North Atlantic. With the closure of the 57 FIS, the F-15E is the only variant to carry them on a routine basis. CFTs have also been sold to Israel and Saudi Arabia.

The McDonnell Douglas F-15E Strike Eagle is a two-seat, dual-role, totally integrated fighter for all-weather, air-to-air, and deep interdiction missions. The rear cockpit is upgraded to include four multipurpose cathode ray tube displays for aircraft systems and weapons management. The digital, triple-redundant Lear Siegler aircraft flight control system permits coupled automatic terrain following, enhanced by a ring-laser gyro inertial navigation system. For low-altitude, high-speed penetration and precision attack on tactical targets at night or in adverse weather, the F-15E carries a high-resolution APG-70 radar and LANTIRN pods to provide thermography. The newest F-15E version is the F-15 Advanced, which features fly-by-wire controls.

The APG-63(V)2 active electronically scanned array (AESA) radar has been retrofitted to 18 U.S. Air Force F-15C aircraft. This upgrade includes most of the new hardware from the APG-63(V)1, but adds an AESA to provide increased pilot situation awareness. The AESA radar has an exceptionally agile beam, providing nearly instantaneous track updates and enhanced multitarget tracking capability. The APG-63(V)2 is compatible with current F-15C weapon loads and enables pilots to take full advantage of AIM-120 AMRAAM capabilities, simultaneously guiding multiple missiles to several targets widely spaced in azimuth, elevation, or range. The further improved APG-63(V)3 AESA radar is expected to be fitted to 179 F-15C aircraft; the first upgraded aircraft was delivered in October 2010. The ZAP (Zone Acquisition Program) missile launch envelope has been integrated into the operational flight program system of all U.S. F-15 aircraft, providing dynamic launch zone and launch acceptability region information for missiles to the pilot by display cues in real-time.

The largest operator of the F-15 is the United States Air Force. The first Eagle, an F-15B, was delivered on 13 November 1974. In January 1976, the first Eagle destined for a combat squadron, the 555th TFS, was delivered. These initial aircraft carried the Hughes Aircraft (now Raytheon) APG-63 radar.

The first kill by an F-15 was scored by Israeli Air Force ace Moshe Melnik in 1979. During Israeli raids against Palestinian factions in Lebanon in 1979–1981, F-15As reportedly downed 13 Syrian MiG-21s and two Syrian MiG-25s. Israeli F-15As and Bs participated as escorts in Operation Opera, an air strike on an Iraqi nuclear reactor. In the 1982 Lebanon War, Israeli F-15s were credited with 41 Syrian aircraft destroyed (23 MiG-21s and 17 MiG-23s, and one Aérospatiale SA.342L Gazelle helicopter). During Operation Mole Cricket 19, Israeli F-15s and F-16s together shot down 82 Syrian fighter aircraft (MiG-21s, MiG-23s, and MiG-23Ms) with no losses.

Israel was the only operator to use and develop the air-to-ground abilities of the air-superiority F-15 variants, doing so because the fighter's range was well beyond other combat aircraft in the Israeli inventory in the 1980s. The first known use of F-15s for a strike mission was during Operation Wooden Leg on 1 October 1985, with six F-15Ds attacking PLO Headquarters in Tunis with two GBU-15 guided bombs per aircraft and two F-15Cs restriking the ruins with six Mk-82 unguided bombs each. This was one of the few times air-superiority F-15s (A/B/C/D models) were used in tactical strike missions. Israeli air-superiority F-15 variants have since been extensively upgraded to carry a wider range of air-to-ground armaments, including JDAM GPS-guided bombs and Popeye missile.

Royal Saudi Air Force F-15C pilots reportedly shot down two Iranian Air Force F-4E Phantom IIs in a skirmish on 5 June 1984.

The ASM-135 missile was designed to be a standoff antisatellite (ASAT) weapon, with the F-15 acting as a first stage. The Soviet Union could correlate a U.S. rocket launch with a spy satellite loss, but an F-15 carrying an ASAT would blend in among hundreds of F-15 flights. From January 1984 to September 1986, two F-15As were used as launch platforms for the ASAT missile. The F-15As were modified to carry one ASM-135 on the centerline station with extra equipment within a special centerline pylon. The launch aircraft executed a Mach 1.22, 3.8 g climb at 65° to release the ASAT missile at an altitude of . The flight computer was updated to control the zoom-climb and missile release.

The third test flight involved a retired P78-1 solar observatory satellite in a 345-mile (555-km) orbit, which was destroyed by kinetic energy. The pilot, USAF Major Wilbert D. "Doug" Pearson, became the only pilot to destroy a satellite. The ASAT program involved five test launches. The program was officially terminated in 1988.

The USAF began deploying F-15C, D, and E model aircraft to the Persian Gulf region in August 1990 for Operations Desert Shield and Desert Storm. During the Gulf War, the F-15 accounted for 36 of the 39 air-to-air victories by U.S. Air Force against Iraqi forces. Iraq has confirmed the loss of 23 of its aircraft in air-to-air combat. The F-15C and D fighters were used in the air-superiority role, while F-15E Strike Eagles were used in air-to-ground attacks mainly at night, hunting modified Scud missile launchers and artillery sites using the LANTIRN system. According to the USAF, its F-15Cs had 34 confirmed kills of Iraqi aircraft during the 1991 Gulf War, most of them by missile fire: five Mikoyan MiG-29s, two MiG-25s, eight MiG-23s, two MiG-21s, two Sukhoi Su-25s, four Sukhoi Su-22s, one Sukhoi Su-7, six Dassault Mirage F1s, one Ilyushin Il-76 cargo aircraft, one Pilatus PC-9 trainer, and two Mil Mi-8 helicopters. Air superiority was achieved in the first three days of the conflict; many of the later kills were reportedly of Iraqi aircraft fleeing to Iran, rather than engaging American aircraft. A Strike Eagle achieved an aerial kill of an Iraqi Mi-8 helicopter with a laser-guided bomb. Two F-15Es were lost to ground fire, another was damaged on the ground by a Scud strike on King Abdulaziz Air Base.

On 11 November 1990, a Royal Saudi Air Force (RSAF) pilot defected to Sudan with an F-15C fighter during Operation Desert Shield. Saudi Arabia paid US$40 million for return of the aircraft three months later. RSAF F-15s shot down two Iraqi Mirage F1s during the Operation Desert storm. According to the Saudis, one F-15C was lost to a crash during the Gulf War in 1991. The IRAF claims this fighter was part of two F-15Cs that engaged two Iraqi MiG-25PDs, and was hit by an R-40 missile before crashing.
They have since been deployed to support Operation Southern Watch, the patrolling of the Iraqi no-fly zones in Southern Iraq; Operation Provide Comfort in Turkey; in support of NATO operations in Bosnia, and recent air expeditionary force deployments. In 1994, two U.S. Army Sikorsky UH-60 Black Hawks were mistakenly downed by USAF F-15Cs in northern Iraq in a friendly-fire incident. USAF F-15Cs shot down four Yugoslav MiG-29s using AIM-120 and Aim-7 Radar guided missiles during NATO's 1999 intervention in Kosovo, Operation Allied Force.

All F-15 aircraft were grounded by the USAF after a Missouri Air National Guard F-15C came apart in flight and crashed on 2 November 2007. The newer F-15E fleet was later cleared for continued operations. The US Air Force reported on 28 November 2007 that a critical location in the upper longerons on the F-15C model was suspected of causing the failure, causing the fuselage forward of the air intakes, including the cockpit and radome, to separate from the airframe.

F-15A through D-model aircraft were grounded until the location received more detailed inspections and repairs as needed. The grounding of F-15s received media attention as it began to place strains on the nation's air-defense efforts. The grounding forced some states to rely on their neighboring states' fighters for air-defense protection, and Alaska to depend on Canadian Forces' fighter support.

On 8 January 2008, the USAF Air Combat Command (ACC) cleared a portion of its F-15A through D-model fleet for return to flying status. It also recommended a limited return to flight for units worldwide using the affected models. The accident review board report was released on 10 January 2008. The report stated that analysis of the F-15C wreckage determined that the longeron did not meet drawing specifications, which led to fatigue cracks and finally a catastrophic failure of the remaining support structures and breakup of the aircraft in flight. In a report released on 10 January 2008, nine other F-15s were identified to have similar problems in the longeron. As a result of these problems, General John D. W. Corley stated, "the long-term future of the F-15 is in question." On 15 February 2008, ACC cleared all its grounded F-15A/B/C/D fighters for flight pending inspections, engineering reviews, and any needed repairs. ACC also recommended release of other U.S. F-15A/B/C/D aircraft.

The F-15 has a combined air-to-air combat record of 104 kills to no losses . The F-15's air superiority versions, the A/B/C/D models, have not suffered any losses to enemy action. Over half of F-15 kills have been achieved by Israeli Air Force pilots.

On 16 September 2009, the last F-15A, an Oregon Air National Guard aircraft, was retired, marking the end of service for the F-15A and F-15B models in the United States.

With the retirement of the F-15A and B models, the F-15C and D models are supplemented in U.S. service by the newer F-22 Raptor. , regular Air Force F-15C and F-15D fighters are based overseas with the Pacific Air Forces at Kadena AB in Japan and with the U.S. Air Forces in Europe at RAF Lakenheath in the United Kingdom. Other regular Air Force F-15s are operated by ACC as adversary/aggressor platforms at Nellis AFB, Nevada, and by Air Force Material Command in test and evaluation roles at Edwards AFB, California, and Eglin AFB, Florida. All remaining combat-coded F-15Cs and F-15Ds are operated by the Air National Guard.
The USAF is upgrading 178 F-15C/Ds with the AN/APG-63(V)3 AESA radar, and equipping other F-15s with the Joint Helmet Mounted Cueing System as of 2006. In 2007, the Air Force planned to keep 178 F-15C/Ds along with 224 F-15Es in service beyond 2025.

As part of the Air Force's FY 2015 budget, the F-15C faced cuts or retirement in response to sequestration. Cuts are principally directed at platforms with single-mission capabilities. The retirement of some of the 250 F-15C fighters would save maintenance and upgrade costs, which could be redirected to speed procurement of the F-35 Lightning II. The air-to-air combat role would be taken up pre-eminently by the F-22 Raptor supported by the F-35. Even if this option is pursued, at least part of the F-15C fleet is likely to be preserved. The Air Force's FY 2015 budget proposal would reduce the F-15C fleet by 51 aircraft. Then in April 2017, Air Force officials announced plans to retire the F-15C/D in the mid-2020s and press more F-16s into roles occupied by the F-15. In December 2018 Bloomberg Government reported that the Pentagon, not the Air Force, in its 2020 budget request, will likely request US$1.2 billion for 12 new-built F-15X fighters to replace older F-15Cs operated by Air National Guard units.

The F-15E will remain in service for years to come because of the model's primary air-to-ground role and the lower number of hours on the F-15E airframes.

During the Yemeni Civil War (2015-present), Houthis have used R-27T missiles modified to serve as surface-to-air missiles. A video released on 7 January 2018 also shows a modified R-27T hitting a Saudi F-15 on a forward-looking infrared camera. Houthi sources claim to have downed the F-15, although this has been disputed, as the missile apparently proximity detonated, though the F-15 continued to fly in its trajectory seemingly unaffected. Rebels later released footage showing an aircraft wreck, but serial numbers on the wreckage suggested the aircraft was a Panavia Tornado, also operated by Saudi forces. On 8 January, the Saudi admitted the loss of an aircraft but by "Technical Reasons".

On 21 March 2018, Houthi rebels released a video where they hit and possibly shot down a Saudi F-15 in Saada province. In the video a R-27T air-to-air missile adapted for surface-to-air use was launched, appearing to have successfully hit a jet. As in the video of the previous similar hit recorded on 8 January, the target, while clearly hit, did not appear to be downed. Saudi forces confirmed the hit, while saying the jet safely landed at a Saudi base. Saudi official sources confirmed the incident, reporting that it happened at 3:48 pm local time after a surface-to-air defense missile was launched at the fighter jet from inside Saada airport.


Twelve prototypes were built and used for trials by the F-15 Joint Test Force at Edwards Air Force Base using McDonnell Douglas and United States Air Force personnel. Most prototypes were later used by NASA for trials and experiments.



A total of 175 F-15s have been lost to non-combat causes as of June 2016. However, the F-15 aircraft is very reliable with only 1 loss per 50,000 flight hours.


Although the F-15 continues to be a front-line fighter, a number of older USAF and IAF models have been retired, with several placed on outdoor display or in museums.









The F-15 was the subject of the IMAX movie "", about the RED FLAG exercises. In Tom Clancy's nonfiction book, "Fighter Wing" (1995), a detailed analysis of the Air Force's premier fighter aircraft, the F-15 Eagle and its capabilities are showcased.

The F-15 has also been a popular subject as a toy, and a fictional likeness of an aircraft similar to the F-15 has been used in cartoons, books, video games, animated television series, and animated films.




</doc>
<doc id="11719" url="https://en.wikipedia.org/wiki?curid=11719" title="Grumman F-14 Tomcat">
Grumman F-14 Tomcat

The Grumman F-14 Tomcat is an American supersonic, twin-engine, two-seat, twin-tail, variable-sweep wing fighter aircraft. It was the first such U.S. jet fighter with twin tails. The Tomcat was developed for the United States Navy's Naval Fighter Experimental (VFX) program after the collapse of the F-111B project. The F-14 was the first of the American Teen Series fighters, which were designed incorporating air combat experience against MiG fighters during the Vietnam War.

The F-14 first flew on 21 December 1970 and made its first deployment in 1974 with the U.S. Navy aboard , replacing the McDonnell Douglas F-4 Phantom II. The F-14 served as the U.S. Navy's primary maritime air superiority fighter, fleet defense interceptor, and tactical aerial reconnaissance platform into the 2000s. The Low Altitude Navigation and Targeting Infrared for Night (LANTIRN) pod system were added in the 1990s and the Tomcat began performing precision ground-attack missions.

In the 1980s, F-14s were used as land-based interceptors by the Islamic Republic of Iran Air Force during the Iran–Iraq War, where they saw combat against Iraqi warplanes. Iranian F-14s reportedly shot down at least 160 Iraqi aircraft during the war, while only 12 to 16 Tomcats were lost; at least half of these losses were due to accidents.

The Tomcat was retired from the U.S. Navy's active fleet on 22 September 2006, having been supplanted by the Boeing F/A-18E/F Super Hornet. The F-14 remains in service with Iran's air force, having been exported to Iran in 1976. In November 2015, reports emerged of Iranian F-14s flying escort for Russian Tupolev Tu-95, Tu-160 and Tu-22M bombers on air strikes in Syria.

Beginning in the late 1950s, the U.S. Navy sought a long-range, high-endurance interceptor to defend its carrier battle groups against long-range anti-ship missiles launched from the jet bombers and submarines of the Soviet Union. The U.S. Navy needed a Fleet Air Defense (FAD) aircraft with a more powerful radar and longer range missiles than the F-4 Phantom II carried to intercept both enemy bombers and missiles. The Navy was directed to participate in the Tactical Fighter Experimental (TFX) program with the U.S. Air Force by Secretary of Defense Robert McNamara. McNamara wanted "joint" solutions to service aircraft needs to reduce development costs and had already directed the Air Force to buy the F-4 Phantom II, which was developed for the Navy and Marine Corps. The Navy strenuously opposed the TFX as it feared compromises necessary for the Air Force's need for a low-level attack aircraft would adversely impact the aircraft's performance as a fighter.

Weight and performance issues plagued the U.S. Navy F-111B variant for TFX and would not be resolved to the Navy's satisfaction. The F-111 manufacturer General Dynamics partnered with Grumman on the Navy F-111B. With the F-111B program in distress, Grumman began studying improvements and alternatives. In 1966, the Navy awarded Grumman a contract to begin studying advanced fighter designs. Grumman narrowed down these designs to its 303 design. Vice Admiral Thomas F. Connolly, Deputy Chief of Naval Operations for Air Warfare, flew the developmental F-111A variant on a flight and discovered that it had difficulty going supersonic and had poor carrier landing characteristics. He later testified before Congress about his concerns against the official U.S. Department of the Navy position and, in May 1968, Congress stopped funding for the F-111B, allowing the Navy to pursue an answer tailored to its requirements. The name "Tomcat" was partially chosen to pay tribute to Admiral Connolly, as the nickname "Tom's Cat" had already been widely used by the manufacturer, although the name also followed the Grumman tradition of naming its fighter aircraft after felines.

The F-111B had been designed for the long-range Fleet Air Defense (FAD) interceptor role, but not for new requirements for air combat based on the experience of American aircraft against agile MiG fighters over Vietnam. The Navy studied the need for VFAX, an additional fighter that was more agile than the F-4 Phantom for air-combat and ground-attack roles. Grumman continued work on its 303 design and offered it to the Navy in 1967, which led to fighter studies by the Navy. The company continued to refine the design into 1968.

In July 1968, the Naval Air Systems Command (NAVAIR) issued a request for proposals (RFP) for the Naval Fighter Experimental (VFX) program. VFX called for a tandem two-seat, twin-engined air-to-air fighter with a maximum speed of Mach 2.2. It would also have a built-in M61 Vulcan cannon and a secondary close air support role. The VFX's air-to-air missiles would be either six AIM-54 Phoenix or a combination of six AIM-7 Sparrow and four AIM-9 Sidewinder missiles. Bids were received from General Dynamics, Grumman, Ling-Temco-Vought, McDonnell Douglas and North American Rockwell; four bids incorporated variable-geometry wings.
McDonnell Douglas and Grumman were selected as finalists in December 1968. Grumman was selected for the contract award in January 1969. Grumman's design reused the TF30 engines from the F-111B, though the Navy planned on replacing them with the Pratt & Whitney F401-400 engines under development for the Navy, along with the related Pratt & Whitney F100 for the USAF. Though lighter than the F-111B, it was still the largest and heaviest U.S. fighter to fly from an aircraft carrier, a consequence of the requirement to carry the large AWG-9 radar and AIM-54 Phoenix missiles (from the F-111B) and an internal fuel load of .

Upon winning the contract for the F-14, Grumman greatly expanded its Calverton, Long Island, New York facility for evaluating the aircraft. Much of the testing, including the first of many compressor stalls and multiple ejections, took place over Long Island Sound. In order to save time and forestall interference from Secretary McNamara, the Navy skipped the prototype phase and jumped directly to full-scale development; the Air Force took a similar approach with its F-15. The F-14 first flew on 21 December 1970, just 22 months after Grumman was awarded the contract, and reached initial operational capability (IOC) in 1973. The United States Marine Corps was initially interested in the F-14 as an F-4 Phantom II replacement; going so far as to send officers to Fighter Squadron One Twenty-Four (VF-124) to train as instructors. The Marine Corps pulled out of any procurement when the development of the stores' management system for ground attack munitions was not pursued. An air-to-ground capability was not developed until the 1990s.

Firing trials involved launches against simulated targets of various types, from cruise missiles to high-flying bombers. AIM-54 Phoenix missile testing from the F-14 began in April 1972. The longest single Phoenix launch was successful against a target at a range of in April 1973. Another unusual test was made on 22 November 1973, when six missiles were fired within 38 seconds at Mach 0.78 and ; four scored direct hits.

With time, the early versions of all the missiles were replaced by more advanced versions, especially with the move to full solid-state electronics that allowed better reliability, better ECCM and more space for the rocket engine. So the early arrangement of the AIM-54A Phoenix active-radar air-to-air missile, the AIM-7E-2 Sparrow semi-active radar homing air-to-air missile, and the AIM-9J Sidewinder heat-seeking air-to-air missile was replaced in the 1980s with the B (1983) and C (1986) version of the Phoenix, the F (1977), M (1982), P (1987 or later) for Sparrows, and with the Sidewinder, L (1979) and M (1982). Within these versions, there are several improved batches (for example, Phoenix AIM-54C++).

The Tactical Airborne Reconnaissance Pod System (TARPS) was developed in the late 1970s for the F-14. Approximately 65 F-14As and all F-14Ds were modified to carry the pod. TARPS was primarily controlled by the Radar Intercept Officer (RIO) via an extra display for observing reconnaissance data. The "TARPS Digital (TARPS-DI)" was a 1996 upgrade featuring a digital camera. The digital camera was further updated beginning in 1998 with the "TARPS Completely Digital (TARPS-CD)" configuration that also provided real-time transmission of imagery.

Some of the F-14A aircraft underwent engine upgrades to the GE F110-400 in 1987. These upgraded Tomcats were redesignated F-14A+, which was later changed to F-14B in 1991. The F-14D variant was developed at the same time; it included the GE F110-400 engines with newer digital avionics systems such as a glass cockpit, and compatibility with the Link 16 secure datalink. The Digital Flight Control System (DFCS) notably improved the F-14's handling qualities when flying at a high angle of attack or in air combat maneuvering.

While the F-14 had been developed as a lightweight alternative to the F-111B, the F-14 was still the heaviest and most expensive fighter of its time. VFAX was revived in the 1970s as a lower cost solution to replacing the Navy and Marine Corps's fleets of F-4s, and A-7s. VFAX was directed to review the fighters in the USAF Light Weight Fighter competition, which led to the development of the F/A-18 Hornet as roughly a midsize fighter and attack aircraft. In 1994, Congress would reject Grumman proposals to the Navy to upgrade the Tomcat beyond the D model (such as the Super Tomcat 21, the cheaper QuickStrike version, and the more advanced Attack Super Tomcat 21).

In the 1990s, with the pending retirement of the A-6 Intruder, the F-14 air-to-ground program was resurrected. Trials with live bombs had been carried out in the 1980s; the F-14 was cleared to use basic iron bombs in 1992. During Operation Desert Storm of the Gulf War, most air-to-ground missions were left to A-7, A-6 Intruder and F/A-18 Hornet squadrons, while the F-14s focused on air defense operations. Following Desert Storm, F-14As and F-14Bs underwent upgrades to avionics and cockpit displays to enable the use of precision munitions, enhance defensive systems, and apply structural improvements. The new avionics were comparable with the F-14D; these upgraded aircraft were designated F-14A (Upgrade) and F-14B (Upgrade) respectively.

By 1994, Grumman and the Navy were proposing ambitious plans for Tomcat upgrades to plug the gap between the retirement of the A-6 and the F/A-18E/F Super Hornet entering service. However, the upgrades would have taken too long to implement to meet the gap, and were priced in the billions. The U.S. Congress considered this too expensive for an interim solution. A quick, inexpensive upgrade using the Low Altitude Navigation and Targeting Infrared for Night (LANTIRN) targeting pod was devised. The LANTIRN pod provided the F-14 with a forward-looking infrared (FLIR) camera for night operations and a laser target designator to direct laser-guided bombs (LGB). Although LANTIRN is traditionally a two-pod system, an AN/AAQ-13 navigation pod with terrain-following radar and a wide-angle FLIR, along with an AN/AAQ-14 targeting pod with a steerable FLIR and a laser target designator, the decision was made to only use the targeting pod. The Tomcat's LANTIRN pod was altered and improved over the baseline configuration, such as a Global Positioning System / Inertial Navigation System (GPS-INS) capability to allow an F-14 to accurately locate itself. The pod was carried on the right wing glove pylon.
The LANTIRN pod did not require changes to the F-14's own system software, but the pod was designed to operate on a MIL-STD-1553B bus not present on the F-14A or B. Consequently, Martin Marietta specially developed an interface card for LANTIRN. The Radar Intercept Officer (RIO) would receive pod imagery on a 10-inch Programmable Tactical Information Display (PTID) or another Multi-Function Display in the F-14 rear cockpit and guided LGBs using a new hand controller installed on the right side console. Initially, the hand controller replaced the RIO's TARPS control panel, meaning a Tomcat configured for LANTIRN could not carry TARPS and the reverse, but eventually a workaround was later developed to allow a Tomcat to carry LANTIRN or TARPS as needed.

An upgraded LANTIRN named "LANTIRN 40K" for operations up to was introduced in 2001, followed by Tomcat Tactical Targeting (T3) and Fast Tactical Imagery (FTI), to provide precise target coordinate determination and ability to transmit images in-flight. Tomcats also added the ability to carry the GBU-38 Joint Direct Attack Munition (JDAM) in 2003, giving it the option of a variety of LGB and GPS-guided weapons. Some F-14Ds were upgraded in 2005 with a ROVER III Full Motion Video (FMV) downlink, a system that transmits real-time images from the aircraft's sensors to the laptop of Forward air controller (FAC) on the ground.

The F-14 Tomcat was designed as both an air superiority fighter and a long-range naval interceptor, which enabled it to both serve as escort attack aircraft when armed with Sparrow missiles and fleet air defense loitering interceptor role when armed with Phoenix missiles. The F-14 was designed with a two-seat cockpit with a bubble canopy which affords all-around visibility aiding aircrew in air-to-air combat. It features variable geometry wings that swing automatically during flight. For high-speed intercept, they are swept back and they swing forward for lower speed flight. It was designed to improve on the F-4 Phantom's air combat performance in most respects.

The F-14's fuselage and wings allow it to climb faster than the F-4, while the twin-tail arrangement offers better stability. The F-14 is equipped with an internal 20 mm M61 Vulcan Gatling cannon mounted on the left side (unlike the Phantom, which was not equipped with an internal gun in the US Navy), and can carry AIM-54 Phoenix, AIM-7 Sparrow, and AIM-9 Sidewinder anti-aircraft missiles. The twin engines are housed in widely spaced nacelles. The flat area of the fuselage between the nacelles is used to contain fuel and avionics systems, such as the wing-sweep mechanism and flight controls, as well as weaponry since the wings are not used for carrying ordnance. By itself, the fuselage provides approximately 40 to 60 percent of the F-14's aerodynamic lifting surface depending on the wing sweep position. The lifting body characteristics of the fuselage allowed one F-14 to safely land after suffering a mid-air collision that sheared off more than half of the plane's right wing in 1991.

The F-14's wing sweep can be varied between 20° and 68° in flight, and can be automatically controlled by the Central Air Data Computer, which maintains wing sweep at the optimum lift-to-drag ratio as the Mach number varies; pilots can manually override the system if desired. When parked, the wings can be "overswept" to 75° to overlap the horizontal stabilizers to save deck space aboard carriers. In an emergency, the F-14 can land with the wings fully swept to 68°, although this presents a significant safety hazard due to greatly increased stall speed. Such an aircraft would typically be diverted from an aircraft carrier to a land base if an incident did occur. The F-14 has flown safely with an asymmetrical wing-sweep during testing, and was deemed able to land aboard a carrier if needed in an emergency. The wing pivot points are significantly spaced far apart. This has two benefits. The first is that weaponry can be fitted on a pylon on the fixed wing glove, liberating the wings from having swiveling pylons fitted, a feature which had proven to add significant drag on the F-111B. Since less of the total lifting area is variable, the centre of lift moves less as the wings moves, reducing trim drag at high speed. When the wing is swept back, its thickness-to-chord ratio decreases, which allows the aircraft to satisfy the Mach 2.4 top speed required by the U.S. Navy. The body of the aircraft contributes significantly to overall lift and so the Tomcat possesses a lower wing loading than its wing area would suggest. When carrying four Phoenix missiles or other heavy stores between the engines this advantage is lost and maneuverability is reduced in those configurations.
Ailerons are not fitted, with roll control being provided by wing-mounted spoilers at low speed (which are disabled if the sweep angle exceeds 57°), and by differential operation of the all-moving tailerons at high speed. Full-span slats and flaps are used to increase lift both for landing and combat, with slats being set at 17° for landing and 7° for combat, while flaps are set at 35° for landing and 10° for combat. An air bag fills up the space occupied by the swept-back wing when the wing is in the forward position and a flexible fairing on top of the wing smooths out the shape transition between the fuselage and top wing area. The twin tail layout helps in maneuvers at high angle of attack (AoA) while reducing the height of the aircraft to fit within the limited roof clearance of hangars aboard aircraft carriers.
Two triangular shaped retractable surfaces, called glove vanes, were originally mounted in the forward part of the wing glove, and could be automatically extended by the flight control system at high Mach numbers. They were used to generate additional lift (force) ahead of the aircraft's center of gravity, thus helping to compensate for mach tuck at supersonic speeds. Automatically deployed at above Mach 1.4, they allowed the F-14 to pull 7.5 g at Mach 2 and could be manually extended with wings swept full aft. They were later disabled, however, owing to their additional weight and complexity. The air brakes consist of top-and-bottom extendable surfaces at the rearmost portion of the fuselage, between the engine nacelles. The bottom surface is split into left and right halves; the tailhook hangs between the two-halves, an arrangement sometimes called the "castor tail".

The F-14 was initially equipped with two Pratt & Whitney TF30 (or JTF10A) augmented turbofan engines, each rated at 20,900 lb (93 kN) of thrust, which enabled the aircraft to attain a maximum speed of Mach 2.34. The F-14 would normally fly at a cruising speed for reduced fuel consumption, which was important for conducting lengthy patrol missions. Both of the engine's rectangular air intake ramps were equipped with movable ramps and bleed doors to meet the airflow requirements of the engine but prevent dangerous shockwaves from entering. De Laval nozzles were also fitted to the engine's exhaust.
The performance of the TF30 engine became an object of criticism. John Lehman, Secretary of the Navy in the 1980s, told the U.S. Congress that the TF30/F-14 combination was "probably the worst engine/airframe mismatch we have had in years" and that the TF30 was "a terrible engine"; 28% of all F-14 accidents were attributed to the engine. A high frequency of turbine blade failures led to the reinforcement of the entire engine bay to limit damage from such failures. The engines also had proved to be extremely prone to compressor stalls, which could easily result in loss of control, severe yaw oscillations, and could lead to an unrecoverable flat spin. At specific altitudes, exhaust produced by missile launches could cause an engine compressor stall. This led to the development of a bleed system that temporarily blocks the frontal intake ramp and reduces engine power during missile launch. With the TF30, the F-14's overall thrust-to-weight ratio at maximum takeoff weight is around 0.56, considerably less than the F-15A's ratio of 0.85; when fitted with the General Electric F110 engine, an improved thrust-to-weight ratio of 0.73 at maximum weight and 0.88 at normal takeoff weight was achieved. Despite having large differences in thrust, the F-14A, F-14B, and later F-14D with the newer General Electric F110 engines were rated at the same top speed.

The wings have a two-spar structure with integral fuel tanks. Around 25% of the structure is made of titanium, including the wing box, wing pivots, and upper and lower wing skins; this is a light, rigid, and strong material. Electron beam welding was used in the construction of the titanium parts.

The landing gear is very robust, in order to withstand catapult launches (takeoffs) and recoveries (landings) needed for carrier operations. It comprises a double nosewheel and widely spaced single main wheels. There are no hardpoints on the sweeping parts of the wings, and so all the armament is fitted on the belly between the air intake ramps and on pylons under the wing gloves. Internal fuel capacity is : in each wing, in a series of tanks aft of the cockpit, and a further in two feeder tanks. It can carry two external drop tanks under the engine intake ramps. There is also an air-to-air refueling probe, which folds into the starboard nose.

The cockpit has two seats, arranged in tandem, outfitted with Martin-Baker GRU-7A rocket-propelled ejection seats, rated from zero altitude and zero airspeed up to 450 knots. The canopy is spacious, and fitted with four mirrors to effectively provide all-round visibility. Only the pilot has flight controls; the flight instruments themselves are of a hybrid analog-digital nature. The cockpit also features a head-up display (HUD) to show primarily navigational information; several other avionics systems such as communications and direction-finders are integrated into the AWG-9 radar's display. A significant feature of the F-14 is its Central Air Data Computer (CADC), designed by Garrett AiResearch, that forms the onboard integrated flight control system. It uses a MOSFET-based Large-Scale Integration chipset, the MP944, making it the first microprocessor in history.
The aircraft's large nose contains a two-person crew and several bulky avionics systems. The main element is the Hughes AN/AWG-9 X band radar; the antenna is a -wide planar array, and has integrated Identification friend or foe antennas. The AWG-9 has several search and tracking modes, such as Track while scan (TWS), Range-While-Search (RWS), Pulse-Doppler Single-Target Track (PDSTT), and Jam Angle Track (JAT); a maximum of 24 targets can be tracked simultaneously, and six can be engaged in TWS mode up to around . Cruise missiles are also possible targets with the AWG-9, which can lock onto and track small objects even at low altitude when in Pulse-Doppler mode. For the F-14D, the AWG-9 was replaced by the upgraded APG-71 radar. The Joint Tactical Information Distribution System (JTIDS)/Link 16 for data communications was added later on.

The F-14 also features electronic countermeasures (ECM) and radar warning receiver (RWR) systems, chaff/flare dispensers, fighter-to-fighter data link, and a precise inertial navigation system. The early navigation system was inertial-based; point-of-origin coordinates were programmed into a navigation computer and gyroscopes would track the aircraft's every motion to calculate distance and direction from that starting point. Global Positioning System later was integrated to provide more precise navigation and redundancy in case either system failed. The chaff/flare dispensers are located on the underside of the fuselage and on the tail. The RWR system consists of several antennas on the aircraft's fuselage, which can roughly calculate both direction and distance of enemy radar users; it can also differentiate between search radar, tracking radar, and missile-homing radar.

Featured in the sensor suite was the AN/ALR-23, an Infra-red search and track sensor using indium antimonide detectors, mounted under the nose; however this was replaced by an optical system, Northrop's AAX-1, also designated TCS (TV Camera Set). The AAX-1 helps pilots visually identify and track aircraft, up to a range of for large aircraft. The radar and the AAX-1 are linked, allowing the one detector to follow the direction of the other. A dual infrared/optical detection system was adopted on the later F-14D.

The F-14 was designed to combat highly maneuverable aircraft as well as the Soviet anti-ship cruise missile and bomber (Tupolev Tu-16, Tupolev Tu-22, Tupolev Tu-22M) threats. The Tomcat was to be a platform for the AIM-54 Phoenix, but unlike the canceled F-111B, it could also engage medium- and short-range threats with other weapons. The F-14 is an air superiority fighter, not just a long-range interceptor aircraft. Over of stores can be carried for combat missions on several hardpoints under the fuselage and under the wings. Commonly, this means a maximum of two–four Phoenixes or Sparrows on the belly stations, two Phoenixes/Sparrows on the wing hardpoints, and two Sidewinders on the wing hardpoints. The F-14 is also fitted with an internal 20 mm M61 Vulcan Gatling-type cannon.

Operationally, the capability to hold up to six Phoenix missiles was never used, although early testing was conducted; there was never a threat requirement to engage six hostile targets simultaneously and the load was too heavy to safely recover aboard an aircraft carrier in the event that the missiles were not fired. During the height of Cold War operations in the late 1970s and 1980s, the typical weapon loadout on carrier-deployed F-14s was usually two AIM-54 Phoenixes, augmented by two AIM-9 Sidewinders, three AIM-7 Sparrow IIIs, a full loadout of 20 mm ammunition and two drop tanks. The Phoenix missile was used twice in combat by the U.S. Navy, both over Iraq in 1999, but the missiles did not score any kills.

Iran made use of the Phoenix system, claiming dozens of kills with it during the 1980–1988 Iran–Iraq War. Due to shortage of air-to-air missiles, Iran tried to use other missiles on the Tomcat. It attempted to integrate the Russian R-27R "Alamo" BVR missile, but was apparently unsuccessful. In 1985, Iran started Project Sky Hawk, attempting to adapt I-Hawk surface-to-air missiles, which Iran had in its inventory, for F-14s. The modified missiles were successfully tested in 1986 and one or two were used in combat, but the project was abandoned due to guidance problems.

The F-14 began replacing the F-4 Phantom II in U.S. Navy service starting in September 1974 with squadrons VF-1 "Wolfpack" and VF-2 "Bounty Hunters" aboard and participated in the American withdrawal from Saigon. The F-14 had its first kills in U.S. Navy service on 19 August 1981 over the Gulf of Sidra in what is known as the Gulf of Sidra incident. In that engagement, two F-14s from VF-41 Black Aces were engaged by two Libyan Su-22 "Fitters". The F-14s evaded the short range heat seeking AA-2 "Atoll" missile and returned fire, downing both Libyan aircraft. U.S. Navy F-14s once again were pitted against Libyan aircraft on 4 January 1989, when two F-14s from VF-32 shot down two Libyan MiG-23 "Floggers" over the Gulf of Sidra in a second Gulf of Sidra incident.

Its first sustained combat use was as a photo reconnaissance platform. The Tomcat was selected to inherit the reconnaissance mission upon the departure of the dedicated RA-5C Vigilante and RF-8G Crusaders from the fleet. A large pod called the Tactical Airborne Reconnaissance Pod System (TARPS) was developed and fielded on the Tomcat in 1981. With the retirement of the last RF-8G Crusaders in 1982, TARPS F-14s became the U.S. Navy's primary tactical reconnaissance system. One of two Tomcat squadrons per airwing was designated as a TARPS unit and received 3 TARPS capable aircraft and training for 4 TARPS aircrews.
While the Tomcat was being used by Iran in combat against Iraq in its intended air superiority mission in the early 1980s, the U.S. Navy found itself flying regular daily combat missions over Lebanon to photograph activity in the Bekaa Valley. At the time, the Tomcat had been thought too large and vulnerable to be used over land, but the need for imagery was so great that Tomcat aircrews developed high-speed medium altitude tactics to deal with considerable AAA and SA-7 SAM threat in the Bekaa area. The first exposure of a Navy Tomcat to an SA-2 missile was over Somalia in April 1983 when a local battery was unaware of two Tomcats scheduled for a TARPS mission in a prelude to an upcoming international exercise in the vicinity of Berbera. An SA-2 was fired at the second Tomcat while conducting 10,000-ft mapping profile at max conserve setting. The Tomcat aircrews spotted the missile launch and dove for the deck thereby evading it without damage. The unexpected demand for combat TARPS laid the way for high altitude sensors such as the KA-93 Long Range Optics (LOROP) to be rapidly procured for the Tomcat as well as an Expanded Chaff Adapter (ECA) to be incorporated in an AIM-54 Phoenix Rail. Commercial "Fuzz buster" type radar detectors were also procured and mounted in pairs in the forward cockpit as a stop gap solution to detect SAM radars such as the SA-6. The ultimate solution was an upgrade to the ALR-67 then being developed, but it would not be ready until the advent of the F-14A+ later in the 1980s.
The participation of the F-14 in the 1991 Operation Desert Storm consisted of Combat Air Patrol (CAP) over the Red Sea and the Persian Gulf and overland missions consisting of strike escort and reconnaissance. Until the waning days of Desert Storm, in-country air superiority was tasked to USAF F-15 Eagles due to the way the Air Tasking Orders (ATO) delegated primary overland CAP stations to the F-15 Eagle. The governing Rules of Engagement (ROE) also dictated a strict Identification Friend or Foe (IFF) requirement when employing Beyond Visual Range weapons such as the AIM-7 Sparrow and particularly the AIM-54 Phoenix. This hampered the Tomcat from using its most powerful weapon. Furthermore, the powerful emissions from the AWG-9 radar are detectable at great range with a radar warning receiver. Iraqi fighters routinely retreated as soon as the Tomcats "lit them up" with the AWG-9. The U.S. Navy suffered its only F-14 loss from enemy action on 21 January 1991 when BuNo 161430, an F-14A upgraded to an F-14A+, from VF-103 was shot down by an SA-2 surface-to-air missile while on an escort mission near Al Asad airbase in Iraq. Both crews survived ejection with the pilot being rescued by USAF Special Operation Forces and the RIO being captured by Iraqi troops as a POW until the end of the war. The F-14 also achieved its final kill in US service, a Mi-8 "Hip" helicopter, with an AIM-9 Sidewinder.
In 1995, F-14s from VF-14 and VF-41 participated in Operation Deliberate Force as well as Operation Allied Force in 1999, and in 1998, VF-32 and VF-213 participated in Operation Desert Fox. On 15 February 2001, the Joint Direct Attack Munition or JDAM was added to the Tomcat's arsenal. On 7 October 2001, F-14s would lead some of the first strikes into Afghanistan marking the start of Operation Enduring Freedom and the first F-14 drop of a JDAM occurred on 11 March 2002. F-14s from VF-2, VF-31, VF-32, VF-154, and VF-213 would also participate in Operation Iraqi Freedom. The F-14Ds of VF-2, VF-31, and VF-213 obtained JDAM capability in March 2003. On 10 December 2005, the F-14Ds of VF-31 and VF-213 were upgraded with a ROVER III downlink for transmitting images to a ground Forward Air Controller (FAC). The Navy decided to retire the F-14 with the F/A-18E/F Super Hornet filling the roles of fleet defense and strike formerly filled by the F-14.
The last American F-14 combat mission was completed on 8 February 2006, when a pair of Tomcats landed aboard after one dropped a bomb over Iraq. During their final deployment with "Theodore Roosevelt", VF-31 and VF-213 collectively completed 1,163 combat sorties totaling 6,876 flight hours, and dropped of ordnance during reconnaissance, surveillance, and close air support missions in support of Operation Iraqi Freedom. USS "Theodore Roosevelt" launched an F-14D, of VF-31, for the last time on 28 July 2006; piloted by Lt. Blake Coleman and Lt. Cmdr Dave Lauderbaugh as RIO. The last two F-14 squadrons, the VF-31 Tomcatters, and the VF-213 Black Lions conducted their last fly-in at Naval Air Station Oceana on 10 March 2006.

The official final flight retirement ceremony was on 22 September 2006 at Naval Air Station Oceana and was flown by Lt. Cmdr. Chris Richard and Lt. Mike Petronis as RIO in a backup F-14 after the primary aircraft experienced mechanical problems. The actual last flight of an F-14 in U.S. service took place 4 October 2006, when an F-14D of VF-31 was ferried from NAS Oceana to Republic Airport on Long Island, New York. The remaining intact F-14 aircraft in the U.S. were flown to and stored at the 309th Aerospace Maintenance and Regeneration Group "Boneyard", at Davis-Monthan Air Force Base, Arizona; in 2007 the U.S. Navy announced plans to shred the remaining F-14s to prevent any components from being acquired by Iran. In August 2009, the 309th AMARG stated that the last aircraft were taken to HVF West, Tucson, Arizona for shredding. At that time only 11 F-14s remained in desert storage.

The sole foreign customer for the Tomcat was the Imperial Iranian Air Force, during the reign of the last Shah of Iran, Mohammad Reza Pahlavi. In the early 1970s, the Imperial Iranian Air Force (IIAF) was searching for an advanced fighter, specifically one capable of intercepting Soviet MiG-25 reconnaissance flights. After a visit of U.S. President Richard Nixon to Iran in 1972, during which Iran was offered the latest in American military technology, the IIAF narrowed its choice between the F-14 Tomcat or the McDonnell Douglas F-15 Eagle. Grumman Corporation arranged a competitive demonstration of the Eagle against the Tomcat before the Shah, and in January 1974, Iran ordered 30 F-14s and 424 AIM-54 Phoenix missiles, initiating Project "Persian King", worth US$300 million. A few months later, this order was increased to a total of 80 Tomcats and 714 Phoenix missiles as well as spare parts and replacement engines for 10 years, complete armament package, and support infrastructure (including construction of the Khatami Air Base near Isfahan).

The first F-14 arrived in January 1976, modified only by the removal of classified avionics components, but fitted with the TF-30-414 engines. The following year 12 more were delivered. Meanwhile, training of the first groups of Iranian crews by the U.S. Navy was underway in the US; one of these conducted a successful shoot-down with a Phoenix missile of a target drone flying at .

Following the overthrow of the Shah in 1979, the air force was renamed the Islamic Republic of Iran Air Force (IRIAF) and the post-revolution Interim Government of Iran canceled most Western arms orders. In 1980, an Iranian F-14 shot down an Iraqi Mil Mi-25 helicopter for its first air-to-air kill during the Iran–Iraq War (1980–1988). According to research by Tom Cooper, Iranian F-14s scored at least 50 air-to-air victories in the first six months of the war against Iraqi MiG-21s, MiG-23s, and some Su-20s/22s. During the same period, only one Iranian F-14 suffered damage after being hit by debris from a nearby MiG-21 that exploded.

Iranian Tomcats were originally used as an early-warning platform assisting other less-sophisticated aircraft with targeting and defense. They were also crucial to the defense of areas deemed vital by the Iranian government, such as oil terminals on Kharg Island and industrial infrastructure in the capital Tehran. Many of these patrols had the support of Boeing 707-3J9C in-flight refueling tankers. As fighting escalated between 1982 and 1986, the F-14s gradually became more involved in the battle. They performed well, but their primary role was to intimidate the Iraqi Air Force and avoid heavy engagement to protect the fleet's numbers. Their presence was often enough to drive away opposing Iraqi fighters. The precision and effectiveness of the Tomcat's AWG-9 weapons system and AIM-54A Phoenix long-range air-to-air missiles enabled the F-14 to maintain air superiority.
By 1987, the Iraqis had suffered heavy losses and were forced to find a solution to level the battlefield. They obtained Mirage F.1EQ-6 fighters from France in 1988, armed with Super530D and Magic Mk.2 air-to-air missiles. The Mirage F.1 fighters were eventually responsible for three confirmed F-14 kills. The IRIAF attempted to keep 60 F-14s operational throughout the war, but reports indicate this number was reduced to 30 by 1986 with only half fully mission-capable.

Based on research by Tom Cooper and Farzad Bishop, Iranian F-14s shot down at least 160 Iraqi aircraft during the Iran–Iraq War, including 58 MiG-23s, 33 Mirage F1s, 23 MiG-21s, 23 Su-20s/22s, nine MiG-25s, five Tu-22s, two MiG-27s, one Mil Mi-24, one Dassault Mirage 5, one B-6D, one Aérospatiale Super Frelon, and two unidentified aircraft. Despite the circumstances the F-14s and their crews faced during the war against Iraq – lacking support from AWACS, AEW aircraft, and Ground Control Intercept (GCI) – the F-14 proved to be successful in combat. It achieved this in the midst of a confrontation with an enemy that was constantly upgrading its capabilities and receiving support from three major countries – France, the US, and the USSR. Part of the success is attributed to the resilient Iranian economy and IRIAF personnel.

While Iraq's army claimed it shot down more than 70 F-14s, the Foreign Broadcast Information System in Washington DC estimated that Iran lost 12 to 16 during the war. Cooper writes only three F-14 were shot down by Iraqis and four by Iranian surface-to-air missiles (SAM). Two Tomcats were lost in unknown circumstances during the battle, and seven crashed due to technical failure or accidents. During the war, the Iranian Air Force F-14s suffered 9 confirmed losses, one lost due to engine stall, one in unknown conditions, two by Iranian Hawk SAMs, two by MIG-23s and three were shot down by Mirage F-1EQs. There are also unconfirmed reports of the downing of 10 more Tomcats.

On 31 August 1986, an Iranian F-14A armed with at least one AIM-54A missile defected to Iraq. In addition, one or more of Iran's F-14A was delivered to the Soviet Union in exchange for technical assistance; at least one of its crew defected to the Soviet Union.

Iran had an estimated 44 F-14s in 2009 according to Combat Aircraft. Aviation Week estimated it had 19 operational F-14s in January 2013, and Flight Global estimated that 28 were in service in 2014.
Following the US Navy's retirement of its Tomcats in 2006, Iran sought to purchase spare parts for its aircraft. In January 2007, the U.S. Department of Defense announced that sales of spare F-14 parts would be suspended over concerns of the parts ending up in Iran. In July 2007, the remaining American F-14s were shredded to ensure that any parts could not be acquired. Despite these measures, Iran managed to significantly increase its stocks of spare parts, increasing the number of airworthy Tomcats, although as it did not manage to obtain spare parts for the aircraft's weapon systems, the number of combat ready Tomcats was still low (seven in 2008). In 2010, Iran requested that the U.S. deliver the 80th F-14 that it had purchased in 1974 but never received due to the Islamic Revolution. In October 2010, an Iranian Air Force commander claimed that the country overhauls and optimizes different types of military aircraft, mentioning that Air Force has installed Iran-made radar systems on the F-14. In 2012, the Iranian Air Force's Mehrabad Overhaul Center delivered an F-14 with upgraded weapon systems with locally sourced components, designated F-14AM. Shortages of Phoenix missiles, led to attempts to integrate the Russian R-27 semi-active radar-guided missile, but these proved unsuccessful. An alternative was the use of modified MIM-23 Hawk missiles to replace the Tomcat's Phoenixes and Sparrows, but as the Tomcat could only carry two Hawks, this project was also abandoned, and the Fakour-90 missile, which used the guidance system of the Hawk packaged into the airframe of the Phoenix, launched. Pre-production Fakour-90s were delivered in 2017, and a production order for 100 missiles (now designated AIM-23B) was placed in 2018, intending to replace the F-14s AIM-7E Sparrow missiles.

On 26 January 2012, an Iranian F-14 crashed three minutes after takeoff. Both crew members were killed.

In November 2015, Iranian F-14s had been reported flying escort for Russian Tu-95 bombers on air strikes in Syria against the Islamic State of Iraq and the Levant.

A total of 712 F-14s were built from 1969 to 1991. F-14 assembly and test flights were performed at Grumman's plant in Calverton on Long Island, New York. Grumman facility at nearby Bethpage, New York was directly involved in F-14 manufacturing and was home to its engineers. The airframes were partially assembled in Bethpage and then shipped to Calverton for final assembly. Various tests were also performed at the Bethpage Plant. Over 160 of the U.S. aircraft were destroyed in accidents.

The F-14A was the initial two-seat, twin-engine, all-weather interceptor fighter variant for the U.S. Navy. It first flew on 21 December 1970. The first 12 F-14As were prototype versions (sometimes called YF-14As). Modifications late in its service life added precision strike munitions to its armament. The U.S. Navy received 478 F-14A aircraft and 79 were received by Iran. The final 102 F-14As were delivered with improved Pratt & Whitney TF30-P-414A engines. Additionally, an 80th F-14A was manufactured for Iran, but was delivered to the U.S. Navy.

The F-14 received its first of many major upgrades in March 1987 with the F-14A Plus (or F-14A+). The F-14A's TF30 engine was replaced with the improved GE F110-GE-400 engine. The F-14A+ also received the state-of-the-art ALR-67 Radar Homing and Warning (RHAW) system. Much of the avionics components, as well as the AWG-9 radar, were retained. The F-14A+ was later redesignated F-14B on 1 May 1991. A total of 38 new aircraft were manufactured and 48 F-14A were upgraded into B variants.

The TF30 had been plagued from the start with susceptibility to compressor stalls at high AoA and during rapid throttle transients or above . The F110-GE-400 engine provided a significant increase in thrust, producing with afterburner at sea level, which rose to at Mach 0.9. The increased thrust gave the Tomcat a better than 1:1 thrust-to-weight ratio at low fuel quantities. The basic engine thrust without afterburner was powerful enough for carrier launches, further increasing safety. Another benefit was allowing the Tomcat to cruise comfortably above , which increased its range and survivability. The F-14B arrived in time to participate in Desert Storm.

In the late 1990s, 67 F-14Bs were upgraded to extend airframe life and improve offensive and defensive avionics systems. The modified aircraft became known as "F-14B Upgrade".

The final variant of the F-14 was the F-14D Super Tomcat. The F-14D variant was first delivered in 1991. The original Pratt & Whitney TF30 engines were replaced with General Electric F110-GE-400 engines, similar to the F-14B. The F-14D also included newer digital avionics systems including a glass cockpit and replaced the AWG-9 with the newer AN/APG-71 radar. Other systems included the Airborne Self Protection Jammer (ASPJ), Joint Tactical Information Distribution System (JTIDS), SJU-17(V) Naval Aircrew Common Ejection Seats (NACES), and Infra-red search and track (IRST).
The GE F110-GE-400 engine provided increased thrust and additional endurance to extend range or to stay on station much longer. In the overland attack role this gave the F-14D 60 percent more striking range or one-third more time on station. The rate of climb was increased by 61 percent. The F110's increased thrust allowed almost all carrier launches to be made in military (dry) power. While this did result in fuel savings, the main reason not to use afterburner during carrier launches was that if an engine failed the F110's thrust in full afterburner would produce a yawing moment too abruptly for the pilot to correct. Thus the launch of an F-14D with afterburner was rare, while the F-14A required full afterburner unless very lightly loaded.

Although the F-14D was to be the definitive version of the Tomcat, not all fleet units received the D variant. In 1989, Secretary of Defense Dick Cheney refused to approve the purchase of any more F-14D model aircraft for $50 million each and pushed for a $25 million modernization of the F-14 fleet instead. Congress decided not to shut production down and funded 55 aircraft as part of a compromise. A total of 37 new aircraft were completed, and 18 F-14A models were upgraded to D-models, designated F-14D(R) for a rebuild. An upgrade to the F-14D's computer software to allow AIM-120 AMRAAM missile capability was planned but was later terminated.

While upgrades had kept the F-14 competitive with modern fighter aircraft technology, Cheney called the F-14 1960s technology. Despite an appeal from the Secretary of the Navy for at least 132 F-14Ds and some aggressive proposals from Grumman for a replacement, Cheney planned to replace the F-14 with a fighter that was not manufactured by Grumman. Cheney called the F-14 a "jobs program", and when the F-14 was canceled, an estimated 80,000 jobs of Grumman employees, subcontractors, or support personnel were affected. Starting in 2005, some F-14Ds received the ROVER III upgrade.

The first "F-14B" was to be an improved version of the F-14A with more powerful "Advanced Technology Engine" F401 turbofans. The "F-14C" was a projected variant of this initial F-14B with advanced multi-mission avionics. Grumman also offered an interceptor version of the F-14B in response to the U.S. Air Force's Improved Manned Interceptor Program to replace the Convair F-106 Delta Dart as an Aerospace Defense Command interceptor in the 1970s. The F-14B program was terminated in April 1974.

Grumman proposed a few improved "Super Tomcat" versions. The first was the "Quickstrike", which was an F-14D with navigational and targeting pods, additional attach points for weapons, and added ground attack capabilities to its radar. The Quickstrike was to fill the role of the A-6 Intruder after it was retired. This was not considered enough of an improvement by Congress, so the company shifted to the "Super Tomcat 21" proposed design. The Super Tomcat 21 was a proposed lower cost alternative to the Navy Advanced Tactical Fighter (NATF). The Grumman design would have the same shape and body as the Tomcat, and an upgraded AN/APG-71 radar. New GE F110-129 engines were to provide a supercruise speed of Mach 1.3 and featured thrust vectoring nozzles. The version would have increased fuel capacity and modified control surfaces for improved takeoffs and lower landing approach speed. The "Attack Super Tomcat 21" version was the last Super Tomcat proposed design. It added even more fuel capacity, more improvements to control surfaces, and possibly an active electronically scanned array (AESA) radar from the canceled A-12 attack aircraft.

The last "Tomcat" variant was the "ASF-14" (Advanced Strike Fighter-14), Grumman's replacement for the NATF concept. By all accounts, it would not be even remotely related to the previous Tomcats save in appearance, incorporating the new technology and design know-how from the Advanced Tactical Fighter (ATF) and Advanced Tactical Aircraft (ATA) programs. The ASF-14 would have been a new-build aircraft; however, its projected capabilities were not that much better than that of the (A)ST-21 variants. In the end, the Attack Super Tomcat was considered to be too costly. The Navy decided to pursue the cheaper F/A-18E/F Super Hornet to fill the fighter-attack role.



Notable F-14s preserved at museums and military installations include:

The Tomcat logo design came when Grumman's Director of Presentation Services, Dick Milligan, and one of his artists, Grumman employee Jim Rodriguez, were asked for a logo by Grumman's Director of Business Development and former Blue Angels No. 5 pilot, Norm Gandia. Per Rodriguez, "He asked me to draw a lifelike Tomcat wearing boxing gloves and trunks sporting a six-shooter on his left side; where the guns are located on the F-14, along with two tails." The Cat was drawn up after a tabby cat was sourced and used for photographs, and named "Tom". The logo has gone through many variations, including one for the then–Imperial Iranian Air Force F-14, called "Ali-cat". The accompanying slogan "Anytime Baby!" was developed by Norm Gandia as a challenge to the U.S. Air Force's McDonnell Douglas F-15 Eagle.

The Grumman F-14 Tomcat was central to the 1986 film "Top Gun". The aviation-themed film was such a success in creating interest in naval aviation that the US Navy, which assisted with the film, set up recruitment desks outside some theaters. Producers paid the US Navy $886,000 as reimbursement for flight time of aircraft in the film with an F-14 billed at $7,600 per flight hour.

Two F-14As of VF-84 from the USS "Nimitz" appeared in the 1980 film "The Final Countdown", with four from the squadron in the 1996 release "Executive Decision", the Jolly Rogers' final film appearance before being disestablished. The military legal drama TV series "JAG" (1995–2005) featured lead character Harmon Rabb, a Tomcat pilot-turned-lawyer, and the Tomcat was a central part of the Stephen Coonts novel "Final Flight".

The F-14 Tomcat is the primary focus of the 1987 Williams pinball machine "F-14 Tomcat".



</doc>
<doc id="11720" url="https://en.wikipedia.org/wiki?curid=11720" title="Lockheed F-117 Nighthawk">
Lockheed F-117 Nighthawk

The Lockheed F-117 Nighthawk is a retired American single-seat, twin-engine stealth attack aircraft that was developed by Lockheed's secretive Skunk Works division and operated by the United States Air Force (USAF). The F-117 was based on the "Have Blue" technology demonstrator.

The Nighthawk was the first operational aircraft to be designed around stealth technology. Its maiden flight took place in 1981 at Groom Lake, Nevada, and the aircraft achieved initial operating capability status in 1983. The Nighthawk was shrouded in secrecy until it was revealed to the public in 1988. Of the 64 F-117s built, 59 were production versions, with the other five being prototypes.

The F-117 was widely publicized for its role in the Persian Gulf War of 1991. Although it was commonly referred to as the "Stealth Fighter", it was strictly a ground-attack aircraft. F-117s took part in the conflict in Yugoslavia, where one was shot down by a surface-to-air missile (SAM) in 1999; it was the only Nighthawk to be lost in combat. The U.S. Air Force retired the F-117 in 2008, primarily due to the fielding of the F-22 Raptor. Despite the type’s retirement, a portion of the fleet has been kept in airworthy condition, and Nighthawks have been observed flying as recently as July 2019.

In 1964, Pyotr Ufimtsev, a Soviet mathematician, published a seminal paper titled "Method of Edge Waves in the Physical Theory of Diffraction" in the journal of the Moscow Institute for Radio Engineering, in which he showed that the strength of the radar return from an object is related to its edge configuration, not its size. Ufimtsev was extending theoretical work published by the German physicist Arnold Sommerfeld. Ufimtsev demonstrated that he could calculate the radar cross-section across a wing's surface and along its edge. The obvious and logical conclusion was that even a large aircraft could reduce its radar signature by exploiting this principle. However, the resulting design would make the aircraft aerodynamically unstable, and the state of computer technology in the early 1960s could not provide the kinds of flight computers which would later allow aircraft such as the F-117 and B-2 Spirit to stay airborne. By the 1970s, when Lockheed analyst Denys Overholser found Ufimtsev's paper, computers and software had advanced significantly, and the stage was set for the development of a stealth airplane.
The F-117 was born after combat experience in the Vietnam War when increasingly sophisticated Soviet surface-to-air missiles (SAMs) downed heavy bombers. It was a black project, an ultra-secret program for much of its life: very few people in the Pentagon knew the program even existed, until the F-117s were revealed to the public in 1988. The project began in 1975 with a model called the "Hopeless Diamond" (a wordplay on the Hope Diamond because of its appearance). The following year, the Defense Advanced Research Projects Agency (DARPA) issued Lockheed Skunk Works a contract to build and test two Stealth Strike Fighters, under the code name ""Have Blue"". These subscale aircraft incorporated jet engines of the Northrop T-38A, fly-by-wire systems of the F-16, landing gear of the A-10, and environmental systems of the C-130. By bringing together existing technology and components, Lockheed built two demonstrators under budget, at $35 million for both aircraft, and in record time.

The maiden flight of the demonstrators occurred on 1 December 1977. Although both aircraft were lost during the demonstration program, test data proved positive. The success of "Have Blue" led the government to increase funding for stealth technology. Much of that increase was allocated towards the production of an operational stealth aircraft, the Lockheed F-117A, under the program code name ""Senior Trend"".

The decision to produce the F-117A was made on 1 November 1978, and a contract was awarded to Lockheed Advanced Development Projects, popularly known as the Skunk Works, in Burbank, California. The program was led by Ben Rich, with Alan Brown as manager of the project. Rich called on Bill Schroeder, a Lockheed mathematician, and Denys Overholser, a computer scientist, to exploit Ufimtsev's work. The three designed a computer program called "Echo", which made it possible to design an airplane with flat panels, called facets, which were arranged so as to scatter over 99% of a radar's signal energy "painting" the aircraft.

The first YF-117A, serial number "79-10780", made its maiden flight from Groom Lake ("Area 51"), Nevada, on 18 June 1981, only 31 months after the full-scale development decision. The first production F-117A was delivered in 1982, and operational capability was achieved in October 1983. The 4450th Tactical Group stationed at Nellis AFB, Nevada were tasked with the operational development of the early F-117, and between 1981 (prior to the arrival of the first models) and 1989 they used LTV A-7 Corsair IIs for training, to bring all pilots to a common flight training baseline and later as chase planes for F-117A tests.

The F-117 was secret for much of the 1980s. Many news articles discussed what they called a "F-19" stealth fighter, and the Testor Corporation produced a very inaccurate scale model. When a F-117 crashed in Sequoia National Forest in July 1986, killing the pilot and starting a fire, the Air Force established restricted airspace. Armed guards prohibited entry, including firefighters, and a helicopter gunship circled the site. All F-117 debris was replaced with remains of a F-101A Voodoo crash stored at Area 51. When another fatal crash in October 1987 occurred inside Nellis, the military again provided little information to the press.

The Air Force denied the existence of the aircraft until 10 November 1988, when Assistant Secretary of Defense J. Daniel Howard displayed a grainy photograph at a Pentagon press conference, disproving the many inaccurate rumors about the shape of the "F-19". After the announcement pilots could fly the F-117 during daytime and no longer needed to be associated with the A-7, flying the T-38 supersonic trainer for travel and training instead. In April 1990, two F-117 aircraft were flown into Nellis Air Force Base, Nevada, arriving during daylight and publicly displayed to a crowd of tens of thousands.

Five Full Scale Development (FSD) aircraft were built, designated "YF-117A". The last of 59 production F-117s were delivered on 3 July 1990.
As the Air Force has stated, "Streamlined management by Aeronautical Systems Center, Wright-Patterson AFB, Ohio, combined breakthrough stealth technology with concurrent development and production to rapidly field the aircraft... The F-117A program demonstrates that a stealth aircraft can be designed for reliability and maintainability."

The operational aircraft was officially designated "F-117A". Most modern U.S. military aircraft use post-1962 designations in which the designation "F" is usually an air-to-air fighter, "B" is usually a bomber, "A" is usually a ground-attack aircraft, etc. (Examples include the F-15, the B-2, and the A-6.) The F-117 is primarily an attack aircraft, so its "F" designation is inconsistent with the DoD system. This is an inconsistency that has been repeatedly employed by the U.S. Air Force with several of its attack aircraft since the late 1950s, including the Republic F-105 Thunderchief and General Dynamics F-111 Aardvark. A televised documentary quoted project manager Alan Brown as saying that Robert J. Dixon, a four-star Air Force general who was the head of Tactical Air Command felt that the top-notch USAF fighter pilots required to fly the new aircraft were more easily attracted to an aircraft with an "F" designation for fighter, as opposed to a bomber ("B") or attack ("A") designation.

The designation "F-117" seems to indicate that it was given an official designation prior to the 1962 U.S. Tri-Service Aircraft Designation System and could be considered numerically to be a part of the earlier "Century series" of fighters. The assumption prior to the revealing of the aircraft to the public was that it would likely receive the F-19 designation as that number had not been used. However, there were no other aircraft to receive a "100" series number following the F-111. Soviet fighters obtained by the U.S. via various means under the Constant Peg program were given F-series numbers for their evaluation by U.S. pilots, and with the advent of the Teen Series fighters, most often Century Series designations.

As with other exotic military aircraft types flying in the southern Nevada area, such as captured fighters, an arbitrary radio call of "117" was assigned. This same radio call had been used by the enigmatic 4477th Test and Evaluation Squadron, also known as the "Red Hats" or "Red Eagles", that often had flown expatriated MiG jet fighters in the area, but there was no relationship to the call and the formal F-19 designation then being considered by the Air Force. Apparently, use of the "117" radio call became commonplace and when Lockheed released its first flight manual (i.e., the Air Force "dash one" manual for the aircraft), F-117A was the designation printed on the cover.

When the Air Force first approached Lockheed with the stealth concept, Skunk Works Director Kelly Johnson proposed a rounded design. He believed smoothly blended shapes offered the best combination of speed and stealth. However, his assistant, Ben Rich, showed that faceted-angle surfaces would provide significant reduction in radar signature, and the necessary aerodynamic control could be provided with computer units. A May 1975 Skunk Works report, "Progress Report No. 2, High Stealth Conceptual Studies", showed the rounded concept that was rejected in favor of the flat-sided approach.

The resulting unusual design surprised and puzzled experienced pilots; a Royal Air Force pilot, who flew it as an exchange officer while it was still a secret project, stated that when he first saw a photograph of the F-117, he "promptly giggled and thought to [himself] 'this clearly can't fly. Early stealth aircraft were designed with a focus on minimal radar cross-section (RCS) rather than aerodynamic performance. Highly-stealthy aircraft like the F-117 Nighthawk are aerodynamically unstable in all three aircraft principal axes and require constant flight corrections from a fly-by-wire (FBW) flight system to maintain controlled flight. It is shaped to deflect radar signals and is approximately the size of an F-15 Eagle.

The single-seat Nighthawk is powered by two non-afterburning General Electric F404 turbofan engines. It is air refuelable and features a V-tail. The maximum speed is at high altitude, the max rate of climb is per minute, and service ceiling is . The cockpit was quite spacious, with ergonomic displays and controls, but the field of view was somewhat obstructed with a large blind spot to the rear.

It has quadruple-redundant fly-by-wire flight controls. To lower development costs, the avionics, fly-by-wire systems, and other parts were derived from the General Dynamics F-16 Fighting Falcon, McDonnell Douglas F/A-18 Hornet and McDonnell Douglas F-15E Strike Eagle. The parts were originally described as spares on budgets for these aircraft, to keep the F-117 project secret.
The aircraft is equipped with sophisticated navigation and attack systems integrated into a digital avionics suite. It navigates primarily by GPS and high-accuracy inertial navigation. Missions are coordinated by an automated planning system that can automatically perform all aspects of an attack mission, including weapons release. Targets are acquired by a thermal imaging infrared system, slaved to a laser rangefinder/laser designator that finds the range and designates targets for laser-guided bombs. The F-117A's split internal bay can carry of ordnance. Typical weapons are a pair of GBU-10, GBU-12, or GBU-27 laser-guided bombs, two BLU-109 penetration bombs, or two Joint Direct Attack Munitions (JDAMs), a GPS/INS guided stand-off bomb.

The F-117 has a radar cross-section of about . Among the penalties for stealth are lower engine thrust due to losses in the inlet and outlet, a very low wing aspect ratio, and a high sweep angle (50°) needed to deflect incoming radar waves to the sides. With these design considerations and no afterburner, the F-117 is limited to subsonic speeds.

The F-117A carries no radar, which lowers emissions and cross-section, and whether it carries any radar detection equipment is classified.

The F-117A's faceted shape (made from 2-dimensional flat surfaces) resulted from the limitations of the 1970s-era computer technology used to calculate its radar cross-section. Later supercomputers made it possible for subsequent aircraft like the B-2 bomber to use curved surfaces while maintaining stealth, through the use of far more computational resources to perform the additional calculations.

An exhaust plume contributes a significant infrared signature. The F-117 reduces IR signature with a non-circular tail pipe (a slit shape) to minimize the exhaust cross-sectional volume and maximize the mixing of hot exhaust with cool ambient air. The F-117 lacks afterburners, because the hot exhaust would increase the infrared signature, and breaking the sound barrier would produce an obvious sonic boom, as well as surface heating of the aircraft skin which also increases the infrared footprint. As a result, its performance in air combat maneuvering required in a dogfight would never match that of a dedicated fighter aircraft. This was unimportant in the case of this aircraft since it was designed to be a bomber.

Passive (multistatic) radar, bistatic radar and especially multistatic radar systems detect some stealth aircraft better than conventional monostatic radars, since first-generation stealth technology (such as the F-117) reflects energy away from the transmitter's line of sight, effectively increasing the radar cross section (RCS) in other directions, which the passive radars monitor.

During the program's early years, from 1984 to mid-1992, the F-117A fleet was based at Tonopah Test Range Airport, Nevada, where it served under the 4450th Tactical Group. Because the F-117 was classified during this time, the unit was officially located at Nellis Air Force Base, Nevada, and equipped with A-7 Corsair II aircraft. All military personnel were permanently assigned to Nellis AFB, and most personnel and their families lived in Las Vegas. This required commercial air and trucking to transport personnel between Las Vegas and Tonopah each week. The 4450th was absorbed by the 37th Tactical Fighter Wing in 1989. In 1992, the entire fleet was transferred to Holloman Air Force Base, New Mexico, under the command of the 49th Fighter Wing. This move also eliminated the Key Air and American Trans Air contract flights to Tonopah, which flew 22,000 passenger trips on 300 flights from Nellis to Tonopah per month.

The F-117 reached initial operating capability status in 1983. The Nighthawk's pilots called themselves "Bandits". Each of the 558 Air Force pilots who have flown the F-117 has a Bandit number, such as "Bandit 52", that indicates the sequential order of their first flight in the F-117. Pilots told friends and families that they flew the Northrop F-5 in aggressor squadrons against Tactical Air Command.

The F-117 has been used several times in war. Its first mission was during the United States invasion of Panama in 1989. During that invasion two F-117A Nighthawks dropped two bombs on Rio Hato airfield.

During the Gulf War in 1991, the F-117 flew approximately 1,300 sorties and scored direct hits on 1,600 high-value targets in Iraq over 6,905 flight hours. Leaflet drops on Iraqi forces displayed the F-117 destroying ground targets and warned "Escape now and save yourselves". Initial claims of its effectiveness were later found to be overstated. For instance it was claimed that the F-117 made up 2.5% of Coalition tactical aircraft in Iraq and they attacked more than 40% of the strategic targets; this ignored the fact that only 229 Coalition aircraft could drop and designate laser-guided bombs of which 36 F-117 represented 15.7%, and only the USAF had the I-2000 bombs intended for hardened targets, so the F-117 represented 32% of all coalition aircraft that could deliver such bombs. Initial reports of F-117s hitting 80% of their targets were later scaled back to "41–60%". On the first night, they failed to hit 40% of their assigned air-defense targets, including the Air Defense Operations Center in Baghdad, and 8 such targets remained functional out of 10 that could be assessed. In their Desert Storm white paper, the USAF claimed that "the F-117 was the only airplane that the planners dared risk over downtown Baghdad" and that this area was particularly well defended. In fact, most of the air defenses were on the outskirts of the city and many other aircraft hit targets in the downtown area, with minimal casualties when they attacked at night like the F-117. This meant they avoided the optically aimed AAA and infra-red SAMs which were the biggest threat to Coalition aircraft.

The aircraft was operated in secret from Tonopah for almost a decade, but after the Gulf War the aircraft moved to Holloman in 1992—however, its integration with the USAF's non-stealth "iron jets" occurred slowly. As one senior F-117A pilot later said: Because of ongoing secrecy others continued to see the aircraft as "none of their business, a stand-alone system". The F-117A and the men and women of the 49th Fighter Wing were deployed to Southwest Asia on multiple occasions. On their first deployment, with the aid of aerial refueling, pilots flew non-stop from Holloman to Kuwait, a flight of approximately 18.5 hours—a record for single-seat fighters that stands today.

One F-117 (AF ser. no. 82-0806) was lost to enemy action. It was downed during a mission against the Army of Yugoslavia on 27 March 1999, during Operation Allied Force. The aircraft was acquired by a fire control radar at a distance of 13 km and an altitude of 8 km: SA-3s were then launched by a Yugoslav version of the Soviet Isayev S-125 "Neva" (NATO name SA-3 "Goa") anti-aircraft missile system. The launcher was run by the 3rd Battalion of the 250th Air Defence Missile Brigade under the command of Colonel Zoltán Dani.

After the explosion, the aircraft became uncontrollable, forcing the pilot to eject. The pilot was recovered six hours later by a United States Air Force Pararescue team. The stealth technology from the downed F-117 may have been acquired by Russia and China, but the United States did not destroy the wreckage because its technology was two decades old.

Some American sources state that a second F-117A was damaged during the same campaign, allegedly on 30 April 1999; the aircraft returned to base, but it supposedly never flew again.

Use of the aircraft as part of Operation Allied Force continued, and it was later used in the Operation Enduring Freedom in 2001 and Operation Iraqi Freedom in 2003. It was operated by the U.S. Air Force.

The loss in Serbia caused the USAF to create a subsection of their existing weapons school to improve tactics. More training was done with other units, and the F-117A began to participate in Red Flag exercises. Though advanced for its time, the F-117's stealthy faceted airframe required a large amount of maintenance and was eventually superseded by streamlined shapes produced with computer-aided design. Other weapon systems began to take on the F-117's roles, such as the F-22 Raptor gaining ability to drop guided bombs. By 2005, the aircraft was used only for certain missions, such as if a pilot needed to verify that the correct target had been hit, or when minimal collateral damage was vital.

The Air Force had once planned to retire the F-117 in 2011, but Program Budget Decision 720 (PBD 720), dated 28 December 2005, proposed retiring it by October 2008 to free up an estimated $1.07 billion to buy more F-22s. PBD 720 called for 10 F-117s to be retired in FY2007 and the remaining 42 in FY2008, stating that other Air Force planes and missiles could stealthily deliver precision ordnance, including the B-2 Spirit, F-22 and JASSM. The planned introduction of the multirole F-35 Lightning II also contributed to the retirement decision.

In late 2006, the Air Force closed the F-117 formal training unit (FTU), and announced the retirement of the F-117. The first six aircraft to be retired took their last flight on 12 March 2007 after a ceremony at Holloman AFB to commemorate the aircraft's career. Brigadier General David L. Goldfein, commander of the 49th Fighter Wing, said at the ceremony, "With the launch of these great aircraft today, the circle comes to a close—their service to our nation's defense fulfilled, their mission accomplished and a job well done. We send them today to their final resting place—a home they are intimately familiar with—their first, and only, home outside of Holloman."
Unlike most other Air Force aircraft that are retired to Davis-Monthan AFB for scrapping, or dispersal to museums, most of the F-117s were placed in "Type 1000" storage in their original hangars at the Tonopah Test Range Airport. At Tonopah, their wings were removed and the aircraft are stored in their original climate-controlled hangars. The decommissioning occurred in eight phases, with the operational aircraft retired to Tonopah in seven waves from 13 March 2007 until the last wave's arrival on 22 April 2008. Four aircraft were kept flying beyond April by the 410th Flight Test Squadron at Palmdale for flight test. By August, two were remaining. The last F-117 (AF Serial No. 86-0831) left Palmdale to fly to Tonopah on 11 August 2008. With the last aircraft retired, the 410th was inactivated in a ceremony on 1 August 2008.

Five aircraft were placed in museums, including the first four YF-117As and some remains of the F-117 shot down over Serbia. Through 2009, one F-117 had been scrapped; AF Serial No. 79-0784 was scrapped at the Palmdale test facility on 26 April 2008. It was the last F-117 at Palmdale and was scrapped to test an effective method for destroying F-117 airframes.

Congress had ordered that all F-117s mothballed from 30 September 2006 onwards were to be maintained "in a condition that would allow recall of that aircraft to future service" as part of the 2007 National Defense Authorization Act. By April 2016, lawmakers appeared ready to "remove the requirement that certain F-117 aircraft be maintained in a condition that would allow recall of those aircraft to future service", which would move them from storage to the aerospace maintenance and regeneration yard in Arizona to be scavenged for hard-to-find parts, or completely disassembled. On 11 September 2017, it was reported that in accordance with the National Defense Authorization Act for Fiscal Year 2017, signed into law on 23 December 2016, "the Air Force will remove four F-117s every year to fully divest them—a process known as demilitarizing aircraft".

Although officially retired, the F-117 fleet remains intact and photos show the aircraft carefully mothballed. Some of the aircraft are flown periodically, and have been spotted flying as recently as February 2019. In March 2019, it was reported that four F-117s had been secretly deployed to the Middle East in 2016 and that one had to make an emergency landing at Ali Al Salem (AAS), Kuwait sometime late that year. 

In February 2019, an F-117 was observed flying through the R-2508 Special Use Airspace Complex in the vicinity of Edwards Air Force Base, escorted by two F-16 Fighting Falcons that may have been providing top cover. Closer photographs of the aircraft revealed that the tail code had been scrubbed in an attempt to remove the paint. The partially-intact code identified it as a former aircraft of the 49th Operations Group. An F-117 was also photographed in 2019 carrying unit markings previously unassociated with the aircraft – a band on the tail bearing the name "Dark Knights", suggesting an either official or unofficial squadron is maintaining the Nighthawks. In July 2019, one Nighthawk was spotted flying above Death Valley, trailing behind a KC-135R Stratotanker in a hybrid aggressor scheme.

The United States Navy tested the F-117 in 1984 but determined it was not suitable for carrier use. In the early 1990s, Lockheed proposed an upgraded, carrier-capable variant of the F-117 dubbed the "Seahawk" to the Navy as an alternative to the canceled A/F-X program. The unsolicited proposal was received poorly by the Department of Defense, which had little interest in the single mission capabilities of such an aircraft, particularly as it would take money away from the Joint Advanced Strike Technology program, which evolved into the Joint Strike Fighter. The new aircraft would have differed from the land-based F-117 in several ways, including the addition "of elevators, a bubble canopy, a less sharply swept wing and reconfigured tail". The "N" variant would also be re-engined to use General Electric F414 turbofans instead of the older General Electric F404s. The aircraft would be optionally fitted with hardpoints, allowing for an additional of payload, and a new ground-attack radar with air-to-air capability. In that role the F-117N could carry AIM-120 AMRAAM air-to-air missiles.

After being rebuffed by the Navy, Lockheed submitted an updated proposal that included afterburning capability and a larger emphasis on the F-117N as a multi-mission aircraft, rather than just an attack aircraft. To boost interest, Lockheed also proposed an "F-117B" land-based variant that shared most of the F-117N capabilities. This variant was proposed to the USAF and the Royal Air Force. Several RAF exchange officers flew the F-117 during its service, two RAF pilots formally evaluated the aircraft in 1986 as a reward for British help with the American bombing of Libya that year, and the British declined an offer during the Reagan administration to purchase the aircraft. This renewed F-117N proposal was also known as the "A/F-117X". Neither the F-117N nor the F-117B were ordered.

United States Air Force



The aircraft's official name is "Night Hawk", however the alternative form "Nighthawk" is frequently used.

As it prioritized stealth over aerodynamics, it earned the nickname "Wobblin' Goblin" due to its alleged instability at low speeds. However, F-117 pilots have stated the nickname is undeserved. "Wobblin' (or Wobbly) Goblin" is likely a holdover from the early "Have Blue" / "Senior Trend" (FSD) days of the project when instability was a problem. In the USAF, "Goblin" (without wobbly) persists as a nickname because of the aircraft's appearance. During Operation Desert Storm, Saudis dubbed the aircraft "Shaba", which is Arabic for "Ghost". Some pilots also called the airplane the "Stinkbug".

The Omaha Nighthawks professional American football team used the F-117 Nighthawk as its logo. The experimental Remora F-117X was featured in the 1996 film "Executive Decision".




</doc>
<doc id="11721" url="https://en.wikipedia.org/wiki?curid=11721" title="Vought F4U Corsair">
Vought F4U Corsair

The Vought F4U Corsair is an American fighter aircraft that saw service primarily in World War II and the Korean War.

Designed and initially manufactured by Chance Vought, the Corsair was soon in great demand; additional production contracts were given to Goodyear, whose Corsairs were designated FG, and Brewster, designated F3A.

The Corsair was designed and operated as a carrier-based aircraft, and entered service in large numbers with the U.S. Navy in late 1944 and early 1945. It quickly became one of the most capable carrier-based fighter-bombers of World War II. Some Japanese pilots regarded it as the most formidable American fighter of World War II and its naval aviators achieved an 11:1 kill ratio. Early problems with carrier landings and logistics led to it being eclipsed as the dominant carrier-based fighter by the Grumman F6F Hellcat, powered by the same Double Wasp engine first flown on the Corsair's first prototype in 1940. Instead, the Corsair's early deployment was to land-based squadrons of the U.S. Marines and U.S. Navy.

The Corsair served almost exclusively as a fighter-bomber throughout the Korean War and during the French colonial wars in Indochina and Algeria. In addition to its use by the U.S. and British, the Corsair was also used by the Royal New Zealand Air Force, French Naval Aviation, and other air forces until the 1960s.

From the first prototype delivery to the U.S. Navy in 1940, to final delivery in 1953 to the French, 12,571 F4U Corsairs were manufactured in 16 separate models. Its 1942–53 production run was the longest of any U.S. piston-engined fighter.

In February 1938 the U.S. Navy Bureau of Aeronautics published two requests for proposal for twin-engined and single-engined fighters. For the single-engined fighter the Navy requested the maximum obtainable speed, and a stalling speed not higher than . A range of was specified. The fighter had to carry four guns, or three with increased ammunition. Provision had to be made for anti-aircraft bombs to be carried in the wing. These small bombs would, according to thinking in the 1930s, be dropped on enemy aircraft formations.
In June 1938, the U.S. Navy signed a contract with Vought for a prototype bearing the factory designation V-166B, the XF4U-1, BuNo 1443. The Corsair design team was led by Rex Beisel. After mock-up inspection in February 1939, construction of the XF4U-1 powered by an XR-2800-4 prototype of the Pratt & Whitney R-2800 Double Wasp twin-row, 18-cylinder radial engine, rated at went ahead quickly, as the very first airframe ever designed from the start to have a Double Wasp engine fitted for flight. When the prototype was completed it had the biggest and most powerful engine, largest propeller, and probably the largest wing on any naval fighter to date. The first flight of the XF4U-1 was made on 29 May 1940, with Lyman A. Bullard, Jr. at the controls. The maiden flight proceeded normally until a hurried landing was made when the elevator trim tabs failed because of flutter.

On 1 October 1940, the XF4U-1 became the first single-engine U.S. fighter to fly faster than by flying at an average ground speed of from Stratford to Hartford. The USAAC's twin engine Lockheed P-38 Lightning had flown over 400 mph in January–February 1939. The XF4U-1 also had an excellent rate of climb but testing revealed that some requirements would have to be rewritten. In full-power dive tests, speeds of up to were achieved, but not without damage to the control surfaces and access panels and, in one case, an engine failure. The spin recovery standards also had to be relaxed as recovery from the required two-turn spin proved impossible without resorting to an anti-spin chute. The problems clearly meant delays in getting the design into production.

Reports coming back from the war in Europe indicated that an armament of two .30 in (7.62 mm) synchronized engine cowling-mount machine guns, and two .50 in (12.7 mm) machine guns (one in each outer wing panel) was insufficient. The U.S. Navy's November 1940 production proposals specified heavier armament. The increased armament comprised three .50 caliber machine guns mounted in each wing panel. This improvement greatly increased the ability of the Corsair to shoot down enemy aircraft.

Formal U.S. Navy acceptance trials for the XF4U-1 began in February 1941. The Navy entered into a letter of intent on 3 March 1941, received Vought's production proposal on 2 April, and awarded Vought a contract for 584 F4U-1 fighters, which were given the name "Corsair" — inherited from the firm's late-1920s Vought O2U naval biplane scout which first bore the name — on 30 June of the same year. The first production F4U-1 performed its initial flight a year later, on 24 June 1942. It was a remarkable achievement for Vought; compared to land-based counterparts, carrier aircraft are "overbuilt" and heavier, to withstand the extreme stress of deck landings.

The F4U incorporated the largest engine available at the time, the 18-cylinder Pratt & Whitney R-2800 Double Wasp radial. To extract as much power as possible, a relatively large Hamilton Standard Hydromatic three-blade propeller of was used.

To accommodate a folding wing the designers considered retracting the main landing gear rearward but, for the chord of wing that was chosen, it was difficult to make the landing gear struts long enough to provide ground clearance for the large propeller. Their solution was an inverted gull wing, which considerably shortened the required length of the struts. The anhedral of the wing's center-section also permitted the wing and fuselage to meet at the optimum angle for minimizing drag, without using wing root fairings. The bent wing, however, was heavier and more difficult to construct, offsetting these benefits.

The Corsair's aerodynamics were an advance over those of contemporary naval fighters. The F4U was the first U.S. Navy aircraft to feature landing gear that retracted into a fully enclosed wheel well. The landing gear oleo struts—each with its own strut door enclosing it when retracted—rotated through 90° during retraction, with the wheel atop the lower end of the strut when retracted. A pair of rectangular doors enclosed each wheel well, leaving a streamlined wing. This swiveling, aft-retracting landing gear design was common to the Curtiss P-40 (and its predecessor, the P-36), as adopted for the F4U Corsair's main gear and its erstwhile Pacific War counterpart, the Grumman F6F Hellcat. The oil coolers were mounted in the heavily anhedraled center-section of the wings, alongside the supercharger air intakes, and used openings in the leading edges of the wings, rather than protruding scoops. The large fuselage panels were made of aluminum and were attached to the frames with the newly developed technique of spot welding, thus mostly eliminating the use of rivets. While employing this new technology, the Corsair was also the last American-produced fighter aircraft to feature fabric as the skinning for the top and bottom of each outer wing, aft of the main spar and armament bays, and for the ailerons, elevators, and rudder. The elevators were also constructed from plywood. The Corsair, even with its streamlining and high speed abilities, could fly slowly enough for carrier landings with full flap deployment of 60°.

In part because of its advances in technology and a top speed greater than existing Navy aircraft, numerous technical problems had to be solved before the Corsair entered service. Carrier suitability was a major development issue, prompting changes to the main landing gear, tail wheel, and tailhook. Early F4U-1s had difficulty recovering from developed spins, since the inverted gull wing's shape interfered with elevator authority. It was also found that the Corsair's right wing could stall and drop rapidly and without warning during slow carrier landings. In addition, if the throttle were suddenly advanced (for example, during an aborted landing) the left wing could stall and drop so quickly that the fighter could flip over with the rapid increase in power. These potentially lethal characteristics were later solved through the addition of a small, -long stall strip to the leading edge of the outer right wing, just outboard of the gun ports. This allowed the right wing to stall at the same time as the left.
Other problems were encountered during early carrier trials. The combination of an aft cockpit and the Corsair's long nose made landings hazardous for newly trained pilots. During landing approaches, it was found that oil from the opened hydraulically-powered cowl flaps could spatter onto the windscreen, severely reducing visibility, and the undercarriage oleo struts had bad rebound characteristics on landing, allowing the aircraft to bounce down the carrier deck. The first problem was solved by locking the top cowl flaps in front of the windscreen down permanently, then replacing them with a fixed panel. The undercarriage bounce took more time to solve, but eventually a "bleed valve" incorporated in the legs allowed the hydraulic pressure to be released gradually as the aircraft landed. The Corsair was not considered fit for carrier use until the wing stall problems and the deck bounce could be solved.

Meanwhile, the more docile and simpler-to-build F6F Hellcat had begun entering service in its intended carrier-based use. The Navy wanted to standardize on one type of carrier fighter, and the Hellcat, while slower than the Corsair, was considered simpler to land on a carrier by an inexperienced pilot and proved to be successful almost immediately after introduction. The Navy's decision to choose the Hellcat meant that the Corsair was released to the U.S. Marine Corps. With no initial requirement for carrier landings, the Marine Corps deployed the Corsair to devastating effect from land bases. Corsair deployment aboard U.S. carriers was delayed until late 1944, by which time the last of the carrier landing problems, relating to the Corsair's long nose, had been tackled by the British.

Production F4U-1s featured several major modifications from the XF4U-1. A change of armament to six wing-mounted .50 in (12.7 mm) M2 Browning machine guns (three in each outer wing panel) and their ammunition (400 rounds for the inner pair, 375 rounds for the outer) meant that the location of the wing fuel tanks had to be changed. In order to keep the fuel tank close to the center of gravity, the only available position was in the forward fuselage, ahead of the cockpit. Later on, different variants of the F4U were given different armaments. While most Corsair variants had the standard armament of six .50 caliber M2 Browning machine guns, some models (like the F4U-1C) were equipped with four 20 millimeter M2 cannons for its main weapon. While these cannons were more powerful than the standard machine guns, they were not favored over the standard loadout. Only 200 models of this particular Corsair model were produced, out of the total 12,571. Other variants were capable of carrying mission specific weapons such as rockets and bombs. The F4U was able to carry up to a total of eight rockets, or four under each wing. It was able to carry up to four thousand pounds of explosive ordnance. This helped the Corsair take on a fighter bomber role, giving it a more versatile role as a ground support aircraft as well as a fighter. 12 12 Accordingly, as a 237 gal (897 l) self-sealing fuel tank replaced the fuselage mounted armament, the cockpit had to be moved back by and the fuselage lengthened. In addition, 150 lb of armor plate was installed, along with a bullet-proof windscreen which was set internally, behind the curved Plexiglas windscreen. The canopy could be jettisoned in an emergency, and half-elliptical planform transparent panels, much like those of certain models of the Curtiss P-40, were inset into the sides of the fuselage's turtledeck structure behind the pilot's headrest, providing the pilot with a limited rear view over his shoulders. A rectangular Plexiglas panel was inset into the lower center section to allow the pilot to see directly beneath the aircraft and assist with deck landings. The engine used was the more powerful R-2800-8 (B series) Double Wasp which produced 2,000 hp (1,491 kW). On the wings the flaps were changed to a NACA slotted type and the ailerons were increased in span to increase the roll rate, with a consequent reduction in flap span. IFF transponder equipment was fitted in the rear fuselage. These changes increased the Corsair's weight by several hundred pounds.

The performance of the Corsair was superior to most of its contemporaries. The F4U-1 was considerably faster than the Grumman F6F Hellcat and only slower than the Republic P-47 Thunderbolt; all three were powered by the R-2800. But while the P-47 achieved its highest speed at with the help of an intercooled turbocharger, the F4U-1 reached its maximum speed at , and used a mechanically supercharged engine.

The U.S. Navy received its first production F4U-1 on 31 July 1942, but getting it into service proved difficult. The framed "birdcage" style canopy provided inadequate visibility for deck taxiing, and the long "hose nose" and nose-up attitude of the Corsair made it difficult to see straight ahead. The enormous torque of the Double Wasp engine also made it a handful for inexperienced pilots if they were forced to bolter. Early Navy pilots called the F4U the "hog", "hosenose", or "bent-wing widow maker".

Carrier qualification trials on the training carrier USS "Wolverine" and escort carriers USS "Core" and USS "Charger" in 1942 found that, despite visibility issues and control sensitivity, the Corsair was "...an excellent carrier type and very easy to land aboard. It is no different than any other airplane." Two Navy units, VF-12 (October 1942) and later VF-17 (April 1943) were equipped with the F4U. By April 1943, VF-12 had successfully completed deck landing qualification.

At the time, the U.S. Navy also had the Grumman F6F Hellcat, which did not have the performance of the F4U, but was a better deck landing aircraft. The Corsair was declared "ready for combat" at the end of 1942, though qualified to operate only from land bases until the last of the carrier qualification issues were worked out. VF-17 went aboard the USS "Bunker Hill" in late 1943, and the Chief of Naval Operations wanted to equip four air groups with Corsairs by the end of 1943. The Commander, Air Forces, Pacific had a different opinion, stating that "In order to simplify spares problems and also to insure flexibility in carrier operations present practice in the Pacific is to assign all Corsairs to Marines and to equip FightRons [fighter squadrons] on medium and light carriers with Hellcats." VF-12 soon abandoned its aircraft to the Marines. VF-17 kept its Corsairs, but was removed from its carrier, , due to perceived difficulties in supplying parts at sea.

The Marines needed a better fighter than the F4F Wildcat. For them, it was not as important that the F4U could be recovered aboard a carrier, as they usually flew from land bases. Growing pains aside, Marine Corps squadrons readily took to the radical new fighter.

From February 1943 onward, the F4U operated from Guadalcanal and ultimately other bases in the Solomon Islands. A dozen USMC F4U-1s of VMF-124, commanded by Major William E. Gise, arrived at Henderson Field (code name "Cactus") on 12 February. The first recorded combat engagement was on 14 February 1943, when Corsairs of VMF-124 under Major Gise assisted P-40s and P-38s in escorting a formation of Consolidated B-24 Liberators on a raid against a Japanese aerodrome at Kahili. Japanese fighters contested the raid and the Americans got the worst of it, with four P-38s, two P-40s, two Corsairs, and two Liberators lost. No more than four Japanese Zeros were destroyed. A Corsair was responsible for one of the kills, albeit due to a midair collision. The fiasco was referred to as the "Saint Valentine's Day Massacre". Despite the debut, the Marines quickly learned how to make better use of the aircraft and started demonstrating its superiority over Japanese fighters. By May, the Corsair units were getting the upper hand, and VMF-124 had produced the first Corsair ace, Second Lieutenant Kenneth A. Walsh, who would rack up a total of 21 kills during the war. He remembered:
VMF-113 was activated on 1 January 1943 at Marine Corps Air Station El Toro as part of Marine Base Defense Air Group 41. They were soon given their full complement of 24 F4U Corsairs. On 26 March 1944, while escorting four B-25 bombers on a raid over Ponape, they recorded their first enemy kills, downing eight Japanese aircraft. In April of that year, VMF-113 was tasked with providing air support for the landings at Ujelang. Since the assault was unopposed, the squadron quickly returned to striking Japanese targets in the Marshall Islands for the remainder of 1944.

Corsairs were flown by the "Black Sheep" Squadron (VMF-214, led by Marine Major Gregory "Pappy" Boyington) in an area of the Solomon Islands called "The Slot". Boyington was credited with 22 kills in F4Us (of 28 total, including six in an AVG P-40, although his score with the AVG has been disputed). Other noted Corsair pilots of the period included VMF-124's Kenneth Walsh, James E. Swett, and Archie Donahue; VMF-215's Robert M. Hanson and Don Aldrich; and VF-17's Tommy Blackburn, Roger Hedrick, and Ira Kepford. Nightfighter versions equipped Navy and Marine units afloat and ashore.

One particularly unusual kill was scored by Marine Lieutenant R. R. Klingman of VMF-312 (the "Checkerboards") over Okinawa. Klingman was in pursuit of a Japanese twin-engine aircraft at high altitude when his guns jammed due to the gun lubrication thickening from the extreme cold. He flew up and chopped off the enemy's tail with the big propeller of the Corsair. Despite missing five inches (127 mm) off the end of his propeller blades, he managed to land safely after this aerial ramming attack. He was awarded the Navy Cross.

At war's end, Corsairs were ashore on Okinawa, combating the "kamikaze", and also were flying from fleet and escort carriers. VMF-312, VMF-323, VMF-224, and a handful of others met with success in the Battle of Okinawa.

Since Corsairs were being operated from shore bases, while still awaiting approval for U.S. carrier operations, 965 FG-1As were built as "land planes" without their hydraulic wing folding mechanisms, hoping to improve performance by reducing aircraft weight, with the added benefit of minimizing complexity. (These Corsairs’ wings could still be manually folded.)

A second option was to remove the folding mechanism in the field using a kit, which could be done for Vought and Brewster Corsairs as well. On 6 December 1943, the Bureau of Aeronautics issued guidance on weight-reduction measures for the F4U-1, FG-1, and F3A. Corsair squadrons operating from land bases were authorized to remove catapult hooks, arresting hooks, and associated equipment, which eliminated 48 pounds of unnecessary weight. While there are no data to indicate to what extent these modifications where incorporated, there are numerous photos in evidence of Corsairs, of various manufacturers and models, on islands in the Pacific without tailhooks installed.

Corsairs also served well as fighter-bombers in the Central Pacific and the Philippines. By early 1944, Marine pilots were beginning to exploit the type's considerable capabilities in the close-support role in amphibious landings. Charles Lindbergh flew Corsairs with the Marines as a civilian technical advisor for United Aircraft Corporation in order to determine how best to increase the Corsair's payload and range in the attack role and to help evaluate future viability of single- versus twin-engine fighter design for Vought. Lindbergh managed to get the F4U into the air with of bombs, with a bomb on the centerline and a bomb under each wing. In the course of such experiments, he performed strikes on Japanese positions during the battle for the Marshall Islands.

By the beginning of 1945, the Corsair was a full-blown "mudfighter", performing strikes with high-explosive bombs, napalm tanks, and HVARs. It proved versatile, able to operate everything from Bat glide bombs to 11.75 in (300 mm) Tiny Tim rockets. The aircraft was a prominent participant in the fighting for the Palaus, Iwo Jima, and Okinawa.

In November 1943, while operating as a shore-based unit in the Solomon Islands, VF-17 reinstalled the tail hooks so its F4Us could land and refuel while providing top cover over the task force participating in the carrier raid on Rabaul. The squadron's pilots landed, refueled, and took off from their former home, "Bunker Hill" and on 11 November 1943.

Twelve USMC F4U-1s arrived at Henderson Field (Guadalcanal) on 12 February 1943. The U.S. Navy did not get into combat with the type until September 1943. The work done by the Royal Navy's FAA meant those models qualified the type for U.S. carrier operations first. The U.S. Navy finally accepted the F4U for shipboard operations in April 1944, after the longer oleo strut was fitted, which eliminated the tendency to bounce. The first US Corsair unit to be based effectively on a carrier was the pioneer USMC squadron VMF-124, which joined "Essex" in December 1944. They were accompanied by VMF-213. The increasing need for fighter protection against "kamikaze" attacks resulted in more Corsair units being moved to carriers.

U.S. figures compiled at the end of the war indicate that the F4U and FG flew 64,051 operational sorties for the U.S. Marines and U.S. Navy through the conflict (44% of total fighter sorties), with only 9,581 sorties (15%) flown from carrier decks. F4U and FG pilots claimed 2,140 air combat victories against 189 losses to enemy aircraft, for an overall kill ratio of over 11:1. While this gave the Corsair the lowest loss rate of any fighter of the Pacific War, this was due in part to operational circumstances; it primarily faced air-to-air combat in the Solomon Islands and Rabaul campaigns (as well as at Leyte and for kamikaze interception), but as operations shifted north and its mission shifted to ground attack the aircraft saw less exposure to enemy aircraft, while other fighter types were exposed to more air combat. Against the best Japanese opponents, the aircraft claimed a 12:1 kill ratio against Mitsubishi A6M and 6:1 against the Nakajima Ki-84, Kawanishi N1K-J, and Mitsubishi J2M combined during the last year of the war. The Corsair bore the brunt of U.S. fighter-bomber missions, delivering of bombs during the war (70% of total bombs dropped by U.S. fighters during the war).

Corsair losses in World War II were as follows:-


In the early days of World War II, Royal Navy fighter requirements had been based on cumbersome two-seat designs, such as the Blackburn Skua (and its turreted derivative the Blackburn Roc) and the Fairey Fulmar, since it was expected that they would encounter only long-range bombers or flying boats and that navigation over featureless seas required the assistance of a radio operator/navigator. The Royal Navy hurriedly adopted higher-performance single-seat aircraft such as the Hawker Sea Hurricane and the less robust Supermarine Seafire, but neither aircraft had sufficient range to operate at a distance from a carrier task force. The Corsair was welcomed as a more robust and versatile alternative.

In November 1943, the Royal Navy received its first batch of 95 Vought F4U-1s, which were given the designation of "Corsair I". The first squadrons were assembled and trained on the U.S. East Coast and then shipped across the Atlantic. The Royal Navy put the Corsair into carrier operations immediately. They found its landing characteristics dangerous, suffering a number of fatal crashes, but considered the Corsair to be the best option they had.

In Royal Navy service, because of the limited hangar deck height in several classes of British carrier, many Corsairs had their outer wings "clipped" by to clear the deckhead. The change in span brought about the added benefit of improving the sink rate, reducing the F4U's propensity to "float" in the final stages of landing. Despite the clipped wings and the shorter decks of British carriers, Royal Navy aviators found landing accidents less of a problem than they had been to U.S. Navy aviators, thanks to the curved approach they used: British units solved the landing visibility problem by approaching the carrier in a medium left-hand turn, which allowed the pilot to keep the carrier's deck in view over the anhedral in the left wing root. This technique was later adopted by U.S. Navy and Marine fliers for carrier use of the Corsair.

The Royal Navy developed a number of modifications to the Corsair that made carrier landings more practical. Among these were a bulged canopy (similar to the Malcolm Hood), raising the pilot's seat , and wiring shut the cowl flaps across the top of the engine compartment, diverting oil and hydraulic fluid spray around the sides of the fuselage.

The Royal Navy initially received 95 "birdcage" F4U-1s from Vought which were designated Corsair Mk I in Fleet Air Arm service. Next from Vought came 510 "blown-canopy" F4U-1A/-1Ds, which were designated Corsair Mk II (the final 150 equivalent to the F4U-1D, but not separately designated in British use). 430 Brewster Corsairs (334 F3A-1 and 96 F3A-1D), more than half of Brewster's total production, were delivered to Britain as the Corsair Mk III. 857 Goodyear Corsairs (400 FG-1/-1A and 457 FG-1D) were delivered and designated Corsair Mk IV. The Mk IIs and Mk IVs were the only versions to be used in combat.

The Royal Navy cleared the F4U for carrier operations well before the U.S. Navy and showed that the Corsair Mk II could be operated with reasonable success even from escort carriers. It was not without problems; one was excessive wear of the arrester wires, due both to the weight of the Corsair and the understandable tendency of the pilots to stay well above the stalling speed. A total of 2,012 Corsairs were supplied to the United Kingdom.

Fleet Air Arm (FAA) units were created and equipped in the United States, at Quonset Point or Brunswick and then shipped to war theaters aboard escort carriers. The first FAA Corsair unit was 1830 NAS, created on the first of June 1943, and soon operating from . At the end of the war, 18 FAA squadrons were operating the Corsair. British Corsairs served both in Europe and in the Pacific. The first, and also most important, European operations were the series of attacks (Operation Tungsten) in April, July, and August 1944 on the , for which Corsairs from and provided fighter cover. It appears the Corsairs did not encounter aerial opposition on these raids.

From April 1944, Corsairs from the British Pacific Fleet took part in a several major air raids in South East Asia beginning with Operation Cockpit, an attack on Japanese targets at Sabang island, in the Dutch East Indies.

In July and August 1945, Corsair naval squadrons 1834, 1836, 1841, and 1842 took part in a series of strikes on the Japanese mainland, near Tokyo. These squadrons operated from "Victorious" and "Formidable." On 9 August 1945, days before the end of the war, Corsairs from "Formidable" attacked Shiogama harbor on the northeast coast of Japan. Royal Canadian Navy Volunteer Reserve pilot, Lieutenant Robert Hampton Gray, of 1841 Squadron was hit by flak but pressed home his attack on a Japanese destroyer, sinking it with a bomb but crashing into the sea. He was posthumously awarded Canada's last Victoria Cross, becoming the second fighter pilot of the war to earn a Victoria Cross as well as the final Canadian casualty of World War II. 

FAA Corsairs originally fought in a camouflage scheme with a Dark Slate Grey/Extra Dark Sea Grey disruptive pattern on top and Sky undersides, but were later painted overall dark blue. As it had become imperative for all Allied aircraft in the Pacific Theater of World War II to abandon all use of any "red devices" in their national insignia — to prevent any chance of misidentification with Japanese military aircraft, all of which bore the circular, all-red "Hinomaru" insignia (nicknamed a "meatball" by Allied aircrew) that is still in use to this day, the United States removed all areas of red color (specifically removing the red center to the roundel) and removed any sort of national fin/rudder markings, which at that time had seven horizontal red stripes, from the American national aircraft insignia scheme by 6 May 1942. The British did likewise, starting with a simple paintover with white paint, of their "Type C" roundel's red center, at about the time the U.S. Navy removed the red-center from their roundel. Later, a shade of slate gray center color replaced the white color on the earlier roundel. When the Americans starting using the added white bars to either side of their blue/white star roundel on 28 June 1943; SEAC British Corsairs, most all of which still used the earlier blue/white Type C roundel with the red center removed, added similar white bars to either side of their blue-white roundels to emulate the Americans.

In all, out of 18 carrier-based squadrons, eight saw combat, flying intensive ground attack/interdiction operations and claiming 47.5 aircraft shot down.

At the end of World War II, under the terms of the Lend-Lease agreement, the aircraft had to be paid for or to be returned to the U.S. As the UK did not have the means to pay for them, the Royal Navy Corsairs were pushed overboard into the sea in Moreton Bay off Brisbane, Australia.

Equipped with obsolete Curtiss P-40s, Royal New Zealand Air Force (RNZAF) squadrons in the South Pacific performed impressively, in particular in the air-to-air role. The American government accordingly decided to give New Zealand early access to the Corsair, especially as it was not initially being used from carriers. Some 424 Corsairs equipped 13 RNZAF squadrons, including No. 14 Squadron RNZAF and No. 15 Squadron RNZAF, replacing Douglas SBD Dauntlesses as well as P-40s. Most of the F4U-1s were assembled by Unit 60 with a further batch assembled and flown at RNZAF Hobsonville. In total there were 336 F4U-1s and 41 F4U-1Ds used by the RNZAF during the Second World War. Sixty FG-1Ds arrived late in the war.
The first deliveries of lend-lease Corsairs began in March 1944 with the arrival of 30 F4U-1s at the RNZAF Base Depot Workshops (Unit 60) on the island of Espiritu Santo in the New Hebrides. From April, these workshops became responsible for assembling all Corsairs for the RNZAF units operating the aircraft in the South West Pacific; and a Test and Despatch flight was set up to test the aircraft after assembly. By June 1944, 100 Corsairs had been assembled and test flown. The first squadrons to use the Corsair were 20 and 21 Squadrons on Espiritu Santo, operational in May 1944. The organization of the RNZAF in the Pacific and New Zealand meant that only the pilots and a small staff belonged to each squadron (the maximum strength on a squadron was 27 pilots): squadrons were assigned to several Servicing Units (SUs, composed of 5–6 officers, 57 NCOs, 212 airmen) which carried out aircraft maintenance and operated from fixed locations: hence F4U-1 "NZ5313" was first used by 20 Squadron/1 SU on Guadalcanal in May 1944; 20 Squadron was then relocated to 2 SU on Bougainville in November. In all there were ten front line SUs plus another three based in New Zealand. Because each of the SUs painted its aircraft with distinctive markings and the aircraft themselves could be repainted in several different color schemes, the RNZAF Corsairs were far less uniform in appearance than their American and FAA contemporaries. By late 1944, the F4U had equipped all ten Pacific-based fighter squadrons of the RNZAF.

By the time the Corsairs arrived, there were very few Japanese aircraft left in New Zealand's allocated sectors of the Southern Pacific, and despite the RNZAF squadrons extending their operations to more northern islands, they were primarily used for close support of American, Australian, and New Zealand soldiers fighting the Japanese. At the end of 1945, all Corsair squadrons but one (No. 14) were disbanded. That last squadron was based in Japan, until the Corsair was retired from service in 1947.

No. 14 Squadron was given new FG-1Ds and in March 1946 transferred to Iwakuni, Japan as part of the British Commonwealth Occupation Force. Only one airworthy example of the 437 aircraft procured survives: FG-1D "NZ5648"/"ZK-COR", owned by the Old Stick and Rudder Company at Masterton, New Zealand.

On 18 July 1944, a British Corsair F4U-1A, "JT404" of 1841 Naval Air Squadron, was involved in anti-submarine patrol from HMS "Formidable" en route to Scapa Flow after the Operation Mascot attack on the German battleship "Tirpitz".. It flew in company with a Fairey Barracuda. Due to technical problems the Corsair made an emergency landing in a field on Hamarøy north of Bodø, Norway. The pilot, Lt Mattholie, was taken prisoner and the aircraft captured undamaged. Luftwaffe interrogators failed to get the pilot to explain how to fold the wings so as to transport the aircraft to Narvik. The Corsair was ferried by boat for further investigation. Later the Corsair was taken to Germany and listed as one of the captured enemy aircraft ("Beuteflugzeug") based at "Erprobungsstelle Rechlin", the central German military aviation test facility and the equivalent of the Royal Aircraft Establishment, for 1944 under repair. This was probably the only Corsair captured by the Germans.

In 1945, U.S. forces captured an F4U Corsair near the Kasumigaura flight school. The Japanese had repaired it, covering damaged parts on the wing with fabric and using spare parts from crashed F4Us. It seems Japan captured two force-landed Corsairs fairly late in the war and may have even tested one in flight.

During the Korean War, the Corsair was used mostly in the close-support role. The AU-1 Corsair was developed from the F4U-5 and was a ground-attack version which normally operated at low altitudes: as a consequence the Pratt & Whitney R-2800-83W engine used a single-stage, manually controlled supercharger, rather than the two-stage automatic supercharger of the -5. The versions of the Corsair used in Korea from 1950 to 1953 were the AU-1, F4U-4B, -4P, and -5N and 5-NL. There were dogfights between F4Us and Soviet-built Yakovlev Yak-9 fighters early in the war, but when the enemy introduced the Mikoyan-Gurevich MiG-15, the Corsair was outmatched. On 10 September 1952, a MiG-15 made the mistake of getting into a turning contest with a Corsair piloted by Marine Captain Jesse G. Folmar, with Folmar shooting the MiG down with his four 20 mm cannon. In turn, four MiG-15s shot down Folmar minutes later; Folmar bailed out and was quickly rescued with little injury.

F4U-5N and -5NL Corsair night fighters were used to attack enemy supply lines, including truck convoys and trains, as well as interdicting night attack aircraft such as the Polikarpov Po-2 "Bedcheck Charlies", which were used to harass United Nations forces at night. The F4Us often operated with the help of C-47 'flare ships' which dropped hundreds of 1,000,000 candlepower magnesium flares to illuminate the targets. For many operations detachments of U.S. Navy F4U-5Ns were posted to shore bases. The leader of one such unit, Lieutenant Guy Bordelon of VC-3 Det D (Detachment D), off , become the Navy's only ace in the war, in addition to being the only American ace in Korea that used a piston engined aircraft. Bordelon, nicknamed "Lucky Pierre", was credited with three Lavochkin La-9s or La-11s and two Yakovlev Yak-18s between 29 June and 16/17 July 1952. Navy and Marine Corsairs were credited with a total of 12 enemy aircraft.

More generally, Corsairs performed attacks with cannons, napalm tanks, various iron bombs, and unguided rockets. The 5 inch HVAR was a reliable standby; sturdy Soviet-built armor proved resistant to the HVAR's punch, which led to a new 6.5 in (16.5 cm) shaped charge antitank warhead being developed. The result was called the "Anti-Tank Aircraft Rocket (ATAR)." The 11 inch (29.85 cm) "Tiny Tim" was also used in combat, with two under the belly.

Lieutenant Thomas J. Hudner, Jr., flying an F4U-4 of VF-32 off , was awarded the Medal of Honor for crash landing his Corsair in an attempt to rescue his squadron mate, Ensign Jesse L. Brown, whose aircraft had been forced down by antiaircraft fire near Changjin. Brown, who did not survive the incident, was the U.S. Navy's first African American naval aviator.

After the war, the French Navy had an urgent requirement for a powerful carrier-borne close-air support aircraft to operate from the French Navy's four aircraft carriers that it acquired in the late 1940s (Two former U.S. Navy and two Royal Navy carriers were transferred). Secondhand US Navy Douglas SBD Dauntless dive-bombers of Flotille 3F and 4F were used to attack enemy targets and support ground forces in the First Indochina War. Former US Grumman F6F-5 Hellcats and Curtiss SB2C Helldivers were also used for close air support. A new and more capable aircraft was needed.

The last production Corsair was the "'F4U-7", which was built specifically for the French naval air arm, the Aéronavale. The XF4U-7 prototype did its test flight on 2 July 1952 with a total of 94 F4U-7s built for the French Navy's "Aéronavale" (79 in 1952, 15 in 1953), with the last of the batch, the final Corsair built, rolled out on 31 January 1953. The F4U-7s were actually purchased by the U.S. Navy and passed on to the Aéronavale through the U.S. Military Assistance Program (MAP). The French Navy used its F4U-7s during the second half of the First Indochina War in the 1950s (12.F, 14.F, 15.F Flotillas), where they were supplemented by at least 25 ex-USMC AU-1s passed on to the French in 1954, after the end of the Korean War.

On 15 January 1953, Flotille 14F, based at Karouba Air Base near Bizerte in Tunisia, became the first Aéronavale unit to receive the F4U-7 Corsair. Flotille 14F pilots arrived at Da Nang on 17 April 1954, but without their aircraft. The next day, the carrier USS "Saipan" delivered 25 war-weary ground attack ex-USMC AU-1 Corsairs (flown by VMA-212 at the end of the Korean War). During three months operating over Dien Bien Phu and Viêt-Nam, the Corsairs flew 959 combat sorties totaling 1,335 flight hours. They dropped some 700 tons of bombs and fired more than 300 rockets and 70,000 20 mm rounds. Six aircraft were damaged and two shot down by Viet Minh.

In September 1954, F4U-7 Corsairs were loaded aboard and brought back to France in November. The surviving Ex-USMC AU-1s were taken to the Philippines and returned to the U.S. Navy. In 1956, Flotille 15F returned to South Vietnam, equipped with F4U-7 Corsairs.

The 14.F and 15.F Flotillas also took part in the Anglo-French-Israeli seizure of the Suez Canal in October 1956, code-named Operation Musketeer. The Corsairs were painted with yellow and black recognition stripes for this operation. They were tasked with destroying Egyptian Navy ships at Alexandria but the presence of U.S. Navy ships prevented the successful completion of the mission. On 3 November 16 F4U-7s attacked airfields in the Delta, with one Corsair shot down by anti-aircraft fire. Two more Corsairs were damaged when landing back on the carriers. The Corsairs engaged in Operation Musketeer dropped a total of 25 tons of bombs, and fired more than 500 rockets and 16,000 20mm rounds.

As soon as they disembarked from the carriers that took part in Operation Musketeer, at the end of 1956, all three Corsair Flotillas moved to Telergma and Oran airfields in Algeria from where they provided CAS and helicopter escort. They were joined by the new "Flottille 17F", established at Hyères in April 1958.

French F4U-7 Corsairs (with some borrowed AU-1s) of the 12F, 14F, 15F, and 17F Flotillas conducted missions during the Algerian War between 1955 and 1962. Between February and March 1958, several strikes and CAS missions were launched from , the only carrier involved in the Algeria War. 
France recognized Tunisian independence and sovereignty in 1956 but continued to station military forces at Bizerte and planned to extend the airbase. In 1961, Tunisia asked France to evacuate the base. Tunisia imposed a blockade on the base on 17 July, hoping to force its evacuation. This resulted in a battle between militiamen and the French military which lasted three days. French paratroopers, escorted by Corsairs of the 12F and 17F Flotillas, were dropped to reinforce the base and the Aéronavale launched air strikes on Tunisian troops and vehicles between 19–21 July, carrying out more than 150 sorties. Three Corsairs were damaged by ground fire. 

In early 1959, the "Aéronavale" experimented with the Vietnam War-era SS.11 wire-guided anti-tank missile on F4U-7 Corsairs. The 12.F pilots trained for this experimental program were required to manually pilot the missile at approximatively two kilometers from the target on low altitude with a joystick using the right hand while keeping track of a flare on its tail, and piloting the aircraft using the left hand; an exercise that could be very tricky in a single-seat aircraft under combat conditions. Despite reportedly effective results during the tests, this armament was not used with Corsairs during the ongoing Algerian War.

The "Aéronavale" used 163 Corsairs (94 F4U-7s and 69 AU-1s), the last of them used by the Cuers-based 14.F Flotilla were out of service by September 1964, with some surviving for museum display or as civilian warbirds. By the early 1960s, two new modern aircraft carriers, and , had entered service with the French Navy and with them a new generation of jet-powered combat aircraft.

Corsairs flew their final combat missions in 1969 during the "Football War" between Honduras and El Salvador, in service with both air forces. The conflict was allegedly triggered, though not really caused, by a disagreement over a soccer (association football) match. Captain Fernando Soto of the Honduran Air Force shot down three Salvadoran Air Force aircraft on 17 July 1969. In the morning he shot down a Cavalier Mustang, killing the pilot. In the afternoon, he shot down two FG-1s; the pilot of the second aircraft may have bailed out, but the third exploded in the air, killing the pilot. These combats were the last ones among propeller-driven aircraft in the world and also making Soto the only pilot credited with three kills in an American continental war. El Salvador did not shoot down any Honduran aircraft. At the outset of the Football War, El Salvador enlisted the assistance of several American pilots with P-51 and F4U experience. Bob Love, a Korean war ace, Chuck Lyford, Ben Hall, and Lynn Garrison are believed to have flown combat missions, but it has never been confirmed. Lynn Garrison had purchased F4U-7 133693 from the French MAAG office when he retired from French naval service in 1964. It was registered N693M and was later destroyed in a 1987 crash in San Diego, California.

The Corsair entered service in 1942. Although designed as a carrier fighter, initial operation from carrier decks proved to be troublesome. Its low-speed handling was tricky due to the left wing stalling before the right wing. This factor, together with poor visibility over the long nose (leading to one of its nicknames, "The Hose Nose"), made landing a Corsair on a carrier a difficult task. For these reasons, most Corsairs initially went to Marine Corps squadrons which operated off land-based runways, with some early Goodyear-built examples (designated FG-1A) being built with fixed wings. The USMC aviators welcomed the Corsair with open arms as its performance was far superior to the contemporary Brewster F2A Buffalo and Grumman F4F-3 and -4 Wildcat.

Moreover, the Corsair was able to outperform the primary Japanese fighter, the A6M Zero. While the Zero could outturn the F4U at low speed, the Corsair was faster and could outclimb and outdive the A6M.

This performance advantage, combined with the ability to take severe punishment, meant a pilot could place an enemy aircraft in the killing zone of the F4U's six .50 (12.7 mm) M2 Browning machine guns and keep him there long enough to inflict major damage. The 2,300 rounds carried by the Corsair gave just under 30 seconds of fire from each gun, which, fired in three to six-second bursts, made the F4U a devastating weapon against aircraft, ground targets, and even ships.

Beginning in 1943, the Fleet Air Arm (FAA) also received Corsairs and flew them successfully from Royal Navy carriers in combat with the British Pacific Fleet and in Norway. These were clipped-wing Corsairs, the wingtips shortened to clear the lower overhead height of RN carriers. FAA also developed a curving landing approach to overcome the F4U's deficiencies.
Infantrymen nicknamed the Corsair "The Sweetheart of the Marianas" and "The Angel of Okinawa" for its roles in these campaigns. Among Navy and Marine aviators, the aircraft was nicknamed "Ensign Eliminator" and "Bent-Wing Eliminator" because it required many more hours of flight training to master than other Navy carrier-borne aircraft. It was also called simply "U-bird" or "Bent Wing Bird". Although Allied World War II sources frequently make the claim that the Japanese called the Corsair the "Whistling Death", Japanese sources do not support this, and it was mainly known as the Sikorsky.

The Corsair has been named the official aircraft of Connecticut due to its multiple connections to Connecticut businesses including airframe manufacturer Vought-Sikorsky Aircraft, engine manufacturer Pratt & Whitney, and propeller manufacturer Hamilton Standard .

During World War II, Corsair production expanded beyond Vought to include Brewster and Goodyear models. Allied forces flying the aircraft in World War II included the Fleet Air Arm and the Royal New Zealand Air Force. Eventually, more than 12,500 F4Us would be built, comprising 16 separate variants.

F4U-1 (called Corsair Mk I by the Fleet Air Arm):

The first production version of the Corsair with the distinctive "birdcage" canopy and low seating position. The differences over the XF4U-1 were as follows:

The Royal Navy's Fleet Air Arm received 95 Vought F4U-1s. These were all early "birdcage" Corsairs. Vought also built a single F4U-1 two-seat trainer; the Navy showed no interest.

F4U-1A (called Corsair Mk II by the Fleet Air Arm):

Mid-to-late production Corsairs incorporated a new, taller, wider canopy with only two frames — very close to what the Malcolm hood did for British fighter aircraft — along with a simplified windscreen; the new canopy design implied that the semi-elliptical turtledeck "flank" windows could be omitted. The designation F4U-1A to differentiate these Corsairs from earlier "birdcage" variants was allowed to be used internally by manufacturers The pilot's seat was raised which, combined with the new canopy and a 6-inch (152.4 mm) lengthening of the tailwheel strut, allowed the pilot better visibility over the long nose. In addition to these changes, the bombing window under the cockpit was omitted. These Corsairs introduced a -long stall strip just outboard of the gun ports on the right wing leading edge and improved undercarriage oleo struts which eliminated bouncing on landing, making these the first truly "carrier capable" F4Us.

360 F4U-1As were delivered to the Fleet Air Arm. In British service, the aircraft type was modified with "clipped" wings ( was cut off each wingtip) for use on British aircraft carriers, although the Royal Navy had been successfully operating the Corsair Mk I since 1 June 1943 when No. 1830 Squadron was commissioned and assigned to HMS Illustrious. F4U-1s in many USMC squadrons had their arrester hooks removed. Additionally, an experimental R-2800-8W engine with water injection was fitted on one of the late F4U-1As. After satisfactory results, many F4U-1As were fitted with the new powerplant. The aircraft carried 237 gal (897 l) in the main fuel tank, located in front of the cockpit, as well as an unarmored, non-self-sealing 62 gal (235 l) fuel tank in each wing. This version of the Corsair was the first to be able to carry a drop tank under the center-section. With drop tanks fitted, the fighter had a maximum ferry range of just over .

F3A-1 and F3A-1D (called Corsair Mk III by the Fleet Air Arm):

This was the designation for Brewster-built F4U-1. Labor troubles delayed production, and the Navy ordered the company's contract terminated; they folded soon after. Poor quality wing fittings meant that these aircraft were red-lined for speed and prohibited from aerobatics after several lost their wings. None of the Brewster-built Corsairs reached front line units. 430 Brewster Corsairs (334 F3A-1 and 96 F3A-1D), more than half of Brewster's total production, were delivered to the Fleet Air Arm.

FG-1A and FG-1D (called Corsair Mk IV by the Fleet Air Arm):

This was the designation for Corsairs that were license built by Goodyear, to the same specifications as Vought's Corsairs. The first Goodyear built FG-1 flew in February 1943 and Goodyear began delivery of FG-1 Corsairs in April 1943. The company continued production until the end of the war and delivered 4,007 FG-1 series Corsairs, including sixty FG-1Ds to the RNZAF and 857 (400 FG-1 and FG-1A, and 457 FG-1D) to the Royal Navy as Corsair Mk IVs. 
F4U-1B: This was an unofficial post-war designation used to identify F4U-1s modified for FAA use.

F4U-1C:

The prototype F4U-1C, appeared in August 1943 and was based on an F4U-1. A total of 200 of this variant were built from July to November 1944; all were based on the F4U-1D and were built in parallel with that variant. Intended for ground-attack as well as fighter missions, the F4U-1C was similar to the F4U-1D but its six machine guns were replaced by four 20 millimeter (0.79 in) AN/M2 cannons with 231 rounds of ammunition per gun. The F4U-1C was introduced to combat during 1945, most notably in the Okinawa campaign. The firepower of 20mm was highly appreciated. It was believed that the 20mm cannon was more effective for all types of combat work than the .50 caliber machine gun. However, despite the superior firepower, many navy pilots preferred .50 caliber machine guns in air combat due to jam and freezing problems of the 20mm cannons. these problems were reduced as the ordnance crews gained experince until the performance of the guns compared favorable with the .50 caliber, but freezing problems remained at 25,000 to 30,000 feet until gun heater installed.

F4U-1D (called Corsair Mk II by the Fleet Air Arm):

This variant was introduced in April 1944, and was built in parallel with the F4U-1C. It had the new R-2800-8W Double Wasp engine equipped with water injection. This change gave the aircraft up to more power, which, in turn, increased performance. Speed was increased from to . Due to the U.S. Navy's need for fighter-bombers, it had a payload of rockets double the -1A's carried on permanent launching rails, as well as twin pylons for bombs or drop tanks. These modifications caused extra drag, but the additional fuel carried by the two drop tanks would still allow the aircraft to fly relatively long missions despite heavy, un-aerodynamic loads. A single piece "blown" clear-view canopy was adopted as standard equipment for the -1D model, and all later F4U production aircraft. 150 F4U-1D were delivered to the Fleet Air Arm.

F4U-1P: A rare photo reconnaissance variant.

XF4U-2: Special night fighter variant, equipped with two auxiliary fuel tanks.

F4U-2: Experimental conversion of the F4U-1 Corsair into a carrier-borne night fighter, armed with five .50 in (12.7 mm) machine guns (the outboard, right gun was deleted), and fitted with Airborne Intercept (AI) radar set in a radome placed outboard on the starboard wing. Since Vought was preoccupied with more important projects, only 32 were converted from existing F4U-1s by the Naval Aircraft Factory and another two by front line units.
The type saw combat with VF(N)-101 aboard and USS "Intrepid" in early 1944, VF(N)-75 in the Solomon Islands, and VMF(N)-532 on Tarawa.

XF4U-3: Experimental aircraft built to hold different engines in order to test the Corsair's performance with a variety of power plants. This variant never entered service. Goodyear also contributed a number of airframes, designated FG-3, to the project. A single sub-variant XF4U-3B with minor modifications was also produced for the FAA.

XF4U-4: New engine and cowling.

F4U-4: The last variant to see action during World War II. Deliveries to the U.S. Navy of the F4U-4 began in early 1945. It had the dual-stage-supercharged -18W engine. When the cylinders were injected with the water/alcohol mixture, power was boosted to . The aircraft required an air scoop under the nose and the unarmored wing fuel tanks of 62 gal (234 l) capacities were removed for better maneuverability at the expense of maximum range. The propeller was changed to a four blade type. Maximum speed was increased to and climb rate to over 4,500 ft/min (1,180 m/min) as opposed to the 2,900 ft/min (884 m/min) of the F4U-1A. The "4-Hog" retained the original armament and had all the external load (i.e., drop tanks, bombs) capabilities of the F4U-1D. The windscreen was now flat bullet-resistant glass to avoid optical distortion, a change from the curved Plexiglas windscreens with the internal plate glass of the earlier Corsairs. Vought also tested the two F4U-4Xs (BuNos 49763 and 50301, prototypes for the new R2800) with fixed wing-tip tanks (the Navy showed no interest) and an Aeroproducts six-blade contraprop (not accepted for production).
F4U-4B: 300 F4U-4s ordered with alternate gun armament of four AN/M3 cannon.

F4U-4E and F4U-4N: Developed late in WWII, these night fighters featured radar radomes projecting from the right wingtip. The -4E was fitted with the APS-4 search radar, while the -4N was fitted with the APS-6 type. In addition, these aircraft were often refitted with four 20mm M2 cannons similar to the F4U-1C. Though these variants would not see combat during WWII, the night fighter variants would see great use during the Korean war.

F4U-4K: Experimental drone.

F4U-4P: F4U-4 equivalent to the -1P, a rare photo reconnaissance variant.

XF4U-5: New engine cowling, other extensive changes.

F4U-5: A 1945 design modification of the F4U-4, first flown on 21 December 1945, was intended to increase the F4U-4 Corsair's overall performance and incorporate many Corsair pilots' suggestions. It featured a more powerful Pratt and Whitney R-2800-32(E) engine with a two-stage supercharger, rated at a maximum of . Other improvements included automatic blower controls, cowl flaps, intercooler doors, and oil cooler for the engine, spring tabs for the elevators and rudder, a completely modernized cockpit, a completely retractable tail wheel, and heated cannon bays and pitot head. The cowling was lowered two degrees to help with forward visibility, but perhaps most striking as the first variant to feature all-metal wings (223 units produced). Maximum speed was and max rate of climb at sea level 4,850 feet per minute.

F4U-5N: Radar equipped version (214 units produced)

F4U-5NL: Winterized version (72 units produced, 29 modified from F4U-5Ns (101 total)). Fitted with rubber de-icing boots on the leading edge of the wings and tail.

F4U-5P: Long-range photo-reconnaissance version (30 units produced)

F4U-6: Re-designated AU-1, this was a ground-attack version produced for the U.S. Marine Corps.

F4U-7 : AU-1 developed for the French Navy.

FG-1E: Goodyear FG-1 with radar equipment.

FG-1K: Goodyear FG-1 as drone.

FG-3: Turbosupercharger version converted from FG-1D.

FG-4: Goodyear F4U-4, never delivered.

AU-1: U.S. Marines attack variant with extra armor to protect the pilot and fuel tank, and the oil coolers relocated inboard to reduce vulnerability to ground fire. The supercharger was simplified as the design was intended for low-altitude operation. Extra racks were also fitted. Fully loaded for combat the AU-1 weighed 20% more than a fully loaded F4U-4, and was capable of carrying 8,200 lb of bombs. The AU-1 had a maximum speed of 238 miles per hour at 9,500 ft, when loaded with 4,600 lb of bombs and a 150-gallon drop-tank. When loaded with eight rockets and two 150-gallon drop-tanks, maximum speed was 298 mph at 19,700 ft. When not carrying external loads, maximum speed was 389 mph at 14,000 ft. First produced in 1952 and used in Korea, and retired in 1957. Re-designated from F4U-6.

In March 1944, Pratt & Whitney requested an F4U-1 Corsair from Vought Aircraft for evaluation of their new P&W R-4360, Wasp Major 4-row 28-cylinder "corncob" radial engine. The F2G-1 and F2G-2 were significantly different aircraft. F2G-1 featured a manual folding wing and propeller, while the F2G-2 had hydraulic operated folding wings, propeller, and carrier arresting hook for carrier use. There were five pre-production XF2G-1s: BuNo 14691, 14692, 14693 (Race 94), 14694 (Race 18), and 14695. There were ten production F2Gs: Five F2G-1s BuNo 88454 (Museum of Flight in Seattle, Washington), 88455, 88456, 88457 (Race 84), and 88458 (Race 57) and five F2G-2s BuNo 88459, 88460, 88461, 88462, and 88463 (Race 74). Five F2Gs were sold as surplus and went on to racing success after the war (indicated by the "Race" number after the BuNo), winning the Thompson trophy races in 1947 and 1949. The only surviving F2G-1s are BuNos 88454 and 88458 (Race 57). The only surviving F2G-2 was BuNo 88463 (Race 74). It was destroyed in a crash September 2012 after having a full restoration completed in July 2011.



According to the FAA there are 45 privately owned F4Us in the U.S.

There is an F4U-4 Corsair with serial number 96995 owned by the Flying Bulls.






</doc>
<doc id="11723" url="https://en.wikipedia.org/wiki?curid=11723" title="Freddy Heineken">
Freddy Heineken

Alfred Henry "Freddy" Heineken (4 November 1923 – 3 January 2002) was a Dutch businessman for Heineken International, the brewing company bought in 1864 by his grandfather Gerard Adriaan Heineken in Amsterdam. He served as chairman of the board of directors and CEO from 1971 until 1989. After his retirement as chairman and CEO, Heineken continued to sit on the board of directors until his death and served as chairman of the supervisory board from 1989 till 1995. At the time of his death, Heineken was one of the richest people in the Netherlands, with a net worth of 9.5 billion guilders.

Heineken was born on 4 November 1923 in Amsterdam in the Netherlands. He was the grandson of Gerard Adriaan Heineken, who was the founder of the brewery Heineken. He entered the service of the Heineken company – which by then was no longer owned by the family – on 1 June 1941 and bought back stock several years later, to ensure the family controlled the company again. He created the Heineken Holding that owned 50.005% of Heineken International; he personally held a majority stake in Heineken Holding. By the time of his resignation as chairman of the board in 1989 he had transformed Heineken from a brand that was known primarily in the Netherlands into a brand name recognized worldwide.

Freddy Heineken and his driver Ab Doderer were kidnapped in 1983 and released on a ransom of 35 million Dutch guilders (about £15.7 million GBPs). The kidnappers Cor van Hout, Willem Holleeder, Jan Boellaard, Frans Meijer, and Martin Erkamps, were eventually caught and served prison terms. Before being extradited, Van Hout and Holleeder stayed for more than three years in France, first on the run, then in prison, and then, awaiting a change of the extradition treaty, under house arrest, and finally in prison again. Meijer escaped and lived in Paraguay for years, until he was discovered by Peter R. de Vries and imprisoned there. In 2003, Meijer halted resisting his extradition to the Netherlands, and was transferred to a Dutch prison to serve the last part of his term. 

The films "The Heineken Kidnapping" (2011) and "Kidnapping Freddy Heineken" (2015) are based on this incident.

Heineken married Lucille Cummins, an American from a Kentucky family of bourbon whiskey distillers. Heineken died unexpectedly from pneumonia on 3 January 2002 at the age of seventy-eight in his home in Noordwijk. The businessman died in the presence of his immediate family, including his daughter Charlene de Carvalho-Heineken. Heineken struggled for some time with deteriorating health, in 1999 he suffered a mild stroke but recovered. Shortly before his death he broke his arm in a fall. Heineken was buried at the General Cemetery in Noordwijk. Heineken's daughter inherited his fortune. Heineken was a member of the People's Party for Freedom and Democracy (VVD).

A film of the kidnapping "De Heineken ontvoering", with Rutger Hauer playing Freddy Heineken, was released in October 2011. A second film, "Kidnapping Mr. Heineken", based on De Vries' book about the kidnapping, was produced by Informant Media in 2013 based on the scenario written by William Brookfield. In this film Heineken is played by Sir Anthony Hopkins with the kidnappers played by Jim Sturgess, Sam Worthington, Ryan Kwanten, Mark van Eeuwen and Thomas Cocquerel.



</doc>
<doc id="11724" url="https://en.wikipedia.org/wiki?curid=11724" title="International Formula 3000">
International Formula 3000

The Formula 3000 International Championship was a motor racing series created by the Fédération Internationale de l'Automobile (FIA) in 1985 to become the final preparatory step for drivers hoping to enter Formula One. Formula Two had become too expensive, and was dominated by works-run cars with factory engines; the hope was that Formula 3000 would offer quicker, cheaper, more open racing. The series began as an open specification, then tyres were standardized from 1986 onwards, followed by engines and chassis in 1996. The series ran annually until 2004, and was replaced in 2005 by the GP2 Series.

The series was staged as the Formula 3000 European Championship in 1985, as the Formula 3000 Intercontinental Championship in 1986 and 1987 and then as the Formula 3000 International Championship from 1988 to 2004.

Formula 3000 replaced Formula Two, and was so named because the engines used were limited to 3000cc maximum capacity. Initially, the Cosworth DFV was a popular choice, having been made obsolete in Formula One by the adoption of 1.5 litre turbocharged engines. The rules permitted any 90-degree V8 engine, fitted with a rev-limiter to keep power output under control. As well as the Cosworth, a Honda engine based on an Indy V8 by John Judd also appeared; a rumoured Lamborghini V8 never raced. In later years, a Mugen-Honda V8 became the unit of choice, eclipsing the DFV; Cosworth responded with the brand new AC engine. Costs began to increase significantly.

The first chassis from March, Automobiles Gonfaronnaises Sportives (AGS) and Ralt were developments of their existing 1984 Formula Two designs, although Lola's entry was based on and looked very much like an IndyCar. A few smaller teams tried obsolete three-litre Formula One cars (from Tyrrell, Williams, Minardi, Arrows and RAM), with little success—the Grand Prix and Indycar-derived entries were too unwieldy as their fuel tanks were about twice the size of those needed for F3000 races, and the weight distribution was not ideal. The first few years of the championship saw March establishing a superiority over Ralt and Lola—there was little to choose between the chassis, but more Marches were sold and ended up in better hands. In 1988, the ambitious Reynard marque entered with a brand new chassis; Reynard had won their first race in every formula they had previously entered, and did so again in F3000. The next couple of years saw Lola improve slightly—their car was competitive with the Reynard in 1990—and March slip, but both were crushed by the Reynard teams, and by the mid-90s, F3000 was a virtual Reynard monopoly, although Lola did eventually return with a promising car and the Japanese Footwork and Dome chassis were seen in Europe. Dallara briefly tried the series before moving up to Formula One, and AGS moved up from Formula Two but never recaptured their occasional success. At least one unraced F3000 chassis existed—the Wagner fitted with a straight-six short-stroke BMW. This was converted into a sports car, however.

The series saw occasional controversy. Definitive rules for the 1985 season did not appear until the championship was well under way. In 1987 questions were asked about the ability of some of the drivers, given the high number of accidents in the formula. In 1989 the eligibility of the new Reynard chassis was challenged, as it was raced with a different nose to the one that had been crash tested. This season also saw problems with driver changes - the cost of F3000 was escalating to the point that teams were finding it difficult to run drivers for a whole season. A rule limiting driver changes to two per car per season meant that some cars had to sit idle while drivers with budgets could not race them. In 1991, some Italian teams started using Agip's so-called "jungle juice" Formula One fuel, worth an estimated 15 bhp, giving their drivers a significant advantage. In the early years of the formula there was much concern about safety, with a high number of accidents resulting in injuries to drivers. There was one fatality in the International Championship - Marco Campos in the very last round of the 1995 series.

Formula 3000 races during the "open chassis" era tended to be of about 100–120 miles in distance, held at major circuits, either headlining meetings or paired with other international events. The "jewel in the crown" of the F3000 season was traditionally the Pau Grand Prix street race, rivalled for a few years by the Birmingham round. Most major circuits in France, Italy, Spain, Germany and the United Kingdom saw the series visit at least once.

In 1996, new rules introduced a single engine (a detuned Judd V8 engine, re-engineered by and badged as a Zytek) and chassis (Lola), to go along with tyre standardization (Avon) introduced in 1986. The following year the calendar was combined with that of Formula One, so the series became support races for the Grand Prix. Several Grand Prix teams established formal links with F3000 teams to develop young drivers (and engineering talent); these relationships varied from formal "junior teams" (such as the one McLaren set up for Nick Heidfeld) to fairly distant relationships based mostly upon shared sponsors and the use of the 'parent' team's name. The series grew dramatically through the late nineties, reaching an entry of nearly 40 cars - although this in itself was problematic as it meant many drivers failed to qualify. In 2000, the series was restricted to 15 teams of two cars each.

However, by 2002 expenses were once more very high and the number of entries, and sponsors, rapidly dwindled. International Formula 3000 was experiencing tough competition with cheaper formulae, such as European F3000 (using ex-FIA 1999 and 2002 Lola chassis), World Series by Nissan (also known as Formula Nissan) and Formula Renault V6 Eurocup. By the end of 2003, car counts had fallen to new lows.

The 2004 season was the last F3000 campaign, due in part to dwindling field sizes. In 2005 it was replaced with a new series known as GP2, with Renault backing.

Three past F3000 champions (Müller, Junqueira and Wirdheim) have never been entered in an F1 race. Montoya and Bourdais became Champions in North American open-wheel (CART and Champcar) respectively, with Fittipaldi, Moreno, Junqueira and Wilson also becoming race winners, and Wirdheim making the ranks. Müller became a BMW driver in WTCC touring car racing after having been a test driver for the BMW-Williams F1 project in 1999 as well as a racer of the BMW V12 LMR Le Mans winner. Sospiri attempted to qualify for one Formula One race but failed to make it, as part of the disastrous MasterCard Lola team. Wirdheim has been third driver in practice sessions for Jaguar Racing, but has never participated in a race.

Three past F3000 champions have won an F1 Grand Prix: Alesi, Panis and Montoya (who also won the Indy 500).



</doc>
<doc id="11725" url="https://en.wikipedia.org/wiki?curid=11725" title="Flunitrazepam">
Flunitrazepam

Flunitrazepam, also known as Rohypnol among other names, is a benzodiazepine used to treat severe insomnia and assist with anesthesia. As with other hypnotics, flunitrazepam has been advised to be prescribed only on a short-term basis or by those with chronic insomnia on an occasional basis.
It was patented in 1962 and came into medical use in 1974. Flunitrazepam has been referred to as a date rape drug, though the percentage of reported rape cases in which it is involved is small.

In countries where this drug is used, it is used for treatment of sleeping problems, and in some countries to begin anesthesia. These were also the uses for which it was originally studied.

Adverse effects of flunitrazepam include dependence, both physical and psychological; reduced sleep quality resulting in somnolence; and overdose, resulting in excessive sedation, impairment of balance and speech, respiratory depression or coma, and possibly death. Because of the latter, flunitrazepam is commonly used in suicide. When used in pregnancy, it might cause hypotonia.

Flunitrazepam as with other benzodiazepines can lead to drug dependence and benzodiazepine withdrawal syndrome. Discontinuation may result in the appearance of withdrawal symptoms. Abrupt withdrawal may lead to a benzodiazepine withdrawal syndrome characterised by seizures, psychosis, insomnia, and anxiety. Rebound insomnia, worse than baseline insomnia, typically occurs after discontinuation of flunitrazepam even from short-term single nightly dose therapy.

Flunitrazepam may cause a paradoxical reaction in some individuals causing symptoms including anxiety, aggressiveness, agitation, confusion, disinhibition, loss of impulse control, talkativeness, violent behavior, and even convulsions. Paradoxical adverse effects may even lead to criminal behaviour.

Benzodiazepines such as flunitrazepam are lipophilic and rapidly penetrate membranes and, therefore, rapidly cross over into the placenta with significant uptake of the drug. Use of benzodiazepines including flunitrazepam in late pregnancy, especially high doses, may result in hypotonia, also known as floppy baby syndrome.

Flunitrazepam impairs cognitive functions. This may appear as lack of concentration, confusion and anterograde amnesia. It can be described as a hangover-like effect which can persist to the next day. It also impairs psychomotor functions similar to other benzodiazepines and nonbenzodiazepine hypnotic drugs; falls and hip fractures were frequently reported. The combination with alcohol increases these impairments. Partial, but incomplete tolerance develops to these impairments.

Other adverse effects include:

Benzodiazepines require special precaution if used in the elderly, during pregnancy, in children, in alcohol- or drug-dependent individuals, and in individuals with comorbid psychiatric disorders.

Impairment of driving skills with a resultant increased risk of road traffic accidents is probably the most important adverse effect. This side-effect is not unique to flunitrazepam but also occurs with other hypnotic drugs. Flunitrazepam seems to have a particularly high risk of road traffic accidents compared to other hypnotic drugs. Extreme caution should be exercised by drivers after taking flunitrazepam.

The use of flunitrazepam in combination with alcoholic beverages synergizes the adverse effects, and can lead to toxicity and death.

Flunitrazepam is a drug that is frequently involved in drug intoxication, including overdose. Overdose of flunitrazepam may result in excessive sedation, or impairment of balance or speech. This may progress in severe overdoses to respiratory depression or coma and possibly death. The risk of overdose is increased if flunitrazepam is taken in combination with CNS depressants such as ethanol (alcohol) and opioids. Flunitrazepam overdose responds to the benzodiazepine receptor antagonist flumazenil, which thus can be used as a treatment.

As of 2016, blood tests can identify flunitrazepam at concentrations of as low as 4 ng/ml; the elimination half life of the drug is 11–25 hours. For urine samples, metabolites can be identified 60 hours to 28 days, depending on the dose and analytical method used. Hair and saliva can also be analyzed; hair is useful when a long time has transpired since ingestion, and saliva for workplace drug tests.

Flunitrazepam can be measured in blood or plasma to confirm a diagnosis of poisoning in hospitalized patients, provide evidence in an impaired driving arrest, or assist in a medicolegal death investigation. Blood or plasma flunitrazepam concentrations are usually in a range of 5–20 μg/L in persons receiving the drug therapeutically as a nighttime hypnotic, 10–50 μg/L in those arrested for impaired driving and 100–1000 μg/L in victims of acute fatal overdosage. Urine is often the preferred specimen for routine drug abuse monitoring purposes. The presence of 7-aminoflunitrazepam, a pharmacologically-active metabolite and "in vitro" degradation product, is useful for confirmation of flunitrazepam ingestion. In postmortem specimens, the parent drug may have been entirely degraded over time to 7-aminoflunitrazepam. Other metabolites include desmethylflunitrazepam and 3-hydroxydesmethylflunitrazepam.

The main pharmacological effects of flunitrazepam are the enhancement of GABA at various GABA receptors.

While 80% of flunitrazepam that is taken orally is absorbed, bioavailability in suppository form is closer to 50%.

Flunitrazepam has a long half-life of 18–26 hours, which means that flunitrazepam's effects after nighttime administration persist throughout the next day.

Flunitrazepam is lipophilic and is metabolised hepatically via oxidative pathways. The enzyme CYP3A4 is the main enzyme in its phase 1 metabolism in human liver microsomes.

Flunitrazepam is classed as a nitro-benzodiazepine. It is the fluorinated "N"-methyl derivative of nitrazepam. Other nitro-benzodiazepines include nitrazepam (the parent compound), nimetazepam (methylamino derivative) and clonazepam (2ʹ-chlorinated derivative).

Flunitrazepam was discovered at Roche as part of the benzodiazepine work led by Leo Sternbach; the patent application was filed in 1962 and it was first marketed in 1974.

Due to abuse of the drug for date rape and recreation, in 1998 Roche modified the formulation to give lower doses, make it less soluble, and add a blue dye for easier detection in drinks. It was never marketed in the US, and by 2016 had been withdrawn from the markets in Spain, France, Germany, and the UK.

A 1989 article in the "European Journal of Clinical Pharmacology" reports that benzodiazepines accounted for 52% of prescription forgeries, suggesting that benzodiazepines was a major prescription drug class of abuse. Nitrazepam accounted for 13% of forged prescriptions.

Flunitrazepam and other sedative hypnotic drugs are detected frequently in cases of people suspected of driving under the influence of drugs. Other benzodiazepines and nonbenzodiazepines (anxiolytic or hypnotic) such as zolpidem and zopiclone (as well as cyclopyrrolones, imidazopyridines, and pyrazolopyrimidines) are also found in high numbers of suspected drugged drivers. Many drivers have blood levels far exceeding the therapeutic dose range, suggesting a high degree of abuse potential for benzodiazepines and similar drugs.

In studies in Sweden, flunitrazepam was the second most common drug used in suicides, being found in about 16% of cases. In a retrospective Swedish study of 1587 deaths, in 159 cases benzodiazepines were found. In suicides when benzodiazepines were implicated, the benzodiazepines flunitrazepam and nitrazepam were occurring in significantly higher concentrations, compared to natural deaths. In 4 of the 159 cases, where benzodiazepines were found, benzodiazepines alone were the only cause of death. It was concluded that flunitrazepam and nitrazepam might be more toxic than other benzodiazepines.

Flunitrazepam is known to induce anterograde amnesia in sufficient doses; individuals are unable to remember certain events that they experienced while under the influence of the drug, which complicates investigations. This effect could be particularly dangerous if flunitrazepam is used to aid in the commission of sexual assault; victims may be unable to clearly recall the assault, the assailant, or the events surrounding the assault.

While use of flunitrazepam in sexual assault has been prominent in the media, as of 2015 appears to be fairly rare, and use of alcohol and other benzodiazepine drugs in date rape appears to be a larger but underreported problem.

In the United Kingdom, the use of flunitrazepam and other "date rape" drugs have also been connected to stealing from sedated victims. An activist quoted by a British newspaper estimated that up to 2,000 individuals are robbed each year after being spiked with powerful sedatives, making drug-assisted robbery a more commonly reported problem than drug-assisted rape.

Flunitrazepam is a Schedule III drug under the international Convention on Psychotropic Substances of 1971.

Flunitrazepam is marketed under many brand names in the countries where it is legal. It also has many street names, including "roofie" and "ruffie".



</doc>
<doc id="11729" url="https://en.wikipedia.org/wiki?curid=11729" title="Fuel cell">
Fuel cell

A fuel cell is an electrochemical cell that converts the chemical energy of a fuel (often hydrogen) and an oxidizing agent (often oxygen) into electricity through a pair of redox reactions. Fuel cells are different from most batteries in requiring a continuous source of fuel and oxygen (usually from air) to sustain the chemical reaction, whereas in a battery the chemical energy usually comes from metals and their ions or oxides that are commonly already present in the battery, except in flow batteries. Fuel cells can produce electricity continuously for as long as fuel and oxygen are supplied.

The first fuel cells were invented by Sir William Grove in 1838. The first commercial use of fuel cells came more than a century later following the invention of the hydrogen–oxygen fuel cell by Francis Thomas Bacon in 1932. The alkaline fuel cell, also known as the Bacon fuel cell after its inventor, has been used in NASA space programs since the mid-1960s to generate power for satellites and space capsules. Since then, fuel cells have been used in many other applications. Fuel cells are used for primary and backup power for commercial, industrial and residential buildings and in remote or inaccessible areas. They are also used to power fuel cell vehicles, including forklifts, automobiles, buses, boats, motorcycles and submarines.

There are many types of fuel cells, but they all consist of an anode, a cathode, and an electrolyte that allows ions, often positively charged hydrogen ions (protons), to move between the two sides of the fuel cell. At the anode a catalyst causes the fuel to undergo oxidation reactions that generate ions (often positively charged hydrogen ions) and electrons. The ions move from the anode to the cathode through the electrolyte. At the same time, electrons flow from the anode to the cathode through an external circuit, producing direct current electricity. At the cathode, another catalyst causes ions, electrons, and oxygen to react, forming water and possibly other products. Fuel cells are classified by the type of electrolyte they use and by the difference in startup time ranging from 1 second for proton exchange membrane fuel cells (PEM fuel cells, or PEMFC) to 10 minutes for solid oxide fuel cells (SOFC). A related technology is flow batteries, in which the fuel can be regenerated by recharging. Individual fuel cells produce relatively small electrical potentials, about 0.7 volts, so cells are "stacked", or placed in series, to create sufficient voltage to meet an application's requirements. In addition to electricity, fuel cells produce water, heat and, depending on the fuel source, very small amounts of nitrogen dioxide and other emissions. The energy efficiency of a fuel cell is generally between 40–60%; however, if waste heat is captured in a cogeneration scheme, efficiencies of up to 85% can be obtained.

The fuel cell market is growing, and in 2013 Pike Research estimated that the stationary fuel cell market will reach 50 GW by 2020.
The first references to hydrogen fuel cells appeared in 1838. In a letter dated October 1838 but published in the December 1838 edition of "The London and Edinburgh Philosophical Magazine and Journal of Science", Welsh physicist and barrister Sir William Grove wrote about the development of his first crude fuel cells. He used a combination of sheet iron, copper and porcelain plates, and a solution of sulphate of copper and dilute acid. In a letter to the same publication written in December 1838 but published in June 1839, German physicist Christian Friedrich Schönbein discussed the first crude fuel cell that he had invented. His letter discussed current generated from hydrogen and oxygen dissolved in water. Grove later sketched his design, in 1842, in the same journal. The fuel cell he made used similar materials to today's phosphoric acid fuel cell.
In 1932, English engineer Francis Thomas Bacon successfully developed a 5 kW stationary fuel cell. The alkaline fuel cell (AFC), also known as the Bacon fuel cell after its inventor, is one of the most developed fuel cell technologies, which NASA has used since the mid-1960s.

In 1955, W. Thomas Grubb, a chemist working for the General Electric Company (GE), further modified the original fuel cell design by using a sulphonated polystyrene ion-exchange membrane as the electrolyte. Three years later another GE chemist, Leonard Niedrach, devised a way of depositing platinum onto the membrane, which served as catalyst for the necessary hydrogen oxidation and oxygen reduction reactions. This became known as the "Grubb-Niedrach fuel cell". GE went on to develop this technology with NASA and McDonnell Aircraft, leading to its use during Project Gemini. This was the first commercial use of a fuel cell. In 1959, a team led by Harry Ihrig built a 15 kW fuel cell tractor for Allis-Chalmers, which was demonstrated across the U.S. at state fairs. This system used potassium hydroxide as the electrolyte and compressed hydrogen and oxygen as the reactants. Later in 1959, Bacon and his colleagues demonstrated a practical five-kilowatt unit capable of powering a welding machine. In the 1960s, Pratt & Whitney licensed Bacon's U.S. patents for use in the U.S. space program to supply electricity and drinking water (hydrogen and oxygen being readily available from the spacecraft tanks). In 1991, the first hydrogen fuel cell automobile was developed by Roger Billings.

UTC Power was the first company to manufacture and commercialize a large, stationary fuel cell system for use as a co-generation power plant in hospitals, universities and large office buildings.

In recognition of the fuel cell industry and America's role in fuel cell development, the US Senate recognized 8 October 2015 as National Hydrogen and Fuel Cell Day, passing S. RES 217. The date was chosen in recognition of the atomic weight of hydrogen (1.008).

Fuel cells come in many varieties; however, they all work in the same general manner. They are made up of three adjacent segments: the anode, the electrolyte, and the cathode. Two chemical reactions occur at the interfaces of the three different segments. The net result of the two reactions is that fuel is consumed, water or carbon dioxide is created, and an electric current is created, which can be used to power electrical devices, normally referred to as the load.

At the anode a catalyst oxidizes the fuel, usually hydrogen, turning the fuel into a positively charged ion and a negatively charged electron. The electrolyte is a substance specifically designed so ions can pass through it, but the electrons cannot. The freed electrons travel through a wire creating the electric current. The ions travel through the electrolyte to the cathode. Once reaching the cathode, the ions are reunited with the electrons and the two react with a third chemical, usually oxygen, to create water or carbon dioxide.
Design features in a fuel cell include:

A typical fuel cell produces a voltage from 0.6–0.7 V at full rated load. Voltage decreases as current increases, due to several factors:

To deliver the desired amount of energy, the fuel cells can be combined in series to yield higher voltage, and in parallel to allow a higher current to be supplied. Such a design is called a "fuel cell stack". The cell surface area can also be increased, to allow higher current from each cell. Within the stack, reactant gases must be distributed uniformly over each of the cells to maximize the power output.

In the archetypical hydrogen–oxide proton-exchange membrane fuel cell design, a proton-conducting polymer membrane (typically nafion) contains the electrolyte solution that separates the anode and cathode sides. This was called a "solid polymer electrolyte fuel cell" ("SPEFC") in the early 1970s, before the proton exchange mechanism was well understood. (Notice that the synonyms "polymer electrolyte membrane" and "'proton exchange mechanism" result in the same acronym.)

On the anode side, hydrogen diffuses to the anode catalyst where it later dissociates into protons and electrons. These protons often react with oxidants causing them to become what are commonly referred to as multi-facilitated proton membranes. The protons are conducted through the membrane to the cathode, but the electrons are forced to travel in an external circuit (supplying power) because the membrane is electrically insulating. On the cathode catalyst, oxygen molecules react with the electrons (which have traveled through the external circuit) and protons to form water.

In addition to this pure hydrogen type, there are hydrocarbon fuels for fuel cells, including diesel, methanol ("see:" direct-methanol fuel cells and indirect methanol fuel cells) and chemical hydrides. The waste products with these types of fuel are carbon dioxide and water. When hydrogen is used, the CO is released when methane from natural gas is combined with steam, in a process called steam methane reforming, to produce the hydrogen. This can take place in a different location to the fuel cell, potentially allowing the hydrogen fuel cell to be used indoors—for example, in fork lifts.

The different components of a PEMFC are

The materials used for different parts of the fuel cells differ by type. The bipolar plates may be made of different types of materials, such as, metal, coated metal, graphite, flexible graphite, C–C composite, carbon–polymer composites etc. The membrane electrode assembly (MEA) is referred as the heart of the PEMFC and is usually made of a proton exchange membrane sandwiched between two catalyst-coated carbon papers. Platinum and/or similar type of noble metals are usually used as the catalyst for PEMFC. The electrolyte could be a polymer membrane.


Phosphoric acid fuel cells (PAFC) were first designed and introduced in 1961 by G. V. Elmore and H. A. Tanner. In these cells phosphoric acid is used as a non-conductive electrolyte to pass positive hydrogen ions from the anode to the cathode. These cells commonly work in temperatures of 150 to 200 degrees Celsius. This high temperature will cause heat and energy loss if the heat is not removed and used properly. This heat can be used to produce steam for air conditioning systems or any other thermal energy consuming system. Using this heat in cogeneration can enhance the efficiency of phosphoric acid fuel cells from 40–50% to about 80%. Phosphoric acid, the electrolyte used in PAFCs, is a non-conductive liquid acid which forces electrons to travel from anode to cathode through an external electrical circuit. Since the hydrogen ion production rate on the anode is small, platinum is used as catalyst to increase this ionization rate. A key disadvantage of these cells is the use of an acidic electrolyte. This increases the corrosion or oxidation of components exposed to phosphoric acid.

Solid acid fuel cells (SAFCs) are characterized by the use of a solid acid material as the electrolyte. At low temperatures, solid acids have an ordered molecular structure like most salts. At warmer temperatures (between 140–150°C for CsHSO), some solid acids undergo a phase transition to become highly disordered "superprotonic" structures, which increases conductivity by several orders of magnitude. The first proof-of-concept SAFCs were developed in 2000 using cesium hydrogen sulfate (CsHSO). Current SAFC systems use cesium dihydrogen phosphate (CsHPO) and have demonstrated lifetimes in the thousands of hours.

The alkaline fuel cell or hydrogen-oxygen fuel cell was designed and first demonstrated publicly by Francis Thomas Bacon in 1959. It was used as a primary source of electrical energy in the Apollo space program. The cell consists of two porous carbon electrodes impregnated with a suitable catalyst such as Pt, Ag, CoO, etc. The space between the two electrodes is filled with a concentrated solution of KOH or NaOH which serves as an electrolyte. H gas and O gas are bubbled into the electrolyte through the porous carbon electrodes. Thus the overall reaction involves the combination of hydrogen gas and oxygen gas to form water. The cell runs continuously until the reactant's supply is exhausted. This type of cell operates efficiently in the temperature range 343–413K and provides a potential of about 0.9V. AAEMFC is a type of AFC which employs a solid polymer electrolyte instead of aqueous potassium hydroxide (KOH) and it is superior to aqueous AFC.

Solid oxide fuel cells (SOFCs) use a solid material, most commonly a ceramic material called yttria-stabilized zirconia (YSZ), as the electrolyte. Because SOFCs are made entirely of solid materials, they are not limited to the flat plane configuration of other types of fuel cells and are often designed as rolled tubes. They require high operating temperatures (800–1000 °C) and can be run on a variety of fuels including natural gas.

SOFCs are unique since in those, negatively charged oxygen ions travel from the cathode (positive side of the fuel cell) to the anode (negative side of the fuel cell) instead of positively charged hydrogen ions travelling from the anode to the cathode, as is the case in all other types of fuel cells. Oxygen gas is fed through the cathode, where it absorbs electrons to create oxygen ions. The oxygen ions then travel through the electrolyte to react with hydrogen gas at the anode. The reaction at the anode produces electricity and water as by-products. Carbon dioxide may also be a by-product depending on the fuel, but the carbon emissions from an SOFC system are less than those from a fossil fuel combustion plant. The chemical reactions for the SOFC system can be expressed as follows:

SOFC systems can run on fuels other than pure hydrogen gas. However, since hydrogen is necessary for the reactions listed above, the fuel selected must contain hydrogen atoms. For the fuel cell to operate, the fuel must be converted into pure hydrogen gas. SOFCs are capable of internally reforming light hydrocarbons such as methane (natural gas), propane and butane. These fuel cells are at an early stage of development.

Challenges exist in SOFC systems due to their high operating temperatures. One such challenge is the potential for carbon dust to build up on the anode, which slows down the internal reforming process. Research to address this "carbon coking" issue at the University of Pennsylvania has shown that the use of copper-based cermet (heat-resistant materials made of ceramic and metal) can reduce coking and the loss of performance. Another disadvantage of SOFC systems is slow start-up time, making SOFCs less useful for mobile applications. Despite these disadvantages, a high operating temperature provides an advantage by removing the need for a precious metal catalyst like platinum, thereby reducing cost. Additionally, waste heat from SOFC systems may be captured and reused, increasing the theoretical overall efficiency to as high as 80–85%.

The high operating temperature is largely due to the physical properties of the YSZ electrolyte. As temperature decreases, so does the ionic conductivity of YSZ. Therefore, to obtain optimum performance of the fuel cell, a high operating temperature is required. According to their website, Ceres Power, a UK SOFC fuel cell manufacturer, has developed a method of reducing the operating temperature of their SOFC system to 500–600 degrees Celsius. They replaced the commonly used YSZ electrolyte with a CGO (cerium gadolinium oxide) electrolyte. The lower operating temperature allows them to use stainless steel instead of ceramic as the cell substrate, which reduces cost and start-up time of the system.

Molten carbonate fuel cells (MCFCs) require a high operating temperature, , similar to SOFCs. MCFCs use lithium potassium carbonate salt as an electrolyte, and this salt liquefies at high temperatures, allowing for the movement of charge within the cell – in this case, negative carbonate ions.

Like SOFCs, MCFCs are capable of converting fossil fuel to a hydrogen-rich gas in the anode, eliminating the need to produce hydrogen externally. The reforming process creates emissions. MCFC-compatible fuels include natural gas, biogas and gas produced from coal. The hydrogen in the gas reacts with carbonate ions from the electrolyte to produce water, carbon dioxide, electrons and small amounts of other chemicals. The electrons travel through an external circuit creating electricity and return to the cathode. There, oxygen from the air and carbon dioxide recycled from the anode react with the electrons to form carbonate ions that replenish the electrolyte, completing the circuit. The chemical reactions for an MCFC system can be expressed as follows:

As with SOFCs, MCFC disadvantages include slow start-up times because of their high operating temperature. This makes MCFC systems not suitable for mobile applications, and this technology will most likely be used for stationary fuel cell purposes. The main challenge of MCFC technology is the cells' short life span. The high-temperature and carbonate electrolyte lead to corrosion of the anode and cathode. These factors accelerate the degradation of MCFC components, decreasing the durability and cell life. Researchers are addressing this problem by exploring corrosion-resistant materials for components as well as fuel cell designs that may increase cell life without decreasing performance.

MCFCs hold several advantages over other fuel cell technologies, including their resistance to impurities. They are not prone to "carbon coking", which refers to carbon build-up on the anode that results in reduced performance by slowing down the internal fuel reforming process. Therefore, carbon-rich fuels like gases made from coal are compatible with the system. The Department of Energy claims that coal, itself, might even be a fuel option in the future, assuming the system can be made resistant to impurities such as sulfur and particulates that result from converting coal into hydrogen. MCFCs also have relatively high efficiencies. They can reach a fuel-to-electricity efficiency of 50%, considerably higher than the 37–42% efficiency of a phosphoric acid fuel cell plant. Efficiencies can be as high as 65% when the fuel cell is paired with a turbine, and 85% if heat is captured and used in a combined heat and power (CHP) system.

FuelCell Energy, a Connecticut-based fuel cell manufacturer, develops and sells MCFC fuel cells. The company says that their MCFC products range from 300 kW to 2.8 MW systems that achieve 47% electrical efficiency and can utilize CHP technology to obtain higher overall efficiencies. One product, the DFC-ERG, is combined with a gas turbine and, according to the company, it achieves an electrical efficiency of 65%.

The electric storage fuel cell is a conventional battery chargeable by electric power input, using the conventional electro-chemical effect. However, the battery further includes hydrogen (and oxygen) inputs for alternatively charging the battery chemically.

Glossary of terms in table:


The energy efficiency of a system or device that converts energy is measured by the ratio of the amount of useful energy put out by the system ("output energy") to the total amount of energy that is put in ("input energy") or by useful output energy as a percentage of the total input energy. In the case of fuel cells, useful output energy is measured in electrical energy produced by the system. Input energy is the energy stored in the fuel. According to the U.S. Department of Energy, fuel cells are generally between 40–60% energy efficient. This is higher than some other systems for energy generation. For example, the typical internal combustion engine of a car is about 25% energy efficient. In combined heat and power (CHP) systems, the heat produced by the fuel cell is captured and put to use, increasing the efficiency of the system to up to 85–90%.

The theoretical maximum efficiency of any type of power generation system is never reached in practice, and it does not consider other steps in power generation, such as production, transportation and storage of fuel and conversion of the electricity into mechanical power. However, this calculation allows the comparison of different types of power generation. The maximum theoretical energy efficiency of a fuel cell is 83%, operating at low power density and using pure hydrogen and oxygen as reactants (assuming no heat recapture) According to the World Energy Council, this compares with a maximum theoretical efficiency of 58% for internal combustion engines.

In a fuel-cell vehicle the tank-to-wheel efficiency is greater than 45% at low loads and shows average values of about 36% when a driving cycle like the NEDC (New European Driving Cycle) is used as test procedure. The comparable NEDC value for a Diesel vehicle is 22%. In 2008 Honda released a demonstration fuel cell electric vehicle (the Honda FCX Clarity) with fuel stack claiming a 60% tank-to-wheel efficiency.

It is also important to take losses due to fuel production, transportation, and storage into account. Fuel cell vehicles running on compressed hydrogen may have a power-plant-to-wheel efficiency of 22% if the hydrogen is stored as high-pressure gas, and 17% if it is stored as liquid hydrogen. Fuel cells cannot store energy like a battery, except as hydrogen, but in some applications, such as stand-alone power plants based on discontinuous sources such as solar or wind power, they are combined with electrolyzers and storage systems to form an energy storage system. As of 2019, 90% of hydrogen is used for oil refining, chemicals and fertilizer production, and 98% of hydrogen is produced by steam methane reforming, which emits carbon dioxide. The overall efficiency (electricity to hydrogen and back to electricity) of such plants (known as "round-trip efficiency"), using pure hydrogen and pure oxygen can be "from 35 up to 50 percent", depending on gas density and other conditions. The electrolyzer/fuel cell system can store indefinite quantities of hydrogen, and is therefore suited for long-term storage.

Solid-oxide fuel cells produce heat from the recombination of the oxygen and hydrogen. The ceramic can run as hot as 800 degrees Celsius. This heat can be captured and used to heat water in a micro combined heat and power (m-CHP) application. When the heat is captured, total efficiency can reach 80–90% at the unit, but does not consider production and distribution losses. CHP units are being developed today for the European home market.

Professor Jeremy P. Meyers, in the Electrochemical Society journal "Interface" in 2008, wrote, "While fuel cells are efficient relative to combustion engines, they are not as efficient as batteries, due primarily to the inefficiency of the oxygen reduction reaction (and ... the oxygen evolution reaction, should the hydrogen be formed by electrolysis of water)... [T]hey make the most sense for operation disconnected from the grid, or when fuel can be provided continuously. For applications that require frequent and relatively rapid start-ups ... where zero emissions are a requirement, as in enclosed spaces such as warehouses, and where hydrogen is considered an acceptable reactant, a [PEM fuel cell] is becoming an increasingly attractive choice [if exchanging batteries is inconvenient]". In 2013 military organizations were evaluating fuel cells to determine if they could significantly reduce the battery weight carried by soldiers.

Stationary fuel cells are used for commercial, industrial and residential primary and backup power generation. Fuel cells are very useful as power sources in remote locations, such as spacecraft, remote weather stations, large parks, communications centers, rural locations including research stations, and in certain military applications. A fuel cell system running on hydrogen can be compact and lightweight, and have no major moving parts. Because fuel cells have no moving parts and do not involve combustion, in ideal conditions they can achieve up to 99.9999% reliability. This equates to less than one minute of downtime in a six-year period.

Since fuel cell electrolyzer systems do not store fuel in themselves, but rather rely on external storage units, they can be successfully applied in large-scale energy storage, rural areas being one example. There are many different types of stationary fuel cells so efficiencies vary, but most are between 40% and 60% energy efficient. However, when the fuel cell's waste heat is used to heat a building in a cogeneration system this efficiency can increase to 85%. This is significantly more efficient than traditional coal power plants, which are only about one third energy efficient. Assuming production at scale, fuel cells could save 20–40% on energy costs when used in cogeneration systems. Fuel cells are also much cleaner than traditional power generation; a fuel cell power plant using natural gas as a hydrogen source would create less than one ounce of pollution (other than ) for every 1,000 kW·h produced, compared to 25 pounds of pollutants generated by conventional combustion systems. Fuel Cells also produce 97% less nitrogen oxide emissions than conventional coal-fired power plants.

One such pilot program is operating on Stuart Island in Washington State. There the Stuart Island Energy Initiative has built a complete, closed-loop system: Solar panels power an electrolyzer, which makes hydrogen. The hydrogen is stored in a tank at , and runs a ReliOn fuel cell to provide full electric back-up to the off-the-grid residence. Another closed system loop was unveiled in late 2011 in Hempstead, NY.

Fuel cells can be used with low-quality gas from landfills or waste-water treatment plants to generate power and lower methane emissions. A 2.8 MW fuel cell plant in California is said to be the largest of the type.

Combined heat and power (CHP) fuel cell systems, including micro combined heat and power (MicroCHP) systems are used to generate both electricity and heat for homes (see home fuel cell), office building and factories. The system generates constant electric power (selling excess power back to the grid when it is not consumed), and at the same time produces hot air and water from the waste heat. As the result CHP systems have the potential to save primary energy as they can make use of waste heat which is generally rejected by thermal energy conversion systems. A typical capacity range of home fuel cell is 1–3 kW, 4–8 kW. CHP systems linked to absorption chillers use their waste heat for refrigeration.

The waste heat from fuel cells can be diverted during the summer directly into the ground providing further cooling while the waste heat during winter can be pumped directly into the building. The University of Minnesota owns the patent rights to this type of system

Co-generation systems can reach 85% efficiency (40–60% electric and the remainder as thermal). Phosphoric-acid fuel cells (PAFC) comprise the largest segment of existing CHP products worldwide and can provide combined efficiencies close to 90%. Molten carbonate (MCFC) and solid-oxide fuel cells (SOFC) are also used for combined heat and power generation and have electrical energy efficiencies around 60%. Disadvantages of co-generation systems include slow ramping up and down rates, high cost and short lifetime. Also their need to have a hot water storage tank to smooth out the thermal heat production was a serious disadvantage in the domestic market place where space in domestic properties is at a great premium.

Delta-ee consultants stated in 2013 that with 64% of global sales the fuel cell micro-combined heat and power passed the conventional systems in sales in 2012. The Japanese ENE FARM project will pass 100,000 FC mCHP systems in 2014, 34.213 PEMFC and 2.224 SOFC were installed in the period 2012–2014, 30,000 units on LNG and 6,000 on LPG.

As of 2017, about 6500 FCEVs have been leased or sold worldwide. Three fuel cell electric vehicles have been introduced for commercial lease and sale: the Honda Clarity, Toyota Mirai and the Hyundai ix35 FCEV. Additional demonstration models include the Honda FCX Clarity, and Mercedes-Benz F-Cell. As of June 2011 demonstration FCEVs had driven more than , with more than 27,000 refuelings. Fuel cell electric vehicles feature an average range of 314 miles between refuelings. They can be refueled in less than 5 minutes. The U.S. Department of Energy's Fuel Cell Technology Program states that, as of 2011, fuel cells achieved 53–59% efficiency at one-quarter power and 42–53% vehicle efficiency at full power, and a durability of over with less than 10% degradation. In a Well-to-Wheels simulation analysis that "did not address the economics and market constraints", General Motors and its partners estimated that per mile traveled, a fuel cell electric vehicle running on compressed gaseous hydrogen produced from natural gas could use about 40% less energy and emit 45% less greenhouse gasses than an internal combustion vehicle. A lead engineer from the Department of Energy whose team is testing fuel cell cars said in 2011 that the potential appeal is that "these are full-function vehicles with no limitations on range or refueling rate so they are a direct replacement for any vehicle. For instance, if you drive a full sized SUV and pull a boat up into the mountains, you can do that with this technology and you can't with current battery-only vehicles, which are more geared toward city driving."

In 2015, Toyota introduced its first fuel cell vehicle, the Mirai, at a price of $57,000. Hyundai introduced the limited production Hyundai ix35 FCEV under a lease agreement. In 2016, Honda started leasing the Honda Clarity Fuel Cell.

Some commentators believe that hydrogen fuel cell cars will never become economically competitive with other technologies or that it will take decades for them to become profitable. Elon Musk, CEO of battery-electric vehicle maker Tesla Motors, stated in 2015 that fuel cells for use in cars will never be commercially viable because of the inefficiency of producing, transporting and storing hydrogen and the flammability of the gas, among other reasons. Jeremy P. Meyers estimated in 2008 that cost reductions over a production ramp-up period will take about 20 years after fuel-cell cars are introduced before they will be able to compete commercially with current market technologies, including gasoline internal combustion engines. In 2011, the chairman and CEO of General Motors, Daniel Akerson, stated that while the cost of hydrogen fuel cell cars is decreasing: "The car is still too expensive and probably won't be practical until the 2020-plus period, I don't know."

In 2012, Lux Research, Inc. issued a report that stated: "The dream of a hydrogen economy ... is no nearer". It concluded that "Capital cost ... will limit adoption to a mere 5.9 GW" by 2030, providing "a nearly insurmountable barrier to adoption, except in niche applications". The analysis concluded that, by 2030, PEM stationary market will reach $1 billion, while the vehicle market, including forklifts, will reach a total of $2 billion. Other analyses cite the lack of an extensive hydrogen infrastructure in the U.S. as an ongoing challenge to Fuel Cell Electric Vehicle commercialization. In 2006, a study for the IEEE showed that for hydrogen produced via electrolysis of water: "Only about 25% of the power generated from wind, water, or sun is converted to practical use." The study further noted that "Electricity obtained from hydrogen fuel cells appears to be four times as expensive as electricity drawn from the electrical transmission grid. ... Because of the high energy losses [hydrogen] cannot compete with electricity." Furthermore, the study found: "Natural gas reforming is not a sustainable solution". "The large amount of energy required to isolate hydrogen from natural compounds (water, natural gas, biomass), package the light gas by compression or liquefaction, transfer the energy carrier to the user, plus the energy lost when it is converted to useful electricity with fuel cells, leaves around 25% for practical use."

In 2014, Joseph Romm, the author of "The Hype About Hydrogen" (2005), said that FCVs still had not overcome the high fueling cost, lack of fuel-delivery infrastructure, and pollution caused by producing hydrogen. "It would take several miracles to overcome all of those problems simultaneously in the coming decades." He concluded that renewable energy cannot economically be used to make hydrogen for an FCV fleet "either now or in the future." Greentech Media's analyst reached similar conclusions in 2014. In 2015, "Clean Technica" listed some of the disadvantages of hydrogen fuel cell vehicles. So did "Car Throttle". A 2019 video by "Real Engineering" noted that, notwithstanding the introduction of vehicles that run on hydrogen, using hydrogen as a fuel for cars does not help to reduce carbon emissions from transportation. The 95% of hydrogen still produced from fossil fuels releases carbon dioxide, and producing hydrogen from water is an energy-consuming process. Storing hydrogen requires more energy either to cool it down to the liquid state or to put it into tanks under high pressure, and delivering the hydrogen to fueling stations requires more energy and may release more carbon. The hydrogen needed to move a FCV a kilometer costs approximately 8 times as much as the electricity needed to move a BEV the same distance.

, there were about 100 fuel cell buses running around the world, including in Whistler, Canada; San Francisco, United States; Hamburg, Germany; Shanghai, China; London, England; and São Paulo, Brazil. Most of these were manufactured by UTC Power, Toyota, Ballard, Hydrogenics, and Proton Motor. UTC buses had driven more than by 2011. Fuel cell buses have from 39% to 141% higher fuel economy than diesel buses and natural gas buses.

As of 2019, the NREL is evaluating several current and planned fuel cell bus projects in the U.S.

A fuel cell forklift (also called a fuel cell lift truck) is a fuel cell-powered industrial forklift truck used to lift and transport materials. In 2013 there were over 4,000 fuel cell forklifts used in material handling in the US, of which 500 received funding from DOE (2012). Fuel cell fleets are operated by various companies, including Sysco Foods, FedEx Freight, GENCO (at Wegmans, Coca-Cola, Kimberly Clark, and Whole Foods), and H-E-B Grocers. Europe demonstrated 30 fuel cell forklifts with Hylift and extended it with HyLIFT-EUROPE to 200 units, with other projects in France and Austria. Pike Research projected in 2011 that fuel cell-powered forklifts would be the largest driver of hydrogen fuel demand by 2020.

Most companies in Europe and the US do not use petroleum-powered forklifts, as these vehicles work indoors where emissions must be controlled and instead use electric forklifts. Fuel cell-powered forklifts can provide benefits over battery-powered forklifts as they can be refueled in 3 minutes and they can be used in refrigerated warehouses, where their performance is not degraded by lower temperatures. The FC units are often designed as drop-in replacements.

In 2005 a British manufacturer of hydrogen-powered fuel cells, Intelligent Energy (IE), produced the first working hydrogen-run motorcycle called the ENV (Emission Neutral Vehicle). The motorcycle holds enough fuel to run for four hours, and to travel in an urban area, at a top speed of . In 2004 Honda developed a fuel-cell motorcycle that utilized the Honda FC Stack.

Other examples of motorbikes and bicycles that use hydrogen fuel cells include the Taiwanese company APFCT's scooter using the fueling system from Italy's Acta SpA and the Suzuki Burgman scooter with an IE fuel cell that received EU Whole Vehicle Type Approval in 2011. Suzuki Motor Corp. and IE have announced a joint venture to accelerate the commercialization of zero-emission vehicles.

In 2003, the world's first propeller-driven airplane to be powered entirely by a fuel cell was flown. The fuel cell was a stack design that allowed the fuel cell to be integrated with the plane's aerodynamic surfaces. Fuel cell-powered unmanned aerial vehicles (UAV) include a Horizon fuel cell UAV that set the record distance flown for a small UAV in 2007. Boeing researchers and industry partners throughout Europe conducted experimental flight tests in February 2008 of a manned airplane powered only by a fuel cell and lightweight batteries. The fuel cell demonstrator airplane, as it was called, used a proton exchange membrane (PEM) fuel cell/lithium-ion battery hybrid system to power an electric motor, which was coupled to a conventional propeller.

In 2009 the Naval Research Laboratory's (NRL's) Ion Tiger utilized a hydrogen-powered fuel cell and flew for 23 hours and 17 minutes. Fuel cells are also being tested and considered to provide auxiliary power in aircraft, replacing fossil fuel generators that were previously used to start the engines and power on board electrical needs, while reducing carbon emissions. In 2016 a Raptor E1 drone made a successful test flight using a fuel cell that was lighter than the lithium-ion battery it replaced. The flight lasted 10 minutes at an altitude of , although the fuel cell reportedly had enough fuel to fly for two hours. The fuel was contained in approximately 100 solid pellets composed of a proprietary chemical within an unpressurized cartridge. The pellets are physically robust and operate at temperatures as warm as . The cell was from Arcola Energy.

Lockheed Martin Skunk Works Stalker is an electric UAV powered by solid oxide fuel cell.

The world's first fuel-cell boat HYDRA used an AFC system with 6.5 kW net output. Iceland has committed to converting its vast fishing fleet to use fuel cells to provide auxiliary power by 2015 and, eventually, to provide primary power in its boats. Amsterdam recently introduced its first fuel cell-powered boat that ferries people around the city's canals.

The Type 212 submarines of the German and Italian navies use fuel cells to remain submerged for weeks without the need to surface.

The U212A is a non-nuclear submarine developed by German naval shipyard Howaldtswerke Deutsche Werft. The system consists of nine PEM fuel cells, providing between 30 kW and 50 kW each. The ship is silent, giving it an advantage in the detection of other submarines. A naval paper has theorized about the possibility of a nuclear-fuel cell hybrid whereby the fuel cell is used when silent operations are required and then replenished from the Nuclear reactor (and water).

Portable fuel cell systems are generally classified as weighing under 10 kg and providing power of less than 5 kW. The potential market size for smaller fuel cells is quite large with an up to 40% per annum potential growth rate and a market size of around $10 billion, leading a great deal of research to be devoted to the development of portable power cells. Within this market two groups have been identified. The first is the microfuel cell market, in the 1-50 W range for power smaller electronic devices. The second is the 1-5 kW range of generators for larger scale power generation (e.g. military outposts, remote oil fields).

Microfuel cells are primarily aimed at penetrating the market for phones and laptops. This can be primarily attributed to the advantageous energy density provided by fuel cells over a lithium-ion battery, for the entire system. For a battery, this system includes the charger as well as the battery itself. For the fuel cell this system would include the cell, the necessary fuel and peripheral attachments. Taking the full system into consideration, fuel cells have been shown to provide 530Wh/kg compared to 44 Wh/kg for lithium ion batteries. However, while the weight of fuel cell systems offer a distinct advantage the current costs are not in their favor. while a battery system will generally cost around $1.20 per Wh, fuel cell systems cost around $5 per Wh, putting them at a significant disadvantage.

As power demands for cell phones increase, fuel cells could become much more attractive options for larger power generation. The demand for longer on time on phones and computers is something often demanded by consumers so fuel cells could start to make strides into laptop and cell phone markets. The price will continue to go down as developments in fuel cells continues to accelerate. Current strategies for improving micro fuelcells is through the use of carbon nanotubes. It was shown by Girishkumar et al. that depositing nanotubes on electrode surfaces allows for substantially greater surface area increasing the oxygen reduction rate.

Fuel cells for use in larger scale operations also show much promise. Portable power systems that use fuel cells can be used in the leisure sector (i.e. RVs, cabins, marine), the industrial sector (i.e. power for remote locations including gas/oil wellsites, communication towers, security, weather stations), and in the military sector. SFC Energy is a German manufacturer of direct methanol fuel cells for a variety of portable power systems. Ensol Systems Inc. is an integrator of portable power systems, using the SFC Energy DMFC. The key advantage of fuel cells in this market is the great power generation per weight. While fuel cells can be expensive, for remote locations that require dependable energy fuel cells hold great power. For a 72-h excursion the comparison in weight is substantial, with a fuel cell only weighing 15 pounds compared to 29 pounds of batteries needed for the same energy.


In 2013, "The New York Times" reported that there were "10 hydrogen stations available to the public in the entire United States: one in Columbia, S.C., eight in Southern California and the one in Emeryville". , there were 31 publicly accessible hydrogen refueling stations in the US, 28 of which were located in California.

A public hydrogen refueling station in Iceland operated from 2003 to 2007. It served three buses in the public transport net of Reykjavík. The station produced its own hydrogen with an electrolyzing unit. The 14 stations in Germany were planned to be expanded to 50 by 2015 through its public–private partnership Now GMBH.

By May 2017, there were 91 hydrogen fueling stations in Japan. As of 2016, Norway planned to build a network of hydrogen stations between the major cities, starting in 2017.

In 2012, fuel cell industry revenues exceeded $1 billion market value worldwide, with Asian pacific countries shipping more than 3/4 of the fuel cell systems worldwide. However, as of January 2014, no public company in the industry had yet become profitable. There were 140,000 fuel cell stacks shipped globally in 2010, up from 11,000 shipments in 2007, and from 2011 to 2012 worldwide fuel cell shipments had an annual growth rate of 85%. Tanaka Kikinzoku expanded its manufacturing facilities in 2011. Approximately 50% of fuel cell shipments in 2010 were stationary fuel cells, up from about a third in 2009, and the four dominant producers in the Fuel Cell Industry were the United States, Germany, Japan and South Korea. The Department of Energy Solid State Energy Conversion Alliance found that, as of January 2011, stationary fuel cells generated power at approximately $724 to $775 per kilowatt installed. In 2011, Bloom Energy, a major fuel cell supplier, said that its fuel cells generated power at 9–11 cents per kilowatt-hour, including the price of fuel, maintenance, and hardware.

Industry groups predict that there are sufficient platinum resources for future demand, and in 2007, research at Brookhaven National Laboratory suggested that platinum could be replaced by a gold-palladium coating, which may be less susceptible to poisoning and thereby improve fuel cell lifetime. Another method would use iron and sulphur instead of platinum. This would lower the cost of a fuel cell (as the platinum in a regular fuel cell costs around , and the same amount of iron costs only around ). The concept was being developed by a coalition of the John Innes Centre and the University of Milan-Bicocca. PEDOT cathodes are immune to monoxide poisoning.

In 2016, Samsung "decided to drop fuel cell-related business projects, as the outlook of the market isn't good".





</doc>
<doc id="11732" url="https://en.wikipedia.org/wiki?curid=11732" title="Finlandization">
Finlandization

Finlandization (; ; ) is the process by which one powerful country makes a smaller neighboring country abide by the former's foreign policy rules, while allowing it to keep its nominal independence and its own political system. The term means "to become like Finland" referring to the influence of the Soviet Union on Finland's policies during the Cold War.

The term is often considered pejorative. It originated in the West German political debate of the late 1960s and 1970s. As the term was used in Germany and other NATO countries, it referred to the decision of a country not to challenge a more powerful neighbour in foreign politics, while maintaining national sovereignty. It is commonly used in reference to Finland's policies in relation to the Soviet Union during the Cold War, but it can refer more generally to similar international relations, such as Denmark's attitude toward Germany between 1871 and 1945, or the policies of the Swiss government towards Nazi Germany until the end of World War II.

In Germany, the term was used mainly by proponents of closer adaptation to US policies, chiefly Franz Josef Strauss, but was initially coined in scholarly debate, and made known by the German political scientists Walter Hallstein and Richard Löwenthal, reflecting feared effects of withdrawal of US troops from Germany. It came to be used in the debate of the NATO countries in response to Willy Brandt's attempts to normalise relations with East Germany, and the following widespread scepticism in Germany against NATO's Dual-Track Decision. Later, after the fall of the Soviet Union, the term has been used in Finland for the post-1968 radicalisation in the latter half of the Urho Kekkonen era.

In Finland, the term "Finlandization" was perceived as blunt criticism, stemming from an inability to understand the practicalities of how a small nation needs to deal with an adjacent superpower without losing its sovereignty. These practicalities existed especially because of the lingering effect of Russian rule in their time, before the Finns first gained sovereignty, and because of the precarious power balance eastwards, springing from a geographically extended yet sparsely populated state with a traditionally imperialist superpower right across the eastern border.

The reason Finland engaged in Finlandization was primarily Realpolitik: to survive. On the other hand, the threat of the Soviet Union was used also in Finland's domestic politics in a way that possibly deepened Finlandization (playing the so-called "idänkortti", "east card"). Finland cut such a deal with Joseph Stalin's government in the late 1940s, and it was largely respected by both parties—and to the gain of both parties—until the fall of the Soviet Union in 1991. While the Finnish political and intellectual elite mostly understood the term to refer more to the foreign policy problems of other countries, and meant mostly for domestic consumption in the speaker's own country, many ordinary Finns considered the term highly offensive. The Finnish political cartoonist Kari Suomalainen once explained Finlandization as "the art of bowing to the East without mooning the West".

Finland's foreign politics before this deal had been varied: independence from Imperial Russia with support of Imperial Germany in 1917; participation in the Russian Civil War (without official declaration of war) alongside the Triple Entente 1918–1920; a non-ratified alliance with Poland in 1922; association with the neutralist and democratic Scandinavian countries in the 1930s ended by the Winter War (1939); and finally in 1940, a rapprochement with Nazi Germany, the only power able and willing to help Finland against the expansionist Soviet Union, which led to the nation's re-entry into the Second World War in 1941.

The Wehrmacht's defeat in the Battle of Stalingrad led Finland to basically revert to its 19th-century traditions, which had been perceived as highly successful until the Russification of Finland (1899–1905). Finland's leaders realised that opposing the Soviets head-on was no longer feasible. No international power was able to give the necessary support. Nazi Germany, Finland's chief supporter against Russia, was losing the war. Sweden was not big enough, and its leadership was wary of confronting Russia. The western powers were allied with the Soviet Union. Thus Finland had to face its bigger neighbour on its own, without any great power's protection. As in the 19th century, Finland chose not to challenge Soviet Russia's foreign policy, but exerted caution to keep its independence.

After the Paris Peace Treaty of 1947, Finland succeeded in retaining democracy and parliamentarism, despite the heavy political pressure on Finland's foreign and internal affairs by the Soviet Union. Finland's foreign relations were guided by the doctrine formulated by Juho Kusti Paasikivi, emphasising the necessity to maintain a good and trusting relationship with the Soviet Union.

Finland signed an Agreement of Friendship, Cooperation, and Mutual Assistance with the Soviet Union in April 1948, under which Finland was obliged to resist armed attacks by "Germany or its allies" against Finland, or against the Soviet Union through Finland, and, if necessary, ask for Soviet military aid to do so. At the same time, the agreement recognised Finland's desire to remain outside great power conflicts, allowing the country to adopt a policy of neutrality during the Cold War.

As a consequence, Finland did not participate in the Marshall Plan and took neutral positions on Soviet overseas initiatives. By keeping very cool relations to NATO and western military powers in general, Finland could fend off Soviet pressure for affiliation to the Warsaw Pact.

However, from the political scene following the post-1968 radicalisation, the Soviet adaptation spread to the editors of mass media, sparking strong forms of self-control, self-censorship and pro-Soviet attitudes. Most of the élite of media and politics shifted their attitudes to match the values that the Soviets were thought to favor and approve.

Only after the ascent of Mikhail Gorbachev to Soviet leadership in 1985 did mass media in Finland gradually begin to criticise the Soviet Union more. When the Soviet Union allowed non-communist governments to take power in Eastern Europe, Gorbachev suggested they could look to Finland as an example to follow.

In the years immediately after the war (1944–1946), the Soviet part of the allied control commission demanded that public libraries should remove from circulation more than 1,700 books that were deemed anti-Soviet, and bookstores were given catalogs of banned books. The Finnish Board of Film Classification likewise banned movies that it considered to be anti-Soviet. Banned movies included "One, Two, Three" (1961 film), directed by Billy Wilder, "The Manchurian Candidate", directed by John Frankenheimer in 1962, "One Day in the Life of Ivan Denisovich" 1970 by Finnish director Caspar Wrede and "Born American" by Finnish director Renny Harlin in 1986.

The censorship never took the form of purging. Possession or use of anti-Soviet books was not banned; it was the reprinting and distribution of such materials that was prohibited. Especially in the realm of radio and television self-censorship, it was sometimes hard to tell whether the motivations were even political: for example, once a system of blacklisting recordings had been introduced, individual policymakers within the Yleisradio also utilized it to censor songs they deemed inappropriate for other reasons, such as some of those featuring sexual innuendos or references to alcohol.

United States foreign policy experts consistently feared that Western Europe and Japan would be Finlandized, leading to a situation in which these key allies no longer supported the United States against the Soviet Union. The theory of bandwagoning provided support for the idea that if the United States was not able to provide strong and credible support for the anti-communist positions of its allies, NATO and the U.S.–Japan alliance could collapse.

However, foreign policy scholars such as Eric Nordlinger in his book "Isolationism Reconfigured" have argued that "a vision of Finlandization in America's absence runs up squarely against the European states' long-standing Communist antipathies and wariness of Moscow's peaceful wiles, valued national traditions and strong democratic institutions, as well as their size and wherewithal".




</doc>
<doc id="11734" url="https://en.wikipedia.org/wiki?curid=11734" title="Fred Singer">
Fred Singer

Siegfried Fred Singer (born September 27, 1924) is an Austrian-born American physicist and emeritus professor of environmental science at the University of Virginia. Singer trained as an atmospheric physicist and is known for his work in space research, atmospheric pollution, rocket and satellite technology, his questioning of the link between UV-B and melanoma rates, and that between chlorofluoro compounds and stratospheric ozone loss, his public downplaying of the health risks of passive smoking, and as an advocate for climate change denial. He is the author or editor of several books including "Global Effects of Environmental Pollution" (1970), "The Ocean in Human Affairs" (1989), "Global Climate Change" (1989), "The Greenhouse Debate Continued" (1992), and "Hot Talk, Cold Science" (1997). He has also co-authored "" (2007) with Dennis Avery, and "Climate Change Reconsidered" (2009) with Craig Idso.

Singer has had a varied career, serving in the armed forces, government, and academia. He designed mines for the U.S. Navy during World War II, before obtaining his Ph.D. in physics from Princeton University in 1948 and working as a scientific liaison officer in the U.S. Embassy in London. He became a leading figure in early space research, was involved in the development of earth observation satellites, and in 1962 established the National Weather Bureau's Satellite Service Center. He was the founding dean of the University of Miami School of Environmental and Planetary Sciences in 1964, and held several government positions, including deputy assistant administrator for the Environmental Protection Agency, and chief scientist for the Department of Transportation. He held a professorship with the University of Virginia from 1971 until 1994, and with George Mason University until 2000.

In 1990 Singer founded the Science & Environmental Policy Project, and in 2006 was named by the Canadian Broadcasting Corporation as one of a minority of scientists said to be creating a stand-off on a consensus on climate change. Singer argues, contrary to the scientific consensus on climate change, that there is no evidence that global warming is attributable to human-caused increases in atmospheric carbon dioxide, and that humanity would benefit if temperatures do rise. He is an opponent of the Kyoto Protocol, and has claimed that climate models are neither based on reality nor evidence. Singer has been accused of rejecting peer-reviewed and independently confirmed scientific evidence in his claims concerning public health and environmental issues.

Singer was born in Vienna, Austria, to a Jewish family, where his father was a jeweler and his mother a homemaker. When the Nazis invaded, the family fled, Singer leaving on a children's transport train with other Jewish children. He ended up in England, where he lived in Northumberland, working for a time as a teenage optician. Several years later he emigrated to Ohio and became an American citizen in 1944. He received a B.E.E. in electrical engineering from Ohio State University in 1943, and an A.M. in physics from Princeton in 1944. He taught physics at Princeton while he worked on his masters and his doctorate, obtaining his Ph.D. there in 1948. His doctoral thesis was titled, ""The density spectrum and latitude dependence of extensive cosmic ray air showers"." His supervisor was John Archibald Wheeler, and his thesis committee included J. Robert Oppenheimer and Niels Bohr.

After his masters, Singer joined the Armed Forces, working for the United States Navy on mine warfare and countermeasures from 1944 until 1946. While with the Naval Ordnance Laboratory he developed an arithmetic element for an electronic digital calculator that he called an "electronic brain". He was discharged in 1946 and joined the Upper Atmosphere Rocket Program at the Johns Hopkins University Applied Physics Laboratory in Silver Spring, Maryland, working there until 1950. He focused on ozone, cosmic rays, and the ionosphere, all measured using balloons and rockets launched from White Sands, New Mexico, or from ships out at sea. Rachel White Scheuering writes that for one mission to launch a rocket, he sailed with a naval operation to the Arctic, and also conducted rocket launching from ships at the equator.

From 1950 to 1953, he was attached to the U.S. Embassy in London as a scientific liaison officer with the Office of Naval Research, where he studied research programs in Europe into cosmic radiation and nuclear physics. While there, he was one of eight delegates with a background in guided weapons projects to address the Fourth International Congress of Astronautics in Zurich in August 1953, at a time when, as "The New York Times" reported, most scientists saw space flight as thinly disguised science fiction.

Singer was one of the first scientists to urge the launching of earth satellites for scientific observation during the 1950s. In 1951 or 1952 he proposed the MOUSE ("Minimal Orbital Unmanned Satellite, Earth"), a satellite that would contain Geiger counters for measuring cosmic rays, photo cells for scanning the Earth, telemetry electronics for sending data back to Earth, a magnetic data storage device, and rudimentary solar energy cells. Although MOUSE never flew, the "Baltimore News Post" reported in 1957 that had Singer's arguments about the need for satellites been heeded, the U.S. could have beaten Russia by launching the first earth satellite. He also proposed (along with R. C. Wentworth) that satellite measurement of ultraviolet backscatter could be used as a method to measure atmospheric ozone profiles. This technique was later used on early weather satellites.

Singer moved back to the United States in 1953, where he took up an associate professorship in physics at the University of Maryland, and at the same time served as the director of the Center for Atmospheric and Space Physics. Scheuering writes that his work involved conducting experiments on rockets and satellites, remote sensing, radiation belts, the magnetosphere, and meteorites. He developed a new method of launching rockets into space: firing them from a high-flying plane, both with and without a pilot. The Navy adopted the idea and Singer supervised the project. He received a White House Special Commendation from President Eisenhower in 1954 for his work.

He became one of 12 board members of the American Astronautical Society, an organization formed in 1954 to represent the country's 300 leading scientists and engineers in the area of guided missiles—he was one of seven members of the board to resign in December 1956 after a series of disputes about the direction and control of the group.

In November 1957 Singer and other scientists at the university successfully designed and fired three new "Oriole" rockets off the Virginia Capes. The rockets weighed less than and could be built for around $2000. Fired from a converted Navy LSM, they could reach an altitude of and had a complete telemetry system to send back information on cosmic, ultraviolet and X-rays. Singer said that the firings placed "the exploration of outer space with high altitude rockets on the same basis, cost-wise and effort-wise, as low atmosphere measurements with weather balloons. From now on, we can fire thousands of these rockets all over the world with very little cost."

In February 1958, when he was head of the cosmic ray group of the University of Maryland's physics department, he was congratulated in a telegram to the president of the university from President Eisenhower for his work in satellite research. In April 1958, he was appointed as a consultant to the House Committee on Astronautics and Space Exploration, which was preparing to hold hearings on President Eisenhower's proposal for a new agency to handle space research, and a month later received the Ohio State University's Distinguished Alumnus Award. He became a full professor at Maryland in 1959, and was chosen that year by the United States Junior Chamber of Commerce as one of the country's ten outstanding young men.

In a January 1960 presentation to the American Physical Society, Singer sketched out his vision of what the environment around the earth might consist of, extending up to into space. He became known for his early predictions about the properties of the electrical particles trapped around the earth, which were partly verified by later discoveries in satellite experiments. In December 1960, he suggested the existence of a shell of visible dust particles around the earth some 600 to in space, beyond which there was a layer of smaller particles, a micrometre or less in diameter, extending 2,000 to . In March 1961 Singer and another University of Maryland physicist, E. J. Opik, were given a $97,000 grant by NASA to conduct a three-year study of interplanetary gas and dust.

In a 1960 "Astronautics" newsletter, Singer commented on Iosif Shklovsky's hypothesis that the orbit of the Martian moon Phobos suggests that it is hollow, which implies it is of artificial origin. Singer wrote: "My conclusion there is, and here I back Shklovsky, that if the satellite is indeed spiraling inward as deduced from astronomical observation, then there is little alternative to the hypothesis that it is hollow and therefore martian made. The big 'if' lies in the astronomical observations; they may well be in error. Since they are based on several independent sets of measurements taken decades apart by different observers with different instruments, systematic errors may have influenced them." Later measurements confirmed Singer's "big "if"" caveat: Shklovsky overestimated Phobos' rate of altitude loss due to bad early data. Photographs by probes beginning in 1972 show a natural stony surface with craters. Ufologists continue to present Singer as an unconditional supporter of Shklovsky's artificial Phobos hypothesis.

"Time" magazine wrote in 1969 that Singer had had a lifelong fascination with Phobos and Mars's second moon, Deimos. He told "Time" it might be possible to pull Deimos into the Earth's orbit so it could be examined. During an international space symposium in May 1966, attended by space scientists from the United States and Soviet Union, he first proposed that manned landings on the Martian moons would be a logical step after a manned landing on the Earth's moon. He pointed out that the very small sizes of Phobos and Deimos—approximately and in diameter and sub milli-g surface gravity—would make it easier for a spacecraft to land and take off again.

In 1962, on leave from the university, Singer was named as the first director of meteorological satellite services for the National Weather Satellite Center, now part of the National Oceanic and Atmospheric Administration, and directed a program for using satellites to forecast the weather. He stayed there until 1964. He told "Time" magazine in 1969 that he enjoyed moving around. "Each move gave me a completely new perspective," he said. "If I had sat still, I'd probably still be measuring cosmic rays, the subject of my thesis at Princeton. That's what happens to most scientists." When he stepped down as director he received a Department of Commerce Gold Medal Award for Distinguished Federal Service.

In 1964, he became the first dean of the School of Environmental and Planetary Sciences at the University of Miami in 1964, the first school of its kind in the country, dedicated to space-age research. In December 1965, "The New York Times" reported on a conference Singer hosted in Miami Beach during which five groups of scientists, working independently, presented research identifying what they believed was the remains of a primordial flash that occurred when the universe was born.

In 1967 he accepted the position of deputy assistant secretary with the U.S. Department of the Interior, where he was in charge of water quality and research. When the U.S. Environmental Protection Agency was created on 1970, he became its deputy assistant administrator of policy.

Singer accepted a professorship in Environmental Sciences at the University of Virginia in 1971, a position he held until 1994, where he taught classes on environmental issues such as ozone depletion, acid rain, climate change, population growth, and public policy issues related to oil and energy. In 1987 he took up a two-year post as chief scientist at the Department of Transportation, and in 1989 joined the Institute of Space Science and Technology in Gainesville, Florida where he contributed to a paper on the results from the Interplanetary Dust Experiment using data from the Long Duration Exposure Facility satellite. When he retired from Virginia in 1994, he became Distinguished Research Professor at the Institute for Humane Studies at George Mason University until 2000.

Naomi Oreskes and Erik Conway say that Singer was involved in the Reagan administration's efforts to prevent regulatory action to reduce acid rain.

Singer has worked as a consultant for several government agencies, including the House Select Committee on Space, NASA, the Government Accountability Office, the National Science Foundation, the United States Atomic Energy Commission, National Research Council, the Department of Defense Strategic Defense Initiative, Department of Energy Nuclear Waste Panel, and the Department of the Treasury. Other clients have included the states of Virginia, Alaska, and Pennsylvania. In the private sector he has worked for Mitre Corporation, General Electric, Ford, General Motors; during the late 1970s Singer consulted with Exxon, Shell, Unocal Sun Oil, and ARCO; and Lockheed Martin, Martin–Marietta, McDonnell Douglas, ANSER, and IBM on space research. He has also advised the Independent Institute, the American Council on Science and Health, and the Frontiers of Freedom Institute.

Throughout his academic career Singer has written frequently in the mainstream press, including "The New York Times", "The Washington Post", and "Wall Street Journal", often striking up positions disputing mainstream thinking. His overall position is one of distrust of federal regulations and a strong belief in the efficacy of the free market. He believes in what Rachel White Scheuering calls "free market environmentalism": that market principles and incentives should be sufficient to lead to the protection of the environment and conservation of resources. Regular themes in his articles have been energy, oil embargoes, OPEC, Iran, and rising prices. Throughout the 1970s, for example, he downplayed the idea of an energy crisis and said it was largely a media event. In several papers in the 1990s and 2000s he struck up other positions against the mainstream, questioning the link between UV-B and melanoma rates, and that between CFCs and stratospheric ozone loss.

In October 1967, Singer wrote an article for "The Washington Post" from the perspective of 2007. His predictions included that planets had been explored but not colonized, and although rockets had become more powerful they had not replaced aircraft and ramjet vehicles. None of the fundamental laws of physics had been overturned. There was increased reliance on the electronic computer and data processor; the most exciting development was the increase in human intellect by direct electronic storage of information in the brain—the coupling of the brain to an external computer, thereby gaining direct access to an information library.

He debated the astronomer Carl Sagan on ABC's "Nightline", regarding the possible environmental effects of the Kuwaiti oil fires. Sagan argued that if enough fire-fighting teams were not assembled in short order, and if many fires were left to burn over a period of months to possibly a year, the smoke might loft into the upper atmosphere and lead to massive agricultural failures over South Asia. Singer argued that it would rise to then be rained out after a few days. In fact, both Sagan and Singer were incorrect; smoke plumes from the fires rose to 10,000–12,000 feet and lingered for nearly a month, but despite absorbing 75–80% of the sun's radiation in the Persian Gulf area the plumes had little global effect.

The public debates in which Singer has received most criticism have been about second-hand smoke and global warming. He has questioned the link between second-hand smoke and lung cancer, and has been an outspoken opponent of the mainstream scientific view on climate change; he argues there is no evidence that increases in carbon dioxide produced by human beings is causing global warming and that the temperature of the earth has always varied. A CBC "Fifth Estate" documentary in 2006 linked these two debates, naming Singer as a scientist who has acted as a consultant to industry in both areas, either directly or through a public relations firm. Naomi Oreskes and Erik Conway named Singer in their book, "Merchants of Doubt", as one of three contrarian physicists—along with Fred Seitz and Bill Nierenberg—who regularly injected themselves into the public debate about contentious scientific issues, positioning themselves as skeptics, their views gaining traction because the media gives them equal time out of a sense of fairness.

According to David Biello and John Pavlus in "Scientific American", Singer is best known for his denial of the health risks of passive smoking. He was involved in 1994 as writer and reviewer of a report on the issue by the Alexis de Tocqueville Institution, where he was a senior fellow. The report criticized the Environmental Protection Agency (EPA) for their 1993 study about the cancer risks of passive smoking, calling it "junk science". Singer told CBC's "The Fifth Estate" in 2006 that he stood by the position that the EPA had "cooked the data" to show that second-hand smoke causes lung cancer. CBC said that tobacco money had paid for Singer's research and for his promotion of it, and that it was organized by APCO. Singer told CBC it made no difference where the money came from. "They don't carry a note on a dollar bill saying 'This comes from the tobacco industry,'" he said. "In any case I was not aware of it, and I didn't ask APCO where they get their money. That's not my business." In December 2010 he wrote in "American Thinker" that he is nonsmoker who finds second-hand smoke an unpleasant irritant that cannot be healthy; he also wrote that his father, a heavy smoker, died of emphysema when relatively young. According to Singer, he serves on the advisory board of an anti-smoking organization, and has never been paid by Philip Morris or the tobacco lobby.

In a 2003 letter to the "Financial Times", Singer wrote that "there is no convincing evidence that the global climate is actually warming." In 2006, the CBC's "Fifth Estate" named Singer as one of a small group of scientists who have created what the documentary called a stand-off that is undermining the political response to global warming. The following year he appeared on the British Channel 4 documentary "The Great Global Warming Swindle". Singer argues there is no evidence that the increases in carbon dioxide produced by humans cause global warming, and that if temperatures do rise it will be good for humankind. He told CBC: "It was warmer a thousand years ago than it is today. Vikings settled Greenland. Is that good or bad? I think it's good. They grew wine in England, in northern England. I think that's good. At least some people think so." "We are certainly putting more carbon dioxide in the atmosphere," he told "The Daily Telegraph" in 2009. "However there is no evidence that this high CO is making a detectable difference. It should in principle, however the atmosphere is very complicated and one cannot simply argue that just because CO is a greenhouse gas it causes warming." He believes that radical environmentalists are exaggerating the dangers. "The underlying effort here seems to be to use global warming as an excuse to cut down the use of energy," he said. "It's very simple: if you cut back the use of energy, then you cut back economic growth. And believe it or not, there are people in the world who believe we have gone too far in economic growth."

Singers's opinions conflict with the scientific opinion on climate change, where there is overwhelming consensus for anthropogenic global warming, and a decisive link between carbon dioxide concentration and global average temperatures, as well as consensus that such a change to the climate will have dangerous consequences. In 2005 Mother Jones magazine described Singer as a "godfather of global warming denial." However, Singer characterizes himself as a "skeptic" rather than a "denier" of global climate change. In an article in "American Thinker", he complains about bad arguments used by the "deniers," saying that "Climate deniers are giving us skeptics a bad name."

In 1990 Singer set up the Science & Environmental Policy Project (SEPP) to argue against preventive measures against global warming. After the 1991 United Nations Conference on Environment and Development, the Earth Summit, Singer started writing and speaking out to cast doubt on the science. He predicted disastrous economic damage from any restrictions on fossil fuel use, and argued that the natural world and its weather patterns are complex and ill-understood, and that little is known about the dynamics of heat exchange from the oceans to the atmosphere, or the role of clouds. As the scientific consensus grew, he continued to argue from a skeptical position. He has repeatedly criticized the climate models that predict global warming. In 1994 he compared model results to observed temperatures and found that the predicted temperatures for 1950–1980 deviated from the temperatures that had actually occurred, from which he concluded in his regular column in "The Washington Times"—with the headline that day "Climate Claims Wither under the Luminous Lights of Science"—that climate models are faulty. In 2007 he collaborated on a study that found tropospheric temperature trends of "Climate of the 20th Century" models differed from satellite observations by twice the model mean uncertainty.

Rachel White Scheuering writes that, when SEPP began, it was affiliated with the Washington Institute for Values in Public Policy, a think tank founded by Unification Church leader Sun Myung Moon. A 1990 article for the Cato Institute identifies Singer as the director of the science and environmental policy project at the Washington Institute for Values in Public Policy, on leave from the University of Virginia. Scheuering writes that Singer had cut ties with the institute, and is funded by foundations and oil companies. She writes that he has been a paid consultant for many years for ARCO, ExxonMobil, Shell, Sun Oil Company, and Unocal, and that SEPP has received grants from ExxonMobil. Singer has said his financial relationships do not influence his research. Scheuering argues that his conclusions concur with the economic interests of the companies that pay him, in that the companies want to see a reduction in environmental regulation.

In August 2007 "Newsweek" reported that in April 1998 a dozen people from what it called "the denial machine" met at the American Petroleum Institute's Washington headquarters. The meeting included Singer's group, the George C. Marshall Institute, and ExxonMobil. Newsweek said that, according to an eight-page memo that was leaked, the meeting proposed a $5-million campaign to convince the public that the science of global warming was controversial and uncertain. The plan was leaked to the press and never implemented. The week after the story, "Newsweek" published a contrary view from Robert Samuelson, one of its columnists, who said the story of an industry-funded denial machine was contrived and fundamentally misleading. ABC News reported in March 2008 that Singer said he is not on the payroll of the energy industry, but he acknowledged that SEPP had received one unsolicited charitable donation of $10,000 from ExxonMobil, and that it was one percent of all donations received. Singer said that his connection to Exxon was more like being on their mailing list than holding a paid position. The relationships have discredited Singer's research among members of the scientific community, according to Scheuering. Congresswoman Lynn Rivers questioned Singer's credibility during a congressional hearing in 1995, saying he had not been able to publish anything in a peer-reviewed scientific journal for the previous 15 years, except for one technical comment.

In 1995 the Intergovernmental Panel on Climate Change (IPCC) issued a report reflecting the scientific consensus that the balance of evidence suggests there is a discernible human influence on global climate. Singer responded with a letter to "Science" saying the IPCC report had presented material selectively. He wrote: "the Summary does not even mention the existence of 18 years of weather satellite data that show a slight global cooling trend, contradicting all theoretical models of climate warming." Scheuering writes that Singer acknowledges the surface thermometers from weather stations show warming, but he argues that the satellites provide better data because their measurements cover pole to pole.
According to Edward Parson and Andrew Dessler, the satellite data did not show surface temperatures directly, but had to be adjusted using models. When adjustment was made for transient events the data showed a slight warming, and research suggested that the discrepancy between surface and satellite data was largely accounted for by problems such as instrument differences between satellites.

Singer wrote the "Leipzig Declaration on Global Climate Change in the U.S." in 1995, updating it in 1997 to rebut the Kyoto Protocol. The Kyoto Protocol was the result of an international convention held in Kyoto, Japan, during which several industrialized nations agreed to reduce their greenhouse gas emissions. Singer's declaration read: "Energy is essential for economic growth ... We understand the motivation to eliminate what are perceived to be the driving forces behind a potential climate change; but we believe the Kyoto Protocol—to curtail carbon dioxide emissions from only a part of the world community—is dangerously simplistic, quite ineffective, and economically destructive to jobs and standards-of-living."

Scheuering writes that Singer circulated this in the United States and Europe and gathered 100 signatories, though she says some of the signatories' credentials were questioned. At least 20 were television weather reporters, some did not have science degrees, and 14 were listed as professors without specifying a field. According to Scheuering, some of them later said they believed they were signing a document in favour of action against climate change.

Singer set up the Nongovernmental International Panel on Climate Change (NIPCC) after a 2004 United Nations climate conference in Milan. NIPCC organized an international climate workshop in Vienna in April 2007, to provide what they called an independent examination of the evidence for climate change. Singer prepared an NIPCC report called "Nature, Not Human Activity, Rules the Climate," published in March 2008 by The Heartland Institute, a conservative think tank. ABC News said the same month that unnamed climate scientists from NASA, Stanford, and Princeton who spoke to ABC about the report dismissed it as "fabricated nonsense". In a letter of complaint to ABC News, Singer said their piece used "prejudicial language, distorted facts, libelous insinuations, and anonymous smears".

On September 18, 2013, the NIPCC's fourth report, entitled "Climate Change Reconsidered II: Physical Science," was published. As with previous NIPCC reports, environmentalists criticized it upon its publication; for example, David Suzuki wrote that it was "full of long-discredited claims, including that carbon dioxide emissions are good because they stimulate life". After the report received favorable coverage from Fox News Channel's Doug McKelway, climate scientists Kevin Trenberth and Michael Oppenheimer criticized this coverage, with Trenberth calling it "irresponsible journalism" and Oppenheimer calling it "flat out wrong".

In December 2009, after the Climatic Research Unit email controversy, Singer wrote an opinion piece for Reuters in which he said the scientists had misused peer review, pressured editors to prevent publication of alternative views, and smeared opponents. He said the leaked e-mails showed that the "surface temperature data that IPCC relies on is based on distorted raw data and algorithms that they will not share with the science community." He argued that the incident exposed a flawed process, and that the temperature trends were heading downwards even as greenhouse gases like CO were increasing in the atmosphere. He wrote: "This negative correlation contradicts the results of the models that IPCC relies on and indicates that anthropogenic global warming (AGW) is quite small," concluding "and now it turns out that global warming might have been 'man made' after all." A British House of Commons Science and Technology Select Committee later issued a report that exonerated the scientists, 
and eight committees investigated the allegations, finding no evidence of fraud or scientific misconduct.



</doc>
<doc id="11736" url="https://en.wikipedia.org/wiki?curid=11736" title="Frederik Pohl">
Frederik Pohl

Frederik George Pohl Jr. (; November 26, 1919 – September 2, 2013) was an American science-fiction writer, editor, and fan, with a career spanning more than 75 years—from his first published work, the 1937 poem "Elegy to a Dead Satellite: Luna", to the 2011 novel "All the Lives He Led" and articles and essays published in 2012.

From about 1959 until 1969, Pohl edited "Galaxy" and its sister magazine "If"; the latter won three successive annual Hugo Awards as the year's best professional magazine. His 1977 novel "Gateway" won four "year's best novel" awards: the Hugo voted by convention participants, the Locus voted by magazine subscribers, the Nebula voted by American science-fiction writers, and the juried academic John W. Campbell Memorial Award. He won the Campbell Memorial Award again for the 1984 collection of novellas "Years of the City", one of two repeat winners during the first 40 years. For his 1979 novel "Jem", Pohl won a U.S. National Book Award in the one-year category Science Fiction. It was a finalist for three other year's best novel awards. He won four Hugo and three Nebula Awards, including receiving both for the 1977 novel "Gateway".
The Science Fiction and Fantasy Writers of America named Pohl its 12th recipient of the Damon Knight Memorial Grand Master Award in 1993 and he was inducted by the Science Fiction and Fantasy Hall of Fame in 1998, its third class of two dead and two living writers.

Pohl won the Hugo Award for Best Fan Writer in 2010, for his blog, "The Way the Future Blogs".

Pohl was the son of Frederik (originally Friedrich) George Pohl (a salesman of German descent) and Anna Jane Mason. Pohl Sr. held various jobs, and the Pohls lived in such wide-flung locations as Texas, California, New Mexico, and the Panama Canal Zone. The family settled in Brooklyn when Pohl was around seven.

He attended Brooklyn Technical High School, and dropped out at 17. In 2009, he was awarded an honorary diploma from Brooklyn Tech.

While a teenager, he co-founded the New York–based Futurians fan group, and began lifelong friendships with Donald Wollheim, Isaac Asimov, and others who would become important writers and editors. Pohl later said that other "friends came and went and were gone, [but] many of the ones I met through fandom were friends all their lives – Isaac, Damon Knight, Cyril Kornbluth, Dirk Wylie, [and] Dick Wilson. In fact, there are one or two – Jack Robins, Dave Kyle – whom I still count as friends, seventy-odd years later..." He published a science-fiction fanzine called "Mind of Man."

During 1936, Pohl joined the Young Communist League because of its positions for unions and against racial prejudice, Adolf Hitler, and Benito Mussolini. He became president of the local Flatbush III Branch of the YCL in Brooklyn. Pohl has said that after the Molotov–Ribbentrop Pact of 1939, the party line changed and he could no longer support it, at which point he left.

Pohl served in the United States Army from April 1943 until November 1945, rising to sergeant as an air corps weatherman. After training in Illinois, Oklahoma, and Colorado, he was mainly stationed in Italy with the 456th Bombardment Group.

Pohl was married five times. His first wife, Leslie Perri, was another Futurian; they were married in August 1940, and divorced in 1944. He then married Dorothy LesTina in Paris in August 1945 while both were serving in the military in Europe; the marriage ended in 1947. During 1948, he married Judith Merril; they had a daughter, Ann. Pohl and Merril divorced in 1952. In 1953, he married Carol M. Ulf Stanton, with whom he had three children and collaborated on several books; they separated in 1977 and were divorced in 1983. From 1984 until his death, Pohl was married to science-fiction expert and academic Elizabeth Anne Hull.

He fathered four children – Ann (m. Walter Weary), Frederik III (deceased), Frederik IV and Kathy. Grandchildren include Canadian writer Emily Pohl-Weary and chef Tobias Pohl-Weary.

From 1984 on, he lived in Palatine, Illinois, a suburb of Chicago. He was previously a longtime resident of Middletown, New Jersey.

Pohl began writing in the late 1930s, using pseudonyms for most of his early works. His first publication was the poem "Elegy to a Dead Satellite: Luna" under the name of Elton Andrews, in the October 1937 issue of "Amazing Stories", edited by T. O'Conor Sloane. (Pohl asked readers 30 years later, "we would take it as a personal favor if no one ever looked it up".) His first story, the collaboration with C.M. Kornbluth "Before the Universe", appeared in 1940 under the pseudonym S.D. Gottesman.

Pohl started a career as a literary agent in 1937, but it was a sideline for him until after World War II, when he began doing it full-time. He ended up "representing more than half the successful writers in science fiction", but his agency did not succeed financially, and he closed it down in the early 1950s.

Pohl stopped being Asimov's agent—the only one the latter ever had—when he became editor from 1939 to 1943 of two pulp magazines, "Astonishing Stories" and "Super Science Stories". Stories by Pohl often appeared in these science-fiction magazines, but never under his own name. Work written in collaboration with Cyril M. Kornbluth was credited to S. D. Gottesman or Scott Mariner; other collaborative work (with any combination of Kornbluth, Dirk Wylie, or Robert A. W. Lownes) was credited to Paul Dennis Lavond. For Pohl's solo work, stories were credited to James MacCreigh (or for one story only, Warren F. Howard.) Works by "Gottesman", "Lavond", and "MacCreigh" continued to appear in various science-fiction pulp magazines throughout the 1940s.

In his autobiography, Pohl said that he stopped editing the two magazines at roughly the time of the German invasion of the Soviet Union in 1941.

Pohl co-founded the Hydra Club, a loose collection of science-fiction professionals and fans who met during the late 1940s and 1950s.

From the early 1960s until 1969, Pohl served as editor of "Galaxy Science Fiction" and "Worlds of if" magazines, taking over after the ailing H. L. Gold could no longer continue working "around the end of 1960". Under his leadership, "if" won the Hugo Award for Best Professional Magazine for 1966, 1967 and 1968. Pohl hired Judy-Lynn del Rey as his assistant editor at "Galaxy" and "if". He also served as editor of "Worlds of Tomorrow" from its first issue in 1963 until it was merged into "if" in 1967.

In the mid-1970s, Pohl acquired and edited novels for Bantam Books, published as "Frederik Pohl Selections"; these included Samuel R. Delany's "Dhalgren" and Joanna Russ's "The Female Man". He also edited a number of science-fiction anthologies.

After World War II, Pohl worked as an advertising copywriter and then as a copywriter and book editor for "Popular Science". Following the war, Pohl began publishing material under his own name, much in collaboration with his fellow Futurian, Cyril Kornbluth.

Though the pen names of "Gottesman", "Lavond", and "MacCreigh" were retired by the early 1950s, Pohl still occasionally used pseudonyms, even after he began to publish work under his real name. These occasional pseudonyms, all of which date from the early 1950s to the early 1960s, included Charles Satterfield, Paul Flehr, Ernst Mason, Jordan Park (two collaborative novels with Kornbluth), and Edson McCann (one collaborative novel with Lester del Rey).

In the 1970s, Pohl re-emerged as a novel writer in his own right, with books such as "Man Plus" and the "Heechee" series. He won back-to-back Nebula Awards with "Man Plus" in 1976 and "Gateway", the first "Heechee" novel, in 1977. In 1978, "Gateway" swept the other two major novel honors, also winning the Hugo Award for Best Novel and John W. Campbell Memorial Award for the best science-fiction novel. Two of his stories have also earned him Hugo Awards: "The Meeting" (with Kornbluth) tied in 1973 and "Fermi and Frost" won in 1986. Another award-winning novel is "Jem" (1980), winner of the National Book Award.

His works include not only science fiction, but also articles for "Playboy" and "Family Circle" magazines and nonfiction books. For a time, he was the official authority for "Encyclopædia Britannica" on the subject of Emperor Tiberius. (He wrote a book on the subject of Tiberius, as "Ernst Mason".)

Some of his short stories take a satirical look at consumerism and advertising in the 1950s and 1960s: "The Wizards of Pung's Corners", where flashy, over-complex military hardware proved useless against farmers with shotguns, and "The Tunnel under the World", where an entire community of seeming-humans is held captive by advertising researchers. ("The Wizards of Pung's Corners" was freely translated into Chinese and then freely translated back into English as "The Wizard-Masters of Peng-Shi Angle" in the first edition of "Pohlstars" (1984)).

Pohl's Law is either "No one is ever ready for anything" or "Nothing is so good that somebody, somewhere will not hate it".

He was a frequent guest on Long John Nebel's radio show from the 1950s to the early 1970s, and an international lecturer.

Starting in 1995, when the Theodore Sturgeon Memorial Award became a juried award, Pohl served first with James Gunn and Judith Merril, and since then with several others until retiring in 2013. Pohl was associated with Gunn since the 1940s, becoming involved in 1975 with what later became Gunn's Center for the Study of Science Fiction at the University of Kansas. There, he presented many talks, recorded a discussion about "The Ideas in Science Fiction" in 1973 for the Literature of Science Fiction Lecture Series, and served the Intensive Institute on Science Fiction and Science Fiction Writing Workshop.

Pohl received the second annual J. W. Eaton Lifetime Achievement Award in Science Fiction from the University of California, Riverside Libraries at the 2009 Eaton Science Fiction Conference, "Extraordinary Voyages: Jules Verne and Beyond".

Pohl's work has been an influence on a wide variety of other science fiction writers, some of whom appear in the 2010 anthology, "", edited by Elizabeth Anne Hull.

Pohl's last novel, "All the Lives He Led", was released on April 12, 2011.

By the time of his death, he was working to finish a second volume of his autobiography "The Way the Future Was" (1979), along with an expanded version of the latter.

In addition to his solo writings, Pohl was also well known for his collaborations, beginning with his first published story. Before and following the war, Pohl did a series of collaborations with his friend Cyril Kornbluth, including a large number of short stories and several novels, among them "The Space Merchants," a dystopian satire of a world ruled by the advertising agencies.

In the mid-1950s, he began a long-running collaboration with Jack Williamson, eventually resulting in 10 collaborative novels over five decades.

Other collaborations included a novel with Lester Del Rey, "Preferred Risk" (1955). This novel was solicited for a contest by Galaxy–Simon & Schuster when the judges did not think any of the contest submissions was good enough to win their contest. It was published under the joint pseudonym Edson McCann. He also collaborated with Thomas T. Thomas on a sequel to his award-winning novel "Man Plus." He wrote two short stories with Isaac Asimov in the 1940s, both published in 1950.

He finished a novel begun by Arthur C. Clarke, "The Last Theorem", which was published on August 5, 2008.

Pohl went to the hospital in respiratory distress on the morning of September 2, 2013, and died that afternoon at the age of 93.





</doc>
<doc id="11740" url="https://en.wikipedia.org/wiki?curid=11740" title="Forrest J Ackerman">
Forrest J Ackerman

Forrest James Ackerman (November 24, 1916 – December 4, 2008) was an American magazine editor, science fiction writer and literary agent, a founder of science fiction fandom, a leading expert on science fiction, horror, and fantasy films, and acknowledged as the world's most avid collector of genre books and movie memorabilia. He was based in Los Angeles, California.

During his career as a literary agent, Ackerman represented such science fiction authors as Ray Bradbury, Isaac Asimov, A.E. Van Vogt, Curt Siodmak, and L. Ron Hubbard. For more than seven decades, he was one of science fiction's staunchest spokesmen and promoters.

Ackerman was the editor and principal writer of the American magazine "Famous Monsters of Filmland", as well as an actor, from the 1950s into the 21st century. He appears in several documentaries related to this period in popular culture, like "Famous Monster: Forrest J Ackerman" (directed by Michael R. MacDonald and written by Ian Johnston), which premiered at the Egyptian Theatre in March 2009, during the Forrest J Ackerman tribute; "The Ackermonster Chronicles!" (a 2012 documentary about Ackerman by writer and filmmaker Jason V Brock); and "Charles Beaumont: The Short Life of Twilight Zone's Magic Man", about the late author Charles Beaumont, a former client of The Ackerman Agency.

Also called "Forry", "Uncle Forry", "The Ackermonster", "Dr. Acula", "Forjak", "4e" and "4SJ", Ackerman was central to the formation, organization and spread of science fiction fandom and a key figure in the wider cultural perception of science fiction as a literary, art, and film genre. Famous for his word play and neologisms, he coined the genre nickname "sci-fi". In 1953, he was voted "#1 Fan Personality" by the members of the World Science Fiction Society, a unique Hugo Award never granted to anyone else.

He was also among the first and most outspoken advocates of Esperanto in the science fiction community.

Ackerman was born Forrest James Ackerman (though he would refer to himself from the early 1930s on as "Forrest J Ackerman" with no period after the middle initial), on November 24, 1916, in Los Angeles, to Carroll Cridland (née Wyman; 1883–1977) and William Schilling Ackerman (1892–1951). His father, Chief Statistician for the Associated Oil Company, and assistant to the Vice-President in charge of transportation, was from New York and his mother was from Ohio (the daughter of architect George Wyman); she was nine years older than William.

Ackerman attended the University of California at Berkeley for a year (1934–1935), then worked as a movie projectionist and at odd jobs with fan friends prior to spending three years in the U.S. Army after enlisting on August 15, 1942, where he rose to the rank of staff sergeant, held the position of editor of his base's newspaper, and passed his entire time in service at Fort MacArthur, California.

Ackerman saw his first "imagi-movie" in 1922 ("One Glorious Day"), purchased his first science fiction magazine, "Amazing Stories", in 1926, created the Boys' Scientifiction Club in 1930 ("girl-fans were as rare as unicorn's horns in those days"). He contributed to both of the first science fiction fanzines, "The Time Traveller", and the "Science Fiction Magazine", published and edited by Shuster and Siegel of Superman fame, in 1932, and by 1933 had 127 correspondents around the world. His name was used for the character of the reporter in the original Superman story "The Reign of the Superman" in issue 3 of "Science Fiction" magazine. He was one of the early members of the Los Angeles Science Fantasy Society and remained active in it for many decades.
He attended the 1st World Science Fiction Convention in 1939, where he wore the first "futuristicostume" (designed and created by his girlfriend Myrtle R. Douglas, better known as Morojo), which sparked decades of fan costuming thereafter, the latest incarnation of which is cosplay. He attended every Worldcon but two thereafter during his lifetime. Ackerman invited Ray Bradbury to attend the Los Angeles Chapter of the Science Fiction League, then meeting weekly at Clifton's Cafeteria in downtown Los Angeles. The club changed its name to the Los Angeles Science Fantasy Society during the period it was meeting at the restaurant. (There never was a "Clifton's Cafeteria Science Fiction Club".) Among the writers frequenting the club were Robert A. Heinlein, Emil Petaja, Fredric Brown, Henry Kuttner, Leigh Brackett, and Jack Williamson. Bradbury often attended meetings with his friend Ray Harryhausen; the two Rays had been introduced to each other by Ackerman. With $90 from Ackerman and Morojo, Bradbury launched a fanzine, "Futuria Fantasia", in 1939, which ran for four issues.

Ackerman was an early member of the Los Angeles Chapter of the Science Fiction League and became so active in and important to the club that in essence he ran it, including (after the name change) the Los Angeles Science Fantasy Society, a prominent regional fan organization, as well as the National Fantasy Fan Federation (N3F). Together with Morojo, he edited and produced "Imagination!", later renamed "Voice of the Imagi-Nation" (which in 1996 would be awarded the Retro Hugo for Best Fanzine of 1946, and in 2014 for 1939), which was nominally the club fanzine for the LASFS.

In the decades that followed, Ackerman amassed an extremely large and complete collection of science fiction, fantasy, and horror film memorabilia, which, until 2002, he maintained in an 18-room home and museum known as the "Son of Ackermansion". (The original Ackermansion where he lived from the early 1950s until the mid-1970s was at 915 S. Sherbourne Drive in Los Angeles; the site is now an apartment building.) This second house, in the Los Feliz district of Los Angeles, contained some 300,000 books and pieces of film and science-fiction memorabilia. From 1951 to 2002, Ackerman entertained some 50,000 fans at open houses - including, on one such evening, a group of 186 fans and professionals that included astronaut Buzz Aldrin. Ackerman was a board member of the Seattle Science Fiction Museum and Hall of Fame, where many items of his collection are now displayed.

He knew most of the writers of science fiction in the first half of the twentieth century. As a literary agent, he represented some 200 writers, and he served as agent of record for many long-lost authors, thereby allowing their work to be reprinted in anthologies. He was Ed Wood's "illiterary" agent. Ackerman was credited with nurturing and even inspiring the careers of several early contemporaries like Ray Bradbury, Ray Harryhausen, Charles Beaumont, Marion Zimmer Bradley, and L. Ron Hubbard. He kept all of the stories submitted to his magazine, even the ones he rejected; Stephen King has stated that Ackerman showed up to a King book signing with a copy of a story King had submitted for publication when he was 11.

Ackerman had 50 stories published, including collaborations with A. E. van Vogt, Francis Flagg, Robert A. W. Lowndes, Marion Zimmer Bradley, Donald Wollheim and Catherine Moore, and the world's shortest – one letter of the alphabet. His stories have been translated into six languages. Ackerman named the sexy comic-book character Vampirella and wrote the origin story for the comic.

He also authored several lesbian stories under the name "Laurajean Ermayne" for "Vice Versa" and provided publishing assistance in the early days of the Daughters of Bilitis. He was dubbed an "honorary lesbian" at a DOB party.

Through his magazine, "Famous Monsters of Filmland" (1958–1983), Ackerman introduced the history of the science fiction, fantasy, and horror film genres to a generation of young readers. At a time when most film-related publications glorified the stars in front of the camera, "Uncle Forry", as he was referred to by many of his fans, promoted the behind-the-scenes artists involved in the magic of the movies. In this way, Ackerman provided inspiration to many who would later become successful artists, including Joe Dante, Peter Jackson, Steven Spielberg, Tim Burton, Stephen King, Donald F. Glut, Penn & Teller, Billy Bob Thornton, Gene Simmons (of the band Kiss), Rick Baker, George Lucas, Danny Elfman, Frank Darabont, Guillermo del Toro, Kirk Hammett (of the band Metallica), John Landis, television producer Kevin Burns and countless other writers, directors, artists, and craftsmen.

He also contributed to film magazines from all around the world, including the Spanish-language "" magazine from Argentina, where he had a monthly column for more than four years.

In the 1960s, Ackerman organized the publication of an English translation in the U.S. of the German science fiction series "Perry Rhodan", the longest-running science fiction series in history. These were published by Ace Books from 1969 through 1977. Ackerman's German-speaking wife Wendayne ("Wendy") did most of the translation. The American books were issued with varying frequency from one to as many as four per month. Ackerman also used the paperback series to promote science fiction short stories, including his own on occasion. These "magabooks" or "bookazines" also included a film review section, known as "Scientifilm World", and letters from readers. The American series came to an end when the management of Ace changed, and the new management decided that the series was too juvenile for their taste. The last Ace issue was #118, which corresponded to German issue #126 as some of the Ace editions contained two of the German issues, and three of the German issues had been skipped. Ackerman later published translations of German issues #127 through #145 on his own under the Master Publications imprint. (The original German series continues today and passed issue #2800 in 2015.)

A lifelong fan of science fiction "B-movies", Ackerman appeared in more than 210 films, including parts in many monster movies and science fiction films ("Dracula vs. Frankenstein", "The Howling", "The Aftermath", "Scalps", "Return of the Living Dead Part II", "Innocent Blood"), more traditional "imagi-movies" ("The Time Travelers", "Future War"), spoofs and comedies ("Amazon Women on the Moon", "The Wizard of Speed and Time", "Curse of the Queerwolf", "Transylvania Twist", "Hard to Die", "Nudist Colony of the Dead", "Attack of the 60 Foot Centerfold") and at least one major music video ("Michael Jackson's Thriller"). His Bacon number is 2.

In 1961, Ackerman narrated the record "Music for Robots" created by Frank Allison Coe. The cover featured Ackerman's face superimposed on the robot from the film "Tobor the Great". The record was reissued on CD in 2005.

Ackerman appears as a character in "The Vampire Affair" by David McDaniel (a novel in the "Man from U.N.C.L.E." series), and Philip José Farmer's novel "The Image Of The Beast", first published as the short story "Blown" in "Screw" magazine by Al Goldstein.

A character based on Ackerman and an analog to the Ackermansion appears in the collaborative novel "Fallen Angels" written jointly by Larry Niven, Jerry Pournelle, and Michael F. Flynn.

"Eccar the Man" is mentioned in "The Flying Sorcerers", a novel jointly written by Niven and David Gerrold, which features a number of characters based on notables from the science fiction community.

He appeared on the intro track of Ohio horror punk music group Manimals' 1999 album "Horrorcore".

In 2001, Ackerman played the part of an old wax museum caretaker in the camp comedy film "The Double-D Avenger" directed by William Winckler and starring Russ Meyer luminaries Kitten Natividad, Haji, and Raven De La Croix. Ackerman played a crazy old man who was in love with Kitten Natividad's character, The Double-D Avenger, and his character also talked to the Frankenstein figure and other wax monsters in the museum's chamber of horrors.

Ackerman appeared extensively on-screen discussing his life and the history of science fiction fandom in the 2006 documentary film "Finding the Future".

In 2007, Roadhouse Films of Canada released a documentary, "Famous Monster: Forrest J Ackerman". The documentary, available on DVD only in the UK, airs regularly on the BRAVO channel.

In the 2012 action film "Premium Rush", the character of the corrupt policeman Bobby Monday (played by Michael Shannon) repeatedly uses the alias "Forrest J Ackerman".

In 2013, the science fiction author Jason V Brock released a feature-length documentary about Ackerman called "The Ackermonster Chronicles!".

Ackerman had one sibling, a younger brother, Alden Lorraine Ackerman, who was killed at the Battle of the Bulge.

Ackerman was married to a German-born teacher and translator, Mathilda Wahrman (1912–1990), whom he met in the early 1950s while she was working in a book store he happened to visit. He eventually dubbed her "Wendayne" or, less formally, "Wendy", by which name she became most generally known within SF and film fandoms, after the character in "Peter Pan", his favorite fantasy. Although they went through a period of separation during the late 1950s and early 1960s, they remained officially married until her death: she suffered serious internal injuries when she was violently mugged while visiting Italy in 1990 and irreparable damage to her kidneys led to her death. They had no children of their own by choice, but Wahrman did have a son by an earlier marriage, Michael Porges, who did not get along with Ackerman and would not live in Ackerman's home.

Ackerman was fluent in the international language Esperanto, and claimed to have walked down Hollywood Boulevard arm-in-arm with Leo G. Carroll singing "La Espero", the hymn of Esperanto.

Ackerman was an atheist, but did not emphasize that fact in his public life and welcomed people of all faiths as well as no faith into his home and personal circle equally.
His first public stance on any political issue was in opposition to the Vietnam War.

On March 16, 1960, Ackerman was found guilty on five counts of mailing "letters which were obscene, lewd, indecent, lascivious and filthy in violation of Title 18, United States Code, Section 1461."

Beginning in January 2018, numerous allegations were made, some by named accusers, concerning Ackerman's long-term predatory and sexually inappropriate behaviour, much of it concerning minors. This was later widely reported and discussed in horror fan communities.

In 2003, Ackerman said, "I aim at hitting 100 and becoming the George Burns of science fiction". His health, however, had been failing. He was susceptible to infection in his later life and, after one final trip to the hospital in October 2008, informed his best friend and caregiver Joe Moe that he did not want to go on but hoped to live long enough to vote for Barack Obama in the November, 2008 presidential election.. Honoring his wishes, his friends brought him home to hospice care. However, it turned out that in order to get Ackerman home, the hospital had cured his infection with antibiotics. So Ackerman went on for a few more weeks holding what he delighted in calling "a living funeral". In his final days he saw everyone he wanted to say goodbye to. Fans were encouraged to send messages of farewell by mail.

While there were several premature reports of his death in the month prior, Ackerman died a minute before midnight on December 4, 2008, at the age of 92. From his "Acker-mini-mansion" in Hollywood, he had entertained and inspired fans weekly with his collection of memorabilia and his stories.

Upon his death, the administration of Ackerman's estate was entrusted to his friend, television producer Kevin Burns. Burns was tasked with the sale and distribution of Mr. Ackerman's extensive collection of Science Fiction and Horror memorabilia. Included in this were Bela Lugosi's ring from "Abbott and Costello Meet Frankenstein" and Lon Chaney's teeth and top hat from "London After Midnight". There were eighteen beneficiaries named in Ackerman's will, including three waitresses from his favorite restaurant and hangout, "The House of Pies". 

Ackerman is interred at Forest Lawn Memorial Park (Glendale) with his wife. His plaque simply reads, "Sci-Fi Was My High".

A 2013 rebroadcast of the PBS program "Visiting ... with Huell Howser," originally airing in 2000, which featured Ackerman and highlighted his memorabilia collection, was revised to indicate that Ackerman had since died and his collection had been auctioned.

On Thursday morning, November 17, 2016 the corner of Franklin and Vermont Avenues, in the heart of the neighborhood "Uncle Forry" lived in for 30 years, was christened Forrest J Ackerman Square.







</doc>
<doc id="11741" url="https://en.wikipedia.org/wiki?curid=11741" title="Fantasy film">
Fantasy film

Fantasy films are films that belong to the fantasy genre with fantastic themes, usually magic, supernatural events, mythology, folklore, or exotic fantasy worlds. The genre is considered a form of speculative fiction alongside science fiction films and horror films, although the genres do overlap. Fantasy films often have an element of magic, myth, wonder, escapism, and the extraordinary.

Several sub-categories of fantasy films can be identified, although the delineations between these subgenres, much as in fantasy literature, are somewhat fluid.

The most common fantasy subgenres depicted in movies are High Fantasy and Sword and Sorcery. Both categories typically employ quasi-medieval settings, wizards, magical creatures and other elements commonly associated with fantasy stories.

High Fantasy films tend to feature a more richly developed fantasy world, and may also be more character-oriented or thematically complex. Often, they feature a hero of humble origins and a clear distinction between good and evil set against each other in an epic struggle. Many scholars cite J. R. R. Tolkien's "The Lord of the Rings" novel as the prototypical modern example of High Fantasy in literature, and the recent Peter Jackson film adaptation of the books is a good example of the High Fantasy subgenre on the silver screen.
Sword and Sorcery movies tend to be more plot-driven than high fantasy and focus heavily on action sequences, often pitting a physically powerful but unsophisticated warrior against an evil wizard or other supernaturally endowed enemy. Although Sword and Sorcery films sometimes describe an epic battle between good and evil similar to those found in many High Fantasy movies, they may alternately present the hero as having more immediate motivations, such as the need to protect a vulnerable maiden or village, or even being driven by the desire for vengeance.

The 1982 film adaptation of Robert E. Howard's "Conan the Barbarian", for example, is a personal (non-epic) story concerning the hero's quest for revenge and his efforts to thwart a single megalomaniac—while saving a beautiful princess in the process. Some critics refer to such films by the term Sword and Sandal rather than Sword and Sorcery, although others would maintain that the Sword and Sandal label should be reserved only for the subset of fantasy films set in ancient times on the planet Earth, and still others would broaden the term to encompass films that have no fantastic elements whatsoever. To some, the term Sword and Sandal has pejorative connotations, designating a film with a low-quality script, bad acting, and poor production values.

Another important subgenre of fantasy films that has become more popular in recent years is contemporary fantasy. Such films feature magical effects or supernatural occurrences happening in the "real" world of today.

Films with live action and animation such as Disney's "Mary Poppins", "Pete's Dragon", "Enchanted", and the Robert Zemeckis film "Who Framed Roger Rabbit" are also fantasy films although are more often referred to as Live action/animation hybrids (2 of those are also classified as musicals).

Fantasy films set in the afterlife, called Bangsian Fantasy, are less common, although films such as the 1991 Albert Brooks comedy "Defending Your Life" would likely qualify. Other uncommon subgenres include Historical Fantasy and Romantic Fantasy, although 2003's "" successfully incorporated elements of both.

As noted above, superhero movies and fairy tale films might each be considered subgenres of fantasy films, although most would classify them as altogether separate movie genres.

As a cinematic genre, fantasy has traditionally not been regarded as highly as the related genre of science fiction film. Undoubtedly, the fact that until recently fantasy films often suffered from the "Sword and Sandal" afflictions of inferior production values, over-the-top acting, and decidedly poor special effects was a significant factor in fantasy film's low regard.

Since the early 2000s, however, the genre has gained new respectability in a way, driven principally by the successful adaptations of J.R.R. Tolkien's "The Lord of the Rings" and J.K. Rowling's "Harry Potter" series. Jackson's "The Lord of the Rings" trilogy is notable due to its ambitious scope, serious tone, and thematic complexity. These pictures achieved phenomenal commercial and critical success, and the of the trilogy became the first fantasy film ever to win the Academy Award for Best Picture. The "Harry Potter" series has been a tremendous financial success, has achieved critical acclaim for its design, thematic sophistication and emotional depth, grittier realism and darkness, narrative complexity, and characterization, and boasts an enormous and loyal fanbase.

Following the success of these ventures, Hollywood studios have greenlighted additional big-budget productions in the genre. These have included adaptations of the first, second, and third books in C. S. Lewis' "The Chronicles of Narnia" series and the teen novel "Eragon", as well as adaptations of Susan Cooper's "The Dark Is Rising", Cornelia Funke's "Inkheart", Philip Pullman's "The Golden Compass", Holly Black's "The Spiderwick Chronicles", Nickelodeon's TV show "", and the "Fantasia" segment (along with Johann Wolfgang von Goethe's original poem) "The Sorcerer's Apprentice"

Fantasy movies in recent years, such as "The Lord of the Rings" films, the first and third "Narnia" adaptations, and the first, second, fourth and seventh "Harry Potter" adaptations have most often been released in November and December. This is in contrast to science fiction films, which are often released during the northern hemisphere summer (June–August). All three installments of the "Pirates of the Caribbean" fantasy films, however, were released in July 2003, July 2006, and May 2007 respectively, and the latest releases in the "Harry Potter" series were released in July 2007 and July 2009. The huge commercial success of these pictures may indicate a change in Hollywood's approach to big-budget fantasy film releases.

Fantasy films have a history almost as old as the medium itself. However, fantasy films were relatively few and far between until the 1980s, when high-tech filmmaking techniques and increased audience interest caused the genre to flourish.

What follows are some notable Fantasy films. For a more complete list see: List of fantasy films

In the era of silent film, the earliest fantasy films were those made by French film pioneer Georges Méliès from 1903. The most famous of these was 1902's "A Trip to the Moon". In the Golden Age of Silent film (1918–1926) the most outstanding fantasy films were Douglas Fairbanks' "The Thief of Bagdad" (1924), Fritz Lang's "Die Nibelungen" (1924), and "Destiny" (1921). Other notables in the genre were F.W. Murnau's romantic ghost story "Phantom", "Tarzan of the Apes" starring Elmo Lincoln, and D. W. Griffith's "The Sorrows of Satan".

Following the advent of sound films, audiences of all ages were introduced from 1937's "Snow White and the Seven Dwarfs" to 1939's "The Wizard of Oz". Also notable of the era, the iconic 1933 film "King Kong" borrows heavily from the Lost World subgenre of fantasy fiction as does such films as the 1935 adaptation of H. Rider Haggard's novel "She" about an African expedition that discovers an immortal queen known as Ayesha "She who must be obeyed". Frank Capra's 1937 picture "Lost Horizon" transported audiences to the Himalayan fantasy kingdom of Shangri-La, where the residents magically never age. Other noteworthy fantasy films of the 30s include "Tarzan the Ape Man" in 1932 starring Johnny Weissmuller starting a successful series of talking pictures based on the fantasy-adventure novels by Edgar Rice Burroughs and the G. W. Pabst directed "The Mistress of Atlantis" from 1932. 1932 saw the release of the Universal Studios monster movie "The Mummy" which combined horror with a romantic fantasy twist. more light-hearted and comedic affairs from the decade include films like 1934s romantic drama film "Death Takes a Holiday" where Fredric March plays Death who takes a human body to experience life for three days and 1937s "Topper" where a man is haunted by two fun-loving ghosts who try to make his life a little more exciting.

The 1940s then saw several full-color fantasy films produced by Alexander Korda, including "The Thief of Bagdad" (1940), a film on par with "The Wizard of Oz", and "Jungle Book" (1942). In 1946, Jean Cocteau's classic adaptation of "Beauty and the Beast" won praise for its surreal elements and for transcending the boundaries of the fairy tale genre. "Sinbad the Sailor" (1947), starring Douglas Fairbanks, Jr., has the feel of a fantasy film though it does not actually have any fantastic elements.

Several other pictures featuring supernatural encounters and aspects of Bangsian fantasy were produced in the 1940s during World War II. These include "Beyond Tomorrow", "The Devil and Daniel Webster", and "Here Comes Mr. Jordan", all from 1941, "Heaven Can Wait" the musical "Cabin in the Sky" (1943), the comedy "The Horn Blows at Midnight" and romances such as "The Ghost and Mrs. Muir" (1947), "One Touch of Venus" and "Portrait of Jennie", both 1948.

An astonishing anticipation of the full "sword and sorcery" genre was made in 1941 in Italy by Alessandro Blasetti. "La Corona di Ferro" presents the struggles of two imaginary kingdoms around the legendary Iron Crown (historically the ancient crown of Italy), with war, cruelty, betrayal, heroism, sex, magic and mysticism, a whirl of events taken from every possible fairy tale and legend source Blasetti could find. This movie is unlike anything done before; indeed, considering that it was finished fifteen years before the publication of Lord Of The Rings, its invention of a vast, national epic mythology is an act of genius. And while the storytelling is rough - due to the need to insert everything - and the resources limited, Blasetti shows how to make a little go a long way through beautifully staged and designed battle and crowd scenes.

Although it's not classified as a fantasy film, Gene Kelly's "Anchors Aweigh" had a fantasy sequence called "The King who Couldn't Dance" in which Gene did a song and dance number with Jerry Mouse from Tom and Jerry.

Because these movies do not feature elements common to high fantasy or sword and sorcery pictures, some modern critics do not consider them to be examples of the fantasy genre.

In the 1950s there were a few major fantasy films, including "Darby O'Gill and the Little People" and "The 5000 Fingers of Dr. T", the latter penned by Dr. Seuss. Jean Cocteau's Orphic Trilogy, begun in 1930 and completed in 1959, is based on Greek mythology and could be classified either as fantasy or surrealist film, depending on how the boundaries between these genres are drawn. Russian fantasy director Aleksandr Ptushko created three mythological epics from Russian fairytales, "Sadko" (1953), "Ilya Muromets" (1956), and "Sampo" (1959). Japanese director Kenji Mizoguchi's 1953 film "Ugetsu Monogatari" draws on Japanese classical ghost stories of love and betrayal.

Other notable pictures from the 1950s that feature fantastic elements and are sometimes classified as fantasy are "Harvey" (1950), featuring a púca of Celtic mythology; "Scrooge", the 1951 adaptation of Charles Dickens' "A Christmas Carol"; and Ingmar Bergman's 1957 masterpiece, "The Seventh Seal". Disney's 1951 animated film "Alice in Wonderland" is also a fantasy classic.

There were also a number of lower budget fantasies produced in the 1950s, typically based on Greek or Arabian legend. The most notable of these may be 1958's "The 7th Voyage of Sinbad", featuring special effects by Ray Harryhausen and music by Bernard Herrmann.

Harryhausen worked on a series of fantasy films in the 1960s, most importantly "Jason and the Argonauts" (1963). Many critics have identified this film as Harryhausen's masterwork for its stop-motion animated statues, skeletons, harpies, hydra, and other mythological creatures. Other Harryhausen fantasy and science fantasy collaborations from the decade include the 1961 adaptation of Jules Verne's "Mysterious Island", the critically panned "One Million Years B.C." starring Raquel Welch, and "The Valley of Gwangi" (1969).

Capitalising on the success of the sword and sandal genre several Italian B-movies based on classical myth were made, including the "Maciste" series. Otherwise, the 1960s were almost entirely devoid of fantasy films. The fantasy picture "7 Faces of Dr. Lao", in which Tony Randall portrayed several characters from Greek mythology, was released in 1964. But the 1967 adaptation of the Broadway musical "Camelot" removed most of the fantasy elements from T. H. White's classic "The Once and Future King", on which the musical had been based. The 1960s also saw a new adaption of Haggard's "She" in 1965 starring Ursula Andress as the immortal "She who must be obeyed" and was followed by a sequel in 1968 "The Vengeance of She" based loosely on the novel "" both produced by Hammer Film Productions, 1968 also saw the release of "Chitty Chitty Bang Bang" based on a story by Ian Fleming with a script from Roald Dahl.

Fantasy elements of Arthurian legend were again featured, albeit absurdly, in 1975's "Monty Python and the Holy Grail". Harryhausen also returned to the silver screen in the 1970s with two additional "Sinbad" fantasies, "The Golden Voyage of Sinbad" (1974) and "Sinbad and the Eye of the Tiger" (1977). The animated movie "Wizards" (1977) had limited success at the box office but achieved status as a cult film. There was also "The Noah" (1975) which was never released theatrically but became a cult favorite when it was finally released on DVD in 2006. Some would consider 1977's "Oh God!", starring George Burns to be a fantasy film, and "Heaven Can Wait" (1978) was a successful Bangsian fantasy remake of 1941's "Here Comes Mr. Jordan" (not 1943's "Heaven Can Wait").

A few low budget "Lost World" pictures were made in the 1970s, such as 1975's "The Land That Time Forgot". Otherwise, the fantasy genre was largely absent from mainstream movies in this decade, although 1971's "Bedknobs and Broomsticks" and "Willy Wonka & the Chocolate Factory" were two fantasy pictures in the public eye the former being predominantly from the same team who did "Mary Poppins" the latter again being from Roald Dahl in both script and novel.

1980s fantasy films were initially characterised by directors finding a new spin on established mythologies. Ray Harryhausen brought the monsters of Greek legends to life in "Clash of the Titans" while Arthurian lore returned to the screen in John Boorman's 1981 "Excalibur". Films such as Ridley Scott's 1985 "Legend" and Terry Gilliam's 1981–1986 trilogy of fantasy epics ("Time Bandits", "Brazil", and "The Adventures of Baron Munchausen") explored a new artist-driven style featuring surrealist imagery and thought-provoking plots. The modern sword and sorcery boom began around the same time with 1982's "Conan the Barbarian" followed by "Krull" and "Fire and Ice" in 1983, as well as a boom in fairy tale-like fantasy films such as "Ladyhawke" (1985), "The Princess Bride" (1987), and "Willow" (1988).

The 1980s also started a trend in mixing modern settings and action movie effects with exotic fantasy-like concepts. "Big Trouble in Little China" (1986), directed by John Carpenter and starring Kurt Russell, combined humor, martial arts and classic Chinese folklore in a modern Chinatown setting. "Highlander", a film about immortal Scottish swordsmen, was released the same year.

Jim Henson produced two iconic fantasy films in the 80s, the solemn "The Dark Crystal" and the more whimsical and lofty "Labyrinth". Meanwhile, Robert Zemeckis helmed "Who Framed Roger Rabbit", featuring various famous cartoon characters from animation's "Golden Age," including Mickey Mouse, Minnie Mouse, Donald Duck, Bugs Bunny, Daffy Duck, Droopy, Wile E. Coyote and Road Runner, Sylvester the Cat, Tweety Pie, and Jiminy Cricket, among others.

 (2012)

"Aladdin" (2019)

"Alice in Wonderland" (2010)

"Alice in Wonderland 2: Through the Looking Glass" (2016)

"Aquaman" (2018)

"A Wrinkle in Time" (2018)

"" (2014)

"" (2017)

"Beauty and the Beast" (2017)

"Black Panther" (2018)

"Brahmastra" (2019)

"Brave" (2012)

"Christopher Robin" (2018)

"Cinderella" (2015)

"Clash of the Titans" (2010) and its 2012 sequel, "Wrath of the Titans"

"Conan the Barbarian" (2011)

"Crimson Peak" (2015)

"Dark Shadows" (2012)

"Doctor Strange" (2016)

"" (2018)

"Fantastic Beasts and Where to Find Them" (2016)

"Frozen" (2013)

Frozen II (2019)

"Goosebumps" (2015)

"Gulliver's Travels" (2010)

"Harry Potter and the Deathly Hallows – Part 1" (2010)

"Harry Potter and the Deathly Hallows – Part 2" (2011)

"Hop" (2011)

"How to Train Your Dragon" (2010–19)

"Immortals" (2011)

"Into the Woods" (2014)

"Jack the Giant Slayer" (2010)

"John Carter" (2012)

"Life of Pi" (2012)

"Maleficent" (2014)

"Mary Poppins Returns" (2018)

"Maximum Shame" (2010)

"Midnight in Paris" (2011)

"Mirror Mirror" (2012)

"Miss Peregrine's Home for Peculiar Children" (2016)

"Oz the Great and Powerful" (2013)

"Paddington" (2014)

"Pan" (2015)

"" (2013)

"" (2010)

"Pete's Dragon" (2016)

"Peter Rabbit" (2018)

"Puss in Boots" (2011)

"Sardaar Ji" (2015) (Punjabi)

"Scott Pilgrim vs. the World" (2010)

"Snow White and the Huntsman" (2012)

"Song of the Sea" (2014)

"Sucker Punch" (2011)

"The BFG" (2016)

"The Hobbit" (2012–14)

"The Jungle Book" (2016)

"The Kid Who Would Be King" (2019)

"The Last Airbender" (2010)

"The Lorax" (2012)

"The Muppets" (2011)

"The Nutcracker and the Four Realms" (2018)

"Trolls" (2016) 

"The Shape of Water" (2017)

"The Sorcerer's Apprentice" (2010)

"" (2017)

"" (2013)

"Thor" (2011)

"Toy Story 3" (2010)

"Toy Story 4" (2019)

"Wonder Woman" (2017)

"Your Highness" (2011)



</doc>
<doc id="11742" url="https://en.wikipedia.org/wiki?curid=11742" title="Finite set">
Finite set

In mathematics, a finite set is a set that has a finite number of elements. Informally, a finite set is a set which one could in principle count and finish counting. For example,
is a finite set with five elements. The number of elements of a finite set is a natural number (a non-negative integer) and is called the cardinality of the set. A set that is not finite is called infinite. For example, the set of all positive integers is infinite:
Finite sets are particularly important in combinatorics, the mathematical study of counting. Many arguments involving finite sets rely on the pigeonhole principle, which states that there cannot exist an injective function from a larger finite set to a smaller finite set.

Formally, a set is called finite if there exists a bijection
for some natural number . The number is the set's cardinality, denoted as ||. The empty set {} or Ø is considered finite, with cardinality zero.

If a set is finite, its elements may be written — in many ways — in a sequence:
In combinatorics, a finite set with elements is sometimes called an "-set" and a subset with elements is called a "-subset". For example, the set {5,6,7} is a 3-set – a finite set with three elements – and {6,7} is a 2-subset of it.

Any proper subset of a finite set "S" is finite and has fewer elements than "S" itself. As a consequence, there cannot exist a bijection between a finite set "S" and a proper subset of "S". Any set with this property is called Dedekind-finite. Using the standard ZFC axioms for set theory, every Dedekind-finite set is also finite, but this implication cannot be proved in ZF (Zermelo–Fraenkel axioms without the axiom of choice) alone. 
The axiom of countable choice, a weak version of the axiom of choice, is sufficient to prove this equivalence.

Any injective function between two finite sets of the same cardinality is also a surjective function (a surjection). Similarly, any surjection between two finite sets of the same cardinality is also an injection.

The union of two finite sets is finite, with
In fact:
More generally, the union of any finite number of finite sets is finite. The Cartesian product of finite sets is also finite, with:
Similarly, the Cartesian product of finitely many finite sets is finite. A finite set with "n" elements has 2 distinct subsets. That is, the
power set of a finite set is finite, with cardinality 2.

Any subset of a finite set is finite. The set of values of a function when applied to elements of a finite set is finite.

All finite sets are countable, but not all countable sets are finite. (Some authors, however, use "countable" to mean "countably infinite", so do not consider finite sets to be countable.)

The free semilattice over a finite set is the set of its non-empty subsets, with the join operation being given by set union.

In Zermelo–Fraenkel set theory without the axiom of choice (ZF), the following conditions are all equivalent:


If the axiom of choice is also assumed (the axiom of countable choice is sufficient), then the following conditions are all equivalent:


Georg Cantor initiated his theory of sets in order to provide a mathematical treatment of infinite sets. Thus the distinction between the finite and the infinite lies at the core of set theory. Certain foundationalists, the strict finitists, reject the existence of infinite sets and thus recommend a mathematics based solely on finite sets. Mainstream mathematicians consider strict finitism too confining, but acknowledge its relative consistency: the universe of hereditarily finite sets constitutes a model of Zermelo–Fraenkel set theory with the axiom of infinity replaced by its negation.

Even for those mathematicians who embrace infinite sets, in certain important contexts, the formal distinction between the finite and the infinite can remain a delicate matter. The difficulty stems from Gödel's incompleteness theorems. One can interpret the theory of hereditarily finite sets within Peano arithmetic (and certainly also vice versa), so the incompleteness of the theory of Peano arithmetic implies that of the theory of hereditarily finite sets. In particular, there exists a plethora of so-called non-standard models of both theories. A seeming paradox is that there are non-standard models of the theory of hereditarily finite sets which contain infinite sets, but these infinite sets look finite from within the model. (This can happen when the model lacks the sets or functions necessary to witness the infinitude of these sets.) On account of the incompleteness theorems, no first-order predicate, nor even any recursive scheme of first-order predicates, can characterize the standard part of all such models. So, at least from the point of view of first-order logic, one can only hope to describe finiteness approximately.

More generally, informal notions like set, and particularly finite set, may receive interpretations across a range of formal systems varying in their axiomatics and logical apparatus. The best known axiomatic set theories include Zermelo-Fraenkel set theory (ZF), Zermelo-Fraenkel set theory with the Axiom of Choice (ZFC), Von Neumann–Bernays–Gödel set theory (NBG), Non-well-founded set theory, Bertrand Russell's Type theory and all the theories of their various models. One may also choose among classical first-order logic, various higher-order logics and intuitionistic logic.

A formalist might see the meaning of "set" varying from system to system. Some kinds of Platonists might view particular formal systems as approximating an underlying reality.

In contexts where the notion of natural number sits logically prior to any notion of set, one can define a set "S" as finite if "S" admits a bijection to some set of natural numbers of the form formula_9. Mathematicians more typically choose to ground notions of number in set theory, for example they might model natural numbers by the order types of finite well-ordered sets. Such an approach requires a structural definition of finiteness that does not depend on natural numbers.

Various properties that single out the finite sets among all sets in the theory ZFC turn out logically inequivalent in weaker systems such as ZF or intuitionistic set theories. Two definitions feature prominently in the literature, one due to Richard Dedekind, the other to Kazimierz Kuratowski. (Kuratowski's is the definition used above.)

A set "S" is called Dedekind infinite if there exists an injective, non-surjective function formula_10. Such a function exhibits a bijection between "S" and a proper subset of "S", namely the image of "f". Given a Dedekind infinite set "S", a function "f", and an element "x" that is not in the image of "f", we can form an infinite sequence of distinct elements of "S", namely formula_11. Conversely, given a sequence in "S" consisting of distinct elements formula_12, we can define a function "f" such that on elements in the sequence formula_13 and "f" behaves like the identity function otherwise. Thus Dedekind infinite sets contain subsets that correspond bijectively with the natural numbers. Dedekind finite naturally means that every injective self-map is also surjective.

Readers unfamiliar with semilattices and other notions of abstract algebra may prefer an entirely elementary formulation. Kuratowski finite means "S" lies in the set "K"("S"), constructed as follows. Write "M" for the set of all subsets "X" of "P"("S") such that:
Then "K"("S") may be defined as the intersection of "M".

In ZF, Kuratowski finite implies Dedekind finite, but not vice versa. In the parlance of a popular pedagogical formulation, when the axiom of choice fails badly, one may have an infinite family of socks with no way to choose one sock from more than finitely many of the pairs. That would make the set of such socks Dedekind finite: there can be no infinite sequence of socks, because such a sequence would allow a choice of one sock for infinitely many pairs by choosing the first sock in the sequence. However, Kuratowski finiteness would fail for the same set of socks.

In ZF set theory without the axiom of choice, the following concepts of finiteness for a set "S" are distinct. They are arranged in strictly decreasing order of strength, i.e. if a set "S" meets a criterion in the list then it meets all of the following criteria. In the absence of the axiom of choice the reverse implications are all unprovable, but if the axiom of choice is assumed then all of these concepts are equivalent. (Note that none of these definitions need the set of finite ordinal numbers to be defined first; they are all pure "set-theoretic" definitions in terms of the equality and membership relations, not involving ω.)


The forward implications (from strong to weak) are theorems within ZF. Counter-examples to the reverse implications (from weak to strong) in ZF with urelements are found using model theory.

Most of these finiteness definitions and their names are attributed to by . However, definitions I, II, III, IV and V were presented in , together with proofs (or references to proofs) for the forward implications. At that time, model theory was not sufficiently advanced to find the counter-examples.

Each of the properties I-finite thru IV-finite is a notion of smallness in the sense that any subset of a set with such a property will also have the property. This is not true for V-finite thru VII-finite because they may have countably infinite subsets.




</doc>
<doc id="11745" url="https://en.wikipedia.org/wiki?curid=11745" title="Farmer Giles of Ham">
Farmer Giles of Ham

Farmer Giles of Ham is a comic Medieval fable written by J. R. R. Tolkien in 1937 and published in 1949. The story describes the encounters between Farmer Giles and a wily dragon named Chrysophylax, and how Giles manages to use these to rise from humble beginnings to rival the king of the land. It is cheerfully anachronistic and light-hearted, set in Britain in an imaginary period of the Dark Ages, and featuring mythical creatures, medieval knights, and primitive firearms. It is only tangentially connected with the author's Middle-earth legendarium: both were originally intended as essays in "English mythology".

The book was originally illustrated by Pauline Baynes. The story has appeared with other works by Tolkien in omnibus editions, including "The Tolkien Reader" and "Tales from the Perilous Realm".

Tolkien dedicated "Farmer Giles of Ham" to Cyril Hackett Wilkinson (1888–1960), a don he knew at Oxford University.

Farmer Giles ("Ægidius Ahenobarbus Julius Agricola de Hammo", "Giles Redbeard Julius, Farmer of Ham") is not a hero. He is fat and red-bearded and enjoys a slow, comfortable life. But a rather deaf and short-sighted giant blunders on to his land, and Giles manages to ward him away with a blunderbuss shot in his general direction. The people of the village cheer: Farmer Giles has become a hero. His reputation spreads across the kingdom, and he is rewarded by the King with a sword named Caudimordax ("Tailbiter")—which turns out to be a powerful weapon against dragons.

The giant, on returning home, relates to his friends that there are no more knights in the Middle Kingdom, just stinging flies—actually the scrap metal shot from the blunderbuss—and this entices a dragon, Chrysophylax Dives, to investigate the area. The terrified neighbours all expect the accidental hero Farmer Giles to deal with him.

The story parodies the great dragon-slaying traditions. The knights sent by the King to pursue the dragon are useless fops, more intent on "precedence and etiquette" than on the huge dragon footprints littering the landscape. The only part of a 'dragon' they know is the annual celebratory dragon-tail cake. Giles by contrast clearly recognises the danger, and resents being sent with them to face it. But hapless farmers can be forced to become heroes, and Giles shrewdly makes the best of the situation.

It has been suggested that the Middle Kingdom is based on early Mercia, and that Giles's break-away realm (the Little Kingdom) is based on Frithuwald's Surrey.

Tolkien, by profession a philologist, sprinkled several philological jokes into the tale, including a variety of ingeniously fake etymologies. Almost all the place-names are supposed to occur relatively close to Oxford, along the Thames, or along the route to London. At the end of the story, Giles is made Lord of Tame, and Count of Worminghall. The village of Oakley, burnt to the ground by the dragon early in the story, may also be named after Oakley, Buckinghamshire, near to Thame.

Tolkien insists, tongue in cheek, that the village of Thame originally referred to the Tame Dragon housed in it, and that "tame with an h is a folly without warrant." Another joke puts a question concerning the definition of blunderbuss to "the four wise clerks of Oxenford" (a reference to Chaucer's Clerk; Tolkien had worked for Henry Bradley, one of the four main editors of the "Oxford English Dictionary"):

A short gun with a large bore firing many balls or slugs, and capable of doing execution within a limited range without exact aim. (Now superseded, in civilised countries, by other firearms.)

and then satirises it with application to the situation at hand:

However, Farmer Giles's blunderbuss had a wide mouth that opened like a horn, and it did not fire balls or slugs, but anything that he could spare to stuff in. And it did not do execution, because he seldom loaded it, and never let it off. The sight of it was usually enough for his purpose. And this country was not yet civilised, for the blunderbuss was not superseded: it was indeed the only kind of gun that there was, and rare at that. 
As Tom Shippey points out: "Giles's blunderbuss ... defies the definition and works just the same." (Introduction to "Tales from the Perilous Realm").

Chrysophylax Dives ( ) is a comically villainous dragon. He stands midway between Smaug, evil and greedy, and The Reluctant Dragon, comical and timid. "Chrysophýlax" () is Greek for "gold-guard" and () is Latin for "rich".

Chrysophylax comes across as a pompous aristocrat—rich, vain, and arrogant, but capable of compromise if handled correctly. Farmer Giles learns that he can be bullied, but is smart enough not to push him to desperation.

Caudimordax is the Latin name of "Tailbiter", the sword of Farmer Giles. The sword cannot be sheathed when a dragon comes within five miles of its bearer's presence. Four generations earlier, the sword belonged to Bellomarius, "the greatest of all the dragon-slayers" in the Middle Kingdom. Farmer Giles is granted this antiquated sword—by then become unfashionable—as a reward for driving off a giant from his fields with his blunderbuss. He later uses the sword to capture and control the dragon.

Garm is the talking dog. The dog is both vain of his master and cowardly. The name is derived from the Norse mythological dog of the same name, Garm.

Pauline Baynes drew Garm as a Greyhound, but Alan Lee drew him as a Mastiff.

This 2008 reprint:

This special edition was published in 1999 to celebrate the Golden Anniversary of this classic. The publisher in the United States is Houghton Mifflin. The edition includes:


</doc>
<doc id="11748" url="https://en.wikipedia.org/wiki?curid=11748" title="List of freshwater aquarium fish species">
List of freshwater aquarium fish species

A vast number of aquatic species have successfully adapted to live in the freshwater aquarium. This list gives some examples of the most common species found in home aquariums.



</doc>
<doc id="11749" url="https://en.wikipedia.org/wiki?curid=11749" title="List of chess players">
List of chess players

This list of chess players includes people who are primarily known as chess players and have an article on the English Wikipedia.




























The people in this list are famous in other areas of activity, but are known to have played chess, or have declared an interest in the game, or created works of art and literature in which the game is prominently featured.





</doc>
<doc id="11751" url="https://en.wikipedia.org/wiki?curid=11751" title="Foresight Institute">
Foresight Institute

The Foresight Institute is a Palo Alto, California-based research non-profit that promotes the development of nanotechnology and other emerging technologies. The institute holds conferences on molecular nanotechnology and awards yearly prizes for developments in the field. 

The Foresight Institute and its founder Eric Drexler have been criticized for unrealistic expectations, ignoring quantum effects in their design, lack of practical output, and technical obsolescence.

The Foresight Institute was founded in 1986 by Christine Peterson, K. Eric Drexler, and James C. Bennett to support the development of nanotechnology. Many of the institute's initial members came to it from the L5 Society, who were hoping to form a smaller group more focused on nanotechnology. In 1991, the Foresight Institute created two suborganizations with funding from tech entrepreneur Mitch Kapor; the Institute for Molecular Manufacturing and the Center for Constitutional Issues in Technology. In the 1990s, the Foresight Institute launched several initiatives to provide funding to developers of nanotechnology. In 1993, it created the Feynman Prize in Nanotechnology, named after physicist Richard Feynman. In May 2005, the Foresight Institute changed its name to "Foresight Nanotech Institute", though it reverted to its original name in June 2009.

The Feynman Prize in Nanotechnology is an award given by the Foresight Institute for significant advances in nanotechnology. Between 1993 and 1997, one prize was given biennially. Since 1997, two prizes have been given each year, divided into the categories of theory and experimentation. The prize is named in honor of physicist Richard Feynman, whose 1959 talk "There's Plenty of Room at the Bottom" is considered to have inspired and informed the start of the field of nanotechnology. Author Colin Milburn refers to the prize as an example of "fetishizing" its namesake Feynman, due to his "prestige as a scientist and his fame among the broader public."

The Foresight Institute also offers the Feynman Grand Prize, a $250,000 award to the first persons to create both a nanoscale robotic arm capable of precise positional control and a nanoscale 8-bit adder, with both conditions conforming to given specifications. The Feynman Grand Prize is intended to emulate historical prizes such as the Longitude prize, Orteig Prize, Kremer prize, Ansari X Prize, and two prizes that were offered by Richard Feynman personally as challenges during his 1959 "There's Plenty of Room at the Bottom" talk. In 2004, X-Prize Foundation founder Peter Diamandis was selected to chair the Feynman Grand Prize committee.




</doc>
<doc id="11752" url="https://en.wikipedia.org/wiki?curid=11752" title="List of freshwater aquarium invertebrate species">
List of freshwater aquarium invertebrate species

This is a list of invertebrates, animals without a backbone, that are commonly kept in freshwater aquaria by hobby aquarists. Numerous shrimp species of various kinds, crayfish, a number of freshwater snail species, and at least one freshwater clam species are found in freshwater aquaria.









</doc>
<doc id="11753" url="https://en.wikipedia.org/wiki?curid=11753" title="List of freshwater aquarium plant species">
List of freshwater aquarium plant species

Aquatic plants are used to give the freshwater aquarium a natural appearance, oxygenate the water, absorb ammonia, and provide habitat for fish, especially fry (babies) and for invertebrates. Some aquarium fish and invertebrates also eat live plants. Hobbyists use aquatic plants for aquascaping, of several aesthetic styles.

Most of these plant species are found either partially or fully submerged in their natural habitat. Although there are a handful of obligate aquatic plants that must be grown entirely underwater, most can grow fully emersed if the soil is moist. Though some are just living at the water margins, still, they can live in the completely submerged habitat.

The taxonomy of most plant genera is not final. Scientific names listed here may, therefore, contradict other sources.

Common aquarium plant species:

Several species of terrestrial plants are frequently sold as "aquarium plants". While such plants are beautiful and can survive and even flourish for months under water, they will eventually die and must be removed so their decay does not contaminate the aquarium water. These plants have no necessary biology to live underwater.





</doc>
<doc id="11754" url="https://en.wikipedia.org/wiki?curid=11754" title="Fonni">
Fonni

Fonni () is a town and "comune" in Sardinia, in the province of Nuoro (Italy).

It is the highest town in Sardinia, and situated among fine scenery with some chestnut woods. Fonni is a winter sports centre with a ski lift to Monte Spada and Bruncu Spina.

The term "Fonni/-e" probably derives from the Latin "fons", meaning "fountain" or "god of the sources". In fact the village contains numerous spring water fountains.

The local costumes are extremely picturesque, and are well seen on the day of St John the Baptist, the patron saint. The men's costume is similar to that worn in the district generally; the linen trousers are long and black gaiters are worn. The women wear a white chemise; over that a very small corselet, and over that a red jacket with blue and black velvet facings. The skirt is brown above and red below, with a blue band between the two colours; it is accordion-pleated. Two identical skirts are often worn, one above the other. The unmarried girls wear white kerchiefs, the married women black.

Neighborhoods in Fonni are called "Rioni" of these the oldest is called "su piggiu" or the peak, probably derived by the fact this is the highest and first layer of the village. Others include "puppuai" and "cresiedda" to the south, and "logotza" to the east.


</doc>
<doc id="11755" url="https://en.wikipedia.org/wiki?curid=11755" title="Fasces">
Fasces

Fasces ( , ; a "plurale tantum", from the Latin word "fascis", meaning "bundle"; ) is a bound bundle of wooden rods, sometimes including an axe with its blade emerging. The fasces had its origin in the Etruscan civilization and was passed on to ancient Rome, where it symbolized a magistrate's power and jurisdiction. The axe originally associated with the symbol, the Labrys (Greek: , "") the double-bitted axe, originally from Crete, is one of the oldest symbols of Greek civilization. To the Romans, it was known as a "bipennis".

The image has survived in the modern world as a representation of magisterial or collective power, law and governance. The fasces frequently occurs as a charge in heraldry: it is present on the reverse of the US Mercury dime coin and behind the podium in the United States House of Representatives; and it was the origin of the name of the National Fascist Party in Italy (from which the term "fascism" is derived).

During the first half of the twentieth century both the fasces and the swastika (each symbol having its own unique ancient religious and mythological associations) became heavily identified with the authoritarian/fascist political movements of Adolf Hitler and Benito Mussolini. During this period the swastika became deeply stigmatized, but the fasces did not undergo a similar process.

The fact that the fasces remained in use in many societies after World War II may have been due to the fact that prior to Mussolini the fasces had already been adopted and incorporated within the governmental iconography of many governments outside Italy. As such, its use persists as an accepted form of governmental and other iconography in various contexts. (The swastika remains in common usage in parts of Asia for religious purposes which are also unrelated to early twentieth century European fascism.)

The fasces is sometimes confused with the related term "fess", which in French heraldry is called a "fasce".

A few artifacts found showing a thin bundle of rods surrounding a two-headed axe point to a possible Etruscan origin for fasces, but little is known about the Etruscans themselves. Fasces symbolism might be derived via the Etruscans from the eastern Mediterranean, with the labrys, the Anatolian, and Minoan double-headed axe, later incorporated into the praetorial fasces. There is little archaeological evidence for precise claims.

By the time of the Roman Republic, the fasces had developed into a thicker bundle of birch rods, sometimes surrounding a single-headed axe and tied together with a red leather ribbon into a cylinder. On certain special occasions, the fasces might be decorated with a laurel wreath.

The symbolism of the fasces could suggest strength through unity (see Unity makes strength); a single rod is easily broken, while the bundle is very difficult to break. This symbolism occurs in Aesop's fable "The Old Man and his Sons". A similar story is told about the Bulgar (pre-Bulgarian, proto-Bulgarian) Khan Kubrat, giving rise to the Bulgarian national motto "Union gives strength" (Съединението прави силата). However, bundled birch twigs could also symbolise corporal punishment (see birching).

The "fasces lictoriae" ("bundles of the lictors") symbolised power and authority ("imperium") in ancient Rome, beginning with the early Roman Kingdom and continuing through the republican and imperial periods. By republican times, use of the fasces was surrounded with tradition and protocol. A corps of "apparitores" (subordinate officials) called lictors each carried fasces before a magistrate, in a number corresponding to his rank. Lictors preceded consuls (and proconsuls), praetors (and propraetors), dictators, curule aediles, quaestors, and the Flamen Dialis during Roman triumphs (public celebrations held in Rome after a military conquest).

According to Livy, it is likely that the lictors were an Etruscan tradition, adopted by Rome. The highest magistrate, the "dictator", was entitled to twenty-four lictors and fasces, the consul to twelve, the proconsul eleven, the praetor six (two within the "pomerium"), the propraetor five, and the curule aediles two.

Another part of the symbolism developed in Republican Rome was the inclusion of just a single-headed axe in the fasces, with the blade projecting from the bundle. The axe indicated that the magistrate's judicial powers ("imperium") included capital punishment. Fasces carried within the "Pomerium"—the boundary of the sacred inner city of Rome—had their axe blades removed; within the city, the power of life and death rested with the people through their assemblies. During times of emergency, however, the Roman Republic might choose a dictator to lead for a limited time period, who was the only magistrate to be granted capital punishment authority within the Pomerium. Lictors attending the dictator kept the axes in their fasces even inside the Pomerium—a sign that the dictator had the ultimate power in his own hands. There were exceptions to this rule: in 48 BC, guards holding bladed fasces guided Vatia Isauricus to the tribunal of Marcus Caelius, and Vatia Isauricus used one to destroy Caelius's magisterial chair ("sella curulis").

An occasional variation on the fasces was the addition of a laurel wreath, symbolizing victory. This occurred during the celebration of a "Triumph" - essentially a victory parade through Rome by a returning victorious general. Previously, all Republican Roman commanding generals had held high office with imperium, and so, already were entitled to the lictors and fasces.

The modern Italian word "fascio", used in the twentieth century to designate peasant cooperatives and industrial workers' unions, is related to "fasces".

Numerous governments and other authorities have used the image of the "fasces" as a symbol of power since the end of the Roman Empire. It also has been used to hearken back to the Roman republic, particularly by those who see themselves as modern-day successors to the old republic or its ideals.

The Ecuadorian coat of arms incorporated the fasces in 1830, although it had already been in use in the of Gran Colombia.

Italian Fascism, which derives its name from the "fasces", arguably used this symbolism the most in the twentieth century. The British Union of Fascists also used it in the 1930s. The "fasces", as a widespread and long-established symbol in the West, however, has avoided the stigma associated with much of fascist symbolism, and many authorities continue to display them, including the federal government of the United States.

A review of the images included in "Les Grands Palais de France "Fontainebleau" " reveals that French architects used the Roman fasces ("faisceaux romains") as a decorative device as early as the reign of Louis XIII (1610–1643) and continued to employ it through the periods of Napoleon I's Empire (1804–1815).

The fasces typically appeared in a context reminiscent of the Roman Republic and of the Roman Empire. The French Revolution used many references to the ancient Roman Republic in its imagery. During the First Republic, topped by the Phrygian cap, the fasces is a tribute to the Roman Republic and means that power belongs to the people. It also symbolizes the "unity and indivisibility of the Republic", as stated in the French Constitution. In 1848 and after 1870, it appears on the seal of the French Republic, held by the figure of Liberty. There is the fasces in the arms of the French Republic with the "RF" for "République française" (see image below), surrounded by leaves of olive tree (as a symbol of peace) and oak (as a symbol of justice). While it is used widely by French officials, this symbol never was officially adopted by the government.

The fasces appears on the helmet and the buckle insignia of the French Army's Autonomous Corps of Military Justice, as well as on that service's distinct cap badges for the prosecuting and defending lawyers in a court-martial.

Since the original founding of the United States in the 18th century, several offices and institutions in the United States have heavily incorporated representations of the "fasces" into much of their iconography.




The following cases all involve the adoption of the fasces as a symbol or icon, although no physical re-introduction has occurred.




</doc>
<doc id="11757" url="https://en.wikipedia.org/wiki?curid=11757" title="Fast combat support ship">
Fast combat support ship

The fast combat support ship (US Navy hull classification symbol: AOE) is the United States Navy's largest combat logistics ship, designed as an oiler, ammunition and supply ship. All fast combat support ships currently in service are operated by Military Sealift Command. They can carry more than 177,000 barrels of oil, 2,150 tons of ammunition, 500 tons of dry stores and 250 tons of refrigerated stores. It receives petroleum products, ammunition and stores from various shuttle ships and redistributes these items when needed to ships in the carrier battle group. This greatly reduces the number of service ships needed to travel with carrier battle groups. 

The four ships of the were 53,000 tons at full load, 796 feet overall length, and carried two Boeing Vertol CH-46 Sea Knight helicopters. The "Sacramento" class was retired in 2005.

The ships displace 48,800 tons full load and carried two Boeing Vertol CH-46 Sea Knight helicopters or two Sikorsky MH-60S Knighthawk helicopters.

Air defense includes the Sea Sparrow radar and infrared surface-to-air missile in eight-cell launchers to provide point defence with 15km to 25km range. There are also two Phalanx mk15 20mm gatling gun close-in weapon systems (CIWS) and two 25mm Raytheon mk88 guns.

China has developed the Type 901 fast combat support ship which serves a similar mission in their navy. 





</doc>
<doc id="11758" url="https://en.wikipedia.org/wiki?curid=11758" title="FASA">
FASA

FASA Corporation was an American publisher of role-playing games, wargames and board games between 1980 and 2001, after which they closed publishing operations for several years, becoming an IP holding company under the name FASA Inc. In 2012, a wholly owned subsidiary called FASA Games Inc. went into operation, using the name and logo under license from the parent company. FASA Games Inc. works alongside Ral Partha Europe, also a subsidiary of FASA Corporation, to bring out new editions of existing properties such as Earthdawn and Demonworld, and to develop new properties within the FASA cosmology.

FASA first appeared as a "Traveller" licensee, producing supplements for that Game Designers' Workshop role-playing game, especially the work of the Keith Brothers. The company went on to establish itself as a major gaming company with the publication of the first licensed "Star Trek" RPG, then several successful original games. Noteworthy lines included "BattleTech" and "Shadowrun". Their "Star Trek" role-playing supplements and tactical ship game enjoyed popularity outside the wargaming community since, at the time, official descriptions of the "Star Trek" universe were not common, and the gaming supplements offered details fans craved.

The highly successful "BattleTech" line led to a series of video games, some of the first virtual reality gaming suites, called Virtual World (created by a subdivision of the company known at the time of development as ESP, an acronym for "Extremely Secret Project") and a Saturday-morning .

Originally the name FASA was an acronym for "Freedonian Aeronautics and Space Administration", a joking allusion to the Marx Brothers film "Duck Soup". This tongue-in-cheek attitude was carried over in humorous self-references in its games. For example, in "Shadowrun", a tactical nuclear device was detonated near FASA's offices at 1026 W. Van Buren St in Chicago, Illinois.

FASA Corporation was founded by Jordan Weisman and L. Ross Babcock III in 1980 with a starting capital of $350. The two were fellow gamers at the United States Merchant Marine Academy. Mort Weisman, Jordan's father, joined the company in 1985 to lead the company's operational management having sold his book publishing business, Swallow Press.

Under the new commercial direction and with Mort's capital injection, the company diversified into books and miniature figures. After consulting their UK distributor, Chart Hobby Distributors, FASA licensed the manufacture of its "BattleTech" figurines to Miniature Figurines (also known as Minifigs). FASA would later acquire the U.S. figures manufacturer Ral Partha, which was the US manufacturer of Minifigs. While Mort ran the paper and metal based sides of the business, the company's founders focused on the development of computer-based games. They were particularly interested in virtual reality (particularly the BattleTech Centers / Virtual World) but also developed desktop computer games.

When Microsoft acquired the FASA Interactive subsidiary, Babcock went with that company. After the sale of Virtual World, Jordan turned his attention to the founding of a new games venture called WizKids.

FASA unexpectedly ceased active operations on April 30, 2001, but still exists as a corporation holding intellectual property rights, which it licenses to other publishers. Contrary to popular belief, the company did not go bankrupt. Allegedly the owners decided to quit while the company was still financially sound in a market they perceived as going downhill. Mort Weisman had been talking of retirement for some years and his confidence in the future of the paper-based games business was low. He considered the intellectual property of FASA to be of high value but did not wish to continue working as he had been for the last decade or more. Unwilling to wrestle with the complexities of dividing up the going concern, the owners issued a press release on January 25, 2001 announcing the immediate closure of the business.

The "BattleTech" and "Shadowrun" properties were sold to WizKids, who in turn licensed their publication to FanPro LLC and then to Catalyst Game Labs. The "Earthdawn" license was sold to WizKids, and then back to FASA. Living Room Games published "Earthdawn" (Second Edition), RedBrick published "Earthdawn" (Classic and Third Editions), but the license has now returned to FASA Corporation, and FASA Games, Inc. is the current license holder for new material. "Crimson Skies" was originally developed by Zipper Interactive under the FASA Interactive brand in late 2000 and used under license by FASA; FASA Interactive had been purchased by Microsoft, so rights to "Crimson Skies" stayed with Microsoft. Rights to the miniatures game "" reverted to the designer Mike "Skuzzy" Nielsen, but it has not been republished in any form due partly to legal difficulties. Microsoft officially closed the FASA team in the company's gaming division on September 12, 2007.

On December 6, 2007, FASA founder Jordan Weisman announced that his new venture, Smith & Tinker, had licensed the electronic gaming rights to "MechWarrior", "Shadowrun", and "Crimson Skies" from Microsoft.
On April 28, 2008 Mike "Skuzzy" Nielsen announced plans to create " 2.0".
At Gen Con 2012, FASA Games, Inc. was revealed, which includes FASA Corporation co-founder Ross Babcock on the Board of Directors. While FASA Corporation still owns and manages the FASA IP and brands, FASA Games, Inc. has announced its intention to develop new games under the FASA banner.







</doc>
<doc id="11759" url="https://en.wikipedia.org/wiki?curid=11759" title="McDonnell Douglas F-4 Phantom II">
McDonnell Douglas F-4 Phantom II

The McDonnell Douglas F-4 Phantom II is a tandem two-seat, twin-engine, all-weather, long-range supersonic jet interceptor and fighter-bomber originally developed for the United States Navy by McDonnell Aircraft. It first entered service in 1960 with the Navy. Proving highly adaptable, it was also adopted by the United States Marine Corps and the United States Air Force, and by the mid-1960s had become a major part of their air arms.

The Phantom is a large fighter with a top speed of over Mach 2.2. It can carry more than 18,000 pounds (8,400 kg) of weapons on nine external hardpoints, including air-to-air missiles, air-to-ground missiles, and various bombs. The F-4, like other interceptors of its time, was initially designed without an internal cannon. Later models incorporated an M61 Vulcan rotary cannon. Beginning in 1959, it set 15 world records for in-flight performance, including an absolute speed record and an absolute altitude record.

The F-4 was used extensively during the Vietnam War. It served as the principal air superiority fighter for the U.S. Air Force, Navy, and Marine Corps and became important in the ground-attack and aerial reconnaissance roles late in the war. During the Vietnam War, one U.S. Air Force pilot, two weapon systems officers (WSOs), one U.S. Navy pilot and one radar intercept officer (RIO) became aces by achieving five aerial kills against enemy fighter aircraft. The F-4 continued to form a major part of U.S. military air power throughout the 1970s and 1980s, being gradually replaced by more modern aircraft such as the F-15 Eagle and F-16 Fighting Falcon in the U.S. Air Force, the F-14 Tomcat in the U.S. Navy, and the F/A-18 Hornet in the U.S. Navy and U.S. Marine Corps.

The F-4 Phantom II remained in use by the U.S. in the reconnaissance and Wild Weasel (Suppression of Enemy Air Defenses) roles in the 1991 Gulf War, finally leaving service in 1996. It was also the only aircraft used by both U.S. flight demonstration teams: the United States Air Force Thunderbirds (F-4E) and the United States Navy Blue Angels (F-4J). The F-4 was also operated by the armed forces of 11 other nations. Israeli Phantoms saw extensive combat in several Arab–Israeli conflicts, while Iran used its large fleet of Phantoms, acquired before the fall of the Shah, in the Iran–Iraq War. Phantom production ran from 1958 to 1981, with a total of 5,195 built, making it the most produced American supersonic military aircraft. As of 2018, 60 years after its first flight, the F-4 remains in service with Iran, Japan, South Korea, Greece, and Turkey. The aircraft has most recently been in service against the Islamic State group in the Middle East.

In 1952, McDonnell's Chief of Aerodynamics, Dave Lewis, was appointed by CEO Jim McDonnell to be the company's preliminary design manager. With no new aircraft competitions on the horizon, internal studies concluded the Navy had the greatest need for a new and different aircraft type: an attack fighter.
In 1953, McDonnell Aircraft began work on revising its F3H Demon naval fighter, seeking expanded capabilities and better performance. The company developed several projects, including a variant powered by a Wright J67 engine, and variants powered by two Wright J65 engines, or two General Electric J79 engines. The J79-powered version promised a top speed of Mach 1.97. On 19 September 1953, McDonnell approached the United States Navy with a proposal for the "Super Demon". Uniquely, the aircraft was to be modular, as it could be fitted with one- or two-seat noses for different missions, with different nose cones to accommodate radar, photo cameras, four 20 mm (.79 in) cannon, or 56 FFAR unguided rockets in addition to the nine hardpoints under the wings and the fuselage. The Navy was sufficiently interested to order a full-scale mock-up of the F3H-G/H, but felt that the upcoming Grumman XF9F-9 and Vought XF8U-1 already satisfied the need for a supersonic fighter.

The McDonnell design was therefore reworked into an all-weather fighter-bomber with 11 external hardpoints for weapons and on 18 October 1954, the company received a letter of intent for two YAH-1 prototypes. Then on 26 May 1955, four Navy officers arrived at the McDonnell offices and, within an hour, presented the company with an entirely new set of requirements. Because the Navy already had the Douglas A-4 Skyhawk for ground attack and F-8 Crusader for dogfighting, the project now had to fulfill the need for an all-weather fleet defense interceptor. A second crewman was added to operate the powerful radar.

The XF4H-1 was designed to carry four semi-recessed AAM-N-6 Sparrow III radar-guided missiles, and to be powered by two J79-GE-8 engines. As in the McDonnell F-101 Voodoo, the engines sat low in the fuselage to maximize internal fuel capacity and ingested air through fixed geometry intakes. The thin-section wing had a leading edge sweep of 45° and was equipped with blown flaps for better low-speed handling.

Wind tunnel testing had revealed lateral instability, requiring the addition of 5° dihedral to the wings. To avoid redesigning the titanium central section of the aircraft, McDonnell engineers angled up only the outer portions of the wings by 12°, which averaged to the required 5° over the entire wingspan. The wings also received the distinctive "dogtooth" for improved control at high angles of attack. The all-moving tailplane was given 23° of anhedral to improve control at high angles of attack, while still keeping the tailplane clear of the engine exhaust. In addition, air intakes were equipped with variable geometry ramps to regulate airflow to the engines at supersonic speeds. All-weather intercept capability was achieved thanks to the AN/APQ-50 radar. To accommodate carrier operations, the landing gear was designed to withstand landings with a sink rate of , while the nose strut could extend by some to increase angle of attack at takeoff.
On 25 July 1955, the Navy ordered two XF4H-1 test aircraft and five YF4H-1 pre-production examples. The Phantom made its maiden flight on 27 May 1958 with Robert C. Little at the controls. A hydraulic problem precluded retraction of the landing gear, but subsequent flights went more smoothly. Early testing resulted in redesign of the air intakes, including the distinctive addition of 12,500 holes to "bleed off" the slow-moving boundary layer air from the surface of each intake ramp. Series production aircraft also featured splitter plates to divert the boundary layer away from the engine intakes. The aircraft soon squared off against the XF8U-3 Crusader III. Due to operator workload, the Navy wanted a two-seat aircraft and on 17 December 1958 the F4H was declared a winner. Delays with the J79-GE-8 engines meant that the first production aircraft were fitted with J79-GE-2 and −2A engines, each having 16,100 lbf (71.8 kN) of afterburning thrust. In 1959, the Phantom began carrier suitability trials with the first complete launch-recovery cycle performed on 15 February 1960 from .

There were proposals to name the F4H "Satan" and "Mithras". In the end, the aircraft was given the less controversial name "Phantom II", the first "Phantom" being another McDonnell jet fighter, the FH-1 Phantom. The Phantom II was briefly given the designation F-110A and the name "Spectre" by the USAF, but neither name was officially used.

Early in production, the radar was upgraded to the Westinghouse AN/APQ-72, an AN/APG-50 with a larger radar antenna, necessitating the bulbous nose, and the canopy was reworked to improve visibility and make the rear cockpit less claustrophobic. During its career the Phantom underwent many changes in the form of numerous variants developed.

The USN operated the F4H-1 (re-designated F-4A in 1962) with J79-GE-2 and -2A engines of 16,100 lbf (71.62 kN) thrust and later builds receiving -8 engines. A total of 45 F-4As were built; none saw combat, and most ended up as test or training aircraft. The USN and USMC received the first definitive Phantom, the F-4B which was equipped with the Westinghouse APQ-72 radar (pulse only), a Texas Instruments AAA-4 Infra-red search and track pod under the nose, an AN/AJB-3 bombing system and powered by J79-GE-8,-8A and -8B engines of 10,900 lbf (48.5 kN) dry and 16,950 lbf (75.4 kN) afterburner (reheat) with the first flight on 25 March 1961. 649 F-4Bs were built with deliveries beginning in 1961 and VF-121 Pacemakers receiving the first examples at NAS Miramar.

The USAF received Phantoms as the result of Defense Secretary Robert McNamara's push to create a unified fighter for all branches of the US military. After an F-4B won the "Operation Highspeed" fly-off against the Convair F-106 Delta Dart, the USAF borrowed two Naval F-4Bs, temporarily designating them F-110A "Spectre" in January 1962, and developed requirements for their own version. Unlike the US Navy's focus on air-to-air interception in the Fleet Air Defense (FAD) mission, the USAF emphasized both an air-to-air and an air-to-ground fighter-bomber role. With McNamara's unification of designations on 18 September 1962, the Phantom became the F-4 with the naval version designated F-4B and USAF F-4C. The first Air Force Phantom flew on 27 May 1963, exceeding Mach 2 on its maiden flight.

The F-4J improved both air-to-air and ground-attack capability; deliveries begun in 1966 and ended in 1972 with 522 built. It was equipped with J79-GE-10 engines with 17,844 lbf (79.374 kN) thrust, the Westinghouse AN/AWG-10 Fire Control System (making the F-4J the first fighter in the world with operational look-down/shoot-down capability), a new integrated missile control system and the AN/AJB-7 bombing system for expanded ground attack capability.

The F-4N (updated F-4Bs) with smokeless engines and F-4J aerodynamic improvements started in 1972 under a U.S. Navy-initiated refurbishment program called "Project Bee Line" with 228 converted by 1978. The F-4S model resulted from the refurbishment of 265 F-4Js with J79-GE-17 smokeless engines of 17,900 lbf (79.379 kN), AWG-10B radar with digitized circuitry for improved performance and reliability, Honeywell AN/AVG-8 Visual Target Acquisition Set or VTAS (world's first operational Helmet Sighting System), classified avionics improvements, airframe reinforcement and leading edge slats for enhanced maneuvering. The USMC also operated the RF-4B with reconnaissance cameras with 46 built.

Phantom II production ended in the United States in 1979 after 5,195 had been built (5,057 by McDonnell Douglas and 138 in Japan by Mitsubishi). Of these, 2,874 went to the USAF, 1,264 to the Navy and Marine Corps, and the rest to foreign customers. The last U.S.-built F-4 went to South Korea, while the last F-4 built was an F-4EJ built by Mitsubishi Heavy Industries in Japan and delivered on 20 May 1981. As of 2008, 631 Phantoms were in service worldwide, while the Phantoms were in use as a target drone (specifically QF-4Cs) operated by the U.S. military until 21 December 2016, when the Air Force officially ended use of the type.

To show off their new fighter, the Navy led a series of record-breaking flights early in Phantom development: All in all, the Phantom set 16 world records. Except for Skyburner, all records were achieved in unmodified production aircraft. Five of the speed records remained unbeaten until the F-15 Eagle appeared in 1975.


The F-4 Phantom is a tandem-seat fighter-bomber designed as a carrier-based interceptor to fill the U.S. Navy's fleet defense fighter role. Innovations in the F-4 included an advanced pulse-Doppler radar and extensive use of titanium in its airframe.

Despite imposing dimensions and a maximum takeoff weight of over 60,000 lb (27,000 kg), the F-4 has a top speed of Mach 2.23 and an initial climb rate of over 41,000 ft/min (210 m/s). The F-4's nine external hardpoints have a capability of up to 18,650 pounds (8,480 kg) of weapons, including air-to-air and air-to-surface missiles, and unguided, guided, and thermonuclear weapons. Like other interceptors of its day, the F-4 was designed without an internal cannon.

The baseline performance of a Mach 2-class fighter with long range and a bomber-sized payload would be the template for the next generation of large and light/middle-weight fighters optimized for daylight air combat.

In air combat, the Phantom's greatest advantage was its thrust, which permitted a skilled pilot to engage and disengage from the fight at will. As a massive fighter aircraft designed to fire radar-guided missiles from beyond visual range, it lacked the agility of its Soviet opponents and was subject to adverse yaw during hard maneuvering. Although thus subject to irrecoverable spins during aileron rolls, pilots reported the aircraft to be very responsive and easy to fly on the edge of its performance envelope. In 1972, the F-4E model was upgraded with leading edge slats on the wing, greatly improving high angle of attack maneuverability at the expense of top speed.
The J79 engines produced noticeable amounts of black smoke (at mid-throttle/cruise settings), a severe disadvantage in that it made it easier for the enemy to spot the aircraft. This was solved on the F-4S, which was fitted with the −10A engine variant with a smokeless combustor.

The F-4's biggest weakness, as it was initially designed, was its lack of an internal cannon. For a brief period, doctrine held that turning combat would be impossible at supersonic speeds and little effort was made to teach pilots air combat maneuvering. In reality, engagements quickly became subsonic, as pilots would slow down in an effort to get behind their adversaries. Furthermore, the relatively new heat-seeking and radar-guided missiles at the time were frequently reported as unreliable and pilots had to fire multiple missiles (also known as ripple-firing), just to hit one enemy fighter. To compound the problem, rules of engagement in Vietnam precluded long-range missile attacks in most instances, as visual identification was normally required. Many pilots found themselves on the tail of an enemy aircraft, but too close to fire short-range Falcons or Sidewinders. Although by 1965 USAF F-4Cs began carrying SUU-16 external gunpods containing a 20 mm (.79 in) M61A1 Vulcan Gatling cannon, USAF cockpits were not equipped with lead-computing gunsights until the introduction of the SUU-23, virtually assuring a miss in a maneuvering fight. Some Marine Corps aircraft carried two pods for strafing. In addition to the loss of performance due to drag, combat showed the externally mounted cannon to be inaccurate unless frequently boresighted, yet far more cost-effective than missiles. The lack of a cannon was finally addressed by adding an internally mounted 20 mm (.79 in) M61A1 Vulcan on the F-4E.

Note: Original amounts were in 1965 U.S. dollars. The figures in these tables have been adjusted for inflation to the current year.

In USAF service, the F-4 was initially designated the F-110 Spectre prior to the introduction of the 1962 United States Tri-Service aircraft designation system. The USAF quickly embraced the design and became the largest Phantom user. The first USAF Phantoms in Vietnam were F-4Cs from the 43rd Tactical Fighter Squadron arrived in December 1964.

Unlike the U.S. Navy and U.S. Marine Corps, which flew the Phantom with a Naval Aviator (pilot) in the front seat and a Naval Flight Officer as a radar intercept officer (RIO) in the back seat, the USAF initially flew its Phantoms with a rated Air Force Pilot in front and back seats. While the rear pilot (GIB, or "guy in back") could fly and ostensibly land the aircraft, he had fewer flight instruments and a very restricted forward view. The Air Force later assigned a rated Air Force Navigator qualified as a weapon/targeting systems officer (later designated as weapon systems officer or WSO) in the rear seat instead of another pilot.

On 10 July 1965, F-4Cs of the 45th Tactical Fighter Squadron, 15th TFW, on temporary assignment in Ubon, Thailand, scored the USAF's first victories against North Vietnamese MiG-17s using AIM-9 Sidewinder air-to-air missiles. On 26 April 1966, an F-4C from the 480th Tactical Fighter Squadron scored the first aerial victory by a U.S. aircrew over a North Vietnamese MiG-21 "Fishbed". On 24 July 1965, another Phantom from the 45th Tactical Fighter Squadron became the first American aircraft to be downed by an enemy SAM, and on 5 October 1966 an 8th Tactical Fighter Wing F-4C became the first U.S. jet lost to an air-to-air missile, fired by a MiG-21.

Early aircraft suffered from leaks in wing fuel tanks that required re-sealing after each flight and 85 aircraft were found to have cracks in outer wing ribs and stringers. There were also problems with aileron control cylinders, electrical connectors, and engine compartment fires. Reconnaissance RF-4Cs made their debut in Vietnam on 30 October 1965, flying the hazardous post-strike reconnaissance missions. The USAF Thunderbirds used the F-4E from the 1969 season until 1974.
Although the F-4C was essentially identical to the Navy/Marine Corps F-4B in flight performance and carried the AIM-9 Sidewinder missiles, USAF-tailored F-4Ds initially arrived in June 1967 equipped with AIM-4 Falcons. However, the Falcon, like its predecessors, was designed to shoot down heavy bombers flying straight and level. Its reliability proved no better than others and its complex firing sequence and limited seeker-head cooling time made it virtually useless in combat against agile fighters. The F-4Ds reverted to using Sidewinders under the "Rivet Haste" program in early 1968, and by 1972 the AIM-7E-2 "Dogfight Sparrow" had become the preferred missile for USAF pilots. Like other Vietnam War Phantoms, the F-4Ds were urgently fitted with radar warning receivers to detect the Soviet-built S-75 Dvina SAMs.

From the initial deployment of the F-4C to Southeast Asia, USAF Phantoms performed both air superiority and ground attack roles, supporting not only ground troops in South Vietnam, but also conducting bombing sorties in Laos and North Vietnam. As the F-105 force underwent severe attrition between 1965 and 1968, the bombing role of the F-4 proportionately increased until after November 1970 (when the last F-105D was withdrawn from combat) it became the primary USAF tactical ordnance delivery system. In October 1972 the first squadron of EF-4C Wild Weasel aircraft deployed to Thailand on temporary duty. The "E" prefix was later dropped and the aircraft was simply known as the F-4C Wild Weasel.
Sixteen squadrons of Phantoms were permanently deployed between 1965 and 1973, and 17 others deployed on temporary combat assignments. Peak numbers of combat F-4s occurred in 1972, when 353 were based in Thailand. A total of 445 Air Force Phantom fighter-bombers were lost, 370 in combat and 193 of those over North Vietnam (33 to MiGs, 30 to SAMs, and 307 to AAA).

The RF-4C was operated by four squadrons, and of the 83 losses, 72 were in combat including 38 over North Vietnam (seven to SAMs and 65 to AAA). By war's end, the U.S. Air Force had lost a total of 528 F-4 and RF-4C Phantoms. When combined with U.S. Navy and Marine Corps losses of 233 Phantoms, 761 F-4/RF-4 Phantoms were lost in the Vietnam War.

On 28 August 1972, Captain Steve Ritchie became the first USAF ace of the war. On 9 September 1972, WSO Capt Charles B. DeBellevue became the highest-scoring American ace of the war with six victories. and WSO Capt Jeffrey Feinstein became the last USAF ace of the war on 13 October 1972. Upon return to the United States, DeBellevue and Feinstein were assigned to undergraduate pilot training (Feinstein was given a vision waiver) and requalified as USAF pilots in the F-4. USAF F-4C/D/E crews claimed 107½ MiG kills in Southeast Asia (50 by Sparrow, 31 by Sidewinder, five by Falcon, 15.5 by gun, and six by other means).

On 31 January 1972, the 170th Tactical Fighter Squadron/183d Tactical Fighter Group of the Illinois Air National Guard became the first Air National Guard unit to transition to Phantoms from Republic F-84F Thunderstreaks which were found to have corrosion problems. Phantoms would eventually equip numerous tactical fighter and tactical reconnaissance units in the USAF active, National Guard, and reserve.

On 2 June 1972, a Phantom flying at supersonic speed shot down a MiG-19 over Thud Ridge in Vietnam for the first supersonic gun kill. At a recorded speed of Mach 1.2, Major Phil Handley's shoot down was the first and only recorded gun kill while flying at supersonic speeds.
On 15 August 1990, 24 F-4G Wild Weasel Vs and six RF-4Cs were deployed to Shaikh Isa AB, Bahrain, for Operation Desert Storm. The F-4G was the only aircraft in the USAF inventory equipped for the Suppression of Enemy Air Defenses (SEAD) role, and was needed to protect coalition aircraft from Iraq's extensive air defense system. The RF-4C was the only aircraft equipped with the ultra-long-range KS-127 LOROP (long-range oblique photography) camera, and was used for a variety of reconnaissance missions. In spite of flying almost daily missions, only one RF-4C was lost in a fatal accident before the start of hostilities. One F-4G was lost when enemy fire damaged the fuel tanks and the aircraft ran out of fuel near a friendly airbase. The last USAF Phantoms, F-4G Wild Weasel Vs from 561st Fighter Squadron, were retired on 26 March 1996. The last operational flight of the F-4G Wild Weasel was from the 190th Fighter Squadron, Idaho Air National Guard, in April 1996. The last operational USAF/ANG F-4 to land was flown by Maj Mike Webb and Maj Gary Leeder of the Idaho ANG.

Like the Navy, the Air Force has operated QF-4 target drones, serving with the 82d Aerial Targets Squadron at Tyndall Air Force Base, Florida, and Holloman Air Force Base, New Mexico. It was expected that the F-4 would remain in the target role with the 82d ATRS until at least 2015, when they would be replaced by early versions of the F-16 Fighting Falcon converted to a QF-16 configuration. Several QF-4s also retain capability as manned aircraft and are maintained in historical color schemes, being displayed as part of Air Combat Command's Heritage Flight at air shows, base open houses, and other events while serving as non-expendable target aircraft during the week. On 19 November 2013, BAE Systems delivered the last QF-4 aerial target to the Air Force. The example had been in storage for over 20 years before being converted. Over 16 years, BAE had converted 314 F-4 and RF-4 Phantom IIs into QF-4s and QRF-4s, with each aircraft taking six months to adapt. As of December 2013, QF-4 and QRF-4 aircraft had flown over 16,000 manned and 600 unmanned training sorties, with 250 unmanned aircraft being shot down in firing exercises. The remaining QF-4s and QRF-4s held their training role until the first of 126 QF-16s were delivered by Boeing. The final flight of an Air Force QF-4 from Tyndall AFB took place on 27 May 2015 to Holloman AFB. After Tyndall AFB ceased operations, the 53d Weapons Evaluation Group at Holloman became the fleet of 22 QF-4s' last remaining operator. The base continued using them to fly manned test and unmanned live fire test support and Foreign Military Sales testing, with the final unmanned flight taking place in August 2016. The type was officially retired from US military service with a four–ship flight at Holloman during an event on 21 December 2016. The remaining QF-4s were to be demilitarized after 1 January 2017.

On 30 December 1960, the VF-121 "Pacemakers" at NAS Miramar became the first Phantom operator with its F4H-1Fs (F-4As). The VF-74 "Be-devilers" at NAS Oceana became the first deployable Phantom squadron when it received its F4H-1s (F-4Bs) on 8 July 1961. The squadron completed carrier qualifications in October 1961 and Phantom's first full carrier deployment between August 1962 and March 1963 aboard . The second deployable U.S. Atlantic Fleet squadron to receive F-4Bs was the VF-102 "Diamondbacks", who promptly took their new aircraft on the shakedown cruise of . The first deployable U.S. Pacific Fleet squadron to receive the F-4B was the VF-114 "Aardvarks", which participated in the September 1962 cruise aboard .

By the time of the Tonkin Gulf incident, 13 of 31 deployable navy squadrons were armed with the type. F-4Bs from made the first Phantom combat sortie of the Vietnam War on 5 August 1964, flying bomber escort in Operation Pierce Arrow. The first Phantom air-to-air victory of the war took place on 9 April 1965 when an F-4B from VF-96 "Fighting Falcons" piloted by Lieutenant (junior grade) Terence M. Murphy and his RIO, Ensign Ronald Fegan, shot down a Chinese MiG-17 "Fresco". The Phantom was then shot down, probably by an AIM-7 Sparrow from one of its wingmen. There continues to be controversy over whether the Phantom was shot down by MiG guns or, as enemy reports later indicated, an AIM-7 Sparrow III from one of Murphy's and Fegan's wingmen. On 17 June 1965, an F-4B from VF-21 "Freelancers" piloted by Commander Louis Page and Lieutenant John C. Smith shot down the first North Vietnamese MiG of the war.

On 10 May 1972, Lieutenant Randy "Duke" Cunningham and Lieutenant (junior grade) William P. Driscoll flying an F-4J, call sign "Showtime 100", shot down three MiG-17s to become the first American flying aces of the war. Their fifth victory was believed at the time to be over a mysterious North Vietnamese ace, Colonel Nguyen Toon, now considered mythical. On the return flight, the Phantom was damaged by an enemy surface-to-air missile. To avoid being captured, Cunningham and Driscoll flew their burning aircraft using only the rudder and afterburner (the damage to the aircraft rendered conventional control nearly impossible), until they could eject over water.
During the war, U.S. Navy F-4 Phantom squadrons participated in 84 combat tours with F-4Bs, F-4Js, and F-4Ns. The Navy claimed 40 air-to-air victories at a cost of 73 Phantoms lost in combat (seven to enemy aircraft, 13 to SAMs, and 53 to AAA). An additional 54 Phantoms were lost in mishaps.

In 1984, all Navy F-4Ns were retired from Fleet service in deployable USN squadrons and by 1987 the last F-4Ss were retired from deployable USN squadrons. On 25 March 1986, an F-4S belonging to the VF-151 "Vigilantes," became the last active duty U.S. Navy Phantom to launch from an aircraft carrier, in this case, . On 18 October 1986, an F-4S from the VF-202 "Superheats", a Naval Reserve fighter squadron, made the last-ever Phantom carrier landing while operating aboard . In 1987, the last of the Naval Reserve-operated F-4S aircraft were replaced by F-14As. The last Phantoms in service with the Navy were QF-4N and QF-4S target drones operated by the Naval Air Warfare Center at NAS Point Mugu, California. These airframes were subsequently retired in 2004.

The Marine Corps received its first F-4Bs in June 1962, with the "Black Knights" of VMFA-314 at Marine Corps Air Station El Toro, California becoming the first operational squadron. Marine Phantoms from VMFA-531 "Gray Ghosts" were assigned to Da Nang airbase on South Vietnam's northeast coast on 10 May 1965 and were initially assigned to provide air defense for the USMC. They soon began close air support missions (CAS) and VMFA-314 'Black Knights', VMFA-232 'Red Devils, VMFA-323 'Death Rattlers', and VMFA-542 'Bengals' soon arrived at the primitive airfield. Marine F-4 pilots claimed three enemy MiGs (two while on exchange duty with the USAF) at the cost of 75 aircraft lost in combat, mostly to ground fire, and four in accidents. 

The VMCJ-1 Golden Hawks (later VMAQ-1 and VMAQ-4 which had the old RM tailcode) flew the first photo recon mission with an RF-4B variant on 3 November 1966 from Da Nang AB, South Vietnam and remained there until 1970 with no RF-4B losses and only one aircraft damaged by anti-aircraft artillery (AAA) fire. VMCJ-2 and VMCJ-3 (now VMAQ-3) provided aircraft for VMCJ-1 in Da Nang and VMFP-3 was formed in 1975 at MCAS El Toro, CA consolidating all USMC RF-4Bs in one unit that became known as "The Eyes of the Corps." VMFP-3 disestablished in August 1990 after the Advanced Tactical Airborne Reconnaissance System was introduced for the F/A-18D Hornet. 

The F-4 continued to equip fighter-attack squadrons in both active and reserve Marine Corps units throughout the 1960s, 1970s and 1980s and into the early 1990s. In the early 1980s, these squadrons began to transition to the F/A-18 Hornet, starting with the same squadron that introduced the F-4 to the Marine Corps, VMFA-314 at MCAS El Toro, California. On 18 January 1992, the last Marine Corps Phantom, an F-4S in the Marine Corps Reserve, was retired by the "Cowboys" of VMFA-112 at NAS Dallas, Texas, after which the squadron was re-equipped with F/A-18 Hornets.

The USAF and the US Navy had high expectations of the F-4 Phantom, assuming that the massive firepower, the best available on-board radar, the highest speed and acceleration properties, coupled with new tactics, would provide Phantoms with an advantage over the MiGs. However, in confrontations with the lighter MiG-21, F-4s did not always succeed and began to suffer losses. Over the course of the air war in Vietnam, between 3 April 1965 and 8 January 1973, each side would ultimately claim favorable kill ratios. 

During the war, U.S. Navy F-4 Phantoms downed 40 air-to-air victories at a loss of seven Phantoms to enemy aircraft. USMC F-4 pilots claimed three enemy MiGs at the cost of one aircraft in air-combat. USAF F-4 Phantom crews scored 107½ MiG kills (including 33½ MiG-17s, eight MiG-19s and 66 MiG-21s) at a cost of 33 Phantoms in air-combat. F-4 pilots were credited with a total of 150½ MiG kills at a cost of 42 Phantoms in air-combat.

According to the VPAF, 103 F-4 Phantoms were shot down by MiG-21s at a cost of 54 MiG-21s downed by F-4s. During the war, the VPAF lost 131 MiGs in air combat (63 MiG-17s, eight MiG-19s and 60 MiG-21s) of which one half were by F-4s.

From 1966 to November 1968, in 46 air battles conducted over North Vietnam between F-4s and MiG-21s, VPAF claimed 27 F-4s were shot down by MiG-21s at a cost of 20 MiG-21s In 1970, one F-4 Phantom was shot down by MiG-21. In 1972, total of 201 air battles took place between American and Vietnamese airplanes. The VPAF lost 54 MiGs (including 36 MiG-21s and one MiG-21) and claimed 90 U.S aircraft were shot down, including 74 F-4 Phantoms and two spy RF-4C (MiG-21s shot down 67 enemy aircraft. MiG-17 shot down 11 and MiG-19 shot down 12 enemy aircraft.) The struggle culminated on 10 May 1972, with VPAF aircraft completing 64 sorties, resulting in 15 air battles. The VPAF claimed seven F-4s were shot down, while U.S. confirmed five F-4s were lost. The Phantoms, in turn, managed to destroy two MiG-21s, three MiG-17s, and one MiG-19. On 11 May, two MiG-21s, which played the role of "bait", brought the four F-4s to two MiG-21s circling at low altitude. The MiGs quickly engaged and shot down two F-4s. On 18 May, Vietnamese aircraft made 26 sorties in eight air engagements, which cost 4 F-4 Phantoms; Vietnamese fighters on that day did not suffer losses.

The Phantom has served with the air forces of many countries, including Australia, Egypt, Germany, United Kingdom, Greece, Iran, Israel, Japan, Spain, South Korea and Turkey.

The Royal Australian Air Force (RAAF) leased 24 USAF F-4Es from 1970 to 1973 while waiting for their order for the General Dynamics F-111C to be delivered. They were so well-liked that the RAAF considered retaining the aircraft after the F-111Cs were delivered. They were operated from RAAF Amberley by No. 1 Squadron and No. 6 Squadron.

In 1979, the Egyptian Air Force purchased 35 former USAF F-4Es along with a number of Sparrow, Sidewinder, and Maverick missiles from the U.S. for $594 million as part of the "Peace Pharaoh" program. An additional seven surplus USAF aircraft were purchased in 1988. Three attrition replacements had been received by the end of the 1990s.

The German Air Force ("Luftwaffe") initially ordered the reconnaissance RF-4E in 1969, receiving a total of 88 aircraft from January 1971. In 1982, the initially unarmed RF-4Es were given a secondary ground attack capability; these aircraft were retired in 1994.
In 1973, under the "Peace Rhine" program, the "Luftwaffe" purchased the F-4F (a lightened and simplified version of the F-4E) which was upgraded in the mid-1980s. 24 German F-4F Phantom IIs were operated by the 49th Tactical Fighter Wing of the USAF at Holloman AFB to train "Luftwaffe" crews until December 2004. In 1975, Germany also received 10 F-4Es for training in the U.S. In the late 1990s, these were withdrawn from service after being replaced by F-4Fs. Germany also initiated the Improved Combat Efficiency (ICE) program in 1983. The 110 ICE-upgraded F-4Fs entered service in 1992, and were expected to remain in service until 2012. All the remaining Luftwaffe Phantoms were based at Wittmund with "Jagdgeschwader" 71 (fighter wing 71) in Northern Germany and WTD61 at Manching. Phantoms were deployed to NATO states under the Baltic Air Policing starting in 2005, 2008, 2009, 2011 and 2012. The German Air Force retired its last F-4Fs on 29 June 2013. German F-4Fs flew 279,000 hours from entering service on 31 August 1973 until retirement.

In 1971, the Hellenic Air Force ordered brand new F-4E Phantoms, with deliveries starting in 1974. In the early 1990s, the Hellenic AF acquired surplus RF-4Es and F-4Es from the "Luftwaffe" and U.S. ANG.

Following the success of the German ICE program, on 11 August 1997, a contract was signed between DASA of Germany and Hellenic Aerospace Industry for the upgrade of 39 aircraft to the very similar "Peace Icarus 2000" standard. The Hellenic AF operated 34 upgraded "F-4E-PI2000" (338 and 339 Squadrons) and 12 RF-4E aircraft (348 Squadron) as of September 2013.

On 5 May 2017, the Hellenic Air Force officially retired the RF-4E Phantom II during a public ceremony.

In the 1960s and 1970s when the U.S. and Iran were on friendly terms, the U.S. sold 225 F-4D, F-4E, and RF-4E Phantoms to Iran. The Imperial Iranian Air Force saw at least one engagement, resulting in a loss, after an RF-4C was rammed by a Soviet MiG-21 during Project Dark Gene, an ELINT operation during the Cold War.
The Islamic Republic of Iran Air Force Phantoms saw heavy action in the Iran–Iraq War in the 1980s and are kept operational by overhaul and servicing from Iran's aerospace industry. Notable operations of Iranian F-4s during the war included Operation Scorch Sword, an attack by two F-4s against the Iraqi Osirak nuclear reactor site near Baghdad on 30 September 1980, and the attack on H3, a 4 April 1981 strike by eight Iranian F-4s against the H-3 complex of air bases in the far west of Iraq, which resulted in many Iraqi aircraft being destroyed or damaged for no Iranian losses.

On 5 June 1984, two Saudi Arabian fighter pilots shot down two Iranian F-4 fighters. The Royal Saudi Air Force pilots were flying American-built F-15s and fired air-to-air missiles to bring down the Iranian planes. The Saudi fighter pilots had KC-135 aerial tanker planes and Boeing E-3 Sentry AWACS surveillance planes assist in the encounter. The aerial fight occurred in Saudi airspace over the Persian Gulf near the Saudi island Al Arabiyah, about 60 miles northeast of Jubail.

Iranian F-4s were in use as of late 2014; the aircraft reportedly conducted air strikes on ISIS targets in the eastern Iraqi province of Diyala.

The Israeli Air Force was the largest foreign operator of the Phantom, flying both newly built and ex-USAF aircraft, as well as several one-off special reconnaissance variants. The first F-4Es, nicknamed ""Kurnass"" (Sledgehammer), and RF-4Es, nicknamed ""Orev"" (Raven), were delivered in 1969 under the "Peace Echo I" program. Additional Phantoms arrived during the 1970s under "Peace Echo II" through "Peace Echo V" and "Nickel Grass" programs. Israeli Phantoms saw extensive combat during Arab–Israeli conflicts, first seeing action during the War of Attrition. In the 1980s, Israel began the "Kurnass 2000" modernization program which significantly updated avionics. The last Israeli F-4s were retired in 2004.

From 1968, the Japan Air Self-Defense Force (JASDF) purchased a total of 140 F-4EJ Phantoms without aerial refueling, AGM-12 Bullpup missile system, nuclear control system or ground attack capabilities. Mitsubishi built 138 under license in Japan and 14 unarmed reconnaissance RF-4Es were imported. One of the aircraft (17-8440) was the very last of the 5,195 F-4 Phantoms to be produced. It was manufactured by Mitsubishi Heavy Industries on 21 May 1981. "The Final Phantom" served with 306th Tactical Fighter Squadron and later transferred to the 301st Tactical Fighter Squadron.
Of these, 96 F-4EJs were modified to the F-4EJ standard. 15 F-4EJ and F-4EJ Kai were converted to reconnaissance aircraft designated RF-4EJ. Japan had a fleet of 90 F-4s in service in 2007. After studying several replacement fighters the F-35 Lightning II was chosen in 2011. Delays with the F-35 program have meant that some F-4s have remained in service, although replacements are underway as of 2019. The 302nd Tactical Fighter Squadron became the first JASDF F-35 Squadron at Misawa Air Base when it converted from F-4EJ Kai on 29 March 2019. The remaining two squadrons, the 301st Tactical Fighter Squadron and 501st Tactical Reconnaissance Squadron (both based at Hyakuri Air Base in Ibaraki prefecture north of Tokyo), are schedule to retire their F-4s in 2020. Some F-4s are also operated by the Air Development and Test Wing in Gifu Prefecture.

The Republic of Korea Air Force purchased its first batch of secondhand USAF F-4D Phantoms in 1968 under the "Peace Spectator" program. The F-4Ds continued to be delivered until 1988. The "Peace Pheasant II" program also provided new-built and former USAF F-4Es.

The Spanish Air Force acquired its first batch of ex-USAF F-4C Phantoms in 1971 under the "Peace Alfa" program. Designated C.12, the aircraft were retired in 1989. At the same time, the air arm received a number of ex-USAF RF-4Cs, designated CR.12. In 1995–1996, these aircraft received extensive avionics upgrades. Spain retired its RF-4s in 2002.

The Turkish Air Force (TAF) received 40 F-4Es in 1974, with a further 32 F-4Es and 8 RF-4Es in 1977–78 under the "Peace Diamond III" program, followed by 40 ex-USAF aircraft in "Peace Diamond IV" in 1987, and a further 40 ex-U.S. Air National Guard Aircraft in 1991. A further 32 RF-4Es were transferred to Turkey after being retired by the Luftwaffe between 1992 and 1994. In 1995, Israel Aerospace Industries (IAI) implemented an upgrade similar to Kurnass 2000 on 54 Turkish F-4Es which were dubbed the F-4E 2020 Terminator. Turkish F-4s, and more modern F-16s have been used to strike Kurdish PKK bases in ongoing military operations in Northern Iraq. On 22 June 2012, a Turkish RF-4E was shot down by Syrian air defenses while flying a reconnaissance flight near the Turkish-Syrian border. Turkey has stated the reconnaissance aircraft was in international airspace when it was shot down, while Syrian authorities stated it was inside Syrian airspace. Turkish F-4s remained in use as of 2015.

On 24 February 2015, two RF-4Es crashed in the Malatya region in the southeast of Turkey, under yet unknown circumstances, killing both crew of two each. On 5 March 2015, an F-4E-2020 crashed in central Anatolia killing both crew. After the recent accidents, the TAF withdrew RF-4Es from active service. Turkey was reported to have used F-4 jets to attack PKK separatists and the ISIS capital on 19 September 2015. The Turkish Air Force has reportedly used the F-4E 2020s against the more recent Third Phase of the PKK conflict on heavy bombardment missions into Iraq on 15 November 2015, 12 January 2016, and 12 March 2016.

The United Kingdom bought versions based on the U.S. Navy's F-4J for use with the Royal Air Force and the Royal Navy's Fleet Air Arm. The UK was the only country outside the United States to operate the Phantom at sea, launching them from . The main differences were the use of the British Rolls-Royce Spey engines and of British-made avionics. The RN and RAF versions were given the designation F-4K and F-4M respectively, and entered service with the British military aircraft designations Phantom FG.1 (fighter/ground attack) and Phantom FGR.2 (fighter/ground attack/reconnaissance). Initially, the FGR.2 was used in the ground attack and reconnaissance role, primarily with RAF Germany, while 43 Squadron was formed in the air defence role using the FG.1s that had been intended for the Fleet Air Arm for use aboard . The superiority of the Phantom over the English Electric Lightning in terms of both range and weapon load, combined with the successful introduction of the SEPECAT Jaguar, meant that, during the mid-1970s, most of the ground attack Phantoms in Germany were redeployed to the UK to replace air defence Lightning squadrons. A second RAF squadron, 111 Squadron, was formed on the FG.1 in 1979 after the disbandment of 892 NAS.

In 1982, during the Falklands War, three Phantom FGR2s of No. 29 Squadron were on active Quick Reaction Alert duty on Ascension Island to protect the base from air attack. After the Falklands War, 15 upgraded ex-USN F-4Js, known as the F-4J(UK) entered RAF service to compensate for one interceptor squadron redeployed to the Falklands.

Around 15 RAF squadrons received various marks of Phantom, many of them based in Germany. The first to be equipped was No. 228 Operational Conversion Unit at RAF Coningsby in August 1968. One noteworthy operator was No. 43 Squadron where Phantom FG1s remained the squadron equipment for 20 years, arriving in September 1969 and departing in July 1989. During this period the squadron was based at Leuchars.

The interceptor Phantoms were replaced by the Panavia Tornado F3 from the late 1980s onwards, and the last British Phantoms were retired in October 1992 when No. 74 Squadron was disbanded.

Sandia National Laboratories used an F-4 mounted on a "rocket sled" in a crash test to see the results of an aircraft hitting a reinforced concrete structure, such as a nuclear power plant.
One aircraft, an F-4D (civilian registration N749CF), is operated by the Massachusetts-based non-profit organization Collings Foundation as a "living history" exhibit. Funds to maintain and operate the aircraft, which is based in Houston, Texas, are raised through donations/sponsorships from public and commercial parties.

NASA used the F-4 to photograph and film Titan II missiles after launch from Cape Canaveral during the 1960s. Retired U.S. Air Force Colonel Jack Petry described how he put his F-4 into a Mach 1.2 dive synchronized to the launch countdown, then "'walked the (rocket's) contrail' up to the intercept point, tweaking closing speed and updating mission control while camera pods mounted under each wing shot film at 900 frames per second." Petry's Phantom stayed with the Titan for 90 seconds, then broke away as the missile continued into space.

NASA's Dryden Flight Research Center acquired an F-4A on 3 December 1965. It made 55 flights in support of short programs, chase on X-15 missions and lifting body flights. The F-4 also supported a biomedical monitoring program involving 1,000 flights by NASA Flight Research Center aerospace research pilots and students of the USAF Aerospace Research Pilot School flying high-performance aircraft. The pilots were instrumented to record accurate and reliable data of electrocardiogram, respiration rate and normal acceleration. In 1967, the Phantom supported a brief military-inspired program to determine whether an airplane's sonic boom could be directed and whether it could be used as a weapon of sorts, or at least an annoyance. NASA also flew an F-4C in a spanwise blowing study from 1983 to 1985, after which it was returned.


The Phantom gathered a number of nicknames during its career. Some of these names included "Snoopy", "Rhino", "Double Ugly", "Old Smokey", the "Flying Anvil", "Flying Footlocker", "Flying Brick", "Lead Sled", the "Big Iron Sled" and the "St. Louis Slugger". In recognition of its record of downing large numbers of Soviet-built MiGs, it was called the "World's Leading Distributor of MiG Parts". As a reflection of excellent performance in spite of its bulk, the F-4 was dubbed "the triumph of thrust over aerodynamics." German "Luftwaffe" crews called their F-4s the "Eisenschwein" ("Iron Pig"), "Fliegender Ziegelstein" ("Flying Brick") and "Luftverteidigungsdiesel" ("Air Defense Diesel").

Imitating the spelling of the aircraft's name, McDonnell issued a series of patches. Pilots became "Phantom Phlyers", backseaters became "Phantom Pherrets", fans of the F-4 "Phantom Phanatics", and call it the "Phabulous Phantom". Ground crewmen who worked on the aircraft are known as "Phantom Phixers".

The aircraft's emblem is a whimsical cartoon ghost called "The Spook", which was created by McDonnell Douglas technical artist, Anthony "Tony" Wong, for shoulder patches. The name "Spook" was coined by the crews of either the 12th Tactical Fighter Wing or the 4453rd Combat Crew Training Wing at MacDill AFB. The figure is ubiquitous, appearing on many items associated with the F-4. The Spook has followed the Phantom around the world adopting local fashions; for example, the British adaptation of the U.S. "Phantom Man" is a Spook that sometimes wears a bowler hat and smokes a pipe.

There are many F-4 Phantom IIs on display worldwide.



</doc>
<doc id="11761" url="https://en.wikipedia.org/wiki?curid=11761" title="McDonnell FH Phantom">
McDonnell FH Phantom

The McDonnell FH Phantom was a twinjet fighter aircraft designed and first flown during World War II for the United States Navy. The Phantom was the first purely jet-powered aircraft to land on an American aircraft carrier and the first jet deployed by the United States Marine Corps. Although with the end of the war, only 62 FH-1s were built, it helped prove the viability of carrier-based jet fighters. As McDonnell's first successful fighter, leading to the development of the follow-on F2H Banshee, which was one of the two most important naval jet fighters of the Korean War, it would also establish McDonnell as an important supplier of navy aircraft. When McDonnell chose to bring the name back with the Mach 2–class McDonnell Douglas F-4 Phantom II, it launched what would become the most versatile and widely used western combat aircraft of the Vietnam War era, adopted by the USAF and the US Navy, remaining in use with various countries to the present day.

The FH Phantom was originally designated the FD Phantom, but the designation was changed as the aircraft entered production.

In early 1943, aviation officials at the United States Navy were impressed with McDonnell's audacious XP-67 Bat project. McDonnell was invited by the navy to cooperate in the development of a shipboard jet fighter, using an engine from the turbojets under development by Westinghouse Electric Corporation. Three prototypes were ordered on 30 August 1943 and the designation XFD-1 was assigned. Under the 1922 United States Navy aircraft designation system, the letter "D" before the dash designated the aircraft's manufacturer. The Douglas Aircraft Company had previously been assigned this letter, but the USN elected to reassign it to McDonnell because Douglas had not provided any fighters for navy service in years.

McDonnell engineers evaluated a number of engine combinations, varying from eight 9.5 in (24 cm) diameter engines down to two engines of 19 inch (48 cm) diameter. The final design used the two 19 in (48 cm) engines after it was found to be the lightest and simplest configuration. The engines were buried in the wing root to keep intake and exhaust ducts short, offering greater aerodynamic efficiency than underwing nacelles, and the engines were angled slightly outwards to protect the fuselage from the hot exhaust blast. Placement of the engines in the middle of the airframe allowed the cockpit with its bubble-style canopy to be placed ahead of the wing, granting the pilot excellent visibility in all directions. This engine location also freed up space under the nose, allowing designers to use tricycle gear, thereby elevating the engine exhaust path and reducing the risk that the hot blast would damage the aircraft carrier deck. The construction methods and aerodynamic design of the Phantom were fairly conventional for the time; the aircraft had unswept wings, a conventional empennage, and an aluminum monocoque structure with flush riveted aluminum skin. Folding wings were used to reduce the width of the aircraft in storage configuration. Provisions for four .50-caliber (12.7 mm) machine guns were made in the nose, while racks for eight 5 in (127 mm) High Velocity Aircraft Rockets could be fitted under the wings, although these were seldom used in service. Adapting a jet to carrier use was a much greater challenge than producing a land-based fighter because of slower landing and takeoff speeds required on a small carrier deck. The Phantom used split flaps on both the folding and fixed wing sections to enhance low-speed landing performance, but no other high-lift devices were used. Provisions were also made for Rocket Assisted Take Off (RATO) bottles to improve takeoff performance.

When the first XFD-1, serial number "48235", was completed in January 1945, only one Westinghouse 19XB-2B engine was available for installation. Ground runs and taxi tests were conducted with the single engine, and such was the confidence in the aircraft that the first flight on 26 January 1945 was made with only the one turbojet engine. During flight tests, the Phantom became the first naval aircraft to exceed 500 mph (434 kn, 805 km/h). With successful completion of tests, a production contract was awarded on 7 March 1945 for 100 FD-1 aircraft. With the end of the war, the Phantom production contract was reduced to 30 aircraft, but was soon increased back to 60.

The first prototype was lost in a fatal crash on 1 November 1945, but the second and final Phantom prototype (serial number "48236") was completed early the next year and became the first purely jet-powered aircraft to operate from an American aircraft carrier, completing four successful takeoffs and landings on 21 July 1946, from near Norfolk, Virginia. At the time, she was the largest carrier serving with the U.S. Navy, allowing the aircraft to take off without assistance from a catapult. The second prototype crashed on 26 August 1946.

Production Phantoms incorporated a number of design improvements. These included provisions for a flush-fitting centerline drop tank, an improved gunsight, and the addition of speed brakes. Production models used Westinghouse J30-WE-20 engines with 1,600 lbf (7.1 kN) of thrust per engine. The top of the vertical tail had a more square shape than the rounder tail used on the prototypes, and a smaller rudder was used to resolve problems with control surface clearance discovered during test flights. The horizontal tail surfaces were shortened slightly, while the fuselage was stretched by 19 in (48 cm). The amount of framing in the windshield was reduced to enhance pilot visibility.

Halfway through the production run, the navy reassigned the designation letter "D" back to Douglas, with the Phantom being redesignated FH-1. Including the two prototypes, a total of 62 Phantoms were finally produced, with the last FH-1 rolling off the assembly line in May 1948.

Realizing that the production of more powerful jet engines was imminent, McDonnell engineers proposed a more powerful variant of the Phantom while the original aircraft was still under development – a proposal that would lead to the design of the Phantom's replacement, the F2H Banshee. Although the new aircraft was originally envisioned as a modified Phantom, the need for heavier armament, greater internal fuel capacity, and other improvements eventually led to a substantially heavier and bulkier aircraft that shared few parts with its agile predecessor. Despite this, the two aircraft were similar enough that McDonnell was able to complete its first F2H-1 in August 1948, a mere three months after the last FH-1 had rolled off the assembly line.

The first Phantoms were delivered to USN fighter squadron VF-17A (later redesignated VF-171) in August 1947; the squadron received a full complement of 24 aircraft on 29 May 1948. Beginning in November 1947, Phantoms were delivered to United States Marine Corps squadron VMF-122, making it the first USMC combat squadron to deploy jets. VF-17A became the USN's first fully operational jet carrier squadron when it deployed aboard on 5 May 1948.

The Phantom was one of the first jets used by the U.S. military for exhibition flying. Three Phantoms used by the Naval Air Test Center were used by a unique demonstration team called the Gray Angels, whose members consisted entirely of naval aviators holding the rank of rear admiral (Daniel V. Gallery, Apollo Soucek and Edgar A. Cruise.) The team's name was an obvious play on the name of the recently formed U.S. Navy Blue Angels, who were still flying propeller-powered Grumman F8F Bearcats at the time. The "Grays" flew in various air shows during the summer of 1947, but the team was abruptly disbanded after their poorly timed arrival at a September air show in Cleveland, Ohio, nearly caused a head-on low-altitude collision with a large formation of other aircraft; their Phantoms were turned over to test squadron VX-3. The VMF-122 Phantoms were later used for air show demonstrations until they were taken out of service in 1949, with the team being known alternately as the Marine Phantoms or the Flying Leathernecks.

The Phantom's service as a frontline fighter would be short-lived. Its limited range and light armament – notably, its inability to carry bombs – made it best suited for duty as a point-defence interceptor aircraft. However, its speed and rate of climb were only slightly better than existing propeller-powered fighters and fell short of other contemporary jets, such as the Lockheed P-80 Shooting Star, prompting concerns that the Phantom would be outmatched by future enemy jets it might soon face. Moreover, recent experience in World War II had demonstrated the value of naval fighters that could double as fighter-bombers, a capability the Phantom lacked. Finally, the aircraft exhibited some design deficiencies – its navigational avionics were poor, it could not accommodate newly developed ejection seats, and the location of the machine guns in the upper nose caused pilots to be dazzled by muzzle flash.

The F2H Banshee and Grumman F9F Panther, both of which began flight tests around the time of the Phantom's entry into service, better satisfied the navy's desire for a versatile, long-range, high-performance jet. Consequently, the FH-1 saw little weapons training, and was primarily used for carrier qualifications to transition pilots from propeller-powered fighters to jets in preparation for flying the Panther or Banshee. In June 1949, VF-171 (VF-17A) re-equipped with the Banshee, and their Phantoms were turned over to VF-172; this squadron, along with the NATC, VX-3, and VMF-122, turned over their Phantoms to the United States Naval Reserve by late 1949 after receiving F2H-1 Banshees. The FH-1 would see training duty with the USNR until being replaced by the F9F Panther in July 1954; none ever saw combat, having been retired from frontline service prior to the outbreak of the Korean War.

In 1964, Progressive Aero, Incorporated of Fort Lauderdale, Florida purchased three surplus Phantoms, intending to use them to teach civilians how to fly jets. A pair were stripped of military equipment and restored to flying condition, but the venture was unsuccessful, and the aircraft were soon retired once again.






</doc>
<doc id="11762" url="https://en.wikipedia.org/wiki?curid=11762" title="Fricative consonant">
Fricative consonant

Fricatives are consonants produced by forcing air through a narrow channel made by placing two articulators close together. These may be the lower lip against the upper teeth, in the case of ; the back of the tongue against the soft palate, in the case of German (the final consonant of "Bach"); or the side of the tongue against the molars, in the case of Welsh (appearing twice in the name "Llanelli"). This turbulent airflow is called frication. 

A particular subset of fricatives are the sibilants. When forming a sibilant, one still is forcing air through a narrow channel, but in addition, the tongue is curled lengthwise to direct the air over the edge of the teeth. English , , , and are examples of sibilants.

The usage of two other terms is less standardized: "Spirant" is an older term for fricatives used by some American and European phoneticians and phonologists. "Strident" could mean just "sibilant", but some authors include also labiodental and uvular fricatives in the class.


All sibilants are coronal, but may be dental, alveolar, postalveolar, or palatal (retroflex) within that range. However, at the postalveolar place of articulation, the tongue may take several shapes: domed, laminal, or apical, and each of these is given a separate symbol and a separate name. Prototypical retroflexes are subapical and palatal, but they are usually written with the same symbol as the apical postalveolars. The alveolars and dentals may also be either apical or laminal, but this difference is indicated with diacritics rather than with separate symbols.


The IPA also has letters for epiglottal fricatives,
with allophonic trilling, but these might be better analyzed as pharyngeal trills.

The lateral fricative occurs as the "ll" of Welsh, as in "Lloyd", "Llewelyn", and "Machynlleth" (, a town), as the unvoiced 'hl' and voiced 'dl' or 'dhl' in the several languages of Southern Africa (such as Xhosa and Zulu), and in Mongolian.


No language distinguishes voiced fricatives from approximants at these places, so the same symbol is used for both. For the pharyngeal, approximants are more numerous than fricatives. A fricative realization may be specified by adding the uptack to the letters, . Likewise, the downtack may be added to specify an approximant realization, .


In many languages, such as English, the glottal "fricatives" are unaccompanied phonation states of the glottis, without any accompanying manner, fricative or otherwise. However, in languages such as Arabic, they are true fricatives.

In addition, is usually called a "voiceless labial-velar fricative", but it is actually an approximant. True doubly articulated fricatives may not occur in any language; but see voiceless palatal-velar fricative for a putative (and rather controversial) example.

Fricatives are very commonly voiced, though cross-linguistically voiced fricatives are not nearly as common as tenuis ("plain") fricatives. Other phonations are common in languages that have those phonations in their stop consonants. However, phonemically aspirated fricatives are rare. contrasts with in Korean; aspirated fricatives are also found in a few Sino-Tibetan languages, in some Oto-Manguean languages, and in the Siouan language Ofo ( and ). The record may be Cone Tibetan, which has four contrastive aspirated fricatives: , , and .

Phonemically nasalized fricatives are rare. Some South Arabian languages have , Umbundu has , and Kwangali and Souletin Basque have . In Coatzospan Mixtec, appear allophonically before a nasal vowel, and in Igbo nasality is a feature of the syllable; when occur in nasal syllables they are themselves nasalized.

Until its extinction, Ubykh may have been the language with the most fricatives (29 not including ), some of which did not have dedicated symbols or diacritics in the IPA. This number actually outstrips the number of all consonants in English (which has 24 consonants). By contrast, approximately 8.7% of the world's languages have no phonemic fricatives at all. This is a typical feature of Australian Aboriginal languages, where the few fricatives that exist result from changes to plosives or approximants, but also occurs in some indigenous languages of New Guinea and South America that have especially small numbers of consonants. However, whereas is "entirely" unknown in indigenous Australian languages, most of the other languages without true fricatives do have in their consonant inventory.

Voicing contrasts in fricatives are largely confined to Europe, Africa, and Western Asia. Languages of South and East Asia, such as Mandarin Chinese, Korean, the Dravidian and Austronesian languages, typically do not have such voiced fricatives as and , which are familiar to many European speakers. These voiced fricatives are also relatively rare in indigenous languages of the Americas. Overall, voicing contrasts in fricatives are much rarer than in plosives, being found only in about a third of the world's languages as compared to 60 percent for plosive voicing contrasts.

About 15 percent of the world's languages, however, have "unpaired voiced fricatives", i.e. a voiced fricative without a voiceless counterpart. Two-thirds of these, or 10 percent of all languages, have unpaired voiced fricatives but no voicing contrast between any fricative pair.

This phenomenon occurs because voiced fricatives have developed from lenition of plosives or fortition of approximants. This phenomenon of unpaired voiced fricatives is scattered throughout the world, but is confined to nonsibilant fricatives with the exception of a couple of languages that have but lack . (Relatedly, several languages have the voiced affricate but lack , and vice versa.) The fricatives that occur most often without a voiceless counterpart are – in order of ratio of unpaired occurrences to total occurrences – , , , and .

Fricatives appear in waveforms as random noise caused by the turbulent airflow, upon which a periodic pattern is overlaid if voiced. Fricatives produced in the front of the mouth tend to have energy concentration at higher frequencies than ones produced in the back. The centre of gravity, the average frequency in a spectrum weighted by the amplitude, may be used to determine the place of articulation of a fricative relative to that of another.




</doc>
<doc id="11763" url="https://en.wikipedia.org/wiki?curid=11763" title="Frost">
Frost

Frost is a thin layer of ice on a solid surface, which forms from water vapor in an above freezing atmosphere coming in contact with a solid surface whose temperature is below freezing, and resulting in a phase change from water vapor (a gas) to ice (a solid) as the water vapor reaches the freezing point. In temperate climates, it most commonly appears on surfaces near the ground as fragile white crystals; in cold climates, it occurs in a greater variety of forms. The propagation of crystal formation occurs by the process of nucleation.

The ice crystals of frost form as the result of fractal process development. The depth of frost crystals varies depending on the amount of time they have been accumulating, and the concentration of the water vapor (humidity). Frost crystals may be invisible (black), clear (translucent), or white; if a mass of frost crystals scatters light in all directions, the coating of frost appears white.

Types of frost include crystalline frost (hoar frost or radiation frost) from deposition of water vapor from air of low humidity, white frost in humid conditions, window frost on glass surfaces, advection frost from cold wind over cold surfaces, black frost without visible ice at low temperatures and very low humidity, and rime under supercooled wet conditions.

Plants that have evolved in warmer climates suffer damage when the temperature falls low enough to freeze the water in the cells that make up the plant tissue. The tissue damage resulting from this process is known as "frost damage". Farmers in those regions where frost damage is known to affect their crops often invest in substantial means to protect their crops from such damage.

If a solid surface is chilled below the dew point of the surrounding humid air and the surface itself is colder than freezing, ice will form on it. If the water deposits as a liquid that then freezes, it forms a coating that may look glassy, opaque, or crystalline, depending on its type. Depending on context, that process also may be called atmospheric icing. The ice it produces differs in some ways from crystalline frost, which consists of spicules of ice that typically project from the solid surface on which they grow.

The main difference between the ice coatings and frost spicules arises from the fact that the crystalline spicules grow directly from desublimation of water vapour from air, and desublimation is not a factor in icing of freezing surfaces. For desublimation to proceed the surface must be below the frost point of the air, meaning that it is sufficiently cold for ice to form without passing through the liquid phase. The air must be humid, but not sufficiently humid to permit the condensation of liquid water, or icing will result instead of desublimation. The size of the crystals depends largely on the temperature, the amount of water vapor available, and how long they have been growing undisturbed.

As a rule, except in conditions where supercooled droplets are present in the air, frost will form only if the deposition surface is colder than the surrounding air. For instance frost may be observed around cracks in cold wooden sidewalks when humid air escapes from the warmer ground beneath. Other objects on which frost commonly forms are those with low specific heat or high thermal emissivity, such as blackened metals; hence the accumulation of frost on the heads of rusty nails.

The apparently erratic occurrence of frost in adjacent localities is due partly to differences of elevation, the lower areas becoming colder on calm nights. Where static air settles above an area of ground in the absence of wind, the absorptivity and specific heat of the ground strongly influence the temperature that the trapped air attains.

Hoar frost, also hoarfrost, radiation frost, or pruina, refers to white ice crystals deposited on the ground or loosely attached to exposed objects, such as wires or leaves. They form on cold, clear nights when conditions are such that heat radiates out to the open air faster than it can be replaced from nearby sources, such as wind or warm objects. Under suitable circumstances, objects cool to below the frost point of the surrounding air, well below the freezing point of water. Such freezing may be promoted by effects such as flood frost or frost pocket. These occur when ground-level radiation losses cool air until it flows downhill and accumulates in pockets of very cold air in valleys and hollows. Hoar frost may freeze in such low-lying cold air even when the air temperature a few feet above ground is well above freezing.

The word "hoar" comes from an Old English adjective that means "showing signs of old age". In this context, it refers to the frost that makes trees and bushes look like white hair. 

Hoar frost may have different names depending on where it forms:

When surface hoar covers sloping snowbanks, the layer of frost crystals may create an avalanche risk; when heavy layers of new snow cover the frosty surface, furry crystals standing out from the old snow hold off the falling flakes, forming a layer of voids that prevent the new snow layers from bonding strongly to the old snow beneath. Ideal conditions for hoarfrost to form on snow are cold clear nights, with very light, cold air currents conveying humidity at the right rate for growth of frost crystals. Wind that is too strong or warm destroys the furry crystals, and thereby may permit a stronger bond between the old and new snow layers. However, if the winds are strong enough and cold enough to lay the crystals flat and dry, carpeting the snow with cold, loose crystals without removing or destroying them or letting them warm up and become sticky, then the frost interface between the snow layers may still present an avalanche danger, because the texture of the frost crystals differs from the snow texture and the dry crystals will not stick to fresh snow. Such conditions still prevent a strong bond between the snow layers.

In very low temperatures where fluffy surface hoar crystals form without subsequently being covered with snow, strong winds may break them off, forming a dust of ice particles and blowing them over the surface. The ice dust then may form yukimarimo, as has been observed in parts of Antarctica, in a process similar to the formation of dust bunnies and similar structures.

Hoar frost and white frost also occurs in man-made environments such as in freezers or industrial cold storage facilities. If such cold spaces or the pipes serving them are not well insulated and are exposed to ambient humidity, the moisture will freeze instantly depending on the freezer temperature. The frost may coat pipes thickly, partly insulating them, but such inefficient insulation still is a source of heat loss.

Advection frost (also called wind frost) refers to tiny ice spikes that form when very cold wind is blowing over tree branches, poles, and other surfaces. It looks like rimming on the edges of flowers and leaves and usually forms against the direction of the wind. It can occur at any hour, day or night.

Window frost (also called fern frost or ice flowers) forms when a glass pane is exposed to very cold air on the outside and warmer, moderately moist air on the inside. If the pane is not a good insulator (for example, if it is a single pane window), water vapour condenses on the glass forming frost patterns. With very low temperatures outside, frost can appear on the bottom of the window even with double pane energy efficient windows because the air convection between two panes of glass ensures that the bottom part of the glazing unit is colder than the top part. On unheated motor vehicles the frost will usually form on the outside surface of the glass first. The glass surface influences the shape of crystals, so imperfections, scratches, or dust can modify the way ice nucleates. The patterns in window frost form a fractal with a fractal dimension greater than one but less than two. This is a consequence of the nucleation process being constrained to unfold in two dimensions, unlike a snowflake which is shaped by a similar process but forms in three dimensions and has a fractal dimension greater than two.

If the indoor air is very humid, rather than moderately so, water will first condense in small droplets and then freeze into clear ice.

Similar patterns of freezing may occur on other smooth vertical surfaces, but they seldom are as obvious or spectacular as on clear glass.

White frost is a solid deposition of ice that forms directly from water vapour contained in air.

White frost forms when there is a relative humidity above 90% and a temperature below −8 °C (18 °F) and it grows against the wind direction, since air arriving from windward has a higher humidity than leeward air, but the wind must not be strong or it damages the delicate icy structures as they begin to form. White frost resembles a heavy coating of hoar frost with big, interlocking crystals, usually needle-shaped.

Rime is a type of ice deposition that occurs quickly, often under heavily humid and windy conditions. Technically speaking, it is not a type of frost, since usually supercooled water drops are involved, in contrast to the formation of hoar frost, in which water vapour desublimates slowly and directly. Ships travelling through Arctic seas may accumulate large quantities of rime on the rigging. Unlike hoar frost, which has a feathery appearance, rime generally has an icy, solid appearance.

Black frost (or "killing frost") is not strictly speaking frost at all, because it is the condition seen in crops when the humidity is too low for frost to form, but the temperature falls so low that plant tissues freeze and die, becoming blackened, hence the term "black frost". Black frost often is called "killing frost" because white frost tends to be less cold, partly because the latent heat of freezing of the water reduces the temperature drop.

Many plants can be damaged or killed by freezing temperatures or frost. This varies with the type of plant, the tissue exposed, and how low temperatures get: a "light frost" of will damage fewer types of plants than a "hard frost" below .

Plants likely to be damaged even by a light frost include vines—such as beans, grapes, squashes, melons—along with nightshades such as tomatoes, eggplants and peppers. Plants that may tolerate (or even benefit) from frosts include:
Even those plants that tolerate frost may be damaged once temperatures drop even lower (below ). Hardy perennials, such as "Hosta", become dormant after the first frosts and regrow when spring arrives. The entire visible plant may turn completely brown until the spring warmth, or may drop all of its leaves and flowers, leaving the stem and stalk only. Evergreen plants, such as pine trees, withstand frost although all or most growth stops. Frost crack is a bark defect caused by a combination of low temperatures and heat from the winter sun.

Vegetation is not necessarily damaged when leaf temperatures drop below the freezing point of their cell contents. In the absence of a site nucleating the formation of ice crystals, the leaves remain in a supercooled liquid state, safely reaching temperatures of . However, once frost forms, the leaf cells may be damaged by sharp ice crystals. Hardening is the process by which a plant becomes tolerant to low temperatures. See also Cryobiology.

Certain bacteria, notably "Pseudomonas syringae", are particularly effective at triggering frost formation, raising the nucleation temperature to about . Bacteria lacking ice nucleation-active proteins (ice-minus bacteria) result in greatly reduced frost damage.

Typical measures to prevent frost or reduce its severity include one or more of:
Such measures need to be applied with discretion, because they may do more harm than good; for example, spraying crops with water can cause damage if the plants become overburdened with ice. An effective low cost method for small crop farms and plant nurseries, exploits the latent heat of freezing. A pulsed irrigation timer delivers water through existing overhead sprinklers at a low volumes to combat frosts down to . If the water freezes it giving off its latent heat, preventing the temperature of the foliage from falling much below zero.

Frost-free areas are found mainly in the tropics, where they cover almost all land except at altitudes above about near the equator and around in the semi-arid middle tropics, but also in areas with subtropical climates that have winters tempered by strong oceanic influences. The most poleward frost-free areas are the lower altitudes of the Azores, Île Amsterdam, Île Saint-Paul, and Tristan da Cunha.

The only reliably frost-free areas in the contiguous United States are the Florida Keys and the coastal areas of the Channel Islands of California. The hardiness zones there are 11a and 11b.

Frost is personified in Russian culture as Ded Moroz. Indigenous peoples of Russia such as the Mordvins have their own traditions of frost deities.

English folklore tradition holds that Jack Frost, an elfish creature, is responsible for feathery patterns of frost found on windows on cold mornings.




</doc>
<doc id="11768" url="https://en.wikipedia.org/wiki?curid=11768" title="Franz Schmidt">
Franz Schmidt

Franz Schmidt (22 December 1874 – 11 February 1939) was an Austro-Hungarian composer, cellist and pianist.

Schmidt was born in Pozsony (known in German as Pressburg), in the Hungarian part of the Austro-Hungarian Empire (the city is now Bratislava, capital of Slovakia). His father was half Hungarian and his mother entirely Hungarian. He was a Roman Catholic.

His earliest teacher was his mother, Mária Ravasz, an accomplished pianist, who gave him a systematic instruction in the keyboard works of J. S. Bach. He received a thorough foundation in theory from Brother Felizian Moczik, the outstanding organist at the Franciscan church in Pressburg. He studied piano briefly with Theodor Leschetizky, with whom he clashed. He moved to Vienna with his family in 1888, and studied at the Vienna Conservatory (composition with Robert Fuchs, cello with Ferdinand Hellmesberger and theory (the counterpoint class) with Anton Bruckner), graduating "with excellence" in 1896.

He beat 13 other applicants and obtained a post as cellist with the Vienna Court Opera Orchestra, where he played until 1914, often under Gustav Mahler. Mahler habitually had Schmidt play all the cello solos, even though Friedrich Buxbaum was the principal cellist. Schmidt was also in demand as a chamber musician. Schmidt and Arnold Schoenberg maintained cordial relations despite their vast differences in style. Also a brilliant pianist, in 1914 Schmidt took up a professorship in piano at the Vienna Conservatory, which had been recently renamed Imperial Academy of Music and the Performing Arts. (Apparently, when asked who the greatest living pianist was, Leopold Godowsky replied, "The other one is Franz Schmidt.") In 1925 he became Director of the Academy, and from 1927 to 1931 its Rector.

As teacher of piano, cello and counterpoint and composition at the Academy, Schmidt trained numerous musicians, conductors and composers who later achieved fame. Among his best-known students were the pianist Friedrich Wührer and Alfred Rosé (son of Arnold Rosé, the legendary founder of the Rosé Quartet, Konzertmeister of the Vienna Philharmonic and brother-in-law of Gustav Mahler). Among the composers were Walter Bricht (his favourite student), Theodor Berger, Marcel Rubin, Alfred Uhl and Ľudovít Rajter. He received many tokens of the high esteem in which he was held, notably the Franz-Josef Order, and an Honorary Doctorate from the University of Vienna.

Schmidt's private life was in stark contrast to the success of his distinguished professional career, and was overshadowed by tragedy. His first wife, Karoline Perssin (c. 1880–1943), was confined in the Vienna mental hospital Am Steinhof in 1919, and three years after his death was murdered under the Nazi euthanasia program. Their daughter Emma Schmidt Holzschuh (1902–1932, married 1929) died unexpectedly after the birth of her first child. Schmidt experienced a spiritual and physical breakdown after this, and achieved an artistic revival and resolution in his Fourth Symphony of 1933 (which he inscribed as "Requiem for my Daughter") and, especially, in his oratorio "The Book with Seven Seals". His second marriage in 1923, to a successful young piano student Margarethe Jirasek (1891–1964), for the first time brought some desperately needed stability into the private life of the artist, who was plagued by many serious health problems.

Schmidt's worsening health forced his retirement from the Academy in early 1937. In the last year of his life Austria was brought into the German Reich by the Anschluss, and Schmidt was feted by the Nazi authorities as the greatest living composer of the so-called Ostmark. He was given a commission to write a cantata entitled "The German Resurrection", which, after 1945, was taken by many as a reason to brand him as having been tainted by Nazi sympathy. However, Schmidt left this composition unfinished, and in the summer and autumn of 1938, a few months before his death, set it aside to devote himself to two other commissioned works for the one-armed pianist Paul Wittgenstein: the Quintet in A major for piano left-hand, clarinet, and string trio; and the Toccata in D minor for solo piano.
Schmidt died on 11 February 1939.

As a composer, Schmidt was slow to develop, but his reputation, at least in Austria, saw a steady growth from the late 1890s until his death in 1939. In his music, Schmidt continued to develop the Viennese classic-romantic traditions he inherited from Schubert, Brahms and his own master, Bruckner. He also takes forward the exotic "gypsy" style of Liszt and Brahms. His works are monumental in form and firmly tonal in language, though quite often innovative in their designs and clearly open to some of the new developments in musical syntax initiated by Mahler and Schoenberg. Although Schmidt did not write a lot of chamber music, what he did write, in the opinion of such critics as Wilhelm Altmann, was important and of high quality. Although Schmidt's organ works may resemble others of the era in terms of length, complexity, and difficulty, they are forward-looking in being conceived for the smaller, clearer, classical-style instruments of the "Orgelbewegung", which he advocated. Schmidt worked mainly in large forms, including four symphonies (1899, 1913, 1928 and 1933) and two operas: "Notre Dame" (1904–6) and "Fredigundis" (1916–21). A CD recording of "Notre Dame" has been available for many years, starring Dame Gwyneth Jones and James King.

No really adequate recording has been made of Schmidt's second and last opera "Fredigundis", of which there has been but one "unauthorized" release in the early 1980s on the Voce label of an Austrian Radio broadcast of a 1979 Vienna performance under the direction of Ernst Märzendorfer. Aside from numerous "royal fanfares" (Fredigundis held the French throne in the sixth century) the score contains some fine examples of Schmidt's transitional style between his earlier and later manner. In many respects, Schmidt seldom ventured so far from traditional tonality again, and his third and final period (in the last decade-and-a-half of his life) was generally one of (at least partial) retrenchment, consolidation and the integration of the style of his opulently scored and melodious early compositions (the First Symphony, "Notre Dame") with elements of the overt experimentation seen in "Fredigundis", combined with an economy of utterance born of artistic maturity. "New Grove" encyclopaedia states that "Fredigundis" was a critical and popular failure, which may be partly attributable to the fact that Fredigundis (Fredegund, the widow of Chilperic I), is presented as a murderous and sadistic feminine monster. Add to this some structural problems with the libretto, and the opera's failure to make headway – despite an admirable and impressive score – becomes comprehensible.

Aside from the mature symphonies (Nos. 2-4), Schmidt's crowning achievement was the oratorio "The Book with Seven Seals" (1935–37), a setting of passages from the Book of Revelation. His choice of subject was prophetic: with hindsight the work appears to foretell, in the most powerful terms, the disasters that were shortly to be visited upon Europe in the Second World War. Here his invention rises to a sustained pitch of genius. A narrative upon the text of the oratorio was provided by the composer.

Schmidt's oratorio stands in the Austro-German tradition stretching back to the time of J. S. Bach and Handel. He was one of relatively few composers to write an oratorio fully on the subject of the Book of Revelation (earlier works include Georg Philipp Telemann: "Der Tag des Gerichts", Schneider: "Das Weltgericht", Louis Spohr: "Die letzten Dinge", Joachim Raff: "Weltende", and Ralph Vaughan Williams: "Sancta Civitas"). Far from glorifying its subject, it is a mystical contemplation, a horrified warning, and a prayer for salvation. The premiere was held in Vienna on 15 June 1938, with the Vienna Symphony Orchestra under Oswald Kabasta: the soloists were Rudolf Gerlach (John), Erika Rokyta, Enid Szantho, Anton Dermota, Josef von Manowarda and Franz Schütz at the organ.

Schmidt is generally, if erroneously, regarded as a conservative composer (such labels rest upon yet-to-be-resolved aesthetic/stylistic arguments), but the rhythmic subtlety and harmonic complexity of much of his music belie this. His music is modern without being modernist, combining a reverence for the great Austro-German lineage of composers with very personal innovations in harmony and orchestration (showing an awareness of the output of composers such as Debussy and Ravel, whose piano music he greatly admired, along with a knowledge of more recent composers in his own German-speaking realm, such as Schoenberg, Berg, Hindemith, etc.). The considerable technical accomplishment of his music ought to compel respect, but he seems to have fallen between two stools: his works are too complex for the conservatively minded, yet too obviously traditional for the avant-garde (they are also notoriously difficult to perform). Since the 1970s his music has enjoyed a modest revival which looks set to continue as it is rediscovered and re-evaluated.


Schmidt's premiere of "The Book with Seven Seals" was made much of by the Nazis (who had annexed Austria shortly before in the Anschluss), and Schmidt was seen to give the Nazi salute (according to a report by Georg Tintner, who revered Schmidt and whose intent to record his symphonies was never realised). His conductor Oswald Kabasta was apparently an enthusiastic Nazi who, being prohibited from conducting in 1946 during de-nazification, committed suicide. These facts long placed Schmidt's posthumous reputation under a cloud. His lifelong friend and colleague Oskar Adler, who fled the Nazis in 1938, wrote afterwards that Schmidt was never a Nazi and never antisemitic but was extremely naive about politics. Hans Keller gave a similar endorsement. Regarding Schmidt's political naivety, Michael Steinberg, in his book "The Symphony", tells of Schmidt's recommending "Variations on a Hebrew Theme" by his student Israel Brandmann to a musical group associated with the proto-Nazi German National Party. Most of Schmidt's principal musical friends were Jews, and they benefited from his generosity.

Schmidt's last listed work, the cantata "German Resurrection", was composed to a Nazi text. As one of the most famous living Austrian composers, Schmidt was well-known to Hitler and received this commission after the Anschluss. He left it unfinished, to be completed later by Robert Wagner. Already seriously ill, Schmidt worked instead on other compositions such as the Quintet in A major for piano (left hand), clarinet and string trio, intended for Paul Wittgenstein and incorporating a variation set based on a theme by Wittgenstein's old teacher, Josef Labor. His failure to complete the cantata is likely to be a further indication that he was not committed to the Nazi cause; such, at any rate, was the opinion of his friend Oskar Adler.















</doc>
<doc id="11771" url="https://en.wikipedia.org/wiki?curid=11771" title="Fucking">
Fucking

Fucking may be:



</doc>
<doc id="11772" url="https://en.wikipedia.org/wiki?curid=11772" title="Finnish Civil War">
Finnish Civil War

The Finnish Civil War was a civil war in Finland in 1918 fought for the leadership and control of Finland during the country's transition from a Grand Duchy of the Russian Empire to an independent state. The clashes took place in the context of the national, political, and social turmoil caused by World War I (Eastern Front) in Europe. The war was fought between the "Reds", led by a section of the Social Democratic Party, and the "Whites", conducted by the conservative-based Senate and the German Imperial Army. The paramilitary Red Guards, composed of industrial and agrarian workers, controlled the cities and industrial centres of southern Finland. The paramilitary White Guards, composed of farmers, along with middle-class and upper-class social strata, controlled rural central and northern Finland.

In the years before the conflict, Finnish society had experienced rapid population growth, industrialisation, pre-urbanisation and the rise of a comprehensive labour movement. The country's political and governmental systems were in an unstable phase of democratisation and modernisation. The socio-economic condition and education of the population had gradually improved, as well as national thinking and cultural life had awakened.

World War I led to the collapse of the Russian Empire, causing a power vacuum in Finland, and a subsequent struggle for dominance led to militarisation and an escalating crisis between the left-leaning labour movement and the conservatives. The Reds carried out an unsuccessful general offensive in February 1918, supplied with weapons by Soviet Russia. A counteroffensive by the Whites began in March, reinforced by the German Empire's military detachments in April. The decisive engagements were the Battles of Tampere and Vyborg (; ), won by the Whites, and the Battles of Helsinki and Lahti, won by German troops, leading to overall victory for the Whites and the German forces. Political violence became a part of this warfare. Around 12,500 Red prisoners of war died of malnutrition and disease in camps. About 39,000 people, of whom 36,000 were Finns, perished in the conflict.

In the aftermath, the Finns passed from Russian governance to the German sphere of influence with a plan to establish a German-led Finnish monarchy. The scheme was cancelled with the defeat of Germany in World War I and Finland instead emerged as an independent, democratic republic. The Civil War divided the nation for decades. Finnish society was reunited through social compromises based on a long-term culture of moderate politics and religion and the post-war economic recovery.

The main factor behind the Finnish Civil War was a political crisis arising out of World War I. Under the pressures of the Great War, the Russian Empire collapsed, leading to the February and October Revolutions in 1917. This breakdown caused a power vacuum and a subsequent struggle for power in Eastern Europe. Russia's Grand Duchy of Finland (1809–1917), became embroiled in the turmoil. Geopolitically less important than the continental Moscow–Warsaw gateway, Finland, isolated by the Baltic Sea was a peaceful side front until early 1918. The war between the German Empire and Russia had only indirect effects on the Finns. Since the end of the 19th century, the Grand Duchy had become a vital source of raw materials, industrial products, food and labour for the growing Imperial Russian capital Petrograd (modern Saint Petersburg), and World War I emphasised that role. Strategically, the Finnish territory was the less important northern section of the Estonian–Finnish gateway and a buffer zone to and from Petrograd through the Narva area, the Gulf of Finland and the Karelian Isthmus.

The German Empire saw Eastern Europe—primarily Russia—as a major source of vital products and raw materials, both during World War I and for the future. Her resources overstretched by the two-front war, Germany attempted to divide Russia by providing financial support to revolutionary groups, such as the Bolsheviks and the Socialist Revolutionary Party, and to radical, separatist factions, such as the Finnish national activist movement leaning toward Germanism. Between 30 and 40 million marks were spent on this endeavour. Controlling the Finnish area would allow the Imperial German Army to penetrate Petrograd and the Kola Peninsula, an area rich in raw materials for the mining industry. Finland possessed large ore reserves and a well-developed forest industry.

From 1809 to 1898, a period called "Pax Russica", the peripheral authority of the Finns gradually increased, and Russo-Finnish relations were exceptionally peaceful in comparison with other parts of the Russian Empire. Russia's defeat in the Crimean War in the 1850s led to attempts to speed up the modernisation of the country. This caused more than 50 years of economic, industrial, cultural and educational progress in the Grand Duchy of Finland, including an improvement in the status of the Finnish language. All this encouraged Finnish nationalism and cultural unity through the birth of the Fennoman movement, which bound the Finns to the domestic administration and led to the idea that the Grand Duchy was an increasingly autonomous state of the Russian Empire.

In 1899, the Russian Empire initiated a policy of integration through the Russification of Finland. The strengthened, pan-slavist central power tried to unite the "Russian Multinational Dynastic Union" as the military and strategic situation of Russia became more perilous due to the rise of Germany and Japan. Finns called the increased military and administrative control, "the First Period of Oppression", and for the first time Finnish politicians drew up plans for disengagement from Russia or sovereignty for Finland. In the struggle against integration, activists drawn from sections of the working class and the Swedish-speaking intelligentsia carried out terrorist acts. During World War I and the rise of Germanism, the pro-Swedish Svecomans began their covert collaboration with Imperial Germany and, from 1915 to 1917, a Jäger (; ) battalion consisting of 1,900 Finnish volunteers was trained in Germany.

The major reasons for rising political tensions among Finns were the autocratic rule of the Russian czar and the undemocratic class system of the estates of the realm. The latter system originated in the regime of the Swedish Empire that preceded Russian governance and divided the Finnish people economically, socially and politically. Finland's population grew rapidly in the nineteenth century (from 860,000 in 1810 to 3,130,000 in 1917), and a class of agrarian and industrial workers, as well as crofters, emerged over the period. The Industrial Revolution was rapid in Finland, though it started later than in the rest of Western Europe. Industrialisation was financed by the state and some of the social problems associated with the industrial process were diminished by the administration's actions. Among urban workers, socio-economic problems steepened during periods of industrial depression. The position of rural workers worsened after the end of the nineteenth century, as farming became more efficient and market-oriented, and the development of industry was insufficiently vigorous to fully utilise the rapid population growth of the countryside.

The difference between Scandinavian-Finnish (Finno-Ugric peoples) and Russian-Slavic culture affected the nature of Finnish national integration. The upper social strata took the lead and gained domestic authority from the Russian czar in 1809. The estates planned to build an increasingly autonomous Finnish state, led by the elite and the intelligentsia. The Fennoman movement aimed to include the common people in a non-political role; the labour movement, youth associations and the temperance movement were initially led "from above".

Between 1870 and 1916 industrialisation gradually improved social conditions and the self-confidence of workers, but while the standard of living of the common people rose in absolute terms, the rift between rich and poor deepened markedly. The commoners' rising awareness of socio-economic and political questions interacted with the ideas of socialism, social liberalism and nationalism. The workers' initiatives and the corresponding responses of the dominant authorities intensified social conflict in Finland.The Finnish labour movement, which emerged at the end of the nineteenth century from temperance, religious movements and Fennomania, had a Finnish nationalist, working-class character. From 1899 to 1906, the movement became conclusively independent, shedding the paternalistic thinking of the Fennoman estates, and it was represented by the Finnish Social Democratic Party, established in 1899. Workers' activism was directed both toward opposing Russification and in developing a domestic policy that tackled social problems and responded to the demand for democracy. This was a reaction to the domestic dispute, ongoing since the 1880s, between the Finnish nobility-bourgeoisie and the labour movement concerning voting rights for the common people.
Despite their obligations as obedient, peaceful and non-political inhabitants of the Grand Duchy (who had, only a few decades earlier, accepted the class system as the natural order of their life), the commoners began to demand their civil rights and citizenship in Finnish society. The power struggle between the Finnish estates and the Russian administration gave a concrete role model and free space for the labour movement. On the other side, due to an at-least century-long tradition and experience of administrative authority, the Finnish elite saw itself as the inherent natural leader of the nation. The political struggle for democracy was solved outside Finland, in international politics: the Russian Empire's failed 1904–1905 war against Japan led to the 1905 Revolution in Russia and to a general strike in Finland. In an attempt to quell the general unrest, the system of estates was abolished in the Parliamentary Reform of 1906. The general strike increased support for the social democrats substantially. The party encompassed a higher proportion of the population than any other socialist movement in the world.

The Reform of 1906 was a giant leap towards the political and social liberalisation of the common Finnish people because the Russian House of Romanov had been the most autocratic and conservative ruler in Europe. The Finns adopted a unicameral parliamentary system, the Parliament of Finland (; ) with universal suffrage. The number of voters increased from 126,000 to 1,273,000, including female citizens. The reform led to the social democrats obtaining about fifty percent of the popular vote, but the Czar regained his authority after the crisis of 1905. Subsequently, during the more severe programme of Russification, called "the Second Period of Oppression" by the Finns, the Czar neutralised the power of the Finnish Parliament between 1908 and 1917. He dissolved the assembly, ordered parliamentary elections almost annually, and determined the composition of the Finnish Senate, which did not correlate with the Parliament.

The capacity of the Finnish Parliament to solve socio-economic problems was stymied by confrontations between the largely uneducated commoners and the former estates. Another conflict festered as employers denied collective bargaining and the right of the labour unions to represent workers. The parliamentary process disappointed the labour movement, but as dominance in the Parliament and legislation was the workers' most likely way to obtain a more balanced society, they identified themselves with the state. Overall domestic politics led to a contest for leadership of the Finnish state during the ten years before the collapse of the Russian Empire.

The Second Period of Russification was halted on 15 March 1917 by the February Revolution, which removed the czar, Nicholas II. The collapse of Russia was caused by military defeats, war-weariness against the duration and hardships of the Great War, and the collision between the most conservative regime in Europe and a Russian people desiring modernisation. The Czar's power was transferred to the State Duma (Russian Parliament) and the right-wing Provisional Government, but this new authority was challenged by the Petrograd Soviet (city council), leading to dual power in the country.

The autonomous status of 1809–1899 was returned to the Finns by the March 1917 manifesto of the Russian Provisional Government. For the first time in history, "de facto" political power existed in the Parliament of Finland. The political left, consisting mainly of social democrats, covered a wide spectrum from moderate to revolutionary socialists. The political right was even more diverse, ranging from social liberals and moderate conservatives to rightist conservative elements. The four main parties were:

During 1917, a power struggle and social disintegration interacted. The collapse of Russia induced a chain reaction of disintegration, starting from the government, military and economy, and spreading to all fields of society, such as local administration, workplaces and to individual citizens. The social democrats wanted to retain the civil rights already achieved and to increase the socialists' power over society. The conservatives feared the loss of their long-held socio-economic dominance. Both factions collaborated with their equivalents in Russia, deepening the split in the nation.

The Social Democratic Party gained an absolute majority in the parliamentary elections of 1916. A new Senate was formed in March 1917 by Oskari Tokoi, but it did not reflect the socialists' large parliamentary majority: it comprised six social democrats and six non-socialists. In theory, the Senate consisted of a broad national coalition, but in practice (with the main political groups unwilling to compromise and top politicians remaining outside of it), it proved unable to solve any major Finnish problem. After the February Revolution, political authority descended to the street level: mass meetings, strike organisations and worker-soldier councils on the left and to active organisations of employers on the right, all serving to undermine the authority of the state.

The February Revolution halted the Finnish economic boom caused by the Russian war-economy. The collapse in business led to unemployment and high inflation, but the employed workers gained an opportunity to resolve workplace problems. The commoners' call for the eight-hour working day, better working conditions and higher wages led to demonstrations and large-scale strikes in industry and agriculture.

While the Finns had specialised in milk and butter production, the bulk of the food supply for the country depended on cereals produced in southern Russia. The cessation of cereal imports from disintegrating Russia led to food shortages in Finland. The Senate responded by introducing rationing and price controls. The farmers resisted the state control and thus a black market, accompanied by sharply rising food prices, formed. As a consequence, export to the free market of the Petrograd area increased. Food supply, prices and, in the end, the fear of starvation became emotional political issues between farmers and urban workers, especially those who were unemployed. Common people, their fears exploited by politicians and an incendiary, polarised political media, took to the streets. Despite the food shortages, no actual large-scale starvation hit southern Finland before the civil war and the food market remained a secondary stimulator in the power struggle of the Finnish state.

The passing of the Tokoi Senate bill called the "Law of Supreme Power" (, more commonly known as "valtalaki"; ) in July 1917, triggered one of the key crises in the power struggle between the social democrats and the conservatives. The fall of the Russian Empire opened the question of who would hold sovereign political authority in the former Grand Duchy. After decades of political disappointment, the February Revolution offered the Finnish social democrats an opportunity to govern; they held the absolute majority in Parliament. The conservatives were alarmed by the continuous increase of the socialists' influence since 1899, which reached a climax in 1917.

The "Law of Supreme Power" incorporated a plan by the socialists to substantially increase the authority of Parliament, as a reaction to the non-parliamentary and conservative leadership of the Finnish Senate between 1906 and 1916. The bill furthered Finnish autonomy in domestic affairs: the Russian Provisional Government was only allowed the right to control Finnish foreign and military policies. The Act was adopted with the support of the Social Democratic Party, the Agrarian League, part of the Young Finnish Party and some activists eager for Finnish sovereignty. The conservatives opposed the bill and some of the most right-wing representatives resigned from Parliament.

In Petrograd, the social democrats' plan had the backing of the Bolsheviks. They had been plotting a revolt against the Provisional Government since April 1917, and pro-Soviet demonstrations during the July Days brought matters to a head. The Helsinki Soviet and the Regional Committee of the Finnish Soviets, led by the Bolshevik Ivar Smilga, both pledged to defend the Finnish Parliament, were it threatened with attack. However, the Provisional Government still had sufficient support in the Russian army to survive and as the street movement waned, Vladimir Lenin fled to Karelia. In the aftermath of these events, the "Law of Supreme Power" was overruled and the social democrats eventually backed down; more Russian troops were sent to Finland and, with the co-operation and insistence of the Finnish conservatives, Parliament was dissolved and new elections announced.

In the October 1917 elections, the social democrats lost their absolute majority, which radicalised the labour movement and decreased support for moderate politics. The crisis of July 1917 did not bring about the Red Revolution of January 1918 on its own, but together with political developments based on the commoners' interpretation of the ideas of Fennomania and socialism, the events favoured a Finnish revolution. In order to win power, the socialists had to overcome Parliament.

The February Revolution resulted in a loss of institutional authority in Finland and the dissolution of the police force, creating fear and uncertainty. In response, both the right and left assembled their own security groups, which were initially local and largely unarmed. By late 1917, following the dissolution of Parliament, in the absence of a strong government and national armed forces, the security groups began assuming a broader and more paramilitary character. The Civil Guards (; ; ) and the later White Guards (; ) were organised by local men of influence: conservative academics, industrialists, major landowners, and activists. The Workers' Order Guards (; ) and the Red Guards (; ) were recruited through the local social democratic party sections and from the labour unions.

The Bolsheviks' and Vladimir Lenin's October Revolution of 7 November 1917 transferred political power in Petrograd to the radical, left-wing socialists. The German government's decision to arrange safe-conduct for Lenin and his comrades from exile in Switzerland to Petrograd in April 1917, was a success. An armistice between Germany and the Bolshevik regime came into force on 6 December and peace negotiations began on 22 December 1917 at Brest-Litovsk.

November 1917 became another watershed in the 1917–1918 rivalry for the leadership of Finland. After the dissolution of the Finnish Parliament, polarisation between the social democrats and the conservatives increased markedly and the period witnessed the appearance of political violence. An agricultural worker was shot during a local strike on 9 August 1917 at Ypäjä and a Civil Guard member was killed in a local political crisis at Malmi on 24 September. The October Revolution disrupted the informal truce between the Finnish non-socialists and the Russian Provisional Government. After political wrangling over how to react to the revolt, the majority of the politicians accepted a compromise proposal by Santeri Alkio, the leader of the Agrarian League. Parliament seized the sovereign power in Finland on 15 November 1917 based on the socialists' "Law of Supreme Power" and ratified their proposals of an eight-hour working day and universal suffrage in local elections, from July 1917.
The purely non-socialist, conservative-led government of Pehr Evind Svinhufvud was appointed on 27 November. This nomination was both a long-term aim of the conservatives and a response to the challenges of the labour movement during November 1917. Svinhufvud's main aspirations were to separate Finland from Russia, to strengthen the Civil Guards, and to return a part of Parliament's new authority to the Senate. There were 149 Civil Guards on 31 August 1917 in Finland, counting local units and subsidiary White Guards in towns and rural communes; 251 on 30 September; 315 on 31 October; 380 on 30 November and 408 on 26 January 1918. The first attempt at serious military training among the Guards was the establishment of a 200-strong cavalry school at the Saksanniemi estate in the vicinity of the town of Porvoo, in September 1917. The vanguard of the Finnish Jägers and German weaponry arrived in Finland during October–November 1917 on the ' freighter and the German U-boat '; around 50 Jägers had returned by the end of 1917.

After political defeats in July and October 1917, the social democrats put forward an uncompromising program called "We Demand" (; ) on 1 November, in order to push for political concessions. They insisted upon a return to the political status before the dissolution of Parliament in July 1917, disbandment of the Civil Guards and elections to establish a Finnish Constituent Assembly. The program failed and the socialists initiated a general strike during 14–19 November to increase political pressure on the conservatives, who had opposed the "Law of Supreme Power" and the parliamentary proclamation of sovereign power on 15 November.

Revolution became the goal of the radicalised socialists after the loss of political control, and events in November 1917 offered momentum for a socialist uprising. In this phase, Lenin and Joseph Stalin, under threat in Petrograd, urged the social democrats to take power in Finland. The majority of Finnish socialists were moderate and preferred parliamentary methods, prompting the Bolsheviks to label them "reluctant revolutionaries". The reluctance diminished as the general strike appeared to offer a major channel of influence for the workers in southern Finland. The strike leadership voted by a narrow majority to start a revolution on 16 November, but the uprising had to be called off the same day due to the lack of active revolutionaries to execute it.
At the end of November 1917, the moderate socialists among the social democrats won a second vote over the radicals in a debate over revolutionary versus parliamentary means, but when they tried to pass a resolution to completely abandon the idea of a socialist revolution, the party representatives and several influential leaders voted it down. The Finnish labour movement wanted to sustain a military force of its own and to keep the revolutionary road open, too. The wavering Finnish socialists disappointed V. I. Lenin and in turn, he began to encourage the Finnish Bolsheviks in Petrograd.

Among the labour movement, a more marked consequence of the events of 1917 was the rise of the Workers' Order Guards. There were 20–60 separate guards between 31 August and 30 September 1917, but on 20 October, after defeat in parliamentary elections, the Finnish labour movement proclaimed the need to establish more worker units. The announcement led to a rush of recruits: on 31 October the number of guards was 100–150; 342 on 30 November 1917 and 375 on 26 January 1918. Since May 1917, the paramilitary organisations of the left had grown in two phases, the majority of them as Workers' Order Guards. The minority were Red Guards, these were partly underground groups formed in industrialised towns and industrial centres, such as Helsinki, Kotka and Tampere, based on the original Red Guards that had been formed during 1905–1906 in Finland.

The presence of the two opposing armed forces created a state of dual power and divided sovereignty on Finnish society. The decisive rift between the guards broke out during the general strike: the Reds executed several political opponents in southern Finland and the first armed clashes between the Whites and Reds took place. In total, 34 casualties were reported. Eventually, the political rivalries of 1917 led to an arms race and an escalation towards civil war.

The disintegration of Russia offered Finns an historic opportunity to gain national independence. After the October Revolution, the conservatives were eager for secession from Russia in order to control the left and minimise the influence of the Bolsheviks. The socialists were skeptical about sovereignty under conservative rule, but they feared a loss of support among nationalistic workers, particularly after having promised increased national liberty through the "Law of Supreme Power". Eventually, both political factions supported an independent Finland, despite strong disagreement over the composition of the nation's leadership.

Nationalism had become a "civic religion" in Finland by the end of nineteenth century, but the goal during the general strike of 1905 was a return to the autonomy of 1809–1898, not full independence. In comparison to the unitary Swedish regime, the domestic power of Finns had increased under the less uniform Russian rule. Economically, the Grand Duchy of Finland benefited from having an independent domestic state budget, a central bank with national currency, the markka (deployed 1860), and customs organisation and the industrial progress of 1860–1916. The economy was dependent on the huge Russian market and separation would disrupt the profitable Finnish financial zone. The economic collapse of Russia and the power struggle of the Finnish state in 1917 were among the key factors that brought sovereignty to the fore in Finland.
Svinhufvud's Senate introduced Finland's Declaration of Independence on 4 December 1917 and Parliament adopted it on 6 December. The social democrats voted against the Senate's proposal, while presenting an alternative declaration of sovereignty. The establishment of an independent state was not a guaranteed conclusion for the small Finnish nation. Recognition by Russia and other great powers was essential; Svinhufvud accepted that he had to negotiate with Lenin for the acknowledgement. The socialists, having been reluctant to enter talks with the Russian leadership in July 1917, sent two delegations to Petrograd to request that Lenin approve Finnish sovereignty.

In December 1917, Lenin was under intense pressure from the Germans to conclude peace negotiations at Brest-Litovsk and the Bolsheviks' rule was in crisis, with an inexperienced administration and the demoralised army facing powerful political and military opponents. Lenin calculated that the Bolsheviks could fight for central parts of Russia but had to give up some peripheral territories, including Finland in the geopolitically less important north-western corner. As a result, Svinhufvud's delegation won Lenin's concession of sovereignty on 31 December 1917.

By the beginning of the Civil War, Austria-Hungary, Denmark, France, Germany, Greece, Norway, Sweden and Switzerland had recognised Finnish independence. The United Kingdom and United States did not approve it; they waited and monitored the relations between Finland and Germany (the main enemy of the Allies), hoping to override Lenin's regime and to get Russia back into the war against the German Empire. In turn, the Germans hastened Finland's separation from Russia so as to move the country to within their sphere of influence.

The final escalation towards war began in early January 1918, as each military or political action of the Reds or the Whites resulted in a corresponding counteraction by the other. Both sides justified their activities as defensive measures, particularly to their own supporters. On the left, the vanguard of the movement was the urban Red Guards from Helsinki, Kotka and Turku; they led the rural Reds and convinced the socialist leaders who wavered between peace and war to support the revolution. On the right, the vanguard was the Jägers, who had transferred to Finland, and the volunteer Civil Guards of southwestern Finland, southern Ostrobothnia and Vyborg province in the southeastern corner of Finland. The first local battles were fought during 9–21 January 1918 in southern and southeastern Finland, mainly to win the arms race and to control Vyborg (; ).
On 12 January 1918, Parliament authorised the Svinhufvud Senate to establish internal order and discipline on behalf of the state. On 15 January, Carl Gustaf Emil Mannerheim, a former Finnish general of the Imperial Russian Army, was appointed the commander-in-chief of the Civil Guards. The Senate appointed the Guards, henceforth called the White Guards, as the White Army of Finland. Mannerheim placed his Headquarters of the White Army in the Vaasa–Seinäjoki area. The White Order to engage was issued on 25 January. The Whites gained weaponry by disarming Russian garrisons during 21–28 January, in particular in southern Ostrobothnia.

The Red Guards, led by Ali Aaltonen, refused to recognise the Whites' hegemony and established a military authority of their own. Aaltonen installed his headquarters in Helsinki and nicknamed it Smolna echoing the Smolny Institute, the Bolsheviks' headquarters in Petrograd. The Red Order of Revolution was issued on 26 January, and a red lantern, a symbolic indicator of the uprising, was lit in the tower of the Helsinki Workers' House. A large-scale mobilisation of the Reds began late in the evening of 27 January, with the Helsinki Red Guard and some of the Guards located along the Vyborg-Tampere railway having been activated between 23 and 26 January, in order to safeguard vital positions and escort a heavy railroad shipment of Bolshevik weapons from Petrograd to Finland. White troops tried to capture the shipment: 20–30 Finns, Red and White, died in the Battle of Kämärä at the Karelian Isthmus on 27 January 1918. The Finnish rivalry for power had culminated.

At the beginning of the war, a discontinuous front line ran through southern Finland from west to east, dividing the country into White Finland and Red Finland. The Red Guards controlled the area to the south, including nearly all the major towns and industrial centres, along with the largest estates and farms with the highest numbers of crofters and tenant farmers. The White Army controlled the area to the north, which was predominantly agrarian and contained small or medium-sized farms and tenant farmers. The number of crofters was lower and they held a better social status than those in the south. Enclaves of the opposing forces existed on both sides of the front line: within the White area lay the industrial towns of Varkaus, Kuopio, Oulu, Raahe, Kemi and Tornio; within the Red area lay Porvoo, Kirkkonummi and Uusikaupunki. The elimination of these strongholds was a priority for both armies in February 1918.

Red Finland was led by the People's Delegation (; ), established on 28 January 1918 in Helsinki. The delegation sought democratic socialism based on the Finnish Social Democratic Party's ethos; their visions differed from Lenin's dictatorship of the proletariat. Otto Ville Kuusinen formulated a proposal for a new constitution, influenced by those of Switzerland and the United States. With it, political power was to be concentrated to Parliament, with a lesser role for a government. The proposal included a multi-party system; freedom of assembly, speech and press; and the use of referenda in political decision-making. In order to ensure the authority of the labour movement, the common people would have a right to permanent revolution. The socialists planned to transfer a substantial part of property rights to the state and local administrations.

In foreign policy, Red Finland leaned on Bolshevist Russia. A Red-initiated Finno–Russian treaty and peace agreement was signed on 1 March 1918, where Red Finland was called the Finnish Socialist Workers' Republic (; ). The negotiations for the treaty implied that –as in World War I in general– nationalism was more important for both sides than the principles of international socialism. The Red Finns did not simply accept an alliance with the Bolsheviks and major disputes appeared, for example, over the demarcation of the border between Red Finland and Soviet Russia. The significance of the Russo–Finnish Treaty evaporated quickly due to the signing of the Treaty of Brest-Litovsk between the Bolsheviks and the German Empire on 3 March 1918.

Lenin's policy on the right of nations to self-determination aimed at preventing the disintegration of Russia during the period of military weakness. He assumed that in war-torn, splintering Europe, the proletariat of free nations would carry out socialist revolutions and unite with Soviet Russia later. The majority of the Finnish labour movement supported Finland's independence. The Finnish Bolsheviks, influential, though few in number, favoured annexation of Finland by Russia.

The government of White Finland, Pehr Evind Svinhufvud's first senate, was called the Vaasa Senate after its relocation to the safer west-coast city of Vaasa, which acted as the capital of the Whites from 29 January to 3 May 1918. In domestic policy, the White Senate's main goal was to return the political right to power in Finland. The conservatives planned a monarchist political system, with a lesser role for Parliament. A section of the conservatives had always supported monarchy and opposed democracy; others had approved of parliamentarianism since the revolutionary reform of 1906, but after the crisis of 1917–1918, concluded that empowering the common people would not work. Social liberals and reformist non-socialists opposed any restriction of parliamentarianism. They initially resisted German military help, but the prolonged warfare changed their stance.

In foreign policy, the Vaasa Senate relied on the German Empire for military and political aid. Their objective was to defeat the Finnish Reds; end the influence of Bolshevist Russia in Finland and expand Finnish territory to East Karelia, a geopolitically significant home to people speaking Finno-Ugric languages. The weakness of Russia inspired an idea of Greater Finland among the expansionist factions of both the right and left: the Reds had claims concerning the same areas. General Mannerheim agreed on the need to take over East Karelia and to request German weapons, but opposed actual German intervention in Finland. Mannerheim recognised the Red Guards' lack of combat skill and trusted in the abilities of the German-trained Finnish Jägers. As a former Russian army officer, Mannerheim was well aware of the demoralisation of the Russian army. He co-operated with White-aligned Russian officers in Finland and Russia.

The number of Finnish troops on each side varied from 70,000 to 90,000 and both had around 100,000 rifles, 300–400 machine guns and a few hundred cannons. While the Red Guards consisted mostly of volunteers, with wages paid at the beginning of the war, the White Army consisted predominantly of conscripts with 11,000–15,000 volunteers. The main motives for volunteering were socio-economic factors, such as salary and food, as well as idealism and peer pressure. The Red Guards included 2,600 women, mostly girls recruited from the industrial centres and cities of southern Finland. Urban and agricultural workers constituted the majority of the Red Guards, whereas land-owning farmers and well-educated people formed the backbone of the White Army. Both armies used child soldiers, mainly between 14 and 17 years of age. The use of juvenile soldiers was not rare in World War I; children of the time were under the absolute authority of adults and were not shielded against exploitation.

Rifles and machine guns from Imperial Russia were the main armaments of the Reds and the Whites. The most commonly used rifle was the Russian Mosin–Nagant Model 1891. In total, around ten different rifle models were in service, causing problems for ammunition supply. The Maxim gun was the most-used machine gun, along with the less-used M1895 Colt–Browning, Lewis and Madsen guns. The machine guns caused a substantial part of the casualties in combat. Russian field guns were mostly used with direct fire.
The Civil War was fought primarily along railways; vital means for transporting troops and supplies, as well for using armoured trains, equipped with light cannons and heavy machine guns. The strategically most important railway junction was Haapamäki, approximately northeast of Tampere, connecting eastern and western Finland and as well as southern and northern Finland. Other critical junctions included Kouvola, Riihimäki, Tampere, Toijala and Vyborg. The Whites captured Haapamäki at the end of January 1918, leading to the Battle of Vilppula.

The Finnish Red Guards seized the early initiative in the war by taking control of Helsinki on 28 January 1918 and by undertaking a general offensive lasting from February till early March 1918. The Reds were relatively well-armed, but a chronic shortage of skilled leaders, both at the command level and in the field, left them unable to capitalise on this momentum, and most of the offensives came to nothing. The military chain of command functioned relatively well at company and platoon level, but leadership and authority remained weak as most of the field commanders were chosen by the vote of the troops. The common troops were more or less armed civilians, whose military training, discipline and combat morale were both inadequate and low.

Ali Aaltonen was replaced on 28 January 1918 by Eero Haapalainen as commander-in-chief. He, in turn, was displaced by the Bolshevik triumvirate of Eino Rahja, Adolf Taimi and Evert Eloranta on 20 March. The last commander-in-chief of the Red Guard was Kullervo Manner, from 10 April until the last period of the war when the Reds no longer had a named leader. Some talented local commanders, such as Hugo Salmela in the Battle of Tampere, provided successful leadership, but could not change the course of the war. The Reds achieved some local victories as they retreated from southern Finland toward Russia, such as against German troops in the Battle of Syrjäntaka on 28–29 April in Tuulos.

The revolutions in Russia divided the Soviet army officers politically and their attitude towards the Finnish Civil War varied. Mikhail Svechnikov led Finnish Red troops in western Finland in February and Konstantin Yeremejev Soviet forces on the Karelian Isthmus, while other officers were mistrustful of their revolutionary peers and instead co-operated with General Mannerheim, in disarming Soviet garrisons in Finland. On 30 January 1918, Mannerheim proclaimed to Russian soldiers in Finland that the White Army did not fight against Russia, but that the objective of the White campaign was to beat the Finnish Reds and the Soviet troops supporting them.

The number of Soviet soldiers active in the civil war declined markedly once Germany attacked Russia on 18 February 1918. The German-Soviet Treaty of Brest-Litovsk of 3 March restricted the Bolsheviks' support for the Finnish Reds to weapons and supplies. The Soviets remained active on the south-eastern front, mainly in the Battle of Rautu on the Karelian Isthmus between February and April 1918, where they defended the approaches to Petrograd.

While the conflict has been called by some, "The War of Amateurs", the White Army had two major advantages over the Red Guards: the professional military leadership of Gustaf Mannerheim and his staff, which included 84 Swedish volunteer officers and former Finnish officers of the czar's army; and 1,450 soldiers of the 1,900-strong, Jäger battalion. The majority of the unit arrived in Vaasa on 25 February 1918. On the battlefield, the Jägers, battle-hardened on the Eastern Front, provided strong leadership that made disciplined combat of the common White troopers possible. The soldiers were similar to those of the Reds, having brief and inadequate training. At the beginning of the war, the White Guards' top leadership had little authority over volunteer White units, which obeyed only their local leaders. At the end of February, the Jägers started a rapid training of six conscript regiments.

The Jäger battalion was politically divided, too. Four-hundred-and-fifty –mostly socialist– Jägers remained stationed in Germany, as it was feared they were likely to side with the Reds. White Guard leaders faced a similar problem when drafting young men to the army in February 1918: 30,000 obvious supporters of the Finnish labour movement never showed up. It was also uncertain whether common troops drafted from the small-sized and poor farms of central and northern Finland had strong enough motivation to fight the Finnish Reds. The Whites' propaganda promoted the idea that they were fighting a defensive war against Bolshevist Russians, and belittled the role of the Red Finns among their enemies. Social divisions appeared both between southern and northern Finland and within rural Finland. The economy and society of the north had modernised more slowly than that of the south. There was a more pronounced conflict between Christianity and socialism in the north, and the ownership of farmland conferred major social status, motivating the farmers to fight against the Reds.

Sweden declared neutrality both during World War I and the Finnish Civil War. General opinion, in particular among the Swedish elite, was divided between supporters of the Allies and the Central powers, Germanism being somewhat more popular. Three war-time priorities determined the pragmatic policy of the Swedish liberal-social democratic government: sound economics, with export of iron-ore and foodstuff to Germany; sustaining the tranquility of Swedish society; and geopolitics. The government accepted the participation of Swedish volunteer officers and soldiers in the Finnish White Army in order to block expansion of revolutionary unrest to Scandinavia.

A 1,000-strong paramilitary Swedish Brigade, led by Hjalmar Frisell, took part in the Battle of Tampere and in the fighting south of the town. In February 1918, the Swedish Navy escorted the German naval squadron transporting Finnish Jägers and German weapons and allowed it to pass through Swedish territorial waters. The Swedish socialists tried to open peace negotiations between the Whites and the Reds. The weakness of Finland offered Sweden a chance to take over the geopolitically vital Finnish Åland Islands, east of Stockholm, but the German army's Finland operation stalled this plan.

In March 1918, the German Empire intervened in the Finnish Civil War on the side of the White Army. Finnish activists leaning on Germanism had been seeking German aid in freeing Finland from Soviet hegemony since late 1917, but because of the pressure they were facing at the Western Front, the Germans did not want to jeopardise their armistice and peace negotiations with the Soviet Union. The German stance changed after 10 February when Leon Trotsky, despite the weakness of the Bolsheviks' position, broke off negotiations, hoping revolutions would break out in the German Empire and change everything. On 13 February, the German leadership decided to retaliate and send military detachments to Finland too. As a pretext for aggression, the Germans invited "requests for help" from the western neighbouring countries of Russia. Representatives of White Finland in Berlin duly requested help on 14 February.

The Imperial German Army attacked Russia on 18 February. The offensive led to a rapid collapse of the Soviet forces and to the signing of the first Treaty of Brest-Litovsk by the Bolsheviks on 3 March 1918. Finland, the Baltic countries, Poland and Ukraine were transferred to the German sphere of influence. The Finnish Civil War opened a low-cost access route to Fennoscandia, where the geopolitical status was altered as a British Naval squadron invaded the Soviet harbour of Murmansk by the Arctic Ocean on 9 March 1918. The leader of the German war effort, General Erich Ludendorff, wanted to keep Petrograd under threat of attack via the Vyborg-Narva area and to install a German-led monarchy in Finland.

On 5 March 1918, a German naval squadron landed on the Åland Islands (in mid-February 1918, the islands had been occupied by a Swedish military expedition, which departed from there in May). On 3 April 1918, the 10,000-strong Baltic Sea Division (), led by General Rüdiger von der Goltz, launched the main attack at Hanko, west of Helsinki. It was followed on 7 April by Colonel Otto von Brandenstein's 3,000-strong Detachment Brandenstein () taking the town of Loviisa east of Helsinki. The larger German formations advanced eastwards from Hanko and took Helsinki on 12–13 April, while Detachment Brandenstein overran the town of Lahti on 19 April. The main German detachment proceeded northwards from Helsinki and took Hyvinkää and Riihimäki on 21–22 April, followed by Hämeenlinna on 26 April. The final blow to the cause of the Finnish Reds was dealt when the Bolsheviks broke off the peace negotiations at Brest-Litovsk, leading to the German eastern offensive in February 1918.

In February 1918, General Mannerheim deliberated on where to focus the general offensive of the Whites. There were two strategically vital enemy strongholds: Tampere, Finland's major industrial town in the south-west, and Vyborg, Karelia's main city. Although seizing Vyborg offered many advantages, his army's lack of combat skills and the potential for a major counterattack by the Reds in the area or in the south-west made it too risky.

Mannerheim decided to strike first at Tampere. He launched the main assault on 16 March 1918, at Längelmäki north-east of the town, through the right flank of the Reds' defence. At the same time, the Whites attacked through the north-western frontline Vilppula–Kuru–Kyröskoski–Suodenniemi. Although the Whites were unaccustomed to offensive warfare, some Red Guard units collapsed and retreated in panic under the weight of the offensive, while other Red detachments defended their posts to the last and were able to slow the advance of the White troops. Eventually, the Whites lay siege to Tampere. They cut off the Reds' southward connection at Lempäälä on 24 March and westward ones at Siuro, Nokia, and Ylöjärvi on 25 March.

The Battle for Tampere was fought between 16,000 White and 14,000 Red soldiers. It was Finland's first large-scale urban battle and one of the four most decisive military engagements of the war. The fight for the area of Tampere began on 28 March, on the eve of Easter 1918, later called "Bloody Maundy Thursday", in the Kalevankangas cemetery. The White Army did not achieve a decisive victory in the fierce combat, suffering more than 50 percent losses in some of their units. The Whites had to re-organise their troops and battle plans, managing to raid the town centre in the early hours of 3 April.

After a heavy, concentrated artillery barrage, the White Guards advanced from house to house and street to street, as the Red Guards retreated. In the late evening of 3 April, the Whites reached the eastern banks of the Tammerkoski rapids. The Reds' attempts to break the siege of Tampere from the outside along the Helsinki-Tampere railway failed. The Red Guards lost the western parts of the town between 4 and 5 April. The Tampere City Hall was among the last strongholds of the Reds. The battle ended 6 April 1918 with the surrender of Red forces in the Pyynikki and Pispala sections of Tampere.

The Reds, now on the defensive, showed increased motivation to fight during the battle. General Mannerheim was compelled to deploy some of the best-trained Jäger detachments, initially meant to be conserved for later use in the Vyborg area. The Battle of Tampere was the bloodiest action of the Civil War. The White Army lost 700–900 men, including 50 Jägers, the highest number of deaths the Jäger battalion suffered in a single battle of the 1918 war. The Red Guards lost 1,000–1,500 soldiers, with a further 11,000–12,000 captured. 71 civilians died, mainly due to artillery fire. The eastern parts of the city, consisting mostly of wooden buildings, were completely destroyed.

After peace talks between Germans and the Finnish Reds were broken off on 11 April 1918, the battle for the capital of Finland began. At 05:00 on 12 April, around 2,000–3,000 German Baltic Sea Division soldiers, led by Colonel Hans von Tschirsky und von Bögendorff, attacked the city from the north-west, supported via the Helsinki-Turku railway. The Germans broke through the area between Munkkiniemi and Pasila, and advanced on the central-western parts of the town. The German naval squadron led by Vice Admiral Hugo Meurer blocked the city harbour, bombarded the southern town area, and landed "Seebataillon" marines at Katajanokka.

Around 7,000 Finnish Reds defended Helsinki, but their best troops fought on other fronts of the war. The main strongholds of the Red defence were the Workers' Hall, the Helsinki railway station, the Red Headquarters at Smolna, the Senate Palace–Helsinki University area and the former Russian garrisons. By the late evening of 12 April, most of the southern parts and all of the western area of the city had been occupied by the Germans. Local Helsinki White Guards, having hidden in the city during the war, joined the battle as the Germans advanced through the town.

On 13 April, German troops took over the Market Square, the Smolna, the Presidential Palace and the Senate-Ritarihuone area. Toward the end, a German brigade with 2,000–3,000 soldiers, led by Colonel Kondrad Wolf joined the battle. The unit rushed from north to the eastern parts of Helsinki, pushing into the working-class neighborhoods of Hermanni, Kallio and Sörnäinen. German artillery bombarded and destroyed the Workers' Hall and put out the red lantern of the Finnish revolution. The eastern parts of the town surrendered around 14:00 on 13 April, when a white flag was raised in the tower of the Kallio Church. Sporadic fighting lasted until the evening. In total, 60 Germans, 300–400 Reds and 23 White Guard troopers were killed in the battle. Around 7,000 Reds were captured. The German army celebrated the victory with a military parade in the centre of Helsinki on 14 April 1918.

On 19 April 1918, Detachment Brandenstein took over the town of Lahti. The German troops advanced from the east-southeast via Nastola, through the Mustankallio graveyard in Salpausselkä and the Russian garrisons at Hennala. The battle was minor but strategically important as it cut the connection between the western and eastern Red Guards. Local engagements broke out in the town and the surrounding area between 22 April and 1 May 1918 as several thousand western Red Guards and Red civilian refugees tried to push through on their way to Russia. The German troops were able to hold major parts of the town and halt the Red advance. In total, 600 Reds and 80 German soldiers perished, and 30,000 Reds were captured in and around Lahti.

After the defeat in Tampere, the Red Guards began a slow retreat eastwards. As the German army seized Helsinki, the White Army shifted the military focus to Vyborg area, where 18,500 Whites advanced against 15,000 defending Reds. General Mannerheim's war plan had been revised as a result of the Battle for Tampere, a civilian, industrial town. He aimed to avoid new, complex city combat in Vyborg, an old military fortress. The Jäger detachments tried to tie down and destroy the Red force outside the town. The Whites were able to cut the Reds' connection to Petrograd and weaken the troops on the Karelian Isthmus on 20–26 April, but the decisive blow remained to be dealt in Vyborg. The final attack began on late 27 April with a heavy Jäger artillery barrage. The Reds' defence collapsed gradually, and eventually the Whites conquered Patterinmäki—the Reds' symbolic last stand of the 1918 uprising—in the early hours of 29 April 1918. In total, 400 Whites died, and 500–600 Reds perished and 12,000–15,000 were captured.

Both Whites and Reds carried out political violence through executions, respectively termed White Terror (; ) and Red Terror (; ). The threshold of political violence had already been crossed by the Finnish activists during the First Period of Russification. Large-scale terror operations were born and bred in Europe during World War I, the first total war. The February and October Revolutions initiated similar violence in Finland: at first by Russian army troops executing their officers, later between the Finnish Reds and Whites.

The terror consisted of a calculated aspect of general warfare and, on the other hand, the local, personal murders and corresponding acts of revenge. In the former, the commanding staff planned and organised the actions and gave orders to the lower ranks. At least a third of the Red terror and most of the White terror was centrally led. In February 1918, a "Desk of Securing Occupied Areas" was implemented by the highest-ranking White staff, and the White troops were given "Instructions for Wartime Judicature", later called the Shoot on the Spot Declaration. This order authorised field commanders to execute essentially anyone they saw fit. No order by the less-organised, highest Red Guard leadership authorising Red Terror has been found. The paper was "burned" or the command was oral.

The main goals of the terror were to destroy the command structure of the enemy; to clear and secure the areas governed and occupied by armies; and to create shock and fear among the civil population and the enemy soldiers. Additionally, the common troops' paramilitary nature and their lack of combat skills drove them to use political violence as a military weapon. Most of the executions were carried out by cavalry units called Flying Patrols, consisting of 10 to 80 soldiers aged 15 to 20 and led by an experienced, adult leader with absolute authority. The patrols, specialised in search and destroy operations and death squad tactics, were similar to German Sturmbattalions and Russian Assault units organized during World War I. The terror achieved some of its objectives but also gave additional motivation to fight against an enemy perceived to be inhuman and cruel. Both Red and White propaganda made effective use of their opponents' actions, increasing the spiral of revenge.
The Red Guards executed influential Whites, including politicians, major landowners, industrialists, police officers, civil servants and teachers as well as White Guards. Ten priests of the Evangelical Lutheran Church and 90 moderate socialists were killed. The number of executions varied over the war months, peaking in February as the Reds secured power, but March saw low counts because the Reds could not seize new areas outside of the original frontlines. The numbers rose again in April as the Reds aimed to leave Finland. The two major centres for Red Terror were Toijala and Kouvola, where 300–350 Whites were executed between February and April 1918.

The White Guards executed Red Guard and party leaders, Red troops, socialist members of the Finnish Parliament and local Red administrators, and those active in implementing Red Terror. The numbers varied over the months as the Whites conquered southern Finland. Comprehensive White Terror started with their general offensive in March 1918 and increased constantly. It peaked at the end of the war and declined and ceased after the enemy troops had been transferred to prison camps. During the high point of the executions, between the end of April and the beginning of May, 200 Reds were shot per day. White Terror was decisive against Russian soldiers who assisted the Finnish Reds, and several Russian non-socialist civilians were killed in the Vyborg massacre, the aftermath of the Battle of Vyborg.

In total, 1,650 Whites died as a result of Red Terror, while around 10,000 Reds perished by White Terror, which turned into political cleansing. White victims have been recorded exactly, while the number of Red troops executed immediately after battles remains unclear. Together with the harsh prison-camp treatment of the Reds during 1918, the executions inflicted the deepest mental scars on the Finns, regardless of their political allegiance. Some of those who carried out the killings were traumatised, a phenomenon that was later documented.

On 8 April 1918, after the defeat in Tampere and the German army intervention, the People's Delegation retreated from Helsinki to Vyborg. The loss of Helsinki pushed them to Petrograd on 25 April. The escape of the leadership embittered many Reds, and thousands of them tried to flee to Russia, but most of the refugees were encircled by White and German troops. In the Lahti area they surrendered on 1–2 May. The long Red caravans included women and children, who experienced a desperate, chaotic escape with severe losses due to White attacks. The scene was described as a "road of tears" for the Reds, but for the Whites, the sight of long, enemy caravans heading east was a victorious moment. The Red Guards' last strongholds between the Kouvola and Kotka area fell by 5 May, after the Battle of Ahvenkoski. The war of 1918 ended on 15 May 1918, when the Whites took over Fort Ino, a Russian coastal artillery base on the Karelian Isthmus, from the Russian troops. White Finland and General Mannerheim celebrated the victory with a large military parade in Helsinki on 16 May 1918.

The Red Guards had been defeated. The initially pacifist Finnish labour movement had lost the Civil War, several military leaders committed suicide and a majority of the Reds were sent to prison camps. The Vaasa Senate returned to Helsinki on 4 May 1918, but the capital was under the control of the German army. White Finland had become a protectorate of the German Empire and General Rüdiger von der Goltz was called "the true Regent of Finland". No armistice or peace negotiations were carried out between the Whites and Reds and an official peace treaty to end the Finnish Civil War was never signed.

The White Army and German troops captured around 80,000 Red prisoners of war (POWs), including 5,000 women, 1,500 children and 8,000 Russians. The largest prison camps were Suomenlinna (an island facing Helsinki), Hämeenlinna, Lahti, Riihimäki, Tammisaari, Tampere and Vyborg. The Senate decided to keep the POWs detained until each individual's role in the Civil War had been investigated. Legislation making provision for a Treason Court (; ) was enacted on 29 May 1918. The judicature of the 145 inferior courts led by the Supreme Treason Court (; ) did not meet the standards of impartiality, due to the condemnatory atmosphere of White Finland. In total 76,000 cases were examined and 68,000 Reds were convicted, primarily for treason; 39,000 were released on parole while the mean-length of punishment for the rest was two to four years in jail. 555 people were sentenced to death, of whom 113 were executed. The trials revealed that some innocent adults had been imprisoned.

Combined with the severe food shortages caused by the Civil War, mass imprisonment led to high mortality rates in the POW camps, and the catastrophe was compounded by the angry, punitive and uncaring mentality of the victors. Many prisoners felt that they had been abandoned by their own leaders, who had fled to Russia. The physical and mental condition of the POWs declined in May 1918. Many prisoners had been sent to the camps in Tampere and Helsinki in the first half of April and food supplies were disrupted during the Reds' eastward retreat. Consequently, in June 2,900 prisoners starved to death, or died as a result of diseases caused by malnutrition or the Spanish flu: 5,000 in July; 2,200 in August; and 1,000 in September. The mortality rate was highest in the Tammisaari camp at 34 percent, while the rate varied between 5 percent and 20 percent in the others. In total, around 12,500 Finns perished (3,000–4,000 due to the Spanish flu) while detained. The dead were buried in mass graves near the camps. Moreover, 700 severely weakened POWs died soon after release from the camps.

Most POWs were paroled or pardoned by the end of 1918, after a shift in the political situation. There were 6,100 Red prisoners left at the end of the year and 4,000 at the end of 1919. In January 1920, 3,000 POWs were pardoned and civil rights were returned to 40,000 former Reds. In 1927, the Social Democratic Party government led by Väinö Tanner pardoned the last 50 prisoners. The Finnish government paid reparations to 11,600 POWs in 1973. The traumatic hardships of the prison camps increased support for communism in Finland.

The Civil War was a catastrophe for Finland: around 36,000 people – 1.2 percent of the population – perished. The war left approximately 15,000 children orphaned. Most of the casualties occurred outside the battlefields: in the prison camps and the terror campaigns. Many Reds fled to Russia at the end of the war and during the period that followed. The fear, bitterness and trauma caused by the war deepened the divisions within Finnish society and many moderate Finns identified themselves as "citizens of two nations."

The conflict caused disintegration within both socialist and non-socialist factions. The rightward shift of power caused a dispute between conservatives and liberals on the best system of government for Finland to adopt: the former demanded monarchy and restricted parliamentarianism; the latter demanded a democratic republic. Both sides justified their views on political and legal grounds. The monarchists leaned on the Swedish regime's 1772 monarchist constitution (accepted by Russia in 1809), belittled the Declaration of Independence of 1917, and proposed a modernised, monarchist constitution for Finland. The republicans argued that the 1772 law lost validity in the February Revolution, that the authority of the Russian czar was assumed by the Finnish Parliament on 15 November 1917, and that the Republic of Finland had been adopted on 6 December that year. The republicans were able to halt the passage of the monarchists' proposal in Parliament. The royalists responded by applying the 1772 law to select a new monarch for the country without reference to Parliament.

The Finnish labour movement was divided into three parts: moderate social democrats in Finland; radical socialists in Finland; and communists in Soviet Russia. The Social Democratic Party had its first official party meeting after the Civil War on 25 December 1918, at which the party proclaimed a commitment to parliamentary means and disavowed Bolshevism and communism. The leaders of Red Finland, who had fled to Russia, established the Communist Party of Finland in Moscow on 29 August 1918. After the power struggle of 1917 and the bloody civil war, the former Fennomans and the social democrats who had supported "ultra-democratic" means in Red Finland declared a commitment to revolutionary Bolshevism–communism and to the dictatorship of the proletariat, under the control of Lenin.

In May 1918, a conservative-monarchist Senate was formed by J. K. Paasikivi, and the Senate asked the German troops to remain in Finland. 3 March 1918 Treaty of Brest-Litovsk and 7 March German-Finnish agreements bound White Finland to the German Empire's sphere of influence. General Mannerheim resigned his post on 25 May after disagreements with the Senate about German hegemony over Finland, and about his planned attack on Petrograd to repulse the Bolsheviks and capture Russian Karelia. The Germans opposed these plans due to their peace treaties with Lenin. The Civil War weakened the Finnish Parliament; it became a Rump Parliament that included only three socialist representatives.

On 9 October 1918, under pressure from Germany, the Senate and Parliament elected a German prince, Friedrich Karl, the brother-in-law of German Emperor William II, to become the King of Finland. The German leadership was able to utilise the breakdown of Russia for the geopolitical benefit of the German Empire in Fennoscandia also. The Civil War and the aftermath diminished independence of Finland, compared to the status it had held at the turn of the year 1917–1918.

The economic condition of Finland deteriorated drastically from 1918; recovery to pre-conflict levels was achieved only in 1925. The most acute crisis was in food supply, already deficient in 1917, though large-scale starvation had been avoided that year. The Civil War caused marked starvation in southern Finland. Late in 1918, Finnish politician Rudolf Holsti appealed for relief to Herbert Hoover, the American chairman of the Committee for Relief in Belgium. Hoover arranged for the delivery of food shipments and persuaded the Allies to relax their blockade of the Baltic Sea, which had obstructed food supplies to Finland, and to allow food into the country.

On 15 March 1917, the fate of Finns had been decided outside Finland, in Petrograd. On 11 November 1918, the future of the nation was determined in Berlin, as a result of Germany's surrender to end World War I. The German Empire collapsed in the German Revolution of 1918–19, caused by lack of food, war-weariness and defeat in the battles of the Western Front. General Rüdiger von der Goltz and his division left Helsinki on 16 December 1918, and Prince Friedrich Karl, who had not yet been crowned, abandoned his role four days later. Finland's status shifted from a monarchist protectorate of the German Empire to an independent republic. The new system of government was confirmed by the Constitution Act (; ) on 17 July 1919.

The first local elections based on universal suffrage in Finland were held during 17–28 December 1918, and the first free parliamentary election took place after the Civil War on 3 March 1919. The United States and the United Kingdom recognised Finnish sovereignty on 6–7 May 1919. The Western powers demanded the establishment of democratic republics in post-war Europe, to lure the masses away from widespread revolutionary movements. The Finno–Russian Treaty of Tartu was signed on 14 October 1920, with the aim of stabilizing political relations between Finland and Russia and settling the border question.

In April 1918, the leading Finnish social liberal and the eventual first President of Finland, Kaarlo Juho Ståhlberg wrote: "It is urgent to get the life and development in this country back on the path that we had already reached in 1906 and which the turmoil of war turned us away from." Moderate social democrat Väinö Voionmaa agonised in 1919: "Those who still trust in the future of this nation must have an exceptionally strong faith. This young independent country has lost almost everything due to the war." Voionmaa was a vital companion for the leader of the reformed Social Democratic Party, Väinö Tanner.

Santeri Alkio supported moderate politics. His party colleague, Kyösti Kallio urged in his Nivala address of 5 May 1918: "We must rebuild a Finnish nation, which is not divided into the Reds and Whites. We have to establish a democratic Finnish republic, where all the Finns can feel that we are true citizens and members of this society." In the end, many of the moderate Finnish conservatives followed the thinking of National Coalition Party member Lauri Ingman, who wrote in early 1918: "A political turn more to the right will not help us now, instead it would strengthen the support of socialism in this country."

Together with other broad-minded Finns, the new partnership constructed a Finnish compromise which eventually delivered a stable and broad parliamentary democracy. The compromise was based both on the defeat of the Reds in the Civil War and the fact that most of the Whites' political goals had not been achieved. After foreign forces left Finland, the militant factions of the Reds and the Whites lost their backing, while the pre-1918 cultural and national integrity and the legacy of Fennomania stood out among the Finns.

The weakness of both Germany and Russia after World War I empowered Finland and made a peaceful, domestic Finnish social and political settlement possible. A reconciliation process led to a slow and painful, but steady, national unification. In the end, the power vacuum and interregnum of 1917–1919 gave way to the Finnish compromise. From 1919 to 1991, the democracy and sovereignty of the Finns withstood challenges from right-wing and left-wing political radicalism, the crisis of World War II and pressure from the Soviet Union during the Cold War.

Between 1918 and the 1950s, mainstream literature and poetry presented the 1918 war from the White victors' point of view, with works such as the "Psalm of the Cannons" () by Arvi Järventaus in 1918. In poetry, Bertel Gripenberg, who had volunteered for the White Army, celebrated its cause in "The Great Age" () in 1928 and V. A. Koskenniemi in "Young Anthony" () in 1918. The war tales of the Reds were kept silent.

The first neutrally critical books were written soon after the war, notably, "Devout Misery" () written by the Nobel Prize laureate Frans Emil Sillanpää in 1919; "Dead Apple Trees" () by Joel Lehtonen in 1918; and "Homecoming" () by Runar Schildt in 1919. These were followed by Jarl Hemmer in 1931 with the book "A Man and His Conscience" () and Oiva Paloheimo in 1942 with "Restless Childhood" (). Lauri Viita's book "Scrambled Ground" () from 1950 presented the life and experiences of a worker family in the Tampere of 1918, including a point of view from outsiders to the Civil War.

Between 1959 and 1962, Väinö Linna described in his trilogy "Under the North Star" () the Civil War and World War II from the viewpoint of the common people. Part II of Linna's work opened a larger view of these events and included tales of the Reds in the 1918 war. At the same time, a new outlook on the war was opened by Paavo Haavikko's book "Private Matters" (), Veijo Meri's "The Events of 1918" () and Paavo Rintala's "My Grandmother and Mannerheim" (), all published in 1960. In poetry, Viljo Kajava, who had experienced the Battle of Tampere at the age of nine, presented a pacifist view of the Civil War in his "Poems of Tampere" () in 1966. The same battle is described in the novel "Corpse Bearer" () by Antti Tuuri from 2007. Jenni Linturi's multilayered "Malmi 1917" (2013) describes contradictory emotions and attitudes in a village drifting towards civil war.

Väinö Linna's trilogy turned the general tide, and after it, several books were written mainly from the Red viewpoint: The Tampere-trilogy by Erkki Lepokorpi in 1977; Juhani Syrjä's "Juho 18" in 1998; "The Command" () by Leena Lander in 2003; and "Sandra" by Heidi Köngäs in 2017. Kjell Westö's epic novel "Where We Once Went" (), published in 2006, deals with the period of 1915–1930 from both the Red and the White sides. Westö's book "Mirage 38" () from 2013, describes post-war traumas of the 1918 war and Finnish mentality in the 1930s. Many of the stories have been utilised in motion pictures and in theatre.





</doc>
<doc id="11773" url="https://en.wikipedia.org/wiki?curid=11773" title="Flynn effect">
Flynn effect

The Flynn effect is the substantial and long-sustained increase in both fluid and crystallized intelligence test scores that were measured in many parts of the world over the 20th century. When intelligence quotient (IQ) tests are initially standardized using a sample of test-takers, by convention the average of the test results is set to 100 and their standard deviation is set to 15 or 16 IQ points. When IQ tests are revised, they are again standardized using a new sample of test-takers, usually born more recently than the first. Again, the average result is set to 100. However, when the new test subjects take the older tests, in almost every case their average scores are significantly above 100.

Test score increases have been continuous and approximately linear from the earliest years of testing to the present. For the Raven's Progressive Matrices test, a study published in the year 2009 found that British children's average scores rose by 14 IQ points from 1942 to 2008. Similar gains have been observed in many other countries in which IQ testing has long been widely used, including other Western European countries, Japan, and South Korea.

There are numerous proposed explanations of the Flynn effect, as well as some skepticism about its implications. Similar improvements have been reported for other cognitions such as semantic and episodic memory. Research suggests that there is an ongoing reversed Flynn effect, i.e. a decline in IQ scores, in Norway, Denmark, Australia, Britain, the Netherlands, Sweden, Finland, France and German-speaking countries, a development which appears to have started in the 1990s.

The Flynn effect is named for James R. Flynn, who did much to document it and promote awareness of its implications. The term itself was coined by Richard Herrnstein and Charles Murray, authors of "The Bell Curve". Although the general term for the phenomenon—referring to no researcher in particular—continues to be "secular rise in IQ scores", many textbooks on psychology and IQ testing have now followed the lead of Herrnstein and Murray in calling the phenomenon the Flynn effect.

IQ tests are updated periodically. For example, the Wechsler Intelligence Scale for Children (WISC), originally developed in 1949, was updated in 1974, 1991, 2003 and again in 2014. The revised versions are standardized based on the performance of test-takers in standardization samples. A standard score of IQ 100 is defined as the median performance of the standardization sample. Thus one way to see changes in norms over time is to conduct a study in which the same test-takers take both an old and new version of the same test. Doing so confirms IQ gains over time. Some IQ tests, for example tests used for military draftees in NATO countries in Europe, report raw scores, and those also confirm a trend of rising scores over time. The average rate of increase seems to be about three IQ points per decade in the United States, as scaled by the Wechsler tests. The increasing test performance over time appears on every major test, in every age range, at every ability level, and in every modern industrialized country, although not necessarily at the same rate as in the United States. The increase was continuous and roughly linear from the earliest days of testing to the mid-1990s. Though the effect is most associated with IQ increases, a similar effect has been found with increases in attention and of semantic and episodic memory.

Ulric Neisser estimated that using the IQ values of 1997, the average IQ of the United States in 1932, according to the first Stanford–Binet Intelligence Scales standardization sample, was 80. Neisser states that "Hardly any of them would have scored 'very superior', but nearly one-quarter would have appeared to be 'deficient.'" He also wrote that "Test scores are certainly going up all over the world, but whether intelligence itself has risen remains controversial."

Trahan et al. (2014) found that the effect was about 2.93 points per decade, based on both Stanford–Binet and Wechsler tests; they also found no evidence the effect was diminishing. In contrast, Pietschnig and Voracek (2015) reported, in their meta-analysis of studies involving nearly 4 million participants, that the Flynn effect had decreased in recent decades. They also reported that the magnitude of the effect was different for different types of intelligence ("0.41, 0.30, 0.28, and 0.21 IQ points annually for fluid, spatial, full-scale, and crystallized IQ test performance, respectively"), and that the effect was stronger for adults than for children.

Raven (2000) found that, as Flynn suggested, data interpreted as showing a decrease in many abilities with increasing age must be re-interpreted as showing that there has been a dramatic increase of these abilities with date of birth. On many tests this occurs at all levels of ability.

Some studies have found the gains of the Flynn effect to be particularly concentrated at the lower end of the distribution. Teasdale and Owen (1989), for example, found the effect primarily reduced the number of low-end scores, resulting in an increased number of moderately high scores, with no increase in very high scores. In another study, two large samples of Spanish children were assessed with a 30-year gap. Comparison of the IQ distributions indicated that the mean IQ scores on the test had increased by 9.7 points (the Flynn effect), the gains were concentrated in the lower half of the distribution and negligible in the top half, and the gains gradually decreased as the IQ of the individuals increased. Some studies have found a reverse Flynn effect with declining scores for those with high IQ.

In 1987, Flynn took the position that the very large increase indicates that IQ tests do not measure intelligence but only a minor sort of "abstract problem-solving ability" with little practical significance. He argued that if IQ gains do reflect intelligence increases, there would have been consequent changes of our society that have not been observed (a presumed non-occurrence of a "cultural renaissance"). Flynn no longer endorses this view of intelligence and has since elaborated and refined his view of what rising IQ scores mean.

Earlier investigators had discovered rises in raw IQ test scores in some study populations, but had not published general investigations of that issue in particular. Historian Daniel C. Calhoun cited earlier psychology literature on IQ score trends in his book "The Intelligence of a People" (1973). R. L. Thorndike drew attention to rises in Stanford-Binet scores in a 1975 review of the history of intelligence testing.

There is debate about whether the rise in IQ scores also corresponds to a rise in general intelligence, or only a rise in special skills related to taking IQ tests. Because children attend school longer now and have become much more familiar with the testing of school-related material, one might expect the greatest gains to occur on such school content-related tests as vocabulary, arithmetic or general information. Just the opposite is the case: abilities such as these have experienced relatively small gains and even occasional decreases over the years. Meta-analytic findings indicate that Flynn effects occur for tests assessing both fluid and crystallized abilities. For example, Dutch conscripts gained 21 points during only 30 years, or 7 points per decade, between 1952 and 1982. But this rise in IQ test scores is not wholly explained by an increase in general intelligence. Studies have shown that while test scores have improved over time, the improvement is not fully correlated with latent factors related to intelligence. Rushton has shown that the gains in IQ over time (the Lynn-Flynn effect) are unrelated to "g". Other researchers have shown that the IQ gains described by the Flynn effect are due in part to increasing intelligence, and in part to increases in test-specific skills. In parallel with the measured gains in IQ scores, secular declines have been found for "mental speed, digit span backwards, the use of difficult words, and color acuity, all of which are related to intelligence".

A 2017 survey of 75 experts in the field of intelligence research suggested four key causes of the Flynn effect: Better health, better nutrition, more and better education, and rising standards of living. Genetic changes were seen as not important. The experts' views agreed with an independently performed meta-analysis on published Flynn effect data, except that the latter found life history speed to be the most important factor.

The expert survey explained the possible end or decline in the Flynn effect by asymmetric fertility by means of genetic effects, migration, asymmetric fertility by means of socialization effects, declines in education, and the influence of media.

Duration of average schooling has increased steadily. One problem with this explanation is that if in the US comparing older and more recent subjects with similar educational levels, then the IQ gains appear almost undiminished in each such group considered individually.

Many studies find that children who do not attend school score drastically lower on the tests than their regularly attending peers. During the 1960s, when some Virginia counties closed their public schools to avoid racial integration, compensatory private schooling was available only for Caucasian children. On average, the scores of African-American children who received no formal education during that period decreased at a rate of about six IQ points per year.

Another explanation is an increased familiarity of the general population with tests and testing. For example, children who take the very same IQ test a second time usually gain five or six points. However, this seems to set an upper limit on the effects of test sophistication. One problem with this explanation and others related to schooling is that in the US, the groups with greater test familiarity show smaller IQ increases.

Early intervention programs have shown mixed results. Some preschool (ages 3–4) intervention programs like "Head Start" do not produce lasting changes of IQ, although they may confer other benefits. The "Abecedarian Early Intervention Project", an all-day program that provided various forms of environmental enrichment to children from infancy onward, showed IQ gains that did not diminish over time. The IQ difference between the groups, although only five points, was still present at age 12. Not all such projects have been successful. Also, such IQ gains can diminish until age 18.

Citing a high correlation between rising literacy rates and gains in IQ, David Marks has argued that the Flynn effect is caused by changes in literacy rates.

Still another theory is that the general environment today is much more complex and stimulating. One of the most striking 20th-century changes of the human intellectual environment has come from the increase of exposure to many types of visual media. From pictures on the wall to movies to television to video games to computers, each successive generation has been exposed to richer optical displays than the one before and may have become more adept at visual analysis. This would explain why visual tests like the Raven's have shown the greatest increases. An increase only of particular form(s) of intelligence would explain why the Flynn effect has not caused a "cultural renaissance too great to be overlooked."

In 2001, Dickens and Flynn presented a model for resolving several contradictory findings regarding IQ. They argue that the measure "heritability" includes both a direct effect of the genotype on IQ and also indirect effects such that the genotype changes the environment, thereby affecting IQ. That is, those with a greater IQ tend to seek stimulating environments that further increase IQ. These reciprocal effects result in gene environment correlation. The direct effect could initially have been very small, but feedback can create large differences of IQ. In their model, an environmental stimulus can have a very great effect on IQ, even for adults, but this effect also decays over time unless the stimulus continues (the model could be adapted to include possible factors, like nutrition during early childhood, that may cause permanent effects). The Flynn effect can be explained by a generally more stimulating environment for all people. The authors suggest that any program designed to increase IQ may produce long-term IQ gains if that program teaches children how to replicate the types of cognitively demanding experiences that produce IQ gains outside the program. To maximize lifetime IQ, the programs should also motivate them to continue searching for cognitively demanding experiences after they have left the program.

Flynn in his 2007 book "What Is Intelligence?" further expanded on this theory. Environmental changes resulting from modernization—such as more intellectually demanding work, greater use of technology and smaller families—have meant that a much larger proportion of people are more accustomed to manipulating abstract concepts such as hypotheses and categories than a century ago. Substantial portions of IQ tests deal with these abilities. Flynn gives, as an example, the question 'What do a dog and a rabbit have in common?' A modern respondent might say they are both mammals (an abstract, or "a priori" answer, which depends only on the meanings of the words "dog" and "rabbit"), whereas someone a century ago might have said that humans catch rabbits with dogs (a concrete, or "a posteriori" answer, which depended on what happened to be the case at that time).

Improved nutrition is another possible explanation. Today's average adult from an industrialized nation is taller than a comparable adult of a century ago. That increase of stature, likely the result of general improvements of nutrition and health, has been at a rate of more than a centimeter per decade. Available data suggest that these gains have been accompanied by analogous increases of head size, and by an increase in the average size of the brain. This argument had been thought to suffer the difficulty that groups who tend to be of smaller overall body size (e.g. women, or people of Asian ancestry) do not have lower average IQs. Richard Lynn, however, claims that while people of East Asian origin may often have smaller bodies, they tend to have larger brains and higher IQs than average whites.

A 2005 study presented data supporting the nutrition hypothesis, which predicts that gains will occur predominantly at the low end of the IQ distribution, where nutritional deprivation is probably most severe. An alternative interpretation of skewed IQ gains could be that improved education has been particularly important for this group. Richard Lynn makes the case for nutrition, arguing that cultural factors cannot typically explain the Flynn effect because its gains are observed even at infant and preschool levels, with rates of IQ test score increase about equal to those of school students and adults. Lynn states that "This rules out improvements in education, greater test sophistication, etc. and most of the other factors that have been proposed to explain the Flynn effect. He proposes that the most probable factor has been improvements in pre-natal and early post-natal nutrition."

A century ago, nutritional deficiencies may have limited body and organ functionality, including skull volume. The first two years of life is a critical time for nutrition. The consequences of malnutrition can be irreversible and may include poor cognitive development, educability, and future economic productivity. On the other hand, Flynn has pointed to 20-point gains on Dutch military (Raven's type) IQ tests between 1952, 1962, 1972, and 1982. He observes that the Dutch 18-year-olds of 1962 had a major nutritional handicap. They were either in the womb, or were recently born, during the great Dutch famine of 1944—when German troops monopolized food and 18,000 people died of starvation. Yet, concludes Flynn, "they do not show up even as a blip in the pattern of Dutch IQ gains. It is as if the famine had never occurred." It appears that the effects of diet are gradual, taking effect over decades (affecting mother as well as child) rather than a few months.

In support of the nutritional hypothesis, it is known that, in the United States, the average height before 1900 was about 10 cm (∼4 inches) shorter than it is today. Possibly related to the Flynn effect is a similar change of skull size and shape during the last 150 years. Though the idea that brain size is unrelated to race and intelligence was popularized in the 1980s, studies continue to show significant correlations.
A Norwegian study found that height gains were strongly correlated with intelligence gains until the cessation of height gains in military conscript cohorts towards the end of the 1980s.<ref name="doi10.1016/j.intell.2004.06.004"></ref> Both height and skull size increases probably result from a combination of phenotypic plasticity and genetic selection over this period. With only five or six human generations in 150 years, time for natural selection has been very limited, suggesting that increased skeletal size resulting from changes in population phenotypes is more likely than recent genetic evolution.

It is well known that micronutrient deficiencies change the development of intelligence. For instance, one study has found that iodine deficiency causes a fall, on average, of 12 IQ points in China.

Scientists James Feyrer, Dimitra Politi, and David N. Weil have found in the U.S. that the proliferation of iodized salt increased IQ by 15 points in some areas. Journalist Max Nisen has stated that, with this type of salt becoming popular, that "the aggregate effect has been extremely positive."

Daley et al. (2003) found a significant Flynn effect among children in rural Kenya, and concluded that nutrition was one of the hypothesized explanations that best explained their results (the others were parental literacy and family structure).

Eppig, Fincher, and Thornhill (2009) argue that "From an energetics standpoint, a developing human will have difficulty building a brain and fighting off infectious diseases at the same time, as both are very metabolically costly tasks" and that "the Flynn effect may be caused in part by the decrease in the intensity of infectious diseases as nations develop." They suggest that improvements in gross domestic product (GDP), education, literacy, and nutrition may have an effect on IQ mainly through reducing the intensity of infectious diseases.

Eppig, Fincher, and Thornhill (2011) in a similar study instead looking at different US states found that states with a higher prevalence of infectious diseases had lower average IQ. The effect remained after controlling for the effects of wealth and educational variation.

Atheendar Venkataramani (2010) studied the effect of malaria on IQ in a sample of Mexicans. Malaria eradication during the birth year was associated with increases in IQ. It also increased the probability of employment in a skilled occupation. The author suggests that this may be one explanation for the Flynn effect and that this may be an important explanation for the link between national malaria burden and economic development. A literature review of 44 papers states that cognitive abilities and school performance were shown to be impaired in sub-groups of patients (with either cerebral malaria or uncomplicated malaria) when compared with healthy controls. Studies comparing cognitive functions before and after treatment for acute malarial illness continued to show significantly impaired school performance and cognitive abilities even after recovery. Malaria prophylaxis was shown to improve cognitive function and school performance in clinical trials when compared to placebo groups.

Heterosis, or hybrid vigor associated with historical reductions of the levels of inbreeding, has been proposed by Michael Mingroni as an alternative explanation of the Flynn effect. However, James Flynn has pointed out that even if everyone mated with a sibling in 1900, subsequent increases in heterosis would not be a sufficient explanation of the observed IQ gains.

Jon Martin Sundet and colleagues (2004) examined scores on intelligence tests given to Norwegian conscripts between the 1950s and 2002. They found that the increase of scores of general intelligence stopped after the mid-1990s and declined in numerical reasoning sub-tests.

Teasdale and Owen (2005) examined the results of IQ tests given to Danish male conscripts. Between 1959 and 1979 the gains were 3 points per decade. Between 1979 and 1989 the increase approached 2 IQ points. Between 1989 and 1998 the gain was about 1.3 points. Between 1998 and 2004 IQ declined by about the same amount as it gained between 1989 and 1998. They speculate that "a contributing factor in this recent fall could be a simultaneous decline in proportions of students entering 3-year advanced-level school programs for 16–18-year-olds." The same authors in a more comprehensive 2008 study, again on Danish male conscripts, found that there was a 1.5-point increase between 1988 and 1998, but a 1.5-point decrease between 1998 and 2003/2004. A possible contributing factor to the more recent decline may be changes in the Danish educational system. Another may be the rising proportion of immigrants or their immediate descendants in Denmark. This is supported by data on Danish draftees where first or second generation immigrants with Danish nationality score below average.

In Australia, the IQ of 6–12 year olds as measured by the Colored Progressive Matrices has shown no increase from 1975–2003.

In the United Kingdom, a study by Flynn (2009) found that tests carried out in 1980 and again in 2008 show that the IQ score of an average 14-year-old dropped by more than two points over the period. For the upper half of the results the performance was even worse. Average IQ scores declined by six points. However, children aged between five and 10 saw their IQs increase by up to half a point a year over the three decades. Flynn argues that the abnormal drop in British teenage IQ could be due to youth culture having “stagnated” or even dumbed down. He also states that the youth culture is more oriented towards computer games than towards reading and holding conversations. Researcher Richard Gray, commenting on the study, also mentions the computer culture diminishing reading books as well as a tendency towards teaching to the test.

Lynn and Harvey argued in 2008 that the causes of the above are difficult to interpret since these countries had had significant recent immigration from countries with lower average national IQs. Nevertheless, they expect that similar patterns will occur, or have occurred, first in other developed nations and then in the developing world as there is a limit to how much environmental factors can improve intelligence. Furthermore, during the last century there is a negative correlation between fertility and intelligence although there is not yet any conclusive evidence of the association between the two. They estimate that there has been a dysgenic decline in the world's genotypic IQ (masked by the Flynn effect for the phenotype) of 0.86 IQ points per decade for the years 1950–2000.

Bratsberg & Rogeberg (2018) present evidence that the Flynn effect in Norway has reversed, and that both the original rise in mean IQ scores and their subsequent decline were caused by environmental factors. They conclude that environmental factors explain all or almost all of the decline, and any effects from immigration or hypothesised declines in genotypic IQ are negligible.

One possible explanation of a worldwide decline in intelligence, suggested by the World Health Organization and the Forum of International Respiratory Societies’ Environmental Committee, is an increase in air pollution, which now affects over 90% of the world's population.

If the Flynn effect has ended in developed nations, then this may possibly allow national differences in IQ scores to diminish if the Flynn effect continues in nations with lower average national IQs.

Also, if the Flynn effect has ended for the majority in developed nations, it may still continue for minorities, especially for groups like immigrants where many may have received poor nutrition during early childhood or have had other disadvantages. A study in the Netherlands found that children of non-Western immigrants had improvements for "g", educational achievements, and work proficiency compared to their parents, although there were still remaining differences compared to ethnic Dutch.

There is a controversy as to whether the US racial gap in IQ scores is diminishing. If that is the case then this may or may not be related to the Flynn effect. Flynn has commented that he never claimed that the Flynn effect has the same causes as the black-white gap, but that it shows that environmental factors can create IQ differences of a magnitude similar to the gap. Research that has examined whether g factor and IQ gains from the Flynn effect are related have found there is a negative correlation between the two, which may indicate that group differences and the Flynn effect are possibly due to differing causes.

The Flynn effect has also been part of the discussions regarding Spearman's hypothesis, which states that differences in the g factor are the major source of differences between blacks and whites observed in many studies of race and intelligence.





</doc>
<doc id="11774" url="https://en.wikipedia.org/wiki?curid=11774" title="Field ion microscope">
Field ion microscope

The Field ion microscope (FIM) was invented by Müller in 1951. It is a type of microscope that can be used to image the arrangement of atoms at the surface of a sharp metal tip.

On October 11, 1955, Erwin Müller and his Ph.D. student, Kanwar Bahadur (Pennsylvania State University) observed individual tungsten atoms on the surface of a sharply pointed tungsten tip by cooling it to 21 K and employing helium as the imaging gas. Müller & Bahadur were the first persons to observe individual atoms directly.

In FIM, a sharp (<50 nm tip radius) metal tip is produced and placed in an ultra high vacuum chamber, which is backfilled with an imaging gas such as helium or neon. The tip is cooled to cryogenic temperatures (20–100 K). A positive voltage of 5 to 10 kilovolts is applied to the tip. Gas atoms adsorbed on the tip are ionized by the strong electric field in the vicinity of the tip (thus, "field ionization"), becoming positively charged and being repelled from the tip. The curvature of the surface near the tip causes a natural magnification — ions are repelled in a direction roughly perpendicular to the surface (a "point projection" effect). A detector is placed so as to collect these repelled ions; the image formed from all the collected ions can be of sufficient resolution to image individual atoms on the tip surface.

Unlike conventional microscopes, where the spatial resolution is limited by the wavelength of the particles which are used for imaging, the FIM is a projection type microscope with atomic resolution and an approximate magnification of a few million times.

FIM like Field Emission Microscopy (FEM) consists of a sharp sample tip and a fluorescent screen (now replaced by a multichannel plate) as the key elements. However, there are some essential differences as follows:
Like FEM, the field strength at the tip apex is typically a few V/Å. The experimental set-up and image formation in FIM is illustrated in the accompanying figures.

In FIM the presence of a strong field is critical. The imaging gas atoms (He, Ne) near the tip are polarized by the field and since the field is non-uniform the polarized atoms are attracted towards the tip surface. The imaging atoms then lose their kinetic energy performing a series of hops and accommodate to the tip temperature. Eventually, the imaging atoms are ionized by tunneling electrons into the surface and the resulting positive ions are accelerated along the field lines to the screen to form a highly magnified image of the sample tip.

In FIM, the ionization takes place close to the tip, where the field is strongest. The electron that tunnels from the atom is picked up by the tip. There is a critical distance, xc, at which the tunneling probability is a maximum. This distance is typically about 0.4 nm. The very high spatial resolution and high contrast for features on the atomic scale arises from the fact that the electric field is enhanced in the vicinity of the surface atoms because of the higher local curvature. The resolution of FIM is limited by the thermal velocity of the imaging ion. Resolution of the order of 1Å (atomic resolution) can be achieved by effective cooling of the tip.

Application of FIM, like FEM, is limited by the materials which can be fabricated in the shape of a sharp tip, can be used in an ultra high vacuum (UHV) environment, and can tolerate the high electrostatic fields. For these reasons, refractory metals with high melting temperature (e.g. W, Mo, Pt, Ir) are conventional objects for FIM experiments. Metal tips for FEM and FIM are prepared by electropolishing (electrochemical polishing) of thin wires. However, these tips usually contain many asperities. The final preparation procedure involves the in situ removal of these asperities by field evaporation just by raising the tip voltage. Field evaporation is a field induced process which involves the removal of atoms from the surface itself at very high field strengths and typically occurs in the range 2-5 V/Å. The effect of the field in this case is to reduce the effective binding energy of the atom to the surface and to give, in effect, a greatly increased evaporation rate relative to that expected at that temperature at zero fields. This process is self-regulating since the atoms that are at positions of high local curvature, such as adatoms or ledge atoms, are removed preferentially. The tips used in FIM is sharper (tip radius is 100~300 Å) compared to those used in FEM experiments (tip radius ~1000 Å).

FIM has been used to study dynamical behavior of surfaces and the behavior of adatoms on surfaces. The problems studied include adsorption-desorption phenomena, surface diffusion of adatoms and clusters, adatom-adatom interactions, step motion, equilibrium crystal shape, etc. However, there is the possibility of the results being affected by the limited surface area (i.e. edge effects) and by the presence of large electric field.





</doc>
<doc id="11775" url="https://en.wikipedia.org/wiki?curid=11775" title="First Battle of El Alamein">
First Battle of El Alamein

The First Battle of El Alamein (1–27 July 1942) was a battle of the Western Desert Campaign of the Second World War, fought in Egypt between Axis forces (Germany and Italy) of the Panzer Army Africa (), which included the under Field Marshal () Erwin Rommel and Allied (British Imperial and Commonwealth) forces (Britain, British India, Australia, South Africa and New Zealand) of the Eighth Army (General Claude Auchinleck).

The British prevented a second advance by the Axis forces into Egypt. Axis positions near El Alamein, only from Alexandria, were dangerously close to the ports and cities of Egypt, the base facilities of the Commonwealth forces and the Suez Canal. However, the Axis forces were too far from their base at Tripoli in Libya to remain at El Alamein indefinitely, which led both sides to accumulate supplies for more offensives, against the constraints of time and distance.

Following their defeat at the Battle of Gazala in Eastern Libya in June 1942, the British Eighth Army, commanded by Lieutenant-General Neil Ritchie, had retreated east from the Gazala line into north-western Egypt as far as Mersa Matruh, roughly inside the border. Ritchie had decided not to hold the defences on the Egyptian border, because the defensive plan there was for infantry to hold defended localities and a strong armoured force behind them to meet any attempts to penetrate or outflank the fixed defences. Since General Ritchie had virtually no armoured units left fit to fight, the infantry positions would be defeated in detail. The Mersa defence plan also included an armoured reserve but in its absence Ritchie believed he could organise his infantry to cover the minefields between the defended localities to prevent Axis engineers from having undisturbed access.

To defend the Matruh line, Ritchie placed 10th Indian Infantry Division (in Matruh itself) and 50th (Northumbrian) Infantry Division (some down the coast at Gerawla) under X Corps HQ, newly arrived from Syria. Inland from X Corps would be XIII Corps with 5th Indian Infantry Division (with only one infantry brigade, 29th Indian, and two artillery regiments) around Sidi Hamza about inland, and the newly arrived 2nd New Zealand Division (short one brigade, the 6th, which had been left out of combat in case the division was captured and it would be needed to serve as the nucleus of a new division) at Minqar Qaim (on the escarpment inland) and 1st Armored Division in the open desert to the south. The 1st Armored Division had taken over 4th and 22nd Armoured Brigades from 7th Armoured Division which by this time had only three tank regiments (battalions) between them.
On 25 June, General Claude Auchinleck—Commander-in-Chief (C-in-C) Middle East Command—relieved Ritchie and assumed direct command of the Eighth Army himself. He decided not to seek a decisive confrontation at the Mersa Matruh position. He concluded that his inferiority in armour after the Gazala defeat, meant he would be unable to prevent Rommel either breaking through his centre or enveloping his open left flank to the south in the same way he had at Gazala. He decided instead to employ delaying tactics while withdrawing a further or more east to a more defensible position near El Alamein on the Mediterranean coast. Only to the south of El Alamein, the steep slopes of the Qattara Depression ruled out the possibility of Axis armour moving around the southern flank of his defences and limited the width of the front he had to defend.

While preparing the Alamein positions, Auchinleck fought strong delaying actions, first at Mersa Matruh on 26–27 June and then Fuka on 28 June. The late change of orders resulted in some confusion in the forward formations (X Corps and XIII Corps) between the desire to inflict damage on the enemy and the intention not to get trapped in the Matruh position but retreat in good order. The result was poor co-ordination between the two forward Corps and units within them. Late on 26 June, the German 90th Light and 21st "Panzer" Divisions managed to find their way through the minefields in the centre of the front. Early on 27 June, resuming its advance, the 90th Light was checked by British 50th Division's artillery. Meanwhile, the 15th and 21st "Panzer" Divisions advanced east above and below the escarpment. The 15th "Panzer" were blocked by 4th Armoured and 7th Motor Brigades, but the 21st "Panzer" were ordered on to attack Minqar Qaim. Rommel ordered 90th Light to resume its advance, requiring it to cut the coast road behind 50th Division by the evening. As the 21st "Panzer" moved on Minqar Qaim, the 2nd New Zealand Division found itself surrounded but broke out on the night of 27/28 June without serious losses and withdrew east.
Auchinleck had planned a second delaying position at Fuka, some east of Matruh, and at 21:20 he issued the orders for a withdrawal to Fuka. Confusion in communication led the division withdrawing immediately to the El Alamein position. X Corps, having made an unsuccessful attempt to secure a position on the escarpment, were out of touch with Eighth Army from 19:30 until 04:30 the next morning. Only then did they discover that the withdrawal order had been given. The withdrawal of XIII Corps had left the southern flank of X Corps on the coast at Matruh exposed and their line of retreat compromised by the cutting of the coastal road east of Matruh. They were ordered to break out southwards into the desert and then make their way east. Auchinleck ordered XIII Corps to provide support but they were in no position to do so. At 21:00 on 28 June, X Corps—organised into brigade groups—headed south. In the darkness, there was considerable confusion as they came across enemy units laagered for the night. In the process, 5th Indian Division in particular sustained heavy casualties, including the destruction of the 29th Indian Infantry Brigade at Fuka. Axis forces captured more than 6,000 prisoners, in addition to 40 tanks and an enormous quantity of supplies.

Alamein itself was an inconsequential railway station on the coast. Some to the south lay the Ruweisat Ridge, a low stony prominence that gave excellent observation for many miles over the surrounding desert; to the south was the Qattara Depression. The line the British chose to defend stretched between the sea and the Depression, which meant that Rommel could outflank it only by taking a significant detour to the south and crossing the Sahara Desert. The British Army in Egypt recognised this before the war and had the Eighth Army begin construction of several "boxes" (localities with dug-outs and surrounded by minefields and barbed wire) the most developed being around the railway station at Alamein. Most of the "line" was open, empty desert. Lieutenant-General William Norrie (General officer commanding [GOC] XXX Corps) organised the position and started to construct three defended "boxes". The first and strongest, at El Alamein on the coast, had been partly wired and mined by 1st South African Division. The Bab el Qattara box—some from the coast and south-west of the Ruweisat Ridge—had been dug but had not been wired or mined, while at the Naq Abu Dweis box (on the edge of the Qattara Depression), from the coast, very little work had been done.

The British position in Egypt was desperate, the rout from Mersa Matruh had created a panic in the British headquarters at Cairo, something later called "the Flap". On what came to be referred to as "Ash Wednesday", at British headquarters, rear echelon units and the British Embassy, papers were hurriedly burned in anticipation of the fall of the city. Auchinleck—although believing he could stop Rommel at Alamein—felt he could not ignore the possibility that he might once more be outmanoeuvred or outfought. To maintain his army, plans must be made for the possibility of a further retreat whilst maintaining morale and retaining the support and co-operation of the Egyptians. Defensive positions were constructed west of Alexandria and on the approaches to Cairo while considerable areas in the Nile delta were flooded. The Axis, too, believed that the capture of Egypt was imminent; Italian leader Benito Mussolini—sensing a historic moment—flew to Libya to prepare for his triumphal entry into Cairo.

The scattering of X Corps at Mersa Matruh disrupted Auchinleck's plan for occupying the Alamein defences. On 29 June, he ordered XXX Corps—the 1st South African, 5th and 10th Indian divisions—to take the coastal sector on the right of the front and XIII Corps—the 2nd New Zealand Division and 4th Indian divisions—to be on the left. The remains of the 1st Armoured Division and the 7th Armoured Division were to be held as a mobile army reserve. His intention was for the fixed defensive positions to channel and disorganise the enemy's advance while mobile units would attack their flanks and rear.

On 30 June, Rommel's "Panzerarmee Afrika" approached the Alamein position. The Axis forces were exhausted and understrength. Rommel had driven them forward ruthlessly, being confident that, provided he struck quickly before Eighth Army had time to settle, his momentum would take him through the Alamein position and he could then advance to the Nile with little further opposition. Supplies remained a problem because the Axis staff had originally expected a pause of six weeks after the capture of Tobruk. German air units were also exhausted and providing little help against the RAF's all-out attack on the Axis supply lines which, with the arrival of United States Army Air Forces (USAAF) heavy bombers, could reach as far as Benghazi. Although captured supplies proved useful, water and ammunition were constantly in short supply, while a shortage of transport impeded the distribution of the supplies that the Axis forces did have.

Rommel's plan was for the 90th Light Division and the 15th and 21st "Panzer" divisions of the "Afrika Korps" to penetrate the Eighth Army lines between the Alamein box and Deir el Abyad (which he believed was defended). The 90th Light Division was then to veer north to cut the coastal road and trap the defenders of the Alamein box (which Rommel thought was occupied by the remains of the 50th Infantry Division) and the "Afrika Korps" would veer right to attack the rear of XIII Corps.

An Italian division was to attack the Alamein box from the west and another was to follow the 90th Light Division. The Italian XX Corps was to follow the "Afrika Korps" and deal with the Qattara box while the 133rd Armoured Division "Littorio" and German reconnaissance units would protect the right flank. Rommel had planned to attack on 30 June but supply and transport difficulties had resulted in a day's delay, vital to the defending forces reorganising on the Alamein line. On 30 June, the 90th Light Division was still short of its start line, 21st "Panzer" Division was immobilised through lack of fuel and the promised air support had yet to move into its advanced airfields.

At 03:00 on 1 July, 90th Light Infantry Division advanced east but strayed too far north and ran into the 1st South African Division's defences and became pinned down. The 15th and 21st "Panzer" Divisions of the "Afrika Korps" were delayed by a sandstorm and then a heavy air attack. It was broad daylight by the time they circled round the back of Deir el Abyad where they found the feature to the east of it occupied by 18th Indian Infantry Brigade which, after a hasty journey from Iraq, had occupied the exposed position just west of Ruweisat Ridge and east of Deir el Abyad at Deir el Shein late on 28 June to create one of Norrie's additional defensive boxes.

At about 10:00 on 1 July, 21st "Panzer" Division attacked Deir el Shein. 18th Indian Infantry Brigade—supported by 23 25-pounder gun-howitzers, 16 of the new 6-pounder anti-tank guns and nine Matilda tanks—held out the whole day in desperate fighting but by evening the Germans succeeded in over-running them. The time they bought allowed Auchinleck to organise the defence of the western end of Ruweisat Ridge. The 1st Armoured Division had been sent to intervene at Deir el Shein. They ran into 15th "Panzer" Division just south of Deir el Shein and drove it west. By the end of the day's fighting, the "Afrika Korps" had 37 tanks left out of its initial complement of 55.

During the early afternoon, 90th Light had extricated itself from the El Alamein box defences and resumed its move eastward. It came under artillery fire from the three South African brigade groups and was forced to dig in.

On 2 July, Rommel ordered the resumption of the offensive. Once again, 90th Light failed to make progress so Rommel called the "Afrika Korps" to abandon its planned sweep southward and instead join the effort to break through to the coast road by attacking east toward Ruweisat Ridge. The British defence of Ruweisat Ridge relied on an improvised formation called "Robcol", comprising a regiment each of field artillery and light anti-aircraft artillery and a company of infantry. Robcol—in line with normal British Army practice for "ad hoc" formations—was named after its commander, Brigadier Robert Waller, the Commander Royal Artillery of the 10th Indian Infantry Division. Robcol was able to buy time, and by late afternoon the two British armoured brigades joined the battle with 4th Armoured Brigade engaging 15th "Panzer" and 22nd Armoured Brigade 21st "Panzer" respectively. They drove back repeated attacks by the Axis armour, who then withdrew before dusk. The British reinforced Ruweisat on the night of 2 July. The now enlarged Robcol became "Walgroup". Meanwhile, the Royal Air Force (RAF) made heavy air attacks on the Axis units.

The next day, 3 July, Rommel ordered the "Afrika Korps" to resume its attack on the Ruweisat ridge with the Italian XX Motorised Corps on its southern flank. Italian X Corps, meanwhile were to hold El Mreir. By this stage the "Afrika Korps" had only 26 operational tanks. There was a sharp armoured exchange south of Ruweisat ridge during the morning and the main Axis advance was held. On 3 July, the RAF flew 780 sorties.

To relieve the pressure on the right and centre of the Eighth Army line, XIII Corps on the left advanced from the Qattara box (known to the New Zealanders as the Kaponga box). The plan was that the New Zealand 2nd Division—with the remains of Indian 5th Division and 7th Motor Brigade under its command—would swing north to threaten the Axis flank and rear. This force encountered the "Ariete" Armoured Division's artillery, which was driving on the southern flank of the division as it attacked Ruweisat. The Italian commander ordered his battalions to fight their way out independently but the "Ariete" lost 531 men (about 350 were prisoners), 36 pieces of artillery, six (or eight?) tanks, and 55 trucks. By the end of the day, the "Ariete" Division had only five tanks. The day ended once again with the "Afrika Korps" and "Ariete" coming off second best to the superior numbers of the British 22nd Armoured and 4th Armoured Brigades, frustrating Rommel's attempts to resume his advance. The RAF once again played its part, flying 900 sorties during the day.

To the south, on 5 July the New Zealand group resumed its advance northwards towards El Mreir intending to cut the rear of the "Ariete" Division. Heavy fire from the Italian "Brescia" Motorised Division at El Mreir, however, north of the Qattara box, checked their progress and led XIII Corps to call off its attack.

At this point, Rommel decided his exhausted forces could make no further headway without resting and regrouping. He reported to the German High Command that his three German divisions numbered just 1,200–1,500 men each and resupply was proving highly problematic because of enemy interference from the air. He expected to have to remain on the defensive for at least two weeks.

Rommel was by this time suffering from the extended length of his supply lines. The Allied Desert Air Force (DAF) was concentrating fiercely on his fragile and elongated supply routes while British mobile columns moving west and striking from the south were causing havoc in the Axis rear echelons. Rommel could afford these losses even less since shipments from Italy had been substantially reduced (in June, he received of supplies compared with in May and 400 vehicles (compared with 2,000 in May). Meanwhile, the Eighth Army was reorganising and rebuilding, benefiting from its short lines of communication. By 4 July, the Australian 9th Division had entered the line in the north, and on 9 July the Indian 5th Infantry Brigade also returned, taking over the Ruweisat position. At the same time, the fresh Indian 161st Infantry Brigade reinforced the depleted Indian 5th Infantry Division.

On 8 July, Auchinleck ordered the new XXX Corps commander—Lieutenant-General William Ramsden—to capture the low ridges at Tel el Eisa and Tel el Makh Khad and then to push mobile battle groups south toward Deir el Shein and raiding parties west toward the airfields at El Daba. Meanwhile, XIII Corps would prevent the Axis from moving troops north to reinforce the coastal sector. Ramsden tasked the Australian 9th Division with 44th Royal Tank Regiment under command with the Tel el Eisa objective and the South African 1st Division with eight supporting tanks, Tel el Makh Khad. The raiding parties were to be provided by 1st Armoured Division.

Following a bombardment which started at 03:30 on 10 July, the Australian 26th Brigade launched an attack against the ridge north of Tel el Eisa station along the coast (Trig 33). The bombardment was the heaviest barrage yet experienced in North Africa, which created panic in the inexperienced soldiers of the Italian 60th Infantry Division "Sabratha" who had only just occupied sketchy defences in the sector. The Australian attack took more than 1,500 prisoners, routed an Italian Division and overran the German Signals Intercept Company 621. Meanwhile, the South Africans had by late morning taken Tel el Makh Khad and were in covering positions.

Elements of the German 164th Light Division and Italian 101st Motorised Division "Trieste" arrived to plug the gap torn in the Axis defences. That afternoon and evening, tanks from the German 15th "Panzer" and Italian "Trieste" Divisions launched counter-attacks against the Australian positions, the counter-attacks failing in the face of overwhelming Allied artillery and the Australian anti-tank guns.

At first light on 11 July, the Australian 2/24th Battalion supported by tanks from 44th Royal Tank Regiment attacked the western end of Tel el Eisa hill (Point 24). By early afternoon, the feature was captured and was then held against a series of Axis counter-attacks throughout the day. A small column of armour, motorised infantry, and guns then set off to raid Deir el Abyad and caused a battalion of Italian infantry to surrender. Its progress was checked at the Miteirya ridge and it was forced to withdraw that evening to the El Alamein box. During the day, more than 1,000 Italian prisoners were taken.

On 12 July, the 21st "Panzer" Division launched a counter-attack against Trig 33 and Point 24, which was beaten off after a 2½-hour fight, with more than 600 German dead and wounded left strewn in front of the Australian positions. The next day, 21. "Panzerdivision" launched an attack against Point 33 and South African positions in the El Alamein box. The attack was halted by intense artillery fire from the defenders. Rommel was still determined to drive the British forces from the northern salient. Although the Australian defenders had been forced back from Point 24, heavy casualties had been inflicted on 21st "Panzer" Division. Another attack was mounted on 15 July but made no ground against tenacious resistance. On 16 July, the Australians—supported by British tanks—launched an attack to try to take Point 24 but were forced back by German counter-attacks, suffering nearly fifty percent casualties.

After seven days of fierce fighting, the battle in the north for Tel el Eisa salient petered out. Australian 9th Division estimated at least 2,000 Axis troops had been killed and more than 3,700 prisoners of war taken in the battle. Possibly the most important feature of the battle, however, was that the Australians had captured Signals Intercept Company 621. This unit had provided Rommel with priceless intelligence, gleaned from intercepting British radio communications. That source of intelligence was now lost to Rommel.

As the Axis forces dug in, Auchinleck—having drawn a number of German units to the coastal sector during the Tel el Eisa fighting—developed a plan—codenamed Operation Bacon—to attack the Italian "Pavia" and "Brescia" Divisions in the centre of the front at the Ruweisat ridge. Signals intelligence was giving Auchinleck clear details of the Axis order of battle and force dispositions. His policy was to "...hit the Italians wherever possible in view of their low morale and because the Germans cannot hold extended fronts without them."

The intention was for the 4th New Zealand Brigade and 5th New Zealand Brigade (on 4th Brigade's right) to attack north-west to seize the western part of the ridge and on their right the Indian 5th Infantry Brigade to capture the eastern part of the ridge in a night attack. Then 2nd Armoured Brigade would pass through the centre of the infantry objectives to exploit toward Deir el Shein and the Miteirya Ridge. On the left, the 22nd Armoured Brigade would be ready to move forward to protect the infantry as they consolidated on the ridge.

The attack commenced at 23:00 on 14 July. The two New Zealand brigades shortly before dawn on 15 July took their objectives, but minefields and pockets of resistance created disarray among the attackers. A number of pockets of resistance were left behind the forward troops' advance which impeded the move forward of reserves, artillery, and support arms. As a result, the New Zealand brigades occupied exposed positions on the ridge without support weapons except for a few anti-tank guns. More significantly, communications with the two British armoured brigades failed, and the British armour did not move forwards to protect the infantry. At first light, a detachment from 15th "Panzer" division's 8th "Panzer" Regiment launched a counter-attack against New Zealand 4th Brigade's 22nd Battalion. A sharp exchange knocked out their anti-tank guns and the infantry found themselves exposed in the open with no alternative but to surrender. About 350 New Zealanders were taken prisoner.

While the 2nd New Zealand Division attacked the western slopes of Ruweisat Ridge, the Indian 5th Brigade made small gains on Ruweisat ridge to the east. By 07:00, word was finally got to 2nd Armoured Brigade which started to move north west. Two regiments became embroiled in a minefield but the third was able to join Indian 5th Infantry 5th Brigade as it renewed its attack. With the help of the armour and artillery, the Indians were able to take their objectives by early afternoon. Meanwhile, the 22nd Armoured Brigade had been engaged at Alam Nayil by 90th Light Division and the "Ariete" Armoured Division, advancing from the south. While—with help from mobile infantry and artillery columns from 7th Armoured Division—they pushed back the Axis probe with ease, they were prevented from advancing north to protect the New Zealand flank.

Seeing the "Brescia" and "Pavia" under pressure, Rommel rushed German troops to Ruweisat. By 15:00, the 3rd Reconnaissance Regiment and part of 21st "Panzer" Division from the north and 33rd Reconnaissance Regiment and the Baade Group comprising elements from 15th "Panzer" Division from the south were in place under Lieutenant-General ("General der Panzertruppe") Walther Nehring. At 17:00, Nehring launched his counter-attack. 4th New Zealand Brigade were still short of support weapons and also, by this time, ammunition. Once again, the anti-tank defences were overwhelmed and about 380 New Zealanders were taken prisoner including Captain Charles Upham who gained a second Victoria Cross for his actions including destroying a German tank and several guns and vehicles with grenades despite being shot through the elbow by a machine gun bullet and having his arm broken. At about 18:00, the brigade HQ was overrun. At about 18:15, 2nd Armoured Brigade engaged the German armour and halted the Axis eastward advance. At dusk, Nehring broke off the action.

Early on 16 July, Nehring renewed his attack. The 5th Indian Infantry Brigade pushed them back but it was clear from intercepted radio traffic that a further attempt would be made. Strenuous preparations to dig in anti-tank guns were made, artillery fire plans organised and a regiment from the 22nd Armoured Brigade was sent to reinforce the 2nd Armoured Brigade. When the attack resumed late in the afternoon, it was repulsed. After the battle, the Indians counted 24 knocked out tanks, as well as armoured cars and numerous anti-tank guns left on the battlefield.

In three days' fighting, the Allies took more than 2,000 Axis prisoners, mostly from the Italian "Brescia" and "Pavia" Divisions; the New Zealand division suffered 1,405 casualties. The fighting at Tel el Eisa and Ruweisat had caused the destruction of three Italian divisions, forced Rommel to redeploy his armour from the south, made it necessary to lay minefields in front of the remaining Italian divisions and stiffen them with detachments of German troops.

To relieve pressure on Ruweisat ridge, Auchinleck ordered the Australian 9th Division to make another attack from the north. In the early hours of 17 July, the Australian 24th Brigade—supported by 44th Royal Tank Regiment (RTR) and strong fighter cover from the air—assaulted Miteirya ridge (known as "Ruin ridge" to the Australians). The initial night attack went well, with 736 prisoners taken, mostly from the Italian "Trento" and "Trieste" motorised divisions. Once again, however, a critical situation for the Axis forces was retrieved by vigorous counter-attacks from hastily assembled German and Italian forces, which forced the Australians to withdraw back to their start line with 300 casualties. Although the Australian Official History of the 24th Brigade's 2/32nd Battalion describes the counter-attack force as "German", the Australian historian Mark Johnston reports that German records indicate that it was the "Trento" Division that overran the Australian battalion.

The Eighth Army now enjoyed a massive superiority in material over the Axis forces: 1st Armoured Division had 173 tanks and more in reserve or in transit, including 61 Grants while Rommel possessed only 38 German tanks and 51 Italian tanks although his armoured units had some 100 tanks awaiting repair.

Auchinleck's plan was for Indian Infantry 161st Brigade to attack along Ruweisat ridge to take Deir el Shein, while the New Zealand 6th Brigade attacked from south of the ridge to the El Mreir depression. At daylight, two British armoured brigades—2nd Armoured Brigade and the fresh 23rd Armoured Brigade—would sweep through the gap created by the infantry. The plan was complicated and ambitious.

The infantry night attack began at 16:30 on 21 July. The New Zealand attack took their objectives in the El Mreir depression but, once again, many vehicles failed to arrive and they were short of support arms in an exposed position. At daybreak on 22 July, the British armoured brigades again failed to advance. At daybreak on 22 July, Nehring's 5th and 8th "Panzer" Regiments responded with a rapid counter-attack which quickly overran the New Zealand infantry in the open, inflicting more than 900 casualties on the New Zealanders. 2nd Armoured Brigade sent forward two regiments to help but they were halted by mines and anti-tank fire.

The attack by Indian 161st Brigade had mixed fortunes. On the left, the initial attempt to clear the western end of Ruweisat failed but at 08:00 a renewed attack by the reserve battalion succeeded. On the right, the attacking battalion broke into the Deir el Shein position but was driven back in hand-to-hand fighting.

Compounding the disaster at El Mreir, at 08:00 the commander of 23rd Armoured Brigade ordered his brigade forward, intent on following his orders to the letter. Major-General Gatehouse—commanding 1st Armoured Division—had been unconvinced that a path had been adequately cleared in the minefields and had suggested the advance be cancelled. However, XIII Corps commander—Lieutenant-General William Gott—rejected this and ordered the attack but on a centre line south of the original plan which he incorrectly believed was mine-free. These orders failed to get through and the attack went ahead as originally planned. The brigade found itself mired in mine fields and under heavy fire. They were then counter-attacked by 21st Panzer at 11:00 and forced to withdraw. The 23rd Armoured Brigade was destroyed, with the loss of 40 tanks destroyed and 47 badly damaged.

At 17:00, Gott ordered 5th Indian Infantry Division to execute a night attack to capture the western half of Ruweisat ridge and Deir el Shein. 3/14th Punjab Regiment from 9th Indian Infantry Brigade attacked at 02:00 on 23 July but failed as they lost their direction. A further attempt in daylight succeeded in breaking into the position but intense fire from three sides resulted in control being lost as the commanding officer was killed, and four of his senior officers were wounded or went missing.

To the north, Australian 9th Division continued its attacks. At 06:00 on 22 July, Australian 26th Brigade attacked Tel el Eisa and Australian 24th Brigade attacked Tel el Makh Khad toward Miteirya (Ruin Ridge). It was during this fighting that Arthur Stanley Gurney performed the actions for which he was posthumously awarded the Victoria Cross. The fighting for Tel el Eisa was costly, but by the afternoon the Australians controlled the feature. That evening, Australian 24th Brigade attacked Tel el Makh Khad with the tanks of 50th RTR in support. The tank unit had not been trained in close infantry support and failed to co-ordinate with the Australian infantry. The result was that the infantry and armour advanced independently and having reached the objective 50th RTR lost 23 tanks because they lacked infantry support.

Once more, the Eighth Army had failed to destroy Rommel's forces, despite its overwhelming superiority in men and equipment. On the other hand, for Rommel the situation continued to be grave as, despite successful defensive operations, his infantry had suffered heavy losses and he reported that "the situation is critical in the extreme".

On 26/27 July, Auchinleck launched Operation Manhood in the northern sector in a final attempt to break the Axis forces. XXX Corps was reinforced with 1st Armoured Division (less 22nd Armoured Brigade), 4th Light Armoured Brigade, and 69th Infantry Brigade. The plan was to break the enemy line south of Miteirya ridge and exploit north-west. The South Africans were to make and mark a gap in the minefields to the south-east of Miteirya by midnight of 26/27 July. By 01:00 on 27 July, 24th Australian Infantry Brigade was to have captured the eastern end of the Miteirya ridge and would exploit toward the north-west. The 69th Infantry Brigade would pass through the minefield gap created by the South Africans to Deir el Dhib and clear and mark gaps in further minefields. The 2nd Armoured Brigade would then pass through to El Wishka and would be followed by 4th Light Armoured Brigade which would attack the Axis lines of communication.
This was the third attempt to break through in the northern sector, and the Axis defenders were expecting the attack. Like the previous attacks, it was hurriedly and therefore poorly planned. The Australian 24th Brigade managed to take their objectives on Miteirya Ridge by 02:00 of 27 July. To the south, the British 69th Brigade set off at 01:30 and managed to take their objectives by about 08:00. However, the supporting anti-tank units became lost in the darkness or delayed by minefields, leaving the attackers isolated and exposed when daylight came. There followed a period during which reports from the battlefront regarding the minefield gaps were confused and conflicting. As a consequence, the advance of 2nd Armoured Brigade was delayed. Rommel launched an immediate counter-attack and the German armoured battlegroups overran the two forward battalions of 69th Brigade. Meanwhile, 50th RTR supporting the Australians was having difficulty locating the minefield gaps made by Australian 2/24th Battalion. They failed to find a route through and in the process were caught by heavy fire and lost 13 tanks. The unsupported 2/28th Australian battalion on the ridge was overrun. The 69th Brigade suffered 600 casualties and the Australians 400 for no gain.

The Eighth Army was exhausted, and on 31 July Auchinleck ordered an end to offensive operations and the strengthening of the defences to meet a major counter-offensive.
Rommel was later to blame the failure to break through to the Nile on how the sources of supply to his army had dried up and how:

Rommel complained bitterly about the failure of important Italian convoys to get through to him desperately needed tanks and supplies, always blaming the Italian Supreme Command, never suspecting British code breaking.

According to Dr James Sadkovich and others, Rommel often displayed a distinct tendency to blame and scapegoat his Italian allies to cover up his own mistakes and deficiencies as a commander in the field. For example, while Rommel was a very good tactical commander, the Italian and German High Commands were concerned that he lacked operational awareness and a sense of strategic objectives. Dr Sadkovich points out that he would often out-run his logistics and squander valuable (mostly Italian) military hardware and resources in battle after battle without clear strategic goals and an appreciation of the limited logistics his Italian allies were desperately trying to provide him.

The battle was a stalemate, but it had halted the Axis advance on Alexandria (and then Cairo and ultimately the Suez Canal). The Eighth Army had suffered over 13,000 casualties in July, including 4,000 in the 2nd New Zealand Division, 3,000 in the 5th Indian Infantry Division and 2,552 battle casualties in the 9th Australian Division but had taken 7,000 prisoners and inflicted heavy damage on Axis men and machines. In his appreciation of 27 July, Auchinleck wrote that the Eighth Army would not be ready to attack again until mid-September at the earliest. He believed that because Rommel understood that with the passage of time the Allied situation would only improve, he was compelled to attack as soon as possible and before the end of August when he would have superiority in armour. Auchinleck therefore made plans for a defensive battle.

In early August, Winston Churchill and General Sir Alan Brooke—the Chief of the Imperial General Staff (CIGS)—visited Cairo on their way to meet Joseph Stalin in Moscow. They decided to replace Auchinleck, appointing the XIII Corps commander, William Gott, to the Eighth Army command and General Sir Harold Alexander as C-in-C Middle East Command. Persia and Iraq were to be split from Middle East Command as a separate Persia and Iraq Command and Auchinleck was offered the post of C-in-C (which he refused). Gott was killed on the way to take up his command when his aircraft was shot down. Lieutenant-General Bernard Montgomery was appointed in his place and took command on 13 August.




</doc>
<doc id="11776" url="https://en.wikipedia.org/wiki?curid=11776" title="First Italo-Ethiopian War">
First Italo-Ethiopian War

The First Italo-Ethiopian War was fought between Italy and Ethiopia (supported by Russia and France) from 1895 to 1896. It originated from the disputed Treaty of Wuchale which, the Italians claimed, turned the country into an Italian protectorate. During the war, the Ethiopans were vastly numerically superior, well-armed with modern firearms and aided by Russia and France with volunteers, military advisers, army training, and the sale of weapons. In contrast, Italy was a young and mostly poor nation, and equipped with antiquated weapons.

Full-scale war broke out in 1895, with Italian troops from Italian Eritrea having initial success until Ethiopian troops counterattacked Italian positions and besieged the Italian fort of Mekele, forcing its surrender. Italian defeat came about after the Battle of Adwa, where the Ethiopian army dealt the heavily outnumbered Italians and Eritrean askaris decisive blow and forced their retreat back into Eritrea. Some Eritreans, regarded as traitors by the Ethiopians, were also captured and mutilated. The war concluded with the Treaty of Addis Ababa. Though it was not the first African victory over Western colonists, this war became a pre-eminent symbol of the pan-Africanism and secured the Ethiopia's sovereignty until 1936.

The Khedive of Egypt Isma'il Pasha, better known as "Isma'il the Magnificent" had conquered Eritrea as part of his efforts to give Egypt an African empire. Isma'il had tried to follow up that conquest with Ethiopia, but the Egyptian attempts to conquer that realm ended in humiliating defeat. After Egypt's bankruptcy in 1876 followed by the "Ansar" revolt under the leadership of the Mahdi in 1881, the Egyptian position in Eritrea was hopeless with the Egyptian forces cut off and unpaid for years. By 1884 the Egyptians began to pull out of both Sudan and Eritrea.

Egypt had been very much in the French sphere of influence until 1882 when Britain occupied Egypt. A major goal of French foreign policy until 1904 was to diminish British power in Egypt and restore it to its place in the French sphere of influence, and in 1883 the French created the colony of French Somaliland which allowed for the establishment of a French naval base at Djibouti on the Red Sea. The opening of the Suez Canal in 1869 had turned the Horn of Africa into a very strategic region as a navy based in the Horn could interdict any shipping going up and down the Red Sea. By building naval bases on the Red Sea that could intercept British shipping in the Red Sea, the French hoped to reduce the value of the Suez Canal for the British, and thus lever them out of Egypt. A French historian in 1900 wrote: "The importance of Djibouti lies almost solely in the uniqueness of its geographic position, which makes it a port of transit and natural entrepôt for areas more infinitely more populated than its own territory...the rich provinces of central Ethiopia." The British historian Harold Marcus noted that for the French: "Ethiopia represented the entrance to the Nile valley; if she could obtain hegemony over Ethiopia, her dream of a west to east French African empire would be closer to reality". In response, Britain consistently supported Italian ambitions in the Horn of Africa as the best way of keeping the French out.

On 3 June 1884, the Hewett Treaty was signed between Britain, Egypt and Ethiopia that allowed the Ethiopians to occupy parts of Eritrea and allowed the Ethiopian goods to pass in and out of Massawa duty-free. From the viewpoint of Britain, it was highly undesirable that the French replace the Egyptians in Eritrea as that would allow the French to have more naval bases on the Red Sea that could interfere with British shipping using the Suez Canal, and as the British did not want the financial burden of ruling Eritrea, they looked for another power to replace the Egyptians. The Hewett treaty seemed to suggest that Eritrea would fall into the Ethiopian sphere of influence as the Egyptians pulled out. After initially encouraging the Emperor Yohannes IV to move into Eritrea to replace the Egyptians, London decided to have the Italians move into Eritrea. In his history of Ethiopia, Augustus Wylde wrote: "England made use of King John [Emperor Yohannes] as long as he was of any service and then threw him over to the tender mercies of Italy...It is one of our worst bits of business out of the many we have been guilty of in Africa...one of the vilest bites of treachery". After the French had unexpectedly made Tunis into their protectorate in 1881, outraging opinion in Italy over the so-called ""Schiaffo di Tunisi"" (the "slap of Tunis"), Italian foreign policy had been extremely anti-French, and from the British viewpoint the best way of ensuring the Eritrean ports on the Red Sea stayed out of French hands was by having the staunchly anti-French Italians move in. In 1882, Italy had joined the Triple Alliance, allying herself with Austria and Germany against France.

On 5 February 1885 Italian troops landed at Massawa to replace the Egyptians. The Italian government for its part was more than happy to embark upon an imperialist policy to distract its people from the failings in post "Risorgimento" Italy. In 1861, the unification of Italy was supposed to mark the beginning of a glorious new era in Italian life, and many Italians were gravely disappointed to find that not much had changed in the new Kingdom of Italy with the vast majority of Italians still living in abject poverty. To compensate, a chauvinist mood was rampant amongst the upper classes in Italy with the newspaper "Il Diritto" writing in an editorial: "Italy must be ready. The year 1885 will decide her fate as a great power. It is necessary to feel the responsibility of the new era; to become again strong men afraid of nothing, with the sacred love of the fatherland, of all Italy, in our hearts". On the Ethiopian side, the wars that Emperor Yohannes had waged first against the invading Egyptians in the 1870s and then more so against the Sudanese "Mahdiyya" state in the 1880s had been presented by him to his subjects as holy wars in defense of Orthodox Christianity against Islam, reinforcing the Ethiopian belief that their country was an especially virtuous and holy land. The struggle against the "Ansar" from Sudan complicated Yohannes's relations with the Italians, whom he sometimes asked to provide him with guns to fight the "Ansar" and other times he resisted the Italians and proposed a truce with the "Ansar".

On 18 January 1887, at a village named Saati, an advancing Italian Army detachment defeated the Ethiopians in a skirmish, but it ended with the numerically superior Ethiopians surrounding the Italians in Saati after they retreated in face of the enemy's numbers. Some 500 Italian soldiers under Colonel de Christoforis together with 50 Eritrean auxiliaries were sent to support the besieged garrison at Saati. At Dogali on his way to Saati, de Christoforis was ambushed by an Ethiopian force under "Ras" Alula, whose men armed with spears skillfully encircled the Italians who retreated to one hill and then to another higher hill. After the Italians ran out of ammunition, "Ras" Alula ordered his men to charge and the Ethiopians swiftly overwhelmed the Italians in an action that featured bayonets against spears. The Battle of Dogali ended with the Italians losing 23 officers and 407 other ranks killed. As a result of the defeat at Dogali, the Italians abandoned Saati and retreated back to the Red Sea coast. Italians newspapers called the battle a "massacre" and excoriated the "Regio Esercito " for not assigning de Chistoforis enough ammunition. Having, at first, encouraged Emperor Yohannes to move into Eritrea, and then having encouraged the Italians to also do so, London realised a war was brewing and decided to try to mediate, largely out of the fear that the Italians might actually lose.

The British consul in Zanzibar, Gerald Portal, was sent in 1887 to mediate between the Ethiopians and Italians before war broke out. Portal set sail on an Egyptian ship, the "Narghileh", which he called a "small, dirty, greasy steamer bound for Jeddah, Suakin and Massawa, in which we very soon discovered that our traveling companions consisted of cockroaches and other smaller animals innumerable, a flock of sheep, a few cows, many cocks, hens, turkeys and geese, and a dozen of the evil-looking Greek adventurers who always appear like vultures around a dead carcass whenever there is a possibility of a campaign in North Africa." Portal upon meeting the Emperor Yohannes on 4 December 1887 presented him with gifts and a letter from Queen Victoria urging him to settle with the Italians. Portal reported: "What might have been possible in August or September was impossible in December, when the whole of the immense available forces in the country were already under arms; and that there now remains no hope of a satisfactory adjustment of the difficulties between Italy and Abyssinia [Ethiopia] until the question of the relative supremacy of these two nations has been decided by an appeal to the fortunes of war...No one who has once seen the nature of the gorges, ravines and mountain passes near the Abyssinian frontier can doubt for a moment that any advance by a civilised army in the face of the hostile Abyssinian hordes would be accomplished at the price of a fearful loss of life on both sides. ... The Abyssinians are savage and untrustworthy, but they are also redeemed by the possession of an unbounded courage, by a disregard of death, and by a national pride which leads them to look down on every human being who has not had the good fortune to be born an Abyssinian". Portal ended by writing that the Italians were making a mistake in preparing to go war against Ethiopia: "It is the old, old story, contempt of a gallant enemy because his skin happens to be chocolate or brown or black, and because his men have not gone through orthodox courses of field-firing, battalion drill, or 'autumn maneuvers'".

The defeat at Dogali made the Italians cautious for a moment, but on 10 March 1889, Emperor Yohannes died after being wounded in battle against the "Ansar" and on his deathbed admitted that "Ras" Mengesha, the supposed son of his brother, was actually his own son and asked that he succeed him. The revelation that the emperor had slept with his brother's wife scandalised intensely Orthodox Ethiopia, and instead the "Negus" Menelik was proclaimed emperor on 26 March 1889. "Ras" Mengesha, one of the most powerful Ethiopian noblemen, was unhappy about being by-passed in the succession and for a time allied himself with the Italians against the Emperor Menelik. Under the feudal Ethiopian system, there was no standing army, and instead, the nobility raised up armies on behalf of the Emperor. In December 1889, the Italians advanced inland again and took the cities of Asmara and Keren and in January 1890 took Adowa.

On March 25, 1889, the Shewa ruler Menelik II, having conquered Tigray and Amhara, declared himself Emperor of Ethiopia (or "Abyssinia", as it was commonly called in Europe at the time). Barely a month later, on May 2, he signed the Treaty of Wuchale with the Italians, which apparently gave them control over Eritrea, the Red Sea coast to the northeast of Ethiopia, in return for recognition of Menelik's rule. Menelik II continued the policy of Tewodros II of integrating Ethiopia.

However, the bilingual treaty did not say the same thing in Italian and Amharic; the Italian version did not give the Ethiopians the "significant autonomy" written into the Amharic translation. The former text established an Italian protectorate over Ethiopia, but the Amharic version merely stated that Menelik could contact foreign powers and conduct foreign affairs through Italy if he so chose. Italian diplomats, however, claimed that the original Amharic text included the clause and Menelik knowingly signed a modified copy of the Treaty. In October 1889, the Italians informed all of the other European governments because of the Treaty of Wuchale that Ethiopia was now an Italian protectorate and therefore the other European nations could not conduct diplomatic relations with Ethiopia. With the exceptions of the Ottoman Empire, which still maintained its claim to Eritrea, and Russia, which disliked the idea of an Orthodox nation being subjugated to a Roman Catholic nation, all of the European powers accepted the Italian claim to a protectorate.

The Italian claim that Menelik was aware of Article XVII turning his nation into an Italian protectorate seems unlikely given that the Emperor Menelik sent letters to Queen Victoria and Emperor Wilhelm II in late 1889 and was informed in the replies in early 1890 that neither Britain nor Germany could have diplomatic relations with Ethiopia on the account of Article XVII of the Treaty of Wuchale, a revelation that came as a great shock to the Emperor. Victoria's letter was polite whereas Wilhelm's letter was somewhat more rude, saying that King Umberto I was a great friend of Germany and Menelik's violation of the supposed Italian protectorate was a grave insult to Umberto, adding that he never wanted to hear from Menelik again. Moreover, Menelik did not know Italian and only signed the Amharic text of the treaty, being assured that there were no differences between the Italian and Amharic texts before he signed. The differences between the Italian and Amharic texts were due to the Italian minister in Addis Ababa, Count Pietro Antonelli, who had been instructed by his government to gain as much territory as possible in negotiating with the Emperor Menelik. However, knowing Menelik was now enthroned as the King of Kings and had a strong position, Antonelli was in the unenviable situation of negotiating a treaty that his own government might disallow. Therefore, he inserted the statement-making Ethiopia give up its right to conduct its foreign affairs to Italy as a way of pleasing his superiors who might otherwise have fired him for only making small territorial gains. Antonelli was fluent in Amharic and given that Menelik only signed the Amharic text he could not have been unaware that the Amharic version of Article XVII only stated that the King of Italy places the services of his diplomats at the disposal of the Emperor of Ethiopia to represent him abroad if he so wished. When his subterfuge was exposed in 1890 with Menelik indignantly saying he would never sign away his country's independence to anybody, Antonelli who left Addis Ababa in mid 1890 resorted to racism, telling his superiors in Rome that as Menelik was a black man, he was thus intrinsically dishonest and it was only natural the Emperor would lie about the protectorate he supposedly willingly turned his nation into.

Francesco Crispi, the Italian Prime Minister was an ultra-imperialist who believed the newly unified Italian state required "the grandeur of a second Roman empire". Crispi believed that the Horn of Africa was the best place for the Italians to start building the new Roman empire. The American journalist James Perry wrote that "Crispi was a fool, a bigot and a very dangerous man". Because of the Ethiopian refusal to abide by the Italian version of the treaty and despite economic handicaps at home, the Italian government decided on a military solution to force Ethiopia to abide by the Italian version of the treaty. In doing so, they believed that they could exploit divisions within Ethiopia and rely on tactical and technological superiority to offset any inferiority in numbers. The efforts of Emperor Menelik, viewed as pro-French in London, to unify Ethiopia and thus bring control source of the Blue Nile under his rule was perceived in Whitehall as a threat to keeping Egypt in the British sphere of influence. As Menelik became increasingly successful in unifying Ethiopia, London brought more pressure to bear on Rome for the Italians to move inland and conquer Ethiopia once and for all.

There was a broader, European background as well: the Triple Alliance of Germany, Austria–Hungary, and Italy was under some stress, with Italy being courted by England. Two secret Anglo-Italian protocols in 1891, left most of Ethiopia in Italy's sphere of influence. France, one of the members of the opposing Franco-Russian Alliance, had its own claims on Eritrea and was bargaining with Italy over giving up those claims in exchange for a more secure position in Tunisia. Meanwhile, Russia was supplying weapons and other aid to Ethiopia. It had been trying to gain a foothold in Ethiopia, and in 1894, after denouncing the Treaty of Wuchale in July, it received an Ethiopian mission in St. Petersburg and sent arms and ammunition to Ethiopia. This support continued after the war ended. The Russian travel writer Alexander Bulatovich who went to Ethiopia to serve as a Red Cross volunteer with the Emperor Menelik made a point of emphasizing in his books that the Ethiopians converted to Christianity before any of the Europeans ever did, described the Ethiopians as a deeply religious people like the Russians, and argued the Ethiopians did not have the "low cultural level" of the other African peoples, making them equal to the Europeans. Germany and Austria supported their ally in the Triple Alliance Italy while France and Russia supported Ethiopia.

In 1893, judging that his power over Ethiopia was secure, Menelik repudiated the treaty; in response the Italians ramped up the pressure on his domain in a variety of ways, including the annexation of small territories bordering their original claim under the Treaty of Wuchale, and finally culminating with a military campaign and across the Mareb River into Tigray (on the border with Eritrea) in December 1894. The Italians expected disaffected potentates like Negus Tekle Haymanot of Gojjam, Ras Mengesha Yohannes, and the Sultan of Aussa to join them; instead, all of the ethnic Tigrayan or Amharic peoples flocked to the Emperor Menelik's side in a display of both nationalism and anti-Italian feeling, while other peoples of dubious loyalty (e.g. the Sultan of Aussa) were watched by Imperial garrisons. In June 1894, "Ras" Mengesha and his generals had appeared in Addis Ababa carrying large stones which they dropped before the Emperor Menelik (a gesture that is a symbol of submission in Ethiopian culture). In Ethiopia, the popular saying at the time was: "Of a black snake's bite, you may be cured, but from the bite of a white snake, you will never recover." There was an overwhelming national unity in Ethiopia as various feuding noblemen rallied behind the emperor who insisted that Ethiopia, unlike the other African nations, would retain its freedom and not be subjected to Italy. The ethnic rivalries between the Tigrians and the Amhara that the Italians were counting upon did not prove to be a factor as Menelik pointed out that the Italians held all Ethnic Africans, regardless of their individual ethnic backgrounds, in contempt, noting the segregation policies in Eritrea applied to all Ethnic Africans. Further, Menelik had spent much of the previous four years building up a supply of modern weapons and ammunition, acquired from the French, British, and the Italians themselves, as the European colonial powers sought to keep each other's North African aspirations in check. They also used the Ethiopians as a proxy army against the Sudanese Mahdists.

In December 1894, Bahta Hagos led a rebellion against the Italians in Akkele Guzay, claiming support of Mengesha. Units of General Oreste Baratieri's army under Major Pietro Toselli crushed the rebellion and killed Bahta at the Battle of Halai. The Italian army then occupied the Tigrian capital, Adwa. Baratieri suspected that Mengesha would invade Eritrea, and met him at the Battle of Coatit in January 1895. The victorious Italians chased the retreating Mengesha, capturing weapons and important documents proving his complicity with Menelik. The victory in this campaign, along with previous victories against the Sudanese Mahdists, led the Italians to underestimate the difficulties to overcome in a campaign against Menelik. At this point, Emperor Menelik turned to France, offering a treaty of alliance; the French response was to abandon the Emperor in order to secure Italian approval of the Treaty of Bardo which would secure French control of Tunisia. Virtually alone, on 17 September 1895, Emperor Menelik issued a proclamation calling up the men of Shewa to join his army at Were Ilu.

As the Italians were poised to enter Ethiopian territory, the Ethiopians mobilised en masse all over the country. Helping it was the newly updated imperial fiscal and taxation system. As a result, a hastily mobilised army of 196,000 men gathered from all parts of Abyssinia, more than half of whom were armed with modern rifles, rallied at Addis Ababa in support of the Emperor and defence of their country.

The only European ally of Ethiopia was Russia. The Ethiopian emperor sent his first diplomatic mission to St. Petersburg in 1895. In June 1895, the newspapers in St. Petersburg wrote, "Along with the expedition, Menelik II sent his diplomatic mission to Russia, including his princes and his bishop". Many citizens of the capital came to meet the train that brought Prince Damto, General Genemier, Prince Belyakio, Bishop of Harer Gabraux Xavier and other members of the delegation to St. Petersburg. On the eve of war, an agreement providing military help for Ethiopia was concluded.

The next clash came at Amba Alagi on 7 December 1895, when Ethiopian soldiers overran the Italian positions dug in on the natural fortress, and forced the Italians to retreat back to Eritrea. The remaining Italian troops under General Giuseppe Arimondi reached the unfinished Italian fort at Mekele. Arimondi left there a small garrison of approximately 1,150 Askaris and 200 Italians, commanded by Major Giuseppe Galliano, and took the bulk of his troops to Adigrat, where Oreste Baratieri, the Italian Commander, was concentrating the Italian Army.

The first Ethiopian troops reached Mekele in the following days. Ras Makonnen surrounded the fort at Mekele on 18 December, but the Italian Commander adroitly used promises of a negotiated surrender to prevent the Ras from attacking the fort. By the first days of January, Emperor Menelik, accompanied by his Queen Taytu Betul, had led large forces into Tigray, and besieged the Italians for sixteen days (6–21 January 1896), making several unsuccessful attempts to carry the fort by storm, until the Italians surrendered with permission from the Italian Headquarters. Menelik allowed them to leave Mekele with their weapons, and even provided the defeated Italians mules and pack animals to rejoin Baratieri. While some historians read this generous act as a sign that Emperor Menelik still hoped for a peaceful resolution to the war, Harold Marcus points out that this escort allowed him a tactical advantage: "Menelik craftily managed to establish himself in Hawzien, at Gendepata, near Adwa, where the mountain passes were not guarded by Italian fortifications."

Heavily outnumbered, Baratieri refused to engage, knowing that due to their lack of infrastructure the Ethiopians could not keep large numbers of troops in the field much longer. However, Baratieri also never knew about the true numerical strength of the Ethiopian army that was to face his army, so he rather further fortified his positions in the Tigray. But the Italian government of Francesco Crispi was unable to accept being stymied by non-Europeans. The prime minister specifically ordered Baratieri to advance deep into enemy territory and bring about a battle.

The decisive battle of the war was the Battle of Adwa on March 1, 1896, which took place in the mountainous country north of the actual town of Adwa (or Adowa). The Italian army comprised four brigades totaling approximately 17,700 men, with fifty-six artillery pieces; the Ethiopian army comprised several brigades numbering between 73,000 and 120,000 men (80–100,000 with firearms: according to Richard Pankhurst, the Ethiopians were armed with approximately 100,000 rifles of which about half were quick-firing), with almost fifty artillery pieces.

General Baratieri planned to surprise the larger Ethiopian force with an early morning attack, expecting his enemy to be asleep. However, the Ethiopians had risen early for Church services and, upon learning of the Italian advance, promptly attacked. The Italian forces were hit by wave after wave of attacks, until Menelik released his reserve of 25,000 men, destroying an Italian brigade. Another brigade was cut off, and destroyed by a cavalry charge. The last two brigades were destroyed piecemeal. By noon, the Italian survivors were in full retreat.

While Menelik's victory was in a large part due to the sheer force of numbers, his troops were well-armed because of his careful preparations. The Ethiopian army only had a feudal system of organisation but proved capable of properly executing the strategic plan drawn up in Menelik's headquarters. However, the Ethiopian army also had its problems. The first was the quality of its arms, as the Italian and British colonial authorities could sabotage the transportation of 30,000–60,000 modern Mosin–Nagant rifles and Berdan rifles from Russia into landlocked Ethiopia. Secondly, the Ethiopian army's feudal organisation meant that nearly the entire force was composed of peasant militia. Russian military experts advising Menelik II suggested a full-contact battle with Italians, to neutralise the Italian fire superiority, instead of engaging in a campaign of harassment designed to nullify problems with arms, training, and organisation.

Some Russian councillors of Menelik II and a team of fifty Russian volunteers participated in the battle, among them Nikolay Leontiev, an officer of the Kuban Cossack army. Russian support for Ethiopia also led to a Russian Red Cross mission, which arrived in Addis Ababa some three months after Menelik's Adwa victory.

The Italians suffered about 7,000 killed and 1,500 wounded in the battle and subsequent retreat back into Eritrea, with 3,000 taken prisoner; Ethiopian losses have been estimated around 4,000 killed and 8,000 wounded. In addition, 2,000 Eritrean Askaris were killed or captured. Italian prisoners were treated as well as possible under difficult circumstances, but 800 captured Askaris, regarded as traitors by the Ethiopians, had their right hands and left feet amputated. Menelik, knowing that the war was very unpopular in Italy with the Italian Socialists in particular condemning the policy of the Crispi government, chose to be a magnanimous victor, making it clear that he saw a difference between the Italian people and Crispi.

Menelik was a well respected ruler whose lineage could be traced back to King Solomon and the Queen of Sheba. He used that status and its power to peacefully create alliances and to conquer those who opposed him. He was such a skillful negotiator that he was able to unify almost all of the Northern, Western, and Central territories peacefully. He made Ras Mengesha Yohannes the prince of Tigray, and along with the threat of the Italians, convinced him to join him. Menelik not only conquered large groups of people like the Oromo, Guarage, and Wolayta, he also managed to incorporate leaders from those groups into his own government, and war council. Whether conquered peacefully or militarily, almost all groups had a voice under Menelik.

From 1888 to 1892, one third of the Ethiopian population died from what would become known as The Great Famine. On the heels of this disaster, Menelik used his relationship with the Europeans to help modernise Ethiopia. The Europeans soon flooded the Ethiopian economy looking for business opportunities. Meanwhile, Menelik established the first national bank, a national currency, a postal system, railroads, modern roads, and electricity. The bank and currency unified the people economically and helped establish economic stability. The railways, roads, and postal system connected the people and tribes as a nation as well as physically. Possibly his greatest achievement in creating a national identity was through the creation of Addis Ababa. This was an important psychological component in the establishment of a nation. It provided a metaphorical ‘head’ for the nation. It became permanent location for the entire country to look upon for support and for guidance.

Menelik retired in good order to his capital, Addis Ababa, and waited for the fallout of the victory to hit Italy. Riots broke out in several Italian cities, and within two weeks, the Crispi government collapsed amidst Italian disenchantment with "foreign adventures".

Menelik secured the Treaty of Addis Ababa in October, which delineated the borders of Eritrea and forced Italy to recognise the independence of Ethiopia. Delegations from the United Kingdom and France—whose colonial possessions lay next to Ethiopia—soon arrived in the Ethiopian capital to negotiate their own treaties with this newly proven power. Owing to Russia's diplomatic support of her fellow Orthodox nation, Russia's prestige greatly increased in Ethiopia. The adventuresome Seljan brothers, Mirko and Stjepan, who were actually Catholic Croats, were warmly welcomed when they arrived in Ethiopia in 1899 when they misinformed their hosts by saying they were Russians. As France supported Ethiopia with weapons, French influence increased markedly. Prince Henri of Orléans, the French traveller, wrote: "France gave rifles to this country and taking the hand of its Emperor like an elder sister has explained to him the old motto which has guided her across the centuries of greatness and glory: Honor and Country!". In December 1896, a French diplomatic mission in Addis Ababa arrived and on 20 March 1897 signed a treaty that was described as ""véritable traité d'alliance". In turn, the increase in French influence in Ethiopia led to fears in London that the French would gain control of the Blue Nile and would be able to "lever" the British out of Egypt. To keep control of the Nile in Egypt, the British decided in March 1896 to advance down the Nile from Egypt into the Sudan to liquidate the "Mahdiyya" state. On 12 March 1896, upon hearing of the Italian defeat at the Battle of Adwa, the Prime Minister Lord Salisbury, gave instructions for the British forces in Egypt to occupy the Sudan before the French could liquidate the "Mahdiyya" state, stating that no hostile power would be allowed to control the Nile.

In 1935, Italy launched a second invasion, which resulted in an Italian victory and the occupation of Ethiopia, which was annexed to Italian East Africa, until the Italians were defeated in the Second World War and expelled from the country by the British, with some assistance from the Ethiopian "Arbegnochs". The Italians successively started a guerrilla war until 1943 in some areas of northern Ethiopia, supporting the rebellion of the Galla in 1942.




</doc>
<doc id="11778" url="https://en.wikipedia.org/wiki?curid=11778" title="Frederick Soddy">
Frederick Soddy

Frederick Soddy FRS (2 September 1877 – 22 September 1956) was an English radiochemist who explained, with Ernest Rutherford, that radioactivity is due to the transmutation of elements, now known to involve nuclear reactions. He also proved the existence of isotopes of certain radioactive elements.

Soddy was born at 5 Bolton Road, Eastbourne, England, the son of Benjamin Soddy, corn merchant, and his wife Hannah Green. He went to school at Eastbourne College, before going on to study at University College of Wales at Aberystwyth and at Merton College, Oxford, where he graduated in 1898 with first class honours in chemistry. He was a researcher at Oxford from 1898 to 1900.

In 1900 he became a demonstrator in chemistry at McGill University in Montreal, Quebec, where he worked with Ernest Rutherford on radioactivity.
He and Rutherford realized that the anomalous behaviour of radioactive elements was because they decayed into other elements.
This decay also produced alpha, beta, and gamma radiation. When radioactivity was first discovered, no one was sure what the cause was. It needed careful work by Soddy and Rutherford to prove that atomic transmutation was in fact occurring.

In 1903, with Sir William Ramsay at University College London, Soddy showed that the decay of radium produced helium gas. In the experiment a sample of radium was enclosed in a thin-walled glass envelope sited within an evacuated glass bulb. After leaving the experiment running for a long period of time, a spectral analysis of the contents of the former evacuated space revealed the presence of helium. Later in 1907, Rutherford and Thomas Royds showed that the helium was first formed as positively charged nuclei of helium (He) which were identical to alpha particles, which could pass through the thin glass wall but were contained within the surrounding glass envelope.

From 1904 to 1914, Soddy was a lecturer at the University of Glasgow. Ruth Pirret worked as his research assistant during this time. 
In May 1910 Soddy was elected a Fellow of the Royal Society. In 1914 he was appointed to a chair at the University of Aberdeen, where he worked on research related to World War I.

The work that Soddy and his research assistant Ada Hitchins did at Glasgow and Aberdeen showed that uranium decays to radium. It also showed that a radioactive element may have more than one atomic mass though the chemical properties are identical. Soddy named this concept isotope meaning 'same place'. The word 'isotope' was initially suggested to him by Margaret Todd. Later, J. J. Thomson showed that non-radioactive elements can also have multiple isotopes.

In 1913, Soddy also showed that an atom moves lower in atomic number by two places on alpha emission, higher by one place on beta emission. This was discovered at about the same time by Kazimierz Fajans, and is known as the radioactive displacement law of Fajans and Soddy, a fundamental step toward understanding the relationships among families of radioactive elements. Soddy published "The Interpretation of Radium" (1909) and "Atomic Transmutation" (1953).

In 1918 he announced discovery of a stable isotope of Protactinium, working with John Arnold Cranston. This slightly post-dated its discovery by German counterparts; however, it is said their discovery was actually made in 1915 but its announcement was delayed due to Cranston's notes being locked away whilst on active service in the First World War.

In 1919 he moved to the University of Oxford as Dr Lee's Professor of Chemistry, where, in the period up till 1936, he reorganized the laboratories and the syllabus in chemistry. He received the 1921 Nobel Prize in chemistry for his research in radioactive decay and particularly for his formulation of the theory of isotopes.

His work and essays popularising the new understanding of radioactivity was the main inspiration for H. G. Wells's "The World Set Free" (1914), which features atomic bombs dropped from biplanes in a war set many years in the future. Wells's novel is also known as "The Last War" and imagines a peaceful world emerging from the chaos. In "Wealth, Virtual Wealth and Debt" Soddy praises Wells’s "The World Set Free". He also says that radioactive processes probably power the stars.

In four books written from 1921 to 1934, Soddy carried on a "campaign for a radical restructuring of global monetary relationships", offering a perspective on economics rooted in physics – the laws of thermodynamics, in particular – and was "roundly dismissed as a crank". While most of his proposals – "to abandon the gold standard, let international exchange rates float, use federal surpluses and deficits as macroeconomic policy tools that could counter cyclical trends, and establish bureaus of economic statistics (including a consumer price index) in order to facilitate this effort" – are now conventional practice, his critique of fractional-reserve banking still "remains outside the bounds of conventional wisdom" although a recent paper by the IMF reinvigorated his proposals. Soddy wrote that financial debts grew exponentially at compound interest but the real economy was based on exhaustible stocks of fossil fuels. Energy obtained from the fossil fuels could not be used again. This criticism of economic growth is echoed by his intellectual heirs in the now emergent field of ecological economics.

In "Wealth, Virtual Wealth and Debt" Soddy cited the (fraudulent) Protocols of the Learned Elders of Zion as evidence for the belief, which was relatively widespread at the time, of a "financial conspiracy to enslave the world". He used the imagery of a Jewish conspiracy to buttress his claim that "A corrupt monetary system strikes at the very life of the nation." In the same document, he made reference to "the semi-Oriental" who is "supreme" in "high finance" and to an "iridescent bubble of beliefs blown around the world by the Hebraic hierarchy". Later in life he published a pamphlet "Abolish Private Money, or Drown in Debt" (1939) with a noted publisher of anti-Semitic texts. The influence of his writing can be gauged, for example, in this quote from Ezra Pound:
"Professor Frederick Soddy states that the Gold Standard monetary system has wrecked a scientific age! ... The world's bankers ... have not been content to take their share of modern wealth production – great as it has been – but they have refused to allow the masses of mankind to receive theirs."

He rediscovered the Descartes' theorem in 1936 and published it as a poem, "The Kiss Precise", quoted at Problem of Apollonius. The kissing circles in this problem are sometimes known as Soddy circles.

He received the Nobel Prize in Chemistry in 1921 and the same year he was elected member of the International Atomic Weights Committee. A small crater on the far side of the Moon as well as the radioactive uranium mineral soddyite are named after him.

Soddy married Winifred Beilby, the daughter of Sir George Beilby, in 1908. He died in Brighton, England in 1956.






</doc>
<doc id="11780" url="https://en.wikipedia.org/wiki?curid=11780" title="Fur seal">
Fur seal

Fur seals are any of nine species of pinnipeds belonging to the subfamily Arctocephalinae in the family Otariidae. They are much more closely related to sea lions than true seals, and share with them external ears (pinnae), relatively long and muscular foreflippers, and the ability to walk on all fours. They are marked by their dense underfur, which made them a long-time object of commercial hunting. Eight species belong to the genus "Arctocephalus" and are found primarily in the Southern Hemisphere, while a ninth species also sometimes called fur seal, the northern fur seal ("Callorhinus ursinus"), belongs to a different genus and inhabits the North Pacific.

Fur seals and sea lions make up the family Otariidae. Along with the Phocidae and Odobodenidae, ottariids are pinnipeds descending from a common ancestor most closely related to modern bears (as hinted by the subfamily Arctocephalinae, meaning "bear-headed"). The name pinniped refers to mammals with front and rear flippers. Otariids arose about 15-17 million years ago in the Miocene, and were originally land mammals that rapidly diversified and adapted to a marine environment, giving rise to the semiaquatic marine mammals that thrive today. Fur seals and sea lions are closely related and commonly known together as the "eared seals". 
Until recently, fur seals were all grouped under a single subfamily of Pinnipedia, called the Arctocephalinae, to contrast them with Otariinae – the sea lions – based on the most prominent common feature, namely the coat of dense underfur intermixed with guard hairs. Recent genetic evidence, however, suggests "Callorhinus" is more closely related to some sea lion species, and the fur seal/sea lion subfamily distinction has been eliminated from many taxonomies. Nonetheless, all fur seals have certain features in common: the fur, generally smaller sizes, farther and longer foraging trips, smaller and more abundant prey items, and greater sexual dimorphism. For these reasons, the distinction remains useful. Fur seals comprise two genera: "Callorhinus", and "Arctocephalus". "Callorhinus" is represented by just one species in the Northern Hemisphere, the northern fur seal ("Callorhinus ursinus"), and "Arctocephalus" is represented by eight species in the Southern Hemisphere. The southern fur seals comprising the genus "Arctocephalus" include Antarctic fur seals, Galapagos fur seals, Juan Fernandez fur seals, New Zealand fur seals, brown fur seals, South American fur seals, and subantarctic fur seals.

Along with the previously mentioned thick underfur, fur seals are distinguished from sea lions by their smaller body structure, greater sexual dimorphism, smaller prey, and longer foraging trips during the feeding cycle. The physical appearance of fur seals varies with individual species, but the main characteristics remain constant. Fur seals are characterized by their external pinnae, dense underfur, vibrissae, and long, muscular limbs. They share with other otariids the ability to rotate their rear limbs forward, supporting their bodies and allowing them to ambulate on land. In water, their front limbs, typically measuring about a fourth of their body length, act as oars and can propel them forward for optimal mobility. The surfaces of these long, paddle-like fore limbs are leathery with small claws. Otariids have a dog-like head, sharp, well-developed canines, sharp eyesight, and keen hearing. They are extremely sexually dimorphic mammals, with the males often two to five times the size of the females, with proportionally larger heads, necks, and chests. Size ranges from about 1.5 m, 64 kg in the male Galapagos fur seal (also the smallest pinniped) to 2.5 m, 180 kg in the adult male New Zealand fur seal. Most fur seal pups are born with a black-brown coat that molts at 2–3 months, revealing a brown coat that typically gets darker with age. Some males and females within the same species have significant differences in appearance, further contributing to the sexual dimorphism. Females and juveniles often have a lighter colored coat overall or only on the chest, as seen in South American fur seals. In a northern fur seal population, the females are typically silvery-gray on the dorsal side and reddish-brown on their ventral side with a light gray patch on their chest. This makes them easily distinguished from the males with their brownish-gray to reddish-brown or black coats.

Of the fur seal family, eight species are considered southern fur seals, and only one is found in the Northern Hemisphere. The southern group includes Antarctic, Galapagos, Guadalupe, Juan Fernandez, New Zealand, brown, South American, and subantarctic fur seals. They typically spend about 70% of their lives in subpolar, temperate, and equatorial waters. Colonies of fur seals can be seen throughout the Pacific and Southern Oceans from south Australia, Africa, and New Zealand, to the coast of Peru and north to California. They are typically nonmigrating mammals, with the exception of the northern fur seal, which has been known to travel distances up to 10,000 km. Fur seals are often found near isolated islands or peninsulas, and can be seen hauling out onto the mainland during winter. Although they are not migratory, they have been observed wandering hundreds of miles from their breeding grounds in times of scarce resources. For example, the subantarctic fur seal typically resides near temperate islands in the South Atlantic and Indian Oceans north of the Antarctic Polar Front, but juvenile males have been seen wandering as far north as Brazil and South Africa.

Typically, fur seals gather during the summer in large rookeries at specific beaches or rocky outcrops to give birth and breed. All species are polygynous, meaning dominant males reproduce with more than one female. For most species, total gestation lasts about 11.5 months, including a several-month period of delayed implantation of the embryo. Northern fur seal males aggressively select and defend the specific females in their harems. Females typically reach sexual maturity around 3–4 years. The males reach sexual maturity around the same time, but do not become territorial or mate until 6–10 years. The breeding season typically begins in November and lasts 2–3 months. The northern fur seals begin their breeding season as early as June due to their region, climate, and resources. In all cases, the males arrive a few weeks early to fight for their territory and groups of females with which to mate. They congregate at rocky, isolated breeding grounds and defend their territory through fighting and vocalization. Males typically do not leave their territory for the entirety of the breeding season, fasting and competing until all energy sources are depleted. The Juan Fernandez fur seals deviate from this typical behavior, using aquatic breeding territories not seen in other fur seals. They use rocky sites for breeding, but males fight for territory on land and on the shoreline and in the water. Upon arriving to the breeding grounds, females give birth to their pups from the previous season. About a week later, the females mate again and shortly after begin their feeding cycle, which typically consists of foraging and feeding at sea for about 5 days, then returning to the breeding grounds to nurse the pups for about 2 days. Mothers and pups locate each other using call recognition during nursing period. The Juan Fernandez fur seal has a particularly long feeding cycle, with about 12 days of foraging and feeding and 5 days of nursing. Most fur seals continue this cycle for about 9 months until they wean their pup. The exception to this is the Antarctic fur seal, which has a feeding cycle that lasts only 4 months. During foraging trips, most female fur seals travel around 200 km from the breeding site, and can dive around 200 m depending on food availability.
The remainder of the year, fur seals lead a largely pelagic existence in the open sea, pursuing their prey wherever it is abundant. They feed on moderately sized fish, squid, and krill. Several species of the southern fur seal also have sea birds, especially penguins, as part of their diets. Fur seals, in turn, are preyed upon by sharks, killer whales, and occasionally by larger sea lions. These opportunistic mammals tend to feed and dive in shallow waters at night, when their prey are swimming near the surface. South American fur seals exhibit a different diet; adults feed almost exclusively on anchovies, while juveniles feed on demersal fish, most likely due to availability.

When fur seals were hunted in the late 18th and early 19th centuries, they hauled out on remote islands where no predators were present. The hunters reported being able to club the unwary animals to death one after another, making the hunt profitable, though the price per seal skin was low.

The average lifespan of fur seals varies with different species from 13 to 25 years, with females typically living longer. Most populations continue to expand as they recover from previous commercial hunting and environmental threats. 
Many species were heavily exploited by commercial sealers, especially during the 19th century, when their fur was highly valued. Beginning in the 1790s, the ports of Stonington and New Haven, Connecticut, were leaders of the American fur seal trade, which primarily entailed clubbing fur seals to death on uninhabited South Pacific islands, skinning them, and selling the hides in China. Many populations, notably the Guadalupe fur seal, northern fur seal, and Cape fur seal, suffered dramatic declines and are still recovering. Currently, most species are protected, and hunting is mostly limited to subsistence harvest. Globally, most populations can be considered healthy, mostly because they often prefer remote habitats that are relatively inaccessible to humans. Nonetheless, environmental degradation, competition with fisheries, and climate change potentially pose threats to some populations.



</doc>
<doc id="11781" url="https://en.wikipedia.org/wiki?curid=11781" title="Frisian">
Frisian

Frisian usually refers to:


Frisian or Friesian may also refer to:




</doc>
<doc id="11784" url="https://en.wikipedia.org/wiki?curid=11784" title="Fauna (disambiguation)">
Fauna (disambiguation)

Fauna is a collective term for animal life.

Fauna may also refer to:



</doc>
<doc id="11786" url="https://en.wikipedia.org/wiki?curid=11786" title="Federico Fellini">
Federico Fellini

Federico Fellini, (; 20 January 1920 – 31 October 1993) was an Italian film director and screenwriter. Known for his distinct style that blends fantasy and baroque images with earthiness, he is recognized as one of the greatest and most influential filmmakers of all time. His films have ranked, in polls such as "Cahiers du cinéma" and "Sight & Sound", as some of the greatest films of all time. "Sight & Sound" lists his 1963 film "8½" as the 10th-greatest film of all time.

In a career spanning almost fifty years, Fellini won the Palme d'Or for "La Dolce Vita", was nominated for twelve Academy Awards and won four in the category of Best Foreign Language Film, the most for any director in the history of the Academy. At the 65th Annual Academy Awards in Los Angeles, he received an honorary award for Lifetime Achievement. Besides "La Dolce Vita" and "8½", his other well-known films include "La Strada", "Nights of Cabiria", "Juliet of the Spirits", "Satyricon", "Amarcord" and "Fellini's Casanova".

Fellini was born on 20 January 1920, to middle-class parents in Rimini, then a small town on the Adriatic Sea. His father, Urbano Fellini (1894–1956), born to a family of Romagnol peasants and small landholders from Gambettola, moved to Rome in 1915 as a baker apprenticed to the Pantanella pasta factory. His mother, Ida Barbiani (1896–1984), came from a bourgeois Catholic family of Roman merchants. Despite her family's vehement disapproval, she had eloped with Urbano in 1917 to live at his parents' home in Gambettola. A civil marriage followed in 1918 with the religious ceremony held at Santa Maria Maggiore in Rome a year later.

The couple settled in Rimini where Urbano became a traveling salesman and wholesale vendor. Fellini had two siblings: Riccardo (1921–1991), a documentary director for RAI Television, and Maria Maddalena (m. Fabbri; 1929–2002).
In 1924, Fellini started primary school in an institute run by the nuns of San Vincenzo in Rimini, attending the Carlo Tonni public school two years later. An attentive student, he spent his leisure time drawing, staging puppet shows and reading "Il corriere dei piccoli", the popular children's magazine that reproduced traditional American cartoons by Winsor McCay, George McManus and Frederick Burr Opper. (Opper's "Happy Hooligan" would provide the visual inspiration for Gelsomina in Fellini's 1954 film "La Strada"; McCay's "Little Nemo" would directly influence his 1980 film "City of Women".) In 1926, he discovered the world of Grand Guignol, the circus with Pierino the Clown and the movies. Guido Brignone’s "Maciste all’Inferno" (1926), the first film he saw, would mark him in ways linked to Dante and the cinema throughout his entire career.

Enrolled at the Ginnasio Giulio Cesare in 1929, he made friends with Luigi ‘Titta’ Benzi, later a prominent Rimini lawyer (and the model for young Titta in "Amarcord" (1973)). In Mussolini’s Italy, Fellini and Riccardo became members of the "Avanguardista", the compulsory Fascist youth group for males. He visited Rome with his parents for the first time in 1933, the year of the maiden voyage of the transatlantic ocean liner "SS Rex" (which is shown in "Amarcord"). The sea creature found on the beach at the end of "La Dolce Vita" (1960) has its basis in a giant fish marooned on a Rimini beach during a storm in 1934.

Although Fellini adapted key events from his childhood and adolescence in films such as "I Vitelloni" (1953), "8½" (1963), and "Amarcord" (1973), he insisted that such autobiographical memories were inventions: 
In 1937, Fellini opened Febo, a portrait shop in Rimini, with the painter Demos Bonini. His first humorous article appeared in the "Postcards to Our Readers" section of Milan's "Domenica del Corriere". Deciding on a career as a caricaturist and gag writer, Fellini travelled to Florence in 1938, where he published his first cartoon in the weekly "420". According to a biographer, Fellini found school "exasperating" and, in one year, had 67 absences. Failing his military culture exam, he graduated from high school in July 1938 after doubling the exam.

In September 1939, he enrolled in law school at the University of Rome to please his parents. Biographer Hollis Alpert reports that "there is no record of his ever having attended a class". Installed in a family "pensione", he met another lifelong friend, the painter Rinaldo Geleng. Desperately poor, they unsuccessfully joined forces to draw sketches of restaurant and café patrons. Fellini eventually found work as a cub reporter on the dailies "Il Piccolo" and "Il Popolo di Roma", but quit after a short stint, bored by the local court news assignments.

Four months after publishing his first article in "Marc’Aurelio", the highly influential biweekly humour magazine, he joined the editorial board, achieving success with a regular column titled "But Are You Listening?" Described as “the determining moment in Fellini’s life”, the magazine gave him steady employment between 1939 and 1942, when he interacted with writers, gagmen, and scriptwriters. These encounters eventually led to opportunities in show business and cinema. Among his collaborators on the magazine's editorial board were the future director Ettore Scola, Marxist theorist and scriptwriter Cesare Zavattini, and Bernardino Zapponi, a future Fellini screenwriter. Conducting interviews for "CineMagazzino" also proved congenial: when asked to interview Aldo Fabrizi, Italy's most popular variety performer, he established such immediate personal rapport with the man that they collaborated professionally. Specializing in humorous monologues, Fabrizi commissioned material from his young protégé.

Retained on business in Rimini, Urbano sent wife and family to Rome in 1940 to share an apartment with his son. Fellini and Ruggero Maccari, also on the staff of "Marc’Aurelio", began writing radio sketches and gags for films.

Not yet twenty and with Fabrizi's help, Fellini obtained his first screen credit as a comedy writer on Mario Mattoli’s "Il pirata sono io" ("The Pirate's Dream"). Progressing rapidly to numerous collaborations on films at Cinecittà, his circle of professional acquaintances widened to include novelist Vitaliano Brancati and scriptwriter Piero Tellini. In the wake of Mussolini’s declaration of war against France and Britain on 10 June 1940, Fellini discovered Kafka’s "The Metamorphosis", Gogol, John Steinbeck and William Faulkner along with French films by Marcel Carné, René Clair, and Julien Duvivier. In 1941 he published "Il mio amico Pasqualino", a 74-page booklet in ten chapters describing the absurd adventures of Pasqualino, an alter ego.

Writing for radio while attempting to avoid the draft, Fellini met his future wife Giulietta Masina in a studio office at the Italian public radio broadcaster EIAR in the autumn of 1942. Well-paid as the voice of Pallina in Fellini's radio serial, "Cico and Pallina", Masina was also well known for her musical-comedy broadcasts which cheered an audience depressed by the war. In November 1942, Fellini was sent to Libya, occupied by Fascist Italy, to work on the screenplay of "I cavalieri del deserto" ("Knights of the Desert", 1942), directed by Osvaldo Valenti and Gino Talamo. Fellini welcomed the assignment as it allowed him "to secure another extension on his draft order". Responsible for emergency re-writing, he also directed the film's first scenes. When Tripoli fell under siege by British forces, he and his colleagues made a narrow escape by boarding a German military plane flying to Sicily. His African adventure, later published in "Marc’Aurelio" as "The First Flight", marked “the emergence of a new Fellini, no longer just a screenwriter, working and sketching at his desk, but a filmmaker out in the field”.

The apolitical Fellini was finally freed of the draft when an Allied air raid over Bologna destroyed his medical records. Fellini and Giulietta hid in her aunt's apartment until Mussolini's fall on 25 July 1943. After dating for nine months, the couple were married on 30 October 1943. Several months later, Masina fell down the stairs and suffered a miscarriage. She gave birth to a son, Pierfederico, on 22 March 1945, but the child died of encephalitis a month later on 24 April 1945. The tragedy had enduring emotional and artistic repercussions.

After the Allied liberation of Rome on 4 June 1944, Fellini and Enrico De Seta opened the Funny Face Shop where they survived the postwar recession drawing caricatures of American soldiers. He became involved with Italian Neorealism when Roberto Rossellini, at work on "Stories of Yesteryear" (later "Rome, Open City"), met Fellini in his shop, and proposed he contribute gags and dialogue for the script. Aware of Fellini's reputation as Aldo Fabrizi's “creative muse”, Rossellini also requested that he try to convince the actor to play the role of Father Giuseppe Morosini, the parish priest executed by the SS on 4 April 1944.

In 1947, Fellini and Sergio Amidei received an Oscar nomination for the screenplay of "Rome, Open City".

Working as both screenwriter and assistant director on Rossellini's "Paisà" ("Paisan") in 1946, Fellini was entrusted to film the Sicilian scenes in Maiori. In February 1948, he was introduced to Marcello Mastroianni, then a young theatre actor appearing in a play with Giulietta Masina. Establishing a close working relationship with Alberto Lattuada, Fellini co-wrote the director's "Senza pietà" ("Without Pity") and "Il mulino del Po" ("The Mill on the Po"). Fellini also worked with Rossellini on the anthology film "L'Amore" (1948), co-writing the screenplay and in one segment titled, "The Miracle", acting opposite Anna Magnani. To play the role of a vagabond rogue mistaken by Magnani for a saint, Fellini had to bleach his black hair blond.

In 1950 Fellini co-produced and co-directed with Alberto Lattuada "Variety Lights" ("Luci del varietà"), his first feature film. A backstage comedy set among the world of small-time travelling performers, it featured Giulietta Masina and Lattuada's wife, Carla del Poggio. Its release to poor reviews and limited distribution proved disastrous for all concerned. The production company went bankrupt, leaving both Fellini and Lattuada with debts to pay for over a decade. In February 1950, "Paisà" received an Oscar nomination for the screenplay by Rossellini, Sergio Amidei, and Fellini.

After travelling to Paris for a script conference with Rossellini on "Europa '51", Fellini began production on "The White Sheik" in September 1951, his first solo-directed feature. Starring Alberto Sordi in the title role, the film is a revised version of a treatment first written by Michelangelo Antonioni in 1949 and based on the "fotoromanzi", the photographed cartoon strip romances popular in Italy at the time. Producer Carlo Ponti commissioned Fellini and Tullio Pinelli to write the script but Antonioni rejected the story they developed. With Ennio Flaiano, they re-worked the material into a light-hearted satire about newlywed couple Ivan and Wanda Cavalli (Leopoldo Trieste, Brunella Bovo) in Rome to visit the Pope. Ivan's prissy mask of respectability is soon demolished by his wife's obsession with the White Sheik. Highlighting the music of Nino Rota, the film was selected at Cannes (among the films in competition was Orson Welles’s "Othello") and then retracted. Screened at the 13th Venice International Film Festival, it was razzed by critics in "the atmosphere of a soccer match”. One reviewer declared that Fellini had “not the slightest aptitude for cinema direction".

In 1953, "I Vitelloni" found favour with the critics and public. Winning the Silver Lion Award in Venice, it secured Fellini his first international distributor.

Fellini directed "La Strada" based on a script completed in 1952 with Pinelli and Flaiano. During the last three weeks of shooting, Fellini experienced the first signs of severe clinical depression. Aided by his wife, he undertook a brief period of therapy with Freudian psychoanalyst Emilio Servadio.

Fellini cast American actor Broderick Crawford to interpret the role of an aging swindler in "Il Bidone". Based partly on stories told to him by a petty thief during production of "La Strada", Fellini developed the script into a con man's slow descent towards a solitary death. To incarnate the role's "intense, tragic face", Fellini's first choice had been Humphrey Bogart but after learning of the actor's lung cancer, chose Crawford after seeing his face on the theatrical poster of "All the King’s Men" (1949). The film shoot was wrought with difficulties stemming from Crawford's alcoholism. Savaged by critics at the 16th Venice International Film Festival, the film did miserably at the box office and did not receive international distribution until 1964.

During the autumn, Fellini researched and developed a treatment based on a film adaptation of Mario Tobino’s novel, "The Free Women of Magliano". Located in a mental institution for women, financial backers considered the subject had no potential and the project was abandoned.

While preparing "Nights of Cabiria" in spring 1956, Fellini learned of his father’s death by cardiac arrest at the age of sixty-two. Produced by Dino De Laurentiis and starring Giulietta Masina, the film took its inspiration from news reports of a woman’s severed head retrieved in a lake and stories by Wanda, a shantytown prostitute Fellini met on the set of "Il Bidone". Pier Paolo Pasolini was hired to translate Flaiano and Pinelli’s dialogue into Roman dialect and to supervise researches in the vice-afflicted suburbs of Rome. The movie won the Academy Award for Best Foreign Language Film at the 30th Academy Awards and brought Masina the Best Actress Award at Cannes for her performance.

With Pinelli, he developed "Journey with Anita" for Sophia Loren and Gregory Peck. An "invention born out of intimate truth", the script was based on Fellini's return to Rimini with a mistress to attend his father's funeral. Due to Loren's unavailability, the project was shelved and resurrected twenty-five years later as "Lovers and Liars" (1981), a comedy directed by Mario Monicelli with Goldie Hawn and Giancarlo Giannini. For Eduardo De Filippo, he co-wrote the script of "Fortunella", tailoring the lead role to accommodate Masina's particular sensibility.

The Hollywood on the Tiber phenomenon of 1958 in which American studios profited from the cheap studio labour available in Rome provided the backdrop for photojournalists to steal shots of celebrities on the via Veneto. The scandal provoked by Turkish dancer Haish Nana's improvised striptease at a nightclub captured Fellini's imagination: he decided to end his latest script-in-progress, "Moraldo in the City", with an all-night "orgy" at a seaside villa. Pierluigi Praturlon’s photos of Anita Ekberg wading fully dressed in the Trevi Fountain provided further inspiration for Fellini and his scriptwriters. 

Changing the title of the screenplay to "La Dolce Vita", Fellini soon clashed with his producer on casting: the director insisted on the relatively unknown Mastroianni while De Laurentiis wanted Paul Newman as a hedge on his investment. Reaching an impasse, De Laurentiis sold the rights to publishing mogul Angelo Rizzoli. Shooting began on 16 March 1959 with Anita Ekberg climbing the stairs to the cupola of Saint Peter’s in a mammoth décor constructed at Cinecittà. The statue of Christ flown by helicopter over Rome to Saint Peter's Square was inspired by an actual media event on 1 May 1956, which Fellini had witnessed. The film wrapped August 15 on a deserted beach at Passo Oscuro with a bloated mutant fish designed by Piero Gherardi.

"La Dolce Vita" broke all box office records. Despite scalpers selling tickets at 1000 lire, crowds queued in line for hours to see an “immoral movie” before the censors banned it. At an exclusive Milan screening on 5 February 1960, one outraged patron spat on Fellini while others hurled insults. Denounced in parliament by right-wing conservatives, undersecretary Domenico Magrì of the Christian Democrats demanded tolerance for the film's controversial themes. The Vatican's official press organ, "l'Osservatore Romano", lobbied for censorship while the Board of Roman Parish Priests and the Genealogical Board of Italian Nobility attacked the film. In one documented instance involving favourable reviews written by the Jesuits of San Fedele, defending "La Dolce Vita" had severe consequences. In competition at Cannes alongside Antonioni's "L’Avventura", the film won the Palme d'Or awarded by presiding juror Georges Simenon. The Belgian writer was promptly “hissed at” by the disapproving festival crowd.

A major discovery for Fellini after his Italian neorealism period (1950–1959) was the work of Carl Jung. After meeting Jungian psychoanalyst Dr. Ernst Bernhard in early 1960, he read Jung's autobiography, "Memories, Dreams, Reflections" (1963) and experimented with LSD. Bernhard also recommended that Fellini consult the "I Ching" and keep a record of his dreams. What Fellini formerly accepted as "his extrasensory perceptions" were now interpreted as psychic manifestations of the unconscious. Bernhard's focus on Jungian depth psychology proved to be the single greatest influence on Fellini's mature style and marked the turning point in his work from neorealism to filmmaking that was "primarily oneiric". As a consequence, Jung's seminal ideas on the "anima" and the "animus", the role of archetypes and the collective unconscious directly influenced such films as "8½" (1963), "Juliet of the Spirits" (1965), "Fellini Satyricon" (1969), "Casanova" (1976), and "City of Women" (1980). Other key influences on his work include Luis Buñuel, Charlie Chaplin, Sergei Eisenstein, Buster Keaton, Laurel and Hardy, the Marx Brothers, and Roberto Rossellini.

Exploiting "La Dolce Vita"’s success, financier Angelo Rizzoli set up Federiz in 1960, an independent film company, for Fellini and production manager Clemente Fracassi to discover and produce new talent. Despite the best intentions, their overcautious editorial and business skills forced the company to close down soon after cancelling Pasolini’s project, "Accattone" (1961).

Condemned as a "public sinner" for "La Dolce Vita", Fellini responded with "The Temptations of Doctor Antonio", a segment in the omnibus "Boccaccio '70". His second colour film, it was the sole project green-lighted at Federiz. Infused with the surrealistic satire that characterized the young Fellini's work at "Marc’Aurelio", the film ridiculed a crusader against vice, interpreted by Peppino De Filippo, who goes insane trying to censor a billboard of Anita Ekberg espousing the virtues of milk.

In an October 1960 letter to his colleague Brunello Rondi, Fellini first outlined his film ideas about a man suffering creative block: "Well then - a guy (a writer? any kind of professional man? a theatrical producer?) has to interrupt the usual rhythm of his life for two weeks because of a not-too-serious disease. It’s a warning bell: something is blocking up his system." Unclear about the script, its title, and his protagonist's profession, he scouted locations throughout Italy “looking for the film” in the hope of resolving his confusion. Flaiano suggested "La bella confusione" (literally "The Beautiful Confusion") as the movie's title. Under pressure from his producers, Fellini finally settled on "8½", a self-referential title referring principally (but not exclusively) to the number of films he had directed up to that time.

Giving the order to start production in spring 1962, Fellini signed deals with his producer Rizzoli, fixed dates, had sets constructed, cast Mastroianni, Anouk Aimée, and Sandra Milo in lead roles, and did screen tests at the Scalera Studios in Rome. He hired cinematographer Gianni Di Venanzo, among key personnel. But apart from naming his hero Guido Anselmi, he still couldn't decide what his character did for a living. The crisis came to a head in April when, sitting in his Cinecittà office, he began a letter to Rizzoli confessing he had "lost his film" and had to abandon the project. Interrupted by the chief machinist requesting he celebrate the launch of "8½", Fellini put aside the letter and went on the set. Raising a toast to the crew, he "felt overwhelmed by shame… I was in a no exit situation. I was a director who wanted to make a film he no longer remembers. And lo and behold, at that very moment everything fell into place. I got straight to the heart of the film. I would narrate everything that had been happening to me. I would make a film telling the story of a director who no longer knows what film he wanted to make". The self-mirroring structure makes that the entire film is inseparable from its reflecting construction.

Shooting began on 9 May 1962. Perplexed by the seemingly chaotic, incessant improvisation on the set, Deena Boyer, the director's American press officer at the time, asked for a rationale. Fellini told her that he hoped to convey the three levels "on which our minds live: the past, the present, and the conditional - the realm of fantasy". After shooting wrapped on 14 October, Nino Rota composed various circus marches and fanfares that would later become signature tunes of the maestro's cinema. Nominated for four Oscars, "8½" won awards for best foreign language film and best costume design in black-and-white. In California for the ceremony, Fellini toured Disneyland with Walt Disney the day after. 

Increasingly attracted to parapsychology, Fellini met the Turin magician Gustavo Rol in 1963. Rol, a former banker, introduced him to the world of Spiritism and séances. In 1964, Fellini took LSD under the supervision of Emilio Servadio, his psychoanalyst during the 1954 production of "La Strada". For years reserved about what actually occurred that Sunday afternoon, he admitted in 1992 that
objects and their functions no longer had any significance. All I perceived was perception itself, the hell of forms and figures devoid of human emotion and detached from the reality of my unreal environment. I was an instrument in a virtual world that constantly renewed its own meaningless image in a living world that was itself perceived outside of nature. And since the appearance of things was no longer definitive but limitless, this paradisiacal awareness freed me from the reality external to my self. The fire and the rose, as it were, became one.

Fellini's hallucinatory insights were given full flower in his first colour feature "Juliet of the Spirits" (1965), depicting Giulietta Masina as Juliet, a housewife who rightly suspects her husband's infidelity and succumbs to the voices of spirits summoned during a séance at her home. Her sexually voracious next door neighbor Suzy (Sandra Milo) introduces Juliet to a world of uninhibited sensuality but Juliet is haunted by childhood memories of her Catholic guilt and a teenaged friend who committed suicide. Complex and filled with psychological symbolism, the film is set to a jaunty score by Nino Rota.

To help promote "Satyricon" in the United States, Fellini flew to Los Angeles in January 1970 for interviews with Dick Cavett and David Frost. He also met with film director Paul Mazursky who wanted to star him alongside Donald Sutherland in his new film, "Alex in Wonderland". In February, Fellini scouted locations in Paris for "The Clowns", a docufiction both for cinema and television, based on his childhood memories of the circus and a "coherent theory of clowning." As he saw it, the clown "was always the caricature of a well-established, ordered, peaceful society. But today all is temporary, disordered, grotesque. Who can still laugh at clowns?... All the world plays a clown now."

In March 1971, Fellini began production on "Roma", a seemingly random collection of episodes informed by the director's memories and impressions of Rome. The "diverse sequences," writes Fellini scholar Peter Bondanella, "are held together only by the fact that they all ultimately originate from the director’s fertile imagination." The film's opening scene anticipates "Amarcord" while its most surreal sequence involves an ecclesiastical fashion show in which nuns and priests roller skate past shipwrecks of cobwebbed skeletons.

Over a period of six months between January and June 1973, Fellini shot the Oscar-winning "Amarcord". Loosely based on the director's 1968 autobiographical essay "My Rimini", the film depicts the adolescent Titta and his friends working out their sexual frustrations against the religious and Fascist backdrop of a provincial town in Italy during the 1930s. Produced by Franco Cristaldi, the seriocomic movie became Fellini's second biggest commercial success after "La Dolce Vita". Circular in form, "Amarcord" avoids plot and linear narrative in a way similar to "The Clowns" and "Roma". The director's overriding concern with developing a poetic form of cinema was first outlined in a 1965 interview he gave to "The New Yorker" journalist Lillian Ross: "I am trying to free my work from certain constrictions – a story with a beginning, a development, an ending. It should be more like a poem with metre and cadence."

Organized by his publisher Diogenes Verlag in 1982, the first major exhibition of 63 drawings by Fellini was held in Paris, Brussels, and the Pierre Matisse Gallery in New York. A gifted caricaturist, much of the inspiration for his sketches was derived from his own dreams while the films-in-progress both originated from and stimulated drawings for characters, decor, costumes and set designs. Under the title, "I disegni di Fellini" (Fellini's Designs), he published 350 drawings executed in pencil, watercolours, and felt pens.

On 6 September 1985 Fellini was awarded the Golden Lion for lifetime achievement at the 42nd Venice Film Festival. That same year, he became the first non-American to receive the Film Society of Lincoln Center’s annual award for cinematic achievement.

Long fascinated by Carlos Castaneda’s "", Fellini accompanied the Peruvian author on a journey to the Yucatán to assess the feasibility of a film. After first meeting Castaneda in Rome in October 1984, Fellini drafted a treatment with Pinelli titled "Viaggio a Tulun". Producer Alberto Grimaldi, prepared to buy film rights to all of Castaneda's work, then paid for pre-production research taking Fellini and his entourage from Rome to Los Angeles and the jungles of Mexico in October 1985. When Castaneda inexplicably disappeared and the project fell through, Fellini's mystico-shamanic adventures were scripted with Pinelli and serialized in "Corriere della Sera" in May 1986. A barely veiled satirical interpretation of Castaneda's work, "Viaggio a Tulun" was published in 1989 as a graphic novel with artwork by Milo Manara and as "Trip to Tulum" in America in 1990.

For "Intervista", produced by Ibrahim Moussa and RAI Television, Fellini intercut memories of the first time he visited Cinecittà in 1939 with present-day footage of himself at work on a screen adaptation of Franz Kafka’s "Amerika". A meditation on the nature of memory and film production, it won the special 40th Anniversary Prize at Cannes and the 15th Moscow International Film Festival Golden Prize. In Brussels later that year, a panel of thirty professionals from eighteen European countries named Fellini the world’s best director and "8½" the best European film of all time.

In early 1989 Fellini began production on "The Voice of the Moon", based on Ermanno Cavazzoni’s novel, "Il poema dei lunatici" ("The Lunatics' Poem"). A small town was built at Empire Studios on the via Pontina outside Rome. Starring Roberto Benigni as Ivo Salvini, a madcap poetic figure newly released from a mental institution, the character is a combination of "La Strada"'s Gelsomina, Pinocchio, and Italian poet Giacomo Leopardi. Fellini improvised as he filmed, using as a guide a rough treatment written with Pinelli. Despite its modest critical and commercial success in Italy, and its warm reception by French critics, it failed to interest North American distributors.

Fellini won the "Praemium Imperiale", the equivalent of the Nobel Prize in the visual arts, awarded by the Japan Art Association in 1990.

In July 1991 and April 1992, Fellini worked in close collaboration with Canadian filmmaker Damian Pettigrew to establish "the longest and most detailed conversations ever recorded on film". Described as the "Maestro's spiritual testament” by his biographer Tullio Kezich, excerpts culled from the conversations later served as the basis of their feature documentary, "" (2002) and the book, "". Finding it increasingly difficult to secure financing for feature films, Fellini developed a suite of television projects whose titles reflect their subjects: "Attore", "Napoli", "L’Inferno", "L'opera lirica", and "L’America".

In April 1993 Fellini received his fifth Oscar, for lifetime achievement, "in recognition of his cinematic accomplishments that have thrilled and entertained audiences worldwide". On 16 June, he entered the Cantonal Hospital in Zurich for an angioplasty on his femoral artery but suffered a stroke at the Grand Hotel in Rimini two months later. Partially paralyzed, he was first transferred to Ferrara for rehabilitation and then to the Policlinico Umberto I in Rome to be near his wife, also hospitalized. He suffered a second stroke and fell into an irreversible coma.

Fellini died in Rome on 31 October 1993 at the age of 73 after a heart attack he suffered a few weeks earlier, a day after his 50th wedding anniversary. The memorial service, in Studio 5 at Cinecittà, was attended by an estimated 70,000 people. At Giulietta Masina's request, trumpeter Mauro Maur played Nino Rota's "Improvviso dell'Angelo" during the ceremony.

Five months later, on 23 March 1994, Masina died of lung cancer. Fellini, Masina and their son, Pierfederico, are buried in a bronze sepulchre sculpted by Arnaldo Pomodoro. Designed as a ship's prow, the tomb is at the main entrance to the Cemetery of Rimini. The Federico Fellini Airport in Rimini is named in his honour.

Fellini was raised in a Roman Catholic family and considered himself a Catholic, but avoided formal activity in the Catholic Church. Fellini's films include Catholic themes; some celebrate Catholic teachings, while others criticize or ridicule church dogma.

While Fellini was for the most part indifferent to politics, he had a general dislike of authoritarian institutions, and is interpreted by Bondanella as believing in "the dignity and even the nobility of the individual human being". In a 1966 interview, he said, "I make it a point to see if certain ideologies or political attitudes threaten the private freedom of the individual. But for the rest, I am not prepared nor do I plan to become interested in politics."

Despite various famous Italian actors favouring the Communists, Fellini was not left-wing. It is rumored that he supported Christian Democracy (DC). Bondanella writes that DC "was far too aligned with an extremely conservative and even reactionary pre-Vatican II church to suit Fellini's tastes", but Fellini opposed the '68 Movement and befriended Giulio Andreotti.

Apart from satirizing Silvio Berlusconi and mainstream television in "Ginger and Fred", Fellini rarely expressed political views in public and never directed an overtly political film. He directed two electoral television spots during the 1990s: one for DC and another for the Italian Republican Party (PRI). His slogan "Non si interrompe un'emozione" ("Don't interrupt an emotion") was directed against the excessive use of TV advertisements. The Democratic Party of the Left also used the slogan in the referendums of 1995.

Personal and highly idiosyncratic visions of society, Fellini's films are a unique combination of memory, dreams, fantasy and desire. The adjectives "Fellinian" and "Felliniesque" are "synonymous with any kind of extravagant, fanciful, even baroque image in the cinema and in art in general". "La Dolce Vita" contributed the term "paparazzi" to the English language, derived from Paparazzo, the photographer friend of journalist Marcello Rubini (Marcello Mastroianni).

Contemporary filmmakers such as Tim Burton, Terry Gilliam, Emir Kusturica, and David Lynch have cited Fellini's influence on their work.

Polish director Wojciech Has, whose two best-received films, "The Saragossa Manuscript" (1965) and "The Hour-Glass Sanatorium" (1973), are examples of modernist fantasies, has been compared to Fellini for the sheer "luxuriance of his images".

"I Vitelloni" inspired European directors Juan Antonio Bardem, Marco Ferreri, and Lina Wertmüller and influenced Martin Scorsese's "Mean Streets" (1973), George Lucas's "American Graffiti" (1974), Joel Schumacher's "St. Elmo's Fire" (1985), and Barry Levinson's "Diner" (1987), among many others. When the American magazine "Cinema" asked Stanley Kubrick in 1963 to name his ten favorite films, he ranked "I Vitelloni" number one.

"Nights of Cabiria" was adapted as the Broadway musical "Sweet Charity" and the movie "Sweet Charity" (1969) by Bob Fosse starring Shirley MacLaine. "City of Women" was adapted for the Berlin stage by Frank Castorf in 1992.

"8½" inspired, among others, "Mickey One" (Arthur Penn, 1965), "Alex in Wonderland" (Paul Mazursky, 1970), "Beware of a Holy Whore" (Rainer Werner Fassbinder, 1971), "Day for Night" (François Truffaut, 1973), "All That Jazz" (Bob Fosse, 1979), "Stardust Memories" (Woody Allen, 1980), "Sogni d'oro" (Nanni Moretti, 1981), "Parad Planet" (Vadim Abdrashitov, 1984), "La Pelicula del rey" (Carlos Sorin, 1986), "Living in Oblivion" (Tom DiCillo, 1995), "8½ Women" (Peter Greenaway, 1999), "Falling Down" (Joel Schumacher, 1993), and the Broadway musical "Nine" (Maury Yeston and Arthur Kopit, 1982). "Yo-Yo Boing!" (1998), a Spanish novel by Puerto Rican writer Giannina Braschi, features a dream sequence with Fellini inspired by "8½".

Fellini's work is referenced on the albums "Fellini Days" (2001) by Fish, "Another Side of Bob Dylan" (1964) by "Bob Dylan" with "Motorpsycho Nitemare", "Funplex" (2008) by the B-52's with the song "Juliet of the Spirits", and in the opening traffic jam of the music video "Everybody Hurts" by R.E.M. American singer Lana Del Rey has cited Fellini as an influence. It influenced the American TV shows "Northern Exposure" and "Third Rock from the Sun". Wes Anderson's short film "Castello Cavalcanti" (2013) is in many places a direct homage to Fellini.

Various film-related material and personal papers of Fellini are in the Wesleyan University Cinema Archives, to which scholars and media experts have full access. In October 2009, the Jeu de Paume in Paris opened an exhibit devoted to Fellini that included ephemera, television interviews, behind-the-scenes photographs, "Book of Dreams" (based on 30 years of the director's illustrated dreams and notes), along with excerpts from "La dolce vita" and "8½".

In 2014, the Blue Devils Drum and Bugle Corps of Concord, California, performed "Felliniesque", a show themed around Fellini's work, with which they won a record 16th Drum Corps International World Class championship with a record score of 99.650. That same year, the weekly entertainment-trade magazine "Variety" announced that French director Sylvain Chomet was moving forward with "The Thousand Miles", a project based on various Fellini works, including his unpublished drawings and writings.











</doc>
<doc id="11787" url="https://en.wikipedia.org/wiki?curid=11787" title="Fleetwood Mac">
Fleetwood Mac

Fleetwood Mac are a British-American rock band, formed in London in 1967. They have sold more than 120 million records worldwide, making them one of the world's best-selling bands. In 1998, select members of Fleetwood Mac were inducted into the Rock and Roll Hall of Fame and received the Brit Award for Outstanding Contribution to Music.

Fleetwood Mac was founded by guitarist Peter Green, drummer Mick Fleetwood and guitarist Jeremy Spencer. Bassist John McVie completed the lineup for their self-titled debut album. Danny Kirwan joined as a third guitarist in 1968. Keyboardist Christine Perfect, who contributed as a session musician from the second album, married McVie and joined in 1970. At this time it was primarily a British blues band, scoring a UK number one with "Albatross", and also had other hits such as the singles "Oh Well" and "Man of the World". All three guitarists left in succession during the early 1970s, to be replaced by guitarists Bob Welch and Bob Weston and vocalist Dave Walker. By 1974, all three had either departed or been dismissed, leaving the band without a male lead vocalist or guitarist.

In late 1974, while Fleetwood was scouting studios in Los Angeles, he was introduced to folk-rock duo Lindsey Buckingham and Stevie Nicks. Fleetwood Mac soon asked Buckingham to be their new lead guitarist, and Buckingham agreed on condition that Nicks would also join the band. The addition of Buckingham and Nicks gave the band a more pop rock sound, and their 1975 self-titled album, "Fleetwood Mac", reached No. 1 in the United States. "Rumours" (1977), Fleetwood Mac's second album after the arrival of Buckingham and Nicks, produced four U.S. Top 10 singles and remained at number one on the American albums chart for 31 weeks. It also reached the top spot in various countries around the world and won a Grammy Award for Album of the Year in 1978. "Rumours" has sold over 40 million copies worldwide, making it the eighth-highest-selling album in history. The band went through personal turmoil while recording the album, as both the romantic partnerships in the band (one being John and Christine McVie, and the other being Buckingham and Nicks) separated while continuing to make music together.

The band's personnel remained stable through three more studio albums, but by the late 1980s began to disintegrate. After Buckingham and Nicks each left the band, they were replaced by a number of other guitarists and vocalists. A 1993 one-off performance for the first inauguration of Bill Clinton featured the lineup of Fleetwood, John McVie, Christine McVie, Nicks, and Buckingham back together for the first time in six years. A full reunion occurred four years later, and the group released their fourth U.S. No. 1 album, "The Dance" (1997), a live compilation of their work. Christine McVie left the band in 1998, but continued to work with the band in a session capacity. Meanwhile, the group remained together as a four-piece, releasing their most recent studio album, "Say You Will", in 2003. Christine McVie rejoined the band full-time in 2014. In 2018, Buckingham was fired from the band and was replaced by Mike Campbell, formerly of Tom Petty and the Heartbreakers, and Neil Finn of Split Enz and Crowded House.

Fleetwood Mac were formed in July 1967 in London, England, when Peter Green left the British blues band John Mayall & the Bluesbreakers. Green had previously replaced guitarist Eric Clapton in the Bluesbreakers and had received critical acclaim for his work on their album "A Hard Road". Green had been in two bands with Mick Fleetwood, Peter B's Looners and the subsequent Shotgun Express (which featured a young Rod Stewart as vocalist), and suggested Fleetwood as a replacement for drummer Aynsley Dunbar when Dunbar left the Bluesbreakers to join the new Jeff Beck/Rod Stewart band. John Mayall agreed and Fleetwood joined the Bluesbreakers.

The Bluesbreakers then consisted of Green, Fleetwood, John McVie and Mayall. Mayall gave Green free recording time as a gift, in which Fleetwood, McVie and Green recorded five songs. The fifth song was an instrumental that Green named after the rhythm section, "Fleetwood Mac" ("Mac" being short for McVie).

Soon after this, Green suggested to Fleetwood that they form a new band. The pair wanted McVie on bass guitar and named the band 'Fleetwood Mac' to entice him, but McVie opted to keep his steady income with Mayall rather than take a risk with a new band. In the meantime Peter Green and Mick Fleetwood had teamed up with slide guitarist Jeremy Spencer and bassist Bob Brunning. Brunning was in the band on the understanding that he would leave if McVie agreed to join. The Green, Fleetwood, Spencer, Brunning version of the band made its debut on 13 August 1967 at the Windsor Jazz and Blues Festival as 'Peter Green's Fleetwood Mac, also featuring Jeremy Spencer'. Brunning played only a few gigs with Fleetwood Mac. Within weeks of this show, John McVie agreed to join the band as permanent bassist.

Fleetwood Mac's self-titled debut album was a no-frills blues album and was released by the Blue Horizon label in February 1968. There were no other players on the album (except on the song "Long Grey Mare", which was recorded with Brunning on bass). The album was successful in the UK and reached no. 4, although it did not have any singles on it. The band soon released two singles: Green's "Black Magic Woman" (later a big hit for Santana) and "Need Your Love So Bad".

The band's second studio album, "Mr. Wonderful", was released in August 1968. Like their first album, it was all blues. The album was recorded live in the studio with miked amplifiers and a PA system, rather than being plugged into the board. They also added horns and featured a friend of the band on keyboards, Christine Perfect of Chicken Shack.

Shortly after the release of their second album, Fleetwood Mac added 18-year-old guitarist Danny Kirwan to their line-up. He was recruited from the South London blues trio Boilerhouse, which consisted of Kirwan on guitar, Trevor Stevens on bass and Dave Terrey on drums. Green and Fleetwood had watched Boilerhouse rehearse in a basement boiler-room, and Green had been so impressed that he invited the band to play support slots for Fleetwood Mac. Green wanted Boilerhouse to become a professional band but Stevens and Terrey were not prepared to turn professional, so Green tried to find another rhythm section for Kirwan by placing an ad in Melody Maker. There were over 300 applicants, but when Green and Fleetwood ran auditions at the Nag's Head in Battersea (home of the Mike Vernon Blue Horizon Club) the hard-to-please Green could not find anyone good enough. Fleetwood invited Kirwan to join Fleetwood Mac as a third guitarist.

Green had been frustrated that Jeremy Spencer did not contribute to his songs. Kirwan, a talented self-taught guitarist, had a signature vibrato and a unique style that added a new dimension to the band's sound. In November 1968, with Kirwan in the band, they released their first number one single in Europe, "Albatross", on which Kirwan duetted with Green. Green said later that the success of 'Albatross' was thanks to Kirwan. "If it wasn't for Danny, I would never had had a number one hit record." Around this time they released the compilation album "English Rose", which contained half of "Mr Wonderful" plus new songs from Kirwan. Their second compilation album,"The Pious Bird of Good Omen", contained a collection of singles, B-sides and a selection of work the band had done with Eddie Boyd.

On tour in the US in January 1969, the band recorded an album at the soon-to-close Chess Records Studio with some of the blues legends of Chicago, including Willie Dixon, Buddy Guy and Otis Spann. These were Fleetwood Mac's last all-blues recordings. Along with the change of style the band was also going through label changes. Up until that point they had been on the Blue Horizon label, but with Kirwan in the band the musical possibilities had become too diverse for a blues-only label. The band signed with Immediate Records and released the single "Man of the World", which became another British and European hit. For the B-side Spencer fronted Fleetwood Mac as "Earl Vince and the Valiants" and recorded "Somebody's Gonna Get Their Head Kicked In Tonite", typifying the more raucous rock 'n' roll side of the band. Immediate Records was in bad shape, however, and the band shopped around for a new deal. The Beatles wanted the band on Apple Records (Mick Fleetwood and George Harrison were brothers-in-law), but the band's manager Clifford Davis decided to go with Warner Bros. Records (through Reprise Records, a Frank Sinatra-founded label), the label they have stayed with ever since.

Under the wing of Reprise, Fleetwood Mac released their third studio album, "Then Play On", in September 1969. Although the initial pressing of the American release of this album was the same as the British version, it was altered to contain the song "Oh Well", which featured consistently in live performances from the time of its release through 1997 and again starting in 2009. "Then Play On", the band's first rock album, featured only the songs of Kirwan and Green. Jeremy Spencer, meanwhile, had recorded a solo album of 1950s-style rock and roll songs, backed by the rest of the band except Green.

By 1970 Peter Green, the frontman of the band, had developed a dependency on LSD. During the band's European tour, Green experienced a bad acid trip at a hippie commune in Munich. Clifford Davis, the band's manager, singled out this incident as the crucial point in Green's mental decline. He said: "The truth about Peter Green and how he ended up how he did is very simple. We were touring Europe in late 1969. When we were in Germany, Peter told me he had been invited to a party. I knew there were going to be a lot of drugs around and I suggested that he didn't go. But he went anyway and I understand from him that he took what turned out to be very bad, impure LSD. He was never the same again." German author and filmmaker Rainer Langhans stated in his autobiography that he and Uschi Obermaier met Green in Munich and invited him to their Highfisch-Kommune, where the drinks were spiked with acid. Langhans and Obermaier were planning to organise an open-air "Bavarian Woodstock", for which they wanted Jimi Hendrix and The Rolling Stones to be the main acts, and they hoped Green would help them to get in contact with The Rolling Stones.

Green's last hit with Fleetwood Mac was "The Green Manalishi (With the Two-Prong Crown)". The track was recorded at Warner-Reprise's studios in Hollywood on the band's third US tour in April 1970, a few weeks before Green left the band. A live performance was recorded at the Boston Tea Party in February 1970, and the song was later recorded by Judas Priest. "Green Manalishi" was released as Green's mental stability deteriorated. He wanted the band to give all their money to charity, but the other members of the band disagreed. 

In April, Green announced his decision to quit the band after the completion of their European tour. His last show with Fleetwood Mac was on 20 May 1970. During that show the band went past their allotted time and the power was shut off, although Mick Fleetwood kept drumming. Some of the Boston Tea Party recordings (5/6/7 February 1970) were eventually released in the 1980s as the "Live in Boston" album. A more complete remastered 3-volume compilation was released by Snapper Music in the late 1990s.

Kirwan and Spencer were left with the task of replacing Green in their live shows and on their recordings. In September 1970 Fleetwood Mac released their fourth studio album, "Kiln House." Kirwan's songs on the album moved the band in the direction of rock, while Spencer's contributions focused on re-creating the country-tinged "Sun Sound" of the late 1950s. Christine Perfect, who had retired from the music business after one unsuccessful solo album, contributed (uncredited) to "Kiln House", singing backup vocals and playing keyboards. She also drew the album cover. After "Kiln House", Fleetwood Mac were progressing and developing a new sound, and she was invited to join the band to help fill out the rhythm section. They released a single, Danny Kirwan's "Dragonfly" b/w "The Purple Dancer" in the UK and certain European countries, but despite good notices in the press it was not a success. The B-side has been reissued only once, on a Reprise German and Dutch-only "Best of" album.
Christine Perfect, who by this point had married bassist John McVie, made her first appearance with the band as Christine McVie at Bristol University, England, in May 1969, just as she was leaving Chicken Shack. She had had success with the Etta James classic "I'd Rather Go Blind" and was twice voted female artist of the year in England. Christine McVie played her first gig as an official member of Fleetwood Mac on 1 August 1970 in New Orleans, Louisiana. CBS Records, which now owned Blue Horizon (except in the US and Canada), released the band's fifth compilation album, "The Original Fleetwood Mac", containing previously unreleased material. The album was relatively successful, and the band continued to gain popularity.

While on tour in February 1971, Jeremy Spencer said he was going out to "get a magazine" but never returned. After several days of frantic searching the band discovered that Spencer had joined a religious group, the Children of God. The band were liable for the remaining shows on the tour and asked Peter Green to step in as a replacement. Green brought along his friend Nigel Watson, who played the congas. (Twenty-five years later Green and Watson collaborated again to form the Peter Green Splinter Group.) Green was only back with Fleetwood Mac temporarily and the band began a search for a new guitarist. Green insisted on playing only new material and none he had written. He and Watson played only the last week of shows. The San Bernardino show on 20 February was taped.

In the summer of 1971 the band held auditions for a replacement guitarist at their large country home, "Benifold", which they had jointly bought with their manager Davis for £23,000 () prior to the "Kiln House" tour. A friend of the band, Judy Wong, recommended her high school friend Bob Welch, who was living in Paris, France, at the time. The band held a few meetings with Welch and decided to hire him, without actually playing with him, after they heard a tape of his songs.

In September 1971 the band released their fifth studio album, "Future Games". As a result of Welch's arrival and Spencer's departure, the album was different from anything they had done previously. While it became the band's first studio album to miss the charts in the UK, it helped to expand the band's appeal in the United States. In Europe CBS released Fleetwood Mac's first Greatest Hits album, which mostly consisted of songs by Peter Green, with one song by Spencer and one by Kirwan.

In 1972, six months after the release of "Future Games", the band released their sixth studio album, "Bare Trees". Mostly composed by Kirwan, "Bare Trees" featured the Welch-penned single "Sentimental Lady", which would be a much bigger hit for Welch five years later when he re-recorded it for his solo album "French Kiss", backed by Mick Fleetwood and Christine McVie. "Bare Trees" also featured "Spare Me a Little of Your Love", a bright Christine McVie song that became a staple of the band's live act throughout the early to mid-1970s.

While the band was doing well in the studio, their tours started to be problematic. By 1972 Danny Kirwan had developed an alcohol dependency and was becoming alienated from Welch and the McVies. When Kirwan smashed his Gibson Les Paul Custom guitar before a concert on a US tour in August 1972, refused to go on stage and criticised the band afterwards, Fleetwood fired him. Fleetwood said later that the pressure had become too much for Kirwan, and he had suffered a breakdown.

In the three albums they released in this period they constantly changed line-ups. In September 1972 the band added guitarist Bob Weston and vocalist Dave Walker, formerly of Savoy Brown and Idle Race. Bob Weston was well known as a slide guitarist and had known the band from his touring period with Long John Baldry. Fleetwood Mac also hired Savoy Brown's road manager, John Courage. Fleetwood, The McVies, Welch, Weston and Walker recorded the band's seventh studio album, "Penguin", which was released in January 1973. After the tour the band fired Walker because they felt his vocal style and attitude did not fit well with the rest of the band.

The remaining five members carried on and recorded the band's eighth studio album, "Mystery to Me", six months later. This album contained Welch's song "Hypnotized", which received a great amount of airplay on the radio and became one of the band's most successful songs to date in the US. The band was proud of the new album and anticipated that it would be a smash hit. While it did eventually go Gold, personal problems within the band emerged. The McVies' marriage was under a lot of stress, which was aggravated by their constant working with each other and by John McVie's considerable alcohol abuse. Subsequent lack of touring meant that the album was unable to chart as high as the previous one.

During the 1973 US tour to promote "Mystery to Me", Weston had an affair with Fleetwood's wife Jenny Boyd Fleetwood, sister of Pattie Boyd Harrison. Fleetwood was emotionally devastated by this and could not continue with the tour. Courage fired Weston and two weeks in, with another twenty-six concerts scheduled, the tour was cancelled. The last date played was Lincoln, Nebraska, on 20 October 1973. In a late-night meeting after that show, the band told their sound engineer that the tour was over and Fleetwood Mac was splitting up.

In late 1973, after the collapse of the US tour, the band's manager, Clifford Davis, was left with major touring commitments and no band. He faced a possible multi-million dollar lawsuit and professional and financial ruin if he could not fulfil the contracted dates. In desperation, he claimed that he owned the name Fleetwood Mac and recruited members of the band Legs, which had recently issued one single under Davis's management, to tour the US as a replacement Fleetwood Mac in early 1974. This band - who former guitarist Dave Walker said were "very good" - consisted of Elmer Gantry (vocals, guitar), Kirby Gregory (guitar), Paul Martinez (bass), Dave Wilkinson (keyboards) and Australian drummer Craig Collinge (formerly of the Librettos, Procession and Third World War). 

The members of this group were told that Mick Fleetwood would join them after the tour had started, to validate the use of the name, and claimed that Fleetwood had been involved in planning it. Davis and others stated that Fleetwood had committed himself to the project and had given instructions to hire musicians and rehearse the band. Davis said Collinge had been hired only as a temporary stand-in drummer for rehearsals and the first two gigs, and that Fleetwood had agreed to appear on the rest of the tour after he had sorted out personal matters, but then had backed out after the tour started.

The tour began in January 1974 in Pittsburgh, and the first concert "went down a storm". More successful gigs followed, but then word got around that this was not the real Fleetwood Mac and audiences became hostile. The band was turned away from several gigs, and the next half-dozen were pulled by promoters. The band struggled on and played more dates in the face of increasing hostility and heckling from audiences, and anger from promoters. More dates were pulled, the keyboard player quit, and after a concert in Edmonton where bottles were thrown at the stage, the tour collapsed. The new band dissolved and the remainder of the tour, nearly three months of dates, was cancelled. 

The lawsuit that followed regarding who owned the rights to the name 'Fleetwood Mac' put the original Fleetwood Mac on hiatus for almost a year. Although the band was named after Mick Fleetwood and John McVie, they had apparently signed contracts in which they had forfeited the rights to the name. Their record company, Warner Brothers, when appealed to, said they didn't know who owned it. The dispute was eventually settled amicably out of court, four years later, in what was described as "a reasonable settlement not unfair to either party."

Nobody from the alternative lineup was ever made a part of the real Fleetwood Mac, although some of them later played in Danny Kirwan's studio band. Gantry and Gregory went on to become members of Stretch, whose 1975 UK hit single "Why Did You Do It" was written about the touring debacle. Gantry later collaborated with the Alan Parsons Project. Martinez went on to play with the Deep Purple offshoot Paice Ashton Lord, as well as Robert Plant's backing band.

While the other band had been on tour, Welch stayed in Los Angeles and connected with entertainment attorneys. He realised that the original Fleetwood Mac was being neglected by Warner Bros and that they would need to change their base of operation from England to America, to which the rest of the band agreed. Rock promoter Bill Graham wrote a letter to Warner Bros to convince them that the real Fleetwood Mac was, in fact, Fleetwood, Welch, and the McVies. This did not end the legal battle but the band was able to record as Fleetwood Mac again. Instead of hiring another manager, Fleetwood Mac, having re-formed, decided to manage themselves.

In September 1974, Fleetwood Mac signed a new recording contract with Warner Bros, but remained on the Reprise label. The band released their ninth studio album, "Heroes Are Hard to Find," in September 1974 and, for the first time in its history, the band had only one guitarist. While on tour they added a second keyboardist, Doug Graves, who had been an engineer on "Heroes Are Hard to Find". In late 1974 Graves was preparing to become a permanent member of the band by the end of their US tour. He said:

However, Graves did not ultimately join full-time. In 1980, Christine McVie explained the decision:

Robert ("Bobby") Hunt, who had been in the band Head West with Bob Welch back in 1970, replaced Graves. Neither musician proved to be a long-term addition to the line-up. Welch left soon after the tour ended (on 5 December 1974 at Cal State University), having grown tired of touring and legal struggles. Nevertheless, the tour had enabled the "Heroes" album to reach a higher position on the American charts than any of the band's previous records.

After Welch announced that he was leaving the band, Fleetwood began searching for a replacement. While Fleetwood was checking out Sound City Studios in Los Angeles, the house engineer, Keith Olsen, played him a track he had recorded in the studio, "Frozen Love", from the album "Buckingham Nicks" (1973). Fleetwood liked it and was introduced to the guitarist from the band, Lindsey Buckingham, who was at Sound City that day recording demos. Fleetwood asked him to join Fleetwood Mac and Buckingham agreed, on the condition that his music partner and girlfriend, Stevie Nicks, be included. Buckingham and Nicks joined the band on New Year's Eve 1974, within four weeks of the previous incarnation splitting.

In 1975, the new line-up released another self-titled album, their tenth studio album. The album was a breakthrough for the band and became a huge hit, reaching No.1 in the US and selling over 7 million copies. Among the hit singles from this album were Christine McVie's "Over My Head" and "Say You Love Me" and Stevie Nicks's "Rhiannon", as well as the much-played album track "Landslide", a live rendition of which became a hit twenty years later on "The Dance" album.
In 1976, the band was suffering from severe stress. With success came the end of John and Christine McVie's marriage, as well as Buckingham and Nicks's long-term romantic relationship. Fleetwood, meanwhile, was in the midst of divorce proceedings from his wife, Jenny. The pressure on Fleetwood Mac to release a successful follow-up album, combined with their new-found wealth, led to creative and personal tensions which were allegedly fuelled by high consumption of drugs and alcohol.

The band's eleventh studio album, "Rumours" (the band's first release on the main Warner label after Reprise was retired and all of its acts were reassigned to the parent label), was released in the spring of 1977. In this album, the band members laid bare the emotional turmoil they were experiencing at the time. "Rumours" was critically acclaimed and won the Grammy Award for Album of the Year in 1977. The album generated multiple Top Ten singles, including Buckingham's "Go Your Own Way", Nicks's US No. 1 "Dreams" and Christine McVie's "Don't Stop" and "You Make Loving Fun". Buckingham's "Second Hand News", Nicks's "Gold Dust Woman" and "The Chain" (the only song written by all five band members) also received significant radio airplay. By 2003 "Rumours" had sold over 19 million copies in the US alone (certified as a diamond album by the RIAA) and a total of 40 million copies worldwide, bringing it to eighth on the list of best-selling albums. Fleetwood Mac supported the album with a lucrative tour.

On 10 October 1979, Fleetwood Mac were honoured with a star on the Hollywood Walk of Fame for their contributions to the music industry at 6608 Hollywood Boulevard.

Buckingham convinced Fleetwood to let his work on their next album be more experimental, and to be allowed to work on tracks at home before bringing them to the rest of the band in the studio. The result of this, the band's twelfth studio album "Tusk", was a 20-track double album released in 1979. It produced three hit singles: Lindsey Buckingham's "Tusk" (US No. 8), which featured the USC Trojan Marching Band, Christine McVie's "Think About Me" (US No. 20), and Stevie Nicks's 6 minute opus "Sara" (US No. 7). "Sara" was cut to 4 minutes for both the hit single and the first CD-release of the album, but the unedited version has since been restored on the 1988 greatest hits compilation, the 2004 reissue of "Tusk" and Fleetwood Mac's 2002 release of "The Very Best of Fleetwood Mac". Original guitarist Peter Green also took part in the sessions of "Tusk" although his playing, on the Christine McVie track "Brown Eyes", is not credited on the album. In an interview in 2019 Fleetwood described "Tusk" as his "personal favourite" and said, “Kudos to Lindsey ... for us not doing a replica of "Rumours"."

"Tusk" sold four million copies worldwide. Fleetwood blamed the album's relative lack of commercial success on the RKO radio chain having played the album in its entirety prior to release, thereby allowing mass home taping.

The band embarked on an 11-month tour to support and promote "Tusk". They travelled across the world, including the US, Australia, New Zealand, Japan, France, Belgium, Germany, the Netherlands, and the United Kingdom. In Germany, they shared the bill with reggae superstar Bob Marley. On this world tour, the band recorded music for their first live album, which was released at the end of 1980.

The band's thirteenth studio album, "Mirage", was released in 1982. Following 1981 solo albums by Nicks ("Bella Donna"), Fleetwood ("The Visitor"), and Buckingham ("Law and Order"), there was a return to a more conventional approach. Buckingham had been chided by critics, fellow band members and music business managers for the lesser commercial success of "Tusk". Recorded at Château d'Hérouville in France and produced by Richard Dashut, "Mirage" was an attempt to recapture the huge success of "Rumours". Its hits included Christine McVie's "Hold Me" and "Love in Store" (co-written by Robbie Patton and Jim Recor, respectively), Stevie Nicks's "Gypsy", and Lindsey Buckingham's "Oh Diane", which made the Top 10 in the UK. A minor hit was also scored by Buckingham's "Eyes Of The World" and "Can't Go Back".

In contrast to the Tusk Tour the band embarked on only a short tour of 18 American cities, the Los Angeles show being recorded and released on video. They also headlined the first US Festival, on 5 September 1982, for which the band was paid $500,000 ($ today). "Mirage" was certified double platinum in the US.

Following "Mirage" the band went on hiatus, which allowed members to pursue solo careers. Stevie Nicks released two more solo albums (1983's "The Wild Heart" and 1985's "Rock a Little"). Lindsey Buckingham issued "Go Insane" in 1984, the same year that Christine McVie made an eponymous album (yielding the Top 10 hit "Got a Hold on Me" and the Top 40 hit "Love Will Show Us How"). All three met with success, Nicks being the most popular. During this period Mick Fleetwood had filed for bankruptcy, Nicks was admitted to the Betty Ford Clinic for addiction problems and John McVie had suffered an addiction-related seizure, all of which were attributed to the lifestyle of excess afforded to them by their worldwide success. It was rumoured that Fleetwood Mac had disbanded, but Buckingham commented that he was unhappy to allow "Mirage" to remain as the band's last effort.

The "Rumours" line-up of Fleetwood Mac recorded one more album, their fourteenth studio album, "Tango in the Night", in 1987. As with various other Fleetwood Mac albums, the material started off as a Buckingham solo album before becoming a group project. The album went on to become their best-selling release since "Rumours", especially in the UK where it hit No. 1 three times in the following year. The album sold three million copies in the US and contained four hits: Christine McVie's "Little Lies" and "Everywhere" ('Little Lies' being co-written with McVie's new husband Eddy Quintela), Sandy Stewart and Stevie Nicks's "Seven Wonders", and Lindsey Buckingham's "Big Love". "Family Man" (Buckingham and Richard Dashut), and "Isn't It Midnight" (Christine McVie), were also released as singles, with less success.

With a ten-week tour scheduled, Buckingham held back at the last minute, saying he felt his creativity was being stifled. A group meeting at Christine McVie's house on 7 August 1987 resulted in turmoil. Tensions were coming to a head. Mick Fleetwood said in his autobiography that there was a physical altercation between Buckingham and Nicks. Buckingham left the band the following day. After Buckingham's departure Fleetwood Mac added two new guitarists to the band, Billy Burnette and Rick Vito, again without auditions.

Burnette was the son of Dorsey Burnette and nephew of Johnny Burnette, both of The Rock and Roll Trio. He had already worked with Mick Fleetwood in Zoo, with Christine McVie as part of her solo band, had done some session work with Stevie Nicks, and backed Lindsey Buckingham on "Saturday Night Live". Fleetwood and Christine McVie had played on his "Try Me" album in 1985. Vito, a Peter Green admirer, had played with many artists from Bonnie Raitt to John Mayall, and worked with John McVie on two Mayall albums.

The 1987–88 "Shake the Cage" tour was the first outing for this line-up. It was successful enough to warrant the release of a concert video, entitled "Tango in the Night", which was filmed at San Francisco's Cow Palace arena in December 1987.

Capitalising on the success of "Tango in the Night", the band released a "Greatest Hits" album in 1988. It featured singles from the 1975–1988 era and included two new compositions, "No Questions Asked" written by Nicks and "As Long as You Follow", written by McVie and Quintela. 'As Long as You Follow' was released as a single in 1988 but only made No. 43 in the US and No.66 in the UK, although it reached No.1 on the US Adult Contemporary charts. The "Greatest Hits" album, which peaked at No. 3 in the UK and No. 14 in the US (though it has since sold over 8 million copies there) was dedicated by the band to Buckingham, with whom they were now reconciled.

In 1990, Fleetwood Mac released their fifteenth studio album, "Behind the Mask". With this album the band veered away from the stylised sound that Buckingham had evolved during his tenure in the band (which was also evident in his solo work) and developed a more adult contemporary style with producer Greg Ladanyi. The album yielded only one Top 40 hit, McVie's "Save Me". "Behind the Mask" only achieved Gold album status in the US, peaking at No. 18 on the "Billboard" album chart, though it entered the UK Albums Chart at No. 1. It received mixed reviews and was seen by some music critics as a low point for the band in the absence of Lindsey Buckingham (who had actually made a guest appearance playing on the title track). But "Rolling Stone" magazine said that Vito and Burnette were "the best thing to ever happen to Fleetwood Mac". The subsequent "Behind the Mask" tour saw the band play sold-out shows at London's Wembley Stadium. In the final show in Los Angeles, Buckingham joined the band on stage. The two women of the band, McVie and Nicks, had decided that the tour would be their last (McVie's father had died during the tour), although both stated that they would still record with the band. In 1991, however, Nicks and Rick Vito announced they were leaving Fleetwood Mac altogether.

In 1992, Mick Fleetwood arranged a 4-disc box set, spanning highlights from the band's 25-year history, entitled "25 Years – The Chain" (an edited 2-disc set was also available). A notable inclusion in the box set was "Silver Springs", a Stevie Nicks composition that was recorded during the "Rumours" sessions but was omitted from the album and used as the B-side of "Go Your Own Way". Nicks had requested use of this track for her 1991 best-of compilation "TimeSpace", but Fleetwood had refused as he had planned to include it in this collection as a rarity. The disagreement between Nicks and Fleetwood garnered press coverage and was believed to have been the main reason for Nicks leaving the band in 1991. The box set also included a new Stevie Nicks/Rick Vito composition, "Paper Doll", which was released in the US as a single and produced by Lindsey Buckingham and Richard Dashut. There were also two new Christine McVie compositions, "Heart of Stone" and "Love Shines". "Love Shines" was released as a single in the UK and elsewhere. Lindsey Buckingham also contributed a new song, "Make Me a Mask". Mick Fleetwood also released a deluxe hardcover companion book to coincide with the release of the box set, titled "My 25 Years in Fleetwood Mac". The volume featured notes written by Fleetwood detailing the band's 25-year history and many rare photographs.

The Buckingham/Nicks/McVie/McVie/Fleetwood line-up reunited in 1993 at the request of US President Bill Clinton for his first Inaugural Ball. Clinton had made Fleetwood Mac's "Don't Stop" his campaign theme song. His request for it to be performed at the Inauguration Ball was met with enthusiasm by the band, although this line-up had no intention of reuniting again.

Inspired by the new interest in the band, Mick Fleetwood, John McVie, and Christine McVie recorded another album as Fleetwood Mac, with Billy Burnette taking lead guitar duties. Burnette left in March 1993 to record a country album and pursue an acting career and Bekka Bramlett, who had worked a year earlier with Mick Fleetwood's Zoo, was recruited to take his place. Solo singer-songwriter/guitarist and Traffic member Dave Mason, who had worked with Bekka's parents Delaney & Bonnie twenty-five years earlier, was subsequently added. In March 1994 Billy Burnette, a good friend and co-songwriter with Delaney Bramlett, returned to the band with Fleetwood's blessing.

The band, minus Christine McVie, toured in 1994, opening for Crosby, Stills, & Nash and in 1995 as part of a package with REO Speedwagon and Pat Benatar. This tour saw the band perform classic Fleetwood Mac songs from their 1967–1974 era. In 1995, at a concert in Tokyo, the band was greeted by former member Jeremy Spencer, who performed a few songs with them.

On 10 October 1995, Fleetwood Mac released their sixteenth studio album, "Time", which was not a success. Although it hit the UK Top 60 for one week, the album had zero impact in the US. It failed to graze the "Billboard" Top 200 albums chart, a reversal for a band that had been a mainstay on that chart for most of the previous two decades. Shortly after the album's release, Christine McVie informed the band that the album would be her last. Bramlett and Burnette subsequently formed a country music duo, Bekka & Billy.

Just weeks after disbanding Fleetwood Mac, Mick Fleetwood announced that he was working with Lindsey Buckingham again. John McVie was added to the sessions, and later Christine McVie. Stevie Nicks also enlisted Lindsey Buckingham to produce a song for a soundtrack.

In May 1996 Mick Fleetwood, John McVie, Christine McVie, and Stevie Nicks performed together at a private party in Louisville, Kentucky, prior to the Kentucky Derby, with Steve Winwood filling in for Lindsey Buckingham. A week later the "Twister" film soundtrack was released, which featured the Stevie Nicks-Lindsey Buckingham duet "Twisted", with Mick Fleetwood on drums. This eventually led to a full reunion of the "Rumours" line-up. The band officially reformed in March 1997.

The regrouped Fleetwood Mac performed a live concert on a soundstage at Warner Bros. Burbank, California, on 22 May 1997. The concert was recorded, and from this performance came the 1997 live album "The Dance", which brought Fleetwood Mac back to the top of the US album charts for the first time in 10 years. "The Dance" returned Fleetwood Mac to a superstar status they had not enjoyed since "Tango in the Night". The album was certified 5 million units by the RIAA. An arena tour followed the MTV premiere of "The Dance" and kept the reunited Fleetwood Mac on the road throughout much of 1997, the 20th anniversary of "Rumours". With additional musicians Neale Heywood on guitar, Brett Tuggle on keyboards, Lenny Castro on percussion and Sharon Celani (who had toured with Fleetwood Mac in the late 1980s) and Mindy Stein on backing vocals, this would be the final appearance of the classic line-up including Christine McVie for 16 years. Neale Heywood and Sharon Celani remain touring members to this day.
In 1998 Fleetwood Mac were inducted into the Rock and Roll Hall of Fame. Members inducted included the original band, Mick Fleetwood, John McVie, Peter Green, Jeremy Spencer and Danny Kirwan, and "Rumours"-era members Christine McVie, Stevie Nicks and Lindsey Buckingham. Bob Welch was not included, despite his key role in keeping the band alive during the early 1970s. The "Rumours"-era version of the band performed both at the induction ceremony and at the Grammy Awards program that year. Peter Green attended the induction ceremony but did not perform with his former bandmates, opting instead to perform his composition "Black Magic Woman" with Santana, who were inducted the same night. Neither Jeremy Spencer nor Danny Kirwan attended. Fleetwood Mac also received the "Outstanding Contribution to Music" award at the Brit Awards (British Phonographic Industry Awards) the same year.

In 1998 Christine McVie left the band. Her departure left Buckingham and Nicks to sing all the lead vocals for the band's seventeenth album, "Say You Will", released in 2003, although Christine contributed some backing vocals and keyboards. The album debuted at No.3 on the "Billboard" 200 chart (No. 6 in the UK) and yielded chart hits with "Peacekeeper" and the title track, and a successful world arena tour which lasted through 2004. The tour grossed $27,711,129 and was ranked No. 21 in the top 25 grossing tours of 2004.

Around 2004–05 there were rumours of a reunion of the early line-up of Fleetwood Mac involving Peter Green and Jeremy Spencer. While these two apparently remained unconvinced, in April 2006 bassist John McVie, during a question-and-answer session on the "Penguin" Fleetwood Mac fan website, said of the reunion idea:

In interviews given in November 2006 to support his solo album "Under the Skin", Buckingham stated that plans for the band to reunite once more for a 2008 tour were still on the cards. Recording plans had been put on hold for the foreseeable future. In an interview Stevie Nicks gave to the UK newspaper "The Daily Telegraph" "i" in September 2007, she stated that she was unwilling to carry on with the band unless Christine McVie returned. However, in a more recent interview, Mick Fleetwood said "... be very happy and hopeful that we will be working again. I can tell you everyone's going to be extremely excited about what's happening with Fleetwood Mac."

On 14 March 2008, the Associated Press reported Sheryl Crow as saying that she would be working with Fleetwood Mac in 2009. Crow and Stevie Nicks had collaborated in the past and Crow had stated that Nicks had been a great teacher and inspiration to her. In a subsequent interview, Buckingham said that after discussions between the band and Crow, the potential collaboration with Crow had "lost its momentum". In an interview in June 2008 Nicks said that Crow would not be joining Fleetwood Mac as a replacement for Christine McVie. According to Nicks, "the group will start working on material and recording probably in October, and finish an album." On 7 October 2008 Mick Fleetwood confirmed on the BBC's "The One Show" that the band were working in the studio. He also announced plans for a world tour in 2009.

In late 2008, it was announced that Fleetwood Mac would tour in 2009, beginning in March. As in the 2003–2004 tour, Christine McVie would not be featured in the line-up. The tour was branded as a greatest hits show entitled "Unleashed", although album tracks such as "Storms" and "I Know I'm Not Wrong" were also played.
During their show on 20 June 2009 in New Orleans, Louisiana, Stevie Nicks premiered part of a new song that she had written about Hurricane Katrina. The song was later released as "New Orleans" on Stevie Nicks's 2011 album "In Your Dreams" with Mick Fleetwood on drums. In October 2009 and November the band toured Europe, followed by Australia and New Zealand in December. In October, The Very Best of Fleetwood Mac was re-released in an extended two-disc format (this format having been released in the US in 2002), entering at number six on the UK Albums Chart. On 1 November 2009 a new one-hour documentary, "Fleetwood Mac: Don't Stop", was broadcast in the UK on BBC One, featuring recent interviews with all four current band members. During the documentary Nicks gave a candid summary of the current state of her relationship with Buckingham, saying "Maybe when we're 75 and Fleetwood Mac is a distant memory, we might be friends."

On 6 November 2009, Fleetwood Mac played the last show of the European leg of their "Unleashed" tour at London's Wembley Arena. Christine McVie was present in the audience. Stevie Nicks paid tribute to her from the stage to a standing ovation from the audience, saying that she thought about her former bandmate "every day", and dedicated that night's performance of "Landslide" to her. On 19 December 2009 Fleetwood Mac played the second-to-last show of their "Unleashed" tour to a sell-out crowd in New Zealand, at what was originally intended to be a one-off event at the TSB Bowl of Brooklands in New Plymouth. Tickets, after pre-sales, sold out within twelve minutes of public release. Another date, Sunday 20 December, was added and also sold out. The tour grossed $84,900,000 and was ranked No. 13 in the highest grossing worldwide tours of 2009. On 19 October 2010, Fleetwood Mac played a private show at the Phoenician Hotel in Scottsdale, Arizona for TPG (Texas Pacific Group).

On 3 May 2011, the Fox Network broadcast an episode of "Glee" entitled "Rumours" that featured six songs from the band's 1977 album. The show sparked renewed interest in the band and its commercially most successful album, and "Rumours" re-entered the "Billboard" 200 chart at No. 11 in the same week that Stevie Nicks's new solo album "In Your Dreams" debuted at No. 6. (Nicks was quoted by "Billboard" saying that her new album was "my own little "Rumours".") The two recordings sold about 30,000 and 52,000 units respectively. Music downloads accounted for 91 percent of the "Rumours" sales. The spike in sales for "Rumours" represented an increase of 1,951%. It was the highest chart entry by a previously issued album since "The Rolling Stones"' reissue of "Exile On Main St." re-entered the chart at No. 2 on 5 June 2010. In an interview in July 2012 Nicks confirmed that the band would reunite for a tour in 2013.

Original Fleetwood Mac bassist Bob Brunning died on 18 October 2011 at the age of 68. Former guitarist and singer Bob Weston was found dead on 3 January 2012 at the age of 64. Former singer and guitarist Bob Welch was found dead from a self-inflicted gunshot wound on 7 June 2012 at the age of 66. Don Aaron, a spokesman at the scene, stated, "He died from an apparent self-inflicted gunshot wound to the chest." A suicide note was found. Welch had been struggling with health issues and was dealing with depression. His wife discovered his body.

The band's 2013 tour, which took place in 34 cities, started on 4 April in Columbus, OH. The band performed two new songs ("Sad Angel" and "Without You"), which Buckingham described as some of the most "Fleetwood Mac-ey" sounding songs since "Mirage". 'Without You' was re-recorded from the Buckingham-Nicks era. The band released their first new studio material in ten years, "Extended Play", on 30 April 2013. The EP debuted and peaked at No. 48 in the US and produced one single, "Sad Angel". On 25 and 27 September 2013, the second and third nights of the band's London O2 shows, Christine McVie joined them on stage for "Don't Stop".
On 27 October 2013, the band announced that John McVie had been diagnosed with cancer and cancelled their New Zealand and Australian performances so that he could undergo treatment. They said: "We are sorry not to be able to play these Australian and New Zealand dates. We hope our Australian and New Zealand fans as well as Fleetwood Mac fans everywhere will join us in wishing John and his family all the best." According to "The Guardian" on 22 November 2013, Christine McVie stated that she would like to return to Fleetwood Mac if they wanted her, and also affirmed that John McVie's prognosis was "really good."

On 11 January 2014, Mick Fleetwood announced that Christine McVie would be rejoining Fleetwood Mac. The news was confirmed on 13 January by the band's primary publicist, Liz Rosenberg, who said that an official announcement regarding a new album and tour would be forthcoming. In October 2013 Stevie Nicks appeared in "" with Fleetwood Mac's song "Seven Wonders" playing in the background.
On with the Show, a 33-city North American tour, opened in Minneapolis, Minnesota, on 30 September 2014. A series of May–June 2015 arena dates in the United Kingdom went on sale on 14 November, selling out in minutes. Due to high demand, additional dates were added to the tour, including an Australian leg.

In January 2015, Buckingham suggested that the new album and tour might be Fleetwood Mac's last, and that the band would cease operations in 2015 or soon afterwards. He concluded: "We're going to continue working on the new album and the solo stuff will take a back seat for a year or two. A beautiful way to wrap up this last act." But Mick Fleetwood stated that the new album might take a few years to complete and that they were waiting for contributions from Nicks, who had been ambivalent about committing to a new record.

In August 2016, Fleetwood revealed that while the band had "a huge amount of recorded music", virtually none of it featured Nicks. Buckingham and Christine McVie, however, had contributed multiple songs to the new project. Fleetwood told "Ultimate Classic Rock": "She [McVie] ... wrote up a storm ... She and Lindsey could probably have a mighty strong duet album if they want. In truth, I hope it will come to more than that. There really are dozens of songs. And they’re really good. So we’ll see."

Nicks explained her reluctance to record another album with Fleetwood Mac. "Is it possible that Fleetwood Mac might do another record? I can never tell you yes or no, because I don't know. I honestly don't know... It's like, do you want to take a chance of going in and setting up in a room for like a year [to record an album] and having a bunch of arguing people? And then not wanting to go on tour because you just spent a year arguing?". She also emphasized that people don't buy as many records as they used to.

Buckingham and Christine McVie announced a new album, titled "Lindsey Buckingham/Christine McVie", which featured contributions from Mick Fleetwood and John McVie. "Lindsey Buckingham/Christine McVie" was released on 9 June 2017, preceded by the single "In My World". A 38-date tour was arranged which began on 21 June and concluded 16 November. Fleetwood Mac also planned to embark on another tour in 2018. The band headlined the second night of the Classic West concert (on 16 July 2017 at Dodger Stadium in Los Angeles) and the second night of the Classic East concert (at New York's Citi Field on 30 July 2017).

Fleetwood Mac were announced at the MusiCares Person of the Year in 2018 and reunited to perform several songs at the Grammy-hosted gala honouring them. Artists including Lorde, Harry Styles, Little Big Town and Miley Cyrus also performed.

In April 2018, the song "Dreams" re-entered the Hot Rock Songs chart at No. 16 after a viral meme had featured the song. This chart re-entry came 40 years after the song had topped the Hot 100. The song's streaming totals also translated into 7,000 "equivalent album units", a jump of 12 percent, which helped "Rumours" to go from No. 21 to No. 13 on the Top Rock Albums chart.
That month Buckingham departed from the group a second time, having reportedly been dismissed. The reason was said to have been a disagreement about the nature of the tour, and in particular the question of whether newer or less well-known material would be included, as Buckingham wanted. Mick Fleetwood and the band appeared on "CBS This Morning" on 25 April 2018 and said that Buckingham would not sign off on a tour that the group had been planning for a year and a half and they had reached a "huge impasse" and "hit a brick wall". When asked if Buckingham had been fired, he said, "Well, we don't use that word because I think it's ugly." He also said that "Lindsey has huge amounts of respect and kudos to what he's done within the ranks of Fleetwood Mac and always will." In October 2018, Buckingham filed a lawsuit against Fleetwood Mac for breach of fiduciary duty, breach of oral contract and intentional interference with prospective economic advantage, among other charges.

Former Tom Petty and the Heartbreakers guitarist Mike Campbell and Neil Finn of Crowded House were named to replace Buckingham. On "CBS This Morning", Fleetwood said that Fleetwood Mac had been reborn and that "This is the new lineup of Fleetwood Mac." Aside from touring, the band plans to record new music with Campbell and Finn in the future.
In April 2018 the band announced "An Evening with Fleetwood Mac" tour starting in October 2018. The band launched the tour at the iHeartRadio Music Festival on 21 September 2018 at the T-Mobile Arena in Las Vegas, NV.

Danny Kirwan, guitarist, songwriter and founding member of Fleetwood Mac (1968–1972) died in London, England, on 8 June 2018, aged 68. An obituary in "The New York Times" said he had died in his sleep after contracting pneumonia earlier in the year. The British music magazine "Mojo", in a two-page tribute to Kirwan's life and music, quoted Christine McVie as saying: "Danny Kirwan was "the" white English blues guy. Nobody else could play like him. He was a one-off ... Danny and Peter [Green] gelled so well together. Danny had a very precise, piercing vibrato – a unique sound ... He was a perfectionist; a fantastic musician and a fantastic writer." One of Kirwan's songs, "Tell Me All the Things You Do" from the 1970 album "Kiln House", was included in the set of the 2018–19 ""An Evening with Fleetwood Mac"" tour.



The following is a list of awards and nominations received by Fleetwood Mac:





</doc>
<doc id="11788" url="https://en.wikipedia.org/wiki?curid=11788" title="Frederick I, Margrave of Brandenburg-Ansbach">
Frederick I, Margrave of Brandenburg-Ansbach

Frederick I of Ansbach and Bayreuth (also known as Frederick V; or ; 8 May 1460 – 4 April 1536) was born at Ansbach as the eldest son of Albert III, Margrave of Brandenburg by his second wife Anna, daughter of Frederick II, Elector of Saxony. His elder half-brother was the Elector Johann Cicero of Brandenburg. Friedrich succeeded his father as Margrave of Ansbach in 1486 and his younger brother Siegmund as Margrave of Bayreuth in 1495. 

After depleting the finances of the margraviate with his lavish lifestyle, Frederick I was deposed by his two elder sons, Casimir and George, in 1515. He was then locked up at Plassenburg Castle by his eldest son Casimir in a tower room from which he could not escape for 12 years. Thereupon, his son Casimir took up the rule of the Margraviate of Bayreuth (Kulmbach) and his son George took up the rule of the Margraviate of Ansbach. However, the overthrow of Frederick did outrage his other younger sons and led to far-reaching political countermeasures. When Elector Joachim I of Brandenburg visited Kulmbach during his journey to Augsburg, and wanted to plead for Frederick's release, he was nevertheless denied entry to Plassenburg Castle. The dispute was finally cleared when an agreement was reached in 1522, in which the demands of the younger sons of Frederick were met. 

On 14 February 1479, at Frankfurt (Oder), Frederick I was married to Princess Sophia of Poland (6 April 1464 – 5 October 1512), daughter of King Casimir IV of Poland by his wife Elisabeth of Austria, and sister of King Sigismund I of Poland. They had seventeen children:

 


</doc>
<doc id="11790" url="https://en.wikipedia.org/wiki?curid=11790" title="F-Zero: Maximum Velocity">
F-Zero: Maximum Velocity

F-Zero: Maximum Velocity is a futuristic racing video game developed by NDcube and published by Nintendo for the Game Boy Advance. The game was released in Japan, North America and Europe in 2001. It is the first F-Zero game to be released on a handheld game console.

"Maximum Velocity" takes place twenty-five years after "F-Zero", in yet another F-Zero Grand Prix. The past generations of F-Zero had "piloted their way to fame", so it is the only "F-Zero" game without Captain Falcon, Samurai Goroh, Pico, or Dr. Stewart. Players control fast hovering crafts and use their speed-boosting abilities to navigate through the courses as quickly as possible.

Every race consists of five laps around a race track. A player will lose the race if his or her machine explodes due to either taking too much damage or landing outside of the track, gets ejected from the race due to falling to 20th place or due to completing a lap with a rank outside of the rank limit of that lap, or he or she decides to give up. In the single player Grand Prix mode, all of these conditions requires the player to use an extra machine if and only if he or she has one or more spare machines to try again.

For each lap completed the player is rewarded with a speed boost, to be used once any time, one of the "SSS" marks will be shaded green to indicate that it can be used. A boost will dramatically increase a player's speed, but will decrease their ability to turn. A boost used before a jump will make the player jump farther, which could allow the player to use a shortcut with the right vehicle. Boost time and speed varies according to the machine, and is usually tuned for proper balance. For example, one machine boasts a boost time of twelve seconds, yet has the slowest boost speed of the entire game. Players can also take advantage of the varying deceleration of each vehicle. Some vehicles, such as the Jet Vermilion, take longer than others to decelerate from top boost speed to normal speed, once the boost has been used up. Players can also take advantage of this effect on boost pads.

The Grand Prix is the main single player component of "Maximum Velocity". It consists of four series named after chess pieces: "Pawn", "Knight", "Bishop" and "Queen". The latter of these can be unlocked by winning the others on "Expert" mode. They have five races in four difficulty settings, "Master" mode is unlocked by winning expert mode in each series, the player unlocks a new machine after completing it. The player needs to be in the top three at the end of the last lap in order to continue to the next race. If the player is unable to continue, the player will lose a machine and can try the race again. If the player runs out of machines, then the game ends, and the player has to start the series from the beginning.

Championship is another single player component. It is basically the same as a "Time Attack" mode, except the player can only race on one, special course: the Synobazz Championship Circuit. This special course is not selectable in any other modes.

"Maximum Velocity" can be played in two multiplayer modes using the Game Boy Advance link cable, with one cartridge, or one cartridge per player. Two to four Players can play in both modes.

In single cart, only one player needs to have a cartridge. The other players will boot off the link cable network from the player with the cart using the GBA's netboot capability. All players drive a generic craft, and the game can only be played on one level, Silence. Silence, along with Fire Field, are the only areas to return from previous games. Aptly, Silence in "Maximum Velocity" has no background music, unlike in most other F-Zero games.

In multi cart, each player needs to have a cartridge to play. This has many advantages over single cart: All players can use any machine in this game that has been unlocked by another player. Players can select any course in this game. After race is finished, all of the player's ranking data are mixed and shared ("Mixed ranking" stored in each cart).

"F-Zero: Maximum Velocity" is one of the first titles to have been developed by NDcube. Like the original "F-Zero" for SNES, "Maximum Velocity" implements a pseudo-3D visual technique based on the scaling and rotation effects of bitmap graphics. In this game, this technique consists of a double-layer; one of which gives the illusion of depth.

"Maximum Velocity" is one of ten Game Boy Advance games released on December 16, 2011 to Nintendo 3DS Ambassadors, a program to give free downloadable games to early adopters who bought a Nintendo 3DS before its price drop. It was also released on the Wii U Virtual Console on April 3, 2014 in Japan and April 17, 2014 in North America and Europe.

On release, "Famitsu" magazine scored the game a 31 out of 40. "F-Zero: Maximum Velocity" went on to sell 334,145 copies in Japan and 273,229 copies in the U.S. as of 2005. The game has total sales of over 1 million copies worldwide & it also got an overall score of 86% on Metacritic and 83.37% on Game Rankings.



</doc>
<doc id="11794" url="https://en.wikipedia.org/wiki?curid=11794" title="Frederick William I of Prussia">
Frederick William I of Prussia

Frederick William I (; 14 August 1688 – 31 May 1740), known as the "Soldier King" (), was the King in Prussia and Elector of Brandenburg from 1713 until his death in 1740, as well as Prince of Neuchâtel. He was succeeded by his son, Frederick the Great.

He was born in Berlin to Frederick I of Prussia and Sophia Charlotte of Hanover. During his first years, he was raised by the Huguenot governess Marthe de Roucoulle.

His father had successfully acquired the title King for the margraves of Brandenburg. On ascending the throne in 1713 (the year before his maternal grandmother’s death and the ascension of his maternal uncle George I of Great Britain to the British throne) the new King sold most of his father's horses, jewels and furniture; he did not intend to treat the treasury as his personal source of revenue the way Frederick I and many of the other German Princes had. Throughout his reign, Frederick William was characterized by his frugal, austere and militaristic lifestyle, as well as his devout Calvinist faith. He practiced rigid management of the treasury, never started a war, and led a simple and austere lifestyle, in contrast to the lavish court his father had presided over. At his death, Prussia had a sound exchequer and a full treasury, in contrast to the other German states.

Frederick William I did much to improve Prussia economically and militarily. He replaced mandatory military service among the middle class with an annual tax, and he established schools and hospitals. The king encouraged farming, reclaimed marshes, stored grain in good times and sold it in bad times. He dictated the manual of Regulations for State Officials, containing 35 chapters and 297 paragraphs in which every public servant in Prussia could find his duties precisely set out: a minister or councillor failing to attend a committee meeting, for example, would lose six months' pay; if he absented himself a second time, he would be discharged from the royal service. In short, Frederick William I concerned himself with every aspect of his relatively small country, ruling an absolute monarchy with great energy and skill.

In 1732, the king invited the Salzburg Protestants to settle in East Prussia, which had been depopulated by plague in 1709. Under the terms of the Peace of Augsburg, the Prince-Archbishop of Salzburg could require his subjects to practice the Catholic faith, but Protestants had the right to emigrate to a Protestant state. Prussian commissioners accompanied 20,000 Protestants to their new homes on the other side of Germany. Frederick William I personally welcomed the first group of migrants and sang Protestant hymns with them.

Frederick William intervened briefly in the Great Northern War, allied with Peter the Great of Russia, in order to gain a small portion of Swedish Pomerania; this gave Prussia new ports on the Baltic Sea coast. More significantly, aided by his close friend Prince Leopold of Anhalt-Dessau, the "Soldier-King" made considerable reforms to the Prussian army's training, tactics and conscription program—introducing the canton system, and greatly increasing the Prussian infantry's rate of fire through the introduction of the iron ramrod. Frederick William's reforms left his son Frederick with the most formidable army in Europe, which Frederick used to increase Prussia's power. The observation that "the pen is mightier than the sword" has sometimes been attributed to him. ("See as well:" "Prussian virtues".)

Although a highly effective ruler, Frederick William had a perpetually short temper which sometimes drove him to physically attack servants (or even his own children) with a cane at the slightest provocation. His violent, harsh nature was further exacerbated by his inherited porphyritic disease, which gave him gout, obesity and frequent crippling stomach pains. He also had a notable contempt for France, and would sometimes fly into a rage at the mere mention of that country, although this did not stop him from encouraging the immigration of French Huguenot refugees to Prussia.

Frederick William died in 1740 at age 51 and was interred at the Garrison Church in Potsdam. During World War II, in order to protect it from advancing allied forces, Hitler ordered the king's coffin, as well as those of Frederick the Great and Paul von Hindenburg, into hiding, first to Berlin and later to a salt mine outside of Bernterode. The coffins were later discovered by occupying American Forces, who re-interred the bodies in St. Elisabeth's Church in Marburg in 1946. In 1953 the coffin was moved to Burg Hohenzollern, where it remained until 1991, when it was finally laid to rest on the steps of the altar in the Kaiser Friedrich Mausoleum in the Church of Peace on the palace grounds of Sanssouci. The original black marble sarcophagus collapsed at Burg Hohenzollern—the current one is a copper copy.

His eldest surviving son was Frederick II (Fritz), born in 1712. Frederick William wanted him to become a fine soldier. As a small child, Fritz was awakened each morning by the firing of a cannon. At the age of 6, he was given his own regiment of children to drill as cadets, and a year later, he was given a miniature arsenal.
The love and affection Frederick William had for his heir initially was soon destroyed due to their increasingly different personalities. Frederick William ordered Fritz to undergo a minimal education, live a simple Protestant lifestyle, and focus on the Army and statesmanship as he had. However, the intellectual Fritz was more interested in music, books and French culture, which were forbidden by his father as decadent and unmanly. As Fritz's defiance for his father's rules increased, Frederick William would frequently beat or humiliate Fritz (he preferred his younger sibling Augustus William). Fritz was beaten for being thrown off a bolting horse and wearing gloves in cold weather. After the prince attempted to flee to England with his tutor, Hans Hermann von Katte, the enraged King had Katte beheaded before the eyes of the prince, who himself was court-martialled. The court declared itself not competent in this case. Whether it was the king's intention to have his son executed as well (as Voltaire claims) is not clear. However, the Holy Roman Emperor Charles VI intervened, claiming that a prince could only be tried by the Imperial Diet of the Holy Roman Empire itself. Frederick was imprisoned in the Fortress of Küstrin from 2 September to 19 November 1731 and exiled from court until February 1732, during which time he was rigorously schooled in matters of state. After achieving a measure of reconciliation, Frederick William had his son married to Princess Elizabeth of Brunswick-Wolfenbüttel, whom Frederick despised, but then grudgingly allowed him to indulge in his musical and literary interests again. He also gifted him a stud farm in East Prussia, and Rheinsberg Palace. By the time of Frederick William's death in 1740, he and Frederick were on at least reasonable terms with each other.

Although the relationship between Frederick William and Frederick was clearly hostile, Frederick himself later wrote that his father "penetrated and understood great objectives, and knew the best interests of his country better than any minister or general."

Frederick William married his first cousin Sophia Dorothea of Hanover, George II's younger sister (daughter of his uncle, King George I of Great Britain and Sophia Dorothea of Celle) on 28 November 1706. Frederick William was faithful and loving to his wife but they did not have a happy relationship: Sophia Dorothea feared his unpredictable temper and resented him, both for allowing her no influence at court and for refusing to marry her children to their English cousins. She also abhorred his cruelty towards their son and heir Frederick (with whom she was close), although rather than trying to mend the relationship between father and son she frequently spurred Frederick on in his defiance. They had fourteen children, including:

He was the godfather of the Prussian envoy Friedrich Wilhelm von Thulemeyer and of his grand-nephew, Prince Edward Augustus of Great Britain.




</doc>
<doc id="11795" url="https://en.wikipedia.org/wiki?curid=11795" title="Felsic">
Felsic

In geology, felsic is an adjective describing igneous rocks that are relatively rich in elements that form feldspar and quartz. It is contrasted with mafic rocks, which are relatively richer in magnesium and iron. Felsic refers to silicate minerals, magma, and rocks which are enriched in the lighter elements such as silicon, oxygen, aluminium, sodium, and potassium. Felsic magma or lava is higher in viscosity than mafic magma/lava.

Felsic rocks are usually light in color and have specific gravities less than 3. The most common felsic rock is granite. Common felsic minerals include quartz, muscovite, orthoclase, and the sodium-rich plagioclase feldspars (albite-rich).

In modern usage, the term "acid rock", although sometimes used as a synonym, normally now refers specifically to a high-silica-content (greater than 63% SiO by weight) volcanic rock, such as rhyolite. Older, broader usage is now considered archaic. That usage, with the contrasting term "basic rock", was based on an incorrect idea, dating from the 19th century, that "silicic acid" was the chief form of silicon occurring in rocks.

The term "felsic" combines the words "feldspar" and "silica". The similarity of the resulting term "felsic" to the German "felsig", "rocky" (from "Fels", "rock"), is purely accidental. "Feldspar" is linked to German. It is a borrowing of "Feldspat". The link is therefore to German "Feld", meaning "field".

In order for a rock to be classified as felsic, it generally needs to contain more than 75% felsic minerals; namely quartz, orthoclase and plagioclase. Rocks with greater than 90% felsic minerals can also be called leucocratic, from the Greek words for white and dominance.

Felsite is a petrologic field term used to refer to very fine-grained or aphanitic, light-colored volcanic rocks which might be later reclassified after a more detailed microscopic or chemical analysis.

In some cases, felsic volcanic rocks may contain phenocrysts of mafic minerals, usually hornblende, pyroxene or a feldspar mineral, and may need to be named after their phenocryst mineral, such as 'hornblende-bearing felsite'.

The chemical name of a felsic rock is given according to the TAS classification of Le Maitre (1975). However, this only applies to volcanic rocks. If the rock is analyzed and found to be felsic but is metamorphic and has no definite volcanic protolith, it may be sufficient to simply call it a 'felsic schist'. There are examples known of highly sheared granites which can be mistaken for rhyolites.

For phaneritic felsic rocks, the QAPF diagram should be used, and a name given according to the granite nomenclature. Often the species of mafic minerals is included in the name, for instance, hornblende-bearing granite, pyroxene tonalite or augite megacrystic monzonite, because the term "granite" already assumes content with feldspar and quartz.

The rock texture thus determines the basic name of a felsic rock.




</doc>
<doc id="11797" url="https://en.wikipedia.org/wiki?curid=11797" title="Frisians">
Frisians

The Frisians are a Germanic ethnic group indigenous to the coastal parts of the Netherlands and northwestern Germany. They inhabit an area known as Frisia and are concentrated in the Dutch provinces of Friesland and Groningen and, in Germany, East Frisia and North Frisia (which was a part of Denmark until 1864). The Frisian languages are still spoken by more than 500,000 people; West Frisian is officially recognised in the Netherlands (in Friesland), and North Frisian and Saterland Frisian are recognised as regional languages in Germany.

The ancient Frisii enter recorded history in the Roman account of Drusus's 12 BC war against the Rhine Germans and the Chauci. They occasionally appear in the accounts of Roman wars against the Germanic tribes of the region, up to and including the Revolt of the Batavi around 70 AD. Frisian mercenaries were hired to assist the Roman invasion of Britain in the capacity of cavalry. They are not mentioned again until 296, when they were deported into Roman territory as "laeti" (i.e., Roman-era serfs; see Binchester Roman Fort and Cuneus Frisionum). The discovery of a type of earthenware unique to 4th century Frisia, called "terp Tritzum", shows that an unknown number of them were resettled in Flanders and Kent, probably as "laeti" under Roman coercion.

From the 3rd through the 5th centuries Frisia suffered marine transgressions that made most of the land uninhabitable, aggravated by a change to a cooler and wetter climate. Whatever population may have remained dropped dramatically, and the coastal lands remained largely unpopulated for the next two centuries. When conditions improved, Frisia received an influx of new settlers, mostly Angles and Saxons. These people would eventually be referred to as 'Frisians', though they were not necessarily descended from the ancient Frisii. It is these 'new Frisians' who are largely the ancestors of the medieval and modern Frisians.

By the end of the 6th century, Frisian territory had expanded westward to the North Sea coast and, in the 7th century, southward down to Dorestad. This farthest extent of Frisian territory is sometimes referred to as "Frisia Magna". Early Frisia was ruled by a High King, with the earliest reference to a 'Frisian King' being dated 678.

In the early 8th century the Frisian nobles came into increasing conflict with the Franks to their south, resulting in a series of wars in which the Frankish Empire eventually subjugated Frisia in 734. These wars benefited attempts by Anglo-Irish missionaries (which had begun with Saint Boniface) to convert the Frisian populace to Christianity, in which Saint Willibrord largely succeeded.

Some time after the death of Charlemagne, the Frisian territories were in theory under the control of the Count of Holland, but in practice the Hollandic counts, starting with Count Arnulf in 993, were unable to assert themselves as the sovereign lords of Frisia. The resulting stalemate resulted in a period of time called the 'Frisian freedom', a period in which feudalism and serfdom (as well as central or judicial administration) did not exist, and in which the Frisian lands only owed their allegiance to the Holy Roman Emperor.

During the 13th century, however, the counts of Holland became increasingly powerful and, starting in 1272, sought to reassert themselves as rightful lords of the Frisian lands in a series of wars, which (with a series of lengthy interruptions) ended in 1422 with the Hollandic conquest of Western Frisia and with the establishment of a more powerful noble class in Central and Eastern Frisia.

In 1524, Frisia became part of the Seventeen Provinces and in 1568 joined the Dutch revolt against Philip II, king of Spain, heir of the Burgundian territories; Central Frisia has remained a part of the Netherlands ever since. The eastern periphery of Frisia would become part of various German states (later Germany) and Denmark. An old tradition existed in the region of exploitation of peatlands.

Though impossible to know exact numbers and migration patterns, research has indicated that many Frisians were part of the wave of ethnic groups to colonise areas of present day England alongside the Angles, Saxons and Jutes, starting from around the fifth century when Frisians arrived along the coastline of Kent. Studies have found the DNA of people tested in Central England to be "indistinguishable" from that of Frisians.

Frisians principally settled in modern-day Kent, East Anglia, the East Midlands, North East England, and Yorkshire. Across these areas, evidence of their settlement includes place names of Frisian origin, such as Frizinghall in Bradford and Frieston in Lincolnshire.

Similarities in dialect between Great Yarmouth and Friesland have been noted, originating from trade between these areas during the Middle Ages. Frisians are also known to have founded the Freston area of Ipswich.

In Scotland, historians have noted that colonies of Angles and Frisians settled as far north as the River Forth. This corresponds to those areas of Scotland which historically constituted part of Northumbria.

As both the Anglo-Saxons of England and the early Frisians were formed from similar tribal confederacies, their respective languages were very similar, together forming the Anglo-Frisian family. Old Frisian is the most closely attested language to Old English and the modern Frisian dialects are in turn the closest related languages to contemporary English that do not themselves derive from Old English.

The Frisian language group is divided into three mutually unintelligible languages:

Of these three languages both Saterland Frisian (2,000 speakers) and North Frisian (10,000 speakers) are endangered. West Frisian is spoken by around 350,000 native speakers in Friesland, and as many as 470,000 when including speakers in neighbouring Groningen province. West Frisian is not listed as threatened, although research published by Radboud University in 2016 has challenged that assumption..

Today there exists a tripartite division of the Frisians, into North Frisians, East Frisians and West Frisians, caused by Frisia's constant loss of territory in the Middle Ages. The West Frisians, in general, do not see themselves as part of a larger group of Frisians, and, according to a 1970 poll, identify themselves more with the Dutch than with the East or North Frisians. Therefore, the term 'Frisian', when applied to the speakers of all three Frisian languages, is a linguistic, ethnic and/or cultural concept, not a political one.






</doc>
<doc id="11800" url="https://en.wikipedia.org/wiki?curid=11800" title="Futurism (disambiguation)">
Futurism (disambiguation)

Futurism is an artistic and social movement that originated in Italy in the early 20th century.
Futures studies, also known as futurology, is the study of possible futures.

Futurism may also refer to:







</doc>
<doc id="11801" url="https://en.wikipedia.org/wiki?curid=11801" title="Filippo Tommaso Marinetti">
Filippo Tommaso Marinetti

Filippo Tommaso Emilio Marinetti (; 22 December 1876 – 2 December 1944) was an Italian poet, editor, art theorist, and founder of the Futurist movement. He was associated with the utopian and Symbolist artistic and literary community Abbaye de Créteil between 1907 and 1908. Marinetti is best known as the author of the first "Futurist Manifesto", which was written and published in 1909, and also of the Fascist Manifesto.

Emilio Angelo Carlo Marinetti (some documents give his name as "Filippo Achille Emilio Marinetti") spent the first years of his life in Alexandria, Egypt, where his father (Enrico Marinetti) and his mother (Amalia Grolli) lived together "more uxorio" (as if married). Enrico was a lawyer from Piedmont, and his mother was the daughter of a literary professor from Milan. They had come to Egypt in 1865, at the invitation of Khedive Isma'il Pasha, to act as legal advisers for foreign companies that were taking part in his modernization program.

His love for literature developed during the school years. His mother was an avid reader of poetry, and introduced the young Marinetti to the Italian and European classics. At age seventeen he started his first school magazine, "Papyrus"; the Jesuits threatened to expel him for publicizing Émile Zola's scandalous novels in the school.

He first studied in Egypt then in Paris, obtaining a "baccalauréat" degree in 1894 at the Sorbonne, and in Italy, graduating in law at the University of Pavia in 1899.

He decided not to be a lawyer but to develop a literary career. He experimented with every type of literature (poetry, narrative, theatre, "words in liberty"), signing everything "Filippo Tommaso Marinetti".

Marinetti and Constantin Brâncuși were visitors of the Abbaye de Créteil c. 1908 along with young writers like Roger Allard (one of the first to defend Cubism), Pierre Jean Jouve, and Paul Castiaux, who wanted to publish their works through the Abbaye. The Abbaye de Créteil was a "phalanstère" community founded in the autumn of 1906 by the painter Albert Gleizes, and the poets , , Alexandre Mercereau and Charles Vildrac. The movement drew its inspiration from the "Abbaye de Thélème," a fictional creation by Rabelais in his novel "Gargantua". It was closed down by its members early in 1908.

Marinetti is known best as the author of the "Futurist Manifesto", which he wrote in 1909. It was published in French on the front page of the most prestigious French daily newspaper, "Le Figaro", on 20 February 1909. In "The Founding and Manifesto of Futurism", Marinetti declared that "Art, in fact, can be nothing but violence, cruelty, and injustice." Georges Sorel, who influenced the entire political spectrum from anarchism to Fascism, also argued for the importance of violence. Futurism had both anarchist and Fascist elements; Marinetti later became an active supporter of Benito Mussolini.

Marinetti, who admired speed, had a minor car accident outside Milan in 1908 when he veered into a ditch to avoid two cyclists. He referred to the accident in the Futurist Manifesto: the Marinetti who was helped out of the ditch was a new man, determined to end the pretense and decadence of the prevailing Liberty style. He discussed a new and strongly revolutionary programme with his friends, in which they should end every artistic relationship with the past, "destroy the museums, the libraries, every type of academy". Together, he wrote, "We will glorify war—the world's only hygiene—militarism, patriotism, the destructive gesture of freedom-bringers, beautiful ideas worth dying for, and scorn for woman".

The Futurist Manifesto was read and debated all across Europe, but Marinetti's first 'Futurist' works were not as successful. In April, the opening night of his drama "Le Roi bombance" (The Feasting King), written in 1905, was interrupted by loud, derisive whistling by the audience... and by Marinetti himself, who thus introduced another element of Futurism, "the desire to be heckled." Marinetti did, however, fight a duel with a critic he considered too harsh.

His drama "La donna è mobile" (Poupées électriques), first presented in Turin, was not successful either. Nowadays, the play is remembered through a later version, named "Elettricità sessuale" (Sexual Electricity), and mainly for the appearance onstage of humanoid automatons, ten years before the Czech writer Karel Čapek would invent the term "robot".
In 1910 his first novel, "Mafarka il futurista", was cleared of all charges by an obscenity trial. That year, Marinetti discovered some allies in three young painters (Umberto Boccioni, Carlo Carrà, Luigi Russolo), who adopted the Futurist philosophy. Together with them (and with poets such as Aldo Palazzeschi), Marinetti began a series of Futurist Evenings, theatrical spectacles in which Futurists declaimed their manifestos in front of a crowd that in part attended the performances in order to throw vegetables at them.

The most successful "happening" of that period was the publicization of the "Manifesto Against Past-Loving Venice" in Venice. In the flier, Marinetti demands "fill(ing) the small, stinking canals with the rubble from the old, collapsing and leprous palaces" to "prepare for the birth of an industrial and militarized Venice, capable of dominating the great Adriatic, a great Italian lake."

In 1911, the Italo-Turkish War began and Marinetti departed for Libya as war correspondent for a French newspaper. His articles were eventually collected and published in "The Battle of Tripoli". He then covered the First Balkan War of 1912–13, witnessing the surprise success of Bulgarian troops against the Ottoman Empire in the Siege of Adrianople. In this period he also made a number of visits to London, which he considered 'the Futurist city par excellence', and where a number of exhibitions, lectures and demonstrations of Futurist music were staged. However, although a number of artists, including Wyndham Lewis, were interested in the new movement, only one British convert was made, the young artist C.R.W. Nevinson. Nevertheless, Futurism was an important influence upon Lewis's Vorticist philosophy.

About the same time Marinetti worked on a very anti-Roman Catholic and anti-Austrian verse-novel, "Le monoplan du Pape" ("The Pope's Aeroplane", 1912) and edited an anthology of futurist poets. But his attempts to renew the style of poetry did not satisfy him. So much so that, in his foreword to the anthology, he declared a new revolution: it was time to be done with traditional syntax and to use "words in freedom" ("parole in libertà"). His sound-poem "Zang Tumb Tumb", an account of the Battle of Adrianople, exemplifies words in freedom. Recordings can be heard of Marinetti reading some of his sound poems: "Battaglia, Peso + Odore" (1912); "Dune, parole in libertà" (1914); "La Battaglia di Adrianopoli" (1926) (recorded 1935).

Marinetti agitated for Italian involvement in World War I, and once Italy was engaged, promptly volunteered for service. In the fall of 1915 he and several other Futurists who were members of the Lombard Volunteer Cyclists were stationed at Lake Garda, in Trentino province, high in the mountains along the Italo-Austrian border. They endured several weeks of fighting in harsh conditions before the cyclists units, deemed inappropriate for mountain warfare, were disbanded.

Marinetti spent most of 1916 supporting Italy's war effort with speeches, journalism, and theatrical work, then returned to military service as a regular army officer in 1917. In May of that year he was seriously wounded while serving with an artillery battalion on the Isonzo front; he returned to service after a long recovery, and participated in the decisive Italian victory at Vittorio Veneto in October 1918.

After an extended courtship, in 1923 Marinetti married Benedetta Cappa (1897–1977), a writer and painter and a pupil of Giacomo Balla. Born in Rome, she had joined the Futurists in 1917. They'd met in 1918, moved in together in Rome, and chose to marry only to avoid legal complications on a lecture tour of Brazil. They would have three daughters: Vittoria, Ala, and Luce.

Cappa and Marinetti collaborated on a genre of mixed-media assemblages in the mid-1920s they called "tattilismo" ("Tactilism"), and she was a strong proponent and practitioner of the aeropittura movement after its inception in 1929. She also produced three experimental novels. Cappa's major public work is likely a series of five murals at the Palermo Post Office (1926–1935) for the Fascist public-works architect Angiolo Mazzoni.

In early 1918 he founded the "Partito Politico Futurista" or Futurist Political Party, which only a year later merged with Benito Mussolini's "Fasci Italiani di Combattimento". Marinetti was one of the first affiliates of the Italian Fascist Party. In 1919 he co-wrote with Alceste De Ambris the Fascist Manifesto, the original manifesto of Italian Fascism. He opposed Fascism's later exaltation of existing institutions, terming them "reactionary," and, after walking out of the 1920 Fascist party congress in disgust, withdrew from politics for three years. However, he remained a notable force in developing the party philosophy throughout the regime's existence. For example, at the end of the "Congress of Fascist Culture" that was held in Bologna on 30 March 1925, Giovanni Gentile addressed Sergio Panunzio on the need to define Fascism more purposefully by way of Marinetti's opinion, stating, "Great spiritual movements make recourse to precision when their primitive inspirations—what F. T. Marinetti identified this morning as artistic, that is to say, the creative and truly innovative ideas, from which the movement derived its first and most potent impulse—have lost their force. We today find ourselves at the very beginning of a new life and we experience with joy this obscure need that fills our hearts—this need that is our inspiration, the genius that governs us and carries us with it."

As part of his campaign to overturn tradition, Marinetti also attacked traditional Italian food. His "Manifesto of Futurist Cooking" was published in the Turin "Gazzetta del Popolo" on 28 December 1930. Arguing that "People think, dress and act in accordance with what they drink and eat", Marinetti proposed wide-ranging changes to diet. He condemned pasta, blaming it for lassitude, pessimism and lack of virility, and promoted the eating of Italian-grown rice. In this, as in other ways, his proposed Futurist cooking was nationalistic, rejecting foreign foods and food names. It was also militaristic, seeking to stimulate men to be fighters.

Marinetti also sought to increase creativity. His attraction to whatever was new made scientific discoveries appealing to him, but his views on diet were not scientifically based. He was fascinated with the idea of processed food, predicting that someday pills would replace food as a source of energy, and calling for the creation of "plastic complexes" to replace natural foods. Food, in turn, would become a matter of artistic expression. Many of the meals Marinetti described and ate resemble performance art, such as the "Tactile Dinner", recreated in 2014 for an exhibit at the Guggenheim Museum. Participants wore pajamas decorated with sponge, sandpaper, and aluminum, and ate salads without using cutlery.

During the Fascist regime Marinetti sought to make Futurism the official state art of Italy but failed to do so. Mussolini was personally uninterested in art and chose to give patronage to numerous styles in order to keep artists loyal to the regime. Opening the exhibition of art by the Novecento Italiano group in 1923, he said: "I declare that it is far from my idea to encourage anything like a state art. Art belongs to the domain of the individual. The state has only one duty: not to undermine art, to provide humane conditions for artists, to encourage them from the artistic and national point of view." Mussolini's mistress, Margherita Sarfatti, successfully promoted the rival Novecento Group, and even persuaded Marinetti to be part of its board.

In Fascist Italy, modern art was tolerated and even approved by the Fascist hierarchy. Towards the end of the 1930s, some Fascist ideologues (for example, the ex-Futurist Ardengo Soffici) wished to import the concept of "degenerate art" from Germany to Italy and condemned modernism, although their demands were ignored by the regime. In 1938, hearing that Adolf Hitler wanted to include Futurism in a traveling exhibition of degenerate art, Marinetti persuaded Mussolini to refuse to let it enter Italy.

On 17 November 1938, Italy passed The Racial Laws, discriminating against Italian Jews, much as the discrimination pronounced in the Nuremberg Laws. The anti-Semitic trend in Italy resulted in attacks against modern art, judged too foreign, too radical and anti-nationalist. In 11 January 1939 issue of the Futurist journal "Artecrazia" Marinetti expressed his condemnation of such attacks on modern art, noting Futurism is both Italian and nationalist, not foreign, and that there are no Jews in Futurism. Furthermore, he claimed Jews were not active in the development of modern art. Regardless, the Italian state shut down "Artecrazia".

Marinetti made numerous attempts to ingratiate himself with the regime, becoming less radical and avant garde with each attempt. He relocated from Milan to Rome. He became an academician despite his condemnation of academies, saying, "It is important that Futurism be represented in the Academy."

He was an atheist, but by the mid 1930s he had come to accept the influence of the Catholic Church on Italian society. In "Gazzetta del Popolo", 21 June 1931, Marinetti proclaimed that "Only Futurist artists...are able to express clearly...the simultaneous dogmas of the Catholic faith, such as the Holy Trinity, the Immaculate Conception and Christ’s Calvary." In his last works, written just before his death in 1944 "L'aeropoema di Gesù" ("The Aeropoem of Jesus") and "Quarto d'ora di poesia per the X Mas" ("A Fifteen Minutes' Poem of the X Mas"), Marinetti sought to reconcile his newfound love for God and his passion for the action that accompanied him throughout his life.

There were other contradictions in his character: despite his nationalism, he was international, educated in Egypt and France, writing his first poems in French, publishing the Futurist Manifesto in a French newspaper and traveling to promote his ideas.

Marinetti volunteered for active service in the Second Italo-Abyssinian War and the Second World War, serving on the Eastern Front for a few weeks in the Summer and Autumn of 1942 at the age of 65.

He died of cardiac arrest in Bellagio on 2 December 1944 while working on a collection of poems praising the wartime achievements of the Decima Flottiglia MAS.





</doc>
<doc id="11803" url="https://en.wikipedia.org/wiki?curid=11803" title="Franz Mesmer">
Franz Mesmer

Franz Friedrich Anton Mesmer (; ; 23 May 1734 – 5 March 1815) was a German doctor with an interest in astronomy. He theorised the existence of a natural energy transference occurring between all animated and inanimate objects; this he called "animal magnetism", sometimes later referred to as "mesmerism". (In modern times New Age spiritualists have revived a similar idea.) Mesmer's theory attracted a wide following between about 1780 and 1850, and continued to have some influence until the end of the 19th century. In 1843 the Scottish doctor James Braid proposed the term "hypnosis" for a technique derived from animal magnetism; today the word "mesmerism" generally functions as a synonym of "hypnosis".

Mesmer was born in the village of Iznang, on the shore of Lake Constance in Swabia, Germany, a son of master forester Anton Mesmer (1701—after 1747) and his wife, Maria/Ursula (née Michel; 1701—1770). After studying at the Jesuit universities of Dillingen and Ingolstadt, he took up the study of medicine at the University of Vienna in 1759. In 1766 he published a doctoral dissertation with the Latin title "De planetarum influxu in corpus humanum" ("On the Influence of the Planets on the Human Body"), which discussed the influence of the moon and the planets on the human body and on disease. This was not medical astrology. Building largely on Isaac Newton's theory of the tides, Mesmer expounded on certain tides in the human body that might be accounted for by the movements of the sun and moon. Evidence assembled by Frank A. Pattie suggests that Mesmer plagiarized a part of his dissertation from a work by Richard Mead, an eminent English physician and Newton's friend. However, in Mesmer's day doctoral theses were not expected to be original.

In January 1768, Mesmer married Anna Maria von Posch, a wealthy widow, and established himself as a doctor in Vienna. In the summers he lived on a splendid estate and became a patron of the arts. In 1768, when court intrigue prevented the performance of "La finta semplice" (K. 51), for which the twelve-year-old Wolfgang Amadeus Mozart had composed 500 pages of music, Mesmer is said to have arranged a performance in his garden of Mozart's "Bastien und Bastienne" (K. 50), a one-act opera, though Mozart's biographer Nissen found no proof that this performance actually took place. Mozart later immortalized his former patron by including a comedic reference to Mesmer in his opera "Così fan tutte".

In 1774, Mesmer produced an "artificial tide" in a patient, Francisca Österlin, who suffered from hysteria, by having her swallow a preparation containing iron and then attaching magnets to various parts of her body. She reported feeling streams of a mysterious fluid running through her body and was relieved of her symptoms for several hours. Mesmer did not believe that the magnets had achieved the cure on their own. He felt that he had contributed animal magnetism, which had accumulated in his work, to her. He soon stopped using magnets as a part of his treatment.

In the same year Mesmer collaborated with Maximilian Hell.

In 1775, Mesmer was invited to give his opinion before the Munich Academy of Sciences on the exorcisms carried out by Johann Joseph Gassner (Gaßner), a priest and healer who grew up in Vorarlberg, Austria. Mesmer said that while Gassner was sincere in his beliefs, his cures resulted because he possessed a high degree of animal magnetism. This confrontation between Mesmer's secular ideas and Gassner's religious beliefs marked the end of Gassner's career as well as, according to Henri Ellenberger, the emergence of dynamic psychiatry.

The scandal that followed Mesmer's only partial success in curing the blindness of an 18-year-old musician, Maria Theresia Paradis, led him to leave Vienna in 1777. In February 1778 Mesmer moved to Paris, rented an apartment in a part of the city preferred by the wealthy and powerful, and established a medical practice. There he would reunite with Mozart who often visited him. Paris soon divided into those who thought he was a charlatan who had been forced to flee from Vienna and those who thought he had made a great discovery.

In his first years in Paris, Mesmer tried and failed to get either the Royal Academy of Sciences or the Royal Society of Medicine to provide official approval for his doctrines. He found only one physician of high professional and social standing, Charles d'Eslon, to become a disciple. In 1779, with d'Eslon's encouragement, Mesmer wrote an 88-page book, "Mémoire sur la découverte du magnétisme animal", to which he appended his famous 27 Propositions. These propositions outlined his theory at that time. Some contemporary scholars equate Mesmer’s animal magnetism with the Qi (chi) of Traditional Chinese Medicine and mesmerism with medical Qigong practices.

According to d'Eslon, Mesmer understood health as the free flow of the process of life through thousands of channels in our bodies. Illness was caused by obstacles to this flow. Overcoming these obstacles and restoring flow produced crises, which restored health. When Nature failed to do this spontaneously, contact with a conductor of animal magnetism was a necessary and sufficient remedy. Mesmer aimed to aid or provoke the efforts of Nature. To cure an insane person, for example, involved causing a fit of madness. The advantage of magnetism involved accelerating such crises without danger.

Mesmer treated patients both individually and in groups. With individuals he would sit in front of his patient with his knees touching the patient's knees, pressing the patient's thumbs in his hands, looking fixedly into the patient's eyes. Mesmer made "passes", moving his hands from patients' shoulders down along their arms. He then pressed his fingers on the patient's hypochondrium region (the area below the diaphragm), sometimes holding his hands there for hours. Many patients felt peculiar sensations or had convulsions that were regarded as crises and supposed to bring about the cure. Mesmer would often conclude his treatments by playing some music on a glass armonica.

By 1780 Mesmer had more patients than he could treat individually and he established a collective treatment known as the "baquet." An English doctor who observed Mesmer described the treatment as follows:In the middle of the room is placed a vessel of about a foot and a half high which is called here a "baquet". It is so large that twenty people can easily sit round it; near the edge of the lid which covers it, there are holes pierced corresponding to the number of persons who are to surround it; into these holes are introduced iron rods, bent at right angles outwards, and of different heights, so as to answer to the part of the body to which they are to be applied. Besides these rods, there is a rope which communicates between the baquet and one of the patients, and from him is carried to another, and so on the whole round. The most sensible effects are produced on the approach of Mesmer, who is said to convey the fluid by certain motions of his hands or eyes, without touching the person. I have talked with several who have witnessed these effects, who have convulsions occasioned and removed by a movement of the hand...

In 1784, without Mesmer requesting it, King Louis XVI appointed four members of the Faculty of Medicine as commissioners to investigate animal magnetism as practiced by d'Eslon. At the request of these commissioners the King appointed five additional commissioners from the Royal Academy of Sciences. These included the chemist Antoine Lavoisier, the doctor Joseph-Ignace Guillotin, the astronomer Jean Sylvain Bailly, and the American ambassador Benjamin Franklin.

The commission conducted a series of experiments aimed not at determining whether Mesmer's treatment worked, but whether he had discovered a new physical fluid. The commission concluded that there was no evidence for such a fluid. Whatever benefit the treatment produced was attributed to "imagination." But one of the commissioners, the botanist Antoine Laurent de Jussieu took exception to the official reports. He wrote a dissenting opinion that declared Mesmer's theory credible and worthy of further investigation.

The commission did not examine Mesmer, but investigated the practice of d'Eslon.

In August 1784 Mesmer visited a Mesmeric society in Lyon. In 1785 Mesmer left Paris. In 1790 he was in Vienna again to settle the estate of his deceased wife Maria Anna. When he sold his house in Vienna in 1801 he was in Paris.

Mesmer was driven into exile soon after the investigations on animal magnetism although his influential student, Armand-Marie-Jacques de Chastenet, Marquis de Puségur (1751-1825), continued to have many followers until his death. Mesmer continued to practice in Frauenfeld, Switzerland, for a number of years and died in 1815 in Meersburg, Germany.

Abbé Faria, an Indo-Portuguese monk in Paris and a contemporary of Mesmer, claimed that "nothing comes from the magnetizer; everything comes from the subject and takes place in his imagination, i.e. autosuggestion generated from within the mind."



</doc>
<doc id="11806" url="https://en.wikipedia.org/wiki?curid=11806" title="Foix–Alajouanine syndrome">
Foix–Alajouanine syndrome

Foix–Alajouanine syndrome, also called subacute ascending necrotizing myelitis, is a disease caused by an arteriovenous malformation of the spinal cord. The patients present with symptoms indicating spinal cord involvement (paralysis of arms and legs, numbness and loss of sensation and sphincter dysfunction), and pathological examination reveals disseminated nerve cell death in the spinal cord and abnormally dilated and tortuous vessels situated on the surface of the spinal cord. Surgical treatment can be tried in some cases. If surgical intervention is contraindicated, corticosteroids may be used.

The condition is named after Charles Foix and Théophile Alajouanine.




</doc>
<doc id="11807" url="https://en.wikipedia.org/wiki?curid=11807" title="Ferromagnetism">
Ferromagnetism

Ferromagnetism is the basic mechanism by which certain materials (such as iron) form permanent magnets, or are attracted to magnets. In physics, several different types of magnetism are distinguished. Ferromagnetism (along with the similar effect ferrimagnetism) is the strongest type and is responsible for the common phenomenon of magnetism in magnets encountered in everyday life. Substances respond weakly to magnetic fields with three other types of magnetism—paramagnetism, diamagnetism, and antiferromagnetism—but the forces are usually so weak that they can be detected only by sensitive instruments in a laboratory. An everyday example of ferromagnetism is a refrigerator magnet used to hold notes on a refrigerator door. The attraction between a magnet and ferromagnetic material is "the quality of magnetism first apparent to the ancient world, and to us today".

Permanent magnets (materials that can be magnetized by an external magnetic field and remain magnetized after the external field is removed) are either ferromagnetic or ferrimagnetic, as are the materials that are noticeably attracted to them. Only a few substances are ferromagnetic. The common ones are iron, cobalt, nickel and most of their alloys, and some compounds of rare earth metals.
Ferromagnetism is very important in industry and modern technology, and is the basis for many electrical and electromechanical devices such as electromagnets, electric motors, generators, transformers, and magnetic storage such as tape recorders, and hard disks, and nondestructive testing of ferrous materials.

Ferromagnetic materials can be divided into magnetically "soft" materials like annealed iron, which can be magnetized but do not tend to stay magnetized, and magnetically "hard" materials, which do. Permanent magnets are made from "hard" ferromagnetic materials such as alnico and ferrite that are subjected to special processing in a strong magnetic field during manufacture to align their internal microcrystalline structure, making them very hard to demagnetize. To demagnetize a saturated magnet, a certain magnetic field must be applied, and this threshold depends on coercivity of the respective material. "Hard" materials have high coercivity, whereas "soft" materials have low coercivity. The overall strength of a magnet is measured by its magnetic moment or, alternatively, the total magnetic flux it produces. The local strength of magnetism in a material is measured by its magnetization.

Historically, the term "ferromagnetism" was used for any material that could exhibit spontaneous magnetization: a net magnetic moment in the absence of an external magnetic field. This general definition is still in common use.

However, in a landmark paper in 1948, Louis Néel showed there are two levels of magnetic alignment that result in this behavior. One is ferromagnetism in the strict sense, where all the magnetic moments are aligned. The other is "ferrimagnetism", where some magnetic moments point in the opposite direction but have a smaller contribution, so there is still a spontaneous magnetization.

In the special case where the opposing moments balance completely, the alignment is known as "antiferromagnetism"; but antiferromagnets do not have a spontaneous magnetization.

The table above lists a selection of ferromagnetic and ferrimagnetic compounds, along with the temperature above which they cease to exhibit spontaneous magnetization (see Curie temperature).

Ferromagnetism is a property not just of the chemical make-up of a material, but of its crystalline structure and microstructure. There are ferromagnetic metal alloys whose constituents are not themselves ferromagnetic, called Heusler alloys, named after Fritz Heusler. Conversely there are non-magnetic alloys, such as types of stainless steel, composed almost exclusively of ferromagnetic metals.

Amorphous (non-crystalline) ferromagnetic metallic alloys can be made by very rapid quenching (cooling) of a liquid alloy. These have the advantage that their properties are nearly isotropic (not aligned along a crystal axis); this results in low coercivity, low hysteresis loss, high permeability, and high electrical resistivity. One such typical material is a transition metal-metalloid alloy, made from about 80% transition metal (usually Fe, Co, or Ni) and a metalloid component (B, C, Si, P, or Al) that lowers the melting point.
A relatively new class of exceptionally strong ferromagnetic materials are the rare-earth magnets. They contain lanthanide elements that are known for their ability to carry large magnetic moments in well-localized f-orbitals.

Most ferromagnetic materials are metals, since the conducting electrons are often responsible for mediating the ferromagnetic interactions. It is therefore a challenge to develop ferromagnetic insulators, especially multiferroic materials, which are both ferromagnetic and ferroelectric.

A number of actinide compounds are ferromagnets at room temperature or exhibit ferromagnetism upon cooling. PuP is a paramagnet with cubic symmetry at room temperature, but which undergoes a structural transition into a tetragonal state with ferromagnetic order when cooled below its T = 125 K. In its ferromagnetic state, PuP's easy axis is in the <100> direction.

In NpFe the easy axis is <111>. Above NpFe is also paramagnetic and cubic. Cooling below the Curie temperature produces a rhombohedral distortion wherein the rhombohedral angle changes from 60° (cubic phase) to 60.53°. An alternate description of this distortion is to consider the length "c" along the unique trigonal axis (after the distortion has begun) and "a" as the distance in the plane perpendicular to "c". In the cubic phase this reduces to . Below the Curie temperature

which is the largest strain in any actinide compound. NpNi undergoes a similar lattice distortion below , with a strain of (43 ± 5) × 10. NpCo is a ferrimagnet below 15 K.

In 2009, a team of MIT physicists demonstrated that a lithium gas cooled to less than one kelvin can exhibit ferromagnetism. The team cooled fermionic lithium-6 to less than (150 billionths of one kelvin) using infrared laser cooling. This demonstration is the first time that ferromagnetism has been demonstrated in a gas.

In 2018, a team of University of Minnesota physicists demonstrated that body-centered tetragonal ruthenium exhibits ferromagnetism at room temperature.

The Bohr–van Leeuwen theorem, discovered in the 1910s, showed that classical physics theories are unable to account for any form of magnetism, including ferromagnetism. Magnetism is now regarded as a purely quantum mechanical effect. Ferromagnetism arises due to two effects from quantum mechanics: spin and the Pauli exclusion principle.

One of the fundamental properties of an electron (besides that it carries charge) is that it has a magnetic dipole moment, i.e., it behaves like a tiny magnet, producing a magnetic field. This dipole moment comes from the more fundamental property of the electron that it has quantum mechanical spin. Due to its quantum nature, the spin of the electron can be in one of only two states; with the magnetic field either pointing "up" or "down" (for any choice of up and down). The spin of the electrons in atoms is the main source of ferromagnetism, although there is also a contribution from the orbital angular momentum of the electron about the nucleus. When these magnetic dipoles in a piece of matter are aligned, (point in the same direction) their individually tiny magnetic fields add together to create a much larger macroscopic field.

However, materials made of atoms with filled electron shells have a total dipole moment of zero: because the electrons all exist in pairs with opposite spin, every electron's magnetic moment is cancelled by the opposite moment of the second electron in the pair. Only atoms with partially filled shells (i.e., unpaired spins) can have a net magnetic moment, so ferromagnetism occurs only in materials with partially filled shells. Because of Hund's rules, the first few electrons in a shell tend to have the same spin, thereby increasing the total dipole moment.

These unpaired dipoles (often called simply "spins" even though they also generally include orbital angular momentum) tend to align in parallel to an external magnetic field, an effect called paramagnetism. Ferromagnetism involves an additional phenomenon, however: in a few substances the dipoles tend to align spontaneously, giving rise to a spontaneous magnetization, even when there is no applied field.

When two nearby atoms have unpaired electrons, whether the electron spins are parallel or antiparallel affects whether the electrons can share the same orbit as a result of the quantum mechanical effect called the exchange interaction. This in turn affects the electron location and the Coulomb (electrostatic) interaction and thus the energy difference between these states.

The exchange interaction is related to the Pauli exclusion principle, which says that two electrons with the same spin cannot also be in the same spatial state (orbital). This is a consequence of the spin-statistics theorem and that electrons are fermions. Therefore, under certain conditions, when the orbitals of the unpaired outer valence electrons from adjacent atoms overlap, the distributions of their electric charge in space are farther apart when the electrons have parallel spins than when they have opposite spins. This reduces the electrostatic energy of the electrons when their spins are parallel compared to their energy when the spins are anti-parallel, so the parallel-spin state is more stable. In simple terms, the electrons, which repel one another, can move "further apart" by aligning their spins, so the spins of these electrons tend to line up. This difference in energy is called the exchange energy.

This energy difference can be orders of magnitude larger than the energy differences associated with the magnetic dipole-dipole interaction due to dipole orientation, which tends to align the dipoles antiparallel. In certain doped semiconductor oxides RKKY interactions have been shown to bring about periodic longer-range magnetic interactions, a phenomenon of significance in the study of spintronic materials.

The materials in which the exchange interaction is much stronger than the competing dipole-dipole interaction are frequently called "magnetic materials". For instance, in iron (Fe) the exchange force is about 1000 times stronger than the dipole interaction. Therefore, below the Curie temperature virtually all of the dipoles in a ferromagnetic material will be aligned. In addition to ferromagnetism, the exchange interaction is also responsible for the other types of spontaneous ordering of atomic magnetic moments occurring in magnetic solids, antiferromagnetism and ferrimagnetism.
There are different exchange interaction mechanisms which create the magnetism in different ferromagnetic, ferrimagnetic, and antiferromagnetic substances. These mechanisms include direct exchange, RKKY exchange, double exchange, and superexchange.

Although the exchange interaction keeps spins aligned, it does not align them in a particular direction. Without magnetic anisotropy, the spins in a magnet randomly change direction in response to thermal fluctuations and the magnet is superparamagnetic. There are several kinds of magnetic anisotropy, the most common of which is magnetocrystalline anisotropy. This is a dependence of the energy on the direction of magnetization relative to the crystallographic lattice. Another common source of anisotropy, inverse magnetostriction, is induced by internal strains. Single-domain magnets also can have a "shape anisotropy" due to the magnetostatic effects of the particle shape. As the temperature of a magnet increases, the anisotropy tends to decrease, and there is often a blocking temperature at which a transition to superparamagnetism occurs.

The above would seem to suggest that every piece of ferromagnetic material should have a strong magnetic field, since all the spins are aligned, yet iron and other ferromagnets are often found in an "unmagnetized" state. The reason for this is that a bulk piece of ferromagnetic material is divided into tiny regions called "magnetic domains" (also known as "Weiss domains"). Within each domain, the spins are aligned, but (if the bulk material is in its lowest energy configuration; i.e. "unmagnetized"), the spins of separate domains point in different directions and their magnetic fields cancel out, so the object has no net large scale magnetic field.

Ferromagnetic materials spontaneously divide into magnetic domains because the "exchange interaction" is a short-range force, so over long distances of many atoms the tendency of the magnetic dipoles to reduce their energy by orienting in opposite directions wins out. If all the dipoles in a piece of ferromagnetic material are aligned parallel, it creates a large magnetic field extending into the space around it. This contains a lot of magnetostatic energy. The material can reduce this energy by splitting into many domains pointing in different directions, so the magnetic field is confined to small local fields in the material, reducing the volume of the field. The domains are separated by thin domain walls a number of molecules thick, in which the direction of magnetization of the dipoles rotates smoothly from one domain's direction to the other.

Thus, a piece of iron in its lowest energy state ("unmagnetized") generally has little or no net magnetic field. However, the magnetic domains in a material are not fixed in place; they are simply regions where the spins of the electrons have aligned spontaneously due to their magnetic fields, and thus can be altered by an external magnetic field. If a strong enough external magnetic field is applied to the material, the domain walls will move by the process of the spins of the electrons in atoms near the wall in one domain turning under the influence of the external field to face in the same direction as the electrons in the other domain, thus reorienting the domains so more of the dipoles are aligned with the external field. The domains will remain aligned when the external field is removed, creating a magnetic field of their own extending into the space around the material, thus creating a "permanent" magnet. The domains do not go back to their original minimum energy configuration when the field is removed because the domain walls tend to become 'pinned' or 'snagged' on defects in the crystal lattice, preserving their parallel orientation. This is shown by the Barkhausen effect: as the magnetizing field is changed, the magnetization changes in thousands of tiny discontinuous jumps as the domain walls suddenly "snap" past defects.

This magnetization as a function of the external field is described by a hysteresis curve. Although this state of aligned domains found in a piece of magnetized ferromagnetic material is not a minimal-energy configuration, it is metastable, and can persist for long periods, as shown by samples of magnetite from the sea floor which have maintained their magnetization for millions of years.

Heating and then cooling (annealing) a magnetized material, subjecting it to vibration by hammering it, or applying a rapidly oscillating magnetic field from a degaussing coil tends to release the domain walls from their pinned state, and the domain boundaries tend to move back to a lower energy configuration with less external magnetic field, thus "demagnetizing" the material.

Commercial magnets are made of "hard" ferromagnetic or ferrimagnetic materials with very large magnetic anisotropy such as alnico and ferrites, which have a very strong tendency for the magnetization to be pointed along one axis of the crystal, the "easy axis". During manufacture the materials are subjected to various metallurgical processes in a powerful magnetic field, which aligns the crystal grains so their "easy" axes of magnetization all point in the same direction. Thus the magnetization, and the resulting magnetic field, is "built in" to the crystal structure of the material, making it very difficult to demagnetize.

As the temperature increases, thermal motion, or entropy, competes with the ferromagnetic tendency for dipoles to align. When the temperature rises beyond a certain point, called the Curie temperature, there is a second-order phase transition and the system can no longer maintain a spontaneous magnetization, so its ability to be magnetized or attracted to a magnet disappears, although it still responds paramagnetically to an external field. Below that temperature, there is a spontaneous symmetry breaking and magnetic moments become aligned with their neighbors. The Curie temperature itself is a critical point, where the magnetic susceptibility is theoretically infinite and, although there is no net magnetization, domain-like spin correlations fluctuate at all length scales.

The study of ferromagnetic phase transitions, especially via the simplified Ising spin model, had an important impact on the development of statistical physics. There, it was first clearly shown that mean field theory approaches failed to predict the correct behavior at the critical point (which was found to fall under a "universality class" that includes many other systems, such as liquid-gas transitions), and had to be replaced by renormalization group theory.




</doc>
<doc id="11809" url="https://en.wikipedia.org/wiki?curid=11809" title="Francesco Cossiga">
Francesco Cossiga

Francesco Cossiga (, ; 1928 – 2010) was an Italian politician. A member of the Christian Democratic Party of Italy, he was Prime Minister of Italy from 1979 to 1980 and the eighth President of Italy from 1985 to 1992. Cossiga is widely considered one of the most prominent and influential politicians of the First Republic.

Cossiga also served as minister on several occasions, most notably as Italian Minister of the Interior. In that position he re-structured the Italian police, civil protection and secret services. Due to his repressive approach to public protests, he has been described as a strongman and labeled "iron minister". He was in office at the time of the kidnapping and murder of Aldo Moro by Red Brigades, and resigned as Minister of the Interior when Moro was found dead in 1978. Cossiga was Prime Minister during the Bologna station bombing in 1980.

Before his political career, Cossiga was a professor of constitutional law at the University of Sassari.

Francesco Cossiga was born in Sassari on 26 July 1928, into a republican and anti-fascist middle-bourgeois family. He was the second-degree cousin of Enrico and Giovanni Berlinguer. Although he was commonly called "Cossìga", the original pronunciation of the surname is "Còssiga" . His surname in Sardinian and Sassarese means "Corsica", likely pointing to the family's origin.

At the age of sixteen, he graduated, three years in advance, at the classical lyceum Domenico Alberto Azuni. The following year he joined in the Christian Democracy, and three years later, at only 19 years old, he graduated in law and started a university career as professor of constitutional law at the faculty of jurisprudence of the University of Sassari.

During his period at the university he became a member of the Catholic Federation of University Students (FUCI), becoming the association's leader for Sassari.

After the 1958 general election Cossiga was elected in the Chamber of Deputies for the first time, representing the constituency of Cagliari–Sassari.

In February 1966 he became the youngest Undersecretary of the Ministry of Defence, in the government of Aldo Moro. In this role he had to face the aftermath of Piano Solo, an envisaged plot for an Italian "coup d'état" requested by then President Antonio Segni, two years before.

From November 1974 to February 1976 Cossiga was Minister of Public Administration in Moro's fourth government.

On 12 February 1976, Cossiga was appointed Minister of the Interior, by Prime Minister Moro. During his term he re-structured the Italian police, civil protection and secret services. Cossiga has been often described as a strongman and labeled "iron minister", for repressing public protests. Moreover, during his tenure his surname was often stylized as "Koiga", using the "SS" symbol.

In 1977 the city of Bologna was the scene of violent street clashes. In particular, on March 11 a militant of the far-left organization "Lotta Continua", Francesco Lorusso, was killed by a gunshot to the back (probably fired by a policeman), when police dispersed protesters against a mass meeting of Communion and Liberation, which was being held that morning at the University. This event served as a detonator for a long series of clashes with security forces for two days, which affected the entire city of Bologna.
Cossiga sent armored vehicles into the university area and other hot spots of the city to quell what he perceived as guerrilla warfare. Clashes with the police caused numerous casualties among people who got caught up in the riots, including uninvolved locals. No old leftist party, except the Youth Socialist Federation, led by local secretary Emilio Lonardo, participated at the funeral of the student Lorusso, showing the dramatic split between the movement and the historical left parties.

Turin was also the scene of bloody clashes and attacks. On October 1, 1977, after a procession had started with an attack on the headquarters of the Italian Social Movement (MSI), a group of militants of "Lotta Continua" reached a downtown bar, "L'angelo azzurro" (The Blue Angel), frequented by young right-wing activists. They threw two Molotov cocktails, and Roberto Crescenzio, a totally apolitical student, died of burns. The perpetrators of the murder were never identified. "Lotta Continua" leader Silvio Viale called it a "tragic accident".

Another innocent victim of the riots of that year was Giorgiana Masi, who was killed in Rome by a gunshot during an event organized by the Radical Party to celebrate the third anniversary of the victory in the referendum on divorce. As the perpetrators of the murder remained unknown, the movement attributed the responsibility of the crime to police officers in plain clothes, which were immortalized at that time dressed in clothing of the style of young people of the movement.

Cossiga was in office at the time of the kidnapping and murder of the Christian Democratic leader Aldo Moro by the Marxist-Leninist extreme-left terrorist group Red Brigades. On the morning of 16 March 1978, the day on which the new cabinet led by Giulio Andreotti was supposed to have undergone a confidence vote in the Italian Parliament, the car of Moro, former prime minister and then president of DC, was assaulted by a group of Red Brigades terrorists in Via Fani in Rome. Firing automatic weapons, the terrorists killed Moro's bodyguards, (two Carabinieri in Moro's car and three policemen in the following car) and kidnapped him.

Cossiga formed immediately two "crisis committees". The first one was a technical-operational-political committee, chaired by Cossiga himself and, in his absence, by undersecretary Nicola Lettieri. Other members included the supreme commanders of the Italian Police Forces, of the Carabinieri, the Guardia di Finanza, the recently named directors of SISMI and SISDE (respectively, Italy's military and civil intelligence services), the national secretary of CESIS (a secret information agency), the director of UCIGOS and the police prefect of Rome. The second one was an information committee, including members of CESIS, SISDE, SISMI and SIOS, another military intelligence office.
A third unofficial committee was created which never met officially, called the "comitato di esperti" ("committee of experts"). Its existence was not disclosed until 1981, by Cossiga himself, in his interrogation by the Italian Parliament's Commission about the Moro affair. He omitted to reveal the decisions and the activities of the committee however. This committee included: Steve Pieczenik, a psychologist of the anti-terrorism section of the US State Department, and notable Italian criminologists. Pieczenik later declared that there were numerous leaks about the discussions made at the committee, and accused Cossiga.

However, on 9 May 1978 Moro's body was found in the trunk of a Renault 4 in Via Caetani after 55 days of imprisonment, during which Moro was submitted to a political trial by the so-called "people's court" set up by the Brigate Rosse and the Italian government was asked for an exchange of prisoners. Despite the common interpretation, the car location in Via Caetani was not halfway between the locations of the national offices of DC and of the Italian Communist Party (PCI) in Rome. After two days, Cossiga resigned as Minister of the Interior. According to Italian journalist Enrico Deaglio, Cossiga, to justify his lack of action, "accused the leaders of CGIL and of the Communist Party of knowing where Moro was detained". Cossiga was also accused by Moro himself, in his letters who wrote during his detention, saying that "his blood will fall over him".

One year after Moro's death and the subsequent Cossiga's resignation as Interior Minister, he was appointed Prime Minister of Italy. He led a government's coalition composed by Christian Democrats, Socialists, Democratic Socialists, Republicans and Liberals.

Cossiga was head of the government during the Bologna massacre, a terrorist bombing of the Bologna Central Station on the morning of 2 August 1980, which killed 85 people and wounded more than 200. The attack was attributed to the neo-fascist terrorist organization "Nuclei Armati Rivoluzionari" (Armed Revolutionary Nucleus), which always denied any involvement; other theories have been proposed, especially in correlation with the strategy of tension.

Francesco Cossiga first assumed the explosion to have been caused by an accident (the explosion of an old boiler located in the basement of the station). Nevertheless, soon the evidence gathered on site of the explosion made it clear that the attack constituted an act of terrorism. "L'Unità", the newspaper of the Communist Party on 3 August already attributed responsibility for the attack to neo-fascists. Later, in a special session to the Senate, Cossiga supported the theory that neofascists were behind the attack, "unlike leftist terrorism, which strikes at the heart of the state through its representatives, black terrorism prefers the massacre because it promotes panic and impulsive reactions."
Later, according to media reports in 2004, taken up again in 2007, Cossiga, in a letter addressed to Enzo Fragala, leader of the National Alliance section in the Mitrokhin Committee, suggested Palestinian involvement of George Habash's Popular Front for the Liberation of Palestine and the Separat group of Ilich Ramirez Sanchez, known as "Carlos the Jackal". In addition, in 2008 Cossiga gave an interview to "BBC" in which it reaffirmed his belief that the massacre would not be attributable to black terrorism, but to an "incident" of Palestinian resistance groups operating in Italy. He declared also being convinced of the innocence of Francesca Mambro and Giuseppe Valerio Fioravanti, the two neo-fascist terrorists accused of the massacre. The PFLP has always denied responsibility.

In October 1980, Cossiga resigned as Prime Minister after the rejection of the financial law by the Italian Parliament.

Following the 1983 general election, Cossiga became a member of the Italian Senate; on 12 July, he was elected President of the Senate.

In the 1985 presidential election, Cossiga was elected as President of Italy with 752 votes out of 977. His candidacy was endorsed by the Christian Democracy, but supported also by communists, socialists, social democrats, liberals and republicans. This was the first time an Italian presidential candidate had won the election on the first ballot, where a two thirds majority is necessary.

The Cossiga presidency was essentially divided into two phases related to the attitudes of the head of state. In the first five years, Cossiga played its role in a traditional way, caring for the role of the republican institutions under the Constitution, which makes the President of the Republic a kind of arbitrator in relations between the powers of the state.

It was in his last two years as President that Cossiga began to express some unusual opinions regarding the Italian political system. He opined that the Italian parties, especially the Christian Democrats and the Communists had to take into account the deep changes brought about by the fall of the Berlin Wall and the end of the Cold War. According to him, DC and PCI would therefore have been seriously affected by this change, but Cossiga believed that political parties and the same institutions refused to recognize it.
Thus, a period of conflict and political controversy began, often provocative and deliberately excessive, and with very strong media exposure. These statements, soon dubbed ""esternazioni"", or "mattock blows" ("picconate"), were considered by many to be inappropriate for a President, and often beyond his constitutional powers; also, his mental health was doubted and Cossiga had to declare "I am the fake madman who speaks the truth." Cossiga suffered from bipolar disorder and depression in the last years of his life.

Among the statements of the President there were also allegations of excessive politicization of the judiciary system, and the stigmatization of the fact that young magistrates, who just came into service, were immediately destined for the Sicilian prosecutor to carry out mafia proceedings.

For his changed attitude, Cossiga received various criticisms by almost every party, with the exception of the Italian Social Movement, which stood beside him in defense of the "picconate". He will, amongst other things, be considered one of the first "cleansers" of MSI, who recognized it as a constitutional and democratic force.

Tension developed between Cossiga and Prime Minister Giulio Andreotti. This tension emerged when Andreotti revealed the existence of Gladio, a stay-behind organization with the official aim of countering a possible Soviet invasion through sabotage and guerrilla warfare behind enemy lines. Cossiga acknowledged his involvement in the establishment of the organization. The Democratic Party of the Left (successor to the Communist Party) started the procedure of impeachment (Presidents of Italy can be impeached only for high treason against the State or for an attempt to overthrow the Constitution). Although he threatened to prevent the impeachment procedure by dissolving Parliament, the impeachment request was ultimately dismissed.

Cossiga resigned two months before the end of his term, on 25 April 1992. In his last speech as President he stated "To young people I want to say to love the fatherland, to honor the nation, to serve the Republic, to believe in freedom and to believe in our country".

According to the Italian Constitution, after his resignation from the office of President, Cossiga became senator for life, joining his predecessors in the upper house of Parliament, with whom he also shared the title of President Emeritus of the Italian Republic.

In February 1998, Cossiga created the Democratic Union for the Republic (UDR), a Christian democratic political party, declaring it to be politically central. The UDR was a crucial component of the majority that supported the Massimo D'Alema government in October 1998, after the fall of the Romano Prodi's government which lost a vote of confidence. Cossiga declared that his support for D'Alema was intended to end the conventional exclusion of the former communist leaders from the premiership in Italy.

In 1999 UDR was dissolved and Cossiga returned to his activities as a senator, with competences in the Military Affairs' Commission.

In May 2006, Cossiga gave his support to the formation of Prodi's second government. In the same month, he brought in a bill that would allow the region of South Tyrol to hold a referendum, where the local electorate could decide whether to remain within the Republic of Italy, take independence, or become part of Austria again.

On 27 November 2006, he resigned from his position as a lifetime senator. His resignation was, however, rejected on 31 January 2007 by a vote of the Senate.

In May 2008, Cossiga voted in favor of the government of Silvio Berlusconi.

Cossiga died on 17 August 2010 from respiratory problems at the Agostino Gemelli Polyclinic. After his death, four letters written by Cossiga were sent to the four highest authorities of the state in office at the time of his death, President of the Republic Giorgio Napolitano, President of the Senate Renato Schifani, President of the Chamber of Deputies Gianfranco Fini and Prime Minister Silvio Berlusconi.

The funeral took place in his hometown, Sassari, at the Church of San Giuseppe. Cossiga is buried in the public cemetery of Sassari, in the family tomb, not far from the one of his predecessor as President of Italy, Antonio Segni.

In 2007, Cossiga wrote (referring to the 2001 September 11 attacks): "all democratic circles in America and of Europe, especially those of the Italian centre-left, now know that the disastrous attack was planned and realized by the American CIA and Mossad with the help of the Zionist world, to place the blame on Arab countries and to persuade the Western powers to intervene in Iraq and Afghanistan". However, the previous year Cossiga had stated that he rejects theoretical conspiracies and that it "seems unlikely that September 11 was the result of an American plot."

In the same statement, Cossiga claimed that a video tape circulated by Osama bin Laden's al Qaeda and containing threats against Silvio Berlusconi was "produced in the studios of Mediaset in Milan" and forwarded to the "Islamist Al-Jazeera television network." The purpose of that video tape (which was actually an audio tape) was to raise "a wave of solidarity to Berlusconi" who was, at the time, facing political difficulties.

In 2008, Francesco Cossiga said that Mario Draghi was "a craven moneyman".

Cossiga blamed the loss of Itavia Flight 870, a passenger jet that crashed in 1980 with the loss of all 81 people on board, on a missile fired from a French Navy aircraft. On 23 January 2013 Italy's top criminal court ruled that there was "abundantly" clear evidence that the flight was brought down by a missile.

As President of the Republic, Cossiga was Head (and also Knight Grand Cross with Grand Cordon) of the Order of Merit of the Italian Republic (from 3 July 1985 to 28 April 1992), Military Order of Italy, Order of the Star of Italian Solidarity, Order of Merit for Labour and Order of Vittorio Veneto and Grand Cross of Merit of the Italian Red Cross. He has also been given honours and awards by other countries.



</doc>
<doc id="11812" url="https://en.wikipedia.org/wiki?curid=11812" title="Lockheed Martin F-35 Lightning II">
Lockheed Martin F-35 Lightning II

The Lockheed Martin F-35 Lightning II is a family of single-seat, single-engine, all-weather, stealth multirole combat aircraft, designed for ground-attack and air-superiority missions. The aircraft was developed and is built by Lockheed Martin and its subcontractors, which include Northrop Grumman, Pratt & Whitney, and BAE Systems. The F-35 has three main variants: the conventional takeoff and landing F-35A (CTOL), the short take-off and vertical-landing F-35B (STOVL), and the carrier-based F-35C (CV). 

The aircraft descends from the Lockheed Martin X-35, which in 2001 beat the Boeing X-32 to win the Joint Strike Fighter (JSF) program. Its development is principally funded by the United States, with additional funding coming from program partners from NATO and close U.S. allies, including the United Kingdom, Italy, Australia, Canada, Norway, Denmark, the Netherlands, and formerly Turkey. The partners generally receive subcontracts to manufacture F-35 components. Several other countries have ordered, or are considering ordering, the aircraft.

The program has drawn much scrutiny and criticism for its unprecedented size, complexity, ballooning costs, and much-delayed deliveries. The decision to start buying the plane while it was still in development and testing led to expensive design changes and retrofits. By 2014, the program was "US$163 billion over budget [and] seven years behind schedule". Critics contended that the high sunk costs and politics made the F-35 "too big to kill".

The F-35 entered service in July 2015, when the U.S. Marine Corps declared its first F-35B squadron ready for deployment. The U.S. Air Force declared its F-35A ready in August 2016 and the U.S. Navy its F-35C in February 2019. The F-35 was first used in combat in 2018, by the Israeli Air Force. In service, some USAF pilots have nicknamed the aircraft "Panther" in lieu of the official "Lightning II". The U.S. plans to buy 2,663 F-35s through 2037, which will represent the bulk of the crewed tactical airpower of the U.S. Air Force, Navy, and Marine Corps for several decades. The aircraft are projected to operate until 2070.

The F-35 was the product of the Joint Strike Fighter (JSF) program, which was the merger of various combat aircraft programs from the 1980s and 1990s. One progenitor program was the Common Affordable Lightweight Fighter (CALF) which ran from 1983 to 1994; CALF was a renamed Defense Advanced Research Projects Agency's (DARPA) Advanced Short Take-Off/Vertical Landing (ASTOVL) program for a Harrier Jump Jet replacement for the U.K. Royal Navy and the U.S. Marine Corps (USMC). Under one of ASTOVL's classified programs, the Supersonic STOVL Fighter (SSF), Lockheed Skunk Works conducted research for a stealthy supersonic STOVL fighter intended for both U.S. Air Force (USAF) and USMC; a key technology explored was the shaft-driven lift fan system. Lockheed's concept was a single-engine canard delta aircraft weighing about empty.

In 1993, the Joint Advanced Strike Technology (JAST) program emerged following the USAF's Multi-Role Fighter (MRF) and U.S. Navy's (USN) Advanced Fighter-Attack (A/F-X) programs cancellations. MRF, a program for a relatively affordable F-16 replacement, was scaled back and delayed due to post-Cold War defense cuts easing the F-16 service life situation and increasing budget pressure from the USAF's F-22 program. The A/F-X, initially known as the Advanced-Attack (A-X), began in 1991 as the USN's follow-on to the Advanced Tactical Aircraft (ATA) program for an A-6 replacement; the resulting A-12 Avenger II was cancelled due to issues and cost overruns in 1991. In the same year, the termination of the Naval Advanced Tactical Fighter (NATF), an offshoot of USAF's Advanced Tactical Fighter (ATF) program, to replace the F-14 resulted in additional fighter capability being added to A-X, which was then renamed A/F-X. Amid increased budget pressure, the Department of Defenses (DoD) Bottom-Up Review (BUR) in September 1993 announced MRF's and A/F-X's cancellation, with applicable experience brought to the emerging JAST program. JAST was not meant to develop a new aircraft, instead developing requirements, maturing technologies, and demonstrating concepts for advanced strike warfare.

As JAST progressed, the need for concept demonstrator aircraft by 1996 emerged, which would coincide with the full-scale flight demonstrator phase of ASTOVL/CALF. Because the ASTOVL/CALF concept appeared to align with the JAST charter, the two programs were eventually merged in 1994 under the JAST name, with the program now serving the USAF, USMC, and USN. JAST was subsequently renamed the Joint Strike Fighter (JSF) program in 1995, with STOVL submissions by McDonnell Douglas, Northrop Grumman, Lockheed Martin, and Boeing. The JSF was expected to eventually replace large numbers of multi-role and strike fighters in the inventories of the US and its allies, including the Harrier, F-16, F/A-18, A-10, and F-117.

International participation is a key aspect of the JSF program, starting with United Kingdom participation in the ASTOVL program. Many international partners requiring modernization of their air forces that deployed the F-16 and F/A-18 were interested in the JSF. The United Kingdom joined JAST/JSF as a founding member in 1995 and thus became the only Tier 1 partner of the JSF program; Italy, the Netherlands, Denmark, Norway, Canada, Australia, and Turkey joined the program during the Concept Demonstration Phase (CDP), with Italy and the Netherlands being Tier 2 partners and the rest Tier 3. Consequently, the aircraft was developed in cooperation with international partners and available for export.

Boeing and Lockheed Martin were selected in early 1997 for CDP, with their demonstrator aircraft designated X-32 and X-35 respectively; the McDonnell Douglas team was eliminated, while Northrop Grumman and British Aerospace joined the Lockheed Martin team. Each firm would produce two prototype air vehicles to demonstrate conventional takeoff and landing (CTOL), carrier takeoff and landing (CV), and STOVL. Lockheed Martin's design would leverage the work on the shaft-driven lift fan (SDLF) system conducted under the ASTOVL/CALF program. The key aspect of the X-35 that enabled STOVL operation, the SDLF system consists of the lift fan in the forward center fuselage that could be activated by engaging a clutch that connects the drive shaft to one of the engine spools and thus augmenting the thrust from the engine's swivel nozzle. Research from prior aircraft incorporating similar systems, such as the Rockwell XFV-12 and Yakovlev Yak-141, were also taken into consideration. By contrast, Boeing's X-32 employed direct lift system that the augmented turbofan would be reconfigured to when engaging in STOVL operation.

Lockheed Martin commonality strategy was to replace the STOVL variant's SDLF with a fuel tank and the aft swivel nozzle with a two-dimensional thrust vectoring nozzle for the CTOL variant. This would enable identical aerodynamic configuration for the STOVL and CTOL variants, while the CV variant would have an enlarged wing in order to reduce landing speed for carrier recovery. Due to aerodynamic characteristics and carrier recovery requirements from the JAST merger, the design configuration would settle on a conventional tail compared to the canard delta design from the ASTOVL/CALF; notably, the conventional tail configuration offers much lower risk for carrier recovery compared to the ASTOVL/CALF canard configuration, which was designed without carrier compatibility in mind. This enabled greater commonality between all three variants, as commonality goal was still very high at this stage of the design. Lockheed Martin's prototypes would consist of the X-35A for demonstrating CTOL before converting it to the X-35B for STOVL demonstration and the larger-winged X-35C for CV compatibility demonstration.

The X-35A first flew on 24 October 2000 and conducted flight tests for subsonic and supersonic flying qualities, handling, range, and maneuver performance. After 28 flights, the aircraft was then converted into the X-35B for STOVL testing, with key changes including the addition of the SDLF, the three-bearing swivel nozzle (3BSD), and roll-control ducts. The X-35B would successfully demonstrate the SDLF system by performing stable hover, vertical landing, and short takeoff in less than . The X-35C first flew on 16 December 2000 and conducted field landing carrier practice tests.

On 26 October 2001, Lockheed Martin was declared the winner and was awarded the System Development and Demonstration (SDD) contract; Pratt & Whitney was separately awarded to develop the F135 engine for the JSF. The F-35 designation, which was out of sequence with standard DoD numbering, was allegedly determined on the spot by program manager Major General Mike Hough; this came as a surprise even to Lockheed Martin, which had expected the "F-24" designation for the JSF.

As the JSF program moved into the SDD phase, the design would evolve into a full weapon system, thus resulting in the F-35 having several differences from the X-35 demonstrator. The forward fuselage was lengthened by to make room for mission systems avionics, while the horizontal stabilizers were correspondingly moved aft to retain balance and control. The diverterless supersonic inlet changed from a four-sided to a three-sided cowl shaped and was moved aft. The fuselage section was fuller, the top surface raised by along the centerline to accommodate weapons bays. Following the designation of the X-35 prototypes, the three variants were designated F-35A (CTOL), F-35B (STOVL), and F-35C (CV).

Adding the expected systems of a fighter aircraft led to substantial weight increases; the F-35B was most affected by weight growth, largely due to a decision in 2003 to increase the weapons bays' size for commonality between variants; the total weight growth was reportedly up to , over 8%, causing all STOVL key performance parameter (KPP) thresholds to be missed. In December 2003, the STOVL Weight Attack Team (SWAT) was formed to reduce the weight increase; changes included more engine thrust, thinned airframe members, smaller weapons bays and vertical stabilizers, less thrust fed to the roll-post outlets, and redesigning the wing-mate joint, electrical elements, and the airframe immediately aft of the cockpit. Many changes from the SWAT effort were applied to all three variants for commonality. By September 2004, these efforts had reduced the F-35B's weight by over , while the F-35A and F-35C were reduced in weight by and respectively. The weight reduction work cost $6.2 billion and caused an 18 month delay. 

The first F-35A prototype flew on 15 December 2006. Testing found several major issues, including cracking of early F-35B airframes, unreliable F-35C arrestor hook design, fuel tank lightning strike risks, and helmet display issues. Furthermore, software was repeatedly delayed due to the unprecedented scope and complexity involved. Issues and corrective measures caused schedule delays, including a program re-baseline in 2011, pushing the Initial Operating Capability (IOC) from the planned 2010 out to July 2015. As a result of weight optimization efforts and each variant's unique requirements, the anticipated commonality of 70% was not achieved, declining to 25%. The concurrency of testing, defect correction, and initial production was also criticized as inefficient. The program received considerable criticism for cost overruns and for the total projected lifetime cost of the F-35.

A USN study in 2010 found that the F-35 will cost 30 to 40% more to maintain than current fighters, not accounting for inflation over its lifetime. A Pentagon study concluded a $1 trillion maintenance cost for the entire fleet over its lifespan without inflation. The F-35 program office found that as of January 2014, fleetwide costs over a 53-year lifecycle totalled $857 billion, while unit costs had been dropping and accounted for the 22 percent life cycle drop since 2010. Lockheed stated that by 2019, F-35 pricing will be less than fourth-generation fighters. An F-35A in 2019 is expected to cost $85 million per unit complete with engines and full mission systems, inflation adjusted from $75 million in December 2013. By 2017, the program was expected to cost $406.5 billion over its lifetime (i.e. until 2070) for acquisition, and an additional $1.1 trillion for operations and maintenance, totaling $1.5 trillion for its estimated lifetime costs.

The F-35 is a family of single-engine, supersonic, stealth multirole fighters. The second fifth generation fighter to enter US service and the first operational supersonic STOVL stealth fighter, the F-35 emphasizes low observables, advanced avionics and sensor fusion that enable a high level of situational awareness and long range lethality; the USAF considers the aircraft its primary strike fighter for conducting suppression of enemy air defense (SEAD) missions, owing to the advanced sensors and mission systems.

The F-35 is much heavier than the lightweight fighters it replaces, the lightest variant has an empty weight of ; much of the weight can be attributed to the internal weapons bays and the extensive avionics carried. It has a wing-tail configuration with two vertical stabilizers canted for stealth. Flight control surfaces include leading-edge flaps, flaperons, rudders, and all-moving horizontal tails (stabilators); leading edge root extensions also run forwards to the inlets. The relatively short 35-foot wingspan of the F-35A and F-35B is set by the requirement to fit inside USN amphibious assault ship parking areas and elevators; the F-35C's larger wing is more fuel efficient. The fixed diverterless supersonic inlets (DSI) use a bumped surface to shed the boundary layer from the forebody from the inlet duct; the inlets form a Y-duct for the Pratt & Whitney F135 turbofan engine.

While lacking the raw performance of the larger twin-engine F-22, the F-35 has kinematics competitive with fourth generation fighters such as the F-16 and F/A-18, especially with ordnance mounted; the F-35's internal weapons carriage eliminates drag from external stores. The powerful F135 engine gives good subsonic acceleration and energy, although supersonic performance is limited. The large stabilitors, leading edge extensions and flaps, and canted rudders provide excellent high alpha (angle-of-attack) characteristics, with a trimmed alpha of 50°. Relaxed stability and fly-by-wire controls provide excellent handling qualities and departure resistance. All variants have a design top speed of Mach 1.6, attainable with full internal payload. Having over double the F-16's internal fuel, the F-35 has considerably greater combat radius, while stealth also enables a more efficient mission flight profile.

The F-35 is designed to be less maintenance-intensive than prior stealth aircraft. Compared to older high-maintenance radar-absorbent material (RAM) coatings, the F-35's coatings consist of a fibermat baked into the skin. The flight control system uses electro-hydrostatic actuators rather than traditional hydraulic systems for lower maintenance needs; these controls can be powered by on-board lithium-ion batteries in case of emergency. Structurally, the F-35 drew upon lessons from the F-22; composites comprise 35% of airframe weight, with the majority being bismaleimide and composite epoxy materials. Newer production lots include some structural nanocomposites, such as carbon nanotube-reinforced epoxy. After corrosion issues on the F-22, the F-35 uses a less galvanic corrosion-inducing skin gap filler, and also has fewer gaps in the airframe skin needing filler and better drainage.

The F-35 has two internal weapons bays with four weapons stations. Internal carriage of weapons preserves the aircraft's stealthy outer mold line and also eliminates additional parasitic drag from external stores. The two outboard weapon stations each can carry ordnance up to , or for F-35B, while the two inboard stations carry smaller weapons such as air-to-air missiles. Air-to-surface weapons include the Joint Direct Attack Munition (JDAM), Paveway series of bombs, Joint Standoff Weapon (JSOW), and cluster munitions (Wind Corrected Munitions Dispenser). The outboard station can carry multiple smaller munitions such as the GBU-39 Small Diameter Bombs (SDB), GBU-53/B SDB II, and the SPEAR 3 anti-tank missiles; up to four SDBs can be carried per station for the F-35A and F-35C, and three for F-35B. The internal inboard station can carry the AIM-120 AMRAAM.

The aircraft can use six external weapons stations for missions that do not require stealth. The wingtip pylons each can carry an AIM-9X or AIM-132 ASRAAM and are canted outwards to reduce their radar cross-section. Additionally, each wing has a inboard station and a middle station, or for F-35B. The external wing stations can carry large air-to-surface weapons that would not fit inside the weapons bays such as the AGM-158 Joint Air to Surface Stand-off Missile (JASSM) cruise missile. An air-to-air missile load of eight AIM-120s and two AIM-9s is possible using internal and external weapons stations; a configuration of six bombs, two AIM-120s and two AIM-9s can also be arranged.

The F-35A is armed with a 25 mm GAU-22/A rotary cannon mounted internally near the left wing root with 182 rounds carried. The F-35B and F-35C have no internal gun and instead can use a Terma A/S multi-mission pod (MMP) carrying the GAU-22/A and 220 rounds; the pod is mounted on the centerline of the aircraft and shaped to reduce its radar cross-section. In lieu of the gun, the pod can also be used for different equipment and purposes, such as electronic warfare, aerial reconnaissance, or rear-facing tactical radar. Both hypersonic missiles and direct energy weapons such as solid-state laser are currently being considered as future upgrades. Lockheed Martin is studying integrating a fiber laser that uses spectral beam combining to channel energy from multiple individual laser modules into a single, high-power beam, which can be scaled up or down for various levels of effects.

Work is currently underway to integrate additional weapons beyond the Block 3 baseline. Lockheed Martin is developing a weapon rack that would enable the internal outboard station to carry two AIM-120s, thus increasing the internal air-to-air payload to six missiles, currently planned for Block 4. Block 4 will also have a rearranged hydraulic line and bracket to allow the F-35B to carry four SDBs per internal outboard station; integration of the MBDA Meteor and Brimstone is also planned. The USAF and USN are planning to integrate the AGM-88G AARGM-ER internally in the F-35A and F-35C. Norway and Australia are funding an adaptation of the Naval Strike Missile (NSM) for the F-35; designated Joint Strike Missile (JSM), two missiles can be carried internally with an additional four externally. Nuclear weapons delivery via internal carriage of the B61 nuclear bomb is planned for Block 4B in 2024.

The USAF plans for the F-35A to take up the close air support (CAS) mission in contested environments; amid criticism that it is not as well suited as a dedicated attack platform, USAF chief of staff Mark Welsh placed a focus on weapons for CAS sorties, including guided rockets, fragmentation rockets that shatter into individual projectiles before impact, and more compact ammunition for higher capacity gun pods. Fragmentary rocket warheads create greater effects than cannon shells as each rocket creates a "thousand-round burst", delivering more projectiles than a strafing run. Some weapons may use the helmet-mounted cueing system to aim, thus not needing to point the nose at targets. Institute for the Study of War's Christopher Harmer queried using such an expensive aircraft for CAS.

The glass cockpit was designed to provide the pilot with a high level of situational awareness. The main display is a 20- by 8-inch (50 by 20 cm) panoramic touchscreen, which shows flight instruments, stores management, navigation, and targeting information; the arrangement of the display information can be customized by the pilot. A smaller stand-by display is located below the main display. The cockpit also uses speech-recognition system, developed by Adacel. Notably, the F-35 does not have a head-up display, and instead presents flight and combat information through a helmet-mounted display system (HMDS). The tinted canopy is single-piece and has an internal frame for structural strength. The ejection seat is the Martin-Baker US16E ejection seat and is launched via a twin-catapult system housed on side rails. The hands on throttle-and-stick HOTAS system consists of the right-hand side stick and throttle. For life support, an onboard oxygen-generation system (OBOGS) is fitted.

A key piece of the F-35's human-machine interface is the HMDS. Replacing the heads-up display of earlier fighters, the HMDS presents relevant flight and combat information to the pilot regardless of the head orientation; sensors use combined radio frequency and infrared to continually track nearby aircraft while the pilot's HMDS displays and selects targets. Infrared and night vision imagery from the Distributed Aperture System can be displayed directly on the HMDS and enables to pilot to "see through" the aircraft. The system enables the F-35 to employ weapons without physically pointing at its target by cuing missile seekers at high angles off-boresight. Each helmet costs $400,000. The HMDS weights more than tradition helmets, and there is concern that it can endanger lightweight pilots during ejection.

Due to the HMDS's vibration, jitter, night-vision and sensor display problems during development, Lockheed Martin and Elbit issued a draft specification in 2011 for an alternative HMDS based on the Anvis-9 night vision goggles as backup, with BAE Systems chosen later that year. A cockpit redesign is needed to adopt an alternative HMDS. Following progress on the baseline helmet, development on the alternative HMDS was halted in October 2013. In 2013, in spite of sustained HDMS problems, the F-35B completed 19 nighttime vertical landings on board USS "Wasp" at sea, by using the DAS instead of the helmet's night vision capability, which offered at best 20/35 vision. In 2016, a Gen 3 helmet featuring an improved night vision camera, new liquid crystal displays, automated alignment and other software enhancements was introduced with low rate initial production (LRIP) lot 7.

The Pratt & Whitney F135 powers the F-35. An alternative engine, the General Electric/Rolls-Royce F136, was being developed until it was canceled by its manufacturers in December 2011 due to lack of funding from the Pentagon. The F135 and F136 engines are not designed to supercruise. However, the F-35 can briefly fly at Mach 1.2 for 150 miles without the use of an afterburner. The F135 is the second (radar) stealthy afterburning jet engine. Like the Pratt & Whitney F119 from which it was derived, the F135 has suffered afterburner pressure pulsations, or 'screech' at low altitude and high speed.
The STOVL F-35B is outfitted with the Rolls-Royce LiftSystem, designed by Lockheed Martin and developed by Rolls-Royce. This system is more similar to the German VJ 101D/E than the preceding STOVL Harrier Jump Jet and the Rolls-Royce Pegasus engine. The Lift System is composed of a lift fan, drive shaft, two roll posts and a "Three Bearing Swivel Module" (3BSM). The 3BSM is a thrust vectoring nozzle which allows the main engine exhaust to be deflected downward at the tail of the aircraft. The lift fan is near the front of the aircraft and provides a counterbalancing thrust using two counter-rotating blisks. It is powered by the engine's low-pressure (LP) turbine via a drive shaft and gearbox. Roll control during slow flight is achieved by diverting unheated engine bypass air through wing-mounted thrust nozzles called Roll Posts.

F136 funding came at the expense of other program elements, impacting on unit costs. The F136 team stated their engine had a greater temperature margin, valuable for VTOL operations in 'hot & high' conditions. Partly in response to GE's claims that the F136 can produce more thrust than the of early F135s, P&W tested higher thrust versions, demonstrating a maximum thrust of over ; making it the most powerful engine ever installed in a fighter as of 2010. It is heavier than previous fighter engines; the Heavy Underway Replenishment system needed to transfer an F135 between ships is an unfunded USN requirement. Thermoelectric-powered sensors monitor turbine bearing health. In May 2017, P&W announced the F135 Growth Option 1 had finished testing and was production ready; it offers a improvement of 6–10% thrust across the flight envelope while also getting a 5–6% fuel burn reduction. Upgrading requires changing the power module on older engines, it can be seamlessly added to future engines at a low unit cost rise and no impact to delivery schedule.

In 2016, the Adaptive Engine Transition Program (AETP) was launched to develop and test adaptive cycle engines, with one major potential application being the re-engining of the F-35. Both GE and P&W were awarded contracts to develop class demonstrators, with the designations XA100 and XA101 respectively.

The F-35 was designed to be supported by a computerized maintenance management system named Autonomic Logistics Information System (ALIS); due to numerous issues, such as security vulnerabilities and excessive connectivity requirements, it is planned to replace ALIS with the cloud-based Operational Data Integrated Network (ODIN) by 2022. In concept, any aircraft can be serviced at any F-35 maintenance facility and for all parts to be globally tracked and shared as needed. Commonality between the different variants allowed the USMC to create their first aircraft maintenance Field Training Detachment to apply the USAF's lessons to their F-35 operations. It has been designed for ease of maintenance, 95% of all field-replaceable parts "one deep" where nothing else needs removal to reach the desired part; for instance, the ejection seat can be replaced without removing the canopy. Other features include using electro-hydrostatic actuators instead of hydraulics and an all-composite skin free of the fragile coatings of earlier stealth aircraft.

In 2012, the F-35 Joint Program Office stated that both pilots and maintainers gave positive feedback, suggesting better performance than predecessors at a similar development stage and that the type was relatively stable from a maintenance standpoint. This was attributed to more extensive maintenance training of F-35 maintainers than on the F-22 Raptor; the stealth coatings are also easier to work with than those of the F-22. Cure times for coating repairs are lower while many fasteners and access panels are not coated, reducing maintenance workload. Some radar-absorbent materials are baked into the composite skin, slowing the degradation of its stealthy signature. Its stealth characteristics makes it still harder to maintain than fourth-generation aircraft.

The DOT&E Report on the F-35 program of January 2015 determined that the plane has not reached any of the nine reliability measures it was supposed to achieve by this point, and that the Joint Program Office had re-categorizing failure incidents to make it look more reliable. Further, its complexity meant that no Service was ready to maintain it, instead being reliant on "contractor support and unacceptable workarounds". DOT&E found that the F-35 achieved 61 percent of planned flight hours and that the average availability rate was as low as 28 percent for the F-35A and 33 percent for the F-35B. The program created a new flight hour projection "since low availability was preventing the full use of bed-down plan flight hours". According to the USAF Assistant Secretary for Financial Management, in FY2014, each non-test F-35 flew only 7.7 hours per month, amounting to approximately one sortie every 5.5 days—for combat purposes, a sortie rate so low as to be crippling. Mean flight hours between removal (MFHBR) had increased but was only 59 percent to 65 percent of the required threshold. DOT&E found that mean corrective maintenance time for critical failures got worse for the F-35A and the F-35C over the year prior. Structural cracking also proved to be a persistent problem as of 2015.

The F-35's sensor and communications suite has situational awareness, command and control and network-centric warfare capabilities. The main sensor is the AN/APG-81 active electronically scanned array-radar, designed by Northrop Grumman Electronic Systems. It is augmented by the nose-mounted Electro-Optical Targeting System (EOTS), it provides the capabilities of an externally mounted Sniper Advanced Targeting Pod with a reduced radar cross-section. The AN/ASQ-239 (Barracuda) system is an improved version of the F-22's AN/ALR-94 electronic warfare suite, providing sensor fusion of radio frequency and infrared tracking functions, advanced radar warning receiver including geolocation threat targeting, multispectral image countermeasures for self-defense against missiles, situational awareness and electronic surveillance, employing 10 radio frequency antennas embedded into the edges of the wing and tail. In September 2015, Lockheed unveiled the "Advanced EOTS" that has short-wave infrared, high-definition television, infrared marker, and superior image detector resolution capabilities. Offered for the Block 4 configuration, it fits into the same area as the baseline EOTS with minimal changes while preserving stealth features.

Six additional passive infrared sensors are distributed over the aircraft as part of Northrop Grumman's electro-optical AN/AAQ-37 Distributed Aperture System (DAS), which acts as a missile warning system, reports missile launch locations, detects and tracks approaching aircraft spherically around the F-35, and replaces traditional night vision devices. All DAS functions are performed simultaneously, in every direction, at all times. The electronic warfare systems are designed by BAE Systems and include Northrop Grumman components. Functions such as the Electro-Optical Targeting System and the electronic warfare system are not usually integrated on fighters. A DAS sensor mounted in a test platform detected a two-stage ballistic missile launch 1,300 kilometers away.
The communications, navigation and identification (CNI) suite, designed by Northrop Grumman, includes the Multifunction Advanced Data Link (MADL), as one of a half dozen different physical links. The F-35 is the first fighter with sensor fusion that combines radio frequency and IR tracking for continuous all-direction target detection and identification which is shared via MADL to other platforms without compromising low observability. Link 16 is present for communication with legacy systems. The F-35 was designed with sensor intercommunication to provide a cohesive image of the local battlespace and availability for any possible use and combination with one another; for example, the AN/APG-81 radar also acts as a part of the electronic warfare system. Program Executive Officer General Bogdan described the sensor fusion software as one of the program's most difficult parts.

Much of the F-35's software is written in the C and C++ programming languages because of programmer availability; Ada83 code also is reused from the F-22. The Integrity DO-178B real-time operating system (RTOS) from Green Hills Software runs on COTS Freescale PowerPC processors. High-speed data networking including IEEE 1394b and Fibre Channel The final Block 3 software is planned to have 8.6 million lines of code. In 2010, Pentagon officials found that more software may be needed. General Norton Schwartz claimed software was the biggest factor that might delay the USAF's initial operational capability. In 2011, Michael Gilmore, Director of Operational Test & Evaluation, noted: "the F-35 mission systems software development and test is tending towards familiar historical patterns of extended development, discovery in flight test, and deferrals to later increments". 

The electronic warfare and electro-optical systems are intended to detect and scan aircraft, allowing engagement or evasion of a hostile aircraft prior to being detected. The CATbird avionics testbed aircraft has proved capable of detecting and jamming radars, including the F-22's AN/APG-77. The F-35 was previously considered a platform for the Next Generation Jammer; attention shifted to using unmanned aircraft in this capacity instead. Several subsystems use Xilinx FPGAs; these COTS components enable supply refreshes from the commercial sector and fleet software upgrades for the software-defined radio systems.

Lockheed Martin's Dave Scott stated that sensor fusion boosts engine thrust and oil efficiency, increasing the aircraft's range. USAF official Ellen M. Pawlikowski proposed using the F-35 to control unmanned combat aerial vehicles (UCAVs) via its sensors and communications equipment; a single F-35 could orchestrate an attack made by up to 20 armed UCAVs.

The F-35 has a lower radar cross-section than the preceding fighter generation, due to its shape and the use of fiber-mat and other radar-absorbent materials. It is also designed to have lower infrared and visual signatures. Among the radar signature reduction features are chines that generate vortex lift in the same fashion as the SR-71 Blackbird. Small bumps just forward of the engine air intakes—part of the diverterless supersonic inlet, a simpler, lighter means to ensure high-quality airflow to the engine across numerous conditions—also eliminate radar reflections between the diverter and the aircraft's skinand reduce the amount of radar energy that reaches the engine fans to be reflected. Such reflection is also reduced by the Y-duct-type air intake ramps, which run parallel to the fuselage and indirectly to the engine fans. Care is taken during production to match the "boilerplate".

The F-35's radar-absorbent materials are designed to be more durable and require less maintenance than those on the F-117, B-2, and F-22. At some frequencies, the F-35 compares favorably to the F-22 in stealth, according to General Mike Hostage, commander of the Air Combat Command. Low-frequency radars can spot stealthy aircraft due to Rayleigh scattering; such radars are also conspicuous, susceptible to clutter, and lack precision. The F-35's anti-radar design is primarily focused on the higher-frequency X-band used by missile lock and targeting sensors, rendering them ineffective beyond close ranges. Ground crews use Repair Verification Radar test sets to ensure that a given repair has not increased its radar signature, which is not a concern for non-stealth aircraft.
Like the Fighter Teen Series (F-14, F-15, F-16, F/A-18), the F-35 can carry large external fuel tanks, but flies most missions without them to keep its radar signature low.

In 2008, USAF officials said the F-35 was about twice as loud as the McDonnell Douglas F-15 Eagle at takeoff and up to four times as loud during landing; residents near two potential F-35 bases—Luke Air Force Base, Arizona, and Eglin Air Force Base, Florida—requested environmental impact studies. In 2009, the city of Valparaiso, Florida, adjacent to Eglin AFB, threatened to sue over the impending F-35 arrival; this lawsuit was settled in March 2010. In 2009, testing reportedly revealed the F-35 was "as noisy as an F-16 fitted with a Pratt & Whitney F100-PW-200 engine", comparable to the F-22 and F/A-18E/F. A 2012 USAF environmental impact study found that replacing F-16s with F-35s at Tucson International Airport subjected more than 21 times as many residents to extreme noise levels. The USN sought ear protection for sailors due to the F-35's "thundering 152 decibels". In October 2014, the F-35 program office said that the F-35B's take-off noise was only two decibels higher than a Super Hornet, indistinguishable to the human ear, and is 10 decibels quieter when flying formations or landing.

The first F-35A (designated AA-1) was rolled out in Fort Worth, Texas, on 19 February 2006. In September 2006, the first engine run of the F135 in an airframe took place. On 15 December 2006, the F-35A completed its maiden flight. A modified Boeing 737–300, the Lockheed Martin CATBird has been used as an avionics test-bed for the F-35 program, including a duplication of the cockpit.

The first F-35B (designated BF-1) made its maiden flight on 11 June 2008, piloted by BAE Systems' test pilot Graham Tomlinson. Flight testing of the STOVL propulsion system began on 7 January 2010. The F-35B's first hover was on 17 March 2010, followed by its first vertical landing the next day. During a test flight on 10 June 2010, the F-35B achieved supersonic speeds. In January 2011, Lockheed Martin reported that a solution was found for an aluminum bulkhead cracking during ground testing, In 2013, the F-35B suffered another bulkhead cracking incident. necessitating a redesign while already close to the ultimate weight limit.

By June 2009, many of the initial flight test targets had been accomplished but the program was behind schedule. During 2008, a Pentagon Joint Estimate Team (JET) estimated that it was two years behind the public schedule, a revised estimate in 2009 predicted a 30-month delay. Delays reduced planned production numbers by 122 aircraft through 2015 to provide an additional $2.8 billion for development while a 13-month timeline extension was mooted internally. JET's performance led Ashton Carter calling for more such teams for other poorly performing projects.
Nearly 30 percent of test flights required more than routine maintenance to make aircraft flightworthy again. By March 2010, the program had used a million more man-hours than predicted. The USN projected that lifecycle costs over a 65-year fleet life for all American F-35s to be $442 billion higher than USAF projections. Delays led to a shortfall of up to 100 fighters in the USN/USMC, somewhat mitigated via existing assets.

The F-35C's maiden flight took place on 7 June 2010, at NAS Fort Worth JRB. On 9 March 2011, all F-35s were grounded after a dual generator failure and oil leak in flight; the cause was later discovered to have been faulty maintenance. In 2012, Navy Commander Erik Etz of the F-35 program office stated that the F-35's sensors had been tested during exercise Northern Edge 2011, serving as a significant risk-reduction step.

On 2 August 2011, an F-35's integrated power package (IPP) failure during a standard engine test, causing an immediate grounding of the F-35 for two weeks. On 10 August 2011, ground operations were re-instituted; preliminary inquiries indicated the IPP failure to have been caused by a control valve error. On 18 August 2011, the flight ban was lifted for 18 of the 20 F-35s; two aircraft remained grounded for lack of monitoring systems. The IPP suffered a second software-related incident in 2013; there was no disruption as the fleet was already grounded by separate engine issues.

On 25 October 2011, the F-35A reached its designed top speed of Mach 1.6 for the first time; further testing demonstrated Mach 1.61 and 9.9g. On 11 February 2013, an F-35A completed its final test flight for clean wing flutter, being reportedly flutter-free at up to Mach 1.6. In October 2011, two F-35Bs conducted three weeks of initial sea trials aboard . On 15 August 2012, an F-35B completed airborne engine start tests.

In 2011, all eight landing tests of the F-35C failed to catch the arresting wire; a redesigned tail hook was developed and delivered two years later in response.

On 6 October 2012, the F-35A dropped its first bomb, followed three days later by an AIM-120 AMRAAM. On 28 November 2012, an F-35C performed a total of eleven weapon releases, including a GBU-31 JDAM and GBU-12 Paveway from its weapons bay in the first weapons released for the F-35C.

On 16 November 2012, the USMC received the first F-35B at MCAS Yuma. A February 2013 "Time" article revealed that Marine pilots are not allowed to perform a vertical landing—the maneuver is deemed too dangerous, and it is reserved only for Lockheed test pilots. On 21 March 2013, the USMC performed its first hover and vertical landing with an F-35B outside of a testing environment. On 10 May 2013, the F-35B completed its first vertical takeoff test. On 3 August 2013, the 500th vertical landing took place.

On 18 January 2013, the F-35B was grounded after an "improperly crimped" fueldraulic line in the propulsion system failed on 16 January; flight tests were cleared to resume on 12 February 2013. On 22 February 2013, the U.S. Department of Defense grounded the entire fleet after a cracked turbine blade was found in a USAF F-35A. On 28 February 2013, the grounding was lifted after an investigation concluded that stressful testing of that specific engine, including a prolonged period of excessive heat, led to cracking, and was not a wider issue. The F-35C's first carrier-based night flight operations occurred off the coast of San Diego on 13 November 2014.

On 5 June 2015, the U.S. Air Education and Training Command Accident Investigation Board reported that catastrophic engine failure had destroyed a USAF F-35A at Eglin Air Force Base, Florida, on 23 June 2014. A rotor arm had fractured and broke free during takeoff, pieces cutting through the fan case, engine bay, internal fuel tank and hydraulic and fuel lines before leaving through the upper fuselage. Leaked fuel and hydraulic fluid ignited a fire, destroying the aircraft's rear. The loss caused the cancelation of the F-35's international debut at the 2014 Farnborough Airshow in England, a temporary grounding, and ongoing flight envelope restrictions.
On 19 June 2015, the RAF successfully launched two 500 lb Paveway IV precision-guided bombs, the first time that non-US munitions were deployed by the type. A Royal Navy F-35 conducted the first "rolling" landing on board Britain's newest aircraft carrier HMS "Queen Elizabeth" in October 2018.

The USMC declared it had met initial operational capability on 31 July 2015, despite shortcomings in night operations, communications, software and weapons carriage capabilities. However, J. Michael Gilmore, director of the Pentagon’s Operational Test and Evaluation Office, criticized the operational trials as invalid: "the exercise was so flawed that it 'was not an operational test... [it] did not—and could not—demonstrate' that the version of the F-35 that was evaluated 'is ready for real-world operational deployments, given the way the event was structured.'"
The Israeli Air Force declared the F-35 operationally capable on 6 December 2017. According to Kuwaiti newspaper "Al Jarida", in July 2018, a test mission of at least three IAF F-35s flew to Iran's capital Tehran and back from Tel Aviv. While publicly unconfirmed, regional leaders acted on the report; Iran's supreme leader Ali Khamenei reportedly fired the air force chief and commander of Iran's Revolutionary Guard Corps over the mission.

In 2011, the Director of Operational Test and Evaluation warned that the USAF's plan to start unmonitored flight training "risks the occurrence of a serious mishap". The leaders of the United States Senate Committee on Armed Services called on Defense Secretary Leon Panetta to reconsider the plan. Despite objections, expanded trial flights began in September 2012.

The F-35A and F-35B were cleared for flight training in early 2012. They were restricted to basic maneuvers with no tactical training allowed. On 24 August 2012, a USMC pilot flew the F-35's 200th sortie at Eglin Air Force Base. The pilot said, "The aircraft have matured dramatically since the early days. The aircraft are predictable and seem to be maintainable, which is good for the sortie production rate. Currently, the flight envelope for the F-35 is very, very restricted, but there are signs of improvement there too". The F-35s at the base no longer need to fly with a chase aircraft and are operating in a normal two-ship element.

On 21 August 2012, J. Michael Gilmore wrote that he would not approve the Operational Test and Evaluation master plan until his concerns about electronic warfare testing, budget, and concurrency were addressed. On 7 September 2012, the Pentagon failed to approve a comprehensive operational testing plan for the F-35. Instead, on 10 September 2012, the USAF began an operational utility evaluation (OUE) of the F-35A, including logistical support, maintenance, personnel training, and pilot execution. On 26 October, pilots began OUE flights. The OUE was completed on 14 November after 24 flights, each pilot having completed six flights.

During the Low Rate Initial Production (LRIP) phase, the three U.S. military services jointly developed tactics and procedures using flight simulators, testing effectiveness, discovering problems and refining design. Maintenance staff found that rebooting software and onboard systems often fixed issues. In January 2013, training began at Eglin Air Force Base with capacity for 100 pilots and 2,100 maintainers at once.

At Red Flag 2017, the F-35 scored a kill ratio of 15:1 against an F-16 aggressor squadron.

On 9 December 2010, a media report stated that the "USMC will base 216 F-35Bs on the East Coast and 184 of them on the West Coast...Cherry Point will get 128 jets to form eight squadrons; Beaufort will have three squadrons and a pilot training center using 88 aircraft; Miramar will form six operational squadrons with 96 jets and 88 F-35s will go to Yuma for five operational squadrons with an additional test and evaluation unit". In 2011, the USMC and USN signed an agreement that the USMC will purchase 340 F-35B and 80 F-35C fighters. The five squadrons of USMC F-35Cs would be assigned to Navy carriers while F-35Bs would be used ashore.

In February 2014, the USAF announced that the first Air National Guard unit to fly the F-35 will be the 158th Fighter Wing of the Vermont Air National Guard based at the Burlington Air Guard Station. The 158th currently flies aging F-16s; the F-35A is expected to arrive in 2020. On 11 March 2014, the first F-35A assigned to Luke Air Force Base arrived; 144 are to be stationed there over the course of the next decade. On 8 January 2015, RAF Lakenheath in the UK was chosen as the first base in Europe to station two American F-35 squadrons, following an announcement by the Pentagon. 48 F-35s, making up 2 squadrons, will add to the 48th Fighter Wing's already existing F-15C and F-15E Strike Eagle jets.

The USMC plans to disperse its F-35Bs among forward deployed bases to enhance survivability while remaining close to a battlespace, similar to RAF Harrier deployment in the Cold War, which relied on the use of off-base locations that offered short runways, shelter, and concealment. Known as distributed STOVL operations (DSO), F-35Bs would operate from temporary bases in allied territory within the range of hostile ballistic and cruise missiles and be moved between temporary locations inside the enemy's 24- to 48-hour targeting cycle; this strategy accounts for the F-35B's short range, the shortest of the three variants, with mobile forward arming and refueling points (M-Farps) accommodating KC-130 and MV-22 Osprey aircraft to rearm and refuel the jets, as well as littoral areas for sea links of mobile distribution sites. M-Farps can be based on small airfields, multi-lane roads, or damaged main bases, while F-35Bs return to rear-area USAF bases or friendly ships for scheduled maintenance. Helicopter-portable metal planking is needed to protect unprepared roads from the F-35B's engine exhaust; the USMC are studying lighter heat-resistant alternatives.

The United Kingdom's Royal Air Force and Royal Navy both operate the F-35B, known simply as the Lightning in British service; it has replaced the Harrier GR9, which was retired in 2010, and Tornado GR4, which was retired in 2019. The F-35 is to be Britain's primary strike aircraft for the next three decades. One of the Royal Navy's requirements for the F-35B was a Shipborne Rolling and Vertical Landing (SRVL) mode to increase maximum landing weight by using wing lift during landing. In July 2013, Chief of the Air Staff, Air Chief Marshal Sir Stephen Dalton announced that No. 617 (The Dambusters) Squadron would be the RAF's first operational F-35 squadron. The second operational squadron will be the Fleet Air Arm's 809 Naval Air Squadron in April 2023.

No. 17 (Reserve) Test and Evaluation Squadron (TES) stood-up on 12 April 2013 as the Operational Evaluation Unit for the Lightning, becoming the first British squadron to operate the type. By June 2013, the RAF had received three F-35s of the 48 on order, all initially based at Eglin Air Force Base. In June 2015, the F-35B undertook its first launches from a ski-jump at NAS Patuxent River. When operated at sea, British F-35B shall use ships fitted with ski-jumps, as will the Italian Navy. British F-35Bs are not intended to receive the Brimstone 2 missile. On 5 July 2017, it was announced the second UK-based RAF squadron would be No. 207 Squadron, which reformed on 1 August 2019 as the Lightning Operational Conversion Unit. No. 617 Squadron reformed on 18 April 2018 during a ceremony in Washington, D.C., US, becoming the first RAF front-line squadron to operate the type; receiving its first four F-35Bs on 6 June, flying from MCAS Beaufort to RAF Marham. Both No. 617 Squadron and its F-35s were declared combat ready on 10 January 2019.

In April 2019, No. 617 Squadron deployed to RAF Akrotiri, Cyprus, the type's first overseas deployment. In October 2019, "the Dambusters" and No. 17 TES F-35s were embarked on HMS "Queen Elizabeth" for the first time. No. 617 Squadron departed RAF Marham on 22 January 2020 for their first Exercise Red Flag with the Lightning.

On 22 May 2018, Israeli Air Force chief Amikam Norkin said that the service had employed their F-35Is in two attacks on two battle fronts, marking the first combat operation of an F-35 by any country. Norkin said it had been flown "all over the Middle East", and showed photos of an F-35I flying over Beirut in daylight.

On 27 September 2018, a USMC F-35B attacked a Taliban target in Afghanistan, the first U.S. combat employment; it had taken off from the amphibious assault ship in the Arabian Sea.

On 15 April 2019, the USAF deployed F-35As to Al Dhafra Air Base, UAE, for their first Middle East deployment. On 27 April 2019, USAF F-35As were first used in combat in an airstrike on an Islamic State tunnel network in northern Iraq.

On 25 June 2019, the first combat use of an RAF F-35B was reportedly undertaken as armed reconnaissance flights searching for Islamic State targets in Iraq and Syria.

In July 2019, Israel reportedly expanded its strikes against Iranian missile shipments; IAF F-35Is allegedly struck Iranian targets in Iraq twice.

While the United States is the primary customer and financial backer, along with the United Kingdom, Italy, the Netherlands, Canada, Turkey, Australia, Norway, and Denmark have agreed to contribute US$4.375 billion towards development costs. Total development costs are estimated at more than US$40 billion. The purchase of an estimated 2,400 aircraft is expected to cost an additional US$200 billion. The initial plan was that the nine major partner nations would acquire over 3,100 F-35s through 2035. Sales to partner nations are made through the Pentagon's Foreign Military Sales program.

There are three levels of international participation. The levels generally reflect financial stake in the program, the amount of technology transfer and subcontracts open for bid by national companies, and the order in which countries can obtain production aircraft. The United Kingdom is the sole "Level 1" partner, contributing about 10% of the planned development costs under the 1995 Memorandum of Understanding that brought the UK into the project. Level 2 partners are Italy and the Netherlands. Level 3 partners are Turkey, Canada, Australia, Norway, and Denmark. Israel and Singapore have joined as Security Cooperative Participants (SCP).

Japan announced on 20 December 2011 its intent to purchase 42 F-35s with deliveries beginning in 2016 to replace the F-4 Phantom II; Japan seeks 38 F-35s, to be assembled domestically.

By 2012, many changes had occurred in the order book. Italy became the first country to reduce its order (from 131 to 90 F-35s). Other nations reduced initial purchases or delayed orders while still intending to purchase the same final numbers. The U.S. canceled the initial purchase of 13 F-35s and postponed orders for another 179. The United Kingdom cut its initial order and delayed a decision on future orders. Australia decided to buy the Boeing F/A-18E/F Super Hornet as an interim measure. Turkey also cut its initial order of four aircraft to two, but confirmed plans to purchase 100 F-35As. Such cuts have raised unit prices, increasing the likelihood of further cuts.

On 3 April 2012, the Auditor General of Canada Michael Ferguson published a report outlining problems with Canada's procurement of the jet; the report states that the government knowingly understated the final cost of 65 F-35s by $10 billion. Canada's Conservative government stated it would not reduce its order, and anticipated a $75–80 million unit cost; the procurement was termed a "scandal" and "fiasco" by the media and faced a full review to determine any Canadian F-35 purchase. On 13 December 2012, in a scathing editorial published by CBC News, journalist Brian Stewart termed the F-35 project a "global wrecking ball" for its runaway costs and lack of affordability for many participating nations. The Canadian government decided not to proceed with a sole-sourced purchase and launched a competition to choose an aircraft.

In May 2013, Lockheed Martin declared that Turkey is projected to earn $12 billion from licensed production of F-35 components. In June 2018, the U.S. Senate blocked the transfer of F-35s to Turkey over security concerns. On 17 July 2019, President Trump vetoed the sale of F-35s to Turkey.

In January 2019, Singapore officially announced its plan to buy a small number of F-35s for an evaluation of capabilities and suitability before deciding on more to replace its aging F-16 fleet.

In May 2019, Poland announced plans to buy 32 F-35As to replace Soviet-era jets used by the Polish Air Force. At a meeting between U.S. President Donald Trump and Polish President Andrzej Duda in Washington D.C, an F-35B was flown over the South Lawn of the White House to demonstrate its capabilities. In October 2019, US State Department approved Poland's possible purchase of the F-35.

The F-35A is the conventional takeoff and landing (CTOL) variant intended for the USAF and other air forces. It is the smallest, lightest version and is the only variant equipped with an internal cannon, the GAU-22/A. This 25 mm cannon is a development of the GAU-12 carried by the USMC's AV-8B Harrier II. It is designed for increased effectiveness against ground targets compared to the 20 mm M61 Vulcan cannon carried by other USAF fighters. On 2 August 2016, the USAF declared the F-35A basic combat ready. The F-35A was scheduled to be fully combat-ready in 2017 with its 3F software upgrade.
The F-35A is expected to match the F-16 in maneuverability and instantaneous high-g performance, and outperform it in stealth, payload, range on internal fuel, avionics, operational effectiveness, supportability, and survivability. The F-35A can be outfitted to receive fuel via either of the two aerial refueling methods. The F-35As for the Royal Norwegian Air Force will have drag chute installed, being the first operator to adopt the drag chute pod.


The F-35B is the short takeoff and vertical landing (STOVL) variant of the aircraft. Similar in size to the A variant, the B sacrifices about a third of the A variant's fuel volume to accommodate the vertical flight system. Vertical takeoffs and landings are riskier because of threats such as foreign object damage. Whereas the F-35A is stressed to 9 g, the F-35B's stress goal is 7 g. , the F-35B is limited to 4.5 g and 400 knots. The next software upgrade includes weapons, and allows 5.5 g and Mach 1.2, with a final target of 7 g and Mach 1.6.

Unlike other variants, the F-35B has no landing hook. The "STOVL/HOOK" control instead engages conversion between normal and vertical flight. Jet thrust is sent directly downwards during vertical flight. The variant's three-bearing swivel nozzle that directs the full thrust of the engine is moved by a "fueldraulic" actuator using pressurized fuel as the working fluid.

The F-35C variant is designed for catapult-assisted take-off but arrested recovery operations from aircraft carriers. Compared to the F-35A, the F-35C features larger wings with foldable wingtip sections, larger wing and tail control surfaces for improved low-speed control, stronger landing gear for the stresses of carrier arrested landings, a twin-wheel nose gear, and a stronger tailhook for use with carrier arrestor cables. The larger wing area allows for decreased landing speed while increasing both range and payload.

The USN declared initial operational capability for the F-35C on 28 February 2019.

A study for a possible upgrade of the F-35A to be fielded by the 2035 target date of the USAF's Future Operating Concept.


The F-35I "Adir" (, meaning "Awesome", or "Mighty One") is an F-35A with unique Israeli modifications. The US initially refused to allow such changes before permitting Israel to integrate its own electronic warfare systems, including sensors and countermeasures. The main computer has a plug-and-play function for add-on systems; proposals include an external jamming pod, and new Israeli air-to-air missiles and guided bombs in the internal weapon bays. A senior IAF official said that the F-35's stealth may be partly overcome within 10 years despite a 30 to 40 year service life, thus Israel's insistence on using their own electronic warfare systems. Israel Aerospace Industries (IAI) has considered a two-seat F-35 concept; an IAI executive noted: "There is a known demand for two seats not only from Israel but from other air forces". IAI plans to produce conformal fuel tanks.

The Canadian CF-35 is a proposed variant that would differ from the F-35A through the addition of a drogue parachute and may include an F-35B/C-style refueling probe. In 2012, it was revealed that the CF-35 would employ the same boom refueling system as the F-35A. One alternative proposal would have been the adoption of the F-35C for its probe refueling and lower landing speed; however, the Parliamentary Budget Officer's report cited the F-35C's limited performance and payload as being too high a price to pay. Following the 2015 Federal Election the Liberal Party, whose campaign had included a pledge to cancel the F-35 procurement, formed a new government and commenced an open competition to replace the existing CF-18 Hornet.


18 received, with 15 in the UK and the rest in the US, where they are used for testing and training. 42 (24 FOC fighters and 18 training aircraft) to be fast-tracked by 2023; 138 F-35 total planned, first 48 aircraft will be F-35B. Declared combat-ready in January 2019.



On 23 June 2014, an F-35A's engine caught fire at Eglin Air Force Base. The pilot escaped unharmed, while the aircraft sustained an estimated US$50 million of damages. The accident caused all flights to be halted on 3 July. The fleet returned to flight on 15 July with flight envelope restrictions. In June 2015, the USAF Air Education and Training Command (AETC) issued its official report, which blamed the failure on the third stage rotor of the engine's fan module, pieces of which cut through the fan case and upper fuselage. Pratt & Whitney applied an extended "rub-in" to increase the gap between the second stator and the third rotor integral arm seal, as well as design alterations to pre-trench the stator by early 2016.

The first crash occurred on 28 September 2018; after the pilot's ejection, a USMC F-35B crashed near Marine Corps Air Station Beaufort, South Carolina. All F-35s were grounded pending a fleet-wide inspection of potentially faulty engine tubes. The next day, the USAF and the USN announced that some F-35s were flying again.

On 9 April 2019, a Japan Air Self-Defense Force F-35A attached to Misawa Air Base disappeared from radar about 84 miles (135 km) east of the Aomori Prefecture during a training mission over the Pacific Ocean. The pilot, Major Akinori Hosomi, had radioed his intention to abort the drill before disappearing. Both US and Japanese Navy assets searched for the missing aircraft and pilot, finding debris on the water that confirmed its crash; Hosomi's remains were recovered in June. In response, Japan grounded its 12 F-35As. There was speculation that China or Russia might attempt to salvage it; the Japanese Defense Ministry announced there had been no "reported activities" from either country. Japan's defense minister Takeshi Iwaya stated that the likely cause was the pilot's spatial disorientation. The F-35 reportedly did not send a distress signal nor did the pilot mention any problems during communication. In addition, since the training was not a low-level flight, Hosomi ought to have time to react given his experience level.

In April 2015, the General Accountability Office reported "61 violations of quality management rules and policies" during an inspection of Pratt & Whitney's work on the F-35 engine and warned that the problems could lead to "further cost increases" and "schedule delays".

In late 2017, the GAO, as "Bloomberg" reported, found that the time needed to repair an F-35 part averaged 172 days, which was "twice the program's objective," adding that those shortages are "degrading readiness" since the jets were "unable to fly about 22 percent of the time" for lack of needed parts. The Pentagon responded that cost had been "brought under control." In a June 2018 report to the U.S. Congress, the GAO recommended that "Congress should consider...that no funds shall be [made] available...for F35 Block 4 until [the Department of Defense] provides a sound business case for the effort" and also recommended to the DoD that "all critical deficiencies" should be resolved "before its full-rate production decision."

In an article in the June 2019 issue of "Harper's", investigative journalist Andrew Cockburn reported that out of the six USMC F-35s deployed in the Middle East, they "over several months, only managed to fly, on average, one combat sortie per plane every three days." Additionally, the F-35 initially carried a radar whose frequent freezing required pilots to regularly switch it on and off, a problem that was "eventually corrected," while the USAF version featured an "unacceptably inaccurate" gun on which the service stated is "working." Environmental issues were also cited, such as the F-35 being "at least four times noisier than the ­F-16". The article claimed it belongs in a "bulging arsenal of weapons systems incapable of performing as advertised and bought at extraordinary cost," the ­F-35 costing, as Cockburn claimed, almost six times more than the ­F-16 it is replacing, while the whole program is, at a projected total cost of $406 billion, the "most expensive weapons program in history". By March 2019, the F-35 program is projected to have a lifetime cost of $1.5 trillion, "roughly what [the U.S.] spent on the entire Iraq War." 

In June 2019, questions were raised about the integrity of the F-35 supply chain when it was reported that a UK subsidiary of a company in the People's Republic of China, Shenzhen Fastprint, manufactures certain circuit board components for the fighter jet. The UK Ministry of Defence denied any risks.

In 2019, the German company Hensoldt claimed that its passive radar detection system TwInvis was able to track the flight of two F-35s for 150 kilometers after the 2018 Berlin Air Show.

 





</doc>
<doc id="11815" url="https://en.wikipedia.org/wiki?curid=11815" title="Food additive">
Food additive

Food additives are substances added to food to preserve flavor or enhance its taste, appearance, or other qualities. Some additives have been used for centuries; for example, preserving food by pickling (with vinegar), salting, as with bacon, preserving sweets or using sulfur dioxide as with wines. With the advent of processed foods in the second half of the twentieth century, many more additives have been introduced, of both natural and artificial origin. Food additives also include substances that may be introduced to food indirectly (called "indirect additives") in the manufacturing process, through packaging, or during storage or transport.

To regulate these additives and inform consumers, each additive is assigned a unique number called an "E number", which is used in Europe for all approved additives. This numbering scheme has now been adopted and extended by the "Codex Alimentarius" Commission to internationally identify all additives, regardless of whether they are approved for use.

E numbers are all prefixed by "E", but countries outside Europe use only the number, whether the additive is approved in Europe or not.
For example, acetic acid is written as E260 on products sold in Europe, but is simply known as additive 260 in some countries. Additive 103, alkannin, is not approved for use in Europe so does not have an E number, although it is approved for use in Australia and New Zealand. Since 1987, Australia has had an approved system of labelling for additives in packaged foods. Each food additive has to be named or numbered. The numbers are the same as in Europe, but without the prefix "E".

The United States Food and Drug Administration (FDA) lists these items as "generally recognized as safe" (GRAS); they are listed under both their Chemical Abstracts Service number and FDA regulation under the United States Code of Federal Regulations.

Food additives can be divided into several groups, although there is some overlap because some additives exert more than one effect. For example, salt is both a preservative as well as a flavor.



With the increasing use of processed foods since the 19th century, food additives are more widely used. Many countries regulate their use. For example, boric acid was widely used as a food preservative from the 1870s to the 1920s, but was banned after World War I due to its toxicity, as demonstrated in animal and human studies. During World War II, the urgent need for cheap, available food preservatives led to it being used again, but it was finally banned in the 1950s. Such cases led to a general mistrust of food additives, and an application of the precautionary principle led to the conclusion that only additives that are known to be safe should be used in foods. In the United States, this led to the adoption of the Delaney clause, an amendment to the Federal Food, Drug, and Cosmetic Act of 1938, stating that no carcinogenic substances may be used as food additives. However, after the banning of cyclamates in the United States and Britain in 1969, saccharin, the only remaining legal artificial sweetener at the time, was found to cause cancer in rats. Widespread public outcry in the United States, partly communicated to Congress by postage-paid postcards supplied in the packaging of sweetened soft drinks, led to the retention of saccharin, despite its violation of the Delaney clause. However, in 2000, saccharin was found to be carcinogenic in rats due only to their unique urine chemistry.

Periodically, concerns have been expressed about a linkage between additives and hyperactivity, however "no clear evidence of ADHD was
provided".

In 2007, Food Standards Australia New Zealand published an official shoppers' guidance with which the concerns of food additives and their labeling are mediated. In the EU it can take 10 years or more to obtain approval for a new food additive. This includes five years of safety testing, followed by two years for evaluation by the European Food Safety Authority and another three years before the additive receives an EU-wide approval for use in every country in the European Union. Apart from testing and analyzing food products during the whole production process to ensure safety and compliance with regulatory standards, Trading Standards officers (in the UK) protect the public from any illegal use or potentially dangerous mis-use of food additives by performing random testing of food products.

There has been significant controversy associated with the risks and benefits of food additives. Natural additives may be similarly harmful or be the cause of allergic reactions in certain individuals. For example, safrole was used to flavor root beer until it was shown to be carcinogenic. Due to the application of the Delaney clause, it may not be added to foods, even though it occurs naturally in sassafras and sweet basil.

A subset of food additives, micronutrients added in food fortification processes preserve nutrient value by providing vitamins and minerals to foods such as flour, cereal, margarine and milk which normally would not retain such high levels. Added ingredients, such as air, bacteria, fungi, and yeast, also contribute manufacturing and flavor qualities, and reduce spoilage.

ISO has published a series of standards regarding the topic and these standards are covered by ICS 67.220.




</doc>
<doc id="11820" url="https://en.wikipedia.org/wiki?curid=11820" title="Fridtjof Nansen">
Fridtjof Nansen

Fridtjof Wedel-Jarlsberg Nansen (; 10 October 1861 – 13 May 1930) was a Norwegian explorer, scientist, diplomat, humanitarian and Nobel Peace Prize laureate. In his youth he was a champion skier and ice skater. He led the team that made the first crossing of the Greenland interior in 1888, traversing the island on cross-country skis. He won international fame after reaching a record northern latitude of 86°14′ during his "Fram" expedition of 1893–1896. Although he retired from exploration after his return to Norway, his techniques of polar travel and his innovations in equipment and clothing influenced a generation of subsequent Arctic and Antarctic expeditions.

Nansen studied zoology at the Royal Frederick University in Christiania and later worked as a curator at the University Museum of Bergen where his research on the central nervous system of lower marine creatures earned him a doctorate and helped establish neuron doctrine. Later, neuroscientist Santiago Ramón y Cajal won the 1906 Nobel Prize in Medicine for his research on the same subject. After 1896 his main scientific interest switched to oceanography; in the course of his research he made many scientific cruises, mainly in the North Atlantic, and contributed to the development of modern oceanographic equipment. 

As one of his country's leading citizens, in 1905 Nansen spoke out for the ending of Norway's union with Sweden, and was instrumental in persuading Prince Carl of Denmark to accept the throne of the newly independent Norway. Between 1906 and 1908 he served as the Norwegian representative in London, where he helped negotiate the Integrity Treaty that guaranteed Norway's independent status.

In the final decade of his life, Nansen devoted himself primarily to the League of Nations, following his appointment in 1921 as the League's High Commissioner for Refugees. In 1922 he was awarded the Nobel Peace Prize for his work on behalf of the displaced victims of the First World War and related conflicts. Among the initiatives he introduced was the "Nansen passport" for stateless persons, a certificate that used to be recognised by more than 50 countries. He worked on behalf of refugees until his sudden death in 1930, after which the League established the Nansen International Office for Refugees to ensure that his work continued. This office received the Nobel Peace Prize in 1938. His name is commemorated in numerous geographical features, particularly in the polar regions.

The Nansen family originated in Denmark. Hans Nansen (1598–1667), a trader, was an early explorer of the White Sea region of the Arctic Ocean. In later life he settled in Copenhagen, becoming the city's "borgmester" in 1654. Later generations of the family lived in Copenhagen until the mid-18th century, when Ancher Antoni Nansen moved to Norway (then in a union with Denmark). His son, Hans Leierdahl Nansen (1764–1821), was a magistrate first in the Trondheim district, later in Jæren. After Norway's separation from Denmark in 1814, he entered national political life as the representative for Stavanger in the first Storting, and became a strong advocate of union with Sweden. After suffering a paralytic stroke in 1821 Hans Leierdahl Nansen died, leaving a four-year-old son, Baldur Fridtjof Nansen, the explorer's father.

Baldur was a lawyer without ambitions for public life, who became Reporter to the Supreme Court of Norway. He married twice, the second time to Adelaide Johanne Thekla Isidore Bølling Wedel-Jarlsberg from Bærum, a niece of Herman Wedel-Jarlsberg who had helped frame the Norwegian constitution of 1814 and was later the Swedish king's Norwegian Viceroy. Baldur and Adelaide settled at Store Frøen, an estate at Aker, a few kilometres north of Norway's capital city, Christiania (since renamed Oslo). The couple had three children; the first died in infancy, the second, born 10 October 1861, was Fridtjof Nansen.

Store Frøen's rural surroundings shaped the nature of Nansen's childhood. In the short summers the main activities were swimming and fishing, while in the autumn the chief pastime was hunting for game in the forests. The long winter months were devoted mainly to skiing, which Nansen began to practice at the age of two, on improvised skis. At the age of 10 he defied his parents and attempted the ski jump at the nearby Huseby installation. This exploit had near-disastrous consequences, as on landing the skis dug deep into the snow, pitching the boy forward: "I, head first, described a fine arc in the air ... [W]hen I came down again I bored into the snow up to my waist. The boys thought I had broken my neck, but as soon as they saw there was life in me ... a shout of mocking laughter went up." Nansen's enthusiasm for skiing was undiminished, though as he records, his efforts were overshadowed by those of the skiers from the mountainous region of Telemark, where a new style of skiing was being developed. "I saw this was the only way", wrote Nansen later.

At school, Nansen worked adequately without showing any particular aptitude. Studies took second place to sports, or to expeditions into the forests where he would live "like Robinson Crusoe" for weeks at a time. Through such experiences Nansen developed a marked degree of self-reliance. He became an accomplished skier and a highly proficient skater. Life was disrupted when, in the summer of 1877, Adelaide Nansen died suddenly. Distressed, Baldur Nansen sold the Store Frøen property and moved with his two sons to Christiania. Nansen's sporting prowess continued to develop; at 18 he broke the world one-mile (1.6 km) skating record, and in the following year won the national cross-country skiing championship, a feat he would repeat on 11 subsequent occasions.

In 1880 Nansen passed his university entrance examination, the "examen artium". He decided to study zoology, claiming later that he chose the subject because he thought it offered the chance of a life in the open air. He began his studies at the Royal Frederick University in Christiania early in 1881.

Early in 1882 Nansen took "...the first fatal step that led me astray from the quiet life of science." Professor Robert Collett of the university's zoology department proposed that Nansen take a sea voyage, to study Arctic zoology at first hand. Nansen was enthusiastic, and made arrangements through a recent acquaintance, Captain Axel Krefting, commander of the sealer "Viking". The voyage began on 11 March 1882 and extended over the following five months. In the weeks before sealing started, Nansen was able to concentrate on scientific studies. From water samples he showed that, contrary to previous assumption, sea ice forms on the surface of the water rather than below. His readings also demonstrated that the Gulf Stream flows beneath a cold layer of surface water. Through the spring and early summer "Viking" roamed between Greenland and Spitsbergen in search of seal herds. Nansen became an expert marksman, and on one day proudly recorded that his team had shot 200 seal. In July, "Viking" became trapped in the ice close to an unexplored section of the Greenland coast; Nansen longed to go ashore, but this was impossible. However, he began to develop the idea that the Greenland icecap might be explored, or even crossed. On 17 July the ship broke free from the ice, and early in August was back in Norwegian waters.

Nansen did not resume formal studies at the university. Instead, on Collett's recommendation, he accepted a post as curator in the zoological department of the Bergen Museum. He was to spend the next six years of his life there—apart from a six-month sabbatical tour of Europe—working and studying with leading figures such as Gerhard Armauer Hansen, the discoverer of the leprosy bacillus, and Daniel Cornelius Danielssen, the museum's director who had turned it from a backwater collection into a centre of scientific research and education. Nansen's chosen area of study was the then relatively unexplored field of neuroanatomy, specifically the central nervous system of lower marine creatures. Before leaving for his sabbatical in February 1886 he published a paper summarising his research to date, in which he stated that "anastomoses or unions between the different ganglion cells" could not be demonstrated with certainty. This unorthodox view was confirmed by the simultaneous researches of the embryologist Wilhelm His and the psychiatrist August Forel. Nansen is considered the first Norwegian defender of the neuron theory, originally proposed by Santiago Ramón y Cajal. His subsequent paper, "The Structure and Combination of Histological Elements of the Central Nervous System", published in 1887, became his doctoral thesis.

The idea of an expedition across the Greenland icecap grew in Nansen's mind throughout his Bergen years. In 1887, after the submission of his doctoral thesis, he finally began organising this project. Before then, the two most significant penetrations of the Greenland interior had been those of Adolf Erik Nordenskiöld in 1883, and Robert Peary in 1886. Both had set out from Disko Bay on the western coast, and had travelled about eastward before turning back. By contrast, Nansen proposed to travel from east to west, ending rather than beginning his trek at Disko Bay. A party setting out from the inhabited west coast would, he reasoned, have to make a return trip, as no ship could be certain of reaching the dangerous east coast and picking them up. By starting from the east—assuming that a landing could be made there—Nansen's would be a one-way journey towards a populated area. The party would have no line of retreat to a safe base; the only way to go would be forward, a situation that fitted Nansen's philosophy completely.

Nansen rejected the complex organisation and heavy manpower of other Arctic ventures, and instead planned his expedition for a small party of six. Supplies would be manhauled on specially designed lightweight sledges. Much of the equipment, including sleeping bags, clothing and cooking stoves, also needed to be designed from scratch. These plans received a generally poor reception in the press; one critic had no doubt that "if [the] scheme be attempted in its present form ... the chances are ten to one that he will ... uselessly throw his own and perhaps others' lives away". The Norwegian parliament refused to provide financial support, believing that such a potentially risky undertaking should not be encouraged. The project was eventually launched with a donation from a Danish businessman, Augustin Gamél; the rest came mainly from small contributions from Nansen's countrymen, through a fundraising effort organised by students at the university.

Despite the adverse publicity, Nansen received numerous applications from would-be adventurers. He wanted expert skiers, and attempted to recruit from the skiers of Telemark, but his approaches were rebuffed. Nordenskiöld had advised Nansen that Sami people, from Finland in the far north of Norway, were expert snow travellers, so Nansen recruited a pair, Samuel Balto and Ole Nielsen Ravna. The remaining places went to Otto Sverdrup, a former sea-captain who had more recently worked as a forester; Oluf Christian Dietrichson, an army officer, and Kristian Kristiansen, an acquaintance of Sverdrup's. All had experience of outdoor life in extreme conditions, and were experienced skiers. Just before the party's departure, Nansen attended a formal examination at the university, which had agreed to receive his doctoral thesis. In accordance with custom he was required to defend his work before appointed examiners acting as "devil's advocates". He left before knowing the outcome of this process.

The sealer "Jason" picked up Nansen's party on 3 June 1888 from the Icelandic port of Ísafjörður. They sighted the Greenland coast a week later, but thick pack ice hindered progress. With the coast still away, Nansen decided to launch the small boats. They were within sight of Sermilik Fjord on 17 July; Nansen believed it would offer a route up the icecap.

The expedition left "Jason" "in good spirits and with the highest hopes of a fortunate result." Days of extreme frustration followed as they drifted south. Weather and sea conditions prevented them from reaching the shore. They spent most time camping on the ice itself—it was too dangerous to launch the boats.

By 29 July, they found themselves south of the point where they left the ship. That day they finally reached land but were too far south to begin the crossing. Nansen ordered the team back into the boats after a brief rest and to begin rowing north. The party battled northward along the coast through the ice floes for the next 12 days. They encountered a large Eskimo encampment on the first day, near Cape Steen Bille. Occasional contacts with the nomadic native population continued as the journey progressed.

The party reached Umivik Bay on 11 August, after covering . Nansen decided they needed to begin the crossing. Although they were still far south of his intended starting place; the season was becoming too advanced. After they landed at Umivik, they spent the next four days preparing for their journey. They set out on the evening of 15 August, heading north-west towards Christianhaab on the western shore of Disko Bay— away.

Over the next few days, the party struggled to ascend. The inland ice had a treacherous surface with many hidden crevasses and the weather was bad. Progress stopped for three days because of violent storms and continuous rain one time. The last ship was due to leave Christianhaab by mid-September. They would not be able to reach it in time, Nansen concluded on 26 August. He ordered a change of course due west, towards Godthaab; a shorter journey by at least . The rest of the party, according to Nansen, "hailed the change of plan with acclamation." 
They continued climbing until 11 September and reached a height of above sea level. Temperatures on the icecap summit of the icecap dropped to at night. From then on the downward slope made travelling easier. Yet, the terrain was rugged and the weather remained hostile. Progress was slow: fresh snowfalls made dragging the sledges like pulling them through sand.

On 26 September, they battled their way down the edge of a fjord westward towards Godthaab. Sverdrup constructed a makeshift boat out of parts of the sledges, willows, and their tent. Three days later, Nansen and Sverdrup began the last stage of the journey; rowing down the fjord.

On 3 October, they reached Godthaab, where the Danish town representative greeted them. He first informed Nansen that he secured his doctorate, a matter that "could not have been more remote from [Nansen's] thoughts at that moment." The team accomplished their crossing in 49 days. Throughout the journey, they maintained meteorological and geographical and other records relating to the previously unexplored interior.

The rest of the team arrived in Godthaab on 12 October. Nansen soon learned no ship was likely to call at Godthaab until the following spring. Still, they were able to send letters back to Norway via a boat leaving Ivigtut at the end of October. He and his party spent the next seven months in Greenland. On 15 April 1889, the Danish ship "Hvidbjørnen" finally entered the harbour. Nansen recorded: "It was not without sorrow that we left this place and these people, among whom we had enjoyed ourselves so well."

"Hvidbjørnen" reached Copenhagen on 21 May 1889. News of the crossing had preceded its arrival, and Nansen and his companions were feted as heroes. This welcome, however, was dwarfed by the reception in Christiania a week later, when crowds of between thirty and forty thousand—a third of the city's population—thronged the streets as the party made its way to the first of a series of receptions. The interest and enthusiasm generated by the expedition's achievement led directly to the formation that year of the Norwegian Geographical Society.

Nansen accepted the position of curator of the Royal Frederick University's zoology collection, a post which carried a salary but involved no duties; the university was satisfied by the association with the explorer's name. Nansen's main task in the following weeks was writing his account of the expedition, but he found time late in June to visit London, where he met the Prince of Wales (the future Edward VII), and addressed a meeting of the Royal Geographical Society (RGS).

The RGS president, Sir Mountstuart Elphinstone Grant Duff, said that Nansen has claimed "the foremost place amongst northern travellers", and later awarded him the Society's prestigious Founder's Medal. This was one of many honours Nansen received from institutions all over Europe. He was invited by a group of Australians to lead an expedition to Antarctica, but declined, believing that Norway's interests would be better served by a North Pole conquest.

On 11 August 1889 Nansen announced his engagement to Eva Sars, the daughter of Michael Sars, a zoology professor who had died when Eva was 11 years old. The couple had met some years previously, at the skiing resort of Frognerseteren, where Nansen recalled seeing "two feet sticking out of the snow". Eva was three years older than Nansen, and despite the evidence of this first meeting, was an accomplished skier. She was also a celebrated classical singer who had been coached in Berlin by Désirée Artôt, one-time paramour of Tchaikovsky. The engagement surprised many; since Nansen had previously expressed himself forcefully against the institution of marriage, Otto Sverdrup assumed he had read the message wrongly. The wedding took place on 6 September 1889, less than a month after the engagement.

Nansen first began to consider the possibility of reaching the North Pole after reading meteorologist Henrik Mohn's theory on polar drift in 1884. Artefacts found on the coast of Greenland were identified to have come from the "Jeannette" expedition. In June 1881, was crushed and sunk off the Siberian coast—the opposite side of the Arctic Ocean. Mohn surmised the location of the artefacts indicated the existence of an ocean current from east to west, all the way across the polar sea and possibly over the pole itself.

The idea remained fixated in Nansen's mind for the next couple of years. He developed a detailed plan for a polar venture after his triumphant return from Greenland. He made his idea public in February 1890, at a meeting of the newly-formed Norwegian Geographical Society. Previous expeditions, he argued, approached the North Pole from the west and failed because they were working against the prevailing east-west current; the secret was to work with the current. 

A workable plan would require a sturdy and manoeuvrable small ship, capable of carrying fuel and provisions for twelve men for five years. This ship would enter the ice pack close to the approximate location of "Jeannette's" sinking, drifting west with the current towards the pole and beyond it—eventually reaching the sea between Greenland and Spitsbergen.

Experienced polar explorers were dismissive: Adolphus Greely called the idea "an illogical scheme of self-destruction". Equally dismissive were Sir Allen Young, a veteran of the searches for Franklin's lost expedition, and Sir Joseph Dalton Hooker, who had sailed to the Antarctic on the Ross expedition. Nansen still managed to secure a grant from the Norwegian parliament after an impassioned speech. Additional funding was secured through a national appeal for private donations.

Nansen chose naval engineer Colin Archer to design and build a ship. Archer designed an extraordinarily sturdy vessel with an intricate system of crossbeams and braces of the toughest oak timbers. Its rounded hull was designed to push the ship upwards when beset by pack ice. Speed and manoeuvrability were to be secondary to its ability as a safe and warm shelter during their predicted confinement.

The length-to-beam ratio— and —gave it a stubby appearance, justified by Archer: "A ship that is built with exclusive regard to its suitability for [Nansen's] object must differ essentially from any known vessel." It was christened "Fram" and launched on 6 October 1892.

Nansen selected a party of twelve from thousands of applicants. Otto Sverdrup, who took part in Nansen's earlier Greenland expedition was appointed as the expedition's second-in-command. Competition was so fierce that army lieutenant and dog-driving expert Hjalmar Johansen signed on as ship's stoker, the only position still available.

"Fram" left Christiania on 24 June 1893, cheered on by thousands of well-wishers. After a slow journey around the coast, the final port of call was Vardø, in the far north-east of Norway. "Fram" left Vardø on 21 July, following the North-East Passage route pioneered by Nordenskiöld in 1878–1879, along the northern coast of Siberia. Progress was impeded by fog and ice conditions in the mainly uncharted seas.

The crew also experienced the dead water phenomenon, where a ship's forward progress is impeded by friction caused by a layer of fresh water lying on top of heavier salt water. Nevertheless, Cape Chelyuskin, the most northerly point of the Eurasian continental mass, was passed on 10 September.

Heavy pack ice was sighted ten days later at around latitude 78°N, as "Fram" approached the area in which was crushed. Nansen followed the line of the pack northwards to a position recorded as , before ordering engines stopped and the rudder raised. From this point "Fram's" drift began. The first weeks in the ice were frustrating, as the drift moved unpredictably; sometimes north, sometimes south.

By 19 November, "Fram's" latitude was south of that at which she had entered the ice. Only after the turn of the year, in January 1894, did the northerly direction become generally settled; the 80°N mark was finally passed on 22 March. Nansen calculated that, at this rate, it might take the ship five years to reach the pole. As the ship's northerly progress continued at a rate rarely above a kilometre and a half per day, Nansen began privately to consider a new plan—a dog sledge journey towards the pole. With this in mind, he began to practice dog-driving, making many experimental journeys over the ice. 

In November, Nansen announced his plan: when the ship passed latitude 83°N, he and Hjalmar Johansen would leave the ship with the dogs and make for the pole while "Fram", under Sverdrup, continued its drift until it emerged from the ice in the North Atlantic. After reaching the pole, Nansen and Johansen would make for the nearest known land, the recently discovered and sketchily mapped Franz Josef Land. They would then cross to Spitzbergen where they would find a ship to take them home.

The crew spent the rest of the winter of 1894 preparing clothing and equipment for the forthcoming sledge journey. Kayaks were built, to be carried on the sledges until needed for the crossing of open water. Preparations were interrupted early in January when violent tremors shook the ship. The crew disembarked, fearing the vessel would be crushed, but "Fram" proved herself equal to the danger. On 8 January 1895, the ship's position was 83°34′N, above Greely's previous record of 83°24′N.

With the ship's latitude at 84°4′N and after two false starts, Nansen and Johansen began their journey on 14 March 1895. Nansen allowed 50 days to cover the to the pole, an average daily journey of . After a week of travel, a sextant observation indicated they averaged per day, which put them ahead of schedule. However, uneven surfaces made skiing more difficult, and their speeds slowed. They also realised they were marching against a southerly drift, and that distances travelled did not necessarily equate to distance progressed. 

On 3 April, Nansen began to doubt whether the pole was attainable. Unless their speed improved, their food would not last them to the pole and back to Franz Josef Land. He confided in his diary: "I have become more and more convinced we ought to turn before time." Four days later, after making camp, he observed the way ahead was "... a veritable chaos of iceblocks stretching as far as the horizon." Nansen recorded their latitude as 86°13′6″N—almost three degrees beyond the previous record—and decided to turn around and head back south.

At first Nansen and Johansen made good progress south, but suffered a serious setback on 13 April, when in his eagerness to break camp, he had forgotten to wind both of their chronometers, which made it impossible to calculate their longitude and accurately navigate to Franz Josef Land. They restarted the watches based on Nansen's guess they were at 86°E. From then on were uncertain of their true position. The tracks of an Arctic fox were observed towards the end of April. It was the first trace of a living creature other than their dogs since they left "Fram". They soon saw bear tracks and by the end of May saw evidence of nearby seals, gulls and whales.
On 31 May, Nansen calculated they were only from Cape Fligely, Franz Josef Land's northernmost point. Travel conditions worsened as increasingly warmer weather caused the ice to break up. On 22 June, the pair decided to rest on a stable ice floe while they repaired their equipment and gathered strength for the next stage of their journey. They remained on the floe for a month.

The day after leaving this camp, Nansen recorded: "At last the marvel has come to pass—land, land, and after we had almost given up our belief in it!" Whether this still-distant land was Franz Josef Land or a new discovery they did not know—they had only a rough sketch map to guide them. The edge of the pack ice was reached on 6 August and they shot the last of their dogs—the weakest of which they killed regularly to feed the others since 24 April. The two kayaks were lashed together, a sail was raised, and they made for the land.

It soon became clear this land was part of an archipelago. As they moved southwards, Nansen tentatively identified a headland as Cape Felder on the western edge of Franz Josef Land. Towards the end of August, as the weather grew colder and travel became increasingly difficult, Nansen decided to camp for the winter. In a sheltered cove, with stones and moss for building materials, the pair erected a hut which was to be their home for the next eight months. With ready supplies of bear, walrus and seal to keep their larder stocked, their principal enemy was not hunger but inactivity. After muted Christmas and New Year celebrations, in slowly improving weather, they began to prepare to leave their refuge, but it was 19 May 1896 before they were able to resume their journey.

On 17 June, during a stop for repairs after the kayaks had been attacked by a walrus, Nansen thought he heard a dog barking as well as human voices. He went to investigate, and a few minutes later saw the figure of a man approaching. It was the British explorer Frederick Jackson, who was leading an expedition to Franz Josef Land and was camped at Cape Flora on nearby Northbrook Island. The two were equally astonished by their encounter; after some awkward hesitation Jackson asked: "You are Nansen, aren't you?", and received the reply "Yes, I am Nansen."

Johansen was picked up and the pair were taken to Cape Flora where, during the following weeks, they recuperated from their ordeal. Nansen later wrote that he could "still scarcely grasp" their sudden change of fortune; had it not been for the walrus attack that caused the delay, the two parties might have been unaware of each other's existence.
On 7 August, Nansen and Johansen boarded Jackson's supply ship "Windward", and sailed for Vardø where they arrived on the 13th. They were greeted by Hans Mohn, the originator of the polar drift theory, who was in the town by chance. The world was quickly informed by telegram of Nansen's safe return, but as yet there was no news of "Fram".

Taking the weekly mail steamer south, Nansen and Johansen reached Hammerfest on 18 August, where they learned that "Fram" had been sighted. She had emerged from the ice north and west of Spitsbergen, as Nansen had predicted, and was now on her way to Tromsø. She had not passed over the pole, nor exceeded Nansen's northern mark. Without delay Nansen and Johansen sailed for Tromsø, where they were reunited with their comrades.

The homeward voyage to Christiania was a series of triumphant receptions at every port. On 9 September, "Fram" was escorted into Christiania's harbour and welcomed by the largest crowds the city had ever seen. The crew were received by King Oscar, and Nansen, reunited with family, remained at the palace for several days as special guests. Tributes arrived from all over the world; typical was that from the British mountaineer Edward Whymper, who wrote that Nansen had made "almost as great an advance as has been accomplished by all other voyages in the nineteenth century put together".

Nansen's first task on his return was to write his account of the voyage. This he did remarkably quickly, producing 300,000 words of Norwegian text by November 1896; the English translation, titled "Farthest North", was ready in January 1897. The book was an instant success, and secured Nansen's long-term financial future. Nansen included without comment the one significant adverse criticism of his conduct, that of Greely, who had written in "Harper's Weekly" on Nansen's decision to leave "Fram" and strike for the pole: "It passes comprehension how Nansen could have thus deviated from the most sacred duty devolving on the commander of a naval expedition."

During the 20 years following his return from the Arctic, Nansen devoted most of his energies to scientific work. In 1897 he accepted a professorship in zoology at the Royal Frederick University, which gave him a base from which he could tackle the major task of editing the reports of the scientific results of the "Fram" expedition. This was a much more arduous task than writing the expedition narrative. The results were eventually published in six volumes, and according to a later polar scientist, Robert Rudmose-Brown, "were to Arctic oceanography what the "Challenger" expedition results had been to the oceanography of other oceans."

In 1900, Nansen became director of the Christiania-based International Laboratory for North Sea Research, and helped found the International Council for the Exploration of the Sea. Through his connection with the latter body, in the summer of 1900 Nansen embarked on his first visit to Arctic waters since the "Fram" expedition, a cruise to Iceland and Jan Mayen Land on the oceanographic research vessel "Michael Sars", named after Eva's father. Shortly after his return he learned that his Farthest North record had been passed, by members of the Duke of the Abruzzi's Italian expedition. They had reached 86°34′N on 24 April 1900, in an attempt to reach the North Pole from Franz Josef Land. Nansen received the news philosophically: "What is the value of having goals for their own sake? They all vanish ... it is merely a question of time."

Nansen was now considered an oracle by all would-be explorers of the north and south polar regions. Abruzzi had consulted him, as had the Belgian Adrien de Gerlache, each of whom took expeditions to the Antarctic. Although Nansen refused to meet his own countryman and fellow-explorer Carsten Borchgrevink (whom he considered a fraud), he gave advice to Robert Falcon Scott on polar equipment and transport, prior to the 1901–04 "Discovery" expedition. At one point Nansen seriously considered leading a South Pole expedition himself, and asked Colin Archer to design two ships. However, these plans remained on the drawing board.

By 1901 Nansen's family had expanded considerably. A daughter, Liv, had been born just before "Fram" set out; a son, Kåre was born in 1897 followed by a daughter, Irmelin, in 1900 and a second son Odd in 1901. The family home, which Nansen had built in 1891 from the profits of his Greenland expedition book, was now too small. Nansen acquired a plot of land in the Lysaker district and built, substantially to his own design, a large and imposing house which combined some of the characteristics of an English manor house with features from the Italian renaissance.

The house was ready for occupation by April 1902; Nansen called it "Polhøgda" (in English "polar heights"), and it remained his home for the rest of his life. A fifth and final child, son Asmund, was born at Polhøgda in 1903.

The union between Norway and Sweden, imposed by the Great Powers in 1814, had been under considerable strain through the 1890s, the chief issue in question being Norway's rights to its own consular service. Nansen, although not by inclination a politician, had spoken out on the issue on several occasions in defence of Norway's interests. It seemed, early in the 20th century that agreement between the two countries might be possible, but hopes were dashed when negotiations broke down in February 1905. The Norwegian government fell, and was replaced by one led by Christian Michelsen, whose programme was one of separation from Sweden.

In February and March Nansen published a series of newspaper articles which placed him firmly in the separatist camp. The new prime minister wanted Nansen in the cabinet, but Nansen had no political ambitions. However, at Michelsen's request he went to Berlin and then to London where, in a letter to "The Times", he presented Norway's legal case for a separate consular service to the English-speaking world. On 17 May 1905, Norway's Constitution Day, Nansen addressed a large crowd in Christiania, saying: "Now have all ways of retreat been closed. Now remains only one path, the way forward, perhaps through difficulties and hardships, but forward for our country, to a free Norway". He also wrote a book, "Norway and the Union with Sweden", to promote Norway's case abroad.

On 23 May the Storting passed the Consulate Act establishing a separate consular service. King Oscar refused his assent; on 27 May the Norwegian cabinet resigned, but the king would not recognise this step. On 7 June the Storting unilaterally announced that the union with Sweden was dissolved. In a tense situation the Swedish government agreed to Norway's request that the dissolution should be put to a referendum of the Norwegian people. This was held on 13 August 1905 and resulted in an overwhelming vote for independence, at which point King Oscar relinquished the crown of Norway while retaining the Swedish throne. A second referendum, held in November, determined that the new independent state should be a monarchy rather than a republic. In anticipation of this, Michelsen's government had been considering the suitability of various princes as candidates for the Norwegian throne. Faced with King Oscar's refusal to allow anyone from his own House of Bernadotte to accept the crown, the favoured choice was Prince Charles of Denmark. In July 1905 Michelsen sent Nansen to Copenhagen on a secret mission to persuade Charles to accept the Norwegian throne. Nansen was successful; shortly after the second referendum Charles was proclaimed king, taking the name Haakon VII. He and his wife, the British princess Maud, were crowned in the Nidaros Cathedral in Trondheim on 22 June 1906.

In April 1906 Nansen was appointed Norway's first Minister in London. His main task was to work with representatives of the major European powers on an Integrity Treaty which would guarantee Norway's position. Nansen was popular in England, and got on well with King Edward, though he found court functions and diplomatic duties disagreeable; "frivolous and boring" was his description. However, he was able to pursue his geographical and scientific interests through contacts with the Royal Geographical Society and other learned bodies. The Treaty was signed on 2 November 1907, and Nansen considered his task complete. Resisting the pleas of, among others, King Edward that he should remain in London, on 15 November Nansen resigned his post. A few weeks later, still in England as the king's guest at Sandringham, Nansen received word that Eva was seriously ill with pneumonia. On 8 December he set out for home, but before he reached Polhøgda he learned, from a telegram, that Eva had died.

After a period of mourning, Nansen returned to London. He had been persuaded by his government to rescind his resignation until after King Edward's state visit to Norway in April 1908. His formal retirement from the diplomatic service was dated 1 May 1908, the same day on which his university professorship was changed from zoology to oceanography. This new designation reflected the general character of Nansen's more recent scientific interests.

In 1905, he had supplied the Swedish physicist Walfrid Ekman with the data which established the principle in oceanography known as the Ekman spiral. Based on Nansen's observations of ocean currents recorded during the "Fram" expedition, Ekman concluded that the effect of wind on the sea's surface produced currents which "formed something like a spiral staircase, down towards the depths".

In 1909 Nansen combined with Bjørn Helland-Hansen to publish an academic paper, "The Norwegian Sea: its Physical Oceanography", based on the "Michael Sars" voyage of 1900. Nansen had by now retired from polar exploration, the decisive step being his release of "Fram" to fellow Norwegian Roald Amundsen, who was planning a North Pole expedition. When Amundsen made his controversial change of plan and set out for the South Pole, Nansen stood by him.

Between 1910 and 1914, Nansen participated in several oceanographic voyages. In 1910, aboard the Norwegian naval vessel "Fridtjof", he carried out researches in the northern Atlantic, and in 1912 he took his own yacht, "Veslemøy", to Bear Island and Spitsbergen. The main objective of the "Veslemøy" cruise was the investigation of salinity in the North Polar Basin. One of Nansen's lasting contributions to oceanography was his work designing instruments and equipment; the "Nansen bottle" for taking deep water samples remained in use into the 21st century, in a version updated by Shale Niskin.

At the request of the Royal Geographical Society, Nansen began work on a study of Arctic discoveries, which developed into a two-volume history of the exploration of the northern regions up to the beginning of the 16th century. This was published in 1911 as "Nord i Tåkeheimen" ("In Northern Mists"). That year he renewed an acquaintance with Kathleen Scott, wife of Robert Falcon Scott whose Terra Nova Expedition had sailed for Antarctica in 1910.

Biographer Roland Huntford has asserted, without any compelling evidence, that Nansen and Kathleen Scott had a brief love affair. Louisa Young, in her biography of Lady Scott, refutes the claim. Many women were attracted to Nansen, and he had a reputation as a womaniser. His personal life was troubled around this time; in January 1913 he received news of the suicide of Hjalmar Johansen, who had returned in disgrace from Amundsen's successful South Pole expedition. In March 1913, Nansen's youngest son Asmund died after a long illness.

In the summer of 1913, Nansen travelled to the Kara Sea, by the invitation of Jonas Lied, as part of a delegation investigating a possible trade route between Western Europe and the Siberian interior. The party then took a steamer up the Yenisei River to Krasnoyarsk, and travelled on the Trans-Siberian Railway to Vladivostok before turning for home. Nansen published a report from the trip in "Through Siberia". The life and culture of the Russian peoples aroused in Nansen an interest and sympathy he would carry through to his later life. Immediately before the First World War, Nansen joined Helland-Hansen in an oceanographical cruise in eastern Atlantic waters.

On the outbreak of war in 1914, Norway declared its neutrality, alongside Sweden and Denmark. Nansen was appointed as the president of the Norwegian Union of Defence, but had few official duties, and continued with his professional work as far as circumstances permitted. As the war progressed, the loss of Norway's overseas trade led to acute shortages of food in the country, which became critical in April 1917, when the United States entered the war and placed extra restrictions on international trade. Nansen was dispatched to Washington by the Norwegian government; after months of discussion, he secured food and other supplies in return for the introduction of a rationing system. When his government hesitated over the deal, he signed the agreement on his own initiative.

Within a few months of the war's end in November 1918, a draft agreement had been accepted by the Paris Peace Conference to create a League of Nations, as a means of resolving disputes between nations by peaceful means. The foundation of the League at this time was providential as far as Nansen was concerned, giving him a new outlet for his restless energy. He became president of the Norwegian League of Nations Society, and although the Scandinavian nations with their traditions of neutrality initially held themselves aloof, his advocacy helped to ensure that Norway became a full member of the League in 1920, and he became one of its three delegates to the League's General Assembly.

In April 1920, at the League's request, Nansen began organising the repatriation of around half a million prisoners of war, stranded in various parts of the world. Of these, 300,000 were in Russia which, gripped by revolution and civil war, had little interest in their fate. Nansen was able to report to the Assembly in November 1920 that around 200,000 men had been returned to their homes. "Never in my life", he said, "have I been brought into touch with so formidable an amount of suffering."

Nansen continued this work for a further two years until, in his final report to the Assembly in 1922, he was able to state that 427,886 prisoners had been repatriated to around 30 different countries. In paying tribute to his work, the responsible committee recorded that the story of his efforts "would contain tales of heroic endeavour worthy of those in the accounts of the crossing of Greenland and the great Arctic voyage."

Even before this work was complete, Nansen was involved in a further humanitarian effort. On 1 September 1921, prompted by the British delegate Philip Noel-Baker, he accepted the post of the League's High Commissioner for Refugees. His main brief was the resettlement of around two million Russian refugees displaced by the upheavals of the Russian Revolution.

At the same time he tried to tackle the urgent problem of famine in Russia; following a widespread failure of crops around 30 million people were threatened with starvation and death. Despite Nansen's pleas on behalf of the starving, Russia's revolutionary government was feared and distrusted internationally, and the League was reluctant to come to its peoples' aid. Nansen had to rely largely on fundraising from private organisations, and his efforts met with limited success. Later he was to express himself bitterly on the matter:

A major problem impeding Nansen's work on behalf of refugees was that most of them lacked documentary proof of identity or nationality. Without legal status in their country of refuge, their lack of papers meant they were unable to go anywhere else. To overcome this, Nansen devised a document that became known as the "Nansen passport", a form of identity for stateless persons that was in time recognised by more than 50 governments, and which allowed refugees to cross borders legally. Although the passport was created initially for refugees from Russia, it was extended to cover other groups.

While attending the Conference of Lausanne in November 1922, Nansen learned that he had been awarded the Nobel Peace Prize for 1922. The citation referred to "his work for the repatriation of the prisoners of war, his work for the Russian refugees, his work to bring succour to the millions of Russians afflicted by famine, and finally his present work for the refugees in Asia Minor and Thrace". Nansen donated the prize money to international relief efforts.

After the Greco-Turkish War of 1919–1922, Nansen travelled to Constantinople to negotiate the resettlement of hundreds of thousands of refugees, mainly ethnic Greeks who had fled from Turkey after the defeat of the Greek Army. The impoverished Greek state was unable to take them in, and so Nansen devised a scheme for a population exchange whereby half a million Turks in Greece were returned to Turkey, with full financial compensation, while further loans facilitated the absorption of the refugee Greeks into their homeland. Despite some controversy over the principle of a population exchange, the plan was implemented successfully over a period of several years.

From 1925 onwards, Nansen devoted much time trying to help Armenian refugees, victims of Armenian genocide at the hands of the Ottoman Empire during the First World War and further ill-treatment thereafter. His goal was the establishment of a national home for these refugees, within the borders of Soviet Armenia. His main assistant in this endeavour was Vidkun Quisling, the future Nazi collaborator and head of a Norwegian puppet government during the Second World War.

After visiting the region, Nansen presented the Assembly with a modest plan for the irrigation of on which 15,000 refugees could be settled. The plan ultimately failed, because even with Nansen's unremitting advocacy the money to finance the scheme was not forthcoming. Despite this failure, his reputation among the Armenian people remains high.

Nansen wrote "Armenia and the Near East" (1923) wherein he describes the plight of the Armenians in the wake of losing its independence to the Soviet Union. The book was translated into many languages. After his visit to Armenia, Nansen wrote two additional books: "Across Armenia" (1927) and "Through the Caucasus to the Volga" (1930).

Within the League's Assembly, Nansen spoke out on many issues besides those related to refugees. He believed that the Assembly gave the smaller countries such as Norway a "unique opportunity for speaking in the councils of the world." He believed that the extent of the League's success in reducing armaments would be the greatest test of its credibility. He was a signatory to the Slavery Convention of 25 September 1926, which sought to outlaw the use of forced labour. He supported a settlement of the post-war reparations issue and championed Germany's membership of the League, which was granted in September 1926 after intensive preparatory work by Nansen.

On 17 January 1919 Nansen married Sigrun Munthe, a long-time friend with whom he had had a love affair in 1905, while Eva was still alive. The marriage was resented by the Nansen children, and proved unhappy; an acquaintance writing of them in the 1920s said Nansen appeared unbearably miserable and Sigrun steeped in hate.

Nansen's League of Nations commitments through the 1920s meant that he was mostly absent from Norway, and was able to devote little time to scientific work. Nevertheless, he continued to publish occasional papers. He entertained the hope that he might travel to the North Pole by airship, but could not raise sufficient funding. In any event he was forestalled in this ambition by Amundsen, who flew over the pole in Umberto Nobile's airship "Norge" in May 1926. Two years later Nansen broadcast a memorial oration to Amundsen, who had disappeared in the Arctic while organising a rescue party for Nobile whose airship had crashed during a second polar voyage. Nansen said of Amundsen: "He found an unknown grave under the clear sky of the icy world, with the whirring of the wings of eternity through space."
In 1926 Nansen was elected Rector of the University of St Andrews in Scotland, the first foreigner to hold this largely honorary position. He used the occasion of his inaugural address to review his life and philosophy, and to deliver a call to the youth of the next generation. He ended:

We all have a Land of Beyond to seek in our life—what more can we ask? Our part is to find the trail that leads to it. A long trail, a hard trail, maybe; but the call comes to us, and we have to go. Rooted deep in the nature of every one of us is the spirit of adventure, the call of the wild—vibrating under all our actions, making life deeper and higher and nobler.

Nansen largely avoided involvement in domestic Norwegian politics, but in 1924 he was persuaded by the long-retired former Prime Minister Christian Michelsen to take part in a new anti-communist political grouping, the Fatherland League. There were fears in Norway that should the Marxist-oriented Labour Party gain power it would introduce a revolutionary programme. At the inaugural rally of the League in Oslo (as Christiania had now been renamed), Nansen declared: "To talk of the right of revolution in a society with full civil liberty, universal suffrage, equal treatment for everyone ... [is] idiotic nonsense." 

Following continued turmoil between the centre-right parties, there was even an independent petition in 1926 gaining some momentum that proposed for Nansen to head a centre-right national unity government on a balanced budget program, an idea he did not reject. He was the headline speaker at the single largest Fatherland League rally with 15,000 attendees in Tønsberg in 1928. In 1929 he went on his final tour for the League on the ship "Stella Polaris", holding speeches from Bergen to Hammerfest.

In 1929, at age 67, Nansen had a love affair with Brenda Ueland, a 37-year-old Minneapolis-born writer whom he met in New York. The love affair was brief, but he continued to write her love letters until his death, even sending her nude photos of himself.

In between his various duties and responsibilities, Nansen had continued to take skiing holidays when he could. In February 1930, aged 68, he took a short break in the mountains with two old friends, who noted that Nansen was slower than usual and appeared to tire easily. On his return to Oslo he was laid up for several months, with influenza and later phlebitis, and was visited on his sickbed by King Haakon VII.

Nansen was a close friend of a clergyman named Wilhelm. Nansen himself was an atheist.

Nansen died of a heart attack on 13 May 1930. He was given a non-religious state funeral before cremation, after which his ashes were laid under a tree at Polhøgda. Nansen's daughter Liv recorded that there were no speeches, just music: Schubert's "Death and the Maiden", which Eva used to sing. 

In his lifetime and thereafter, Nansen received honours and recognition from many countries. Among the many tributes paid to him subsequently was that of Lord Robert Cecil, a fellow League of Nations delegate, who spoke of the range of Nansen's work, done with no regard for his own interests or health: "Every good cause had his support. He was a fearless peacemaker, a friend of justice, an advocate always for the weak and suffering."

Nansen was a pioneer and innovator in many fields. As a young man he embraced the revolution in skiing methods that transformed it from a means of winter travel to a universal sport, and quickly became one of Norway's leading skiers. He was later able to apply this expertise to the problems of polar travel, in both his Greenland and his "Fram" expeditions.

He invented the "Nansen sledge" with broad, ski-like runners, the "Nansen cooker" to improve the heat efficiency of the standard spirit stoves then in use, and the layer principle in polar clothing, whereby the traditionally heavy, awkward garments were replaced by layers of lightweight material. In science, Nansen is recognised both as one of the founders of modern neurology, and as a significant contributor to early oceanographical science, in particular for his work in establishing the Central Oceanographic Laboratory in Christiania.

Through his work on behalf of the League of Nations, Nansen helped to establish the principle of international responsibility for refugees. Immediately after his death the League set up the Nansen International Office for Refugees, a semi-autonomous body under the League's authority, to continue his work. The Nansen Office faced great difficulties, in part arising from the large numbers of refugees from the European dictatorships during the 1930s. Nevertheless, it secured the agreement of 14 countries (including a reluctant Great Britain) to the Refugee Convention of 1933.

It also helped to repatriate 10,000 Armenians to Yerevan in Soviet Armenia, and to find homes for a further 40,000 in Syria and Lebanon. In 1938, the year in which it was superseded by a wider-ranging body, the Nansen Office was awarded the Nobel Peace Prize. In 1954, the League's successor body, the United Nations, established the Nansen Medal, later named the Nansen Refugee Award, given annually by the United Nations High Commissioner for Refugees to an individual, group or organisation "for outstanding work on behalf of the forcibly displaced".

Numerous geographical features bear his name: the Nansen Basin and the Nansen-Gakkel Ridge in the Arctic Ocean; Mount Nansen in the Yukon region of Canada; Mount Nansen, Mount Fridtjof Nansen and Nansen Island, all in Antarctica; as well as Nansen Island in the Kara Sea, Nansen Land in Greenland and Nansen Island in Franz Josef Land; 853 Nansenia, an asteroid; Nansen crater at the Moon's north pole and Nansen crater on Mars. His Polhøgda mansion is now home to the Fridtjof Nansen Institute, an independent foundation which engages in research on environmental, energy and resource management politics.

"Just a life – the story of Fridtjof Nansen" was released, a 1968 Norwegian/Soviet biographical film with Knut Wigert as Nansen.
The Royal Norwegian Navy launched the first of a series of five s in 2004, with as its lead ship.






</doc>
<doc id="11824" url="https://en.wikipedia.org/wiki?curid=11824" title="Frederick Augustus II of Saxony">
Frederick Augustus II of Saxony

Frederick Augustus II (; 18 May 1797 in Dresden – 9 August 1854 in Brennbüchel, Karrösten, Tyrol) was King of Saxony and a member of the House of Wettin.

He was the eldest son of Maximilian, Prince of Saxony – younger son of the Elector Frederick Christian of Saxony – by his first wife, Caroline of Bourbon, Princess of Parma.

From his birth, it was clear that one day Frederick Augustus would become the ruler of Saxony. His father was the only son of the Elector Frederick Christian of Saxony who left surviving male issue. When the King Frederick Augustus I died (1827) and Anton succeeded him as King, Frederick Augustus became second in line to the throne, preceded only by his father Maximilian.

He was an officer in the War of the Sixth Coalition. However, he had little interest in military affairs.

The July Revolution of 1830 in France marked the beginning of disturbances in Saxony that autumn. The people claimed a change in the constitution and demanded a young regent of the kingdom to share the government with the King Anton. On 1 September the Prince Maximilian renounced his rights of succession in favor of his son Frederick Augustus, who was proclaimed Prince Co-Regent (de: "Prinz-Mitregenten") of Saxony. On 2 February 1832 Frederick Augustus brought Free Autonomy to the cities. Also, by an edict of 17 March of that year, the farmers were freed from the corvée and hereditary submission.

On 6 June 1836, King Anton died and Frederick Augustus succeeded him. As an intelligent man, he was quickly popular with the people as he had been since the time of his regency. The new king solved political questions only from a pure sense of duty. Mostly he preferred to leave these things on the hands of his ministers.

A standardized jurisdiction for Saxony created the Criminal Code of 1836. During the Revolutionary disturbances of 1848 (March Revolution), he appointed liberal ministers in the government, lifted censorship, and remitted a liberal electoral law. Later his attitude changed. On 28 April Frederick August II dissolved the Parliament. In 1849, Frederick Augustus was forced to flee to the Königstein Fortress. The May Uprising was crushed by Saxon and Prussian troops and Frederick was able to return after only a few days.

In 1844 Frederick Augustus, accompanied by his personal physician Carl Gustav Carus, made an informal ("incognito") visit to England and Scotland. Among places they visited were Lyme Regis where he purchased from the local fossil collector and dealer, Mary Anning, an ichthyosaur skeleton for his own extensive natural history collection. It was not a state visit, but the King was the guest of Queen Victoria and Prince Albert at Windsor Castle, visited many of the sights in London and in the university cities of Oxford and Cambridge, and toured widely in England, Wales and Scotland.

During a journey in Tyrol, he had an accident in Brennbüchel in which he fell in front of a horse that stepped on his head. On 8 August 1854, he died in the Gasthof Neuner. He was buried on 16 August in the Katholische Hofkirche of Dresden. In his memory, the Dowager Queen Maria arranged to establish the Königskapelle (King's Chapel) at the accident place, which was consecrated one year later, some of the last members of the Saxon royal family, including Maria Emanuel, Margrave of Meissen, are buried beside the chapel

In Vienna on 26 September 1819 (by proxy) and again in Dresden on 7 October 1819 (in person), Frederick Augustus married firstly with the Archduchess Maria Caroline of Austria (Maria Karoline Ferdinande Theresia Josephine Demetria), daughter of Emperor Francis I of Austria. They had no children.

In Dresden on 24 April 1833 Frederick Augustus married secondly with the Princess Maria Anna of Bavaria (Maria Anna Leopoldine Elisabeth Wilhelmine), daughter of the King Maximilian I Joseph of Bavaria. Like his first marriage, this was childless.

The musician Theodor Uhlig (1822–1853) was an illegitimate son of Frederick Augustus.

Without legitimate issue, after his death Frederick Augustus was succeeded by his younger brother, Johann.


</doc>
<doc id="11826" url="https://en.wikipedia.org/wiki?curid=11826" title="Free market">
Free market

In economics, a free market is a system in which the prices for goods and services are self-regulated by the open market and by consumers. In a free market, the laws and forces of supply and demand are free from any intervention by a government or other authority and from all forms of economic privilege, monopolies and artificial scarcities. Proponents of the concept of free market contrast it with a regulated market in which a government intervenes in supply and demand through various methods such as tariffs used to restrict trade and to protect the local economy. In an idealized free-market economy, prices for goods and services are set freely by the forces of supply and demand and are allowed to reach their point of equilibrium without intervention by government policy.

Scholars contrast the concept of a free market with the concept of a coordinated market in fields of study such as political economy, new institutional economics, economic sociology and political science. All of these fields emphasize the importance in currently existing market systems of rule-making institutions external to the simple forces of supply and demand which create space for those forces to operate to control productive output and distribution. Although free markets are commonly associated with capitalism within a market economy in contemporary usage and popular culture, free markets have also been advocated by anarchists, socialists and some proponents of cooperatives and advocates of profit sharing.

Criticism of the theoretical concept may regard systems with significant market power, inequality of bargaining power, or information asymmetry as less than free, with regulation being necessary to control those imbalances in order to allow markets to function more efficiently as well as produce more desirable social outcomes.

The Heritage Foundation, a conservative and right-wing think tank based in Washington, D.C. that defines capitalism as the free market which is free from state intervention and government regulation, tried to identify the key factors necessary to measure the degree of freedom of economy of a particular country. In 1986, they introduced the Index of Economic Freedom which is based on some fifty variables. While this and other similar indices do not necessarily define a free market, The Heritage Foundation measures the degree to which a modern economy is free. The variables are divided into the following major groups:

According to The Heritage Foundation, these free market principles are what helped the United States transition to a free-market economy. International free trade improved the country and in order for Americans to prosper from a strong economy they had no choice but to embrace it. Each group is assigned a numerical value between 1 and 5 as the index is the arithmetical mean of the values, rounded to the nearest hundredth. Initially, countries which were traditionally considered capitalistic received high ratings, but the method improved over time. Some economists such as Milton Friedman and other "laissez-faire" economists have argued that there is a direct relationship between economic growth and economic freedom and some studies suggest this is true. Ongoing debates exist among scholars regarding methodological issues in empirical studies of the connection between economic freedom and economic growth. These debates and studies continue to explore just what that relationship entails.

The Free Market Monument Foundation defines the principles of a free market as such:

For classical economists such as Adam Smith, the term free market does not necessarily refer to a market free from government interference, but rather free from all forms of economic privilege, monopolies and artificial scarcities. This implies that economic rents, i.e. profits generated from a lack of perfect competition, must be reduced or eliminated as much as possible through free competition.

Economic theory suggests the returns to land and other natural resources are economic rents that cannot be reduced in such a way because of their perfect inelastic supply. Some economic thinkers emphasize the need to share those rents as an essential requirement for a well functioning market. It is suggested this would both eliminate the need for regular taxes that have a negative effect on trade (see deadweight loss) as well as release land and resources that are speculated upon or monopolised. Two features that improve the competition and free market mechanisms. Winston Churchill supported this view by the following statement: "Land is the mother of all monopoly". The American economist and social philosopher Henry George, the most famous proponent of this thesis, wanted to accomplish this through a high land value tax that replaces all other taxes. Followers of his ideas are often called Georgists or geoists and geolibertarians.

Léon Walras, one of the founders of the neoclassical economics who helped formulate the general equilibrium theory, had a very similar view. He argued that free competition could only be realized under conditions of state ownership of natural resources and land. Additionally, income taxes could be eliminated because the state would receive income to finance public services through owning such resources and enterprises.

The "laissez-faire" principle expresses a preference for an absence of non-market pressures on prices and wages such as those from discriminatory government taxes, subsidies, tariffs, regulations of purely private behavior, or government-granted or coercive monopolies. In "The Pure Theory of Capital", Friedrich Hayek argued that the goal is the preservation of the unique information contained in the price itself.

The definition of free market has been disputed and made complex by collectivist political philosophers and socialist economic ideas. This contention arose from the divergence from classical economists such as Richard Cantillon, Adam Smith, David Ricardo and Thomas Robert Malthus and from the continental economic science developed primarily by the Spanish scholastic and French classical economists, including Anne-Robert-Jacques Turgot, Baron de Laune, Jean-Baptiste Say and Frédéric Bastiat. During the marginal revolution, subjective value theory was rediscovered.

Although "laissez-faire" has been commonly associated with capitalism, there is a similar economic theory associated with socialism called left-wing or socialist "laissez-faire", or free-market anarchism, also known as free-market anti-capitalism and free-market socialism to distinguish it from "laissez-faire" capitalism. Critics of "laissez-faire" as commonly understood argue that a truly "laissez-faire" system would be anti-capitalist and socialist.

Various forms of socialism based on free markets have existed since the 19th century. Early notable socialist proponents of free markets include Pierre-Joseph Proudhon, Benjamin Tucker and the Ricardian socialists. These economists believed that genuinely free markets and voluntary exchange could not exist within the exploitative conditions of capitalism. These proposals ranged from various forms of worker cooperatives operating in a free-market economy such as the mutualist system proposed by Proudhon, to state-owned enterprises operating in unregulated and open markets. These models of socialism are not to be confused with other forms of market socialism (e.g. the Lange model) where publicly owned enterprises are coordinated by various degrees of economic planning, or where capital good prices are determined through marginal cost pricing.

Advocates of free-market socialism such as Jaroslav Vanek argue that genuinely free markets are not possible under conditions of private ownership of productive property. Instead, he contends that the class differences and inequalities in income and power that result from private ownership enable the interests of the dominant class to skew the market to their favor, either in the form of monopoly and market power, or by utilizing their wealth and resources to legislate government policies that benefit their specific business interests. Additionally, Vanek states that workers in a socialist economy based on cooperative and self-managed enterprises have stronger incentives to maximize productivity because they would receive a share of the profits (based on the overall performance of their enterprise) in addition to receiving their fixed wage or salary. The stronger incentives to maximize productivity that he conceives as possible in a socialist economy based on cooperative and self-managed enterprises might be accomplished in a capitalist free-market if employee-owned companies were the norm as envisioned by various thinkers including Louis O. Kelso and James S. Albus.

Socialists also assert that free-market capitalism leads to an excessively skewed distribution of income which in turn leads to social instability. As a result, corrective measures in the form of social welfare, re-distributive taxation and administrative costs are required, but they end up being paid into workers hands who spend and help the economy to run. They claim corporate monopolies run rampant in free markets, with endless agency over the consumer. Thus, free-market socialism desires government regulation of markets to prevent social instability, although at the cost of taxpayer dollars.

Conditions that must exist for unregulated markets to behave as free markets are summarized at perfect competition. An absence of any of these perfect competition ideal conditions is a market failure. Most schools of economics allow that regulatory intervention may provide a substitute force to counter a market failure. Under this thinking, this form of market regulation may be better than an unregulated market at providing a free market.

Demand for an item (such as goods or services) refers to the economic market pressure from people trying to buy it. Buyers have a maximum price they are willing to pay and sellers have a minimum price they are willing to offer their product. The point at which the supply and demand curves meet is the equilibrium price of the good and quantity demanded. Sellers willing to offer their goods at a lower price than the equilibrium price receive the difference as producer surplus. Buyers willing to pay for goods at a higher price than the equilibrium price receive the difference as consumer surplus.

The model is commonly applied to wages in the market for labor. The typical roles of supplier and consumer are reversed. The suppliers are individuals, who try to sell (supply) their labor for the highest price. The consumers are businesses, which try to buy (demand) the type of labor they need at the lowest price. As more people offer their labor in that market, the equilibrium wage decreases and the equilibrium level of employment increases as the supply curve shifts to the right. The opposite happens if fewer people offer their wages in the market as the supply curve shifts to the left.

In a free market, individuals and firms taking part in these transactions have the liberty to enter, leave and participate in the market as they so choose. Prices and quantities are allowed to adjust according to economic conditions in order to reach equilibrium and properly allocate resources. However, in many countries around the world governments seek to intervene in the free market in order to achieve certain social or political agendas. Governments may attempt to create social equality or equality of outcome by intervening in the market through actions such as imposing a minimum wage (price floor) or erecting price controls (price ceiling). Other lesser-known goals are also pursued, such as in the United States, where the federal government subsidizes owners of fertile land to not grow crops in order to prevent the supply curve from further shifting to the right and decreasing the equilibrium price. This is done under the justification of maintaining farmers' profits; due to the relative inelasticity of demand for crops, increased supply would lower the price but not significantly increase quantity demanded, thus placing pressure on farmers to exit the market. Those interventions are often done in the name of maintaining basic assumptions of free markets such as the idea that the costs of production must be included in the price of goods. Pollution and depletion costs are sometimes not included in the cost of production (a manufacturer that withdraws water at one location then discharges it polluted downstream, avoiding the cost of treating the water), therefore governments may opt to impose regulations in an attempt to try to internalize all of the cost of production and ultimately include them in the price of the goods.

Advocates of the free market contend that government intervention hampers economic growth by disrupting the natural allocation of resources according to supply and demand while critics of the free market contend that government intervention is sometimes necessary to protect a country's economy from better-developed and more influential economies, while providing the stability necessary for wise long-term investment. Milton Friedman pointed to failures of central planning, price controls and state-owned corporations, particularly in the Soviet Union and China while Ha-Joon Chang cites the examples of post-war Japan and the growth of South Korea's steel industry.

With varying degrees of mathematical rigor over time, the general equilibrium theory has demonstrated that under certain conditions of competition the law of supply and demand predominates in this ideal free and competitive market, influencing prices toward an equilibrium that balances the demands for the products against the supplies. At these equilibrium prices, the market distributes the products to the purchasers according to each purchaser's preference or utility for each product and within the relative limits of each buyer's purchasing power. This result is described as market efficiency, or more specifically a Pareto optimum.

This equilibrating behavior of free markets requires certain assumptions about their agents—collectively known as perfect competition—which therefore cannot be results of the market that they create. Among these assumptions are several which are impossible to fully achieve in a real market, such as complete information, interchangeable goods and services and lack of market power. The question then is what approximations of these conditions guarantee approximations of market efficiency and which failures in competition generate overall market failures. Several Nobel Prizes in Economics have been awarded for analyses of market failures due to asymmetric information.

A free market does not require the existence of competition, however it does require a framework that allows new market entrants. Hence, in the lack of coercive barriers, for example, paid licensing certification for certain services and businesses, competition between businesses flourishes all through the demands of consumers, or buyers. It often suggests the presence of the profit motive, although neither a profit motive or profit itself are necessary for a free market. All modern free markets are understood to include entrepreneurs, both individuals and businesses. Typically, a modern free-market economy would include other features such as a stock exchange and a financial services sector, but they do not define it.

Friedrich Hayek popularized the view that market economies promote spontaneous order which results in a better "allocation of societal resources than any design could achieve". According to this view, market economies are characterized by the formation of complex transactional networks which produce and distribute goods and services throughout the economy. These networks are not designed, but they nevertheless emerge as a result of decentralized individual economic decisions. The idea of spontaneous order is an elaboration on the invisible hand proposed by Adam Smith in "The Wealth of Nations". About the individual, Smith wrote:
By preferring the support of domestic to that of foreign industry, he intends only his own security; and by directing that industry in such a manner as its produce may be of the greatest value, he intends only his own gain, and he is in this, as in many other cases, led by an invisible hand to promote an end which was no part of his intention. Nor is it always the worse for society that it was no part of it. By pursuing his own interest, he frequently promotes that of the society more effectually than when he really intends to promote it. I have never known much good done by those who affected to trade for the public good.

Smith pointed out that one does not get one's dinner by appealing to the brother-love of the butcher, the farmer or the baker. Rather, one appeals to their self-interest and pays them for their labor, arguing:
It is not from the benevolence of the butcher, the brewer or the baker, that we expect our dinner, but from their regard to their own self-interest. We address ourselves, not to their humanity but to their self-love, and never talk to them of our own necessities but of their advantages.

Supporters of this view claim that spontaneous order is superior to any order that does not allow individuals to make their own choices of what to produce, what to buy, what to sell and at what prices due to the number and complexity of the factors involved. They further believe that any attempt to implement central planning will result in more disorder, or a less efficient production and distribution of goods and services.

Critics such as political economist Karl Polanyi question whether a spontaneously ordered market can exist, completely free of distortions of political policy, claiming that even the ostensibly freest markets require a state to exercise coercive power in some areas, namely to enforce contracts, govern the formation of labor unions, spell out the rights and obligations of corporations, shape who has standing to bring legal actions and define what constitutes an unacceptable conflict of interest.

Critics of the free market have argued that in real world situations it has proven to be susceptible to the development of price fixing monopolies. Such reasoning has led to government intervention, e.g. the United States antitrust law.

Two prominent Canadian authors argue that government at times has to intervene to ensure competition in large and important industries. Naomi Klein illustrates this roughly in her work "The Shock Doctrine" and John Ralston Saul more humorously illustrates this through various examples in "The Collapse of Globalism and the Reinvention of the World". While its supporters argue that only a free market can create healthy competition and therefore more business and reasonable prices, opponents say that a free market in its purest form may result in the opposite. According to Klein and Ralston, the merging of companies into giant corporations or the privatization of government-run industry and national assets often result in monopolies or oligopolies requiring government intervention to force competition and reasonable prices. Another form of market failure is speculation, where transactions are made to profit from short term fluctuation, rather from the intrinsic value of the companies or products. This criticism has been challenged by historians such as Lawrence Reed, who argued that monopolies have historically failed to form even in the absence of antitrust law. This is because monopolies are inherently difficult to maintain as a company that tries to maintain its monopoly by buying out new competitors, for instance, is incentivizing newcomers to enter the market in hope of a buy-out.

American philosopher and author Cornel West has derisively termed what he perceives as dogmatic arguments for "laissez-faire" economic policies as free-market fundamentalism. West has contended that such mentality "trivializes the concern for public interest" and "makes money-driven, poll-obsessed elected officials deferential to corporate goals of profit – often at the cost of the common good". American political philosopher Michael J. Sandel contends that in the last thirty years the United States has moved beyond just having a market economy and has become a market society where literally everything is for sale, including aspects of social and civic life such as education, access to justice and political influence. The economic historian Karl Polanyi was highly critical of the idea of the market-based society in his book "The Great Transformation", noting that any attempt at its creation would undermine human society and the common good.

Critics of free market economics range from those who reject markets entirely in favour of a planned economy as advocated by various Marxists to those who wish to see market failures regulated to various degrees or supplemented by government interventions. Keynesians support market roles for government such as using fiscal policy for economic stimulus when actions in the private sector lead to sub-optimal economic outcomes of depressions or recessions. Business cycle is used by Keynesians to explain liquidity traps, by which underconsumption occurs, to argue for government intervention with fiscal policy. David McNally of the University of Houston argues in the Marxist tradition that the logic of the market inherently produces inequitable outcomes and leads to unequal exchanges, arguing that Adam Smith's moral intent and moral philosophy espousing equal exchange was undermined by the practice of the free market he championed. According to McNally, the development of the market economy involved coercion, exploitation and violence that Smith's moral philosophy could not countenance. McNally also criticizes market socialists for believing in the possibility of fair markets based on equal exchanges to be achieved by purging parasitical elements from the market economy such as private ownership of the means of production, arguing that market socialism is an oxymoron when socialism is defined as an end to wage labour.

Some would argue that only one known example of a true free market exists, namely the black market. The black market is under constant threat by the police, but under no circumstances do the police regulate the substances that are being created. The black market produces wholly unregulated goods and are purchased and consumed unregulated. That is to say, anyone can produce anything at any time and anyone can purchase anything available at any time. The alternative view is that the black market is not a free market at all since high prices and natural monopolies are often enforced through murder, theft and destruction. Black markets can only exist peripheral to regulated markets where laws are being regularly enforced.




</doc>
