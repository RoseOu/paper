<doc id="24673" url="https://en.wikipedia.org/wiki?curid=24673" title="Penny Arcade">
Penny Arcade

Penny Arcade is a webcomic focused on video games and video game culture, written by Jerry Holkins and illustrated by Mike Krahulik. The comic debuted in 1998 on the website "loonygames.com". Since then, Holkins and Krahulik have established their own site, which is typically updated with a new comic strip each Monday, Wednesday, and Friday. The comics are accompanied by regular updates on the site's blog.

"Penny Arcade" is among the most popular and longest running webcomics currently online, listed in 2010 as having 3.5 million readers. Holkins and Krahulik are among the first webcomic creators successful enough to make a living from their work. In addition to the comic, Holkins and Krahulik also created Child's Play, a children's charity; PAX, a gaming convention; Penny Arcade TV, a YouTube channel; Pinny Arcade, a pin exchange; and the episodic video game "" with Hothead Games and Zeboyd Games.

The strip features Krahulik and Holkins' cartoon alter egos, John "Gabe" Gabriel and Tycho Brahe, respectively. While often borrowing from the authors' experiences, Holkins and Krahulik do not treat them as literal avatars or caricatures of themselves. The two characters spend much of their time playing and commenting on computer and video games, which forms the basis of the humor in the strip. Most of the time Gabe serves the purpose of the comic and Tycho the comic foil. The strip can feature in-jokes that are explained in the news posts accompanying each comic, written by the authors.

Both Krahulik and Holkins make a living from "Penny Arcade", placing them in a small group of professional webcomic artists devoted to their creations full-time. Originally, like many webcomics, "Penny Arcade" was supported solely by donations. A graph on the main page indicated how much people had donated that month. After hiring Robert Khoo as their business manager, Holkins and Krahulik switched to a different income stream based on advertising and merchandise revenue alone. According to Holkins, the website in 2006 handled more than two million pageviews daily (excluding forum traffic). On November 13, 2005, the website was given a facelift in celebration of their seventh year running and to match the designs of the Child's Play Charity and Penny Arcade Expo websites. Afterwards, the site has been redesigned multiple times.

As a (primarily) topical video gaming news comic, there is little plot or general continuity in "Penny Arcade" strips. Any story sustained for longer than a single strip is referred to as "dreaded continuity", something of a running gag in the newsposts. A character who dies a violent death in one strip will come back in the next, perfectly whole, though occasionally these deaths have an effect on later comics. For example, often, when Gabe kills Tycho or vice versa, the killer takes a certain Pac-Man watch off the dead character, but only if he currently has the watch. Profanity and violence are common in "Penny Arcade" and the strip is known for its surrealism; zombies, a talking alcoholic DIVX player called Div, Santa Claus, a robotic juicer called the "Fruit Fucker 2000", and Jesus, among others, are known to drop in often and for petty reasons. Other such occurrences are implied, if not shown, such as mentioning Dante from "Devil May Cry" living in the building next door. However, the comic does occasionally expand into more serious issues; one even had Krahulik, in the guise of the character Gabe, proposing to his girlfriend of two years, while another had both Gabe and Tycho praising Casey Heynes for standing up to bullying.

Some of the strips are drawn from the perspective of fictional characters within a game or movie. Occasionally, Gabe and Tycho are featured as they would be as characters or players in the game themselves, often having some sarcastic remark to make about some feature or bug in the game. At times the comic also depicts meetings between game developers or business people, and features or mocks the reporters of a news article that is commented on in Holkins' newspost.

"Penny Arcade" has a theme song, "Penny Arcade Theme", written and performed by nerdcore artist MC Frontalot. It was written as a thank-you by Frontalot for the creators of the webcomic linking his website to their front page and declaring him their "rapper laureate" in 2002. The song appears in the dance game "In the Groove".

Mike Krahulik's comic alter ego is energetic and free-spirited, but has a propensity to become extremely angry. He has a Pac-Man tattoo on his right arm, as well as a tattoo in honor of the demise of SNK on his back. His eyes are a shade of slate blue. He almost always wears a yellow Pac-Man shirt, and in one comic he mentioned having a glass eye as a result of an incident after Tycho beat him at "Warcraft II", although no other references to it have been made. He has a fascination with unicorns, a secret love of Barbies, is a dedicated fan of Spider-Man and "Star Wars", and has proclaimed "Jessie's Girl" to be the greatest song of all time. He practices line dancing with the Kansas City Hotsteppers. He is a diabetic, though he continues to consume large quantities of sugar products. He has an odd affinity for a cardboard tube which he had fantasies of wielding as a wandering samurai, often in feudal Japan. He was for a short time addicted to "Tribes" but soon grew out of it. He also has an obsession with his own genitalia and possible latent homosexual tendencies. This theory can be supported by a recent recurrence of Gabriel's "personal" interest in actor Patrick Swayze. Despite this, his "son" is also present in the strip and appears alongside Gabe's wife. As a contrast to Tycho's expansive vocabulary, Gabe usually speaks using only simple, common words. Krahulik named his son "Gabriel" in honor of the character.
Jerry Holkins' comic alter ego (named after the astronomer Tycho Brahe) is bitter and sarcastic. His eyes are burnt sienna, and he's almost invariably clad in a blue-striped sweater. Tycho enjoys books, role-playing video games, using large and uncommon words in conversation, and deflating Gabe's ego. He is a rabid fan of "Harry Potter" and "Doctor Who". He also plays "Dungeons & Dragons" often (the website's previous banner illustrated him holding a 20-sided die), and adopts a wildly theatrical style when acting as a dungeon master. He occasionally makes reference to his scarring childhood, during which his mother physically abused him and blamed him for the family's abandonment by his father due to his body, "swelling with evil" (in fact, his puberty). It has been mentioned that one of his aunts, believing him to be gay, regularly sends him homo-erotic material. Tycho also has a drinking problem. In one strip, after a dream, Tycho is shown to be host to an evil spirit, the presence of which is indicated by his eyes glowing with pink light; this theme is repeated over the course of the strip. Some strips appear to indicate that he has an unhealthy sexual obsession with long-necked animals such as giraffes and ostriches, or even with inhuman alien creatures. In "Poker Night at the Inventory", Tycho is voiced by Kid Beyond.

Krahulik and Holkins began to record and release audio content on March 20, 2006, titled "Downloadable Content." The podcasts specifically captured the creative process that goes into the creation of a "Penny Arcade" comic, usually starting with a perusal of recent gaming news, with conversational tangents and digressions to follow. As well as being a behind-the-scenes look at the creation of "Penny Arcade", Krahulik and Holkins discuss possible subjects for the comic.

The format of the show was mostly "fly-on-the-wall" style, in that the hosts rarely acknowledged the existence of the microphone. There was no theme music, intro, or outro. The podcasts were of varying lengths, beginning abruptly and ending with the idea for the current comic. New episodes were released irregularly, with six month gaps not uncommon.

Although the shows were initially published weekly, Holkins stated in a May 2006 blog post that they have found difficulties when trying to produce the podcasts on a regular basis. The duo planned to keep recording podcasts occasionally.

Since airing the first episode of the new PATV in February 2010, the podcast has not been updated. A new segment has since appeared on PATV called "The Fourth Panel," which presents a fly-on-the-wall look at comics creation much as the podcast did.

On May 8, 2013 Penny Arcade launched a Kickstarter campaign to fund the continuation of "Downloadable Content". The kickstarter was successful, with new Podcasts being added each Wednesday.

"" is an episodic video game based on the strip. The first two episodes were developed by Hothead Games, and were built on a version of the Torque Game Engine. The first episode was released worldwide on May 21, 2008, and the second on October 29, 2008. They were self-published via the PlayStation Network and Xbox Live as well as the PlayGreenhouse.com service created by "Penny Arcade" to distribute independent games. The game features many elements of the "Penny Arcade" universe in a 1920s steampunk setting. In 2010, Krahulik and Holkins announced that the remainder of the series had been cancelled, to allow Hothead to focus on other projects. At PAX Prime 2011, however, it was announced that the series would be revived and developed by Zeboyd Games, with a retro style similar to Zeboyd's past titles. The third episode was released on Steam and on Penny Arcade's web store June 25, 2012. The fourth and final episode was announced in January 2013, and released to Steam and Xbox Live in June 2013.

A teaser trailer released by Telltale Games on August 28, 2010, revealed that Tycho would appear in an upcoming game alongside "Team Fortress 2's" Heavy, Strong Bad and Max. The game, called "Poker Night at the Inventory", was officially revealed on September 2, 2010.

"The Last Christmas" and "The Hawk and the Hare", two stories that were published on the site, were released as motion comics for iOS developed by SRRN Games.

The North American release of "Tekken 6" has a skin for Yoshimitsu based on the Cardboard Tube Samurai. An official DLC skin pack was released for Dungeon Defenders featuring Tycho, Cardboard Tube Samurai Gabe, Annarchy and Jim Darkmagic skins.

Cryptozoic Entertainment released the licensed deck-building card game "Penny Arcade The Game: Gamers Vs. Evil" in 2011, and followed it with the expansion pack "Penny Arcade The Game: Rumble in R'lyeh" in 2012. Playdek released a digital conversion of "Penny Arcade The Game: Gamers Vs. Evil" for iOS in 2012.

"Penny Arcade: The Series" first aired online on February 20, 2010. It is a multi-season documentary series based on the exploits of the Penny Arcade company and its founders Krahulik and Holkins.

Under the banner of "Penny Arcade Presents", Krahulik and Holkins are sometimes commissioned to create promotional artwork/comic strips for new video games, with their signature artistic style and humor. They are usually credited simply as "Penny Arcade" rather than by their actual names. Some of these works have been included with the distribution of the game, and others have appeared on pre-launch official websites. An official list can be found on the Penny Arcade website.

On August 8, 2005, Krahulik announced that "Penny Arcade", in partnership with Sabertooth Games, would be producing a collectible card game based on the "Penny Arcade" franchise. The resulting "Penny Arcade" "battle box" was released in February 2006 as part of the Universal Fighting System.

There are also a few spinoffs from the main comic that have gained independent existences. An example is "" (ELotH:TES), a parody of the written-by-committee fantasy fiction used as back-story for a wide variety of games: originally a one-off gag in the "Penny Arcade" comic, in late 2005 this was expanded into a complete fantasy universe, documented on a hoax "fan-wiki". ELotH:TES first appeared in the webcomic of February 7, 2005, and has subsequently been featured in the comics of November 7, 2005 and November 30, 2005. Several elements of the ELotH:TES universe are featured on the cover of their second comics collection, "Epic Legends of the Magic Sword Kings".

On May 31, 2006 Krahulik announced a new advertising campaign for the Entertainment Software Rating Board. According to Krahulik, the ESRB "wanted a campaign that would communicate to gamers why the ESRB is important even if they don't think it directly affects them." Among the reasons he listed for "Penny Arcade"<nowiki>'</nowiki>s accepting the job was that he and Holkins are both fathers and are concerned about the games their children might play. The ad campaign was rolled out in the summer and fall of 2006 and a second campaign was released in 2012 featuring a mother, a father and a gamer describing the tools employed by the ESRB.

Announced on June 2, 2011, Paramount Pictures had acquired the rights to produce an animated film, via Paramount Animation to make this, of the one-off strip "The New Kid" which was published on October 29, 2010. The strip was one of three mini-strips which featured a cinematic opening to a larger story left unexplored. "The New Kid" is about a boy who's moving to a new planet with his family because of his father's career. The script was written by Gary Whitta and would have been produced by Mary Parent and Cale Boyter.

At PAX Australia in 2016, during a Q&A session, Holkins revealed that changes at Paramount resulted in the movie rights being returned to Penny Arcade and the project canceled. He did note, however, that Whitta's script was complete and the project could move forward with another production company in the future.

The Trenches was a comic series by Krahulik and Holkins in collaboration with webcomic "PvP"'s creator Scott Kurtz. The comic followed a man named Issac and his life as a game tester. The series was launched on August 9, 2011 and featured new strips every Tuesday and Thursday, usually accompanied by a "Tale from the Trenches", which was a short piece submitted by a reader detailing their own experiences in the game industry.

In September 2012, Kurtz stopped illustrating the webcomic, due to lack of time, and was replaced by Mary Cagle, a former intern of his, and the creator of the webcomic Kiwi Blitz. Kurtz still continued to collaborate with Krahulik and Holkins in writing the comic. In late August 2013, illustration was taken over by Ty Halley ("Secret Life of a Journal Writer") and Monica Ray ("Phuzzy Comics"), former contestants of the Penny Arcade series "Strip Search".

"The Trenches" was ultimately abandoned. The last comic was posted January 5, 2016, while the last "Tales" is from September 10, 2015.

Krahulik and Holkins have also released an application for iOS devices called "The Decide-o-tron", presented by Eedar and developed by The Binary Mill. The app works as a recommendation engine for video games; users input games they've enjoyed and the app attempts to predict their ratings of titles they haven't yet played. Holkins described it as "Pandora for games".

Penny Arcade has created two Kickstarter projects. The first was the "Penny Arcade's Paint the Line" card game which was used as an alternative to pre-ordering it and came with an exclusive comic. The second was entitled "Penny Arcade Sells Out" and was intended to replace advertising revenue with crowd funding. The leaderboard ad on the home page of Penny Arcade would be removed if the minimum goal of $250,000 were reached, whereas the entire site would become completely ad-free for a year at $999,999. The reality web series described as "our version of America's Next Top Webcomic" titled "Strip Search" arose from the $450,000 stretch goal.

Krahulik and Holkins created a comic strip which compares the 7th generation consoles that appears in the December 2006 issue of "Wired" magazine.

Every Christmas since 2003, "Penny Arcade" hosts a charity called Child's Play to buy new toys for children's hospitals. They have also sponsored a three-day gaming festival called the Penny Arcade Expo every August since 2004.

Krahulik and Holkins received a cease-and-desist letter from American Greetings Corporation over the use of American Greetings' Strawberry Shortcake and Plum Puddin' characters in the April 14, 2003 "Penny Arcade" strip entitled "Tart as a Double Entendre". The strip was intended as a parody of the works of both American McGee (especially the computer game "Alice") and McFarlane Toys. At the time, McFarlane toys and American McGee made separate toy lines, each portraying a dark, frightening interpretation of the characters and situations from "The Wonderful Wizard of Oz". Krahulik and Holkins' portrayal of Strawberry Shortcake parodied McFarlane Toys' depiction of Dorothy as bound and blindfolded by a pair of munchkins.

Krahulik and Holkins chose not to enter into a legal battle over whether or not the strip was a protected form of parody, and they complied with the cease-and-desist by replacing it with an image directing their audience to send a letter to a lawyer for American Greetings. They later lampooned the incident by portraying an American Greetings employee as a Nazi.

On June 15, 2011, a strip entitled "Reprise" revisited the issue, due to the release of "", another American McGee game. In the strip, Gabe suggests that he and Tycho parody a brand not "under constant surveillance", resulting in a spoof of the "Rainbow Brite" franchise. Holkins stated in the accompanying news post that "it seemed like an incredible opportunity to relive the days of yore."

On October 17, 2005 Krahulik and Holkins donated US$10,000 to the Entertainment Software Association foundation in the name of Jack Thompson, an activist against violence in video games. Earlier, Thompson himself had promised to donate $10,000 if a video game was created in which the player kills video game developers ("A Modest Video Game Proposal"), but after a mod to the game "Grand Theft Auto" was pointed out to already exist, Thompson called his challenge satire (referring to the title of the letter as a reference to "A Modest Proposal") and refused to donate the money. He claimed these games were not going to be manufactured, distributed, or sold like retail games, as his Modest Proposal stated, and therefore, the deal went unfulfilled. His refusal was met with disdain, given that multiple games were created or in the process of being created under Thompson's criteria. Krahulik and Holkins donated the money in his place, with a check containing the memo: "For Jack Thompson, Because Jack Thompson Won't".

Thompson proceeded to phone Krahulik, as related by Holkins in the corresponding news post.

On October 18, 2005 it was reported that Jack Thompson had faxed a letter to Seattle Police Chief Gil Kerlikowske claiming that "Penny Arcade" "employs certain personnel who have decided to commence and orchestrate criminal harassment of me by various means". Holkins defended the site by saying that the "harassment" Thompson referred to was simply "the natural result of a public figure making statements that people disagree with, and letting him know their thoughts on the matter via his publicly available contact information".

On October 21, 2005 Thompson claimed to have sent a letter to John McKay, U.S. Attorney for the Western District of Washington, in an attempt to get the FBI involved. Thompson re-iterated his claims of "extortion" and accused "Penny Arcade" of using "their Internet site and various other means to encourage and solicit criminal harassment". Penny Arcade denied the charge of "extortion", noting that they paid the $10,000 to charity, and asked nothing in return.

Thompson claimed the harassment of him is a direct result of Mike Krahulik's posts, which listed links to the Florida Bar Association. Thompson accused "Penny Arcade" of soliciting complaints to the Bar against him, even though Krahulik actually posted the opposite, asking fans to cease sending letters to the Bar, as the Bar acknowledged that it is aware of Thompson's actions, thanks to previous letters.

The Seattle PD eventually acknowledged receiving a complaint from Thompson, but have commented that they believe the issue to be a civil, rather than criminal, matter. They noted that this was from initial impressions of the letter they received, and their criminal investigations bureau is reviewing the letter to make sure that there were not any criminal matters that they missed.

On the same day, Scott Kurtz, creator of the webcomic "PvP" and a longtime friend of Krahulik and Holkins, used the image of the letter Thompson sent to the Seattle PD to create a parody letter in which Jack attempts to enlist the aid of the Justice League of America by claiming Gabe and Tycho to be villains of some description.

The "Penny Arcade" shop had at the time sold an "I hate Jack Thompson" T-shirt, claiming that every living creature, including Thompson's own mother, hates Jack Thompson.

On March 21, 2007 Thompson filed a countersuit to the lawsuit brought against him by Take Two Interactive claiming that they are at the center of a RICO conspiracy. "Penny Arcade" was named as one of the co-conspirators. At Sakura-Con 2007, Krahulik announced that the suit had been dropped.

An August 11, 2010 comic entitled "The Sixth Slave" wherein an NPC pleads with a player to save him from being raped nightly by monsters called "dickwolves", drew criticism from many commentators, including from "The American Prospect" and "The Boston Phoenix". Krahulik and Holkins dismissed these criticisms, later selling "Team Dickwolves" T-shirts based on the strip. They later removed the "Team Dickwolves" shirt from their store due to complaints that it made potential PAX attendees uncomfortable. After the removal, Krahulik posted online that removing the shirts was only partly caving to pressure but mainly due to people who had personally emailed him and were reasonable with their concerns. Krahulik also stated that anyone still hesitant about going to PAX even after removal of the shirts should not come to PAX. In September 2013, on the last day of PAX, Krahulik told a panel that he thought that "pulling the dickwolves merchandise was a mistake", to cheers from the crowd. However, Krahulik later apologized on the "Penny Arcade" website, stating that he regretted contributing to the furor that had followed the original comic.

Both critics of the comic strip and Krahulik and Holkins, made claims of receiving verbal abuse through social media and death threats.

"John Gabriel's Greater Internet Fuckwad Theory" was posted in the "Penny Arcade" strip published March 19, 2004. It regards the online disinhibition effect, in which Internet users exhibit unsociable tendencies while interacting with other Internet users. Krahulik and Holkins suggest that, given both anonymity and an audience, an otherwise regular person becomes aggressively antisocial. In 2013, Holkins gave the corollary that "Normal Person - "Consequences" + Audience = Total Fuckwad".

Clay Shirky, an adjunct professor at New York University who studies social and economic effects of Internet technologies, explains: "There’s a large crowd and you can act out in front of it without paying any personal price to your reputation,” which "creates conditions most likely to draw out the typical Internet user’s worst impulses." In an "Advocate" article about online homophobia, this theory was used to account for behavior on online forums where one can remain anonymous in front of an audience: for instance, posting comments on popular YouTube videos.


On December 13, 2006, "Next Generation Magazine" rated Krahulik and Holkins among its "Top 25 People of the Year". Also appearing on the list were Nintendo of America President Reggie Fils-Aime and former Xbox corporate vice-president Peter Moore. Krahulik made a post about the honor, in which he explained that "Penny Arcade" was created only because Next Gen rejected the duo's entry to a comic contest many years before. "Entertainment Weekly" listed "Penny Arcade" on their "100 Sites to Bookmark Now," calling it "a hilarious and smart webcomic for gamers." MTV Online named Holkins and Krahulik two of the world's most influential gamers, saying "they have become the closest the medium has to leaders of a gamers' movement." Time.com named "Penny Arcade" as one of its "50 Best Websites" for 2008 "...for the way it pokes fun at the high-tech industry and the people who love it."
1UP.com described it as "the One True Gaming Webcomic." "Penny Arcade" was used along with "American Elf", "Fetus-X", and "Questionable Content" as an example of comics using the web to create "an explosion of diverse genres and styles" in Scott McCloud's 2006 book "Making Comics".

On March 5, 2009, the Washington State Senate honored Holkins and Krahulik, both originally from Spokane, for the contribution that they had made to the state, the video game industry, and to children's charities from around the world courtesy of their Child's Play initiative. Later in March, "Penny Arcade" won the category "Best Webcomic" in the fan voted Project Fanboy Awards for 2008.

In 2010, Holkins, Krahulik, and Khoo were awarded the annual "Ambassador Award" at GDC's Game Developers Choice Awards for contributions they had made to the industry. The same year, "Time" included Holkins and Krahulik in the annual "Time 100", the magazine's listing of the world's 100 most influential people.

In July 2015, Holkins and Krahulik were recognized as "Multimedia Empire Builders" in Ad Week's 10 Visual Artists Changing the Way We See Advertising issue.




</doc>
<doc id="24675" url="https://en.wikipedia.org/wiki?curid=24675" title="Permanent Way Institution">
Permanent Way Institution

The Permanent Way Institution is a technical Institution which aims to provide technical knowledge, advice and support to all those engaged in rail infrastructure systems worldwide.

Permanent Way is used to describe the course of a railway line, including the components that form the track, aggregate that supports the track and the civil engineering assets covering bridges, tunnels, viaducts and earthworks.

The Permanent Way Institution is split up into a number of sections throughout the United Kingdom and also has internationally located sections across the world.

Membership is open to anyone who is either actively involved in the rail industry, retired or just has a general interest in rail infrastructure engineering.

Home Sections are:

Ashford, 
Croydon & Brighton, 
Glasgow, 
London, 
North Wales, 
Wessex, 
Birmingham, 
Darlington & NE, 
Manchester & Liverpool, 
Nottingham & Derby, 
South & West Wales, 
West Yorkshire, 
Bristol & West of England, 
Edinburgh, 
Lancaster, Barrow & Carlisle, 
Milton Keynes, 
Sheffield & Doncaster, 
Thames Valley, 
York






</doc>
<doc id="24676" url="https://en.wikipedia.org/wiki?curid=24676" title="President of Ireland">
President of Ireland

The president of Ireland () is the head of state of Ireland and the supreme commander of the Irish Defence Forces.

The president holds office for seven years, and can be elected for a maximum of two terms. The president is directly elected by the people, although there is no poll if only one candidate is nominated, which has occurred on six occasions to date. The presidency is largely a ceremonial office, but the president does exercise certain limited powers with absolute discretion. The president acts as a representative of the Irish state and guardian of the constitution. The president's official residence is in Phoenix Park, Dublin. The office was established by the Constitution of Ireland in 1937, the first president took office in 1938, and became internationally recognised as head of state in 1949 following the coming into force of the Republic of Ireland Act.

The current president is Michael D. Higgins, who was first elected on 29 October 2011. His inauguration was held on 11 November 2011. He was re-elected for a second term on 26 October 2018.

The Constitution of Ireland provides for a parliamentary system of government, under which the role of the head of state is largely a ceremonial one. The president is formally one of three parts of the Oireachtas (national parliament), which also comprises Dáil Éireann (the house of representatives or lower house) and Seanad Éireann (the Senate or upper house).

Unlike most parliamentary republics, the president is not even the "nominal" chief executive. Rather, executive authority in Ireland is expressly vested in the government (cabinet). The government is obliged, however, to keep the president generally informed on matters of domestic and foreign policy. Most of the functions of the president may be carried out only in accordance with the strict instructions of the Constitution, or the binding "advice" of the government. The president does, however, possess certain personal powers that may be exercised at his or her discretion.

The main functions are prescribed by the Constitution:

Other functions specified by statute or otherwise include:


The president possesses the following powers exercised "in his absolute discretion" according to the English version of the Constitution. The Irish version states that these powers are exercised "as a chomhairle féin" which is usually translated as "under his own counsel." Lawyers have suggested that a conflict may exist in this case between both versions of the constitution. In the event of a clash between the Irish and English versions of the constitution, the Irish one is given supremacy. While "absolute discretion" appears to leave some freedom for manoeuvre for a president in deciding whether to initiate contact with the opposition, "own counsel" has been interpreted by some lawyers as suggesting that "no" contact whatsoever can take place. As a result, it is considered controversial for the president to be contacted by the leaders of any political parties in an effort to influence a decision made using the discretionary powers. It is required that, before exercising certain reserve powers, the president consult the Council of State. However, the president is not compelled to act in accordance with the council's advice.

The Taoiseach is required to resign if he has "ceased to retain the support of a majority in Dáil Eireann," unless he asks the president to dissolve the Dáil. The president has the right to refuse such a request, in which case the Taoiseach must resign immediately. This power has never been invoked. However, the necessary circumstances existed in 1944, 1982 and 1994. The apparent discrepancy, referred to above, between the Irish and English versions of the Constitution has discouraged presidents from contemplating the use of the power. On the three occasions when the necessary circumstances existed, presidents have adopted an ultra-strict policy of non-contact with the opposition. The most notable instance of this was in January 1982, when Patrick Hillery instructed an aide, Captain Anthony Barber, to ensure that no telephone calls from the opposition were to be passed on to him. Nevertheless, three opposition figures, including Fianna Fáil leader Charles Haughey, demanded to be connected to Hillery, with Haughey threatening to end Barber's career if the calls weren't put through. Hillery, as Supreme Commander of the Defence Forces, recorded the threat in Barber's military personnel file and recorded that Barber had been acting on his instructions in refusing the call. Even without this consideration, refusing such a request would arguably create a constitutional crisis, as it is considered a fairly strong constitutional convention that the head of state always grants a parliamentary dissolution.

If requested to do so by a petition signed by a majority of the membership of the Seanad, and one-third of the membership of the Dáil, the president may, after consultation with the Council of State, decline to sign into law a bill (other than a bill to amend the constitution) they consider to be of great "national importance" until it has been approved by either the people in a referendum or the Dáil reassembling after a general election, held within eighteen months. This power has never been used, and no such petition has been invoked. Of the 60 senators, 11 are nominated by the Taoiseach, so there is rarely a majority opposed to a government bill.

The president may appoint up to seven members of the Council of State, and remove or replace such appointed members. (See list of presidential appointees to the Council of State.) The following powers all require prior consultation with the Council of State, although the president need not take its advice:

The president is directly elected by secret ballot using the instant-runoff voting, the single-winner analogue of the Single Transferable Vote. Under the Presidential Elections Act, 1993 a candidate's election formally takes place in the form of a 'declaration' by the returning officer. Where more than one candidate is nominated, the election is 'adjourned' so that a ballot can take place, allowing the electors to choose between candidates. A presidential election is held in time for the winner to take office the day after the end of the incumbent's seven-year term. In the event of premature vacancy, an election must be held within sixty days.

Only resident Irish citizens aged eighteen or more may vote; a 1983 bill to extend the right to resident British citizens was ruled unconstitutional.

Candidates must be Irish citizens and over 35 years old. However, there is a discrepancy between the English- and Irish-language texts of Article 12.4.1º. According to the English text, an eligible candidate "has reached his thirty-fifth year of age", whereas the Irish text has this as "ag a bhfuil cúig bliana tríochad slán" ("has completed his thirty-five years"). Because a person's thirty-fifth year of life begins on their thirty-fourth birthday, this means there is a year's difference between the minimum ages as stated in the two texts. Various proposals have been made to amend the Constitution so as to eliminate this discrepancy. At present, however, the Irish version of the subsection prevails in accordance with the rule stated in Article 25.5.4º. The current government has introduced the Thirty-fifth Amendment of the Constitution (Age of Eligibility for Election to the Office of President) Bill 2015 to reduce the age of candidacy from 35 to 21, which was put to referendum in May 2015 but the bill was heavily defeated, with approximately 73% of voters voting against reducing the age of eligibility.

Presidents can serve a maximum of two terms, consecutive or otherwise. They must be nominated by one of the following:
Where only one candidate is nominated, he or she is deemed elected without the need for a ballot. For this reason, where there is a consensus among political parties not to have a contest, the president may be 'elected' without the occurrence of an actual ballot. Since the establishment of the office this has occurred on six occasions.

The most recent presidential election was held on 26 October 2018.

There is no office of vice president of Ireland. In the event of a premature vacancy a successor must be elected within sixty days. In a vacancy or where the president is unavailable, the duties and functions of the office are carried out by a presidential commission, consisting of the chief justice, the ceann comhairle (speaker) of the Dáil, and the cathaoirleach (chairperson) of the Seanad. Routine functions, such as signing bills into law, have often been fulfilled by the presidential commission when the president is abroad on a state visit. The government's power to prevent the president leaving the state is relevant in aligning the diplomatic and legislative calendars.

Technically each president's term of office expires at midnight on the day before the new president's inauguration. Therefore, between midnight and the inauguration the following day the presidential duties and functions are carried out by the presidential commission. The constitution also empowers the Council of State, acting by a majority of its members, to "make such provision as to them may seem meet" for the exercise of the duties of the president in any contingency the constitution does not foresee. However, to date, it has never been necessary for the council to take up this role. Though an outgoing president of Ireland who has been re-elected is usually described in the media as "president" before the taking of the Declaration of Office, that is actually incorrect. The Irish Constitution makes it clear that a president's term of office expires on the day before the inauguration of their successor. In the interregnum period, the presidential commission acts as president, though given that it is usually for less than 11 hours no presidential commission has ever been called on to do anything in that period. Technically for that period the outgoing president is a "former" president and, if re-elected, "president-elect".

Vacancies in the presidency have occurred three times: on the death of Erskine Hamilton Childers in 1974, and on the resignations of Cearbhall Ó Dálaigh in 1976 and Mary Robinson in 1997.

The official residence of the president is Áras an Uachtaráin, located in the Phoenix Park in Dublin. The ninety-two-room building formerly served as the 'out-of-season' residence of the Irish Lord Lieutenant and the residence of two of the three Irish Governors-General: Tim Healy and James McNeill. The president is normally referred to as 'President' or 'Uachtarán', rather than 'Mr/Madam President' or similar forms. The style used is normally "His Excellency/Her Excellency" (); sometimes people may orally address the president as 'Your Excellency' ( ), or simply 'President' ( (vocative case)). The Presidential Salute is taken from the National Anthem, "Amhrán na bhFiann". It consists of the first four bars followed by the last five, without lyrics.

The Constitution provides that the president of Ireland is inaugurated in a major public ceremony. The ceremony takes place on the day following the expiry of the term of office of the preceding president. No location is specified in the constitution, but all inaugurations have taken place in Saint Patrick's Hall in the State Apartments in Dublin Castle. The ceremony is transmitted live by national broadcaster RTÉ on its principal television and radio channels, typically from around 11 am. To highlight the significance of the event, all key figures in the executive (the government of Ireland), the legislature (Oireachtas) and the judiciary attend, as do members of the diplomatic corps and other invited guests.

During the period of the Irish Free State (1922 to 1937), the governor-general had been installed into office as the representative of the Crown in a low-key ceremony, twice in Leinster House (the seat of the Oireachtas), but in the case of the last governor-general, Domhnall Ua Buachalla, in his brother's drawing room. By contrast, the Constitution of Ireland adopted in 1937, provided that the president of Ireland would be inaugurated in state in a major public ceremony.

Under the Constitution, in assuming office the president must subscribe to a formal declaration, made publicly and in the presence of members of both Houses of the Oireachtas, judges of the Supreme Court and the High Court, and other "public personages". The inauguration of the president takes place in St Patrick's Hall in Dublin Castle. The declaration is specified in Article 12.8:

To date every president has subscribed to the declaration in Irish. Erskine H. Childers, who never learnt Irish and spoke with a distinctive Oxbridge accent that made pronouncing Irish quite difficult, opted with some reluctance for the Irish version in 1973. Pictures of the event show Childers reading from an exceptionally large board where it had been written down phonetically for him. At his second inauguration in 2018, Michael D. Higgins first made the declaration in Irish, then repeated it in English.

In 1993 the United Nations Human Rights Committee expressed concern that, because of its religious language, the declaration amounts to a religious test for office. The Oireachtas Committee in 1998 recommended that the religious references be made optional.

Having taken the Declaration of Office, the new president traditionally delivers an address to the guests. Constitutionally all addresses or messages to 'the Nation' or to 'the Oireachtas' are supposed to have prior government approval. Some lawyers have questioned whether the speech at the inauguration should fall into the category requiring government approval. However, as it is impractical to get approval given that the new president is only president for a matter of moments before delivering the speech and so has not had a time to submit it, any constitutional questions as to its status are ignored.

Inauguration Day involves a lot of ritual and ceremonial. Until 1983 the morning saw the president-elect, accompanied by his spouse, escorted by the Presidential Motorcycle Escort to one of Dublin's cathedrals. If they were Catholic they were brought to St Mary's Pro-Cathedral for a Pontifical High Mass. If they were Church of Ireland, they were brought to St Patrick's Cathedral for a Divine Service. In the 1970s instead of separate denominational ceremonies a single ecumenical multi-faith service was held in the cathedral of the faith of the president-elect. Some additional religious ceremonies also featured: President-elect Cearbhall Ó Dálaigh attended a prayer ceremony in a synagogue in Dublin to reflect his longstanding relationship with the Jewish Community in Ireland.
In 1983, to reduce the costs of the day in a period of economic retrenchment, the separate religious blessing ceremony was incorporated into the inauguration ceremony itself, with the president-elect blessed by representatives of the Roman Catholic Church, the Church of Ireland, the Presbyterian Church, Methodism, the Society of Friends, and the Jewish and Islamic faiths. This inter-faith service has featured in the inaugurations since 1983. Since 2011, a representative from the Humanist Association of Ireland, representing humanism and the non-religious population of Ireland, has appeared alongside ministers of a religion.

For the first inauguration in 1938 President-elect Douglas Hyde wore a morning suit, with black silk top hat. Morning suits continued to be a standard feature of Irish presidential inaugurations until 1997 when Mary McAleese, whose husband disliked wearing formal suits, abolished their use for inaugurations (and for all other presidential ceremonial). From then, guests were required to wear plain business suits, and judges were prohibited from wearing their distinctive wigs and gowns. Ambassadors were also discouraged from wearing national dress.

The president-elect (unless they are already a serving president, in which case they will already be living in the presidential residence) are usually driven to the inauguration from their private home. After the ceremony they are driven through the streets of Dublin to Áras an Uachtaráin, the official presidential residence, where they are welcomed by the secretary-general to the president, the head of the presidential secretariat.

That evening, the Irish government hosts a reception in their honour in the State Apartments (the former Royal Apartments) in Dublin Castle. Whereas the dress code was formerly white tie affair, it is now more usually black tie.

The president can be removed from office in two ways, neither of which has ever been invoked. The Supreme Court, in a sitting of at least five judges, may find the president "permanently incapacitated", while the Oireachtas may remove the president for "stated misbehaviour". Either house of the Oireachtas may instigate the latter process by passing an impeachment resolution, provided at least thirty members move it and at least two-thirds support it. The other house will then either investigate the stated charges or commission a body to do so; following which at least two-thirds of members must agree both that the president is guilty and that the charges warrant removal.

As head of state of Ireland, the president receives the highest level of protection in the state. Áras an Uachtaráin is protected by armed guards from the Garda Síochána and Defence Forces at all times, and is encircled by security fencing and intrusion detection systems. At all times the president travels with an armed security detail in Ireland and overseas, which is provided by the Special Detective Unit (SDU), an elite wing of the Irish police force. Protection is increased if there is a known threat. The presidential limousine is a Mercedes-Benz S-Class LWB. The Presidential Limousine is dark navy blue and carries the presidential standard on the left front wing and the tricolour on the right front wing. When travelling the presidential limousine is always accompanied by support cars (normally BMW 5 Series, Audi A6 and Volvo S60 driven by trained drivers from the SDU) and several Garda motorcycle outriders from the Garda Traffic Corps which form a protective convoy around the car.

The president-elect is usually escorted to and from the ceremony by the Presidential Motorcycle Escort ceremonial outriders. Until 1947 they were a cavalry mounted escort, wearing light blue hussar-style uniforms. However to save money the first Inter-Party Government replaced the Irish horses by Japanese motorbikes, which the then Minister for Defence believed would be "much more impressive."

At the presidential inauguration in 1945, alongside the mounted escort on horseback, president-elect Seán T. O'Kelly rode in the old state landau of Queen Alexandra the Queen Mother. The use of the state carriage was highly popular with crowds. However an accident with a later presidential carriage at the Royal Dublin Society Horse show led to the abolition of the carriage and its replacement by a Rolls-Royce Silver Wraith in 1947. The distinctive 1947 Rolls-Royce is still used to bring the president to and from the inauguration today.

The Presidential State Car is a 1947 Rolls-Royce Silver Wraith landaulette, which is used only for ceremonial occasions.

The president also has the full use of all Irish Air Corps aircraft at his/her disposal if so needed, including helicopters and private jets.

The office of president was established in 1937, in part as a replacement for the office of governor-general that existed during the 1922–37 Irish Free State. The seven-year term of office of the president was inspired by that of the presidents of Weimar Germany. At the time the office was established critics warned that the post might lead to the emergence of a dictatorship. However, these fears were not borne out as successive presidents played a limited, largely apolitical role in national affairs.

During the period of 1937 to 1949 it was unclear whether the Irish head of state was actually the president of Ireland or George VI, the king of Ireland. This period of confusion ended in 1949 when the state was declared to be a republic. The 1937 constitution did not mention the king, but neither did it state that the president was head of state, saying rather that the president "shall take precedence over all other persons in the State". The president exercised some powers that could be exercised by heads of state but which could also be exercised by governors or governors-general, such as appointing the government and promulgating the law.

However, in 1936, George VI had been declared "King of Ireland" and, under the External Relations Act of the same year, it was this king who represented the state in its foreign affairs. Treaties, therefore, were signed in the name of the King of Ireland, who also accredited ambassadors and received the letters of credence of foreign diplomats. This role meant, in any case, that George VI was the Irish head of state in the eyes of foreign nations. The Republic of Ireland Act 1948, which came into force in April 1949, proclaimed a republic and transferred the role of representing the state abroad from the monarch to the president. No change was made to the constitution.

After the inaugural presidency of Douglas Hyde, who was an interparty nominee for the office, the nominees of the Fianna Fáil political party won every presidential election until 1990. The party traditionally used the nomination as a reward for its most senior and prominent members, such as party founder and longtime Taoiseach Éamon de Valera and European Commissioner Patrick Hillery. Most of its occupants to that time followed Hyde's precedent-setting conception of the presidency as a conservative, low-key institution that used its ceremonial prestige and few discretionary powers sparingly. In fact, the presidency was such a quiet position that Irish politicians sought to avoid contested presidential elections as often as possible, feeling that the attention such elections would bring to the office was an unnecessary distraction, and office-seekers facing economic austerity would often suggest the elimination of the office as a money-saving measure.

Despite the historical meekness of the presidency, however, it has been at the centre of some high-profile controversies. In particular, the fifth president, Cearbhall Ó Dálaigh, faced a contentious dispute with the government in 1976 over the signing of a bill declaring a state of emergency, which ended in Ó Dálaigh's resignation. His successor, Patrick Hillery, was also involved in a controversy in 1982, when then-Taoiseach Garret FitzGerald requested a dissolution of the Dáil Éireann. Hillery was bombarded with phone calls from opposition members urging him to refuse the request, an action that Hillery saw as highly inappropriate interference with the president's constitutional role and resisted the political pressure.

The presidency began to be transformed in the 1990s. Hillery's conduct regarding the dissolution affair in 1982 came to light in 1990, imbuing the office with a new sense of dignity and stability. However, it was Hillery's successor, seventh president Mary Robinson, who ultimately revolutionized the presidency. The winner of an upset victory in the highly controversial election of 1990, Robinson was the Labour nominee, the first president to defeat Fianna Fáil in an election and the first female president. Upon election, however, Robinson took steps to de-politicize the office. She also sought to widen the scope of the presidency, developing new economic, political and cultural links between the state and other countries and cultures, especially those of the Irish diaspora. Robinson used the prestige of the office to activist ends, placing emphasis during her presidency on the needs of developing countries, linking the history of the Great Irish Famine to today's nutrition, poverty and policy issues, attempting to create a bridge of partnership between developed and developing countries.

After the 2018 presidential election the official salary or "personal remuneration" of the president will be €249,014. The incumbent, Michael D. Higgins, chooses to receive the same salary although he is entitled to a higher figure of €325,507. The president's total "emoluments and allowances" includes an additional €317,434 for expenses. The Office of the President's total budget estimate for 2017 was €3.9 million, of which €2.6 million was for pay and running costs, and the balance for the "President's Bounty" paid to centenarians on their hundredth birthday.

The salary was fixed at IR£5000 from 1938 to 1973, since when it has been calculated as 10% greater than that of the Chief Justice. After the post-2008 Irish economic downturn most public-sector workers took significant pay cuts, but the Constitution prohibited a reduction in the salary of the president and the judiciary during their terms of office, in order to prevent such a reduction being used by the government to apply political pressure on them. While a 2011 Constitutional amendment allows judges' pay to be cut, it did not extend to the president, although incumbent Mary McAleese offered to take a voluntary cut in solidarity.

The text of the Constitution of Ireland, as originally enacted in 1937, made reference in its Articles 2 and 3 to two geopolitical entities: a thirty-two county 'national territory' (i.e., the island of Ireland), and a twenty-six county 'state' formerly known as the Irish Free State. The implication behind the title 'president of Ireland' was that the president would function as the head of all Ireland. However, this implication was challenged by the Ulster Unionists and the United Kingdom of Great Britain and Northern Ireland which was the state internationally acknowledged as having jurisdiction over Northern Ireland. Articles 2 and 3 were substantially amended in consequence of the 1998 Good Friday Agreement.

Ireland in turn challenged the proclamation in the United Kingdom of Queen Elizabeth II in 1952 as '[Queen] of the United Kingdom of Great Britain and Northern Ireland'. The Irish government refused to attend royal functions as a result; for example, Patrick Hillery declined on government advice to attend the wedding of the Prince of Wales to Lady Diana Spencer in 1981, to which he had been invited by Queen Elizabeth, just as Seán T. O'Kelly had declined on government advice to attend the 1953 Coronation Garden Party at the British Embassy in Dublin. Britain in turn insisted on referring to the president as 'president of the Republic of Ireland' or 'president of the Irish Republic'. Letters of Credence from Queen Elizabeth, on the British government's advice, appointing United Kingdom ambassadors to Ireland were not addressed to the 'president of Ireland' but to the president personally (for example: 'President Hillery').

The naming dispute and consequent avoidance of contact at head of state level has gradually thawed since 1990. President Robinson (1990–97) chose unilaterally to break the taboo by regularly visiting the United Kingdom for public functions, frequently in connection with Anglo-Irish Relations or to visit the Irish emigrant community in Great Britain. In another breaking of precedent, she accepted an invitation to Buckingham Palace by Queen Elizabeth II. Palace accreditation supplied to journalists referred to the "visit of the president of Ireland". Between 1990 and 2010, both Robinson and her successor President McAleese (1997–2011) visited the Palace on numerous occasions, while senior members of the British royal family – the Prince of Wales, the Duke of York, the Earl of Wessex and the Duke of Edinburgh – all visited both presidents of Ireland at Áras an Uachtaráin. The presidents also attended functions with the Princess Royal. President Robinson jointly hosted a reception with the queen at St. James's Palace, London, in 1995, to commemorate the one hundred and fiftieth anniversary of the foundation of the Queen's Colleges in 1845 (the Queen's Colleges are now known as the Queen's University of Belfast, University College, Cork, and National University of Ireland, Galway). These contacts eventually led to a state visit of Queen Elizabeth to Ireland in 2011.

Though the president's title implicitly asserted authority in Northern Ireland, in reality the Irish president needed government permission to visit there. (The Constitution of Ireland in Article 3 explicitly stated that "[p]ending the re-integration of the national territory" the authority of the Irish state did not extend to Northern Ireland. Presidents prior to the presidency of Mary Robinson were regularly refused permission by the Irish government to visit Northern Ireland.)

However, since the 1990s and in particular since the Good Friday Agreement of 1998, the president has regularly visited Northern Ireland. President McAleese, who was the first president to have been born in Northern Ireland, continued on from President Robinson in this regard. In a sign of the warmth of modern British-Irish relations, she has even been warmly welcomed by most leading unionists. At the funeral for a child murdered by the Real IRA in Omagh she symbolically walked up the main aisle of the church hand-in-hand with the Ulster Unionist Party leader and then First Minister of Northern Ireland, David Trimble. But in other instances, Mary McAleese had been criticised for certain comments, such as a reference to the way in which Protestant children in Northern Ireland had been brought up to hate Catholics just as German children had been encouraged to hate Jews under the Nazi regime, on 27 January 2005, following her attendance at the ceremony commemorating the sixtieth anniversary of the liberation of Auschwitz concentration camp. These remarks caused outrage among Northern Ireland's unionist politicians, and McAleese later apologised and conceded that her statement had been unbalanced.

There have been many suggestions for reforming the office of president over the years. In 1996, the Constitutional Review Group recommended that the office of President should remain largely unchanged. However, it suggested that the Constitution should be amended to explicitly declare the president to be head of state (at present that term does not appear in the text), and that consideration be given to the introduction of a constructive vote of no confidence system in the Dáil, along the lines of that in Germany. If this system were introduced then the power of the president to refuse a Dáil dissolution would be largely redundant and could be taken away. The All-party Oireachtas Committee on the Constitution's 1998 Report made similar recommendations.

In an October 2009 poll, concerning support for various potential candidates in the 2011 presidential election conducted by the "Sunday Independent", a "significant number" of people were said to feel that the presidency is a waste of money and should be abolished.

The functions of the president were exercised by the Presidential Commission from the coming into force of the Constitution on 29 December 1937 until the election of Douglas Hyde in 1938, and during the vacancies of 1974, 1976, and 1997.

Currently, there are two living former presidents: Mary Robinson and Mary McAleese. Former presidents who are able and willing to act are members of the Council of State.






</doc>
<doc id="24677" url="https://en.wikipedia.org/wiki?curid=24677" title="Premier of Queensland">
Premier of Queensland

The Premier of Queensland is the head of government in the Australian state of Queensland.

By convention the Premier is the leader of the party with a parliamentary majority in the unicameral Legislative Assembly of Queensland. The Premier is appointed by the Governor of Queensland.

The incumbent Premier of Queensland since the 2015 election is Annastacia Palaszczuk of the Labor Party.

Under section 42 of the Constitution of Queensland the Premier and other members of Cabinet are appointed by the Governor and are collectively responsible to Parliament. The text of the Constitution assigns to the Premier certain powers, such as the power to assign roles (s. 25) to Assistant Ministers (formerly known as Parliamentary Secretaries), and to appoint Ministers as acting Ministers (s. 45) for a period of 14 days.

In practice, under the conventions of the Westminster System followed in Queensland, the Premier's power is derived from two sources: command of a majority in the Legislative Assembly, and the Premier's role as chair of Cabinet, determining the appointment and roles of Ministers. Although ministerial appointments are the prerogative of the Governor of Queensland, in normal circumstances the Governor will make these appointments under the "advice" (in reality, direction) of the Premier.

Immediately following an election for the Legislative Assembly, the Governor will call on the leader of the party which commands a majority in the Legislative Assembly, and ask them to commission a government. A re-elected government will be resworn, with adjustments to the ministry as determined by the Premier.

The Premier has an office in the Executive Annexe of Parliament House, Brisbane, which is normally used while Parliament is sitting. At other times the Premier's ministerial office is in 1 William Street, which is across the road from the Executive Annexe.

Before the 1890s, there was no developed party system in Queensland. Political affiliation labels before that time indicate a general tendency only. Before the end of the first decade of the twentieth century, political parties were more akin to parliamentary factions, and were fluid, informal and disorganised by modern standards.

, six former premiers are alive, the oldest being Russell Cooper (1989, born 1941). The most recent premier to die was Wayne Goss (1951–2014), on 10 November 2014.



</doc>
<doc id="24678" url="https://en.wikipedia.org/wiki?curid=24678" title="Premier of South Australia">
Premier of South Australia

The Premier of South Australia is the head of government in the state of South Australia, Australia. The Government of South Australia follows the Westminster system, with a Parliament of South Australia acting as the legislature. The Premier is appointed by the Governor of South Australia, and by modern convention holds office by virtue of his or her ability to command the support of a majority of members of the lower house of Parliament, the House of Assembly.

Steven Marshall is the current Premier, having served since 19 March 2018.

Before the 1890s when there was no formal party system in South Australia, MPs tended to have historical liberal or conservative beliefs. The liberals dominated government from the 1893 election to 1905 election with the support of the South Australian United Labor Party, with the conservatives mostly in opposition. Labor took government with the support of eight dissident liberals in 1905 when Labor won the most seats for the first time. The rise of Labor saw non-Labor politics start to merge into various party incarnations.

The two independent conservative parties, the Australasian National League (formerly National Defence League) and the Farmers and Producers Political Union merged with the Liberal and Democratic Union to become the Liberal Union in 1910. Labor formed South Australia's first majority government after winning the 1910 state election, triggering the merger. The 1910 election came two weeks after federal Labor formed Australia's first elected majority government at the 1910 federal election.

No "Country" or rural conservative parties emerged as serious long-term forces in South Australian state politics, often folding into the main non-Labor party.

The first six Governors of South Australia oversaw governance from proclamation in 1836 until self-government and an elected Parliament of South Australia was enacted in the year prior to the inaugural 1857 election.

There are seven living former premiers, the oldest being Steele Hall (1968–70, born 1928). The most recent premier to die was John Bannon (Premier 1982–1992) on 13 December 2015.

In the following timeline, the legend includes the Liberal and Democratic Union, the Liberal Union and the Liberal Federation represented as "Liberal (pre-1979)". The Liberal Party is represented as "Liberal (post-1979)" only. The grey area represents the duration of Playmander electoral malapportionment, beginning in 1936, in effect until the 1970 election.





</doc>
<doc id="24680" url="https://en.wikipedia.org/wiki?curid=24680" title="Premier of Western Australia">
Premier of Western Australia

The Premier of Western Australia is the head of the executive branch of government in the Australian state of Western Australia. The Premier has similar functions in Western Australia to those performed by the Prime Minister of Australia at the national level, subject to the different Constitutions.

The incumbent Premier of Western Australia is Mark McGowan who won the 2017 state election and was sworn in on 17 March 2017 by Governor Kerry Sanderson as the 30th Premier of Western Australia.

The premier must be a member of one of the two Houses of the Parliament of Western Australia; and by convention the premier is a member of the lower house, the Legislative Assembly. He or she is appointed by the governor on the advice of the lower house, and must resign if he or she loses the support of the majority of that house. Consequently, the premier is almost always the leader of the political party or coalition of parties with the majority of seats in the lower house.

The office of premier of Western Australia was first formed in 1890, after Western Australia was officially granted responsible government by Britain in 1889. The Constitution of Western Australia does not explicitly provide for a premier, and the office was not formally listed as one of the executive offices until the appointment of Ross McLarty in 1947. Nonetheless, John Forrest immediately adopted the title on taking office as first premier of Western Australia in 1890, and it has been used ever since.

John Forrest was the only premier of Western Australia as a self-governing colony. Following the Federation of Australia in 1901, Western Australia became an Australian state and the responsibilities of the office of premier were diminished.

Party politics began in Western Australia with the rise of the Labor party in 1901. By 1904, the party system was entrenched in Western Australian politics. Since then the premiers have been associated with political parties.

Western Australia's constitution contains nothing to preclude the premier being a member of the upper house, the Western Australian Legislative Council. Historically and by convention, however, the premier is a member of the Assembly. The only exception has been Hal Colebatch, a member of the Legislative Council who accepted the premiership in April 1919 on the understanding that an Assembly seat would be found for him, only to resign a month later when no seat could be found.

During the economic boom of the 1980s, the Western Australian government became closely involved with a number of large businesses. A succession of deals were made between the government and businesses, and these ultimately caused great losses for the state. A subsequent royal commission found evidence of widespread corruption. Three former premiers were found to have acted improperly and two of them, Ray O'Connor and Brian Burke, were jailed. This scandal became popularly known as WA Inc.

As of , seven former premiers are alive, the oldest being Peter Dowding (born 1943), who served from 1988 to 1990. The most recent premier to die was Ray O'Connor, on 25 February 2013, aged 86.


 The only premier to serve in the upper house while premier was Sir Hal Colebatch, who was elected by the Nationalist Party to fill the vacancy presented by the resignation of Henry Lefroy, on the condition that a seat in the lower house would be found for him. He served as premier for a month before resigning after no seat could be found.



</doc>
<doc id="24681" url="https://en.wikipedia.org/wiki?curid=24681" title="Pigeonhole sort">
Pigeonhole sort

Pigeonhole sorting is a sorting algorithm that is suitable for sorting lists of elements where the number of elements ("n") and the length of the range of possible key values ("N") are approximately the same. It requires O("n" + "N") time. It is similar to counting sort, but differs in that it "moves items twice: once to the bucket array and again to the final destination [whereas] counting sort builds an auxiliary array then uses the array to compute each item's final destination and move the item there."

The pigeonhole algorithm works as follows:

Suppose one were sorting these value pairs by their first element:


For each value between 3 and 8 we set up a pigeonhole, then move each element to its pigeonhole:


The pigeonhole array is then iterated over in order, and the elements are moved back to the original list.

The difference between pigeonhole sort and counting sort is that in counting sort, the auxiliary array does not contain lists of input elements, only counts:


Using this information, one could perform a series of exchanges on the input array that would put it in order, moving items only once.

For arrays where "N" is much larger than "n", bucket sort is a generalization that is more efficient in space and time.



</doc>
<doc id="24683" url="https://en.wikipedia.org/wiki?curid=24683" title="Pope Innocent XIII">
Pope Innocent XIII

Pope Innocent XIII (; 13 May 1655 – 7 March 1724), born as Michelangelo dei Conti, was head of the Catholic Church and ruler of the Papal States from 8 May 1721 to his death in 1724. He is the last pope to date to take the pontifical name of "Innocent" upon his election.

Pope Innocent XIII was reform-oriented, and he imposed new standards of frugality, abolishing excessive spending. He took steps to finally end the practice of nepotism by issuing a decree which forbade his successors from granting land, offices or income to any relatives - something opposed by many cardinals who hoped that they might become pope and benefit their families.

Michelangelo dei Conti was born on 13 May 1655 in Poli, near Rome as the son of Carlo II, Duke of Poli, and Isabella d'Monti. Like Pope Innocent III (1198–1216), Pope Gregory IX (1227–1241) and Pope Alexander IV (1254–1261), he was a member of the land-owning family of the Conti, who held the titles of counts and dukes of Segni. He included the family crest in his pontifical coats of arms.

Conti commenced his studies in Ancona and then with the Jesuits in Rome at the Collegio Romano and then later at La Sapienza University. After he received his doctorate in canon law and civil law, he was ordained to the priesthood. Conti also served as the Referendary of the Apostolic Signatura in 1691, later to be appointed as the Governor of Ascoli until 1692. Conti was also the Governor of Campagna and Marittima from 1692 to 1693 and the Governor of Viterbo from 1693 to 1695.

Pope Innocent XII selected Conti as the Titular Archbishop of Tarso on 13 June 1695 and he received his episcopal consecration on 16 June 1695 in Rome. Conti was also the nuncio to both Switzerland and Portugal.

On 7 June 1706, Conti was elevated to the cardinalate and was made the Cardinal-Priest of Santi Quirico e Giulitta under Pope Clement XI (1700–21). His appointment came about as the replacement of Gabriele Filippucci who declined the cardinalate. He would receive his titular church on 23 February 1711. From 1697 to 1710 he acted as papal nuncio to the Kingdom of Portugal, where he is believed to have formed those unfavourable impressions of the Jesuits which afterwards influenced his conduct towards them. While in Portugal, he was witness to Father Bartolomeu de Gusmão's early aerostat experiments.

He was also transferred to Osimo as its archbishop in 1709 and was later translated one last time to Viterbo e Toscanella in 1712. He also served as Camerlengo of the Sacred College of Cardinals from 1716 to 1717 and resigned his position in his diocese due to illness in 1719.

After the death of Pope Clement XI in 1721, a conclave was called to choose a new pope. It took 75 ballots just to reach a decision and choose Conti as the successor of Clement XI. After all candidates seemed to slip, support turned to Conti. The curial factions also turned their attention to him. In the morning of 8 May 1721, he was elected. He chose the name of Innocent XIII in honour of Pope Innocent III. On the following 18 May, he was solemnly crowned by the protodeacon, Cardinal Benedetto Pamphili.

In 1721 his high reputation for ability, learning, purity, and a kindly disposition secured his election to succeed Clement XI as Pope Innocent XIII. His pontificate was prosperous, but comparatively uneventful. He held two consistories that saw three new cardinals elevated on 16 June 1721 and 16 July 1721.

The Chinese Rites controversy that started under his predecessor continued during his reign. Innocent XIII prohibited the Jesuits from prosecuting their mission in China, and ordered that no new members should be received into the order. This indication of his sympathies encouraged some French bishops to approach him with a petition for the recall of the bull "Unigenitus" by which Jansenism had been condemned; the request, however, was peremptorily denied.

The pope also assisted the Venetians in their struggles and also assisted Malta in its struggles against the Turks.

Innocent XIII, like his predecessor, showed much favour to James Francis Edward Stuart, the "Old Pretender" to the British throne and liberally supported him. The pope's cousin, Francesco Maria Conti, from Siena, became chamberlain of James' little court in the Roman Muti Palace.

Innocent XIII held two consistories in which he named three cardinals. One of those new cardinals was his own brother, Bernardo Maria.

Innocent XIII beatified three individuals during his pontificate: John of Nepomuk (31 May 1721), Dalmazio Moner (13 August 1721), and Andrea dei Conti (11 December 1723).

In 1722, he named Saint Isidore of Seville as a Doctor of the Church.

Innocent XIII fell ill in 1724. He was tormented by a hernia of which he spoke to nobody but his valet. At one point, it had burst and caused inflammation and fever. Innocent XIII asked for the last rites, made his profession of faith, and died on 7 March 1724, at the age of 68. His pontificate was unremarkable, given that he was hampered by physical suffering. He was interred in the grottoes at Saint Peter's Basilica.

In 2005 upon the occasion of the 350 years since the birth of the late pontiff, the citizens in the late pope's village of birth asked the Holy See to introduce the cause of beatification for Innocent XIII.



</doc>
<doc id="24684" url="https://en.wikipedia.org/wiki?curid=24684" title="Pope Julius I">
Pope Julius I

Pope Julius I (died 12 April 352) was Pope of the Catholic Church from 6 February 337 to his death in 352. He was notable for asserting the authority of the pope over the Arian Eastern bishops.

Julius was a native of Rome and was chosen as successor of Pope Mark after the Roman seat had been vacant for four months. He is chiefly known by the part he took in the Arian controversy. After the followers of Eusebius of Nicomedia, who had become the archbishop of Constantinople, renewed their deposition of Athanasius at a synod held in Antioch in 341, they resolved to send delegates to Constans, Emperor of the West, and also to Julius, setting forth the grounds on which they had proceeded. Julius, after expressing an opinion favourable to Athanasius, adroitly invited both parties to lay the case before a synod to be presided over by himself. This proposal, however, the Arian Eastern bishops declined to accept.

On this second banishment from Alexandria, Athanasius came to Rome, and was recognised as a regular bishop by the synod presided over by Julius in 342. Julius sent a letter to the Eastern bishops that is an early instance of the claims of primacy for the bishop of Rome. Even if Athanasius and his companions were somewhat to blame, the letter runs, the Alexandrian Church should first have written to the pope. "Can you be ignorant," writes Julius, "that this is the custom, that we should be written to first, so that from here what is just may be defined" (Epistle of Julius to Antioch, c. xxii).

It was through the influence of Julius that, at a later date, the council of Sardica in Illyria was held, which was attended only by seventy-six Eastern bishops, who speedily withdrew to Philippopolis and deposed Julius at the council of Philippopolis, along with Athanasius and others. The three hundred Western bishops who remained, confirmed the previous decisions of the Roman synod and issued a number of decrees regarding church discipline. The first canon forbade the transfer of bishops from one see to another, for if frequently made, it was seen to encourage covetousness and ambition.

By its 3rd, 4th, and 5th decrees relating to the rights of revision claimed by Julius, the council of Sardica perceptibly helped forward the claims of the Bishop of Rome. Julius built several basilicas and churches in Rome and died there 12 April 352. He was succeeded by Liberius.

Pope Julius I is venerated as a saint by the Catholic Church. His feast day is on 12 April.

Around 350 A.D. Pope Julius I declared December 25 as the official date of the birth of Jesus, around the same time as the festival of Saturnalia; the actual date of Jesus's birth is unknown. Some have speculated that part of the reason why he chose this date may have been because he was trying to create a Christian alternative to Saturnalia. Another reason for the decision may have been because, in 274 AD, the Roman emperor Aurelian had declared 25 December the birthdate of Sol Invictus and Julius I may have thought that he could attract more converts to Christianity by allowing them to continue to celebrate on the same day. He may have also been influenced by the idea that Jesus had died on the anniversary of his conception; because Jesus died during Passover and, in the third century AD, Passover was celebrated on 25 March, he may have assumed that Jesus's birthday must have come nine months later, on 25 December.




</doc>
<doc id="24685" url="https://en.wikipedia.org/wiki?curid=24685" title="Pope Julius III">
Pope Julius III

Pope Julius III (; 10 September 1487 – 23 March 1555), born Giovanni Maria Ciocchi del Monte, was head of the Catholic Church and ruler of the Papal States from 7 February 1550 to his death in 1555.

After a career as a distinguished and effective diplomat, he was elected to the papacy as a compromise candidate after the death of Paul III. As pope, he made only reluctant and short-lived attempts at reform, mostly devoting himself to a life of personal pleasure. His reputation, and that of the Catholic Church, were greatly harmed by his scandal-ridden relationship with his adopted nephew.

Giovanni Maria Ciocchi del Monte was born in Monte San Savino. He was educated by the humanist Raffaele Brandolini Lippo, and later studied law at Perugia and Siena. During his career, he distinguished himself as a brilliant canonist rather than as a theologian.

Del Monte was the nephew of Antonio Maria Ciocchi del Monte, Archbishop of Manfredonia (1506–1511). When his uncle exchanged this see for a position as a Cardinal in 1511, Giovanni Maria Ciocchi del Monte succeeded in Manfredonia in 1512. In 1520, del Monte also became Bishop of Pavia. Popular for his affable manner and respected for his administrative skills, he was twice Governor of Rome and was entrusted by the papal curia with several duties. At the Sack of Rome (1527) he was one of the hostages given by Pope Clement VII to the Emperor's forces, and barely escaped execution. Pope Paul III made him Cardinal-bishop of Palestrina in 1536 and employed him in several important legations, notably as papal legate and first president of the Council of Trent (1545/47) and then at Bologna (1547/48).

Paul III died on 10 November 1549, and in the ensuing conclave the forty-eight cardinals were divided into three factions: of the primary factions, the Imperial faction wished to see the Council of Trent reconvened, the French faction wished to see it dropped. The Farnese faction, loyal to the family of the previous Pope, supported the election of Paul III's grandson, Cardinal Alessandro Farnese, and also the family's claim to the Duchy of Parma, which was contested by Emperor Charles V.

Neither the French nor the Germans favoured del Monte, and the Emperor had expressly excluded him from the list of acceptable candidates, but the French were able to block the other two factions, allowing del Monte to promote himself as a compromise candidate and be elected on 7 February 1550. Ottavio Farnese, whose support had been crucial to the election, was immediately confirmed as Duke of Parma. But, when Farnese applied to France for aid against the emperor, Julius allied himself with the emperor, declared Farnese deprived of his fief, and sent troops under the command of his nephew Giambattista del Monte to co-operate with Duke Gonzaga of Milan in the capture of Parma.

At the start of his reign Julius had seriously desired to bring about a reform of the Catholic Church and to reconvene the Council of Trent, but very little was actually achieved during his five years in office. In 1551, at the request of Emperor Charles V, he consented to the reopening of the council of Trent and entered into a league against the duke of Parma and Henry II of France (1547–59), causing the War of Parma. However, Julius soon came to terms with the duke and France and in 1553 suspended the meetings of the council.

King Henry II of France had threatened to withdraw recognition from the Pope if the new Pope was pro-Habsburg in orientation, and when Julius III reconvened the Council of Trent, Henry blocked French bishops from attending and did not enforce the papal decrees in France. Even after Julius III suspended the Council again he proceeded to bully the pope into taking his side against the Habsburgs by threatening schism.

Julius increasingly contented himself with Italian politics and retired to his luxurious palace at the Villa Giulia, which he had built for himself close to the Porta del Popolo. From there he passed the time in comfort, emerging from time to time to make timid efforts to reform the Church through the reestablishment of the reform commissions. He was a friend of the Jesuits, to whom he granted a fresh confirmation in 1550; and through the papal bull, "Dum sollicita" of August 1552, he founded the Collegium Germanicum, and granted an annual income.

During his pontificate, Catholicism was restored in England under Queen Mary in 1553. Julius sent Cardinal Reginald Pole as legate with powers that he could use at his discretion to help the restoration succeed. In February 1555, an envoy was dispatched from the English Parliament to Julius to inform him of the country's formal submission, but the pope died before the envoy reached Rome.

Shortly before his death, Julius dispatched Cardinal Giovanni Morone to represent the interests of the Holy See at the Peace of Augsburg. His inactivity during the last three years of his pontificate may have been caused by the frequent and severe attacks of the gout to which he was subject.

Julius' papacy was marked by scandals, the most notable of which is centered around the pope's adoptive nephew, Innocenzo Ciocchi Del Monte. Innocenzo del Monte was a teenaged beggar found in the streets of Parma who was hired by the family as a lowly hall boy in their primary residence, the boy's age being variously given as 14, 15, or 17 years. After the elevation of Julius to the papacy, Innocenzo Del Monte was adopted into the family by the pope's brother and, by Julius, was then promptly created cardinal-nephew. Julius showered his favourite with benefices, including the "commendatario" of the abbeys of Mont Saint-Michel in Normandy and Saint Zeno in Verona, and, later, of the abbeys of Saint Saba, Miramondo, Grottaferrata and Frascati, among others. As rumours began to circle about the particular relationship between the pope and his adoptive nephew, Julius refused to take advice. The cardinals Reginald Pole and Giovanni Carafa warned the pope of the "evil suppositions to which the elevation of a fatherless young man would give rise".

Poet Joachim du Bellay, who lived in Rome through this period in the retinue of his relative, Cardinal Jean du Bellay, expressed his scandalized opinion of Julius in two sonnets in his series Les regrets (1558), hating to see, he wrote, "a Ganymede with the red hat on his head". The courtier and poet Girolamo Muzio in a letter of 1550 to Ferrante Gonzaga, governor of Milan, wrote: "They write many bad things about this new pope; that he is vicious, proud, and odd in the head", and the Pope's enemies made capital of the scandal, Thomas Beard, in the "Theatre of God's judgement" (1597) saying it was Julius' "custome ... to promote none to ecclesiastical livings, save only his buggerers”. In Italy, it was said that Julius showed the impatience of a "lover awaiting a mistress" while awaiting Innocenzo's arrival in Rome and boasted of the boy's prowess in bed, while the Venetian ambassador reported that Innocenzo Del Monte shared the pope's bed "as if he [Innocenzo] were his [Julius'] own son or grandson." "The charitably-disposed told themselves that the boy might after all be simply his bastard son."

Despite the damage which the scandal was inflicting on the church, it was not until after Julius' death in 1555 that anything could be done to curb Innocenzo's visibility. He underwent temporary banishment following the murder of two men who had insulted him, and then again following the rape of two women. He tried to use his connections in the College of Cardinals to plead his cause, but his influence waned, and he died in obscurity. He was buried in Rome in the Del Monte family chapel. One outcome of the cardinal-nephew scandal, however, was the upgrading of the position of Papal Secretary of State, as the incumbent had to take over the duties Innocenzo Del Monte was unfit to perform: the Secretary of State eventually replaced the cardinal-nephew as the most important official of the Holy See.

The pope's lack of interest in political or ecclesiastical affairs caused dismay among his contemporaries. He spent the bulk of his time, and a great deal of papal money, on entertainments at the Villa Giulia, created for him by Vignola, but more significant and lasting was his patronage of the great Renaissance composer Giovanni Pierluigi da Palestrina, whom he brought to Rome as his "maestro di cappella", Giorgio Vasari, who supervised the design of the Villa Giulia, and Michelangelo, who worked there.

In the novel "Q" by Luther Blissett, Julius appears toward the end of the book as a moderate cardinal favouring religious tolerance, in the upheavals caused by the Reformation and the Roman Church's response during the 16th century. His election as pope and the subsequent unleashing of the Inquisition form the last chapters of the novel.






</doc>
<doc id="24686" url="https://en.wikipedia.org/wiki?curid=24686" title="Pope Eugene I">
Pope Eugene I

Pope Eugene I (died 2 June 657), also known as Eugenius I, was Bishop of Rome from 10 August 654 to his death in 657. He was a native of Rome, born to one Rufinianus.

In June 653, in the midst of a dispute with Byzantine Emperor Constans II over Monothelitism, Pope Martin I was seized and carried to Constantinople and subsequently exiled to Cherson in the Crimea. Initially, in the pontiff's absence, the church was probably governed by the archpriest, archdeacon and the primicerius of the notaries. Over a year later, and with no sign of Martin's return, Eugene was chosen to succeed. If the emperor expected Eugene to take a different approach from that of his predecessor, he was disappointed. 

Little is known of Pope Eugene's early life other than that he was a Roman from the Aventine and was known for his holiness, gentleness, and charity. He had been a cleric from his youth and held various positions within the Church of Rome.

On the banishment of Pope Martin I by Byzantine Emperor Constans II, he showed greater deference than his predecessor to the emperor's wishes and made no public stand against the Monothelitism of the patriarchs of Constantinople.

Martin I was carried off from Rome on 18 June 653 and was kept in exile until his death in September 655. Little is known about what happened in Rome after Pope Martin's departure, but it was typical in those days for the Holy See to be governed by the archpriest and archdeacon.

After a year and two months, a successor was found to Martin in Eugene.

Almost immediately after his election, Eugene was forced to deal with Monothelitism, the belief that Christ had only one will.

One of the first acts of the new pope was to send papal legates to Constantinople with letters to Emperor Constans II informing him of his election and professing his faith. The legates unfortunately allowed themselves to be deceived, or bribed, and brought back a synodical letter from Patriarch Peter of Constantinople (656–666), while the emperor's envoy, who accompanied them, brought offerings for Saint Peter and a request from the emperor that the pope would enter into communion with the Patriarch of Constantinople. Peter's letter proved to be written in a difficult and obscure style and avoided making any specific declaration as to the number of "wills or operations" in Christ. When its contents were read to the clergy and people in the church of St. Mary Major in 656, they not only rejected the letter with indignation, but would not allow the pope to leave the basilica until he had promised that he would not on any account accept it.

So furious were the Byzantine officials at this harsh rejection of the wishes of their emperor and patriarch that they threatened to roast Eugene, just as they had roasted Pope Martin I. Eugene's persecution was averted by the ensuing conquest of the Muslims, who took Rhodes in 654 and defeated Constans himself in the naval battle of Phoenix (655).

It was almost certainly this pope who received the youthful Wilfrid on the occasion of his first visit to Rome (c. 654). At Rome he gained the affection of Archdeacon Boniface, a counsellor of the apostolic pope, who presented him to his master. Eugene "placed his blessed hand on the head of the youthful servant of God, prayed for him, and blessed him." Nothing more is known of Eugene except that he consecrated twenty-one bishops for different parts of the world, and that he was buried in St. Peter's Basilica.

He died in 657 and was acclaimed a saint, his day being the 2nd of June, although, according to Anastasius, he died on the 1st of that month.



Attribution



</doc>
<doc id="24687" url="https://en.wikipedia.org/wiki?curid=24687" title="Pope Eugene II">
Pope Eugene II

Pope Eugene II (; died 27 August 827) was Pope from June 6, 824 to his death in 827. A native of Rome, he was chosen to succeed Paschal I. Another candidate, Zinzinnus, was proposed by the plebeian faction, and the presence of Lothair I, son of the Frankish emperor Louis the Pious, was necessary in order to maintain the authority of the new pope. Lothair took advantage of this opportunity to redress many abuses in the papal administration, to vest the election of the pope in the nobles, and to confirm the statute that no pope should be consecrated until his election had the approval of the Frankish emperor.

Pope Eugene convened a council at Rome in 826 to address matters of church discipline. The practice of simony was condemned and untrained clergy were to be suspended until they had improved their knowledge to carry out their sacred duties. It was decreed that schools were to be established at cathedral churches and other places to give instruction in sacred and secular literature. 

He was elected pope on 6 June 824, after the death of Paschal I. The late pope had attempted to curb the rapidly increasing power of the Roman nobility, who had turned for support to the Franks to strengthen their positions against him. When Paschal died, these nobles made strenuous efforts to replace him with a candidate of their own. The clergy put forward a candidate likely to continue the policy of Paschal. However, even though the Roman Council of 769 under Stephen IV had decreed that the nobles had no right to a real share in a papal election, the nobles were successful in securing the consecration of Eugene, who was archpriest of St Sabina on the Aventine. Eugene candidacy was endorsed by Abbot Walla, who was then in Rome and served as a councilor to both the current emperor and his late father.

In earlier editions of the "Liber Pontificalis" Eugene is said to have been the son of Boemund, but in the more recent and more accurate editions, his father's name is not given. While archpriest of the Roman Church, he is credited with having fulfilled most conscientiously the duties of his position. After he became pope, he beautified his ancient church of St. Sabina with mosaics and metalwork bearing his name that were still intact as late as the 16th century. Eugene is described by his biographer as simple and humble, learned and eloquent, handsome and generous, a lover of peace, and wholly occupied with the thought of doing what was pleasing to God.

The election of Eugene II was a triumph for the Franks, and they subsequently resolved to improve their position. Emperor Louis the Pious accordingly sent his son Lothair to Rome to strengthen the Frankish influence. The Roman nobles who had been banished during the preceding reign and fled to France were recalled, and their property was restored to them. A "Constitutio Romana" was then agreed upon between the pope and the emperor in 824 which advanced the imperial pretensions in the city of Rome, but also checked the power of the nobles. This constitution included the statute that no pope should be consecrated until his election had the approval of the Frankish emperor. It decreed that those who were under the special protection of the pope or emperor were to be inviolable, and that church property not be plundered after the death of a pope.

Seemingly before Lothair left Rome, there arrived ambassadors from Emperor Louis and from the Greeks concerning the image question. At first the Eastern Roman Emperor Michael II showed himself tolerant towards the image-worshippers, and their great champion, Theodore the Studite, wrote to him to exhort him "to unite us [the Church of Constantinople] to the head of the Churches of God, Rome, and through it with the three Patriarchs" and to refer any doubtful points to the decision of Old Rome in accordance with ancient custom. But Michael soon forgot his tolerance, bitterly persecuted the image worshippers, and endeavoured to secure the co-operation of Louis the Pious. He also sent envoys to the pope to consult him on certain points connected with the worship of images. Before taking any steps to meet the wishes of Michael, Louis asked the pope's permission for a number of his bishops to assemble and make a selection of passages from the Fathers to elucidate the question that the Greeks had put before them. The leave was granted, but the bishops who met at Paris in 825 were incompetent for the task. Their collection of extracts from the Fathers was a mass of confused and ill-digested lore, and both their conclusions and the letters they wished the pope to forward to the Greeks were based on a complete misunderstanding of the decrees of the Second Council of Nicaea. Their labours do not appear to have accomplished much; nothing is known of the result of their researches.

In 826 Eugene held an important council at Rome of 62 bishops, in which 38 disciplinary decrees were issued. The council passed several enactments for the restoration of church discipline, and took measures for the foundation of schools or chapters. The decrees are noteworthy as showing that Eugene had at heart the advancement of learning. Not only were ignorant bishops and priests to be suspended till they had acquired sufficient learning to perform their sacred duties, but it was decreed that, as in some localities there were neither masters nor zeal for learning, masters were to be attached to the episcopal palaces, cathedral churches and other places to give instruction in sacred and polite literature. It also ruled against priests wearing secular dress or engaging in secular occupations. Simony was forbidden. Eugene also adopted various provisions for the care of the poor, widows and orphans, and on that account received the name of "father of the people". 

To help in the work of the conversion of the North, Eugene wrote commending St. Ansgar, the Apostle of the Scandinavians, and his companions "to all the sons of the Catholic Church". Coins of this pope are extant bearing his name and that of Emperor Louis.

He died on 27 August 827. It is supposed that he was buried in St. Peter's in accordance with the custom of the time, even though there is no documentary record to confirm it.




</doc>
<doc id="24688" url="https://en.wikipedia.org/wiki?curid=24688" title="Pope Eugene III">
Pope Eugene III

Pope Eugene III (; c. 1080 – 8 July 1153), born Bernardo Pignatelli, called Bernardo da Pisa, was Pope from 15 February 1145 to his death in 1153. He was the first Cistercian to become Pope. In response to the fall of Edessa to the Muslims in 1144, Eugene proclaimed the Second Crusade. The crusade failed to recapture Edessa, which was the first of many failures by the Christians in the crusades to recapture lands won in the First Crusade.

He was beatified on 28 December 1872 by Pope Pius IX on the account of his sanctity.

Bernardo was born in the vicinity of Pisa. Little is known about his origins and family except that he was son of a certain Godius. From the 16th century he is commonly identified as member of the family of Paganelli di Montemagno, which belonged to the Pisan aristocracy, but this has not been proven and contradicts earlier testimonies that suggest he was a man of rather humble origins. In 1106 he was a canon of the cathedral chapter in Pisa and from 1115 is attested as subdeacon. 1133–1138 he acted as "vicedominus" of the archdiocese of Pisa.

Between May 1134 and February 1137 he was ordained to the priesthood by Pope Innocent II, who resided at that time in Pisa. Under the influence of Bernard of Clairvaux he entered the Cistercian Order in the monastery of Clairvaux in 1138. A year later he returned to Italy as leader of the Cistercian community in Scandriglia. In Autumn 1140, Pope Innocent II named him abbot of the monastery of S. Anastasio alle Tre Fontane outside Rome. Some chronicles indicate that he was also elevated to the College of Cardinals, but these testimonies probably resulted from a confusion because Bernardo is not attested as cardinal in any document and from the letter of Bernard of Clairvaux addressed to the cardinals shortly after his election clearly appears that he was not a cardinal.

Bernardo was elected pope on 15 February 1145, the same day as the death of his predecessor Lucius II who had unwisely decided to take the offensive against the Roman Senate and was killed by a "heavy stone" thrown at him during an attack on the Capitol. He took the pontifical name of "Eugene III". He was "a simple character, gentle and retiring - not at all, men thought, the material of which Popes are made". He owed his elevation partly to the fact that no one was eager to accept an office the duties of which were at the time so difficult and dangerous and because the election was "held on safe Frangipani territory".

His election was assisted by being a friend and pupil of Bernard of Clairvaux, the most influential ecclesiastic of the Western Church and a strong assertor of the pope's temporal authority. The choice did not have the approval of Bernard, however, who remonstrated against the election, writing to the entire Curia:"May God forgive you what you have done! ... What reason or counsel, when the Supreme Pontiff was dead, made you rush upon a mere rustic, lay hands on him in his refuge, wrest from his hands the axe, pick or hoe, and lift him to a throne?"Bernard was equally forthright in his views directly to Eugene, writing:"Thus does the finger of God raise up the poor out of the dust and lift up the beggar from the dunghill that he may sit with princes and inherit the throne of glory."Despite these criticisms, Eugene seems to have borne no resentment to Bernard and notwithstanding these criticisms, after the choice was made, Bernard took advantage of the qualities in Eugene III which he objected to, so as virtually to rule in his name.

During nearly the whole of his pontificate, Eugene III was unable to reside in Rome. Hardly had he left the city to be consecrated in the monastery of Farfa (about 40 km north of Rome), when the citizens, under the influence of Arnold of Brescia, the great opponent of the Pope's temporal power, established the old Roman constitution, the Commune of Rome and elected Giordano Pierleoni to be "Patrician". Eugene III appealed for help to Tivoli, Italy, to other cities at feud with Rome, and to King Roger II of Sicily (who sent his general Robert of Selby), and with their aid was successful in making such conditions with the Roman citizens as enabled him for a time to hold the semblance of authority in his capital. But as he would not agree to a treacherous compact against Tivoli, he was compelled to leave the city in March 1146. He stayed for some time at Viterbo, and then at Siena, but went ultimately to France.

On hearing of the fall of Edessa (now the modern day city of Urfa, the first of the Crusader states established in the Levant) to the Turks, which occurred in 1144, he had, in December 1145, addressed the bull "Quantum praedecessores" to Louis VII of France, calling on him to take part in another crusade. At a great diet held at Speyer in 1146, King of the Romans Conrad III and many of his nobles were also incited to dedicate themselves to the crusade by the eloquence of Bernard who preached to an enormous crowd at Vézelay.

In the end, the Second Crusade was "an ignominious fiasco" and, after travelling for a year, the army abandoned their campaign after just five days of siege "having regained not one inch of Muslim territory." The crusaders suffered immense losses in both men and materiel and suffered, in the view of one modern historian, "the ultimate humiliation which neither they, nor their enemies, would forget".

Eugene III held synods in northern Europe at Paris, Rheims (March 1148), and Trier in 1147 that were devoted to the reform of clerical life. He also considered and approved the works of Hildegard of Bingen.

In June 1148, Eugene III returned to Italy and took up his residence at Viterbo. He was unable to return to Rome due to the popularity of Arnold of Brescia, who opposed Papal temporal authority, in the city. He established himself at Prince Ptolemy's fortress in Tusculum, the closest town to Rome at which he could safely install himself, on 8 April 1149.

There he met the returning Crusader king Louis VII of France and his wife Eleanor of Aquitaine who were by then barely on speaking terms given the strains of the failed Crusade and the suggestion that Eleanor may have entered into a relationship with her uncle Raymond during the Crusade. Eugene, "a gentle, kind-hearted man who hated to see people unhappy" attempted to assuage the pain of the failed Crusade and their failing marriage by insisting that they slept in the same bed and "by daily converse to restore the love between them". His efforts were unsuccessful, and two years later Eugene agreed to annul the marriage on the grounds of consanguinity. Eleanor went on to remarry and become the wife of one King of England, and the mother of two.

Eugene stayed at Tusculum until 7 November. At the end of November 1149, through the aid of the King of Sicily, he was again able to enter Rome, but the atmosphere of open hostility from the Comune soon compelled him to retire (June 1150).
The Emperor Frederick I Barbarossa had promised to aid him against his revolted subjects, but this was not to be: Eugene III died at Tivoli on 8 July 1153. Though the citizens of Rome were jealous of the efforts of Eugene III to assert his temporal authority, they were always ready to recognize him as their spiritual lord. Besides that, they deeply reverenced his personal character. Until the day of his death he continued to wear, under his robes, the coarse habit of a Cistercian monk. Accordingly, he was buried in the Vatican with every mark of respect, and his tomb soon acquired an extraordinary fame for miraculous cures.

The people of Rome were quick to recognize Eugene III as a pious figure who was meek and spiritual. His tomb acquired considerable fame owing to the miracle purported to have occurred there and his cause for sainthood commenced. Pope Pius IX beatified him in 1872.




</doc>
<doc id="24689" url="https://en.wikipedia.org/wiki?curid=24689" title="Persistence">
Persistence

Persistence may refer to:






</doc>
<doc id="24690" url="https://en.wikipedia.org/wiki?curid=24690" title="Plaintiff">
Plaintiff

A plaintiff (Π in legal shorthand) is the party who initiates a lawsuit (also known as an "action") before a court. By doing so, the plaintiff seeks a legal remedy; if this search is successful, the court will issue judgment in favor of the plaintiff and make the appropriate court order (e.g., an order for damages). "Plaintiff" is the term used in civil cases in most English-speaking jurisdictions, the notable exception being England and Wales, where a plaintiff has, since the introduction of the Civil Procedure Rules in 1999, been known as a "claimant", but that term also has other meanings. In criminal cases, the prosecutor brings the case against the defendant, but the key complaining party is often called the "complainant".

In some jurisdictions, a lawsuit is commenced by filing a summons, claim form or a complaint. These documents are known as pleadings, that set forth the alleged wrongs committed by the defendant or defendants with a demand for relief. In other jurisdictions, the action is commenced by service of legal process by delivery of these documents on the defendant by a process server; they are only filed with the court subsequently with an affidavit from the process server that they had been given to the defendant according to the rules of civil procedure.

In most English-speaking jurisdictions, including Hong Kong, Nigeria, Australia, Canada and the United States, as well as in both Northern Ireland and the Republic of Ireland, the legal term "plaintiff" is used as a general term for the party taking action in a civil case.

The word "plaintiff" can be traced to the year 1278, and stems from the Anglo-French word "pleintif" meaning "complaining". It was identical to "plaintive" at first and receded into legal usage with the -iff spelling in the 15th century.

A plaintiff identified by name in a class action is called a named plaintiff.

In most common-law jurisdictions, the term "claimant" used in England and Wales since 1999 (see below) is used only in specific, often non-judicial contexts. In particular, in American usage, terms such as "claimant" and "claim form" are limited to extrajudicial process in insurance and administrative law. After exhausting remedies available through an insurer or government agency, an American claimant in need of further relief would turn to the courts, file a complaint (thus establishing a real court case under judicial supervision) and become a plaintiff.

In England and Wales, the term "claimant" replaced "plaintiff" after the Civil Procedure Rules came into force on 26 April 1999. The move, which brings England and Wales out of line with general usage in English-speaking jurisdictions, was reportedly based on an assessment that the word "claimant" is more acceptable as "plain English" than the word "plaintiff". In Scottish law a plaintiff is referred to as a "pursuer" and a defendant as a "defender".

The party against whom the complaint is made is the defendant; or, in the case of a petition, a respondent. Case names are usually given with the plaintiff first, as in "Plaintiff v. Defendant".

The similar term "complainant" denotes the complaining witness in a criminal proceeding.



</doc>
<doc id="24694" url="https://en.wikipedia.org/wiki?curid=24694" title="Philosophy of law">
Philosophy of law

Philosophy of law is a branch of philosophy that examines the nature of law and law's relationship to other systems of norms, especially ethics and political philosophy. It asks questions like "What is law?", "What are the criteria for legal validity?", and "What is the relationship between law and morality?" Philosophy of law and jurisprudence are often used interchangeably, though jurisprudence sometimes encompasses forms of reasoning that fit into economics or sociology.

Philosophy of law can be sub-divided into analytical jurisprudence and normative jurisprudence. Analytical jurisprudence aims to define what law is and what it is not by identifying law's essential features. Normative jurisprudence investigates both the non-legal norms that shape law and the legal norms that are generated by law and guide human action.

Analytical jurisprudence seeks to provide a general account of the nature of law through the tools of conceptual analysis. The account is general in the sense of targeting universal features of law that hold at all times and places. Whereas lawyers are interested in what the law is on a specific issue in a specific jurisdiction, philosophers of law are interested in identifying the features of law shared across cultures, times, and places. Taken together, these foundational features of law offer the kind of universal definition philosophers are after. The general approach allows philosophers to ask questions about, for example, what separates law from morality, politics, or practical reason. Often, scholars in the field presume that law has a unique set of features that separate it from other phenomena, though not all share the presumption.

While the field has traditionally focused on giving an account of law's nature, some scholars have begun to examine the nature of domains within law, e.g. tort law, contract law, or criminal law. These scholars focus on what makes certain domains of law distinctive and how one domain differs from another. A particularly fecund area of research has been the distinction between tort law and criminal law, which more generally bears on the difference between civil and criminal law.

Several schools of thought have developed around the nature of law, the most influential of which are:


In recent years, debates about the nature of law have become increasingly fine-grained. One important debate exists within legal positivism about the separability of law and morality. Exclusive legal positivists claim that the legal validity of a norm never depends on its moral correctness. Inclusive legal positivists claim that moral considerations "may" determine the legal validity of a norm, but that it is not necessary that this is the case. Positivism began as an inclusivist theory; but influential exclusive legal positivists, including Joseph Raz, John Gardner, and Leslie Green, later rejected the idea.

A second important debate, often called the "Hart-Dworkin Debate," concerns the battle between the two most dominant schools in the late 20th and early 21st century, legal interpretivism and legal positivism.

In addition to analytic jurisprudence, legal philosophy is also concerned with normative theories of law. "Normative jurisprudence involves normative, evaluative, and otherwise prescriptive questions about the law." For example, What is the goal or purpose of law? What moral or political theories provide a foundation for the law? Three approaches have been influential in contemporary moral and political philosophy, and these approaches are reflected in normative theories of law:
There are many other normative approaches to the philosophy of law, including critical legal studies and libertarian theories of law.

Philosophers of law are also concerned with a variety of philosophical problems that arise in particular legal subjects, such as constitutional law, Contract law, Criminal law, and Tort law. Thus, philosophy of law addresses such diverse topics as theories of contract law, theories of criminal punishment, theories of tort liability, and the question of whether judicial review is justified.




</doc>
<doc id="24695" url="https://en.wikipedia.org/wiki?curid=24695" title="Personal property">
Personal property

Personal property is property that is movable. In common law systems, personal property may also be called chattels or personalty. In civil law systems, personal property is often called movable property or movables – any property that can be moved from one location to another.

Personal property can be understood in comparison to real estate, immovable property or real property (such as land and buildings). 

Movable property on land (larger livestock, for example) was not automatically sold with the land, it was "personal" to the owner and moved with the owner. 

The word "cattle" is the Old Norman variant of Old French "chatel", chattel (derived from Latin "capitalis", “of the head”), which was once synonymous with general movable personal property. 

Personal property may be classified in a variety of ways.

Intangible personal property or "intangibles" refers to personal property that cannot actually be moved, touched or felt, but instead represents something of value such as negotiable instruments, securities, service (economics), and intangible assets including chose in action.

Tangible personal property refers to any type of property that can generally be moved (i.e., it is not attached to real property or land), touched or felt. These generally include items such as furniture, clothing, jewelry, art, writings, or household goods. In some cases, there can be formal title documents that show the ownership and transfer rights of that property after a person's death (for example, motor vehicles, boats, etc.) In many cases, however, tangible personal property will not be "titled" in an owner's name and is presumed to be whatever property he or she was in possession of at the time of his or her death.

Accountants also distinguish personal property from real property because personal property can be depreciated faster than improvements (while land is not depreciable at all). It is an owner's right to get tax benefits for chattel, and there are businesses that specialize in appraising personal property, or chattel.

The distinction between these types of property is significant for a variety of reasons. Usually one's rights on movables are more attenuated than one's rights on immovables (or real property). The statutes of limitations or prescriptive periods are usually shorter when dealing with personal or movable property. Real property rights are usually enforceable for a much longer period of time and in most jurisdictions real estate and immovables are registered in government-sanctioned land registers. In some jurisdictions, rights (such as a lien or other security interest) can be registered against personal or movable property.

In the common law it is possible to place a mortgage upon real property. Such mortgage requires payment or the owner of the mortgage can seek foreclosure. Personal property can often be secured with similar kind of device, variously called a chattel mortgage, trust receipt, or security interest. In the United States, Article 9 of the Uniform Commercial Code governs the creation and enforcement of security interests in most (but not all) types of personal property.

There is no similar institution to the mortgage in the civil law, however a hypothec is a device to secure real rights against property. These real rights follow the property along with the ownership. In the common law a lien also remains on the property and it is not extinguished by alienation of the property; liens may be real or equitable.

Many jurisdictions levy a personal property tax, an annual tax on the privilege of owning or possessing personal property within the boundaries of the jurisdiction. Automobile and boat registration fees are a subset of this tax. Most household goods are exempt as long as they are kept or used within the household; the tax usually becomes a problem when the taxing authority discovers that expensive personal property like art is being regularly stored outside of the household.

The distinction between tangible and intangible personal property is also significant in some of the jurisdictions which impose sales taxes. In Canada, for example, provincial and federal sales taxes were imposed primarily on sales of tangible personal property whereas sales of intangibles tended to be exempt. The move to value added taxes, under which almost all transactions are taxable, has diminished the significance of the distinction.

In political/economic theory, notably socialist, Marxist, and most anarchist philosophies, the distinction between private and personal property is extremely important. Which items of property constitute which is open to debate. In some economic systems, such as capitalism, private and personal property are considered to be exactly equivalent.





</doc>
<doc id="24696" url="https://en.wikipedia.org/wiki?curid=24696" title="Prima facie">
Prima facie

Prima facie (; ) is a Latin expression meaning "on its first encounter" or "at first sight". The literal translation would be "at first face" or "at first appearance", from the feminine forms of "primus" ("first") and "facies" ("face"), both in the ablative case. In modern, colloquial and conversational English, a common translation would be "on the face of it". The term "prima facie" is used in modern legal English (including both civil law and criminal law) to signify that upon initial examination, sufficient corroborating evidence appears to exist to support a case. In common law jurisdictions, "prima facie" denotes evidence that, unless rebutted, would be sufficient to prove a particular proposition or fact. The term is used similarly in academic philosophy. Most legal proceedings, in most jurisdictions, require a "prima facie" case to exist, following which proceedings may then commence to test it, and create a ruling.

In most legal proceedings, one party has a burden of proof, which requires it to present "prima facie" evidence for all of the essential facts in its case. If it cannot, its claim may be dismissed without any need for a response by other parties. A "prima facie" case might not stand or fall on its own; if an opposing party introduces other evidence or asserts an affirmative defense it can only be reconciled with a full trial. Sometimes the introduction of "prima facie" evidence is informally called "making a case" or "building a case".

For example, in a trial under criminal law the prosecution has the burden of presenting "prima facie" evidence of each element of the crime charged against the defendant. In a murder case, this would include evidence that the victim was in fact dead, that the defendant's act caused the death, and that the defendant acted with malice aforethought. If no party introduces new evidence, the case stands or falls just by the "prima facie" evidence or lack thereof, respectively.

"Prima facie" evidence does not need to be conclusive or irrefutable: at this stage, evidence rebutting the case is not considered, only whether any party's case has enough merit to take it to a full trial.

In common law jurisdictions such as the United Kingdom and the United States, the prosecution in a criminal trial must disclose all evidence to the defense. This includes the "prima facie" evidence.

An aim of the doctrine of "prima facie" is to prevent litigants from bringing spurious charges which simply waste all other parties' time.

"Prima facie" is often confused with "res ipsa loquitur" ("the thing speaks for itself", or literally "the thing itself speaks"), the common law doctrine that when the facts make it self-evident that negligence or other responsibility lies with a party, it is not necessary to provide extraneous details, since any reasonable person would immediately find the facts of the case.

The difference between the two is that "prima facie" is a term meaning there is enough evidence for there to be a case to answer, while "Res ipsa loquitur" means that the facts are so obvious a party does not need to explain any more. For example: "There is a "prima facie" case that the defendant is liable. They controlled the pump. The pump was left on and flooded the plaintiff's house. The plaintiff was away and had left the house in the control of the defendant. "Res ipsa loquitur"."

In Canadian tort law, this doctrine has been subsumed by general negligence law.

The phrase is also used in academic philosophy. Among its most notable uses is in the theory of ethics first proposed by W. D. Ross, often called the "Ethic of Prima Facie Duties", as well as in epistemology, as used, for example, by Robert Audi. It is generally used in reference to an obligation. "I have a "prima facie" obligation to keep my promise and meet my friend" means that I am under an obligation, but this may yield to a more pressing duty. A more modern usage prefers the title "pro tanto obligation": an obligation that may be later overruled by another more pressing one; it exists only "pro tempore".

The phrase "prima facie" is sometimes misspelled ' in the mistaken belief that ' is the actual Latin word; however, "faciē" is in fact the ablative case of "faciēs", a fifth declension Latin noun.

In policy debate theory, "prima facie" is used to describe the mandates or planks of an affirmative case, or, in some rare cases, a negative counterplan. When the negative team appeals to "prima facie", it appeals to the fact that the affirmative team cannot add or amend anything in its plan after being stated in the first affirmative constructive.

A common usage of the phrase is the concept of a ""prima facie" speed limit", which has been used in Australia and the United States. A "prima facie" speed limit is a default speed limit that applies when no other specific speed limit is posted, and may be exceeded by a driver. However, if the driver is detected, and cited by police for exceeding the limit, the onus of proof is on the driver, to show that the speed at which the driver was travelling was safe under the circumstances. In most jurisdictions, this type of speed limit has been replaced by absolute speed limits.




</doc>
<doc id="24697" url="https://en.wikipedia.org/wiki?curid=24697" title="Product liability">
Product liability

 
Product liability is the area of law in which manufacturers, distributors, suppliers, retailers, and others who make products available to the public are held responsible for the injuries those products cause. Although the word "product" has broad connotations, product liability as an area of law is traditionally limited to products in the form of tangible personal property.

In most nations legislatures have taken the lead in imposing strict liability for product defects. The courts of several countries, including Canada and South Africa, have not followed California's (US) "Greenman" holding.

In the United States, the majority of product liability laws are determined at the state level and vary widely from state to state. Each type of product liability claim requires proof of different elements in order to present a valid claim.

Of the various U.S. states, California was the first to throw away the fiction of a warranty and to boldly assert the doctrine of strict liability in tort for defective products, in the Supreme Court of California's decision in "Greenman v. Yuba Power Products", 59 Cal. 2d 57 (1963) (in which the majority opinion was authored by then-Associate Justice Roger J. Traynor). The Greenman decision was highly influential on the development of product liability law in other states.

In "Greenman", Traynor cited to his own earlier concurring opinion in "Escola v. Coca-Cola Bottling Co.", 24 Cal. 2d 453, 462 (1944) (Traynor, J., concurring). In "Escola", now widely recognized as a landmark case in American law, Justice Traynor laid the foundation for "Greenman" with these words:

Even if there is no negligence, however, public policy demands that responsibility be fixed wherever it will most effectively reduce the hazards to life and health inherent in defective products that reach the market. It is evident that the manufacturer can anticipate some hazards and guard against the recurrence of others, as the public cannot. Those who suffer injury from defective products are unprepared to meet its consequences. The cost of an injury and the loss of time or health may be an overwhelming misfortune to the person injured, and a needless one, for the risk of injury can be insured by the manufacturer and distributed among the public as a cost of doing business. It is to the public interest to discourage the marketing of products having defects that are a menace to the public. If such products nevertheless find their way into the market it is to the public interest to place the responsibility for whatever injury they may cause upon the manufacturer, who, even if he is not negligent in the manufacture of the product, is responsible for its reaching the market. However intermittently such injuries may occur and however haphazardly they may strike, the risk of their occurrence is a constant risk and a general one. Against such a risk there should be general and constant protection and the manufacturer is best situated to afford such protection.

The year after "Greenman", the Supreme Court of California proceeded to extend strict liability to "all" parties involved in the manufacturing, distribution, and sale of defective products (including retailers) and in 1969 made it clear that such defendants were liable not only to direct customers and users, but also to any innocent bystanders randomly injured by defective products.

Many jurisdictions have been swayed by Justice Traynor's arguments on behalf of the strict liability rule in "Escola", "Greenman", and subsequent cases. In the 40 years after "Greenman", the highest courts of nearly all U.S. states and territories followed California's example in imposing strict liability on manufacturers, distributors, and retailers for defective products. In a landmark 1986 decision, the U.S. Supreme Court embraced strict liability for defective products by adopting it as part of federal admiralty law.

Although the "Greenman" rule was adopted by many other states through Section 402A of the Restatement of Torts, Second (published in 1964 after "Greenman"), the Supreme Court of California refused to adopt Section 402A's "unreasonably dangerous" limitation upon strict liability in 1972. Thus, strict liability in California is truly strict, in that the plaintiff need not show that the defect was unreasonable or dangerous. On the other hand, in California, the defendant is allowed to introduce evidence in a strict products liability action that the plaintiff contributed to his or her own injuries.

California's courts continue to follow the standard set forth in "Greenman". In 2002 the California Supreme Court held that strict liability for defective products applies to makers of component products that are installed into and sold as part of real property. However, strict liability is not limitless. In 2012, the Court held that manufacturers are liable under strict liability and negligence only for defects in their products, as distinguished from other products that could potentially be used in association with their products.

Section 2 of the "Restatement (Third) of Torts: Products Liability" distinguishes between three major types of product liability claims:


However, in most states, these are not legal claims in and of themselves, but are pleaded in terms of the theories mentioned above. For example, a plaintiff might plead negligent failure to warn or strict liability for defective design.

In the United States, the claims most commonly associated with product liability are negligence, strict liability, breach of warranty, and various consumer protection claims.

Warranties are statements by a manufacturer or seller concerning a product during a commercial transaction. Warranty claims commonly require privity between the injured party and the manufacturer or seller; in plain English, this means they must be dealing with each other directly. Breach of warranty-based product liability claims usually focus on one of three types:
Express warranty claims focus on express statements by the manufacturer or the seller concerning the product (e.g., "This chainsaw is useful to cut turkeys").

The various implied warranties cover those expectations common to all products (e.g., that a tool is not unreasonably dangerous when used for its proper purpose), unless specifically disclaimed by the manufacturer or the seller. Claims involving real estate may also be brought under a theory of implied warranty of habitability.

A basic negligence claim consists of proof of


As demonstrated in cases such as "Winterbottom v. Wright", the scope of the duty of care was limited to those with whom one was in privity. Later cases like "MacPherson v. Buick Motor Co." broadened the duty of care to all who could be foreseeably injured by one's conduct.

Over time, negligence concepts have arisen to deal with certain specific situations, including negligence "per se" (using a manufacturer's violation of a law or regulation, in place of proof of a duty and a breach) and res ipsa loquitur (an inference of negligence under certain conditions).

Rather than focus on the behavior of the manufacturer (as in negligence), strict liability claims focus on the product itself. Under strict liability, the manufacturer is liable if the product is defective, even if the manufacturer was not negligent in making that product defective.

The difficulty with negligence is that it still requires the plaintiff to prove that the defendant's conduct fell below the relevant standard of care. However, if an entire industry tacitly settles on a somewhat careless standard of conduct (that is, as analyzed from the perspective of a layperson), then the plaintiff may not be able to recover even though he or she is severely injured, because although the defendant's conduct "caused" his or her injuries, such conduct was not negligent in the legal sense (if everyone within the trade would inevitably testify that the defendant's conduct conformed to that of a reasonable tradeperson in such circumstances). As a practical matter, with the increasing complexity of products, injuries, and medical care (which made many formerly fatal injuries survivable), it is quite a difficult and expensive task to find and retain good expert witnesses who can establish the standard of care, breach, and causation.

Therefore, in the 1940s and 1950s, many American courts departed from the "MacPherson" standard and decided that it was too harsh to require seriously injured consumer plaintiffs to prove negligence claims against manufacturers or retailers. To avoid having to deny such plaintiffs any relief, these courts began to look for facts in their cases which they could characterize as an express or implied warranty from the manufacturer to the consumer. The "res ipsa loquitur" doctrine was also stretched to reduce the plaintiff's burden of proof. Over time, the resulting legal fictions became increasingly strained.

In addition to common law remedies, many states have enacted consumer protection statutes that provide specific remedies for a variety of product defects. Under the product liabiity "economic loss rule", strict liability is generally unavailable for products that damage only themselves. Statutory remedies may apply to defects that merely render the product unusable (and hence cause economic injury) but do not cause physical injury or damage to other property.

The best known examples of consumer protection laws for product defects are lemon laws, which provide protection to purchasers of defective new vehicles and, in a small number of states, used vehicles.

In Europe, a movement towards strict liability began with the Council of Europe Convention on Products Liability in regard to Personal Injury and Death (the Strasbourg Convention) in 1977, which never entered into force. 

On July 25, 1985, the (then) European Economic Community adopted the Product Liability Directive. In language similar to Traynor's, the Directive stated that "liability without fault on the part of the producer is the sole means of adequately solving the problem, peculiar to our age of increasing technicality, of a fair apportionment of the risks inherent in modern technological production." The Directive gave each member state the option of imposing a liability cap of 70 million euros per defect. The Directive only imposed strict liability upon manufacturers or importers, and deviated significantly from the U.S. model by not imposing strict liability on purely domestic distributors or retailers.

The legislatures of many other countries outside the EU (then: EEC) subsequently enacted strict liability regimes based on the European model (that is, generally applying only to manufacturers and importers), including Israel (March 1980, based on an early proposed draft of the Directive), Brazil (September 1990), Peru (November 1991), Australia (July 1992), Russia (February 1992), Switzerland (December 1992), Argentina (October 1993), Japan (June 1994), Taiwan (June 1994), Malaysia (August 1999), South Korea (January 2000), Thailand (December 2007), and South Africa (April 2009).

Advocates of strict liability laws argue that strict products liability causes manufacturers to internalize costs they would normally externalize. Strict liability thus requires manufacturers to evaluate the full costs of their products. In this way, strict liability provides a mechanism for ensuring that a product's absolute good outweighs its absolute harm.

Between two parties who are not negligent (manufacturer and consumer), one will necessarily shoulder the costs of product defects. Proponents say it is preferable to place the economic costs on the manufacturer because it can better absorb them and pass them on to other consumers. The manufacturer thus becomes a de facto insurer against its defective products, with premiums built into the product's price.

Strict liability also seeks to diminish the impact of information asymmetry between manufacturers and consumers. Manufacturers have better knowledge of their own products' dangers than do consumers. Therefore, manufacturers properly bear the burden of finding, correcting, and warning consumers of those dangers.

Strict liability reduces litigation costs, because a plaintiff need only prove causation, not imprudence. Where causation is easy to establish, parties to a strict liability suit will most likely settle, because only damages are in dispute.

Critics charge that strict liability creates risk of moral hazard. They claim that strict liability causes consumers to under invest in care even when they are the least-cost avoiders. This, they say, results in a lower aggregate level of care than under a negligence standard. Proponents counter that people have enough natural incentive to avoid inflicting serious harm on themselves to mitigate this concern.

Critics charge that the requiring manufacturers to internalize costs they would otherwise externalize increases the price of goods. Critics claim that in elastic, price-sensitive markets, price increases cause some consumers to seek substitutes for that product. As a result, they say, manufacturers may not produce the socially optimal level of goods. Proponents respond that these consumer opt outs reflect a product whose absolute harm outweighs its absolute value; products that do more harm than good ought not be produced.

In the law and economics literature, there is a debate about whether liability and regulation are substitutes or complements. If they are substitutes, then either liability or regulation should be used. If they are complements, then the joint use of liability and regulation is optimal.




</doc>
<doc id="24698" url="https://en.wikipedia.org/wiki?curid=24698" title="Proximate cause">
Proximate cause

In law, a proximate cause is an event sufficiently related to an injury that the courts deem the event to be the cause of that injury. There are two types of causation in the law: cause-in-fact, and proximate (or legal) cause. Cause-in-fact is determined by the "but for" test: But for the action, the result would not have happened. (For example, but for running the red light, the collision would not have occurred.) The action is a necessary condition, but may not be a sufficient condition, for the resulting injury. A few circumstances exist where the but for test is ineffective (see But-for test). Since but-for causation is very easy to show (but for stopping to tie your shoe, you would not have missed the train and would not have been mugged), a second test is used to determine if an action is close enough to a harm in a "chain of events" to be legally valid. This test is called proximate cause. Proximate cause is a key principle of Insurance and is concerned with how the loss or damage actually occurred. There are several competing theories of proximate cause (see Other factors). For an act to be deemed to cause a harm, both tests must be met; proximate cause is a legal limitation on cause-in-fact.

The formal Latin term for "but for" (cause-in-fact) causation, is sine qua non causation.

A few circumstances exist where the "but for" test is complicated, or the test is ineffective. The primary examples are:

Since but-for causation is very easy to show and does not assign culpability (but for the rain, you would not have crashed your carthe rain is not morally or legally culpable but still constitutes a cause), there is a second test used to determine if an action is close enough to a harm in a "chain of events" to be a legally culpable cause of the harm. This test is called proximate cause, from the Latin "proxima causa".

There are several competing theories of proximate cause.

The most common test of proximate cause under the American legal system is foreseeability. It determines if the harm resulting from an action could reasonably have been predicted. The test is used in most cases only in respect to the type of harm. It is foreseeable, for example, that throwing a baseball at someone could cause them a blunt-force injury. But proximate cause is still met if a thrown baseball misses the target and knocks a heavy object off a shelf behind them, which causes a blunt-force injury. Evident in Corrigan v HSE (2011 IEHC 305).

This is also known as the "extraordinary in hindsight" rule.

Direct causation is a minority test, which addresses only the metaphysical concept of causation. It does not matter how foreseeable the result as long as what the negligent party's physical activity can be tied to what actually happened. The main thrust of direct causation is that there are no intervening causes between an act and the resulting harm. An intervening cause has several requirements: it must 1) be independent of the original act, 2) be a voluntary human act or an abnormal natural event, and 3) occur in time between the original act and the harm.

Direct causation is the only theory that addresses only causation and does not take into account the culpability of the original actor.

The plaintiff must demonstrate that the defendant's action increased the risk that the particular harm suffered by the plaintiff would occur. If the action were repeated, the likelihood of the harm would correspondingly increase. This is also called foreseeable risk.

The harm within the risk (HWR) test determines whether the victim was among the class of persons who could foreseeably be harmed, and whether the harm was foreseeable within the class of risks. It is the strictest test of causation, made famous by Benjamin Cardozo in "Palsgraf v. Long Island Railroad Co." case under New York state law.

The first element of the test is met if the injured person was a member of a class of people who could be expected to be put at risk of injury by the action. For example, a pedestrian, as an expected user of sidewalks, is among the class of people put at risk by driving on a sidewalk, whereas a driver who is distracted by another driver driving on the sidewalk, and consequently crashes into a utility pole, is not.

The HWR test is no longer much used, outside of New York law. When it is used, it is used to consider the class of people injured, not the type of harm. The main criticism of this test is that it is preeminently concerned with culpability, rather than actual causation.

Referred to by the Reporters of the Second and Third Restatements of the Law of Torts as the "scope-of-the-risk" test, the term "Risk Rule" was coined by the University of Texas School of Law's Dean Robert Keeton. The rule is that “[a]n actor’s liability is limited to those physical harms that result from the risks that made the actor’s conduct tortious.” Thus, the operative question is "what were the particular risks that made an actor's conduct negligent?" If the injury suffered is not the result of one of those risks, there can be no recovery. Two examples will illustrate this principle:


The most obvious objection to this approach is that it requires courts to consider an arguably endless possibility of hypothetical situations. Not only can such an undertaking be an exercise in futility, but this approach lacks even a minimal amount of precision such that parties might be able to predict outcomes and results during litigation. Notwithstanding the already-complex nature of this and other questions relating to proximate or legal cause, this fluid standard could be misused by plaintiff-friendly or defense-favoring judges in attempts to vindicate their own personal philosophies regarding the appropriate reach of tort law.

The doctrine of proximate cause is notoriously confusing. The doctrine is phrased in the language of causation, but in most of the cases in which proximate cause is actively litigated, there is not much real dispute that the defendant but-for caused the plaintiff's injury. The doctrine is actually used by judges in a somewhat arbitrary fashion to limit the scope of the defendant's liability to a subset of the total class of potential plaintiffs who may have suffered some harm from the defendant's actions. 

For example, in the two famous "Kinsman Transit" cases from the 2nd Circuit (exercising admiralty jurisdiction over a New York incident), it was clear that mooring a boat improperly could lead to the risk of that boat drifting away and crashing into another boat, and that both boats could crash into a bridge, which collapsed and blocked the river, and in turn, the wreckage could flood the land adjacent to the river, as well as prevent any traffic from traversing the river until it had been cleared. But under proximate cause, the property owners adjacent to the river could sue ("Kinsman I"), but not the owners of the boats or cargoes which could not move until the river was reopened ("Kinsman II").

Therefore, in the final version of the "Restatement (Third), Torts: Liability for Physical and Emotional Harm", published in 2010, the American Law Institute argued that proximate cause should be replaced with scope of liability. Chapter 6 of the Restatement is titled "Scope of Liability (Proximate Cause)." It begins with a special note explaining the Institute's decision to reframe the concept in terms of "scope of liability" because it does not involve true causation, and to also include "proximate cause" in the chapter title in parentheses to help judges and lawyers understand the connection between the old and new terminology. The Institute added that it "fervently hopes" the parenthetical will be unnecessary in a future fourth Restatement of Torts.

A related doctrine is the insurance law doctrine of efficient proximate cause. Under this rule, in order to determine whether a loss resulted from a cause covered under an insurance policy, a court looks for the predominant cause which sets into motion the chain of events producing the loss, which may not necessarily be the "last" event that immediately preceded the loss. Many insurers have attempted to contract around efficient proximate cause through the use of "anti-concurrent causation" (ACC) clauses, under which if a covered cause and a noncovered cause join together to cause a loss, the loss is not covered.

ACC clauses frequently come into play in jurisdictions where property insurance does not normally include flood insurance and expressly excludes coverage for floods. The classic example of how ACC clauses work is where a hurricane hits a building with wind and flood hazards "at the same time." If the evidence later shows that the wind blew off a building's roof and then water damage resulted only because there was no roof to prevent rain from entering, there would be coverage, but if the building was simultaneously flooded (i.e., because the rain caused a nearby body of water to rise or simply overwhelmed local sewers), an ACC clause would completely block coverage for the "entire" loss (even if the building owner could otherwise attribute damage to wind v. flood).

A minority of jurisdictions have ruled ACC clauses to be unenforceable as against public policy, but they are generally enforceable in the majority of jurisdictions.




</doc>
<doc id="24702" url="https://en.wikipedia.org/wiki?curid=24702" title="Peace">
Peace

Peace is a concept of societal friendship and harmony in the absence of hostility and violence. In a social sense, peace is commonly used to mean a lack of conflict (such as war) and freedom from fear of violence between individuals or groups. Throughout history leaders have used peacemaking and diplomacy to establish a certain type of behavioral restraint that has resulted in the establishment of regional peace or economic growth through various forms of agreements or peace treaties. Such behavioral restraint has often resulted in the reduction of conflicts, greater economic interactivity, and consequently substantial prosperity.

"Psychological peace" (such as a peaceful thinking and emotions) is perhaps less well defined yet often a necessary precursor to establishing "behavioral peace." Peaceful behavior sometimes results from a "peaceful inner disposition." Some have expressed the belief that peace can be initiated with a certain quality of inner tranquility that does not depend upon the uncertainties of daily life for its existence. The acquisition of such a "peaceful internal disposition" for oneself and others can contribute to resolving of otherwise seemingly irreconcilable competing interests.

The Anglo-French term "Pes" itself comes from the Latin "pax", meaning "peace, compact, agreement, treaty of peace, tranquility, absence of hostility, harmony." The English word came into use in various personal greetings from c.1300 as a translation of the Hebrew word shalom, which, according to Jewish theology, comes from a Hebrew verb meaning 'to be complete, whole'. Although 'peace' is the usual translation, however, it is an incomplete one, because 'shalom,' which is also cognate with the Arabic "salaam", has multiple other meanings in addition to peace, including justice, good health, safety, well-being, prosperity, equity, security, good fortune, and friendliness, as well as simply the greetings, "hello" and "goodbye". At a personal level, peaceful behaviors are kind, considerate, respectful, just, and tolerant of others' beliefs and behaviors – tending to manifest goodwill. The term-'peace' originates most recently from the Anglo-French "pes," and the Old French "pais", meaning "peace, reconciliation, silence, agreement" (11th century).

This latter understanding of peace can also pertain to an individual's introspective sense or concept of her/himself, as in being "at peace" in one's own mind, as found in European references from c.1200. The early English term is also used in the sense of "quiet", reflecting calm, serene, and meditative approaches to family or group relationships that avoid quarreling and seek tranquility — an absence of disturbance or agitation.

In many languages, the word for peace is also used as a greeting or a farewell, for example the Hawaiian word aloha, as well as the Arabic word "salaam". In English the word peace is occasionally used as a farewell, especially for the dead, as in the phrase "rest in peace".

Wolfgang Dietrich in his research project which led to the book "The Palgrave International Handbook of Peace Studies" (2011) maps the different meanings of peace in different languages and from different regions across the world. Later, in his "Interpretations of Peace in History and Culture" (2012), he groups the different meanings of peace into five peace families: Energetic/Harmony, Moral/Justice, Modern/Security, Postmodern/Truth, and Transrational, a synthesis of the positive sides of the four previous families and the society.

In ancient times and more recently, peaceful alliances between different nations were codified through royal marriages. Two examples, Hermodike I c.800BC and Hermodike II c.600BC were Greek princesses from the house of Agamemnon who married kings from what is now Central Turkey. The union of Phrygia / Lydia with Aeolian Greeks resulted in regional peace, which facilitated the transfer of ground-breaking technological skills into Ancient Greece; respectively, the phonetic written script and the minting of coinage (to use a token currency, where the value is guaranteed by the state). Both inventions were rapidly adopted by surrounding nations through further trade and cooperation and have been of fundamental benefit to the progress of civilization.

Since classical times, it has been noted that peace has sometimes been achieved by the victor over the vanquished by the imposition of ruthless measures. In his book "Agricola" the Roman historian Tacitus includes eloquent and vicious polemics against the rapacity and greed of Rome. One, that Tacitus says is by the Caledonian chieftain Calgacus, ends "Auferre trucidare rapere falsis nominibus imperium, atque ubi solitudinem faciunt, pacem appellant." (To ravage, to slaughter, to usurp under false titles, they call empire; and where they make a desert, they call it peace. — Oxford Revised Translation).

Discussion of peace is therefore at the same time a discussion on the form of such peace. Is it simple absence of mass organized killing (war) or does peace require a particular morality and justice? ("just peace").
A peace must be seen at least in two forms:

More recently, advocates for radical reform in justice systems have called for a public policy adoption of non-punitive, non-violent Restorative Justice methods, and many of those studying the success of these methods, including a United Nations working group on Restorative Justice, have attempted to re-define justice in terms related to peace. From the late 2000s on, a Theory of Active Peace has been proposed which conceptually integrates justice into a larger peace theory.

The United Nations (UN) is an international organization whose stated aims are to facilitate cooperation in international law, international security, economic development, social progress, human rights, and achieving world peace. The UN was founded in 1945 after World War II to replace the League of Nations, to stop wars between countries, and to provide a platform for dialogue.

The UN, after approval by the Security Council, sends peacekeepers to regions where armed conflict has recently ceased or paused to enforce the terms of peace agreements and to discourage combatants from resuming hostilities. Since the UN does not maintain its own military, peacekeeping forces are voluntarily provided by member states of the UN. The forces, also called the "Blue Helmets", who enforce UN accords are awarded United Nations Medals, which are considered international decorations instead of military decorations. The peacekeeping force as a whole received the Nobel Peace Prize in 1988.

The obligation of the state to provide for domestic peace within its borders in usually charged to the police and other general domestic policing activities. The police are a constituted body of persons empowered by a state to enforce the law, to protect the lives, liberty and possessions of citizens, and to prevent crime and civil disorder. Their powers include the power of arrest and the legitimized use of force. The term is most commonly associated with the police forces of a sovereign state that are authorized to exercise the police power of that state within a defined legal or territorial area of responsibility. Police forces are often defined as being separate from the military and other organizations involved in the defense of the state against foreign aggressors; however, gendarmerie are military units charged with civil policing. Police forces are usually public sector services, funded through taxes.

It is the obligation of national security to provide for peace and security in a nation against foreign threats and foreign aggression. Potential causes of national insecurity include actions by other states (e.g. military or cyber attack), violent non-state actors (e.g. terrorist attack), organised criminal groups such as narcotic cartels, and also the effects of natural disasters (e.g. flooding, earthquakes). Systemic drivers of insecurity, which may be transnational, include climate change, economic inequality and marginalisation, political exclusion, and militarisation. In view of the wide range of risks, the preservation of peace and the security of a nation state have several dimensions, including economic security, energy security, physical security, environmental security, food security, border security, and cyber security. These dimensions correlate closely with elements of national power.

The principal forerunner of the United Nations was the League of Nations. It was created at the Paris Peace Conference of 1919, and emerged from the advocacy of Woodrow Wilson and other idealists during World War I. The Covenant of the League of Nations was included in the Treaty of Versailles in 1919, and the League was based in Geneva until its dissolution as a result of World War II and replacement by the United Nations. The high hopes widely held for the League in the 1920s, for example amongst members of the League of Nations Union, gave way to widespread disillusion in the 1930s as the League struggled to respond to challenges from Nazi Germany, Fascist Italy, and Japan. 

One of the most important scholars of the League of Nations was Sir Alfred Zimmern. Like many of the other British enthusiasts for the League, such as Gilbert Murray and Florence Stawell – the so-called "Greece and peace" set – he came to this from the study of the classics.

The creation of the League of Nations, and the hope for informed public opinion on international issues (expressed for example by the Union for Democratic Control during World War I), also saw the creation after World War I of bodies dedicated to understanding international affairs, such as the Council on Foreign Relations in New York and the Royal Institute of International Affairs at Chatham House in London. At the same time, the academic study of international relations started to professionalize, with the creation of the first professorship of international politics, named for Woodrow Wilson, at Aberystwyth, Wales, in 1919.

The late 19th century idealist advocacy of peace which led to the creation of the Nobel Peace Prize, the Rhodes Scholarships, the Carnegie Endowment for International Peace, and ultimately the League of Nations, also saw the re-emergence of the ancient Olympic ideal. Led by Pierre de Coubertin, this culminated in the holding in 1896 of the first of the modern Olympic Games.

The highest honour awarded to peace maker is the Nobel Prize in Peace, awarded since 1901 by the Norwegian Nobel Committee. It is awarded annually to internationally notable persons following the prize's creation in the will of Alfred Nobel. According to Nobel's will, the Peace Prize shall be awarded to the person who "...shall have done the most or the best work for fraternity between nations, for the abolition or reduction of standing armies and for the holding and promotion of peace congresses."

In creating the Rhodes Scholarships for outstanding students from the United States, Germany and much of the British Empire, Cecil Rhodes wrote in 1901 that 'the object is that an understanding between the three great powers will render war impossible and educational relations make the strongest tie'. This peace purpose of the Rhodes Scholarships was very prominent in the first half of the 20th century, and became prominent again in recent years under Warden of the Rhodes House Donald Markwell, a historian of thought about the causes of war and peace. This vision greatly influenced Senator J. William Fulbright in the goal of the Fulbright fellowships to promote international understanding and peace, and has guided many other international fellowship programs, including the Schwarzman Scholars to China created by Stephen A. Schwarzman in 2013.

The International Gandhi Peace Prize, named after Mahatma Gandhi, is awarded annually by the Government of India. It is launched as a tribute to the ideals espoused by Gandhi in 1995 on the occasion of the 125th anniversary of his birth. This is an annual award given to individuals and institutions for their contributions towards social, economic and political transformation through non-violence and other Gandhian methods. The award carries Rs. 10 million in cash, convertible in any currency in the world, a plaque and a citation. It is open to all persons regardless of nationality, race, creed or sex.

The Student Peace Prize is awarded biennially to a student or a student organization that has made a significant contribution to promoting peace and human rights.

The Culture of Peace News Network, otherwise known simply as CPNN, is a UN authorized interactive online news network, committed to supporting the global movement for a culture of peace.

Every year in the first week of November, the Sydney Peace Foundation presents the Sydney Peace Prize. The Sydney Peace Prize is awarded to an organization or an individual whose life and work has demonstrated significant contributions to:
The achievement of peace with justice locally, nationally or internationally
The promotion and attainment of human rights
The philosophy, language and practice of non-violence

A peace museum is a museum that documents historical peace initiatives. Many peace museums also provide advocacy programs for nonviolent conflict resolution. This may include conflicts at the personal, regional or international level.

Smaller institutions:

Religious beliefs often seek to identify and address the basic problems of human life, including the conflicts between, among, and within persons and societies. In ancient Greek-speaking areas the virtue of peace was personified as the goddess Eirene, and in Latin-speaking areas as the goddess Pax. Her image was typically represented by ancient sculptors as that of a full-grown woman, usually with a horn of plenty and scepter and sometimes with a torch or olive leaves.

Christians, who believe Jesus of Nazareth to be the Jewish Messiah called Christ (meaning Anointed One), interpret Isaiah 9:6 as a messianic prophecy of Jesus in which he is called the "Prince of Peace." In the Gospel of Luke, Zechariah celebrates his son John: And you, child, will be called prophet of the Most High, for you will go before the Lord to prepare his ways, to give his people knowledge of salvation through the forgiveness of their sins, because of the tender mercy of our God by which the daybreak from on high will visit us to shine on those who sit in darkness and death's shadow, to guide our feet into the path of peace.

Numerous pontifical documents on the Holy Rosary document a continuity of views of the Popes to have confidence in the Holy Rosary as a means to foster peace. Subsequently, to the Encyclical Mense maio,1965, in which he urged the practice of the Holy Rosary, "the prayer so dear to the Virgin and so much recommended by the Supreme Pontiffs," and as reaffirmed in the encyclical Christi Matri, 1966, to implore peace, Pope Paul VI stated in the apostolic Recurrens mensis, October 1969, that the Rosary is a prayer that favors the great gift of peace.

Islam derived from the root word salam which literally means peace. Muslims are called followers of Islam. Quran clearly stated "Those who have believed and whose hearts are assured by the remembrance of Allah. Unquestionably, by the remembrance of Allah, hearts are assured" and stated "O you who have believed, when you are told, "Space yourselves" in assemblies, then make space; Allah will make space for you. And when you are told, "Arise," then arise; Allah will raise those who have believed among you and those who were given knowledge, by degrees. And Allah is Acquainted with what you do."

Buddhists believe that peace can be attained once all suffering ends. They regard all suffering as stemming from cravings (in the extreme, greed), aversions (fears), or delusions. To eliminate such suffering and achieve personal peace, followers in the path of the Buddha adhere to a set of teachings called the Four Noble Truths — a central tenet in Buddhist philosophy.

Hindu texts contain the following passages:

Pacifism is the categorical opposition to the behaviors of war or violence as a means of settling disputes or of gaining advantage. Pacifism covers a spectrum of views ranging from the belief that international disputes can and should all be resolved via peaceful behaviors; to calls for the abolition of various organizations which tend to institutionalize aggressive behaviors, such as the military, or arms manufacturers; to opposition to any organization of society that might rely in any way upon governmental force. Such groups which sometimes oppose the governmental use of force include anarchists and libertarians. Absolute pacifism opposes violent behavior under all circumstance, including defense of self and others.

Pacifism may be based on moral principles (a deontological view) or pragmatism (a consequentialist view). Principled pacifism holds that all forms of violent behavior are inappropriate responses to conflict, and are morally wrong. Pragmatic pacifism holds that the costs of war and inter-personal violence are so substantial that better ways of resolving disputes must be found.

Psychological or inner peace (i.e. peace of mind) refers to a state of being internally or spiritually at peace, with sufficient knowledge and understanding to keep oneself calm in the face of apparent discord or stress. Being internally "at peace" is considered by many to be a healthy mental state, or homeostasis and to be the opposite of feeling stressful, mentally anxious, or emotionally unstable. Within the meditative traditions, the psychological or inward achievement of "peace of mind" is often associated with bliss and happiness.

Peace of mind, serenity, and calmness are descriptions of a disposition free from the effects of stress. In some meditative traditions, inner peace is believed to be a state of consciousness or enlightenment that may be cultivated by various types of meditation, prayer, t'ai chi ch'uan (太极拳, tàijíquán), yoga, or other various types of mental or physical disciplines. Many such practices refer to this peace as an experience of knowing oneself. An emphasis on finding one's inner peace is often associated with traditions such as Buddhism, Hinduism, and some traditional Christian contemplative practices such as monasticism, as well as with the New Age movement.

Satyagraha is a philosophy and practice of nonviolent resistance developed by Mohandas Karamchand Gandhi. He deployed satyagraha techniques in campaigns for Indian independence and also during his earlier struggles in South Africa.

The word "satyagraha" itself was coined through a public contest that Gandhi sponsored through the newspaper he published in South Africa, 'Indian Opinion', when he realized that neither the common, contemporary Hindu language nor the English language contained a word which fully expressed his own meanings and intentions when he talked about his nonviolent approaches to conflict. According to Gandhi's autobiography, the contest winner was Maganlal Gandhi (presumably no relation), who submitted the entry 'sadagraha', which Gandhi then modified to 'satyagraha'. Etymologically, this Hindic word means 'truth-firmness', and is commonly translated as 'steadfastness in the truth' or 'truth-force'.

Satyagraha theory also influenced Martin Luther King Jr. during the campaigns he led during the civil rights movement in the United States. The theory of satyagraha sees means and ends as inseparable. Therefore, it is contradictory to try to use violence to obtain peace. As Gandhi wrote: "They say, 'means are, after all, means'. I would say, 'means are, after all, everything'. As the means so the end..." A contemporary quote sometimes attributed to Gandhi, but also to A. J. Muste, sums it up: 'There is no way to peace; peace is the way.'

The following are monuments to peace:

Many different theories of "peace" exist in the world of peace studies, which involves the study of de-escalation, conflict transformation, disarmament, and cessation of violence. The definition of "peace" can vary with religion, culture, or subject of study.

The classical "realist" position is that the key to promoting order between states, and so of increasing the chances of peace, is the maintenance of a balance of power between states – a situation where no state is so dominant that it can "lay down the law to the rest". Exponents of this view have included Metternich, Bismarck, Hans Morgenthau, and Henry Kissinger. A related approach – more in the tradition of Hugo Grotius than Thomas Hobbes – was articulated by the so-called "English school of international relations theory" such as Martin Wight in his book "Power Politics" (1946, 1978) and Hedley Bull in "The Anarchical Society" (1977).

As the maintenance of a balance of power could in some circumstances require a willingness to go to war, some critics saw the idea of a balance of power as promoting war rather than promoting peace. This was a radical critique of those supporters of the Allied and Associated Powers who justified entry into World War I on the grounds that it was necessary to preserve the balance of power in Europe from a German bid for hegemony.

In the second half of the 20th century, and especially during the cold war, a particular form of balance of power – mutual nuclear deterrence – emerged as a widely held doctrine on the key to peace between the great powers. Critics argued that the development of nuclear stockpiles increased the chances of war rather than peace, and that the "nuclear umbrella" made it "safe" for smaller wars (e.g. the Vietnam war and the Soviet invasion of Czechoslovakia to end the Prague Spring), so making such wars more likely.

It was a central tenet of classical liberalism, for example among English liberal thinkers of the late 19th and early 20th century, that free trade promoted peace. For example, the Cambridge economist John Maynard Keynes (1883–1946) said that he was "brought up" on this idea and held it unquestioned until at least the 1920s. During the economic globalization in the decades leading up to World War I, writers such as Norman Angell argued that the growth of economic interdependence between the great powers made war between them futile and therefore unlikely. He made this argument in 1913. A year later Europe's economically interconnected states were embroiled in what would later become known as the First World War.

These ideas have again come to prominence among liberal internationalists during the globalization of the late 20th and early 21st century. These ideas have seen capitalism as consistent with, even conducive to, peace.

The "Peace & War Game" is an approach in game theory to understand the relationship between peace and conflicts.

The iterated game hypotheses was originally used by academic groups and computer simulations to study possible strategies of cooperation and aggression.

As peace makers became richer over time, it became clear that making war had greater costs than initially anticipated. One of the well studied strategies that acquired wealth more rapidly was based on Genghis Khan, i.e. a constant aggressor making war continually to gain resources. This led, in contrast, to the development of what's known as the "provokable nice guy strategy", a peace-maker until attacked, improved upon merely to win by occasional forgiveness even when attacked. By adding the results of all pairwise games for each player, one sees that multiple players gain wealth cooperating with each other while bleeding a constantly aggressive player.

Socialist, communist, and left-wing liberal writers of the 19th and 20th centuries (e.g., Lenin, J.A. Hobson, John Strachey) argued that capitalism caused war (e.g. through promoting imperial or other economic rivalries that lead to international conflict). This led some to argue that international socialism was the key to peace.

However, in response to such writers in the 1930s who argued that capitalism caused war, the economist John Maynard Keynes (1883–1946) argued that managed capitalism could promote peace. This involved international coordination of fiscal/monetary policies, an international monetary system that did not pit the interests of countries against each other, and a high degree of freedom of trade. These ideas underlay Keynes's work during World War II that led to the creation of the International Monetary Fund and the World Bank at Bretton Woods in 1944, and later of the General Agreement on Tariffs and Trade (subsequently the World Trade Organization).

Borrowing from the teachings of Norwegian theorist Johan Galtung, one of the pioneers of the field of Peace Research, on 'Positive Peace', and on the writings of Maine Quaker Gray Cox, a consortium of theorists, activists, and practitioners in the experimental John Woolman College initiative have arrived at a theory of "active peace". This theory posits in part that peace is part of a triad, which also includes justice and wholeness (or well-being), an interpretation consonant with scriptural scholarly interpretations of the meaning of the early Hebrew word "shalom". Furthermore, the consortium have integrated Galtung's teaching of the meanings of the terms peacemaking, peacekeeping, and peacebuilding, to also fit into a triadic and interdependent formulation or structure. Vermont Quaker John V. Wilmerding posits five stages of growth applicable to individuals, communities, and societies, whereby one transcends first the 'surface' awareness that most people have of these kinds of issues, emerging successively into acquiescence, pacifism, passive resistance, active resistance, and finally into "active peace", dedicating themselves to peacemaking, peacekeeping or peace building.

One of the most influential theories of peace, especially since Woodrow Wilson led the creation of the League of Nations at the Paris Peace Conference of 1919, is that peace will be advanced if the intentional anarchy of states is replaced through the growth of international law promoted and enforced through international organizations such as the League of Nations, the United Nations, and other functional international organizations. One of the most important early exponents of this view was Sir Alfred Zimmern, for example in his 1936 book "The League of Nations and the Rule of Law".

Many "idealist" thinkers about international relations – e.g. in the traditions of Kant and Karl Marx – have argued that the key to peace is the growth of some form of solidarity between peoples (or classes of people) spanning the lines of cleavage between nations or states that lead to war.

One version of this is the idea of promoting international understanding between nations through the international mobility of students – an idea most powerfully advanced by Cecil Rhodes in the creation of the Rhodes Scholarships, and his successors such as J. William Fulbright.

Another theory is that peace can be developed among countries on the basis of active management of water resources.

Following Wolfgang Dietrich, Wolfgang Sützl and the Innsbruck School of Peace Studies, some peace thinkers have abandoned any single and all-encompassing definition of peace. Rather, they promote the idea of "many peaces". They argue that since no singular, correct definition of peace can exist, peace should be perceived as a plurality. This post-modern understanding of peace(s) was based on the philosophy of Jean Francois Lyotard. It served as a fundament for the more recent concept of trans-rational peace(s) and elicitive conflict transformation.

In 2008 Dietrich enlarged his approach of the "many peaces" to the so-called "five families" of peace interpretations: the energetic, moral, modern, post-modern and trans-rational approach. Trans-rationality unites the rational and mechanistic understanding of modern peace in a relational and culture-based manner with spiritual narratives and energetic interpretations. The systemic understanding of trans-rational peaces advocates a client-centred method of conflict transformation, the so-called elicitive approach.


"Peace and conflict studies" is an academic field which identifies and analyses violent and nonviolent behaviours, as well as the structural mechanisms attending violent and non-violent social conflicts. This is to better understand the processes leading to a more desirable human condition. One variation,
"Peace studies" (irenology), is an interdisciplinary effort aiming at the prevention, de-escalation, and solution of conflicts. This contrasts with war studies (polemology), directed at the efficient attainment of victory in conflicts. Disciplines involved may include political science, geography, economics, psychology, sociology, international relations, history, anthropology, religious studies, and gender studies, as well as a variety of other disciplines.

Although peace is widely perceived as something intangible, various organizations have been making efforts to quantify and measure it. The Global Peace Index produced by the Institute for Economics and Peace is a known effort to evaluate peacefulness in countries based on 23 indicators of the absence of violence and absence of the fear of violence.

The last edition of the Index ranks 163 countries on their internal and external levels of peace. According to the 2017 Global Peace Index, Iceland is the most peaceful country in the world while Syria is the least peaceful one. Fragile States Index (formerly known as the Failed States Index) created by the Fund for Peace focuses on risk for instability or violence in 178 nations. This index measures how fragile a state is by 12 indicators and subindicators that evaluate aspects of politics, social economy, and military facets in countries. The 2015 Failed State Index reports that the most fragile nation is South Sudan, and the least fragile one is Finland. University of Maryland publishes the Peace and Conflict Instability Ledger in order to measure peace. It grades 163 countries with 5 indicators, and pays the most attention to risk of political instability or armed conflict over a three-year period. The most recent ledger shows that the most peaceful country is Slovenia on the contrary Afghanistan is the most conflicted nation. Besides indicated above reports from the Institute for Economics and Peace, Fund for Peace, and University of Maryland, other organizations including George Mason University release indexes that rank countries in terms of peacefulness.

The longest continuing period of neutrality among currently existing states is observed in Switzerland, which has had an official policy of neutrality since 1815. This was made possible partly by the periods of relative peace in Europe and the world known as Pax Britannica (1815–1914), Pax Europaea/Pax Americana (since 1950s), and Pax Atomica (also since the 1950s).

Other examples of long periods of peace are:



</doc>
<doc id="24703" url="https://en.wikipedia.org/wiki?curid=24703" title="Portland Vase">
Portland Vase

The Portland Vase is a Roman cameo glass vase, which is dated to between AD 1 and AD 25, though low BC dates have some scholarly support. It is the best known piece of Roman cameo glass and has served as an inspiration to many glass and porcelain makers from about the beginning of the 18th century onwards. It is first recorded in Rome in 1600–1601, and since 1810 has been in the British Museum in London. It was bought by the museum in 1945 (GR 1945,0927.1) and is normally on display in Room 70.

The vase is about high and in circumference. It is made of violet-blue glass, and surrounded with a single continuous white glass cameo making two distinct scenes, depicting seven human figures, plus a large snake, and two bearded and horned heads below the handles, marking the break between the scenes.

The bottom of the vase was a cameo glass disc, also in blue and white, showing a head, presumed to be of Paris or Priam on the basis of the Phrygian cap it wears. This roundel clearly does not belong to the vase, and has been displayed separately since 1845. It may have been added to mend a break in antiquity or after, or the result of a conversion from an original amphora form (paralleled by a similar blue-glass cameo vessel from Pompeii) – it was attached to the bottom from at least 1826.

The meaning of the images on the vase is unclear, and none of the many theories put forward has been found generally satisfactory. They fall into two main groups: mythological and historical, though a historical interpretation of a myth is also a possibility. Historical interpretations focus on Augustus, his family and his rivals, especially given the quality and expense of the object, and the somewhat remote neo-classicism of the style, which compares with some Imperial gemstone cameos featuring Augustus and his family with divine attributes, such as the Gemma Augustea, the Great Cameo of France and the Blacas Cameo (the last also in the British Museum). Interpretations of the portrayals have included that of a marine setting (due to the presence of a ketos or sea-snake), and of a marriage theme/context, as the vase may have been a wedding gift. Many scholars (including Charles Towneley) have concluded that the figures do not fit into a single iconographic set.

Interpretations include:

Interpretations include:

Another variant theory is that the vase dates back to circa 32 BC, and was commissioned by Octavian (later Caesar Augustus), as an attempt to promote his case against his fellow-consuls, Mark Antony and Marcus Lepidus in the period after the death of Julius Caesar. It is based on the skill of the famous Greek carver of engraved gems Dioskourides, who is recorded as active and at his peak circa 40–15 BC and three of whose attributed cameos bear a close resemblance in line and quality to the Portland vase figures. This theory proposes that the first two figures are Gaius Octavius, father of the future emperor, and Atia Balba Caesonia, his mother (hence Cupid with the arrow) who had a dream of being impregnated by Apollo in the form of a sea serpent (ketos), note the snake's prominent teeth. The onlooker with his staff, could be Aeneas, a hero of the Trojan Wars who saved his father by carrying over his back (hence his hunched position, and his Trojan beard) and who is believed to have founded Rome, and from whom the Julian gens, including Julius Caesar and Attia, claimed descent, witnessing the conception of Rome's future savior as an Empire, and the greatest of all the Emperors.

On the reverse is Octavian, Octavia his sister, widow of Mark Anthony (downcast flambeau, broken tablets) and Livia, Octavian's third wife who outlived him. These two are looking directly at each other. Octavian commanded she divorce her then husband and marry him with a few weeks of meeting, she was mother to the future Emperor Tiberius.

This vase suggests Octavian was descended partly from Apollo (thus partly divine, shades of Achilles), whom he worshiped as a god, gave private parties in his honor together with Minerva, Roman Goddess of War, from the founder of Rome, and his connection to his uncle Julius Caesar, for whom as a young man he gave a remarkable funeral oratory, and who adopted him on his father's death, when he was only four. All the pieces and people fit in this theory and it explains most mysteries (apart from who actually made it). It would have been a fabulously expensive piece to commission, so that few men of the period could have afforded it. Several attempts at creating the vase must have been made, as modern reproduction trials show today (see below). Historians and archeologists dismiss this modern theory as gods and goddesses with mythical allegories were usually portrayed, but could this remarkable vase have broken convention, and shown realism in portraiture, known solely on coins of the period, before it, in turn, was broken?

Cameo-glass vessels were probably all made within about two generations, as experiments when the blowing technique (discovered in about 50 BC) was still in its infancy. Recent research suggests that the Portland vase, like the majority of cameo-glass vessels, was made by the dip-overlay method, whereby an elongated bubble of glass was partially dipped into a crucible of white glass, before the two were blown together. After cooling the white layer was cut away to form the design.

The work in making a 19th-century copy proved to be incredibly painstaking, and based on this it is believed that the Portland Vase must have taken its original artisan no less than two years to produce. The cutting was probably performed by a skilled gem-cutter. It is believed that the cutter may have been Dioskourides, as engraved gems thought to be cut by him of a similar period and signed by him (Vollenweider 1966, see Gem in the collection of the Duke of Devonshire "Diomedes stealing the Palladium") are extant. This is confirmed by the Corning Museum in their 190-page study of the vase – see above.

According to a controversial theory by Rosemarie Lierke, the vase, along with the rest of Roman cameo glass, was moulded rather than cold-cut, probably using white glass powder for the white layer.

Jerome Eisenberg has argued in "Minerva" that the vase was produced in the 16th century AD and not antiquity, because the iconography is incoherent, but this theory has not been widely accepted.

One story suggests that it was discovered by Fabrizio Lazzaro in what was then thought to be the sarcophagus of the Emperor Alexander Severus (died 235) and his mother, at Monte del Grano near Rome, and excavated some time around 1582.

The first historical reference to the vase is in a letter of 1601 from the French scholar Nicolas Claude Fabri de Peiresc to the painter Peter Paul Rubens, where it is recorded as in the collection of Cardinal Francesco Maria Del Monte in Italy. In 1626 it passed into the Barberini family collection (which also included sculptures such as the Barberini Faun and Barberini Apollo) where it remained for some two hundred years, being one of the treasures of Maffeo Barberini, later Pope Urban VIII (1623–1644). It was at this point that the Severan connection is first recorded. The vase was known as the "Barberini Vase" in this period.

Between 1778 and 1780, Sir William Hamilton, British ambassador in Naples, bought the vase from James Byres, a Scottish art dealer, who had acquired it after it was sold by Cornelia Barberini-Colonna, Princess of Palestrina. She had inherited the vase from the Barberini family. Hamilton brought it to England on his next leave, after the death of his first wife, Catherine. In 1784, with the assistance of his niece, Mary, he arranged a private sale of the vase to Margaret Cavendish-Harley, widow of William Bentinck, 2nd Duke of Portland, and dowager Duchess of Portland. It was sold at auction in 1786 and passed into the possession of the duchess's son, William Cavendish-Bentinck, 3rd Duke of Portland.

The 3rd Duke lent the original vase to Josiah Wedgwood and then to the British Museum for safe-keeping, by which point it was known as the "Portland Vase". It was deposited there permanently by the fourth Duke in 1810, after a friend of his broke its base. It has remained in the British Museum ever since 1810, apart from 1929–32, when the 6th Duke put it up for sale at Christie's (where it failed to reach its reserve). It was finally purchased by the museum from the 7th Duke in 1945 with the aid of a bequest from James Rose Vallentin.

The 3rd Duke lent the vase to Josiah Wedgwood, who had already had it described to him by the sculptor John Flaxman as "the finest production of Art that has been brought to England and seems to be the very apex of perfection to which you are endeavoring". Wedgwood devoted four years of painstaking trials at duplicating the vase – not in glass but in black and white jasperware. He had problems with his copies ranging from cracking and blistering (clearly visible on the example at the Victoria and Albert Museum) to the sprigged reliefs 'lifting' during the firing, and in 1786 he feared that he could never apply the Jasper relief thinly enough to match the glass original's subtlety and delicacy. He finally managed to perfect it in 1790, with the issue of the "first-edition" of copies (with some of this edition, including the V&A one, copying the cameo's delicacy by a combination of undercutting and shading the reliefs in grey), and it marks his last major achievement.

Wedgwood put the first edition on private show between April and May 1790, with that exhibition proving so popular that visitor numbers had to be restricted by only printing 1,900 tickets, before going on show in his public London showrooms. (One ticket to the private exhibition, illustrated by Samuel Alkin and printed with 'Admission to see Mr Wedgwood's copy of The Portland Vase, Greek Street, Soho, between 12 o'clock and 5', was bound into the Wedgwood catalogue on view in the Victoria and Albert Museum's British Galleries.) As well as the V&A copy (said to have come from the collection of Wedgwood's grandson, the naturalist Charles Darwin), others are held at the Fitzwilliam Museum (this is the copy sent by Wedgwood to Erasmus Darwin which his descendants lent to the Museum in 1963 and later sold to them); the Indianapolis Museum of Art and the Department of Prehistory and Europe at the British Museum.

The vase also inspired a 19th-century competition to duplicate its cameo-work in glass, with Benjamin Richardson offering a £1,000 prize to anyone who could achieve that feat. Taking three years, glass maker Philip Pargeter made a copy and John Northwood engraved it, to win the prize. This copy is in the Corning Museum of Glass in Corning, New York.

The Wedgwood Museum, in Barlaston, near Stoke-on-Trent, contains a display describing the trials of replicating the vase, and several examples of the early experiments are shown.

At 3:45 p.m. on 7 February 1845, the vase was shattered by William Lloyd, who, after drinking all the previous week, threw a nearby sculpture on top of the case, smashing both it and the vase. He was arrested and charged with the crime of willful damage. When his lawyer pointed out an error in the wording of the act which seemed to limit its application to the destruction of objects worth no more than five pounds, he was convicted instead of the destruction of the glass case in which the vase had sat. He was ordered to pay a fine of three pounds (approximately 350 pounds equivalent in 2017) or spend two months in prison. He remained in prison until an anonymous benefactor paid the fine by mail. The name William Lloyd is thought to be a pseudonym. Investigators hired by the British Museum concluded that he was actually William Mulcahy, a student who had gone missing from Trinity College. Detectives reported that the Mulcahy family was impoverished. The owner of the vase declined to bring a civil action against William Mulcahy because he did not want his family to suffer for "an act of folly or madness which they could not control".

The vase was pieced together with fair success in 1845 by British Museum restorer John Doubleday, though he was unable to replace thirty-seven small fragments. It appears they had been put into a box and forgotten. On 5 October 1948, the keeper Bernard Ashmole received them in a box from Mr. G.A. Croker of Putney, who did not know what they were. After Doubleday's death, a fellow restorer from the British Museum took them to Mr. G.H. Gabb, a box maker, who was asked to make a box with thirty seven compartments, one for each fragment. However, the restorer also died and the box was never collected. After Gabb's death, his executrix, Miss Amy Reeves, brought in Croker to value Gabb's effects. This was how Crocker came to bring them to the museum to ask for help in identifying them.

By November 1948, the restoration appeared aged and it was decided to restore the vase again. It was dismantled by conservator J.W.R. Axtell in mid-November 1948. The pieces were examined by D.B. Harden and W.A. Thorpe, who confirmed that the circular glass base removed in 1845 was not original. Axtell then carried out a reconstruction, completed by 2 February 1949, in which he was only successful in replacing three of the 37 loose fragments. He reportedly used "new adhesives" for this restoration, which some thought might be epoxy resins or shellac, but were later discovered to simply be the same type of animal glue that Doubleday used in 1845. He also filled some areas with wax. No documentation of his work was produced.

By the late 1980s, the adhesive was again yellowing and brittle. Although the vase was shown at the British Museum as part of the "Glass of the Caesars" exhibition (November 1987 – March 1988), it was too fragile to travel to other locations afterwards. Instead, another reconstruction was performed between 1 June 1988 and 1 October 1989 by Nigel Williams and Sandra Smith. The pair was overseen by David Akehurst (CCO of Glass and Ceramics) who had assessed the vase's condition during the "Glass of the Caesars" exhibition and decided to go ahead with reconstruction and stabilization. The treatment had scholarly attention and press coverage. The vase was photographed and drawn to record the position of fragments before dismantling; the BBC filmed the conservation process. Conservation scientists at the museum tested many adhesives for long-term stability, choosing an epoxy resin with excellent ageing properties. Reassembly revealed some fragments had been filed down during the restorations, complicating the process. All but a few small splinters were integrated. Gaps were filled with blue or white resin.

Little sign of the original damage is visible, and, except for light cleaning, it is hoped that the vase should not require major conservation work for at least another century.





</doc>
<doc id="24705" url="https://en.wikipedia.org/wiki?curid=24705" title="Patrimony">
Patrimony

Patrimony may refer to:





</doc>
<doc id="24707" url="https://en.wikipedia.org/wiki?curid=24707" title="Pyrenees">
Pyrenees

The Pyrenees (; ; ; ; ; ; ) is a range of mountains in southwest Europe that forms a natural border between Spain and France. Reaching a height of altitude at the peak of Aneto, the range separates the Iberian Peninsula from the rest of continental Europe, and extends for about from the Bay of Biscay (Cap Higuer) to the Mediterranean Sea (Cap de Creus).

For the most part, the main crest forms a divide between Spain and France, with the microstate of Andorra sandwiched in between. The Basque Country straddles the western Pyrenees. Historically, the Principality of Catalonia, the Kingdom of Aragon, Occitania and the Kingdom of Navarre extended on both sides of the mountain range.

In Greek mythology, Pyrene is a princess who gave her name to the Pyrenees. The Greek historian Herodotus says Pyrene is the name of a town in Celtic Europe. According to Silius Italicus, she was the virgin daughter of Bebryx, a king in Mediterranean Gaul by whom the hero Hercules was given hospitality during his quest to steal the cattle of Geryon during his famous Labours. Hercules, characteristically drunk and lustful, violates the sacred code of hospitality and rapes his host's daughter. Pyrene gives birth to a serpent and runs away to the woods, afraid that her father will be angry. Alone, she pours out her story to the trees, attracting the attention of wild beasts who tear her to pieces.

After his victory over Geryon, Hercules passes through the kingdom of Bebryx again, finding the girl's lacerated remains. As is often the case in stories of this hero, the sober Hercules responds with heartbroken grief and remorse at the actions of his darker self, and lays Pyrene to rest tenderly, demanding that the surrounding geography join in mourning and preserve her name: "struck by Herculean voice, the mountaintops shudder at the ridges; he kept crying out with a sorrowful noise 'Pyrene!' and all the rock-cliffs and wild-beast haunts echo back 'Pyrene!' … The mountains hold on to the wept-over name through the ages." Pliny the Elder connects the story of Hercules and Pyrene to Lusitania, but rejects it as "fabulosa", highly fictional.

Other classical sources derived the name from the Greek word for fire, (IPA: ). According to Greek historian Diodorus Siculus "..in ancient times, we are told, certain herdsmen left a fire and the whole area of the mountains was entirely consumed; and due to this fire, since it raged continuously day after day, the surface of the earth was also burned and the mountains, because of what had taken place, were called the Pyrenees."

The Spanish Pyrenees are part of the following provinces, from east to west: Girona, Barcelona, Lleida (all in Catalonia), Huesca (in Aragon), Navarra (in Navarre) and Gipuzkoa (in the Basque Country).

The French Pyrenees are part of the following "départements", from east to west: Pyrénées-Orientales (North Catalonia and Fenolheda), Aude, Ariège, Haute-Garonne, Hautes-Pyrénées, and Pyrénées-Atlantiques (the latter two of which include the Pyrenees National Park).

The independent principality of Andorra is sandwiched in the eastern portion of the mountain range between the Spanish Pyrenees and French Pyrenees.

Physiographically, the Pyrenees may be divided into three sections: the Atlantic (or Western), the Central, and the Eastern Pyrenees. Together, they form a distinct physiographic province of the larger Alpine System division.

In the Western Pyrenees, from the Basque mountains near the Bay of Biscay of the Atlantic Ocean, the average elevation gradually increases from west to east.

The Central Pyrenees extend eastward from the Somport pass to the Aran Valley, and they include the highest summits of this range:

In the Eastern Pyrenees, with the exception of one break at the eastern extremity of the "Pyrénées Ariègeoises" in the Ariège area, the mean elevation is remarkably uniform until a sudden decline occurs in the easternmost portion of the chain known as the Albères.

Most foothills of the Pyrenees are on the Spanish side, where there is a large and complex system of ranges stretching from Spanish Navarre, across northern Aragon and into Catalonia, almost reaching the Mediterranean coast with summits reaching . At the eastern end on the southern side lies a distinct area known as the Sub-Pyrenees.

On the French side the slopes of the main range descend abruptly and there are no foothills except in the Corbières Massif in the northeastern corner of the mountain system.

The Pyrenees are older than the Alps: their sediments were first deposited in coastal basins during the Paleozoic and Mesozoic eras. Between 100 and 150 million years ago, during the Lower Cretaceous Period, the Bay of Biscay fanned out, pushing present-day Spain against France and applying intense compressional pressure to large layers of sedimentary rock. The intense pressure and uplifting of the Earth's crust first affected the eastern part and moved progressively to the entire chain, culminating in the Eocene Epoch.

The eastern part of the Pyrenees consists largely of granite and gneissose rocks, while in the western part the granite peaks are flanked by layers of limestone. The massive and unworn character of the chain comes from its abundance of granite, which is particularly resistant to erosion, as well as weak glacial development.

The upper parts of the Pyrenees contain low-relief surfaces forming a peneplain. This peneplain originated no earlier than in Late Miocene times. Presumably it formed at height as extensive sedimentation raised the local base level considerably.

Conspicuous features of Pyrenean scenery are:

The highest waterfall is Gavarnie (462 m or 1,515 ft), at the head of the Gave de Pau; the Cirque de Gavarnie, in the same valley, together with the nearby Cirque de Troumouse and Cirque d'Estaubé, are notable examples of the cirque formation. 

Low passes are lacking, and the principal roads and the railroads between France and Spain run only in the lowlands at the western and eastern ends of the Pyrenees, near sea level. The main passes of note are:
Because of the lack of low passes a number of tunnels have been created, beneath the passes at Somport, Envalira, and Puymorens and new routes in the center of the range at Bielsa and Vielha.

A notable visual feature of this mountain range is La Brèche de Roland, a gap in the ridge line, whichaccording to legendwas created by Roland.

The metallic ores of the Pyrenees are not in general of much importance now, though there were iron mines at several locations in Andorra, as well as at Vicdessos in Ariège, and the foot of Canigou in Pyrénées-Orientales long ago. Coal deposits capable of being profitably worked are situated chiefly on the Spanish slopes, but the French side has beds of lignite. The open pit of Trimoun near the commune of Luzenac (Ariège) is one of the greatest sources of talc in Europe.

Mineral springs are abundant and remarkable, and especially noteworthy are the hot springs. The hot springs, among which those of Les Escaldes in Andorra, Panticosa and Lles in Spain, Ax-les-Thermes, Bagnères-de-Luchon and Eaux-Chaudes in France may be mentioned, are sulfurous and mostly situated high, near the contact of the granite with the stratified rocks. The lower springs, such as those of Bagnères-de-Bigorre (Hautes-Pyrénées), Rennes-les-Bains (Aude), and Campagne-sur-Aude (Aude), are mostly selenitic and not hot.

The amount of precipitation the range receives, including rain and snow, is much greater in the western than in the eastern Pyrenees because of the moist air that blows in from the Atlantic Ocean over the Bay of Biscay. After dropping its moisture over the western and central Pyrenees, the air is left dry over the eastern Pyrenees. The winter average temperature is -2 °C (28.4 °F).

Sections of the mountain range vary in more than one respect. There are some glaciers in the western and snowy central Pyrenees, but there are no glaciers in the eastern Pyrenees because there is insufficient snowfall to cause their development. Glaciers are confined to the northern slopes of the central Pyrenees, and do not descend, like those of the Alps, far down into the valleys but rather have their greatest lengths along the direction of the mountain chain. They form, in fact, in a narrow zone near the crest of the highest mountains. Here, as in the other great mountain ranges of central Europe, there is substantial evidence of a much wider expanse of glaciation during the glacial periods. The best evidence of this is in the valley of Argeles Gazost, between Lourdes and Gavarnie, in the "" of Hautes-Pyrénées.

The annual snow-line varies in different parts of the Pyrenees from about 2,700 to 2,800 metres above sea level. In average the seasonal snow is observed at least 50% of the time above 1,600 metres between December and April.

A still more marked effect of the preponderance of rainfall in the western half of the chain is seen in the vegetation. The lower mountains in the extreme west are wooded, but the extent of forest declines as one moves eastwards. The eastern Pyrenees are peculiarly wild and barren, all the more since it is in this part of the chain that granitic masses prevail. Also moving from west to east, there is a change in the composition of the flora, with the change becoming most evident as one passes the centre of the mountain chain from which point the Corbières stretch north-eastwards towards the central plateau of France. Though the difference in latitude is only about 1°, in the west the flora resembles that of central Europe while in the east it is distinctly Mediterranean in character. The Pyrenees are nearly as rich in endemic species as the Alps, and among the most remarkable instances of that endemism is the occurrence of the monotypic genus "Xatardia" (family Apiaceae), which grows only on a high alpine pass between the Val d'Eynes and Catalonia. Other examples include "Arenaria montana", "Bulbocodium vernum", and "Ranunculus glacialis". The genus most abundantly represented in the range is that of the saxifrages, several species of which are endemic here.

In their fauna the Pyrenees present some striking instances of endemism. The Pyrenean desman is found only in some of the streams of the northern slopes of these mountains; the only other desmans are confined to the rivers of the Caucasus in southern Russia. The Pyrenean euprocte ("Euproctus pyrenaicus"), an endemic relative of the salamander, also lives in streams and lakes located at high altitudes. Among other peculiarities of Pyrenean fauna are blind insects in the caverns of Ariège, the principal genera of which are "Anophthalmus" and "Adelops".

The Pyrenean ibex mysteriously became extinct in January 2000; the native Pyrenean brown bear was hunted to near-extinction in the 1990s, but it was re-introduced in 1996 when three bears were brought from Slovenia. The bear population has bred successfully, and there are now believed to be about 15 brown bears in the central region around Fos, but only four native ones are still living in the Aspe Valley.

Principal nature reserves and national parks:

The Pyrenean region possesses a varied ethnology, folklore and history: see Andorra; Aragon; Ariège; Basque Country; Béarn; Catalonia; Navarre; Roussillon. For their history, see also Almogavars, Marca Hispanica.

The principal languages spoken in the area are Spanish, French, Aragonese, Catalan (in Catalonia and Andorra), and Basque.
Also spoken, to a lesser degree, is the Occitan language, consisting of the Gascon and Languedocien dialects in France and the Aranese dialect in the Aran Valley.

An important feature of rural life in the Pyrenees is 'transhumance', the moving of livestock from the farms in the valleys up to the higher grounds of the mountains for the summer. In this way the farming communities could keep larger herds than the lowland farms could support on their own. The principal animals moved were cows and sheep, but historically most members of farming families also moved to the higher pastures along with their animals, so they also took with them pigs, horses and chickens. Transhumance thus took the form of a mass biannual migration, moving uphill in May or June and returning to the farms in September or October. During the summer period, the families would live in basic stone cabins in the high mountains. 

Nowadays, industrialisation and changing agriculture practices have diminished the custom. However, the importance of transhumance continues to be recognised through its celebration in popular festivals.

No big cities are in the range itself. The largest urban area close to the Pyrenees is Toulouse (Haute-Garonne), France with a population of 1,330,954 in its metropolitan area. On the Spanish side Pamplona, (Navarre) is the closest city with a population of 319,208 in its metropolitan area. Inside the Pyrenees the main towns are Andorra la Vella (22,256), Jaca (12,813) in Spain and Lourdes (13,976) and Foix (10,046) in France.

The following is the complete list of the summits of the Pyrenees above 3,000 meters:

Both sides of the Pyrenees are popular spots for winter sports such as alpine skiing and mountaineering. The Pyrenees are also a good place for athletes to do high-altitude training in the summertime, such as by bicycling and cross-country running.

In the summer and the autumn, the Pyrenees are usually featured in two of cycling's grand tours, the Tour de France held annually in July and the Vuelta a España held in September. The stages held in the Pyrenees are often crucial legs of both tours, drawing hundreds of thousands of spectators to the region.

Three main long-distance footpaths run the length of the mountain range: the GR 10 across the northern slopes, the GR 11 across the southern slopes, and the HRP which traverses peaks and ridges along a high altitude route. In addition, there are numerous marked and unmarked trails throughout the region.

"Pirena" is a dog-mushing competition held in the Pyrenees.

Ski resorts in the Pyrenees include:




</doc>
<doc id="24709" url="https://en.wikipedia.org/wiki?curid=24709" title="Planetary nomenclature">
Planetary nomenclature

Planetary nomenclature, like terrestrial nomenclature, is a system of uniquely identifying features on the surface of a planet or natural satellite so that the features can be easily located, described, and discussed. Since the invention of the telescope, astronomers have given names to the surface features they have discerned, especially on the Moon and Mars. To standardize planetary nomenclature, the International Astronomical Union (IAU) was assigned in 1919 the task of selecting official names for features on Solar System bodies.

When images are first obtained of the surface of a planet or satellite, a theme for naming features is chosen and a few important features are named, usually by members of the appropriate IAU task group (a commonly accepted planet-naming group). Later, as higher resolution images and maps become available, additional features are named at the request of investigators mapping or describing specific surfaces, features, or geologic formations. Anyone may suggest that a specific name be considered by a task group. If the members of the task group agree that the name is appropriate, it can be retained for use when there is a request from a member of the scientific community that a specific feature be named. Names successfully reviewed by a task group are submitted to the IAU Working Group for Planetary System Nomenclature (WGPSN). Upon successful review by the members of the WGPSN, names are considered provisionally approved and can be used on maps and in publications as long as the provisional status is clearly stated. Provisional names are then presented for adoption to the IAU's General Assembly, which met triennially in the past, and which now adopts nomenclature for planetary surface features as required. A name is not considered to be official — that is, "adopted" — until the General Assembly has given its approval.

Names adopted by the IAU must follow various rules and conventions established and amended through the years by the Union. These include:


In addition to these general rules, each task group develops additional conventions as it formulates an interesting and meaningful nomenclature for individual planetary bodies.

Names for all planetary features include a descriptor term, with the exception of two feature types. For craters, the descriptor term is implicit. Some features named on Io and Triton do not carry a descriptor term because they are ephemeral.

In general, the naming convention for a feature type remains the same regardless of its size. Exceptions to this rule are valleys and craters on Mars and Venus; naming conventions for these features differ according to size.

One feature classification, "regio", was originally used on early maps of the Moon and Mercury (drawn from telescopic observations) to describe vague albedo features. It is now used to delineate a broad geographic region.

Named features on bodies so small that coordinates have not yet been determined are identified on drawings of the body that are included in the IAU Transactions volume of the year when the names were adopted. Satellite rings and gaps in the rings are named for scientists who have studied these features; drawings that show these names are also included in the pertinent Transactions volume. Names for atmospheric features are informal at present; a formal system will be chosen in the future.

The boundaries of many large features (such as "terrae, regiones, planitiae" and "plana") are not topographically or geomorphically distinct; the coordinates of these features are identified from an arbitrarily chosen center point. Boundaries (and thus coordinates) may be determined more accurately from geochemical and geophysical data obtained by future missions.

During active missions, small surface features are often given informal names. These may include landing sites, spacecraft impact sites, and small topographic features, such as craters, hills, and rocks. Such names will not be given official status by the IAU, except as provided for by Rule 2 above. As for the larger objects, official names for any such small features would have to conform to established IAU rules and categories.

All but three features on Venus are named after females. These three exceptions were named before the convention was adopted, being respectively Alpha Regio, Beta Regio, and Maxwell Montes which is named after James Clerk Maxwell.

When space probes have landed on Mars, individual small features such as rocks, dunes, and hollows have often been given informal names. Many of these are frivolous: features have been named after ice cream (such as Cookies N Cream); cartoon characters (such as SpongeBob SquarePants and Patrick); and '70s music acts (such as ABBA and the Bee Gees).

Features on Deimos are named after authors who wrote about Martian satellites. There are currently two named features on Deimos - Swift crater and Voltaire crater - after Jonathan Swift and Voltaire who predicted the presence of Martian moons.

All features on Phobos are named after scientists involved with the discovery, dynamics, or properties of the Martian satellites or people and places from Jonathan Swift's "Gulliver's Travels".

People and places associated with the Amalthea myth

Features on Thebe are named after people and places associated with the Thebe myth. There is only one named feature on Thebe - Zethus Crater.

People from myth of Castor and Pollux (twins)

People from myth of Castor and Pollux (twins)

People and places from Malory's "Le Morte d'Arthur" legends (Baines translation)

People and places from Burton's "Arabian Nights"

People and places from Homer's "Odyssey"

People and places from Virgil's "Aeneid"

People and places from creation myths

Sun and Moon deities

People and places from Sayers' translation of "Chanson de Roland", the only exception is Cassini Regio, which is named after its discoverer, Giovanni Cassini.

Satellites of Uranus are named for characters from the works of William Shakespeare.

Mischievous (Pucklike) spirits (class)

Characters, places from Shakespeare's plays

Light spirits (individual and class)

Dark spirits (individual)

Female Shakespearean characters, places

Shakespearean tragic heroes and places

There are currently no named features on Uranian small satellites, however the naming convention is heroines from plays by Shakespeare and Pope.

Features on Proteus are to be named after water-related spirits, gods or goddesses who are neither Greek nor Roman. The only named feature on Proteus is crater Pharos.

Geological features on Triton should be assigned aquatic names, excluding those which are Roman and Greek in origin. Possible themes for individual descriptor terms include worldwide aquatic spirits, famous terrestrial fountains or fountain locations, terrestrial aquatic features, famous terrestrial geysers or geyser locations and terrestrial islands.

There are currently no named features on Nereid. When features are discovered, they are to be named after individual nereids.

Features on other satellites of Neptune, once discovered, should be named after gods and goddesses associated with Neptune/Poseidon mythology or generic mythological aquatic beings.

In February 2017, the IAU approved the following themes for surface features on Pluto and its satellites:










</doc>
<doc id="24710" url="https://en.wikipedia.org/wiki?curid=24710" title="North American P-51 Mustang">
North American P-51 Mustang

The North American Aviation P-51 Mustang is an American long-range, single-seat fighter and fighter-bomber used during World War II and the Korean War, among other conflicts. The Mustang was designed in April 1940 by a design team headed by James Kindelberger of North American Aviation (NAA) in response to a requirement of the British Purchasing Commission. The Purchasing Commission approached North American Aviation to build Curtiss P-40 fighters under license for the Royal Air Force (RAF). Rather than build an old design from another company, North American Aviation proposed the design and production of a more modern fighter. The prototype NA-73X airframe was rolled out on 9 September 1940, 102 days after the contract was signed, and first flew on 26 October.

The Mustang was designed to use the Allison V-1710 engine, which had limited high-altitude performance in its earlier variants. The aircraft was first flown operationally by the Royal Air Force (RAF) as a tactical-reconnaissance aircraft and fighter-bomber (Mustang Mk I). Replacing the Allison with a Rolls-Royce Merlin resulted in the P-51B/C (Mustang Mk III) model and transformed the aircraft's performance at altitudes above (without sacrificing range), allowing it to compete with the Luftwaffe's fighters. The definitive version, the P-51D, was powered by the Packard V-1650-7, a license-built version of the two-speed two-stage-supercharged Merlin 66, and was armed with six .50 caliber (12.7 mm) AN/M2 Browning machine guns.

From late 1943, P-51Bs and P-51Cs (supplemented by P-51Ds from mid-1944) were used by the USAAF's Eighth Air Force to escort bombers in raids over Germany, while the RAF's Second Tactical Air Force and the USAAF's Ninth Air Force used the Merlin-powered Mustangs as fighter-bombers, roles in which the Mustang helped ensure Allied air superiority in 1944. The P-51 was also used by Allied air forces in the North African, Mediterranean, Italian and Pacific theaters. During World War II, Mustang pilots claimed to have destroyed 4,950 enemy aircraft.

At the start of the Korean War, the Mustang, by then redesignated F-51, was the main fighter of the United Nations until jet fighters, including North American's F-86, took over this role; the Mustang then became a specialized fighter-bomber. Despite the advent of jet fighters, the Mustang remained in service with some air forces until the early 1980s. After the Korean War, Mustangs became popular civilian warbirds and air racing aircraft.

In April 1940, the British government established a purchasing commission in the United States, headed by Sir Henry Self. Self was given overall responsibility for Royal Air Force (RAF) production, research and development, and also served with Sir Wilfrid Freeman, the Air Member for Development and Production. Self also sat on the British Air Council Sub-committee on Supply (or "Supply Committee") and one of his tasks was to organize the manufacturing and supply of American fighter aircraft for the RAF. At the time, the choice was very limited, as no U.S. aircraft then in production or flying met European standards, with only the Curtiss P-40 Tomahawk coming close. The Curtiss-Wright plant was running at capacity, so P-40s were in short supply.

North American Aviation (NAA) was already supplying its Harvard trainer to the RAF, but was otherwise underused. NAA President "Dutch" Kindelberger approached Self to sell a new medium bomber, the B-25 Mitchell. Instead, Self asked if NAA could manufacture P-40s under license from Curtiss. Kindelberger said NAA could have a better aircraft with the same Allison V-1710 engine in the air sooner than establishing a production line for the P-40. The Commission stipulated armament of four .303 in (7.7 mm) machine guns (as used on the Tomahawk), a unit cost of no more than $40,000 and delivery of the first production aircraft by January 1941. In March 1940, 320 aircraft were ordered by Freeman, who had become the executive head of the Ministry of Aircraft Production (MAP) and the contract was promulgated on 24 April.

The NA-73X, which was designed by a team led by lead engineer Edgar Schmued, followed the best conventional practice of the era, but included several new features. One was a wing designed using laminar flow airfoils, which were developed co-operatively by North American Aviation and the National Advisory Committee for Aeronautics (NACA). These airfoils generated low drag at high speeds. During the development of the NA-73X, a wind tunnel test of two wings, one using NACA five-digit airfoils and the other using the new NAA/NACA 45–100 airfoils, was performed in the University of Washington Kirsten Wind Tunnel. The results of this test showed the superiority of the wing designed with the NAA/NACA 45–100 airfoils.
The other feature was a new cooling arrangement (aft positioned, single ducted water and oil radiators assembly) that reduced the cooling drag. Later, after much development, they discovered that the cooling assembly could take advantage of the Meredith effect: in which heated air exited the radiator with a slight amount of jet thrust. Because NAA lacked a suitable wind tunnel to test this feature, it used the GALCIT wind tunnel at the California Institute of Technology. This led to some controversy over whether the Mustang's cooling system aerodynamics were developed by NAA's engineer Edgar Schmued or by Curtiss, although NAA had purchased the complete set of P-40 and XP-46 wind tunnel data and flight test reports for US$56,000. The NA-73X was also one of the first aircraft to have a fuselage lofted mathematically using conic sections; this resulted in smooth, low drag surfaces. To aid production, the airframe was divided into five main sections—forward, center, rear fuselage, and two wing halves—all of which were fitted with wiring and piping before being joined.

The prototype NA-73X was rolled out in September 1940, just 102 days after the order had been placed; it first flew on 26 October 1940, 149 days into the contract, an uncommonly short development period, even during the war. With test pilot Vance Breese at the controls, the prototype handled well and accommodated an impressive fuel load. The aircraft's three-section, semi-monocoque fuselage was constructed entirely of aluminum to save weight. It was armed with four .30 caliber (7.62 mm) AN/M2 Browning machine guns in the wings and two .50 caliber (12.7 mm) AN/M2 Browning machine guns mounted under the engine and firing through the propeller arc using gun-synchronizing gear.

While the United States Army Air Corps could block any sales it considered detrimental to the interests of the US, the NA-73 was considered to be a special case because it had been designed at the behest of the British. In September 1940, a further 300 NA-73s were ordered by the MAP. To ensure uninterrupted delivery, Colonel Oliver P. Echols arranged with the Anglo-French Purchasing Commission to deliver the aircraft and NAA gave two examples (41-038 and 41-039) to the USAAC for evaluation.
The Mustang was initially developed for the RAF, which was its first user. As the first Mustangs were built to British requirements, these aircraft used factory numbers and were not P-51s; the order comprised 320 NA-73s, followed by 300 NA-83s, all of which were designated North American Mustang Mark I by the RAF. The first RAF Mustangs supplied under Lend-Lease were 93 P-51s, designated Mk Ia, followed by 50 P-51As used as Mustang Mk IIs. Aircraft supplied to Britain under Lend-Lease were required for accounting purposes to be on the USAAC's books before they could be supplied to Britain. However, the British Aircraft Purchasing Commission signed its first contract for the North American NA-73 on 24 April 1940, before Lend-Lease was in effect. Thus, the initial order for the P-51 Mustang (as it was later known) was placed by the British under the "Cash and Carry" program, as required by the US Neutrality Acts of the 1930s.

After the arrival of the initial aircraft in the UK in October 1941, the first Mustang Mk Is entered service in January 1942, the first unit being 26 Squadron RAF. Due to poor high-altitude performance, the Mustangs were used by Army Co-operation Command, rather than Fighter Command, and were used for tactical reconnaissance and ground-attack duties. On 10 May 1942, Mustangs first flew over France, near Berck-sur-Mer. On 27 July 1942, 16 RAF Mustangs undertook their first long-range reconnaissance mission over Germany. During the amphibious Dieppe Raid on the French coast (19 August 1942), four British and Canadian Mustang squadrons, including 26 Squadron, saw action covering the assault on the ground. By 1943–1944, British Mustangs were used extensively to seek out V-1 flying bomb sites. The last RAF Mustang Mk I and Mustang Mk II aircraft were struck off charge in 1945.
The RAF also operated 308 P-51Bs and 636 P-51Cs, which were known in RAF service as Mustang Mk IIIs; the first units converted to the type in late 1943 and early 1944. Mustang Mk III units were operational until the end of World War II, though many units had already converted to the Mustang Mk IV (P-51D) and Mk IVa (P-51K) (828 in total, comprising 282 Mk IV and 600 Mk IVa). As all except the earliest aircraft were obtained under Lend-Lease, all Mustang aircraft still on RAF charge at the end of the war were either returned to the USAAF "on paper" or retained by the RAF for scrapping. The last RAF Mustangs were retired from service in 1947.

Prewar doctrine was based on the idea "the bomber will always get through". Despite RAF and Luftwaffe experience with daylight bombing, the USAAF still incorrectly believed in 1942 that tightly packed formations of bombers would have so much firepower that they could fend off fighters on their own. Fighter escort was a low priority but when the concept was discussed in 1941, the Lockheed P-38 Lightning was considered to be most appropriate as it had the speed and range. Another school of thought favored a heavily up-armed "gunship" conversion of a strategic bomber. A single-engined, high-speed fighter with the range of a bomber was thought to be an engineering impossibility.

The 8th Air Force started operations from Britain in August 1942. At first, because of the limited scale of operations, no conclusive evidence showed American doctrine was failing. In the 26 operations flown to the end of 1942, the loss rate had been under 2%.

In January 1943, at the Casablanca Conference, the Allies formulated the Combined Bomber Offensive (CBO) plan for "round-the-clock" bombing – USAAF daytime operations complementing the RAF nighttime raids on industrial centers. In June 1943, the Combined Chiefs of Staff issued the Pointblank Directive to destroy the Luftwaffe's capacity before the planned invasion of Europe, putting the CBO into full implementation. German daytime fighter efforts were, at that time, focused on the Eastern Front and several other distant locations. Initial efforts by the 8th met limited and unorganized resistance, but with every mission, the Luftwaffe moved more aircraft to the west and quickly improved their battle direction. In fall 1943, the 8th Air Force's heavy bombers conducted a series of deep-penetration raids into Germany, beyond the range of escort fighters. The Schweinfurt–Regensburg mission in August lost 60 B-17s of a force of 376, the 14 October attack lost 77 of a force of 291—26% of the attacking force. 

For the US, the very concept of self-defending bombers was called into question, but instead of abandoning daylight raids and turning to night bombing, as the RAF suggested, they chose other paths; at first, a bomber with more guns (the Boeing YB-40) was believed to be able to escort the bomber formations, but when the concept proved to be unsuccessful, thoughts then turned to the Lockheed P-38 Lightning. In early 1943, the USAAF also decided that the Republic P-47 Thunderbolt and P-51B be considered for the role of a smaller escort fighter, and in July, a report stated that the P-51B was "the most promising plane" with an endurance of 4 hours 45 minutes with the standard internal fuel of 184 gallons plus 150 gallons carried externally. In August, a P-51B was fitted with an extra internal 85-gallon tank, and although problems with longitudinal stability occurred and some compromises in performance with the tank full were made, and because the fuel from the fuselage tank would be used during the initial stages of a mission, the fuel tank would be fitted in all Mustangs destined for VIII Fighter Command.

The P-51 Mustang was a solution to the need for an effective bomber escort. It used a common, reliable engine and had internal space for a larger-than-average fuel load. With external fuel tanks, it could accompany the bombers from England to Germany and back.

However, the Allison engine in the P-51A had a single-stage supercharger that caused power to drop off rapidly above 15,000 ft. This made it unsuitable for combat at the altitudes where USAAF bombers planned to fly. Following the RAF's initial disappointing experience with the Mustang I (P-51A), Ronald Harker, a test pilot for Rolls-Royce, suggested fitting a Merlin 61, as fitted to the Spitfire Mk IX. The Merlin 61 had a two-speed, two-stage, intercooled supercharger, designed by Stanley Hooker of Rolls-Royce, and this gave an increase in horsepower from the Allison's , or in War Emergency Power, delivering an increase of top speed from , as well as raising the service ceiling to almost . Initial flights of what was known to Rolls-Royce as the Mustang Mk X were completed at Rolls-Royce's airfield at Hucknall in October 1942.
At the same time, the possibility of combining the P-51 airframe with the US license-built Packard version of the Merlin engine was being explored on the other side of the Atlantic. In July 1942 a contract was let for two prototypes, briefly designated XP-78 but soon to become the XP-51B. The first flight of the XP-51B took place in November 1942, but the USAAF was so interested in the possibility that an initial contract for 400 aircraft was placed three months beforehand in August. The conversion led to production of the P-51B beginning at North American's Inglewood, California, plant in June 1943, and P-51s started to become available to the 8th and 9th Air Forces in the winter of 1943–1944. During the conversion to the two-stage, supercharged Merlin engine, which was slightly heavier than the single-stage Allison, so moved the aircraft's center-of-gravity forward, North American's engineers took the opportunity to add a large additional fuselage fuel tank behind the pilot, greatly increasing the aircraft's range over that of the earlier P-51A.

By the time the "Pointblank" offensive resumed in early 1944, matters had changed. Bomber escort defenses were initially layered, using the shorter-range P-38s and P-47s to escort the bombers during the initial stages of the raid before handing over to the P-51s when they were forced to turn for home. This provided continuous coverage during the raid. The Mustang was so clearly superior to earlier US designs that the 8th Air Force began to steadily switch its fighter groups to the Mustang, first swapping arriving P-47 groups to the 9th Air Force in exchange for those that were using P-51s, then gradually converting its Thunderbolt and Lightning groups. By the end of 1944, 14 of its 15 groups flew the Mustang.

The Luftwaffe's twin-engined Messerschmitt Bf 110 heavy fighters brought up to deal with the bombers proved to be easy prey for the Mustangs, and had to be quickly withdrawn from combat. The Focke-Wulf Fw 190A, already suffering from poor high-altitude performance, was outperformed by the Mustang at the B-17's altitude, and when laden with heavy bomber-hunting weapons as a replacement for the more vulnerable twin-engined "Zerstörer" heavy fighters, it suffered heavy losses. The Messerschmitt Bf 109 had comparable performance at high altitudes, but its lightweight airframe was even more greatly affected by increases in armament. The Mustang's much lighter armament, tuned for antifighter combat, allowed it to overcome these single-engined opponents.

At the start of 1944, Major General James Doolittle, the new commander of the 8th Air Force, ordered many fighter pilots to stop flying in formation with the bombers and instead attack the "Luftwaffe" wherever it could be found. The aim was to achieve air supremacy. Mustang groups were sent far ahead of the bombers in a "fighter sweep" in order to intercept attacking German fighters.

The Luftwaffe answered with the "Gefechtsverband" ("battle formation"). This consisted of a "Sturmgruppe" of heavily armed and armored Fw 190As escorted by two "Begleitgruppen" of Messerschmitt Bf 109s, whose task was to keep the Mustangs away from the Fw 190As attacking the bombers. This strategy proved to be problematic, as the large German formation took a long time to assemble and was difficult to maneuver. It was often intercepted by the P-51 "fighter sweeps" before it could attack the bombers. However, German attacks against bombers could be effective when they did occur; the bomber-destroyer Fw 190As swept in from astern and often pressed their attacks to within .
While not always able to avoid contact with the escorts, the threat of mass attacks and later the "company front" (eight abreast) assaults by armored "Sturmgruppe" Fw 190As brought an urgency to attacking the Luftwaffe wherever it could be found, either in the air or on the ground. Beginning in late February 1944, 8th Air Force fighter units began systematic strafing attacks on German airfields with increasing frequency and intensity throughout the spring, with the objective of gaining air supremacy over the Normandy battlefield. In general these were conducted by units returning from escort missions but, beginning in March, many groups also were assigned airfield attacks instead of bomber support. The P-51, particularly with the advent of the K-14 Gyro gunsight and the development of "Clobber Colleges" for the training of fighter pilots in fall 1944, was a decisive element in Allied countermeasures against the "Jagdverbände".

The numerical superiority of the USAAF fighters, superb flying characteristics of the P-51, and pilot proficiency helped cripple the Luftwaffe's fighter force. As a result, the fighter threat to US, and later British, bombers was greatly diminished by July 1944. The RAF, long proponents of night bombing for protection, were able to reopen daylight bombing in 1944 as a result of the crippling of the Luftwaffe fighter arm. Reichsmarschall Hermann Göring, commander of the German Luftwaffe during the war, was quoted as saying, "When I saw Mustangs over Berlin, I knew the jig was up."

On 15 April 1944, VIII Fighter Command began "Operation Jackpot", attacks on Luftwaffe fighter airfields. As the efficacy of these missions increased, the number of fighters at the German airbases fell to the point where they were no longer considered worthwhile targets. On 21 May, targets were expanded to include railways, locomotives, and rolling stock used by the Germans to transport materiel and troops, in missions dubbed "Chattanooga". The P-51 excelled at this mission, although losses were much higher on strafing missions than in air-to-air combat, partially because the Mustang's liquid-cooled engine (particularly its coolant system) was vulnerable to small-arms fire, unlike the air-cooled R-2800 radials of its Republic P-47 Thunderbolt stablemates based in England, regularly tasked with ground-strafing missions.
Given the overwhelming Allied air superiority, the Luftwaffe put its effort into the development of aircraft of such high performance that they could operate with impunity, but which also made bomber attack much more difficult, merely from the flight velocities they achieved. Foremost among these were the Messerschmitt Me 163B point-defense rocket interceptors, which started their operations with JG 400 near the end of July 1944, and the longer-endurance Messerschmitt Me 262A jet fighter, first flying with the "Gruppe"-strength Kommando Nowotny unit by the end of September 1944. In action, the Me 163 proved to be more dangerous to the Luftwaffe than to the Allies, and was never a serious threat. The Me 262A was a serious threat, but attacks on their airfields neutralized them. The pioneering Junkers Jumo 004 axial-flow jet engines of the Me 262As needed careful nursing by their pilots, and these aircraft were particularly vulnerable during takeoff and landing. Lt. Chuck Yeager of the 357th Fighter Group was one of the first American pilots to shoot down an Me 262, which he caught during its landing approach. On 7 October 1944, Lt. Urban L. Drew of the 361st Fighter Group shot down two Me 262s that were taking off, while on the same day Lt. Col. Hubert Zemke, who had transferred to the Mustang-equipped 479th Fighter Group, shot down what he thought was a Bf 109, only to have his gun camera film reveal that it may have been an Me 262. On 25 February 1945, Mustangs of the 55th Fighter Group surprised an entire "Staffel" of Me 262As at takeoff and destroyed six jets.

The Mustang also proved useful against the V-1s launched toward London. P-51B/Cs using 150-octane fuel were fast enough to catch the V-1 and operated in concert with shorter-range aircraft such as advanced marks of the Supermarine Spitfire and Hawker Tempest.

By 8 May 1945, the 8th, 9th, and 15th Air Force's P-51 groups claimed some 4,950 aircraft shot down (about half of all USAAF claims in the European theater, the most claimed by any Allied fighter in air-to-air combat) and 4,131 destroyed on the ground. Losses were about 2,520 aircraft. The 8th Air Force's 4th Fighter Group was the top-scoring fighter group in Europe, with 1,016 enemy aircraft claimed destroyed. This included 550 claimed in aerial combat and 466 on the ground.

In air combat, the top-scoring P-51 units (both of which exclusively flew Mustangs) were the 357th Fighter Group of the 8th Air Force with 565 air-to-air combat victories and the 9th Air Force's 354th Fighter Group with 664, which made it one of the top-scoring fighter groups. The top Mustang ace was the USAAF's George Preddy, whose final tally stood at 26.83 victories (a number that includes shared one half- and one third victory credits), 23 of which were scored with the P-51. Preddy was shot down and killed by friendly fire on Christmas Day 1944 during the Battle of the Bulge.

In early 1945, P-51C, D, and K variants also joined the Chinese Nationalist Air Force. These Mustangs were provided to the 3rd, 4th, and 5th Fighter Groups and used to attack Japanese targets in occupied areas of China. The P-51 became the most capable fighter in China, while the Imperial Japanese Army Air Force used the Nakajima Ki-84 "Hayate" against it.

The P-51 was a relative latecomer to the Pacific Theater, due largely to the need for the aircraft in Europe, although the P-38's twin-engined design was considered a safety advantage for long, over-water flights. The first P-51s were deployed in the Far East later in 1944, operating in close-support and escort missions, as well as tactical photo reconnaissance. As the war in Europe wound down, the P-51 became more common; eventually, with the capture of Iwo Jima, it was able to be used as a bomber escort during Boeing B-29 Superfortress missions against the Japanese homeland.

The P-51 was often mistaken for the Japanese Kawasaki Ki-61 "Hien" in both China and Pacific because of its similar appearance.

Chief Naval Test Pilot and C.O. Captured Enemy Aircraft Flight Capt. Eric Brown, CBE, DSC, AFC, RN, tested the Mustang at RAE Farnborough in March 1944 and noted, "The Mustang was a good fighter and the best escort due to its incredible range, make no mistake about it. It was also the best American dogfighter. But the laminar-flow wing fitted to the Mustang could be a little tricky. It could not by any means out-turn a Spitfire. No way. It had a good rate-of-roll, better than the Spitfire, so I would say the plusses to the Spitfire and the Mustang just about equate. If I were in a dogfight, I'd prefer to be flying the Spitfire. The problem was I wouldn't like to be in a dogfight near Berlin, because I could never get home to Britain in a Spitfire!"

The U.S. Air Forces, Flight Test Engineering, assessed the Mustang B on 24 April 1944 thus: "The rate of climb is good and the high speed in level flight is exceptionally good at all altitudes, from sea level to 40,000 feet. The airplane is very maneuverable with good controllability at indicated speeds up to 400 MPH [sic]. The stability about all axes is good and the rate of roll is excellent; however, the radius of turn is fairly large for a fighter. The cockpit layout is excellent, but visibility is poor on the ground and only fair in level flight."

Kurt Bühligen, the third-highest scoring German fighter pilot of World War II's Western Front (with 112 confirmed victories, three against Mustangs), later stated, "We would out-turn the P-51 and the other American fighters, with the Bf 109 or the Fw 190. Their turn rate was about the same. The P-51 was faster than us, but our munitions and cannon were better." Heinz Bär said that the P-51 "was perhaps the most difficult of all Allied aircraft to meet in combat. It was fast, maneuverable, hard to see, and difficult to identify because it resembled the Me 109".

In the aftermath of World War II, the USAAF consolidated much of its wartime combat force and selected the P-51 as a "standard" piston-engined fighter, while other types, such as the P-38 and P-47, were withdrawn or given substantially reduced roles. As the more advanced (P-80 and P-84) jet fighters were introduced, the P-51 was also relegated to secondary duties.

In 1947, the newly formed USAF Strategic Air Command employed Mustangs alongside F-6 Mustangs and F-82 Twin Mustangs, due to their range capabilities. In 1948, the designation P-51 (P for pursuit) was changed to F-51 (F for fighter) and the existing F designator for photographic reconnaissance aircraft was dropped because of a new designation scheme throughout the USAF. Aircraft still in service in the USAF or Air National Guard (ANG) when the system was changed included: F-51B, F-51D, F-51K, RF-51D (formerly F-6D), RF-51K (formerly F-6K) and TRF-51D (two-seat trainer conversions of F-6Ds). They remained in service from 1946 through 1951. By 1950, although Mustangs continued in service with the USAF after the war, the majority of the USAF's Mustangs had become surplus to requirements and placed in storage, while some were transferred to the Air Force Reserve and the ANG.
From the start of the Korean War, the Mustang once again proved useful. A "substantial number" of stored or in-service F-51Ds were shipped, via aircraft carriers, to the combat zone, and were used by the USAF, the South African Air Force, and the Republic of Korea Air Force (ROKAF). The F-51 was used for ground attack, fitted with rockets and bombs, and photo reconnaissance, rather than being as interceptors or "pure" fighters. After the first North Korean invasion, USAF units were forced to fly from bases in Japan and the F-51Ds, with their long range and endurance, could attack targets in Korea that short-ranged F-80 jets could not. Because of the vulnerable liquid cooling system, however, the F-51s sustained heavy losses to ground fire. Due to its lighter structure and a shortage of spare parts, the newer, faster F-51H was not used in Korea.

Mustangs continued flying with USAF and ROKAF fighter-bomber units on close support and interdiction missions in Korea until 1953, when they were largely replaced as fighter-bombers by USAF F-84s and by United States Navy (USN) Grumman F9F Panthers. Other air forces and units using the Mustang included the Royal Australian Air Force's 77 Squadron, which flew Australian-built Mustangs as part of British Commonwealth Forces Korea. The Mustangs were replaced by Gloster Meteor F8s in 1951. The South African Air Force's 2 Squadron used U.S.-built Mustangs as part of the U.S. 18th Fighter Bomber Wing and had suffered heavy losses by 1953, after which 2 Squadron converted to the F-86 Sabre.

F-51s flew in the Air Force Reserve and ANG throughout the 1950s. The last American USAF Mustang was F-51D-30-NA AF serial no. 44-74936, which was finally withdrawn from service with the West Virginia Air National Guard's 167th Fighter Interceptor Squadron in January 1957 and retired to what was then called the Air Force Central Museum, although it was briefly reactivated to fly at the 50th anniversary of the Air Force Aerial Firepower Demonstration at the Air Proving Ground, Eglin AFB, Florida, on 6 May 1957. This aircraft, painted as P-51D-15-NA serial no. 44-15174, is on display at the National Museum of the United States Air Force, Wright-Patterson AFB, in Dayton, Ohio.

The final withdrawal of the Mustang from USAF dumped hundreds of P-51s onto the civilian market. The rights to the Mustang design were purchased from North American by the Cavalier Aircraft Corporation, which attempted to market the surplus Mustang aircraft in the U.S. and overseas. In 1967 and again in 1972, the USAF procured batches of remanufactured Mustangs from Cavalier, most of them destined for air forces in South America and Asia that were participating in the Military Assistance Program (MAP). These aircraft were remanufactured from existing original F-51D airframes fitted with new V-1650-7 engines, a new radio, tall F-51H-type vertical tails, and a stronger wing that could carry six machine guns and a total of eight underwing hardpoints. Two bombs and six rockets could be carried. They all had an original F-51D-type canopy, but carried a second seat for an observer behind the pilot. One additional Mustang was a two-seat, dual-control TF-51D (67-14866) with an enlarged canopy and only four wing guns. Although these remanufactured Mustangs were intended for sale to South American and Asian nations through the MAP, they were delivered to the USAF with full USAF markings. They were, however, allocated new serial numbers (67-14862/14866, 67-22579/22582 and 72-1526/1541).

The last U.S. military use of the F-51 was in 1968, when the U. S. Army employed a vintage F-51D (44-72990) as a chase aircraft for the Lockheed YAH-56 Cheyenne armed helicopter project. This aircraft was so successful that the Army ordered two F-51Ds from Cavalier in 1968 for use at Fort Rucker as chase planes. They were assigned the serials 68-15795 and 68-15796. These F-51s had wingtip fuel tanks and were unarmed. Following the end of the Cheyenne program, these two chase aircraft were used for other projects. One of them (68-15795) was fitted with a 106 mm recoilless rifle for evaluation of the weapon's value in attacking fortified ground targets. Cavalier Mustang 68-15796 survives at the Air Force Armament Museum, Eglin AFB, Florida, displayed indoors in World War II markings.

The F-51 was adopted by many foreign air forces and continued to be an effective fighter into the mid-1980s with smaller air arms. The last Mustang ever downed in battle occurred during Operation Power Pack in the Dominican Republic in 1965, with the last aircraft finally being retired by the Dominican Air Force in 1984.

After World War II, the P-51 Mustang served in the air arms of more than 25 nations. During the war, a Mustang cost about $51,000, while many hundreds were sold postwar for the nominal price of one dollar to signatories of the Inter-American Treaty of Reciprocal Assistance, ratified in Rio de Janeiro in 1947.

These countries used the P-51 Mustang:




Many P-51s were sold as surplus after the war, often for as little as $1,500. Some were sold to former wartime fliers or other aficionados for personal use, while others were modified for air racing.
One of the most significant Mustangs involved in air racing was a surplus P-51C-10-NT (44-10947) purchased by film stunt pilot Paul Mantz. The aircraft was modified by creating a "wet wing", sealing the wing to create a giant fuel tank in each wing, which eliminated the need for fuel stops or drag-inducing drop tanks. This Mustang, named "Blaze of Noon" after the film "Blaze of Noon", came in first in the 1946 and 1947 Bendix Air Races, second in the 1948 Bendix, and third in the 1949 Bendix. He also set a U.S. coast-to-coast record in 1947. The Mantz Mustang was sold to Charles F. Blair Jr (future husband of Maureen O'Hara) and renamed "Excalibur III". Blair used it to set a New York-to-London ("circa" ) record in 1951: 7 hr 48 min from takeoff at Idlewild to overhead London Airport. Later that same year, he flew from Norway to Fairbanks, Alaska, via the North Pole ("circa" ), proving that navigation via sun sights was possible over the magnetic north pole region. For this feat, he was awarded the Harmon Trophy and the Air Force was forced to change its thoughts on a possible Soviet air strike from the north. This Mustang now resides in the National Air and Space Museum at the Steven F. Udvar-Hazy Center.
The most prominent firm to convert Mustangs to civilian use was Trans-Florida Aviation, later renamed Cavalier Aircraft Corporation, which produced the Cavalier Mustang. Modifications included a taller tailfin and wingtip tanks. A number of conversions included a Cavalier Mustang specialty: a "tight" second seat added in the space formerly occupied by the military radio and fuselage fuel tank.

In 1958, 78 surviving RCAF Mustangs were retired from service's inventory and were ferried by Lynn Garrison, an RCAF pilot, from their varied storage locations to Canastota, New York, where the American buyers were based. In effect, Garrison flew each of the surviving aircraft at least once. These aircraft make up a large percentage of the aircraft presently flying worldwide.

In the late 1960s and early 1970s, when the United States Department of Defense wished to supply aircraft to South American countries and later Indonesia for close air support and counter insurgency, it turned to Cavalier to return some of their civilian conversions back to updated military specifications.

In the 21st century, a P-51 can command a price of more than $1 million, even for only partially restored aircraft. There were 204 privately owned P-51s in the U.S. on the FAA registry in 2011, most of which are still flying, often associated with organizations such as the Commemorative Air Force (formerly the Confederate Air Force).

In May 2013, Doug Matthews set an altitude record of in a P-51 named "The Rebel", for piston-powered aircraft weighing . Mathews departed from a grass runway at Florida's Indiantown airport and flew "The Rebel" over Lake Okeechobee. He set world records for time to reach altitudes of , 18 minutes and , 31 minutes. He achieved a new height record of in level flight and a maximum altitude. The previous record of had stood since 1954.


Over 20 variants of the P-51 Mustang were produced from 1940 to after the war.

Except for the small numbers assembled or produced in Australia, all Mustangs were built by North American initially at Inglewood, California, but then additionally in Dallas, Texas.


As indicative of the iconic nature of the P-51, manufacturers within the hobby industry have created scale plastic model kits of the P-51 Mustang, with varying degrees of detail and skill levels. The aircraft have also been the subject of numerous scale flying replicas. Aside from the popular radio-controlled aircraft, several kitplane manufacturers offer ½, ⅔, and ¾-scale replicas capable of comfortably seating one (or even two) and offering high performance combined with more forgiving flight characteristics. Such aircraft include the Titan T-51 Mustang, W.A.R. P-51 Mustang, Linn Mini Mustang, Jurca Gnatsum, Thunder Mustang, Stewart S-51D Mustang, Loehle 5151 Mustang and ScaleWings SW51 Mustang.



</doc>
<doc id="24714" url="https://en.wikipedia.org/wiki?curid=24714" title="Precession">
Precession

Precession is a change in the orientation of the rotational axis of a rotating body. In an appropriate reference frame it can be defined as a change in the first Euler angle, whereas the third Euler angle defines the rotation itself. In other words, if the axis of rotation of a body is itself rotating about a second axis, that body is said to be precessing about the second axis. A motion in which the second Euler angle changes is called "nutation". In physics, there are two types of precession: torque-free and torque-induced.

In astronomy, "precession" refers to any of several slow changes in an astronomical body's rotational or orbital parameters. An important example is the steady change in the orientation of the axis of rotation of the Earth, known as the precession of the equinoxes.

Torque-free precession implies that no external moment (torque) is applied to the body. In torque-free precession, the angular momentum is a constant, but the angular velocity vector changes orientation with time. What makes this possible is a time-varying moment of inertia, or more precisely, a time-varying inertia matrix. The inertia matrix is composed of the moments of inertia of a body calculated with respect to separate coordinate axes (e.g. , , ). If an object is asymmetric about its principal axis of rotation, the moment of inertia with respect to each coordinate direction will change with time, while preserving angular momentum. The result is that the component of the angular velocities of the body about each axis will vary inversely with each axis' moment of inertia.

The torque-free precession rate of an object with an axis of symmetry, such as a disk, spinning about an axis not aligned with that axis of symmetry can be calculated as follows:

where is the precession rate, is the spin rate about the axis of symmetry, is the moment of inertia about the axis of symmetry, is moment of inertia about either of the other two equal perpendicular principal axes, and is the angle between the moment of inertia direction and the symmetry axis.

When an object is not perfectly solid, internal vortices will tend to damp torque-free precession, and the rotation axis will align itself with one of the inertia axes of the body.

For a generic solid object without any axis of symmetry, the evolution of the object's orientation, represented (for example) by a rotation matrix that transforms internal to external coordinates, may be numerically simulated. Given the object's fixed internal moment of inertia tensor and fixed external angular momentum , the instantaneous angular velocity is
Precession occurs by repeatedly recalculating and applying a small rotation vector for the short time ; e.g.:
for the skew-symmetric matrix . The errors induced by finite time steps tend to increase the rotational kinetic energy:
this unphysical tendency can be counteracted by repeatedly applying a small rotation vector perpendicular to both and , noting that

Torque-induced precession (gyroscopic precession) is the phenomenon in which the axis of a spinning object (e.g., a gyroscope) describes a cone in space when an external torque is applied to it. The phenomenon is commonly seen in a spinning toy top, but all rotating objects can undergo precession. If the speed of the rotation and the magnitude of the external torque are constant, the spin axis will move at right angles to the direction that would intuitively result from the external torque. In the case of a toy top, its weight is acting downwards from its center of mass and the normal force (reaction) of the ground is pushing up on it at the point of contact with the support. These two opposite forces produce a torque which causes the top to precess.
The device depicted on the right (or above on mobile devices) is gimbal mounted. From inside to outside there are three axes of rotation: the hub of the wheel, the gimbal axis, and the vertical pivot.

To distinguish between the two horizontal axes, rotation around the wheel hub will be called "spinning", and rotation around the gimbal axis will be called "pitching". Rotation around the vertical pivot axis is called "rotation".

First, imagine that the entire device is rotating around the (vertical) pivot axis. Then, spinning of the wheel (around the wheelhub) is added. Imagine the gimbal axis to be locked, so that the wheel cannot pitch. The gimbal axis has sensors, that measure whether there is a torque around the gimbal axis.

In the picture, a section of the wheel has been named . At the depicted moment in time, section is at the perimeter of the rotating motion around the (vertical) pivot axis. Section , therefore, has a lot of angular rotating velocity with respect to the rotation around the pivot axis, and as is forced closer to the pivot axis of the rotation (by the wheel spinning further), because of the Coriolis effect, with respect to the vertical pivot axis, tends to move in the direction of the top-left arrow in the diagram (shown at 45°) in the direction of rotation around the pivot axis. Section of the wheel is moving away from the pivot axis, and so a force (again, a Coriolis force) acts in the same direction as in the case of . Note that both arrows point in the same direction.

The same reasoning applies for the bottom half of the wheel, but there the arrows point in the opposite direction to that of the top arrows. Combined over the entire wheel, there is a torque around the gimbal axis when some spinning is added to rotation around a vertical axis.

It is important to note that the torque around the gimbal axis arises without any delay; the response is instantaneous.

In the discussion above, the setup was kept unchanging by preventing pitching around the gimbal axis. In the case of a spinning toy top, when the spinning top starts tilting, gravity exerts a torque. However, instead of rolling over, the spinning top just pitches a little. This pitching motion reorients the spinning top with respect to the torque that is being exerted. The result is that the torque exerted by gravity – via the pitching motion – elicits gyroscopic precession (which in turn yields a counter torque against the gravity torque) rather than causing the spinning top to fall to its side.

Precession or gyroscopic considerations have an effect on bicycle performance at high speed. Precession is also the mechanism behind gyrocompasses.

Precession is the change of angular velocity and angular momentum produced by a torque. The general equation that relates the torque to the rate of change of angular momentum is:

where formula_7 and formula_8 are the torque and angular momentum vectors respectively.

Due to the way the torque vectors are defined, it is a vector that is perpendicular to the plane of the forces that create it. Thus it may be seen that the angular momentum vector will change perpendicular to those forces. Depending on how the forces are created, they will often rotate with the angular momentum vector, and then circular precession is created.

Under these circumstances the angular velocity of precession is given by: 

where is the moment of inertia, is the angular velocity of spin about the spin axis, is the mass, is the acceleration due to gravity and is the perpendicular distance of the spin axis about the axis of precession. The torque vector originates at the center of mass. Using , we find that the period of precession is given by:

Where is the moment of inertia, is the period of spin about the spin axis, and is the torque. In general, the problem is more complicated than this, however.
There is an easy way to understand why gyroscopic precession occurs without using any mathematics. The behavior of a spinning object simply obeys laws of inertia by resisting any change in direction. A spinning object possesses a property known as rigidity in space, meaning the spin axis resists any change in orientation. It is the inertia of matter comprising the object as it resists any change in direction that provides this property. Of course, the direction this matter travels constantly changes as the object spins, but any further change in direction is resisted. If a force is applied to the surface of a spinning disc, for example, matter experiences no change in direction at the place the force was applied (or 180 degrees from that place). But 90 degrees before and 90 degrees after that place, matter is forced to change direction. This causes the object to behave as if the force was applied at those places instead. When a force is applied to anything, the object exerts an equal force back but in the opposite direction. Since no actual force was applied 90 degrees before or after, nothing prevents the reaction from taking place, and the object causes itself to move in response. A good way to visualize why this happens is to imagine the spinning object to be a large hollow doughnut filled with water, as described in the book "Thinking Physics" by Lewis Epstein. The doughnut is held still while water circulates inside it. As the force is applied, the water inside is caused to change direction 90 degrees before and after that point. The water then exerts its own force against the inner wall of the doughnut and causes the doughnut to rotate as if the force was applied 90 degrees ahead in the direction of rotation. Epstein exaggerates the vertical and horizontal motion of the water by changing the shape of the doughnut from round to square with rounded corners.

Now imagine the object to be a spinning bicycle wheel, held at both ends of its axle in the hands of a subject. The wheel is spinning clock-wise as seen from a viewer to the subject's right. Clock positions on the wheel are given relative to this viewer. As the wheel spins, the molecules comprising it are traveling exactly horizontal and to the right the instant they pass the 12-o'clock position. They then travel vertically downward the instant they pass 3 o'clock, horizontally to the left at 6 o'clock, vertically upward at 9 o’clock and horizontally to the right again at 12 o'clock. Between these positions, each molecule travels components of these directions. Now imagine the viewer applying a force to the rim of the wheel at 12 o’clock. For this example's sake, imagine the wheel tilting over when this force is applied; it tilts to the left as seen from the subject holding it at its axle. As the wheel tilts to its new position, molecules at 12 o’clock (where the force was applied) as well as those at 6 o’clock, still travel horizontally; their direction did not change as the wheel was tilting. Nor is their direction different after the wheel settles in its new position; they still move horizontally the instant they pass 12 and 6 o’clock. BUT, molecules passing 3 and 9 o’clock were forced to change direction. Those at 3 o’clock were forced to change from moving straight downward, to downward and to the right as viewed from the subject holding the wheel. Molecules passing 9 o’clock were forced to change from moving straight upward, to upward and to the left. This change in direction is resisted by the inertia of those molecules. And when they experience this change in direction, they exert an equal and opposite force in response AT THOSE LOCATIONS-3 AND 9 O’CLOCK. At 3 o’clock, where they were forced to change from moving straight down to downward and to the right, they exert their own equal and opposite reactive force to the left. At 9 o’clock, they exert their own reactive force to the right, as viewed from the subject holding the wheel. This makes the wheel as a whole react by momentarily rotating counter-clockwise as viewed from directly above. Thus, as the force was applied at 12 o’clock, the wheel behaved as if that force was applied at 3 o’clock, which is 90 degrees ahead in the direction of spin. Or, you can say it behaved as if a force from the opposite direction was applied at 9 o'clock, 90 degrees prior to the direction of spin.

In summary, when you apply a force to a spinning object to change the direction of its spin axis, you are not changing the direction of the matter comprising the object at the place you applied the force (nor at 180 degrees from it); matter experiences zero change in direction at those places. Matter experiences the maximum change in direction 90 degrees before and 90 degrees beyond that place, and lesser amounts closer to it. The equal and opposite reaction that occurs 90 degrees before and after then causes the object to behave as it does. This principle is demonstrated in helicopters. Helicopter controls are rigged so that inputs to them are transmitted to the rotor blades at points 90 degrees prior to and 90 degrees beyond the point at which the change in aircraft attitude is desired. The effect is dramatically felt on motorcycles. A motorcycle will suddenly lean and turn in the opposite direction the handle bars are turned.

Gyro precession causes another phenomenon for spinning objects such as the bicycle wheel in this scenario. If the subject holding the wheel removes a hand from one end of its axle, the wheel will not topple over, but will remain upright, supported at just the other end. However, it will immediately take on an additional motion; it will begin to rotate about a vertical axis, pivoting at the point of support as it continues spinning. If you allowed the wheel to continue rotating, you would have to turn your body in the same direction as the wheel rotated. If the wheel was not spinning, it would obviously topple over and fall when one hand is removed. The initial action of the wheel beginning to topple over is equivalent to applying a force to it at 12 o'clock in the direction toward the unsupported side (or a force at 6 o’clock toward the supported side). When the wheel is spinning, the sudden lack of support at one end of its axle is equivalent to this same force. So, instead of toppling over, the wheel behaves as if a continuous force is being applied to it at 3 or 9 o’clock, depending on the direction of spin and which hand was removed. This causes the wheel to begin pivoting at the one supported end of its axle while remaining upright. Although it pivots at that point, it does so only because of the fact that it is supported there; the actual axis of precessional rotation is located vertically through the wheel, passing through its center of mass. Also, this explanation does not account for the effect of variation in the speed of the spinning object; it only illustrates how the spin axis behaves due to precession. More correctly, the object behaves according to the balance of all forces based on the magnitude of the applied force, mass and rotational speed of the object. Once it is visualized why the wheel remains upright and rotates, it can easily be seen why the axis of a spinning top slowly rotates while the top spins as shown in the illustration on this page. A top behaves exactly like the bicycle wheel due to the force of gravity pulling downward. The point of contact with the surface it spins on is equivalent to the end of the axle the wheel is supported at. As the top's spin slows, the reactive force that keeps it upright due to inertia is overcome by gravity. Once the reason for gyro precession is visualized, the mathematical formulas start to make sense.

The special and general theories of relativity give three types of corrections to the Newtonian precession, of a gyroscope near a large mass such as Earth, described above. They are:

In astronomy, precession refers to any of several gravity-induced, slow and continuous changes in an astronomical body's rotational axis or orbital path. Precession of the equinoxes, perihelion precession, changes in the tilt of Earth's axis to its orbit, and the eccentricity of its orbit over tens of thousands of years are all important parts of the astronomical theory of ice ages. "(See Milankovitch cycles.)"

Axial precession is the movement of the rotational axis of an astronomical body, whereby the axis slowly traces out a cone. In the case of Earth, this type of precession is also known as the "precession of the equinoxes", "lunisolar precession", or "precession of the equator". Earth goes through one such complete precessional cycle in a period of approximately 26,000 years or 1° every 72 years, during which the positions of stars will slowly change in both equatorial coordinates and ecliptic longitude. Over this cycle, Earth's north axial pole moves from where it is now, within 1° of Polaris, in a circle around the ecliptic pole, with an angular radius of about 23.5°.

The ancient Greek astronomer Hipparchus (c. 190–120 BC) is generally accepted to be the earliest known astronomer to recognize and assess the precession of the equinoxes at about 1° per century (which is not far from the actual value for antiquity, 1.38°), although there is some minor dispute about whether he was. In ancient China, the Jin-dynasty scholar-official Yu Xi (fl. 307-345 AD) made a similar discovery centuries later, noting that the position of the Sun during the winter solstice had drifted roughly one degree over the course of fifty years relative to the position of the stars. The precession of Earth's axis was later explained by Newtonian physics. Being an oblate spheroid, Earth has a non-spherical shape, bulging outward at the equator. The gravitational tidal forces of the Moon and Sun apply torque to the equator, attempting to pull the equatorial bulge into the plane of the ecliptic, but instead causing it to precess. The torque exerted by the planets, particularly Jupiter, also plays a role.

The orbits of planets around the Sun do not really follow an identical ellipse each time, but actually trace out a flower-petal shape because the major axis of each planet's elliptical orbit also precesses within its orbital plane, partly in response to perturbations in the form of the changing gravitational forces exerted by other planets. This is called perihelion precession or apsidal precession.

In the adjunct image, Earth's apsidal precession is illustrated. As the Earth travels around the Sun, its elliptical orbit rotates gradually over time. The eccentricity of its ellipse and the precession rate of its orbit are exaggerated for visualization. Most orbits in the Solar System have a much smaller eccentricity and precess at a much slower rate, making them nearly circular and nearly stationary.

Discrepancies between the observed perihelion precession rate of the planet Mercury and that predicted by classical mechanics were prominent among the forms of experimental evidence leading to the acceptance of Einstein's Theory of Relativity (in particular, his General Theory of Relativity), which accurately predicted the anomalies. Deviating from Newton's law, Einstein's theory of gravitation predicts an extra term of , which accurately gives the observed excess turning rate of 43″ every 100 years.

The gravitational forces due to the Sun and the Moon induce the precession in the terrestrial orbit. This precession is the major cause of the climate oscillation on the Earth having a period of 19,000 to 23,000 years. It follows that the changes in Earth's orbital parameters (e.g., orbital inclination, the angle between Earth's rotation axis and its plane of orbit) are important for the study of Earth's climate, in particular for the study of past ice ages.

Orbital nodes also precess over time.




</doc>
<doc id="24717" url="https://en.wikipedia.org/wiki?curid=24717" title="Punjab">
Punjab

The Punjab (, , , ; ), also spelled and romanised as Panjāb, is a geopolitical, cultural and historical region in South Asia, specifically in the northern part of the Indian subcontinent, comprising areas of eastern Pakistan and northern India. The boundaries of the region are ill-defined and focus on historical accounts.

The geographical definition of the term "Punjab" has changed over time: in the 16th century Mughal Empire it referred to a relatively smaller area lying between the Indus and the Sutlej rivers. In British India, until the Partition of Punjab in 1947, the Punjab Province encompassed the present-day Indian states and union territories of Punjab, Haryana, Himachal Pradesh, Chandigarh, and Delhi; and the Pakistani provinces of Punjab and Islamabad Capital Territory. It bordered the Balochistan and Pashtunistan regions to the west, Kashmir to the north, the Hindi Belt to the east, and Rajasthan and Sindh to the south.

The people of the Punjab today are called Punjabis, and their principal language is Punjabi. The main religions of the Indian Punjab region are Sikhism and Hinduism. The main religion of the Pakistani Punjab region is Islam. Other religious groups are Christianity, Jainism, Zoroastrianism, Buddhism, and Ravidassia. The Punjab region was the cradle for the Indus Valley Civilisation. The region had numerous migration by the Indo-Aryan peoples. The land was later contested by the Persians, Indo-Greeks, Indo-Scythians, Kushans, Macedonians, Ghaznavids, Turkic, Mongols, Timurids, Mughals, Marathi, Arabs, Pashtuns, British and other peoples. Historic foreign invasions mainly targeted the most productive central region of the Punjab known as the Majha region, which is also the bedrock of Punjabi culture and traditions. The Punjab region is often referred to as the breadbasket in both India and Pakistan.

The region was originally called Sapta Sindhu, the Vedic land of the seven rivers flowing into the ocean.

The origin of the word Punjab can probably be traced to the Sanskrit "panca-nada" , which literally means "five rivers", and is used as the name of a region in "Mahabharata". The later name for the region, "Punjab" (Persian: پنج‌آب) is a compound of two Persian words: پنج "panj" —meaning ""five""—and آب "âb" —meaning ""water"", introduced to the region by the Turko-Persian conquerors of India, and more formally popularised during the Mughal Empire. Punjab thus means "[The Land of] Five Waters", referring to the rivers Jhelum, Chenab, Ravi, Sutlej, and Beas. All are tributaries of the Indus River, the Sutlej being the largest.

The Greeks referred to the region as "Pentapotamía" (), which has the same etymology as the original Persian word, but is otherwise known as "Pantzáb" (Παντζάμπ)—a transliteration of the original word.

In the 16th century, during the reign of the Mughal emperor Akbar, the term "Punjab" was synonymous with the Lahore province. It covered a relatively smaller area lying between the Indus and the Sutlej rivers.

The 19th century definition of the Punjab region focuses on the collapse of the Sikh Empire and the creation of the British Punjab province between 1846 and 1849. According to this definition, the Punjab region incorporates, in Pakistan, Azad Kashmir including Bhimber and Mirpur and parts of Khyber Pakhtunkhwa (especially Peshawar known in the Punjab region as Pishore). In India the wider definition includes parts of Delhi and Jammu Division.

Using the older definition of the Punjab region, the Punjab region covers a large territory and can be divided into five natural areas:

The formation of the Himalayan Range of mountains to the east and north-east of the Punjab is the result of a collision between the north-moving Indo-Australian Plate and the Eurasian Plate. The plates are still moving together, and the Himalayas are rising by about per year.

The upper regions are snow-covered the whole year. Lower ranges of hills run parallel to the mountains. The Lower Himalayan Range runs from north of Rawalpindi through Jammu and Kashmir, Himachal Pradesh and further south. The mountains are relatively young, and are eroding rapidly. The Indus and the five rivers of the Punjab have their sources in the mountain range and carry loam, minerals and silt down to the rich alluvial plains, which consequently are very fertile.

The 1947 definition defines the Punjab region with reference to the dissolution of British India whereby the then British Punjab Province was partitioned between India and Pakistan. In Pakistan, the region now includes the Punjab province and Islamabad Capital Territory. In India, it includes the Punjab state, Chandigarh, Haryana, and Himachal Pradesh.

Using the 1947 definition, the Punjab borders the Balochistan and Pashtunistan regions to the west, Kashmir to the north, the Hindi Belt to the east, and Rajasthan and Sindh to the south. Accordingly, the Punjab region is very diverse and stretches from the hills of the Kangra Valley to the plains and to the Cholistan Desert.

Using the 1947 definition of the Punjab region, some of the major cities of the area include Lahore, Faisalabad and Ludhiana.

According to the older definition, some of the major cities include Jammu, Peshawar and parts of Delhi.
The third definition of the Punjab region adds to the definitions cited above and includes parts of Rajasthan on linguistic lines and takes into consideration the location of the Punjab rivers in ancient times. In particular, the Sri Ganganagar and Hanumangarh districts are included in the Punjab region.
The climate is a factor contributing to the economy of the Punjab. It is not uniform over the whole region, with the sections adjacent to the Himalayas receiving heavier rainfall than those at a distance.

There are three main seasons and two transitional periods. During the hot season from mid-April to the end of June, the temperature may reach . The monsoon season, from July to September, is a period of heavy rainfall, providing water for crops in addition to the supply from canals and irrigation systems. The transitional period after the monsoon is cool and mild, leading to the winter season, when the temperature in January falls to at night and by day. During the transitional period from winter to the hot season, sudden hailstorms and heavy showers may occur, causing damage to crops.

The Punjab region of India and Pakistan has a historical and cultural link to Indo-Aryan peoples as well as partially to various indigenous communities. As a result of several invasions from Central Asia and the Middle East, many ethnic groups and religions make up the cultural heritage of the Punjab.

In prehistoric times, one of the earliest known cultures of South Asia, the Indus Valley civilisation was located in the region.

The epic battles described in the "Mahabharata" are described as being fought in what is now the State of Haryana and historic Punjab. The Gandharas, Kambojas, Trigartas, Andhra, Pauravas, Bahlikas (Bactrian settlers of the Punjab), Yaudheyas and others sided with the Kauravas in the great battle fought at Kurukshetra. According to DrFauja Singh and DrL.M. Joshi: "There is no doubt that the Kambojas, Daradas, Kaikayas, Andhra, Pauravas, Yaudheyas, Malavas, Saindhavas and Kurus had jointly contributed to the heroic tradition and composite culture of ancient Punjab".

In 326 BCE, Alexander the Great invaded Pauravas and defeated King Porus. His armies entered the region via the Hindu Kush in northwest Pakistan and his rule extended up to the city of Sagala (present-day Sialkot in northeast Pakistan). In 305BCE the area was ruled by the Maurya Empire. In a long line of succeeding rulers of the area, Chandragupta Maurya and Ashoka stand out as the most renowned. The Maurya presence in the area was then consolidated in the Indo-Greek Kingdom in 180BCE. Menander I Soter "The Saviour" (known as Milinda in Indian sources) is the most renowned leader of the era, he conquered the Punjab and made Sagala the capital of his Empire. Menander carved out a Greek kingdom in the Punjab and ruled the region till his death in 130BCE. The neighbouring Seleucid Empire rule came to an end around 12BCE, after several invasions by the Yuezhi and the Scythian people.

In 711–713 CE, the 18-year-old Arab general Muhammad bin Qasim of Taif, a city in what is now Saudi Arabia, came by way of the Arabian Sea with Arab troops to defeat Raja Dahir. BinQasim then led his troops to conquer the Sindh and Punjab regions for the Islamic Umayyad Caliphate, making him the first to bring Islam to the region.
During the establishment and consolidation of the Muslim Turkic Mughal Empire prosperity, growth, and relative peace were established, particularly under the reign of Jahangir. Muslim empires ruled the Punjab for approximately 1,000 years. The period was also notable for the emergence of Guru Nanak (1469–1539), the founder of Sikhism.

The Afghan forces of Durrani Empire also known as Afghan Empire under the command of Ahmad Shah Durrani entered Punjab in 1749, and captured Punjab, with Lahore being governed by Pashtuns, and Kashmir regions. In 1758, Punjab came under the rule of Marathas, who captured the region by defeating the Afghan forces of Ahmad Shah Abdali. Following Third Battle of Panipat against Marathas, Durranis reconsolidated its power and dominion over the Punjab region, and Kashmir Valley. Abdali's Indian invasion weakened the Maratha influence. After the death of Ahmad Shah, the Punjab was freed from the Afghan rule by Sikhs for a brief period between 1773 and 1818. At the time of the formation of the Dal Khalsa in 1748 at Amritsar, the Punjab had been divided into 36 areas and 12 separate Sikh principalities, called misl. From this point onward, the beginnings of a Punjabi Sikh Empire emerged. Out of the 36 areas, 22 were united by Maharaja Ranjit Singh. The other 14 accepted British sovereignty. After Ranjit Singh's death, assassinations and internal divisions severely weakened the empire. Six years later the British East India Company was given an excuse to declare war, and in 1849, after two Anglo-Sikh wars, the Punjab was annexed by the British.

In the Indian Rebellion of 1857 the Sikh rulers backed the East India Company, providing troops and support, but in Jhelum 35 British soldiers of HMXXIV regiment were killed by the local resistance, and in Ludhiana a rebellion was crushed with the assistance of the Punjab chiefs of Nabha and Malerkotla.

The British Raj had political, cultural, philosophical, and literary consequences in the Punjab, including the establishment of a new system of education. During the independence movement, many Punjabis played a significant role, including Madan Lal Dhingra, Sukhdev Thapar, Ajit Singh Sandhu, Bhagat Singh, Udham Singh, Kartar Singh Sarabha, Bhai Parmanand, Chaudhary Rehmat Ali, and Lala Lajpat Rai.

At the time of partition in 1947, the province was split into East and West Punjab. East Punjab (48%) became part of India, while West Punjab (52%) became part of Pakistan. The Punjab bore the brunt of the civil unrest following the end of the British Raj, with casualties estimated to be in the millions.


 The major language spoken in the Punjab is Punjabi. In the Indian Punjab this is written in the Gurmukhi script. Pakistan uses the Shahmukhi script, that is closer to Urdu script. Hindi, written in the Devanagri script, is used widely in the Indian states of Himanchal Pradesh and Haryana. Several dialects of Punjabi are spoken in the different regions. The Majhi dialect is considered to be textbook Punjabi and is shared by both countries.

The vast majority of Pakistani Punjabis are Sunni Muslim by faith, but also include large minority faiths mostly Shia Muslim, Ahmadis and Christians.
Sikhism, founded by Guru Nanak is the main religion practised in the post-1966 Indian Punjab state. About 57.7% of the population of Punjab state is Sikh, 38.5% is Hindu, and the rest are Muslims, Christians, and Jains. Punjab state contains the holy Sikh cities of Amritsar, Anandpur Sahib, Tarn Taran Sahib, Fatehgarh Sahib and Chamkaur Sahib.

The Punjab was home to several Sufi saints, and Sufism is well established in the region. Also, Kirpal Singh revered the Sikh Gurus as saints.

Punjabis celebrate the following cultural, seasonal and religious festivals:

Traditional Punjabi clothing includes the following:

The historical region of Punjab is considered to be one of the most fertile regions on Earth. Both east and west Punjab produce a relatively high proportion of India and Pakistan's food output respectively.

The region has been used for extensive wheat farming. In addition, rice, cotton, sugarcane, fruit, and vegetables are also grown.

The agricultural output of the Punjab region in Pakistan contributes significantly to Pakistan's GDP. Both Indian and Pakistani Punjab are considered to have the best infrastructure of their respective countries. Indian Punjab has been estimated to be the second richest state in India. Pakistani Punjab produces 68% of Pakistan's food grain production. Its share of Pakistan's GDP has historically ranged from 51.8% to 54.7%.

Called "The Granary of India" or "The Bread Basket of India", Indian Punjab produces 1% of the world's rice, 2% of its wheat, and 2% of its cotton. In 2001, it was recorded that farmers made up 39% of Indian Punjab's workforce.

Alternatively, Punjab is also adding to the economy with the increase in employment of Punjab youth in the private sector. Government schemes such as 'Ghar Ghar Rozgar and Karobar Mission' have brought enhanced employability in the private sector. So far, 32,420 youths have been placed in different jobs and 12,114 have been skill-trained.




</doc>
<doc id="24718" url="https://en.wikipedia.org/wiki?curid=24718" title="Ring system">
Ring system

A ring system is a disc or ring orbiting an astronomical object that is composed of solid material such as dust and moonlets, and is a common component of satellite systems around giant planets. A ring system around a planet is also known as a planetary ring system.

The most prominent and most famous planetary rings in the Solar System are those around Saturn, but the other three giant planets (Jupiter, Uranus, and Neptune) also have ring systems. Recent evidence suggests that ring systems may also be found around other types of astronomical objects, including minor planets, moons, and brown dwarfs, and as well, the interplanetary spaces between planets such as Venus and Mercury.

There are three ways that thicker planetary rings (the rings around planets) have been proposed to have formed: from material of the protoplanetary disk that was within the Roche limit of the planet and thus could not coalesce to form moons, from the debris of a moon that was disrupted by a large impact, or from the debris of a moon that was disrupted by tidal stresses when it passed within the planet's Roche limit. Most rings were thought to be unstable and to dissipate over the course of tens or hundreds of millions of years, but it now appears that Saturn's rings might be quite old, dating to the early days of the Solar System.

Fainter planetary rings can form as a result of meteoroid impacts with moons orbiting around the planet or, in case of Saturn's E-ring, the ejecta of cryovolcanic material.

The composition of ring particles varies; they may be silicate or icy dust. Larger rocks and boulders may also be present, and in 2007 tidal effects from eight 'moonlets' only a few hundred meters across were detected within Saturn's rings. The maximum size of a ring particle is determined by the specific strength of the material it is made of, its density, and the tidal force at its altitude. The tidal force is proportional to the average density inside the radius of the ring, or to the mass of the planet divided by the radius of the ring cubed. It is also inversely proportional to the square of the orbital period of the ring.

Sometimes rings will have "shepherd" moons, small moons that orbit near the inner or outer edges of rings or within gaps in the rings. The gravity of shepherd moons serves to maintain a sharply defined edge to the ring; material that drifts closer to the shepherd moon's orbit is either deflected back into the body of the ring, ejected from the system, or accreted onto the moon itself.

It is also predicted that Phobos, a moon of Mars, will break up and form into a planetary ring in about 50 million years. Its low orbit, with an orbital period that is shorter than a Martian day, is decaying due to tidal deceleration.

Jupiter's ring system was the third to be discovered, when it was first observed by the "Voyager 1" probe in 1979, and was observed more thoroughly by the "Galileo" orbiter in the 1990s. Its four main parts are a faint thick torus known as the "halo"; a thin, relatively bright main ring; and two wide, faint "gossamer rings". The system consists mostly of dust.

Saturn's rings are the most extensive ring system of any planet in the Solar System, and thus have been known to exist for quite some time. Galileo Galilei first observed them in 1610, but they were not accurately described as a disk around Saturn until Christiaan Huygens did so in 1655. With help from the NASA/ESA/ASI Cassini mission, a further understanding of the ring formation and active movement was understood. The rings are not a series of tiny ringlets as many think, but are more of a disk with varying density. They consist mostly of water ice and trace amounts of rock, and the particles range in size from micrometers to meters.

Uranus' ring system lies between the level of complexity of Saturn's vast system and the simpler systems around Jupiter and Neptune. They were discovered in 1977 by James L. Elliot, Edward W. Dunham, and Jessica Mink. In the time between then and 2005, observations by "Voyager 2" and the Hubble Space Telescope led to a total of 13 distinct rings being identified, most of which are opaque and only a few kilometers wide. They are dark and likely consist of water ice and some radiation-processed organics. The relative lack of dust is due to aerodynamic drag from the extended exosphere-corona of Uranus.

The system around Neptune consists of five principal rings that, at their densest, are comparable to the low-density regions of Saturn's rings. However, they are faint and dusty, much more similar in structure to those of Jupiter. The very dark material that makes up the rings is likely organics processed by radiation, like in the rings of Uranus. 20 to 70 percent of the rings are dust, a relatively high proportion. Hints of the rings were seen for decades prior to their conclusive discovery by "Voyager 2" in 1989.

Reports in March 2008 suggested that Saturn's moon Rhea may have its own tenuous ring system, which would make it the only moon known to have a ring system. A later study published in 2010 revealed that imaging of Rhea by the "Cassini" spacecraft was inconsistent with the predicted properties of the rings, suggesting that some other mechanism is responsible for the magnetic effects that had led to the ring hypothesis.

It had been theorized by some astronomers that Pluto might have a ring system. However, this possibility has been ruled out by "New Horizons", which would have detected any such ring system.

10199 Chariklo, a centaur, was the first minor planet discovered to have rings. It has two rings, perhaps due to a collision that caused a chain of debris to orbit it. The rings were discovered when astronomers observed Chariklo passing in front of the star UCAC4 248-108672 on June 3, 2013 from seven locations in South America. While watching, they saw two dips in the star's apparent brightness just before and after the occultation. Because this event was observed at multiple locations, the conclusion that the dip in brightness was in fact due to rings is unanimously the leading hypothesis. The observations revealed what is likely a -wide ring system that is about 1,000 times closer than the Moon is to Earth. In addition, astronomers suspect there could be a moon orbiting amidst the ring debris. If these rings are the leftovers of a collision as astronomers suspect, this would give fodder to the idea that moons (such as the Moon) form through collisions of smaller bits of material. Chariklo's rings have not been officially named, but the discoverers have nicknamed them Oiapoque and Chuí, after two rivers near the northern and southern ends of Brazil.

A second centaur, 2060 Chiron, is also suspected to have a pair of rings. Based on stellar-occultation data that were initially interpreted as resulting from jets associated with Chiron's comet-like activity, the rings are proposed to be 324 (± 10) km in radius. Their changing appearance at different viewing angles can explain the long-term variation in Chiron's brightness over time.

Ring systems may form around centaurs when they are tidally disrupted in a close encounter (within 0.4 to 0.8 times the Roche limit) with a giant planet. (By definition, a centaur is a minor planet whose orbit crosses the orbit(s) of one or more giant planets.) For a differentiated body approaching a giant planet at an initial relative velocity of 3−6 km/s with an initial rotational period of 8 hours, a ring mass of 0.1%−10% of the centaur's mass is predicted. Ring formation from an undifferentiated body is less likely. The rings would be composed mostly or entirely of material from the parent body's icy mantle. After forming, the ring would spread laterally, leading to satellite formation from whatever portion of it spreads beyond the centaur's Roche Limit. Satellites could also form directly from the disrupted icy mantle. This formation mechanism predicts that roughly 10% of centaurs will have experienced potentially ring-forming encounters with giant planets.

A ring around Haumea, a dwarf planet and resonant Kuiper belt member, was revealed by a stellar occultation observed on 21 January 2017. This makes it the first trans-Neptunian object found to have a ring system. The ring has a radius of about 2,287 km, a width of ≈70 km and an opacity of 0.5. The ring plane coincides with Haumea's equator and the orbit of its larger, outer moon Hi’iaka (which has a semimajor axis of ≈25,657 km). The ring is close to the 3:1 resonance with Haumea's rotation, which is located at a radius of 2,285 ± 8 km. It is well within Haumea's Roche limit, which would lie at a radius of about 4,400 km if Haumea were spherical (being nonspherical pushes the limit out farther).

Because all giant planets of the Solar System have rings, the existence of exoplanets with rings is plausible. Although particles of ice, the material that is predominant in the rings of Saturn, can only exist around planets beyond the frost line, within this line rings consisting of rocky material can be stable in the long term. Such ring systems can be detected for planets observed by the transit method by additional reduction of the light of the central star if their opacity is sufficient. As of January 2015, no such observations are known.

A sequence of occultations of the star 1SWASP J140747.93-394542.6 observed in 2007 over 56 days was interpreted as a transit of a ring system of a (not directly observed) substellar companion dubbed “J1407b”. This ring system is attributed a radius of about 90 million km (about 200 times that of Saturn's rings). In press releases, the term super-Saturn was dubbed. However, the age of this stellar system is only about 16 million years, which suggests that this structure, if real, is more like a protoplanetary disk rather than a stable ring system in an evolved planetary system. The ring was observed to have a 0.0267 AU-wide gap at a radial distance of 0.4 AU. Simulations suggest that this gap is more likely the result of an embedded moon than resonance effects of an external moon(s).

Fomalhaut b was found to be large and unclearly defined when detected in 2008. This may either be due to a cloud of dust attracted from the dust disc of the star, or a possible ring system.



</doc>
<doc id="24721" url="https://en.wikipedia.org/wiki?curid=24721" title="Phoebe">
Phoebe

Phoebe may refer to:








</doc>
<doc id="24722" url="https://en.wikipedia.org/wiki?curid=24722" title="P-code machine">
P-code machine

In computer programming, a p-code machine, or portable code machine is a virtual machine designed to execute p-code (the assembly language of a hypothetical CPU). This term is applied both generically to all such machines (such as the Java Virtual Machine and MATLAB precompiled code), and to specific implementations, the most famous being the p-Machine of the Pascal-P system, particularly the UCSD Pascal implementation (among whose developers the "p" in "p-code" was construed to mean "pseudo" more often than "portable", "pseudo-code" thus meaning instructions for a pseudo-machine) .

Although the concept was first implemented circa 1966 (as O-code for BCPL and P a code for the Euler Language), the term p-code first appeared in the early 1970s. Two early compilers generating p-code were the Pascal-P compiler in 1973, by Kesav V. Nori, Urs Ammann, Kathleen Jensen, Hans-Heinrich Nägeli, and Christian Jacobi, and the Pascal-S compiler in 1975, by Niklaus Wirth.

Programs that have been translated to p-code can either be interpreted by a software program that emulates the behavior of the hypothetical CPU, or translated into the machine code of the CPU on which the program is to run and then executed. If there is sufficient commercial interest, a hardware implementation of the CPU specification may be built (e.g., the Pascal MicroEngine or a version of the Java processor).

Compared to direct translation into native machine code, a two-stage approach involving translation into p-code and execution by an interpreter or just-in-time compiler offers several advantages.


One of the significant disadvantages of p-code is execution speed, which can sometimes be remedied through the use of a JIT compiler. P-code is often also easier to reverse-engineer than native code.

In the early 1980s, at least two operating systems achieved machine independence through extensive use of p-code. The Business Operating System (BOS) was a cross-platform operating system designed to run p-code programs exclusively. The UCSD p-System, developed at The University of California, San Diego, was a self-compiling and self-hosted operating system based on p-code optimized for generation by the Pascal programming language.

In the 1990s, translation into p-code became a popular strategy for implementations of languages such as Python, Microsoft P-Code in Visual Basic and Java bytecode in Java.

The Go programming language uses a generic, portable assembly as a form of p-code, implemented by Ken Thompson as an extension of the work on Plan 9 from Bell Labs. Unlike CLR bytecode or JVM bytecode, there is no stable specification, and the Go build tools do not emit a bytecode format to be used at a later time. The Go assembler uses the generic assembly language as an intermediate representation, and Go executables are machine-specific statically linked binaries.

Like many other p-code machines, the UCSD p-Machine is a stack machine, which means that most instructions take their operands from the stack, and place results back on the stack. Thus, the "add" instruction replaces the two topmost elements of the stack with their sum. A few instructions take an immediate argument. Like Pascal, the p-code is strongly typed, supporting boolean (b), character (c), integer (i), real (r), set (s), and pointer (a) types natively.

Some simple instructions:

Unlike other stack-based environments (such as Forth and the Java Virtual Machine) but very similar to a real target CPU, the p-System has only one stack shared by procedure stack frames (providing return address, etc.) and the arguments to local instructions. Three of the machine's registers point into the stack (which grows upwards):


Also present is a constant area, and, below that, the heap growing down towards the stack. The NP (the new pointer) register points to the top (lowest used address) of the heap. When EP gets greater than NP, the machine's memory is exhausted.

The fifth register, PC, points at the current instruction in the code area.

Stack frames look like this:

The procedure calling sequence works as follows: The call is introduced with

where codice_1 specifies the difference in nesting levels (remember that Pascal supports nested procedures). This instruction will "mark" the stack, i.e. reserve the first five cells of the above stack frame, and initialise previous EP, dynamic, and static link. The caller then computes and pushes any parameters for the procedure, and then issues

to call a user procedure (codice_1 being the number of parameters, codice_3 the procedure's address). This will save the PC in the return address cell, and set the procedure's address as the new PC.

User procedures begin with the two instructions

The first sets SP to MP + codice_4, the second sets EP to SP + codice_5. So codice_4 essentially specifies the space reserved for locals (plus the number of parameters plus 5), and codice_5 gives the number of entries needed locally for the stack. Memory exhaustion is checked at this point.

Returning to the caller is accomplished via

with codice_8 giving the return type (i, r, c, b, a as above, and p for no return value). The return value has to be stored in the appropriate cell previously. On all types except p, returning will leave this value on the stack.

Instead of calling a user procedure (cup), standard procedure codice_9 can be called with

These standard procedures are Pascal procedures like codice_10 (codice_11), codice_12 (codice_13), etc. Peculiarly codice_14 is a p-Code instruction instead.

Niklaus Wirth specified a simple p-code machine in the 1976 book "Algorithms + Data Structures = Programs". The machine had 3 registers - a program counter "p", a base register "b", and a top-of-stack register "t". There were 8 instructions:

This is the code for the machine, written in Pascal:

This machine was used to run Wirth's PL/0, which was a Pascal subset compiler used to teach compiler development.




</doc>
<doc id="24723" url="https://en.wikipedia.org/wiki?curid=24723" title="Proton-pump inhibitor">
Proton-pump inhibitor

Proton-pump inhibitors (PPIs) are a group of medications whose main action is a pronounced and long-lasting reduction of stomach acid production. Within the class of medications, there is no clear evidence that one agent works better than another.

They are the most potent inhibitors of acid secretion available. This group of medications followed and largely superseded another group of medications with similar effects, but a different mode of action, called H-receptor antagonists.
PPIs are among the most widely sold medications in the world, and the first one, omeprazole, is on the World Health Organization's List of Essential Medicines, the safest and most effective medicines needed in a health system. Cost varies significantly between different agents.

These medications are used in the treatment of many conditions, such as:

Specialty professional organizations recommend that people take the lowest effective PPI dose to achieve the desired therapeutic result when used to treat gastroesophageal reflux disease long-term. In the United States, the Food and Drug Administration (FDA) has advised that no more than three 14-day treatment courses should be used in one year.

Despite their extensive use, the quality of the evidence supporting their use in some of these conditions is variable. The effectiveness of PPIs has not been demonstrated for every case. For example, although they reduce the incidence of esophageal adenocarcinoma in Barrett's oesophagus, they do not change the length affected.

PPIs are often used longer than necessary. In about half of people who are hospitalized or seen at a primary care clinic there is no documented reason for their long-term use of PPIs. Some researchers believe that, given the little evidence of long-term effectiveness, the cost of the medication and the potential for harm means that clinicians should consider stopping PPIs in many people.

After four weeks, if symptoms have resolved, the PPI may be stopped in those who were using them for heartburn, gastroesophageal reflux disease, or inflammation of the esophagus if these last two were not severe. Stopping is not recommended in those with Barrett esophagus or a bleeding stomach ulcer. Stopping may be carried out by first decreasing the amount of medication taken or having the person take the medication only when symptoms are present.

In general, proton pump inhibitors are well tolerated, and the incidence of short-term adverse effects is relatively low. The range and occurrence of adverse effects are similar for all of the PPIs, though they have been reported more frequently with omeprazole. This may be due to its longer availability and, hence, clinical experience.

Common adverse effects include headache, nausea, diarrhea, abdominal pain, fatigue, and dizziness. Infrequent adverse effects include rash, itch, flatulence, constipation, anxiety, and depression. Also infrequently, PPI use may be associated with occurrence of myopathies, including the serious reaction rhabdomyolysis.

Long-term use of PPIs requires assessment of the balance of the benefits and risks of the therapy. Various adverse outcomes have been associated with long-term PPI use in several primary reports, but reviews assess the overall quality of evidence in these studies as "low" or "very low". They describe inadequate evidence to establish causal relationships between PPI therapy and many of the proposed associations, due to study design and small estimates of effect size. Benefits outweigh risks when PPIs are used appropriately, but when used inappropriately, modest risks become important. They recommend that PPIs should be used at the lowest effective dose in people with a proven indication, but discourage dose escalation and continued chronic therapy in people unresponsive to initial empiric therapy.

A three-year trial of pantoprazole, completed in 2019, did not find any significant adverse events.

Gastric acid is important for breakdown of food and release of micronutrients, and some studies have shown possibilities for interference with absorption of iron, calcium, magnesium, and vitamin B. With regard to iron and vitamin B, the data are weak and several confounding factors have been identified.
Low levels of magnesium can be found in people on PPI therapy and these can be reversed when they are switched to H2-receptor antagonist medications.

High dose or long-term use of PPIs carries a possible increased risk of bone fractures which was not found with short-term, low dose use; the FDA included a warning regarding this on PPI drug labels in 2010.

Some studies have shown a correlation between use of PPIs and "Clostridium difficile" infections. While the data are contradictory and controversial, the FDA had sufficient concern to include a warning about this adverse effect on the label of PPI medications. Concerns have also been raised about spontaneous bacterial peritonitis in older people taking PPIs and in people with irritable bowel syndrome taking PPIs; both types of infections arise in these populations due to underlying conditions and it is not clear if this is a class effect of PPIs. PPIs may predispose an individual to developing small intestinal bacterial overgrowth or fungal overgrowth.

Long-term use of PPIs is associated with the development of benign polyps from fundic glands (which is distinct from fundic gland polyposis); these polyps do not cause cancer and resolve when PPIs are discontinued. There is concern that use of PPIs may mask gastric cancers or other serious gastric problems.

PPI use has also been associated with the development of microscopic colitis.

There is also evidence that PPI use alters the composition of the bacterial populations inhabiting the gut. Although the mechanisms by which PPIs cause these changes are yet to be determined they may have a role in the increased risk of bacterial infections with PPI use. These infections can include "Helicobacter pylori" due to this species not favouring an acid environment, leading an increased risk of ulcers and Gastric cancer risk in genetically susceptible patients.

Cheung KS, Chan EW, Wong AYS, et al. (2018) showed that even after "H. pylori" eradication, long-term PPI use is still associated with an increased risk of gastric cancer by more than twofold. Hence, long-term PPIs should be used judiciously after considering individual’s risk–benefit profile, particularly among those with history of "H. pylori" infection. Further well-designed prospective studies are warranted to confirm the potential role of PPIs in gastric cancer according to baseline gastric histology and its interaction with other chemopreventive agents like aspirin, statins and metformin.

During a median observation period of 7.6 years [interquartile range (IQR):5.1–10.3 years], 61 PPI use (defined as at least weekly use) was associated with an increased gastric cancer risk (HR 2.44; 95% CI 1.42–4.20).

Associations of PPI use and cardiovascular events have also been widely studied but clear conclusions have not been made as these relative risks are confounded by other factors. PPIs are commonly used in people with cardiovascular disease for gastric protection when aspirin is given for its antiplatelet actions. An interaction between PPIs and the metabolism of the platelet inhibitor clopidogrel is known and this drug is also often used in people with cardiac disease.<ref name="doi/10.1136/bmj.l1580"></ref>

One suggested mechanism for cardiovascular effects is because PPIs bind and inhibit dimethylargininase, the enzyme that degrades asymmetric dimethylarginine (ADMA), resulting in higher ADMA levels and a decrease in bioavailable nitric oxide.

Associations have been shown between PPI use and an increased risk of pneumonia, particularly in the 30 days after starting therapy, where it was found to be 50% higher in community use. Other very weak associations of PPI use have been found, such as with chronic kidney disease and dementia. As these results were derived from observational studies, it remains uncertain whether such associations are causal relationships.

Proton pump inhibitors act by irreversibly blocking the hydrogen/potassium adenosine triphosphatase enzyme system (the H/K ATPase, or, more commonly, the gastric proton pump) of the gastric parietal cells. The proton pump is the terminal stage in gastric acid secretion, being directly responsible for secreting H ions into the gastric lumen, making it an ideal target for inhibiting acid secretion.

Targeting the terminal step in acid production, as well as the irreversible nature of the inhibition, results in a class of medications that are significantly more effective than H antagonists and reduce gastric acid secretion by up to 99%.

Decreasing the acid in the stomach can aid the healing of duodenal ulcers and reduce the pain from indigestion and heartburn. However, stomach acids are needed to digest proteins, vitamin B, calcium, and other nutrients, and too little stomach acid causes the condition hypochlorhydria.

The PPIs are given in an inactive form, which is neutrally charged (lipophilic) and readily crosses cell membranes into intracellular compartments (like the parietal cell canaliculus) with acidic environments. In an acid environment, the inactive drug is protonated and rearranges into its active form. As described above, the active form will covalently and irreversibly bind to the gastric proton pump, deactivating it.

The rate of omeprazole absorption is decreased by concomitant food intake. In addition, the absorption of lansoprazole and esomeprazole is decreased and delayed by food. It has been reported, however, that these pharmacokinetic effects have no significant impact on efficacy.

PPIs have a half-life in human blood plasma of only 60–90 minutes, but because they covalently bind to the pump, the half-life of their inhibition of gastric acid secretion lasts an estimated 24 hours. Dissociation of the inhibitory complex is probably due to the effect of the endogenous antioxidant glutathione which leads to the release of omeprazole sulfide and reactivation of the enzyme.

Medically used proton pump inhibitors:

PPIs were developed in the 1980s with omeprazole being launched in 1988. Most of these medications are benzimidazole derivatives, related to omeprazole, but imidazopyridine derivatives such as tenatoprazole have also been developed. Potassium-competitive inhibitors such as revaprazan reversibly block the potassium-binding site of the proton pump, acting more quickly, but are not available in most countries.

In British Columbia, Canada the cost of the PPIs varies significantly from 0.20 CAD to 2.38 CAD per dose while all agents in the class appear more or less equally effective.

A comparative table of FDA-approved indications for PPIs is shown below.


</doc>
<doc id="24724" url="https://en.wikipedia.org/wiki?curid=24724" title="Pan-Slavism">
Pan-Slavism

Pan-Slavism, a movement which crystallized in the mid-19th century, is the political ideology concerned with the advancement of integrity and unity for the Slavic-speaking peoples. Its main impact occurred in the Balkans, where non-Slavic empires had ruled the South Slavs for centuries. These were mainly the Byzantine Empire, Austria-Hungary (both as separate entities for most of the period), the Ottoman Empire, and Venice.

Extensive pan-Slavism began much like Pan-Germanism, both of which grew from the sense of unity and nationalism experienced within ethnic groups after the French Revolution and the consequent Napoleonic Wars against European monarchies. Like other Romantic nationalist movements, Slavic intellectuals and scholars in the developing fields of history, philology, and folklore actively encouraged the passion of their shared identity and ancestry. Pan-Slavism also co-existed with the Southern Slavic independence.

Commonly used symbols of the Pan-Slavic movement were the Pan-Slavic colours (blue, white and red) and the Pan-Slavic anthem, "Hey, Slavs".

The first pan-Slavists were the 16th-century Croatian writer Vinko Pribojević and the 17th-century Aleksandar Komulović, Bartol Kašić, Ivan Gundulić and Croatian Catholic missionary Juraj Križanić. Some of the earliest manifestations of Pan-Slavic thought within the Habsburg Monarchy have been attributed to Adam Franz Kollár and Pavel Jozef Šafárik. The movement began following the end of the Napoleonic Wars in 1815. In the aftermath, the leaders of Europe sought to restore the pre-war status quo. At the Congress of Vienna, Austria's representative, Prince von Metternich, felt the threat to this status quo in Austria was the nationalists demanding independence from the empire. While their subjects were composed of numerous ethnic groups (such as Italians, Romanians, Hungarians, etc.), most of the subjects were Slavs.

The First Pan-Slav congress was held in Prague, Bohemia in June, 1848, during the revolutionary movement of 1848. The Czechs had refused to send representatives to the Frankfurt Assembly feeling that Slavs had a distinct interest from the Germans. The Austroslav, František Palacký, presided over the event. Most of the delegates were Czech and Slovak. Palacký called for the co-operation of the Habsburgs and had also endorsed the Habsburg monarchy as the political formation most likely to protect the peoples of central Europe. When the Germans asked him to declare himself in favour of their desire for national unity, he replied that he would not as this would weaken the Habsburg state: “Truly, if it were not that Austria had long existed, it would be necessary, in the interest of Europe, in the interest of humanity itself, to create it.”

The Pan-Slav congress met during the revolutionary turmoil of 1848. Young inhabitants of Prague had taken to the streets and in the confrontation, a stray bullet had killed the wife of Field Marshal Alfred I, Prince of Windisch-Grätz, the commander of the Austrian forces in Prague. Enraged, Windischgrätz seized the city, disbanded the congress, and established martial law throughout Bohemia.

The first Pan-Slavic convention was held in Prague on June 2 through 16, 1848. The delegates at the Congress were specifically both anti-Austrian and anti-Russian. Still "the Right"—the moderately liberal wing of the Congress—under the leadership of František Palacký (1798–1876), a Czech historian and politician, and Pavol Jozef Šafárik (1795–1861), a Slovak philologist, historian and archaeologist, favored autonomy of the Slav lands within the framework of Austrian (Habsburg) monarchy. In contrast "the Left"—the radical wing of the Congress—under the leadership of Karel Sabina (1813–1877), a Czech writer and journalist, Josef Václav Frič, a Czech nationalist, Karol Libelt (1817–1861), a Polish writer and politician, and others, pressed for a close alliance with the revolutionary-democratic movement going on in Germany and Hungary in 1848.

A national rebirth in the Hungarian "Upper Land" (now Slovakia) awoke in a completely new light, both before the Slovak Uprising in 1848 and after. The driving force of this rebirth movement were Slovak writers and politicians who called themselves Štúrovci, the followers of Ľudovít Štúr. As the Slovak nobility was Magyarized and most Slovaks were merely farmers or priests, this movement failed to attract much attention. Nonetheless, the campaign was successful as a brotherly cooperation between the Croats and the Slovaks brought its fruit throughout the war. Most of the battles between Slovaks and Hungarians however, did not turn out in favor for the Slovaks who were logistically supported by the Austrians, but not sufficiently. The shortage of manpower proved to be decisive as well.

During the war, the Slovak National Council brought its demands to the young Austrian emperor, Franz Joseph I, who seemed to take a note of it and promised support for the Slovaks against the revolutionary radical Hungarians. However the moment the revolution was over, Slovak demands were forgotten. These demands included an autonomous land within the Austrian Empire called "Slovenský kraj" which would be eventually led by a Serbian prince. This act of ignorance from the Emperor convinced the Slovak and the Czech elite who proclaimed the concept of Austroslavism as dead. 

Disgusted by the Emperor's policy, in 1849, Ľudovít Štúr, the person who codified the first official Slovak language, wrote a book he would name "Slavdom and the World of the Future". This book served as a manifesto where he noted that Austroslavism was not the way to go anymore. He also wrote a sentence that often serves as a quote until this day: "Every nation has its time under God's sun, and the linden [a symbol of the Slavs] is blossoming, while the oak [a symbol of the Teutons] bloomed long ago." 

He expressed confidence in the Russian Empire however, as it was the only country of Slavs that was not dominated by anybody else, yet it was one of the most powerful nations in the world. He often symbolized Slavs as being a tree, with "minor" Slavic nations being branches while the trunk of the tree was Russian. His Pan-Slavic views were unleashed in this book, where he stated that the land of Slovaks should be annexed by the Tsar's empire and that eventually the population could be not only Russified, but also converted into the rite of Orthodoxy, religion originally spread by Cyril and Methodius during the times of Great Moravia, which served as an opposition to the Catholic missionaries from the Franks. After the Hungarian invasion of Pannonia, Hungarians converted into Catholicism, which effectively influenced the Slavs living in Pannonia and in the land south of the Lechs.

However, the Russian Empire often claimed Pan-Slavism as a justification for its aggressive moves in the Balkan Peninsula of Europe against the Ottoman Empire, which conquered and held the land of Slavs for centuries. This eventually led to the Balkan campaign of the Russian Empire, which resulted in the entire Balkan being liberated from the Ottoman Empire, with the help and the initiative of the Russian Empire. Pan-Slavism has some supporters among Czech and Slovak politicians, especially among the nationalistic and far-right ones, such as People's Party - Our Slovakia.

During World War I, captured Slavic soldiers were asked to fight against "oppression in the Austrian Empire". Consequently, some did. (see Czechoslovak Legions)

The creation of an independent Czechoslovakia made the old ideals of Pan-Slavism anachronistic. Relations with other Slavic states varied, sometimes being so tense it escalated into an armed conflict, such as with the Second Polish Republic where border clashes over Silesia resulted in a short hostile conflict, the Polish–Czechoslovak War. Even tensions between Czechs and Slovaks had appeared before and during the World War II.

Pan-Slavism in the south would often turn to Russia for support. The Southern Slavic movement advocated the independence of the Slavic peoples in the Austro-Hungarian Empire, Republic of Venice and the Ottoman Empire. Some Serbian intellectuals sought to unite all of the Southern, Balkan Slavs, whether Catholic (Croats, Slovenes), or Orthodox (Serbs), Bulgarians) as a "Southern-Slavic nation of three faiths".

Austria feared that Pan-Slavists would endanger the empire. In Austria-Hungary Southern Slavs were distributed among several entities: Slovenes in the Austrian part (Carniola, Styria, Carinthia, Gorizia and Gradisca, Trieste, Istria (also Croats)), Croats and Serbs in the Hungarian part within the autonomous Kingdom of Croatia-Slavonia and in the Austrian part within the autonomous Kingdom of Dalmatia, and in Bosnia and Herzegovina, under direct control from Vienna. Due to a different position within Austria-Hungary several different goals were prominent among the Southern Slavs of Austria-Hungary. A strong alternative to Pan-Slavism was Austroslavism, especially among the Croats and Slovenes. Because the Serbs were dispersed among several regions, and the fact that they had ties to the independent nation state of Kingdom of Serbia, they were among the strongest supporters of independence of South-Slavs from Austria-Hungary and uniting into a common state under Serbian monarchy.

In 1863, the Association of Serbian Philology commemorated the death of Cyril a thousand years earlier, its president Dimitrije Matić, talked of the creation of an ethnically "pure" Slavonic people: "with God’s help, there should be a whole Slavonic people with purely Slavonic faces and of purely Slavonic character"

After World War I the creation of the Kingdom of Yugoslavia, under Serbian royalty of the Karađorđević dynasty, united most Southern Slavic-speaking nations regardless of religion and cultural background. The only ones they did not unite with were the Bulgarians. Still, in the years after the Second World War, there were proposals to incorporate Bulgaria into a Greater Yugoslavia thus uniting all south Slavic-speaking nations into one state. The idea was abandoned after the split between Josip Broz Tito and Joseph Stalin in 1948. This led to some bitter sentiment between the people of Yugoslavia and Bulgaria in the aftermath.

At the end of Second World War, the Partisans leader Josip Broz Tito, a Croat, became Yugoslav president, and the country become a socialist republic. Tito advocated Brotherhood and unity which meant equality among the ethnic groups, including non-Slav minorities. This led to relatively peaceful co-existence and prosperity until the breakup of the federation.

Although early Pan-Slavism had found support among some Poles, it soon lost its appeal as the movement became dominated by Russia. While Russian Pan-Slavists spoke of liberation of other Slavs through Russian actions, parts of Poland had been ruled by the Russian Empire since the Partitions of Poland. At different points in history, Poland often saw itself in partnership with non-Slavic nations, such as Hungary, Saxony, Sweden and Lithuania under the Polish–Lithuanian Commonwealth. Especially after 1795, Revolutionary and Napoleonic France was held in high regard by most Poles, and seen as the main champion of reconstitution of their country, particularly since it was a mutual enemy of Austria, Prussia and Russia. The influence of 19th century Pan-Slavism had little impact in Poland except for creating sympathy towards the other oppressed Slavic nations and their aspirations to independence. At the same time while Pan-Slavism worked against Austro-Hungary with South Slavs, Poles enjoyed a wide autonomy within the state and assumed a loyalist position towards the Habsburgs. Within the Austro-Hungarian polity, they were able to develop their national culture and preserve the Polish language, both of which were under threat in both German and Russian Empires. A Pan-Slavic federation was proposed, but on the condition that the Russian Empire would be excluded from such an entity. After Poland regained its independence (from Germany, Austria and Russia) in 1918 no major force considered Pan-Slavism as a serious alternative, viewing Pan-Slavism as little more than a code word for Russification. During Poland's communist era, the USSR used Pan-Slavism as propaganda tool to justify its control over the country. The issue of the Pan-Slavism was not part of current mainstream politics, and is widely seen as an ideology of Russian imperialism.

Joseph Conrad in Notes on Life and Letters.:
""... between Polonism and Slavonism there is not so much hatred as a complete and ineradicable incompatibility."" ... Conrad argues that "nothing is more foreign than what in the literary world is called Slavonism to his "individual" sensibility and "the whole Polish mentality""

Pan-Slavism is popular amongst immigrants from the former USSR to Slavic countries of the European Union. It expresses fierce populism, nostalgia for the Soviet era, and strong anti-Western sentiments.

During the time of the Soviet Union, Bolshevik teachings viewed Pan-Slavism as a reactionary element formerly used by the Russian Empire. As a result, Bolsheviks viewed it as contrary to their Marxist ideology. However, with the emergence of World War II, the Stalinist government saw fit to utilize Pan-Slavic politics, resulting in the Pan-Slavic congress being held in Moscow in 1942.

The authentic idea of unity of the Slavic people was all but gone after World War I when the maxim "Versailles and Trianon have put an end to all Slavisms" and was finally put to rest with the fall of communism in Central and Eastern Europe in late 1980s. With the breakup of federal states such as Czechoslovakia and Yugoslavia and the problem of Russian dominance in any proposed all-Slavic organisation, the idea of Pan-Slavic unity is mostly considered dead in the western world. Varying relations between the Slavic countries exist nowadays; they range from mutual respect on equal footing and sympathy towards one another through traditional dislike and enmity, to indifference. None, other than culture and heritage oriented organizations, are currently considered as a form of rapprochement among the countries with Slavic origins. The political parties which include panslavism as part of their program usually live on the fringe of the political spectrum (e.g. in Poland candidates from Związek Słowiański got no more than few thousands votes). In modern times, the appeals to Pan-Slavism are often made in Belarus, Russia, Serbia and Slovakia.

The similarity of Slavic languages inspired many people to create Pan-Slavic languages, i.e., zonal constructed languages for all Slavic people to communicate with one another. Several of these languages were created in the past, but due to the Internet, many more Pan-Slavic languages were created in the Digital Age. The most popular modern Pan-Slavic language is Interslavic.





</doc>
<doc id="24727" url="https://en.wikipedia.org/wiki?curid=24727" title="Pan-Germanism">
Pan-Germanism

Pan-Germanism ( or '), also occasionally known as Pan-Germanicism"', is a pan-nationalist political idea. Pan-Germanists originally sought to unify all the German and possibly also Germanic-speaking peoples in a single nation-state known as "Großdeutschland".

Pan-Germanism was highly influential in German politics in the 19th century during the unification of Germany when the German Empire was proclaimed as a nation-state in 1871 but without Austria (Kleindeutsche Lösung/Lesser Germany), and the first half of the 20th century in the Austro-Hungarian Empire and the German Empire. From the late 19th century, many Pan-Germanist thinkers, since 1891 organized in the Pan-German League, had adopted openly ethnocentric and racist ideologies, and ultimately gave rise to the foreign policy "Heim ins Reich" pursued by Nazi Germany under Austrian-born Adolf Hitler from 1938, one of the primary factors leading to the outbreak of World War II.
As a result of the disaster of World War II, Pan-Germanism was mostly seen as a taboo ideology in the postwar period in both West and East Germany. Today, Pan-Germanism is mainly limited to some nationalist groups in Germany and Austria.

The word "pan" is a Greek word element meaning "all, every, whole, all-inclusive". The word "German" in this context derives from Latin "Germani" originally used by Julius Caesar referring to tribes or a single tribe in northeastern Gaul. In the Late Middle Ages, it acquired a loose meaning referring to the speakers of Germanic languages (alongside 'Almain' and 'Teuton') most of whom spoke dialects ancestral to modern German. In English, "Pan-German" was first attested in 1892. In German, there exists a synonym ""Alldeutsche Bewegung"" which is a calque using German instead of Latin and Greek roots.

Pan-Germanism's origins began with the birth of Romantic nationalism during the Napoleonic Wars, with Friedrich Ludwig Jahn and Ernst Moritz Arndt being early proponents. Germans, for the most part, had been a loose and disunited people since the Reformation, when the Holy Roman Empire was shattered into a patchwork of states following the end of the Thirty Years' War with the Peace of Westphalia.

Advocates of the "Großdeutschland" (Greater Germany) solution sought to unite all the German-speaking people in Europe, under the leadership of the German Austrians from the Austrian Empire. Pan-Germanism was widespread among the revolutionaries of 1848, notably among Richard Wagner and the Brothers Grimm. Writers such as Friedrich List and Paul Anton Lagarde argued for German hegemony in Central and Eastern Europe, where German domination in some areas had begun as early as the 9th century AD with the Ostsiedlung, Germanic expansion into Slavic and Baltic lands. For the Pan-Germanists, this movement was seen as a Drang nach Osten, in which Germans would be naturally inclined to seek Lebensraum by moving eastwards to reunite with the German minorities there.

The "Deutschlandlied" ("Song of Germany"), written in 1841 by Hoffmann von Fallersleben, in its first stanza defines "Deutschland" as reaching "From the Meuse to the Memel / From the Adige to the Belt", i.e. as including East Prussia and South Tyrol.

Reflecting upon the First Schleswig War in 1848, Karl Marx noted in 1853 that "by quarrelling amongst themselves, instead of confederating, Germans and Scandinavians, both of them belonging to the same great race, only prepare the way for their hereditary enemy, the Slav."

 
By the 1860s the Kingdom of Prussia and the Austrian Empire had become the two most powerful states dominated by German-speaking élites. Both sought to expand their influence and territory. The Austrian Empire—like the Holy Roman Empire—was a multi-ethnic state, but the German-speaking people there did not have an absolute numerical majority; its re-shaping into the Austro-Hungarian Empire was one result of the growing nationalism of other ethnicities—especially the Hungarians. Under Prussian leadership, Otto von Bismarck would ride on the coat-tails of nationalism to unite all of the northern German lands. After Bismarck excluded Austria and the German Austrians from Germany in the German war of 1866 and (following a few other events over the next few years), the unification of Germany, established the Prussian-dominated German Empire ("Second Reich") in 1871 with the proclamation of Wilhelm I as head of a union of German-speaking states, while disregarding millions of its non-German subjects who desired self-determination from German rule. After World War I the Pan-Germanist philosophy changed drastically during the ascendancy of Adolf Hitler. Pan-Germanists originally sought to unify all the German-speaking populations of Europe in a single nation-state known as "Großdeutschland" (Greater Germany), where "German-speaking" was sometimes taken as synonymous with Germanic-speaking, to the inclusion of the Frisian- and Dutch-speaking populations of the Low Countries, and Scandinavia.

Although Bismarck had excluded Austria and the German Austrians from his creation of the Kleindeutschland state in 1871, integrating the German Austrians nevertheless remained a strong desire for many people of both Austria and Germany. The most radical Austrian pan-German Georg Schönerer (1842–1921) and (1862–1941) articulated Pan-Germanist sentiments in the Austro-Hungarian Empire. There was also a rejection of Roman Catholicism with the Away from Rome! movement (ca 1900 onwards) calling for German-speakers to identify with Lutheran or Old Catholic churches. The Pan-German Movement gained an institutional format in 1891, when , a professor at the University of Leipzig and a member of the Reichstag, organized the Pan-German League, an ultra-nationalist political-interest organization which promoted imperialism, anti-semitism, and support for ethnic German minorities in other countries.
The organization achieved great support among the educated middle and upper class; it promoted German nationalist consciousness, especially among ethnic Germans outside Germany. In his three-volume work, "Deutsche Politik" (1905–07), Hasse called for German imperialist expansion in Europe. The Munich professor Karl Haushofer, , and Hans Grimm (author of the novel "Volk ohne Raum") preached similar expansionist policies.

After the Revolutions of 1848/49, in which the liberal nationalistic revolutionaries advocated the Greater German solution, the Austrian defeat in the Austro-Prussian War (1866) with the effect that Austria was now excluded from Germany, and increasing ethnic conflicts in the multinational Habsburg Monarchy, a German national movement evolved in Austria. Led by the radical German nationalist and anti-semite Georg von Schönerer, organisations such as the "Pan-German Society" demanded the annexation of all German-speaking territories of the Danube Monarchy to the German Empire, and fervently rejected Austrian patriotism and a pan-Austrian identity. Schönerer's völkisch and racist German nationalism was an inspiration to Hitler's Nazi ideology.

In 1933, Austrian Nazis and the national-liberal Greater German People's Party formed an action group, fighting together against the Austrofascist regime which imposed a distinct Austrian national identity and in accordance said that Austrians were "better Germans", while Kurt Schuschnigg adopted a policy of appeasement towards Austrian-born Hitler's annexing of Austria to Nazi Germany and called Austria the "better German state", but he still struggled to keep Austria independent. With "Anschluss" of Austria in 1938, the historic aim of Austria's German nationalists was achieved.

After the end of Nazi Germany and the events of World War II in 1945, the ideas of pan-Germanism and an "Anschluss" fell out of favour due to their association with Nazism and allowed Austrians to develop their own national identity. Nevertheless, such notions were revived with the German national camp in the Federation of Independents and the early Freedom Party of Austria.

The idea of including the North Germanic-speaking Scandinavians into a Pan-German state, sometimes referred to as Pan-Germanicism, was promoted alongside mainstream pan-German ideas. Jacob Grimm adopted Munch's anti-Danish Pan-Germanism and argued that the entire peninsula of Jutland had been populated by Germans before the arrival of the Danes and that thus it could justifiably be reclaimed by Germany, whereas the rest of Denmark should be incorporated into Sweden. This line of thinking was countered by Jens Jacob Asmussen Worsaae, an archaeologist who had excavated parts of Danevirke, who argued that there was no way of knowing the language of the earliest inhabitants of Danish territory. He also pointed out that Germany had more solid historical claims to large parts of France and England, and that Slavs—by the same reasoning—could annex parts of Eastern Germany. Regardless of the strength of Worsaae's arguments, pan-Germanism spurred on the German nationalists of Schleswig and Holstein and led to the First Schleswig War in 1848. In turn, this likely contributed to the fact that Pan-Germanism never caught on in Denmark as much as it did in Norway. Pan-Germanic tendencies were particularly widespread among the Norwegian independence movement. Prominent supporters included Peter Andreas Munch, Christopher Bruun, Knut Hamsun, Henrik Ibsen and Bjørnstjerne Bjørnson. Bjørnson, who wrote the lyrics for the Norwegian national anthem, proclaimed in 1901:

Anti-German Scandinavism surged in Denmark in the 1930s and 1940s in response to the pan-Germanic ambitions of Nazi Germany.

World War I became the first attempt to carry out the Pan-German ideology in practice, and the Pan-German movement argued forcefully for expansionist imperialism.

Following the defeat in World War I, the influence of German-speaking elites over Central and Eastern Europe was greatly limited. At the Treaty of Versailles, Germany was substantially reduced in size. Austria-Hungary was split up. A Rump-Austria, which to a certain extent corresponded to the German-speaking areas of Austria-Hungary (a complete split into language groups was impossible due to multi-lingual areas and language-exclaves) adopted the name "German Austria" () in hope for union with Germany. Union with Germany and the name "German Austria" was forbidden by the Treaty of St. Germain and the name had to be changed back to Austria.

It was in the post-World War I period that the Austrian-born Adolf Hitler, under the influence of the stab-in-the-back myth, first took up German nationalist ideas in his "Mein Kampf". Hitler met Heinrich Class in 1918, and Class provided Hitler with support for the 1923 Beer Hall Putsch. Hitler and his National Socialist friends shared most of the basic pan-German visions with the Pan-German League, but differences in political style led the two groups to open rivalry. The German Workers Party of Bohemia cut its ties to the pan-German movement, which was seen as being too dominated by the upper classes, and joined forces with the German Workers Party led by Anton Drexler, which later became the National Socialist German Workers Party (Nazi party) that was to be headed by Adolf Hitler from 1921.

Nazi propaganda also used the political slogan "Ein Volk, ein Reich, ein Führer" ("One people, one Reich, one leader"), to enforce pan-German sentiment in Austria for an "Anschluss".

The "Heim ins Reich" ("Back Home to the Reich") initiative was a policy pursued by the Nazis which attempted to convince the ethnic Germans living outside of Nazi Germany (such as in Austria and Sudetenland) that they should strive to bring these regions "home" into a Greater Germany. This notion also led the way for an even more expansive state to be envisioned, the Greater Germanic Reich, which Nazi Germany tried to establish. This pan-Germanic empire was expected to assimilate practically all of Germanic Europe into an enormously expanded Greater Germanic Reich. Territorially speaking, this encompassed the already-enlarged Reich itself (consisting of pre-1938 Germany plus the areas annexed into the "Großdeutsche Reich"), the Netherlands, Belgium, areas in north-eastern France considered to be historically and ethnically Germanic, Denmark, Norway, Sweden, Iceland, at least the German-speaking parts of Switzerland, and Liechtenstein. The most notable exception was the predominantly Anglo-Saxon United Kingdom, which was not projected as having to be reduced to a German province but to instead become an allied seafaring partner of the Germans.

The eastern "Reichskommissariats" in the vast stretches of Ukraine and Russia were also intended for future integration, with plans for them stretching to the Volga or even beyond the Urals. They were deemed of vital interest for the survival of the German nation, as it was a core tenet of national-socialist ideology that it needed "living space" ("Lebensraum"), creating a "pull towards the East" ("Drang nach Osten") where that could be found and colonized, in a model that the Nazis explicitly derived from the American Manifest Destiny in the Far West and its clearing of native inhabitants.

The defeat of Germany in World War II brought about the decline of Pan-Germanism, much as World War I had led to the demise of Pan-Slavism. Parts of Germany itself were devastated, and the country was divided, firstly into Soviet, French, American, and British zones and then into West Germany and East Germany. To add to the disaster, Germany suffered even larger territorial losses than it did in the First World War, with vast portions of eastern Germany directly annexed by the Soviet Union and Poland. The scale of the Germans' defeat was unprecedented; Pan-Germanism became taboo because it had been tied to racist concepts of the "master race" and "Nordicism" by the Nazi party. However, the reunification of Germany in 1990 revived the old debates.

Up to and during 18th century 

19th century 

20th century 



</doc>
<doc id="24730" url="https://en.wikipedia.org/wiki?curid=24730" title="Patrick Abercromby">
Patrick Abercromby

Patrick Abercromby (1656) was a Scottish physician and antiquarian, noted for being physician to King James VII (II of England) and his fervent opposition to the Act of Union between Scotland and England.

Patrick Abercromby was the third son of Alexander Abercromby of Fetterneir in Aberdeenshire, and brother of Francis Abercromby, who was created Lord Glasford by King James II. He was born at Forfar in 1656 apparently of a Roman Catholic family.

Intending to become a doctor of medicine he entered the University of St Andrews, where he took his degree of M.D. in 1685, but apparently he spent most of his youthful years abroad. It has been stated that he attended the university of Paris, France. "A Discourse of Wit" (1685), sometimes assigned to him, belongs to Dr David Abercromby.

On his return to Scotland, he is found practising as a physician in Edinburgh, where, besides his professional duties, he gave himself with characteristic zeal to the study of antiquities. He was appointed physician to James II in 1685, but the revolution deprived him of the post. Living during the agitations for the union of England and Scotland, he took part as a Jacobite in the war of pamphlets inaugurated and sustained by prominent men on both sides of the Border, and he crossed swords with no less redoubtable a foe than Daniel Defoe in his "Advantages of the Act of Security compared with those of the intended Union" (Edinburgh, 1707), and "A Vindication of the Same against Mr De Foe" (ibid.).

A minor literary work of Abercromby's was a translation of Jean de Beaugué's "Histoire de la guerre d'Écosse" (1556) which appeared in 1707. But the work with which his name is permanently associated is his "Martial Atchievements "[sic]" of the Scots Nation", issued in two large folios, vol. i. 1711, vol. ii. 1716. In the title-page and preface to vol. i. he disclaims the ambition of being an historian, but in vol. ii., in title-page and preface alike, he is no longer a simple biographer, but an historian. Even though, read in the light of later research, much of the first volume must necessarily be relegated to the region of the mythical, nonetheless, the historian was a laborious and accomplished reader and investigator of all available authorities, as well manuscript as printed; while the roll of names of those who aided him includes every man of note in Scotland at the time, from Sir Thomas Craig and Sir George Mackenzie to Alexander Nisbet and Thomas Ruddiman.

The date of Abercromby's death is uncertain. It has been variously assigned to 1715, 1716, 1720, and 1726, and it is usually added that he left a widow in great poverty. The Memoirs of the Abercrombys, commonly attributed to him, do not appear to have been published.




</doc>
<doc id="24731" url="https://en.wikipedia.org/wiki?curid=24731" title="Positron">
Positron

The positron or antielectron is the antiparticle or the antimatter counterpart of the electron. The positron has an electric charge of +1 "e", a spin of 1/2 (the same as the electron), and has the same mass as an electron. When a positron collides with an electron, annihilation occurs. If this collision occurs at low energies, it results in the production of two or more photons.

Positrons can be created by positron emission radioactive decay (through weak interactions), or by pair production from a sufficiently energetic photon which is interacting with an atom in a material.

In 1928, Paul Dirac published a paper proposing that electrons can have both a positive and negative charge. This paper introduced the Dirac equation, a unification of quantum mechanics, special relativity, and the then-new concept of electron spin to explain the Zeeman effect. The paper did not explicitly predict a new particle but did allow for electrons having either positive or negative energy as solutions. Hermann Weyl then published a paper discussing the mathematical implications of the negative energy solution. The positive-energy solution explained experimental results, but Dirac was puzzled by the equally valid negative-energy solution that the mathematical model allowed. Quantum mechanics did not allow the negative energy solution to simply be ignored, as classical mechanics often did in such equations; the dual solution implied the possibility of an electron spontaneously jumping between positive and negative energy states. However, no such transition had yet been observed experimentally.

Dirac wrote a follow-up paper in December 1929 that attempted to explain the unavoidable negative-energy solution for the relativistic electron. He argued that "... an electron with negative energy moves in an external [electromagnetic] field as though it carries a positive charge." He further asserted that all of space could be regarded as a "sea" of negative energy states that were filled, so as to prevent electrons jumping between positive energy states (negative electric charge) and negative energy states (positive charge). The paper also explored the possibility of the proton being an island in this sea, and that it might actually be a negative-energy electron. Dirac acknowledged that the proton having a much greater mass than the electron was a problem, but expressed "hope" that a future theory would resolve the issue.

Robert Oppenheimer argued strongly against the proton being the negative-energy electron solution to Dirac's equation. He asserted that if it were, the hydrogen atom would rapidly self-destruct. Persuaded by Oppenheimer's argument, Dirac published a paper in 1931 that predicted the existence of an as-yet-unobserved particle that he called an "anti-electron" that would have the same mass and the opposite charge as an electron and that would mutually annihilate upon contact with an electron.

Feynman, and earlier Stueckelberg, proposed an interpretation of the positron as an electron moving backward in time, reinterpreting the negative-energy solutions of the Dirac equation. Electrons moving backward in time would have a positive electric charge. Wheeler invoked this concept to explain the identical properties shared by all electrons, suggesting that "they are all the same electron" with a complex, self-intersecting worldline. Yoichiro Nambu later applied it to all production and annihilation of particle-antiparticle pairs, stating that "the eventual creation and annihilation of pairs that may occur now and then is no creation or annihilation, but only a change of direction of moving particles, from the past to the future, or from the future to the past." The backwards in time point of view is nowadays accepted as completely equivalent to other pictures, but it does not have anything to do with the macroscopic terms "cause" and "effect", which do not appear in a microscopic physical description.

Dmitri Skobeltsyn first observed the positron in 1929. While using a Wilson cloud chamber to try to detect gamma radiation in cosmic rays, Skobeltsyn detected particles that acted like electrons but curved in the opposite direction in an applied magnetic field.

Likewise, in 1929 Chung-Yao Chao, a graduate student at Caltech, noticed some anomalous results that indicated particles behaving like electrons, but with a positive charge, though the results were inconclusive and the phenomenon was not pursued.

Carl David Anderson discovered the positron on 2 August 1932, for which he won the Nobel Prize for Physics in 1936. Anderson did not coin the term "positron", but allowed it at the suggestion of the "Physical Review" journal editor to whom he submitted his discovery paper in late 1932. The positron was the first evidence of antimatter and was discovered when Anderson allowed cosmic rays to pass through a cloud chamber and a lead plate. A magnet surrounded this apparatus, causing particles to bend in different directions based on their electric charge. The ion trail left by each positron appeared on the photographic plate with a curvature matching the mass-to-charge ratio of an electron, but in a direction that showed its charge was positive.

Anderson wrote in retrospect that the positron could have been discovered earlier based on Chung-Yao Chao's work, if only it had been followed up on. Frédéric and Irène Joliot-Curie in Paris had evidence of positrons in old photographs when Anderson's results came out, but they had dismissed them as protons.

The positron had also been contemporaneously discovered by Patrick Blackett and Giuseppe Occhialini at the Cavendish Laboratory in 1932. Blackett and Occhialini had delayed publication to obtain more solid evidence, so Anderson was able to publish the discovery first.

Positrons are produced naturally in β decays of naturally occurring radioactive isotopes (for example, potassium-40) and in interactions of gamma quanta (emitted by radioactive nuclei) with matter. Antineutrinos are another kind of antiparticle produced by natural radioactivity (β decay). Many different kinds of antiparticles are also produced by (and contained in) cosmic rays. In research published in 2011 by the American Astronomical Society positrons were discovered originating above thunderstorm clouds; positrons are produced in gamma-ray flashes created by electrons accelerated by strong electric fields in the clouds. Antiprotons have also been found to exist in the Van Allen Belts around the Earth by the PAMELA module.

Antiparticles, of which the most common are positrons due to their low mass, are also produced in any environment with a sufficiently high temperature (mean particle energy greater than the pair production threshold). During the period of baryogenesis, when the universe was extremely hot and dense, matter and antimatter were continually produced and annihilated. The presence of remaining matter, and absence of detectable remaining antimatter, also called baryon asymmetry, is attributed to CP-violation: a violation of the CP-symmetry relating matter to antimatter. The exact mechanism of this violation during baryogenesis remains a mystery.

Positron production from radioactive decay can be considered both artificial and natural production, as the generation of the radioisotope can be natural or artificial. Perhaps the best known naturally-occurring radioisotope which produces positrons is potassium-40, a long-lived isotope of potassium which occurs as a primordial isotope of potassium. Even though a small percent of potassium (0.0117%) it is the single most abundant radioisotope in the human body. In a human body of 70 kg mass, about 4,400 nuclei of K decay per second. The activity of natural potassium is 31 Bq/g. About 0.001% of these K decays produce about 4000 natural positrons per day in the human body. These positrons soon find an electron, undergo annihilation, and produce pairs of 511 keV photons, in a process similar (but much lower intensity) to that which happens during a PET scan nuclear medicine procedure. 

Recent observations indicate black holes and neutron stars produce vast amounts of positron-electron plasma in astrophysical jets. Large clouds of positron-electron plasma have also been associated with neutron stars.

Satellite experiments have found evidence of positrons (as well as a few antiprotons) in primary cosmic rays, amounting to less than 1% of the particles in primary cosmic rays. These do not appear to be the products of large amounts of antimatter from the Big Bang, or indeed complex antimatter in the universe (evidence for which is lacking, see below). Rather, the antimatter in cosmic rays appear to consist of only these two elementary particles, probably made in energetic processes long after the Big Bang. 

Preliminary results from the presently operating Alpha Magnetic Spectrometer ("AMS-02") on board the International Space Station show that positrons in the cosmic rays arrive with no directionality, and with energies that range from 10 to 250 GeV. In September 2014, new results with almost twice as much data were presented in a talk at CERN and published in Physical Review Letters. A new measurement of positron fraction up to 500 GeV was reported, showing that positron fraction peaks at a maximum of about 16% of total electron+positron events, around an energy of 275 ± 32 GeV. At higher energies, up to 500 GeV, the ratio of positrons to electrons begins to fall again. The absolute flux of positrons also begins to fall before 500 GeV, but peaks at energies far higher than electron energies, which peak about 10 GeV. These results on interpretation have been suggested to be due to positron production in annihilation events of massive dark matter particles.

Positrons, like anti-protons, do not appear to originate from any hypothetical "antimatter" regions of the universe. On the contrary, there is no evidence of complex antimatter atomic nuclei, such as antihelium nuclei (i.e., anti-alpha particles), in cosmic rays. These are actively being searched for. A prototype of the "AMS-02" designated "AMS-01", was flown into space aboard the on STS-91 in June 1998. By not detecting any antihelium at all, the "AMS-01" established an upper limit of 1.1×10 for the antihelium to helium flux ratio.

Physicists at the Lawrence Livermore National Laboratory in California have used a short, ultra-intense laser to irradiate a millimeter-thick gold target and produce more than 100 billion positrons. Presently significant lab production of 5 MeV positron-electron beams allows investigation of multiple characteristics such as how different elements react to 5 MeV positron interactions or impacts, how energy is transferred to particles, and the shock effect of gamma-ray bursts (GRBs).

Certain kinds of particle accelerator experiments involve colliding positrons and electrons at relativistic speeds. The high impact energy and the mutual annihilation of these matter/antimatter opposites create a fountain of diverse subatomic particles. Physicists study the results of these collisions to test theoretical predictions and to search for new kinds of particles.

The ALPHA experiment combines positrons with antiprotons to study properties of antihydrogen.

Gamma rays, emitted indirectly by a positron-emitting radionuclide (tracer), are detected in positron emission tomography (PET) scanners used in hospitals. PET scanners create detailed three-dimensional images of metabolic activity within the human body.

An experimental tool called positron annihilation spectroscopy (PAS) is used in materials research to detect variations in density, defects, displacements, or even voids, within a solid material.




</doc>
<doc id="24733" url="https://en.wikipedia.org/wiki?curid=24733" title="Phencyclidine">
Phencyclidine

Phencyclidine (PCP), also known as angel dust among other names, is a drug used for its mind-altering effects. PCP may cause hallucinations, distorted perceptions of sounds, and violent behavior. As a recreational drug, it is typically smoked, but may be taken by mouth, snorted, or injected. It may also be mixed with cannabis or tobacco.
Adverse effects may include seizures, coma, addiction, and an increased risk of suicide. Flashbacks may occur despite stopping usage. Chemically, PCP is a member of the arylcyclohexylamine class, and pharmacologically, it is a dissociative anesthetic. PCP works primarily as an NMDA receptor antagonist.
PCP is most commonly used in the United States. While usage peaked there in the 1970s, between 2005 and 2011 an increase in visits to emergency departments as a result of the drug occurred. As of 2017 in the United States about 1% of people in grade twelve reported using PCP in the prior year while 2.9% of those over the age of 25 reported using it at some point in their life.
PCP was initially made in 1926 and brought to market as an anesthetic medication in the 1950s. Its use in humans was disallowed in the United States in 1965 due to the high rates of side effects while its use in other animals was disallowed in 1978. Moreover, ketamine was discovered and was better tolerated as an anesthetic. PCP is classified as a schedule II drug in the United States. A number of derivatives of PCP have been sold for recreational and non-medical use.

Phencyclidine is used for its ability to induce a dissociative state. 

Behavioral effects can vary by dosage. Low doses produce a numbness in the extremities and intoxication, characterized by staggering, unsteady gait, slurred speech, bloodshot eyes, and loss of balance. Moderate doses (5–10 mg intranasal, or 0.01–0.02 mg/kg intramuscular or intravenous) will produce analgesia and anesthesia. High doses may lead to convulsions. The drug is often illegally produced under poorly controlled conditions; this means that users may be unaware of the actual dose they are taking.

Psychological effects include severe changes in body image, loss of ego boundaries, paranoia, and depersonalization. Psychosis, agitation and dysphoria, hallucinations, blurred vision, euphoria, and suicidal impulses are also reported, as well as occasional aggressive behavior. Like many other drugs, PCP has been known to alter mood states in an unpredictable fashion, causing some individuals to become detached, and others to become animated. PCP may induce feelings of strength, power, and invulnerability as well as a numbing effect on the mind.

Studies by the Drug Abuse Warning Network in the 1970s show that media reports of PCP-induced violence are greatly exaggerated and that incidents of violence are unusual and often limited to individuals with reputations for aggression regardless of drug use. Although uncommon, events of PCP-intoxicated individuals acting in an unpredictable fashion, possibly driven by their delusions or hallucinations, have been publicized. One example is the case of Big Lurch, a former rapper with a history of violent crime, who was convicted of murdering and cannibalizing his roommate while under the influence of PCP. Other commonly cited types of incidents include inflicting property damage and self-mutilation of various types, such as pulling one's own teeth. These effects were not noted in its medicinal use in the 1950s and 1960s however, and reports of physical violence on PCP have often been shown to be unfounded.

Recreational doses of the drug also occasionally appear to induce a psychotic state that resembles a schizophrenic episode. Users generally report feeling detached from reality.

Symptoms are summarized by the mnemonic device RED DANES: rage, erythema (redness of skin), dilated pupils, delusions, amnesia, nystagmus (oscillation of the eyeball when moving laterally), excitation, and skin dryness.

PCP is self-administered and induces ΔFosB expression in the D1-type medium spiny neurons of the nucleus accumbens, and accordingly, excessive PCP use is known to cause addiction. PCP's rewarding and reinforcing effects are at least partly mediated by blocking the NMDA receptors in the glutamatergic inputs to D1-type medium spiny neurons in the nucleus accumbens. PCP has been shown to produce conditioned place aversion and conditioned place preference in animal studies.

PCP comes in both powder and liquid forms (PCP base is dissolved most often in ether), but typically it is sprayed onto leafy material such as cannabis, mint, oregano, tobacco, parsley, or ginger leaves, then smoked.

Management of PCP intoxication mostly consists of supportive care – controlling breathing, circulation, and body temperature – and, in the early stages, treating psychiatric symptoms. Benzodiazepines, such as lorazepam, are the drugs of choice to control agitation and seizures (when present). Typical antipsychotics such as phenothiazines and haloperidol have been used to control psychotic symptoms, but may produce many undesirable side effects – such as dystonia – and their use is therefore no longer preferred; phenothiazines are particularly risky, as they may lower the seizure threshold, worsen hyperthermia, and boost the anticholinergic effects of PCP. If an antipsychotic is given, intramuscular haloperidol has been recommended.

Forced acid diuresis (with ammonium chloride or, more safely, ascorbic acid) may increase clearance of PCP from the body, and was somewhat controversially recommended in the past as a decontamination measure. However, it is now known that only around 10% of a dose of PCP is removed by the kidneys, which would make increased urinary clearance of little consequence; furthermore, urinary acidification is dangerous, as it may induce acidosis and worsen rhabdomyolysis (muscle breakdown), which is not an unusual manifestation of PCP toxicity.

PCP is well known for its primary action on the NMDA receptor, an ionotropic glutamate receptor, in rats and in rat brain homogenate. As such, PCP is an NMDA receptor antagonist. The role of NMDAR antagonism in the effect of PCP, ketamine, and related dissociative agents was first published in the early 1980s by David Lodge and colleagues. Other NMDA receptor antagonists include ketamine, tiletamine, dextromethorphan, nitrous oxide, and dizocilpine (MK-801).

Research also indicates that PCP inhibits nicotinic acetylcholine receptors (nAChRs) among other mechanisms. Analogues of PCP exhibit varying potency at nACh receptors and NMDA receptors. Findings demonstrate that presynaptic nAChRs and NMDA receptor interactions influence postsynaptic maturation of glutamatergic synapses and consequently impact synaptic development and plasticity in the brain. These effects can lead to inhibition of excitatory glutamate activity in certain brain regions such as the hippocampus and cerebellum thus potentially leading to memory loss as one of the effects of prolonged use. Acute effects on the cerebellum manifest as changes in blood pressure, breathing rate, pulse rate, and loss of muscular coordination during intoxication.

PCP, like ketamine, also acts as a potent dopamine D receptor partial agonist in rat brain homogenate and has affinity for the human cloned D receptor. This activity may be associated with some of the other more psychotic features of PCP intoxication, which is evidenced by the successful use of D receptor antagonists (such as haloperidol) in the treatment of PCP psychosis.

In addition to its well explored interactions with NMDA receptors, PCP has also been shown to inhibit dopamine reuptake, and thereby leads to increased extracellular levels of dopamine and hence increased dopaminergic neurotransmission. However, PCP has little affinity for the human monoamine transporters, including the dopamine transporter (DAT). Instead, its inhibition of monoamine reuptake may be mediated by interactions with allosteric sites on the monoamine transporters. PCP is notably a high-affinity ligand of the PCP site 2 (K = 154 nM), a not-well-characterized site associated with monoamine reuptake inhibition.

Studies on rats indicate that PCP interacts indirectly with opioid receptors (endorphin and enkephalin) to produce analgesia.

A binding study assessed PCP at 56 sites including neurotransmitter receptors and transporters and found that PCP had K values of >10,000 nM at all sites except the dizocilpine (MK-801) site of the NMDA receptor (K = 59 nM), the σ receptor (PC12) (K = 136 nM), and the serotonin transporter (K = 2,234 nM). The study notably found K values of >10,000 nM for the D receptor, the opioid receptors, the σ receptor, and the dopamine and norepinephrine transporters. These results suggest that PCP is a highly selective ligand of the NMDAR and σ receptor. However, PCP may also interact with allosteric sites on the monoamine transporters to produce inhibition of monoamine reuptake.

Phencyclidine is an NMDA receptor antagonist that blocks the activity of the NMDA receptor to cause anaesthesia and analgesia without causing cardiorespiratory depression. NMDA is an excitatory receptor in the brain, when activated normally the receptor acts as an ion channel and there is an influx of positive ions through the channel to cause nerve cell depolarisation. Phencyclidine enters the ion channel and binds, reversibly and non-competitively, inside the channel pore to block the entry of positive ions to the cell therefore inhibiting cell depolarisation.

Some studies found that, like other NMDA receptor antagonists, PCP can cause a kind of brain damage called Olney's lesions in rats. Studies conducted on rats showed that high doses of the NMDA receptor antagonist dizocilpine caused reversible vacuoles to form in certain regions of the rats' brains. All studies of Olney's lesions have only been performed on non-human animals and may not apply to humans. One unpublished study by Frank Sharp reportedly showed no damage by the NDMA antagonist, ketamine, a structurally similar drug, far beyond recreational doses, but due to the study never having been published, its validity is controversial.

PCP has also been shown to cause schizophrenia-like changes in "N"-acetylaspartate and "N"-acetylaspartylglutamate levels in the rat brain, which are detectable both in living rats and upon necropsy examination of brain tissue. It also induces symptoms in humans that mimic schizophrenia. PCP not only produced symptoms similar to schizophrenia, it also yielded electroencephalogram changes in the thalamocortical pathway (increased delta decreased alpha) and in the hippocampus (increase theta bursts) that were similar to those in schizophrenia. PCP induced augmentation of dopamine release may link the NMDA and DA hypothesis of schizophrenia.

PCP is metabolized into PCHP, PPC and PCAA. The drug is metabolized 90% by oxidative hydroxylation in the liver during the first pass. Metabolites are glucuronidated and excreted in the urine. PCP is excreted 9% in its unchanged form.

When smoked, some of the compound is broken down by heat into 1-phenylcyclohexene (PC) and piperidine.

It takes 15 to 60 minutes for effects of PCP to onset.

PCP is an arylcyclohexylamine.

Fewer than 30 different analogs of PCP were reported as being used on the street during the 1970s and 1980s, mainly in the United States. Only of a few of these compounds were widely used including rolicyclidine (PCPy), eticyclidine (PCE), and tenocyclidine (TCP). Less common analogs include 3-HO-PCP, 3-MeO-PCMo, and 3-MeO-PCP.

The generalized structural motif required for PCP-like activity is derived from structure-activity relationship studies of PCP derivatives. All of these derivatives are likely to share some of their psychoactive effects with PCP itself, although a range of potencies and varying mixtures of anesthetic, dissociative, and stimulant effects are known, depending on the particular drug and its substituents. In some countries such as the United States, Australia, and New Zealand, all of these compounds would be considered controlled substance analogs of PCP under the Federal Analog Act and are hence illegal drugs if sold for human consumption.

PCP was initially made in 1926 and brought to market as an anesthetic medication in the 1950s. Its anesthetic effects were discovered by Victor Maddox, a chemist at Parke-Davis in Michigan, while investigating synthetic analgesic agents. It was known under the developmental code name "CI-395". It was approved for use as an investigational drug under the brand names Sernyl and Sernylan in the 1950s as an anesthetic, but because of its long terminal half-life and adverse side effects, such as hallucinations, mania, delirium, and disorientation, it was removed from the market in 1965 and limited to veterinary use.

PCP is a Schedule II substance in the United States and its ACSCN is 7471. Its manufacturing quota for 2014 was 19 grams.

It is a Schedule I drug by the Controlled Drugs and Substances act in Canada, a List I drug of the Opium Law in the Netherlands, and a Class A substance in the United Kingdom.

PCP began to emerge as a recreational drug in major cities in the United States in 1960s. In 1978, "People" magazine and Mike Wallace of "60 Minutes" called PCP the country's "number one" drug problem. Although recreational use of the drug had always been relatively low, it began declining significantly in the 1980s. In surveys, the number of high school students admitting to trying PCP at least once fell from 13% in 1979 to less than 3% in 1990.



</doc>
<doc id="24734" url="https://en.wikipedia.org/wiki?curid=24734" title="Product of group subsets">
Product of group subsets

In mathematics, one can define a product of group subsets in a natural way. If "S" and "T" are subsets of a group "G", then their product is the subset of "G" defined by
The subsets "S" and "T" need not be subgroups for this product to be well defined. The associativity of this product follows from that of the group product. The product of group subsets therefore defines a natural monoid structure on the power set of "G".

A lot more can be said in the case where "S" and "T" are subgroups. The product of two subgroups "S" and "T" of a group "G" is itself a subgroup of "G" if and only if "ST" = "TS".

If "S" and "T" are subgroups of "G", their product need not be a subgroup (for example, two distinct subgroups of order 2 in the symmetric group on 3 symbols). This product is sometimes called the "Frobenius product". In general, the product of two subgroups "S" and "T" is a subgroup if and only if "ST" = "TS", and the two subgroups are said to permute. (Walter Ledermann has called this fact the "Product Theorem", but this name, just like "Frobenius product" is by no means standard.) In this case, "ST" is the group generated by "S" and "T"; i.e., "ST" = "TS" = ⟨"S" ∪ "T"⟩.

If either "S" or "T" is normal then the condition "ST" = "TS" is satisfied and the product is a subgroup. If both "S" and "T" are normal, then the product is normal as well.

If "S" and "T" are finite subgroups of a group "G", then "ST" is a subset of "G" of size "|ST|" given by the "product formula":
Note that this applies even if neither "S" nor "T" is normal.

The following modular law (for groups) holds for any "Q" a subgroup of "S", where "T" is any other arbitrary subgroup (and both "S" and "T" are subgroups of some group "G"):
The two products that appear in this equality are not necessarily subgroups.

If "QT" is a subgroup (equivalently, as noted above, if "Q" and "T" permute) then "QT" = ⟨"Q" ∪ "T"⟩ = "Q" ∨ "T"; i.e., "QT" is the join of "Q" and "T" in the lattice of subgroups of "G", and the modular law for such a pair may also be written as "Q" ∨ ("S" ∩ "T") = "S" ∩ ("Q ∨ T"), which is the equation that defines a modular lattice if it holds for any three elements of the lattice with "Q" ≤ "S". In particular, since normal subgroups permute with each other, they form a modular sublattice.

A group in which every subgroup permutes is called an Iwasawa group. The subgroup lattice of an Iwasawa group is thus a modular lattice, so these groups are sometimes called "modular groups" (although this latter term may have other meanings.)

The assumption in the modular law for groups (as formulated above) that "Q" is a subgroup of "S" is essential. If "Q" is "not" a subgroup of "S", then the tentative, more general distributive property that one may consider "S" ∩ ("QT") = ("S" ∩ "Q")("S" ∩ "T") is "false".

In particular, if "S" and "T" intersect only in the identity, then every element of "ST" has a unique expression as a product "st" with "s" in "S" and "t" in "T". If "S" and "T" also commute, then "ST" is a group, and is called a Zappa–Szép product. Even further, if "S" or "T" is normal in "ST", then "ST" coincides with the semidirect product of "S" and "T". Finally, if both "S" and "T" are normal in "ST", then "ST" coincides with the direct product of "S" and "T".

If "S" and "T" are subgroups whose intersection is the trivial subgroup (identity element) and additionally "ST" = "G", then "S" is called a complement of "T" and vice versa.

By a (locally unambiguous) abuse of terminology, two subgroups that intersect only on the (otherwise obligatory) identity are sometimes called disjoint.

A question that arises in the case of a non-trivial intersection between a normal subgroup "N" and a subgroup "K" is what is the structure of the quotient "NK"/"N". Although one might be tempted to just "cancel out" "N" and say the answer is "K", that is not correct because a homomorphism with kernel "N" will also "collapse" (map to 1) all elements of "K" that happen to be in "N". Thus the correct answer is that "NK"/"N" is isomorphic with "K"/("N"∩"K"). This fact is sometimes called the second isomorphism theorem, (although the numbering of these theorems sees some variation between authors); it has also been called the "diamond theorem" by I. Martin Isaacs because of the shape of subgroup lattice involved, and has also been called the "parallelogram rule" by Paul Moritz Cohn, who thus emphasized analogy with the parallelogram rule for vectors because in the resulting subgroup lattice the two sides assumed to represent the quotient groups ("SN") / "N" and "S" / ("S" ∩ "N") are "equal" in the sense of isomorphism.

Frattini's argument guarantees the existence of a product of subgroups (giving rise to the whole group) in a case where the intersection is not necessarily trivial (and for this latter reason the two subgroups are not complements). More specifically, if "G" is a finite group with normal subgroup "N", and if "P" is a Sylow "p"-subgroup of "N", then "G" = "N"("P")"N", where "N"("P") denotes the normalizer of "P" in "G". (Note that the normalizer of "P" includes "P", so the intersection between "N" and "N"("P") is at least "P".)

In a semigroup S, the product of two subsets defines a structure of semigroup on P(S), the power set of the semigroup S; furthermore P(S) is a semiring with addition as union (of subsets) and multiplication as product of subsets.



</doc>
<doc id="24736" url="https://en.wikipedia.org/wiki?curid=24736" title="PCHP">
PCHP

1-(1-Phenylcyclohexyl)-4-hydroxypiperidine (PCHP) is a metabolite of phencyclidine (PCP). PCHP can be detected in the hair, urine, stool, sweat, and saliva of PCP users.



</doc>
<doc id="24737" url="https://en.wikipedia.org/wiki?curid=24737" title="4-Phenyl-4-(1-piperidinyl)cyclohexanol">
4-Phenyl-4-(1-piperidinyl)cyclohexanol

4-Phenyl-4-(1-piperidinyl)cyclohexanol, also known as PPC, is an organic chemical which is a metabolite of phencyclidine (PCP). It can be detected in the hair of PCP users.

PPC has been shown to cause increases in locomotor activity in lab mice.



</doc>
<doc id="24738" url="https://en.wikipedia.org/wiki?curid=24738" title="PCAA">
PCAA

PCAA, or 5-["N"-(1-phenylcyclohexyl)]-aminopentanoic acid, is a metabolite of phencyclidine (PCP). It can be detected in the urine of PCP users by mass spectrometry as means of drug screening.


</doc>
<doc id="24739" url="https://en.wikipedia.org/wiki?curid=24739" title="Piperidine">
Piperidine

Piperidine is an organic compound with the molecular formula (CH)NH. This heterocyclic amine consists of a six-membered ring containing five methylene bridges (–CH–) and one amine bridge (–NH–). It is a colorless liquid with an odor described as objectionable, and typical of amines. The name comes from the genus name "Piper", which is the Latin word for pepper. Although piperidine is a common organic compound, it is best known as a representative structure element within many pharmaceuticals and alkaloids, such as natural-occurring solenopsins.

Piperidine was first reported in 1850 by the Scottish chemist Thomas Anderson and again, independently, in 1852 by the French chemist Auguste Cahours, who named it. Both men obtained piperidine by reacting piperine with nitric acid.

Industrially, piperidine is produced by the hydrogenation of pyridine, usually over a molybdenum disulfide catalyst:

Pyridine can also be reduced to piperidine via a modified Birch reduction using sodium in ethanol.

Piperidine itself has been obtained from black pepper, from "Psilocaulon absimile" (Aizoaceae), and in "Petrosimonia monandra".

The piperidine structural motif is present in numerous natural alkaloids. These include piperine, which gives black pepper its spicy taste. This gave the compound its name. Other examples are the fire ant toxin solenopsin, the nicotine analog anabasine of tree tobacco ("Nicotiana glauca"), lobeline of Indian tobacco, and the toxic alkaloid coniine from poison hemlock, which was used to put Socrates to death.

Piperidine prefers a chair conformation, similar to cyclohexane. Unlike cyclohexane, piperidine has two distinguishable chair conformations: one with the N–H bond in an axial position, and the other in an equatorial position. After much controversy during the 1950s–1970s, the equatorial conformation was found to be more stable by 0.72 kcal/mol in the gas phase. In nonpolar solvents, a range between 0.2 and 0.6 kcal/mol has been estimated, but in polar solvents the axial conformer may be more stable. The two conformers interconvert rapidly through nitrogen inversion; the free energy activation barrier for this process, estimated at 6.1 kcal/mol, is substantially lower than the 10.4 kcal/mol for ring inversion. In the case of "N"-methylpiperidine, the equatorial conformation is preferred by 3.16 kcal/mol, which is much larger than the preference in methylcyclohexane, 1.74 kcal/mol.

Piperidine is a widely used secondary amine. It is widely used to convert ketones to enamines. Enamines derived from piperidine can be used in the Stork enamine alkylation reaction.

Upon treatment with calcium hypochlorite, piperidine convert to N-chloropiperidine, the chloramine with the formula CHNCl. The resulting chloramine undergoes dehydrohalogenation to afford the cyclic imine.


Piperidine is used as a solvent and as a base. The same is true for certain derivatives: "N"-formylpiperidine is a polar aprotic solvent with better hydrocarbon solubility than other amide solvents, and 2,2,6,6-tetramethylpiperidine is a highly sterically hindered base, useful because of its low nucleophilicity and high solubility in organic solvents.

A significant industrial application of piperidine is for the production of dipiperidinyl dithiuram tetrasulfide, which is used as an accelerator of the sulfur vulcanization of rubber.

Piperidine and its derivatives are ubiquitous building blocks in pharmaceuticals and fine chemicals. The piperidine structure is found in, for example:
Piperidine is also commonly used in chemical degradation reactions, such as the sequencing of DNA in the cleavage of particular modified nucleotides. Piperidine is also commonly used as a base for the deprotection of Fmoc-amino acids used in solid-phase peptide synthesis.

Piperidine is listed as a Table II precursor under the United Nations Convention Against Illicit Traffic in Narcotic Drugs and Psychotropic Substances due to its use (peaking in the 1970s) in the clandestine manufacture of PCP (1-(1-phenylcyclohexyl)piperidine, also known as angel dust, sherms, wet, etc.).


</doc>
<doc id="24740" url="https://en.wikipedia.org/wiki?curid=24740" title="Political question">
Political question

In United States constitutional law, the political question doctrine is closely linked to the concept of justiciability, as it comes down to a question of whether or not the court system is an appropriate forum in which to hear the case. This is because the court system only has authority to hear and decide a legal question, not a political question. Legal questions are deemed to be justiciable, while political questions are nonjusticiable. One scholar explained:

A ruling of nonjusticiability ultimately prohibits the issue that brings the case before the court from a resolution in a court of law. In the typical case where there is a finding of nonjusticiability due to the political question doctrine, the issue presented before the court is usually so specific that the Constitution gives all power to one of the coordinate political branches, or at the opposite end of the spectrum, the issue presented is so vague that the United States Constitution does not even consider it. A court can only decide issues based on law. The Constitution dictates the different legal responsibilities of each respective branch of government. If there is an issue where the court does not have the Constitution as a guide, there are no legal criteria to use. When there are no specific constitutional duties involved, the issue is to be decided through the democratic process. The court will not engage in political disputes.

A constitutional dispute that requires knowledge of a non-legal character or the use of techniques not suitable for a court or explicitly assigned by the Constitution to the U.S. Congress, or the President of the United States, is a political question, which judges customarily refuse to address.

The doctrine has its roots in the historic Supreme Court case of "Marbury v. Madison" (1803). In that case, Chief Justice John Marshall drew a distinction between two different functions of the U.S. Secretary of State. Marshall stated that when the Secretary of State was performing a purely discretionary matter, such as advising the President on matters of policy, he was not held to any legally identifiable standards. Therefore, some of the Secretary's actions are unable to be reviewed by a court of law.

The doctrine is grounded in the federal judiciary's desire to avoid inserting itself into conflicts between branches of the federal government. It is justified by the notion that there exist some questions best resolved through the political process, voters approving or correcting the challenged action by voting for or against those involved in the decision.

The leading Supreme Court case in the area of the political question doctrine is "Baker v. Carr" (1962). In the opinion written for Baker, the Court outlined six characteristics of a political question. These include:

While this is a still rather unsettled doctrine, its application has been settled in a few decided areas. These areas are:

The Guarantee Clause, Article IV, section 4, requires the federal government to "guarantee to every State in this Union a Republican Form of Government". The Supreme Court has declared that this Clause does not imply any set of "judicially manageable standards which a court could utilize independently in order to identify a State's lawful government".

Article I, section 2 of the Constitution states that the House "shall have the sole power of Impeachment", and Article I, section 3 provides that the "Senate shall have the sole Power to try all Impeachments". Since the Constitution placed the sole power of impeachment in two political bodies, it is qualified as a political question. As a result, neither the decision of the House to impeach nor a vote of the Senate to remove a President or any other official can be appealed to any court. 




Important cases discussing the political question doctrine:

The political question doctrine has also had significance beyond American constitutional law. 

Before international courts, the International Court of Justice has dealt with the doctrine in its advisory function, and the European Court of Human Rights has engaged with the doctrine through the margin of appreciation. 

Within European Union law, the Court of Justice of the European Union has never addressed the political question doctrine in its jurisprudence explicitly, yet it has been argued that there are traces of the doctrine present in its rulings. 



</doc>
<doc id="24742" url="https://en.wikipedia.org/wiki?curid=24742" title="Paul Dirac">
Paul Dirac

Paul Adrien Maurice Dirac (; 8 August 1902 – 20 October 1984) was an English theoretical physicist who is regarded as one of the most significant physicists of the 20th century.

Dirac made fundamental contributions to the early development of both quantum mechanics and quantum electrodynamics. Among other discoveries, he formulated the Dirac equation which describes the behaviour of fermions and predicted the existence of antimatter. Dirac shared the 1933 Nobel Prize in Physics with Erwin Schrödinger "for the discovery of new productive forms of atomic theory". He also made significant contributions to the reconciliation of general relativity with quantum mechanics.

Dirac was regarded by his friends and colleagues as unusual in character. In a 1926 letter to Paul Ehrenfest, Albert Einstein wrote of Dirac, "This balancing on the dizzying path between genius and madness is awful."

He was the Lucasian Professor of Mathematics at the University of Cambridge, a member of the Center for Theoretical Studies, University of Miami, and spent the last decade of his life at Florida State University.

Paul Adrien Maurice Dirac was born at his parents' home in Bristol, England, on 8 August 1902, and grew up in the Bishopston area of the city. His father, Charles Adrien Ladislas Dirac, was an immigrant from Saint-Maurice, Switzerland, who worked in Bristol as a French teacher. His mother, Florence Hannah Dirac, Holten, the daughter of a ship's captain, was born in Cornwall, England, and worked as a librarian at the Bristol Central Library. Paul had a younger sister, Béatrice Isabelle Marguerite, known as Betty, and an older brother, Reginald Charles Félix, known as Felix, who committed suicide in March 1925. Dirac later recalled: "My parents were terribly distressed. I didn't know they cared so much [...] I never knew that parents were supposed to care for their children, but from then on I knew."

Charles and the children were officially Swiss nationals until they became naturalised on 22 October 1919. Dirac's father was strict and authoritarian, although he disapproved of corporal punishment. Dirac had a strained relationship with his father, so much so that after his father's death, Dirac wrote, "I feel much freer now, and I am my own man." Charles forced his children to speak to him only in French, in order that they learn the language. When Dirac found that he could not express what he wanted to say in French, he chose to remain silent.

Dirac was educated first at Bishop Road Primary School and then at the all-boys Merchant Venturers' Technical College (later Cotham School), where his father was a French teacher. The school was an institution attached to the University of Bristol, which shared grounds and staff. It emphasised technical subjects like bricklaying, shoemaking and metal work, and modern languages. This was unusual at a time when secondary education in Britain was still dedicated largely to the classics, and something for which Dirac would later express his gratitude.

Dirac studied electrical engineering on a City of Bristol University Scholarship at the University of Bristol's engineering faculty, which was co-located with the Merchant Venturers' Technical College. Shortly before he completed his degree in 1921, he sat for the entrance examination for St John's College, Cambridge. He passed and was awarded a £70 scholarship, but this fell short of the amount of money required to live and study at Cambridge. Despite his having graduated with a first class honours Bachelor of Science degree in engineering, the economic climate of the post-war depression was such that he was unable to find work as an engineer. Instead, he took up an offer to study for a Bachelor of Arts degree in mathematics at the University of Bristol free of charge. He was permitted to skip the first year of the course owing to his engineering degree.

In 1923, Dirac graduated, once again with first class honours, and received a £140 scholarship from the Department of Scientific and Industrial Research. Along with his £70 scholarship from St John's College, this was enough to live at Cambridge. There, Dirac pursued his interests in the theory of general relativity, an interest he had gained earlier as a student in Bristol, and in the nascent field of quantum physics, under the supervision of Ralph Fowler. From 1925 to 1928 he held an 1851 Research Fellowship from the Royal Commission for the Exhibition of 1851. He completed his PhD in June 1926 with the first thesis on quantum mechanics to be submitted anywhere. He then continued his research in Copenhagen and Göttingen.

In 1937, Dirac married Margit Wigner (Eugene Wigner's sister). He adopted Margit's two children, Judith and Gabriel. Paul and Margit Dirac had two children together, both daughters, Mary Elizabeth and Florence Monica.

Margit, known as Manci, visited her brother in 1934 in Princeton, New Jersey, from her native Hungary and, while at dinner at the Annex Restaurant, met the "lonely-looking man at the next table". This account from a Korean physicist, Y. S. Kim, who met and was influenced by Dirac, also says: "It is quite fortunate for the physics community that Manci took good care of our respected Paul A. M. Dirac. Dirac published eleven papers during the period 1939–46... Dirac was able to maintain his normal research productivity only because Manci was in charge of everything else".

Dirac was known among his colleagues for his precise and taciturn nature. His colleagues in Cambridge jokingly defined a unit called a "dirac", which was one word per hour. When Niels Bohr complained that he did not know how to finish a sentence in a scientific article he was writing, Dirac replied, "I was taught at school never to start a sentence without knowing the end of it." He criticised the physicist J. Robert Oppenheimer's interest in poetry: "The aim of science is to make difficult things understandable in a simpler way; the aim of poetry is to state simple things in an incomprehensible way. The two are incompatible."

Dirac himself wrote in his diary during his postgraduate years that he concentrated solely on his research, and stopped only on Sunday when he took long strolls alone.

An anecdote recounted in a review of the 2009 biography tells of Werner Heisenberg and Dirac sailing on an ocean liner to a conference in Japan in August 1929. "Both still in their twenties, and unmarried, they made an odd couple. Heisenberg was a ladies' man who constantly flirted and danced, while Dirac—'an Edwardian geek', as biographer Graham Farmelo puts it—suffered agonies if forced into any kind of socialising or small talk. 'Why do you dance?' Dirac asked his companion. 'When there are nice girls, it is a pleasure,' Heisenberg replied. Dirac pondered this notion, then blurted out: 'But, Heisenberg, how do you know beforehand that the girls are nice?

Margit Dirac told both George Gamow and Anton Capri in the 1960s that her husband had said to a house visitor, "Allow me to present Wigner's sister, who is now my wife."

Another story told of Dirac is that when he first met the young Richard Feynman at a conference, he said after a long silence, "I have an equation. Do you have one too?"

After he presented a lecture at a conference, one colleague raised his hand and said: "I don't understand the equation on the top-right-hand corner of the blackboard". After a long silence, the moderator asked Dirac if he wanted to answer the question, to which Dirac replied: "That was not a question, it was a comment."

Dirac was also noted for his personal modesty. He called the equation for the time evolution of a quantum-mechanical operator, which he was the first to write down, the "Heisenberg equation of motion". Most physicists speak of Fermi–Dirac statistics for half-integer-spin particles and Bose–Einstein statistics for integer-spin particles. While lecturing later in life, Dirac always insisted on calling the former "Fermi statistics". He referred to the latter as "Einstein statistics" for reasons, he explained, of "symmetry".

Heisenberg recollected a conversation among young participants at the 1927 Solvay Conference about Einstein and Planck's views on religion between Wolfgang Pauli, Heisenberg and Dirac. Dirac's contribution was a criticism of the political purpose of religion, which Bohr regarded as quite lucid when hearing it from Heisenberg later. Among other things, Dirac said:
I cannot understand why we idle discussing religion. If we are honest—and scientists have to be—we must admit that religion is a jumble of false assertions, with no basis in reality. The very idea of God is a product of the human imagination. It is quite understandable why primitive people, who were so much more exposed to the overpowering forces of nature than we are today, should have personified these forces in fear and trembling. But nowadays, when we understand so many natural processes, we have no need for such solutions. I can't for the life of me see how the postulate of an Almighty God helps us in any way. What I do see is that this assumption leads to such unproductive questions as why God allows so much misery and injustice, the exploitation of the poor by the rich and all the other horrors He might have prevented. If religion is still being taught, it is by no means because its ideas still convince us, but simply because some of us want to keep the lower classes quiet. Quiet people are much easier to govern than clamorous and dissatisfied ones. They are also much easier to exploit. Religion is a kind of opium that allows a nation to lull itself into wishful dreams and so forget the injustices that are being perpetrated against the people. Hence the close alliance between those two great political forces, the State and the Church. Both need the illusion that a kindly God rewards—in heaven if not on earth—all those who have not risen up against injustice, who have done their duty quietly and uncomplainingly. That is precisely why the honest assertion that God is a mere product of the human imagination is branded as the worst of all mortal sins.

Heisenberg's view was tolerant. Pauli, raised as a Catholic, had kept silent after some initial remarks, but when finally he was asked for his opinion, said: "Well, our friend Dirac has got a religion and its guiding principle is 'There is no God and Paul Dirac is His prophet. Everybody, including Dirac, burst into laughter.

Later in life, Dirac's views towards the idea of God were less acerbic. As an author of an article appearing in the May 1963 edition of "Scientific American", Dirac wrote:
It seems to be one of the fundamental features of nature that fundamental physical laws are described in terms of a mathematical theory of great beauty and power, needing quite a high standard of mathematics for one to understand it. You may wonder: Why is nature constructed along these lines? One can only answer that our present knowledge seems to show that nature is so constructed. We simply have to accept it. One could perhaps describe the situation by saying that God is a mathematician of a very high order, and He used very advanced mathematics in constructing the universe. Our feeble attempts at mathematics enable us to understand a bit of the universe, and as we proceed to develop higher and higher mathematics we can hope to understand the universe better.

In 1971, at a conference meeting, Dirac expressed his views on the existence of God. Dirac explained that the existence of God could only be justified if an improbable event were to have taken place in the past:

It could be that it is extremely difficult to start life. It might be that it is so difficult to start life that it has happened only once among all the planets... Let us consider, just as a conjecture, that the chance life starting when we have got suitable physical conditions is 10. I don't have any logical reason for proposing this figure, I just want you to consider it as a possibility. Under those conditions ... it is almost certain that life would not have started. And I feel that under those conditions it will be necessary to assume the existence of a god to start off life. I would like, therefore, to set up this connexion between the existence of a god and the physical laws: if physical laws are such that to start off life involves an excessively small chance, so that it will not be reasonable to suppose that life would have started just by blind chance, then there must be a god, and such a god would probably be showing his influence in the quantum jumps which are taking place later on. On the other hand, if life can start very easily and does not need any divine influence, then I will say that there is no god.

Dirac did not commit himself to any definite view, but he described the possibilities for answering the question of God in a scientific manner.

Dirac shared the 1933 Nobel Prize for physics with Erwin Schrödinger "for the discovery of new productive forms of atomic theory". Dirac was also awarded the Royal Medal in 1939 and both the Copley Medal and the Max Planck Medal in 1952. He was elected a Fellow of the Royal Society in 1930, an Honorary Fellow of the American Physical Society in 1948, and an Honorary Fellow of the Institute of Physics, London in 1971. He received the inaugural J. Robert Oppenheimer Memorial Prize in 1969. Dirac became a member of the Order of Merit in 1973, having previously turned down a knighthood as he did not want to be addressed by his first name.

In 1984, Dirac died in Tallahassee, Florida, and was buried at Tallahassee's Roselawn Cemetery. Dirac's childhood home in Bristol is commemorated with a blue plaque and the nearby Dirac Road is named in recognition of his links with the city. A commemorative stone was erected in a garden in Saint-Maurice, Switzerland, the town of origin of his father's family, on 1 August 1991. On 13 November 1995 a commemorative marker, made from Burlington green slate and inscribed with the Dirac equation, was unveiled in Westminster Abbey. The Dean of Westminster, Edward Carpenter, had initially refused permission for the memorial, thinking Dirac to be anti-Christian, but was eventually (over a five-year period) persuaded to relent.

Dirac established the most general theory of quantum mechanics and discovered the relativistic equation for the electron, which now bears his name. The remarkable notion of an antiparticle to each fermion particle – e.g. the positron as antiparticle to the electron – stems from his equation. He was the first to develop quantum field theory, which underlies all theoretical work on sub-atomic or "elementary" particles today, work that is fundamental to our understanding of the forces of nature. He proposed and investigated the concept of a magnetic monopole, an object not yet known empirically, as a means of bringing even greater symmetry to James Clerk Maxwell's equations of electromagnetism.

He quantised the gravitational field, and developed a general theory of quantum field theories with dynamical constraints, which forms the basis of the gauge theories and superstring theories of today. The influence and importance of his work have increased with the decades, and physicists use the concepts and equations that he developed daily.

Dirac's first step into a new quantum theory was taken late in September 1925. Ralph Fowler, his research supervisor, had received a proof copy of an exploratory paper by Werner Heisenberg in the framework of the old quantum theory of Bohr and Sommerfeld. Heisenberg leaned heavily on Bohr's correspondence principle but changed the equations so that they involved directly observable quantities, leading to the matrix formulation of quantum mechanics. Fowler sent Heisenberg's paper on to Dirac, who was on vacation in Bristol, asking him to look into this paper carefully.

Dirac's attention was drawn to a mysterious mathematical relationship, at first sight unintelligible, that Heisenberg had reached. Several weeks later, back in Cambridge, Dirac suddenly recognised that this mathematical form had the same structure as the Poisson brackets that occur in the classical dynamics of particle motion. From this thought, he quickly developed a quantum theory that was based on non-commuting dynamical variables. This led him to a more profound and significant general formulation of quantum mechanics than was achieved by any other worker in this field. Dirac's formulation allowed him to obtain the quantisation rules in a novel and more illuminating manner. For this work, published in 1926, Dirac received a PhD from Cambridge. This formed the basis for Fermi-Dirac statistics that applies to systems consisting of many identical spin 1/2 particles (i.e. that obey the Pauli exclusion principle), e.g. electrons in solids and liquids, and importantly to the field of conduction in semi-conductors.

Dirac was famously not bothered by issues of interpretation in quantum theory. In fact, in a paper published in a book in his honour, he wrote: "The interpretation of quantum mechanics has been dealt with by many authors, and I do not want to discuss it here. I want to deal with more fundamental things."

In 1928, building on 2×2 spin matrices which he purported to have discovered independently of Wolfgang Pauli's work on non-relativistic spin systems (Dirac told Abraham Pais, "I believe I got these [matrices] independently of Pauli and possibly Pauli got these independently of me."), he proposed the Dirac equation as a relativistic equation of motion for the wave function of the electron. This work led Dirac to predict the existence of the positron, the electron's antiparticle, which he interpreted in terms of what came to be called the "Dirac sea". The positron was observed by Carl Anderson in 1932. Dirac's equation also contributed to explaining the origin of quantum spin as a relativistic phenomenon.

The necessity of fermions (matter) being created and destroyed in Enrico Fermi's 1934 theory of beta decay led to a reinterpretation of Dirac's equation as a "classical" field equation for any point particle of spin "ħ"/2, itself subject to quantisation conditions involving anti-commutators. Thus reinterpreted, in 1934 by Werner Heisenberg, as a (quantum) field equation accurately describing all elementary matter particles – today quarks and leptons – this Dirac field equation is as central to theoretical physics as the Maxwell, Yang–Mills and Einstein field equations. Dirac is regarded as the founder of quantum electrodynamics, being the first to use that term. He also introduced the idea of vacuum polarisation in the early 1930s. This work was key to the development of quantum mechanics by the next generation of theorists, in particular Schwinger, Feynman, Sin-Itiro Tomonaga and Dyson in their formulation of quantum electrodynamics.

Dirac's "The" "Principles of Quantum Mechanics", published in 1930, is a landmark in the history of science. It quickly became one of the standard textbooks on the subject and is still used today. In that book, Dirac incorporated the previous work of Werner Heisenberg on matrix mechanics and of Erwin Schrödinger on wave mechanics into a single mathematical formalism that associates measurable quantities to operators acting on the Hilbert space of vectors that describe the state of a physical system. The book also introduced the Dirac delta function. Following his 1939 article, he also included the bra–ket notation in the third edition of his book, thereby contributing to its universal use nowadays.

In 1931, Dirac proposed that the existence of a single magnetic monopole in the universe would suffice to explain the quantisation of electrical charge. In 1975, 1982 and 2009, intriguing results suggested the possible detection of magnetic monopoles, but there is, to date, no direct evidence for their existence (see also Searches for magnetic monopoles).

Dirac was the Lucasian Professor of Mathematics at Cambridge from 1932 to 1969. In 1937, he proposed a speculative cosmological model based on the so-called large numbers hypothesis. During World War II, he conducted important theoretical and experimental research on uranium enrichment by gas centrifuge.

Dirac's quantum electrodynamics (QED) made predictions that were – more often than not – infinite and therefore unacceptable. A workaround known as renormalisation was developed, but Dirac never accepted this. "I must say that I am very dissatisfied with the situation", he said in 1975, "because this so-called 'good theory' does involve neglecting infinities which appear in its equations, neglecting them in an arbitrary way. This is just not sensible mathematics. Sensible mathematics involves neglecting a quantity when it is small – not neglecting it just because it is infinitely great and you do not want it!" His refusal to accept renormalisation resulted in his work on the subject moving increasingly out of the mainstream.

However, from his once rejected notes he managed to work on putting quantum electrodynamics on "logical foundations" based on Hamiltonian formalism that he formulated. He found a rather novel way of deriving the anomalous magnetic moment "Schwinger term" and also the Lamb shift, afresh in 1963, using the Heisenberg picture and without using the joining method used by Weisskopf and French, and by the two pioneers of modern QED, Schwinger and Feynman. That was two years before the Tomonaga–Schwinger–Feynman QED was given formal recognition by an award of the Nobel Prize for physics.

Weisskopf and French (FW) were the first to obtain the correct result for the Lamb shift and the anomalous magnetic moment of the electron. At first FW results did not agree with the incorrect but independent results of Feynman and Schwinger. The 1963–1964 lectures Dirac gave on quantum field theory at Yeshiva University were published in 1966 as the Belfer Graduate School of Science, Monograph Series Number, 3. After having relocated to Florida to be near his elder daughter, Mary, Dirac spent his last fourteen years (of both life and physics research) at the University of Miami in Coral Gables, Florida, and Florida State University in Tallahassee, Florida.

In the 1950s in his search for a better QED, Paul Dirac developed the Hamiltonian theory of constraints based on lectures that he delivered at the 1949 International Mathematical Congress in Canada. Dirac had also solved the problem of putting the Schwinger–Tomonaga equation into the Schrödinger representation and given explicit expressions for the scalar meson field (spin zero pion or pseudoscalar meson), the vector meson field (spin one rho meson), and the electromagnetic field (spin one massless boson, photon).

The Hamiltonian of constrained systems is one of Dirac's many masterpieces. It is a powerful generalisation of Hamiltonian theory that remains valid for curved spacetime. The equations for the Hamiltonian involve only six degrees of freedom described by formula_1,formula_2 for each point of the surface on which the state is considered. The formula_3 ("m" = 0, 1, 2, 3) appear in the theory only through the variables formula_4, formula_5 which occur as arbitrary coefficients in the equations of motion.
There are four constraints or weak equations for each point of the surface formula_6 = constant. Three of them formula_7 form the four vector density in the surface. The fourth formula_8 is a 3-dimensional scalar density in the surface "H" ≈ 0; "H" ≈ 0 ("r" = 1, 2, 3)

In the late 1950s, he applied the Hamiltonian methods he had developed to cast Einstein's general relativity in Hamiltonian form and to bring to a technical completion the quantisation problem of gravitation and bring it also closer to the rest of physics according to Salam and DeWitt. In 1959 he also gave an invited talk on "Energy of the Gravitational Field" at the New York Meeting of the American Physical Society later published in 1959 Phys Rev Lett 2, 368. In 1964 he published his "Lectures on Quantum Mechanics" (London: Academic) which deals with constrained dynamics of nonlinear dynamical systems including quantisation of curved spacetime. He also published a paper entitled "Quantization of the Gravitational Field" in the 1967 ICTP/IAEA Trieste Symposium on Contemporary Physics.

From September 1970 to January 1971, Dirac was Visiting Professor at Florida State University in Tallahassee. During that time he was offered a permanent position there, which he accepted, becoming a full professor in 1972. Contemporary accounts of his time there describe it as happy except that he apparently found the summer heat oppressive and liked to escape from it to Cambridge.

He would walk about a mile to work each day and was fond of swimming in one of the two nearby lakes (Silver Lake and Lost Lake), and was also more sociable than he had been at Cambridge, where he mostly worked at home apart from giving classes and seminars; at FSU he would usually eat lunch with his colleagues before taking a nap.

Dirac published over 60 papers in those last twelve years of his life, including a short book on general relativity. His last paper (1984), entitled "The inadequacies of quantum field theory," contains his final judgment on quantum field theory;

"These rules of renormalisation give surprisingly, excessively good agreement with experiments. Most physicists say that these working rules are, therefore, correct. I feel that is not an adequate reason. Just because the results happen to be in agreement with observation does not prove that one's theory is correct."

The paper ends with these words;

"I have spent many years searching for a Hamiltonian to bring into the theory and have not yet found it. I shall continue to work on it as long as I can and other people, I hope, will follow along such lines."

Amongst his many students were Homi J. Bhabha, Fred Hoyle and John Polkinghorne. Polkinghorne recalls that Dirac "was once asked what was his fundamental belief. He strode to a blackboard and wrote that the laws of nature should be expressed in beautiful equations."

In 1975, Dirac gave a series of five lectures at the University of New South Wales which were subsequently published as a book, "Directions in Physics" (1978). He donated the royalties from this book to the university for the establishment of the Dirac Lecture Series. The Silver Dirac Medal for the Advancement of Theoretical Physics is awarded by the University of New South Wales to commemorate the lecture.

Immediately after his death, two organisations of professional physicists established annual awards in Dirac's memory. The Institute of Physics, the United Kingdom's professional body for physicists, awards the Paul Dirac Medal for "outstanding contributions to theoretical (including mathematical and computational) physics". The first three recipients were Stephen Hawking (1987), John Stewart Bell (1988), and Roger Penrose (1989). The International Centre for Theoretical Physics awards the Dirac Medal of the ICTP each year on Dirac's birthday (8 August).

The Dirac-Hellman Award at Florida State University was endowed by Dr Bruce P. Hellman in 1997 to reward outstanding work in theoretical physics by FSU researchers. The Paul A.M. Dirac Science Library at Florida State University, which Manci opened in December 1989, is named in his honour, and his papers are held there. Outside is a statue of him by Gabriella Bollobás. The street on which the National High Magnetic Field Laboratory in Innovation Park of Tallahassee, Florida, is located is named Paul Dirac Drive. As well as in his hometown of Bristol, there is also a road named after him, Dirac Place, in Didcot, Oxfordshire. The BBC named a video codec, Dirac, in his honour.
An asteroid discovered in 1983 was named after Dirac. The Distributed Research utilising Advanced Computing (DiRAC) and Dirac software are named in his honour.





</doc>
<doc id="24743" url="https://en.wikipedia.org/wiki?curid=24743" title="Pessimism">
Pessimism

Pessimism is a negative or depressed mental attitude in which an undesirable outcome is anticipated from a given situation. Pessimists tend to focus on the negatives of life in general. A common question asked to test for pessimism is "Is the glass half empty or half full?"; in this situation a pessimist is said to see the glass as half empty, while an optimist is said to see the glass as half full. Throughout history, the pessimistic disposition has had effects on all major areas of thinking.

Philosophical pessimism is the related idea that views the world in a strictly anti-optimistic fashion. This form of pessimism is not an emotional disposition as the term commonly connotes. Instead, it is a philosophy or worldview that directly challenges the notion of progress and what may be considered the faith-based claims of optimism. Philosophical pessimists are often existential nihilists believing that life has no intrinsic meaning or value. Their responses to this condition, however, are widely varied and often life-affirming.

The term pessimism derives from the Latin word "pessimus" meaning 'the worst'. It was first used by Jesuit critics of Voltaire's 1759 novel 'Candide, ou l'Optimisme'. Voltaire was satirizing the philosophy of Leibniz who maintained that this was the 'best (optimum) of all possible worlds'. In their attacks on Voltaire, the Jesuits of the "Revue de Trévoux" accused him of "pessimisme".

Philosophical pessimism is not a state of mind or a psychological disposition, but rather it is a worldview or ethic that seeks to face up to perceived distasteful realities of the world and eliminate irrational hopes and expectations (such as the Idea of Progress and religious faith) which may lead to undesirable outcomes. Ideas which prefigure philosophical pessimism can be seen in ancient texts such as the Dialogue of Pessimism and Ecclesiastes (which maintains that everything is "hevel", literally 'vapor' or 'breath', but could also mean 'senseless' and 'absurd'.)

In Western philosophy, philosophical pessimism is not a single coherent movement, but rather a loosely associated group of thinkers with similar ideas and a family resemblance to each other. In "Pessimism: Philosophy, Ethic, Spirit", Joshua Foa Dienstag outlines the main propositions shared by most philosophical pessimists as "that time is a burden; that the course of history is in some sense ironic; that freedom and happiness are incompatible; and that human existence is absurd."

Philosophical pessimists see the self-consciousness of man as bound up with his consciousness of time and that this leads to greater suffering than mere physical pain. While many organisms live in the present, humans and certain species of animals can contemplate the past and future, and this is an important difference. Human beings have foreknowledge of their own eventual fate and this "terror" is present in every moment of our lives as a reminder of the impermanent nature of life and of our inability to control this change.

The philosophical pessimistic view of the effect of historical progress tends to be more negative than positive. The philosophical pessimist does not deny that certain areas like science can "progress" but they deny that this has resulted in an overall improvement of the human condition. In this sense it could be said that the pessimist views history as ironic; while seemingly getting better, it is mostly in fact not improving at all, or getting worse. This is most clearly seen in Rousseau's critique of enlightenment civil society and his preference for man in the primitive and natural state. For Rousseau, "our souls have become corrupted to the extent that our sciences and our arts have advanced towards perfection".

The pessimistic view of the human condition is that it is in a sense "absurd". Absurdity is seen as an ontological mismatch between our desire for meaning and fulfillment and our inability to find or sustain those things in the world, or as Camus puts it: "a divorce between man and his life, the actor and his setting". The idea that rational thought would lead to human flourishing can be traced to Socrates and is at the root of most forms of western optimistic philosophies. Pessimism turns the idea on its head; it faults the human freedom to reason as the feature that misaligned humanity from our world and sees it as the root of human unhappiness.

The responses to this predicament of the human condition by pessimists are varied. Some philosophers, such as Schopenhauer and Mainländer, recommend a form of resignation and self-denial (which they saw exemplified in Indian religions and Christian monasticism). Some followers tend to believe that "expecting the worst leads to the best." Rene Descartes even believed that life was better if emotional reactions to "negative" events were removed. Karl Robert Eduard von Hartmann asserted that with cultural and technological progress, the world and its inhabitants will reach a state in which they will voluntarily embrace nothingness. Others like Nietzsche, Leopardi, Julius Bahnsen and Camus respond with a more life-affirming view, what Nietzsche called a "Dionysian pessimism", an embrace of life as it is in all of its constant change and suffering, without appeal to progress or hedonistic calculus. Albert Camus indicated that the common responses to the absurdity of life are often: Suicide, a leap of faith (as per Kierkegaard's knight of faith), or recognition/rebellion. Camus rejected all but the last option as unacceptable and inauthentic responses.

Philosophical pessimism has often been tied to the arts and literature. Schopenhauer's philosophy was very popular with composers (Wagner, Brahms and Mahler). While there are earlier examples of literary pessimism, such as in the work of Miguel de Cervantes, several philosophical pessimists also wrote novels or poetry (Camus and Leopardi respectively). A distinctive literary form which has been associated with pessimism is aphoristic writing, and this can be seen in Leopardi, Nietzsche and Cioran. Nineteenth and twentieth-century writers which could be said to express pessimistic views in their works or to be influenced by pessimistic philosophers include Charles Baudelaire, Samuel Beckett, Gottfried Benn, Jorge Luis Borges, Charles Bukowski, Dino Buzzati, Lord Byron, Louis-Ferdinand Céline, Joseph Conrad, Fyodor Dostoyevsky, Mihai Eminescu, Sadegh Hedayat, H. P. Lovecraft, Thomas Mann, and Camilo Pessanha. Late-twentieth and twenty-first century authors who could be said to express or explore philosophical pessimism include Thomas Bernhard, Friedrich Dürrenmatt, John Gray, Michel Houellebecq, Alexander Kluge, Thomas Ligotti, Cormac McCarthy, Eugene Thacker, and Peter Wessel Zapffe.

In "Philosophy in the Tragic Age of the Greeks", Friedrich Nietzsche argued that the pre-Socratic philosophers such as Anaximander, Heraclitus (called "the Weeping Philosopher") and Parmenides represented a classical form of pessimism. Nietzsche saw Anaximander's philosophy as the "enigmatic proclamation of a true pessimist". Similarly, of Heraclitus' philosophy of flux and strife he wrote:
Heraclitus denied the duality of totally diverse worlds—a position which Anaximander had been compelled to assume. He no longer distinguished a physical world from a metaphysical one, a realm of definite qualities from an undefinable "indefinite." And after this first step, nothing could hold him back from a second, far bolder negation: he altogether denied being. For this one world which he retained [...] nowhere shows a tarrying, an indestructibility, a bulwark in the stream. Louder than Anaximander, Heraclitus proclaimed: "I see nothing other than becoming. Be not deceived. It is the fault of your short-sightedness, not of the essence of things, if you believe you see land somewhere in the ocean of becoming and passing-away. You use names for things as though they rigidly, persistently endured; yet even the stream into which you step a second time is not the one you stepped into before." "The Birth of Tragedy. 5, pp. 51–52" 
Another Greek expressed a form of pessimism in his philosophy: the ancient Cyrenaic philosopher Hegesias (290 BCE). Like later pessimists, Hegesias argued that lasting happiness is impossible to achieve and that all we can do is to try to avoid pain as much as possible.
Complete happiness cannot possibly exist; for that the body is full of many sensations, and that the mind sympathizes with the body, and is troubled when that is troubled, and also that fortune prevents many things which we cherished in anticipation; so that for all these reasons, perfect happiness eludes our grasp.
Hegesias held that all external objects, events and actions are indifferent to the wise man, even death: "for the foolish person it is expedient to live, but to the wise person it is a matter of indifference". According to Cicero, Hegesias wrote a book called "Death by Starvation", which supposedly persuaded many people that death was more desirable than life. Because of this, Ptolemy II Philadelphus banned Hegesias from teaching in Alexandria.

From the 3rd century BCE, Stoicism propounded as an exercise "the premeditation of evils"—concentration on worst possible outcomes.

Schopenhauer engaged extensively with the works of Baltasar Gracián (1601–1658) and considered Gracián's novel "El Criticón" "Absolutely unique... a book made for constant use...a companion for life" for "those who wish to prosper in the great world." Schopenhauer's pessimistic outlook was influenced by Gracián, and he translated Gracián's "The Pocket Oracle and Art of Prudence" into German. He praised Gracián for his aphoristic writing style (conceptismo) and often quoted him in his works. Gracian's novel "El Criticón" (The Critic) is an extended allegory of the human search for happiness which turns out to be fruitless on this Earth. "The Critic" paints a bleak and desolate picture of the human condition. His "Pocket Oracle" was a book of aphorisms on how to live in what he saw as a world filled with deception, duplicity and disillusionment.

Voltaire was the first European to be labeled as a pessimist due to his critique of Alexander Pope's optimistic "An Essay on Man", and Leibniz' affirmation that "we live in the best of all possible worlds." Voltaire's novel Candide is an extended criticism of theistic optimism and his Poem on the Lisbon Disaster is especially pessimistic about the state of mankind and the nature of God. Though himself a Deist, Voltaire argued against the existence of a compassionate personal God through his interpretation of the problem of evil.

The major themes of philosophical pessimism were first presented by Rousseau and he has been called "the patriarch of pessimism". For Rousseau, humans in their "natural goodness" have no sense of self-consciousness in time and thus are happier than humans corrupted by society. Rousseau saw the movement out of the state of nature as the origin of inequality and mankind's lack of freedom. The wholesome qualities of man in his natural state, a non-destructive love of self and compassion are gradually replaced by "amour propre", a self-love driven by pride and jealousy of his fellow man. Because of this, modern man lives "always outside himself", concerned with other men, the future and external objects. Rousseau also blames the human faculty of "perfectibility" and human language for tearing us away from our natural state by allowing us to imagine a future in which we are different than what we are now and therefore making us appear inadequate to ourselves (and thus 'perfectible').

Rousseau saw the evolution of modern society as the replacement of natural egalitarianism by alienation and class distinction enforced by institutions of power. Thus "The Social Contract" opens with the famous phrase "Man is born free, and everywhere he is in chains." Even the ruling classes are not free, in fact for Rousseau they are "greater slaves" because they require more esteem from others to rule and must therefore constantly live "outside themselves".

Though a lesser known figure outside Italy, Giacomo Leopardi was highly influential in the 19th century, especially for Schopenhauer and Nietzsche. In Leopardi's darkly comic essays, aphorisms, fables and parables, life is often described as a sort of divine joke or mistake. According to Leopardi, because of our conscious sense of time and our endless search for truth, the human desire for happiness can never be truly satiated and joy cannot last. Leopardi claims that "Therefore they greatly deceive themselves, [those] who declare and preach that the perfection of man consists in knowledge of the truth and that all his woes proceed from false opinions and ignorance, and that the human race will at last be happy, when all or most people come to know the truth, and solely on the grounds of that arrange and govern their lives." Furthermore, Leopardi believes that for man it is not possible to forget truth and that "it is easier to rid oneself of any habit before that of philosophizing."

Leopardi's response to this condition is to face up to these realities and try to live a vibrant and great life, to be risky and take up uncertain tasks. This uncertainty makes life valuable and exciting but does not free us from suffering, it is rather an abandonment of the futile pursuit of happiness. He uses the example of Christopher Columbus who went on a dangerous and uncertain voyage and because of this grew to appreciate life more fully. Leopardi also sees the capacity of humans to laugh at their condition as a laudable quality that is able to help us deal with our predicament. For Leopardi: "He who has the courage to laugh is master of the world, much like him who is prepared to die."

Arthur Schopenhauer's pessimism comes from his elevating of Will above reason as the mainspring of human thought and behavior. The Will is the ultimate metaphysical animating noumenon and it is futile, illogical and directionless striving. Schopenhauer sees reason as weak and insignificant compared to Will; in one metaphor, Schopenhauer compares the human intellect to a lame man who can see, but who rides on the shoulder of the blind giant of Will. Schopenhauer saw human desires as impossible to satisfy. 
He pointed to motivators such as hunger, thirst and sexuality as the fundamental features of the Will in action, which are always by nature unsatisfactory.

All satisfaction, or what is commonly called happiness, is really and essentially always "negative" only, and never positive. It is not a gratification which comes to us originally and of itself, but it must always be the satisfaction of a wish. For desire, that is to say, want, is the precedent condition of every pleasure; but with the satisfaction, the desire and therefore the pleasure cease; and so the satisfaction or gratification can never be more than deliverance from a pain, from a want. Such is not only every actual and evident suffering, but also every desire whose importunity disturbs our peace, and indeed even the deadening boredom that makes existence a burden to us.

Schopenhauer notes that once satiated, the feeling of satisfaction rarely lasts and we spend most of our lives in a state of endless striving; in this sense we are, deep down, nothing but Will. Even the moments of satisfaction, when repeated often enough, only lead to boredom and thus human existence is constantly swinging "like a pendulum to and fro between pain and boredom, and these two are in fact its ultimate constituents". This ironic cycle eventually allows us to see the inherent vanity at the truth of existence ("nichtigkeit") and to realize that "the purpose of our existence is not to be happy".

Moreover, the business of biological life is a war of all against all filled with constant physical pain and distress, not merely unsatisfied desires. There is also the constant dread of death on the horizon to consider, which makes human life worse than animals. Reason only compounds our suffering by allowing us to realize that biology's agenda is not something we would have chosen had we been given a choice, but it is ultimately helpless to prevent us from serving it.

Schopenhauer saw in artistic contemplation a temporary escape from the act of willing. He believed that through "losing yourself" in art one could sublimate the Will. However, he believed that only a resignation from the pointless striving of the will to life through a form of asceticism (as those practiced by eastern monastics and by "saintly persons") could free oneself from the Will altogether.

Schopenhauer never used the term "pessimism" to describe his philosophy but he also didn't object when others called it that. Other common terms used to describe his thought were voluntarism and irrationalism which he also never used.

During the endtimes of Schopenhauer's life and subsequent years after his death, post-Schopenhauerian pessimism became a rather popular "trend" in 19th century Germany. Nevertheless, it was viewed with disdain by the other popular philosophies at the time, such as Hegelianism, materialism, neo-Kantianism and the emerging positivism. In an age of upcoming revolutions and exciting new discoveries in science, the resigned and a-progressive nature of the typical pessimist was seen as detriment to social development. To respond to this growing criticism, a group of philosophers greatly influenced by Schopenhauer (indeed, some even being his personal acquaintances) developed their own brand of pessimism, each in their own unique way. Thinkers such as Julius Bahnsen, Karl Robert Eduard von Hartmann, Philipp Mainländer and others cultivated the ever-increasing threat of pessimism by converting Schopenhauer's transcendental idealism into what Frederick C. Beiser calls transcendental realism. The transcendental idealist thesis is that we know only the appearances of things (not things-in-themselves); the transcendental realist thesis is that "the knowledge we have of how things appear to us in experience gives us knowledge of things-in-themselves."

By espousing transcendental realism, Schopenhauer's own dark observations about the nature of the world would become completely knowable and objective, and in this way they would attain certainty. The certainty of pessimism being, that non-existence is preferable to existence. That, along with the metaphysical reality of the will, were the premises which the "post-Schopenhauerian" thinkers inherited from the Frankfurt sage's teachings. After this common starting point, each philosopher developed his own negative view of being in their respective philosophies. Some pessimists would "assuage" the critics by accepting the validity of their criticisms and embracing historicism, as was the case with Schopenhauer's literary executor Julius Frauenstadt and with Karl Robert Eduard von Hartmann (who gave transcendental realism a unique twist). Julius Bahnsen would reshape the understanding of pessimism overall, while Philipp Mainländer set out to reinterpret and elucidate the nature of the will, by presenting it as a self-mortifying will-to-death.

Friedrich Nietzsche could be said to be a philosophical pessimist even though unlike Schopenhauer (whom he read avidly) his response to the 'tragic' pessimistic view is neither resigned nor self-denying, but a life-affirming form of pessimism. For Nietzsche this was a "pessimism of the future", a "Dionysian pessimism." Nietzsche identified his Dionysian pessimism with what he saw as the pessimism of the Greek pre-socratics and also saw it at the core of ancient Greek tragedy. He saw tragedy as laying bare the terrible nature of human existence, bound by constant flux. In contrast to this Nietzsche saw Socratic philosophy as an optimistic refuge of those who could not bear the tragic any longer. Since Socrates posited that wisdom could lead to happiness, Nietzsche saw this as "morally speaking, a sort of cowardice...amorally, a ruse". Nietzsche was also critical of Schopenhauer's pessimism because in judging the world negatively, it turned to moral judgements about the world and therefore led to weakness and nihilism. Nietzsche's response was a total embracing of the nature of the world, a "great liberation" through a "pessimism of strength" which "does not sit in judgement of this condition". Nietzsche believed that the task of the philosopher was to wield this pessimism like a hammer, to first attack the basis of old moralities and beliefs and then to "make oneself a new pair of wings", i.e. to re-evaluate all values and create new ones. A key feature of this Dionysian pessimism was 'saying yes' to the changing nature of the world, this entailed embracing destruction and suffering joyfully, forever (hence the ideas of amor fati and eternal recurrence). Pessimism for Nietzsche is an art of living that is "good for one's health" as a "remedy and an aid in the service of growing and struggling life".

In a 1945 article, Albert Camus wrote "the idea that a pessimistic philosophy is necessarily one of discouragement is a puerile idea." Camus helped popularize the idea of "the absurd", a key term in his famous essay "The Myth of Sisyphus". Like previous philosophical pessimists, Camus sees human consciousness and reason as that which "sets me in opposition to all creation". For Camus, this clash between a reasoning mind which craves meaning and a 'silent' world is what produces the most important philosophical problem, the 'problem of suicide'. Camus believed that people often escape facing the absurd through "eluding" ("l'esquive"), a 'trickery' for "those who live not for life itself but some great idea that will transcend it, refine it, give it a meaning, and betray it". He considered suicide and religion as inauthentic forms of eluding or escaping the problem of existence. For Camus, the only choice was to rebelliously accept and live with the absurd, for "there is no fate that cannot be surmounted by scorn." Camus' response to the absurd problem is illustrated by using the Greek mythic character of Sisyphus, who was condemned by the gods to push a boulder up a hill for eternity. Camus imagines Sisyphus while pushing the rock, realizing the futility of his task, but doing it anyway out of rebellion: "One must imagine Sisyphus happy."

There are several theories of epistemology which could arguably be said to be pessimistic in the sense that they consider it difficult or even impossible to obtain knowledge about the world. These ideas are generally related to nihilism, philosophical skepticism and relativism.

Friedrich Heinrich Jacobi (1743–1819), analyzed rationalism, and in particular Immanuel Kant's "critical" philosophy in order to carry out a reductio ad absurdum according to which all rationalism reduces to nihilism, and thus it should be avoided and replaced with a return to some type of faith and revelation.

Richard Rorty, Michel Foucault, and Ludwig Wittgenstein questioned whether our particular concepts could relate to the world in any absolute way and whether we can justify our ways of describing the world as compared with other ways. In general, these philosophers argue that truth was not about getting it right or representing reality, but was part of subjective social relations of power, or language-games that served our purposes in a particular time. Therefore, these forms of anti-foundationalism, while not being pessimistic per se, rejects any definitions that claims to have discovered absolute 'truths' or foundational facts about the world as valid.

Philosophical pessimism stands opposed to the optimism or even utopianism of Hegelian philosophies. Emil Cioran claimed "Hegel is chiefly responsible for modern optimism. How could he have failed to see that consciousness changes only its forms and modalities, but never progresses?" Philosophical pessimism is differentiated from other political philosophies by having no ideal governmental structure or political project, rather pessimism generally tends to be an anti-systematic philosophy of individual action. This is because philosophical pessimists tend to be skeptical that any politics of social progress can actually improve the human condition. As Cioran states, "every step forward is followed by a step back: this is the unfruitful oscillation of history". Cioran also attacks political optimism because it creates an "idolatry of tomorrow" which can be used to authorize anything in its name. This does not mean however, that the pessimist cannot be politically involved, as Camus argued in The Rebel.

There is another strain of thought generally associated with a pessimistic worldview, this is the pessimism of cultural criticism and social decline which is seen in Oswald Spengler's 'The Decline of the West'. Spengler promoted a cyclic model of history similar to the theories of Giambattista Vico. Spengler believed modern western civilization was in the 'winter' age of decline ("untergang"). Spenglerian theory was immensely influential in interwar Europe, especially in Weimar Germany. Similarly, traditionalist Julius Evola thought that the world was in the Kali Yuga, a dark age of moral decline.

Intellectuals like Oliver James correlate economic progress with economic inequality, the stimulation of artificial needs, and affluenza. Anti-consumerists identify rising trends of conspicuous consumption and self-interested, image-conscious behavior in culture. Post-modernists like Jean Baudrillard have even argued that culture (and therefore our lives) now has no basis in reality whatsoever.

Conservative thinkers, especially social conservatives, often perceive politics in a generally pessimistic way. William F. Buckley famously remarked that he was "standing athwart history yelling 'stop!'" and Whittaker Chambers was convinced that capitalism was bound to fall to communism, though he was himself violently anti-communist. Social conservatives often see the West as a decadent and nihilistic civilization which has abandoned its roots in Christianity and/or Greek philosophy, leaving it doomed to fall into moral and political decay. Robert Bork's "Slouching Toward Gomorrah" and Allan Bloom's "The Closing of the American Mind" are famous expressions of this point of view.

Many economic conservatives and libertarians believe that the expansion of the state and the role of government in society is inevitable, and they are at best fighting a holding action against it. They hold that the natural tendency of people is to be ruled and that freedom is an exceptional state of affairs which is now being abandoned in favor of social and economic security provided by the welfare state. Political pessimism has sometimes found expression in dystopian novels such as George Orwell's "Nineteen Eighty-Four". Political pessimism about one's country often correlates with a desire to emigrate.

During the financial crisis of 2007–08 in the United States, the neologism "pessimism porn" was coined to describe the alleged eschatological and survivalist thrill some people derive from predicting, reading and fantasizing about the collapse of civil society through the destruction of the world's economic system.

Technological pessimism is the belief that advances in science and technology do not lead to an improvement in the human condition. Technological pessimism can be said to have originated during the industrial revolution with the Luddite movement. Luddites blamed the rise of industrial mills and advanced factory machinery for the loss of their jobs and set out to destroy them. The Romantic movement was also pessimistic towards the rise of technology and longed for simpler and more natural times. Poets like William Wordsworth and William Blake believed that industrialization was polluting the purity of nature.

Some social critics and environmentalists believe that globalization, overpopulation and the economic practices of modern capitalist states over-stress the planet's ecological equilibrium. They warn that unless something is done to slow this, climate change will worsen eventually leading to some form of social and ecological collapse. James Lovelock believes that the ecology of the Earth has already been irretrievably damaged, and even an unrealistic shift in politics would not be enough to save it. According to Lovelock, the Earth’s climate regulation system is being overwhelmed by pollution and the Earth will soon jump from its current state into a dramatically hotter climate. Lovelock blames this state of affairs on what he calls “polyanthroponemia”, which is when: “humans overpopulate until they do more harm than good.” Lovelock states:

The presence of 7 billion people aiming for first-world comforts…is clearly incompatible with the homeostasis of climate but also with chemistry, biological diversity and the economy of the system.

Some radical environmentalists, anti-globalization activists, and Neo-luddites can be said to hold to this type of pessimism about the effects of modern "progress". A more radical form of environmental pessimism is anarcho-primitivism which faults the agricultural revolution with giving rise to social stratification, coercion, and alienation. Some anarcho-primitivists promote deindustrialization, abandonment of modern technology and rewilding.

An infamous anarcho-primitivist is Theodore Kaczynski, also known as the Unabomber who engaged in a nationwide mail bombing campaign. In his 1995 manifesto, "Industrial Society and Its Future" he called attention to the erosion of human freedom by the rise of the modern "industrial-technological system". The manifesto begins thus: The Industrial Revolution and its consequences have been a disaster for the human race. They have greatly increased the life-expectancy of those of us who live in “advanced” countries, but they have destabilized society, have made life unfulfilling, have subjected human beings to indignities, have led to widespread psychological suffering (in the Third World to physical suffering as well) and have inflicted severe damage on the natural world. The continued development of technology will worsen the situation. It will certainly subject human beings to greater indignities and inflict greater damage on the natural world, it will probably lead to greater social disruption and psychological suffering, and it may lead to increased physical suffering even in “advanced” countries.

One of the most radical pessimist organizations is the voluntary human extinction movement which argues for the extinction of the human race through antinatalism.

Pope Francis' controversial 2015 encyclical on ecological issues is ripe with pessimistic assessments of the role of technology in the modern world.

'Entropy pessimism' represents a special case of technological and environmental pessimism, based on thermodynamic principles. According to the first law of thermodynamics, matter and energy is neither created nor destroyed in the economy. According to the second law of thermodynamics — also known as the entropy law — what happens in the economy is that all matter and energy is transformed from states available for human purposes (valuable natural resources) to states unavailable for human purposes (valueless waste and pollution). In effect, all of man's technologies and activities are only speeding up the general march against a future planetary 'heat death' of degraded energy, exhausted natural resources and a deteriorated environment — a state of maximum entropy locally on earth; 'locally' on earth, that is, when compared to the heat death of the universe, taken as a whole.

The term 'entropy pessimism' was coined to describe the work of Romanian American economist Nicholas Georgescu-Roegen, a progenitor in economics and the paradigm founder of ecological economics. Georgescu-Roegen made extensive use of the entropy concept in his magnum opus on "The Entropy Law and the Economic Process". Since the 1990s, leading ecological economist and steady-state theorist Herman Daly — a student of Georgescu-Roegen — has been the economists profession's most influential proponent of entropy pessimism.

Among other matters, the entropy pessimism position is concerned with the existential impossibility of allocating earth's finite stock of mineral resources evenly among an unknown number of present and future generations. This number of generations is likely to remain unknown to us, as there is no way — or only little way — of knowing in advance if or when mankind will ultimately face extinction. In effect, "any" conceivable intertemporal allocation of the stock will inevitably end up with universal economic decline at some future point. 

Entropy pessimism is a widespread view in ecological economics and in the degrowth movement.

Bibas writes that some criminal defense attorneys prefer to err on the side of pessimism: "Optimistic forecasts risk being proven disastrously wrong at trial, an embarrassing result that makes clients angry. On the other hand, if clients plead based on their lawyers' overly pessimistic advice, the cases do not go to trial and the clients are none the wiser."

In the ancient world, psychological pessimism was associated with melancholy, and was believed to be caused by an excess of black bile in the body. 
The study of pessimism has parallels with the study of depression. Psychologists trace pessimistic attitudes to emotional pain or even biology. Aaron Beck argues that depression is due to unrealistic negative views about the world. Beck starts treatment by engaging in conversation with clients about their unhelpful thoughts. Pessimists, however, are often able to provide arguments that suggest that their understanding of reality is justified; as in Depressive realism or (pessimistic realism). Deflection is a common method used by those who are depressed. They let people assume they are revealing everything which proves to be an effective way of hiding. The pessimism item on the Beck Depression Inventory has been judged useful in predicting suicides. The Beck Hopelessness Scale has also been described as a measurement of pessimism.

Wender and Klein point out that pessimism can be useful in some circumstances: "If one is subject to a series of defeats, it pays to adopt a conservative game plan of sitting back and waiting and letting others take the risks. Such waiting would be fostered by a pessimistic outlook. Similarly if one is raking in the chips of life, it pays to adopt an expansive risk taking approach, and thus maximize access to scarce resources."

Through history, some have concluded that a pessimistic attitude, although justified, must be avoided in order to endure. Optimistic attitudes are favored and of emotional consideration. Al-Ghazali and William James rejected their pessimism after suffering psychological, or even psychosomatic illness. Criticisms of this sort however assume that pessimism leads inevitably to a mood of darkness and utter depression. Many philosophers would disagree, claiming that the term "pessimism" is being abused. The link between pessimism and nihilism is present, but the former does not necessarily lead to the latter, as philosophers such as Albert Camus believed. Happiness is not inextricably linked to optimism, nor is pessimism inextricably linked to unhappiness. One could easily imagine an unhappy optimist, and a happy pessimist. Accusations of pessimism may be used to silence legitimate criticism. The economist Nouriel Roubini was largely dismissed as a pessimist, for his dire but accurate predictions of a coming global financial crisis, in 2006. "Personality Plus" opines that pessimistic temperaments (e.g. melancholy and phlegmatic) can be useful inasmuch as pessimists' focus on the negative helps them spot problems that people with more optimistic temperaments (e.g. choleric and sanguine) miss.




</doc>
<doc id="24744" url="https://en.wikipedia.org/wiki?curid=24744" title="Peter Wessel Zapffe">
Peter Wessel Zapffe

Peter Wessel Zapffe (December 18, 1899 – October 12, 1990) was a Norwegian metaphysician, author, lawyer and mountaineer. He is often noted for his philosophically pessimistic and fatalistic view of human existence—his system of philosophy in line with the work of the earlier philosopher Arthur Schopenhauer, by whom he was inspired—as well as his firm advocacy of antinatalism. His thoughts regarding the error of human life are presented in the essay "The Last Messiah" (Norwegian: "Den sidste Messias", 1933). This essay is a shorter version of his best-known work, the philosophical treatise "On the Tragic" ("Om det tragiske", 1941).

Zapffe's view is that humans are born with an overdeveloped skill (understanding, self-knowledge) which does not fit into nature's design. The human craving for justification on matters such as life and death cannot be satisfied, hence humanity has a need that nature cannot satisfy. The tragedy, following this theory, is that humans spend all their time trying not to be human. The human being, therefore, is a paradox.

In "The Last Messiah" Zapffe described four principal defense mechanisms that humankind uses to avoid facing this paradox:


Zapffe was a prolific mountaineer and took a very early interest in environmentalism. This form of nature conservationism sprung from the intent, not of protecting nature, but to avoid human culturalization of nature. He is the author of many humorous short stories about climbing and other adventures in nature.

Zapffe married twice. He remained married to his second wife Berit Zapffe until his death in 1990. Berit died in May 2008. Zapffe remained childless by choice.







</doc>
<doc id="24745" url="https://en.wikipedia.org/wiki?curid=24745" title="Franc Poincaré">
Franc Poincaré

The Franc Poincaré is a unit of account that was used in the international regulation of liability. It is defined as 65.5 milligrams of gold of millesimal fineness .900. Formerly it was identical to the French franc, although it has not been so since the 1920s.

Practice on its conversion to national currencies varies from state to state; in most states the conversion factor is based not on the market price of gold, but on an official price (a remnant of the gold standard, frequently far below its market price today). The Franc Poincaré has been replaced for most purposes by special drawing rights.

Conventions which used the Franc Poincaré included the Convention for the Unification of Certain Rules Relating to International Carriage by Air, the International Convention on Civil Liability for Oil Pollution Damage and the International Convention on the Establishment of an International Fund for Compensation for Oil Pollution Damage.


</doc>
<doc id="24746" url="https://en.wikipedia.org/wiki?curid=24746" title="PCX">
PCX

PCX, standing for "PiCture eXchange", is an image file format developed by the now-defunct ZSoft Corporation of Marietta, Georgia, United States. It was the native file format for PC Paintbrush and became one of the first widely accepted DOS imaging standards, although it has since been succeeded by more sophisticated image formats, such as BMP, JPEG, and PNG. PCX files commonly stored palette-indexed images ranging from 2 or 4 colors to 16 and 256 colors, although the format has been extended to record true-color (24-bit) images as well.

PCX was designed during the early development of PC display hardware and most of the formats it supported are no longer used, Table A shows a list of the most commonly used PCX formats. Contemporary image editing programs may not read PCX files that match older hardware.

PCX is supported by common image processing software including ACDSee, GIMP, ImageMagick, IrfanView, LView, Netpbm, PaintShop Pro, Photoshop, Visio, PMview, XnView and GraphicConverter. In version 2.1.4 FFmpeg could encode and decode the PCX pixel formats "rgb24, rgb8, bgr8, rgb4_byte, bgr4_byte, gray, pal8," and "monob".

There is a multi-page version of PCX, used by some computer fax and document management programs, with file extension codice_1. A DCX file consists of a header introducing a set of following PCX files.

PCX files were designed for use on IBM-compatible PCs and always use little endian byte ordering. A PCX file has three main sections, in the following order

The PCX file header contains an identifier byte (value 10), a version number, image dimensions, 16 palette colors, number color planes, bit depth of each plane, and a value for compression method. PCX version numbers range from 0 to 5, this originally denoted the version of the PC Paintbrush program used to create the PCX file. The header always has space for 16 colors though the number of colors used depends upon the bit depth of the image. The header is 74 bytes long and the image data begins 128 bytes after the start of the file, the 54 bytes between are not used. The header is composed of 18 fields:

All PCX files use the same compression scheme and the compression value is always 1. No other values have been defined and there are no uncompressed PCX files. One source claims that 0 (uncompressed) is "allowed, but not much software supports it".

PCX image data is stored in rows or scan lines in top-down order. If the image has multiple planes, these are stored by plane within row, such that all the red data for row 0 are followed by all the green data for row 0, then all the blue data, then alpha data. This pattern is repeated for each line as shown in Table B.

When an image is less than 8 bits per pixel, each line is padded to the next byte boundary. For example, if an image has 1 plane of 1-bit data (monochrome) with a width of 22 pixels, each row will be 3 bytes long, having 24 bits per row with 2 bits unused.

PCX image data are compressed using run-length encoding (RLE), a simple lossless compression algorithm that collapses a series of three or more consecutive bytes with identical values into a two-byte pair. The two most-significant bits of a byte are used to determine whether the given data represent a single pixel of a given palette index or color value, or an RLE pair representing a series of several pixels of a single value:
Compared to the maximum run length of 128, possible with TGA RLE compression, the PCX run-length encoding offers a larger single-pixel value range, while the maximum run length is restricted to 63.

Due to the use of the two most-significant bits as flags, pixel values from 192 to 255 (with their most-significant bit already set) must be stored in an RLE byte pair, even when they only occur one or two pixels in succession, whereas color indexes 0 to 191 can be stored directly "or" in RLE byte pairs (whichever is more space-efficient); therefore, the actual compression ratio could be optimized with proper sorting of palette entries, though this is not feasible where the file must share its color palette with other images. For example, a palette could be optimized with the most commonly used colors occurring in palette positions 0 to 191 and the least common colors allocated to the remaining quarter of the palette.

Another inefficiency with the RLE algorithm is that it is possible to store chunks with a length of 0, which allows whitespace in the file. This allowed PCX files to be decompressed slightly faster on the processors it was originally intended for. This quirk could be used for steganography.

The PCX compression algorithm requires very little processor power or memory to apply, a significant concern with the computer systems when it was designed. As computers and display hardware grow more sophisticated, the PCX algorithm becomes less space-efficient. Compression algorithms used by newer image formats are more efficient when compressing images such as photographs, and dithered or otherwise complex graphics.

A PCX file has space in its header for a 16 color palette. When 256-color VGA hardware became available there was not enough space for the palette in a PCX file; even the 54 unused bytes after the header would not be enough. The solution chosen was to put the palette at the end of the file, along with a marker byte to confirm its existence.

If a PCX file has a 256-color palette, it is found 768 bytes from the end of the file. In this case the value in the byte preceding the palette should be 12 (0x0C). The palette is stored as a sequence of RGB triples; its usable length is defined by the number of colors in the image. Colors values in a PCX palette always use 8 bits, regardless of the bit depth of the image.


</doc>
<doc id="24749" url="https://en.wikipedia.org/wiki?curid=24749" title="Permian–Triassic extinction event">
Permian–Triassic extinction event

The Permian–Triassic extinction event, also known as the P–Tr extinction, the P–T extinction, the End-Permian Extinction, and colloquially as the Great Dying, formed the boundary between the Permian and Triassic geologic periods, as well as between the Paleozoic and Mesozoic eras, approximately 252 million years ago. It is the Earth's most severe known extinction event, with up to 96% of all marine species and 70% of terrestrial vertebrate species becoming extinct. It was the largest known mass extinction of insects. Some 57% of all biological families and 83% of all genera became extinct. Because so much biodiversity was lost, the recovery of land-dwelling life took significantly longer than after any other extinction event, possibly up to 10 million years. Studies in Bear Lake County, near Paris, Idaho, showed a relatively quick rebound in a localized marine ecosystem, taking around 2 million years to recover, suggesting that the impact of the extinction may have been felt less severely in some areas than others.

There is evidence for one to three distinct pulses, or phases, of extinction. Potential causes for those pulses include one or more large meteor impact events, massive volcanic eruptions (such as the Siberian Traps<ref name="lava/coal fires"> </ref>), and climate change brought on by large releases of underwater methane or methane-producing microbes.

Until 2000, it was thought that rock sequences spanning the Permian–Triassic boundary were too few and contained too many gaps for scientists to reliably determine its details. However, it is now possible to date the extinction with millennial precision. U–Pb zircon dates from five volcanic ash beds from the Global Stratotype Section and Point for the Permian–Triassic boundary at Meishan, China, establish a high-resolution age model for the extinction – allowing exploration of the links between global environmental perturbation, carbon cycle disruption, mass extinction, and recovery at millennial timescales. The extinction occurred between 251.941 ± 0.037 and 251.880 ± 0.031 Ma ago, a duration of 60 ± 48 ka. A large (approximately 0.9%), abrupt global decrease in the ratio of the stable isotope to that of , coincides with this extinction, and is sometimes used to identify the Permian–Triassic boundary in rocks that are unsuitable for radiometric dating. Further evidence for environmental change around the P–Tr boundary suggests an rise in temperature, and an increase in levels by (for comparison, the concentration immediately before the industrial revolution was , and the amount today is about 410 ppm). There is also evidence of increased ultraviolet radiation reaching the earth, causing the mutation of plant spores.

It has been suggested that the Permian–Triassic boundary is associated with a sharp increase in the abundance of marine and terrestrial fungi, caused by the sharp increase in the amount of dead plants and animals fed upon by the fungi. For a while this "fungal spike" was used by some paleontologists to identify the Permian–Triassic boundary in rocks that are unsuitable for radiometric dating or lack suitable index fossils, but even the proposers of the fungal spike hypothesis pointed out that "fungal spikes" may have been a repeating phenomenon created by the post-extinction ecosystem in the earliest Triassic. The very idea of a fungal spike has been criticized on several grounds, including: "Reduviasporonites", the most common supposed fungal spore, may be a fossilized alga; the spike did not appear worldwide; and in many places it did not fall on the Permian–Triassic boundary. The reduviasporonites may even represent a transition to a lake-dominated Triassic world rather than an earliest Triassic zone of death and decay in some terrestrial fossil beds. Newer chemical evidence agrees better with a fungal origin for "Reduviasporonites", diluting these critiques.

Uncertainty exists regarding the duration of the overall extinction and about the timing and duration of various groups' extinctions within the greater process. Some evidence suggests that there were multiple extinction pulses or that the extinction was spread out over a few million years, with a sharp peak in the last million years of the Permian. Statistical analyses of some highly fossiliferous strata in Meishan, Zhejiang Province in southeastern China, suggest that the main extinction was clustered around one peak. Recent research shows that different groups became extinct at different times; for example, while difficult to date absolutely, ostracod and brachiopod extinctions were separated by 670,000 to 1.17 million years. In a well-preserved sequence in east Greenland, the decline of animals is concentrated in a period 10,000 to 60,000 years long, with plants taking an additional several hundred thousand years to show the full impact of the event.

An older theory, still supported in some recent papers, is that there were two major extinction pulses 9.4 million years apart, separated by a period of extinctions well above the background level, and that the final extinction killed off only about 80% of marine species alive at that time while the other losses occurred during the first pulse or the interval between pulses. According to this theory one of these extinction pulses occurred at the end of the Guadalupian epoch of the Permian. For example, all but one of the surviving dinocephalian genera died out at the end of the Guadalupian, as did the Verbeekinidae, a family of large-size fusuline foraminifera. The impact of the end-Guadalupian extinction on marine organisms appears to have varied between locations and between taxonomic groups — brachiopods and corals had severe losses.
Marine invertebrates suffered the greatest losses during the P–Tr extinction. Evidence of this was found in samples from south China sections at the P–Tr boundary. Here, 286 out of 329 marine invertebrate genera disappear within the final two sedimentary zones containing conodonts from the Permian. The decrease in diversity was probably caused by a sharp increase in extinctions, rather than a decrease in speciation.

The extinction primarily affected organisms with calcium carbonate skeletons, especially those reliant on stable CO levels to produce their skeletons. These organisms were susceptible to the effects of the ocean acidification that resulted from increased atmospheric CO.

Among benthic organisms the extinction event multiplied background extinction rates, and therefore caused maximum species loss to taxa that had a high background extinction rate (by implication, taxa with a high turnover). The extinction rate of marine organisms was catastrophic.

Surviving marine invertebrate groups included articulate brachiopods (those with a hinge), which had undergone a slow decline in numbers since the P–Tr extinction; the Ceratitida order of ammonites; and crinoids ("sea lilies"), which very nearly became extinct but later became abundant and diverse.

The groups with the highest survival rates generally had active control of circulation, elaborate gas exchange mechanisms, and light calcification; more heavily calcified organisms with simpler breathing apparatuses suffered the greatest loss of species diversity. In the case of the brachiopods, at least, surviving taxa were generally small, rare members of a formerly diverse community.

The ammonoids, which had been in a long-term decline for the 30 million years since the Roadian (middle Permian), suffered a selective extinction pulse 10 million years before the main event, at the end of the Capitanian stage. In this preliminary extinction, which greatly reduced disparity, or the range of different ecological guilds, environmental factors were apparently responsible. Diversity and disparity fell further until the P–Tr boundary; the extinction here (P–Tr) was non-selective, consistent with a catastrophic initiator. During the Triassic, diversity rose rapidly, but disparity remained low.

The range of morphospace occupied by the ammonoids, that is, their range of possible forms, shapes or structures, became more restricted as the Permian progressed. A few million years into the Triassic, the original range of ammonoid structures was once again reoccupied, but the parameters were now shared differently among clades.

The Permian had great diversity in insect and other invertebrate species, including the largest insects ever to have existed. The end-Permian is the largest known mass extinction of insects; according to some sources, it is the "only" insect mass extinction. Eight or nine insect orders became extinct and ten more were greatly reduced in diversity. Palaeodictyopteroids (insects with piercing and sucking mouthparts) began to decline during the mid-Permian; these extinctions have been linked to a change in flora. The greatest decline occurred in the Late Permian and was probably not directly caused by weather-related floral transitions.

Most fossil insect groups found after the Permian–Triassic boundary differ significantly from those before: Of Paleozoic insect groups, only the Glosselytrodea, Miomoptera, and Protorthoptera have been discovered in deposits from after the extinction. The caloneurodeans, monurans, paleodictyopteroids, protelytropterans, and protodonates became extinct by the end of the Permian. In well-documented Late Triassic deposits, fossils overwhelmingly consist of modern fossil insect groups.

The geological record of terrestrial plants is sparse and based mostly on pollen and spore studies. Plants are relatively immune to mass extinction, with the impact of all the major mass extinctions "insignificant" at a family level. Even the reduction observed in species diversity (of 50%) may be mostly due to taphonomic processes. However, a massive rearrangement of ecosystems does occur, with plant abundances and distributions changing profoundly and all the forests virtually disappearing; the Palaeozoic flora scarcely survived this extinction.

At the P–Tr boundary, the dominant floral groups changed, with many groups of land plants entering abrupt decline, such as "Cordaites" (gymnosperms) and "Glossopteris" (seed ferns). Dominant gymnosperm genera were replaced post-boundary by lycophytes—extant lycophytes are recolonizers of disturbed areas.

Palynological or pollen studies from East Greenland of sedimentary rock strata laid down during the extinction period indicate dense gymnosperm woodlands before the event. At the same time that marine invertebrate macrofauna declined, these large woodlands died out and were followed by a rise in diversity of smaller herbaceous plants including Lycopodiophyta, both Selaginellales and Isoetales. Later, other groups of gymnosperms again become dominant but again suffered major die offs. These cyclical flora shifts occurred a few times over the course of the extinction period and afterwards. These fluctuations of the dominant flora between woody and herbaceous taxa indicate chronic environmental stress resulting in a loss of most large woodland plant species. The successions and extinctions of plant communities do not coincide with the shift in values, but occurred many years after. The recovery of gymnosperm forests took 4–5 million years.

No coal deposits are known from the Early Triassic, and those in the Middle Triassic are thin and low-grade. This "coal gap" has been explained in many ways. It has been suggested that new, more aggressive fungi, insects and vertebrates evolved, and killed vast numbers of trees. These decomposers themselves suffered heavy losses of species during the extinction, and are not considered a likely cause of the coal gap. It could simply be that all coal-forming plants were rendered extinct by the P–Tr extinction, and that it took 10 million years for a new suite of plants to adapt to the moist, acid conditions of peat bogs. Abiotic factors (factors not caused by organisms), such as decreased rainfall or increased input of clastic sediments, may also be to blame.

On the other hand, the lack of coal may simply reflect the scarcity of all known sediments from the Early Triassic. Coal-producing ecosystems, rather than disappearing, may have moved to areas where we have no sedimentary record for the Early Triassic. For example, in eastern Australia a cold climate had been the norm for a long period, with a peat mire ecosystem adapted to these conditions. Approximately 95% of these peat-producing plants went "locally" extinct at the P–Tr boundary; Coal deposits in Australia and Antarctica disappear significantly "before" the P–Tr boundary.

There is enough evidence to indicate that over two thirds of terrestrial labyrinthodont amphibians, sauropsid ("reptile") and therapsid ("proto-mammal") families became extinct. Large herbivores suffered the heaviest losses.

All Permian anapsid reptiles died out except the procolophonids (although testudines have "morphologically"-anapsid skulls, they are now thought to have separately evolved from diapsid ancestors). Pelycosaurs died out before the end of the Permian. Too few Permian diapsid fossils have been found to support any conclusion about the effect of the Permian extinction on diapsids (the "reptile" group from which lizards, snakes, crocodilians, and dinosaurs (including birds) evolved).

The groups that survived suffered extremely heavy losses of species, and some terrestrial vertebrate groups very nearly became extinct at the end of the Permian. Some of the surviving groups did not persist for long past this period, but others that barely survived went on to produce diverse and long-lasting lineages. However, it took 30million years for the terrestrial vertebrate fauna to fully recover both numerically and ecologically.

An analysis of marine fossils from the Permian's final Changhsingian stage found that marine organisms with low tolerance for hypercapnia (high concentration of carbon dioxide) had high extinction rates, and the most tolerant organisms had very slight losses.

The most vulnerable marine organisms were those that produced calcareous hard parts (from calcium carbonate) and had low metabolic rates and weak respiratory systems, notably calcareous sponges, rugose and tabulate corals, calcite-depositing brachiopods, bryozoans, and echinoderms; about 81% of such genera became extinct. Close relatives without calcareous hard parts suffered only minor losses, such as sea anemones, from which modern corals evolved. Animals with high metabolic rates, well-developed respiratory systems, and non-calcareous hard parts had negligible losses except for conodonts, in which 33% of genera died out.

This pattern is consistent with what is known about the effects of hypoxia, a shortage but not total absence of oxygen. However, hypoxia cannot have been the only killing mechanism for marine organisms. Nearly all of the continental shelf waters would have had to become severely hypoxic to account for the magnitude of the extinction, but such a catastrophe would make it difficult to explain the very selective pattern of the extinction. Mathematical models of the Late Permian and Early Triassic atmospheres show a significant but protracted decline in atmospheric oxygen levels, with no acceleration near the P–Tr boundary. Minimum atmospheric oxygen levels in the Early Triassic are never less than present-day levels and so the decline in oxygen levels does not match the temporal pattern of the extinction.

Marine organisms are more sensitive to changes in (carbon dioxide) levels than terrestrial organisms are for a variety of reasons. is 28 times more soluble in water than is oxygen. Marine animals normally function with lower concentrations of in their bodies than land animals, as the removal of in air-breathing animals is impeded by the need for the gas to pass through the respiratory system's membranes (lungs' alveolus, tracheae, and the like), even when diffuses more easily than oxygen. In marine organisms, relatively modest but sustained increases in concentrations hamper the synthesis of proteins, reduce fertilization rates, and produce deformities in calcareous hard parts. In addition, an increase in concentration is inevitably linked to ocean acidification, consistent with the preferential extinction of heavily calcified taxa and other signals in the rock record that suggest a more acidic ocean. The decrease in ocean pH is calculated to be up to 0.7 units.

It is difficult to analyze extinction and survival rates of land organisms in detail because few terrestrial fossil beds span the Permian–Triassic boundary. Triassic insects are very different from those of the Permian, but a gap in the insect fossil record spans approximately 15 million years from the late Permian to early Triassic. The best-known record of vertebrate changes across the Permian–Triassic boundary occurs in the Karoo Supergroup of South Africa, but statistical analyses have so far not produced clear conclusions. However, analysis of the fossil river deposits of the floodplains indicate a shift from meandering to braided river patterns, indicating an abrupt drying of the climate. The climate change may have taken as little as 100,000 years, prompting the extinction of the unique "Glossopteris" flora and its herbivores, followed by the carnivorous guild. End-Permian extinctions did not occur at an instantaneous time horizon; particularly, floral extinction was delayed in time.

Earlier analyses indicated that life on Earth recovered quickly after the Permian extinctions, but this was mostly in the form of disaster taxa, opportunist organisms such as the hardy "Lystrosaurus". Research published in 2006 indicates that the specialized animals that formed complex ecosystems, with high biodiversity, complex food webs and a variety of niches, took much longer to recover. It is thought that this long recovery was due to the successive waves of extinction, which inhibited recovery, and prolonged environmental stress to organisms, which continued into the Early Triassic. Research indicates that recovery did not begin until the start of the mid-Triassic, 4 to 6 million years after the extinction; and some writers estimate that the recovery was not complete until after the P–Tr extinction, i.e. in the late Triassic.

A study published in the journal "Science" found that during the Great Extinction, ocean surface temperatures reached in some places. This explains why recovery took so long: it was too hot for life to survive. Anoxic waters may have also delayed the recovery.
During the early Triassic (4 to 6 million years after the P–Tr extinction), the plant biomass was insufficient to form coal deposits, which implies a limited food mass for herbivores. River patterns in the Karoo changed from meandering to braided, indicating that vegetation there was very sparse for a long time.

Each major segment of the early Triassic ecosystem—plant and animal, marine and terrestrial—was dominated by a small number of genera, which appeared virtually worldwide, for example: the herbivorous therapsid "Lystrosaurus" (which accounted for about 90% of early Triassic land vertebrates) and the bivalves "Claraia", "Eumorphotis", "Unionites" and "Promylina". A healthy ecosystem has a much larger number of genera, each living in a few preferred types of habitat.

Disaster taxa took advantage of the devastated ecosystems and enjoyed a temporary population boom and increase in their territory. Microconchids are the dominant component of otherwise impoverished Early Triassic encrusting assemblages. For example: "Lingula" (a brachiopod); stromatolites, which had been confined to marginal environments since the Ordovician; "Pleuromeia" (a small, weedy plant); "Dicroidium" (a seed fern).

Prior to the extinction, about two thirds of marine animals were sessile and attached to the sea floor. During the Mesozoic, only about half of the marine animals were sessile while the rest were free-living. Analysis of marine fossils from the period indicated a decrease in the abundance of sessile epifaunal suspension feeders such as brachiopods and sea lilies and an increase in more complex mobile species such as snails, sea urchins and crabs.

Before the Permian mass extinction event, both complex and simple marine ecosystems were equally common. After the recovery from the mass extinction, the complex communities outnumbered the simple communities by nearly three to one, and the increase in predation pressure led to the Mesozoic Marine Revolution.

Bivalves were fairly rare before the P–Tr extinction but became numerous and diverse in the Triassic, and one group, the rudist clams, became the Mesozoic's main reef-builders. Some researchers think much of the change happened in the 5 million years between the two major extinction pulses.

Crinoids ("sea lilies") suffered a selective extinction, resulting in a decrease in the variety of their forms. Their ensuing adaptive radiation was brisk, and resulted in forms possessing flexible arms becoming widespread; motility, predominantly a response to predation pressure, also became far more prevalent.

"Lystrosaurus", a pig-sized herbivorous dicynodont therapsid, constituted as much as 90% of some earliest Triassic land vertebrate fauna. Smaller carnivorous cynodont therapsids also survived, including the ancestors of mammals. In the Karoo region of southern Africa, the therocephalians "Tetracynodon", "Moschorhinus" and "Ictidosuchoides" survived, but do not appear to have been abundant in the Triassic.

Archosaurs (which included the ancestors of dinosaurs and crocodilians) were initially rarer than therapsids, but they began to displace therapsids in the mid-Triassic. In the mid to late Triassic, the dinosaurs evolved from one group of archosaurs, and went on to dominate terrestrial ecosystems during the Jurassic and Cretaceous. This "Triassic Takeover" may have contributed to the evolution of mammals by forcing the surviving therapsids and their mammaliform successors to live as small, mainly nocturnal insectivores; nocturnal life probably forced at least the mammaliforms to develop fur and higher metabolic rates, while losing part of the differential color-sensitive retinal receptors reptilians and birds preserved.

Some temnospondyl amphibians made a relatively quick recovery, in spite of nearly becoming extinct. "Mastodonsaurus" and trematosaurians were the main aquatic and semiaquatic predators during most of the Triassic, some preying on tetrapods and others on fish.

Land vertebrates took an unusually long time to recover from the P–Tr extinction; Palaeontologist Michael Benton estimated the recovery was not complete until after the extinction, i.e. not until the Late Triassic, in which dinosaurs, pterosaurs, crocodiles, archosaurs, amphibians, and mammaliforms were abundant and diverse.

Pinpointing the exact causes of the Permian–Triassic extinction event is difficult, mostly because it occurred over 250 million years ago, and since then much of the evidence that would have pointed to the cause has been destroyed or is concealed deep within the Earth under many layers of rock. The sea floor is also completely recycled every 200 million years by the ongoing process of plate tectonics and seafloor spreading, leaving no useful indications beneath the ocean.

Yet, scientists have gathered significant evidence for causes, and several mechanisms have been proposed. The proposals include both catastrophic and gradual processes (similar to those theorized for the Cretaceous–Paleogene extinction event).

Any hypothesis about the cause must explain the selectivity of the event, which affected organisms with calcium carbonate skeletons most severely; the long period (4 to 6 million years) before recovery started, and the minimal extent of biological mineralization (despite inorganic carbonates being deposited) once the recovery began.

Evidence that an impact event may have caused the Cretaceous–Paleogene extinction event (Cretaceous–Tertiary) has led to speculation that similar impacts may have been the cause of other extinction events, including the P–Tr extinction, and thus to a search for evidence of impacts at the times of other extinctions, such as large impact craters of the appropriate age.

Reported evidence for an impact event from the P–Tr boundary level includes rare grains of shocked quartz in Australia and Antarctica; fullerenes trapping extraterrestrial noble gases; meteorite fragments in Antarctica; and grains rich in iron, nickel, and silicon, which may have been created by an impact. However, the accuracy of most of these claims has been challenged. For example, quartz from Graphite Peak in Antarctica, once considered "shocked", has been re-examined by optical and transmission electron microscopy. The observed features were concluded to be due not to shock, but rather to plastic deformation, consistent with formation in a tectonic environment such as volcanism.

An impact crater on the sea floor would be evidence of a possible cause of the P–Tr extinction, but such a crater would by now have disappeared. As 70% of the Earth's surface is currently sea, an asteroid or comet fragment is now perhaps more than twice as likely to hit ocean as it is to hit land. However, Earth's oldest ocean-floor crust is 200 million years old because it is continually destroyed and renewed by spreading and subduction. Furthermore, craters produced by very large impacts may be masked by extensive flood basalting from below after the crust is punctured or weakened. Yet, subduction should not be entirely accepted as an explanation for the lack of evidence: as with the K-T event, an ejecta blanket stratum rich in siderophilic elements (such as iridium) would be expected in formations from the time.

A large impact might have triggered other mechanisms of extinction described below, such as the Siberian Traps eruptions at either an impact site or the antipode of an impact site. The abruptness of an impact also explains why more species did not rapidly evolve to survive, as would be expected if the Permian–Triassic event had been slower and less global than a meteorite impact.

Several possible impact craters have been proposed as the site of an impact causing the P–Tr extinction, including the Bedout structure off the northwest coast of Australia and the hypothesized Wilkes Land crater of East Antarctica. An impact has not been proved in either case, and the idea has been widely criticized. The Wilkes Land sub-ice geophysical feature is of very uncertain age, possibly later than the Permian–Triassic extinction.

The Araguainha crater in Brazil has been most recently dated to 254.7 ± 2.5 million years ago, overlapping with estimates for the Permo-Triassic boundary. Much of the local rock was oil shale. The estimated energy released by the Araguainha impact is insufficient to have directly caused the global mass extinction, but the colossal local earth tremors would have released huge amounts of oil and gas from the shattered rock. The resulting sudden global warming might have precipitated the Permian–Triassic extinction event.

A 2017 paper by Rampino, Rocca and Presser (after a 1992 abstract by Rampino) noted the discovery of a circular gravity anomaly near the Falkland Islands which might correspond to an impact crater with a diameter of , as supported by seismic and magnetic evidence. Estimates for the age of the structure range up to 250 million years old. This would be substantially larger than the well-known Chicxulub impact crater associated with a later extinction. However, Dave McCarthy and colleagues from the British Geological Survey illustrated that the gravity anomaly is not circular and also that the seismic data presented by Rocca, Rampino and Baez Presser did not cross the proposed crater or provide any evidence for an impact crater.

The final stages of the Permian had two flood basalt events. A smaller one, the Emeishan Traps in China, occurred at the same time as the end-Guadalupian extinction pulse, in an area close to the equator at the time. The flood basalt eruptions that produced the Siberian Traps constituted one of the largest known volcanic events on Earth and covered over with lava. The date of the Siberian Traps eruptions and the extinction event are in good agreement.

The Emeishan and Siberian Traps eruptions may have caused dust clouds and acid aerosols, which would have blocked out sunlight and thus disrupted photosynthesis both on land and in the photic zone of the ocean, causing food chains to collapse. The eruptions may also have caused acid rain when the aerosols washed out of the atmosphere. That may have killed land plants and molluscs and planktonic organisms which had calcium carbonate shells. The eruptions would also have emitted carbon dioxide, causing global warming. When all of the dust clouds and aerosols washed out of the atmosphere, the excess carbon dioxide would have remained and the warming would have proceeded without any mitigating effects.

The Siberian Traps had unusual features that made them even more dangerous. Pure flood basalts produce fluid, low-viscosity lava and do not hurl debris into the atmosphere. It appears, however, that 20% of the output of the Siberian Traps eruptions was pyroclastic (consisted of ash and other debris thrown high into the atmosphere), increasing the short-term cooling effect. The basalt lava erupted or intruded into carbonate rocks and into sediments that were in the process of forming large coal beds, both of which would have emitted large amounts of carbon dioxide, leading to stronger global warming after the dust and aerosols settled.

In January 2011, a team, led by Stephen Grasby of the Geological Survey of Canada—Calgary, reported evidence that volcanism caused massive coal beds to ignite, possibly releasing more than 3 trillion tons of carbon. The team found ash deposits in deep rock layers near what is now the Buchanan Lake Formation. According to their article, "coal ash dispersed by the explosive Siberian Trap eruption would be expected to have an associated release of toxic elements in impacted water bodies where fly ash slurries developed... Mafic megascale eruptions are long-lived events that would allow significant build-up of global ash clouds." In a statement, Grasby said, "In addition to these volcanoes causing fires through coal, the ash it spewed was highly toxic and was released in the land and water, potentially contributing to the worst extinction event in earth history." In 2013, a team led by Q.Y. Yang reported the total amounts of important volatiles emitted from the Siberian Traps are 8.5 × 10 Tg CO, 4.4 × 10 Tg CO, 7.0 × 10 Tg HS and 6.8 × 10 Tg SO, the data support a popular notion that the end-Permian mass extinction on the Earth was caused by the emission of enormous amounts of volatiles from the Siberian Traps into the atmosphere.

In 2015, evidence and a timeline indicated the extinction was caused by events in the large igneous province of the Siberian Traps.

Scientists have found worldwide evidence of a swift decrease of about 1% in the C/C isotope ratio in carbonate rocks from the end-Permian. This is the first, largest, and most rapid of a series of negative and positive excursions (decreases and increases in C/C ratio) that continues until the isotope ratio abruptly stabilised in the middle Triassic, followed soon afterwards by the recovery of calcifying life forms (organisms that use calcium carbonate to build hard parts such as shells).

A variety of factors may have contributed to this drop in the C/C ratio, but most turn out to be insufficient to account fully for the observed amount:

Other hypotheses include mass oceanic poisoning releasing vast amounts of and a long-term reorganisation of the global carbon cycle.

Prior to consideration of the inclusion of roasting carbonate sediments by volcanism, the only proposed mechanism sufficient to cause a global 1% reduction in the C/C ratio was the release of methane from methane clathrates. Carbon-cycle models confirm that it would have had enough effect to produce the observed reduction. Methane clathrates, also known as methane hydrates, consist of methane molecules trapped in cages of water molecules. The methane, produced by methanogens (microscopic single-celled organisms), has a C/C ratio about 6.0% below normal ( −6.0%). At the right combination of pressure and temperature, it gets trapped in clathrates fairly close to the surface of permafrost and in much larger quantities at continental margins (continental shelves and the deeper seabed close to them). Oceanic methane hydrates are usually found buried in sediments where the seawater is at least deep. They can be found up to about below the sea floor, but usually only about below the sea floor.

The area covered by lava from the Siberian Traps eruptions is about twice as large as was originally thought, and most of the additional area was shallow sea at the time. The seabed probably contained methane hydrate deposits, and the lava caused the deposits to dissociate, releasing vast quantities of methane.
A vast release of methane might cause significant global warming since methane is a very powerful greenhouse gas. Strong evidence suggests the global temperatures increased by about 6 °C (10.8 °F) near the equator and therefore by more at higher latitudes: a sharp decrease in oxygen isotope ratios (O/O); the extinction of "Glossopteris" flora ("Glossopteris" and plants that grew in the same areas), which needed a cold climate, with its replacement by floras typical of lower paleolatitudes.

However, the pattern of isotope shifts expected to result from a massive release of methane does not match the patterns seen throughout the early Triassic. Not only would such a cause require the release of five times as much methane as postulated for the PETM, but would it also have to be reburied at an unrealistically high rate to account for the rapid increases in the C/C ratio (episodes of high positive ) throughout the early Triassic before it was released again several times.

Evidence for widespread ocean anoxia (severe deficiency of oxygen) and euxinia (presence of hydrogen sulfide) is found from the Late Permian to the Early Triassic. Throughout most of the Tethys and Panthalassic Oceans, evidence for anoxia, including fine laminations in sediments, small pyrite framboids, high uranium/thorium ratios, and biomarkers for green sulfur bacteria, appear at the extinction event. However, in some sites, including Meishan, China, and eastern Greenland, evidence for anoxia precedes the extinction. Biomarkers for green sulfur bacteria, such as isorenieratane, the diagenetic product of isorenieratene, are widely used as indicators of photic zone euxinia because green sulfur bacteria require both sunlight and hydrogen sulfide to survive. Their abundance in sediments from the P-T boundary indicates hydrogen sulfide was present even in shallow waters.

This spread of toxic, oxygen-depleted water would have devastated marine life, causing widespread die-offs. Models of ocean chemistry suggest that anoxia and euxinia were closely associated with hypercapnia (high levels of carbon dioxide). This suggests that poisoning from hydrogen sulfide, anoxia, and hypercapnia acted together as a killing mechanism. Hypercapnia best explains the selectivity of the extinction, but anoxia and euxinia probably contributed to the high mortality of the event. The persistence of anoxia through the Early Triassic may explain the slow recovery of marine life after the extinction. Models also show that anoxic events can cause catastrophic hydrogen sulfide emissions into the atmosphere (see below).

The sequence of events leading to anoxic oceans may have been triggered by carbon dioxide emissions from the eruption of the Siberian Traps. In that scenario, warming from the enhanced greenhouse effect would reduce the solubility of oxygen in seawater, causing the concentration of oxygen to decline. Increased weathering of the continents due to warming and the acceleration of the water cycle would increase the riverine flux of phosphate to the ocean. The phosphate would have supported greater primary productivity in the surface oceans. The increase in organic matter production would have caused more organic matter to sink into the deep ocean, where its respiration would further decrease oxygen concentrations. Once anoxia became established, it would have been sustained by a positive feedback loop because deep water anoxia tends to increase the recycling efficiency of phosphate, leading to even higher productivity.

A severe anoxic event at the end of the Permian would have allowed sulfate-reducing bacteria to thrive, causing the production of large amounts of hydrogen sulfide in the anoxic ocean. Upwelling of this water may have released massive hydrogen sulfide emissions into the atmosphere and would poison terrestrial plants and animals and severely weaken the ozone layer, exposing much of the life that remained to fatal levels of UV radiation.
Indeed, biomarker evidence for anaerobic photosynthesis by Chlorobiaceae (green sulfur bacteria) from the Late-Permian into the Early Triassic indicates that hydrogen sulfide did upwell into shallow waters because these bacteria are restricted to the photic zone and use sulfide as an electron donor.

The hypothesis has the advantage of explaining the mass extinction of plants, which would have added to the methane levels and should otherwise have thrived in an atmosphere with a high level of carbon dioxide. Fossil spores from the end-Permian further support the theory: many show deformities that could have been caused by ultraviolet radiation, which would have been more intense after hydrogen sulfide emissions weakened the ozone layer.

In the mid-Permian (during the Kungurian age of the Permian's Cisuralian epoch), Earth's major continental plates joined, forming a supercontinent called Pangaea, which was surrounded by the superocean, Panthalassa.

Oceanic circulation and atmospheric weather patterns during the mid-Permian produced seasonal monsoons near the coasts and an arid climate in the vast continental interior.

As the supercontinent formed, the ecologically diverse and productive coastal areas shrank. The shallow aquatic environments were eliminated and exposed formerly protected organisms of the rich continental shelves to increased environmental volatility.

Pangaea's formation depleted marine life at near catastrophic rates. However, Pangaea's effect on land extinctions is thought to have been smaller. In fact, the advance of the therapsids and increase in their diversity is attributed to the late Permian, when Pangaea's global effect was thought to have peaked.

While Pangaea's formation certainly initiated a long period of marine extinction, its impact on the "Great Dying" and the end of the Permian is uncertain.

John Gribbin argues that the Solar System last passed through a spiral arm of the Milky Way around 250 million years ago and that the resultant dusty gas clouds may have caused a dimming of the Sun which combined with the effect of Pangea to produce an ice age.

A hypothesis published in 2014 posits that a genus of anaerobic methanogenic archaea known as "Methanosarcina" was responsible for the event. Three lines of evidence suggest that these microbes acquired a new metabolic pathway via gene transfer at about that time, enabling them to efficiently metabolize acetate into methane. That would have led to their exponential reproduction, allowing them to rapidly consume vast deposits of organic carbon that had accumulated in the marine sediment. The result would have been a sharp buildup of methane and carbon dioxide in the Earth's oceans and atmosphere, in a manner that may be consistent with the C/C isotopic record. Massive volcanism facilitated this process by releasing large amounts of nickel, a scarce metal which is a cofactor for enzymes involved in producing methane. On the other hand, in the canonical Meishan sections, the nickel concentration increases somewhat after the concentrations have begun to fall.

Possible causes supported by strong evidence appear to describe a sequence of catastrophes, each worse than the last: the Siberian Traps eruptions were bad enough alone, but because they occurred near coal beds and the continental shelf, they also triggered very large releases of carbon dioxide and methane. The resultant global warming may have caused perhaps the most severe anoxic event in the oceans' history: according to this theory, the oceans became so anoxic, anaerobic sulfur-reducing organisms dominated the chemistry of the oceans and caused massive emissions of toxic hydrogen sulfide.

However, there may be some weak links in this chain of events: the changes in the C/C ratio expected to result from a massive release of methane do not match the patterns seen throughout the early Triassic; and the types of oceanic thermohaline circulation that may have existed at the end of the Permian are not likely to have supported deep-sea anoxia.




</doc>
<doc id="24750" url="https://en.wikipedia.org/wiki?curid=24750" title="Porter Blanchard">
Porter Blanchard

Porter George Blanchard (1886–1973) was an American silversmith living and working in Pacoima, California. He is considered to be part of the Arts and Crafts Movement.

Blanchard learned the trade of the silversmith from his father, George Porter Blanchard in Gardner, Massachusetts. In 1923, Blanchard moved to Burbank, California, where he established a studio for silversmithing. Between the 1930s and 1950, he operated a shop in Hollywood. He then worked from his home in Pacoima from the 1940s until his death in 1973.

His daughter Alice Blanchard married Lewis Wise, who conducted business as Porter Blanchard Silversmiths in Calabasas, California. After 1955, all Porter Blanchard flatware was made at the Calabasas shop, while the holloware was made at Blanchard's Pacoima home. His daughter Rebecca married Allan Adler, who continued designing as a silversmith in the Arts and Crafts tradition.

Blanchard was a member of the Boston Society of Arts and Crafts and was awarded their title of medalist in 1944.

Many of his papers, including photographs of his shop, are collected in the Archives of American Art at the Smithsonian Institution in Washington, D.C. They were donated to the Archives by his daughters, Rebecca Adler and Alice E. Wise.

Blanchard's works are in the collections of various museums, including the Cooper-Hewitt National Design Museum, the Los Angeles County Museum of Art, and the Oakland Museum of California.




</doc>
<doc id="24751" url="https://en.wikipedia.org/wiki?curid=24751" title="Punjab, Pakistan">
Punjab, Pakistan


</doc>
<doc id="24752" url="https://en.wikipedia.org/wiki?curid=24752" title="Politburo">
Politburo

A politburo () or political bureau is the executive committee for communist parties. It is present in most former and existing communist states. Under Trotskyism, the Politburo is a bureau of the Central Committee.

The term "politburo" in English comes from the Russian "Politbyuro" (), itself a contraction of "Politicheskoye Byuro" (, "Political Bureau"). The Spanish term "Politburó" is directly loaned from Russian, as is the German "Politbüro". Chinese uses a calque (), from which the Vietnamese (), and Korean ( "Jeongchiguk") terms derive.

The first politburo was created in Russia by the Bolshevik Party in 1917 to provide strong and continuous leadership during the Russian Revolution occurring during the same year. The first Politburo had seven members: Lenin, Zinoviev, Kamenev, Trotsky, Stalin, Sokolnikov, and Bubnov. During the 20th century, nations that had a politburo included the USSR, East Germany, Afghanistan, Czechoslovakia and China, among others. Today, there are five countries that have a politburo system: China, North Korea, Laos, Vietnam, and Cuba.

In Marxist–Leninist states, the party is seen as the vanguard of the people and from that legitimizes itself to lead the state. Essentially, the party officials in the Politburo informally lead the state.

Officially, the Party Congress elects a Central Committee which, in turn, elects the Politburo and General Secretary in a process termed democratic centralism. The Politburo was theoretically answerable to the Central Committee.

In Trotskyist parties, the Politburo is a bureau of the Central Committee tasked with making day-to-day political decisions, which must later be ratified by the Central Committee. It is appointed by the Central Committee from among its members. The post of General Secretary carries far less weight in this model. See, for example, the Lanka Sama Samaja Party.



</doc>
<doc id="24755" url="https://en.wikipedia.org/wiki?curid=24755" title="Pope Julius II">
Pope Julius II

Pope Julius II (; ) (5 December 1443 – 21 February 1513), born Giuliano della Rovere, was head of the Roman Catholic Church and ruler of the Papal States from 1503 to his death in 1513. Nicknamed the "Warrior Pope" or the "Fearsome Pope", he chose his papal name not in honour of Pope Julius I but in emulation of Julius Caesar. One of the most powerful and influential popes, Julius II was a central figure of the High Renaissance and left a significant mark in world history.

Julius II became Pope in the context of the Italian Wars, a period in which the major powers of Europe fought for primacy in the Italian peninsula. Louis XII of France controlled the Duchy of Milan, previously held by the Sforza, and French influence had replaced that of the Medici in the Republic of Florence. The Kingdom of Naples was under Spanish rule, and the Borja family from Spain was a major political faction in the Papal States following the reign of Alexander VI. The Archduke of Austria Maximilian I was hostile to France and Venice, and desired to descend in Italy in order to obtain the Papal coronation as Holy Roman Emperor. The conclave capitulation preceding his election included several terms, such as the opening of an ecumenical council and the organization of a crusade against the Ottoman Turks. Once crowned, Julius II proclaimed instead his goal to centralize the Papal States (in large part a patchwork of communes and "signorie") and "free Italy from the barbarians". 

In his early years as Pope, Julius II removed the Borjas from power and exiled them to Spain. Cesare Borgia, Duke of Romagna, shared the same fate and lost his possessions. In 1506, Julius II initiated the rebuilding of the St. Peter's Basilica and established the renowned Swiss Guards for his personal protection. The same year he ratified the Treaty of Tordesillas, establishing the first bishoprics in the Americas and beginning the catholicization of Latin America, and commanded a successful campaign in Romagna against the lords of Bologna and Perugia. In 1508, Julius II commissioned the Raphael Rooms and Michelangelo's paintings in the Sistine Chapel. He also joined an anti-Venetian league formed in Cambrai between France, Spain, and Austria, with the goal of capturing the coast of Romagna, including Rimini and Faenza, from the Venetian Republic. Having achieved this goal, he formed an anti-French "Holy League" with Venice following the defeat of the latter at the Battle of Agnadello. His main goal was now again to "kick the barbarians out" ("Fuori i Barbari!"). Julius II brought Spain in the alliance, declaring Naples a papal fief and promising the catholic Ferdinand of Spain a formal investiture. 
Having previously recognized Maximilian as Holy Roman Emperor, by declaring that the Imperial election was sufficient to use the title of Emperor without Papal coronation, he later obtained Habsburg support against France as well. Julius II personally led the Papal armed forces at the victorious Battle of Mirandola and, despite subsequent defeats and great losses at the Battle of Ravenna, he ultimately forced the French troops of Louis XII to retreat behind the Alps after the arrival of Swiss mercenaries from the Holy Roman Empire. 

At the Congress of Mantua in 1512, Julius II presented himself as the "liberator of Italy". At Julius' orders, Italian families were restored to power in the vacuum of French power: the Imperial Swiss led by Massimiliano Sforza restored Sforza rule in Milan, and a Spanish army led by Giovanni de Medici restored Medici rule in Florence. The Kingdom of Naples was recognized as a papal fief. The Venetians regained their territories lost to France, and the Papal States annexed Parma and Piacenza. The conciliarist movement promoted by foreign monarchs was crushed, and Julius II affirmed ultramontanism at the Fifth Lateran Council. This is often presented in traditional historiography as the moment in which Renaissance Italy came the closest to unification after the end of the Italic League of the 15th century. However, Julius II was far away from the possibility to form a single Italian kingdom, if that was his goal at all, since foreign armies were largely involved in his wars and the French were preparing new campaigns against the Swiss for Milan. Naples, even if it was now recognized as a papal fief, was still in Spanish hands and in fact Julius II confessed to a Venetian ambassador a plan to give the kingdom to his counselor Luigi d'Aragona. Nevertheless, by 1513, his objective to make the Papacy the main force in the Italian Wars was achieved.

Julius planned to call for a crusade against the Ottoman Empire in order to retake Constantinople, but died before making official announcements. His successor Pope Leo X, along with Emperor Maximilian, would re-establish the status quo ante bellum by ratifying the treaties of Brussels and Noyon (1516): France would again control Milan after the victory of Francis I at the Battle of Marignano, and Spain would be recognized as the direct ruler of Naples. However, the Papal States would remain independent and centralized as a result of Julius' policies and the office of the Papacy would remain crucial, diplomatically and politically, during the entire 16th century in Italy and Europe. Julius II was described as the ideal Prince by Machiavelli in his works. Martin Luther's visit to Rome occurred in 1510, and Julius' practice of selling indulgences was condemned by the Protestants after his death. In his "Julius Excluded from Heaven", the scholar Erasmus of Rotterdam described a Pope Julius II in the after-life planning to capture the Paradise.
Giuliano della Rovere Albisola, was born near Savona in the Republic of Genoa. He was of a noble but impoverished family, the son of Raffaelo della Rovere. and Theodora Manerola, a lady of Greek ancestry. He had three brothers; Bartolomeo, a Franciscan friar who then became Bishop of Ferrara (1474–1494); Leonardo; and Giovanni, Prefect of the City of Rome (1475–1501) and Prince of Sorea and Senigallia. He also had a sister, Lucina (later the mother of Cardinal Sisto Gara della Rovere). Giuliano was educated by his uncle, Fr. Francesco della Rovere, O.F.M. among the Franciscans, who took him under his special charge. He was later sent by this same uncle (who by that time had become Minister General of the Franciscans (1464–1469)), to the Franciscan friary in Perugia, where he could study the sciences at the University.

Della Rovere, as a young man, showed traits of being rough, coarse and given to bad language. During the late 1490s, he became more closely acquainted with Cardinal Medici and his nephew (both relatives), and the two dynasties became uneasy allies in the context of papal politics. Both houses desired an end to the occupation of Italian lands by the armies of France. He seemed less enthused by theology; rather Paul Strathern argues his imagined heroes were military leaders such as Frederic Colonna.

After his uncle was elected Pope Sixtus IV on 10 August 1471, Giuliano was appointed Bishop of Carpentras in the Comtat Venaissin on 16 October 1471. In an act of literal nepotism he was immediately raised to the cardinalate on 16 December 1471, and assigned the same titular church as that formerly held by his uncle, San Pietro in Vincoli. Guilty of serial simony and pluralism he held several powerful offices at once: in addition to the archbishopric of Avignon he held no fewer than eight bishoprics, including Lausanne from 1472, and Coutances (1476–1477).

In 1474, Giuliano led an army to Todi, Spoleto, and Città di Castello as papal legate. He returned to Rome in May, in the company of Duke Federigo of Urbino, who promised his daughter in marriage to Giuliano's brother Giovanni, who was subsequently named Lord of Senigallia and of Mondovì. On 22 December 1475, Pope Sixtus IV created the new Archdiocese of Avignon, assigning to it as suffragan dioceses the Sees of Vaison, Cavaillon, and Carpentras. He appointed Giuliano as the first archbishop. Giuliano held the archdiocese until his later election to the papacy. In 1476 the office of Legate was added, and he left Rome for France in February. On 22 August 1476 he founded the "Collegium de Ruvere" in Avignon. He returned to Rome on 4 October 1476.

In 1479, Cardinal Giuliano served his one-year term as Chamberlain of the College of Cardinals. In this office he was responsible for collecting all the revenues owed to the cardinals as a group (from "ad limina" visits, for example) and for the proper disbursements of appropriate shares to cardinals who were in service in the Roman Curia.

Giuliano was again named Papal Legate to France on 28 April 1480, and left Rome on 9 June. As Legate, his mission was threefold: to make peace between King Louis XI and the Emperor Maximilian of Austria; to raise funds for a war against the Ottoman Turks; and to negotiate the release of Cardinal Jean Balue and Bishop Guillaume d'Harancourt (who by then had been imprisoned by Louis for eleven years on charges of treason). He reached Paris in September, and finally, on 20 December 1480, Louis gave orders that Balue be handed over to the Archpriest of Loudun, who had been commissioned by the Legate to receive him in the name of the Pope. He returned to Rome on 3 February 1482. Shortly thereafter the sum of 300,000 ecus of gold was received from the French in a subsidy of the war.

On 31 January 1483 Cardinal della Rovere was promoted suburbicarian Bishop of Ostia, in succession to Cardinal Guillaume d'Estouteville who had died on 22 January. It was the privilege of the Bishop of Ostia to consecrate an elected pope a bishop, if he were not already a bishop. This actually occurred in the case of Pius III (Francesco Todeschini-Piccolomini), who was ordained a priest on 30 September 1503 and consecrated a bishop on 1 October 1503 by Cardinal Giuliano della Rovere.

Around this time, in 1483, an illegitimate daughter was born, Felice della Rovere.

On 3 November 1483, Cardinal della Rovere was named Bishop of Bologna and Papal Legate, succeeding Cardinal Francesco Gonzaga, who had died on 21 October. He held the diocese until 1502. On 28 December 1484, Giuliano participated in the investiture of his brother Giovanni as Captain-General of the Papal Armies by Pope Innocent VIII.

By 1484 Giuliano was living in the new palazzo which he had constructed next to the Basilica of the Twelve Apostles, which he had also restored. Pope Sixtus IV paid a formal visit to the newly restored building on 1 May 1482, and it may be that Giuliano was already in residence then.

Sixtus IV died on 12 August 1484 and was succeeded by Innocent VIII. After the ceremonies of the election of Pope Innocent were completed, the cardinals were dismissed to their own homes, but Cardinal della Rovere accompanied the new Pope to the Vatican Palace and was the only one to remain with him. Ludwig Pastor quotes the Florentine ambassador as remarking, "[Pope Innocent] gives the impression of a man who is guided rather by the advice of others than by his own lights." The ambassador of Ferrara stated, "While with his uncle [Della Rovere] had not the slightest influence, he now obtains whatever he likes from the new Pope." Della Rovere was one of the five cardinals named to the committee to make the arrangements for the Coronation.

In 1485 Pope Innocent and Cardinal della Rovere (as the Pope's new principal advisor), decided to involve themselves in the political affairs of the Kingdom of Naples, in what was called the "Conspiracy of the Barons". On Palm Sunday, 20 March, Cardinal della Rovere, concealing his activities from his principal rival, Cardinal Rodrigo Borgia (later Pope Alexander VI), rode out of Rome and took ship at Ostia, intending to head for Genoa and Avignon to prepare to wage war between the Church and the King of Naples, Ferdinand I (Ferrante). On 28 June the Pope sent back to Naples the token gift of a palfrey which symbolized the King of Naples' submission and demanded the full feudal submission of the Kingdom of Naples to the Roman Church according to long-standing tradition. In a second attempt to overthrow the Aragonese monarchy, the Prince of Salerno Antonello II di Sanseverino, on the advice of Antonello Petrucci and Francesco Coppola, gathered together several feudal families belonging to the Guelph faction and supporting the Angevin claim to Naples. Antonello de Sanseverino was the brother-in-law of Cardinal della Rovere's brother Giovanni, who was a noble of Naples because of his fief of Sora. The principal complaints of the barons were the heavy taxation imposed by Ferdinand to finance his war against the Saracens, who had occupied Bari in 1480; and the vigorous efforts of Ferrante to centralize the administrative apparatus of the kingdom, moving it away from a feudal to a bureaucratic system. The barons seized L'Aquila and appealed to the Pope for assistance as their feudal overlord. Genoa and Venice supported the Papacy, while Florence and Milan opted for Naples. In Rome, the Orsini allied themselves with Ferrante's son Alfonso, and therefore the Colonna supported the Pope in the street fighting that ensued. Ferrante reacted by seizing the fiefs of the barons, and, when the two parties met to negotiate a settlement, Ferrante had them arrested, and eventually executed. The prestige of the della Rovere family was seriously damaged, and in an attempt to exculpate himself Pope Innocent began to withdraw his support for them. Peace was restored in 1487, but Innocent VIII's papacy was discredited.

On 23 March 1486, the pope sent Giuliano as Papal Legate to the Court of King Charles VIII of France to ask for help. A French entourage arrived in Rome on 31 May, but immediately relations broke down with the Pro-Spanish Cardinal Rodrigo. But Ferrante's army decided the pope's humiliation, Innocent backed down and on 10 August signed a treaty. Innocent looked for new allies and settled on the Republic of Florence.

On 2 March 1487, Giuliano was appointed legate in the March of Ancona and to the Republic of Venice. He encouraged trade with the sizeable Turkish community at these ports. But urgent reports arrived from the King of Hungary that the Ottoman Sultan was threatening Italy. He returned on 8 April 1488, and again took up his residence in the Palazzo Colonna next to the Basilica of the XII Apostles.

In the Conclave of 1492, following the death of Innocent VIII, Cardinal della Rovere was supported for election by both King Charles VIII of France and by Charles' enemy King Ferrante of Naples. It was reported that France had deposited 200,000 ducats into a bank account to promote della Rovere's candidature, while the Republic of Genoa had deposited 100,000 ducats to the same end. Della Rovere, however, had enemies, both because of the influence he had exercised over Pope Sixtus IV, and because of his French sympathies. His rivals included Cardinal Ardicio della Porta and Cardinal Ascanio Sforza, both patronized by the Milanese. Kellogg, Baynes & Smith, continue, a "rivalry had, however, gradually grown up between [della Rovere] and [then-Cardinal] Rodrigo Borgia, and on the death of Innocent VIII in 1492 Borgia by means of a secret agreement and simony with Ascanio Sforza succeeded in being elected by a large majority, under the name of Pope Alexander VI." Della Rovere, jealous and angry, hated Borgia for being elected over him.

On 31 August 1492 the new Pope, Alexander VI, held a consistory in which he named six cardinal legates, one of whom was Giuliano della Rovere, who was appointed Legate in Avignon. Cardinal Giuliano was increasingly alarmed by the powerful position assumed by Cardinal Ascanio Sforza and the Milanese faction in the Court of Alexander VI, and after Christmas Day in December 1492 chose to withdraw to his fortress in the town and diocese of Ostia, at the mouth of the Tiber River. In that same month, Federico of Altamura, the second son of King Ferdinando (Ferrante) of Naples was in Rome to pay homage to the new pope, and he reported back to his father that Alexander and Cardinal Sforza were working on establishing new alliances, which would upset Ferrante's security arrangements. Ferrante, therefore, decided to use Della Rovere as the center of an anti-Sforza party at the papal court, a prospect made easier since Ferrante had prudently repaired his relations with Cardinal Giuliano after the War of the Barons. He also warned King Ferdinand and Queen Isabella of Spain that Alexander was intriguing with the French, which brought an immediate visit of a Spanish ambassador to the Pope. In June Federico of Altamura was back in Rome, and held conversations with Della Rovere, assuring him of Neapolitan protection. On 24 July 1493, Cardinal della Rovere returned to Rome (despite the warnings of Virginius Orsini) and dined with the Pope.

Della Rovere at once determined to take refuge from Borgia's wrath at Ostia. On 23 April 1494, the Cardinal took ship, having placed his fortress at Ostia in the hands of his brother Giovanni della Rovere, and traveled to Genoa and then to Avignon. He was summoned by King Charles VIII to Lyons, where the two met on 1 June 1494. He joined Charles VIII of France who undertook to take Italy back from the Borgias by military force. The King entered Rome with his army on 31 December 1495, with Giuliano della Rovere riding on one side and Cardinal Ascanio Sforza riding on the other. The King made several demands of Pope Alexander, one of which was that the Castel S. Angelo be turned over to French forces. This Pope Alexander refused to do, claiming that Cardinal della Rovere would occupy it and become master of Rome. Charles soon conquered Naples, making his triumphal entry on 22 February 1495, but he was forced to remove most of his army. As he was returning to the north, his army was defeated at the Battle of Foronovo on 5 July 1495, and his Italian adventure came to an end. The last remnants of the French invasion were gone by November 1496. Ostia, however, remained in French hands until March 1497, making difficulties in the provisioning of the city of Rome.

Back in Lyon in 1496, Charles VIII and Giuliano della Rovere were planning another war. Giuliano was traveling back and forth from Lyon to Avignon, raising troops. It was being reported in France by June 1496, moreover, that King Charles intended to have a papal election in France and to have Cardinal della Rovere elected pope.

In March 1497 Pope Alexander deprived Cardinal della Rovere of his benefices as an enemy of the Apostolic See, and Giovanni della Rovere of the Prefecture of Rome. His action against the Cardinal was done not only without the consent of the cardinals in consistory, but in fact over their vigorous objections. By June, however, the Pope was in negotiations with the Cardinal for reconciliation and return to Rome. His benefices were restored to him after an apparent reconciliation with the Pope in August 1498.

King Charles VIII of France, the last of the senior branch of the House of Valois, died on 7 April 1498 of after accidentally striking his head on the lintel of a door at the Château d'Amboise. When Cesare Borgia passed through southern France in October 1498 on his way to meet King Louis XII for his investiture as Duke of Valentinois, he stopped in Avignon and was magnificently entertained by Cardinal della Rovere. They then moved on to meet the King at Chinon, where Cesare Borgia fulfilled one of the terms of the treaty between Louis and Alexander by producing the red hat of a cardinal, which had been promised for the Archbishop of Rouen, Georges d'Amboise. It was Cardinal della Rovere, the Papal Legate, who placed the hat on Amboise's head.

Louis wanted an annulment from Queen Joan so he could marry Anne of Brittany, in the hope of annexing the Duchy of Brittany; Alexander, in turn, wanted a French princess as wife for Cesare. Della Rovere, who was trying to repair his relations with the House of Borgia, was also involved in another clause of the treaty, the marriage between Cesare Borgia and Carlotta, the daughter of the King of Naples, who had been brought up at the French Court. Della Rovere was in favor of the marriage, but, according to Pope Alexander, King Louis XII was not, and, most especially, Carlotta was stubbornly refusing her consent. Alexander's plan of securing a royal throne for his son fell through, and he was very angry. Louis offered Cesare another of his relatives, the "beautiful and rich" Charlotte d'Albret, whom Cesare married at Blois on 13 May 1499.

The marriage produced a complete "volta facie" in Pope Alexander. He became an open partisan of the French and Venice, and accepted their goal, the destruction of the Sforza hold on Milan. On 14 July, Cardinal Ascanio Sforza, della Rovere's sworn enemy, fled Rome with all his property and friends. Meanwhile, the French army crossed the Alps and captured Alessandria in Piedmont. On 1 September 1499 Lodovico "Il Moro" fled Milan, and on 6 September the city surrendered to the French. Cardinal Giuliano was in the King's entourage when he entered Milan on 6 October.

Pope Alexander then turned his attention, stimulated by the Venetians, to the threat of the Osmanli Turks. In the autumn of 1499, he called for a crusade and sought aid and money from all Christendom. The rulers of Europe paid little attention, but to show his sincerity Alexander imposed a tithe on all the residents of the Papal States and a tithe on the clergy of the entire world. A list of cardinals and their incomes, drawn up for the occasion, shows that Cardinal della Rovere was the second-richest cardinal, with an annual income of 20,000 ducats.

Another break in relations between Pope Alexander and Cardinal Giuliano came at the end of 1501 or the beginning of 1502 when Giuliano was transferred from the Bishopric of Bologna to the diocese of Vercelli.

On 21 June 1502, Pope Alexander sent his secretary, Francesco Troche (Trochia), and Cardinal Amanieu d'Albret (brother-in-law of Cesare Borgia) to Savona to seize Cardinal della Rovere by stealth and bring him back to Rome as quickly as possible and turn him over to the Pope. The kidnapping party returned to Rome on 12 July, without having accomplished its mission. On 20 July 1502, Cardinal Giovanni Battista Ferrari died in his rooms at the Vatican Palace; he had been poisoned, and his property was claimed by the Borgia. On 3 January 1503, Cardinal Orsini was arrested and sent to the Castel S. Angelo; on 22 February he died there, poisoned on orders of Alexander VI.

A veteran of the Sacred College, della Rovere had won influence for the election of Pope Pius III with the help of Florentine Ambassador to Naples, Lorenzo de' Medici. In spite of a violent temper della Rovere succeeded by dexterous diplomacy in winning the support of Cesare Borgia, whom he won over by his promise of money and continued papal backing for Borgia policies in the Romagna. This election was, in Ludwig von Pastor's view, certainly achieved by means of bribery with money, but also with promises. "Giuliano, whom the popular voice seemed to indicate as the only possible pope, was as unscrupulous as any of his colleagues in the means which he employed. Where promises and persuasions were unavailing, he did not hesitate to have recourse to bribery." Indeed, his election on 1 November 1503 took only a few hours, and the only two votes he did not receive were his own and the one of Georges d'Amboise, his most vigorous opponent and the favourite of the French monarchy. In the end, as in all papal elections, the vote is made unanimous after the leading candidate has achieved the required number of votes for election.

Giuliano Della Rovere thenceforth took the name of his fourth-century predecessor, Julius I, and was pope for nine years, from 1503 to 1513. From the beginning, Julius II set out to defeat the various powers that challenged his temporal authority; in a series of complicated stratagems, he first succeeded in rendering it impossible for the Borgias to retain their power over the Papal States. Indeed, on the day of his election, he declared: Others indicate that his decision was taken on 26 November 1507, not in 1503. The Borgia Apartments were turned to other uses. The "Sala de Papi" was redecorated by two pupils of Raphael by order of Pope Leo X. The rooms were used to accommodate Emperor Charles V on his visit to the Vatican after the Sack of Rome (1527), and subsequently, they became the residence of the Cardinal-nephew and then the Secretary of State.

Julius used his influence to reconcile two powerful Roman families, the Orsini and Colonna. Decrees were made in the interests of the Roman nobility, in whose shoes the new pope now stepped. Being thus secure in Rome and the surrounding country, he set himself the task to expel the Republic of Venice from Faenza, Rimini, and the other towns and fortresses of Italy which it occupied after the death of Pope Alexander. In 1504, finding it impossible to succeed with the Doge of Venice by remonstrance, he brought about a union of the conflicting interests of France and the Holy Roman Empire, and sacrificed temporarily to some extent the independence of Italy to conclude with them an offensive and defensive alliance against Venice. The combination was, however, at first little more than nominal, and was not immediately effective in compelling the Venetians to deliver up more than a few unimportant places in the Romagna. With a campaign in 1506, he personally led an army to Perugia and Bologna, freeing the two papal cities from their despots, Giampolo Baglioni and Giovanni II Bentivoglio.

In December 1503, Julius issued a dispensation allowing the future Henry VIII of England to marry Catherine of Aragon; Catherine had previously been briefly married to Henry's older brother Prince Arthur, who had died, but Henry later argued that she had remained a virgin for the five months of the marriage. Some twenty years later, when Henry was attempting to wed Anne Boleyn (since his son by Catherine of Aragon survived only a few days, and two of her sons were stillborn, and therefore he had no male heir), he sought to have his marriage annulled, claiming that the dispensation of Pope Julius should never have been issued. The retractation of the dispensation was refused by Pope Clement VII.

The Bull entitled "Ea quae pro bono pacis" issued on 24 January 1506, confirmed papal approval of the "mare clausum" policy being pursued by Spain and Portugal amid their explorations, and approved the changes of the 1494 Treaty of Tordesillas to previous papal bulls. In the same year, the Pope founded the Swiss Guard to provide a constant corps of soldiers to protect the Vatican City. As part of the Renaissance program of reestablishing the glory of antiquity for the Christian capital, Rome, Julius II took considerable effort to present himself as a sort of emperor-pope, capable of leading a Latin-Christian empire. On Palm Sunday, 1507, "Julius II entered Rome . . . both as a second Julius Caesar, heir to the majesty of Rome's imperial glory, and in the likeness of Christ, whose vicar the pope was, and who in that capacity governed the universal Roman Church." Julius, who modeled himself after his namesake Caesar, would personally lead his army across the Italian peninsula under the imperial war-cry, "Drive out the barbarians." Yet, despite the imperial rhetoric, the campaigns were highly localized. Perugia voluntarily surrendered in March 1507 to direct control, as it had always been within the Papal States; it was in these endeavors he had enlisted French mercenaries. 

Urbino's magnificent court palace was infiltrated by French soldiers in the pay of the Duke of Gonzaga; the Montefeltro Conspiracy against his loyal cousins earned the occupying armies the Pope's undying hatred. Julius relied upon Guidobaldo's help to raise his nephew and heir Francesco Maria della Rovere; the intricate web of nepotism helped secure the Italian Papacy. Moreover, the Pope's interest in Urbino was widely known in the French court. Julius left a spy at the Urbino Palace, possibly Galeotto Franciotti della Rovere, Cardinal of San Pietro, to watch the Mantua stables in total secret; the secular progress of the Papal Curia was growing in authority and significance. In Rome, the Pope watched from his private chapel to see how his court behaved. This was an age of Renaissance conspiracy.

In addition to an active military policy, the new pope personally led troops into battle on at least two occasions, the first to expel Giovanni Bentivoglio from Bologna (17 August 1506 – 23 March 1507), which was achieved successfully with the assistance of the Duchy of Urbino. The second was an attempt to recover Ferrara for the Papal States (1 September 1510 – 29 June 1512). In 1508, Julius was fortuitously able to form the League of Cambrai with Louis XII, King of France, Maximilian I, Holy Roman Emperor (proclaimed without coronation as Emperor by Pope Julius II at Trent in 1508) and Ferdinand II, King of Aragon. The League fought against the Republic of Venice. Among other things, Julius wanted possession of Venetian Romagna; Emperor Maximilian I wanted Friuli and Veneto; Louis XII wanted Cremona, and Ferdinand II desired the Apulian ports. This war was a conflict in what was collectively known as the "Italian Wars". In the spring of 1509, the Republic of Venice was placed under an interdict by Julius, In May 1509 Julius sent troops to fight against the Venetians who had occupied parts of the Romagna winning back the Papal States in a decisive battle near Cremona. During the War of the Holy League alliances kept changing: in 1510 Venice and France switched places, and by 1513, Venice had joined France. The achievements of the League soon outstripped the primary intention of Julius. In one single battle, the Battle of Agnadello on 14 May 1509, the dominion of Venice in Italy was practically lost to His Holiness. Yet neither the King of France nor the Holy Roman Emperor was satisfied with merely effecting the purposes of the Pope, the latter found it necessary to enter into an arrangement with the Venetians to defend himself from those who immediately before had been his allies. The Venetians, on making humble submission, were absolved at the beginning of 1510, and shortly afterward France was placed under papal interdict.
Attempts to cause a rupture between France and England proved unsuccessful; on the other hand, at a synod convened by Louis at Tours in September 1510, the French bishops withdrew from papal obedience, and resolved, with the Emperor's co-operation, to seek dethronement of the pope. With some courage Julius marched his army to Bologna and then against the French to Mirandola. In November 1511, a council met at Pisa, called by rebel cardinals with support from the French king and the Empire, they demanded the deposition of Charles II at Pisa. Despite being seriously he refused to shave showing utter contempt for the hated French occupation. "per vendicarsi et diceva...anco fuora scazato el re Ludovico Franza d'Italia."
Whereupon Julius entered into another Holy League of 1511: in alliance with Ferdinand II of Aragon and the Venetians he conspired against the Gallican liberties. In a short time, both Henry VIII, King of England (1509–47), and Maximilian I also joined the Holy League of 1511 against France. Ferdinand of Spain now recognized Naples as a papal fief, invested in 1511, and therefore Julius II now regarded France as the main foreign power in the Italian peninsula hostile to Papal interests. Louis XII defeated the alliance at Battle of Ravenna on 11 April 1512. When a desperate battle felled over 20,000 men in a bloodbath the Pope commanded his protege, a newly-released young Cardinal Medici to re-take Florence with a Spanish army. The rescue of the city on 1 September 1512 saved Rome from another invasion, ousting Soderini, and returning the dynastic rule of the Medici. Julius had seemingly restored "fortuna" or control by exercising his manly "vertu", just as Machiavelli wrote. This re-asserted a strong relation between Florence and Rome; a lasting legacy of Julius II. Yet Machiavelli and his methods would not outlast Julius' Papacy. Julius hired Swiss mercenaries to fight against the French in Milan in May 1512.

When Swiss mercenaries came to the Pope's aid, the French army withdrew across the Alps into Savoy in 1512. The papacy gained control of Parma and Piacenza in central Italy. With the French out of Italy and Spain recognizing Naples as a papal fief with a cardinal as viceroy, a Congress was held in Mantua by Julius II to declare the liberation of the peninsula. Nevertheless, although Julius had centralized and expanded the Papal States, he was far from realizing his dream of an independent Italian kingdom. In fact, some years after his death, the treaties of Noyon and Brussels in 1516 will divide again Italy between French and Spanish influence.

In May 1512 a general or ecumenical council, the Fifth Council of the Lateran, was held in Rome. According to an oath taken on his election to observe the Electoral Capitulations of the Conclave of October 1513, Julius had sworn to summon a general council, but it had been delayed, he affirmed, because of the occupation of Italy by his enemies. The real stimulus came from a false council which took place in 1511, called the "Conciliabulum Pisanum", inspired by Louis XII and Maximilian I as a tactic to weaken Julius, and which threatened Julius II with deposition. Julius' reply was the issuing of the bull "Non-sini gravi" of 18 July 1511, which fixed the date of 19 April 1512 for the opening of his own council. The Council actually convened on 3 May, and Paris de Grassis reports that the crowd at the basilica was estimated at 50,000. It held its first working session on 10 May. In the third plenary session, on 3 December 1512, Julius attended, though he was ill; but he wanted to witness and receive the formal adhesion of Emperor Maximilian to the Lateran Council and his repudiation of the "Conciliabulum Pisanum". This was one of Julius' great triumphs. The Pope was again in attendance at the fourth session on 10 December, this time to hear the accrediting of the Venetian Ambassador as the Serene Republic's representative at the Council; he then had the letter of King Louis XI (of 27 November 1461), in which he announced the revocation of the Pragmatic Sanction, read out to the assembly, and demanded that all persons who accepted the Pragmatic Sanction appear before the Council within sixty days to justify their conduct. This was directed against King Louis XII.

The fifth session was held on 16 February, but Pope Julius was too ill to attend. Cardinal Raffaele Riario, the Dean of the College of Cardinals and Bishop of Ostia, presided. The Bishop of Como, Scaramuccia Trivulzio, then read from the pulpit a bull of Pope Julius, "Si summus rerum", dated that very day and containing within its text the complete bull of 14 January 1505, "Cum tam divino". The bull was submitted to the Council fathers for their consideration and ratification. Julius wanted to remind everyone of his legislation on papal conclaves, in particular against simony, and to fix his regulations firmly in canon law so that they could not be dispensed or ignored. Julius was fully aware that his death was imminent, and though he had been a witness to a good deal of simony at papal conclaves and had been a practitioner himself, he was determined to stamp out the abuse. The reading of the bull "Cum tam divino" became a regular feature of the first day of every conclave.

On the Vigil of Pentecost in May 1512, Pope Julius, aware that he was seriously ill and that his health was failing, despite comments on the part of some cardinals about how well he looked, remarked to Paris de Grassis, "They are flattering me; I know better; my strength diminishes from day to day and I cannot live much longer. Therefore I beg you not to expect me at Vespers or at Mass from henceforth." Nonetheless, he continued his restless activities, including Masses, visits to churches, and audiences. On 24 June, in the morning Paris found the Pope "debilem et semifebricantem". On Christmas Eve, Julius ordered Paris to summon the College of Cardinals and the Sacristan of the Apostolic Palace, "quia erat sic infirmus, quod non-speraret posse diu supravivere." From then until 6 January he was confined to bed, and most of the time with a fever; he had lost his appetite, but the doctors were unable to diagnose his languor. On 4 February he had an extensive conversation with Paris concerning the arrangements for his funeral.

Pope Julius was reported to be seriously ill in a dispatch received in Venice on 10 February 1513. He received Holy Communion and was granted the plenary indulgence on the morning of 19 February, according to the Venetian Ambassador. On the 20th, according to Paris de Grassis, he received Holy Communion from the hands of Cardinal Raffaele Riario, the Camerlengo. He died of a fever in the night of 20–21 February 1513.

On the evening of 21 February, Paris de Grassis conducted the funeral of Julius II, even though the Canons of the Vatican Basilica and the beneficiati refused to cooperate. The body was placed for a time at the Altar of Saint Andrew in the Basilica and was then carried by the Imperial Ambassador, the papal Datary, and two of Paris' assistants to the altar of the Chapel of Pope Sixtus, where the Vicar of the Vatican Basilica performed the final absolution. At the third hour of the evening, the body was laid in a sepulcher between the altar and the wall of the tribune.

Despite the fact that the so-called "Tomb of Julius" by Michelangelo is in San Pietro in Vincoli in Rome, Julius is in fact buried in the Vatican. Michelangelo's tomb was not completed until 1545 and represents a much-abbreviated version of the planned original, which was initially intended for the new St. Peter's Basilica. His remains lay alongside his uncle, Pope Sixtus IV, but were later desecrated during the Sack of Rome in 1527. Today both men lie in St. Peter's Basilica on the floor in front of the monument to Pope Clement X. A simple marble tombstone marks the site. Julius II was succeeded by Pope Leo X.

In 1484 Cardinal Giuliano della Rovere had begun negotiations to persuade Marquis Francesco Gonzaga of Mantua to allow Andrea Mantegna to come to Rome, which finally bore fruit in 1488; Mantegna was given the commission to decorate the chapel of the Belvedere for Pope Innocent VIII, on which he spent two years.

Beyond Julius II's political and military achievements, he enjoys a title to honor in his patronage of art, architecture, and literature. He did much to improve and beautify the city.

Early in his papacy, Julius decided to revive the plan for replacing the dilapidated Constantinian basilica of St. Peter's. The idea was not his, but originally that of Nicholas V, who had commissioned designs from Bernardo Rossellino. Other more pressing problems distracted the attention of Nicholas and subsequent popes, but Julius was not the sort of person to be distracted once he had settled on an idea, in this case, for the greatest building on earth, for the glory of Saint Peter and himself. In the competition for a building plan, the design of Rossellino was immediately rejected as being out of date. A second design was submitted by Giuliano da Sangallo, an old friend of Julius, who had worked on several projects for him before, including the palazzo at S. Pietro in Vincoli, and who had left Rome with Julius when he fled the wrath of Alexander VI in 1495. Through Cardinal della Rovere, Sangallo had presented Charles VIII a plan for a palace, and in 1496 he had made a tour of the architectural monuments of Provence, returning to his native Florence in 1497. His proposals for S. Peter's, however, were not accepted despite what he believed to be a promise, and he retired in anger to Florence.

On 18 April 1506 Pope Julius II laid the foundation stone of the new St. Peter's Basilica for the successful architect, Donato Bramante. However, he also began the demolition of the old St. Peter's Basilica, which had stood for more than 1,100 years. He was a friend and patron of Bramante and Raphael, and a patron of Michelangelo. Several of Michelangelo's greatest works (including the painting of the ceiling of the Sistine Chapel) were commissioned by Julius.

Long before he became Pope, Julius had a violent temper. He often treated subordinates and people who worked for him very badly. His manner was gruff and coarse, just as his peasant-like sense of humour. Others suggest that Julius had little sense of humor. Ludwig von Pastor wrote, "Paris de Grassis, his Master of Ceremonies, who has handed on to us so many characteristic features of his master's life, says that he hardly ever jested. He was generally absorbed in deep and silent thought..."

To most historians Julius was manly and virile, an energetic man of action, whose courage saved the Papacy. There was a sense that war caused him serious illness, exhaustion, and fatigue, that most popes could not have withstood. To many Julius II has been described as the best in an era of exceptionally bad popes: Alexander VI was evil and despotic, exposing the future Julius II to a number of assassination attempts that required tremendous fortitude.

Julius II is usually depicted with a beard, after his appearance in the celebrated portrait by Raphael, the artist whom he first met in 1509. However, the pope only wore his beard from 27 June 1511 to March 1512, as a sign of mourning at the loss of the city of Bologna by the Papal States. He was nevertheless the first pope since antiquity to grow facial hair, a practice otherwise forbidden by canon law since the 13th century. The pope's hirsute chin may have raised severe, even vulgar criticism, as at one Bologna banquet held in 1510 at which papal legate Marco Cornaro was present. In overturning the ban on beards Pope Julius challenged Gregorian conventional wisdom in dangerous times. Julius shaved his beard again before his death, and his immediate successors were clean-shaven; nonetheless Pope Clement VII sported a beard when mourning the sack of Rome. Thenceforward, all popes were bearded until the death of Pope Innocent XII in 1700.

The frescoes on the ceiling of Stanza d'Eliodoro in the stanze of Raphael depict the traumatic events in 1510–11 when the Papacy regained its freedom. Although Raphael's original was lost, it was thought to relate closely to the personal iconography of Stanza della Segnatura, commissioned by Pope Julius himself. The Lateran Council that formed the Holy League marked a high point in his personal success. Saved by an allegory to the Expulsion of Helidorus, the French gone, Julius collapsed once again in late 1512, very seriously ill once more.

Julius was not the first pope to have fathered children before being elevated to high office, and is believed to have had a daughter born to Lucrezia Normanni in 1483 – after he had been made a cardinal. Felice della Rovere survived into adulthood. Shortly after Felice was born, Julius arranged for Lucrezia to marry Bernardino de Cupis, Chamberlain to Julius's cousin, Cardinal Girolamo Basso della Rovere.

Despite producing an illegitimate daughter (and having at least one mistress), it was suggested that Julius may have had homosexual lovers - although it is not possible to establish this claim. His confrontational style inevitably created enemies and sodomy was the "common currency of insult and innuendo". Such accusations were made to discredit him, but perhaps in so doing his accusers were attacking a perceived weakness. The Venetians, who were implacably opposed to the pope's new military policy, were among the most vociferous opponents; notable among them were the diarist Girolamo Priuli, and the historian Marino Sanudo. Erasmus also impropriated sexual misconduct in his 1514 dialogues ""Julius Excluded from Heaven""; a theme picked up in the denunciation made at the conciliabulum of Pisa. Criticism was furthermore made of the sinister influence exerted by his advisor, Francesco Alidosi, whom Julius had made a cardinal in 1505. However, it is likely that the closeness was down to the fact that he simply knew how to handle him well. This sexual reputation survived Julius, and the accusation continued to be made without reservation by Protestant opponents in their polemics against "papism" and Catholic decadence. The French writer Philippe de Mornay (1549–1623) accused all Italians of being sodomites, but added specifically: "This horror is ascribed to good Julius."






 


</doc>
<doc id="24759" url="https://en.wikipedia.org/wiki?curid=24759" title="Proteus">
Proteus

In Greek mythology, Proteus (; Ancient Greek: Πρωτεύς) is an early prophetic sea-god or god of rivers and oceanic bodies of water, one of several deities whom Homer calls the "Old Man of the Sea" "(halios gerôn)". Some who ascribe a specific domain to Proteus call him the god of "elusive sea change", which suggests the constantly changing nature of the sea or the liquid quality of water. He can foretell the future, but, in a mytheme familiar to several cultures, will change his shape to avoid doing so; he answers only to those who are capable of capturing him. From this feature of Proteus comes the adjective protean, meaning "versatile", "mutable", or "capable of assuming many forms". "Protean" has positive connotations of flexibility, versatility and adaptability.

Proteus' name suggests the "first" (from Greek "πρῶτος" "prōtos", "first"), as "prōtogonos" (πρωτόγονος) is the "primordial" or the "firstborn". It is not certain to what this refers, but in myths where he is the son of Poseidon, it possibly refers to his being Poseidon's eldest son, older than Poseidon's other son, the sea-god Triton. The first attestation of the name, although it is not certain whether it refers to the god or just a person, is in Mycenaean Greek; the attested form, in Linear B, is , "po-ro-te-u".

Proteus was generally regarded as the son of the sea-god Poseidon. The children of Proteus, besides Eidothea, include Polygonus and Telegonus, who both challenged Heracles at the behest of Hera and were killed, one of Heracles' many successful encounters with representatives of the pre-Olympian world order. Cabeiro, mother of the Cabeiri and the three Cabeirian nymphs by Hephaestus, was also called the daughter of Proteus.

According to Homer ("Odyssey" iv: 355), the sandy island of Pharos situated off the coast of the Nile Delta was the home of Proteus, the oracular Old Man of the Sea and herdsman of the sea-beasts. In the "Odyssey", Menelaus relates to Telemachus that he had been becalmed here on his journey home from the Trojan War. He learned from Proteus' daughter Eidothea ("the very image of the Goddess"), that if he could capture her father, he could force him to reveal which of the gods he had offended and how he could propitiate them and return home. Proteus emerged from the sea to sleep among his colony of seals, but Menelaus was successful in holding him, though Proteus took the forms of a lion, a serpent, a leopard, a pig, even of water or a tree. Proteus then answered truthfully, further informing Menelaus that his brother Agamemnon had been murdered on his return home, that Ajax the Lesser had been shipwrecked and killed, and that Odysseus was stranded on Calypso's Isle Ogygia.

According to Virgil in the fourth Georgic, at one time the bees of Aristaeus, son of Apollo, all died of a disease. Aristaeus went to his mother, Cyrene, for help; she told him that Proteus could tell him how to prevent another such disaster, but would do so only if compelled. Aristaeus had to seize Proteus and hold him, no matter what he would change into. Aristaeus did so, and Proteus eventually gave up and told him that the bees' death was a punishment for causing the death of Eurydice. To make amends, Aristaeus needed to sacrifice 12 animals to the gods, leave the carcasses in the place of sacrifice, and return three days later. He followed these instructions, and upon returning, he found in one of the carcasses a swarm of bees which he took to his apiary. The bees were never again troubled by disease.

There are also legends concerning Apollonius of Tyana that say Proteus incarnated himself as the 1st century philosopher. These legends are mentioned in the 3rd century biographical work "Life of Apollonius of Tyana".

In the "Odyssey" (iv.430ff) Menelaus wrestles with "Proteus of Egypt, the immortal old man of the sea who never lies, who sounds the deep in all its depths, Poseidon's servant" (Robert Fagles's translation). Proteus of Egypt is mentioned in an alternative version of the story of Helen of Troy in the tragedy "Helen" of Euripides (produced in 412 BC). The often unconventional playwright introduces a "real" Helen and a "phantom" Helen (who caused the Trojan War), and gives a backstory that makes the father of his character Theoclymenus, Proteus, a king in Egypt who had been wed to a Nereid Psamathe. In keeping with one of his themes in "Helen", Euripides mentions in passing "Eido" ("image"), a daughter of the king and therefore sister of Theoclymenus who underwent a name-change after her adolescence and became "Theonoë," "god-minded," since she was as it turned out capable of foreseeing the future--as such, she is a prophet who appears as a crucial character in the play. The play's king Proteus is already dead at the start of the action, and his tomb is present onstage. It appears that he is only marginally related to the "Old Man of the Sea" and should not be confused with the sea god Proteus, although it is tempting to see Euripides as playing a complex literary game with the sea god's history--both Proteuses, for example, are protectors of the house of Menelaus, both are connected with the sea, both dwell in Egypt, and both are "grandfatherly" or "ancient" figures.

At Pharos a king of Egypt named Proteus welcomed the young god Dionysus in his wanderings. In Hellenistic times, Pharos was the site of the Lighthouse of Alexandria, one of the seven wonders of the ancient world.

The German mystical alchemist Heinrich Khunrath wrote of the shape-changing sea-god who, because of his relationship to the sea, is both a symbol of the unconscious as well as the perfection of the art. Alluding to the "scintilla", the spark from ‘the light of nature’ and symbol of the "anima mundi", Khunrath in Gnostic vein stated of the Protean element Mercury:

In modern times, the Swiss psychologist Carl Jung defined the mythological figure of Proteus as a personification of the unconscious, who, because of his gift of prophecy and shape-changing, has much in common with the central but elusive figure of alchemy, Mercurius.

The poet John Milton, aware of the association of Proteus with the Hermetic art of alchemy, wrote in "Paradise Lost" of alchemists who sought the philosopher's stone:
In his 1658 discourse "The Garden of Cyrus", Sir Thomas Browne, pursuing the figure of the quincunx, queried:
"Why Proteus in Homer the Symbole of the first matter, before he settled himself in the midst of his Sea-Monsters, doth place them out by fives?"

Shakespeare uses the image of Proteus to establish the character of his great royal villain Richard III in the play "Henry VI, Part Three", in which the future usurper boasts:
Shakespeare also names one of the main characters of his play "The Two Gentlemen of Verona" Proteus. Inconsistent with his affections, his deceptions have unraveled at the finale of the play as he is brought face-to-face with his friend Valentine and original love Julia:
In 1807, William Wordsworth finished his sonnet on the theme of a modernity deadened to Nature, which opens "The world is too much with us", with a sense of nostalgia for the lost richness of a world numinous with deities: 
In James Joyce's "Ulysses", uses Protean transformations of matter in time for self exploration. "Proteus" is the title provided for the third chapter in the Linati schema for Ulysses.

The protagonist of Kurt Vonnegut's 1952 novel "Player Piano" is an engineer named Paul Proteus.

"Proteus" is the name of the submarine in the original story by Otto Klement and Jay Lewis Bixby, which became the basis for the 1966 film "Fantastic Voyage" and Isaac Asimov's novelization.

John Barth's novelette "Menelaiad" in "Lost in the Funhouse" is built around a battle between Proteus and Menelaus. It is told as a multiply-nested frame tale, and the narrators bleed into each other as the battle undermines their identities.

"Proteus: The City" is the title of Book Four of Thomas Wolfe's autobiographical novel "Of Time and the River".

As a concept and as a word, Proteus is not a commonly used term today, but has been adopted by some companies to be an interesting concept for the basis of their business names, ranging from healthcare to industrial supplies all the way to sports nutrition and supplementation.

In medicine, Proteus syndrome refers to a rare genetic condition characterized by symmetric overgrowth of the bones, skin, and other tissues. Organs and tissues affected by the disease grow out of proportion to the rest of the body. This condition is associated with mutations of the PTEN gene. Proteus also refers to a genus of Gram-negative Proteobacteria, some of which are opportunistic human pathogens known to cause urinary tract infections, most notably. "Proteus mirabilis" is one of these and is most referenced in its tendency to produce "stag-horn" calculi composed of struvite (magnesium ammonium phosphate) that fill the human renal pelvis.

In Professional Wrestling, British company PROGRESS Wrestling has announced the introduction of a Proteus Championship. The current holder of the championship will be allowed to declare the type of match they will defend the championship in, with each new champion being able to set their own match type. The name of the championship was chosen due to its ever-changing nature, reflecting the shape-changing abilities of the deity it was named for.

The protist Amoeba proteus is named for the Greek god, as it has no fixed shape and constantly changes form.





</doc>
<doc id="24760" url="https://en.wikipedia.org/wiki?curid=24760" title="Pope Eusebius">
Pope Eusebius

Pope Eusebius (from Greek Εὐσέβιος "pious"; died 17 August 310) was the Bishop of Rome from 18 April 310 until his death four months later.

His pontificate lasted four months, after which, in consequence of disturbances within the Roman Church which led to acts of violence, he was banished by the emperor Maxentius, who had been the ruler of Rome since 306, and had at first shown himself friendly to the Christians. The difficulty arose, as in the case of his predecessor Pope Marcellus I, out of his attitude toward the lapsi.

Eusebius maintained the attitude of the Roman Church, adopted after the Decian persecutions (250-51), that the apostates should not be forever debarred from ecclesiastical communion, but on the other hand, should be readmitted only after doing proper penance. This view was opposed by a faction of Christians in Rome under the leadership of Heraclius. Johann Peter Kirsch believes it likely that Heraclius was the chief of a party made up of apostates and their followers, who demanded immediate restoration to the Roman Church. Maxentius exiled them both.

Eusebius died in exile in Sicily and was buried in the catacomb of Callixtus. Pope Damasus I placed an epitaph of eight hexameters over his tomb because of his firm defense of ecclesiastical discipline and the banishment which he suffered thereby.

His feast is celebrated on 26 September.




</doc>
<doc id="24761" url="https://en.wikipedia.org/wiki?curid=24761" title="Persian Gulf">
Persian Gulf

The Persian Gulf () is a mediterranean sea in Western Asia. The body of water is an extension of the Indian Ocean (Gulf of Oman) through the Strait of Hormuz and lies between Iran to the northeast and the Arabian Peninsula to the southwest. The Shatt al-Arab river delta forms the northwest shoreline.

The body of water is historically and internationally known as the "Persian Gulf". Some Arab governments refer to it as the "Arabian Gulf" () or "The Gulf", but neither term is recognized globally. The name "Gulf of Iran (Persian Gulf)" is used by the International Hydrographic Organization.

The Persian Gulf was a battlefield of the 1980–1988 Iran–Iraq War, in which each side attacked the other's oil tankers. It is the namesake of the 1991 Gulf War, the largely air- and land-based conflict that followed Iraq's invasion of Kuwait.

The Persian Gulf has many fishing grounds, extensive reefs (mostly rocky, but also coral), and abundant pearl oysters, but its ecology has been damaged by industrialization and oil spills.

The Persian Gulf is in the Persian Gulf Basin, which is of Cenozoic origin and related to the subduction of the Arabian Plate under the Zagros Mountains. The current flooding of the basin started 15,000 years ago due to rising sea levels of the Holocene glacial retreat.

This inland sea of some is connected to the Gulf of Oman in the east by the Strait of Hormuz; and its western end is marked by the major river delta of the Shatt al-Arab, which carries the waters of the Euphrates and the Tigris. In Iran this is called "Arvand Rood", where "Rood" means "river". Its length is , with Iran covering most of the northern coast and Saudi Arabia most of the southern coast. The Persian Gulf is about wide at its narrowest, in the Strait of Hormuz. The waters are overall very shallow, with a maximum depth of and an average depth of .

Countries with a coastline on the Persian Gulf are (clockwise, from the north): Iran; Oman's Musandam exclave; the United Arab Emirates; Saudi Arabia; Qatar, on a peninsula off the Saudi coast; Bahrain, on an island; Kuwait; and Iraq in the northwest. Various small islands also lie within the Persian Gulf, some of which are the subject of territorial disputes between the states of the region.

The International Hydrographic Organization defines the Persian Gulf's southern limit as "The Northwestern limit of Gulf of Oman". This limit is defined as "A line joining Ràs Limah (25°57'N) on the coast of Arabia and Ràs al Kuh (25°48'N) on the coast of Iran (Persia)".

The Persian Gulf is connected to the Indian Ocean through the Strait of Hormuz. Writing the water balance budget for the Persian Gulf, the inputs are river discharges from Iran and Iraq (estimated to be per second), as well as precipitation over the sea which is around /year in Qeshm Island. The evaporation of the sea is high, so that after considering river discharge and rain contributions, there is still a deficit of per year. This difference is supplied by currents at the Strait of Hormuz. The water from the Persian Gulf has a higher salinity, and therefore exits from the bottom of the Strait, while ocean water with less salinity flows in through the top. Another study revealed the following numbers for water exchanges for the Persian Gulf: evaporation = -/year, precipitation = /year, inflow from the Strait = /year, outflow from the Strait = -/year, and the balance is 0 m (0 ft)/year. Data from different 3D computational fluid mechanics models, typically with spatial resolution of and depth each element equal to are predominantly used in computer models.

The Persian Gulf and its coastal areas are the world's largest single source of petroleum, and related industries dominate the region. Safaniya Oil Field, the world's largest offshore oilfield, is located in the Persian Gulf. Large gas finds have also been made, with Qatar and Iran sharing a giant field across the territorial median line (North Field in the Qatari sector; South Pars Field in the Iranian sector). Using this gas, Qatar has built up a substantial liquefied natural gas (LNG) and petrochemical industry.

In 2002, the Persian Gulf nations of Bahrain, Iran, Iraq, Kuwait, Qatar, Saudi Arabia, and the UAE produced about 25% of the world's oil, held nearly two-thirds of the world's crude oil reserves, and about 35% of the world's natural gas reserves. The oil-rich countries (excluding Iraq) that have a coastline on the Persian Gulf are referred to as the "Persian Gulf States". Iraq's egress to the Persian gulf is narrow and easily blockaded consisting of the marshy river delta of the Shatt al-Arab, which carries the waters of the Euphrates and the Tigris rivers, where the east bank is held by Iran.

In 550 BC, the Achaemenid Empire established the first ancient empire in Persis ("Pars", or modern "Fars"), in the southwestern region of the Iranian plateau. Consequently, in the Greek sources, the body of water that bordered this province came to be known as the "Persian Gulf".

During the years 550 to 330 BC, coinciding with the sovereignty of the Achaemenid Persian Empire over the Middle East area, especially the whole part of the Persian Gulf and some parts of the Arabian Peninsula, the name of "Pars Sea" is widely found in the compiled written texts.

In the travel account of Pythagoras, several chapters are related to description of his travels accompanied by the Achaemenid king Darius the Great, to Susa and Persepolis, and the area is described. From among the writings of others in the same period, there is the inscription and engraving of Darius the Great, installed at junction of waters of Red Sea and the Nile river and the Rome river (current Mediterranean) which belongs to the 5th century BC where Darius the Great has named the Persian Gulf Water Channel: "Pars Sea" ("Persian Sea"). King Darius says:

Considering the historical background of the name Persian Gulf, Sir Arnold Wilson mentions in a book published in 1928 that "no water channel has been so significant as Persian Gulf to the geologists, archaeologists, geographers, merchants, politicians, excursionists, and scholars whether in past or in present. This water channel which separates the Iran Plateau from the Arabia Plate, has enjoyed an Iranian Identity since at least 2200 years ago."

Before being given its present name, the Persian Gulf was called many different names. The classical Greek writers, like Herodotus, called it "the Red Sea". In Babylonian texts, it was known as "the sea above Akkad".

The name of this gulf, historically and internationally known as the Persian Gulf after the land of Persia (Iran), has been disputed by some Arab countries since the 1960s. Rivalry between Iran and some Arab states, along with the emergence of pan-Arabism and Arab nationalism, has seen the name "Arabian Gulf" become predominant in most Arab countries. Names beyond these two have also been applied to or proposed for this body of water.

Earliest evidence of human presence on Persian Gulf islands dates back to Middle Paleolithic and consist of stone tools discovered at Qeshm Island.The world's oldest known civilization (Sumer) developed along the Persian Gulf and southern Mesopotamia. The shallow basin that now underlies the Persian Gulf was an extensive region of river valley and wetlands during the transition between the end of the Last Glacial Maximum and the start of the Holocene, which, according to University of Birmingham archaeologist Jeffrey Rose, served as an environmental refuge for early humans during periodic hyperarid climate oscillations, laying the foundations for the legend of Dilmun.

For most of the early history of the settlements in the Persian Gulf, the southern shores were ruled by a series of nomadic tribes. During the end of the fourth millennium BC, the southern part of the Persian Gulf was dominated by the Dilmun civilization. For a long time the most important settlement on the southern coast of the Persian Gulf was Gerrha. In the 2nd century the Lakhum tribe, who lived in what is now Yemen, migrated north and founded the Lakhmid Kingdom along the southern coast. Occasional ancient battles took place along the Persian Gulf coastlines, between the Sassanid Persian empire and the Lakhmid Kingdom, the most prominent of which was the invasion led by Shapur II against the Lakhmids, leading to Lakhmids' defeat, and advancement into Arabia, along the southern shore lines. During the 7th century the Sassanid Persian empire conquered the whole of the Persian Gulf, including southern and northern shores.

Between 625 BC and 226 AD, the northern side was dominated by a succession of Persian empires including the Median, Achaemenid, Seleucid and Parthian empires. Under the leadership of the Achaemenid king Darius the Great (Darius I), Persian ships found their way to the Persian Gulf. Persian naval forces laid the foundation for a strong Persian maritime presence in Persian Gulf, that started with Darius I and existed until the arrival of the British East India Company, and the Royal Navy by mid-19th century AD. Persians were not only stationed on islands of the Persian Gulf, but also had ships often of 100 to 200 capacity patrolling empire's various rivers including Shatt-al-Arab, Tigris, and the Nile in the west, as well as Sind waterway, in India.

The Achaemenid high naval command had established major naval bases located along Shatt al-Arab river, Bahrain, Oman, and Yemen. The Persian fleet would soon not only be used for peacekeeping purposes along the Shatt al-Arab but would also open the door to trade with India via Persian Gulf.

Following the fall of Achaemenid Empire, and after the fall of the Parthian Empire, the Sassanid empire ruled the northern half and at times the southern half of the Persian Gulf. The Persian Gulf, along with the Silk Road, were important trade routes in the Sassanid empire. Many of the trading ports of the Persian empires were located in or around Persian Gulf. Siraf, an ancient Sassanid port that was located on the northern shore of the Persian gulf, located in what is now the Iranian province of Bushehr, is an example of such commercial port. Siraf, was also significant in that it had a flourishing commercial trade with China by the 4th century, having first established connection with the far east in 185 AD.

Portuguese expansion into the Indian Ocean in the early 16th century following Vasco da Gama's voyages of exploration saw them battle the Ottomans up the coast of the Persian Gulf. In 1521, a Portuguese force led by commander Antonio Correia invaded Bahrain to take control of the wealth created by its pearl industry. On April 29, 1602, Shāh Abbās, the Persian emperor of the Safavid Persian Empire expelled the Portuguese from Bahrain, and that date is commemorated as National Persian Gulf day in Iran. With the support of the British fleet, in 1622 'Abbās took the island of Hormuz from the Portuguese; much of the trade was diverted to the town of Bandar 'Abbās, which he had taken from the Portuguese in 1615 and had named after himself. The Persian Gulf was therefore opened by Persians to a flourishing commerce with the Portuguese, Dutch, French, Spanish and the British merchants, who were granted particular privileges.
The Ottoman Empire reasserted itself into Eastern Arabia in 1871. Under military and political pressure from the governor of the Ottoman Vilayet of Baghdad, Midhat Pasha, the ruling Al Thani tribe submitted peacefully to Ottoman rule. The Ottomans were forced to withdraw from the area with the start of World War I and the need for troops in various other frontiers.

In World War II, the Western Allies used Iran as a conduit to transport military and industrial supply to the USSR, through a pathway known historically as the "Persian Corridor". Britain utilized the Persian Gulf as the entry point for the supply chain in order to make use of the Trans-Iranian Railway. The Persian Gulf therefore became a critical maritime path through which the Allies transported equipment to Soviet Union against the Nazi invasion.

The piracy in the Persian Gulf was prevalent until the 19th century. Many of the most notable historical instances of piracy were perpetrated by the Al Qasimi tribe. This led to the British mounting the Persian Gulf campaign of 1819. The campaign led to the signing of the General Maritime Treaty of 1820 between the British and the Sheikhs of what was then known as the 'Pirate Coast'.

From 1763 until 1971, the British Empire maintained varying degrees of political control over some of the Persian Gulf states, including the United Arab Emirates (originally called the Trucial States) and at various times Bahrain, Kuwait, Oman, and Qatar through the British Residency of the Persian Gulf.

The United States' role in the Persian Gulf grew in the second half of the Twentieth Century. On July 3, 1988, Iran Air Flight 655 was shot down by the U.S. military (which had mistaken the Airbus A300 operating the flight for an Iranian F-14 Tomcat) while it was flying over the Persian Gulf, killing all 290 people on board. On The United Kingdom maintains a profile in the region; in 2006 alone, over 1 million British nationals visited Dubai. In 2018, the UK opened a permanent military base, , in the Persian Gulf, the first since it withdrew from East of Suez in 1971 and is developing a support facility in Oman.

The Persian Gulf is home to many islands such as Bahrain, an Arab state. Geographically the biggest island in the Persian Gulf is Qeshm island located in the Strait of Hormuz and belongs to Iran. Other significant islands in the Persian Gulf include Greater Tunb, Lesser Tunb and Kish administered by Iran, Bubiyan administered by Kuwait, Tarout administered by Saudi Arabia, and Dalma administered by UAE. In recent years, there has also been addition of artificial islands for tourist attractions, such as The World Islands in Dubai and The Pearl-Qatar in Doha. Persian Gulf islands are often also historically significant, having been used in the past by colonial powers such as the Portuguese and the British in their trade or as acquisitions for their empires.

Eight nations have coasts along the Persian Gulf: Bahrain, Iran, Iraq, Kuwait, Oman, Qatar, Saudi Arabia, and the United Arab Emirates. The Persian gulf's strategic location has made it an ideal place for human development over time. Today, many major cities of the Middle East are located in this region.

The wildlife of the Persian Gulf is diverse, and entirely unique due to the Persian gulf's geographic distribution and its isolation from the international waters only breached by the narrow Strait of Hormuz. The Persian Gulf has hosted some of the most magnificent marine fauna and flora, some of which are near extirpation or at serious environmental risk. From corals, to dugongs, Persian Gulf is a diverse cradle for many species who depend on each other for survival. However, the Persian gulf is not as biologically diverse as the Red Sea.

Overall, the wild life of the Persian Gulf is endangered from both global factors, and regional, local negligence. Most pollution is from ships; land generated pollution counts as the second most common source of pollution.

Along the mediterranean regions of the Arabian Sea, including the Persian Gulf, the Red Sea, the Gulf of Kutch, the Gulf of Suez, the Gulf of Aqaba, the Gulf of Aden, and the Gulf of Oman, dolphins and finless porpoises are the most common marine mammals in the waters, while larger whales and orcas are rarer today. Historically, whales had been abundant in the Persian gulf before commercial hunts wiped them out. Whales were reduced even further by illegal mass hunts by the Soviet Union and Japan in the 1960s and 1970s. Along with Bryde's whales, these once common residents can still can be seen in deeper marginal seas such as Gulf of Aden, Israel coasts, and in the Strait of Hormuz. Other species such as the critically endangered Arabian humpback whale, (also historically common in Gulf of Aden and increasingly sighted in the Red Sea since 2006, including in the Gulf of Aqaba), omura's whale, minke whale, and orca also swim into the Persian gulf, while many other large species such as blue whale, sei, and sperm whales were once migrants into the Gulf of Oman and off the coasts in deeper waters, and still migrate into the Red Sea, but mainly in deeper waters of outer seas. In 2017, waters of the Persian Gulf along Abu Dhabi were revealed to hold the world's largest population of Indo-Pacific humpbacked dolphins.

One of the more unusual marine mammals living in the Persian Gulf is the dugong ("Dugong dugon"). Also called "sea cows", for their grazing habits and mild manner resembling livestock, dugongs have a life expectancy similar to that of humans and they can grow up to in length. These gentle mammals feed on sea grass and are closer relatives of certain land mammals than are dolphins and whales. Their simple grass diet is negatively affected by new developments along the Persian Gulf coastline, particularly the construction of artificial islands by Arab states and pollution from oil spills caused during the "Persian Gulf war" and various other natural and artificial causes. Uncontrolled hunting has also had a negative impact on the survival of dugongs. After Australian waters, which are estimated to contain some 80,000 dugong inhabitants, the waters off Qatar, Bahrain, UAE, and Saudi Arabia make the Persian Gulf the second most important habitat for the species, hosting some 7,500 remaining dugongs. However, the current number of dugongs is dwindling and it is not clear how many are currently alive or what their reproductive trend is. Unfortunately, ambitious and uncalculated construction schemes, political unrest, ever-present international conflict, the most lucrative world supply of oil, and the lack of cooperation between Arab states and Iran, have had a negative impact on the survival of many marine species, including dugongs.

The Persian Gulf is also home to many migratory and local birds. There is great variation in color, size, and type of the bird species that call the Persian gulf home. Concerns regarding the endangerment of the "kalbaensis" subspecies of the collared kingfishers were raised by conservationists due to real state development by the United Arab Emirates and Oman. Estimates from 2006 showed that only three viable nesting sites were available for this ancient bird, one located from Dubai, and two smaller sites in Oman. Such real estate expansion could prove devastating to this subspecies. A UN plan to protect the mangroves as a biological reserve was ignored by the emirate of Sharjah, which allowed the dredging of a channel that bisects the wetland and construction of an adjacent concrete walkway. Environmental watchdogs in Arabia are few, and those that do advocate the wildlife are often silenced or ignored by developers of real estate many of whom have governmental connections.

Real estate development in the Persian Gulf by the United Arab Emirates and Oman also raised concerns that habitats of species such as the hawksbill turtle, greater flamingo, and booted warbler may be destroyed. The dolphins that frequent the Persian gulf in northern waters around Iran are also at risk. Recent statistics and observations show that dolphins are at danger of entrapment in purse seine fishing nets and exposure to chemical pollutants; perhaps the most alarming sign is the "mass suicides" committed by dolphins off Iran's Hormozgan province, which are not well understood, but are suspected to be linked with a deteriorating marine environment from water pollution from oil, sewage, and industrial run offs.

The Persian Gulf is home to over 700 species of fish, most of which are native. Of these 700 species, more than 80% are reef associated. These reefs are primarily rocky, but there are also a few coral reefs. Compared to the Red Sea, the coral reefs in the Persian Gulf are relatively few and far between. This is primarily connected to the influx of major rivers, especially the Shatt al-Arab (Euphrates and Tigris), which carry large amounts of sediment (most reef-building corals require strong light) and causes relatively large variations in temperature and salinity (corals in general are poorly suited to large variations). Nevertheless, coral reefs have been found along sections of coast of all countries in the Persian gulf. Corals are vital ecosystems that support multitude of marine species, and whose health directly reflects the health of the Persian gulf. Recent years have seen a drastic decline in the coral population in the Persian gulf, partially owing to global warming but majorly due to irresponsible dumping by Arab states like the UAE and Bahrain. Construction garbage such as tires, cement, and chemical by products have found their way to the Persian Gulf in recent years. Aside from direct damage to the coral, the construction waste creates "traps" for marine life in which they are trapped and die. The end result has been a dwindling population of the coral, and as a result a decrease in number of species that rely on the corals for their survival.

A great example of this symbiosis are the mangroves in the Persian gulf, which require tidal flow and a combination of fresh and salt water for growth, and act as nurseries for many crabs, small fish, and insects; these fish and insects are the source of food for many of the marine birds that feed on them. Mangroves are a diverse group of shrubs and trees belonging to the genus "Avicennia" or "Rhizophora" that flourish in the salt water shallows of the Persian gulf, and are the most important habitats for small crustaceans that dwell in them. They are as crucial an indicator of biological health on the surface of the water, as the corals are to biological health of the Persian gulf in deeper waters. Mangroves' ability to survive the salt water through intricate molecular mechanisms, their unique reproductive cycle, and their ability to grow in the most oxygen-deprived waters have allowed them extensive growth in hostile areas of the Persian gulf. However, with the advent of artificial island development, most of their habitat is destroyed, or occupied by man-made structures. This has had a negative impact on the crustaceans that rely on the mangrove, and in turn on the species that feed on them.




</doc>
<doc id="24762" url="https://en.wikipedia.org/wiki?curid=24762" title="P53">
P53

Tumor protein p53, also known as p53, cellular tumor antigen p53 (UniProt name), the Guardian of the Genome, phosphoprotein p53, tumor suppressor p53, antigen NY-CO-13, or transformation-related protein 53 (TRP53), is any isoform of a protein encoded by homologous genes in various organisms, such as "TP53" (humans) and "Trp53" (mice). This homolog (originally thought to be, and often spoken of as, a single protein) is crucial in multicellular organisms, where it prevents cancer formation, and thus functions as a tumor suppressor. As such, p53 has been described as "the guardian of the genome" because of its role in conserving stability by preventing genome mutation. Hence "TP53" is classified as a tumor suppressor gene.

The name p53 was given in 1979 describing the apparent molecular mass; SDS-PAGE analysis indicates that it is a 53-kilodalton (kDa) protein. However, the actual mass of the full-length p53 protein (p53α) based on the sum of masses of the amino acid residues is only 43.7 kDa. This difference is due to the high number of proline residues in the protein, which slow its migration on SDS-PAGE, thus making it appear heavier than it actually is. In addition to the full-length protein, the human "TP53" gene encodes at least 15 protein isoforms, ranging in size from 3.5 to 43.7 kDa. All these p53 proteins are called the p53 isoforms. The TP53 gene is the most frequently mutated gene (>50%) in human cancer, indicating that the "TP53" gene plays a crucial role in preventing cancer formation. "TP53" gene encodes proteins that bind to DNA and regulate gene expression to prevent mutations of the genome.

In humans, the "TP53" gene is located on the short arm of chromosome 17 (17p13.1). The gene spans 20 kb, with a non-coding exon 1 and a very long first intron of 10 kb. The coding sequence contains five regions showing a high degree of conservation in vertebrates, predominantly in exons 2, 5, 6, 7 and 8, but the sequences found in invertebrates show only distant resemblance to mammalian TP53. "TP53" orthologs have been identified in most mammals for which complete genome data are available.

In humans, a common polymorphism involves the substitution of an arginine for a proline at codon position 72. Many studies have investigated a genetic link between this variation and cancer susceptibility; however, the results have been controversial. For instance, a meta-analysis from 2009 failed to show a link for cervical cancer. A 2011 study found that the "TP53" proline mutation did have a profound effect on pancreatic cancer risk among males. A study of Arab women found that proline homozygosity at "TP53" codon 72 is associated with a decreased risk for breast cancer. One study suggested that "TP53" codon 72 polymorphisms, MDM2 SNP309, and A2164G may collectively be associated with non-oropharyngeal cancer susceptibility and that MDM2 SNP309 in combination with "TP53" codon 72 may accelerate the development of non-oropharyngeal cancer in women. A 2011 study found that "TP53" codon 72 polymorphism was associated with an increased risk of lung cancer.

Meta-analyses from 2011 found no significant associations between "TP53" codon 72 polymorphisms and both colorectal cancer risk and endometrial cancer risk. A 2011 study of a Brazilian birth cohort found an association between the non-mutant arginine "TP53" and individuals without a family history of cancer. Another 2011 study found that the p53 homozygous (Pro/Pro) genotype was associated with a significantly increased risk for renal cell carcinoma.


Mutations that deactivate p53 in cancer usually occur in the DBD. Most of these mutations destroy the ability of the protein to bind to its target DNA sequences, and thus prevents transcriptional activation of these genes. As such, mutations in the DBD are recessive loss-of-function mutations. Molecules of p53 with mutations in the OD dimerise with wild-type p53, and prevent them from activating transcription. Therefore, OD mutations have a dominant negative effect on the function of p53.

Wild-type p53 is a labile protein, comprising folded and unstructured regions that function in a synergistic manner.

p53 plays a role in regulation or progression through the cell cycle, apoptosis, and genomic stability by means of several mechanisms:


WAF1/CIP1 encoding for p21 and hundreds of other down-stream genes. p21 (WAF1) binds to the G1-S/CDK (CDK4/CDK6, CDK2, and CDK1) complexes (molecules important for the G1/S transition in the cell cycle) inhibiting their activity.

When p21(WAF1) is complexed with CDK2, the cell cannot continue to the next stage of cell division. A mutant p53 will no longer bind DNA in an effective way, and, as a consequence, the p21 protein will not be available to act as the "stop signal" for cell division. Studies of human embryonic stem cells (hESCs) commonly describe the nonfunctional p53-p21 axis of the G1/S checkpoint pathway with subsequent relevance for cell cycle regulation and the DNA damage response (DDR). Importantly, p21 mRNA is clearly present and upregulated after the DDR in hESCs, but p21 protein is not detectable. In this cell type, p53 activates numerous microRNAs (like miR-302a, miR-302b, miR-302c, and miR-302d) that directly inhibit the p21 expression in hESCs.

The p21 protein binds directly to cyclin-CDK complexes that drive forward the cell cycle and inhibits their kinase activity thereby causing cell cycle arrest to allow repair to take place. p21 can also mediate growth arrest associated with differentiation and a more permanent growth arrest associated with cellular senescence. The p21 gene contains several p53 response elements that mediate direct binding of the p53 protein, resulting in transcriptional activation of the gene encoding the p21 protein.

The p53 and RB1 pathways are linked via p14ARF, raising the possibility that the pathways may regulate each other.

p53 expression can be stimulated by UV light, which also causes DNA damage. In this case, p53 can initiate events leading to tanning.

Levels of p53 play an important role in the maintenance of stem cells throughout development and the rest of human life.

In human embryonic stem cells (hESCs)s, p53 is maintained at low inactive levels. This is because activation of p53 leads to rapid differentiation of hESCs. Studies have shown that knocking out p53 delays differentiation and that adding p53 causes spontaneous differentiation, showing how p53 promotes differentiation of hESCs and plays a key role in cell cycle as a differentiation regulator. When p53 becomes stabilized and activated in hESCs, it increases p21 to establish a longer G1. This typically leads to abolition of S-phase entry, which stops the cell cycle in G1, leading to differentiation. p53 also activates miR-34a and miR-145, which then repress the hESCs pluripotency factors, further instigating differentiation.

In adult stem cells, p53 regulation is important for maintenance of stemness in adult stem cell niches. Mechanical signals such as hypoxia affect levels of p53 in these niche cells through the hypoxia inducible factors, HIF-1α and HIF-2α. While HIF-1α stabilizes p53, HIF-2α suppresses it. Suppression of p53 plays important roles in cancer stem cell phenotype, induced pluripotent stem cells and other stem cell roles and behaviors, such as blastema formation. Cells with decreased levels of p53 have been shown to reprogram into stem cells with a much greater efficiency than normal cells. Papers suggest that the lack of cell cycle arrest and apoptosis gives more cells the chance to be reprogrammed. Decreased levels of p53 were also shown to be a crucial aspect of blastema formation in the legs of salamanders. p53 regulation is very important in acting as a barrier between stem cells and a differentiated stem cell state, as well as a barrier between stem cells being functional and being cancerous.

Apart from the cellular and molecular effects above, p53 has a tissue-level anticancer effect that works by inhibiting angiogenesis. As tumors grow they need to recruit new blood vessels to supply them, and p53 inhibits that by (i) interfering with regulators of humor hypoxia that also affect angiogenesis, such as HIF1 and HIF2, (ii) inhibiting the production of angiogenic promoting factors, and (iii) directly increasing the production of angiogenesis inhibitors, such as arresten.

p53 by regulating Leukemia Inhibitory Factor has been shown to facilitate implantation in the mouse and possibly humans reproduction.

p53 becomes activated in response to myriad stressors, including but not limited to DNA damage (induced by either UV, IR, or chemical agents such as hydrogen peroxide), oxidative stress, osmotic shock, ribonucleotide depletion, and deregulated oncogene expression. This activation is marked by two major events. First, the half-life of the p53 protein is increased drastically, leading to a quick accumulation of p53 in stressed cells. Second, a conformational change forces p53 to be activated as a transcription regulator in these cells. The critical event leading to the activation of p53 is the phosphorylation of its N-terminal domain. The N-terminal transcriptional activation domain contains a large number of phosphorylation sites and can be considered as the primary target for protein kinases transducing stress signals.

The protein kinases that are known to target this transcriptional activation domain of p53 can be roughly divided into two groups. A first group of protein kinases belongs to the MAPK family (JNK1-3, ERK1-2, p38 MAPK), which is known to respond to several types of stress, such as membrane damage, oxidative stress, osmotic shock, heat shock, etc. A second group of protein kinases (ATR, ATM, CHK1 and CHK2, DNA-PK, CAK, TP53RK) is implicated in the genome integrity checkpoint, a molecular cascade that detects and responds to several forms of DNA damage caused by genotoxic stress. Oncogenes also stimulate p53 activation, mediated by the protein p14ARF.

In unstressed cells, p53 levels are kept low through a continuous degradation of p53. A protein called Mdm2 (also called HDM2 in humans), binds to p53, preventing its action and transports it from the nucleus to the cytosol. Mdm2 also acts as an ubiquitin ligase and covalently attaches ubiquitin to p53 and thus marks p53 for degradation by the proteasome. However, ubiquitylation of p53 is reversible. On activation of p53, Mdm2 is also activated, setting up a feedback loop. p53 levels can show oscillations (or repeated pulses) in response to certain stresses, and these pulses can be important in determining whether the cells survive the stress, or die.

MI-63 binds to MDM2, reactivating p53 in situations where p53's function has become inhibited.

A ubiquitin specific protease, USP7 (or HAUSP), can cleave ubiquitin off p53, thereby protecting it from proteasome-dependent degradation via the ubiquitin ligase pathway . This is one means by which p53 is stabilized in response to oncogenic insults. USP42 has also been shown to deubiquitinate p53 and may be required for the ability of p53 to respond to stress.

Recent research has shown that HAUSP is mainly localized in the nucleus, though a fraction of it can be found in the cytoplasm and mitochondria. Overexpression of HAUSP results in p53 stabilization. However, depletion of HAUSP does not result to a decrease in p53 levels but rather increases p53 levels due to the fact that HAUSP binds and deubiquitinates Mdm2. It has been shown that HAUSP is a better binding partner to Mdm2 than p53 in unstressed cells.

USP10 however has been shown to be located in the cytoplasm in unstressed cells and deubiquitinates cytoplasmic p53, reversing Mdm2 ubiquitination. Following DNA damage, USP10 translocates to the nucleus and contributes to p53 stability. Also USP10 does not interact with Mdm2.

Phosphorylation of the N-terminal end of p53 by the above-mentioned protein kinases disrupts Mdm2-binding. Other proteins, such as Pin1, are then recruited to p53 and induce a conformational change in p53, which prevents Mdm2-binding even more. Phosphorylation also allows for binding of transcriptional coactivators, like p300 and PCAF, which then acetylate the carboxy-terminal end of p53, exposing the DNA binding domain of p53, allowing it to activate or repress specific genes. Deacetylase enzymes, such as Sirt1 and Sirt7, can deacetylate p53, leading to an inhibition of apoptosis. Some oncogenes can also stimulate the transcription of proteins that bind to MDM2 and inhibit its activity.

If the "TP53" gene is damaged, tumor suppression is severely compromised. People who inherit only one functional copy of the "TP53" gene will most likely develop tumors in early adulthood, a disorder known as Li-Fraumeni syndrome.

The "TP53" gene can also be modified by mutagens (chemicals, radiation, or viruses), increasing the likelihood for uncontrolled cell division. More than 50 percent of human tumors contain a mutation or deletion of the "TP53" gene. Loss of p53 creates genomic instability that most often results in an aneuploidy phenotype.

Increasing the amount of p53 may seem a solution for treatment of tumors or prevention of their spreading. This, however, is not a usable method of treatment, since it can cause premature aging. Restoring endogenous normal p53 function holds some promise. Research has shown that this restoration can lead to regression of certain cancer cells without damaging other cells in the process. The ways by which tumor regression occurs depends mainly on the tumor type. For example, restoration of endogenous p53 function in lymphomas may induce apoptosis, while cell growth may be reduced to normal levels. Thus, pharmacological reactivation of p53 presents itself as a viable cancer treatment option. The first commercial gene therapy, Gendicine, was approved in China in 2003 for the treatment of head and neck squamous cell carcinoma. It delivers a functional copy of the p53 gene using an engineered adenovirus.

Certain pathogens can also affect the p53 protein that the "TP53" gene expresses. One such example, human papillomavirus (HPV), encodes a protein, E6, which binds to the p53 protein and inactivates it. This mechanism, in synergy with the inactivation of the cell cycle regulator pRb by the HPV protein E7, allows for repeated cell division manifested clinically as warts. Certain HPV types, in particular types 16 and 18, can also lead to progression from a benign wart to low or high-grade cervical dysplasia, which are reversible forms of precancerous lesions. Persistent infection of the cervix over the years can cause irreversible changes leading to carcinoma in situ and eventually invasive cervical cancer. This results from the effects of HPV genes, particularly those encoding E6 and E7, which are the two viral oncoproteins that are preferentially retained and expressed in cervical cancers by integration of the viral DNA into the host genome.

The p53 protein is continually produced and degraded in cells of healthy people, resulting in damped oscillation. The degradation of the p53 protein is associated with binding of MDM2. In a negative feedback loop, MDM2 itself is induced by the p53 protein. Mutant p53 proteins often fail to induce MDM2, causing p53 to accumulate at very high levels. Moreover, the mutant p53 protein itself can inhibit normal p53 protein levels. In some cases, single missense mutations in p53 have been shown to disrupt p53 stability and function.

Suppression of p53 in human breast cancer cells is shown to lead to increased CXCR5 chemokine receptor gene expression and activated cell migration in response to chemokine CXCL13.

One study found that p53 and Myc proteins were key to the survival of Chronic Myeloid Leukaemia (CML) cells. Targeting p53 and Myc proteins with drugs gave positive results on mice with CML.

Most p53 mutations are detected by DNA sequencing. However, it is known that single missense mutations can have a large spectrum from rather mild to very severe functional affects.

The large spectrum of cancer phenotypes due to mutations in the "TP53" gene is also supported by the fact that different isoforms of p53 proteins have different cellular mechanisms for prevention against cancer. Mutations in "TP53" can give rise to different isoforms, preventing their overall functionality in different cellular mechanisms and thereby extending the cancer phenotype from mild to severe. Recents studies show that p53 isoforms are differentially expressed in different human tissues, and the loss-of-function or gain-of-function mutations within the isoforms can cause tissue-specific cancer or provides cancer stem cell potential in different tissues. TP53 mutation also hits energy metabolism and increases glycolysis in breast cancer cells.

The dynamics of p53 proteins, along with its antagonist Mdm2, indicate that the levels of p53, in units of concentration, oscillate as a function of time. This "damped" oscillation is both clinically documented and mathematically modelled. Mathematical models also indicate that the p53 concentration oscillates much faster once teratogens, such as double-stranded breaks (DSB) or UV radiation, are introduced to the system. This supports and models the current understanding of p53 dynamics, where DNA damage induces p53 activation (see p53 regulation for more information). Current models can also be useful for modelling the mutations in p53 isoforms and their effects on p53 oscillation, thereby promoting "de novo" tissue-specific pharmacological drug discovery.

p53 was identified in 1979 by Lionel Crawford, David P. Lane, Arnold Levine, and Lloyd Old, working at Imperial Cancer Research Fund (UK) Princeton University/UMDNJ (Cancer Institute of New Jersey), and Memorial Sloan-Kettering Cancer Center, respectively. It had been hypothesized to exist before as the target of the SV40 virus, a strain that induced development of tumors. The "TP53" gene from the mouse was first cloned by Peter Chumakov of the Russian Academy of Sciences in 1982, and independently in 1983 by Moshe Oren in collaboration with David Givol (Weizmann Institute of Science). The human "TP53" gene was cloned in 1984 and the full length clone in 1985.

It was initially presumed to be an oncogene due to the use of mutated cDNA following purification of tumor cell mRNA. Its role as a tumor suppressor gene was revealed in 1989 by Bert Vogelstein at the Johns Hopkins School of Medicine and Arnold Levine at Princeton University.

Warren Maltzman, of the Waksman Institute of Rutgers University first demonstrated that TP53 was responsive to DNA damage in the form of ultraviolet radiation. In a series of publications in 1991–92, Michael Kastan of Johns Hopkins University, reported that TP53 was a critical part of a signal transduction pathway that helped cells respond to DNA damage.

In 1993, p53 was voted "molecule of the year" by Science magazine.

As with 95% of human genes, TP53 encodes more than one protein. Several isoforms were discovered in 2005, and so far 12 human p53 isoforms have been identified (p53α, p53β, p53γ, ∆40p53α, ∆40p53β, ∆40p53γ, ∆133p53α, ∆133p53β, ∆133p53γ, ∆160p53α, ∆160p53β, ∆160p53γ). Furthermore, p53 isoforms are expressed in a tissue dependent manner and p53α is never expressed alone.

The full length p53 isoform proteins can be subdivided into different protein domains. Starting from the N-terminus, there are first the amino-terminal transactivation domains (TAD 1, TAD 2), which are needed to induce a subset of p53 target genes. This domain is followed by the proline rich domain (PXXP), whereby the motif PXXP is repeated (P is a proline and X can be any amino acid). It is required among others for p53 mediated apoptosis. Some isoforms lack the proline rich domain, such as Δ133p53β,γ and Δ160p53α,β,γ; hence some isoforms of p53 are not mediating apoptosis, emphasizing the diversifying roles of the "TP53" gene. Afterwards there is the DNA binding domain (DBD), which enables the proteins to sequence specific binding. The carboxyl terminal domain completes the protein. It includes the nuclear localization signal (NLS), the nuclear export signal (NES) and the oligomerisation domain (OD). The NLS and NES are responsible for the subcellular regulation of p53. Through the OD, p53 can form a tetramer and then bind to DNA. Among the isoforms, some domains can be missing, but all of them share most of the highly conserved DNA-binding domain.

The isoforms are formed by different mechanisms. The beta and the gamma isoforms are generated by multiple splicing of intron 9, which leads to a different C-terminus. Furthermore, the usage of an internal promoter in intron 4 causes the ∆133 and ∆160 isoforms, which lack the TAD domain and a part of the DBD. Moreover, alternative initiation of translation at codon 40 or 160 bear the ∆40p53 and ∆160p53 isoforms.

Due to the isoformic nature of p53 proteins, there have been several sources of evidence showing that mutations within the "TP53" gene giving rise to mutated isoforms are causative agents of various cancer phenotypes, from mild to severe, due to single mutation in the "TP53" gene (refer to section Experimental analysis of p53 mutations for more details).

p53 has been shown to interact with:




</doc>
<doc id="24764" url="https://en.wikipedia.org/wiki?curid=24764" title="Pointless topology">
Pointless topology

In mathematics, pointless topology (also called point-free or pointfree topology, or locale theory) is an approach to topology that avoids mentioning points.

Traditionally, a topological space consists of a set of points together with a "topology", a system of subsets called open sets that with the operations of intersection and union forms a lattice with certain properties. Point-free topology is based on the concept of a "realistic spot" instead of a point without extent. Spots can be joined (forming a complete lattice) and if a spot meets a join of others it has to meet some of the constituents, which, roughly speaking, leads to the distributive law

formula_1.

The basic concept is that of a frame, a complete lattice satisfying the distributive law above; frame homomorphisms respect all joins (in particular, the least element of the lattice) and finite meets (in particular, the greatest element of the lattice).

Frames, together with frame homomorphisms, form a category.

In classical topology, represented on a set formula_2 by the system formula_3 of open sets, formula_3 (partially ordered by inclusion) is a frame, and if formula_5 is a continuous map, formula_6 defined by formula_7 is a frame homomorphism. For sober spaces such formula_8 are precisely the frame homomorphisms formula_9. Hence formula_10 is a full embedding of the category of sober spaces into the dual of the category of frames (usually called of the category of locales). This justifies thinking of frames (locales) as of generalized topological spaces. A frame is "spatial" if it is isomorphic to a formula_3. There are plenty of non-spatial ones and this fact turned out to be helpful in several problems.

The theory of frames and locales in the contemporary sense was initiated in the late 1950s (Charles Ehresmann, Jean Bénabou, Hugh Dowker, Dona Papert) and developed through the following decades (John Isbell, Peter Johnstone, Harold Simmons, , , Till Plewe, Japie Vermeulen, Steve Vickers) into a lively branch of topology, with application in various fields, in particular also in theoretical computer science. For more on the history of locale theory see.

It is possible to translate most concepts of point-set topology into the context of locales, and prove analogous theorems. Regarding the advantages of the point-free approach let us point out, for example, the fact that some important facts of classical topology depending on choice principles become choice-free (that is, constructive, which is, in particular, appealing for computer science). Thus for instance, products of compact locales are compact constructively, or completions of uniform locales are constructive. This can be useful if one works in a topos that does not have the axiom of choice. Other advantages include the much better behaviour of paracompactness, or the fact that subgroups of localic groups are always closed.

Another point where locale theory and topology diverge strongly is the concepts of subspaces versus sublocales: by Isbell's density theorem, every locale has a smallest dense sublocale. This has absolutely no equivalent in the realm of topological spaces.


A general introduction to pointless topology is

This is, in its own words, to be read as the trailer for Johnstone's excellent monograph (which appeared already in 1982 and can still be used for basic reference):


There is a recent monograph


where one also finds a more extensive bibliography.

For relations with logic:


For a more concise account see the respective chapters in:



</doc>
<doc id="24767" url="https://en.wikipedia.org/wiki?curid=24767" title="Phobos">
Phobos

Phobos (Greek for "fear") most commonly refers to:

Phobos may also refer to:






</doc>
<doc id="24768" url="https://en.wikipedia.org/wiki?curid=24768" title="Pizza">
Pizza

Pizza (, ) is a savory dish of Italian origin, consisting of a usually round, flattened base of leavened wheat-based dough topped with tomatoes, cheese, and often various other ingredients (anchovies, olives, meat, etc.) baked at a high temperature, traditionally in a wood-fired oven. A small pizza is sometimes called a pizzetta.

In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced and eaten with the use of a knife and fork. In casual settings it is cut into wedges to be eaten while held in the hand.

The term "pizza" was first recorded in the 10th century in a Latin manuscript from the Southern Italian town of Gaeta in Lazio, on the border with Campania. Modern pizza was invented in Naples, and the dish and its variants have since become popular in many countries. It has become one of the most popular foods in the world and a common fast food item in Europe and North America, available at pizzerias (restaurants specializing in pizza), restaurants offering Mediterranean cuisine, and via pizza delivery. Many companies sell ready-baked frozen pizzas to be reheated in an ordinary home oven.

The "Associazione Verace Pizza Napoletana" (lit. True Neapolitan Pizza Association) is a non-profit organization founded in 1984 with headquarters in Naples that aims to promote traditional Neapolitan pizza. In 2009, upon Italy's request, Neapolitan pizza was registered with the European Union as a Traditional Speciality Guaranteed dish, and in 2017 the art of its making was included on UNESCO's list of intangible cultural heritage.

The word "pizza" first appeared in a Latin text from the central Italian town of Gaeta, then still part of the Byzantine Empire, in 997 AD; the text states that a tenant of certain property is to give the bishop of Gaeta "duodecim pizze" ("twelve pizzas") every Christmas Day, and another twelve every Easter Sunday.

Suggested etymologies include:

Foods similar to pizza have been made since the Neolithic Age. Records of people adding other ingredients to bread to make it more flavorful can be found throughout ancient history. In the 6th century BC, the Persian soldiers of Achaemenid Empire during the rule King Darius I baked flatbreads with cheese and dates on top of their battle shields and the ancient Greeks supplemented their bread with oils, herbs, and cheese. An early reference to a pizza-like food occurs in the Aeneid, when Celaeno, queen of the Harpies, foretells that the Trojans would not find peace until they are forced by hunger to eat their tables (Book III). In Book VII, Aeneas and his men are served a meal that includes round cakes (like pita bread) topped with cooked vegetables. When they eat the bread, they realize that these are the "tables" prophesied by Celaeno.

Modern pizza evolved from similar flatbread dishes in Naples, Italy, in the 18th or early 19th century. Prior to that time, flatbread was often topped with ingredients such as garlic, salt, lard, cheese, and basil. It is uncertain when tomatoes were first added and there are many conflicting claims. Until about 1830, pizza was sold from open-air stands and out of pizza bakeries, antecedents to modern pizzerias.

A popular contemporary legend holds that the archetypal pizza, "pizza Margherita", was invented in 1889, when the Royal Palace of Capodimonte commissioned the Neapolitan pizzaiolo (pizza maker) Raffaele Esposito to create a pizza in honor of the visiting Queen Margherita. Of the three different pizzas he created, the Queen strongly preferred a pizza swathed in the colors of the Italian flag — red (tomato), green (basil), and white (mozzarella). Supposedly, this kind of pizza was then named after the Queen, although later research cast doubt on this legend. An official letter of recognition from the Queen's "head of service" remains on display in Esposito's shop, now called the Pizzeria Brandi.

Pizza was brought to the United States with Italian immigrants in the late nineteenth century and first appeared in areas where Italian immigrants concentrated. The country's first pizzeria, Lombardi's, opened in 1905. Following World War II, veterans returning from the Italian Campaign, who were introduced to Italy's native cuisine, proved a ready market for pizza in particular.

Pizza is sold fresh or frozen, and whole or as portion-size slices or pieces. Methods have been developed to overcome challenges such as preventing the sauce from combining with the dough and producing a crust that can be frozen and reheated without becoming rigid. There are frozen pizzas with raw ingredients and self-rising crusts.

Another form of uncooked pizza is available from take and bake pizzerias. This pizza is assembled in the store, then sold to customers to bake in their own ovens. Some grocery stores sell fresh dough along with sauce and basic ingredients, to complete at home before baking in an oven.

In restaurants, pizza can be baked in an oven with stone bricks above the heat source, an electric deck oven, a conveyor belt oven, or, in the case of more expensive restaurants, a wood or coal-fired brick oven. On deck ovens, pizza can be slid into the oven on a long paddle, called a peel, and baked directly on the hot bricks or baked on a screen (a round metal grate, typically aluminum). Prior to use, a peel may be sprinkled with cornmeal to allow pizza to easily slide onto and off of it. When made at home, it can be baked on a pizza stone in a regular oven to reproduce the effect of a brick oven. Cooking directly in a metal oven results in too rapid heat transfer to the crust, burning it. Aficionado home-chefs sometimes use a specialty wood-fired pizza oven, usually installed outdoors. Dome-shaped pizza ovens have been used for centuries, which is one way to achieve true heat distribution in a wood-fired pizza oven. Another option is grilled pizza, in which the crust is baked directly on a barbecue grill. Greek pizza, like Chicago-style pizza, is baked in a pan rather than directly on the bricks of the pizza oven.

When it comes to preparation, the dough and ingredients can be combined on any kind of table. With mass production of pizza, the process can be completely automated. Most restaurants still use standard and purpose-built pizza preparation tables. Pizzerias nowadays can even opt for hi tech pizza preparation tables that combine mass production elements with traditional techniques.

The bottom of the pizza, called the "crust", may vary widely according to style, thin as in a typical hand-tossed Neapolitan pizza or thick as in a deep-dish Chicago-style. It is traditionally plain, but may also be seasoned with garlic or herbs, or stuffed with cheese. The outer edge of the pizza is sometimes referred to as the "cornicione". Pizza dough often contains sugar, both to help its yeast rise and enhance browning of the crust.

Dipping sauce specifically for pizza was invented by American pizza chain Papa John's Pizza in 1984 and has since become popular when eating pizza, especially the crust.

Mozzarella is commonly used on pizza, with the highest quality buffalo mozzarella produced in the surroundings of Naples. Eventually, other cheeses were used well as pizza ingredients, particularly Italian cheeses including provolone, pecorino romano, ricotta, and scamorza. Less expensive processed cheeses or cheese analogues have been developed for mass-market pizzas to produce desirable qualities like browning, melting, stretchiness, consistent fat and moisture content, and stable shelf life. This quest to create the ideal and economical pizza cheese has involved many studies and experiments analyzing the impact of vegetable oil, manufacturing and culture processes, denatured whey proteins, and other changes in manufacture. In 1997, it was estimated that annual production of pizza cheese was in the U.S. and in Europe.

Authentic Neapolitan pizza ("pizza napoletana") is made with San Marzano tomatoes, grown on the volcanic plains south of Mount Vesuvius, and mozzarella di bufala Campana, made with milk from water buffalo raised in the marshlands of Campania and Lazio. This mozzarella is protected with its own European protected designation of origin. Other traditional pizzas include "pizza alla marinara", which is topped with marinara sauce and is supposedly the most ancient tomato-topped pizza,
pizza capricciosa, which is prepared with mozzarella cheese, baked ham, mushroom, artichoke, and tomato, and pizza pugliese, prepared with tomato, mozzarella, and onions.

A popular variant of pizza in Italy is Sicilian pizza (locally called "sfincione" or "sfinciuni"), a thick-crust or deep-dish pizza originating during the 17th century in Sicily: it is essentially a focaccia that is typically topped with tomato sauce and other ingredients. Until the 1860s, "sfincione" was the type of pizza usually consumed in Sicily, especially in the Western portion of the island. Other variations of pizzas are also found in other regions of Italy, for example "pizza al padellino" or "pizza al tegamino", a small-sized, thick-crust, deep-dish pizza typically served in Turin, Piedmont.

13% of the United States population consumes pizza on any given day. Pizza chains such as Domino's Pizza, Pizza Hut, and Papa John's, pizzas from take and bake pizzerias, and chilled or frozen pizzas from supermarkets make pizza readily available nationwide. 

Common toppings for pizza in the United States include ground beef, mushrooms, onions, pepperoni, pineapple, garlic, olives, peppers, carrots, tomatoes, spinach, anchovies, chicken, bacon, ham, and sausage. Distinct regional types developed in the 20th century, including Buffalo, California, Chicago, Detroit, Greek, New Haven, New York, and St. Louis styles. The first pizzeria in the U.S. was opened in New York's Little Italy in 1905, and since then regions throughout the U.S. offer variations, including deep-dish, stuffed, pockets, turnovers, rolled, and pizza-on-a-stick, each with seemingly limitless combinations of sauce and toppings.

Another variation is grilled pizza, created by taking a fairly thin, round (more typically, irregularly shaped) sheet of yeasted pizza dough, placing it directly over the fire of a grill, and then turning it over once the bottom has baked and placing a thin layer of toppings on the baked side. Toppings may be sliced thin to ensure that they heat through, and chunkier toppings such as sausage or peppers may be precooked before being placed on the pizza. Garlic, herbs, or other ingredients are sometimes added to the pizza or the crust to maximize the flavor of the dish.

Grilled pizza was offered in the United States at the Al Forno restaurant in Providence, Rhode Island by owners Johanne Killeen and George Germon in 1980. Although it was inspired by a misunderstanding that confused a wood-fired brick oven with a grill, grilled pizza did exist prior to 1980, both in Italy, and in Argentina where it is known as "pizza a la parrilla". It has become a popular cookout dish, and there are even some pizza restaurants that specialize in the style. The traditional style of grilled pizza employed at Al Forno restaurant uses a dough coated with olive oil, strained tomato sauce, thin slices of fresh mozzarella, and a garnish made from shaved scallions, and is served uncut. The final product can be likened to flatbread with pizza toppings. Another Providence establishment, Bob & Timmy's Grilled Pizza, was featured in a Providence-themed episode of the Travel Channel's "Man v. Food Nation" in 2011.

Argentina, and more specifically Buenos Aires, received a massive Italian immigration at the turn of the 19th century. Immigrants from Naples and Genoa opened the first pizza bars, though over time Spanish residents came to own the majority of the pizza businesses.

Standard Argentine pizza has a thicker crust, called "media masa" (half dough) than traditional Italian style pizza and includes more cheese. Argentine gastronomy tradition, served pizza with fainá, which is a Genovese chick pea-flour dough placed over the piece of pizza, and moscato wine. The most popular variety of pizza is called "muzzarella" (mozzarella), similar to Neapolitan pizza (bread, tomato sauce and cheese) but made with a thicker "media masa" crust, triple cheese and tomato sauce, usually also with olives. It can be found in nearly every corner of the country; Buenos Aires is considered the city with the most pizza bars by person of the world. Other popular varieties include jam, tomato slices, red pepper and longaniza. Two Argentine-born varieties of pizza with onion, are also very popular: fugazza with cheese and fugazzetta. The former one consists in a regular pizza crust topped with cheese and onions; the later has the cheese between two pizza crusts, with onions on top.

The world's largest pizza was prepared in Rome in December 2012, and measured . The pizza was named "Ottavia" in homage to the first Roman emperor Octavian Augustus, and was made with a gluten-free base. The world's longest pizza was made in
Fontana, California in 2017 and measured .

The world's most expensive pizza listed by "Guinness World Records" is a commercially available thin-crust pizza at Maze restaurant in London, United Kingdom, which costs . The pizza is wood fire-baked, and is topped with onion puree, white truffle paste, fontina cheese, baby mozzarella, pancetta, cep mushrooms, freshly picked wild mizuna lettuce, and fresh shavings of a rare Italian white truffle.

There are several instances of more expensive pizzas, such as the "Pizza Royale 007" at Haggis restaurant in Glasgow, Scotland, which is topped with caviar, lobster, and 24-carat gold dust, and the caviar pizza made by Nino's Bellissima pizzeria in New York City, New York. However, these are not officially recognized by "Guinness World Records". Additionally, a pizza was made by the restaurateur Domenico Crolla that included toppings such as sunblush-tomato sauce, Scottish smoked salmon, medallions of venison, edible gold, lobster marinated in cognac, and champagne-soaked caviar. The pizza was auctioned for charity in 2007, raising .

In 2017, the world pizza market was $128 billion, and in the US it was $44 billion spread over 76,000 pizzerias. Overall, 13% of the U.S. population aged 2 years and over consumed pizza on any given day. A Technomic study concluded that 83% of consumers eat pizza at least once per month. According to PMQ in 2018 60.47% of respondents reported an increase in sales over the previous year. 

Some mass-produced pizzas by fast food chains have been criticized as having an unhealthy balance of ingredients. Pizza can be high in salt, fat, and calories (food energy). The USDA reports an average sodium content of 5,101 mg per pizza in fast food chains. There are concerns about negative health effects. Food chains have come under criticism at various times for the high salt content of some of their meals.

Frequent pizza eaters in Italy have been found to have a relatively low incidence of cardiovascular disease and digestive tract cancers relative to infrequent pizza eaters, although the nature of the association between pizza and such perceived benefits is unclear. Pizza consumption in Italy might only indicate adherence to traditional Mediterranean dietary patterns, which have been shown to have various health benefits.

Some attribute the apparent health benefits of pizza to the lycopene content in pizza sauce, which research indicates likely plays a role in protecting against cardiovascular disease and various cancers.

National Pizza Month is an annual observance that occurs for the month of October in the United States and some areas of Canada. This observance began in October 1984, and was created by Gerry Durnell, the publisher of "Pizza Today" magazine. During this time, some people observe National Pizza Month by consuming various types of pizzas or pizza slices, or going to various pizzerias.





</doc>
<doc id="24772" url="https://en.wikipedia.org/wiki?curid=24772" title="Phase modulation">
Phase modulation

Phase modulation (PM) is a modulation pattern for conditioning communication signals for transmission. It encodes a message signal as variations in the instantaneous phase of a carrier wave. Phase modulation is one of the two principal forms of angle modulation, together with frequency modulation.

The phase of a carrier signal is modulated to follow the changing signal level (amplitude) of the message signal. The peak amplitude and the frequency of the carrier signal are maintained constant, but as the amplitude of the message signal changes, the phase of the carrier changes correspondingly.

Phase modulation is widely used for transmitting radio waves and is an integral part of many digital transmission coding schemes that underlie a wide range of technologies like Wi-Fi, GSM and satellite television.

PM is used for signal and waveform generation in digital synthesizers, such as the Yamaha DX7, to implement FM synthesis. A related type of sound synthesis called phase distortion is used in the Casio CZ synthesizers. 

PM changes the phase angle of the complex envelope in direct proportion to the message signal.

If "m(t)" is the message signal to be transmitted and the carrier onto which the signal is modulated is

then the modulated signal is

This shows how formula_3 modulates the phase - the greater m(t) is at a point in time, the greater the phase shift of the modulated signal at that point. It can also be viewed as a change of the frequency of the carrier signal, and phase modulation can thus be considered a special case of FM in which the carrier frequency modulation is given by the time derivative of the phase modulation.

The modulation signal could here be

The mathematics of the spectral behavior reveals that there are two regions of particular interest:

As with other modulation indices, this quantity indicates by how much the modulated variable varies around its unmodulated level. It relates to the variations in the phase of the carrier signal:
where formula_9 is the peak phase deviation. Compare to the modulation index for frequency modulation.



</doc>
<doc id="24774" url="https://en.wikipedia.org/wiki?curid=24774" title="Phosphodiesterase inhibitor">
Phosphodiesterase inhibitor

A phosphodiesterase inhibitor is a drug that blocks one or more of the five subtypes of the enzyme phosphodiesterase (PDE), thereby preventing the inactivation of the intracellular second messengers cyclic adenosine monophosphate (cAMP) and cyclic guanosine monophosphate (cGMP) by the respective PDE subtype(s). The ubiquitous presence of this enzyme means that non-specific inhibitors have a wide range of actions, the actions in the heart, and lungs being some of the first to find a therapeutic use.

The different forms or subtypes of phosphodiesterase were initially isolated from rat brains in the early 1970s and were soon afterward shown to be selectively inhibited in the brain and in other tissues by a variety of drugs. The potential for selective phosphodiesterase inhibitors as therapeutic agents was predicted as early as 1977 by Weiss and Hait. This prediction meanwhile has proved to be true in a variety of fields.

Methylated xanthines and derivatives:
Methylated xanthines act as both
But different analogues show varying potency at the numerous subtypes, and a wide range of synthetic xanthine derivatives (some nonmethylated) have been developed in the search for compounds with greater selectivity for phosphodiesterase enzyme or adenosine receptor subtypes.




PDE3 is sometimes referred to as cGMP-inhibited phosphodiesterase.


PDE4 is the major cAMP-metabolizing enzyme found in inflammatory and immune cells. PDE4 inhibitors have proven potential as anti-inflammatory drugs, especially in inflammatory pulmonary diseases such as asthma, COPD, and rhinitis. They suppress the release of cytokines and other inflammatory signals, and inhibit the production of reactive oxygen species. PDE4 inhibitors may have antidepressive effects and have also recently been proposed for use as antipsychotics.

On October 26, 2009, The University of Pennsylvania reported that researchers at their institution had discovered a link between elevated levels of PDE4 (and therefore decreased levels of cAMP) in sleep deprived mice. Treatment with a PDE4 inhibitor raised the deficient cAMP levels and restored some functionality to Hippocampus-based memory functions.


Recent studies have shown Quinazoline type PDE7 inhibitor to be potent anti-inflammatory and neuroprotective agents.

Paraxanthine, the main metabolite of Caffeine (84% in humans), is another cGMP-specific phosphodiesterase inhibitor which inhibits PDE9, a cGMP preferring phosphodiesterase. PDE9 is expressed as high as PDE5 in the corpus cavernosum.

Papaverine, an opium alkaloid, has been reported to act as a PDE10 inhibitor. 
PDE10A is almost exclusively expressed in the striatum and subsequent increase in cAMP and cGMP after PDE10A inhibition (e.g. by papaverine) is "a novel therapeutic avenue in the discovery of antipsychotics".


</doc>
<doc id="24776" url="https://en.wikipedia.org/wiki?curid=24776" title="Piston">
Piston

A piston is a component of reciprocating engines, reciprocating pumps, gas compressors and pneumatic cylinders, among other similar mechanisms. It is the moving component that is contained by a cylinder and is made gas-tight by piston rings. In an engine, its purpose is to transfer force from expanding gas in the cylinder to the crankshaft via a piston rod and/or connecting rod. In a pump, the function is reversed and force is transferred from the crankshaft to the piston for the purpose of compressing or ejecting the fluid in the cylinder. In some engines, the piston also acts as a valve by covering and uncovering ports in the cylinder.

An internal combustion engine is acted upon by the pressure of the expanding combustion gases in the combustion chamber space at the top of the cylinder. This force then acts downwards through the connecting rod and onto the crankshaft. The connecting rod is attached to the piston by a swivelling gudgeon pin (US: wrist pin). This pin is mounted within the piston: unlike the steam engine, there is no piston rod or crosshead (except big two stroke engines).

The typical piston design is on the picture. This type of piston is widely used in car diesel engines. According to purpose, supercharging level and working conditions of engines the shape and proportions can be changed.

High-power diesel engines work in difficult conditions. Maximum pressure in the combustion chamber can reach 20 MPa and maximum temperature of some piston surfaces can exceed 450°C. It is possible to improve piston cooling by creating special cooling cavity. Injector supplies this cooling cavity «A» with oil through oil supply channel «B». For better temperature reduction construction should be carefully calculated and analyzed. Oil flow in cooling cavity should be not less than 80% from oil flow through the injector.
The pin itself is of hardened steel and is fixed in the piston, but free to move in the connecting rod. A few designs use a 'fully floating' design that is loose in both components. All pins must be prevented from moving sideways and the ends of the pin digging into the cylinder wall, usually by circlips.

Gas sealing is achieved by the use of piston rings. These are a number of narrow iron rings, fitted loosely into grooves in the piston, just below the crown. The rings are split at a point in the rim, allowing them to press against the cylinder with a light spring pressure. Two types of ring are used: the upper rings have solid faces and provide gas sealing; lower rings have narrow edges and a U-shaped profile, to act as oil scrapers. There are many proprietary and detail design features associated with piston rings.

Pistons are cast from aluminium alloys. For better strength and fatigue life, some racing pistons may be forged instead. Billet pistons are also used in racing engines because they do not rely on the size and architecture of available forgings, allowing for last-minute design changes. Although not commonly visible to the naked eye, pistons themselves are designed with a certain level of ovality and profile taper, meaning they are not perfectly round, and their diameter is larger near the bottom of the skirt than at the crown. 

Early pistons were of cast iron, but there were obvious benefits for engine balancing if a lighter alloy could be used. To produce pistons that could survive engine combustion temperatures, it was necessary to develop new alloys such as Y alloy and Hiduminium, specifically for use as pistons.

A few early gas engines had double-acting cylinders, but otherwise effectively all internal combustion engine pistons are single-acting. During World War II, the US submarine "Pompano" was fitted with a prototype of the infamously unreliable H.O.R. double-acting two-stroke diesel engine. Although compact, for use in a cramped submarine, this design of engine was not repeated.

Trunk pistons are long relative to their diameter. They act both as a piston and cylindrical crosshead. As the connecting rod is angled for much of its rotation, there is also a side force that reacts along the side of the piston against the cylinder wall. A longer piston helps to support this.

Trunk pistons have been a common design of piston since the early days of the reciprocating internal combustion engine. They were used for both petrol and diesel engines, although high speed engines have now adopted the lighter weight slipper piston.

A characteristic of most trunk pistons, particularly for diesel engines, is that they have a groove for an oil ring below the gudgeon pin, in addition to the rings between the gudgeon pin and crown.

The name 'trunk piston' derives from the 'trunk engine', an early design of marine steam engine. To make these more compact, they avoided the steam engine's usual piston rod with separate crosshead and were instead the first engine design to place the gudgeon pin directly within the piston. Otherwise these trunk engine pistons bore little resemblance to the trunk piston; they were extremely large diameter and double-acting. Their 'trunk' was a narrow cylinder mounted in the centre of the piston.

Large slow-speed Diesel engines may require additional support for the side forces on the piston. These engines typically use crosshead pistons. The main piston has a large piston rod extending downwards from the piston to what is effectively a second smaller-diameter piston. The main piston is responsible for gas sealing and carries the piston rings. The smaller piston is purely a mechanical guide. It runs within a small cylinder as a trunk guide and also carries the gudgeon pin.

Lubrication of the crosshead has advantages over the trunk piston as its lubricating oil is not subject to the heat of combustion: the oil is not contaminated by combustion soot particles, it does not break down owing to the heat and a thinner, less viscous oil may be used. The friction of both piston and crosshead may be only half of that for a trunk piston.

Because of the additional weight of these pistons, they are not used for high-speed engines.

A slipper piston is a piston for a petrol engine that has been reduced in size and weight as much as possible. In the extreme case, they are reduced to the piston crown, support for the piston rings, and just enough of the piston skirt remaining to leave two lands so as to stop the piston rocking in the bore. The sides of the piston skirt around the gudgeon pin are reduced away from the cylinder wall. The purpose is mostly to reduce the reciprocating mass, thus making it easier to balance the engine and so permit high speeds. In racing applications, slipper piston skirts can be configured to yield extremely light weight while maintaining the rigidity and strength of a full skirt. Reduced inertia also improves mechanical efficiency of the engine: the forces required to accelerate and decelerate the reciprocating parts cause more piston friction with the cylinder wall than the fluid pressure on the piston head. A secondary benefit may be some reduction in friction with the cylinder wall, since the area of the skirt, which slides up and down in the cylinder is reduced by half. However, most friction is due to the piston rings, which are the parts which actually fit the tightest in the bore and the bearing surfaces of the wrist pin, and thus the benefit is reduced.

Deflector pistons are used in two-stroke engines with crankcase compression, where the gas flow within the cylinder must be carefully directed in order to provide efficient scavenging. With cross scavenging, the transfer (inlet to the cylinder) and exhaust ports are on directly facing sides of the cylinder wall. To prevent the incoming mixture passing straight across from one port to the other, the piston has a raised rib on its crown. This is intended to deflect the incoming mixture upwards, around the combustion chamber.

Much effort, and many different designs of piston crown, went into developing improved scavenging. The crowns developed from a simple rib to a large asymmetric bulge, usually with a steep face on the inlet side and a gentle curve on the exhaust. Despite this, cross scavenging was never as effective as hoped. Most engines today use Schnuerle porting instead. This places a pair of transfer ports in the sides of the cylinder and encourages gas flow to rotate around a vertical axis, rather than a horizontal axis.

In racing engines, piston strength and stiffness is typically much higher than that of a passenger car engine, while the weight is much less, to achieve the high engine RPM necessary in racing.

Steam engines are usually double-acting (i.e. steam pressure acts alternately on each side of the piston) and the admission and release of steam is controlled by slide valves, piston valves or poppet valves. Consequently, steam engine pistons are nearly always comparatively thin discs: their diameter is several times their thickness. (One exception is the trunk engine piston, shaped more like those in a modern internal-combustion engine.) Another factor is that since almost all steam engines use crossheads to translate the force to the drive rod, there are few lateral forces acting to try and "rock" the piston, so a cylinder-shaped piston skirt isn't necessary.

Piston pumps can be used to move liquids or compress gases.

There are two special type of pistons used in air cannons: close tolerance pistons and double pistons. In close tolerance pistons O-rings serve as a valve, but O-rings are not used in double piston types.





</doc>
<doc id="24778" url="https://en.wikipedia.org/wiki?curid=24778" title="PK">
PK

PK or pk may refer to:












</doc>
<doc id="24779" url="https://en.wikipedia.org/wiki?curid=24779" title="Psi">
Psi

Psi or the initials PSI or Ψ may refer to:














</doc>
<doc id="24780" url="https://en.wikipedia.org/wiki?curid=24780" title="Five precepts">
Five precepts

The five precepts (; ) or five rules of training (; ) is the most important system of morality for Buddhist lay people. They constitute the basic code of ethics to be undertaken by lay followers of Buddhism. The precepts are commitments to abstain from killing living beings, stealing, sexual misconduct, lying and intoxication. Within the Buddhist doctrine, they are meant to develop mind and character to make progress on the path to enlightenment. They are sometimes referred to as the śrāvakayāna precepts in the Mahāyāna tradition, contrasting them with the "bodhisattva" precepts. The five precepts form the basis of several parts of Buddhist doctrine, both lay and monastic. With regard to their fundamental role in Buddhist ethics, they have been compared with the ten commandments in Abrahamic religions or the ethical codes of Confucianism. The precepts have been connected with utilitarianist, deontological and virtue approaches to ethics, though by 2017, such categorization by western terminology had mostly been abandoned by scholars. The precepts have been compared with human rights because of their universal nature, and some scholars argue they can complement the concept of human rights.

The five precepts were common to the religious milieu of 6th-century BCE India, but the Buddha's focus on awareness through the fifth precept was unique. As shown in Early Buddhist Texts, the precepts grew to be more important, and finally became a condition for membership of the Buddhist religion. When Buddhism spread to different places and people, the role of the precepts began to vary. In countries where Buddhism had to compete with other religions, such as China, the ritual of undertaking the five precepts developed into an initiation ceremony to become a Buddhist lay person. On the other hand, in countries with little competition from other religions, such as Thailand, the ceremony has had little relation to the rite of becoming Buddhist, as many people are presumed Buddhist from birth.

Undertaking and upholding the five precepts is based on the principle of non-harming (Pāli and ). The Pali Canon recommends one to compare oneself with others, and on the basis of that, not to hurt others. Compassion and a belief in karmic retribution form the foundation of the precepts. Undertaking the five precepts is part of regular lay devotional practice, both at home and at the local temple. However, the extent to which people keep them differs per region and time. People keep them with an intention to develop themselves, but also out of fear of a bad rebirth.

The first precept consists of a prohibition of killing, both humans and all animals. Scholars have interpreted Buddhist texts about the precepts as an opposition to and prohibition of capital punishment, suicide, abortion and euthanasia. In practice, however, many Buddhist countries still use the death penalty. With regard to abortion, Buddhist countries take the middle ground, by condemning though not prohibiting it. The Buddhist attitude to violence is generally interpreted as opposing all warfare, but some scholars have raised exceptions. The second precept prohibits theft. The third precept refers to adultery in all its forms, and has been defined by modern teachers with terms such as "sexual responsibility" and "long-term commitment". The fourth precept involves falsehood spoken or committed to by action, as well as malicious speech, harsh speech and gossip. The fifth precept prohibits intoxication through alcohol, drugs or other means. Early Buddhist Texts nearly always condemn alcohol, and so do Chinese Buddhist post-canonical texts. Buddhist attitudes toward smoking differ per time and region, but are generally permissive. In modern times, traditional Buddhist countries have seen revival movements to promote the five precepts. As for the West, the precepts play a major role in Buddhist organizations. They have also been integrated in mindfulness training programs, though many mindfulness specialists do not support this because of the precepts' religious import. Lastly, many conflict prevention programs make use of the precepts.

Buddhist scriptures explain the five precepts as the minimal standard of Buddhist morality. It is the most important system of morality in Buddhism, together with the monastic rules. "Śīla" (Sanskrit; ) is used to refer to Buddhist precepts, including the five. But the word also refers to the virtue and morality which lies at the foundation of the spiritual path to enlightenment, which is the first of the three forms of training on the path. Thus, the precepts are rules or guidelines to develop mind and character to make progress on the path to enlightenment. The five precepts are part of the right speech, action and livelihood aspects of the Noble Eightfold Path, the core teaching of Buddhism. Moreover, the practice of the five precepts and other parts of "śīla" are described as forms of merit-making, means to create good karma. The five precepts have been described as social values that bring harmony to society, and breaches of the precepts described as antithetical to a harmonious society. On a similar note, in Buddhist texts, the ideal, righteous society is one in which people keep the five precepts.

Comparing different parts of Buddhist doctrine, the five precepts form the basis of the eight precepts, which are lay precepts stricter than the five precepts, similar to monastic precepts. Secondly, the five precepts form the first half of the ten or eleven precepts for a person aiming to become a Buddha ("bodhisattva"), as mentioned in the "Brahmajala Sūtra" of the Mahāyāna tradition. Contrasting these precepts with the five precepts, the latter were commonly referred to by Mahāyānists as the "śrāvakayāna" precepts, or the precepts of those aiming to become enlightened disciples (; ) of a Buddha, but not Buddhas themselves. The teneleven "bodhisattva" precepts presuppose the five precepts, and are partly based on them. The five precepts are also partly found in the teaching called the ten good courses of action, referred to in Theravāda () and Tibetan Buddhism (; ). Finally, the first four of the five precepts are very similar to the most fundamental rules of monastic discipline (), and may have influenced their development.

In conclusion, the five precepts lie at the foundation of all Buddhist practice, and in that respect, can be compared with the ten commandments in Christianity and Judaism or the ethical codes of Confucianism.

The five precepts were part of early Buddhism and are common to nearly all schools of Buddhism. In early Buddhism, the five precepts were regarded as an ethic of restraint, to restrain unwholesome tendencies and thereby purify one's being to attain enlightenment. The five precepts were based on the "pañcaśīla", prohibitions for pre-Buddhist Brahmanic priests, which were adopted in many Indic religions around 6th century BCE. The first four Buddhist precepts were nearly identical to these "pañcaśīla", but the fifth precept, the prohibition on intoxication, was new in Buddhism: the Buddha's emphasis on awareness () was unique.

In some schools of ancient Indic Buddhism, Buddhist devotees could choose to adhere to only a number of precepts, instead of the complete five. The schools that would survive in later periods, however, that is Theravāda and Mahāyāna Buddhism, were both ambiguous about this practice. Some early Mahāyāna texts allow it, but some do not; Theravāda texts do not discuss this practice at all.

The prohibition on killing had motivated early Buddhists to form a stance against animal sacrifice, a common ritual practice in ancient India. According to the Pāli Canon, however, early Buddhists did not adopt a vegetarian lifestyle.

In Early Buddhist Texts, the role of the five precepts gradually develops. First of all, the precepts are combined with a declaration of faith in the triple gem (the Buddha, his teaching and the monastic community). Next, the precepts develop to become the foundation of lay practice. The precepts are seen as a preliminary condition for the higher development of the mind. At a third stage in the texts, the precepts are actually mentioned together with the triple gem, as though they are part of it. Lastly, the precepts, together with the triple gem, become a required condition for the practice of Buddhism, as lay people have to undergo a formal initiation to become a member of the Buddhist religion. When Buddhism spread to different places and people, the role of the precepts began to vary. In countries in which Buddhism was adopted as the main religion without much competition from other religious disciplines, such as Thailand, the relation between the initiation of a lay person and the five precepts has been virtually non-existent. In such countries, the taking of the precepts has become a sort of ritual cleansing ceremony. People are presumed Buddhist from birth without much of an initiation. The precepts are often committed to by new followers as part of their installment, yet this is not very pronounced. However, in some countries like China, where Buddhism was not the only religion, the precepts became an ordination ceremony to initiate lay people into the Buddhist religion.

In China, the five precepts were introduced in the first centuries CE, both in their "śrāvakayāna" and "bodhisattva" formats. During this time, it was particularly Buddhist teachers who promoted abstinence from alcohol (the fifth precept), since Daoism and other thought systems emphasized moderation rather than full abstinence. Chinese Buddhists interpreted the fifth precept strictly, even more so than in Indic Buddhism. For example, the monk Daoshi ( 600–83) dedicated large sections of his encyclopedic writings to abstinence from alcohol. However, in some parts of China, such as Dunhuang, considerable evidence has been found of alcohol consumption among both lay people and monastics. Later, from the 8th century onward, strict attitudes of abstinence led to a development of a distinct tea culture among Chinese monastics and lay intellectuals, in which tea gatherings replaced gatherings with alcoholic beverages, and were advocated as such. These strict attitudes were formed partly because of the religious writings, but may also have been affected by the bloody An Lushan Rebellion of 775, which had a sobering effect on 8th-century Chinese society. When the five precepts were integrated in Chinese society, they were associated and connected with karma, Chinese cosmology and medicine, a Daoist worldview, and Confucian virtue ethics.

In the Theravāda tradition, the precepts are recited in a standardized fashion, using Pāli language. In Thailand, a leading lay person will normally request the monk to administer the precepts by reciting the following three times:

After this, the monk administering the precepts will recite a reverential line of text to introduce the ceremony, after which he guides the lay people in declaring that they take their refuge in the three refuges or triple gem.

He then continues with reciting the five precepts:

After the lay people have repeated the five precepts after the monk, the monk will close the ceremony reciting:

The format of the ceremony for taking the precepts occurs several times in the Chinese Buddhist Canon, in slightly different forms.

One formula of the precepts can be found in the "Treatise on Taking Refuge and the Precepts" ():


Similarly, in the Mūla-Sarvāstivāda texts used in Tibetan Buddhism, the precepts are formulated such that one takes the precepts upon oneself for one's entire lifespan, following the examples of the enlightened disciples of the Buddha ("arahant").

The five precepts can be found in many places in the Early Buddhist Texts. The precepts are regarded as means to building good character, or as an expression of such character. The Pāli Canon describes them as means to avoid harm to oneself and others. It further describes them as gifts toward oneself and others. Moreover, the texts say that people who uphold them will be confident in any gathering of people, will have wealth and a good reputation, and will die a peaceful death, reborn in heaven or as a human being. On the other hand, living a life in violation of the precepts is believed to lead to rebirth in an unhappy destination. They are understood as principles that define a person as human in body and mind.

The precepts are normative rules, but are formulated and understood as "undertakings" rather than commandments enforced by a moral authority, according to the voluntary and gradualist standards of Buddhist ethics. They are forms of restraint formulated in negative terms, but are also accompanied by virtues and positive behaviors, which are cultivated through the practice of the precepts. The most important of these virtues is non-harming (Pāli and ), which underlies all of the five precepts. Precisely, the texts say that one should keep the precepts, adhering to the principle of comparing oneself with others:
In other words, all living beings are alike in that they want to be happy and not suffer. Comparing oneself with others, one should therefore not hurt others as one would not want to be hurt. Ethicist Pinit Ratanakul argues that the compassion which motivates upholding the precepts comes from an understanding that all living beings are equal and of a nature that they are 'not-self' (). Another aspect that is fundamental to this is the belief in karmic retribution.

In the upholding or violation of the precepts, intention is crucial. In the Pāli scriptures, an example is mentioned of a person stealing an animal only to set it free, which was not seen as an offense of theft. In the Pāli commentaries, a precept is understood to be violated when the person violating it finds the object of the transgression (e.g. things to be stolen), is aware of the violation, has the intention to violate it, does actually act on that intention, and does so successfully.

Upholding the precepts is sometimes distinguished in three levels: to uphold them without having formally undertaken them; to uphold them formally, willing to sacrifice one's own life for it; and finally, to spontaneously uphold them. The latter refers to the "arahant", who is understood to be morally incapable of violating the first four precepts. A layperson who upholds the precepts is described in the texts as a "jewel among laymen". On the other hand, the most serious violations of the precepts are the five actions of immediate retribution, which are believed to lead the perpetrator to an unavoidable rebirth in hell. These consist of injuring a Buddha, killing an "arahant", killing one's father or mother, and causing the monastic community to have a schism.

Lay followers often undertake these training rules in the same ceremony as they take the refuges. Monks administer the precepts to the laypeople, which creates an additional psychological effect. Buddhist lay people may recite the precepts regularly at home, and before an important ceremony at the temple to prepare the mind for the ceremony.

The five precepts are at the core of Buddhist morality. In field studies in some countries like Sri Lanka, villagers describe them as the core of the religion. Anthropologist Barend Terwiel found in his fieldwork that most Thai villagers knew the precepts by heart, and many, especially the elderly, could explain the implications of the precepts following traditional interpretations.

Nevertheless, Buddhists do not all follow them with the same strictness. Devotees who have just started keeping the precepts will typically have to exercise considerable restraint. When they become used to the precepts, they start to embody them more naturally. Researchers doing field studies in traditional Buddhist societies have found that the five precepts are generally considered demanding and challenging. For example, anthropologist Stanley Tambiah found in his field studies that strict observance of the precepts had "little positive interest for the villager ... not because he devalues them but because they are not normally open to him". Observing precepts was seen to be mostly the role of a monk or an elderly lay person. More recently, in a 1997 survey in Thailand, only 13.8% of the respondents indicated they adhered to the five precepts in their daily lives, with the fourth and fifth precept least likely to be adhered to. Yet, people do consider the precepts worth striving for, and do uphold them out of fear of bad karma and being reborn in hell, or because they believe in that the Buddha issued these rules, and that they therefore should be maintained. Anthropologist Melford Spiro found that Burmese Buddhists mostly upheld the precepts to avoid bad karma, as opposed to expecting to gain good karma. Scholar of religion Winston King observed from his field studies that the moral principles of Burmese Buddhists were based on personal self-developmental motives rather than other-regarding motives. Scholar of religion Richard Jones concludes that the moral motives of Buddhists in adhering to the precepts are based on the idea that renouncing self-service, ironically, serves oneself.

In East Asian Buddhism, the precepts are intrinsically connected with the initiation as a Buddhist lay person. Early Chinese translations such as the "Upāsaka-śila Sūtra" hold that the precepts should only be ritually transmitted by a monastic. The texts describe that in the ritual the power of the Buddhas and "bodhisattvas" is transmitted, and helps the initiate to keep the precepts. This "lay ordination" ritual usually occurs after a stay in a temple, and often after a monastic ordination (); has taken place. The ordained lay person is then given a religious name. The restrictions that apply are similar to a monastic ordination, such as permission from parents.

In the Theravāda tradition, the precepts are usually taken "each separately" (), to indicate that if one precept should be broken, the other precepts are still intact. In very solemn occasions, or for very pious devotees, the precepts may be taken as a group rather than each separately. This does not mean, however, that only some of the precepts can be undertaken; they are always committed to as a complete set. In East Asian Buddhism, however, the vow of taking the precepts is considered a solemn matter, and it is not uncommon for lay people to undertake only the precepts that they are confident they can keep. The act of taking a vow to keep the precepts is what makes it karmically effective: Spiro found that someone who did not violate the precepts, but did not have any intention to keep them either, was not believed to accrue any religious merit. On the other hand, when people took a vow to keep the precepts, and then broke them afterwards, the negative karma was considered larger than in the case no vow was taken to keep the precepts.

Several modern teachers such as Thich Nhat Hanh and Sulak Sivaraksa have written about the five precepts in a wider scope, with regard to social and institutional relations. In these perspectives, mass production of weapons or spreading untruth through media and education also violates the precepts. On a similar note, human rights organizations in Southeast Asia have attempted to advocate respect for human rights by referring to the five precepts as guiding principles.

The first precept prohibits the taking of life of a sentient being. It is violated when someone intentionally and successfully kills such a sentient being, having understood it to be sentient and using effort in the process. Causing injury goes against the spirit of the precept, but does, technically speaking, not violate it. The first precept includes taking the lives of animals, even small insects. However, it has also been pointed out that the seriousness of taking life depends on the size, intelligence, benefits done and the spiritual attainments of that living being. Killing a large animal is worse than killing a small animal (also because it costs more effort); killing a spiritually accomplished master is regarded as more severe than the killing of another "more average" human being; and killing a human being is more severe than the killing of an animal. But all killing is condemned. Virtues that accompany this precept are respect for dignity of life, kindness and compassion, the latter expressed as "trembling for the welfare of others". A positive behavior that goes together with this precept is protecting living beings. Positive virtues like sympathy and respect for other living beings in this regard are based on a belief in the cycle of rebirththat all living beings must be born and reborn. The concept of the fundamental Buddha nature of all human beings also underlies the first precept.

The description of the first precept can be interpreted as a prohibition of capital punishment. Suicide is also seen as part of the prohibition. Moreover, abortion (of a sentient being) goes against the precept, since in an act of abortion, the criteria for violation are all met. In Buddhism, human life is understood to start at conception. A prohibition of abortion is mentioned explicitly in the monastic precepts, and several Buddhist tales warn of the harmful karmic consequences of abortion. Bioethicist Damien Keown argues that Early Buddhist Texts do not allow for exceptions with regard to abortion, as they consist of a "consistent' (i.e. exceptionless) pro-life position". Keown further proposes that a middle way approach to the five precepts is logically hard to defend. Asian studies scholar Giulo Agostini argues, however, that Buddhist commentators in India from the 4th century onward thought abortion did not break the precepts under certain circumstances.

Ordering another person to kill is also included in this precept, therefore requesting or administering euthanasia can be considered a violation of the precept, as well as advising another person to commit abortion. With regard to euthanasia and assisted suicide, Keown quotes the Pāli "Dīgha Nikāya" that says a person upholding the first precept "does not kill a living being, does not cause a living being to be killed, does not approve of the killing of a living being". Keown argues that in Buddhist ethics, regardless of motives, death can never be the aim of one's actions.

Interpretations of how Buddhist texts regard warfare are varied, but in general Buddhist doctrine is considered to oppose all warfare. In many "Jātaka" tales, such as that of Prince Temiya, as well as some historical documents, the virtue of non-violence is taken as an opposition to all war, both offensive and defensive. At the same time, though, the Buddha is often shown not to explicitly oppose war in his conversations with political figures. Buddhologist André Bareau points out that the Buddha was reserved in his involvement of the details of administrative policy, and concentrated on the moral and spiritual development of his disciples instead. He may have believed such involvement to be futile, or detrimental to Buddhism. Nevertheless, at least one disciple of the Buddha is mentioned in the texts who refrained from retaliating his enemies because of the Buddha, that is King Pasenadi (). The texts are ambiguous in explaining his motives though. In some later Mahāyāna texts, such as in the writings of Asaṅga, examples are mentioned of people who kill those who persecute Buddhists. In these examples, killing is justified by the authors because protecting Buddhism was seen as more important than keeping the precepts. Another example that is often cited is that of King Duṭṭhagāmaṇī, who is mentioned in the post-canonical Pāli Mahāvaṃsa chronicle. In the chronicle, the king is saddened with the loss of life after a war, but comforted by a Buddhist monk, who states that nearly everyone who was killed did not uphold the precepts anyway. Buddhist studies scholar Lambert Schmithausen argues that in many of these cases Buddhist teachings like that of emptiness were misused to further an agenda of war or other violence.

Field studies in Cambodia and Burma have shown that many Buddhists considered the first precept the most important, or the most blamable. In some traditional communities, such as in Kandal Province in pre-war Cambodia, as well as Burma in the 1980s, it was uncommon for Buddhists to slaughter animals, to the extent that meat had to be bought from not-Buddhists. In his field studies in Thailand in the 1960s, Terwiel found that villagers did tend to kill insects, but were reluctant and self-conflicted with regard to killing larger animals. In Spiro's field studies, however, Burmese villagers were highly reluctant even to kill insects.

Early Buddhists did not adopt a vegetarian lifestyle. Indeed, in several Pāli texts vegetarianism is described as irrelevant in the spiritual purification of the mind. There are prohibitions on certain types of meat, however, especially those which are condemned by society. The idea of abstaining from killing animal life has also led to a prohibition on professions that involve trade in flesh or living beings, but not to a full prohibition of all agriculture that involves cattle. In modern times, referring to the law of supply and demand or other principles, some Theravādin Buddhists have attempted to promote vegetarianism as part of the five precepts. For example, the Thai Santi Asoke movement practices vegetarianism.

Furthermore, among some schools of Buddhism, there has been some debate with regard to a principle in the monastic discipline. This principle states that a Buddhist monk cannot accept meat if it comes from animals especially slaughtered for him. Some teachers have interpreted this to mean that when the recipient has no knowledge on whether the animal has been killed for him, he cannot accept the food either. Similarly, there has been debate as to whether laypeople should be vegetarian when adhering to the five precepts. Though vegetarianism among Theravādins is generally uncommon, it has been practiced much in East Asian countries, as some Mahāyāna texts, such as the "Mahāparanirvana Sūtra" and the "Laṅkāvatāra Sūtra", condemn the eating of meat. Nevertheless, even among Mahāyāna Buddhistsand East Asian Buddhiststhere is disagreement on whether vegetarianism should be practiced. In the "Laṅkāvatāra Sūtra", biological, social and hygienic reasons are given for a vegetarian diet; however, historically, a major factor in the development of a vegetarian lifestyle among Mahāyāna communities may have been that Mahāyāna monastics cultivated their own crops for food, rather than living from alms. Already from the 4th century CE, Chinese writer Xi Chao understood the five precepts to include vegetarianism.
Apart from trade in flesh or living beings, there are also other professions considered undesirable. Vietnamese teacher Thich Nhat Hanh gives a list of examples, such as working in the arms industry, the military, police, producing or selling poison or drugs such as alcohol and tobacco.

In general, the first precept has been interpreted by Buddhists as a call for non-violence and pacifism. But there have been some exceptions of people who did not interpret the first precept as an opposition to war. For example, in the twentieth century, some Japanese Zen teachers wrote in support of violence in war, and some of them argued this should be seen as a means to uphold the first precept. There is some debate and controversy surrounding the problem whether a person can commit suicide, such as self-immolation, to reduce other people's suffering in the long run, such as in protest to improve a political situation in a country. Teachers like the Dalai Lama and Shengyan have rejected forms of protest like self-immolation, as well as other acts of self-harming or fasting as forms of protest.

Although capital punishment goes against the first precept, as of 2001, many countries in Asia still maintained the death penalty, including Sri Lanka, Thailand, China and Taiwan. In some Buddhist countries, such as Sri Lanka and Thailand, capital punishment was applied during some periods, while during other periods no capital punishment was used at all. In other countries with Buddhism, like China and Taiwan, Buddhism, or any religion for that matter, has had no influence in policy decisions of the government. Countries with Buddhism that have abolished capital punishment include Cambodia and Hong Kong.

In general, Buddhist traditions oppose abortion. In many countries with Buddhist traditions such as Thailand, Taiwan, Korea and Japan, however, abortion is a widespread practice, whether legal or not. Many people in these countries consider abortion immoral, but also think it should be less prohibited. Ethicist Roy W. Perrett, following Ratanakul, argues that this field research data does not so much indicate hypocrisy, but rather points at a "middle way" in applying Buddhist doctrine to solve a moral dilemma. Buddhists tend to take "both sides" on the pro-lifepro-choice debate, being against the taking of life of a fetus in principle, but also believing in compassion toward mothers. Similar attitudes may explain the Japanese "mizuko kuyō" ceremony, a Buddhist memorial service for aborted children, which has led to a debate in Japanese society concerning abortion, and finally brought the Japanese to a consensus that abortion should not be taken lightly, though it should be legalized. This position, held by Japanese Buddhists, takes the middle ground between the Japanese neo-Shinto "pro-life" position, and the liberationist, "pro-choice" arguments. Keown points out, however, that this compromise does not mean a Buddhist middle way between two extremes, but rather incorporates two opposite perspectives. In Thailand, women who wish to have abortion usually do so in the early stages of pregnancy, because they believe the karmic consequences are less then. Having had abortion, Thai women usually make merits to compensate for the negative karma.

The second precept prohibits theft, and involves the intention to steal what one perceives as not belonging to oneself ("what is not given") and acting successfully upon that intention. The severity of the act of theft is judged by the worth of the owner and the worth of that which is stolen. Underhand dealings, fraud, cheating and forgery are also included in this precept. Accompanying virtues are generosity, renunciation, and right livelihood, and a positive behavior is the protection of other people's property.

The second precept includes different ways of stealing and fraud. Borrowing without permission is sometimes included, as well as gambling. Psychologist Vanchai Ariyabuddhiphongs did studies in the 2000s and 2010s in Thailand and discovered that people who did not adhere to the five precepts more often tended to believe that money was the most important goal in life, and would more often pay bribes than people who did adhere to the precepts. On the other hand, people who observed the five precepts regarded themselves as wealthier and happier than people who did not observe the precepts.

Professions that are seen to violate the second precept include working in the gambling industry or marketing products that are not actually required for the customer.

The third precept condemns sexual misconduct. This has been interpreted in classical texts to include adultery with a married or engaged person, rape, incest, sex with a minor (or a person "protected by any relative"), and sex with a prostitute. In later texts, details such as intercourse at an inappropriate time or inappropriate place are also counted as breaches of the third precept. Masturbation goes against the spirit of the precept, though in the early texts it is not prohibited for laypeople.

The third precept is explained as leading to greed in oneself and harm to others. The transgression is regarded as more severe if the other person is a good person. Virtues that go hand-in-hand with the third precept are contentment, especially with one's partner, and recognition and respect for faithfulness in a marriage.

The third precept is interpreted as avoiding harm to another by using sensuality in the wrong way. This means not engaging with inappropriate partners, but also respecting one's personal commitment to a relationship. In some traditions, the precept also condemns adultery with a person whose spouse agrees with the act, since the nature of the act itself is condemned. Furthermore, flirting with a married person may also be regarded as a violation. Though prostitution is discouraged in the third precept, it is usually not actively prohibited by Buddhist teachers. With regard to applications of the principles of the third precept, the precept, or any Buddhist principle for that matter, is usually not connected with a stance against contraception. In traditional Buddhist societies such as Sri Lanka, pre-marital sex is considered to violate the precept, though this is not always adhered to by people who already intend to marry.

In the interpretation of modern teachers, the precept includes any person in a sexual relationship with another person, as they define the precept by terms such as "sexual responsibility" and "long-term commitment". Some modern teachers include masturbation as a violation of the precept, others include certain professions, such as those that involve sexual exploitation, prostitution or pornography, and professions that promote unhealthy sexual behavior, such as in the entertainment industry.

The fourth precept involves falsehood spoken or committed to by action. Avoiding other forms of wrong speech are also considered part of this precept, consisting of malicious speech, harsh speech and gossip. A breach of the precept is considered more serious if the falsehood is motivated by an ulterior motive (rather than, for example, "a small white lie"). The accompanying virtue is being honest and dependable, and involves honesty in work, truthfulness to others, loyalty to superiors and gratitude to benefactors. In Buddhist texts, this precept is considered second in importance to the first precept, because a lying person is regarded to have no shame, and therefore capable of many wrongs. Untruthfulness is not only to be avoided because it harms others, but also because it goes against the Buddhist ideal of finding the truth.

The fourth precept includes avoidance of lying and harmful speech. Some modern teachers such as Thich Nhat Hanh interpret this to include avoiding spreading false news and uncertain information. Work that involves data manipulation, false advertising or online scams can also be regarded as violations. Terwiel reports that among Thai Buddhists, the fourth precept is also seen to be broken when people insinuate, exaggerate or speak abusively or deceitfully.

The fifth precept prohibits intoxication through alcohol, drugs or other means, and its virtues are mindfulness and responsibility, applied to food, work, behavior, and with regard to the nature of life. Awareness, meditation and heedfulness can also be included here. Medieval Pāli commentator Buddhaghosa writes that whereas violating the first four precepts may be more or less blamable depending on the person or animal affected, the fifth precept is always "greatly blamable", as it hinders one from understanding the Buddha's teaching and may lead one to "madness". In ancient China, Daoshi described alcohol as the "doorway to laxity and idleness" and as a cause of suffering. Nevertheless, he did describe certain cases when drinking was considered less of a problem, such as in the case of a queen distracting the king by alcohol to prevent him from murder. However, Daoshi was generally strict in his interpretations: for example, he allowed medicinal use of alcohol only in extreme cases. Early Chinese translations of the Tripitaka describe negative consequences for people breaking the fifth precept, for themselves and their families. The Chinese translation of the "Upāsikaśila Sūtra", as well as the Pāli version of the Sigālovāda Sutta, speak of ill consequences such as loss of wealth, ill health, a bad reputation and "stupidity", concluding in a rebirth in hell. The "Dīrghāgama" adds to that that alcohol leads to quarreling, negative states of mind and damage to one's intelligence. The Mahāyāna "Brahmajāla Sūtra" describes the dangers of alcohol in very strong terms, including the selling of alcohol. Similar arguments against alcohol can be found in Nāgārjuna's writings. The strict interpretation of prohibition of alcohol consumption can be supported by the "Upāli Sūtra"<nowiki>'</nowiki>s statement that a disciple of the Buddha should not drink any alcohol, "even a drop on the point of a blade of grass". However, in the writing of some Abhidharma commentators, consumption was condemned or condoned, depending on the intention with which alcohol was consumed.

The fifth precept is regarded as important, because drinking alcohol is condemned for the sluggishness and lack of self-control it leads to, which might lead to breaking the other precepts. In Spiro's field studies, violating the fifth precept was seen as the worst of all the five precepts by half of the monks interviewed, citing the harmful consequences. Nevertheless, in practice it is often disregarded by lay people. In Thailand, drinking alcohol is fairly common, even drunkenness. Among Tibetans, drinking beer is common, though this is only slightly alcoholic. Medicinal use of alcohol is generally not frowned upon, and in some countries like Thailand and Laos, smoking is usually not regarded as a violation of the precept. Thai and Laotian monks have been known to smoke, though monks who have received more training are less likely to smoke. On a similar note, as of 2000, no Buddhist country prohibited the sale or consumption of alcohol, though in Sri Lanka Buddhist revivalists attempted unsuccessfully to get a full prohibition passed in 1956. Moreover, pre-Communist Tibet used to prohibit smoking in some areas of the capital. Monks were prohibited from smoking, and the import of tobacco was banned.

Thich Nhat Hanh also includes mindful consumption in this precept, which consists of unhealthy food, unhealthy entertainment and unhealthy conversations, among others.

In modern times, adherence to the precepts among Buddhists is less strict than it traditionally was. This is especially true for the third precept. For example, in Cambodia in the 1990s and 2000s, standards with regard to sexual restraint were greatly relaxed. Some Buddhist movements and communities have tried to go against the modern trend of less strict adherence to the precepts. In Cambodia, a millenarian movement led by Chan Yipon promoted the revival of the five precepts. And in the 2010s, the Supreme Sangha Council in Thailand ran a nationwide program called "The Villages Practicing the Five Precepts", aiming to encourage keeping the precepts, with an extensive classification and reward system.

In many Western Buddhist organizations, the five precepts play a major role in developing ethical guidelines. Furthermore, Buddhist teachers such as Philip Kapleau, Thich Nhat Hanh and Robert Aitken have promoted mindful consumption in the West, based on the five precepts. In another development in the West, some scholars working in the field of mindfulness training have proposed that the five precepts be introduced as a component in such trainings. Specifically, to prevent organizations from using mindfulness training to further an economical agenda with harmful results to its employees, the economy or the environment, the precepts could be used as a standardized ethical framework. As of 2015, several training programs made explicit use of the five precepts as secular, ethical guidelines. However, many mindfulness training specialists consider it problematic to teach the five precepts as part of training programs in secular contexts because of their religious origins and import.

Peace studies scholar Theresa Der-lan Yeh notes that the five precepts address physical, economical, familial and verbal aspects of interaction, and remarks that many conflict prevention programs in schools and communities have integrated the five precepts in their curriculum. On a similar note, peace studies founder Johan Galtung describes the five precepts as the "basic contribution of Buddhism in the creation of peace".

Studying lay and monastic ethical practice in traditional Buddhist societies, Spiro argued ethical guidelines such as the five precepts are adhered to as a means to a higher end, that is, a better rebirth or enlightenment. He therefore concluded that Buddhist ethical principles like the five precepts are similar to Western utilitarianism. Keown, however, has argued that the five precepts are regarded as rules that cannot be violated, and therefore may indicate a deontological perspective in Buddhist ethics. On the other hand, Keown has also suggested that Aristotle's virtue ethics could apply to Buddhist ethics, since the precepts are considered good in themselves, and mutually dependent on other aspects of the Buddhist path of practice. Philosopher Christopher Gowans disagrees that Buddhist ethics are deontological, arguing that virtue and consequences are also important in Buddhist ethics. Gowans argues that there is no moral theory in Buddhist ethics that covers all conceivable situations such as when two precepts may be in conflict, but is rather characterized by "a commitment to and nontheoretical grasp of the basic Buddhist moral values". As of 2017, many scholars of Buddhism no longer think it is useful to try to fit Buddhist ethics into a Western philosophical category.

Keown has argued that the five precepts are very similar to human rights, with regard to subject matter and with regard to their universal nature. Other scholars, as well as Buddhist writers and human rights advocates, have drawn similar comparisons. For example, the following comparisons are drawn:

Keown describes the relationship between Buddhist precepts and human rights as "look[ing] both ways along the juridical relationship, both to what one is due to do, and to what is due to one". On a similar note, Cambodian human rights advocates have argued that for human rights to be fully implemented in society, the strengthening of individual morality must also be addressed. Buddhist monk and scholar Phra Payutto sees the Human Rights Declaration as an unfolding and detailing of the principles that are found in the five precepts, in which a sense of ownership is given to the individual, to make legitimate claims on one's rights. He believes that human rights should be seen as a part of human development, in which one develops from moral discipline (), to concentration () and finally wisdom (). He does not believe, however, that human rights are natural rights, but rather human conventions. Buddhism scholar Somparn Promta disagrees with him. He argues that human beings do have natural rights from a Buddhist perspective, and refers to the "attūpanāyika-dhamma", a teaching in which the Buddha prescribes a kind of golden rule of comparing oneself with others. ("See §Principles, above.") From this discourse, Promta concludes that the Buddha has laid down the five precepts in order to protect individual rights such as right of life and property: human rights are implicit within the five precepts. Academic Buntham Phunsap argues, however, that though human rights are useful in culturally pluralistic societies, they are in fact not required when society is entirely based on the five precepts. Phunsap therefore does not see human rights as part of Buddhist doctrine.




</doc>
<doc id="24782" url="https://en.wikipedia.org/wiki?curid=24782" title="Pente">
Pente

Pente is a strategy board game for two or more players, created in 1977 by Gary Gabrel, a dishwasher at Hideaway Pizza, in Stillwater, Oklahoma. Customers played Pente at Hideaway Pizza on checkerboard tablecloths while waiting for their orders to arrive. Thirty years later, patrons are still playing Pente at Hideaway Pizza, although now with roll-up Pente boards. Pente is based on the Japanese game ninuki-renju, a variant of renju or gomoku that is played on a Go board of 19x19 intersections with white and black stones. Like "ninuki-renju," Pente allows captures, but Pente added a new opening rule. In the nineteenth century, "gomoku" was introduced to Britain where it was known as "Go Bang" (this term is borrowed from Japanese "goban" 碁盤 meaning "go board").

Pente is a registered trademark of Hasbro for strategy game equipment. Pente (πέντε) is the number five in Greek.

Hasbro ceased distribution of Pente in 1993. It later licensed the name to Winning Moves, a classic games publisher that resurrected the game in 2004. The 2004 version includes 4 extra stones, called power stones, that can be played in the Pente Plus version.

The players alternate in placing stones of their color on free intersections, with White always assuming the opening move. The players aim to align five stones of the same color in vertical, horizontal or diagonal lines. Captures are obtained by flanking pairs of an opponent's stones in any same direction. Captures must consist of exactly two stones; flanking a single stone or three stones does not result in a capture. For example, if the stones are X O O _ and you place your stone so it becomes X O O X, then your opponent's stones are removed from the board, leaving X _ _ X. A stone may legally be placed on any empty intersection, even if it forms a pair between two enemy stones. For example, if the stones are X O _ X you may place your stone so it becomes X O O X. Your stones are NOT captured in this case. When playing with multiple players the inside stones can be different colors, but the two stones on the outside must be the same colors. For example, X O Y X. It must be a pair in order to capture. 

A player wins by scoring five stones in a row. It can be horizontal, vertical, or diagonal. A player can also win by capturing five pairs of opponent stones. Pente can also be played by four people, with pairs of two acting as partners. It can also be played with multiple independent players when each player has their own different colored stones. 

In this common variation, the first player's second move is restricted — it must be at least three intersections away from the center of the board. The tournament rule was created by Tom Braunlich to reduce the advantage held by the first player.



</doc>
<doc id="24783" url="https://en.wikipedia.org/wiki?curid=24783" title="Pompatus">
Pompatus

Pompatus (or Pompitus) () is a nonce word coined by Steve Miller famously in his 1973 hit single "The Joker". The word is probably a corruption or imagined version of the word "puppetuse", an original coinage of the 14-year-old Vernon Green, and subsequently released in 1954 as the doo-wop song "The Letter" performed by him and The Medallions -- a song which also included another original coinage, "pismotality." In other songs, "Enter Maurice" and "The Conversation," Miller adds the word "epismetology" to "pompatus," one in spoken word, the style of "The Letter," in a likely homage to The Medallions' song. The oddness of the word "pompatus" occasioned some attention and further use, including being used in the title of a movie.

The lyrics of "The Joker" include the quatrain:

Each line references a track on a previous Miller album: "Space Cowboy" on "Brave New World" (1969); "Gangster of Love" on "Sailor" (1968); and "Enter Maurice" on "Recall the Beginning...A Journey from Eden" (1972), which includes the lines:

Although Miller claims he invented the words "epismetology" (a metathesis of the word epistemology) and "pompatus", both are variants of words which Miller most likely heard in a song by Vernon Green called "The Letter," which was recorded by the Los Angeles doo-wop group The Medallions in 1954.

Green's "The Letter" as performed by the Medallions had the lines:

Green describes the lyrics as a description of his dream woman. ""Pizmotality" described words of such secrecy that they could only be spoken to the one you loved", Green explained. He coined the term "puppetutes" "to mean a secret paper-doll fantasy figure who would be my everything and bear my children".

Because of its peculiarity, the word "pompatus" has secured a niche in 20th century pop culture. Wolfman Jack frequently referenced the phrase and there is a sound clip of him using the line within the song "Clap for the Wolfman" by The Guess Who. "The Pompatus of Love", a 1996 film starring Jon Cryer, featured four men discussing a number of assorted topics, including attempts to determine the meaning of the phrase. Jon Cryer was also a writer of the film, and describes finding out the meaning of the phrase during a phone call with Vernon Green in his autobiography "so that happened" in chapter 22, page 217. The line has been mentioned in various television show gags, including "The Simpsons" and "South Park".

Humor columnist Dave Barry frequently refers to the song line as a source of comedic value, particularly in his 1997 book "Dave Barry's Book of Bad Songs". 'Pompatus' is used by Michael Ondaatje in his 2001 book "Anil's Ghost". Stephen King uses the word in his 2006 novel "Lisey's Story". Tim Dorsey uses the word in his 2010 novel, "Gator a-Go-Go". It was the subject of the October 9, 2011 "Over the Hedge" comic strip.



</doc>
<doc id="24787" url="https://en.wikipedia.org/wiki?curid=24787" title="UGM-27 Polaris">
UGM-27 Polaris

The UGM-27 Polaris missile was a two-stage solid-fueled nuclear-armed submarine-launched ballistic missile. The United States Navy's first SLBM, it served from 1961 to 1996.

In the mid-1950s the Navy was involved in the Jupiter missile project with the U.S. Army, and had influenced the design by making it squat so it would fit in submarines. However, they had concerns about the use of liquid fuel rockets onboard ships, and some consideration was given to a solid fuel version, Jupiter S. In 1956, during an anti-submarine study known as Project Nobska, Edward Teller suggested that very small hydrogen bomb warheads were possible. A crash program to develop a missile suitable for carrying such warheads began as Polaris, launching its first shot less than four years later, in February 1960.

As the Polaris missile was fired underwater from a moving platform, it was essentially invulnerable to counterattack. This led the Navy to suggest, starting around 1959, that they be given the entire nuclear deterrent role. This led to new infighting between the Navy and the U.S. Air Force, the latter responding by developing the counterforce concept that argued for the strategic bomber and ICBM as key elements in flexible response. Polaris formed the backbone of the U.S. Navy's nuclear force aboard a number of custom-designed submarines. In 1963, the Polaris Sales Agreement led to the Royal Navy taking over the United Kingdom's nuclear role, and while some tests were carried out by the Italian Navy, this did not lead to use.

The Polaris missile was gradually replaced on 31 of the 41 original SSBNs in the U.S. Navy by the MIRV-capable Poseidon missile beginning in 1972. During the 1980s, these missiles were replaced on 12 of these submarines by the Trident I missile. The 10 - and SSBNs retained Polaris A-3 until 1980 because their missile tubes were not large enough to accommodate Poseidon. With beginning sea trials in 1980, these submarines were disarmed and redesignated as attack submarines to avoid exceeding the SALT II strategic arms treaty limits.

The Polaris missile program's complexity led to the development of new project management techniques, including the Program Evaluation and Review Technique (PERT) to replace the simpler Gantt chart methodology.

The Polaris missile replaced an earlier plan to create a submarine-based missile force based on a derivative of the U.S. Army Jupiter Intermediate-range ballistic missile. Chief of Naval Operations Admiral Arleigh Burke appointed Rear Admiral W. F. "Red" Raborn as head of a Special Project Office to develop Jupiter for the Navy in late 1955. The Jupiter missile's large diameter was a product of the need to keep the length short enough to fit in a reasonably-sized submarine. At the seminal Project Nobska conference in 1956, with Admiral Burke present, nuclear physicist Edward Teller stated that a physically small one-megaton warhead could be produced for Polaris within a few years, and this prompted Burke to leave the Jupiter program and concentrate on Polaris in December of that year. Polaris was spearheaded by the Special Project Office's Missile Branch under Rear Admiral Roderick Osgood Middleton, and is still under the Special Project Office. Admiral Burke later was instrumental in determining the size of the Polaris submarine force, suggesting that 40-45 submarines with 16 missiles each would be sufficient. Eventually, the number of Polaris submarines was fixed at 41.

The was the first submarine capable of deploying U.S. developed submarine-launched ballistic missiles (SLBM). The responsibility of the development of SLBMs was given to the Navy and the Army. The Air Force was charged with developing a land-based intermediate range ballistic missile (IRBM), while an IRBM which could be launched by land or by sea was tasked to the Navy and Army. The Navy Special Projects (SP) office was at the head of the project. It was led by Rear Admiral William Raborn.

On September 13, 1955, James R. Killian, head of a special committee organized by President Eisenhower, recommended that both the Army and Navy come together under a program aimed at developing an intermediate-range ballistic missile (IRBM). The missile, later known as Jupiter, would be developed under the Joint Army-Navy Ballistic Missile Committee approved by Secretary of Defense Charles E. Wilson in early November of that year. The first IRBM boasted a liquid-fueled design. Liquid fuel is compatible with aircraft; it is less compatible with submarines. Solid fuels, on the other hand, make logistics and storage simpler and are safer. Not only was the Jupiter a liquid fuel design, it was also very large; even after it was designed for solid fuel, it was still a whopping 160,000 pounds. A smaller, new design would weigh much less, estimated at 30,000 pounds. The Navy would rather develop a smaller, more easily manipulated design. Edward Teller was one of the scientists encouraging the progress of smaller rockets. He argued that the technology needed to be discovered, rather than apply technology that is already created. Raborn was also convinced he could develop smaller rockets. He sent officers to make independent estimates of size to determine the plausibility of a small missile; while none of the officers could agree on a size, their findings were encouraging nonetheless.

The U.S. Navy began work on nuclear-powered submarines in 1946. They launched the first one, the in 1955. Nuclear powered submarines were the least vulnerable to a first strike from the Soviet Union.The next question that led to further development was what kind of arms the nuclear-powered submarines should be equipped with. In the summer of 1956, the navy sponsored a study by the National Academy of Sciences on anti-submarine warfare at Nobska Point in Woods Hole, Massachusetts, known as Project NOBSKA. The navy's intention was to have a new missile developed that would be lighter than existing missiles and cover a range up to fifteen hundred miles. A problem that needed to be solved was that this design would not be able to carry the desired one-megaton thermonuclear warhead.

This study brought Edward Teller from the recently formed nuclear weapons laboratory at Livermore and J. Carson Mark, representing the Los Alamos nuclear weapons laboratory. Teller was already known as a nuclear salesman, but this became the first instance where there was a big betting battle where he outbid his Los Alamos counterpart. The two knew each other well: Mark was named head of the theoretical division of Los Alamos in 1947, a job that was originally offered for Teller. Mark was a cautious physicist and no match for Teller in a bidding war.

At the NOBSKA summer study, Edward Teller made his famous contribution to the FBM program. Teller offered to develop a lightweight warhead of one-megaton strength within five years. He suggested that nuclear-armed torpedoes could be substituted for conventional ones to provide a new anti-submarine weapon. Livermore received the project. When Teller returned to Livermore, people were astonished by the boldness of Teller's promise. It seemed inconceivable with the current size of nuclear warheads, and Teller was challenged to support his assertion. He pointed out the trend in warhead technology, which indicated reduced weight to yield ratios in each succeeding generation. When Teller was questioned about the application of this to the FBM program, he asked, ‘Why use a 1958 warhead in a 1965 weapon system?’

Mark disagreed with Teller's prediction that the desired one-megaton warhead could be made to fit the missile envelope within the timescale envisioned. Instead, Mark suggested that half a megaton would be more realistic and he quoted a higher price and a longer deadline. This simply confirmed the validity of Teller's prediction in the Navy's eyes. Whether the warhead was half or one megaton mattered little so long as it fitted the missile and would be ready by the deadline. Almost four decades later, Teller said, referring to Mark's performance, that it was “an occasion when I was happy about the other person being bashful.”
When the Atomic Energy Commission backed up Teller's estimate in early September, Admiral Burke and the Navy Secretariat decided to support SPO in heavily pushing for the new missile, now named Polaris by Admiral Raborn.

There is a contention that the Navy's "Jupiter" missile program was unrelated to the Army program. The Navy also expressed an interest in Jupiter as an SLBM, but left the collaboration to work on their Polaris. At first, the newly assembled SPO team had the problem of making the large, liquid-fuel Jupiter IRBM to work properly. Jupiter retained the short, squat shape intended to fit in naval submarines. Its sheer size and volatility of its fuel made it very unsuited to submarine launching and was only slightly more attractive for deployment on ships. The missile continued to be developed by the Army's German team in collaboration with their main contractor, Chrysler Corporation. SPO's responsibility was to develop a sea-launching platform with necessary fire control and stabilization systems for that very purpose. The original schedule was to have a ship-based IRBM system ready for operation evaluation by January 1, 1960, and a submarine-based one by January 1, 1965.
However, the Navy was deeply dissatisfied with the liquid fuel IRBM. The first concern was that the cryogenic liquid fuel was not only extremely dangerous to handle, but launch-preparations were also very time-consuming. Second, an argument was made that liquid-fueled rockets gave relatively low initial acceleration, which is disadvantageous in launching a missile from a moving platform in certain sea states. By mid-July 1956, the Secretary of Defense's Scientific Advisory Committee had recommended that a solid-propellant missile program be fully instigated but not using the unsuitable Jupiter payload and guidance system.
By October 1956, a study group comprising key figures from Navy, industry and academic organizations considered various design parameters of the Polaris system and trade-offs between different sub-sections. The estimate that a 30,000-pound missile could deliver a suitable warhead over 1500 nautical miles was endorsed. With this optimistic assessment, the Navy now decided to scrap the Jupiter program altogether and sought out the Department of Defense to back a separate Navy missile.
A huge surfaced submarine would carry four "Jupiter" missiles, which would be carried and launched horizontally. This was probably the never-built SSM-N-2 Triton program. However, a history of the Army's Jupiter program states that the Navy was involved in the Army program, but withdrew at an early stage.

Originally, the Navy favored cruise missile systems in a strategic role, such as the Regulus missile deployed on the earlier and a few other submarines, but a major drawback of these early cruise missile launch systems (and the Jupiter proposals) was the need to surface, and remain surfaced for some time, to launch. Submarines were very vulnerable to attack during launch, and a fully or partially fueled missile on deck was a serious hazard. The difficulty of preparing a launch in rough weather was another major drawback for these designs, but rough sea conditions did not unduly affect Polaris' submerged launches.

It quickly became apparent that solid-fueled ballistic missiles had advantages over cruise missiles in range and accuracy, and could be launched from a submerged submarine, improving submarine survivability.

The prime contractor for all three versions of Polaris was Lockheed Missiles and Space Company (now Lockheed Martin).

The Polaris program started development in 1956. , the first U.S. missile submarine, successfully launched the first Polaris missile from a submerged submarine on July 20, 1960. The A-2 version of the Polaris missile was essentially an upgraded A-1, and it entered service in late 1961. It was fitted on a total of 13 submarines and served until June 1974.(1). Ongoing problems with the W-47 warhead, especially with its mechanical arming and safing equipment, led to large numbers of the missiles being recalled for modifications, and the U.S. Navy sought a replacement with either a larger yield or equivalent destructive power. The result was the W-58 warhead used in a "cluster" of three warheads for the Polaris A-3, the final model of the Polaris missile.

One of the initial problems the Navy faced in creating an SLBM was that the sea moves, while a launch platform on land does not. Waves and swells rocking the boat or submarine, as well as possible flexing of the ship's hull, had to be taken into account to properly aim the missile.

The Polaris development was kept on a tight schedule and the only influence that changed this was the USSR's launching of SPUTNIK on October 4, 1957. This caused many working on the project to want to accelerate development. The launch of a second Russian satellite and pressing public and government opinions caused Secretary Wilson to move the project along more quickly.

The Navy favored an underwater launch of an IRBM, although the project began with an above-water launch goal. They decided to continue the development of an underwater launch, and developed two ideas for this launch: wet and dry. Dry launch meant encasing the missile in a shell that would peel away when the missile reached the water's surface. Wet launch meant shooting the missile through the water without a casing. While they Navy was in favor of a wet launch, they developed both methods as a failsafe. They did this with the development of gas and air propulsion of the missile out of the submerged tube as well.

The first Polaris missile tests were given the names “AX-#” and later renamed “A1X-#”. Testing of the missiles occurred:

Sept 24, 1958: AX-1, at Cape Canaveral from a launch pad; the missile was destroyed, after it failed to turn into the correct trajectory following a programming-error.

October 1958: AX-2, at Cape Canaveral from a launch pad; exploded on the launch pad.

December 30, 1958: AX-3, at Cape Canaveral from a launch pad; launched correctly, but was destroyed because of the fuel overheating.

January 19, 1959: AX-4, at Cape Canaveral from launch pad: launched correctly but began to behave erratically and was destroyed.

February 27, 1959: AX-5, at Cape Canaveral from launch pad: launched correctly but began to behave erratically and was destroyed.

April 20, 1959: AX-6, at Cape Canaveral from launch pad: this test was a success. The missile launched, separated, and splashed into the Atlantic 300 miles off shore.

It was in between these two tests that the inertial guidance system was developed and implemented for testing.

July 1, 1959: AX-11 at Cape Canaveral from a launch pad: this launch was successful, but pieces of the missile detached causing failure. It did show that the new guidance systems worked.

At the time that the Polaris project went live, submarine navigation systems were and at this time that standard was sufficient enough to sustain effective military efforts given the existing weapons systems in use by the Army, Air Force and Navy. Initially, developers of Polaris were set to utilize the existing 'Stable Platform' configuration of the inertial guidance system. Created at the MIT Instrumentation Laboratory, this Ships Inertial Navigation System (SINS) was supplied to the Navy in 1954. The developers of Polaris encountered many issues from the birth of the project, however, perhaps the most unsettling for them was the outdated technology of the gyroscopes they would be implementing.
This 'Stable Platform' configuration did not account for the change in gravitational fields that the submarine would experience while it was in motion, nor did it account for the ever-altering position of the Earth. This problem raised many concerns, as this would make it nearly impossible for navigational read outs to remain accurate and reliable. A submarine equipped with Ballistic Missiles was of little to no use if operators had no way to direct them. Polaris was thus forced to seek elsewhere and quickly found hope in a guidance system that had been abandoned by the U.S. Air Force. The Autonetics Division of North American Aviation had previously been faced with the task of developing a guidance system for the U.S. Air Force Navaho known as the XN6 Autonavigator. The XN6 was a system designed for air-breathing Cruise missiles, but by 1958 had proved useful for installment on submarines.

A predecessor to the GPS satellite navigation system, the Transit system (later called NAVSAT), was developed because the submarines needed to know their position at launch in order for the missiles to hit their targets. Two American physicists, William Guier and George Weiffenbach, at Johns Hopkins's Applied Physics Laboratory (APL), began this work in 1958. A computer small enough to fit through a submarine hatch was developed in 1958, the AN/UYK-1. It was used to interpret the Transit satellite data and send guidance information to the Polaris, which had its own guidance computer made with ultra miniaturized electronics, very advanced for its time, because there wasn't much room in a Polaris—there were 16 on each submarine. The Ship's Inertial Navigation System (SINS) was developed earlier to provide a continuous dead reckoning update of the submarine's position between position fixes via other methods, such as LORAN. This was especially important in the first few years of Polaris, because Transit was not operational until 1964. By 1965 microchips similar to the Texas Instruments units made for the Minuteman II were being purchased by the Navy for the Polaris. The Minuteman guidance systems each required 2000 of these, so the Polaris guidance system may have used a similar number. To keep the price under control, the design was standardized and shared with Westinghouse Electric Company and RCA. In 1962, the price for each Minuteman chip was $50, the price dropped to $2 in 1968.

This missile replaced the earlier A-1 and A-2 models in the U.S. Navy, and also equipped the British Polaris force. The A-3 had a range extended to and a new weapon bay housing three Mk 2 re-entry vehicles (ReB or Re-Entry Body in U.S. Navy and British usage); and the new W-58 warhead of 200 kt yield. This arrangement was originally described as a "cluster warhead" but was replaced with the term Multiple Re-Entry Vehicle (MRV). The three warheads, also known as "bomblets", were spread out in a "shotgun" like pattern above a single target and were not independently targetable (such as a MIRV missile is). The three warheads were stated to be equivalent in destructive power to a single one-megaton warhead due to their spread out pattern on the target. The first Polaris submarine outfitted with MRV A-3's was the USS "Daniel Webster" in 1964. Later the Polaris A-3 missiles (but not the ReBs) were also given limited hardening to protect the missile electronics against nuclear electromagnetic pulse effects while in the boost phase. This was known as the A-3T ("Topsy") and was the final production model.

The initial test model of the Polaris was referred to as the AX series and made its maiden flight from Cape Canaveral on September 24, 1958. The missile failed to perform its pitch and roll maneuver and instead just flew straight up, however the flight was considered a partial success (at that time, "partial success" was used for any missile test that returned usable data). The next flight on October 15 failed spectacularly when the second stage ignited on the pad and took off by itself. Range Safety blew up the errant rocket while the first stage sat on the pad and burned. The third and fourth tests (December 30 and January 9) had problems due to overheating in the boattail section. This necessitated adding extra shielding and insulation to wiring and other components. When the final AX flight was conducted a year after the program began, 17 Polaris missiles had been flown of which five met all of their test objectives.

The first operational version, the Polaris A-1, had a range of and a single Mk 1 re-entry vehicle, carrying a single W-47-Y1 600 kt nuclear warhead, with an inertial guidance system which provided a circular error probable (CEP) of . The two-stage solid propellant missile had a length of , a body diameter of , and a launch weight of .

Work on its W47 nuclear warhead began in 1957 at the facility that is now called the Lawrence Livermore National Laboratory by a team headed by John Foster and Harold Brown. The Navy accepted delivery of the first 16 warheads in July 1960. On May 6, 1962, a Polaris A-2 missile with a live W47 warhead was tested in the "Frigate Bird" test of Operation Dominic by in the central Pacific Ocean, the only American test of a live strategic nuclear missile.

The two stages were both steered by thrust vectoring. Inertial navigation guided the missile to about a 900 m (3,000-foot) CEP, insufficient for use against hardened targets. They were mostly useful for attacking dispersed military surface targets (airfields or radar sites), clearing a pathway for heavy bombers, although in the general public perception Polaris was a strategic second-strike retaliatory weapon.

The Polaris A-1 missile was developed to complement the limited number of medium-range systems deployed throughout Europe. As those systems lacked the range to attack major Soviet targets, Polaris was developed to increase the level of nuclear deterrence. At this time there was little threat of counterforce strikes, as few systems had the accuracy to destroy missile systems. The primary advantages of ballistic missile submarines was their ability to launch submerged, which offered improved survivability for the submarine while also (like their Regulus predecessors) keeping shorter ranged systems within range.

The USN had forward-basing arrangements for its Atlantic-based Polaris fleet with both the United Kingdom and Spain, permitting the use of bases at the Holy Loch in Scotland (established in 1961) and at Naval Station Rota (Polaris base established 1964) in the Bay of Cadiz. The forward deployment bases were much closer to patrol areas than U.S. East Coast bases, avoiding the necessity for lengthy transit times. In the Pacific, a Polaris base was also established at Guam in 1964. The Regulus missile program was deactivated with the advent of Polaris in the Pacific. The forward-basing arrangement was continued when Poseidon replaced Polaris, starting in 1972, in what by then were the 31 Atlantic Fleet SSBNs. The 10 older SSBNs that could not use Poseidon were assigned to the Pacific Fleet in the 1970s. Polaris was not accurate enough to destroy hardened targets, but would have been effective against dispersed surface targets, such as airfields, radar and SAM sites, as well as military and industrial centers of strategic importance. The military authorities, however, regarded Polaris as but one part of a nuclear triad including ICBMs and bombers, each with its own function. The task allotted to Polaris of 'taking out' peripheral defenses was well-suited to its characteristics and limitations.

The forward deployment strategy required some infrastructure. To allow quick establishment of bases and to minimize the impact on the host country, each base was centered around a submarine tender and a floating drydock, with minimal facilities on shore, mostly family support for the tender's crew. The first Polaris submarine tender was , a World War II tender that was refitted in 1959–60 with the insertion of a midships missile storage compartment and handling crane. "Proteus" established each of the three forward deployment bases. Four additional Polaris tenders (, , , and ) were commissioned 1962–65.

A two-crew concept was established for SSBNs, combined with forward deployment to maximize the time each submarine would spend on patrol. The crews were named Blue and Gold after the U.S. Naval Academy colors. The crews were deployed for 105 days and at their home bases for 95 days, with a 3-day turnover period on each end of the deployed period. Crews were flown from their home bases to and from the forward deployment bases. After taking over the boat, the crew would perform a 30-day refit assisted by the tender, followed by a 70-day deterrent patrol. Sometimes a port visit would be arranged in the middle of the patrol. The home bases for Atlantic Fleet crews were Groton, Connecticut and Charleston, South Carolina. Pacific Fleet crews were based at Pearl Harbor, Hawaii.

Two Polaris missile depots were established in the United States, Polaris Missile Facility Atlantic (POMFLANT) at Charleston, South Carolina in 1960 and later Strategic Weapons Facility Pacific (SWFPAC) at Bangor, Washington. To transport missiles and other supplies from the missile depots to the forward deployment bases, several cargo ships were converted to carry missiles and were designated as T-AKs, operated by the Military Sealift Command with a mostly-civilian crew.

The advent of the Trident I missile, refitted to 12 Atlantic Fleet SSBNs starting in 1979 and with a much greater range than Polaris or Poseidon, meant that SSBNs could be based in the United States. The 18 s, slated to replace the 41 older SSBNs, also started commissioning in 1981, initially carrying 24 Trident I missiles but later refitted with the much larger and more capable Trident II missile. In the late 1970s it was decided that Pacific Fleet "Ohio"-class SSBNs would be based at Bangor, WA, collocated with SWFPAC, and that the refitted Trident I SSBNs and additional "Ohio"-class SSBNs would be based at a new facility in King's Bay, Georgia. Also, a new missile depot, Strategic Weapons Facility Atlantic (SWFLANT), was constructed at King's Bay to replace POMFLANT. The SSBN facility at Rota was closed in 1979 as King's Bay began refitting submarines. As commenced sea trials in 1980, the 10 remaining Polaris submarines in the Pacific Fleet were disarmed and reclassified as SSNs to avoid exceeding SALT II treaty limits. The SSBN base at Guam was closed at this time. By 1992, the Soviet Union had collapsed, 12 "Ohio"-class SSBNs had been commissioned, and the START I treaty had gone into effect, so Holy Loch was closed and the remaining 31 original SSBNs disarmed. Most of these were decommissioned and later scrapped in the Ship-Submarine Recycling Program, but a few were converted to other roles. Two remain in service but decommissioned as nuclear power training vessels attached to Naval Nuclear Power School at Charleston, SC, and .

To meet the need for greater accuracy over the longer ranges the Lockheed designers included a reentry vehicle concept, improved guidance, fire control, and navigation systems to achieve their goals. To obtain the major gains in performance of the Polaris A3 in comparison to early models, there were many improvements, including propellants and material used in the construction of the burn chambers. The later versions (the A-2, A-3, and B-3) were larger, weighed more, and had longer ranges than the A-1. The range increase was most important: The A-2 range was , the A-3 , and the B-3 . The A-3 featured multiple re-entry vehicles (MRVs) which spread the warheads about a common target, and the B-3 was to have penetration aids to counter Soviet Anti-Ballistic Missile defenses.

The U.S. Navy began to replace Polaris with Poseidon in 1972. The B-3 missile evolved into the C-3 Poseidon missile, which abandoned the decoy concept in favor of using the C3's greater throw-weight for larger numbers (10–14) of new hardened high-re-entry-speed reentry vehicles that could overwhelm Soviet defenses by sheer weight of numbers, and its high speed after re-entry. This turned out to be a less than reliable system and soon after both systems were replaced by the Trident. A proposed Undersea Long-Range Missile System (ULMS) program outlined a long-term plan which proposed the development of a longer-range missile designated as ULMS II, which was to achieve twice the range of the existing Poseidon (ULMS I) missile. In addition to a longer-range missile, a larger submarine (Ohio-class) was proposed to replace the submarines currently being used with Poseidon. The ULMS II missile system was designed to be retrofitted to the existing SSBNs, while also being fitted to the proposed Ohio-class submarine.

In May 1972, the term ULMS II was replaced with Trident. The Trident was to be a larger, higher-performance missile with a range capacity greater than 6000 miles. Under the agreement, the United Kingdom paid an additional 5% of their total procurement cost of 2.5 billion dollars to the U.S. government as a research and development contribution.
In 2002, the United States Navy announced plans to extend the life of the submarines and the D5 missiles to the year 2040. This requires a D5 Life Extension Program (D5LEP), which is currently underway. The main aim is to replace obsolete components at minimal cost by using commercial off the shelf (COTS) hardware; all the while maintaining the demonstrated performance of the existing Trident II missiles.

STARS, a strategic targeting system, is a BMDO program managed by the U. S. Army Space and Strategic Defense Command (SSDC). It began in 1985 in response to concerns that the supply of surplus Minuteman I boosters used to launch targets and other experiments on intercontinental ballistic missile flight trajectories in support of the Strategic Defense Initiative would be depleted by 1988. SSDC tasked Sandia National Laboratories, a Department of Energy laboratory, to develop an alternative launch vehicle using surplus Polaris boosters. The Sandia National Laboratories developed two STARS booster configurations: STARS I and STARS II.

STARS I consisted of refurbished Polaris first and second stages and a
commercially procured Orbis I third stage. It can deploy single or multiple payloads, but the multiple payloads cannot be deployed in a manner that simulates the operation of a post-boost vehicle. To meet this specific need, Sandia developed an Operations and Deployment
Experiments Simulator (ODES), which functions as a PBV. When ODES was added to STARS I, the configuration is became known as STARS II. The development phase of the STARS program was completed in 1994, and BMDO provided about $192.1 million for this effort. The operational phase began in 1995. The first STARS I flight, a hardware check-out flight, was launched in February 1993, and the second flight, a STARS I reentry vehicle experiment, was launched in August 1993.

The third flight, a STARS II development mission, was launched in July 1994, with all three flights considered to be successful by BMDO. The Secretary of Defense conducted a comprehensive review in 1993 of the nation's defense strategy, which drastically reduced the number of STARS launches required to support National Missile Defense (NMD)2 and BMDO funding. Due to the launch and budget reductions, the STARS office developed a draft long-range plan for the STARS program. The study examined three options:
When the STARS program was started in 1985 it was perceived that there would be four launches per year. Because of the large number of anticipated launches and an unknown defect rate for surplus Polaris motors, the STARS office acquired 117 first-stage and 102 second-stage surplus motors. As of December 1994, seven first-stage and five second-stage refurbished motors were available for future launches. BMDO is currently evaluating STARS as a potential long-range system for launching targets for development tests of future Theater Missile Defense 3 systems. STARS I was first launched in 1993, and from 2004 onwards has served as the standard booster for trials of the Ground-Based Interceptor.

From the early days of the Polaris program, American senators and naval officers suggested that the United Kingdom might use Polaris. In 1957 Chief of Naval Operations Arleigh Burke and First Sea Lord Louis Mountbatten began corresponding on the project. After the cancellations of the Blue Streak and Skybolt missiles in the 1960s, under the 1962 Nassau Agreement that emerged from meetings between Harold Macmillan and John F. Kennedy, the United States would supply Britain with Polaris missiles, launch tubes, ReBs, and the fire-control systems. Britain would make its own warheads and initially proposed to build five ballistic missile submarines, later reduced to four by the incoming Labour government of Harold Wilson, with 16 missiles to be carried on each boat. The Nassau Agreement also featured very specific wording. The intention of wording the agreement in this manner was to make it intentionally opaque. The sale of the Polaris was malleable in how an individual country could interpret it due to the diction choices taken in the Nassau Agreement. For the United States of America, the wording allowed for the sale to fall under the scope of NATO's deterrence powers. On the other hand, for the British, the sale could be viewed as a solely British deterrent. The Polaris Sales Agreement was signed on April 6, 1963.

In return, the British agreed to assign control over their Polaris missile targeting to the SACEUR (Supreme Allied Commander, Europe), with the provision that in a national emergency when unsupported by the NATO allies, the targeting, permission to fire, and firing of those Polaris missiles would reside with the British national authorities. Nevertheless, the consent of the British Prime Minister is and has been always required for the use of British nuclear weapons, including SLBMs.

The operational control of the Polaris submarines was assigned to another NATO Supreme Commander, the SACLANT (Supreme Allied Commander, Atlantic), who is based near Norfolk, Virginia, although the SACLANT routinely delegated control of the missiles to his deputy commander in the Eastern Atlantic area, COMEASTLANT, who was always a British admiral.

Polaris was the largest project in the Royal Navy's peacetime history. Although in 1964 the new Labour government considered cancelling Polaris and turning the submarines into conventionally armed hunter-killers, it continued the program as Polaris gave Britain a global nuclear capacity—perhaps east of Suez—at a cost £150 million less than that of the V bomber force. By adopting many established, American, methodologies and components Polaris was finished on time and within budget. On 15 February 1968, , the lead ship of her class, became the first British vessel to fire a Polaris. All Royal Navy SSBNs have been based at Faslane, only a few miles from Holy Loch. Although one submarine of the four was always in a shipyard undergoing a refit, recent declassifications of archived files disclose that the Royal Navy deployed four boatloads of reentry vehicles and warheads, plus spare warheads for the Polaris A3T, retaining a limited ability to re-arm and put to sea the submarine that was in refit. When replaced by the Chevaline warhead, the sum total of deployed RVs and warheads was reduced to three boatloads.

The original U.S. Navy Polaris had not been designed to penetrate anti-ballistic missile (ABM) defenses, but the Royal Navy had to ensure that its small Polaris force operating alone, and often with only one submarine on deterrent patrol, could penetrate the ABM screen around Moscow. Britain's submarines featured the Polaris A3T missiles, a modification to the model of the Polaris used by the U.S. from 1968 to 1972. Similar concerns were present in the U.S. as well, resulting in a new American defense program.

The program became known as Antelope, and its purpose was to alter the Polaris. Various aspects of the Polaris, such as increasing deployment efficiency and creating ways to improve the penetrative power were specific items considered in the tests conducted during the Antelope program. The British's uncertainty with their missiles led to the examination of the Antelope program. The assessments of Antelope occurred at Aldermaston. Evidence from the evaluation of Antelope led to the British decision to undertake their program following that of the United States.

The result was a programme called "Chevaline" that added multiple decoys, chaff, and other defensive countermeasures. Its existence was only revealed in 1980, partly because of the cost overruns of the project, which had almost quadrupled the original estimate given when the project was finally approved in January 1975. The program also ran into trouble when dealing with the British Labour Party. Their Chief Scientific Adviser, Solly Zuckerman, believed that Britain no longer needed new designs for nuclear weapons and no more nuclear warhead tests would be necessary. Though the Labour party provided a clear platform on nuclear weapons, the Chevaline program found supporters. One such individual who supported modification to the Polaris was the Secretary of state for Defense, Denis Healey.

Despite the approval of the program, the expenses caused hurdles that augmented the time it took for the system to come to fruition. The cost of the project led to Britain's revisit of disbanding the program in 1977. The system became operational in mid-1982 on , and the last British SSBN submarine was equipped with it in mid-1987. Chevaline was withdrawn from service in 1996.

Though Britain adopted the Antelope program methods, no input on the design came from the United States. Aldermaston was solely responsible for the Chevaline warheads.

The British did not ask to extend the Polaris Sales Agreement to cover the Polaris successor Poseidon due to its cost. The Ministry of Defence upgraded its nuclear missiles to the longer-ranged Trident after much political wrangling within the Callaghan Labour Party government over its cost and whether it was necessary. The outgoing Prime Minister James Callaghan made his government's papers on Trident available to Margaret Thatcher's new incoming Conservative Party government, which took the decision to acquire the Trident C4 missile.

A subsequent decision to upgrade the missile purchase to the even larger, longer-ranged Trident D5 missile was possibly taken to ensure that there was missile commonality between the U.S. Navy and the Royal Navy, which was considerably important when the Royal Navy Trident submarines were also to use the Naval Submarine Base Kings Bay.

Even though the U.S. Navy initially deployed the Trident C4 missile in the original set of its "Ohio"-class submarines, it was always planned to upgrade all of these submarines to the larger and longer-ranged Trident D5 missile—and that eventually, all of the C4 missiles would be eliminated from the U.S. Navy. This change-over has been completely carried out, and no Trident C4 missiles remain in service.

The Polaris missile remained in Royal Navy service long after it had been completely retired and scrapped by the U.S. Navy in 1980–1981. Consequently, many spare parts and repair facilities for the Polaris that were located in the U.S. ceased to be available (such as at Lockheed, which had moved on first to the Poseidon and then to the Trident missile).

During its reconstruction program in 1957–1961, the was fitted with four Polaris missile launchers located in the aft part of the ship. The Italian usage of Polaris missiles was partially the result of the Kennedy administration. Prior to 1961, the Italian and Turkish fleets were outfitted with Jupiter missiles. Three factors were instrumental in the movement away from the Jupiter project in Italy and Turkey: the president's view of the project, new understanding about weapons systems and the diminished necessity of the Jupiter missile. The Joint Congressional Committee report on Atomic Energy accentuated the three previous factors in Italy's decision to switch to the Polaris missiles.Successful tests held in 1961–1962 induced the United States to study a NATO Multilateral Nuclear Force (MLF), consisting of 25 international surface vessels from the US, United Kingdom, France, Italy, and West Germany, equipped with 200 Polaris nuclear missiles, enabling European allies to participate in the management of the NATO nuclear deterrent.

The report advocated a change from the outdated Jupiter missiles, already housed by the Italians, to the newer missile, Polaris. The report resulted in Secretary of State Dean Rusk and Assistant Secretary of Defense Paul Nitze discussing the possibility of changing the warheads in the Mediterranean. The Italians were not swayed by the American's interest in modernizing their warheads. However, after the Cuban Missile Crisis, Kennedy met the Italian leader Amitore Fanfani in Washington. Fanfani conceded and went along with Kennedy's Polaris plan, despite the Italians hoping to stick with the Jupiter missile.

The MLF plan, as well as the Italian Polaris Program, were abandoned, both for political reasons (in consequence of the Cuban Missile Crisis) and the initial operational availability of the first SSBN , which was capable of launching SLBMs while submerged, a solution preferable to surface-launched missiles.

Italy developed a new domestic version of the missile, the SLBM-designated Alfa. That program was cancelled in 1975 after Italy ratified the Nuclear Non-Proliferation Treaty, with the final launch of the third prototype in 1976.

Two Italian Navy cruisers, commissioned in 1963–1964, were "fitted for but not with" two Polaris missile launchers per ship. All four launchers were built but never installed, and were stored at the La Spezia naval facility.

The , launched in 1969, was also "fitted for but not with" four Polaris missile launchers. During refit periods in 1980–1983, these facilities were removed and used for other weapons and systems.


Notes
Bibliography




</doc>
<doc id="24788" url="https://en.wikipedia.org/wiki?curid=24788" title="UGM-73 Poseidon">
UGM-73 Poseidon

The UGM-73 Poseidon missile was the second US Navy nuclear-armed submarine-launched ballistic missile (SLBM) system, powered by a two-stage solid-fuel rocket. It succeeded the UGM-27 Polaris beginning in 1972, bringing major advances in warheads and accuracy. It was followed by Trident I in 1979, and Trident II in 1990.

A development study for a longer range version of the Polaris missile—achieved by enlarging it to the maximum possible size allowed by existing launch tubes—started in 1963. Tests had already shown that Polaris missiles could be operated without problems in launch tubes that had their fiberglass liners and locating rings removed.

The project was given the title Polaris B3 in November, but the missile was eventually named Poseidon C3 to emphasize the technical advances over its predecessor. The C3 was the only version of the missile produced, and it was also given the designation UGM-73A.

Slightly longer and considerably wider and heavier than Polaris A3, Poseidon had the same range, greater payload capacity, improved accuracy, and multiple independently targetable reentry vehicle (MIRV) capability. MIRV capacity has been given as up to either ten or fourteen W68 thermonuclear warheads contained in Mark 3 reentry vehicles to multiple targets.

As with Polaris, starting a rocket motor when the missile was still in the submarine was considered very dangerous. Therefore, the missile was ejected from its launch tube using high pressure steam produced by a solid-fueled boiler. The main rocket motor ignited automatically when the missile had risen approximately above the submarine.

The first test launch took place on 16 August 1968, the first successful at-sea launch was from a surface ship, the (from July 1 to December 16, 1969), earning the ship the Meritorious Unit Commendation, and the first test launch from a submarine took place on the on 3 August 1970. The weapon officially entered service on 31 March 1971. It eventually equipped 31 -, -, and -class submarines.

The Royal Navy also considered adopting Poseidon in the 1970s as an upgrade to its Polaris A3T boats, and like the US this would have kept the existing hulls. Although the Navy's favoured option, the British government instead adopted Chevaline, a two warhead MRV system with decoys, on the existing Polaris airframes and later moved to the Trident D5 in new boats.

Beginning in 1979, 12 Poseidon-equipped SSBNs were refitted with Trident I. By 1992, the Soviet Union had collapsed, 12 Ohio-class submarines had been commissioned, and the START I treaty had gone into effect, so the 31 older Poseidon- and Trident I-armed SSBNs were disarmed, withdrawing Poseidon from service.




</doc>
<doc id="24789" url="https://en.wikipedia.org/wiki?curid=24789" title="Portuguese">
Portuguese

Portuguese may refer to:



</doc>
<doc id="24793" url="https://en.wikipedia.org/wiki?curid=24793" title="POTS">
POTS

Pots most commonly refers to pottery, the ceramic ware made by potters

POTS or Pots may also refer to:



</doc>
<doc id="24795" url="https://en.wikipedia.org/wiki?curid=24795" title="Private (rank)">
Private (rank)

A private is a soldier of the lowest military rank (equivalent to NATO Rank Grades OR-1 to OR-3 depending on the force served in).

In modern military writing, "private" is abridged to "Pte" in the United Kingdom and other Commonwealth of Nations countries and to "Pvt" in the United States.

The term derives from the medieval term "private soldiers" (a term still used in the British Army), denoting individuals who were either hired, conscripted, or mustered into service by a feudal nobleman commanding a battle group of an army. The usage of "private" dates from the 18th century.

In the Israel Defense Forces, טוראי "Turai" ("private") refers to the lowest enlisted rank. After 7–10 months of service (7 for combatants, 8 for combat support and 10 for non-combatants) soldiers are promoted from private to corporal ("rav-turai" or "rabat"), if they performed their duties appropriately during this time. Soldiers who take a commander's course, are prisoner instructors or practical engineers become corporals earlier. An IDF private wears no uniform insignia and is sometimes described as having a "slick sleeve" for this reason.

The equivalent ranks to privates within the North and South Korean armies are "ilbyeong" (private first class) and "ibyeong" (private second class). The symbol for this rank is 1 line ( | ) or 2 lines ( || ). Private second class is known by 1 line, while private first class is 2 lines.

Once recruits complete their Basic Military Training (BMT) or Basic Rescue Training (BRT), they attain the rank of private (PTE). Privates do not wear ranks on their rank holder. PTEs who performed well are promoted to the rank of Lance Corporal (LCP). The PFC rank is rarely awarded nowadays by SAF. All private enlistees can be promoted directly to lance corporal should they meet the minimum qualifying requirements, conduct appraisal and work performance. Recruits who did not complete BMT but completed 2 years of National Service will be promoted to private.

In Indonesia, this rank is referred to as (specifically "Prajurit"), which is the lowest rank in the Indonesian National Armed Forces and special Police Force. In the Indonesian Army, Indonesian Marine Corps, and Indonesian Air Force, "Private" has three levels, which are: Private ("Prajurit Dua"), Private First Class ("Prajurit Satu"), and Master Private ("Prajurit Kepala"). After this rank, it is promoted the rank: Corporal.

In the Australian Army, a soldier of private rank wears no insignia. Like its British Army counterpart, the Australian Army rank of private (PTE) has other titles, depending on the corps and specification of that service member.

The following alternative ranks are available for privates in the Australian Army:


In the Bangladesh Army the lowest enlisted rank is "sainik" (সৈনিক), literally meaning "soldier".

In the Canadian Armed Forces, "private" is the lowest rank for members who wear the uniform of the Army. There are three levels of private: private (recruit), private (basic), and private (trained). All persons holding the rank of private are referred to as such and the qualifier shown in brackets is used on employment records only. The air force rank of aviator was formerly private, but this changed when traditional air force rank insignia were restored. The French-language equivalent of private is .

Canadian Army privates may be known by other titles, depending on their military trade and their unit’s tradition:

In the Indian Army and Pakistan Army the lowest enlisted rank is sepoy (/ˈsiːpɔɪ/), literally meaning "soldier" derived from Persian. A sepoy does not wear any rank insignia on his uniform.

In the South African Army the lowest enlisted rank is Private. Privates don't wear insignia on their uniforms. In the different corps it is known with different titles.

In the British Army, a private (Pte) equates to both OR-1 and OR-2 on the NATO scale, although there is no difference in rank. Privates wear no insignia. Many regiments and corps use other distinctive and descriptive names instead of private, some of these ranks have been used for centuries, others are less than 100 years old. In the contemporary British Armed Forces, the army rank of private is broadly equivalent to able seaman in the Royal Navy, aircraftman, leading aircraftman and senior aircraftman in the Royal Air Force, and marine (Mne) or bandsman, as appropriate equivalent rank in the Royal Marines. In the Boys' Brigade the rank of private is used when a boy moves from the junior section to the company section.

Distinctive equivalents for private include:

In the Corps of Royal Marines the rank structure follows that of British infantry regiments, the only real exception being that the Royal Marines equivalent of private is Marine (Mne).

The lowest rank in the Austrian Armed Forces is the "Rekrut" (literally "Recruit"). For recruits in training to become non-commissioned or commissioned officers the rank bears an additional silver crossbar.

Up until 1998 the rank was called "Wehrmann". In 2017 the silver crossbar was removed, as the system of the 'officers career' changed.

The equivalent rank to private in the Spanish, Mexican, Colombian, Dominican and Argentinian army is the "soldado raso" meaning "rankless soldier" or simply "soldado".

On enlistment in the Belgian army one is given the rank of (Dutch) or (French), whether one wishes to be a volunteer, non-commissioned officer or officer. Subsequent rank depends on the branch of the service: for example, at the Royal Military Academy (for officer training) one is soon promoted to the rank of (Dutch) or (French) i.e. "corporal". The insignia is a simple black mark or the simplified version of the Royal Military Academy's coat of arms for candidate officers.

"Soldado" is the rank equivalent to private in the Brazilian and Portuguese Armed Forces. "Soldado" means "soldier" in Portuguese.

The Finnish equivalent rank is "sotamies" (literally "war man"), although since 1973 this has been purely a paper term as all infantry troopers were renamed as "jääkäri" troops, previously reserved only to mobile light infantry. As in the British army, the various branches use different names:


In the Finnish Air Force, the basic rank is "lentosotamies" ("flight war man"). In the Finnish Navy, the basic rank is "matruusi" ("seaman") or "tykkimies" ("cannon man") in the marine infantry.

Special corps troopers may be referred by their function or unit, such as "kaartinjääkäri" (Guards jaeger), "panssarijääkäri" (panzer jaeger), "laskuvarjojääkäri" (paratroop jaeger), "rajajääkäri" (border jaeger) or "rannikkojääkäri" (coastal jaeger).

In the French army "soldat de seconde classe" is the lowest military rank. This rank is also referred to as "recrue" ("recruit").

The German "Bundeswehr" modern-day equivalent of the private rank (NATO-standard code OR-2) is Gefreiter.

The equivalent of the lowest rank (NATO-standard code OR-1) is either "Schütze" (rifleman), "Kanonier" (gunner) or "Jäger" (light-infantryman otherwise ranger), and sometimes in general simply "Soldat" (soldier), as well as other unit-specific distinctions. Up until 1918 it was "Gemeine" (Ordinary [soldier]) as well as unit-specific distinctions such as "Musketier" (musketeer), "Infanterist" (infantryman), "Kürassier" (cuirassier), "Jäger" (light-infantryman otherwise ranger), "Füsilier" (fusilier) etc., until 1945 "Soldat" (soldier) and unit-specific distinctions such as "Schütze" (rifleman), "Grenadier" (grenadier) etc. The navy equivalent of the OR-1 rank is known as "Matrose" (sailor or seaman), and the German Air Force equivalent is "Flieger" (aviator or airman) which is also used by army aviators.

The name of the lowest rank in the Hungarian army ("Magyar Honvédség") is the "honvéd" which means "homeland defender". The word is also used informally for a soldier in general of any rank (i.e. "our "honvéds"" or an officer referred as a "honvédtiszt", "honvéd" officer). This is because Hungarian military traditions are strictly defensive, despite the Hungarian army participating in offensives on foreign soil in both world wars. The word "honvéd" has been in use since the Hungarian Revolution of 1848. The term is not used for soldiers of foreign armies: a foreign soldier with no rank is called "közlegény", literally "common lad" or "common man".

Private (Pte) ("saighdiúr singil" in Irish), is the lowest enlisted rank in the Irish Army. Soldiers enlist as recruits then undergo a basic course of instruction. There are three grades of private in the army. After basic training the soldier is upgraded (rather than promoted) from recruit to private 2 star (Pte 2*) ("saighdiúr singil, 2 réalta"). After more corps-specific training (usually lasting eight weeks) the soldier is upgraded to private 3 star (Pte 3*) ("saighdiúr singil, 3 réalta"). All are usually just addressed as "private", although before being upgraded, recruits may be addressed as "recruit".

In corps units, the rank designation changes. In the artillery, the rank is known as gunner (Gnr), but usually only after the completion of a gunners' course, and in the cavalry it is known as trooper (Tpr). Communications and Information Services privates are known as signalman or signalwoman. Medical orderlies are sometimes referred to as medic, although this can apply to privates and corporals.

In the Italian Army is the lowest military rank. This rank is also referred to as (meaning recruit).

In the Royal Netherlands Army, the "Landmacht", the equivalent ranks are "soldaat" (soldier), similar to the original French, with different classes:


Depending on where the "soldaat" serves, he may be deemed a "kanonnier" (gunner in the artillery), "huzaar" (hussar in the cavalry) or "fuselier" (rifleman in the rifles) as well as "commando", "jager" or "rijder". There is less differentiation than in other countries between different armed forces. A "soldaat" can be promoted to "korporaal" (corporal).

In the Swedish Armed Forces a recruit is given the rank of in the army and in the navy.

After basic training which is roughly 3 months other terms can be used such as ’’soldat’’ (soldier), ’’jägare’’, etc.

In the Swiss Armed Forces a recruit is given the rank of when he finishes basic training, mostly after 13 weeks.

In the Turkish Land Forces, Turkish Air Force and Turkish Naval Forces; "Er" (Private) is the lowest rank possible. This rank does not have any insignia.

In the United States Army, private is used for the two lowest enlisted ranks, just below private first class (E-3) or PFC. The lowest rank is "Private (E-1)" or PV1, and sometimes referred to as recruit, but also held by some soldiers after punishment through the Uniform Code of Military Justice or prisoners after conviction until they are discharged. A PV1 wears no uniform rank insignia; since the advent of the Army Combat Uniform (ACU), the term "fuzzy" has come into vogue, referring to the blank velcro patch on the ACU where the rank would normally be placed. The second rank, "Private (E-2)" or PV2, wears a single chevron, known colloquially as "mosquito wings". Advancement to PV2 is automatic after six months' time in service, but may get shortened to four months if given a waiver. A person who earned the Eagle Scout award, the Gold Award, or completed at least two years of JROTC may enlist at any time at the rank of PV2. The term of address, "Private," may be properly applied to any Army soldier E-1 (PV1) to E-3 (PFC). The abbreviation "PVT" may be used whenever the specific grade of private is immaterial (such as in Tables of Organization and Equipment).

In the United States Marine Corps, "private" (Pvt) refers only to the lowest enlisted rank, just below private first class. A Marine Corps private wears no uniform insignia and is sometimes described as having a "slick sleeve" for this reason. Most new, non-officer Marines begin their military career as a private. In the Marine Corps, privates first class are not referred to as "private"; it is more appropriate to use either "private first class" or "PFC".

The rank is used by the National Bolivarian Armed Forces of Venezuela and has no insignia.



</doc>
<doc id="24797" url="https://en.wikipedia.org/wiki?curid=24797" title="Proclus">
Proclus

Proclus Lycaeus (; 8 February 412 – 17 April 485 AD), called the Successor (Greek , "Próklos ho Diádokhos"), was a Greek Neoplatonist philosopher, one of the last major classical philosophers (see Damascius). He set forth one of the most elaborate and fully developed systems of Neoplatonism. He stands near the end of the classical development of philosophy and influenced Western medieval philosophy (Greek and Latin).

Proclus was born on February 8, 412 AD (his birth date is deduced from a horoscope cast by a disciple, Marinus) in Constantinople to a family of high social status in Lycia (his father Patricius was a high legal official, very important in the Eastern Roman Empire's court system) and raised in Xanthus. He studied rhetoric, philosophy and mathematics in Alexandria, with the intent of pursuing a judicial position like his father. Before completing his studies, he returned to Constantinople when his rector, his principal instructor (one Leonas), had business there.

Proclus became a successful practicing lawyer. However, the experience of the practice of law made Proclus realize that he truly preferred philosophy. He returned to Alexandria, and began determinedly studying the works of Aristotle under Olympiodorus the Elder. He also began studying mathematics during this period as well with a teacher named Heron (no relation to Hero of Alexandria, who was also known as Heron). As a gifted student, he eventually became dissatisfied with the level of philosophical instruction available in Alexandria, and went to Athens, the pre-eminent philosophical center of the day, in 431 to study at the Neoplatonic successor of the famous Academy founded 800 years earlier (in 387 BC) by Plato; there he was taught by Plutarch of Athens (not to be confused with Plutarch of Chaeronea), Syrianus, and Asclepigenia; he succeeded Syrianus as head of the Academy, and would in turn be succeeded on his death by Marinus of Neapolis.

He lived in Athens as a vegetarian bachelor, prosperous and generous to his friends, until the end of his life, except for a voluntary one-year exile, which was designed to lessen the pressure put on him by his political-philosophical activity, little appreciated by the Christian rulers; he spent the exile traveling and being initiated into various mystery cults. He was also instructed in the "theurgic" Neoplatonism, as derived from the Orphic and Chaldean Oracles. His house has been discovered recently in Athens, under the pavement of Dionysiou Areopagitou Street, south of Acropolis, opposite the theater of Dionysus. He had a great devotion to the goddess Athena, who he believed guided him at key moments in his life. Marinus reports that when Christians removed the statue of the goddess from the Parthenon, a beautiful woman appeared to Proclus in a dream and announced that the "Athenian Lady" wished to stay at his home. Proclus died aged 73, and was buried near Mount Lycabettus in a tomb. It is reported that he was writing 700 lines each day.

The majority of Proclus's works are commentaries on dialogues of Plato ("Alcibiades", "Cratylus", "Parmenides", "Republic", "Timaeus"). In these commentaries he presents his own philosophical system as a faithful interpretation of Plato, and in this he did not differ from other Neoplatonists, as he considered that "nothing in Plato’s corpus is unintended or there by chance", that "that Plato’s writings were divinely inspired" (ὁ θεῖος Πλάτων "ho theios Platon"—the divine Plato, inspired by the gods), that "the formal structure and the content of Platonic texts imitated those of the universe", and therefore that they spoke often of things under a veil, hiding the truth from the philosophically uninitiate. Proclus was however a close reader of Plato, and quite often makes very astute points about his Platonic sources. A number of his Platonic commentaries are lost.

Proclus, the scholiast to Euclid, knew Eudemus of Rhodes' "History of Geometry" well, and gave a short sketch of the early history of geometry, which appeared to be founded on the older, lost book of Eudemus. The passage has been referred to as "the Eudemian summary," and determines some approximate dates, which otherwise might have remained unknown. The influential commentary on the first book of Euclid's "Elements of Geometry" is one of the most valuable sources we have for the history of ancient mathematics, and its Platonic account of the status of mathematical objects was influential. In this work, Proclus also listed the first mathematicians associated with Plato: a mature set of mathematicians (Leodamas of Thasos, Archytas of Taras, and Theaetetus), a second set of younger mathematicians (Neoclides, Eudoxus of Cnidus), and a third yet younger set (Amyntas, Menaechmus and his brother Dinostratus, Theudius of Magnesia, Hermotimus of Colophon and Philip of Opus). Some of these mathematicians were influential in arranging the Elements that Euclid later published.

In addition to his commentaries, Proclus wrote two major systematic works. The "Elements of Theology" (Στοιχείωσις θεολογική) consists of 211 propositions, each followed by a proof, beginning from the existence of the One (divine Unity) and ending with the descent of individual souls into the material world. The "Platonic Theology" (Περὶ τῆς κατὰ Πλάτωνα θεολογίας) is a systematisation of material from Platonic dialogues, showing from them the characteristics of the divine orders, the part of the universe which is closest to the One.

We also have three essays, extant only in Latin translation: "Ten doubts concerning providence" ("De decem dubitationibus circa providentiam"); "On providence and fate" ("De providentia et fato"); "On the existence of evils" ("De malorum subsistentia").

He also wrote a number of minor works, which are listed in the bibliography below.

Proclus's system, like that of the other Neoplatonists, is a combination of Platonic, Aristotelian, and Stoic elements. In its broad outlines, Proclus's system agrees with that of Plotinus. However, following Iamblichus, Plutarch of Athens, and his master Syrianus, Proclus presents a much more elaborate universe than Plotinus, subdividing the elements of Plotinus's system into their logically distinct parts, and positing these parts as individual things. This multiplication of entities is balanced by the monism which is common to all Neoplatonists. What this means is that, on the one hand the universe is composed of hierarchically distinct things, but on the other all things are part of a single continuous emanation of power from the One. From this latter perspective, the many distinctions to be found in the universe are a result of the divided perspective of the human soul, which needs to make distinctions in its own thought in order to understand unified realities. The idealist tendency is taken further in John Scotus Eriugena.

There is a double motivation found in Neoplatonic systems. The first is a need to account for the origin and character of all things in the universe. The second is a need to account for how we can know this origin and character of things. These two aims are related: they begin from the assumption that we can know reality, and then ask the question of what reality must be like, in its origin and unfolding, so that we can know it. An important element in the Neoplatonic answer to these questions is its reaction to Scepticism. In response to the sceptical position that we only know the appearances presented by our senses, and not the world as it is, Plotinus placed the object of knowledge inside the soul itself, and accounted for this interior truth through the soul's kinship with its own productive principles.

The first principle in Neoplatonism is the One (Greek: "to Hen"). Being proceeds from the One. The One cannot itself be a being. If it were a being, it would have a particular nature, and so could not be universally productive. Because it is "beyond being" ("epekeina tes ousias", a phrase from Plato's "Republic" 509b), it is also beyond thought, because thinking requires the determinations which belong to being: the division between subject and object, and the distinction of one thing from another. For this reason, even the name "The One" is not a positive name, but rather the most non-multiple name possible, a name derived from our own inadequate conception of the simplicity of the first principle. The One causes all things by conferring unity, in the form of individuality, on them, and in Neoplatonism existence, unity, and form tend to become equivalent. The One causes things to exist by donating unity, and the particular manner in which a thing is one is its form (a dog and a house are individual in different manners, for example). Because the One makes things exist by giving them the individuality which makes them what they are as distinct and separate beings, the Neoplatonists thought of it also as the source of the good of everything. So the other name for the One is the Good. Despite appearances, the first principle is not double; all things have a double relation to it, as coming from them (One) and then being oriented back towards them to receive their perfection or completion (Good).

The particular characteristic of Proclus's system is his elaboration of a level of individual ones, called "henads," between the One which is before being and intelligible divinity. The henads exist "superabundantly", also beyond being, but they stand at the head of chains of causation ("seirai") and in some manner give to these chains their particular character. He identifies them with the Greek gods, so one henad might be Apollo and be the cause of all things apollonian, while another might be Helios and be the cause of all "sunny" things. Each henad participates in every other henad, according to its character. What appears to be multiplicity is not multiplicity at all, because any henad may rightly be considered the center of the polycentric system.

The principle which is produced below the level of the One and the Henads is the divine Intellect ("Nous"). The One cannot have a determinate nature if it is to be the source of all determinate natures, so what it produces is the totality of all determinate natures, or Being. By determination is meant existence within boundaries, a being "this" and not "that". The most important determinate natures are the "Greatest Kinds" from Plato's "Sophist" (Being, Same, Other, Rest, Motion) and Aristotle's ten categories (Quantity, Quality, etc.). In other words, the One produces what Plato called the Forms, and the Forms are understood to be the first determinations into which all things fall. The One produces the Forms through the activity of thinking. The One itself does not think, but instead produces a divine mind, Intellect, whose thoughts are themselves the Forms. Intellect is both Thinking and Being. It is a mind which has its own contents as its object. All things relate to the first principle as both One and Good. As Being, Intellect is the product of the One. But it also seeks to return to its cause, and so in Thinking it attempts to grasp the One as its Good. But because the simplicity of the One/Good does not allow Intellect to grasp it, what Intellect does is generate a succession of perspectives around its simple source. Each of these perspectives is itself a Form, and is how Intellect generates for itself its own content.

Plotinus speaks about the generation of Intellect from the One, and Intellect's attempt to return to the One in a thinking which is also a desiring. Proclus systematises this production through a threefold movement of remaining, procession, and return ("mone, proodos, epistrophe"). Intellect remains in the One, which means that it has the One as its origin. It proceeds from the One, which means that it comes to be as a separate entity. But it returns to the One, which means that it does not cut itself off from its source, but receives the good which is its identity from the One. This threefold motion is used by Proclus to structure all levels of his system below the One and above material reality, so that all things except those mentioned remain, proceed, and return.

Proclus also gives a much more elaborate account of Intellect than does Plotinus. In Plotinus we find the distinction between Being and Thinking in Intellect. Proclus, in keeping with his triadic structure of remaining, procession, and return, distinguishes three moments in Intellect: Intelligible, Intelligible-Intellectual, and Intellectual. They correspond to the object of thought, the power of the object to be grasped by the subject, and the thinking subject. These three divisions are elaborated further, so that the intelligible moment consists of three triads (Being, Eternity, and the Living Being or Paradigm from Plato's "Timaeus"). The intelligible-intellectual moment also consists of three triads, and the intellectual moment is a hebdomad (seven elements), among which is numbered the Demiurge from Plato's "Timaeus" and also the monad of Time (which is before temporal things). In this elaboration of Intellect as a whole, Proclus is attempting to give a hierarchical ordering to the various metaphysical elements and principles that other philosophers have discussed, by containing them within a single triadic logic of unfolding.

Proclus's universe unfolds according to the smallest steps possible, from unity to multiplicity. With Intellect emerges the multiplicity which allows one being to be different from another being. But as a divine mind, Intellect has a complete grasp of all its moments in one act of thought. For this reason, Intellect is outside of Time.

Intellect as the second principle also gives rise to individual intellects, which hold various places within Proclus's cosmos.

In terms of his sources, Intellect is like taking the Platonic Forms and placing them in the self-thinking thought which is Aristotle's Unmoved Mover.

Soul ("Psyche") is produced by Intellect, and so is the third principle in the Neoplatonic system. It is a mind, like Intellect, but it does not grasp all of its own content as one. Therefore with Soul, Time comes to be, as a measure of Soul's movement from one object of thought to another. Intellect tries to grasp the One, and ends up producing its own ideas as its content. Soul attempts to grasp Intellect in its return, and ends up producing its own secondary unfoldings of the Forms in Intellect. Soul, in turn, produces Body, the material world.

In his commentary on Plato's "Timaeus" Proclus explains the role the Soul as a principle has in mediating the Forms in Intellect to the body of the material world as a whole. The Soul is constructed through certain proportions, described mathematically in the "Timaeus", which allow it to make Body as a divided image of its own arithmetical and geometrical ideas.

Individual souls have the same overall structure as the principle of Soul, but they are weaker. They have a tendency to be fascinated with the material world, and be overpowered by it. It is at this point that individual souls are united with a material body (i.e. when they are born). Once in the body, our passions have a tendency to overwhelm our reason. According to Proclus, philosophy is the activity which can liberate the soul from a subjection to bodily passions, remind it of its origin in Soul, Intellect, and the One, and prepare it not only to ascend to the higher levels while still in this life, but to avoid falling immediately back into a new body after death.

Because the soul's attention, while inhabiting a body, is turned so far away from its origin in the intelligible world, Proclus thinks that we need to make use of bodily reminders of our spiritual origin. In this he agrees with the doctrines of theurgy put forward by Iamblichus. Theurgy is possible because the powers of the gods (the "henads") extend through their series of causation even down to the material world. And by certain power-laden words, acts, and objects, the soul can be drawn back up the series, so to speak. Proclus himself was a devotee of many of the religions in Athens, considering that the power of the gods could be present in these various approaches.

For Proclus, philosophy is important because it is one of the primary ways to rescue the soul from a fascination with the body and restore it to its station. However, beyond its own station, the soul has Intellect as its goal, and ultimately has unification with the One as its goal. So higher than philosophy is the non-discursive reason of Intellect, and the pre-intellectual unity of the One. Philosophy is therefore a means of its own overcoming, in that it points the soul beyond itself.

Proclus can be considered as the spokesman of mature Neoplatonism. His works had a great influence on the history of western philosophy. The extent of this influence, however, is obscured by the channels through which it was exercised. An important source of Procline ideas was through the Pseudo-Dionysius. This late-5th- or early-6th-century Christian Greek author wrote under the pseudonym Dionysius the Areopagite, the figure converted by St. Paul in Athens. Because of this fiction, his writings were taken to have almost apostolic authority. He is an original Christian writer, and in his works can be found a great number of Proclus's metaphysical principles.

Another important source for the influence of Proclus on the Middle Ages is Boethius's "Consolation of Philosophy", which has a number of Proclus principles and motifs. The central poem of Book III is a summary of Proclus's "Commentary on the Timaeus", and Book V contains the important principle of Proclus that things are known not according to their own nature, but according to the character of the knowing subject.

A summary of Proclus's "Elements of Theology" circulated under the name "Liber de Causis" (the "Book of Causes"). This book is of uncertain origin, but circulated in the Arabic world as a work of Aristotle, and was translated into Latin as such. It had great authority because of its supposed Aristotelian origin, and it was only when Proclus's "Elements" were translated into Latin that Thomas Aquinas realised its true origin.

Proclus's works also exercised an influence during the Renaissance through figures such as Georgius Gemistus Pletho and Marsilio Ficino. Before the contemporary period, the most significant scholar of Proclus in the English-speaking world was Thomas Taylor, who produced English translations of most of his works, with commentaries.

His work inspired the New England Transcendentalists, including Ralph Waldo Emerson, who declared in 1843 that, in reading Proclus, "I am filled with hilarity & spring, my heart dances, my sight is quickened, I behold shining relations between all beings, and am impelled to write and almost to sing."

Modern scholarship on Proclus essentially begins with E. R. Dodds edition of the "Elements of Theology" in 1933. Since then he has attracted considerable attention, especially in the French-speaking world. Procline scholarship, however, still (2006) falls far short of the attention paid to Plotinus.

The following epigram is engraved on the tomb which houses Proclus and his master Syrianus:

The crater Proclus on the Moon is named after him.


A number of other minor works or fragments of works survive. A number of major commentaries have been lost.

The "Liber de Causis" (Book of Causes) is not a work by Proclus, but a summary of his work the "Elements of Theology", likely written by an Arabic interpreter. It was mistakenly thought in the Middle Ages to be a work of Aristotle, but was recognised by Aquinas not to be so.

A list of modern editions and translations of his surviving works is available at:

Monographs

Collections of essays

Bibliographic resources




</doc>
<doc id="24799" url="https://en.wikipedia.org/wiki?curid=24799" title="Production team">
Production team

A production team is the group of technical staff who produce a play, television show, recording, or film. Generally the term refers to all individuals responsible for the technical aspects of creating of a particular product, regardless of where in the process their expertize is required, or how long they are involved in the project. For example, in a theatrical performance, the production team includes not only the running crew, but also the theatrical producer, designers and theatre direction.

A production company in filmmaking is composed of a film crew and a television crew in video production.

In music, the term "production team" typically refers to a group of individuals filling the role of "record producer" usually reserved for one individual. Some examples of musical production teams include Matmos and D-Influence.



</doc>
<doc id="24801" url="https://en.wikipedia.org/wiki?curid=24801" title="Pinconning cheese">
Pinconning cheese

Pinconning cheese is an aged semi-hard whole cow's milk, Colby style cheese named after Pinconning, Michigan, where it was first developed and produced by Dan Horn in 1915. Since then and currently, Pinconning Cheese is made and distributed based on the original family traditional recipe by the originator's related companies, Pinconning Cheese Company and Wilson's (Horn) Cheese Shoppe in Pinconning, Michigan. It is available in mild and then aged many years to sharpness levels of medium mild, medium sharp, sharp, extra sharp, and super sharp (7 plus years old). Its hardness and texture change and sharpness increase with aging. Pinconning's flavor and texture are rich, creamy and open. It is unusual and a different experience than eating traditional Colby Cheese. It is often used as a replacement for Cheddar and Colby cheeses in dishes such as macaroni and soufflés." Pinconning was chosen as the ‘Cheese Capital of Michigan’ after the Pinconning brand of cheese where it was originated and still sold today.


</doc>
<doc id="24805" url="https://en.wikipedia.org/wiki?curid=24805" title="Prophet">
Prophet

In religion, a prophet is an individual who is regarded as being in contact with a divine being and is said to speak on that entity's behalf, serving as an intermediary with humanity by delivering messages or teachings from the supernatural source to other people. The message that the prophet conveys is called a prophecy.

Claims of prophethood have existed in many cultures throughout history, including Judaism, Christianity, Islam, in ancient Greek religion, Zoroastrianism, Manichaeism, and many others.

The English word "prophet" is a compound Greek word, from "pro" (in advance) and the verb "phesein" (to tell); thus, a προφήτης ("profétés") is someone who foretells future events, and also conveys messages from the divine to humans; in a different interpretation, it means advocate or speaker.

In Hebrew, the word נָבִיא ("nāvî"), "spokesperson", traditionally translates as "prophet". The second subdivision of the Tanakh, (Nevi'im), is devoted to the Hebrew prophets. The meaning of "navi" is perhaps described in Deuteronomy 18:18, where God said, "...and I will put My words in his mouth, and he shall speak unto them all that I shall command him." Thus, the "navi" was thought to be the "mouth" of God. The root nun-bet-alef ("navi") is based on the two-letter root nun-bet which denotes hollowness or openness; to receive transcendental wisdom, one must make oneself "open".

In addition to writing and speaking messages from God, Israelite or Judean nevi'im ("spokespersons", "prophets") often acted out prophetic parables in their life. For example, in order to contrast the people's disobedience with the obedience of the Rechabites, God has Jeremiah invite the Rechabites to drink wine, in disobedience to their ancestor's command. The Rechabites refuse, for which God commends them. Other prophetic parables acted out by Jeremiah include burying a linen belt so that it gets ruined to illustrate how God intends to ruin Judah's pride. Likewise, Jeremiah buys a clay jar and smashes it in the Valley of Ben Hinnom in front of elders and priests to illustrate that God will smash the nation of Judah and the city of Judah beyond repair. God instructs Jeremiah to make a yoke from wood and leather straps and to put it on his own neck to demonstrate how God will put the nation under the yoke of Nebuchadnezzar, king of Babylon. In a similar way, the prophet Isaiah had to walk stripped and barefoot for three years to illustrate the coming captivity, and the prophet Ezekiel had to lie on his side for 390 days and eat measured food to illustrate the coming siege.

The prophetic assignment is not always portrayed as positive in the Hebrew Bible, and prophets were often the target of persecution and opposition. God's personal prediction for Jeremiah, "Attack you they will, overcome you they can't," was performed many times in the biblical narrative as Jeremiah warned of destruction of those who continued to refuse repentance and accept more moderate consequences. In return for his adherence to God's discipline and speaking God's words, Jeremiah was attacked by his own brothers, beaten and put into the stocks by a priest and false prophet, imprisoned by the king, threatened with death, thrown into a cistern by Judah's officials, and opposed by a false prophet. Likewise, Isaiah was told by his hearers who rejected his message, "Leave the way! Get off the path! Let us hear no more about the Holy One of Israel!" The life of Moses being threatened by Pharaoh is another example.

According to I Samuel 9:9, the old name for navi is "ro'eh", רֹאֶה, which literally means "Seer". That could document an ancient shift, from viewing prophets as seers for hire to viewing them as moral teachers. Allen (1971) comments that in the First Temple Era, there were essentially seer-priests, who formed a guild, divined, performed rituals and sacrifices, and were scribes, and then there were canonical prophets, who did none of these (and were against divination) and had instead a message to deliver. The seer-priests were usually attached to a local shrine or temple, such as Shiloh, and initiated others as priests in that priesthood: it was a mystical craft-guild with apprentices and recruitment. Canonical prophets were not organised this way.

Some examples of prophets in the Tanakh include Abraham, Moses, Miriam, Isaiah, Samuel, Ezekiel, Malachi, and Job. In Jewish tradition Daniel is not counted in the list of prophets.

A Jewish tradition suggests that there were twice as many prophets as the number which left Egypt, which would make 1,200,000 prophets. The Talmud recognizes the existence of 48 male prophets who bequeathed permanent messages to mankind. According to the Talmud there were also seven women who are counted as prophetesses whose message bears relevance for all generations: Sarah, Miriam, Devorah, Hannah (mother of the prophet Samuel), Abigail (a wife of King David), Huldah (from the time of Jeremiah), and Esther. The Talmudic and Biblical commentator Rashi points out that Rebecca, Rachel, and Leah were also prophets.
Isaiah 8:3-4 refers he married "the prophetess", which conceived and gave to him a son, named by God Mahèr-salàl-cash-baz. Her name isn't elsewhere specified.

Prophets in Tanakh are not always Jews. The story of Balaam in Numbers 22 describes a non-Jewish prophet. According to the Talmud, Obadiah is said to have been a convert to Judaism.

The last nevi'im ("spokespersons", "prophets") mentioned in the Jewish Bible are Haggai, Zechariah, and Malachi, all of whom lived at the end of the 70-year Babylonian exile. The Talmud (Sanhedrin 11a) states that Haggai, Zachariah, and Malachi were the last prophets, and nowadays only the "Bath Kol" (בת קול, lit. "daughter of a voice", "voice of God") exists.

In Christianity, a prophet (or seer) is one inspired by God through the Holy Spirit to deliver a message. Some Christian denominations limit a prophet's message to words intended only for the entire church congregation, excluding personal messages not intended for the body of believers; but in the Bible on a number of occasions prophets were called to deliver personal messages. The reception of a message is termed revelation and the delivery of the message is termed prophecy.

The term "prophet" applies to those who receive public or private revelation. Public revelation, in Catholicism, is part of the Deposit of faith, the revelation of which was completed by Jesus; whereas private revelation does not add to the Deposit. The term "deposit of faith" refers to the entirety of Jesus Christ's revelation, and is passed to successive generations in two different forms, sacred scripture (the Bible) and sacred tradition.

The Bible terms anyone who claims to speak God's words or to teach in his name without being a prophet a false prophet. One Old Testament text in Deuteronomy contains a warning against those who prophesy events which do not come to pass and says they should be put to death. Elsewhere a false prophet may be someone who is purposely trying to deceive, is delusional, under the influence of Satan or is speaking from his own spirit.

Some Christians believe that the Holy Spirit gives spiritual gifts to Christians. These may include prophecy, tongues, miraculous healing ability, and discernment (Matthew 12:32 KJV "Whosoever speaketh a word against the Son of Man, it shall be forgiven him: but whosoever speaketh against the Holy Ghost, it shall not be forgiven him, neither in this world, neither in the world to come."). Cessationists believe that these gifts were given only in New Testament times and that they ceased after the last apostle died.

New Testament passages that explicitly discuss prophets existing after the death and resurrection of Christ include Revelation 11:10, Matthew 10:40–41 and 23:34, John 13:20 and 15:20 and Acts 11:25–30, 13:1 and 15:32.

The "Didache" gives extensive instruction in how to distinguish between true and false prophets, as well as commands regarding tithes to prophets in the church. Irenaeus, wrote of 2nd-century believers with the gift of prophecy, while Justin Martyr argued in his "Dialogue with Trypho" that prophets were not found among the Jews in his time, but that the church had prophets. "The Shepherd of Hermas" describes revelation in a vision regarding the proper operation of prophecy in the church. Eusebius mentions that Quadratus and Ammia of Philadelphia were both prominent prophets following the age of the Twelve Apostles. Tertullian, writing of the church meetings of the Montanists (to whom he belonged), described in detail the practice of prophecy in the 2nd-century church.

A number of later Christian saints were claimed to have powers of prophecy, such as Columba of Iona (521-597), Saint Malachy (1094-1148) or Padre Pio (1887-1968). Marian apparitions like those at Fatima in 1917 or at Kibeho in Rwanda in the 1980s often included prophetic predictions regarding the future of the world as well as of the local areas they occurred in.

Prophetic movements in particular can be traced throughout the Christian Church's history, expressing themselves in (for example) Montanism, Novatianism, Donatism, Franciscanism, Anabaptism, Camisard enthusiasm, Puritanism, Quakerism, Quietism, Lutheranism and Pietism. Modern Pentecostals and Charismatics, members of movements which together comprised approximately 584 million people , believe in the contemporary function of the gift of prophecy, and some in these movements allow for idea that God may continue to gift the church with some individuals who are prophets.

Some Christian sects recognize the existence of a "modern-day" prophets. One such denomination is The Church of Jesus Christ of Latter-day Saints, which teaches that God still communicates with mankind through prophecy.

The Quran identifies a number of men as "Prophets of Islam" ( "nabī"; pl. "anbiyāʾ"). Muslims believe such individuals were assigned a special mission by God to guide humanity. Besides Muhammad, this includes prophets such as Abraham ("Ibrāhīm"), Moses ("Mūsā") and Jesus ("ʿĪsā").
Although only twenty-five prophets are mentioned by name in the Quran, a hadith (no. 21257 in "Musnad Ahmad ibn Hanbal") mentions that there were (more or less) 124,000 prophets in total throughout history. Other traditions place the number of prophets at 224,000. Some scholars hold that there are an even greater number in the history of mankind, and only God knows. The Quran says that God has sent a prophet to every group of people throughout time, and that Muhammad is the last of the prophets, sent for the whole of humankind. The message of all the prophets is believed to be the same. In Islam, all prophetic messengers are prophets (such as Adam, Noah, Abraham, Moses, Jesus, and Muhammad) though not all prophets are prophetic messengers. The primary distinction is that a prophet is required to demonstrate God's law through his actions, character, and behavior without necessarily calling people to follow him, while a prophetic messenger is required to pronounce God's law (i.e. revelation) and call his people to submit and follow him. Muhammad is distinguished from the rest of the prophetic messengers and prophets in that he was commissioned by God to be the prophetic messenger to all of mankind. Many of these prophets are also found in the texts of Judaism (The Torah, the Prophets, and the Writings) and Christianity.

Muslims often refer to Muhammad as "the Prophet", in the form of a noun. Jesus is the result of a virgin birth in Islam as in Christianity, and is regarded as a prophet.

Traditionally, four prophets are believed to have been sent holy books: the Torah ("Tawrat") to Moses, the Psalms ("Zābūr") to David, the Gospel to Jesus, and the Quran to Muhammad; those prophets are considered "Messengers" or "rasūl". Other main prophets are considered messengers or "nabī", even if they didn't receive a Book from God. Examples include the messenger-prophet Aaron| ("Hārūn"), the messenger-prophet Ishmael ("Ismāʿīl")) and the messenger-prophet Joseph ("Yūsuf").

Although it offers many incidents from the lives of many prophets, the Quran focuses with special narrative and rhetorical emphasis on the careers of the first four of these five major prophets. Of all the figures before Muhammad, the significance of Jesus in Islam is reflected in his being mentioned in the Quran in 93 verses with various titles attached such as "Son of Mary" and other relational terms, mentioned directly and indirectly, over 187 times. He is thus the most mentioned person in the Quran by reference; 25 times by the name Isa, third-person 48 times, first-person 35 times, and the rest as titles and attributes. Moses("Musa") and Abraham("ibrahim") are also referred to frequently in the Quran. As for the fifth, the Quran is frequently addressed directly to Muhammad, and it often discusses situations encountered by him. Direct use of his name in the text, however, is rare. Rarer still is the mention of Muhammad's contemporaries.

The Bahá'í Faith refers to what are commonly called prophets as "Manifestations of God" who are directly linked with the concept of Progressive revelation. Bahá'ís believe that God expresses this will at all times and in many ways, including through a series of divine messengers referred to as "Manifestations of God" or "divine educators". In expressing God's intent, these Manifestations are seen to establish religion in the world. Thus they are seen as an intermediary between God and humanity.

The Manifestations of God are not seen as incarnations of God, and are also not seen as ordinary mortals. Instead, the Bahá'í concept of the Manifestation of God emphasizes simultaneously the humanity of that intermediary and the divinity in the way they show forth the will, knowledge and attributes of God; thus they have both human and divine stations.

In addition to the Manifestations of God, there are also minor prophets. While the Manifestations of God, or major prophets, are compared to the Sun (which produces its own heat and light), minor prophets are compared to the Moon (which receives its light from the sun). Moses, for example, is taught as having been a Manifestation of God and his brother Aaron a minor prophet. Moses spoke on behalf of God, and Aaron spoke on behalf of Moses (Exodus 4:14–17). Other Jewish prophets are considered minor prophets, as they are considered to have come in the shadow of the dispensation of Moses to develop and consolidate the process he set in motion.

In modern times the term "prophet" can be somewhat controversial. Many Christians with Pentecostal or charismatic beliefs believe in the continuation of the gift of prophecy and the continuation of the role of prophet as taught in Ephesians 4. The content of prophecies can vary widely. Prophecies are often spoken as quotes from God. They may contain quotes from scripture, statements about the past or current situation, or predictions of the future. Prophecies can also 'make manifest the secrets' of the hearts of other people, telling about the details of their lives. Sometimes, more than one person in a congregation will receive the same message in prophecy, with one giving it before another.

Other movements claim to have prophets. In France, Michel Potay says he received a revelation, called "The Revelation of Arès", dictated by Jesus in 1974, then by God in 1977. He is considered a prophet by his followers, the Pilgrims of Arès.

A number of modern catholic saints have been claimed to have powers of prophecy, such as Padre Pio and Alexandrina Maria da Costa.

In addition to this many modern Marian apparitions included prophecies in them about the world and about the local areas. The Fátima apparition in 1917 included a prophecy given by Mary to three children, that on October 13, 1917 there would be a great miracle for all to see at Fátima, Portugal, and on that day tens of thousands of people headed to Fátima to see what would happen including newspaper journalists. Many witnesses, including journalists, claimed to see the sun "dance" in the sky in the afternoon of that day, exactly as the visionaries had predicted several months before. The Kibeho apparition in Rwanda in the 1980s included many prophecies about great violence and destruction that was coming, and the Rwandan genocide only ten years later was interpreted by the visionaries as the fulfilment of these prophecies 

Several miracles and a vision of the identity of the last 112 Popes were attributed to Saint Malachy, the Archbishop of Armagh (1095–1148).

Jehovah's Witnesses do not consider any single person in their modern-day organization to be a prophet. Their literature has referred to their organization collectively as God's "prophet" on earth; this is understood, however, in the sense of declaring their interpretation of God's judgments from the Bible along with God's guidance of His Holy Spirit. Their publishing company, Watch Tower, and official position magazine, "The Watchtower", have asserted: "Ever since "The Watchtower" began to be published in July 1879 it has looked ahead into the future... No, "The Watchtower" is no inspired prophet, but it follows and explains a Book of prophecy the predictions in which have proved to be unerring and unfailing till now. "The Watchtower" is therefore under safe guidance. It may be read with confidence, for its statements may be checked against that prophetic Book." They also claim that they are God's one and only true channel to mankind on earth, and used by God for this purpose.

They have made many eschatological forecasts, some of which have led people (including followers) to incorrect assumptions. One example is "The Watchtower's" assertions that the end of the "Gentile times" or "times of the nations" would occur in 1914; even prominent Watch Tower representatives such as A. H. Macmillan incorrectly concluded and overstated their expectations. As a result, "The Watchtower" has acknowledged that Jehovah's Witnesses "have made mistakes in their understanding of what would occur at the end of certain time periods." Concurrently with these exceptions, Jehovah's Witnesses in their literature and assemblies have taught their leadership was personally chosen by Jesus Christ in 1919 (a prophetic year in Jehovah's Witnesses eschatology) and that they are "God's sole channel on earth," and "Jehovah's spirit directed organization".

Joseph Smith, who established the Church of Christ in 1830, is considered a prophet by members of the Latter Day Saint movement, of which The Church of Jesus Christ of Latter-day Saints (LDS Church) is the largest denomination. Additionally, many churches within the movement believe in a succession of modern prophets (accepted by Latter Day Saints as "prophets, seers, and revelators") since the time of Joseph Smith. Russell M. Nelson is the current Prophet and President of The Church of Jesus Christ of Latter-day Saints.

Baptist preacher William Miller is credited with beginning the mid-19th century North American religious movement now known as Adventism. He announced a Second Coming, resulting in the Great Disappointment.

The Seventh-day Adventist Church, established in 1863, believes Ellen G. White, one of the church's founders, was given the spiritual gift of prophecy.

The Branch Davidians sect evolved from the Seventh-Day Adventists Church. David Koresh, who died in the well-known Waco Siege in 1993, in 1983 claimed to be their final prophet and "the Son of God, the Lamb".


The Ahmadiyya movement in Islam believes that Mirza Ghulam Ahmad was a non law-bearing Prophet, who claimed to be a fulfillment of the various Islamic prophecies regarding the spiritual second advent of Jesus of Nazareth near the end times.

Nathan of Gaza was a theologian and author who became famous as a prophet for the alleged messiah, Sabbatai Zevi.

Divination remains an important aspect of the lives of the people of contemporary Africa, especially amongst the usually rural, socially traditionalistic segments of its population. In arguably its most influential manifestation, the system of prophecy practiced by the Babalawos and Iyanifas of the historically Yoruba regions of West Africa have bequeathed to the world a corpus of fortune-telling poetic methodologies so intricate that they have been added by UNESCO to its official "intangible cultural heritage of the World list".

Tenrikyo's prophet, Nakayama Miki, is believed by Tenrikyoans to have been a messenger of God.


The Great Peacemaker (sometimes referred to as "Deganawida" or "Dekanawida") co-founded the Haudenosaunee league in pre-Columbian times. In retrospect, his prophecy of the boy seer could appear to refer to the conflict between natives and Europeans (white serpent).

From 1805 until the Battle of Tippecanoe that falsified his predictions in 1811, the "Shawnee prophet" Tenskwatawa lead an Indian alliance to stop Europeans to take more and more land going west. He reported visions he had. He is said to have accurately predicted a solar eclipse. His brother Tecumseh re-established the alliance for Tecumseh's War, that ended with the latter's death in 1813. Tecumseh fought together with British forces that, in the area of the Great Lakes, occupied essentially today's territory of Canada.

Francis the Prophet, influenced by Tecumseh and Tenskwatawa, was a leader of the Red Stick faction of the Creek Indians. He traveled to England in 1815 as a representative of the "four Indian nations" in an unsuccessful attempt to get Great Britain to help them resist the expansionism of the white settlers.

20 years later (1832), Wabokieshiek, the "Winnebago Prophet", after whom Prophetstown has been named, (also called "White Cloud") claimed that British forces would support the Indians in the Black Hawk War against the United States as 20 years earlier (based on "visions"). They did not, and no longer he was considered a "prophet".

In 1869, the Paiute Wodziwob founded the Ghost Dance movement. The dance rituals were an occasion to announce his visions of an earthquake that would swallow the whites. He seems to have died in 1872.

The Northern Paiute Wovoka claimed he had a vision during the solar eclipse of January 1, 1889, that the Paiute dead would come back and the whites would vanish from America, provided the natives performed Ghost Dances. This idea spread among other Native American peoples. The government were worried about a rebellion and sent troops, which lead to the death of Sitting Bull and to the Wounded Knee massacre in 1890.

Clifford Trafzer compiled an anthology of essays on the topic, American Indian Prophets. 

In the late 20th century the appellation of "prophet" has been used to refer to individuals particularly successful at analysis in the field of economics, such as in the derogatory "prophet of greed". Alternatively, social commentators who suggest escalating crisis are often called "prophets of doom."





</doc>
<doc id="24807" url="https://en.wikipedia.org/wiki?curid=24807" title="Pleading">
Pleading

In law as practiced in countries that follow the English models, a pleading is a formal written statement of a party's claims or defenses to another party's claims in a civil action. The parties' pleadings in a case define the issues to be adjudicated in the action.

The Civil Procedure Rules (CPR) govern pleading in England and Wales. Federal Rules of Civil Procedure govern pleading in United States federal courts. Each state in the United States has its own statutes and rules that govern pleading in the courts of that state.

In the United States, a "complaint" is the first pleading filed by a plaintiff which initiates a lawsuit. A complaint sets forth the relevant allegations of fact that give rise to one or more legal causes of action along with a prayer for relief and sometimes a statement of damages claimed (an ad quod damnum clause). In some situations, a complaint is called a "petition", in which case the party filing it is called the petitioner and the other party is the respondent. In equity, sometimes called chancery, the initial pleading may be called either a "petition" or a "bill of complaint in chancery".

In England and Wales, the first pleading is a Claim Form, issued under either Part 7 or Part 8 of the Civil Procedure Rules, which sets out the nature of the action and the relief sought, and may give brief particulars of the claim. The Claimant also has the option, under Practice Direction 7A.61 to serve Particulars of Claim (a document setting out the allegations which found the cause of action) within 14 days of issue of the Claim Form.

When used in civil proceedings in England and Wales, the term "complaint" refers to the mechanism by which civil proceedings are instituted in the magistrates' court and may be either written or oral.

A "demurrer" is a pleading (usually filed by a defendant) which objects to the legal sufficiency of the opponent's pleading (usually a complaint) and demands that the court rule immediately about whether the pleading is legally adequate before the party must plead on the merits in response. Since demurrer procedure required an immediate ruling like a motion, many common law jurisdictions therefore went to a narrower understanding of pleadings as framing the issues in a case but not being motions in and of themselves, and replaced the demurrer with the motion to dismiss for failure to state a cause of action or the application to strike out particulars of claim.

An "answer" is a pleading filed by a defendant which admits or denies the specific allegations set forth in a complaint and constitutes a general appearance by a defendant. In England and Wales, the equivalent pleading is called a Defence.

A defendant may also file a cross-complaint against another defendant named by the plaintiff, and may also file a "third-party complaint" bring other parties into a case by the process of impleader.

A defendant may file a "counter-claim" to raise a cause of action to defend, reduce or set off the claim of the plaintiff.

Common law pleading was the system of civil procedure used in England, which early on developed a strong emphasis on the form of action rather than the cause of action (as a result of the Provisions of Oxford, which severely limited the evolution of the common law writ system). The emphasis was on procedure over substance.

Law and equity evolved as separate judicial systems, each with its own procedures and remedies. Because the types of claims eligible for consideration was capped early during the development of the English legal system, claims that might have been acceptable to the courts' evolving sense of justice often did not match up perfectly with any of the established forms of action. Lawyers had to engage in great ingenuity to shoehorn their clients' claims into existing forms of action. The result was that at common law, pleadings were stuffed full of awkward legal fictions that had little to do with the actual "real-world" facts of the case. The placeholder name John Doe (still commonly used in American pleading to name unknown parties) is a remnant of this period.

In its final form in the 19th century, common law pleading was terribly complex and slow by modern standards. The parties would normally go through several rounds of pleadings before the parties were deemed to have clearly stated their controversy, so that the case was "at issue" and could proceed to trial. A case would begin with a complaint in which the plaintiff alleged the facts entitling him to relief, then the defendant would file any one of a variety of pleas as an answer, followed by a replication from the plaintiff, a rejoinder from the defendant, a surrejoinder from the plaintiff, a rebutter from the defendant, and a surrebutter from the plaintiff. At each stage, a party could file a demurrer to the other's pleading (essentially a request that the court immediately rule on whether the pleading was legally adequate before they had to file a pleading in response) or simply file another pleading in response.

Generally, a plea could be dilatory or peremptory. There were three kinds of dilatory plea: to the jurisdiction, in suspension, or in abatement. The first challenged the court's jurisdiction, the second asked the court to stay the action, and the third asked the court to dismiss the action without prejudice to the other side's right to bring the claims in another action or another court. A peremptory plea had only one kind: a plea in bar. A party making a plea in bar could either traverse the other side's pleading (i.e., deny all or some of the facts pleaded) or confess and avoid it (i.e., admit the facts pleaded but plead new ones that would dispel their effect). A traverse could be general (deny everything) or specific. Either side could plead imparlance in order to get more time to plead on the merits. Once the case was at issue, the defendant could reopen the pleadings in order to plead a newly discovered defense (and start the whole sequence again) by filing a plea puis darrein.

The result of all this complexity was that to ascertain what was "at issue" in a case, a stranger to the case (i.e., such as a newly appointed judge) would have to sift through a huge pile of pleadings to figure out what had happened to the original averments of the complaint and whether there was anything left to be actually adjudicated by the court.

Code pleading was first introduced in 1850 in New York and in 1872 in California, and eventually spread to 22 other states. Code pleading sought to abolish the distinction between law and equity. It unified civil procedure for all types of actions as much as possible. The focus shifted from pleading the right form of action (that is, the right procedure) to pleading the right cause of action (that is, a substantive right to be enforced by the law). Under code pleading, the required elements of each action are supposed to be set out in carefully codified statutes.

Code pleading stripped out most of the legal fictions that had encrusted common law pleading by requiring parties to plead "ultimate facts." This means that to plead a cause of action, the pleader has to plead each element and also allege specific facts which, if proven with evidence at trial, would constitute proof of that element. Failure to provide such detail could lead to dismissal of the case if the defendant successfully demurred to the complaint on the basis that it merely stated "legal conclusions" or "evidentiary facts."

Code pleading also drastically shortened the pleading process. Most of the old common law pleadings were abolished. From now on, a case required only a complaint and an answer, with an optional cross-complaint and cross-answer, and with the demurrer kept as the standard attack on improper pleadings. Instead of piling layers and layers of pleadings and averments on top of each other, a pleading that was attacked by demurrer would either be completely superseded by an amended pleading or would proceed immediately "at issue" as to the validly pleaded parts. This meant that to determine what the parties were currently fighting about, a stranger to a case would no longer have to read the entire case file from scratch, but could (in theory) look "only" at the most recent version of the complaint filed by the plaintiff, the defendant's most recent answer to that complaint, and any court orders on demurrers to either pleading.

Code pleading was criticized because many lawyers felt that it was too difficult to fully research all the facts needed to bring a complaint "before" one had even initiated the action, and thus meritorious plaintiffs could not bring their complaints in time before the statute of limitations expired. Code pleading has also been criticized as promoting "hypertechnical reading of legal papers".

Notice pleading is the dominant form of pleading used in the United States today. In 1938, the Federal Rules of Civil Procedure were adopted to govern civil procedure in United States federal courts. One goal of the Federal Rules of Civil Procedure was to relax the strict rules of code pleading. However, each state also has its own rules of civil procedure, which may require different, looser, or stricter rules in state court.

Louisiana, a state that derives its legal tradition from the Spanish and French (as opposed to English common law), employs a system of fact pleading wherein it is only necessary to plead the facts that give rise to a cause of action. It is not necessary even for the petitioner to identify the cause of action being pleaded. Mere conclusory allegations such as "the defendant was negligent" are not, by themselves, sufficient to sustain a cause of action.

Other states, including Connecticut and New Jersey, are also fact-pleading jurisdictions. Illinois, for example, requires that a complaint "must assert a legally recognized cause of action and it must plead facts which bring the particular case within that cause of action."

In alternative pleading, legal fiction is employed to permit a party to argue two mutually exclusive possibilities, for example, submitting an injury complaint alleging that the harm to the plaintiff caused by the defendant was so outrageous that it must have either been intended as a malicious attack or, if not, must have been due to gross negligence.

The use of "pleaded" versus "pled" as the past tense version of "pleading" has been a subject of controversy among many of those that practice law. "Pled" is almost never used in Australian publications, while being somewhat common in American, British, and Canadian publications. In a 2010 search of the Westlaw legal database, "pled" is used in a narrow majority of cases over "pleaded". The AP stylebook and Chicago Manual of Style call for "pleaded", and a Westlaw search shows the US supreme court has used pleaded in over 3,000 opinions and pled in only 26.




</doc>
<doc id="24808" url="https://en.wikipedia.org/wiki?curid=24808" title="Personal Communications Service">
Personal Communications Service

At the most basic level, Personal Communications Service (PCS) describes a set of communications capabilities which allows some combination of terminal mobility, personal mobility, and service profile management. More specifically, PCS refers to any of several types of wireless voice or wireless data communications systems, typically incorporating digital technology, providing services similar to advanced cellular mobile or paging services. In addition, PCS can also be used to provide other wireless communications services, including services which allow people to place and receive communications while away from their home or office, as well as wireless communications to homes, office buildings and other fixed locations. Described in more commercial terms, PCS is a generation of wireless-phone technology that combines a range of features and services surpassing those available in analog- and digital-cellular phone systems, providing a user with an all-in-one wireless phone, paging, messaging, and data service.

The International Telecommunication Union describes Personal Communications Services as a component of the IMT-2000 (3G) standard. PCS and the IMT-2000 standard of which PCS is a part do not specify a particular air interface and channel access method. Wireless service providers may deploy equipment using any of several air interface and channel access methods, as long as the network meets the service description characteristics described in the standard.

In Canada, Mexico and the United States, PCS are provided in the "1900 MHz band" (specifically 1850–1990 MHz). This frequency band was designated by the United States FCC and Industry Canada to be used for new wireless services to alleviate capacity caps inherent in the original AMPS and D-AMPS cellular networks in the "850 MHz band" (specifically 800–894 MHz). These frequency bands are particular to North America and other frequency bands may be designated in other regions.

In the United States, Sprint PCS was the first company to build and operate a PCS network, launching service in November 1995 under the "Sprint Spectrum" brand in the Baltimore-Washington metropolitan area. Sprint originally built out the network using GSM radio interface equipment. Sprint PCS later selected CDMA as the radio interface for its nationwide network and built out a parallel CDMA network in the Baltimore-Washington area, launching service in 1997. Sprint operated the two networks in parallel until finishing a migration of its area customers to the CDMA network. After completing the customer migration, Sprint PCS sold the GSM radio interface network equipment to Omnipoint Communications in January 2000. Omnipoint was later purchased by VoiceStream Wireless which subsequently became T-Mobile USA.




</doc>
<doc id="24809" url="https://en.wikipedia.org/wiki?curid=24809" title="PCS">
PCS

PCS may refer to:







</doc>
<doc id="24811" url="https://en.wikipedia.org/wiki?curid=24811" title="Puck">
Puck

Puck may refer to:







</doc>
<doc id="24815" url="https://en.wikipedia.org/wiki?curid=24815" title="Polaris Sales Agreement">
Polaris Sales Agreement

The Polaris Sales Agreement was a treaty between the United States and the United Kingdom which began the UK Polaris programme. The agreement was signed on 6 April 1963. It formally arranged the terms and conditions under which the Polaris missile system was provided to the United Kingdom.

The United Kingdom had been planning to buy the air-launched Skybolt missile to extend the operational life of the British V bombers, but the United States decided to cancel the Skybolt program in 1962 as it no longer needed the missile. The crisis created by the cancellation prompted an emergency meeting between the President of the United States, John F. Kennedy, and the Prime Minister of the United Kingdom, Harold Macmillan, which resulted in the Nassau Agreement, under which the United States agreed to provide Polaris missiles to the United Kingdom instead.

The Polaris Sales Agreement provided for the implementation of the Nassau Agreement. The United States would supply the United Kingdom with Polaris missiles, launch tubes, and the fire control system. The United Kingdom would manufacture the warheads and submarines. In return, the US was given certain assurances by the United Kingdom regarding the use of the missile, but not a veto on the use of British nuclear weapons. The British Polaris ballistic missile submarines were built on time and under budget, and came to be seen as a credible deterrent that enhanced Britain's international status.

Along with the 1958 US–UK Mutual Defence Agreement, the Polaris Sales Agreement became a pillar of the nuclear Special Relationship between Britain and the United States. The agreement was amended in 1982 to provide for the sale of the Trident missile system.

During the early part of the Second World War, Britain had a nuclear weapons project, codenamed Tube Alloys. In August 1943, the Prime Minister of the United Kingdom, Winston Churchill and the President of the United States, Franklin Roosevelt, signed the Quebec Agreement, which merged Tube Alloys with the American Manhattan Project. The British government trusted that the United States would continue to share nuclear technology, which it regarded as a joint discovery, but the 1946 McMahon Act ended cooperation. Fearing a resurgence of United States isolationism, and Britain losing its great power status, the British government restarted its own development effort, now codenamed High Explosive Research. The first British atomic bomb was tested in Operation Hurricane on 3 October 1952. The subsequent British development of the hydrogen bomb, and a favourable international relations climate created by the Sputnik crisis, led to the McMahon Act being amended in 1958, and the restoration of the nuclear Special Relationship in the form of the 1958 US–UK Mutual Defence Agreement (MDA), which allowed Britain to acquire nuclear weapons systems from the United States.

Britain's nuclear weapons armament was initially based on free-fall bombs delivered by the V bombers of the Royal Air Force (RAF), but the possibility of the manned bomber becoming obsolete by the late 1960s due to improvements in anti-aircraft defences was foreseen. In 1953, work began on a medium-range ballistic missile (MRBM) called Blue Streak, but by 1958, there were concerns about its vulnerability to a pre-emptive nuclear strike. To extend the effectiveness and operational life of the V bombers, an air-launched, rocket-propelled standoff missile called Blue Steel was developed, but it was anticipated that the air defences of the Soviet Union would improve to the extent that V bombers might still find it difficult to attack their targets. A solution appeared to be the American Skybolt missile, which combined the range of Blue Streak with the mobile basing of the Blue Steel, and was small enough that two could be carried on an Avro Vulcan bomber.

An institutional challenge to Skybolt came from the United States Navy, which was developing a submarine-launched ballistic missile (SLBM), the UGM-27 Polaris. The US Chief of Naval Operations, Admiral Arleigh Burke, kept the First Sea Lord, Lord Mountbatten, apprised of its development. By moving the deterrent out to sea, Polaris offered the prospect of a deterrent that was invulnerable to a first strike, and reduced the risk of a nuclear strike on the British Isles. The British Nuclear Deterrent Study Group (BNDSG) produced a study that argued that SLBM technology was as yet unproven, that Polaris would be expensive, and that given the time it would take to build the boats, it could not be deployed before the early 1970s. The Cabinet Defence Committee therefore approved the acquisition of Skybolt in February 1960. The Prime Minister, Harold Macmillan, met with the President, Dwight D. Eisenhower, in March 1960, and secured permission to buy Skybolt. In return, the Americans could base the US Navy's Polaris ballistic missile submarines in the Holy Loch in Scotland. The financial arrangement was particularly favourable to Britain, as the US was charging only the unit cost of Skybolt, absorbing all the research and development costs. With this agreement in hand, the cancellation of Blue Streak was announced in the House of Commons on 13 April 1960.

The subsequent American decision to cancel Skybolt created a political crisis in the UK, and an emergency meeting between Macmillan and President John F. Kennedy was called in Nassau, Bahamas. Macmillan rejected the US offers of paying half the cost of developing Skybolt, and of supplying the AGM-28 Hound Dog missile instead. This brought options down to Polaris, but the Americans would only supply it on condition that it be used as part of a proposed Multilateral Force (MLF). Kennedy ultimately relented, and agreed to supply Britain with Polaris missiles, while "the Prime Minister made it clear that except where Her Majesty's Government may decide that supreme national interests are at stake, these British forces will be used for the purposes of international defence of the Western Alliance in all circumstances." A joint statement to this effect, the Nassau Agreement, was issued on 21 December 1962.

With the Nassau Agreement in hand, it remained to work out the details. Vice Admiral Michael Le Fanu had a meeting with the United States Secretary of Defense, Robert S. McNamara, on 21 December 1962, the final day of the Nassau conference. He found McNamara eager to help, and enthusiastic about the idea of Polaris costing as little as possible. The first issue identified was how many Polaris boats should be built. While the Vulcans to carry Skybolt were already in service, the submarines to carry Polaris were not, and there was no provision in the defence budget for them. Some naval officers feared that their construction would adversely impact the hunter-killer submarine programme. The First Sea Lord, Admiral of the Fleet Sir Caspar John, denounced the "millstone of Polaris hung around our necks" as "potential wreckers of the real navy".

The number of missiles required was based on substituting for Skybolt. To achieve the same capability, the BNDSG calculated that this would require eight Polaris submarines, each of which would have 16 missiles, for a total of 128 missiles, with 128 one-megaton warheads. It was subsequently decided to halve this, based on the decision that the ability to destroy twenty Soviet cities would have nearly as great a deterrent effect as the ability to destroy forty. The Admiralty considered the possibility of hybrid submarines that could operate as hunter-killers while carrying eight Polaris missiles, but McNamara noted that this would be inefficient, as twice as many submarines would need to be on station to maintain the deterrent, and cautioned that the effect of tinkering with the US Navy's 16-missile layout was unpredictable. The Treasury costed a four-boat Polaris fleet at £314 million by 1972/73. A Cabinet Defence Committee meeting on 23 January 1963 approved the plan for four boats, with Thorneycroft noting that four boats would be cheaper and faster to build.

A mission led by Sir Solly Zuckerman, the Chief Scientific Adviser to the Ministry of Defence, left for the United States to discuss Polaris on 8 January 1963. It included the Vice Chief of the Naval Staff, Vice Admiral Sir Varyl Begg; the Deputy Secretary of the Admiralty, James Mackay; Rear Admiral Hugh Mackenzie; and physicist Sir Robert Cockburn and F. J. Doggett from the Ministry of Aviation. That the involvement of the Ministry of Aviation might be a complicating factor was foreseen, but it had experience with nuclear weapons development. Mackenzie had been the Flag Officer Submarines until 31 December 1962, when Le Fanu had appointed him the Chief Polaris Executive (CPE). As such, he was directly answerable to Le Fanu as Controller of the Navy. His CPE staff was divided between London and Foxhill, near Bath, Somerset, where Royal Navy had its ship design, logistics and weapons groups. It was intended as a counterpart to the United States Navy Special Projects Office (SPO), with whom it would have to deal.

The principal finding of the Zuckerman mission was that the Americans had developed a new version of the Polaris missile, the A3. With a range extended of , it had a new weapons bay housing three re-entry vehicles (REBs or Re-Entry Bodies in US Navy parlance) and a new W58 warhead to penetrate improved Soviet anti-missile defences expected to become available around 1970. A decision was therefore required on whether to purchase the old A2 missile or the new A3. The Zuckerman mission came out in favour of the new A3 missile, although it was still under development and not expected to enter service until August 1964, as the deterrent would remain credible for much longer. The decision was endorsed by the First Lord of the Admiralty, Lord Carrington, in May 1963, and was officially made by Thorneycroft on 10 June 1963.

The choice of the A3 created a problem for the Atomic Weapons Research Establishment (AWRE) at Aldermaston, for the Skybolt warhead that had recently been tested in the Tendrac nuclear test at the Nevada Test Site in the United States would require a redesigned Re-Entry System (RES) in order to be fitted to a Polaris missile, at an estimated cost of between £30 million and £40 million. The alternative was to make a British copy of the W58. While the AWRE was familiar with the W47 warhead used in the A2, it knew nothing of the W58. A presidential determination was required to release information on the W58 under the MDA, but with this in hand, a mission led by John Challens, the Chief of Warhead Development at the AWRE, visited the Lawrence Livermore Laboratory from 22 to 24 January 1963, and was shown details of the W58.
The Zuckerman mission found the SPO helpful and forthcoming, but there was one major shock. The British were expected to contribute to the research and development costs of the A3, backdated to 1 January 1963. These were expected to top $700 million by 1968. Skybolt had been offered to the UK at unit cost, with the US absorbing the research and development costs, but no such agreement had been reached at Nassau for Polaris. Thorneycroft baulked at the prospect of paying research and development costs, but McNamara pointed out that the United States Congress would not stand for an agreement that placed all the burden on the United States. Macmillan instructed the British Ambassador to the United States, Sir David Ormsby-Gore, to inform Kennedy that Britain was not willing to commit to an open-ended sharing of research and development costs, but, as a compromise, would pay an additional five per cent for each missile. He asked that Kennedy be informed that a breakdown of the Nassau Agreement would likely cause the fall of his government. Ormsby-Gore met with Kennedy that very day, and while Kennedy noted that the five per cent offer "was not the most generous offer he had ever heard of", he accepted it. McNamara, certain that the United States was being ripped off, calculated the five percent on top of not just the missiles, but their fire control and navigation systems as well, adding around £2 million to the bill. On Ormsby-Gore's advice, this formulation was accepted.

An American mission now visited the United Kingdom. This was led by Paul H. Nitze, the Assistant Secretary of Defense for International Security Affairs, and included Walt W. Rostow, the Director of Policy Planning at the State Department, and Admiral Ignatius J. Galantin, the head of the SPO. The Americans had ideas about how the programme should be organised. They foresaw the UK Polaris programme having project officers from both countries, with a Joint Steering Task Group that met regularly to provide advice. This was accepted, and would become part of the final agreement. However, a follow-up British mission under Leslie Williams, the Director General Atomic Weapons at the Ministry of Aviation, whose members included Challens and Rear Admiral Frederick Dossor, was given a letter by the SPO with a list of subjects that were off limits. These included penetration aids, which were held to be outside the scope of the Nassau Agreement.

One remaining obstacle in the path of the programme was how it would be integrated with the MLF. The British response to the MLF concept "ranged from unenthusiastic to hostile throughout the military establishment and in the two principal political parties". Apart from anything else, it was estimated to cost as much as £100 million over ten years. Nonetheless, the Foreign Office argued that Britain must support the MLF. The Nassau Agreement had invigorated the MLF effort in the United States. Kennedy appointed Livingston T. Merchant to negotiate the MLF with the European governments, which he did in February and March 1963. While reaffirming support for those parts of the Nassau Agreement concerning the MLF, the British were successful in getting them omitted from the Polaris Sales Agreement.
The British team completed drafting the agreement in March 1963, and copies were circulated for discussion. The contracts for their construction were announced that month. The Polaris boats would be the largest submarines built in Britain up to that time, and would be built by Vickers Armstrong Shipbuilders in Barrow-in-Furness and Cammell Laird in Birkenhead. For similar reasons to the US Navy, the Royal Navy decided to base the boats at Faslane, on the Gareloch, not far from the US Navy's base on the Holy Loch. The drawback of the site was that it isolated the Polaris boats from the rest of the navy. The Polaris Sales Agreement was signed in Washington, DC, on 6 April 1963 by Ormsby-Gore and Dean Rusk, the United States Secretary of State.

The two liaison officers were appointed in April; Captain Peter la Niece became the Royal Navy project officer in Washington, DC, while Captain Phil Rollings became the US Navy project officer in London. The Joint Steering Task Group held its first meeting in Washington on 26 June 1963. The shipbuilding programme would prove to be a remarkable achievement, with the four submarines built on time and within the budget. The first boat, was launched in September 1966, and commenced its first deterrent patrol in June 1968. The annual running costs of the Polaris boats came to around two per cent of the defence budget, and they came to be seen as a credible deterrent that enhanced Britain's international status. Along with the more celebrated 1958 US–UK Mutual Defence Agreement, the Polaris Sales Agreement became a pillar of the nuclear Special Relationship between Britain and the United States.

The Polaris Sales Agreement provided an established framework for negotiations over missiles and re-entry systems. The legal agreement took the form of amending the Polaris Sales Agreement through an exchange of notes between the two governments so that "Polaris" in the original now also covered the purchase of Trident. There were also some amendments to the classified annexes of the Polaris Sales Agreement to delete the exclusion of penetrating aids. Under the Polaris Sales Agreement, the United Kingdom paid a five per cent levy on the cost of equipment supplied in recognition of US research and development costs already incurred. For Trident, a payment of $116 million was substituted. The United Kingdom procured the Trident system from America and fitted them to their own submarines, which had only 16 missile tubes like Polaris rather than the 24 in the American . The first , , entered operational service in December 1994, by which time the Cold War had ended.



</doc>
<doc id="24818" url="https://en.wikipedia.org/wiki?curid=24818" title="Proto-Indo-Europeans">
Proto-Indo-Europeans

The Proto-Indo-Europeans were a hypothetical prehistoric people of Eurasia who spoke Proto-Indo-European (PIE), the ancestor of the Indo-European languages according to linguistic reconstruction.

Knowledge of them comes chiefly from that linguistic reconstruction, along with material evidence from archaeology and archaeogenetics. The Proto-Indo-Europeans likely lived during the late Neolithic, or roughly the 4th millennium BC. Mainstream scholarship places them in the Pontic–Caspian steppe zone in Eastern Europe (present day Ukraine and Russia). Some archaeologists would extend the time depth of PIE to the middle Neolithic (5500 to 4500 BC) or even the early Neolithic (7500 to 5500 BC), and suggest alternative location hypotheses.

By the early second millennium BC, offshoots of the Proto-Indo-Europeans had reached far and wide across Eurasia, including Anatolia (Hittites), the Aegean (the ancestors of Mycenaean Greece), the north of Europe (Corded Ware culture), the edges of Central Asia (Yamnaya culture), and southern Siberia (Afanasievo culture).

Using linguistic reconstruction, hypothetical features of the Proto-Indo-European language are deduced. Assuming that these linguistic features reflect culture and environment of the Proto-Indo-Europeans, the following cultural and environmental traits are widely proposed:

Researchers have made many attempts to identify particular prehistoric cultures with the Proto-Indo-European-speaking peoples, but all such theories remain speculative. 

The scholars of the 19th century who first tackled the question of the Indo-Europeans' original homeland (also called "Urheimat", from German), had essentially only linguistic evidence. They attempted a rough localization by reconstructing the names of plants and animals (importantly the beech and the salmon) as well as the culture and technology (a Bronze Age culture centered on animal husbandry and having domesticated the horse). The scholarly opinions became basically divided between a European hypothesis, positing migration from Europe to Asia, and an Asian hypothesis, holding that the migration took place in the opposite direction.

In the early 20th century, the question became associated with the expansion of a supposed "Aryan race", a fallacy promoted during the expansion of European empires and the rise of "scientific racism". The question remains contentious within some flavours of ethnic nationalism (see also Indigenous Aryans).

A series of major advances occurred in the 1970s due to the convergence of several factors. First, the radiocarbon dating method (invented in 1949) had become sufficiently inexpensive to be applied on a mass scale. Through dendrochronology (tree-ring dating), pre-historians could calibrate radiocarbon dates to a much higher degree of accuracy. And finally, before the 1970s, parts of Eastern Europe and Central Asia had been off limits to Western scholars, while non-Western archaeologists did not have access to publication in Western peer-reviewed journals. The pioneering work of Marija Gimbutas, assisted by Colin Renfrew, at least partly addressed this problem by organizing expeditions and arranging for more academic collaboration between Western and non-Western scholars.

The Kurgan hypothesis, the most widely held theory, depends on linguistic and archaeological evidence, but is not universally accepted. It suggests PIE origin in the Pontic-Caspian steppe during the Chalcolithic. A minority of scholars prefer the Anatolian hypothesis, suggesting an origin in Anatolia during the Neolithic. Other theories (Armenian hypothesis, Out of India theory, Paleolithic Continuity Theory, Balkan hypothesis) have only marginal scholarly support.

In regard to terminology, in the 19th and early 20th centuries, the term "Aryan" was used to refer to the Proto-Indo-Europeans and their descendants. However, "Aryan" more properly applies to the Indo-Iranians, the Indo-European branch that settled parts of the Middle East and South Asia, as only Indic and Iranian languages explicitly affirm the term as a self-designation referring to the entirety of their people, whereas the same Proto-Indo-European root (*aryo-) is the basis for Greek and Germanic word forms which seem only to denote the ruling elite of Proto-Indo-European (PIE) society. In fact, the most accessible evidence available confirms only the existence of a common, but vague, socio-cultural designation of "nobility" associated with PIE society, such that Greek socio-cultural lexicon and Germanic proper names derived from this root remain insufficient to determine whether the concept was limited to the designation of an exclusive, socio-political elite, or whether it could possibly have been applied in the most inclusive sense to an inherent and ancestral "noble" quality which allegedly characterized all ethnic members of PIE society. Only the latter could have served as a true and universal self-designation for the Proto-Indo-European people.

By the early twentieth century this term had come to be widely used in a racist context referring to a hypothesized white, blonde and blue eyed "master race", culminating with the pogroms of the Nazis in Europe. Subsequently, the term "Aryan" as a general term for Indo-Europeans has been largely abandoned by scholars (though the term "Indo-Aryan" is still used to refer to the branch that settled in Southern Asia).

According to some archaeologists, PIE speakers cannot be assumed to have been a single, identifiable people or tribe, but were a group of loosely related populations ancestral to the later, still partially prehistoric, Bronze Age Indo-Europeans. This view is held especially by those archaeologists who posit an original homeland of vast extent and immense time depth. However, this view is not shared by linguists, as proto-languages, like all languages before modern transport and communication, occupied small geographical areas over a limited time span, and were spoken by a set of close-knit communities—a tribe in the broad sense.

Researchers have put forward a great variety of proposed locations for the first speakers of Proto-Indo-European. Few of these hypotheses have survived scrutiny by academic specialists in Indo-European studies sufficiently well to be included in modern academic debate.

In 1956 Marija Gimbutas (1921–1994) first proposed the Kurgan hypothesis. The name originates from the "kurgans" (burial mounds) of the Eurasian steppes. The hypothesis suggests that the Indo-Europeans, a nomadic culture of the Pontic-Caspian steppe (now part of Eastern Ukraine and Southern Russia), expanded in several waves during the 3rd millennium BC. Their expansion coincided with the taming of the horse. Leaving archaeological signs of their presence (see battle-axe people), they subjugated the peaceful European neolithic farmers of Gimbutas' Old Europe. As Gimbutas' beliefs evolved, she put increasing emphasis on the patriarchal, patrilinear nature of the invading culture, sharply contrasting it with the supposedly egalitarian, if not matrilinear culture of the invaded, to a point of formulating essentially feminist archaeology. A modified form of this theory by JP Mallory (1945- ), dating the migrations earlier (to around 3500 BC) and putting less insistence on their violent or quasi-military nature, remains the most widely accepted view of the Proto-Indo-European expansion.

The Armenian hypothesis, based on the glottalic theory, suggests that the Proto-Indo-European language was spoken during the 4th millennium BC in the Armenian Highland. This Indo-Hittite model does not include the Anatolian languages in its scenario. The phonological peculiarities of PIE proposed in the glottalic theory would be best preserved in the Armenian language and the Germanic languages, the former assuming the role of the dialect which remained "in situ", implied to be particularly archaic in spite of its late attestation. Proto-Greek would be practically equivalent to Mycenean Greek and would date to the 17th century BC, closely associating Greek migration to Greece with the Indo-Aryan migration to India at about the same time (viz., Indo-European expansion at the transition to the Late Bronze Age, including the possibility of Indo-European Kassites). The Armenian hypothesis argues for the latest possible date of Proto-Indo-European ("sans" Anatolian), a full millennium later than the mainstream Kurgan hypothesis. In this, it figures as an opposite to the Anatolian hypothesis, in spite of the geographical proximity of the respective "Urheimaten" suggested, diverging from the time-frame suggested there by a full three millennia.

The Anatolian hypothesis proposes that the Indo-European languages spread peacefully into Europe from Asia Minor from around 7000 BC with the advance of farming ("wave of advance"). The leading propagator of the theory is Colin Renfrew. The culture of the Indo-Europeans as inferred by linguistic reconstruction raises difficulties for this theory, since early neolithic cultures had neither the horse, nor the wheel, nor metal, terms for all of which are securely reconstructed for Proto-Indo-European. Renfrew dismisses this argument, comparing such reconstructions to a theory that the presence of the word "café" in all modern Romance languages implies that the ancient Romans had cafés too. The linguistic counter-argument to this might state that whereas there can be no clear Proto-Romance reconstruction of the word "café" according to historical linguistic methodology, words such as "wheel" in the Indo-European languages clearly point to an archaic form of the protolanguage. Another argument against Renfrew is the fact that ancient Anatolia is known to have been inhabited by non-Indo-European Caucasian-speaking peoples, namely the Hattians, the Chalybes, and the Hurrians.

Following the publication of several studies on ancient DNA in 2015, Colin Renfrew has accepted the reality of migrations of populations speaking one or several Indo-European languages from the Pontic steppe towards Northwestern Europe.

The rise of archaeogenetic evidence which uses genetic analysis to trace migration patterns also added new elements to the origins puzzle.

According to three autosomal DNA studies, haplogroups R1b and R1a, now the most common in Europe (R1a is also very common in South Asia) would have expanded from the Russian steppes, along with the Indo European languages; they also detected an autosomal component present in modern Europeans which was not present in Neolithic Europeans, which would have been introduced with paternal lineages R1b and R1a, as well as Indo European Languages. Studies which analysed ancient human remains in Ireland and Portugal suggest that R1b was introduced in these places along with autosomal DNA from the Eastern European steppes.

The subclade R1a1a (R-M17 or R-M198) is most commonly associated with Indo-European speakers, although the subclade R1b1a (P-297) has also been linked to the Centum branch of Indo-European. Data so far collected indicate that there are two widely separated areas of high frequency, one in Eastern Europe, around Poland and the Russian core, and the other in South Asia, around Indo-Gangetic Plain. The historical and prehistoric possible reasons for this are the subject of on-going discussion and attention amongst population geneticists and genetic genealogists, and are considered to be of potential interest to linguists and archaeologists also.

A large, 2014 study by Underhill et al., using 16,244 individuals from over 126 populations from across Eurasia, concluded there was compelling evidence, that R1a-M420 originated in the vicinity of Iran. The mutations that characterize haplogroup R1a occurred ~10,000 years BP. Its defining mutation (M17) occurred about 10,000 to 14,000 years ago. Pamjav et al. (2012) believe that R1a originated and initially diversified either within the Eurasian Steppes or the Middle East and Caucasus region.

Ornella Semino et al. propose a postglacial (Holocene) spread of the R1a1 haplogroup from north of the Black Sea during the time of the Late Glacial Maximum, which was subsequently magnified by the expansion of the Kurgan culture into Europe and eastward.

According to Jones et al. (2015) and Haak et al. (2015), Yamnaya culture was exclusively R1b, autosomic tests indicate that the Yamnaya-people were the result of admixture between two different hunter-gatherer populations: distinctive "Eastern European Hunter-Gatherers" with high affinity to the Mal'ta-Buret' culture or other, closely related Ancient North Eurasian (ANE) people from Siberia and to Western Hunter-Gatherers (WHG) and a population of "Caucasus hunter-gatherers" who probably arrived from somewhere in the Near East, probably the Caucasus or Iran. Each of those two populations contributed about half the Yamnaya DNA. According to co-author Dr. Andrea Manica of the University of Cambridge: 
An analysis by David W. Anthony (2019) also suggests a genetic origin of proto-Indo-Europeans (the Yamnaya people) in the Eastern European steppe north of the Caucasus, derived from a mixture of Eastern European hunter-gatherers and hunter-gatherers from the Caucasus. Anthony also suggests that the proto-Indo-European language formed mainly from a base of languages spoken by Eastern European hunter-gathers with influences from languages of northern Caucasus hunter-gatherers, in addition to a possible later influence from the language of the Maikop culture to the south (which is hypothesized to have belonged to the North Caucasian family) in the later neolithic or bronze age involving little genetic impact.

According to Haak et al. (2015), "Eastern European hunter-gatherers" who inhabited Russia were a distinctive population of hunter-gatherers with high affinity to a ~24,000-year-old Siberian from Mal'ta-Buret' culture, or other, closely related Ancient North Eurasian (ANE) people from Siberia and to the Western Hunter Gatherers (WHG). Remains of the "Eastern European hunter-gatherers" have been found in Mesolithic or early Neolithic sites in Karelia and Samara Oblast, Russia, and put under analysis. Three such hunter-gathering individuals of the male sex have had their DNA results published. Each was found to belong to a different Y-DNA haplogroup: R1a, R1b, and J. R1b is also the most common Y-DNA haplogroup found among both the Yamnaya and modern-day Western Europeans.

The Near East population were most likely hunter-gatherers from the Caucasus (CHG) c.q. Iran Chalcolithic related people with a CHG-component.

Jones et al. (2015) analyzed genomes from males from western Georgia, in the Caucasus, from the Late Upper Palaeolithic (13,300 years old) and the Mesolithic (9,700 years old). These two males carried Y-DNA haplogroup: J* and J2a. The researchers found that these Caucasus hunters were probably the source of the farmer-like DNA in the Yamnaya, as the Caucasians were distantly related to the Middle Eastern people who introduced farming in Europe. Their genomes showed that a continued mixture of the Caucasians with Middle Eastern took place up to 25,000 years ago, when the coldest period in the last Ice Age started.

According to Lazaridis et al. (2016), "a population related to the people of the Iran Chalcolithic contributed ~43% of the ancestry of early Bronze Age populations of the steppe." According to Lazaridis et al. (2016), these Iranian Chalcolithic people were a mixture of "the Neolithic people of western Iran, the Levant, and Caucasus Hunter Gatherers." Lazaridis et al. (2016) also note that farming spread at two places in the Near East, namely the Levant and Iran, from where it spread, Iranian people spreading to the steppe and south Asia.

Haak et al. (2015) studied DNA from 94 skeletons from Europe and Russia aged between 3,000 and 8,000 years old. They concluded that about 4,500 years ago there was a major influx into Europe of Yamnaya culture people originating from the Pontic-Caspian steppe north of the Black Sea and that the DNA of copper-age Europeans matched that of the Yamnaya. The genetic basis of a number of features of the Yamnaya people were ascertained: they were genetically tall (phenotypic height is determined by both genetics and environmental factors), overwhelmingly dark-eyed (brown), dark-haired and had a skin colour that was moderately light, though somewhat darker than that of the average modern European:
From the Corded Ware culture the Indo-Europeans spread eastward again, forming the Andronovo culture. Most researchers associate the Andronovo horizon with early Indo-Iranian languages, though it may have overlapped the early Uralic-speaking area at its northern fringe. According to Allentoft et al. (2015), the Sintashta culture and Andronovo culture are derived from the Corded Ware culture. According to Keyser et al. (2009), out of 10 human male remains assigned to the Andronovo horizon from the Krasnoyarsk region, nine possessed the R1a Y-chromosome haplogroup and one had the C-M130 haplogroup (xC3). Furthermore, 90% of the Bronze Age period mtDNA haplogroups were of west Eurasian origin, and the study determined that at least 60% of the individuals overall (out of the 25 Bronze and Iron Age human-remains samples from the study that could be tested) had blue or green eyes.

A 2004 study also established that during the Bronze Age/Iron Age period, the majority of the population of Kazakhstan (part of the Andronovo culture during Bronze Age), was of west Eurasian origin (with mtDNA haplogroups such as U, H, HV, T, I and W), and that prior to the 13th–7th centuries BC, all samples from Kazakhstan belonged to European lineages.

Luigi Luca Cavalli-Sforza and Alberto Piazza argue that Renfrew and Gimbutas reinforce rather than contradict each other. states that "It is clear that, genetically speaking, peoples of the Kurgan steppe descended at least in part from people of the Middle Eastern Neolithic who immigrated there from Turkey." Piazza and Cavalli-Sforza (2006) state that:
Spencer Wells suggests in a 2001 study that the origin, distribution and age of the R1a1 haplotype points to an ancient migration, possibly corresponding to the spread by the Kurgan people in their expansion across the Eurasian steppe around 3000 BC.

About his old teacher Cavalli-Sforza's proposal, states that "there is nothing to contradict this model, although the genetic patterns do not provide clear support either", and instead argues that the evidence is much stronger for Gimbutas' model:
David Reich (2018), noting the presence of some Indo-European languages (such as Hittite) in parts of ancient Anatolia, argues that "the most likely location of the population that first spoke an Indo-European language was south of the Caucasus Mountains, perhaps in present-day Iran or Armenia, because ancient DNA from people who lived there matches what we would expect for a source population both for the Yamnaya and for ancient Anatolians." Yet, Reich also notes that "...the evidence here is circumstantial as no ancient DNA from the Hittites themselves has yet been published." Kristian Kristiansen, in an interview with "Der Spiegel" in May 2018, stated that the Yamnaya culture may have had a predecessor at the Caucasus, where "proto-proto-Indo-European" was spoken.

Recent DNA-research has led to renewed suggestions of a Caucasian homeland for the 'proto-Indo-Europeans'. According to Kroonen et al. (2018), Damgaard et al. (2018) ancient Anatolia "show no indication of a large-scale intrusion of a steppe population." They further note that this lends support to the Indo-Hittite hypothesis, according to which both proto-Anatolian and proto-Indo-European split-off from a common mother language "no later than the 4th millennium BCE." Haak et al. (2015) states that "the Armenian plateau hypothesis gains in plausibility" since the Yamnaya partly descended from a Near Eastern population, which resembles present-day Armenians."

Wang et al. (2018) note that the Caucasus served as a corridor for gene flow between the steppe and cultures south of the Caucasus during the Eneolithic and the Bronze Age, stating that this "opens up the possibility of a homeland of PIE south of the Caucasus." However, Wang et al. also comment that the most recent genetic evidence supports an expansion of proto-Indo-Europeans through the steppe, noting: "but the latest ancient DNA results from South Asia also lend weight to a spread of Indo-European languages "via the steppe belt. The spread of some or all of the proto-Indo-European branches would have been possible via the North Caucasus and Pontic region and from there, along with pastoralist expansions, to the heart of Europe. This scenario finds support from the well attested and now widely documented 'steppe ancestry' in European populations, the postulate of increasingly patrilinear societies in the wake of these expansions (exemplified by R1a/R1b), as attested in the latest study on the Bell Beaker phenomenon."

David Anthony in a 2019 analysis, criticizes the "southern" or "Armenian" hypothesis (citing Reich, Kristaiansen, and Wang). Among his reasons being: that the Yamnaya lack evidence of genetic influence from the bronze age or late neolithic Caucasus (deriving instead from an earlier mixture of Eastern European hunter-gatherers and Caucasus hunter-gatherers) and have paternal lineages that seem to derive from the hunter-gatherers of the Eastern European Steppe rather than the Caucasus, as well as a scarcity in the Yamnaya of the Anatolian Farmer admixture that had become common and substantial in the Caucasus around 5,000 BC. Anthony instead suggests a genetic and linguistic origin of proto-Indo-Europeans (the Yamnaya) in the Eastern European steppe north of the Caucasus, from a mixture of these two groups (EHG and CHG). He suggests that the roots of Proto-Indo-European ("archaic" or proto-proto-Indo-European) were in the steppe rather than the south and that PIE formed mainly from a base of languages spoken by Eastern European hunter-gathers with some influences from languages of Caucasus hunter-gatherers.




</doc>
<doc id="24820" url="https://en.wikipedia.org/wiki?curid=24820" title="Peter Mark Roget">
Peter Mark Roget

Peter Mark Roget ( ; 18 January 1779 – 12 September 1869) was a British physician, natural theologian and lexicographer. He is best known for publishing, in 1852, the "Thesaurus of English Words and Phrases", a classified collection of related words.

Peter Mark Roget was born in London, the son of Jean (John) Roget (1751–1783), a Genevan cleric, and his wife Catherine Romilly, sister of Samuel Romilly. After his father's death, the family moved to Edinburgh, in 1793, and he shortly began to study medicine at the University of Edinburgh, graduating in 1798. Samuel Romilly, who had supported his education, also introduced Roget into Whig social circles.

Roget then attended lectures at London medical schools. Living in Clifton, Bristol in 1798–9, he knew Thomas Beddoes and Humphry Davy, and frequented the Pneumatic Institute.

Not making a quick start to a medical career, Roget in 1802 took a position as a tutor to the sons of John Leigh Philips. He began with them a Grand Tour, during the Peace of Amiens, travelling with a friend Lovell Edgeworth, son of Richard Lovell Edgeworth. When the Peace abruptly ended, he was detained as a prisoner in Geneva. He was able to bring his pupils back to England, in late 1803, but Edgeworth was in captivity until Napoleon's fall.

Roget became, with help from Samuel Romilly, private physician to William Petty, 1st Marquess of Lansdowne, who died in 1805. He then succeeded Thomas Percival at Manchester Infirmary, and began to lecture on physiology. He moved to London in 1808, and in 1809 became a licentiate of the Royal College of Physicians. After an extended period of dispensary work and lecturing, in particular at the Russell Institution and Royal Institution, he was taken onto the staff of the Queen Charlotte Hospital in 1817. He also lectured at the London Institution and the Windmill Street School.

Sir Samuel Romilly committed suicide, dying in Roget's presence, in 1818. Roget had been called in as adviser by the family, following the death of Lady Romilly.

In 1823 Roget and Peter Mere Latham were brought in to investigate disease at Millbank Penitentiary. In 1828 Roget, with William Thomas Brande and Thomas Telford, submitted a report on London's water supply. In 1834 he became the first Fullerian Professor of Physiology at the Royal Institution. One of those who helped found the University of London in 1837, he was an examiner in physiology there. He gave up medical practice in 1840.

Roget in later life became deaf, and was cared for by his daughter Kate. He died while on holiday in West Malvern, Worcestershire, aged 90, and is buried there in the cemetery of St James's Church.

Roget retired from professional life in 1840, and by 1846 was working on the book that perpetuates his memory. It has been claimed that Roget struggled with depression for most of his life, and that the thesaurus arose partly from an effort to battle it. A biographer stated that obsession with list-making as a coping mechanism was well established by the time Roget was eight years old. He began to maintain a notebook classification scheme for words in 1805. At this period he moved to Manchester, and there he became the first secretary of the Portico Library.

It was a catalogue of words organized by their meanings. Its first printed edition, in 1852, was called "Thesaurus of English Words and Phrases Classified and Arranged so as to Facilitate the Expression of Ideas and Assist in Literary Composition". During Roget's lifetime the work had twenty-eight printings; after his death it was revised and expanded by his son, John Lewis Roget (1828–1908), and later by John's son, the engineer Samuel Romilly Roget (1875–1953).

Roget was elected a Fellow of the Royal Society in 1815, in recognition of a paper on a slide rule with a loglog scale. He was a secretary of the Society from 1827 to 1848. On 9 December 1824, Roget presented a paper on a peculiar optical illusion to the "Philosophical Transactions", which was published in 1825, as "Explanation of an optical deception in the appearance of the spokes of a wheel when seen through vertical apertures." The paper was noted by Michael Faraday and by Joseph Plateau, who both mentioned it in their articles that presented new illusions with apparent motion. It has often been heralded as the basis for the persistence of vision theory, which has for a long time been falsely regarded as the principle causing the perception of motion in animation and film. In 1834, Roget claimed to have invented "the Phantasmascope or Phenakisticope" in the spring 1831, a few years before Plateau introduced this first device that demonstrated stroboscopic animation.

One of the promoters of the Medical and Chirurgical Society of London, which later became the Royal Society of Medicine, Roget was also a founder of the Society for the Diffusion of Useful Knowledge, writing a series of popular manuals for it. He wrote numerous papers on physiology and health, among them the fifth "Bridgewater Treatise", "Animal and Vegetable Physiology considered with reference to Natural Theology" (1834), and articles for the "Encyclopædia Britannica". He was hostile to phrenology, writing against it in a "Britannica" supplement in 1818, and devoting a two-volume work to it (1838).

A chess player, in an article in the "London and Edinburgh Philosophical Magazine" Roget solved the general open knight's tour problem. He composed chess problems, and designed an inexpensive pocket chessboard.


Canadian writer Keath Fraser published a story, "Roget's Thesaurus," in 1982, which is narrated in Roget's voice. He has Roget speak on his wife's death, from cancer.

Roget also appears in Shelagh Stephenson's "An Experiment with an Air Pump", set in 1799, as the only historical character. The play takes place in the fictional household of Joseph Fenwick, and Roget is one of Fenwick's assistants.

A picture book biography of Roget entitled "The Right Word: Roget and His Thesaurus" was published by Eerdmans Books in 2014. It was named a Caldecott Honor book for excellence in illustration and won the Sibert Medal for excellence in children's nonfiction.

In 1824 Roget married Mary Taylor (1795–1833), daughter of Jonathan Hobson. They had a son John Lewis (1828–1908), and a daughter Kate.



 


</doc>
<doc id="24823" url="https://en.wikipedia.org/wiki?curid=24823" title="Pterodactylus">
Pterodactylus

Pterodactylus (meaning "winged finger") is an extinct genus of pterosaurs, whose members are commonly known as pterodactyls ( ). It is thought to contain only a single species, Pterodactylus antiquus, the first pterosaur species to be named and identified as a flying reptile.

The fossil remains of this species have been found primarily in the Solnhofen limestone of Bavaria, Germany, dated to the late Jurassic Period (early Tithonian), about 150.8–148.5 million years ago, though more fragmentary remains have been tentatively identified from elsewhere in Europe and in Africa.

It was a carnivore and probably preyed upon fish and other small animals. Like all pterosaurs, "Pterodactylus" had wings formed by a skin and muscle membrane stretching from its elongated fourth finger to its hind limbs. It was supported internally by collagen fibres and externally by keratinous ridges.

"Pterodactylus" is known from over 30 fossil specimens, and though most of those are juveniles, many preserve complete skeletons. "Pterodactylus antiquus" was a relatively small pterosaur, with an estimated adult wingspan of about (the only known adult specimen is represented by an isolated skull). Other "species" were once thought to be smaller. However, these smaller specimens have been shown to represent juveniles of "Pterodactylus", as well as its contemporary relatives including "Ctenochasma", "Germanodactylus", "Aurorazhdarcho", "Gnathosaurus" (and hypothetically "Aerodactylus" if this genus is truly valid).

The skulls of adult "Pterodactylus" were long and thin with about 90 narrow, conical teeth. The teeth extended back from the tips of both jaws, and became smaller farther away from the jaw tips (unlike some relatives, where teeth were absent in the upper jaw tip and were relatively uniform in size). The teeth extended farther back into the jaw than in close relatives, as some were present below the front of the "nasoantorbital fenestra", the largest opening in the skull. Unlike related species, the skull and jaws were straight, not curved upwards.
"Pterodactylus", like related pterosaurs, had a crest on its skull composed mainly of soft tissues. In adult "Pterodactylus", this crest extended between the back edge of the antorbital fenestra (the largest opening in the skull) and the back of the skull. In at least one specimen, the crest had a short bony base, also seen in related pterosaurs like "Germanodactylus". Solid crests have only been found on large, fully adult specimens of "Pterodactylus", indicating that this was a display structure that became larger and more well developed as individuals reached maturity. Bennett (2013) noted that other authors claimed that the soft tissue crest of "Pterodactylus" extended backward behind the skull; Bennett himself, however, didn't find any evidence for the crest extending past the back of the skull. Two specimens of "P. antiquus" (the holotype specimen BSP AS I 739 and the incomplete skull BMMS 7, the largest known skull of "P. antiquus") have a low bony crest on their skulls; in BMMS 7 it is 47.5 mm long (1.87 inches, more or less 24% of the estimated total length of its skull) and has a maximum height of 0.9 mm (0.035 inches) above the orbit. Several specimens previously referred to "P. antiquus" preserved evidence of the soft tissue extensions of these crests, including an "occipital lappet", a flexible, tab-like structure extending from the back of the skull. Most of these specimens have been reclassified in the related species "Aerodactylus scolopaciceps", which may however be nothing more than a junior synonym. Even if "Aerodactylus" were valid, at least one specimen with these features is still considered to belong to "Pterodactylus". This is BSP 1929 I 18, which has an occipital lappet similar to the proposed "Aerodactylus" definition. This specimen also has a small triangular soft tissue crest with the peak of the crest positioned above the eyes.

Like other pterosaurs (notably "Rhamphorhynchus"), "Pterodactylus" specimens can vary considerably based on age or level of maturity. Both the proportions of the limb bones, size and shape of the skull, and size and number of teeth changed as the animals grew. Historically, this has led to various growth stages (including growth stages of related pterosaurs) being mistaken for new species of "Pterodactylus". Several detailed studies using various methods to measure growth curves among known specimens have suggested that there is actually only one valid "Pterodactylus" species, "P. antiquus".

The youngest immature "Pterodactylus antiquus" specimens (alternately interpreted as young specimens of the distinct species "P. kochi") have a small number of teeth (as few as 15), and the teeth have a relatively broad base. The teeth of other "P. antiquus" specimens are both narrower and more numerous (up to 90 teeth are present in some specimens).

"Pterodactylus" specimens can be divided into two distinct year classes. In the first year class, the skulls are only 15-45mm (0.59-1.77 inches) in length. The second year class is characterized by skulls 55-95mm (2.16-3.74 inches) long, but still immature. These first two size groups were once classified as juveniles and adults of the species "P. kochi", until further study showed that even the supposed "adults" were immature, and possibly belong to a distinct genus. A third year class is represented by specimens of the "traditional" "P. antiquus", as well as a few isolated, large specimens once assigned to "P. kochi" that overlap "P. antiquus" in size. However, all specimens in this third year class also show sign of immaturity. Fully mature "Pterodactylus" specimens remain unknown, or may have been mistakenly classified as a different genus.

The distinct year classes of "Pterodactylus antiquus" specimens show that this species, like the contemporary "Rhamphorhynchus muensteri", likely bred seasonally and grew consistently during its lifetime. A new generation of 1st year class "P. antiquus" would have been produced seasonally, and reached 2nd-year size by the time the next generation hatched, creating distinct 'clumps' of similarly-sized and aged individuals in the fossil record. The smallest size class probably consisted of individuals that had just begun to fly and were less than one year old. The second year class represents individuals one to two years old, and the rare third year class is composed of specimens over two years old. This growth pattern is similar to modern crocodilians, rather than the rapid growth of modern birds.

Comparisons between the scleral rings of "Pterodactylus antiquus" and modern birds and reptiles suggest that it may have been diurnal. This may also indicate niche partitioning with contemporary pterosaurs inferred to be nocturnal, such as "Ctenochasma" and "Rhamphorhynchus".

The type specimen of the animal now known as "Pterodactylus antiquus" was one of the first pterosaur fossils ever to be identified. The first "Pterodactylus" specimen was described by the Italian scientist Cosimo Alessandro Collini in 1784, based on a fossil skeleton that had been unearthed from the Solnhofen limestone of Bavaria. Collini was the curator of the "Naturalienkabinett", or nature cabinet (a precursor to the modern concept of the natural history museum), in the palace of Charles Theodore, Elector of Bavaria at Mannheim. The specimen had been given to the collection by Count Friedrich Ferdinand zu Pappenheim, probably around 1780, having been recovered from a lithographic limestone quarry in Eichstätt. The actual date of the specimen's discovery and entry into the collection is unknown. It was not mentioned in a catalogue of the collection taken in 1767 and so must have been acquired at some point between that date and its 1784 description by Collini. This makes it potentially the earliest documented pterosaur find; the "Pester Exemplar" of "Pterodactylus micronyx" was described in 1779 and possibly discovered earlier than the Mannheim specimen, but it was at first considered to be a fossil crustacean.
Collini, in his first description of the Mannheim specimen, did not conclude that it was a flying animal. In fact, Collini could not fathom what kind of animal it might have been, rejecting affinities with the birds or the bats. He speculated that it may have been a sea creature, not for any anatomical reason, but because he thought the ocean depths were more likely to have housed unknown types of animals. The idea that pterosaurs were aquatic animals persisted among a minority of scientists as late as 1830, when the German zoologist Johann Georg Wagler published a text on "amphibians" which included an illustration of "Pterodactylus" using its wings as flippers. Wagler went so far as to classify "Pterodactylus", along with other aquatic vertebrates (namely plesiosaurs, ichthyosaurs, and monotremes), in the class Gryphi, between birds and mammals.

It was the German/French scientist Johann Hermann who first stated that "Pterodactylus" used its long fourth finger to support a wing membrane. In March 1800, Hermann alerted the French scientist George Cuvier to the existence of Collini's fossil, believing that it had been captured by the occupying armies of Napoleon and sent to the French collections in Paris (and perhaps to Cuvier himself) as war booty; at the time special French political commissars systematically seized art treasures and objects of scientific interest. Hermann sent Cuvier a letter containing his own interpretation of the specimen (though he had not examined it personally), which he believed to be a mammal, including the first known life restoration of a pterosaur. Hermann restored the animal with wing membranes extending from the long fourth finger to the ankle and a covering of fur (neither wing membranes nor fur had been preserved in the specimen). Hermann also added a membrane between the neck and wrist, as is the condition in bats. Cuvier agreed with this interpretation, and at Hermann's suggestion, Cuvier became the first to publish these ideas in December 1800 in a very short description. Cuvier remarked, "[It is not possible to doubt that the long finger served to support a membrane that, by lengthening the anterior extremity of this animal, formed a good wing.]" However, contrary to Hermann, Cuvier was convinced the animal was a reptile.

The specimen had not in fact been seized by the French. Rather, in 1802, following the death of Charles Theodore, it was brought to Munich, where Baron Johann Paul Carl von Moll had obtained a general exemption of confiscation for the Bavarian collections. Cuvier asked von Moll to study the fossil but was informed it could not be found. In 1809 Cuvier published a somewhat longer description, in which he named the animal a "ptero-dactyle" and refuted a hypothesis by Johann Friedrich Blumenbach that it would have been a shore bird.

Contrary to von Moll's report, the fossil was not missing; it was being studied by Samuel Thomas von Sömmerring, who gave a public lecture about it on 27 December 1810. In January 1811, von Sömmerring wrote a letter to Cuvier deploring the fact that he had only recently been informed of Cuvier's request for information. His lecture was published in 1812, and in it von Sömmerring named the species "Ornithocephalus antiquus". The animal was described as being both a mammal, a bat, and a form in between mammals and birds, i.e. not intermediate in descent but in "affinity" or archetype. Cuvier disagreed, and the same year in his "Ossemens fossiles" provided a lengthy description in which he restated that the animal was a reptile. It was not until 1817 that a second specimen of "Pterodactylus" came to light, again from Solnhofen. This tiny specimen was that year described by von Soemmerring as "Ornithocephalus brevirostris", named for its short snout, now understood to be a juvenile character (this specimen is now thought to represent a juvenile specimen of a different genus, probably "Ctenochasma"). He provided a restoration of the skeleton, the first one published for any pterosaur. This restoration was very inaccurate, von Soemmerring mistaking the long metacarpals for the bones of the lower arm, the lower arm for the humerus, this upper arm for the breast bone and this sternum again for the shoulder blades. Soemmerring did not change his opinion that these forms were bats and this "bat model" for interpreting pterosaurs would remain influential long after a consensus had been reached around 1860 that they were reptiles. The standard assumptions were that pterosaurs were quadrupedal, clumsy on the ground, furred, warmblooded and had a wing membrane reaching the ankle. Some of these elements have been confirmed, some refuted by modern research, while others remain disputed.

The genus now known as "Pterodactylus" was originally named "Petro-Dactyle" by Cuvier in 1809, though this was a typographical error, later corrected by him to "Ptéro-Dactyle". In 1812, Samuel Thomas von Sömmerring named the same specimen "Ornithocephalus antiquus". The genus name was emended to the current "Pterodactylus" by Constantine Samuel Rafinesque in 1815. Unaware of Rafinesque's publication, Cuvier himself in 1819 again emended the genus name, but the specific name he then gave, "longirostris", has to give precedence to von Soemmerring's "antiquus". In 1888 Richard Lydekker designated "Pterodactylus antiquus" the type species. The original specimen is the holotype of the genus, BSP No. AS.I.739.

Hermann von Meyer, in 1830, used the name Pterodactyli to contain "Pterodactylus" and other pterosaurs known at the time. This was emended to the family Pterodactylidae by Prince Charles Lucien Bonaparte in 1838. This group has more recently been given several competing definitions.

Below is a cladogram showing the results of a phylogenetic analysis presented by Andres, Clark & Xu, 2014.

Numerous species have been assigned to "Pterodactylus" in the years since its discovery. In the first half of the nineteenth century any new pterosaur species would be named "Pterodactylus", which thus became a typical "wastebasket taxon". Even after clearly different forms had later been given their own generic name, new species would be created from the very productive late Jurassic German sites, often based on only slightly different material.

Around 1980, subsequent revisions by Peter Wellnhofer had reduced the number of recognized species to about half a dozen. Many species assigned to "Pterodactylus" had been based on juvenile specimens, and subsequently been recognized as immature individuals of other species or genera. By the 1990s it was understood that this was even true for part of the remaining species. "P. elegans", for example, was found by numerous studies to be an immature "Ctenochasma". Another species of "Pterodactylus" originally based on small, immature specimens was "P. micronyx". However, it has been difficult to determine exactly of what genus and species "P. micronyx" might be the juvenile form. Stéphane Jouve, Christopher Bennett and others had once suggested that it probably belonged either to "Gnathosaurus subulatus" or one of the "Ctenochasma" species, though after additional research Bennett assigned it to the genus "Aurorazhdarcho". Another species with a complex history is "P. longicollum", named by von Meyer in 1854, based on a large specimen with a long neck and fewer teeth. Many researchers, including David Unwin, have found "P. longicollum" to be distinct from "P. kochi" and "P. antiquus". Unwin found "P. longicollum" to be closer to "Germanodactylus" and therefore requiring a new genus name. It has sometimes been placed in the genus "Diopecephalus" because Harry Govier Seeley based this genus partly on the "P. longicollum" material. However, it was shown by Bennett that the type specimen later designated for "Diopecephalus" was a fossil belonging to "P. kochi", and no longer thought to be separate from "Pterodactylus". "Diopecephalus" is therefore a synonym of "Pterodactylus", and as such is unavailable for use as a new genus for "P." "longicollum". ""P." longicollum" was eventually made the type species of a separate genus "Ardeadactylus".
The only well-known and well-supported species left by the first decades of the 21st century were "P. antiquus" and "P. kochi". However, most studies between 1995 and 2010 found little reason to separate even these two species, and treated them as synonymous. In 1996, Bennett suggested that the differences between specimens of "P. kochi" and "P. antiquus" could be explained by differences in age, with "P. kochi" (including specimens alternately classified in the species "P. scolopaciceps") representing an immature growth stage of "P. antiquus". In a 2004 paper, Jouve used a different method of analysis and recovered the same result, showing that the "distinctive" features of "P. kochi" were age-related, and using mathematical comparison to show that the two forms are different growth stages of the same species. An additional review of the specimens published in 2013 demonstrated that some of the supposed differences between "P. kochi" and "P. antiquus" were due to measurement errors, further supporting their synonymy.

By the 2010s, a large body of research had been developed based on the idea that "P. kochi" and "P. scolopaciceps" were early growth stages of "P. antiquus". However, in 2014, two scientists began publishing research that challenged this paradigm. Steven Vidovic and David Martill concluded that differences between specimens of "P. kochi", "P. scolopaciceps", and "P. antiquus", such as different lengths of neck vertebrae, thinner or thicker teeth, more rounded skulls, and how far the teeth extended back in the jaws, were significant enough to separate them into three distinct species. Vidovic and Martill also performed a phylogenetic analysis which treated all relevant specimens as distinct units, and found that the "P. kochi" type specimen did not form a natural group with that of "P. antiquus". They concluded that the genus "Diopecephalus" could be returned to use to distinguish "P". "kochi" from "P. antiquus". They named the new genus "Aerodactylus" for "P. scolopaciceps" as well. So, what Bennett considered early growth stages of one species, Vidovic and Martill considered representatives of new species.

In 2017, Bennett challenged this hypothesis. He claimed that while Vidovic and Martill had identified real differences between the these three groups of specimens, they had not provided any rationale that the differences were enough to distinguish them as species, rather than just individual variation, growth changes, or simply due to crushing and distortion during the fossilization process. Bennett pointed in particular to the data used to distinguish ""Aerodactylus"", which was so different from the data for related species, it might be due to an unnatural assemblage of specimens. As a result, Bennett continued to consider "Diopecephalus" and "Aerodactylus" simply as year-classes of immature "Pterodactylus antiquus".

During its over-200-year history, the various species of "Pterodactylus" have gone through a number of changes in classification, and thus have acquired a large number of synonyms. Additionally, a number of species assigned to "Pterodactylus" are based on poor remains that have proven difficult to assign to one species or another, and are therefore considered "nomina dubia" ("doubtful names"). The following list includes names that are based on German material presently, or until recently, thought to be pertaining to "Pterodactylus" proper and names based on other material that has as yet not been assigned to other genera.



</doc>
<doc id="24824" url="https://en.wikipedia.org/wiki?curid=24824" title="Pterosaur">
Pterosaur

Pterosaurs (; from Greek "pteron" and "sauros", meaning "wing lizard") were flying reptiles of the extinct clade or order Pterosauria. They existed during most of the Mesozoic: from the late Triassic to the end of the Cretaceous (228 to 66 million years ago). Pterosaurs are the earliest vertebrates known to have evolved powered flight. Their wings were formed by a membrane of skin, muscle, and other tissues stretching from the ankles to a dramatically lengthened fourth finger.

There were two major types of pterosaurs. Basal pterosaurs (also called 'non-pterodactlyoid pterosaurs' or ‘rhamphorhynchoids’) were smaller animals with fully toothed jaws and, typically, long tails. Their wide wing membranes probably included and connected the hind legs. On the ground, they would have had an awkward sprawling posture, but their joint anatomy and strong claws would have made them effective climbers, and they may have lived in trees. Basal pterosaurs were insectivores or predators on small vertebrates. Later pterosaurs (pterodactyloids) evolved many sizes, shapes, and lifestyles. Pterodactlyoids had narrower wings with free hind limbs, highly reduced tails, and long necks with large heads. On the ground, pterodactyloids walked well on all four limbs with an upright posture, standing plantigrade on the hind feet and folding the wing finger upward to walk on the three-fingered "hand." They could take off from the ground, and fossil trackways show at least some species were able to run and wade or swim. Their jaws had horny beaks, and some groups lacked teeth. Some groups developed elaborate head crests with sexual dimorphism. 

Pterosaurs sported coats of hair-like filaments known as pycnofibers, which covered their bodies and parts of their wings. Pycnofibers grew in several forms, from simple filaments to branching down feathers. These are homologous to the down feathers of birds and some dinosaurs, suggesting that early feathers evolved in the common ancestor of pterosaurs and dinosaurs, possibly as insulation. In life, pterosaurs would have had smooth or fluffy coats that did not resemble bird feathers. They were warm-blooded (endothermic) active animals. The respiratory system had efficient unidirectional "flow-through" breathing using air sacs, which hollowed out their bones to an extreme extent. Pterosaurs spanned a wide range of adult sizes, from the very small anurognathids to the largest known flying creatures of all time, including "Quetzalcoatlus" and "Hatzegopteryx", which reached wingspans of at least nine metres. The combination of endothermy, a good oxygen supply and strong muscles allowed pterosaurs to be powerful and capable flyers.

Pterosaurs are often referred to by popular media or the general public as "flying dinosaurs", but dinosaurs are defined as the descendants of the last common ancestor of the Saurischia and Ornithischia, which excludes the pterosaurs. Pterosaurs are nonetheless more closely related to birds and other dinosaurs than to crocodiles or any other living reptile, though they are not bird ancestors. Pterosaurs are also colloquially referred to as "pterodactyls", particularly in fiction and by journalists. However, technically, "pterodactyl" only refers to members of the genus "Pterodactylus", and more broadly to members of the suborder Pterodactyloidea of the pterosaurs.

Pterosaurs had a variety of lifestyles. Traditionally seen as fish-eaters, the group is now understood to have included hunters of land animals, insectivores, fruit eaters and even predators of other pterosaurs. They reproduced by means of eggs, some fossils of which have been discovered.

The anatomy of pterosaurs was highly modified from their reptilian ancestors by the adaptation to flight. Pterosaur bones were hollow and air-filled, like those of birds. This provided a higher muscle attachment surface for a given skeletal weight. The bone walls were often paper-thin. They had a large and keeled breastbone for flight muscles and an enlarged brain able to coordinate complex flying behaviour. Pterosaur skeletons often show considerable fusion. In the skull, the sutures between elements disappeared. In some later pterosaurs, the backbone over the shoulders fused into a structure known as a notarium, which served to stiffen the torso during flight, and provide a stable support for the shoulder blade. Likewise, the sacral vertebrae could form a single synsacrum while the pelvic bones fused also.

Basal pterosaurs include the clades Dimorphodontidae ("Dimorphodon"), Campylognathididae ("Eudimorphodon", "Campyognathoides"), and Rhamphorhynchidae ("Rhamphorhynchus", "Scaphognathus"). 

Pterodactyloids include the clades Ornithocheiroidea ("Istiodactylus", "Ornithocheirus", "Pteranodon"), Ctenochasmatoidea ("Ctenochasma", "Pterodactylus"), Dsungaripteroidea ("Germnaodactylus", "Dsungaripterus"), and Azhdarchoidea ("Tapejara","Tupuxuara", "Quetzalcoatlus").

The two groups overlapped in time, but the earliest pterosaurs in the fossil record are basal pterosaurs, and the latest pterosaurs are pterodactyloids. 

The position of the clade Anurognathidae ("Anurognathus, Jeholopterus, Vesperopterylus") is debated. Anurognathids (frog-headed pterosaurs) were highly specialized. Small flyers with shortened jaws and a wide gape, some had large eyes suggesting nocturnal or crepescular habits, mouth bristles, and feet adapted for clinging. Parallel adaptations are seen in birds and bats that prey on insects in flight. 

Pterosaurs had a wide range of sizes. Generally they were rather large. Even the smallest species had a wingspan no less than . The most sizeable forms represent the largest known animals ever to fly, with wingspans of up to .

Standing, such giants could reach the height of a modern giraffe. Traditionally, it was assumed that pterosaurs were extremely light relative to their size. Later, it was understood that this would imply unrealistically low densities of their soft tissues. Some modern estimates therefore extrapolate a weight of up to 250 kilogrammes for the largest species.

Compared to the other vertebrate flying groups, the birds and bats, pterosaur skulls were typically quite large. Most pterosaur skulls had elongated jaws. Their skull bones tend to be fused in adult individuals. Early pterosaurs often had heterodont teeth, varying in build, and some still had teeth in the palate. In later groups the teeth mostly became conical. Front teeth were often longer, forming a "prey grab" in transversely expanded jaw tips, but size and position were very variable among species. With the derived Pterodactyloidea, the skulls became even more elongated, sometimes surpassing the combined neck and torso in length. This was caused by a stretching and fusion of the front snout bone, the premaxilla, with the upper jaw bone, the maxilla. Unlike most archosaurs, the nasal and antorbital openings of pterodactyloid pterosaurs merged into a single large opening, called the "nasoantorbital fenestra". This feature likely evolved to lighten the skull for flight. In contrast, the bones behind the eye socket contracted and rotated, strongly inclining the rear skull and bringing the jaw joint forward. The braincase was relatively large for reptiles.

In some cases, fossilized keratinous beak tissue has been preserved, though in toothed forms, the beak is small and restricted to the jaw tips and does not involve the teeth. Some advanced beaked forms were toothless, such as the Pteranodontidae and Azhdarchidae, and had larger, more extensive, and more bird-like beaks. Some groups had specialised tooth forms. The Istiodactylidae had recurved teeth for eating meat. Ctenochasmatidae used combs of numerous needle-like teeth for filter feeding; "Pterodaustro" could have over a thousand bristle-like teeth. Dsungaripteridae covered their teeth with jawbone tissue for a crushing function. If teeth were present, they were placed in separate tooth sockets. Replacement teeth were generated behind, not below, the older teeth.

The public image of pterosaurs is defined by their elaborate head crests. This was influenced by the distinctive backward-pointing crest of the well-known "Pteranodon". The main positions of such crests are the front of the snout, as an outgrowth of the premaxillae, or the rear of the skull as an extension of the parietal bones in which case it is called a "supraoccipital crest". Front and rear crests can be present simultaneously and might be fused into a single larger structure, the most expansive of which is shown by the Tapejaridae. "Nyctosaurus" sported a bizarre antler-like crest. The crests were only a few millimetres thin transversely. The bony crest base would typically be extended by keratinous or other soft tissue.

Since the 1990s, new discoveries and a more thorough study of old specimens have shown that crests are far more widespread among pterosaurs than previously assumed. That they were extended by or composed completely of keratin, which does not fossilize easily, had misled earlier research. For "Pterorhynchus" and "Pterodactylus", the true extent of these crests has only been uncovered using ultraviolet photography. While fossil crests used to be restricted to the more advanced Pterodactyloidea, "Pterorhynchus" and "Austriadactylus" show that even some early pterosaurs possessed them.

Like the upper jaws, the paired lower jaws of pterosaurs were very elongated. In advanced forms, they tended to be shorter than the upper cranium because the jaw joint was in a more forward position. The front lower jaw bones, the dentaries or "ossa dentalia", were at the tip tightly fused into a central symphysis. This made the lower jaws function as a single connected whole, the mandible. The symphysis was often very thin tranversely and long, accounting for a considerable part of the jaw length, up to 60%. If a crest was present on the snout, the symphysis could feature a matching mandible crest, jutting out to below. Toothed species also bore teeth in their dentaries. The mandible opened and closed in a simple vertical or "orthal" up-and-down movement.

The vertebral column of pterosaurs numbered between thirty-four and seventy vertebrae. The vertebrae in front of the tail were "procoelous": the cotyle (front of the vertebral body) was concave and into it fitted a convex extension at the rear of the preceding vertebra, the condyle. Advanced pterosaurs are unique in possessing special processes projecting adjacent to their condyle and cotyle, the exapophyses, and the cotyle also may possess a small prong on its midline called a hypapophysis.

The neck of pterosaurs was relatively long and straight. In pterodactyloids, the neck is typically longer than the torso. This length is not caused by an increase of the number of vertebrae, which is invariably seven. Some researchers include two transitional "cervicodorsals" which brings the number to nine. Instead, the vertebrae themselves became more elongated, up to eight times longer than wide. Nevertheless, the cervicals were wider than high, implying a better vertical than horizontal neck mobility. Pterodactyloids have lost all neck ribs. Pterosaur necks were probably rather thick and well-muscled, especially vertically.

The torso was relatively short and egg-shaped. The vertebrae in the back of pterosaurs originally might have numbered eighteen. With advanced species a growing number of these tended to be incorporated into the sacrum. Such species also often show a fusion of the front dorsal vertebrae into a rigid whole which is called the notarium after a comparable structure in birds. This was an adaptation to withstand the forces caused by flapping the wings. The notarium included three to seven vertebrae, depending on the species involved but also on individual age. These vertebrae could be connected by tendons or a fusion of their neural spines into a "supraneural plate". Their ribs also would be tightly fused into the notarium. In general, the ribs are double-headed. The sacrum consisted of three to ten sacral vertebrae. They too, could be connected via a supraneural plate that, however, would not contact the notarium.

The tails of pterosaurs were always rather slender. This means that the caudofemoralis retractor muscle which in most basal Archosauria provides the main propulsive force for the hindlimb, was relatively unimportant. The tail vertebrae were amphicoelous, the vertebral bodies on both ends being concave. Early species had long tails, containing up to fifty caudal vertebrae, the middle ones stiffened by elongated articulation processes, the zygapophyses, and chevrons. Such tails acted as rudders, sometimes ending at the rear in a vertical diamond-shaped or oval vane. In pterodactyloids, the tails were much reduced and never stiffened, with some species counting as few as ten vertebrae.

The shoulder girdle was a strong structure that transferred the forces of flapping flight to the thorax. It was probably covered by thick muscle layers. The upper bone, the shoulder blade, was a straight bar. It was connected to a lower bone, the coracoid that is relatively long in pterosaurs. In advanced species, their combined whole, the scapulocoracoid, was almost vertically oriented. The shoulder blade in that case fitted into a recess in the side of the notarium, while the coracoid likewise connected to the breastbone. This way, both sides together made for a rigid closed loop, able to withstand considerable forces. A peculiarity was that the breastbone connections of the coracoids often were asymmetrical, with one coracoid attached in front of the other. In advanced species the shoulder joint had moved from the shoulder blade to the coracoid. The joint was saddle-shaped and allowed considerable movement to the wing. It faced sideways and somewhat upwards.

The breastbone, formed by fused paired "sterna", was wide. It had only a shallow keel. Via sternal ribs, it was at its sides attached to the dorsal ribs. At its rear, a row of belly ribs or gastralia was present, covering the entire belly. To the front, a long point, the "cristospina", jutted obliquely upwards. The rear edge of the breastbone was the deepest point of the thorax. Clavicles or interclavicles were completely absent.

Pterosaur wings were formed by bones and membranes of skin and other tissues. The primary membranes attached to the extremely long fourth finger of each arm and extended along the sides of the body. Where they ended has been very controversial but since the 1990s a dozen specimens with preserved soft tissue have been found that seem to show they attached to the ankles. The exact curvature of the trailing edge, however, is still equivocal.

While historically thought of as simple leathery structures composed of skin, research has since shown that the wing membranes of pterosaurs were highly complex dynamic structures suited to an active style of flight. The outer wings (from the tip to the elbow) were strengthened by closely spaced fibers called "actinofibrils". The actinofibrils themselves consisted of three distinct layers in the wing, forming a crisscross pattern when superimposed on one another. The function of the actinofibrils is unknown, as is the exact material from which they were made. Depending on their exact composition (keratin, muscle, elastic structures, etc.), they may have been stiffening or strengthening agents in the outer part of the wing. The wing membranes also contained a thin layer of muscle, fibrous tissue, and a unique, complex circulatory system of looping blood vessels. The combination of actinofibrils and muscle layers may have allowed the animal to adjust the wing slackness and camber.

As shown by cavities in the wing bones of larger species and soft tissue preserved in at least one specimen, some pterosaurs extended their system of respiratory air sacs into the wing membrane.

The pterosaur wing membrane is divided into three basic units. The first, called the "propatagium" ("fore membrane"), was the forward-most part of the wing and attached between the wrist and shoulder, creating the "leading edge" during flight. The "brachiopatagium" ("arm membrane") was the primary component of the wing, stretching from the highly elongated fourth finger of the hand to the hindlimbs. Finally, at least some pterosaur groups had a membrane that stretched between the legs, possibly connecting to or incorporating the tail, called the uropatagium; the extent of this membrane is not certain, as studies on "Sordes" seem to suggest that it simply connected the legs but did not involve the tail (rendering it a cruropatagium). A common interpretation is that non-pterodactyloid pterosaurs had a broader uro/cruropatagium stretched between their long fifth toes, with pterodactyloids, lacking such toes, only having membranes running along the legs.
There has been considerable argument among paleontologists about whether the main wing membranes (brachiopatagia) attached to the hindlimbs, and if so, where. Fossils of the rhamphorhynchoid "Sordes", the anurognathid "Jeholopterus", and a pterodactyloid from the Santana Formation seem to demonstrate that the wing membrane did attach to the hindlimbs, at least in some species. However, modern bats and flying squirrels show considerable variation in the extent of their wing membranes and it is possible that, like these groups, different species of pterosaur had different wing designs. Indeed, analysis of pterosaur limb proportions shows that there was considerable variation, possibly reflecting a variety of wing-plans.

The bony elements of the arm formed a mechanism to support and extend the wing. Near the body, the humerus or upper arm bone is short but powerfully built. It sports a large deltopectoral crest, to which the major flight muscles are attached. Despite the considerable forces exerted on it, the humerus is hollow or pneumatised inside, reinforced by bone struts. The long bones of the lower arm, the ulna and radius, are much longer than the humerus. They were probably incapable of pronation.

A bone unique to pterosaurs, known as the pteroid, connected to the wrist and helped to support the forward membrane (the propatagium) between the wrist and shoulder. Evidence of webbing between the three free fingers of the pterosaur forelimb suggests that this forward membrane may have been more extensive than the simple pteroid-to-shoulder connection traditionally depicted in life restorations. The position of the pteroid bone itself has been controversial. Some scientists, notably Matthew Wilkinson, have argued that the pteroid pointed forward, extending the forward membrane and allowing it to function as an adjustable flap. This view was contradicted in a 2007 paper by Chris Bennett, who showed that the pteroid did not articulate as previously thought and could not have pointed forward, but rather was directed inward toward the body as traditionally interpreted. David Peters in 2009 proposed that the pteroid articulated with the 'saddle' of the radiale (proximal syncarpal) and both the pteroid and preaxial carpal were migrated centralia. This seems to be confirmed by specimens of "Changchengopterus pani" and "Darwinopterus linglongtaensis" showing the pteroid in articulation with the proximal syncarpal.

The pterosaur wrist consists of two inner (proximal, at the side of the long bones of the arm) and four outer (distal, at the side of the hand) carpals (wrist bones), excluding the pteroid bone, which may itself be a modified distal carpal. The proximal carpals are fused together into a "syncarpal" in mature specimens, while three of the distal carpals fuse to form a distal syncarpal. The remaining distal carpal, referred to here as the medial carpal, but which has also been termed the distal lateral, or pre-axial carpal, articulates on a vertically elongate biconvex facet on the anterior surface of the distal syncarpal. The medial carpal bears a deep concave fovea that opens anteriorly, ventrally and somewhat medially, within which the pteroid articulates, according to Wilkinson.

In derived pterodactyloids like pteranodontians and azhdarchoids, metacarpals I-III are small and do not connect to the carpus, instead hanging in contact with the fourth metacarpal. With these derived species, the fourth metacarpal has been enormously elongated, typically equalling or exceeding the length of the long bones of the lower arm. The fifth metacarpal had been lost. In all species, the first to third fingers are much smaller than the fourth, the "wingfinger", and contain two, three and four phalanges respectively. The smaller fingers are clawed, with the ungual size varying among species. In nyctosaurids the forelimb digits besides the wingfinger have been lost altogether. The wingfinger accounts for about half or more of the total wing length. It normally consists of four phalanges. Their relative lengths tend to vary among species, which has often been used to distinguish related forms. The fourth phalanx is usually the shortest. It lacks a claw and has been lost completely by nyctosaurids. It is curved to behind, resulting in a rounded wing tip, which reduces induced drag. The wingfinger is also bent somewhat downwards.

When standing, pterosaurs probably rested on their metacarpals, with the outer wing folded to behind. In this position, the "anterior" sides of the metacarpals were rotated to the rear. This would point the smaller fingers obliquely to behind. According to Bennett, this would imply that the wingfinger, able to describe the largest arc of any wing element, up to 175°, was not folded by flexion but by an extreme extension. The wing was automatically folded when the elbow was bowed.

The pelvis of pterosaurs was of moderate size compared to the body as a whole. Often the three pelvic bones were fused. The ilium was long and low, its front and rear blades projecting horizontally beyond the edges of the lower pelvic bones. Despite this length, the rod-like form of these processes indicates that the hindlimb muscles attached to them were limited in strength. The, in side view narrow, pubic bone fused with the broad ischium into an ischiopubic blade. Sometimes, the blades of both sides were also fused, closing the pelvis from below and forming the pelvic canal. The hip joint was not perforated and allowed considerable mobility to the leg. It was directed obliquely upwards, preventing a perfectly vertical position of the leg.

The front of the pubic bones articulated with a unique structure, the paired prepubic bones. Together these formed a cusp covering the rear belly, between the pelvis and the belly ribs. The vertical mobility of this element suggests a function in breathing, compensating the relative rigidity of the chest cavity.

The hindlimbs of pterosaurs were strongly built, yet relative to their wingspans smaller than those of birds. They were long in comparison to the torso length. The thighbone was rather straight, with the head making only a small angle with the shaft. This implies that the legs were not held vertically below the body but were somewhat sprawling. The shinbone was often fused with the upper ankle bones into a tibiotarsus that was longer than the thighbone. It could attain a vertical position when walking. The calf bone tended to be slender, especially at its lower end that in advanced forms did not reach the ankle, sometimes reducing total length to a third. Typically it was fused to the shinbone. The ankle was a simple, "mesotarsal", hinge. The, rather long and slender, metatarsus was always splayed to some degree. The foot was plantigrade, meaning that during the walking cycle the sole of the metatarsus was pressed onto the soil.

There was a clear difference between early pterosaurs and advanced species regarding the form of the fifth digit. Originally, the fifth metatarsal was robust and not very shortened. It was connected to the ankle in a higher position than the other metatsarsals. It bore a long, and often curved, mobile clawless fifth toe consisting of two phalanges. The function of this element has been enigmatic. It used to be thought that the animals slept upside-down like bats, hanging from branches and using the fifth toes as hooks. Another hypothesis held that they stretched the brachiopatagia, but in articulated fossils the fifth digits are always flexed towards the tail. Later it became popular to assume that these toes extended an uropatagium or cruropatagium between them. As the fifth toes were on the outside of the feet, such a configuration would only have been possible if these rotated their fronts outwards in flight. Such a rotation could be caused by an abduction of the thighbone, meaning that the legs would be spread. This would also turn the feet into a vertical position. They then could act as rudders to control jaw. Some specimens show membranes between the toes, allowing them to function as flight control surfaces. The (cr)uroptagium would control pitch. When walking the toes could flex upwards to lift the membrane from the ground. In Pterodactyloidea, the fifth metatarsal was much reduced and the fifth toe, if present, little more than a stub. This suggests that their membranes were split, increasing flight manoeuvrability.

The first to fourth toes were long. They had two, three, four and five phalanges respectively. Often the third toe was longest; sometimes the fourth. Flat joints indicate a limited mobility. These toes were clawed but the claws were smaller than the hand claws.

The rare conditions that allowed for the fossilisation of pterosaur remains, sometimes also preserved soft tissues. Modern synchotron or ultraviolet light photography has revealed many traces not visible to the naked eye. These are often imprecisely called "impressions" but mostly consist of petrifications, natural casts and transformations of the original material. They may include horn crests, beaks or claw sheaths as well as the various flight membranes. Exceptionally, muscles were preserved. Skin patches show small round non-overlapping scales on the soles of the feet, the ankles and the ends of the metacarpals. They covered pads cushioning the impact of walking. Scales are unknown from other parts of the body.

Most or all pterosaurs had hair-like filaments known as pycnofibers on the head and torso. The term "pycnofiber", meaning "dense filament", was coined by palaeontologist Alexander Kellner and colleagues in 2009. Pycnofibers were unique structures similar to, but not homologous (sharing a common origin) with, mammalian hair, an example of convergent evolution. A fuzzy integument was first reported from a specimen of "Scaphognathus crassirostris" in 1831 by Georg Augustus Goldfuss, but had been widely doubted. Since the 1990s, pterosaur finds and histological and ultraviolet examination of pterosaur specimens have provided incontrovertible proof: pterosaurs had pycnofiber coats. "Sordes pilosus" (which translates as "hairy demon") and "Jeholopterus ninchengensis" show pycnofibers on the head and body.

The presence of pycnofibers strongly indicates that pterosaurs were endothermic (warm-blooded). They aided thermoregulation, as is common in warm-blooded animals who need insulation to prevent excessive heat-loss. Pycnofibers were flexible, short filaments, about five to seven millimetres long and rather simple in structure with a hollow central canal. Pterosaur pelts might have been comparable in density to many Mesozoic mammals.

Pterosaur filaments could share a common origin with feathers, as speculated in 2002 by Czerkas and Ji. In 2009, Kellner concluded that pycnofibers were structured similarly to theropod proto-feathers. Others were unconvinced, considering the difference with the "quills" found on many of the bird-like maniraptoran specimens too fundamental.

A 2018 study of the remains of two small Jurassic-age pterosaurs from Inner Mongolia, China, found that pterosaurs had a wide array of pycnofiber shapes and structures, as opposed to the homogeneous structures that had generally been assumed to cover them. Some of these had frayed ends, very similar in structure to four different feather types known from birds or other dinosaurs but almost never known from pterosaurs prior to the study, suggesting homology.

Pterosaur fossils are very rare, due to their light bone construction. Complete skeletons can generally only be found in geological layers with exceptional preservation conditions, the so-called "Lagerstätten". The pieces from one such "Lagerstätte", the Late Jurassic Solnhofen Limestone in Bavaria, became much sought after by rich collectors. In 1784, the Italian naturalist Cosimo Alessandro Collini was the first scientist in history to describe a pterosaur fossil. At that time the concepts of evolution and extinction were only imperfectly developed. The bizarre build of the pterosaur was therefore shocking, as it could not clearly be assigned to any existing animal group. The discovery of pterosaurs would thus play an important rôle in the progress of modern paleontology and geology. If such creatures were still alive, only the sea was a credible habitat and Collini suggested it might be a swimming animal that used its long front limbs as paddles. A few scientists continued to support the aquatic interpretation even until 1830, when the German zoologist Johann Georg Wagler suggested that "Pterodactylus" used its wings as flippers and was affiliated with Ichthyosauria and Plesiosauria. 

In 1800, Johann Hermann first suggested that it represented a flying creature in a letter to Georges Cuvier. Cuvier agreed in 1801, understanding it was an extinct flying reptile. In 1809, he coined the name "Ptéro-Dactyle", "wing-finger". This was in 1815 Latinised to "Pterodactylus". At first most species were assigned to this genus and ultimately "pterodactyl" was popularly and incorrectly applied to all members of Pterosauria. Today, paleontologists limit the term to the genus "Pterodactylus" or members of the Pterodactyloidea.

In 1812 and 1817, Samuel Thomas von Soemmerring redescribed the original specimen and an additional one. He saw them as affiliated to birds and bats. Although he was mistaken in this, his "bat model" would be very influential during the nineteenth century. In 1843, Edward Newman thought pterosaurs were flying marsupials. As the bat model correctly depicted pterosaurs as furred and warm-blooded, it better approached the true physiology of pterosaurs than Cuvier's "reptile model". In 1834, Johann Jakob Kaup coined the term Pterosauria.

In 1828, Mary Anning in England found the first pterosaur genus outside Germany, by Richard Owen named as "Dimorphodon", also the first non-pterodactyloid pterosaur known. Later in the century, the Early Cretaceous Cambridge Greensand produced thousands of pterosaur fossils, that however, were of poor quality, consisting mostly of strongly eroded fragments. Based on these, nevertheless numerous genera and species would be named. Many were described by Harry Govier Seeley, at the time the main English expert on the subject, who also wrote the first pterosaur book, "Ornithosauria", and in 1901 the first popular book, "Dragons of the Air". Seeley thought that pterosaurs were warm-blooded and dynamic creatures, closely related to birds. Earlier, the evolutionist St. George Jackson Mivart had suggested pterosaurs were the direct ancestors of birds. Owen opposed the views of both men, seeing pterosaurs as cold-blooded "true" reptiles.

In the US, Othniel Charles Marsh in 1870 discovered "Pteranodon" in the Niobrara Chalk, then the largest known pterosaur, the first toothless one and the first from America. These layers too rendered thousands of fossils, also including relatively complete skeletons that were three-dimensionally preserved instead of being strongly compressed as with the Solnhofen specimens. This led to a much better understanding of many anatomical details, such as the hollow nature of the bones.

Meanwhile, finds from the Solnhofen had continued, accounting for the majority of complete high quality specimens discovered. They allowed to identify most new basal taxa, such as "Rhamphorhynchus", "Scaphognathus" and "Dorygnathus". This material gave birth to a German school of pterosaur research, which saw flying reptiles as the warm-blooded, furry and active Mesozoic counterparts of modern bats and birds. In 1882, Marsh and Karl Alfred Zittel published studies about the wing membranes of specimens of "Rhamphorhynchus". German studies continued well into the 1930s, describing new species such as "Anurognathus". In 1927, Ferdinand Broili discovered hair follicles in pterosaur skin, and paleoneurologist Tilly Edinger determined that the brains of pterosaurs more resembled those of birds than modern cold-blooded reptiles.

In contrast, English and American paleontologists by the middle of the twentieth century largely lost interest in pterosaurs. They saw them as failed evolutionary experiments, cold-blooded and scaly, that hardly could fly, the larger species only able to glide, being forced to climb trees or throw themselves from cliffs to achieve a take-off. In 1914, for the first time pterosaur aerodynamics were quantitatively analysed, by Ernest Hanbury Hankin and David Meredith Seares Watson, but they interpreted "Pteranodon" as a pure glider. Little research was done on the group during the 1940s and 1950s.

The situation for dinosaurs was comparable. From the 1960s onwards, a dinosaur renaissance took place, a quick increase in the number of studies and critical ideas, influenced by the discovery of additional fossils of "Deinonychus", whose spectacular traits refuted what had become entrenched orthodoxy. In 1970, likewise the description of the furry pterosaur "Sordes" began what Robert Bakker named a renaissance of pterosaurs. Especially Kevin Padian propagated the new views, publishing a series of studies depicting pterosaurs as warm-blooded, active and running animals. This coincided with a revival of the German school through the work of Peter Wellnhofer, who in 1970s laid the foundations of modern pterosaur science. In 1978, he published the first pterosaur textbook, the "Handbuch der Paläoherptologie, Teil 19: Pterosauria", and in 1991 the second ever popular science pterosaur book, the "Encyclopedia of Pterosaurs".

This development accelerated through the exploitation of two new "Lagerstätten". During the 1970s, the Early Cretaceous Santana Formation in Brazil began to produce chalk nodules that, though often limited in size and the completeness of the fossils they contained, perfectly preserved three-dimensional pterosaur skeletal parts. German and Dutch institutes bought such nodules from fossil poachers and prepared them in Europe, allowing their scientists to describe many new species and revealing a whole new fauna. Soon, Brazilian researchers, among them Alexander Kellner, intercepted the trade and named even more species.

Even more productive was the Early Cretaceous Chinese Jehol Biota of Liaoning that since the 1990s has brought forth hundreds of exquisitely preserved two-dimensional fossils, often showing soft tissue remains. Chinese researchers such as Lü Junchang have again named many new taxa. As discoveries also increased in other parts of the world, a sudden surge in the total of named genera took place. By 2009, when they had increased to about ninety, this growth showed no sign of levelling-off. In 2013, M.P. Witton indicated that the number of discovered pterosaur species had risen to 130. Over ninety percent of known taxa has been named during the "renaissance". Many of these were from groups the existence of which had been unknown. Advances in computing power allowed to determine their complex relationships through the quantitative method of cladistics. New and old fossils yielded much more information when subjected to modern ultraviolet light or roentgen photography, or CAT-scans. Insights from other fields of biology were applied to the data obtained. All this resulted in a substantial progress in pterosaur research, rendering older accounts in popular science books completely outdated.

Because pterosaur anatomy has been so heavily modified for flight, and immediate transitional fossil predecessors have not so far been described, the ancestry of pterosaurs is not fully understood. The oldest known pterosaurs were already fully adapted to a flying lifestyle. Since Seeley, it was recognised that pterosaurs were likely to have had their origin in the "archosaurs", what today would be called the Archosauromorpha. In the 1980s, the first cladistic analyses indicated that they more precisely were members of the Ornithodira (or Avemetatarsalia), perhaps closely related to "Scleromochlus". As this would make them also rather close relations of the dinosaurs, these results were seen by Kevin Padian as confirming his interpretation of pterosaurs as bipedal warm-blooded animals. Because these early analyses were based on a limited number of taxa and characters, their results were inherently uncertain. Several influential researchers rejecting Padian's conclusions felt justified to offer alternative hypotheses. David Unwin proposed an ancestry among the basal Archosauromorpha, or at least basal archosauriforms, like "Euparkeria", or among the protorosaurs. Some of these seemed to be good candidates for a rôle as close pterosaur relatives because they were long-limbed, such as "Sharovipteryx", a gliding form with membranes.

Two researchers, S. Christopher Bennett in 1996, and paleoartist David Peters in 2000, published analyses finding pterosaurs to be protorosaurs or closely related to them. Peters however, for data gathering used a technique called DGS, which involves applying the digital tracing features of photo editing software to images of pterosaur fossils. Bennett only recovered pterosaurs as close relatives of the protorosaurs after removing characteristics of the hindlimb from his analysis, to test the possibility of convergent evolution between pterosaurs and dinosaurs. Dave Hone and Michael Benton in 2007 could not reproduce this result, finding pterosaurs to be closely related to dinosaurs even without hindlimb characters. They criticized David Peters for drawing conclusions without access to the primary evidence, that is, the pterosaur fossils themselves. Hone and Benton concluded that, although more basal pterosauromorphs are needed to clarify their relationships, current evidence indicates that pterosaurs are ornithodirans, as either the sister group of "Scleromochlus" or a branch between the latter and "Lagosuchus". Sterling Nesbitt in 2011, benefiting from far more data, found strong support for a clade composed of "Scleromochlus" and pterosaurs.

A related problem is the origin of pterosaur flight. Like with birds, hypotheses can be ordered into two main varieties: "ground up" or "tree down". Climbing a tree would cause height and gravity provide both the energy and a strong selection pressure for incipient flight. Rupert Wild in 1983 proposed a hypothetical "propterosaurus": a lizard-like arboreal animal developing a membrane between its limbs, first to safely parachute and then, gradually elongating the fourth finger, to glide. However, the later cladistic results did not well fit this model. Neither protorosaurs nor ornithodirans are all that lizard-like. Furthermore, the transition between gliding and flapping flight is not well-understood. More recent studies on basal pterosaur hindlimb morphology seem to vindicate a connection to "Scleromochlus". Like this archosaur, basal pterosaur lineages have plantigrade hindlimbs that show adaptations for saltation.

It was once thought that competition with early bird species might have resulted in the extinction of many of the pterosaurs. Part of this is due to the fact it used to be thought that by the end of the Cretaceous, only large species of pterosaurs were present (no longer true; see below). The smaller species were thought to have become extinct, their niche filled by birds. However, pterosaur decline (if actually present) seems unrelated to bird diversity, as ecological overlap between the two groups appears to be minimal. In fact, at least some avian niches were reclaimed by pterosaurs prior to the KT event. At the end of the Cretaceous period, the Cretaceous–Paleogene extinction event, which wiped out all non-avian dinosaurs and most avian dinosaurs as well, and many other animals, seems also to have taken the pterosaurs.

In the early 2010s, several new pterosaur taxa were discovered dating to the Campanian/Maastrichtian, such as the ornithocheirids "Piksi" and "Ornithocheirus", possible pteranodontids and nyctosaurids, several tapejarids and the indeterminate non-azhdarchid "Navajodactylus". Small azhdarchoid pterosaurs were also present in the Campanian. This suggests that late Cretaceous pterosaur faunas were far more diverse than previously thought, possibly not even having declined significantly from the early Cretaceous.

Small sized pterosaur species apparently were present in the Csehbánya Formation, indicating a higher diversity of Late Cretaceous pterosaurs than previously accounted for. The recent findings of a small cat-sized adult azhdarchid further indicate that small pterosaurs from the Late Cretaceous might actually have simply been rarely preserved in the fossil record, helped by the fact that there is a strong bias against terrestrial small sized vertebrates such as juvenile dinosaurs, and that their diversity might actually have been much larger than previously thought.

At least some non-pterodactyloid pterosaurs survived into the Late Cretaceous, postulating a lazarus taxa situation for late Cretaceous pterosaur faunas.

In phylogenetic taxonomy, the clade Pterosauria has usually been defined as node-based and anchored to several extensively studied taxa as well as those thought to be primitive. One 2003 study defined Pterosauria as "The most recent common ancestor of the Anurognathidae, "Preondactylus" and "Quetzalcoatlus" and all their descendants." However, these types of definition would inevitably leave any related species that are slightly more primitive out of the Pterosauria. To remedy this, a new definition was proposed that would anchor the name not to any particular species but to an anatomical feature, the presence of an enlarged fourth finger that supports a wing membrane. A broader clade, Pterosauromorpha, has been defined as all ornithodirans more closely related to pterosaurs than to dinosaurs.

The internal classification of pterosaurs has historically been difficult, because there were many gaps in the fossil record. Starting from the 21st century, new discoveries are now filling in these gaps and giving a better picture of the evolution of pterosaurs. Traditionally, they were organized into two suborders: the Rhamphorhynchoidea, a "primitive" group of long-tailed pterosaurs, and the Pterodactyloidea, "advanced" pterosaurs with short tails. However, this traditional division has been largely abandoned. Rhamphorhynchoidea is a paraphyletic (unnatural) group, since the pterodactyloids evolved directly from them and not from a common ancestor, so, with the increasing use of cladistics, it has fallen out of favor among most scientists.

The precise relationships between pterosaurs is still unsettled. Many studies of pterosaur relationships in the past have included limited data and were highly contradictory. However, newer studies using larger data sets are beginning to make things clearer. The cladogram (family tree) below follows a phylogenetic analysis presented by Andres & Myers in 2013.

The mechanics of pterosaur flight are not completely understood or modeled at this time.

Katsufumi Sato, a Japanese scientist, did calculations using modern birds and concluded that it was impossible for a pterosaur to stay aloft. In the book "Posture, Locomotion, and Paleoecology of Pterosaurs" it is theorized that they were able to fly due to the oxygen-rich, dense atmosphere of the Late Cretaceous period. However, both Sato and the authors of "Posture, Locomotion, and Paleoecology of Pterosaurs" based their research on the now outdated theories of pterosaurs being seabird-like, and the size limit does not apply to terrestrial pterosaurs, such as azhdarchids and tapejarids. Furthermore, Darren Naish concluded that atmospheric differences between the present and the Mesozoic were not needed for the giant size of pterosaurs.

Another issue that has been difficult to understand is how they took off. Earlier suggestions were that pterosaurs were largely cold-blooded gliding animals, deriving warmth from the environment like modern lizards, rather than burning calories. In this case, it was unclear how the larger ones of enormous size, with an inefficient cold-blooded metabolism, could manage a bird-like takeoff strategy, using only the hind limbs to generate thrust for getting airborne. Later research shows them instead as being warm-blooded and having powerful flight muscles, and using the flight muscles for walking as quadrupeds. Mark Witton of the University of Portsmouth and Mike Habib of Johns Hopkins University suggested that pterosaurs used a vaulting mechanism to obtain flight. The tremendous power of their winged forelimbs would enable them to take off with ease. Once aloft, pterosaurs could reach speeds of up to and travel thousands of kilometres.

In 1985, the Smithsonian Institution commissioned aeronautical engineer Paul MacCready to build a half-scale working model of "Quetzalcoatlus northropi". The replica was launched with a ground-based winch. It flew several times in 1986 and was filmed as part of the Smithsonian's IMAX film "On the Wing".

A 2009 study showed that pterosaurs had a lung-and-air-sac system and a precisely controlled skeletal breathing pump, which supports a flow-through pulmonary ventilation model in pterosaurs, analogous to that of birds. The presence of a subcutaneous air sac system in at least some pterodactyloids would have further reduced the density of the living animal. Like modern crocodilians, pterosaurs appeared to have had a hepatic piston, seeing as their shoulder-pectoral girdles were too inflexible to move the sternum as in birds, and they possessed strong gastralia. Thus, their respiratory system had characteristics comparable to both modern archosaur clades.

An X-ray study of pterosaur brain cavities revealed that the animals ("Rhamphorhynchus muensteri" and "Anhanguera santanae") had massive flocculi. The flocculus is a brain region that integrates signals from joints, muscles, skin and balance organs. The pterosaurs' flocculi occupied 7.5% of the animals' total brain mass, more than in any other vertebrate. Birds have unusually large flocculi compared with other animals, but these only occupy between 1 and 2% of total brain mass.

The flocculus sends out neural signals that produce small, automatic movements in the eye muscles. These keep the image on an animal's retina steady. Pterosaurs may have had such a large flocculus because of their large wing size, which would mean that there was a great deal more sensory information to process. The low relative mass of the flocculi in birds is also a result of birds having a much larger brain overall; though this has been considered an indication that pterosaurs lived in a structurally simpler environment or had less complex behaviour compared to birds, recent studies of crocodilians and other reptiles show that it is common for sauropsids to achieve high intelligence levels with small brains. Studies on the endocast of "Allkaruen" show that brain evolution in pterodactyloids was a modular process.

Pterosaurs' hip sockets are oriented facing slightly upwards, and the head of the femur (thigh bone) is only moderately inward facing, suggesting that pterosaurs had an erect stance. It would have been possible to lift the thigh into a horizontal position during flight, as gliding lizards do.

There was considerable debate whether pterosaurs ambulated as quadrupeds or as bipeds. In the 1980s, paleontologist Kevin Padian suggested that smaller pterosaurs with longer hindlimbs, such as "Dimorphodon", might have walked or even ran bipedally, in addition to flying, like road runners. However, a large number of pterosaur trackways were later found with a distinctive four-toed hind foot and three-toed front foot; these are the unmistakable prints of pterosaurs walking on all fours.

Fossil footprints show that pterosaurs stood with the entire foot in contact with the ground (plantigrade), in a manner similar to many mammals like humans and bears. Footprints from azhdarchids and several unidentified species show that pterosaurs walked with an erect posture with their four limbs held almost vertically beneath the body, an energy-efficient stance used by most modern birds and mammals, rather than the sprawled limbs of modern reptiles. Indeed, erect-limbs may be omnipresent in pterosaurs.

Though traditionally depicted as ungainly and awkward when on the ground, the anatomy of some pterosaurs (particularly pterodactyloids) suggests that they were competent walkers and runners. Early pterosaurs have long been considered particularly cumbersome locomotors due to the presence of large cruropatagia, but they too appear to have been generally efficient on the ground.

The forelimb bones of azhdarchids and ornithocheirids were unusually long compared to other pterosaurs, and, in azhdarchids, the bones of the arm and hand (metacarpals) were particularly elongated. Furthermore, as a whole, azhdarchid front limbs were proportioned similarly to fast-running ungulate mammals. Their hind limbs, on the other hand, were not built for speed, but they were long compared with most pterosaurs, and allowed for a long stride length. While azhdarchid pterosaurs probably could not run, they would have been relatively fast and energy efficient.

The relative size of the hands and feet in pterosaurs (by comparison with modern animals such as birds) may indicate the type of lifestyle pterosaurs led on the ground. Azhdarchid pterosaurs had relatively small feet compared to their body size and leg length, with foot length only about 25%–30% the length of the lower leg. This suggests that azhdarchids were better adapted to walking on dry, relatively solid ground. "Pteranodon" had slightly larger feet (47% the length of the tibia), while filter-feeding pterosaurs like the ctenochasmatoids had very large feet (69% of tibial length in "Pterodactylus", 84% in "Pterodaustro"), adapted to walking in soft muddy soil, similar to modern wading birds. Though clearly forelimb-based launchers, basal pterosaurs have hindlimbs well adapted for hopping, suggesting a connection with archosaurs such as "Scleromochlus".

Tracks made by ctenochasmatoids indicate that these pterosaurs swam using their hindlimbs. In general, these have large hindfeet and long torsos, indicating that they were probably more adapted for swimming than other pterosaurs. Pteranodontians conversely have several speciations in their humeri interpreted to have been suggestive of a water-based version of the typical quadrupedal launch, and several like boreopterids must have foraged while swimming, as they seem incapable of frigatebird-like aerial hawking. These adaptations are also seen in terrestrial pterosaurs like azhdarchids, which presumably still needed to launch from water in case they found themselves in it. The nyctosaurid "Alcione" may display adaptations for wing-propelled diving like modern gannets and tropicbirds.

Traditionally, almost all pterosaurs were seen as surface-feeding piscivores or fish-eaters, a view that still dominates popular science. Today, many pterosaurs groups are thought to have been terrestrial carnivores, omnivores or insectivores.

Early-on it was recognised that the small Anurognathidae were nocturnal, aerial insectivores. With highly flexible joints on the wing finger, a broad, triangular wing shape, large eyes and short tail, these pterosaurs were likely analogous to nightjars or extant insectivorous bats, being capable of high manoeuvrability at relatively low speeds.

Interpretations of the habits of basal groups have changed profoundly. "Dimorphodon", envisioned as a puffin analogue in the past, is indicated by its jaw structure, gait, and poor flight capabilities, as a terrestrial/semiarboreal predator of small mammals, squamates, and large insects. Its robust dentition caused "Campylognathoides" to be seen as a generalist or a terrestrial predator of small vertebrates, but the highly robust humerus and high-aspect wing morphology, suggest it may have been capable of grabbing prey on the wing. The small insectivorous "Carniadactylus" and the larger "Eudimorphodon" were highly aerial animals and fast, agile flyers with long robust wings. "Eudimorphodon" has been found with fish remains in its stomach, but its dentition suggests an opportunistic diet. Slender-winged "Austriadactylus" and "Caviramus" were likely terrestrial/semiarboreal generalists. "Caviramus" likely had a strong bite force, indicating an adaptation towards hard food items that might have been chewed in view of the tooth wear.

Some Rhamphorhynchidae, such as "Rhamphorhynchus" itself or "Dorygnathus", were fish-eaters with long, slender wings, needle-like dentition and long, thin jaws. "Sericipterus", "Scaphognathus" and "Harpactognathus" had more robust jaws and teeth (which were ziphodont, dagger-shaped, in " Sericipterus"), and shorter, broader wings. These were either terrestrial/aerial predators of vertebrates or corvid-like generalists. Wukongopteridae like "Darwinopterus" were first considered aerial predators. Lacking a robust jaw structure or powerful flying muscles, they are now seen as arboreal or semiterrestrial insectivores. "Darwinopterus robustidens", in particular, seems to have been a beetle specialist.

Among pterodactyloids, a greater variation in diet is present. Pteranodontia contained many piscivorous taxa, such as the Ornithocheirae, Boreopteridae, Pteranodontidae and Nyctosauridae. Niche partitioning caused ornithocheirs and the later nyctosaurids to be aerial dip-feeders like today's frigatebirds (with the exception of the plunge-diving adapted "Alcione elainus"), while boreopterids were freshwater diving animals similar to cormorants, and pteranodonts pelagic plunge-divers akin to boobies and gannets. The istiodactylids were likely primarily scavengers. Archaeopterodactyloidea obtained food in coastal or freshwater habitats. "Germanodactylus" and "Pterodactylus" were piscivores, while the Ctenochasmatidae were suspension feeders, using their numerous fine teeth to filter small organisms from shallow water. "Pterodaustro" was adaptated for flamingo-like filter-feeding.

In contrast, Azhdarchoidea mostly were terrestrial pterosaurs. Tapejaridae were arboreal omnivores, supplementing seeds and fruits with small insects and vertebrates. Dsungaripteridae were specialist molluscivores, using their powerful jaws to crush the shells of molluscs and crustaceans. Thalassodromidae were likely terrestrial carnivores. "Thalassodromeus" itself was named after a fishing method known as "skim-feeding", later understood to be biomechanically impossible. Perhaps it pursued relatively large prey, in view of its reinforced jaw joints and relatively high bite force. Azhdarchidae are now understood to be terrestrial predators akin to ground hornbills or some storks, eating any prey item they could swallow whole. "Hatzegopteryx" was a robustly built predator of relatively large prey, including medium-sized dinosaurs. "Alanqa" may have been a specialist molluscivore.

Pterosaurs are known to have been eaten by theropods. In the 1 July 2004 edition of "Nature", paleontologist Eric Buffetaut discusses an early Cretaceous fossil of three cervical vertebrae of a pterosaur with the broken tooth of a spinosaur, most likely "Irritator", embedded in it. The vertebrae are known not to have been eaten and exposed to digestion, as the joints are still articulated.

While very little is known about pterosaur reproduction, it is believed that, similar to all dinosaurs, all pterosaurs reproduced by laying eggs, though such findings are very rare. The first known pterosaur egg was found in the quarries of Liaoning, the same place that yielded feathered dinosaurs. The egg was squashed flat with no signs of cracking, so evidently the eggs had leathery shells, as in modern lizards. This was supported by the description of an additional pterosaur egg belonging to the genus "Darwinopterus", described in 2011, which also had a leathery shell and, also like modern reptiles but unlike birds, was fairly small compared to the size of the mother. In 2014 five unflattened eggs from the species "Hamipterus tianshanensis" were found in an Early Cretaceous deposit in northwest China. Examination of the shells by scanning electron microscopy showed the presence of a thin calcareous eggshell layer with a membrane underneath. A study of pterosaur eggshell structure and chemistry published in 2007 indicated that it is likely pterosaurs buried their eggs, like modern crocodiles and turtles. Egg-burying would have been beneficial to the early evolution of pterosaurs, as it allows for more weight-reducing adaptations, but this method of reproduction would also have put limits on the variety of environments pterosaurs could live in, and may have disadvantaged them when they began to face ecological competition from birds.

A "Darwinopterus" specimen showcases that at least some pterosaurs had a pair of functional ovaries, as opposed to the single functional ovary in birds, dismissing the reduction of functional ovaries as a requirement for powered flight.

Wing membranes preserved in pterosaur embryos are well developed, suggesting that pterosaurs were ready to fly soon after birth. Fossils of pterosaurs only a few days to a week old (called "flaplings") have been found, representing several pterosaur families, including pterodactylids, rhamphorhinchids, ctenochasmatids and azhdarchids. All preserve bones that show a relatively high degree of hardening ("ossification") for their age, and wing proportions similar to adults. In fact, many pterosaur flaplings have been considered adults and placed in separate species in the past. Additionally, flaplings are normally found in the same sediments as adults and juveniles of the same species, such as the "Pterodactylus" and "Rhamphorhynchus" flaplings found in the Solnhofen limestone of Germany, and "Pterodaustro" flaplings from Argentina. All are found in deep aquatic environment far from shore.

It is not known whether pterosaurs practiced any form of parental care, but their ability to fly as soon as they emerged from the egg and the numerous flaplings found in environments far from nests and alongside adults has led most researchers, including Christopher Bennett and David Unwin, to conclude that the young were dependent on their parents for a relatively short period of time, during a period of rapid growth while the wings grew long enough to fly, and then left the nest to fend for themselves, possibly within days of hatching. Alternatively, they may have used stored yolk products for nourishment during their first few days of life, as in modern reptiles, rather than depend on parents for food.

Growth rates of pterosaurs once they hatched varied across different groups. In more primitive, long-tailed pterosaurs ("rhamphorhynchoids"), such as "Rhamphorhynchus", the average growth rate during the first year of life was 130% to 173%, slightly faster than the growth rate of alligators. Growth in these species slowed after sexual maturity, and it would have taken more than three years for "Rhamphorhynchus" to attain maximum size. In contrast, the more advanced, large pterodactyloid pterosaurs, such as "Pteranodon", grew to adult size within the first year of life. Additionally, pterodactyloids had "determinate growth", meaning that the animals reached a fixed maximum adult size and stopped growing.

Comparisons between the scleral rings of pterosaurs and modern birds and reptiles have been used to infer daily activity patterns of pterosaurs. The pterosaur genera "Pterodactylus", "Scaphognathus", and "Tupuxuara" have been inferred to be diurnal, "Ctenochasma", "Pterodaustro", and "Rhamphorhynchus" have been inferred to be nocturnal, and "Tapejara" has been inferred to be cathemeral, being active throughout the day for short intervals. As a result, the possibly fish-eating "Ctenochasma" and "Rhamphorhynchus" may have had similar activity patterns to modern nocturnal seabirds, and the filter-feeding "Pterodaustro" may have had similar activity patterns to modern anseriform birds that feed at night. The differences between activity patterns of the Solnhofen pterosaurs "Ctenochasma", "Rhamphorhynchus", "Scaphognathus", and "Pterodactylus" may also indicate niche partitioning between these genera.

Pterosaurs have been a staple of popular culture for as long as their cousins the dinosaurs, though they are usually not featured as prominently in films, literature or other art. While the depiction of dinosaurs in popular media has changed radically in response to advances in paleontology, a mainly outdated picture of pterosaurs has persisted since the mid 20th century.

The vague generic term "pterodactyl" is often used for these creatures. The animals depicted frequently represent either "Pteranodon" or (non-pterodactyloid) "Rhamphorhynchus", or a fictionalized hybrid of the two. Many children's toys and cartoons feature "pterodactyls" with "Pteranodon"-like crests and long, "Rhamphorhynchus"-like tails and teeth, a combination that never existed in nature. However, at least one pterosaur "did" have both the "Pteranodon"-like crest and teeth: "Ludodactylus", whose name means "toy finger" for its resemblance to old, inaccurate children's toys. Pterosaurs have sometimes been incorrectly identified as (the ancestors of) "birds", though birds are actually theropod dinosaurs, not closely related to pterosaurs.

Pterosaurs were used in fiction in Arthur Conan Doyle's 1912 novel "The Lost World", and subsequent 1925 film adaptation. They appeared in a number of films and television programs since, including the 1933 film "King Kong", and 1966's "One Million Years B.C.". In the latter, animator Ray Harryhausen had to add inaccurate bat-like wing fingers to his stop motion models in order to keep the membranes from falling apart, though this particular error was common in art even before the film was made. The Japanese character Rodan, a fictional giant monster (or "kaiju") which first appeared in the 1956 film "Rodan", is portrayed as an enormous irradiated species of "Pteranodon". Rodan has appeared in multiple "Godzilla" films released during the 1960s, 1970s, 1990s, and 2000s, and also appeared in the 2019 American-produced film "".

After the 1960s, pterosaurs remained mostly absent from notable American film appearances until 2001, with "Jurassic Park III". Paleontologist Dave Hone noted that the pterosaurs in this film had not been significantly updated to reflect modern research. Errors persisting were teeth while toothless "Pteranodon" was intended to be depicted, nesting behavior that was known to be inaccurate by 2001, and leathery wings, rather than the taut membranes of muscle fiber required for pterosaur flight.

In most media appearances, pterosaurs are depicted as piscivores, not reflecting their full dietary variation. They are also often shown as aerial predators similar to birds of prey, grasping human victims with talons on their feet. However, only the small anurognathid "Vesperopterylus" is known to possesses prehensile feet; all other pterosaurs have flat, plantigrade feet with no opposable toes, and the feet are generally proportionally small at least in the case of Pteranodontia.




</doc>
<doc id="24825" url="https://en.wikipedia.org/wiki?curid=24825" title="Pteranodon">
Pteranodon

Pteranodon (; from Greek πτερόν ( pteron, "wing") and ἀνόδων (anodon, "toothless")) is a genus of pterosaur that included some of the largest known flying reptiles, with wingspans over 7 meters (23 feet). They lived during the late Cretaceous geological period of North America in present-day Kansas, Alabama, Nebraska, Wyoming, and South Dakota. More fossil specimens of "Pteranodon" have been found than any other pterosaur, with about 1,200 specimens known to science, many of them well preserved with nearly complete skulls and articulated skeletons. It was an important part of the animal community in the Western Interior Seaway.

"Pteranodon" were pterosaurs, not dinosaurs. By definition, all dinosaurs belong to one of the two groups within Dinosauria, i.e. Saurischia or Ornithischia. As such, this excludes pterosaurs. Nonetheless, "Pteranodon" are frequently featured in dinosaur media and are strongly associated with dinosaurs by the general public. While not dinosaurs, pterosaurs such as "Pteranodon" form a sister clade to dinosaurs within the clade Avemetatarsalia.

"Pteranodon" species are extremely well represented in the fossil record, allowing for detailed descriptions of their anatomy and analysis of their life history. Over 1,000 specimens have been identified, though less than half are complete enough to give researchers good anatomical information. Still, this is more fossils material than is known for any other pterosaur, and it includes both male and female specimens of various age groups and possibly species.

Adult "Pteranodon" specimens from the two major species can be divided into two distinct size classes. The smaller class of specimens have small, rounded head crests and very wide pelvic canals, even wider than those of the much larger size class. The size of the pelvic canal probably allowed the laying of eggs, indicating that these smaller adults are females. The larger size class, representing male individuals, have narrow hips and very large crests, which were probably for display.

Adult male "Pteranodon" were among the largest pterosaurs, and were the largest flying animals known until the late 20th century, when the giant azhdarchid pterosaurs were discovered. The wingspan of an average adult male "Pteranodon" was . Adult females were much smaller, averaging in wingspan. The largest specimen of "Pteranodon longiceps" from the Niobrara Formation measured from wingtip to wingtip. An even larger specimen is known from the Pierre Shale Formation, with a wingspan of , though this specimen may belong to the distinct genus and species "Geosternbergia maysei". While most specimens are found crushed, enough fossils exist to put together a detailed description of the animal.

Methods used to estimate the mass of large male "Pteranodon" specimens (those with wingspans of about 7 meters) have been notoriously unreliable, producing a wide range of estimates from as low as to as high as . In a review of pterosaur size estimates published in 2010, researchers Mark Witton and Mike Habib demonstrated that the latter, largest estimates are almost certainly incorrect given the total volume of a "Pteranodon" body, and could only be correct if the animal "was principally aluminium". Witton and Habib considered the methods used by researchers who obtained smaller mass estimates equally flawed. Most have been produced by scaling modern animals such as bats and birds up to "Pteranodon" size, despite the fact that pterosaurs have vastly different body proportions and soft tissue anatomy from any living animal.

Other distinguishing characteristics that set "Pteranodon" apart from other pterosaurs include narrow neural spines on the vertebrae, plate-like bony ligaments strengthening the vertebrae above the hip, and a relatively short tail in which the last few vertebrae are fused into a long rod. The entire length of the tail was about 3.5% as long as the wingspan, or up to in the largest males.

Unlike earlier pterosaurs, such as "Rhamphorhynchus" and "Pterodactylus", "Pteranodon" had toothless beaks, similar to those of birds. "Pteranodon" beaks were made of solid, bony margins that projected from the base of the jaws. The beaks were long, slender, and ended in thin, sharp points. The upper jaw, which was longer than the lower jaw, was curved upward; while this normally has been attributed only to the upward-curving beak, one specimen (UALVP 24238) has a curvature corresponding with the beak widening towards the tip. While the tip of the beak is not known in this specimen, the level of curvature suggests it would have been extremely long. The unique form of the beak in this specimen led Alexander Kellner to assign it to a distinct genus, "Dawndraco", in 2010.

The most distinctive characteristic of "Pteranodon" is its cranial crest. These crests consisted of skull bones (frontals) projecting upward and backward from the skull. The size and shape of these crests varied due to a number of factors, including age, sex, and species. Male "Pteranodon sternbergi", the older species of the two described to date (and sometimes placed in the distinct genus "Geosternbergia"), had a more vertical crest with a broad forward projection, while their descendants, "Pteranodon longiceps", evolved a narrower, more backward-projecting crest. Females of both species were smaller and bore small, rounded crests. The crests were probably mainly display structures, though they may have had other functions as well.

The wing shape of "Pteranodon" suggests that it would have flown rather like a modern-day albatross. This is based on the fact that "Pteranodon" had a high aspect ratio (wingspan to chord length) similar to that of the albatross — 9:1 for "Pteranodon", compared to 8:1 for an albatross. Albatrosses spend long stretches of time at sea fishing, and use a flight pattern called "dynamic soaring" which exploits the vertical gradient of wind speed near the ocean surface to travel long distances without flapping, and without the aid of thermals (which do not occur over the open ocean the same way they do over land). While most of a "Pteranodon" flight would have depended on soaring, like long-winged seabirds, it probably required an occasional active, rapid burst of flapping, and studies of "Pteranodon" wing loading (the strength of the wings vs. the weight of the body) indicate that they were capable of substantial flapping flight, contrary to some earlier suggestions that they were so big they could only glide.

Like other pterosaurs, "Pteranodon" probably took off from a standing, quadrupedal position. Using their long forelimbs for leverage, they would have vaulted themselves into the air in a rapid leap. Almost all of the energy would have been generated by the forelimbs. The upstroke of the wings would have occurred when the animal cleared the ground followed by a rapid down-stroke to generate additional lift and complete the launch into the air.

Historically, the terrestrial locomotion of "Pteranodon", especially whether it was bipedal or quadrupedal, has been the subject of debate. Today, most pterosaur researchers agree that pterosaurs were quadrupedal, thanks largely to the discovery of pterosaur trackways.

The possibility of aquatic locomotion via swimming has been discussed briefly in several papers (Bennett 2001, 1994, and Bramwell & Whitfield 1974).

The diet of "Pteranodon" is known to have included fish; fossilized fish bones have been found in the stomach area of one "Pteranodon", and a fossilized fish bolus has been found between the jaws of another "Pteranodon", specimen AMNH 5098. Numerous other specimens also preserve fragments of fish scales and vertebrae near the torso, indicating that fish made up a majority of the diet of "Pteranodon" (though they may also have taken invertebrates).

Traditionally, most researchers have suggested that "Pteranodon" would have taken fish by dipping their beaks into the water while in low, soaring flight. However, this was probably based on the assumption that the animals could not take off from the water surface. It is more likely that "Pteranodon" could take off from the water, and would have dipped for fish while swimming rather than while flying. Even a small, female "Pteranodon" could have reached a depth of at least with its long bill and neck while floating on the surface, and they may have reached even greater depths by plunge-diving into the water from the air like some modern long-winged seabirds. In 1994, Bennett noted that the head, neck, and shoulders of "Pteranodon" were as heavily built as diving birds, and suggested that they could dive by folding back their wings like the modern gannet.

"Pteranodon" was notable for its skull crest, though the function of this crest has been a subject of debate. Most explanations have focused on the blade-like, backward pointed crest of male "P. longiceps", however, and ignored the wide range of variation across age and sex. The fact that the crests vary so much rules out most practical functions other than for use in mating displays. Therefore, display was probably the main function of the crest, and any other functions were secondary.

Scientific interpretations of the crest's function began in 1910, when George Francis Eaton proposed two possibilities: an aerodynamic counterbalance and a muscle attachment point. He suggested that the crest might have anchored large, long jaw muscles, but admitted that this function alone could not explain the large size of some crests. Bennett (1992) agreed with Eaton's own assessment that the crest was too large and variable to have been a muscle attachment site. Eaton had suggested that a secondary function of the crest might have been as a counterbalance against the long beak, reducing the need for heavy neck muscles to control the orientation of the head. Wind tunnel tests showed that the crest did function as an effective counterbalance to a degree, but Bennett noted that, again, the hypothesis focuses only on the long crests of male "P. longiceps", not on the larger crests of "P. sternbergi" and very small crests that existed among the females. Bennett found that the crests of females had no counterbalancing effect, and that the crests of male "P. sternbergi" would, by themselves, have a negative effect on the balance of the head. In fact, side to side movement of the crests would have required more, not less, neck musculature to control balance.

In 1943, Dominik von Kripp suggested that the crest may have served as a rudder, an idea embraced by several later researchers. One researcher, Ross S. Stein, even suggested that the crest may have supported a membrane of skin connecting the backward-pointing crest to the neck and back, increasing its surface area and effectiveness as a rudder. The rudder hypothesis, again, does not take into account females nor "P. sternbergi", which had an upward-pointing, not backward-pointing crest. Bennett also found that, even in its capacity as a rudder, the crest would not provide nearly so much directional force as simply maneuvering the wings. The suggestion that the crest was an air brake, and that the animals would turn their heads to the side in order to slow down, suffers from a similar problem. Additionally, the rudder and air brake hypotheses do not explain why such large variation exists in crest size even among adults.

Alexander Kellner suggested that the large crests of the pterosaur "Tapejara", as well as other species, might be used for heat exchange, allowing these pterosaurs to absorb or shed heat and regulate body temperature, which also would account for the correlation between crest size and body size. There is no evidence of extra blood vessels in the crest for this purpose, however, and the large, membranous wings filled with blood vessels would have served that purpose much more effectively.

With these hypotheses ruled out, the best-supported hypothesis for crest function seems to be as a sexual display. This is consistent with the size variation seen in fossil specimens, where females and juveniles have small crests and males large, elaborate, variable crests.

Adult "Pteranodon" specimens may be divided into two distinct size classes, small and large, with the large size class being about one and a half times larger than the small class, and the small class being twice as common as the large class. Both size classes lived alongside each other, and while researchers had previously suggested that they represent different species, Christopher Bennett showed that the differences between them are consistent with the concept that they represent females and males, and that "Pteranodon" species were sexually dimorphic. Skulls from the larger size class preserve large, upward and backward pointing crests, while the crests of the smaller size class are small and triangular. Some larger skulls also show evidence of a second crest that extended long and low, toward the tip of the beak, which is not seen in smaller specimens.

The sex of the different size classes was determined, not from the skulls, but from the pelvic bones. Contrary to what may be expected, the smaller size class had disproportionately large and wide-set pelvic bones. Bennett interpreted this as indicating a more spacious birth canal, through which eggs would pass. He concluded that the small size class with small, triangular crests represent females, and the larger, large-crested specimens represent males.

Note that the overall size and crest size also corresponds to age. Immature specimens are known from both females and males, and immature males often have small crests similar to adult females. Therefore, it seems that the large crests only developed in males when they reached their large, adult size, making the sex of immature specimens difficult to establish from partial remains.

The fact that females appear to have outnumbered males two to one suggests that, as with modern animals with size-related sexual dimorphism, such as sea lions and other pinnipeds, "Pteranodon" might have been polygynous, with a few males competing for association with groups consisting of large numbers of females. Similar to modern pinnipeds, "Pteranodon" may have competed to establish territory on rocky, offshore rookeries, with the largest, and largest-crested, males gaining the most territory and having more success mating with females. The crests of male "Pteranodon" would not have been used in competition, but rather as "visual dominance-rank symbols", with display rituals taking the place of physical competition with other males. If this hypothesis is correct, it also is likely that male "Pteranodon" played little to no part in rearing the young; such a behavior is not found in the males of modern polygynous animals who father many offspring at the same time.

Specimens assigned to "Pteranodon" have been found in both the Smoky Hill Chalk deposits of the Niobrara Formation, and the slightly younger Sharon Springs deposits of the Pierre Shale Formation. When "Pteranodon" was alive, this area was covered by a large inland sea, known as the Western Interior Seaway. Famous for fossils collected since 1870, these formations extend from as far south as Kansas in the United States to Manitoba in Canada. However, "Pteranodon" specimens (or any pterosaur specimens) have only been found in the southern half of the formation, in Kansas, Wyoming, and South Dakota. Despite the fact that numerous fossils have been found in the contemporary parts of the formation in Canada, no pterosaur specimens have ever been found there. This strongly suggests that the natural geographic range of "Pteranodon" covered only the southern part of the Niobrara, and that its habitat did not extend farther north than South Dakota.

Some very fragmentary fossils belonging to pteranodontian pterosaurs, and possibly "Pteranodon" itself, have also been found on the Gulf Coast and East Coast of the United States. For example, some bone fragments from the Mooreville Formation of Alabama and the Merchantville Formation of Delaware may have come from "Pteranodon", though they are too incomplete to make a definite identification. Some remains from Japan have also been tentatively attributed to "Pteranodon", but their distance from its known Western Interior Seaway habitat makes this identification unlikely.
"Pteranodon longiceps" would have shared the sky with the giant-crested pterosaur "Nyctosaurus". Compared to "P. longiceps", which was a very common species, "Nyctosaurus" was rare, making up only 3% of pterosaur fossils from the formation. Also less common was the early toothed bird, "Ichthyornis".

It is likely that, as in other polygynous animals (in which males compete for association with harems of females), "Pteranodon" lived primarily on offshore rookeries, where they could nest away from land-based predators and feed far from shore; most "Pteranodon" fossils are found in locations which at the time, were hundreds of kilometres from the coastline.

Below the surface, the sea was populated primarily by invertebrates such as ammonites and squid. Vertebrate life, apart from basal fish, included sea turtles, such as "Toxochelys", the plesiosaur "Styxosaurus", and the flightless diving bird "Parahesperornis". Mosasaurs were the most common marine reptiles, with genera including "Clidastes" and "Tylosaurus". At least some of these marine reptiles are known to have fed on "Pteranodon". Barnum Brown, in 1904, reported plesiosaur stomach contents containing "pterodactyl" bones, most likely from "Pteranodon".

Fossils from terrestrial dinosaurs also have been found in the Niobrara Chalk, suggesting that animals who died on shore must have been washed out to sea (one specimen of a hadrosaur appears to have been scavenged by a shark).

"Pteranodon" was the first pterosaur found outside of Europe. Its fossils first were found by Othniel Charles Marsh in 1870, in the Late Cretaceous Smoky Hill Chalk deposits of western Kansas. These chalk beds were deposited at the bottom of what was once the Western Interior Seaway, a large shallow sea over what now is the midsection of the North American continent. These first specimens, YPM 1160 and YPM 1161, consisted of partial wing bones, as well as a tooth from the prehistoric fish "Xiphactinus", which Marsh mistakenly believed to belong to this new pterosaur (all known pterosaurs up to that point had teeth). In 1871, Marsh named the find ""Pterodactylus oweni"", assigning it to the well-known (but much smaller) European genus "Pterodactylus". Marsh also collected more wing bones of the large pterosaur in 1871. Realizing that the name he had chosen had already been used for Harry Seeley's European pterosaur species "Pterodactylus oweni" in 1864, Marsh re-named his giant North American pterosaur Pterodactylus occidentalis, meaning "Western wing finger," in his 1872 description of the new specimen. He also named two additional species, based on size differences: Pterodactylus ingens (the largest specimen so far), and Pterodactylus velox (the smallest).

Meanwhile, Marsh's rival Edward Drinker Cope also had unearthed several specimens of the large North American pterosaur. Based on these specimens, Cope named two new species, Ornithochirus umbrosus and Ornithochirus harpyia, in an attempt to assign them to the large European genus "Ornithocheirus", though he misspelled the name (forgetting the 'e'). Cope's paper naming his species was published in 1872, just five days after Marsh's paper. This resulted in a dispute, fought in the published literature, over whose names had priority in what obviously were the same species. Cope conceded in 1875 that Marsh's names did have priority over his, but maintained that "Pterodactylus umbrosus" was a distinct species (but not genus) from any that Marsh had named previously. Re-evaluation by later scientists has supported Marsh's case, and found that Cope's assertion that "P. umbrosus" was a larger, distinct species were incorrect.

While the first "Pteranodon" wing bones were collected by Marsh and Cope in the early 1870s, the first "Pteranodon" skull was found on May 2, 1876, along the Smoky Hill River in Wallace County (now Logan County), Kansas, USA, by Samuel Wendell Williston, a fossil collector working for Marsh. A second, smaller skull soon was discovered as well. These skulls showed that the North American pterosaurs were different from any European species, in that they lacked teeth and had bony crests on their skulls. Marsh recognized this major difference, describing the specimens as "distinguished from all previously known genera of the order Pterosauria by the entire absence of teeth." Marsh recognized that this characteristic warranted a new genus, and he coined the name "Pteranodon" ("wing without tooth") in 1876. Marsh reclassified all the previously named North American species from "Pterodactylus" to "Pteranodon". He considered the smaller skull to belong to "Pteranodon occidentalis", based on its size. Marsh classified the larger skull, YPM 1117, in the new species "Pteranodon longiceps", which he thought to be a medium-sized species in between the small "P. occidentalis" and the large "P. ingens". Marsh also named several additional species: Pteranodon comptus and "Pteranodon nanus" were named for fragmentary skeletons of small individuals, while "Pteranodon gracilis" was based on a wing bone that he mistook for a pelvic bone. He soon realized his mistake, and re-classified that specimen again into a separate genus, which he named "Nyctosaurus". "P, nanus" was also later recognized as a "Nyctosaurus" specimen.

In 1892, Samuel Williston examined the question of "Pteranodon" classification. He noticed that, in 1871, Seeley had mention the existence of a partial set of toothless pterosaur jaws from the Cambridge Greensand of England, which he named "Ornithostoma". Because the primary characteristic Marsh had used to separate "Pteranodon" from other pterosaurs was its lack of teeth, Williston concluded that "Ornithostoma" must be considered the senior synonym of "Pteranodon". However, in 1901, Pleininger pointed out that "Ornithostoma" had never been scientifically described or even assigned a species name until Williston's work, and therefore had been a "nomen nudum" and could not beat out "Pteranodon" for naming priority. Williston accepted this conclusion and went back to calling the genus "Pteranodon". However, both Williston and Pleininger were incorrect, because unnoticed by both of them was the fact that, in 1891, Seeley himself had finally described and properly named "Ornithostoma", assigning it to the species "O. sedgwicki". In the 2010s, more research on the identity of "Ornithostoma" showed that it was probably not "Pteranodon" or even a close relative, but may in fact have been an azhdarchoid, a different type of toothless pterosaur.

Williston was also the first scientist to critically evaluate all of the pteranodont species classified by Cope and Marsh. He agreed with most of Marsh's classification, with a few exceptions. First, he did not believe that "P. ingens" and "P. umbrosus" could be considered synonyms, which even Cope had come to believe. He considered both "P. velox" and "P. longiceps" to be dubious; the first was based on non-diagnostic fragments, and the second, though known from a complete skull, probably belonged to one of the other, previously-named species. In 1903, Williston revisited the question of "Pteranodon" classification, and revised his earlier conclusion that there were seven species down to just three. He considered both "P. comptus" and "P. nanus" to be specimens of "Nyctosaurus", and divided the others into small ("P. velox"), medium ("P. occidentalis"), and large species ("P. ingens"), based primarily on the shape of their upper arm bones. He thought "P. longiceps", the only one known from a skull, could be a synonym of either "P. velox" or "P. occidentalis", based on its size.

In 1910, Eaton became the first scientist to publish a more detailed description of the entire "Pteranodon" skeleton, as it was known at the time. He used his findings to revise the classification of the genus once again based on a better understanding of the differences in pteranodont anatomy. Eaton conducted experiments using clay models of bones to help determine the effects of crushing and flattening on the shapes of the arm bones Williston had used in his own classification. Eaton found that most of the differences in bone shapes could be easily explained by the pressures of fossilization, and concluded that no "Pteranodon" skeletons had any significant differences from each other besides their size. Therefore, Eaton was left to decide his classification scheme based on differences in the skulls alone, which he assigned to species just as Marsh did, by their size. In the end, Eaton recognized only three valid species: "P. occidentalis", "P. ingens", and "P. longiceps".

The discovery of specimens with upright crests, classified by Harksen in 1966 as the new species "Pteranodon sternbergi", complicated the situation even further, prompting another revision of the genus by Miller in 1972. Because it was impossible to determine crest shape for all of the species based on headless skeletons, Miller concluded that all "Pteranodon" species except the two based on skulls ("P. longiceps" and "P. sternbergi") must be considered "nomena dubia" and abandoned. The skull Eaton thought belonged to "P. ingens" was placed in the new species Pteranodon marshi, and the skull Eaton assigned to "P. occidentalis" was re-named Pteranodon eatoni. Miller also recognized another species based on a skull with a crest similar to that of "P. sternbergi"; Miller named this Pteranodon walkeri. To help bring order to this tangle of names, Miller created three categories or "subgenera" for them. "P. marshi" and "P. longiceps" were placed in the subgenus "Longicepia", though this was later changed to simply "Pteranodon" due to the rules of priority. "P. sternbergi" and "P. walkeri", the upright-crested species, were given the subgenus "Sternbergia", which was later changed to "Geosternbergia" because "Sternbergia" was already in use ("preoccupied"). Finally, Miller named the subgenus "Occidentalia" for "P. eatoni", the skull formerly associated with "P. occidentalis". Miller further expanded the concept of "Pteranodon" to include "Nyctosaurus" as a fourth subgenus. Miller considered these to be an evolutionary progression, with the primitive "Nyctosaurus", at the time thought to be crestless, giving rise to "Occidentalia" (with a small crest), which in turn gave rise to "Pteranodon" with its long backwards crest, finally leading to "Geosternbergia" with its large, upright crest. However, Miller made several mistakes in his study concerning which specimens Marsh had assigned to which species, and most scientists disregarded his work on the subject in their later research, though Wellnhofer (1978) followed Miller's species list. and Schoch (1984) somewhat oddly published another revision that essentially returned to Marsh's original classification scheme, most notably sinking "P. longiceps" as a synonym of "P. ingens".

During the early 1990s, S. Christopher Bennett also published several major papers reviewing the anatomy, taxonomy and life history of "Pteranodon".

Fragmentary fossils assigned to "Pteranodon" have also been discovered in Skåne, Sweden.

"Pteranodon" fossils are known primarily from the Niobrara Formation of the central United States. Broadly defined, "Pteranodon" existed for more than four million years, during the late Coniacian to early Campanian stages of the Cretaceous period. The genus is present in most layers of the Niobrara Formation except for the upper two; in 2003, Kenneth Carpenter surveyed the distribution and dating of fossils in this formation, demonstrating that "Pteranodon sternbergi" existed there from 88 to 85 million years ago, while "P. longiceps" existed between 86 and 84.5 million years ago. A possible third species, which Kellner named "Geosternbergia maysei" in 2010, is known from the Sharon Springs member of the Pierre Shale Formation in Kansas, Wyoming, and South Dakota, dating to between 81.5 and 80.5 million years ago.

In the early 1990s, Bennett noted that the two major morphs of pteranodont present in the Niobrara Formation were precisely separated in time with little, if any, overlap. Due to this, and to their gross overall similarity, he suggested that they probably represent "chronospecies" within a single evolutionary lineage lasting about 4 million years. In other words, only one species of "Pteranodon" would have been present at any one time, and "P. sternbergi" (or "Geosternbergia") in all likelihood was the direct ancestor species of "P. longiceps".

Many researchers consider there to be at least two species of "Pteranodon". However, aside from the differences between males and females described above, the post-cranial skeletons of "Pteranodon" show little to no variation between species or specimens, and the bodies and wings of all pteranodonts were essentially identical.

Two species of "Pteranodon" are traditionally recognized as valid: "Pteranodon longiceps", the type species, and "Pteranodon sternbergi". The species differ only in the shape of the crest in adult males (described above), and possibly in the angle of certain skull bones. Because well-preserved "Pteranodon" skull fossils are extremely rare, researchers use stratigraphy (i.e. which rock layer of the geologic formation a fossil is found in) to determine species identity in most cases.

"Pteranodon sternbergi" is the only known species of "Pteranodon" with an upright crest. The lower jaw of "P. sternbergi" was long. It was collected by George F. Sternberg in 1952 and described by John Christian Harksen in 1966, from the lower portion of the Niobrara Formation. It was older than "P. longiceps" and is considered by Bennett to be the direct ancestor of the later species.

Because fossils identifiable as "P. sternbergi" are found exclusively in the lower layers of the Niobrara Formation, and "P. longiceps" fossils exclusively in the upper layers, a fossil lacking the skull can be identified based on its position in the geologic column (though for many early fossil finds, precise data about its location was not recorded, rendering many fossils unidentifiable).

Below is a cladogram showing the phylogenetic placement of this genus within Pteranodontia from Andres and Myers (2013).

Due to the subtle variations between specimens of pteranodontid from the Niobrara Formation, most researchers have assigned all of them to the single genus "Pteranodon", in at least two species ("P. longiceps" and "P. sternbergi") distinguished mainly by the shape of the crest. However, the classification of these two forms has varied from researcher to researcher. In 1972, Halsey Wilkinson Miller published a paper arguing that the various forms of "Pteranodon" were different enough to be placed in distinct subgenera. He named these "Pteranodon (Occidentalia) occidentalis" (for the now-disused species "P. occidentalis") and "Pteranodon (Sternbergia) sternbergi". However, the name "Sternbergia" was preoccupied, and in 1978 Miller re-named the species "Pteranodon (Geosternbergia) sternbergi", and named a third subgenus/species combination for "P. longiceps", as "Pteranodon (Longicepia) longiceps". Most prominent pterosaur researchers of the late 20th century however, including S. Christopher Bennett and Peter Wellnhofer, did not adopt these subgeneric names, and continued to place all pteranodont species into the single genus "Pteranodon".

In 2010, pterosaur researcher Alexander Kellner revisited H.W. Miller's classification. Kellner followed Miller's opinion that the differences between the "Pteranodon" species were great enough to place them into different genera. He placed "P. sternbergi" into the genus named by Miller, "Geosternbergia", along with the Pierre Shale skull specimen which Bennett had previously considered to be a large male "P. longiceps". Kellner argued that this specimen's crest, though incompletely preserved, was most similar to "Geosternbergia". Because the specimen was millions of years younger than any known "Geosternbergia", he assigned it to the new species "Geosternbergia maysei". Numerous other pteranodont specimens are known from the same formation and time period, and Kellner suggested they may belong to the same species as "G. maysei", but because they lack skulls, he could not confidently identify them.

A number of additional species of "Pteranodon" have been named since the 1870s, although most now are considered to be junior synonyms of two or three valid species. The best-supported is the type species, "P. longiceps", based on the well-preserved specimen including the first-known skull found by S. W. Williston. This individual had a wingspan of . Other valid species include the possibly larger "P. sternbergi", with a wingspan originally estimated at . "P. oweni" ("P. occidentalis"), "P. velox", "P. umbrosus", "P. harpyia", and "P. comptus" are considered to be "nomina dubia" by Bennett (1994) and others who question their validity. All probably are synonymous with the more well-known species.

Because the key distinguishing characteristic Marsh noted for "Pteranodon" was its lack of teeth, any toothless pterosaur jaw fragment, wherever it was found in the world, tended to be attributed to "Pteranodon" during the late nineteenth and early twentieth centuries. This resulted in a plethora of species and a great deal of confusion. The name became a wastebasket taxon, rather like the dinosaur "Megalosaurus", to label any pterosaur remains that could not be distinguished other than by the absence of teeth. Species (often dubious ones now known to be based on sexual variation or juvenile characters) have been reclassified a number of times, and several subgenera have in the 1970s been erected by Halsey Wilkinson Miller to hold them in various combinations, further confusing the taxonomy (subgenera include "Longicepia", "Occidentalia", and "Geosternbergia"). Notable authors who have discussed the various aspects of "Pteranodon" include Bennett, Padian, Unwin, Kellner, and Wellnhofer. Two species, "P. orogensis" and "P. orientalis", are not pteranodontids and have been renamed "Bennettazhia oregonensis" and "Bogolubovia orientalis" respectively.

Status of names listed below follow a survey by Bennett, 1994 unless otherwise noted.




</doc>
<doc id="24826" url="https://en.wikipedia.org/wiki?curid=24826" title="Passive voice">
Passive voice

A passive voice construction is a grammatical voice construction that is found in many languages. In a clause with passive voice, the grammatical subject expresses the "theme" or "patient" of the main verb – that is, the person or thing that undergoes the action or has its state changed. This contrasts with active voice, in which the subject has the agent role. For example, in the passive sentence "The tree was pulled down", the subject ("the tree") denotes the patient rather than the agent of the action. In contrast, the sentences "Someone pulled down the tree" and "The tree is down" are active sentences.

Typically, in passive clauses, what is usually expressed by the object (or sometimes another argument) of the verb is now expressed by the subject, while what is usually expressed by the subject is either deleted or is indicated by some adjunct of the clause. Thus, turning an active verb into a passive verb is a valence-decreasing process ("detransitivizing process"), because it turns transitive verbs into intransitive verbs. This is not always the case; for example in Japanese a passive-voice construction does not necessarily decrease valence.

Many languages have both an active and a passive voice; this allows for greater flexibility in sentence construction, as either the semantic agent or patient may take the syntactic role of subject. The use of passive voice allows speakers to organize stretches of discourse by placing figures other than the agent in subject position. This may be done to foreground the patient, recipient, or other thematic role; it may also be useful when the semantic patient is the topic of on-going discussion. The passive voice may also be used to avoid specifying the agent of an action.

Different languages use various grammatical forms to indicate passive voice.

In some languages, passive voice is indicated by verb conjugation, specific forms of the verb. Examples of languages that indicate voice through conjugation include Latin and North Germanic languages such as Swedish.

Norwegian (Nynorsk) and Icelandic have a similar system, but the usage of the passive is more restricted. The passive forms in Nynorsk are restricted to only be accompanied by an auxiliary verb, which is not the case in Swedish and Danish. 

In Latin, the agent of a passive sentence (if indicated) is expressed using a noun in the ablative case, in this case "servō" (the ablative of "servus"). Different languages use different methods for expressing the agent in passive clauses. In Swedish, the agent can be expressed by means of a prepositional phrase with the preposition "av" (equivalent here to the English "by").

The Austronesian language Kimaragang Dusun also indicates passive voice by verb conjugation using the infix, "-in-".
Other languages, including English, express the passive voice periphrastically, using an auxiliary verb.

English, like some other languages, uses a periphrastic passive. Rather than conjugating directly for voice, English uses the past participle form of the verb plus an auxiliary verb, either "be" or "get" (called linking verbs in traditional grammar), to indicate passive voice.

If the agent is mentioned, it usually appears in a prepositional phrase introduced by the preposition "by".

The subject of the passive voice usually corresponds to the direct object of the corresponding active-voice formulation (as in the above examples), but English also allows passive constructions in which the subject corresponds to an indirect object or preposition complement:
In sentences of the second type, a stranded preposition is left. This is called the "prepositional passive" or "pseudo-passive" (although the latter term can also be used with other meanings).

The active voice is the dominant voice used in English. Many commentators, notably George Orwell in his essay "Politics and the English Language" and Strunk & White in "The Elements of Style", have urged minimizing use of the passive voice, but this is almost always based on these commentators' misunderstanding of what the passive voice is. Contrary to common critiques, the passive voice has important uses, with virtually all writers using the passive voice (including Orwell and Strunk & White). 
There is general agreement that the passive voice is useful for emphasis, or when the receiver of the action is more important than the actor.

"Merriam–Webster's Dictionary of English Usage" refers to three statistical studies of passive versus active sentences in various periodicals, stating: "the highest incidence of passive constructions was 13 percent. Orwell runs to a little over 20 percent in "Politics and the English Language". Clearly he found the construction useful in spite of his advice to avoid it as much as possible".

In the field of linguistics, the term "passive" is applied to a wide range of grammatical structures. Linguists therefore find it difficult to define the term in a way that makes sense across all human languages. The canonical passive in European languages has the following properties:
The problem arises with non-European languages. Many constructions in these languages share at least one property with the canonical European passive, but not all. While it seems justified to call these constructions "passive" when comparing them to European languages' passive constructions, as a whole the passives of the world's languages do not share a single common feature.

R. M. W. Dixon has defined four criteria for determining whether a construction is a passive:
Dixon acknowledges that this excludes some constructions labeled as "passive" by some linguists.

Some languages, including several Southeast Asian languages, use a form of passive voice to indicate that an action or event was unpleasant or undesirable. This so-called "adversative passive" works like the ordinary passive voice in terms of syntactic structure—that is, a theme or instrument acts as subject. In addition, the construction indicates adversative affect, suggesting that someone was negatively affected.

In Japanese, for example, the adversative passive (also called indirect passive) indicates adversative affect. The indirect or adversative passive has the same form as the direct passive. Unlike the direct passive, the indirect passive may be used with intransitive verbs.

Yup'ik, from the Eskimo-Aleut family, has two different suffixes that can indicate passive, "-cir-" and "-ma-". The morpheme "-cir-" has an adversative meaning. If an agent is included in a passive sentence with the "-cir" passive, the noun is usually in the allative (oblique) case.

In some languages, for example English, there is often a similarity between clauses expressing an action or event in the passive voice and clauses expressing a state. For example, the string of words "The dog is fed" can have the following two different meanings:
The additions in parentheses "force" the same string of words to clearly show only one of their two possible grammatical functions and the related meaning. In the first sentence, the combination of the auxiliary verb "is" and the past participle "fed" is a regular example of the construction of the passive voice in English. In the second sentence, "is" can however be interpreted as an ordinary copula and the past participle as an adjective.

Sentences of the second type are called "false passives" by some linguists, who feel that such sentences are simply confused with the passive voice due to their outward similarity. Other linguists consider the second type to be a different kind of passive – a "stative passive" (rarely called "statal", "static", or "resultative passive"), in contrast to the "dynamic" or "eventive" passive illustrated by the first sentence. Some languages express or can express these different meanings using different constructions.

The difference between dynamic and stative passives is more evident in languages such as German that use different words or constructions for the two. In German, the auxiliary verb "sein" marks static passive (German: "Zustandspassiv", rarely "statisches Passiv", in referring to German also called ""sein"-Passiv" or "Sein-Passiv"), while "werden" marks the dynamic passive ("Vorgangspassiv" or "Handlungspassiv", rarely "dynamisches Passiv", in referring to German also called ""werden"-Passiv" or "Werden-Passiv" or simply "Passiv" or "Passivum").
The English string of words "the lawn is mown" has two possible meanings corresponding to the example "the dog is fed" above. It can be used in the following two different senses:
German uses two different grammatical constructions for these sentences:

Further examples and explanations:

A number of German verbs such as "bedecken" ("cover"), "erfüllen" ("fill"), and "trennen" ("separate"), when used as stative verbs, usually only form static passives.

In English, the passive voice expressed with the auxiliary verb "get" rather than "be" ("get-passive") expresses a dynamic rather than a static meaning. But when the auxiliary verb "be" is used, the main verb can have either a dynamic or static meaning as shown below (including copies of some examples from above):

Verbs that typically express static meaning can show dynamic meaning when used in the passive formed with "get", for example "be known" (static) vs. "get known" (dynamic):


(https://wals.info/chapter/107)


</doc>
<doc id="24829" url="https://en.wikipedia.org/wiki?curid=24829" title="Primitive recursive function">
Primitive recursive function

In computability theory, a primitive recursive function is roughly speaking a function that can be computed by a computer program whose loops are all "for" loops (that is, an upper bound of the number of iterations of every loop can be determined before entering the loop). Primitive recursive functions form a strict subset of those general recursive functions that are also total functions. 

The importance of primitive recursive functions lies on the fact that most computable functions that are studied in number theory (and more generally in mathematics) are primitive recursive. For example, addition and division, the factorial and exponential function, and the function which returns the "n"th prime are all primitive recursive. In fact, for showing that a computable function is primitive recursive, it suffices to show that its computational complexity is bounded above by a primitive recursive function of the input size. It follows that it is difficult to devise a computable function that is "not" primitive recursive, although some are known (see the section on Limitations below).

The set of primitive recursive functions is known as PR in computational complexity theory.

The primitive recursive functions are among the number-theoretic functions, which are functions from the natural numbers (nonnegative integers) {0, 1, 2, ...} to the natural numbers. These functions take "n" arguments for some natural number "n" and are called "n"-ary.

The basic primitive recursive functions are given by these axioms:
More complex primitive recursive functions can be obtained by applying the operations given by these axioms:

Example. We take "f"("x") as the "S"("x") defined above. This f is a 1-ary primitive recursive function. And so is "g"("x") = "S"("x"). So "h"("x") defined as "f"("g"("x")) = "S"("S"("x")) is a primitive recursive 1-ary function too. Informally speaking, "h"("x") is the function that turns "x" into "x"+2.

Example. Suppose "f"("x") = "P"("x") = "x" and "g"("x","y","z")= "S"("P"("x","y","z")) = "S"("y"). Then "h"(0,"x") = "x" and "h"("S"("y"),"x") = "g"("y","h"("y","x"),"x") = "S"("h"("y","x")). Now "h"(0,1) = 1, "h"(1,1) = "S"("h"(0,1)) = 2, "h"(2,1) = "S"("h"(1,1)) = 3. This "h" is a 2-ary primitive recursive function. We can call it 'addition'.

Interpretation. The function "h" acts as a For loop from 0 up to the value of its first argument. The rest of the arguments for "h", denoted here with "x"’s ("i" = 1, ..., "k"), are a set of initial conditions for the For loop which may be used by it during calculations but which are immutable by it. The functions "f" and "g" on the right side of the equations which define "h" represent the body of the loop, which performs calculations. Function "f" is only used once to perform initial calculations. Calculations for subsequent steps of the loop are performed by "g". The first parameter of "g" is fed the “current” value of the For loop’s index. The second parameter of "g" is fed the result of the For loop’s previous calculations, from previous steps. The rest of the parameters for "g" are those immutable initial conditions for the For loop mentioned earlier. They may be used by "g" to perform calculations but they will not themselves be altered by "g".

The primitive recursive functions are the basic functions and those obtained from the basic functions by applying these operations a finite number of times.

The projection functions can be used to avoid the apparent rigidity in terms of the arity of the functions above; by using compositions with various projection functions, it is possible to pass a subset of the arguments of one function to another function. For example, if "g" and "h" are 2-ary primitive recursive functions then
is also primitive recursive. One formal definition using projection functions is

In some settings it is natural to consider primitive recursive functions that take as inputs tuples that mix numbers with truth values (that is "t" for true and "f" for false), or that produce truth values as outputs. This can be accomplished by identifying the truth values with numbers in any fixed manner. For example, it is common to identify the truth value "t" with the number 1 and the truth value "f" with the number 0. Once this identification has been made, the characteristic function of a set "A", which always returns 1 or 0, can be viewed as a predicate that tells whether a number is in the set "A". Such an identification of predicates with numeric functions will be assumed for the remainder of this article.

An example of a primitive recursive programming language is one that contains basic arithmetic operators (e.g. + and −, or ADD and SUBTRACT), conditionals and comparison (IF-THEN, EQUALS, LESS-THAN), and bounded loops, such as the basic for loop, where there is a known or calculable upper bound to all loops (FOR i FROM 1 to n, with neither i nor n modifiable by the loop body). No control structures of greater generality, such as while loops or IF-THEN plus GOTO, are admitted in a primitive recursive language. Douglas Hofstadter's BlooP in "Gödel, Escher, Bach" is one such. Adding unbounded loops (WHILE, GOTO) makes the language partially recursive, or Turing-complete; Floop is such, as are almost all real-world computer languages.

Arbitrary computer programs, or Turing machines, cannot in general be analyzed to see if they halt or not (the halting problem). However, all primitive recursive functions halt. This is not a contradiction; primitive recursive programs are a non-arbitrary subset of all possible programs, constructed specifically to be analyzable.

Most number-theoretic functions definable using recursion on a single variable are primitive recursive. Basic examples include the addition and truncated subtraction functions.

Intuitively, addition can be recursively defined with the rules:

To fit this into a strict primitive recursive definition, define:

Here S("n") is "the successor of "n"" (i.e., "n"+1), "P" is the identity function, and "P" is the projection function that takes 3 arguments and returns the second one. Functions "f" and "g" required by the above definition of the primitive recursion operation are respectively played by "P" and the composition of "S" and "P".

Because primitive recursive functions use natural numbers rather than integers, and the natural numbers are not closed under subtraction, a truncated subtraction function (also called "proper subtraction") is studied in this context. This limited subtraction function sub("a", "b") [or "b" ∸ "a"] returns "b" - "a" if this is nonnegative and returns "0" otherwise.

The predecessor function acts as the opposite of the successor function and is recursively defined by the rules:

These rules can be converted into a more formal definition by primitive recursion:

The limited subtraction function is definable from the predecessor function in a manner analogous to the way addition is defined from successor:

Here sub("a", "b") corresponds to "b" ∸ "a"; for the sake of simplicity, the order of the arguments has been switched from the "standard" definition to fit the requirements of primitive recursion. This could easily be rectified using composition with suitable projections.

Exponentiation and primality testing are primitive recursive. Given primitive recursive functions "e", "f", "g", and "h", a function that returns the value of "g" when "e"≤"f" and the value of "h" otherwise is primitive recursive.

By using Gödel numberings, the primitive recursive functions can be extended to operate on other objects such as integers and rational numbers. If integers are encoded by Gödel numbers in a standard way, the arithmetic operations including addition, subtraction, and multiplication are all primitive recursive. Similarly, if the rationals are represented by Gödel numbers then the field operations are all primitive recursive.

In first-order Peano arithmetic, there are infinitely many variables (0-ary symbols) but no k-ary non-logical symbols with k>0 other than S, +, *, and ≤. Thus in order to define primitive recursive functions one has to use the following trick by Gödel.

By using a Gödel numbering for sequences, for example Gödel's β function, any finite sequence of numbers can be encoded by a single number. Such a number can therefore represent the primitive recursive function until a given n.

Let "h" be a 1-ary primitive recursion function defined by:
where C is a constant and "g" is an already defined function.

Using Gödel's β function, for any sequence of natural numbers (k, k, …, k), there are natural numbers b and c such that, for every i ≤ n, β(b, c, i) = k. We may thus use the following formula to define "h"; more precisely, "m"="h"("n") is a shorthand for the following:

and the equating to "g", being already defined, is in fact shorthand for some other already defined formula (as is β, whose formula is given here).

The generalization to any k-ary primitive recursion function is trivial.

The broader class of partial recursive functions is defined by introducing an unbounded search operator. The use of this operator may result in a partial function, that is, a relation with "at most" one value for each argument, but does not necessarily have "any" value for any argument (see domain). An equivalent definition states that a partial recursive function is one that can be computed by a Turing machine. A total recursive function is a partial recursive function that is defined for every input.

Every primitive recursive function is total recursive, but not all total recursive functions are primitive recursive. The Ackermann function "A"("m","n") is a well-known example of a total recursive function (in fact, provable total), that is not primitive recursive. There is a characterization of the primitive recursive functions as a subset of the total recursive functions using the Ackermann function. This characterization states that a function is primitive recursive if and only if there is a natural number "m" such that the function can be computed by a Turing machine that always halts within A("m","n") or fewer steps, where "n" is the sum of the arguments of the primitive recursive function.

An important property of the primitive recursive functions is that they are a recursively enumerable subset of the set of all total recursive functions (which is not itself recursively enumerable). This means that there is a single computable function "f"("m","n") that enumerates the primitive recursive functions, namely:
"f" can be explicitly constructed by iteratively repeating all possible ways of creating primitive recursive functions. Thus, it is provably total. One can use a diagonalization argument to show that "f" is not recursive primitive in itself: had it been such, so would be "h"("n") = "f"("n","n")+1. But if this equals some primitive recursive function, there is an "m" such that "h"("n") = "f"("m","n") for all "n", and then "h"("m") = "f"("m","m"), leading to contradiction.

However, the set of primitive recursive functions is not the "largest" recursively enumerable subset of the set of all total recursive functions. For example, the set of provably total functions (in Peano arithmetic) is also recursively enumerable, as one can enumerate all the proofs of the theory. While all primitive recursive functions are provably total, the converse is not true.

Primitive recursive functions tend to correspond very closely with our intuition of what a computable function must be. Certainly the initial functions are intuitively computable (in their very simplicity), and the two operations by which one can create new primitive recursive functions are also very straightforward. However, the set of primitive recursive functions does not include every possible total computable function—this can be seen with a variant of Cantor's diagonal argument. This argument provides a total computable function that is not primitive recursive. A sketch of the proof is as follows:

This argument can be applied to any class of computable (total) functions that can be enumerated in this way, as explained in the article Machine that always halts. Note however that the "partial" computable functions (those that need not be defined for all arguments) can be explicitly enumerated, for instance by enumerating Turing machine encodings.

Other examples of total recursive but not primitive recursive functions are known:

In the following we observe that primitive recursive functions can be of four types:

In the following the mark " ' ", e.g. a', is the primitive mark meaning "the successor of", usually thought of as " +1", e.g. a +1 = a'. The functions 16-20 and #G are of particular interest with respect to converting primitive recursive predicates to, and extracting them from, their "arithmetical" form expressed as Gödel numbers.

Similarly, many of the syntactic results in proof theory can be proved in PRA, which implies that there are primitive recursive functions that carry out the corresponding syntactic transformations of proofs.

In proof theory and set theory, there is an interest in finitistic consistency proofs, that is, consistency proofs that themselves are finitistically acceptable. Such a proof establishes that the consistency of a theory "T" implies the consistency of a theory "S" by producing a primitive recursive function that can transform any proof of an inconsistency from "S" into a proof of an inconsistency from "T". One sufficient condition for a consistency proof to be finitistic is the ability to formalize it in PRA. For example, many consistency results in set theory that are obtained by forcing can be recast as syntactic proofs that can be formalized in PRA.

Recursive definitions had been used more or less formally in mathematics before, but the construction of primitive recursion is traced back to Richard Dedekind's theorem 126 of his "Was sind und was sollen die Zahlen?" (1888). This work was the first to give a proof that a certain recursive construction defines a unique function.

Primitive recursive arithmetic was first proposed by Thoralf Skolem in 1923.

The current terminology was coined by Rózsa Péter (1934) after Ackermann had proved in 1928 that the function which today is named after him was not primitive recursive, an event which prompted the need to rename what until then were simply called recursive functions.




</doc>
<doc id="24830" url="https://en.wikipedia.org/wiki?curid=24830" title="Peisistratus (disambiguation)">
Peisistratus (disambiguation)

Peisistratus was a tyrant of Athens, Greece, three different times between 561 and 528 BC.

Peisistratus, Peisistratos or Pisistratus may also refer to:


</doc>
<doc id="24833" url="https://en.wikipedia.org/wiki?curid=24833" title="Prime Minister of Japan">
Prime Minister of Japan

The is the head of government of Japan. The prime minister is appointed by the emperor of Japan after being designated by the National Diet and must enjoy the confidence of the House of Representatives to remain in office. He is the head of the Cabinet and appoints and dismisses the other ministers of state. The literal translation of the Japanese name for the office is "Minister for the Comprehensive Administration of ("or" the Presidency over) the Cabinet".

Before the adoption of the Meiji Constitution, Japan had in practice no written constitution. Originally, a Chinese-inspired legal system known as "ritsuryō" was enacted in the late Asuka period and early Nara period. It described a government based on an elaborate and rational meritocratic bureaucracy, serving, in theory, under the ultimate authority of the Emperor; although in practice, real power was often held elsewhere, such as in the hands of the Fujiwara clan, who intermarried with the Imperial Family in the Heian period, or by the ruling "shōgun". Theoretically, the last "ritsuryō" code, the Yōrō Code enacted in 752, was still in force at the time of the Meiji Restoration.

Under this system, the was the head of the "Daijō-kan" (Department of State), the highest organ of Japan's pre-modern Imperial government during the Heian period and until briefly under the Meiji Constitution with the appointment of Sanjō Sanetomi in 1871. The office was replaced in 1885 with the appointment of Itō Hirobumi to the new position of Prime Minister, four years before the enactment of the Meiji Constitution, which mentions neither the Cabinet nor the position of Prime Minister explicitly. It took its current form with the adoption of the Constitution of Japan in 1947.

To date, 62 people have served this position. The current Prime Minister is Shinzō Abe, who re-took office on December 26, 2012. He is the first former Prime Minister to return to office since 1948, and the longest serving Prime Minister to date.

The Prime Minister is designated by both houses of the Diet, before the conduct of any other business. For that purpose, each conducts a ballot under the run-off system. If the two houses choose different individuals, then a joint committee of both houses is appointed to agree on a common candidate. Ultimately, however, if the two houses do not agree within ten days, the decision of the House of Representatives is deemed to be that of the Diet. Therefore, the House of Representatives can theoretically ensure the appointment of any Prime Minister it wants. The candidate is then presented with his or her commission, and formally appointed to office by the Emperor. 

In practice, the Prime Minister is almost always the leader of the majority party in the House of Representatives, or the leader of the senior partner in the governing coalition.




In most other constitutional monarchies, the monarch is nominal chief executive, while being bound by convention to act on the advice of the cabinet. In contrast, the Constitution of Japan explicitly vests executive power in the Cabinet, of which the Prime Minister is the leader. His countersignature is required for all laws and Cabinet orders. While most ministers in parliamentary democracies have some freedom of action within the bounds of cabinet collective responsibility, the Japanese Cabinet is effectively an extension of the Prime Minister's authority.

Located near the Diet building, the Office of the Prime Minister of Japan is called the . The original Kantei served from 1929 until 2002, when a new building was inaugurated to serve as the current Kantei. The old Kantei was then converted into the Official Residence, or . The Kōtei lies to the southwest of the Kantei, and is linked by a walkway.

The Prime Minister of Japan travels in a Lexus LS 600h L, the official transport for the head of government, or an unmodified Toyota Century escorted by a police motorcade of numerous Toyota Celsiors.

For long distance air travel, Japan maintains two Boeing 747-400 aircraft mostly for the Prime Minister of Japan, the Emperor, Empress and other members of the Imperial Family, operated by the Japan Air Self-Defense Force.

They have the radio callsigns Japanese Air Force One and Japanese Air Force Two when operating on official business, and Cygnus One and Cygnus Two when operating outside of official business (e.g., on training flights). The aircraft always fly together on government missions, with one serving as the primary transport and the other serving as a backup with maintenance personnel on board. The aircraft are officially referred to as .

The aircraft were constructed at the Boeing factory at the same time as the U.S. Air Force One VC-25s, though the U.S. aircraft were built to the 747-200 design, while the Japanese aircraft were built to the more contemporary 747-400 design. Both Japanese aircraft were delivered in 1990. The 747s will be replaced by new Boeing 777-300ER aircraft in fiscal year 2019.

Until the mid-1930s, the Prime Minister of Japan was normally granted a hereditary peerage ("kazoku") prior to leaving office if he had not already been ennobled. Titles were usually bestowed in the ranks of count, viscount or baron, depending on the relative accomplishments and status of the Prime Minister. The two highest ranks, marquess and prince, were only bestowed upon highly distinguished statesmen, and were not granted to a Prime Minister after 1928. The last Prime Minister who was a peer was Baron Kijūrō Shidehara, who served as Prime Minister from October 1945 to May 1946. The peerage was abolished when the Constitution of Japan came into effect in May 1947.

Certain eminent Prime Ministers have been awarded the Order of the Chrysanthemum, typically in the degree of Grand Cordon. The highest honour in the Japanese honours system, the Collar of the Order of the Chrysanthemum, has only been conferred upon select Prime Ministers and eminent statesmen; the last such award to a living Prime Minister was to Saionji Kinmochi in 1928. More often, the Order of the Chrysanthemum has been a posthumous distinction; the Collar of the order was last awarded posthumously to former Prime Minister Eisaku Satō in June 1975. The Grand Cordon has typically been posthumously awarded; the most recent such award was to Ryutaro Hashimoto in July 2006.

After relinquishing office, the Prime Minister is normally accorded the second or senior third rank in the court order of precedence, and is usually raised to the senior second rank posthumously. Certain distinguished Prime Ministers have been posthumously raised to the first rank; the last such award was to Sato Eisaku in 1975. Since the 1920s, following their tenure in office, Prime Ministers have typically been conferred with the Grand Cordon of the Order of the Paulownia Flowers (until 2003 a special higher class of the Order of the Rising Sun), depending on tenure and eminence. However, honours may be withheld due to misconduct or refusal on the part of the Prime Minister (for example, Kiichi Miyazawa).





</doc>
<doc id="24834" url="https://en.wikipedia.org/wiki?curid=24834" title="Protein targeting">
Protein targeting

Protein targeting or protein sorting is the biological mechanism by which proteins are transported to their appropriate destinations in the cell or outside it. Proteins can be targeted to the inner space of an organelle, different intracellular membranes, plasma membrane, or to exterior of the cell via secretion. This delivery process is carried out based on information contained in the protein itself. Correct sorting is crucial for the cell; errors can lead to diseases.

Targeting signals are the pieces of information that enable the cellular transport machinery to correctly position a protein inside or outside the cell. This information is contained in the polypeptide chain or in the folded protein. The continuous stretch of amino acid residues in the chain that enables targeting are called signal peptides or targeting peptides. There are two types of targeting peptides, the presequences and the internal targeting peptides. The presequences of the targeting peptide are often found at the N-terminal extension and is composed of between 6-136 basic and hydrophobic amino acids. In case of peroxisomes the targeting sequence is on the C-terminal extension mostly. Other signals, known as signal patches, are composed of parts which are separate in the primary sequence. They become functional when folding brings them together on the protein surface. In addition, protein modifications like glycosylations can induce targeting.

In 1970, Günter Blobel conducted experiments on the translocation of proteins across membranes. He was awarded the 1999 Nobel prize for his findings. He discovered that many proteins have a signal sequence, that is, a short amino acid sequence at one end that functions like a postal code for the target organelle. The translation of mRNA into protein by a ribosome takes place within the cytosol. If the synthesized proteins "belong" in a different organelle, they can be transported there in either of two ways depending on the protein: Co-translational translocation (translocation during the process of translation), and post-translational translocation (translocation after the process of translation is complete).

Most proteins that are secretory, membrane-bound, or reside in the endoplasmic reticulum (ER), golgi or endosomes use the co-translational translocation pathway. This process begins with the N-terminal signal peptide of the protein being recognized by a signal recognition particle (SRP) "while the protein is still being synthesized on the ribosome". The synthesis pauses while the ribosome-protein complex is transferred to an SRP receptor on the ER in eukaryotes, and the plasma membrane in prokaryotes. There, the nascent protein is inserted into the translocon, a membrane-bound protein conducting channel composed of the Sec61 translocation complex in eukaryotes, and the homologous SecYEG complex in prokaryotes. In secretory proteins and type I transmembrane proteins, the signal sequence is immediately cleaved from the nascent polypeptide once it has been translocated into the membrane of the ER (eukaryotes) or plasma membrane (prokaryotes) by signal peptidase. The signal sequence of type II membrane proteins and some polytopic membrane proteins are not cleaved off and therefore are referred to as signal anchor sequences. Within the ER, the protein is first covered by a chaperone protein to protect it from the high concentration of other proteins in the ER, giving it time to fold correctly. Once folded, the protein is modified as needed (for example, by glycosylation), then transported to the Golgi for further processing and goes to its target organelles or is retained in the ER by various ER retention mechanisms.

The amino acid chain of transmembrane proteins, which often are transmembrane receptors, passes through a membrane one or several times. They are inserted into the membrane by translocation, until the process is interrupted by a stop-transfer sequence, also called a membrane anchor or signal-anchor sequence. These complex membrane proteins are at the moment mostly understood using the same model of targeting that has been developed for secretory proteins. However, many complex multi-transmembrane proteins contain structural aspects that do not fit the model. Seven transmembrane G-protein coupled receptors (which represent about 5% of the genes in humans) mostly do not have an amino-terminal signal sequence. In contrast to secretory proteins, the first transmembrane domain acts as the first signal sequence, which targets them to the ER membrane. This also results in the translocation of the amino terminus of the protein into the ER membrane lumen. This would seem to break the rule of "co-translational" translocation which has always held for mammalian proteins targeted to the ER. This has been demonstrated with opsin with in vitro experiments. A great deal of the mechanics of transmembrane topology and folding remains to be elucidated.

Even though most secretory proteins are co-translationally translocated, some are translated in the cytosol and later transported to the ER/plasma membrane by a post-translational system. In prokaryotes this requires certain cofactors such as SecA and SecB. This pathway is poorly understood in eukaryotes, but is facilitated by Sec62 and Sec63, two membrane-bound proteins.

In addition, proteins targeted to other destinations, such as mitochondria, chloroplasts, or peroxisomes, use specialized post-translational pathways. Also, proteins targeted for the nucleus are translocated post-translation. They pass through the nuclear envelope via nuclear pores.

Most mitochondrial proteins are synthesized as cytosolic precursors containing uptake peptide signals. Cytosolic chaperones deliver preproteins to channel linked receptors in the mitochondrial membrane. The preprotein with presequence targeted for the mitochondria is bound by receptors and the General Import Pore (GIP) (Receptors and GIP are collectively known as Translocase of Outer Membrane or TOM) at the outer membrane. The preprotein is translocated through TOM as hairpin loops. The preprotein is transported through the intermembrane space by small TIMs (which also acts as molecular chaperones) to the TIM23 or 22 (Translocase of Inner Membrane) at the inner membrane. Within the matrix the targeting sequence is cleaved off by mtHsp70.

Three mitochondrial outer membrane receptors are known:
The TOM channel (TOM40) is a cation specific high conductance channel with a molecular weight of 410 kDa and a pore diameter of 21Å.

The presequence translocase23 (TIM23) is localized to the mitochondrial inner membrane and acts a pore forming protein which binds precursor proteins with its N-terminus. TIM23 acts a translocator for preproteins for the mitochondrial matrix, the inner mitochondrial membrane as well as for the intermembrane space. TIM50 is bound to TIM23 at the inner mitochondrial side and found to bind presequences. TIM44 is bound on the matrix side and found binding to mtHsp70. 
The presequence translocase22 (TIM22) binds preproteins exclusively bound for the inner mitochondrial membrane.

Mitochondrial matrix targeting sequences are rich in positively charged amino acids and hydroxylated ones.

Proteins are targeted to submitochondrial compartments by multiple signals and several pathways.

Targeting to the outer membrane, intermembrane space, and inner membrane often requires another signal sequence in addition to the matrix targeting sequence.

The preprotein for chloroplasts may contain a stromal import sequence or a stromal and thylakoid targeting sequence. The majority of preproteins are translocated through the Toc and Tic complexes located within the chloroplast envelope. In the stroma the stromal import sequence is cleaved off and folded as well as intra-chloroplast sorting to thylakoids continues. Proteins targeted to the envelope of chloroplasts usually lack cleavable sorting sequence.

Many proteins are needed in both mitochondria and chloroplasts. In general the targeting peptide is of intermediate character to the two specific ones. The targeting peptides of these proteins have a high content of basic and hydrophobic amino acids, a low content of negatively charged amino acids. They have a lower content of alanine and a higher content of leucine and phenylalanine. The dual targeted proteins have a more hydrophobic targeting peptide than both mitochondrial and chloroplastic ones.

All peroxisomal proteins are encoded by nuclear genes.

To date there are two types of known Peroxisome Targeting Signals (PTS):

Peroxisome targeting signal 1 (PTS1): a C-terminal tripeptide with a consensus sequence (S/A/C)-(K/R/H)-(L/A). The most common PTS1 is serine-lysine-leucine (SKL). Most peroxisomal matrix proteins possess a PTS1 type signal.

Peroxisome targeting signal 2 (PTS2): a nonapeptide located near the N-terminus with a consensus sequence (R/K)-(L/V/I)-XXXXX-(H/Q)-(L/A/F) (where X can be any amino acid).

There are also proteins that possess neither of these signals. Their transport may be based on a so-called "piggy-back" mechanism: such proteins associate with PTS1-possessing matrix proteins and are translocated into the peroxisomal matrix together with them.

Peroxisomal protein transport is defective in the following genetic diseases:

As discussed above (see protein translocation), most prokaryotic membrane-bound and secretory proteins are targeted to the plasma membrane by either a co-translation pathway that uses bacterial SRP or a post-translation pathway that requires SecA and SecB. At the plasma membrane, these two pathways deliver proteins to the SecYEG translocon for translocation. Bacteria may have a single plasma membrane (Gram-positive bacteria), or an inner membrane plus an outer membrane separated by the periplasm (Gram-negative bacteria). Besides the plasma membrane the majority of prokaryotes lack membrane-bound organelles as found in eukaryotes, but they may assemble proteins onto various types of inclusions such as gas vesicles and storage granules.

In gram-negative bacteria proteins may be incorporated into the plasma membrane, the outer membrane, the periplasm or secreted into the environment. Systems for secreting proteins across the bacterial outer membrane may be quite complex and play key roles in pathogenesis. These systems may be described as type I secretion, type II secretion, etc.

In most gram-positive bacteria, certain proteins are targeted for export across the plasma membrane and subsequent covalent attachment to the bacterial cell wall. A specialized enzyme, sortase, cleaves the target protein at a characteristic recognition site near the protein C-terminus, such as an LPXTG motif (where X can be any amino acid), then transfers the protein onto the cell wall. Several analogous systems are found that likewise feature a signature motif on the extracytoplasmic face, a C-terminal transmembrane domain, and cluster of basic residues on the cytosolic face at the protein's extreme C-terminus. The PEP-CTERM/exosortase system, found in many Gram-negative bacteria, seems to be related to extracellular polymeric substance production. The PGF-CTERM/archaeosortase A system in archaea is related to S-layer production. The GlyGly-CTERM/rhombosortase system, found in the Shewanella, Vibrio, and a few other genera, seems involved in the release of proteases, nucleases, and other enzymes.

Minimotif Miner is a bioinformatics tool that searches protein sequence queries for a known protein targeting sequence motifs.


 


</doc>
<doc id="24837" url="https://en.wikipedia.org/wiki?curid=24837" title="Pinochle">
Pinochle

Pinochle (), also called pinocle or penuchle, is a trick-taking, Ace-Ten card game typically for two to four players and played with a 48-card deck. It is derived from the card game bezique; players score points by trick-taking and also by forming combinations of cards into melds. It is thus considered part of a "trick-and-meld" category which also includes the game belote. Each hand is played in three phases: bidding, melds, and tricks. The standard game today is called "partnership auction pinochle."

There are two possible origins in looking at pinochle's ancestry. One is that it is a cousin of binokel with both games evolving from the game of bezique. A second alternative is that pinochle actually developed from the Swiss and, later, South German, game of binocle or binokel which in turn is a descendant of bezique.. The word pinochle has several different potential derivations. It may come from the French word "binocle" meaning "eyeglasses" or "binoculars". There are suggestions that it comes from "bis" (until) and "knochle" (knuckle) because originally the game ended when a player rapped their knuckles on the table. The term may also be related to the French word "binage" for the combination of cards called "binocle". This latter pronunciation of the game was adopted by German speakers. German immigrants brought the game to America in the latter quarter of the 19th century, where it was mispronounced and misspelled "pinochle." Pinochle was the favorite card game of American Jewish and Irish immigrants, while skat was the preferred game of a majority of German immigrants.

Auction pinochle for three players has some similarities with the German game skat, although the bidding is more similar to that of bid whist.

During World War I, the city of Syracuse, New York outlawed the playing of pinochle in a gesture of anti-German sentiment.

A pinochle deck consists of two copies of each of the 9, 10, jack, queen, king, and ace cards of all four suits, for 48 cards per deck. Aces are always considered high. Pinochle follows a nonstandard card ordering. The complete ordering from highest to lowest is A, 10, K, Q, J, 9. The game can also be played using standard ranking with a simple change to scoring.

Originally, the deck had to be composed by combining two poker, piquet or euchre decks and removing unneeded cards (a piquet deck does not have the 2-6, making it easier to modify, and a euchre deck is exactly half a pinochle deck), but with the game's popularity in the United States in the early 1900s, a single boxed deck with the necessary cards was marketed, and these specialized pinochle decks are now widely available in similar styles to common 52-card counterparts. Variants of pinochle can be played with five, six, eight or more players. These larger variations can combine two pinochle decks called a "double deck". The double deck can also be used when playing with four players; hand sizes, average scores and minimum bids are doubled.

The game is played with a deck of 48 cards and four players; one player is the dealer.

After the shuffle, the dealer will offer a cut to the player on their right, then distribute the cards. All the cards are dealt in partnership pinochle. In variations for odd numbers of players like three, a "widow's hand" (also called a "kitty", "talon", or "stock") of cards remain. Traditionally, the deal is done clockwise, dealing a packet of three or four cards at a time, starting with the player to the left (the eldest hand) and ending with the dealer. The deal rotates clockwise, so the dealer's left-hand opponent will deal next.

In auction pinochle, players bid for the points they predict their hand could earn. The highest bidder earns the right to declare the trump suit. One of the players, usually the player to the left of the dealer, or the dealer themselves, is obligated to open with a first bid. The size of bids is based on the point scale and number of decks used; traditionally, points are in multiples of 10, thus a minimum opening bid might be agreed to be 100 or 250. However, many alternate scoring rules drop the unnecessary trailing zero; in that case, bids of 10 and 25, respectively, have the same values. When a player has the turn to bid, the player may either bid or pass.

A popular variation for four (or three) player pinochle involves dealing a 4 card kitty (3 or 6 cards for three players), with the bid winner taking the kitty and discarding 4 (3 or 6) cards from his hand. The point value of the discards can sometimes be added to the bid winner's total trick count or not, depending on the pre-established rules. In three player games the 6 card kitty can often lead to very competitive and extravagant bidding.

Each bid must be greater than the previous one, and be a multiple of 10 or 25 (if playing without trailing zeroes, the bid must be one or two greater respectively). When a player passes, they can no longer bid. The auction ends when all subsequent players in rotation have passed after the last bid. The last bid becomes the "contract". The player that made this final bid will then declare trump in the suit that is desired. In some house rules, trump cannot be declared in any suit not containing a "run", "marriage" or "dix" meld.

In order for the winning bidder to win the hand, the combined total of melding and trick points must be equal to or greater than the winning bid. Thus bidding involves anticipating the points that will be accumulated from melds and from the points accumulated from winning tricks. If the combined score is lower than the bid, then the bidding team or player has been "set". This means that the total bid amount is subtracted from the total game score, often accompanied by losing the points scored in meld for that hand as well. This can result in a negative score.

A related though different style of bidding is for the players to bid individually, and partners' bids are then summed. The winning bid only decides trump; both (or all) teams' bids become their contract, meaning any team can score or be set. This creates a more balanced game.

In some versions of pinochle, after the bid has been taken and trump declared in a partnership game, the bid winning team exchanges cards. It may be two, three, or four cards, depending on the version of the game. The partner of the bid winner passes first. The objective of the partner is either to add to the total points in meld or to pass trick-winning cards. After receiving the cards, the bid winner examines what will create the strongest hand and then discards an equal number of cards back to their partner. Variations are for the bid winner and partner to exchange the designated number of cards simultaneously, or for no passing to occur.

Melding consists of displaying specific combinations of cards to all players. Typically this is done by placing the combination of cards face up on the playing surface until all players have had the opportunity to examine them. All players meld after the bid winner shows meld first. The types of melds include "arounds", "marriages", "flushes" and "pinochles". These melds are placed under "headings" where a card which is melded under a particular heading can be used again under another heading, but cannot be melded again under the same heading.

The group melds containing four of the same face cards – ace, king, queen or jack – must include one card from each of the different suits. They are scored as follows:

The marriages and flush are the "sequence melds":

A marriage in each suit is worth 240 or 24 total points, which is nothing more than the sum of the marriages, plus kings around and queens around. As a shortcut, this is called a "roundtable", "marriages around", "round house", or a "round robin".

The pinochle and dix are the "special melds".

In the most common form of the game (see variations below), any one card may be used in only one meld of each type. Thus, a queen can be used in one marriage with one king, regardless of if the player has the other king of the same suit. However, a queen can be used to score a marriage and a pinochle if the player also has the correct jack.

After the melds are displayed, the points are counted and each player totals their individual meld scores.
Because all of these values are multiples of ten, one can arrive at simplified values by removing the trailing zero from each point total. For instance, a pinochle has a simplified score of 4, a double Pinochle would score 30.

In playing cards for tricks, there are strict rules of forced play, which limit a player's ability to strategically retain high cards. The high bidder leads the play with the first card, which can be any card in the contract winner's hand, although some rules require the first card led to be a trump card. Then there are two variations of following suit depending if you are playing post-1945 or pre-1945 rules.

According to the pre-1945 rules, every player must follow the lead suit if possible. Usually every player must play a winning card against those played so far, if it is possible to do so, even when the current player expects a later player to win the hand with a better card. The only exception is if a player played a trump card when trump was not the suit led. In that case, those following that player may play any card of the lead suit, since they must follow the lead suit but are already losing to the player who played trump. Likewise, if a player cannot follow suit, but has trump, they must play trump. Again, if a player does not have any cards of the lead suit and can play a trump card higher than any other trump played so far, the player must do so, even if the player expects that a later player will beat the card. If another trump has already been played that a player cannot beat, then they can play any trump in their hand, but they still must play a trump card if they can. Only when a player has no cards in suit, and has no trump, can the player choose to play any card in their hand.

Most books of post-1945 rules say that unless trump is led, there is no requirement to try to win the trick. It is only when trump is led that "heading" the trick is mandatory. In pinochle circles and tournaments the post-1945 rules are played about half of the time according to Pagat and Hoyle.

If two identical cards are played, the first one outranks the second.

After the first trick, the winner of each trick leads the first card for the next trick, until all the cards are played.

Points are scored based on the tricks won in the hand. There are several ways to count up the points for play, but they always add up to 250 points. The last trick is always worth an additional 10 points added to any existing points in the actual trick cards. The classic counting system of pinochle is where aces are worth 11, tens are worth 10, kings are worth four, queens are worth three, jacks are worth two, and nines are worth zero. This method takes longer to count the score at the end of each hand.

A simpler method is to count aces and tens for 10 points, kings and queens for five points, and jacks and nines are worth zero.

An even simpler method has aces, tens, and kings worth 10 (and known as "counters"), and everything else zero ("garbage"). Since all points are multiples of ten in the third method, most players drop the redundant zero. Aces, tens, and kings won in tricks are worth one point. The meld scoring can also avoid the zero in the tenth place. Melds like 1,000 aces are thus worth 100. The terms "1,000 aces", "800 kings" and so on are often used, even though the point values are one-tenth.

Two-handed pinochle is the original pinochle game, while partnership, auction, and all other variants are derived from it. It is the game most similar to the original Bèzique game, whence pinochle was derived, via the German game of Binokel. The only significant difference in its rules from Bèzique is the scoring.

The original version of pinochle involves a partial deal of twelve cards to both players in packets of four, leaving a stock of 24 cards. A player can score one meld after each trick won of the first 12 tricks. Melded cards can even be used to win tricks. After each trick, players draw one card from the stock into their hand starting with the trick-winning player. For the last 12 tricks, melds are taken into each player's hand and are no longer announced by the player who wins the trick. The traditional trick-taking rules apply only for these last 12 tricks.

In variations of two-handed play, no cards are initially dealt, a distinction from all other variations. Instead, the entire deck is placed face-down on the playing surface between the two players to form the widow. One player begins the hand-building process by drawing the top card of the widow. The player can either keep that card for her or his hand or reject the card. If the player chooses to hold the initial card, the player then draws a second card from the widow, then places it face-down, without looking at it, creating a discard pile. If the player rejects the first card, the card becomes the first card in the discard pile. The second card drawn from the widow must be kept, regardless of whether she or he preferred the first card. Players alternate turns in this hand-building process until all cards are chosen.

With bidding, the player winning the bid declares trump, then lays all meld face-up on the table. The other player shows her or his melds as well. Meld points are tallied, and players return meld cards to their hands. Some varieties accept a "round house", kings and queens of each suit, and earn a bonus 10 points awarding a total of 250 points.

Trick-taking commences and continues until all held cards have been played. One variation has no "leading" requirement for the bid winner or subsequent trick winner to lead a specific card, however the rules of "following" are still observed.

When adding counters, cards from each player's discard pile are included in totals for a total of 240 counters per round, plus one counter for winning the final trick. One variation to make it more difficult for the bid-winning player, the discard pile created by drawing cards is used by the non-bidding player to score towards tricks.

In Three-handed pinochle, each player plays for him or herself. The dealer deals 15 cards to each player and three cards to the kitty—a separate pile in the middle.

All players review their cards and silently determine their bids. The player to the dealer's left initiates the bidding process. If the player has a meld, he or she is required to open the bidding; otherwise, they may pass or bid. If he or she passes, the obligation to bid passes to the next player, if meld is held. Once a player passes, he or she is out of the auction.

Bidding begins at 20, or as little as 19 if dealer, and increases in multiples of 1. The highest bidder wins the auction and turns up the three-card kitty for all to see. The three widow cards are placed in the bid winner's hand. The bid winner then declares trump and lays down meld. The other two players also lay meld face-up for count. After the appropriate points have been tallied the bid winner must set aside any three cards that have not been melded. This will reduce the bid winner's hand to 15 cards. For all three players, meld is now returned to each respective player's hand, and the round is played. During the round, a player must take at least one trick to "save one's meld", even if the trick contains no points; otherwise, no meld points will be counted for that player during that round.

After all tricks are taken, counters are tallied for each player. The three discards by the highest bidder count toward their counter score for the hand, so there is always a total of 25 points for the trick score among the three players. If the highest bidder fails to make their contract by adding meld points and trick points from the play, then their score is negative the amount of the bid for that hand. The meld count is cancelled.


The game is won when one player reaches 100 points. It is possible for two or all three players to go over 100 on the same hand. There are three methods of resolving ties:


Any time a player accidentally misplays during the play portion of the hand, it is called a renege. There are various forms of misplay:


If the bidder reneges, they automatically takes a double set and the amount of the bid is subtracted from their score. The two opposing players get to count their meld points and the remainder of the hand is thrown in.

If either of the two nonbidders misplay, the bidder automatically makes their bid. The bidder gets to score the amount of their bid and meld, the player that misplayed loses all meld and takes a single set, and the third player scores only their meld.

Card-Fault Misdeal

If at any point during melding or play it is determined that a non-standard deck is being used, any player may declare a card-fault misdeal. This results in the nullification of the entire hand including all meld and points obtained.

Similar to three-handed pinochle, cutthroat is a simple modification. The dealer deals the entire deck out (16 cards to each player), in packets of four. The player to the left of the dealer begins the bidding once meld has been silently determined by all players. Play continues normally in terms of scoring and trick taking. The only way to win in cutthroat pinochle, however, is to "bid and out", or to have taken the bid and surpassed the predetermined winning score. It is then possible for multiple players to go over the winning score, yet if none has taken a bid and met the resulting contract, a win has not happened and play continues. It is also possible for a person to lose with the high score if they do not take a winning bid.

Four-handed pinochle, or "partnership pinochle" is played with two teams of two players each. Partners are seated opposite from each other. Each player is dealt 12 cards. The opening bid is typically 150, but can be a higher agreed on value. All four players may bid. Both the bidder and his partner have their score count towards making the contract. High bidder names trump. There typically is no kitty. With a kitty, the four cards are distributed, one to each player, by the bid winner. Each hand must meld separately. As in the three-handed version, the first player is forced to bid when holding meld. Play is often to 1000 but can increase to 1500 during partnership.

Games with five hands or more typically modify partnership pinochle in a variety of ways. They are generally played with 1 1/2 or doubled decks, with extra dix added or withheld to make an even deal. With an odd number of players, the bidder asks for a desired card in the trump suit, with the first matching player being partner for that hand. Everyone else plays against the team. In larger groups, one or more players can sit out each hand allowing the remaining players to follow the appropriate rules for the respective number of players.

Check pinochle is a gambling variant of three-hand. It is the same as to 1000, except that players keep track of "checks". If playing for $1 stakes, each check gained means that the other two players owe a dollar. The following events cause a gain or loss of checks.


Today "double-deck" pinochle is a popular form of the game, exclusively played by the National Pinochle Association, the American Pinochle Association, the Cambridge Pinochle Association, and in the "World Series of Pinochle".

Double-deck pinochle is played with two pinochle decks, without the nines. This makes for an 80 card deck.

Play is similar to regular pinochle, except 20 cards are dealt to each person and minimum bid is increased to 500 points. In some variations, bids are made in increments of 10 or more points until 600 is reached, then by 50 points. This version often features "meld bidding", a bid made to let a partner know what is in the bidder's hand. The only communication during bidding should be a numerical number or "pass", any other way of communicating is called "talking across the table" and is forbidden.

There are occasionally different meld values for a run and a pinochle; a run being 250 or 150 points, and a pinochle being 150 or 40 points. All other aspects of the game generally remain the same.

Technical Misdeal

If a player is dealt 13 or more non-counters and no aces, the player may declare a technical misdeal. This must declared before he or she plays the first trick. A technical misdeal nullifies all points melded for all players. The hand is then re-dealt by the original dealer of that hand.

In triple-deck pinochle six play in two partnerships of three each; each player has an opponent at their right and left. Three pinochle decks with no nines are mixed together, making a pack of 120 cards. Each player is dealt 20 cards, and the rules of double deck pinochle apply, except that the minimum bid is 75, and the last trick is worth 3 points. most of the extra melds made possible by the triple pack do not count extra. i.e. if a player should hold twenty aces, five of each suit, the value would be that of double aces and triple aces combined.

Internet pinochle is almost always "double deck" except for a few applications for some smart phones. Today the Internet is host to many live professional cash tournaments, although many are still cautious about playing online because of potential cheating.

Note that this use of the term "racehorse" is inconsistent with the commonly understood meaning of the term when applied to Pinochle. As summarized by Dave LeVasseur: "Racehorse means that, after the winning bidder has named trump, that player's partner passes cards across the table"

Played much the same as "double deck" but to six hands, the point values are inflated.

Two teams are formed, 20 cards are then dealt to each player and 4 cards are dealt to the blind. Bidding commences with the person immediately to the left of the dealer automatically bidding 500. The winner of the bid includes the blind into their hand, calls trump and melds.

Note: all runs, double, triple, and quadruple, marriages must be in trump

The game continues with the standard rules of play. When the play is over each team adds up their points in the count with kings, 10s, and aces worth ten points, while queens and jacks are worth zero. If a team count plus meld does not equal their bid, they "go set". By going set the amount of the bid is subtracted from the team's score and their count is discarded. The other team retains both their meld and their count provided they took at least 10 points in the count.

Two full decks are dealt between eight players, forming four teams. Team members are spaced so that they are not able to see any other hands. The game is usually played to a score of 5,000 or higher. Other than this, the four player rules apply, and any variations may also be used. There is an increased possibility that when one team declares trump another team may have an equal number of trump also, which may lead to an interesting game. An optional scoring rule rewards 1,000 points for a quadruple pinochle—four jacks of diamonds and four queens of spades in a meld.

Alternate end games

One variation on winning allows a team or individual to win instantly from any score by taking all the tricks in a hand. To win in this fashion, the winning player or team must play very skillfully to prevent opposing players from taking even one lowly (even zero-point) trick. This victory is known as "pinochling". A player or team can play for this victory even if they are not the highest bidder. "pinochling" does not require a bidder to make their bid. They also can play for this victory even if their bid cannot be made with the maximum number of trick points available plus their meld. However, the highest bidding player or team can prevent other players from attempting this if they elect to "throw in" the hand before the first card is played.

When playing "bid-out" rules, a team can win without bidding if their score reaches (and remains above) the agreed upon game-ending score while their opponents fail to make their bid three times. This is known as a "slide-out".




</doc>
<doc id="24838" url="https://en.wikipedia.org/wiki?curid=24838" title="Peptidoglycan">
Peptidoglycan

Peptidoglycan (murein) is a polymer consisting of sugars and amino acids that forms a mesh-like layer outside the plasma membrane of most bacteria, forming the cell wall. The sugar component consists of alternating residues of β-(1,4) linked "N"-acetylglucosamine (NAG) and "N"-acetylmuramic acid (NAM). Attached to the "N"-acetylmuramic acid is a peptide chain of three to five amino acids. The peptide chain can be cross-linked to the peptide chain of another strand forming the 3D mesh-like layer. Peptidoglycan serves a structural role in the bacterial cell wall, giving structural strength, as well as counteracting the osmotic pressure of the cytoplasm. Peptidoglycan is also involved in binary fission during bacterial cell reproduction.

The peptidoglycan layer is substantially thicker in Gram-positive bacteria (20 to 80 nanometers) than in Gram-negative bacteria (7 to 8 nanometers). Peptidoglycan forms around 90% of the dry weight of Gram-positive bacteria but only 10% of Gram-negative strains. Thus, presence of high levels of peptidoglycan is the primary determinant of the characterisation of bacteria as Gram-positive. In Gram-positive strains, it is important in attachment roles and serotyping purposes. For both Gram-positive and Gram-negative bacteria, particles of approximately 2 nm can pass through the peptidoglycan.

The peptidoglycan layer in the bacterial cell wall is a crystal lattice structure formed from linear chains of two alternating amino sugars, namely "N"-acetylglucosamine (GlcNAc or NAGA) and "N"-acetylmuramic acid (MurNAc or NAMA). The alternating sugars are connected by a β-(1,4)-glycosidic bond. Each MurNAc is attached to a short (4- to 5-residue) amino acid chain, containing -alanine, -glutamic acid, "meso"-diaminopimelic acid, and -alanine in the case of "Escherichia coli" (a Gram-negative bacterium) or -alanine, -glutamine, -lysine, and -alanine with a 5-glycine interbridge between tetrapeptides in the case of "Staphylococcus aureus" (a Gram-positive bacterium). Peptidoglycan is one of the most important sources of D-amino acids in nature.

Cross-linking between amino acids in different linear amino sugar chains occurs with the help of the enzyme DD-transpeptidase and results in a 3-dimensional structure that is strong and rigid. The specific amino acid sequence and molecular structure vary with the bacterial species.

The peptidoglycan monomers are synthesized in the cytosol and are then attached to a membrane carrier bactoprenol. Bactoprenol transports peptidoglycan monomers across the cell membrane where they are inserted into the existing peptidoglycan.

In the first step of peptidoglycan synthesis, glutamine, which is an amino acid, donates an amino group to a sugar, fructose 6-phosphate. This turns fructose 6-phosphate into glucosamine-6-phosphate. In step two, an acetyl group is transferred from acetyl CoA to the amino group on the glucosamine-6-phosphate creating "N"-acetyl-glucosamine-6-phosphate. In step three of the synthesis process, the "N"-acetyl-glucosamine-6-phosphate is isomerized, which will change "N"-acetyl-glucosamine-6-phosphate to "N"-acetyl-glucosamine-1-phosphate.

In step 4, the "N"-acetyl-glucosamine-1-phosphate, which is now a monophosphate, attacks UTP. Uridine triphosphate, which is a pyrimidine nucleotide, has the ability to act as an energy source. In this particular reaction, after the monophosphate has attacked the UTP, an inorganic pyrophosphate is given off and is replaced by the monophosphate, creating UDP-N-acetylglucosamine (2,4). (When UDP is used as an energy source, it gives off an inorganic phosphate.) This initial stage, is used to create the precursor for the NAG in peptidoglycan.

In step 5, some of the UDP-N-acetylglucosamine (UDP-GlcNAc) is converted to UDP-MurNAc (UDP-N-acetylmuramic acid) by the addition of a lactyl group to the glucosamine. Also in this reaction, the C3 hydroxyl group will remove a phosphate from the alpha carbon of phosphoenolpyruvate. This creates what is called an enol derivative that will be reduced to a “lactyl moiety” by NADPH in step six.

In step 7, the UDP–MurNAc is converted to UDP-MurNAc pentapeptide by the addition of five amino acids, usually including the dipeptide -alanyl--alanine. Each of these reactions requires the energy source ATP. This is all referred to as Stage one.

Stage two occurs in the cytoplasmic membrane. It is in the membrane where a lipid carrier called bactoprenol carries peptidoglycan precursors through the cell membrane. Bactoprenol will attack the UDP-MurNAc penta, creating a PP-MurNac penta, which is now a lipid. UDP-GlcNAc is then transported to MurNAc, creating Lipid-PP-MurNAc penta-GlcNAc, a disaccharide, also a precursor to peptidoglycan. How this molecule is transported through the membrane is still not understood. However, once it is there, it is added to the growing glycan chain. The next reaction is known as tranglycosylation. In the reaction, the hydroxyl group of the GlcNAc will attach to the MurNAc in the glycan, which will displace the lipid-PP from the glycan chain. The enzyme responsible for this is transglycosylase.
Some antibacterial drugs such as penicillin interfere with the production of peptidoglycan by binding to bacterial enzymes known as penicillin-binding proteins or DD-transpeptidases. Penicillin-binding proteins form the bonds between oligopeptide crosslinks in peptidoglycan. For a bacterial cell to reproduce through binary fission, more than a million peptidoglycan subunits (NAM-NAG+oligopeptide) must be attached to existing subunits. Mutations in genes coding for transpeptidases that lead to reduced interactions with an antibiotic are a significant source of emerging antibiotic resistance.

Lysozyme, which is found in tears and constitutes part of the body's innate immune system exerts its antibacterial effect by breaking the β-(1,4)-glycosidic bonds in peptidoglycan (see above).

Some archaea have a similar layer of pseudopeptidoglycan (also known as pseudomurein), in which the sugar residues are β-(1,3) linked "N"-acetylglucosamine and "N"-acetyltalosaminuronic acid. This makes the cell walls of such archaea insensitive to lysozyme.



</doc>
<doc id="24844" url="https://en.wikipedia.org/wiki?curid=24844" title="PDE">
PDE

PDE can refer to:



</doc>
