<doc id="24973" url="https://en.wikipedia.org/wiki?curid=24973" title="Prime time">
Prime time

The prime time or the peak time is the block of broadcast programming taking place during the middle of the evening for television programming. It is used by the major television networks to broadcast their season's nightly programming.

The term "prime time" is often defined in terms of a fixed time period—for example (in the United States), from 8:00 p.m. to 11:00 p.m. (Eastern and Pacific Time) or 7:00 p.m. to 10:00 p.m. (Central and Mountain Time). In India and some Middle Eastern countries, prime time consists of the programmes that are aired on TV between 8:00 p.m. and 11:00 p.m. local time.

In Bangladeshi Television Channels, the 19:00-to-22:00 time slot is known as Prime Time. Several National Broadcasters like Maasranga Television, Gazi TV, Channel 9, Channel i broadcast their prime-time shows from 20:00 to 23:00 after their Primetime news at 19:00.
During Eid Season, most of the TV Stations broadcast their especially produced shows and World Television Premiers starting from 15:00 to midnight.
In Ramadan, the broadcasters also air special Religious and Cooking shows starting from 14:00 to 20:00 affecting the primetime hours. Besides, Late Night Talkshows are also aired from 01:00 to 04:00 with Ramadan being exception. Religious shows are also broadcast simultaneously from 01:00 along with Talkshows and News Analysis.

In Chinese television, the 19:00-to-22:00 time slot is known as Golden Time (Traditional Chinese: 黄金時間; Simplified Chinese: 黄金时间; Pinyin: Huángjīn shíjiān). The term also influenced a nickname of a strip of holidays in known as Golden Week.

Prime time usually takes place from 19:00 until 22:00. After that, programs classified as "PG" (Parental Guidance) are allowed to be broadcast. Frontline dramas appear during this time slot in Cantonese, as well as movies in English.

In India, prime time occurs between 19:00 and 22:00. Usually, programmes during prime time are domestic dramas, talent shows and reality shows.

Prime time usually takes place from 18:00 to 23:00 WIB, preceded by a daily newscast at 17:00 (although some channels broadcast their daily evening newscasts earlier, usually at 16:00 or 16:30 but the practice ended in 2018, except for TVRI). After prime time, programs classified as Adult, as well as cigarette commercials, are allowed to be broadcast.

Like another Muslim-majority country, there is also a 'midnight prime time' during sahur time in a month of Ramadan. It takes place from 02:00 (or 02:30 in some channels) and ends at the Fajr prayer call, varies between 04:30 and 05:00. The time slot is usually filled with comedy and religious programming.

In Iraq, prime time runs from 20:00 to 23:00. The main news programs are broadcast at 20:00 and the highest-rated television program airs at 21:00.

In Japanese television, prime time runs from 19:00 to 23:00. Especially, the 19:00-to-22:00 time slot is also known as . The term also influenced a nickname of a strip of holidays in known as Golden Week.

Malaysian prime time starts with the main news from 20:00 to 20:30 (now 20:00 to 21:00) and ends either at 23:00 or 1:00, or possibly later. Usually, programmes during prime time are domestic dramas, foreign drama series (mostly American), films and entertainment programmes. Programmes classified as 18 are not allowed to be broadcast before 10:00 p.m. but on RTM, most programmes on this slot are rated U (U means "Umum" in Malay and literally General Viewing or General Audiences in English) throughout the whole day. However, programmes broadcast after 23:00 are still considered prime time. As of 2019, NTV7's prime time continues until 12:00 a.m. Programmes during prime time may have longer commercial breaks due to number of viewers.

Some domestic prime-time productions may be affected because of certain major sporting events such as FIFA World Cup. However, only FIFA World Cup held in the Americas do not affect the domestic prime-time programmes but only during daytime.

In Pakistan, prime time begins between 20:00—22:00 Pakistan Standard Time. During this time majority of the local channels broadcast news and or drama serials, however on state channels it has been observed that they broadcast Khabarnama (New Bulletin) from past many decades.

In the Philippines, prime-time blocks begin at 18:00 (now 17:50 or 17:00) and run until about 23:00 (or 23:30) on weekdays, and 19:00 to 23:00 on weekends. The weekday prime-time blocks usually consists of local teleseryes (soap operas) and foreign television series. The network's highest-rated programs are usually aired right after the evening newscast at 20:00, while a foreign series usually precedes the late night newscast.

On weekends, non-scripted programming such as comedy series, talent shows, reality shows and current affairs shows air in prime time. For the minor networks, prime time consists of American television series on weekdays, with encores of those shows on weekends. Prime time originally started earlier at around 19:00, but the evening newscasts were lengthened to 90 minutes and now start at 18:30, instead of the original one-hour newscast that starts at 18:00.

In Singapore, prime time begins at 18:00 on Mediacorp Channel 5, 18:30 on Mediacorp Channel 8 and 19:00 on MediaCorp Channel U, Channel NewsAsia, MediaCorp Suria, MediaCorp Vasantham. which are also the main (Free-to-air) television channels in Singapore.

On Channel 8, prime time ends at midnight or 0:15 on weekdays, at 0:30 on Saturday nights and at 23:30 on Sunday nights. On Channel 5, prime time ends at 0:00 on weekdays, at 1:30 (or later) on Saturday nights and at 0:30 on Sunday nights. On Suria, prime time ends at 22:30 on Monday to Thursday nights, 00:30 on Friday nights, 23:00 on weekends and at 00:30 or 01:00 on eve and actual days of Public Holidays. On Vasantham, prime time ends at 23:00 on Mondays to Thursdays, midnight (or later) on Friday and Saturday nights and at 23:30 on Sunday nights. On Channel NewsAsia, prime time ends at 23:01, immediately after the news headlines, seven days a week and on Channel U, prime time ends at 23:00 seven days a week. Generally, however, prime time is considered to be from 18:00 to 00:00.

In South Korea, prime time usually runs from 20:00 to 23:00 during the week, while on Saturdays and Sundays, it runs from 18:00 to 23:00. Family-oriented television shows are broadcast before 22:00, and adult-oriented television shows air after 22:00.

In Taiwan, prime time (called "bādiǎn dàng"——in Mandarin Chinese) starts at 20:00 in the evening. Taiwanese drama series played then are called 8 o'clock series and are expected to have high viewer ratings.

In Thailand, prime time dramas (ละคร; la-korn) air from 20:30 to 22:30. Most dramas are soap operas. Prime time dramas are popular and influential to Thai society.

In Vietnam Prime time is also known as Golden Time (Tiếng Việt: Giờ vàng), prime time starts at 20:00 in the evening and ends at 23:00.

In Bosnia and Herzegovina, prime time starts at 20:00 and finishes at 22:00. It is preceded by a daily newscast ("Dnevnik") at 19:00 and followed by a late night newscast ("Vijesti") at 22:00.

In Croatia, prime time starts between 20:00 and 20:15. Croatian public broadcaster HRT broadcasts a daily newscast from 19:00 to 20:00. Also, many private broadcasters have daily newscasts either before or after the HTY newscast, at around 20.05, followed by the start of their own prime time. Many broadcasters without daily newscasts start their prime time at 20:00. Prime time generally ends between 22:00 and 23:00, followed by the late night edition of the network newscast and adult-oriented programming.

In Denmark, prime time starts at 20:00.

In Finland, prime time starts at 21:00. It is preceded by a daily newscast at 20:30.

In France prime time runs from 20:45 (after the main channels' evening news programmes) until around 22:30.

In Georgia, prime time starts between 18:45 and 20:00 and generally ends at midnight. However, on Friday night / Saturday morning prime time usually continues until 1:00.

At 20:00 each evening Das Erste (The First), Germany's oldest public television network, airs the country's most-watched news broadcast, the main edition of the "Tagesschau"—which is also simulcast on most of its other specialist and regional channels (The Third). The conclusion of the bulletin 15 minutes later marks the beginning of prime time, as it has since the 1950s. In consequence, most channels also choose to start their prime time at 20:15. In the 1990s, the commercial channel Sat.1 suffered a significant loss of audience share when it tried moving the start of its prime time to 20:00.

In Greece, prime time runs from 21:00 (usually following the news) to midnight.

In Hungary, prime time on weekdays on the two big commercial stations (RTL Klub and TV2) starts at 19:00 with game shows, tabloid and docu-reality programmes. At 21:00, two popular soap operas air: "Barátok közt" and "Jóban Rosszban", which follows at 21:30. American and other series, movies, talk-shows and magazines run until 23:30. The prime-time lineup is preceded by daily news programmes at 18:30. At weekends prime time begins at 19:00, with blockbuster movies and television shows.

Before 15 March 2015, the public television station M1 began its prime time with a game show at 18:30, which was followed by the daily news programme "Híradó" at 19:30. After the news, the channel broadcast American and other series, talk shows, magazines, and news programmes until 22:00, after which came the daily news magazine "Este" and the late edition of "Híradó".

From 15 March 2015, Duna began broadcasting all of the entertainment programming transferred to it from that date from M1, meaning that prime time on Duna now begins at 18:00, starting with the simulcast of the 18:00 edition of Híradó from the newly re-launched news channel, M1.

In Iceland, prime time starts at 19:30. It is preceded by a daily newscast at 19:00.

In Ireland, prime starts at 18:30 and ends at 22:00.

In Italy, prime time (called "prima serata") starts between 21:00 and 21:45 (main channels) and ends between 23:30 and 00:30. On Friday and Saturday night some shows last until 01:30–02:00. It usually follows news and, on some networks (like Rai 1 and Canale 5), a slot called "access prime time". Shows, movies, and sport events are usually shown during prime time.

Much like in Germany, prime time in the Netherlands usually begins at 20:30 in order to not compete with NOS's flagship 20:00 newscast.

In Norway, prime time starts at 19:45. On the NRK1 channel it is preceded by the daily newscast "Dagsrevyen" at 19:00. Locally, prime time is called (lit. "best time for broadcasting").

In Poland, prime time starts around 20:00 (sometimes 20:30). On (TVP 1) It is preceded by a daily newscast at 19:30, on (TVN) the newscast is aired at 19:00 followed by the newsmagazine Uwaga at 19:50 (weekdays)/19:45 (weekends) and then the soap Na Wspólnej at 20:05 (Monday to Thursday, from Friday to Sunday (at 20:00) various: movies on Friday, show or movies (Winter and Summer) at Saturday, and programme or movies (Winter and Summer) at Sunday), on (Polsat) the news is aired at 18:50, followed by a sitcom Świat według Kiepskich at 19:30.

In Russia television prime time is between 19:00 and 23:00 on working days and from 15:00 to 01:00 on holidays.
On radio stations there are morning, day and evening prime times. The most common division:
morning—6:30 to 10:00;
day—~12:00 to 14:00;
evening—16:00 to 21:00.

Public television in Slovakia consists of two channels; on the main channel (Jednotka) prime time starts at 20:10, and on the second one (Dvojka) prime-time programming starts at 20:00. The two biggest private broadcasters set the start of prime-time programming at 20:20 (Markíza) and 20:30 (JOJ). Generally, however, prime time is considered to be from 20:00 to 23:00.

In Slovenia, prime time, the period in which the most-watched shows are broadcast, is from 8:00pm to 11:00pm. It is preceded by daily newscasts; Dnevnik RTV SLO (7:00pm–8:00pm) on TV SLO 1, 24ur (6:55pm–8:00pm) on POP TV, Svet na Kanalu A (6:00pm–7:00pm; 7:50pm–8:0pm), and Danes (7:30pm–8:00pm) on Planet TV.

In Spain, prime time refers to the time period in which the most-watched shows are broadcast. Prime time in Spain starts quite late when compared to most nations as it runs from 22:30 till 01:00. Most news programmes in Spain air at 21:00 for an hour and prime time follows. However, due to fierce competition, especially among the private stations prime time has even been delayed until 23:00. Most channels are delaying prime time in order to protect their top shows from sporting events.

In the 1990s, prime time in Spain began at 21:00, moving to 21:30 in the latter half of the 1990s and 22:00 in the early 2000s. Commercial broadcaster laSexta and the second channel from the Public broadcasting La 2 have attempted to shift prime time back to 21:30 in 2006 and Spring 2007, but these attempts have been unsuccessful. Fellow public channel La 1 also tried to pull prime time back to 21:00 in early 2015, to no avail.

The lateness in the start of prime time in Spain is also due to Spanish culture. Spanish people generally work from 09:00–14:00 and then from 17:00–20:00 as opposed to the standard 09:00–17:00. The popular late-night show "Crónicas Marcianas" during the late 1990s–2000 also helped to extend prime time well into the early hours with the show being watched by a share of 40%, despite finishing at 02:00.

Spain might also be unique in that it has a second prime time, running from 14:30–17:00 which coincides with the extended Spanish lunch break. Shows airing in the secondary prime time period on many occasions beat those prime-time shows at night on a daily basis. The second prime time only occurs on weekdays, though and the slot is usually filled with "The Simpsons", news, soap operas and talk shows.

In Sweden, prime time starts at 20:00. It is preceded by a daily newscast at 19:30 and local news at 19:50.

In the UK, prime time (known as peak time in that country) runs from 17:30 to 23:00.

In North America, television networks feed their prime-time programming in two blocks: one for the Eastern and Central time zones, and the other, on a three-hour tape delay, for the Pacific time zone, to their local network affiliates. In Atlantic Canada (including Newfoundland) as well as Alaska and Hawaii, there is no change in the interpretation or usage of "prime time" as the concept is not attached to time zones in any way. Affiliates in the Mountain, Alaskan, and Hawaiian zones are either on their own to delay broadcast by an hour or two, or collectively form a small, regional network feed with others in the same time zone.

Prime time is commonly defined as 8:00–11:00 p.m. Eastern/Pacific and 7:00–10:00 p.m. Central/Mountain. On Sundays, the major broadcast television networks traditionally begin their primetime programming at 7:00 p.m. (Eastern/Pacific, 6:00 p.m. Central/Mountain) instead. Some networks such as Fox, The CW, and MyNetworkTV only broadcast from 8:00–10:00 p.m., a time period known as "common prime". Most networks air primetime programming nightly, but the smaller MyNetworkTV only broadcasts prime-time programs on weekdays since 2009, and The CW only broadcasts on weekdays and Sundays as of 2018, leaving Saturday's schedule to their affiliates. In Canada, CTV and Global both follow the same model as the larger U.S. networks (although both may occasionally air programming in the 7:00 p.m. hour in the event of scheduling conflicts with other U.S. imports), while CBC Television, Citytv and CTV Two only schedule prime-time programs within the common prime period (with the 10:00 p.m. p.m. hour dedicated to syndicated programming on Citytv and CTV Two, and CBC airing its news program "The National"). The Canadian Radio-television and Telecommunications Commission (CRTC) has alternatively defined prime time as ranging from 6 pm to 11 pm to 7 pm to 11 pm. 

Since the early 2000s, the major networks have come to consider Saturday prime time as a graveyard slot, and have largely abandoned scheduling of new scripted programming on that night. The major networks still maintain a prime-time programming schedule on Saturdays; while live sporting events (most commonly college football in the United States and ice hockey in Canada) are generally preferred to fill the time slot, they typically air encores of programs aired earlier in the week, films, non-scripted reality programs, true crime programs produced by their news divisions and, occasionally, burned off episodes of low-rated or cancelled series.

Prime time can be extended or truncated if coverage of sporting events run past their allotted end time. Since the "Heidi Game" incident in 1968, in which NBC cut away from coverage of a New York Jets/Oakland Raiders football game on the east coast in order to show a movie (and, in the process, causing viewers to miss an unexpected comeback by the Raiders to win the game), the present-day National Football League mandated that all games be broadcast in their entirety in the markets of the teams involved. Due to this rule, game telecasts may sometimes overrun into the 7:00 p.m. ET hour. Fox previously scheduled repeats of its animated series in the 7:00 hour, allowing themselves to simply pre-empt the reruns if a game ran long. This was later replaced by a half-hour-long wrap-up show, "". In contrast, CBS does not, as its weekly newsmagazine "60 Minutes" has traditionally aired as close to 7:00 p.m. ET as possible. Even if a game runs past that hour, CBS shows "60 Minutes" in its entirety after the conclusion of coverage, and the rest of the prime-time schedule on the East Coast is shifted to compensate. For example, if game coverage were to end at 7:30 p.m., prime time would end at 11:30 p.m.

However, in the rare case where the NFL game runs excessively late (8 p.m. or later), the series scheduled to air at 10 p.m. is preempted, with the West Coast and eastern markets airing only an early afternoon game usually receiving a repeat of the 10 p.m. series instead. In an extreme case, CBS's prime time can be extended past midnight during broadcasts of the NCAA Division I Men's Basketball Tournament. This does not necessarily apply universally; in 2001, after an XFL game went into double overtime, causing a 45-minute delay of a highly promoted episode of "Saturday Night Live", NBC made a decision to cut off all future XFL broadcasts at 11:00 p.m. ET. Since the launch of NBCSN, NBC has occasionally invoked this curfew by moving sports overruns to that channel if necessary.

Until the Federal Communications Commission (FCC) regulated time slots prior to prime time with the now-defunct Prime Time Access Rule in the 1971–1972 season, networks began programming at 7:30 p.m. Eastern and Pacific/6:30 p.m. Central and Mountain on weeknights. The change helped instigate what is colloquially known as the "rural purge"—a long-term trend away from programs appealing to older and rural audiences in favor of programs catering towards younger, "urban" viewers. As a result, the hour became a lucrative timeslot for syndicated programming in the years that followed, with game and variety shows, as well as other syndicated reruns, becoming popular.

The vast majority of prime-time programming in English-speaking North America comes from the United States, with only a limited amount produced in Canada. The Canadian Radio-television and Telecommunications Commission mandates quotas for Canadian content in prime time; these quotas indicate at least half of Canadian prime-time programs must be Canadian in origin, but the majority of this is served by national and local news or localized entertainment gossip shows such as Global's "ET Canada" and CTV's "eTalk".

Likewise, the vast majority of Spanish-language programming in North America comes from Mexico. Televisa, a Mexican network, provides the majority of programming to the dominant U.S.-based Spanish broadcaster, Univision. Univision does produce a fairly large amount of unscripted Spanish-language programming, the best known having been the long-running variety show "Sábado Gigante", hosted and created by Chilean national Don Francisco. Univision's distant second-place competitor, Telemundo, produces a much greater share of in-house content, including a long line of telenovelas.

In Quebec, the largest Francophone area of North America, French-language programming consists of originally produced programs (most of which are produced in Montreal, with a few produced in Quebec City) and a few French-language dubs of English language programs. On all of the Quebec networks, entertainment programming is scheduled only between 8 and 10 p.m., with the 10–11 p.m. hour given over to a network newscast or a nightly talk show.

Prime time is the daypart (a block of a day's programming schedule) with the most viewers and is generally where television networks and local stations reap much of their advertising revenues. In recent years television advertising expenditure in the US has been highest during prime-time drama shows.

The Nielsen ratings system is explicitly designed for the optimum measurement of audience viewership by dayparts with prime time being of most interest. Television viewership is, in general, highest on weekday evenings, as most Americans are at work during the day, asleep during the overnights, and out taking part in social events on weekends; thus, television has its highest audience at times when people are unlikely to be away from home.

Prime time for radio is called drive time and, in Eastern and Pacific Time, is 6–10 a.m. and 3–7 p.m. and, for Mountain and Central Time, is 5–9 a.m. and 2–6 p.m. The difference between peak radio listenership and television viewership times is due to the fact that people listen to their radios most often while driving to and from work (hence the name "drive time").

A survey by Nielsen revealed that viewers watched almost two hours' worth of TV during prime time.

In a great part of Latin American countries, prime time (known in most countries as "horario central" or "Central Time") is considered to be from 6:00 or 7:00 p.m. to 10:00 or 11:00 p.m. The time slot is usually used for news, telenovelas and television series, and special time slots are used for reality shows, with great popularity, especially in Mexico and Brazil. In Mexico, prime time is known as "horario estelar" ("Stellar Time"). In Brazil, it is called "horário nobre" ("noble time"), which is the time the three most famous telenovelas in the country are shown each weekday and on Saturdays. There are also news programs, reality shows, and sitcoms.

In Argentina, prime time is considered to be from 8:00 p.m. until 12:00 a.m.; with the most successful series and telenovelas in the country (such as "Los Roldán" and "Valientes"), and entertainment shows, like CQC (Caiga Quien Caiga).

In Chile, prime time is considered to be from 10:30 p.m. until 01:00 a.m.; with the most successful series and telenovelas in the country (such as "Socias" and "Las Vega's"). Investigation entertainment shows (like "Informe Especial", "Contacto", "Apuesto por tí") also air.

Prime time in Australia is officially from 6:00 p.m. to midnight, following Australian Eastern Standard Time, with the highest ratings normally achieved between 6:00 p.m. to 9:00 p.m.

Traditionally, prime time in New Zealand is considered to be 7:30pm to 10:30pm, but can be extended to cover the entire evening of television (5:30pm to 11:00pm).



</doc>
<doc id="24974" url="https://en.wikipedia.org/wiki?curid=24974" title="Pelton wheel">
Pelton wheel

A Pelton wheel is an impulse-type water turbine invented by Lester Allan Pelton in the 1870s. The Pelton wheel extracts energy from the impulse of moving water, as opposed to water's dead weight like the traditional overshot water wheel. Many earlier variations of impulse turbines existed, but they were less efficient than Pelton's design. Water leaving those wheels typically still had high speed, carrying away much of the dynamic energy brought to the wheels. Pelton's paddle geometry was designed so that when the rim ran at half the speed of the water jet, the water left the wheel with very little speed; thus his design extracted almost all of the water's impulse energywhich allowed for a very efficient turbine.

Lester Allan Pelton was born in Vermillion, Ohio in 1829. In 1850, he travelled overland to take part in the California Gold Rush. Pelton worked by selling fish he caught in the Sacramento River. In 1860, he moved to Camptonville, a center of placer mining activity. At this time many mining operations were powered by steam engines which consumed vast amounts of wood as their fuel. Some water wheels were used in the larger rivers, but they were ineffective in the smaller streams that were found near the mines. Pelton worked on a design for a water wheel that would work with the relatively small flow found in these streams.

By the mid 1870s, Pelton had developed a wooden prototype of his new wheel. In 1876, he approached the Miners Foundry in Nevada City, California to build the first commercial models in iron. The first Pelton Wheel was installed at the Mayflower Mine in Nevada City in 1878.. The efficiency advantages of Pelton's invention were quickly recognized and his product was soon in high demand. By the mid-1880s, the Miners Foundry could not meet the demand, and in 1888, Pelton sold the rights to his name and the patents to his invention to the Pelton Water Wheel Company in San Francisco. The company established a factory at 121/123 Main Street in San Francisco.

The Pelton Water Wheel Company manufactured a large number of Pelton Wheels in San Francisco which were shipped around the world. In 1892, the Company added a branch on the east coast at 143 Liberty Street in New York City. By 1900, over 11,000 turbines were in use. In 1914, the company moved manufacturing to new, larger premises at 612 Alabama Street in San Francisco. In 1956, the company was acquired by the Baldwin-Lima-Hamilton Company, which ended manufacture of Pelton Wheels.

In New Zealand, A & G Price in Thames, New Zealand produced Pelton waterwheels for the local market. One of these is on outdoor display at the Thames Goldmine Experience.

Nozzles direct forceful, high-speed streams of water against a series of spoon-shaped buckets, also known as impulse blades, which are mounted around the outer rim of a drive wheel (also called a "runner"). As the water jet hits the blades, the direction of water velocity is changed to follow the contours of the blades. The impulse energy of the water jet exerts torque on the bucket-and-wheel system, spinning the wheel; the water jet does a "u-turn" and exits at the outer sides of the bucket, decelerated to a low velocity. In the process, the water jet's momentum is transferred to the wheel and hence to a turbine. Thus, "impulse" energy does work on the turbine. Maximum power and efficiency are achieved when the velocity of the water jet is twice the velocity of the rotating buckets. A very small percentage of the water jet's original kinetic energy will remain in the water, which causes the bucket to be emptied at the same rate it is filled, and thereby allows the high-pressure input flow to continue uninterrupted and without waste of energy.

Typically two buckets are mounted side-by-side on the wheel, with the water jet split into two equal streams; this balances the side-load forces on the wheel and helps to ensure smooth, efficient transfer of momentum from the water jet to the turbine wheel.

Because water is nearly incompressible, almost all of the available energy is extracted in the first stage of the hydraulic turbine. Therefore, Pelton wheels have only one turbine stage, unlike gas turbines that operate with compressible fluid.

Pelton wheels are the preferred turbine for hydro-power where the available water source has relatively high hydraulic head at low flow rates. Pelton wheels are made in all sizes. There exist multi-ton Pelton wheels mounted on vertical oil pad bearings in hydroelectric plants. The largest units – the Bieudron Hydroelectric Power Station at the Grande Dixence Dam complex in Switzerland – are over 400 megawatts.

The smallest Pelton wheels are only a few inches across, and can be used to tap power from mountain streams having flows of a few gallons per minute. Some of these systems use household plumbing fixtures for water delivery. These small units are recommended for use with or more of head, in order to generate significant power levels. Depending on water flow and design, Pelton wheels operate best with heads from , although there is no theoretical limit.

The specific speed formula_1 parameter is independent of a particular turbine's size.

Compared to other turbine designs, the relatively low specific speed of the Pelton wheel, implies that the geometry is inherently a "low gear" design. Thus it is most suitable to being fed by a hydro source with a low ratio of flow to pressure, (meaning relatively low flow and/or relatively high pressure).

The specific speed is the main criterion for matching a specific hydro-electric site with the optimal turbine type. It also allows a new turbine design to be scaled from an existing design of known performance.

formula_2 (dimensioned parameter), 

where:

The formula implies that the Pelton turbine is "geared" most suitably for applications with relatively high hydraulic head "H", due to the 5/4 exponent being greater than unity, and given the characteristically low specific speed of the Pelton.

In the ideal (frictionless) case, all of the hydraulic potential energy ("E" = "mgh") is converted into kinetic energy ("E" = "mv"/2) (see Bernoulli's principle). Equating these two equations and solving for the initial jet velocity ("V") indicates that the theoretical (maximum) jet velocity is "V" = . For simplicity, assume that all of the velocity vectors are parallel to each other. Defining the velocity of the wheel runner as: ("u"), then as the jet approaches the runner, the initial jet velocity relative to the runner is: ("V" − "u").
The initial velocity of jet is "V"

Assuming that the jet velocity is higher than the runner velocity, if the water is not to become backed-up in runner, then due to conservation of mass, the mass entering the runner must equal the mass leaving the runner. The fluid is assumed to be incompressible (an accurate assumption for most liquids). Also it is assumed that the cross-sectional area of the jet is constant. The jet "speed" remains constant relative to the runner. So as the jet recedes from the runner, the jet velocity relative to the runner is: −("V" − "u") = −"V" + "u". In the standard reference frame (relative to the earth), the final velocity is then: "V" = (−"V" + u) + "u" = −"V" + 2"u".

We know that the ideal runner speed will cause all of the kinetic energy in the jet to be transferred to the wheel. In this case the final jet velocity must be zero. If we let −"V" + 2"u" = 0, then the optimal runner speed will be "u" = "V" /2, or half the initial jet velocity.

By Newton's second and third laws, the force "F" imposed by the jet on the runner is equal but opposite to the rate of momentum change of the fluid, so
where "ρ" is the density, and "Q" is the volume rate of flow of fluid. If "D" is the wheel diameter, the torque on the runner is
The torque is maximal when the runner is stopped (i.e. when "u" = 0, "T" = "ρQDV"). When the speed of the runner is equal to the initial jet velocity, the torque is zero (i.e. when "u" = "V", then "T" = 0). On a plot of torque versus runner speed, the torque curve is straight between these two points: (0, "pQDV") and ("V", 0).
Nozzle efficiency is the ratio of the jet power to the water power at the base of nozzle

The power "P" = "Fu" = "Tω", where "ω" is the angular velocity of the wheel. Substituting for "F", we have "P" = 2"ρQ"("V" − "u")"u". To find the runner speed at maximum power, take the derivative of "P" with respect to "u" and set it equal to zero, ["dP"/"du" = 2"ρQ"("V" − 2"u")]. Maximum power occurs when "u" = "V" /2. "P" = "ρQV"/2. Substituting the initial jet power "V" = , this simplifies to "P" = "ρghQ". This quantity exactly equals the kinetic power of the jet, so in this ideal case, the efficiency is 100%, since all the energy in the jet is converted to shaft output.

A wheel power divided by the initial jet power, is the turbine efficiency, "η" = 4"u"("V" − "u")/"V". It is zero for "u" = 0 and for "u" = "V". As the equations indicate, when a real Pelton wheel is working close to maximum efficiency, the fluid flows off the wheel with very little residual velocity. In theory, the energy efficiency varies only with the efficiency of the nozzle and wheel, and does not vary with hydraulic head.
The term "efficiency" can refer to: Hydraulic, Mechanical, Volumetric, Wheel, or overall efficiency.

The conduit bringing high-pressure water to the impulse wheel is called the penstock. Originally the penstock was the name of the valve, but the term has been extended to include all of the fluid supply hydraulics. Penstock is now used as a general term for a water passage and control that is under pressure, whether it supplies an impulse turbine or not.




</doc>
<doc id="24975" url="https://en.wikipedia.org/wiki?curid=24975" title="Piezoelectricity">
Piezoelectricity

Piezoelectricity is the electric charge that accumulates in certain solid materials (such as crystals, certain ceramics, and biological matter such as bone, DNA and various proteins) in response to applied mechanical stress. The word "piezoelectricity" means electricity resulting from pressure and latent heat. It is derived from the Greek word ; "piezein", which means to squeeze or press, and "ēlektron", which means amber, an ancient source of electric charge. French physicists Jacques and Pierre Curie discovered piezoelectricity in 1880.

The piezoelectric effect results from the linear electromechanical interaction between the mechanical and electrical states in crystalline materials with no inversion symmetry. The piezoelectric effect is a reversible process: materials exhibiting the piezoelectric effect (the internal generation of electrical charge resulting from an applied mechanical force) also exhibit the reverse piezoelectric effect, the internal generation of a mechanical strain resulting from an applied electrical field. For example, lead zirconate titanate crystals will generate measurable piezoelectricity when their static structure is deformed by about 0.1% of the original dimension. Conversely, those same crystals will change about 0.1% of their static dimension when an external electric field is applied to the material. The inverse piezoelectric effect is used in the production of ultrasonic sound waves.

Piezoelectricity is exploited in a number of useful applications, such as the production and detection of sound, piezoelectric inkjet printing, generation of high voltages, electronic frequency generation, microbalances, to drive an ultrasonic nozzle, and ultrafine focusing of optical assemblies. It forms the basis for a number of scientific instrumental techniques with atomic resolution, the scanning probe microscopies, such as STM, AFM, MTA, and SNOM. It also finds everyday uses such as acting as the ignition source for cigarette lighters, push-start propane barbecues, used as the time reference source in quartz watches, as well as in amplification pickups for some guitars and triggers in most modern electronic drums.

The pyroelectric effect, by which a material generates an electric potential in response to a temperature change, was studied by Carl Linnaeus and Franz Aepinus in the mid-18th century. Drawing on this knowledge, both René Just Haüy and Antoine César Becquerel posited a relationship between mechanical stress and electric charge; however, experiments by both proved inconclusive.
The first demonstration of the direct piezoelectric effect was in 1880 by the brothers Pierre Curie and Jacques Curie. They combined their knowledge of pyroelectricity with their understanding of the underlying crystal structures that gave rise to pyroelectricity to predict crystal behavior, and demonstrated the effect using crystals of tourmaline, quartz, topaz, cane sugar, and Rochelle salt (sodium potassium tartrate tetrahydrate). Quartz and Rochelle salt exhibited the most piezoelectricity.

The Curies, however, did not predict the converse piezoelectric effect. The converse effect was mathematically deduced from fundamental thermodynamic principles by Gabriel Lippmann in 1881. The Curies immediately confirmed the existence of the converse effect, and went on to obtain quantitative proof of the complete reversibility of electro-elasto-mechanical deformations in piezoelectric crystals.

For the next few decades, piezoelectricity remained something of a laboratory curiosity, though it was a vital tool in the discovery of polonium and radium by Pierre and Marie Curie in 1898. More work was done to explore and define the crystal structures that exhibited piezoelectricity. This culminated in 1910 with the publication of Woldemar Voigt's "Lehrbuch der Kristallphysik" ("Textbook on Crystal Physics"), which described the 20 natural crystal classes capable of piezoelectricity, and rigorously defined the piezoelectric constants using tensor analysis.

The first practical application for piezoelectric devices was sonar, first developed during World War I. In France in 1917, Paul Langevin and his coworkers developed an ultrasonic submarine detector. The detector consisted of a transducer, made of thin quartz crystals carefully glued between two steel plates, and a hydrophone to detect the returned echo. By emitting a high-frequency pulse from the transducer, and measuring the amount of time it takes to hear an echo from the sound waves bouncing off an object, one can calculate the distance to that object.

The use of piezoelectricity in sonar, and the success of that project, created intense development interest in piezoelectric devices. Over the next few decades, new piezoelectric materials and new applications for those materials were explored and developed.

Piezoelectric devices found homes in many fields. Ceramic phonograph cartridges simplified player design, were cheap and accurate, and made record players cheaper to maintain and easier to build. The development of the ultrasonic transducer allowed for easy measurement of viscosity and elasticity in fluids and solids, resulting in huge advances in materials research. Ultrasonic time-domain reflectometers (which send an ultrasonic pulse through a material and measure reflections from discontinuities) could find flaws inside cast metal and stone objects, improving structural safety.

During World War II, independent research groups in the United States, Russia, and Japan discovered a new class of synthetic materials, called ferroelectrics, which exhibited piezoelectric constants many times higher than natural materials. This led to intense research to develop barium titanate and later lead zirconate titanate materials with specific properties for particular applications.

One significant example of the use of piezoelectric crystals was developed by Bell Telephone Laboratories. Following World War I, Frederick R. Lack, working in radio telephony in the engineering department, developed the "AT cut" crystal, a crystal that operated through a wide range of temperatures. Lack's crystal did not need the heavy accessories previous crystal used, facilitating its use on aircraft. This development allowed Allied air forces to engage in coordinated mass attacks through the use of aviation radio.

Development of piezoelectric devices and materials in the United States was kept within the companies doing the development, mostly due to the wartime beginnings of the field, and in the interests of securing profitable patents. New materials were the first to be developed—quartz crystals were the first commercially exploited piezoelectric material, but scientists searched for higher-performance materials. Despite the advances in materials and the maturation of manufacturing processes, the United States market did not grow as quickly as Japan's did. Without many new applications, the growth of the United States' piezoelectric industry suffered.

In contrast, Japanese manufacturers shared their information, quickly overcoming technical and manufacturing challenges and creating new markets. In Japan, a temperature stable crystal cut was developed by Issac Koga. Japanese efforts in materials research created piezoceramic materials competitive to the United States materials but free of expensive patent restrictions. Major Japanese piezoelectric developments included new designs of piezoceramic filters for radios and televisions, piezo buzzers and audio transducers that can connect directly to electronic circuits, and the piezoelectric igniter, which generates sparks for small engine ignition systems and gas-grill lighters, by compressing a ceramic disc. Ultrasonic transducers that transmit sound waves through air had existed for quite some time but first saw major commercial use in early television remote controls. These transducers now are mounted on several car models as an echolocation device, helping the driver determine the distance from the car to any objects that may be in its path.

The nature of the piezoelectric effect is closely related to the occurrence of electric dipole moments in solids. The latter may either be induced for ions on crystal lattice sites with asymmetric charge surroundings (as in BaTiO and PZTs) or may directly be carried by molecular groups (as in cane sugar). The dipole density or polarization (dimensionality [C·m/m] ) may easily be calculated for crystals by summing up the dipole moments per volume of the crystallographic unit cell. As every dipole is a vector, the dipole density P is a vector field. Dipoles near each other tend to be aligned in regions called Weiss domains. The domains are usually randomly oriented, but can be aligned using the process of "poling" (not the same as magnetic poling), a process by which a strong electric field is applied across the material, usually at elevated temperatures. Not all piezoelectric materials can be poled.

Of decisive importance for the piezoelectric effect is the change of polarization P when applying a mechanical stress. This might either be caused by a reconfiguration of the dipole-inducing surrounding or by re-orientation of molecular dipole moments under the influence of the external stress. Piezoelectricity may then manifest in a variation of the polarization strength, its direction or both, with the details depending on: 1. the orientation of P within the crystal; 2. crystal symmetry; and 3. the applied mechanical stress. The change in P appears as a variation of surface charge density upon the crystal faces, i.e. as a variation of the electric field extending between the faces caused by a change in dipole density in the bulk. For example, a 1 cm cube of quartz with 2 kN (500 lbf) of correctly applied force can produce a voltage of 12500 V.

Piezoelectric materials also show the opposite effect, called the converse piezoelectric effect, where the application of an electrical field creates mechanical deformation in the crystal.

Linear piezoelectricity is the combined effect of

These may be combined into so-called "coupled equations", of which the strain-charge form is:
In matrix form,
where ["d"] is the matrix for the direct piezoelectric effect and ["d"] is the matrix for the converse piezoelectric effect. The superscript "E" indicates a zero, or constant, electric field; the superscript "T" indicates a zero, or constant, stress field; and the superscript t stands for transposition of a matrix.

Notice that the third order tensor formula_7 maps vectors into symmetric matrices. There are no non-trivial rotation-invariant tensors that have this property, which is why there are no isotropic piezoelectric materials.

The strain-charge for a material of the 4mm (C) crystal class (such as a poled piezoelectric ceramic such as tetragonal PZT or BaTiO) as well as the 6mm crystal class may also be written as (ANSI IEEE 176):

where the first equation represents the relationship for the converse piezoelectric effect and the latter for the direct piezoelectric effect.

Although the above equations are the most used form in literature, some comments about the notation are necessary. Generally, "D" and "E" are vectors, that is, Cartesian tensors of rank 1; and permittivity "ε" is a Cartesian tensor of rank 2. Strain and stress are, in principle, also rank-2 tensors. But conventionally, because strain and stress are all symmetric tensors, the subscript of strain and stress can be relabeled in the following fashion: 11 → 1; 22 → 2; 33 → 3; 23 → 4; 13 → 5; 12 → 6. (Different conventions may be used by different authors in literature. For example, some use 12 → 4; 23 → 5; 31 → 6 instead.) That is why "S" and "T" appear to have the "vector form" of six components. Consequently, "s" appears to be a 6-by-6 matrix instead of a rank-3 tensor. Such a relabeled notation is often called Voigt notation. Whether the shear strain components "S", "S", "S" are tensor components or engineering strains is another question. In the equation above, they must be engineering strains for the 6,6 coefficient of the compliance matrix to be written as shown, i.e., 2("s" − "s"). Engineering shear strains are double the value of the corresponding tensor shear, such as "S" = 2"S" and so on. This also means that "s" = , where "G" is the shear modulus.

In total, there are four piezoelectric coefficients, "d", "e", "g", and "h" defined as follows:

where the first set of four terms corresponds to the direct piezoelectric effect and the second set of four terms corresponds to the converse piezoelectric effect, and the reason why the direct piezoelectric tensor is equal to the transpose of the converse piezoelectric tensor originated from the Maxwell Relations in Thermodynamics. For those piezoelectric crystals for which the polarization is of the crystal-field induced type, a formalism has been worked out that allows for the calculation of piezoelectrical coefficients "d" from electrostatic lattice constants or higher-order Madelung constants.

Of the 32 crystal classes, 21 are non-centrosymmetric (not having a centre of symmetry), and of these, 20 exhibit direct piezoelectricity (the 21st is the cubic class 432). Ten of these represent the polar crystal classes, which show a spontaneous polarization without mechanical stress due to a non-vanishing electric dipole moment associated with their unit cell, and which exhibit pyroelectricity. If the dipole moment can be reversed by applying an external electric field, the material is said to be ferroelectric.


For polar crystals, for which P ≠ 0 holds without applying a mechanical load, the piezoelectric effect manifests itself by changing the magnitude or the direction of P or both.

For the nonpolar but piezoelectric crystals, on the other hand, a polarization P different from zero is only elicited by applying a mechanical load. For them the stress can be imagined to transform the material from a nonpolar crystal class (P = 0) to a polar one, having P ≠ 0.

Many materials exhibit piezoelectricity.

Ceramics with randomly oriented grains must be ferroelectric to exhibit piezoelectricity. The macroscopic piezoelectricity is possible in textured polycrystalline non-ferroelectric piezoelectric materials, such as AlN and ZnO.
The family of ceramics with perovskite, tungsten-bronze and related structures exhibits piezoelectricity:

So far, neither the environmental effect nor the stability of supplying these substances has been measured.

A piezoelectric potential can be created in any bulk or nanostructured semiconductor crystal having non central symmetry, such as the Group III–V and II–VI materials, due to polarization of ions under applied stress and strain. This property is common to both the zincblende and wurtzite crystal structures. To first order, there is only one independent piezoelectric coefficient in zincblende, called e, coupled to shear components of the strain. In wurtzite, there are instead three independent piezoelectric coefficients: "e", "e" and "e".
The semiconductors where the strongest piezoelectricity is observed are those commonly found in the wurtzite structure, i.e. GaN, InN, AlN and ZnO (see piezotronics).

Since 2006, there have also been a number of reports of strong non linear piezoelectric effects in polar semiconductors.
Such effects are generally recognized to be at least important if not of the same order of magnitude as the first order approximation.

The piezo-response of polymers is not as high as the response for ceramics; however, polymers hold properties that ceramics do not. Over the last few decades, non-toxic, piezoelectric polymers have been studied and applied due to their flexibility and smaller acoustical impedance. Other properties that make these materials significant include their biocompatibility, biodegradability, low cost, and low power consumption compared to other piezo-materials (ceramics, etc.). Piezoelectric polymers and non-toxic polymer composites can be used given their different physical properties.

Piezoelectric polymers can be classified by bulk polymers, voided charged polymers, and polymer composites. A piezo-response observed by bulk polymers is mostly due to its molecular structure. There are two types of bulk polymers: amorphous and semi-crystalline. Examples of semi-crystalline polymers are Polyvinylidene Fluoride (PVDF) and its copolymers, Polyamides, and Paralyne-C. Non-crystalline polymers, such as Polyimide and Polyvinylidene Chloride (PVDC), fall under amorphous bulk polymers. Voided charged polymers exhibit the piezoelectric effect due to charge induced by poling of a porous polymeric film. Under an electric field, charges form on the surface of the voids forming dipoles. Electric responses can be caused by any deformation of these voids. The piezoelectric effect can also be observed in polymer composites by integrating piezoelectric ceramic particles into a polymer film. A polymer does not have to be piezo-active to be an effective material for a polymer composite. In this case, a material could be made up of an inert matrix with a separate piezo-active component.

PVDF exhibits piezoelectricity several times greater than quartz. The piezo-response observed from PVDF is about 20–30 pC/N. That is an order of 5–50 times less than that of piezoelectric ceramic lead zirconate titanate (PZT). The thermal stability of the piezoelectric effect of polymers in the PVDF family (ie. vinylidene fluoride co-poly trifluoroethylene) goes up to 125 °C. Some applications of PVDF are pressure sensors, hydrophones, and shock wave sensors.

Due to their flexibility, piezoelectric composites have been proposed as energy harvesters and nanogenerators. In 2018, it was reported by Zhu et al. that a piezoelectric response of about 17 pC/N could be obtained from PDMS/PZT nanocomposite at 60% porosity. Another PDMS nanocomposite was reported in 2017, in which BaTiO3 was integrated into PDMS to make a stretchable, transparent nanogenerator for self-powered physiological monitoring. In 2016, polar molecules were introduced into a polyurethane foam in which high responses of up to 244 pC/N were reported. 
Most materials exhibit at least weak piezoelectric responses. Trivial examples include sucrose (table sugar), DNA, viral proteins, including those from bacteriophage. An actuator based on wood fibers, called cellulose fibers, has been reported. D33 responses for cellular polypropylene are around 200 pC/N. Some applications of cellular polypropylene are musical key pads, microphones, and ultrasound-based echolocation systems.

Currently, industrial and manufacturing is the largest application market for piezoelectric devices, followed by the automotive industry. Strong demand also comes from medical instruments as well as information and telecommunications. The global demand for piezoelectric devices was valued at approximately US$14.8 billion in 2010. The largest material group for piezoelectric devices is piezoceramics, and piezopolymer is experiencing the fastest growth due to its low weight and small size.

Piezoelectric crystals are now used in numerous ways:

Direct piezoelectricity of some substances, like quartz, can generate potential differences of thousands of volts.

The principle of operation of a piezoelectric sensor is that a physical dimension, transformed into a force, acts on two opposing faces of the sensing element. Depending on the design of a sensor, different "modes" to load the piezoelectric element can be used: longitudinal, transversal and shear.

Detection of pressure variations in the form of sound is the most common sensor application, e.g. piezoelectric microphones (sound waves bend the piezoelectric material, creating a changing voltage) and piezoelectric pickups for acoustic-electric guitars. A piezo sensor attached to the body of an instrument is known as a contact microphone.

Piezoelectric sensors especially are used with high frequency sound in ultrasonic transducers for medical imaging and also industrial nondestructive testing (NDT).

For many sensing techniques, the sensor can act as both a sensor and an actuator—often the term "transducer" is preferred when the device acts in this dual capacity, but most piezo devices have this property of reversibility whether it is used or not. Ultrasonic transducers, for example, can inject ultrasound waves into the body, receive the returned wave, and convert it to an electrical signal (a voltage). Most medical ultrasound transducers are piezoelectric.

In addition to those mentioned above, various sensor applications include:

As very high electric fields correspond to only tiny changes in the width of the crystal, this width can be changed with better-than-µm precision, making piezo crystals the most important tool for positioning objects with extreme accuracy—thus their use in actuators.
Multilayer ceramics, using layers thinner than , allow reaching high electric fields with voltage lower than . These ceramics are used within two kinds of actuators: direct piezo actuators and Amplified piezoelectric actuators. While direct actuator's stroke is generally lower than , amplified piezo actuators can reach millimeter strokes.

The piezoelectrical properties of quartz are useful as a standard of frequency.

Types of piezoelectric motor include:

Aside from the stepping stick-slip motor, all these motors work on the same principle. Driven by dual orthogonal vibration modes with a phase difference of 90°, the contact point between two surfaces vibrates in an elliptical path, producing a frictional force between the surfaces. Usually, one surface is fixed, causing the other to move. In most piezoelectric motors, the piezoelectric crystal is excited by a sine wave signal at the resonant frequency of the motor. Using the resonance effect, a much lower voltage can be used to produce a high vibration amplitude.

A stick-slip motor works using the inertia of a mass and the friction of a clamp. Such motors can be very small. Some are used for camera sensor displacement, thus allowing an anti-shake function.

Different teams of researchers have been investigating ways to reduce vibrations in materials by attaching piezo elements to the material. When the material is bent by a vibration in one direction, the vibration-reduction system responds to the bend and sends electric power to the piezo element to bend in the other direction. Future applications of this technology are expected in cars and houses to reduce noise. Further applications to flexible structures, such as shells and plates, have also been studied for nearly three decades.

In a demonstration at the Material Vision Fair in Frankfurt in November 2005, a team from TU Darmstadt in Germany showed several panels that were hit with a rubber mallet, and the panel with the piezo element immediately stopped swinging.

Piezoelectric ceramic fiber technology is being used as an electronic damping system on some HEAD tennis rackets.

In people with previous total fertilization failure, piezoelectric activation of oocytes together with intracytoplasmic sperm injection (ICSI) seems to improve fertilization outcomes.

Piezosurgery Piezosurgery is a minimally invasive technique that aims to cut a target tissue with little damage to neighboring tissues. For example, Hoigne "et al." uses frequencies in the range 25–29 kHz, causing microvibrations of 60–210 μm. It has the ability to cut mineralized tissue without cutting neurovascular tissue and other soft tissue, thereby maintaining a blood-free operating area, better visibility and greater precision.

In 2015, Cambridge University researchers working in conjunction with researchers from the National Physical Laboratory and Cambridge-based dielectric antenna company Antenova Ltd, using thin films of piezoelectric materials found that at a certain frequency, these materials become not only efficient resonators, but efficient radiators as well, meaning that they can potentially be used as antennas. The researchers found that by subjecting the piezoelectric thin films to an asymmetric excitation, the symmetry of the system is similarly broken, resulting in a corresponding symmetry breaking of the electric field, and the generation of electromagnetic radiation.

Several attempts at the macro-scale application of the piezoelectric technology have emerged to harvest kinetic energy from walking pedestrians.

In this case, locating high traffic areas is critical for optimization of the energy harvesting efficiency, as well as the orientation of the tile pavement significantly affects the total amount of the harvested energy. A density flow evaluation is recommended to qualitatively evaluate the piezoelectric power harvesting potential of the considered area based on the number of pedestrian crossings per unit time. In X. Li's study, the potential application of a commercial piezoelectric energy harvester in a central hub building at Macquarie University in Sydney, Australia is examined and discussed. Optimization of the piezoelectric tile deployment is presented according to the frequency of pedestrian mobility and a model is developed where 3.1% of the total floor area with the highest pedestrian mobility is paved with piezoelectric tiles. The modelling results indicate that the total annual energy harvesting potential for the proposed optimized tile pavement model is estimated at 1.1 MW h/year, which would be sufficient to meet close to 0.5% of the annual energy needs of the building. In Israel, there is a company which has installed piezoelectric materials under a busy highway. The energy generated is adequate and powers street lights, billboards and signs.

Tire company Goodyear has plans to develop an electricity generating tire which has piezoelectric material lined inside it. As the tire moves, it deforms and thus electricity is generated.

The efficiency of a hybrid photovoltaic cell that contains piezoelectric materials can be increased simply by placing it near a source of ambient noise or vibration. The effect was demonstrated with organic cells using zinc oxide nanotubes. The electricity generated by the piezoelectric effect itself is a negligible percentage of the overall output. Sound levels as low as 75 decibels improved efficiency by up to 50%. Efficiency peaked at 10 kHz, the resonant frequency of the nanotubes. The electrical field set up by the vibrating nanotubes interacts with electrons migrating from the organic polymer layer. This process decreases the likelihood of recombination, in which electrons are energized but settle back into a hole instead of migrating to the electron-accepting ZnO layer.




</doc>
<doc id="24977" url="https://en.wikipedia.org/wiki?curid=24977" title="Product (mathematics)">
Product (mathematics)

In mathematics, a product is the result of multiplying, or an expression that identifies factors to be multiplied. Thus, for instance, 15 is the product of 3 and 5 (the result of multiplication), and formula_1 is the product of formula_2 and formula_3 (indicating that the two factors should be multiplied together).

The order in which real or complex numbers are multiplied has no bearing on the product; this is known as the commutative law of multiplication. When matrices or members of various other associative algebras are multiplied, the product usually depends on the order of the factors. Matrix multiplication, for example, and multiplication in other algebras is in general non-commutative.

There are many different kinds of products in mathematics: besides being able to multiply just numbers, polynomials or matrices, one can also define products on many different algebraic structures.

Placing several stones into a rectangular pattern with formula_4 rows and formula_5 columns gives

stones. Another approach to multiplication that applies also to real numbers is continuously stretching the number line from , so that the is stretched to the one factor, and looking up the product, where the other factor is stretched to.

Integers allow positive and negative numbers. Their product is determined by the product of their positive amounts, combined with the sign derived from the following rule, which is a necessary consequence of demanding distributivity of the multiplication over addition, but is "no additional rule".

In words, we have:

Two fractions can be multiplied by multiplying their numerators and denominators:

For a rigorous definition of the product of two real numbers see Construction of the real numbers.

Two complex numbers can be multiplied by the distributive law and the fact that formula_9, as follows:

Complex numbers can be written in polar coordinates:
Furthermore,
from which one obtains

The geometric meaning is that the magnitudes are multiplied and the arguments are added.

The product of two quaternions can be found in the article on quaternions. However, in this case, formula_14 and formula_15 are in general different.

The product operator for the product of a sequence is denoted by the capital Greek letter pi ∏ (in analogy to the use of the capital Sigma ∑ as summation symbol). The product of a sequence consisting of only one number is just that number itself. The product of no factors at all is known as the empty product, and is equal to 1.

Commutative rings have a product operation.

Residue classes in the rings formula_16 can be added:

and multiplied:

Two functions from the reals to itself can be multiplied in another way, called the convolution.

If

then the integral

is well defined and is called the convolution.

Under the Fourier transform, convolution becomes point-wise function multiplication.

The product of two polynomials is given by the following:

with

There are many different kinds of products in linear algebra; some of these have confusingly similar names (outer product, exterior product) but have very different meanings. Others have very different names (outer product, tensor product, Kronecker product) but convey essentially the same idea. A brief overview of these is given here.

By the very definition of a vector space, one can form the product of any scalar with any vector, giving a map formula_23.

A scalar product is a bi-linear map:

with the following conditions, that formula_25 for all formula_26.

From the scalar product, one can define a norm by letting formula_27.

The scalar product also allows one to define an angle between two vectors:

In formula_29-dimensional Euclidean space, the standard scalar product (called the dot product) is given by:

The cross product of two vectors in 3-dimensions is a vector perpendicular to the two factors, with length equal to the area of the parallelogram spanned by the two factors.

The cross product can also be expressed as the formal determinant:

A linear mapping can be defined as a function "f" between two vector spaces "V" and "W" with underlying field F, satisfying
If one only considers finite dimensional vector spaces, then
in which b andb denote the bases of "V" and "W", and "v" denotes the component of v on b, and Einstein summation convention is applied.

Now we consider the composition of two linear mappings between finite dimensional vector spaces. Let the linear mapping "f" map "V" to "W", and let the linear mapping "g" map "W" to "U". Then one can get
Or in matrix form:
in which the "i"-row, "j"-column element of F, denoted by "F", is "f", and "G=g".

The composition of more than two linear mappings can be similarly represented by a chain of matrix multiplication.

Given two matrices

their product is given by

There is a relationship between the composition of linear functions and the product of two matrices. To see this, let r = dim(U), s = dim(V) and t = dim(W) be the (finite) dimensions of vector spaces U, V and W. Let 
formula_39 be a basis of U, 
formula_40 be a basis of V and 
formula_41 be a basis of W. In terms of this basis, let
formula_42
be the matrix representing f : U → V and 
formula_43 
be the matrix representing g : V → W. Then

is the matrix representing formula_45.

In other words: the matrix product is the description in coordinates of the composition of linear functions.

Given two finite dimensional vector spaces "V" and "W", the tensor product of them can be defined as a (2,0)-tensor satisfying:
where "V" and "W" denote the dual spaces of "V" and "W".

For infinite-dimensional vector spaces, one also has the:

The tensor product, outer product and Kronecker product all convey the same general idea. The differences between these are that the Kronecker product is just a tensor product of matrices, with respect to a previously-fixed basis, whereas the tensor product is usually given in its intrinsic definition. The outer product is simply the Kronecker product, limited to vectors (instead of matrices).

In general, whenever one has two mathematical objects that can be combined in a way that behaves like a linear algebra tensor product, then this can be most generally understood as the internal product of a monoidal category. That is, the monoidal category captures precisely the meaning of a tensor product; it captures exactly the notion of why it is that tensor products behave the way they do. More precisely, a monoidal category is the class of all things (of a given type) that have a tensor product.

Other kinds of products in linear algebra include:


In set theory, a Cartesian product is a mathematical operation which returns a set (or product set) from multiple sets. That is, for sets "A" and "B", the Cartesian product is the set of all ordered pairs where and .

The class of all things (of a given type) that have Cartesian products is called a Cartesian category. Many of these are Cartesian closed categories. Sets are an example of such objects.

The empty product on numbers and most algebraic structures has the value of 1 (the identity element of multiplication) just like the empty sum has the value of 0 (the identity element of addition). However, the concept of the empty product is more general, and requires special treatment in logic, set theory, computer programming and category theory.

Products over other kinds of algebraic structures include:

A few of the above products are examples of the general notion of an internal product in a monoidal category; the rest are describable by the general notion of a product in category theory.

All of the previous examples are special cases or examples of the general notion of a product. For the general treatment of the concept of a product, see product (category theory), which describes how to combine two objects of some kind to create an object, possibly of a different kind. But also, in category theory, one has:





</doc>
<doc id="24979" url="https://en.wikipedia.org/wiki?curid=24979" title="4-polytope">
4-polytope

In geometry, a 4-polytope (sometimes also called a polychoron, polycell, or polyhedroid) is a four-dimensional polytope. It is a connected and closed figure, composed of lower-dimensional polytopal elements: vertices, edges, faces (polygons), and cells (polyhedra). Each face is shared by exactly two cells.

The two-dimensional analogue of a 4-polytope is a polygon, and the three-dimensional analogue is a polyhedron.

Topologically 4-polytopes are closely related to the uniform honeycombs, such as the cubic honeycomb, which tessellate 3-space; similarly the 3D cube is related to the infinite 2D square tiling. Convex 4-polytopes can be "cut and unfolded" as nets in 3-space.

A 4-polytope is a closed four-dimensional figure. It comprises vertices (corner points), edges, faces and cells. A cell is the three-dimensional analogue of a face, and is therefore a polyhedron. Each face must join exactly two cells, analogous to the way in which each edge of a polyhedron joins just two faces. Like any polytope, the elements of a 4-polytope cannot be subdivided into two or more sets which are also 4-polytopes, i.e. it is not a compound.

The most familiar 4-polytope is the tesseract or hypercube, the 4D analogue of the cube.
4-polytopes cannot be seen in three-dimensional space due to their extra dimension. Several techniques are used to help visualise them.

Orthogonal projections can be used to show various symmetry orientations of a 4-polytope. They can be drawn in 2D as vertex-edge graphs, and can be shown in 3D with solid faces as visible projective envelopes.
Just as a 3D shape can be projected onto a flat sheet, so a 4-D shape can be projected onto 3-space or even onto a flat sheet. One common projection is a Schlegel diagram which uses stereographic projection of points on the surface of a 3-sphere into three dimensions, connected by straight edges, faces, and cells drawn in 3-space.

Just as a slice through a polyhedron reveals a cut surface, so a slice through a 4-polytope reveals a cut "hypersurface" in three dimensions. A sequence of such sections can be used to build up an understanding of the overall shape. The extra dimension can be equated with time to produce a smooth animation of these cross sections.

A net of a 4-polytope is composed of polyhedral cells that are connected by their faces and all occupy the same three-dimensional space, just as the polygon faces of a net of a polyhedron are connected by their edges and all occupy the same plane.

The topology of any given 4-polytope is defined by its Betti numbers and torsion coefficients.

The value of the Euler characteristic used to characterise polyhedra does not generalize usefully to higher dimensions, and is zero for all 4-polytopes, whatever their underlying topology. This inadequacy of the Euler characteristic to reliably distinguish between different topologies in higher dimensions led to the discovery of the more sophisticated Betti numbers.

Similarly, the notion of orientability of a polyhedron is insufficient to characterise the surface twistings of toroidal 4-polytopes, and this led to the use of torsion coefficients.

Like all polytopes, 4-polytopes may be classified based on properties like "convexity" and "symmetry".


The following lists the various categories of 4-polytopes classified according to the criteria above:

Uniform 4-polytope (vertex-transitive):

Other convex 4-polytopes:
Infinite uniform 4-polytopes of Euclidean 3-space (uniform tessellations of convex uniform cells)

Infinite uniform 4-polytopes of hyperbolic 3-space (uniform tessellations of convex uniform cells)

Dual uniform 4-polytope (cell-transitive):

Others:

Abstract regular 4-polytopes:

These categories include only the 4-polytopes that exhibit a high degree of symmetry. Many other 4-polytopes are possible, but they have not been studied as extensively as the ones included in these categories.





</doc>
<doc id="24980" url="https://en.wikipedia.org/wiki?curid=24980" title="Punctuated equilibrium">
Punctuated equilibrium

Punctuated equilibrium (also called punctuated equilibria) is a theory in evolutionary biology which proposes that once a species appears in the fossil record the population will become stable, showing little evolutionary change for most of its geological history. This state of little or no morphological change is called "stasis". When significant evolutionary change occurs, the theory proposes that it is generally restricted to rare and geologically rapid events of branching speciation called cladogenesis. Cladogenesis is the process by which a species splits into two distinct species, rather than one species gradually transforming into another.

Punctuated equilibrium is commonly contrasted against phyletic gradualism, the idea that evolution generally occurs uniformly and by the steady and gradual transformation of whole lineages (called anagenesis). In this view, evolution is seen as generally smooth and continuous.

In 1972, paleontologists Niles Eldredge and Stephen Jay Gould published a landmark paper developing their theory and called it "punctuated equilibria". Their paper built upon Ernst Mayr's model of geographic speciation, I. Michael Lerner's theories of developmental and genetic homeostasis, and their own empirical research. Eldredge and Gould proposed that the degree of gradualism commonly attributed to Charles Darwin is virtually nonexistent in the fossil record, and that stasis dominates the history of most fossil species.

Punctuated equilibrium originated as a logical consequence of Ernst Mayr's concept of genetic revolutions by allopatric and especially peripatric speciation as applied to the fossil record. Although the sudden appearance of species and its relationship to speciation was proposed and identified by Mayr in 1954, historians of science generally recognize the 1972 Eldredge and Gould paper as the basis of the new paleobiological research program. Punctuated equilibrium differs from Mayr's ideas mainly in that Eldredge and Gould placed considerably greater emphasis on stasis, whereas Mayr was concerned with explaining the morphological discontinuity (or "sudden jumps") found in the fossil record. Mayr later complimented Eldredge and Gould's paper, stating that evolutionary stasis had been "unexpected by most evolutionary biologists" and that punctuated equilibrium "had a major impact on paleontology and evolutionary biology."

A year before their 1972 Eldredge and Gould paper, Niles Eldredge published a paper in the journal "Evolution" which suggested that gradual evolution was seldom seen in the fossil record and argued that Ernst Mayr's standard mechanism of allopatric speciation might suggest a possible resolution.

The Eldredge and Gould paper was presented at the Annual Meeting of the Geological Society of America in 1971. The symposium focused its attention on how modern microevolutionary studies could revitalize various aspects of paleontology and macroevolution. Tom Schopf, who organized that year's meeting, assigned Gould the topic of speciation. Gould recalls that "Eldredge's 1971 publication [on Paleozoic trilobites] had presented the only new and interesting ideas on the paleontological implications of the subject—so I asked Schopf if we could present the paper jointly." According to Gould "the ideas came mostly from Niles, with yours truly acting as a sounding board and eventual scribe. I coined the term "punctuated equilibrium" and wrote most of our 1972 paper, but Niles is the proper first author in our pairing of Eldredge and Gould." In his book "Time Frames" Eldredge recalls that after much discussion the pair "each wrote roughly half. Some of the parts that would seem obviously the work of one of us were actually first penned by the other—I remember for example, writing the section on Gould's snails. Other parts are harder to reconstruct. Gould edited the entire manuscript for better consistency. We sent it in, and Schopf reacted strongly against it—thus signaling the tenor of the reaction it has engendered, though for shifting reasons, down to the present day."

John Wilkins and Gareth Nelson have argued that French architect Pierre Trémaux proposed an "anticipation of the theory of punctuated equilibrium of Gould and Eldredge."

The fossil record includes well documented examples of both phyletic gradualism and punctuational evolution. As such, much debate persists over the prominence of stasis in the fossil record. Before punctuated equilibrium, most evolutionists considered stasis to be rare or unimportant. The paleontologist George Gaylord Simpson, for example, believed that phyletic gradual evolution (called "horotely" in his terminology) comprised 90% of evolution. More modern studies, including a meta-analysis examining 58 published studies on speciation patterns in the fossil record showed that 71% of species exhibited stasis, and 63% were associated with punctuated patterns of evolutionary change. According to Michael Benton, "it seems clear then that stasis is common, and that had not been predicted from modern genetic studies." A paramount example of evolutionary stasis is the fern "Osmunda claytoniana". Based on paleontological evidence it has remained unchanged, even at the level of fossilized nuclei and chromosomes, for at least 180 million years.

When Eldredge and Gould published their 1972 paper, allopatric speciation was considered the "standard" model of speciation. This model was popularized by Ernst Mayr in his 1954 paper "Change of genetic environment and evolution," and his classic volume "Animal Species and Evolution" (1963).

Allopatric speciation suggests that species with large central populations are stabilized by their large volume and the process of gene flow. New and even beneficial mutations are diluted by the population's large size and are unable to reach fixation, due to such factors as constantly changing environments. If this is the case, then the transformation of whole lineages should be rare, as the fossil record indicates. Smaller populations on the other hand, which are isolated from the parental stock, are decoupled from the homogenizing effects of gene flow. In addition, pressure from natural selection is especially intense, as peripheral isolated populations exist at the outer edges of ecological tolerance. If most evolution happens in these rare instances of allopatric speciation then evidence of gradual evolution in the fossil record should be rare. This hypothesis was alluded to by Mayr in the closing paragraph of his 1954 paper:

Although punctuated equilibrium generally applies to sexually reproducing organisms, some biologists have applied the model to non-sexual species like viruses, which cannot be stabilized by conventional gene flow. As time went on biologists like Gould moved away from wedding punctuated equilibrium to allopatric speciation, particularly as evidence accumulated in support of other modes of speciation. Gould, for example, was particularly attracted to Douglas Futuyma's work on the importance of reproductive isolating mechanisms.

Many hypotheses have been proposed to explain the putative causes of stasis. Gould was initially attracted to I. Michael Lerner's theories of developmental and genetic homeostasis. However this hypothesis was rejected over time, as evidence accumulated against it. Other plausible mechanisms which have been suggested include: habitat tracking, stabilizing selection, the Stenseth-Maynard Smith stability hypothesis, constraints imposed by the nature of subdivided populations, normalizing clade selection, and koinophilia.

Evidence for stasis has also been corroborated from the genetics of sibling species, species which are morphologically indistinguishable, but whose proteins have diverged sufficiently to suggest they have been separated for millions of years. Fossil evidence of reproductively isolated extant species of sympatric Olive Shells ("Amalda" sp.) also confirm morphological stasis in multiple lineages over three million years. 

According to Gould, "stasis may emerge as the theory's most important contribution to evolutionary science." Philosopher Kim Sterelny in clarifying the meaning of stasis adds, "In claiming that species typically undergo no further evolutionary change once speciation is complete, they are not claiming that there is no change at all between one generation and the next. Lineages do change. But the change between generations does not accumulate. Instead, over time, the species wobbles about its phenotypic mean. Jonathan Weiner's "The Beak of the Finch" describes this very process."

Punctuated equilibrium has also been cited as contributing to the hypothesis that species are Darwinian individuals, and not just classes, thereby providing a stronger framework for a hierarchical theory of evolution.

Much confusion has arisen over what proponents of punctuated equilibrium actually argued, what mechanisms they advocated, how fast the punctuations were, what taxonomic scale their theory applied to, how revolutionary their claims were intended to be, and how punctuated equilibrium related to other ideas like saltationism, quantum evolution, and mass extinction.

The punctuational nature of punctuated equilibrium has engendered perhaps the most confusion over Eldredge and Gould's theory. Gould's sympathetic treatment of Richard Goldschmidt, the controversial geneticist who advocated the idea of "hopeful monsters," led some biologists to conclude that Gould's punctuations were occurring in single-generation jumps. This interpretation has frequently been used by creationists to characterize the weakness of the paleontological record, and to portray contemporary evolutionary biology as advancing neo-saltationism. In an often quoted remark, Gould stated, "Since we proposed punctuated equilibria to explain trends, it is infuriating to be quoted again and again by creationists—whether through design or stupidity, I do not know—as admitting that the fossil record includes no transitional forms. Transitional forms are generally lacking at the species level, but they are abundant between larger groups." Although there exist some debate over how long the punctuations last, supporters of punctuated equilibrium generally place the figure between 50,000 and 100,000 years.

Quantum evolution was a controversial hypothesis advanced by Columbia University paleontologist George Gaylord Simpson, who was regarded by Gould as "the greatest and most biologically astute paleontologist of the twentieth century." Simpson's conjecture was that according to the geological record, on very rare occasions evolution would proceed very rapidly to form entirely new families, orders, and classes of organisms. This hypothesis differs from punctuated equilibrium in several respects. First, punctuated equilibrium was more modest in scope, in that it was addressing evolution specifically at the species level. Simpson's idea was principally concerned with evolution at higher taxonomic groups. Second, Eldredge and Gould relied upon a different mechanism. Where Simpson relied upon a synergistic interaction between genetic drift and a shift in the adaptive fitness landscape, Eldredge and Gould relied upon ordinary speciation, particularly Ernst Mayr's concept of allopatric speciation. Lastly, and perhaps most significantly, quantum evolution took no position on the issue of stasis. Although Simpson acknowledged the existence of stasis in what he called the bradytelic mode, he considered it (along with rapid evolution) to be unimportant in the larger scope of evolution. In his "Major Features of Evolution" Simpson stated, "Evolutionary change is so nearly the universal rule that a state of motion is, figuratively, normal in evolving populations. The state of rest, as in bradytely, is the exception and it seems that some restraint or force must be required to maintain it." Despite such differences between the two models, earlier critiques—from such eminent commentators as Sewall Wright as well as Simpson himself—have argued that punctuated equilibrium is little more than quantum evolution relabeled.

Punctuated equilibrium is often portrayed to oppose the concept of gradualism, when it is actually a form of gradualism. This is because even though evolutionary change appears instantaneous between geological sedimentary layers, change is still occurring incrementally, with no great change from one generation to the next. To this end, Gould later commented that "Most of our paleontological colleagues missed this insight because they had not studied evolutionary theory and either did not know about allopatric speciation or had not considered its translation to geological time. Our evolutionary colleagues also failed to grasp the implication(s), primarily because they did not think at geological scales".

Richard Dawkins dedicated a chapter in "The Blind Watchmaker" to correcting, in his view, the wide confusion regarding "rates of change". His first point is to argue that phyletic gradualism—understood in the sense that evolution proceeds at a single uniform rate of speed, called "constant speedism" by Dawkins—is a "caricature of Darwinism" and "does not really exist". His second argument, which follows from the first, is that once the caricature of "constant speedism" is dismissed, we are left with one logical alternative, which Dawkins terms "variable speedism". Variable speedism may also be distinguished one of two ways: ""discrete variable" speedism" and ""continuously variable" speedism". Eldredge and Gould, proposing that evolution jumps between stability and relative rapidity, are described as "discrete variable speedists", and "in this respect they are genuinely radical." They assert that evolution generally proceeds in bursts, or not at all. "Continuously variable speedists", on the other hand, advance that "evolutionary rates fluctuate continuously from very fast to very slow and stop, with all intermediates. They see no particular reason to emphasize certain speeds more than others. In particular, stasis, to them, is just an extreme case of ultra-slow evolution. To a punctuationist, there is something very special about stasis." Dawkins therefore commits himself here to an empirical claim about the geological record, in contrast to his earlier claim that "The paleontological evidence can be argued about, and I am not qualified to judge it." It is this particular commitment that Eldredge and Gould have aimed to overturn.

Richard Dawkins regards the apparent gaps represented in the fossil record to document migratory events rather than evolutionary events. According to Dawkins, evolution certainly occurred but "probably gradually" elsewhere. However, the punctuational equilibrium model may still be inferred from both the observation of stasis and examples of rapid and episodic speciation events documented in the fossil record.

Dawkins also emphasizes that punctuated equilibrium has been "oversold by some journalists", but partly due to Eldredge and Gould's "later writings". Dawkins contends that the hypothesis "does not deserve a particularly large measure of publicity". It is a "minor gloss," an "interesting but minor wrinkle on the surface of neo-Darwinian theory," and "lies firmly within the neo-Darwinian synthesis".

In his book "Darwin's Dangerous Idea", philosopher Daniel Dennett is especially critical of Gould's presentation of punctuated equilibrium. Dennett argues that Gould alternated between revolutionary and conservative claims, and that each time Gould made a revolutionary statement—or appeared to do so—he was criticized, and thus retreated to a traditional neo-Darwinian position. Gould responded to Dennett's claims in "The New York Review of Books", and in his technical volume "The Structure of Evolutionary Theory".

English professor Heidi Scott argues that Gould's talent for writing vivid prose, his use of metaphor, and his success in building a popular audience of nonspecialist readers altered the "climate of specialized scientific discourse" favorably in his promotion of punctuated equilibrium. While Gould is celebrated for the color and energy of his prose, as well as his interdisciplinary knowledge, critics such as Scott, Richard Dawkins, and Daniel Dennett have concerns that the theory has gained undeserved credence among non-scientists because of Gould's rhetorical skills. Philosopher John Lyne and biologist Henry Howe believed punctuated equilibrium's success has much more to do with the nature of the geological record than the nature of Gould's rhetoric. They state, a "re-analysis of existing fossil data has shown, to the increasing satisfaction of the paleontological community, that Eldredge and Gould were correct in identifying periods of evolutionary stasis which are interrupted by much shorter periods of evolutionary change."

Some critics jokingly referred to the theory of punctuated equilibrium as "evolution by jerks",
which reportedly prompted punctuationists to describe phyletic gradualism as "evolution by creeps."

The sudden appearance of most species in the geologic record and the lack of evidence of substantial gradual change in most species—from their initial appearance until their extinction—has , including by Charles Darwin who appealed to the imperfection of the record as the favored explanation. When presenting his ideas against the prevailing influences of catastrophism and progressive creationism, which envisaged species being supernaturally created at intervals, Darwin needed to forcefully stress the gradual nature of evolution in accordance with the gradualism promoted by his friend Charles Lyell. He privately expressed concern, noting in the margin of his 1844 "Essay", "Better begin with this: If species really, after catastrophes, created in showers world over, my theory false."

It is often incorrectly assumed that he insisted that the rate of change must be constant, or nearly so, but even the first edition of "On the Origin of Species" states that "Species of different genera and classes have not changed at the same rate, or in the same degree. In the oldest tertiary beds a few living shells may still be found in the midst of a multitude of extinct forms... The Silurian "Lingula" differs but little from the living species of this genus". "Lingula" is among the few brachiopods surviving today but also known from fossils over 500 million years old. In the fourth edition (1866) of "On the Origin of Species" Darwin wrote that "the periods during which species have undergone modification, though long as measured in years, have probably been short in comparison with the periods during which they retain the same form." Thus punctuationism in general is consistent with Darwin's conception of evolution.

According to early versions of punctuated equilibrium, "peripheral isolates" are considered to be of critical importance for speciation. However, Darwin wrote, ""I can by no means agree" ... that immigration and isolation are necessary elements... Although isolation is of great importance in the production of new species, on the whole I am inclined to believe that largeness of area is still more important, especially for the production of species which shall prove capable of enduring for a long period, and of spreading widely."

The importance of isolation in forming species had played a significant part in Darwin's early thinking, as shown in his "Essay" of 1844. But by the time he wrote the "Origin" he had downplayed its importance. He explained the reasons for his revised view as follows:
Throughout a great and open area, not only will there be a greater chance of favourable variations, arising from the large number of individuals of the same species there supported, but the conditions of life are much more complex from the large number of already existing species; and if some of these species become modified and improved, others will have to be improved in a corresponding degree, or they will be exterminated. Each new form, also, as soon as it has been improved, will be able to spread over the open and continuous area, and will thus come into competition with many other forms ... the new forms produced on large areas, which have already been victorious over many competitors, will be those that will spread most widely, and will give rise to the greatest number of new varieties and species. They will thus play a more important role in the changing history of the organic world.

Thus punctuated equilibrium is incongruous with some of Darwin's ideas regarding the specific mechanisms of evolution, but generally accords with Darwin's theory of evolution by natural selection.

Recent work in developmental biology has identified dynamical and physical mechanisms of tissue morphogenesis that may underlie abrupt morphological transitions during evolution. Consequently, consideration of mechanisms of phylogenetic change that have been found in reality to be non-gradual is increasingly common in the field of evolutionary developmental biology, particularly in studies of the origin of morphological novelty. A description of such mechanisms can be found in the multi-authored volume "Origination of Organismal Form" (MIT Press; 2003).

In linguistics, R. M. W. Dixon has proposed a punctuated equilibrium model for language histories, with reference particularly to the prehistory of the indigenous languages of Australia and his objections to the proposed Pama–Nyungan language family there. Although his model has raised considerable interest, it does not command majority support within linguistics.

Separately, recent work using computational phylogenetic methods claims to show that punctuational bursts play an important factor when languages split from one another, accounting for anywhere from 10 to 33% of the total divergence in vocabulary.

Punctuational evolution has been argued to explain changes in folktales and mythology over time.



</doc>
<doc id="24981" url="https://en.wikipedia.org/wiki?curid=24981" title="Pioneer 11">
Pioneer 11

Pioneer 11 (also known as Pioneer G) is a robotic space probe launched by NASA on April 6, 1973 to study the asteroid belt, the environment around Jupiter and Saturn, solar wind and cosmic rays. It was the first probe to encounter Saturn and the second to fly through the asteroid belt and by Jupiter. Thereafter, "Pioneer 11" became the second of five artificial objects to achieve the escape velocity that will allow them to leave the Solar System. Due to power constraints and the vast distance to the probe, the last routine contact with the spacecraft was on September 30, 1995, and the last good engineering data was received on November 24, 1995.

Approved in February 1969, "Pioneer 11" and its twin probe, "Pioneer 10", were the first to be designed for exploring the outer Solar System. Yielding to multiple proposals throughout the 1960s, early mission objectives were defined as:

Subsequent planning for an encounter with Saturn added many more goals:

"Pioneer 11" was built by TRW and managed as part of the Pioneer program by NASA Ames Research Center. A backup unit, Pioneer H, is currently on display in the "Milestones of Flight" exhibit at the National Air and Space Museum in Washington, D.C.. Many elements of the mission proved to be critical in the planning of the "Voyager" program.

The "Pioneer 11" bus measures deep and with six panels forming the hexagonal structure. The bus houses propellant to control the orientation of the probe and eight of the twelve scientific instruments. The spacecraft has a mass of 260 kilograms.

Pioneer has one additional instrument more than Pioneer 10, a flux-gate magnetometer.

The "Pioneer 11" probe was launched on April 6, 1973 at 02:11:00 UTC, by the National Aeronautics and Space Administration from Space Launch Complex 36A at Cape Canaveral, Florida aboard an Atlas-Centaur launch vehicle, with a Star 37E propulsion module. Its twin probe, "Pioneer 10", had launched a year earlier on March 3, 1972. 

"Pioneer 11" was launched on a trajectory directly aimed at Jupiter without any prior gravitational assists. In May 1974, Pioneer was retargeted to fly past Jupiter on a north-south trajectory enabling a Saturn flyby in 1979. The maneuver used 17 pounds of propellant, lasted 42 minutes and 36 seconds and increased Pioneer 11's speed by 230 km/h. It also made two mid-course corrections, on April 11, 1973 and November 7, 1974.

"Pioneer 11" flew past Jupiter in November and December 1974. During its closest approach, on December 2, it passed above the cloud tops. The probe obtained detailed images of the Great Red Spot, transmitted the first images of the immense polar regions, and determined the mass of Jupiter's moon Callisto. Using the gravitational pull of Jupiter, a gravity assist was used to alter the trajectory of the probe towards Saturn and gain velocity. On April 16, 1975, following the Jupiter encounter, the micrometer detector was turned off.

"Pioneer 11" passed by Saturn on September 1, 1979, at a distance of 21,000 km from Saturn's cloud tops.

By this time "Voyager 1" and "Voyager 2" had already passed Jupiter and were also en route to Saturn, so it was decided to target "Pioneer 11" to pass through the Saturn ring plane at the same position that the soon-to-come Voyager probes would use in order to test the route before the Voyagers arrived. If there were faint ring particles that could damage a probe in that area, mission planners felt it was better to learn about it via Pioneer. Thus, "Pioneer 11" was acting as a "pioneer" in a true sense of the word; if danger were detected, then the Voyager probes could be rerouted further away from the rings, but missing the opportunity to visit Uranus and Neptune in the process.

"Pioneer 11" imaged and nearly collided with one of Saturn's small moons, passing at a distance of no more than . The object was tentatively identified as Epimetheus, a moon discovered the previous day from "Pioneer"s imaging, and suspected from earlier observations by Earth-based telescopes. After the Voyager flybys, it became known that there are two similarly-sized moons (Epimetheus and Janus) in the same orbit, so there is some uncertainty about which one was the object of Pioneer's near-miss. "Pioneer 11" encountered Janus on September 1, 1979 at 14:52 UTC at a distance of 2500 km and Mimas at 16:20 UTC the same day at 103000 km.

Besides Epimetheus, instruments located another previously undiscovered small moon and an additional ring, charted Saturn's magnetosphere and magnetic field and found its planet-size moon, Titan, to be too cold for life. Hurtling underneath the ring plane, the probe sent back pictures of Saturn's rings. The rings, which normally seem bright when observed from Earth, appeared dark in the Pioneer pictures, and the dark gaps in the rings seen from Earth appeared as bright rings.

On February 25, 1990, "Pioneer 11" became the 4th man-made object to pass beyond the orbit of the planets.

By 1995, "Pioneer 11" could no longer power any of its detectors, so the decision was made to shut it down. On September 29, 1995, NASA's Ames Research Center, responsible for managing the project, issued a press release that began, "After nearly 22 years of exploration out to the farthest reaches of the Solar System, one of the most durable and productive space missions in history will come to a close." It indicated NASA would use its Deep Space Network antennas to listen "once or twice a month" for the spacecraft's signal, until "some time in late 1996" when "its transmitter will fall silent altogether." NASA Administrator Daniel Goldin characterized "Pioneer 11" as "the little spacecraft that could, a venerable explorer that has taught us a great deal about the Solar System and, in the end, about our own innate drive to learn. "Pioneer 11" is what NASA is all about – exploration beyond the frontier." Besides announcing the end of operations, the dispatch provided a historical list of "Pioneer 11" mission achievements. NASA terminated routine contact with the spacecraft on September 30, 1995, but continued to make contact for about 2 hours every 2 to 4 weeks. Scientists received a few minutes of good engineering data on 24 November 1995 but then lost final contact once Earth permanently moved out of view of the spacecraft's antenna. Its signal became too faint to hear in 2002.

On January 30, 2019, "Pioneer 11" was from the Earth and from the Sun; and traveling at (relative to the Sun) and traveling outward at about 2.37 AU per year. The spacecraft is heading in the direction of the constellation Scutum near the current position (August 2017) RA 18h 50m dec -8° 39.5' (J2000.0) close to Messier 26. In 928,000 years it will pass within 0.25pc of the K dwarf TYC 992-192-1.

"Pioneer 11" has now been overtaken by the two Voyager probes, launched in 1977, and "Voyager 1" is now the most distant object built by humans.

Analysis of the radio tracking data from the "Pioneer 10" and "11" spacecraft at distances between 20–70 AU from the Sun has consistently indicated the presence of a small but anomalous Doppler frequency drift. The drift can be interpreted as due to a constant acceleration of directed towards the Sun. Although it is suspected that there is a systematic origin to the effect, none was found. As a result, there is sustained interest in the nature of this so-called "Pioneer anomaly". Extended analysis of mission data by Slava Turyshev and colleagues has determined the source of the anomaly to be asymmetric thermal radiation and the resulting thermal recoil force acting on the face of the Pioneers away from the Sun, and in July 2012 the group of researchers published their results in the "Physical Review Letters" scientific journal.

"Pioneer 10" and "11" both carry a gold-anodized aluminum plaque in the event that either spacecraft is ever found by intelligent lifeforms from other planetary systems. The plaques feature the nude figures of a human male and female along with several symbols that are designed to provide information about the origin of the spacecraft.

In 1991, "Pioneer 11" was honored on one of 10 United States Postage Service stamps commemorating unmanned spacecraft exploring each of the then nine planets and the Moon. "Pioneer 11" was the spacecraft featured with Jupiter. Pluto was listed as "Not yet explored".



</doc>
<doc id="24982" url="https://en.wikipedia.org/wiki?curid=24982" title="Psychometrics">
Psychometrics

Psychometrics is a field of study concerned with the theory and technique of psychological measurement. As defined by the US National Council on Measurement in Education (NCME), psychometrics refers to psychological measurement. Generally, it refers to the field in psychology and education that is devoted to testing, measurement, assessment, and related activities.

The field is concerned with the objective measurement of skills and knowledge, abilities, attitudes, personality traits, and educational achievement. Some psychometric researchers focus on the construction and validation of assessment instruments such as questionnaires, tests, raters' judgments, and personality tests. Others focus on research relating to measurement theory (e.g., item response theory; intraclass correlation).

Practitioners are described as psychometricians. Psychometricians usually possess a specific qualification, and most are psychologists with advanced graduate training. In addition to traditional academic institutions, many psychometricians work for the government or in human resources departments. Others specialize as learning and development professionals.

Psychological testing has come from two streams of thought: the first, from Darwin, Galton, and Cattell on the measurement of individual differences, and the second, from Herbart, Weber, Fechner, and Wundt and their psychophysical measurements of a similar construct. The second set of individuals and their research is what has led to the development of experimental psychology, and standardized testing.

Charles Darwin was the inspiration behind Sir Francis Galton who led to the creation of psychometrics. In 1859, Darwin published his book "The Origin of Species", which pertained to individual differences in animals. This book discussed how individual members in a species differ and how they possess characteristics that are more adaptive and successful or less adaptive and less successful. Those who are adaptive and successful are the ones that survive and give way to the next generation, who would be just as or more adaptive and successful. This idea, studied previously in animals, led to Galton's interest and study of human beings and how they differ one from another, and more importantly, how to measure those differences.

Galton wrote a book entitled "Hereditary Genius" about different characteristics that people possess and how those characteristics make them more "fit" than others. Today these differences, such as sensory and motor functioning (reaction time, visual acuity, and physical strength) are important domains of scientific psychology. Much of the early theoretical and applied work in psychometrics was undertaken in an attempt to measure intelligence. Galton, often referred to as "the father of psychometrics," devised and included mental tests among his anthropometric measures. James McKeen Cattell, who is considered a pioneer of psychometrics went on to extend Galton's work. Cattell also coined the term "mental test", and is responsible for the research and knowledge which ultimately led to the development of modern tests. (Kaplan & Saccuzzo, 2010)

The origin of psychometrics also has connections to the related field of psychophysics. Around the same time that Darwin, Galton, and Cattell were making their discoveries, Herbart was also interested in "unlocking the mysteries of human consciousness" through the scientific method. (Kaplan & Saccuzzo, 2010) Herbart was responsible for creating mathematical models of the mind, which were influential in educational practices in years to come.

E.H. Weber built upon Herbart's work and tried to prove the existence of a psychological threshold, saying that a minimum stimulus was necessary to activate a sensory system. After Weber, G.T. Fechner expanded upon the knowledge he gleaned from Herbart and Weber, to devise the law that the strength of a sensation grows as the logarithm of the stimulus intensity. A follower of Weber and Fechner, Wilhelm Wundt is credited with founding the science of psychology. It is Wundt's influence that paved the way for others to develop psychological testing.

The psychometrician L. L. Thurstone, founder and first president of the Psychometric Society in 1936, developed and applied a theoretical approach to measurement referred to as the law of comparative judgment, an approach that has close connections to the psychophysical theory of Ernst Heinrich Weber and Gustav Fechner. In addition, Spearman and Thurstone both made important contributions to the theory and application of factor analysis, a statistical method developed and used extensively in psychometrics. In the late 1950s, Leopold Szondi made an historical and epistemological assessment of the impact of statistical thinking onto psychology during previous few decades: "in the last decades, the specifically psychological thinking has been almost completely suppressed and removed, and replaced by a statistical thinking. Precisely here we see the cancer of testology and testomania of today."

More recently, psychometric theory has been applied in the measurement of personality, attitudes, and beliefs, and academic achievement. Measurement of these unobservable phenomena is difficult, and much of the research and accumulated science in this discipline has been developed in an attempt to properly define and quantify such phenomena. Critics, including practitioners in the physical sciences and social activists, have argued that such definition and quantification is impossibly difficult, and that such measurements are often misused, such as with psychometric personality tests used in employment procedures:

Figures who made significant contributions to psychometrics include Karl Pearson, Henry F. Kaiser, Carl Brigham, L. L. Thurstone, E. L. Thorndike, Georg Rasch, Eugene Galanter, Johnson O'Connor, Frederic M. Lord, Ledyard R Tucker, and J. Loevinger Weissman.

The definition of measurement in the social sciences has a long history. A currently widespread definition, proposed by Stanley Smith Stevens (1946), is that measurement is "the assignment of numerals to objects or events according to some rule." This definition was introduced in the paper in which Stevens proposed four levels of measurement. Although widely adopted, this definition differs in important respects from the more classical definition of measurement adopted in the physical sciences, namely that scientific measurement entails "the estimation or discovery of the ratio of some magnitude of a quantitative attribute to a unit of the same attribute" (p. 358)

Indeed, Stevens's definition of measurement was put forward in response to the British Ferguson Committee, whose chair, A. Ferguson, was a physicist. The committee was appointed in 1932 by the British Association for the Advancement of Science to investigate the possibility of quantitatively estimating sensory events. Although its chair and other members were physicists, the committee also included several psychologists. The committee's report highlighted the importance of the definition of measurement. While Stevens's response was to propose a new definition, which has had considerable influence in the field, this was by no means the only response to the report. Another, notably different, response was to accept the classical definition, as reflected in the following statement:

These divergent responses are reflected in alternative approaches to measurement. For example, methods based on covariance matrices are typically employed on the premise that numbers, such as raw scores derived from assessments, are measurements. Such approaches implicitly entail Stevens's definition of measurement, which requires only that numbers are "assigned" according to some rule. The main research task, then, is generally considered to be the discovery of associations between scores, and of factors posited to underlie such associations.

On the other hand, when measurement models such as the Rasch model are employed, numbers are not assigned based on a rule. Instead, in keeping with Reese's statement above, specific criteria for measurement are stated, and the goal is to construct procedures or operations that provide data that meet the relevant criteria. Measurements are estimated based on the models, and tests are conducted to ascertain whether the relevant criteria have been met.

The firstpsychometric instruments were designed to measure the concept of intelligence. One historical approach involved the Stanford-Binet IQ test, developed originally by the French psychologist Alfred Binet. Intelligence tests are useful tools for various purposes. An alternative conception of intelligence is that cognitive capacities within individuals are a manifestation of a general component, or general intelligence factor, as well as cognitive capacity specific to a given domain.

Another major focus in psychometrics has been on personality testing. There have been a range of theoretical approaches to conceptualizing and measuring personality. Some of the better known instruments include the Minnesota Multiphasic Personality Inventory, the Five-Factor Model (or "Big 5") and tools such as Personality and Preference Inventory and the Myers-Briggs Type Indicator. Attitudes have also been studied extensively using psychometric approaches. A common method in the measurement of attitudes is the use of the Likert scale. An alternative method involves the application of unfolding measurement models, the most general being the Hyperbolic Cosine Model (Andrich & Luo, 1993).

Psychometricians have developed a number of different measurement theories. These include classical test theory (CTT) and item response theory (IRT). An approach which seems mathematically to be similar to IRT but also quite distinctive, in terms of its origins and features, is represented by the Rasch model for measurement. The development of the Rasch model, and the broader class of models to which it belongs, was explicitly founded on requirements of measurement in the physical sciences.

Psychometricians have also developed methods for working with large matrices of correlations and covariances. Techniques in this general tradition include: factor analysis, a method of determining the underlying dimensions of data; multidimensional scaling, a method for finding a simple representation for data with a large number of latent dimensions; and data clustering, an approach to finding objects that are like each other. All these multivariate descriptive methods try to distill large amounts of data into simpler structures. More recently, structural equation modeling and path analysis represent more sophisticated approaches to working with large covariance matrices. These methods allow statistically sophisticated models to be fitted to data and tested to determine if they are adequate fits.

One of the main deficiencies in various factor analyses is a lack of consensus in cutting points for determining the number of latent factors. A usual procedure is to stop factoring when eigenvalues drop below one because the original sphere shrinks. The lack of the cutting points concerns other multivariate methods, also.

Key concepts in classical test theory are reliability and validity. A reliable measure is one that measures a construct consistently across time, individuals, and situations. A valid measure is one that measures what it is intended to measure. Reliability is necessary, but not sufficient, for validity.

Both reliability and validity can be assessed statistically. Consistency over repeated measures of the same test can be assessed with the Pearson correlation coefficient, and is often called "test-retest reliability." Similarly, the equivalence of different versions of the same measure can be indexed by a Pearson correlation, and is called "equivalent forms reliability" or a similar term.

Internal consistency, which addresses the homogeneity of a single test form, may be assessed by correlating performance on two halves of a test, which is termed "split-half reliability"; the value of this Pearson product-moment correlation coefficient for two half-tests is adjusted with the Spearman–Brown prediction formula to correspond to the correlation between two full-length tests. Perhaps the most commonly used index of reliability is Cronbach's α, which is equivalent to the mean of all possible split-half coefficients. Other approaches include the intra-class correlation, which is the ratio of variance of measurements of a given target to the variance of all targets.

There are a number of different forms of validity. Criterion-related validity can be assessed by correlating a measure with a criterion measure theoretically expected to be related. When the criterion measure is collected at the same time as the measure being validated the goal is to establish "concurrent validity"; when the criterion is collected later the goal is to establish "predictive validity". A measure has "construct validity" if it is related to measures of other constructs as required by theory. "Content validity" is a demonstration that the items of a test do an adequate job of covering the domain being measured. In a personnel selection example, test content is based on a defined statement or set of statements of knowledge, skill, ability, or other characteristics obtained from a "job analysis".

Item response theory models the relationship between latent traits and responses to test items. Among other advantages, IRT provides a basis for obtaining an estimate of the location of a test-taker on a given latent trait as well as the standard error of measurement of that location. For example, a university student's knowledge of history can be deduced from his or her score on a university test and then be compared reliably with a high school student's knowledge deduced from a less difficult test. Scores derived by classical test theory do not have this characteristic, and assessment of actual ability (rather than ability relative to other test-takers) must be assessed by comparing scores to those of a "norm group" randomly selected from the population. In fact, all measures derived from classical test theory are dependent on the sample tested, while, in principle, those derived from item response theory are not.

Many psychometricians are also concerned with finding and eliminating test bias from their psychological tests. Test bias is a form of systematic (i.e., non-random) error which leads to examinees from one demographic group having an unwarranted advantage over examinees from another demographic group. According to leading experts, test bias may cause differences in average scores across demographic groups, but differences in group scores are not sufficient evidence that test bias is actually present because the test could be measuring real differences among groups. Psychometricians use sophisticated scientific methods to search for test bias and eliminate it. Research shows that it is usually impossible for people reading a test item to accurately determine whether it is biased or not.

The considerations of validity and reliability typically are viewed as essential elements for determining the quality of any test. However, professional and practitioner associations frequently have placed these concerns within broader contexts when developing standards and making overall judgments about the quality of any test as a whole within a given context. A consideration of concern in many applied research settings is whether or not the metric of a given psychological inventory is meaningful or arbitrary.

In 2014, the American Educational Research Association (AERA), American Psychological Association (APA), and National Council on Measurement in Education (NCME) published a revision of the "Standards for Educational and Psychological Testing", which describes standards for test development, evaluation, and use. The "Standards" cover essential topics in testing including validity, reliability/errors of measurement, and fairness in testing. The book also establishes standards related to testing operations including test design and development, scores, scales, norms, score linking, cut scores, test administration, scoring, reporting, score interpretation, test documentation, and rights and responsibilities of test takers and test users. Finally, the "Standards" cover topics related to testing applications, including psychological testing and assessment, workplace testing and credentialing, educational testing and assessment, and testing in program evaluation and public policy.

In the field of evaluation, and in particular educational evaluation, the Joint Committee on Standards for Educational Evaluation has published three sets of standards for evaluations. "The Personnel Evaluation Standards" was published in 1988, "The Program Evaluation Standards" (2nd edition) was published in 1994, and "The Student Evaluation Standards" was published in 2003.

Each publication presents and elaborates a set of standards for use in a variety of educational settings. The standards provide guidelines for designing, implementing, assessing and improving the identified form of evaluation. Each of the standards has been placed in one of four fundamental categories to promote educational evaluations that are proper, useful, feasible, and accurate. In these sets of standards, validity and reliability considerations are covered under the accuracy topic. For example, the student accuracy standards help ensure that student evaluations will provide sound, accurate, and credible information about student learning and performance.

Psychometrics addresses "human" abilities, attitudes, traits and educational evolution. Notably, the study of behavior, mental processes and abilities of non-human "animals" is usually addressed by comparative psychology, or with a continuum between non-human animals and the rest of animals by evolutionary psychology. Nonetheless there are some advocators for a more gradual transition between the approach taken for humans and the approach taken for (non-human) animals.
The evaluation of abilities, traits and learning evolution of "machines" has been mostly unrelated to the case of humans and non-human animals, with specific approaches in the area of artificial intelligence. A more integrated approach, under the name of universal psychometrics, has also been proposed.





</doc>
<doc id="24983" url="https://en.wikipedia.org/wiki?curid=24983" title="Philosophy of education">
Philosophy of education

The philosophy of education examines the goals, forms, methods, and meaning of education. The term is used to describe both fundamental philosophical analysis of these themes and the description or analysis of particular pedagogical approaches. Considerations of how the profession relates to broader philosophical or sociocultural contexts may be included. The philosophy of education thus overlaps with the field of education and applied philosophy. 

For example, philosophers of education study what constitutes upbringing and education, the values and norms revealed through upbringing and educational practices, the limits and legitimization of education as an academic discipline, and the relation between educational theory and practice. 

In universities, the philosophy of education usually forms part of departments or colleges of education.

Date: 424/423 BC – 348/347 BC

Plato's educational philosophy was grounded in a vision of an ideal "Republic" wherein the individual was best served by being subordinated to a just society due to a shift in emphasis that departed from his predecessors. The mind and body were to be considered separate entities. In the dialogues of Phaedo, written in his "middle period" (360 B.C.E.) Plato expressed his distinctive views about the nature of knowledge, reality, and the soul:When the soul and body are united, then nature orders the soul to rule and govern, and the body to obey and serve. Now which of these two functions is akin to the divine? and which to the mortal? Does not the divine appear…to be that which naturally orders and rules, and the mortal to be that which is subject and servant?On this premise, Plato advocated removing children from their mothers' care and raising them as wards of the state, with great care being taken to differentiate children suitable to the various castes, the highest receiving the most education, so that they could act as guardians of the city and care for the less able. Education would be holistic, including facts, skills, physical discipline, and music and art, which he considered the highest form of endeavor.

Plato believed that talent was distributed non-genetically and thus must be found in children born in any social class. He built on this by insisting that those suitably gifted were to be trained by the state so that they might be qualified to assume the role of a ruling class. What this established was essentially a system of selective public education premised on the assumption that an educated minority of the population were, by virtue of their education (and inborn educability), sufficient for healthy governance.

Plato's writings contain some of the following ideas:
Elementary education would be confined to the guardian class till the age of 18, followed by two years of compulsory military training and then by higher education for those who qualified. While elementary education made the soul responsive to the environment, higher education helped the soul to search for truth which illuminated it. Both boys and girls receive the same kind of education. Elementary education consisted of music and gymnastics, designed to train and blend gentle and fierce qualities in the individual and create a harmonious person.

At the age of 20, a selection was made. The best students would take an advanced course in mathematics, geometry, astronomy and harmonics. The first course in the scheme of higher education would last for ten years. It would be for those who had a flair for science. At the age of 30 there would be another selection; those who qualified would study dialectics and metaphysics, logic and philosophy for the next five years. After accepting junior positions in the army for 15 years, a man would have completed his theoretical and practical education by the age of 50.

Date: 1724–1804

Immanuel Kant believed that education differs from training in that the former involves thinking whereas the latter does not. In addition to educating reason, of central importance to him was the development of character and teaching of moral maxims. Kant was a proponent of public education and of learning by doing.

Date: 1770–1831

Date: 384 BC – 322 BC

Only fragments of Aristotle's treatise "On Education" are still in existence. We thus know of his philosophy of education primarily through brief passages in other works. Aristotle considered human nature, habit and reason to be equally important forces to be cultivated in education. Thus, for example, he considered repetition to be a key tool to develop good habits. The teacher was to lead the student systematically; this differs, for example, from Socrates' emphasis on questioning his listeners to bring out their own ideas (though the comparison is perhaps incongruous since Socrates was dealing with adults).

Aristotle placed great emphasis on balancing the theoretical and practical aspects of subjects taught. Subjects he explicitly mentions as being important included reading, writing and mathematics; music; physical education; literature and history; and a wide range of sciences. He also mentioned the importance of play.

One of education's primary missions for Aristotle, perhaps its most important, was to produce good and virtuous citizens for the polis. "All who have meditated on the art of governing mankind have been convinced that the fate of empires depends on the education of youth."

Date: 980 AD – 1037 AD

In the medieval Islamic world, an elementary school was known as a "maktab", which dates back to at least the 10th century. Like madrasahs (which referred to higher education), a maktab was often attached to a mosque. In the 11th century, Ibn Sina (known as "Avicenna" in the West), wrote a chapter dealing with the "maktab" entitled "The Role of the Teacher in the Training and Upbringing of Children", as a guide to teachers working at "maktab" schools. He wrote that children can learn better if taught in classes instead of individual tuition from private tutors, and he gave a number of reasons for why this is the case, citing the value of competition and emulation among pupils as well as the usefulness of group discussions and debates. Ibn Sina described the curriculum of a "maktab" school in some detail, describing the curricula for two stages of education in a "maktab" school.

Ibn Sina wrote that children should be sent to a "maktab" school from the age of 6 and be taught primary education until they reach the age of 14. During which time, he wrote that they should be taught the Qur'an, Islamic metaphysics, language, literature, Islamic ethics, and manual skills (which could refer to a variety of practical skills).

Ibn Sina refers to the secondary education stage of "maktab" schooling as the period of specialization, when pupils should begin to acquire manual skills, regardless of their social status. He writes that children after the age of 14 should be given a choice to choose and specialize in subjects they have an interest in, whether it was reading, manual skills, literature, preaching, medicine, geometry, trade and commerce, craftsmanship, or any other subject or profession they would be interested in pursuing for a future career. He wrote that this was a transitional stage and that there needs to be flexibility regarding the age in which pupils graduate, as the student's emotional development and chosen subjects need to be taken into account.

The empiricist theory of 'tabula rasa' was also developed by Ibn Sina. He argued that the "human intellect at birth is rather like a "tabula rasa", a pure potentiality that is actualized through education and comes to know" and that knowledge is attained through "empirical familiarity with objects in this world from which one abstracts universal concepts" which is developed through a "syllogistic method of reasoning; observations lead to prepositional statements, which when compounded lead to further abstract concepts." He further argued that the intellect itself "possesses levels of development from the material intellect ("al-‘aql al-hayulani"), that potentiality that can acquire knowledge to the active intellect ("al-‘aql al-fa‘il"), the state of the human intellect in conjunction with the perfect source of knowledge."

Date: c. 1105 – 1185

In the 12th century, the Andalusian-Arabian philosopher and novelist Ibn Tufail (known as "Abubacer" or "Ebn Tophail" in the West) demonstrated the empiricist theory of 'tabula rasa' as a thought experiment through his Arabic philosophical novel, "Hayy ibn Yaqzan", in which he depicted the development of the mind of a feral child "from a tabula rasa to that of an adult, in complete isolation from society" on a desert island, through experience alone. Some scholars have argued that the Latin translation of his philosophical novel, "Philosophus Autodidactus", published by Edward Pococke the Younger in 1671, had an influence on John Locke's formulation of tabula rasa in "An Essay Concerning Human Understanding".

Date: 1632–1704

In "Some Thoughts Concerning Education" and "Of the Conduct of the Understanding" Locke composed an outline on how to educate this mind in order to increase its powers and activity:

"The business of education is not, as I think, to make them perfect in any one of the sciences, but so to open and dispose their minds as may best make them capable of any, when they shall apply themselves to it."

"If men are for a long time accustomed only to one sort or method of thoughts, their minds grow stiff in it, and do not readily turn to another. It is therefore to give them this freedom, that I think they should be made to look into all sorts of knowledge, and exercise their understandings in so wide a variety and stock of knowledge. But I do not propose it as a variety and stock of knowledge, but a variety and freedom of thinking, as an increase of the powers and activity of the mind, not as an enlargement of its possessions." 

Locke expressed the belief that education maketh the man, or, more fundamentally, that the mind is an "empty cabinet", with the statement, "I think I may say that of all the men we meet with, nine parts of ten are what they are, good or evil, useful or not, by their education."

Locke also wrote that "the little and almost insensible impressions on our tender infancies have very important and lasting consequences." He argued that the "associations of ideas" that one makes when young are more important than those made later because they are the foundation of the self: they are, put differently, what first mark the "tabula rasa". In his "Essay", in which is introduced both of these concepts, Locke warns against, for example, letting "a foolish maid" convince a child that "goblins and sprites" are associated with the night for "darkness shall ever afterwards bring with it those frightful ideas, and they shall be so joined, that he can no more bear the one than the other."

"Associationism", as this theory would come to be called, exerted a powerful influence over eighteenth-century thought, particularly educational theory, as nearly every educational writer warned parents not to allow their children to develop negative associations. It also led to the development of psychology and other new disciplines with David Hartley's attempt to discover a biological mechanism for associationism in his "Observations on Man" (1749).

Date: 1712–1778

Rousseau, though he paid his respects to Plato's philosophy, rejected it as impractical due to the decayed state of society. Rousseau also had a different theory of human development; where Plato held that people are born with skills appropriate to different castes (though he did not regard these skills as being inherited), Rousseau held that there was one developmental process common to all humans. This was an intrinsic, natural process, of which the primary behavioral manifestation was curiosity. This differed from Locke's 'tabula rasa' in that it was an active process deriving from the child's nature, which drove the child to learn and adapt to its surroundings.

Rousseau wrote in his book "" that all children are perfectly designed organisms, ready to learn from their surroundings so as to grow into virtuous adults, but due to the malign influence of corrupt society, they often fail to do so. Rousseau advocated an educational method which consisted of removing the child from society—for example, to a country home—and alternately conditioning him through changes to his environment and setting traps and puzzles for him to solve or overcome.

Rousseau was unusual in that he recognized and addressed the potential of a problem of legitimation for teaching. He advocated that adults always be truthful with children, and in particular that they never hide the fact that the basis for their authority in teaching was purely one of physical coercion: "I'm bigger than you." Once children reached the age of reason, at about 12, they would be engaged as free individuals in the ongoing process of their own.

He once said that a child should grow up without adult interference and that the child must be guided to suffer from the experience of the natural consequences of his own acts or behaviour. When he experiences the consequences of his own acts, he advises himself.

"Rousseau divides development into five stages (a book is devoted to each). Education in the first two stages seeks to the senses: only when Émile is about 12 does the tutor begin to work to develop his mind. Later, in Book 5, Rousseau examines the education of Sophie (whom Émile is to marry). Here he sets out what he sees as the essential differences that flow from sex. 'The man should be strong and active; the woman should be weak and passive' (Everyman edn: 322). From this difference comes a contrasting education. They are not to be brought up in ignorance and kept to housework: Nature means them to think, to will, to love to cultivate their minds as well as their persons; she puts these weapons in their hands to make up for their lack of strength and to enable them to direct the strength of men. They should learn many things, but only such things as suitable' (Everyman edn.: 327)."
Émile

Date: 1902–2001

Mortimer Jerome Adler was an American philosopher, educator, and popular author. As a philosopher he worked within the Aristotelian and Thomistic traditions. He lived for the longest stretches in New York City, Chicago, San Francisco, and San Mateo, California. He worked for Columbia University, the University of Chicago, Encyclopædia Britannica, and Adler's own Institute for Philosophical Research. Adler was married twice and had four children. Adler was a proponent of educational perennialism.

Date: 1905–1998

Broudy's philosophical views were based on the tradition of classical realism, dealing with truth, goodness, and beauty. However he was also influenced by the modern philosophy existentialism and instrumentalism. In his textbook Building a Philosophy of Education he has two major ideas that are the main points to his philosophical outlook: The first is truth and the second is universal structures to be found in humanity's struggle for education and the good life. Broudy also studied issues on society's demands on school. He thought education would be a link to unify the diverse society and urged the society to put more trust and a commitment to the schools and a good education.

Date: c. 1225 – 1274

See Religious perennialism.

Date: 1608–1674

The objective of medieval education was an overtly religious one, primarily concerned with uncovering transcendental truths that would lead a person back to God through a life of moral and religious choice (Kreeft 15). The vehicle by which these truths were uncovered was dialectic:

To the medieval mind, debate was a fine art, a serious science, and a fascinating entertainment, much more than it is to the modern mind, because the medievals believed, like Socrates, that dialectic could uncover truth. Thus a 'scholastic disputation' was not a personal contest in cleverness, nor was it 'sharing opinions'; it was a shared journey of discovery (Kreeft 14–15).

Date: 1859–1952

In "Democracy and Education: An Introduction to the Philosophy of Education", Dewey stated that education, in its broadest sense, is the means of the "social continuity of life" given the "primary ineluctable facts of the birth and death of each one of the constituent members in a social group". Education is therefore a necessity, for "the life of the group goes on." Dewey was a proponent of Educational Progressivism and was a relentless campaigner for reform of education, pointing out that the authoritarian, strict, pre-ordained knowledge approach of modern traditional education was too concerned with delivering knowledge, and not enough with understanding students' actual experiences.

Date: 1842–1910

Date: 1871–1965

William Heard Kilpatrick was a US American philosopher of education and a colleague and a successor of John Dewey. He was a major figure in the progressive education movement of the early 20th century. Kilpatrick developed the Project Method for early childhood education, which was a form of Progressive Education organized curriculum and classroom activities around a subject's central theme. He believed that the role of a teacher should be that of a "guide" as opposed to an authoritarian figure. Kilpatrick believed that children should direct their own learning according to their interests and should be allowed to explore their environment, experiencing their learning through the natural senses. Proponents of Progressive Education and the Project Method reject traditional schooling that focuses on memorization, rote learning, strictly organized classrooms (desks in rows; students always seated), and typical forms of assessment.

Date: 1929–

Noddings' first sole-authored book "Caring: A Feminine Approach to Ethics and Moral Education" (1984) followed close on the 1982 publication of Carol Gilligan’s ground-breaking work in the ethics of care "In a Different Voice". While her work on ethics continued, with the publication of "Women and Evil" (1989) and later works on moral education, most of her later publications have been on the philosophy of education and educational theory. Her most significant works in these areas have been "Educating for Intelligent Belief or Unbelief" (1993) and "Philosophy of Education" (1995).

Noddings' contribution to education philosophy centers around the ethic of care. Her belief was that a caring teacher-student relationship will result in the teacher designing a differentiated curriculum for each student, and that this curriculum would be based around the students' particular interests and needs. The teacher's claim to care must not be based on a one time virtuous decision but an ongoing interest in the students' welfare.

Date: 1931–2007

G.E Moore (1873–1858)
Bertrand Russell (1872–1970)

Gottlob Frege (1848–1925)

Date: 1919–

The existentialist sees the world as one's personal subjectivity, where goodness, truth, and reality are individually defined. Reality is a world of existing, truth subjectively chosen, and goodness a matter of freedom. The subject matter of existentialist classrooms should be a matter of personal choice. Teachers view the individual as an entity within a social context in which the learner must confront others' views to clarify his or her own. Character development emphasizes individual responsibility for decisions. Real answers come from within the individual, not from outside authority. Examining life through authentic thinking involves students in genuine learning experiences. Existentialists are opposed to thinking about students as objects to be measured, tracked, or standardized. Such educators want the educational experience to focus on creating opportunities for self-direction and self-actualization. They start with the student, rather than on curriculum content.

Date: 1921–1997

A Brazilian philosopher and educator committed to the cause of educating the impoverished peasants of his nation and collaborating with them in the pursuit of their liberation from what he regarded as "oppression," Freire is best known for his attack on what he called the "banking concept of education," in which the student was viewed as an empty account to be filled by the teacher. Freire also suggests that a deep reciprocity be inserted into our notions of teacher and student; he comes close to suggesting that the teacher-student dichotomy be completely abolished, instead promoting the roles of the participants in the classroom as the teacher-student (a teacher who learns) and the student-teacher (a learner who teaches). In its early, strong form this kind of classroom has sometimes been criticized on the grounds that it can mask rather than overcome the teacher's authority.

Aspects of the Freirian philosophy have been highly influential in academic debates over "participatory development" and development more generally. Freire's emphasis on what he describes as "emancipation" through interactive participation has been used as a rationale for the participatory focus of development, as it is held that 'participation' in any form can lead to empowerment of poor or marginalised groups. Freire was a proponent of critical pedagogy.
"He participated in the import of European doctrines and ideas into Brazil,
assimilated them to the needs of a specific socio-economic situation, and thus expanded and
refocused them in a thought-provoking way"

Date: 1889–1976

Heidegger's philosophizing about education was primarily related to higher education. He believed that teaching and research in the university should be unified and aim towards testing and interrogating the "ontological assumptions presuppositions which implicitly guide research in each domain of knowledge."

Date: 1900–2002

Date: 1924–1998

Date: 1926–1984

"Normative philosophies or theories of education may make use of the results of philosophical thought and of factual inquiries about human beings and the psychology of learning, but in any case they propound views about what education should be, what dispositions it should cultivate, why it ought to cultivate them, how and in whom it should do so, and what forms it should take. In a full-fledged philosophical normative theory of education, besides analysis of the sorts described, there will normally be propositions of the following kinds:


Perennialists believe that one should teach the things that one deems to be of everlasting importance to all people everywhere. They believe that the most important topics develop a person. Since details of fact change constantly, these cannot be the most important. Therefore, one should teach principles, not facts. Since people are human, one should teach first about humans, not machines or techniques. Since people are people first, and workers second if at all, one should teach liberal topics first, not vocational topics. The focus is primarily on teaching reasoning and wisdom rather than facts, the liberal arts rather than vocational training.

Date: 1930–1992

Bloom, a professor of political science at the University of Chicago, argued for a traditional Great Books-based liberal education in his lengthy essay "The Closing of the American Mind".

The Classical education movement advocates a form of education based in the traditions of Western culture, with a particular focus on education as understood and taught in the Middle Ages. The term "classical education" has been used in English for several centuries, with each era modifying the definition and adding its own selection of topics. By the end of the 18th century, in addition to the trivium and quadrivium of the Middle Ages, the definition of a classical education embraced study of literature, poetry, drama, philosophy, history, art, and languages. In the 20th and 21st centuries it is used to refer to a broad-based study of the liberal arts and sciences, as opposed to a practical or pre-professional program. Classical Education can be described as rigorous and systematic, separating children and their learning into three rigid categories, Grammar, Dialectic, and Rhetoric.

Date: 1842–1923

Mason was a British educator who invested her life in improving the quality of children's education. Her ideas led to a method used by some homeschoolers. Mason's philosophy of education is probably best summarized by the principles given at the beginning of each of her books. Two key mottos taken from those principles are "Education is an atmosphere, a discipline, a life" and "Education is the science of relations." She believed that children were born persons and should be respected as such; they should also be taught the Way of the Will and the Way of Reason. Her motto for students was "I am, I can, I ought, I will." Charlotte Mason believed that children should be introduced to subjects through living books, not through the use of "compendiums, abstracts, or selections." She used abridged books only when the content was deemed inappropriate for children. She preferred that parents or teachers read aloud those texts (such as Plutarch and the Old Testament), making omissions only where necessary.

Educational essentialism is an educational philosophy whose adherents believe that children should learn the traditional basic subjects and that these should be learned thoroughly and rigorously. This is based on the view that there are essentials that men should know for being educated and are expected to learn the academic areas of reading, writing, mathematics, science, geography, and technology. This movement, thus, stresses the role played by the teacher as the authority in the classroom, driving the goal of content mastery. 

An essentialist program normally teaches children progressively, from less complex skills to more complex. The "back to basics" movement is an example of essentialism.

Date: 1874–1946

William Chandler Bagley taught in elementary schools before becoming a professor of education at the University of Illinois, where he served as the Director of the School of Education from 1908 until 1917. He was a professor of education at Teachers College, Columbia, from 1917 to 1940. An opponent of pragmatism and progressive education, Bagley insisted on the value of knowledge for its own sake, not merely as an instrument, and he criticized his colleagues for their failure to emphasize systematic study of academic subjects. Bagley was a proponent of educational essentialism.

Critical pedagogy is an "educational movement, guided by passion and principle, to help students develop consciousness of freedom, recognize authoritarian tendencies, and connect knowledge to power and the ability to take constructive action." Based in Marxist theory, critical pedagogy draws on radical democracy, anarchism, feminism, and other movements for social justice.

Date: 1889–1974

Date: 1870–1952

The Montessori method arose from Dr. Maria Montessori's discovery of what she referred to as "the child's true normal nature" in 1907, which happened in the process of her experimental observation of young children given freedom in an environment prepared with materials designed for their self-directed learning activity. The method itself aims to duplicate this experimental observation of children to bring about, sustain and support their true natural way of being.

Waldorf education (also known as Steiner or Steiner-Waldorf education) is a humanistic approach to pedagogy based upon the educational philosophy of the Austrian philosopher Rudolf Steiner, the founder of anthroposophy. Learning is interdisciplinary, integrating practical, artistic, and conceptual elements. The approach emphasizes the role of the imagination in learning, developing thinking that includes a creative as well as an analytic component. The educational philosophy's overarching goals are to provide young people the basis on which to develop into free, morally responsible and integrated individuals, and to help every child fulfill his or her unique destiny, the existence of which anthroposophy posits. Schools and teachers are given considerable freedom to define curricula within collegial structures.

Date: 1861–1925

Steiner founded a holistic educational impulse on the basis of his spiritual philosophy (anthroposophy). Now known as Steiner or Waldorf education, his pedagogy emphasizes a balanced development of cognitive, affective/artistic, and practical skills (head, heart, and hands). Schools are normally self-administered by faculty; emphasis is placed upon giving individual teachers the freedom to develop creative methods.

Steiner's theory of child development divides education into three discrete developmental stages predating but with close similarities to the stages of development described by Piaget. Early childhood education occurs through imitation; teachers provide practical activities and a healthy environment. Steiner believed that young children should meet only goodness. Elementary education is strongly arts-based, centered on the teacher's creative authority; the elementary school-age child should meet beauty. Secondary education seeks to develop the judgment, intellect, and practical idealism; the adolescent should meet truth.

Democratic education is a theory of learning and school governance in which students and staff participate freely and equally in a school democracy. In a democratic school, there is typically shared decision-making among students and staff on matters concerning living, working, and learning together.

Date: 1883–1973

Neill founded Summerhill School, the oldest existing democratic school in Suffolk, England in 1921. He wrote a number of books that now define much of contemporary democratic education philosophy. Neill believed that the happiness of the child should be the paramount consideration in decisions about the child's upbringing, and that this happiness grew from a sense of personal freedom. He felt that deprivation of this sense of freedom during childhood, and the consequent unhappiness experienced by the repressed child, was responsible for many of the psychological disorders of adulthood.

Educational progressivism is the belief that education must be based on the principle that humans are social animals who learn best in real-life activities with other people. Progressivists, like proponents of most educational theories, claim to rely on the best available scientific theories of learning. Most progressive educators believe that children learn as if they were scientists, following a process similar to John Dewey's model of learning known as "the pattern of inquiry": 1) Become aware of the problem. 2) Define the problem. 3) Propose hypotheses to solve it. 4) Evaluate the consequences of the hypotheses from one's past experience. 5) Test the likeliest solution.

Date: 1859–1952

In 1896, Dewey opened the Laboratory School at the University of Chicago in an institutional effort to pursue together rather than apart "utility and culture, absorption and expression, theory and practice, [which] are [indispensable] elements in any educational scheme. As the unified head of the departments of Philosophy, Psychology and Pedagogy, John Dewey articulated a desire to organize an educational experience where children could be more creative than the best of progressive models of his day. Transactionalism as a pragmatic philosophy grew out of the work he did in the Laboratory School. The two most influential works that stemmed from his research and study were "The Child and the Curriculum" (1902) and "Democracy and Education" (1916). Dewey wrote of the dualisms that plagued educational philosophy in the latter book: "Instead of seeing the educative process steadily and as a whole, we see conflicting terms. We get the case of the child vs. the curriculum; of the individual nature vs. social culture." Dewey found that the preoccupation with facts as knowledge in the educative process led students to memorize "ill-understood rules and principles" and while second-hand knowledge learned in mere words is a beginning in study, mere words can never replace the ability to organize knowledge into both useful and valuable experience.

Date: 1896–1980

Jean Piaget was a Swiss developmental psychologist known for his epistemological studies with children. His theory of cognitive development and epistemological view are together called "genetic epistemology". Piaget placed great importance on the education of children. As the Director of the International Bureau of Education, he declared in 1934 that "only education is capable of saving our societies from possible collapse, whether violent, or gradual." Piaget created the International Centre for Genetic Epistemology in Geneva in 1955 and directed it until 1980. According to Ernst von Glasersfeld, Jean Piaget is "the great pioneer of the constructivist theory of knowing."

Jean Piaget described himself as an epistemologist, interested in the process of the qualitative development of knowledge. As he says in the introduction of his book "Genetic Epistemology" (): ""What the genetic epistemology proposes is discovering the roots of the different varieties of knowledge, since its elementary forms, following to the next levels, including also the scientific knowledge.""

Date: 1915–2016

Another important contributor to the inquiry method in education is Bruner. His books "The Process of Education" and "Toward a Theory of Instruction" are landmarks in conceptualizing learning and curriculum development. He argued that any subject can be taught in some intellectually honest form to any child at any stage of development. This notion was an underpinning for his concept of the "spiral" (helical) curriculum which posited the idea that a curriculum should revisit basic ideas, building on them until the student had grasped the full formal concept. He emphasized intuition as a neglected but essential feature of productive thinking. He felt that interest in the material being learned was the best stimulus for learning rather than external motivation such as grades. Bruner developed the concept of discovery learning which promoted learning as a process of constructing new ideas based on current or past knowledge. Students are encouraged to discover facts and relationships and continually build on what they already know.

Unschooling is a range of educational philosophies and practices centered on allowing children to learn through their natural life experiences, including child directed play, game play, household responsibilities, work experience, and social interaction, rather than through a more traditional school curriculum. Unschooling encourages exploration of activities led by the children themselves, facilitated by the adults. Unschooling differs from conventional schooling principally in the thesis that standard curricula and conventional grading methods, as well as other features of traditional schooling, are counterproductive to the goal of maximizing the education of each child.

In 1964 Holt published his first book, "How Children Fail", asserting that the academic failure of schoolchildren was not "despite" the efforts of the schools, but actually "because" of the schools. Not surprisingly, "How Children Fail" ignited a firestorm of controversy. Holt was catapulted into the American national consciousness to the extent that he made appearances on major TV talk shows, wrote book reviews for "Life" magazine, and was a guest on the "To Tell The Truth" TV game show. In his follow-up work, "How Children Learn", published in 1967, Holt tried to elucidate the learning process of children and why he believed school short circuits that process.

Contemplative education focuses on bringing introspective practices such as mindfulness and yoga into curricular and pedagogical processes for diverse aims grounded in secular, spiritual, religious and post-secular perspectives. Contemplative approaches may be used in the classroom, especially in tertiary or (often in modified form) in secondary education. Parker Palmer is a recent pioneer in contemplative methods. The Center for Contemplative Mind in Society founded a branch focusing on education, The Association for Contemplative Mind in Higher Education.

Contemplative methods may also be used by teachers in their preparation; Waldorf education was one of the pioneers of the latter approach. In this case, inspiration for enriching the content, format, or teaching methods may be sought through various practices, such as consciously reviewing the previous day's activities; actively holding the students in consciousness; and contemplating inspiring pedagogical texts. Zigler suggested that only through focusing on their own spiritual development could teachers positively impact the spiritual development of students.





</doc>
<doc id="24984" url="https://en.wikipedia.org/wiki?curid=24984" title="Personality psychology">
Personality psychology

Personality psychology is a branch of psychology that studies personality and its variation among individuals. It is a scientific study which aims to show how people are individually different due to psychological forces. Its areas of focus include:


"Personality" is a dynamic and organized set of characteristics possessed by a person that uniquely influences their environment, cognition, emotions, motivations, and behaviors in various situations. The word "personality" originates from the Latin "persona", which means "mask".

Personality also refers to the pattern of thoughts, feelings, social adjustments, and behaviors consistently exhibited over time that strongly influences one's expectations, self-perceptions, values, and attitudes. Personality also predicts human reactions to other people, problems, and stress. Gordon Allport (1937) described two major ways to study personality: the nomothetic and the idiographic. "Nomothetic psychology" seeks general laws that can be applied to many different people, such as the principle of self-actualization or the trait of extraversion. "Idiographic psychology" is an attempt to understand the unique aspects of a particular individual.

The study of personality has a broad and varied history in psychology with an abundance of theoretical traditions. The major theories include dispositional (trait) perspective, psychodynamic, humanistic, biological, behaviorist, evolutionary, and social learning perspective. However, many researchers and psychologists do not explicitly identify themselves with a certain perspective and instead take an eclectic approach. Research in this area is empirically driven — such as dimensional models, based on multivariate statistics such as factor analysis — or emphasizes theory development, such as that of the psychodynamic theory. There is also a substantial emphasis on the applied field of personality testing. In psychological education and training, the study of the nature of personality and its psychological development is usually reviewed as a prerequisite to courses in abnormal psychology or clinical psychology.

Many of the ideas developed by historical and modern personality theorists stem from the basic philosophical assumptions they hold. The study of personality is not a purely empirical discipline, as it brings in elements of art, science, and philosophy to draw general conclusions. The following five categories are some of the most fundamental philosophical assumptions on which theorists disagree:


Personality type refers to the psychological classification of different types of people. Personality types are distinguished from personality traits, which come in different degrees. There are many types of theories regarding personality, but each theory contains several and sometimes many sub theories. A "theory of personality" constructed by any given psychologist will contain multiple relating theories or sub theories often expanding as more psychologists explore the theory. For example, according to type theories, there are two types of people, introverts and extroverts. According to trait theories, introversion and extroversion are part of a continuous dimension with many people in the middle. The idea of psychological types originated in the theoretical work of Carl Jung, specifically in his 1921 book "Psychologische Typen" ("Psychological Types") and William Marston.

Building on the writings and observations of Jung during World War II, Isabel Briggs Myers and her mother, Katharine C. Briggs, delineated personality types by constructing the Myers–Briggs Type Indicator. This model was later used by David Keirsey with a different understanding from Jung, Briggs and Myers. In the former Soviet Union, Lithuanian Aušra Augustinavičiūtė independently derived a model of personality type from Jung's called socionics.

Theories could also be considered an "approach" to personality or psychology and is generally referred to as a model. The model is an older and more theoretical approach to personality, accepting extroversion and introversion as basic psychological orientations in connection with two pairs of psychological functions:


Briggs and Myers also added another personality dimension to their type indicator to measure whether a person prefers to use a judging or perceiving function when interacting with the external world. Therefore, they included questions designed to indicate whether someone wishes to come to conclusions (judgement) or to keep options open (perception).

This personality typology has some aspects of a trait theory: it explains people's behavior in terms of opposite fixed characteristics. In these more traditional models, the sensing/intuition preference is considered the most basic, dividing people into "N" (intuitive) or "S" (sensing) personality types. An "N" is further assumed to be guided either by thinking or feeling and divided into the "NT" (scientist, engineer) or "NF" (author, humanitarian) temperament. An "S", in contrast, is assumed to be guided more by the judgment/perception axis and thus divided into the "SJ" (guardian, traditionalist) or "SP" (performer, artisan) temperament. These four are considered basic, with the other two factors in each case (including always extraversion/introversion) less important. Critics of this traditional view have observed that the types can be quite strongly stereotyped by professions (although neither Myers nor Keirsey engaged in such stereotyping in their type descriptions), and thus may arise more from the need to categorize people for purposes of guiding their career choice. This among other objections led to the emergence of the five-factor view, which is less concerned with behavior under work conditions and more concerned with behavior in personal and emotional circumstances. (The MBTI is not designed to measure the "work self", but rather what Myers and McCaulley called the "shoes-off self.")

Type A and Type B personality theory: During the 1950s, Meyer Friedman and his co-workers defined what they called Type A and Type B behavior patterns. They theorized that intense, hard-driving Type A personalities had a higher risk of coronary disease because they are "stress junkies." Type B people, on the other hand, tended to be relaxed, less competitive, and lower in risk. There was also a Type AB mixed profile.

John L. Holland's "RIASEC" vocational model, commonly referred to as the "Holland Codes", stipulates that six personality types lead people to choose their career paths. In this circumplex model, the six types are represented as a hexagon, with adjacent types more closely related than those more distant. The model is widely used in vocational counseling.

Trnka et al. (2016) pointed out "the reductionist nature of the two-dimensional paradigm in the psychological theory of emotions and challenge the circumplex model” and constructed a 3D hypercube-projection.

Eduard Spranger's personality-model, consisting of six (or, by some revisions, 6 +1) basic types of "value attitudes", described in his book "Types of Men" ("Lebensformen"; Halle (Saale): Niemeyer, 1914; English translation by P. J. W. Pigors - New York: G. E. Stechert Company, 1928).

The Enneagram of Personality, a model of human personality which is principally used as a typology of nine interconnected personality types. It has been criticized as being subject to interpretation, making it difficult to test or validate scientifically.

Perhaps the most ancient attempt at personality psychology is the personality typology outlined by the Indian Buddhist Abhidharma schools. This typology mostly focuses on negative personal traits (greed, hatred, and delusion) and the corresponding positive meditation practices used to counter those traits.

Psychoanalytic theories explain human behavior in terms of the interaction of various components of personality. Sigmund Freud was the founder of this school of thought. Freud drew on the physics of his day (thermodynamics) to coin the term psychodynamics. Based on the idea of converting heat into mechanical energy, he proposed psychic energy could be converted into behavior. Freud's theory places central importance on dynamic, unconscious psychological conflicts.

Freud divides human personality into three significant components: the id, ego and super-ego. The id acts according to the "pleasure principle", demanding immediate gratification of its needs regardless of external environment; the ego then must emerge in order to realistically meet the wishes and demands of the id in accordance with the outside world, adhering to the "reality principle". Finally, the superego (conscience) inculcates moral judgment and societal rules upon the ego, thus forcing the demands of the id to be met not only realistically but morally. The superego is the last function of the personality to develop, and is the embodiment of parental/social ideals established during childhood. According to Freud, personality is based on the dynamic interactions of these three components.

The channeling and release of sexual (libidal) and aggressive energies, which ensues from the "Eros" (sex; instinctual self-preservation) and "Thanatos" (death; instinctual self-annihilation) drives respectively, are major components of his theory. It is important to note that Freud's broad understanding of sexuality included all kinds of pleasurable feelings experienced by the human body.

Freud proposed five psychosexual stages of personality development. He believed adult personality is dependent upon early childhood experiences and largely determined by age five. Fixations that develop during the infantile stage contribute to adult personality and behavior.

One of Sigmund Freud's earlier associates, Alfred Adler, did agree with Freud that early childhood experiences are important to development and believed birth order may influence personality development. Adler believed that the oldest child was the individual who would set high achievement goals in order to gain attention lost when the younger siblings were born. He believed the middle children were competitive and ambitious. He reasoned that this behavior was motivated by the idea of surpassing the firstborn's achievements. He added, however, that the middle children were often not as concerned about the glory attributed with their behavior. He also believed the youngest would be more dependent and sociable. Adler finished by surmising that an only child loves being the center of attention and matures quickly but in the end fails to become independent.

Heinz Kohut thought similarly to Freud's idea of transference. He used narcissism as a model of how people develop their sense of self. Narcissism is the exaggerated sense of one self in which one is believed to exist in order to protect one's low self-esteem and sense of worthlessness. Kohut had a significant impact on the field by extending Freud's theory of narcissism and introducing what he called the 'self-object transferences' of mirroring and idealization. In other words, children need to idealize and emotionally "sink into" and identify with the idealized competence of admired figures such as parents or older siblings. They also need to have their self-worth mirrored by these people. These experiences allow them to thereby learn the self-soothing and other skills that are necessary for the development of a healthy sense of self.

Another important figure in the world of personality theory is Karen Horney. She is credited with the development of "Feminist Psychology". She disagrees with Freud on some key points, one being that women's personalities aren't just a function of "Penis Envy", but that girl children have separate and different psychic lives unrelated to how they feel about their fathers or primary male role models. She talks about three basic Neurotic needs "Basic Anxiety", "Basic Hostility" and "Basic Evil". She posits that to any anxiety an individual experiences they would have one of three approaches, moving toward people, moving away from people or moving against people. It's these three that give us varying personality types and characteristics. She also places a high premium on concepts like Overvaluation of Love and romantic partners.

Behaviorists explain personality in terms of the effects external stimuli have on behavior. The approaches used to analyze the behavioral aspect of personality are known as behavioral theories or learning-conditioning theories. These approaches were a radical shift away from Freudian philosophy. One of the major tenets of this concentration of personality psychology is a strong emphasis on scientific thinking and experimentation. This school of thought was developed by B. F. Skinner who put forth a model which emphasized the mutual interaction of the person or "the organism" with its environment. Skinner believed children do bad things because the behavior obtains attention that serves as a reinforcer. For example: a child cries because the child's crying in the past has led to attention. These are the "response", and "consequences". The response is the child crying, and the attention that child gets is the reinforcing consequence. According to this theory, people's behavior is formed by processes such as operant conditioning. Skinner put forward a "three term contingency model" which helped promote analysis of behavior based on the "Stimulus - Response - Consequence Model" in which the critical question is: "Under which circumstances or antecedent 'stimuli' does the organism engage in a particular behavior or 'response', which in turn produces a particular 'consequence'?"

Richard Herrnstein extended this theory by accounting for attitudes and traits. An attitude develops as the response strength (the tendency to respond) in the presences of a group of stimuli become stable. Rather than describing conditionable traits in non-behavioral language, response strength in a given situation accounts for the environmental portion. Herrstein also saw traits as having a large genetic or biological component, as do most modern behaviorists.

Ivan Pavlov is another notable influence. He is well known for his classical conditioning experiments involving dogs, which led him to discover the foundation of behaviorism.

In cognitive theory, behavior is explained as guided by cognitions (e.g. expectations) about the world, especially those about other people. Cognitive theories are theories of personality that emphasize cognitive processes, such as thinking and judging.

Albert Bandura, a social learning theorist suggested the forces of memory and emotions worked in conjunction with environmental influences. Bandura was known mostly for his "Bobo doll experiment". During these experiments, Bandura video taped a college student kicking and verbally abusing a bobo doll. He then showed this video to a class of kindergarten children who were getting ready to go out to play. When they entered the play room, they saw bobo dolls, and some hammers. The people observing these children at play saw a group of children beating the doll. He called this study and his findings observational learning, or modeling.

Early examples of approaches to cognitive style are listed by Baron (1982). These include Witkin's (1965) work on field dependency, Gardner's (1953) discovering people had consistent preference for the number of categories they used to categorise heterogeneous objects, and Block and Petersen's (1955) work on confidence in line discrimination judgments. Baron relates early development of cognitive approaches of personality to ego psychology. More central to this field have been:


Various scales have been developed to assess both attributional style and locus of control. Locus of control scales include those used by Rotter and later by Duttweiler, the Nowicki and Strickland (1973) Locus of Control Scale for Children and various locus of control scales specifically in the health domain, most famously that of Kenneth Wallston and his colleagues, The Multidimensional Health Locus of Control Scale. Attributional style has been assessed by the Attributional Style Questionnaire, the Expanded Attributional Style Questionnaire, the Attributions Questionnaire, the Real Events Attributional Style Questionnaire and the Attributional Style Assessment Test.


Recognition that the tendency to believe that hard work and persistence often results in attainment of life and academic goals has influenced formal educational and counseling efforts with students of various ages and in various settings since the 1970s research about achievement. Counseling aimed toward encouraging individuals to design ambitious goals and work toward them, with recognition that there are external factors that may impact, often results in the incorporation of a more positive achievement style by students and employees, whatever the setting, to include higher education, workplace, or justice programming.

Walter Mischel (1999) has also defended a cognitive approach to personality. His work refers to "Cognitive Affective Units", and considers factors such as encoding of stimuli, affect, goal-setting, and self-regulatory beliefs. The term "Cognitive Affective Units" shows how his approach considers affect as well as cognition.

Cognitive-Experiential Self-Theory (CEST) is another cognitive personality theory. Developed by Seymour Epstein, CEST argues that humans operate by way of two independent information processing systems: experiential system and rational system. The experiential system is fast and emotion-driven. The rational system is slow and logic-driven. These two systems interact to determine our goals, thoughts, and behavior.

Personal construct psychology (PCP) is a theory of personality developed by the American psychologist George Kelly in the 1950s. Kelly's fundamental view of personality was that people are like naive scientists who see the world through a particular lens, based on their uniquely organized systems of construction, which they use to anticipate events. But because people are naive scientists, they sometimes employ systems for construing the world that are distorted by idiosyncratic experiences not applicable to their current social situation. A system of construction that chronically fails to characterize and/or predict events, and is not appropriately revised to comprehend and predict one's changing social world, is considered to underlie psychopathology (or mental illness.)
From the theory, Kelly derived a psychotherapy approach and also a technique called "The Repertory Grid Interview" that helped his patients to uncover their own "constructs" with minimal intervention or interpretation by the therapist. The repertory grid was later adapted for various uses within organizations, including decision-making and interpretation of other people's world-views.

Humanistic psychology emphasizes that people have free will and that this plays an active role in determining how they behave. Accordingly, humanistic psychology focuses on subjective experiences of persons as opposed to forced, definitive factors that determine behavior. Abraham Maslow and Carl Rogers were proponents of this view, which is based on the "phenomenal field" theory of Combs and Snygg (1949). Rogers and Maslow were among a group of psychologists that worked together for a decade to produce the "Journal of Humanistic Psychology". This journal was primarily focused on viewing individuals as a whole, rather than focusing solely on separate traits and processes within the individual.

Robert W. White wrote the book "The Abnormal Personality" that became a standard text on abnormal psychology. He also investigated the human need to strive for positive goals like competence and influence, to counterbalance the emphasis of Freud on the pathological elements of personality development.

Maslow spent much of his time studying what he called "self-actualizing persons", those who are "fulfilling themselves and doing the best they are capable of doing". Maslow believes all who are interested in growth move towards self-actualizing (growth, happiness, satisfaction) views. Many of these people demonstrate a trend in dimensions of their personalities. Characteristics of self-actualizers according to Maslow include the four key dimensions:

Maslow and Rogers emphasized a view of the person as an active, creative, experiencing human being who lives in the present and subjectively responds to current perceptions, relationships, and encounters. They disagree with the dark, pessimistic outlook of those in the Freudian psychoanalysis ranks, but rather view humanistic theories as positive and optimistic proposals which stress the tendency of the human personality toward growth and self-actualization. This progressing self will remain the center of its constantly changing world; a world that will help mold the self but not necessarily confine it. Rather, the self has opportunity for maturation based on its encounters with this world. This understanding attempts to reduce the acceptance of hopeless redundancy. Humanistic therapy typically relies on the client for information of the past and its effect on the present, therefore the client dictates the type of guidance the therapist may initiate. This allows for an individualized approach to therapy. Rogers found patients differ in how they respond to other people. Rogers tried to model a particular approach to therapy- he stressed the reflective or empathetic response. This response type takes the client's viewpoint and reflects back their feeling and the context for it. An example of a reflective response would be, "It seems you are feeling anxious about your upcoming marriage". This response type seeks to clarify the therapist's understanding while also encouraging the client to think more deeply and seek to fully understand the feelings they have expressed.

Biology plays a very important role in the development of personality. The study of the biological level in personality psychology focuses primarily on identifying the role of genetic determinants and how they mold individual personalities. Some of the earliest thinking about possible biological bases of personality grew out of the case of Phineas Gage. In an 1848 accident, a large iron rod was driven through Gage's head, and his personality apparently changed as a result, although descriptions of these psychological changes are usually exaggerated.

In general, patients with brain damage have been difficult to find and study. In the 1990s, researchers began to use electroencephalography (EEG), positron emission tomography (PET), and more recently functional magnetic resonance imaging (fMRI), which is now the most widely used imaging technique to help localize personality traits in the brain.

Ever since the Human Genome Project allowed for a much more in depth understanding of genetics, there has been an ongoing controversy involving heritability, personality traits, and environmental vs. genetic influence on personality. The human genome is known to play a role in the development of personality.
Previously, genetic personality studies focused on specific genes correlating to specific personality traits. Today's view of the gene-personality relationship focuses primarily on the activation and expression of genes related to personality and forms part of what is referred to as behavioural genetics. Genes provide numerous options for varying cells to be expressed; however, the environment determines which of these are activated. Many studies have noted this relationship in varying ways in which our bodies can develop, but the interaction between genes and the shaping of our minds and personality is also relevant to this biological relationship.
DNA-environment interactions are important in the development of personality because this relationship determines what part of the DNA code is actually made into proteins that will become part of an individual. While different choices are made available by the genome, in the end, the environment is the ultimate determinant of what becomes activated. Small changes in DNA in individuals are what lead to the uniqueness of every person as well as differences in looks, abilities, brain functioning, and all the factors that culminate to develop a cohesive personality.

Cattell and Eysenck have proposed that genetics have a strong influence on personality. A large part of the evidence collected linking genetics and the environment to personality have come from twin studies. This "twin method" compares levels of similarity in personality using genetically identical twins. One of the first of these twin studies measured 800 pairs of twins, studied numerous personality traits, and determined that identical twins are most similar in their general abilities. Personality similarities were found to be less related for self-concepts, goals, and interests.

Twin studies have also been important in the creation of the five factor personality model: neuroticism, extraversion, openness, agreeableness, and conscientiousness. Neuroticism and extraversion are the two most widely studied traits. A person that may fall into the extravert category can display characteristics such as impulsiveness, sociability, and activeness. A person falling into the neuroticism category may be more likely to be moody, anxious, or irritable. Identical twins, however, have higher correlations in personality traits than fraternal twins. One study measuring genetic influence on twins in five different countries found that the correlations for identical twins were .50, while for fraternal they were about .20. It is suggested that heredity and environment interact to determine one's personality.

Charles Darwin is the founder of the theory of the evolution of the species. The evolutionary approach to personality psychology is based on this theory. This theory examines how individual personality differences are based on natural selection. Through natural selection organisms change over time through adaptation and selection. Traits are developed and certain genes come into expression based on an organism's environment and how these traits aid in an organism's survival and reproduction.

Polymorphisms, such as gender and blood type, are forms of diversity which evolve to benefit a species as a whole. The theory of evolution has wide-ranging implications on personality psychology. Personality viewed through the lens of evolutionary psychology places a great deal of emphasis on specific traits that are most likely to aid in survival and reproduction, such as conscientiousness, sociability, emotional stability, and dominance. The social aspects of personality can be seen through an evolutionary perspective. Specific character traits develop and are selected for because they play an important and complex role in the social hierarchy of organisms. Such characteristics of this social hierarchy include the sharing of important resources, family and mating interactions, and the harm or help organisms can bestow upon one another.

In the 1930s, John Dollard and Neal Elgar Miller met at Yale University, and began an attempt to integrate drives (see Drive theory), into a theory of personality, basing themselves on the work of Clark Hull. They began with the premise that personality could be equated with the habitual responses exhibited by an individual – their habits. From there, they determined that these habitual responses were built on secondary, or acquired drives.

Secondary drives are internal needs directing the behaviour of an individual that results from learning. Acquired drives are learned, by and large in the manner described by classical conditioning. When we are in a certain environment and experience a strong response to a stimulus, we internalize cues from the said environment. When we find ourselves in an environment with similar cues, we begin to act in anticipation of a similar stimulus. Thus, we are likely to experience anxiety in an environment with cues similar to one where we have experienced pain or fear – such as the dentist's office.

Secondary drives are built on primary drives, which are biologically driven, and motivate us to act with no prior learning process – such as hunger, thirst or the need for sexual activity. However, secondary drives are thought to represent more specific elaborations of primary drives, behind which the functions of the original primary drive continue to exist. Thus, the primary drives of fear and pain exist behind the acquired drive of anxiety. Secondary drives can be based on multiple primary drives and even in other secondary drives. This is said to give them strength and persistence. Examples include the need for money, which was conceptualized as arising from multiple primary drives such as the drive for food and warmth, as well as from secondary drives such as imitativeness (the drive to do as others do) and anxiety.

Secondary drives vary based on the social conditions under which they were learned – such as culture. Dollard and Miller used the example of food, stating that the primary drive of hunger manifested itself behind the learned secondary drive of an appetite for a specific type of food, which was dependent on the culture of the individual.

Secondary drives are also explicitly social, representing a manner in which we convey our primary drives to others. Indeed, many primary drives are actively repressed by society (such as the sexual drive). Dollard and Miller believed that the acquisition of secondary drives was essential to childhood development. As children develop, they learn not to act on their primary drives, such as hunger but acquire secondary drives through reinforcement. Friedman and Schustack describe an example of such developmental changes, stating that if an infant engaging in an active orientation towards others brings about the fulfillment of primary drives, such as being fed or having their diaper changed, they will develop a secondary drive to pursue similar interactions with others – perhaps leading to an individual being more gregarious. Dollard and Miller's belief in the importance of acquired drives led them to reconceive Sigmund Freud's theory of psychosexual development. They found themselves to be in agreement with the timing Freud used but believed that these periods corresponded to the successful learning of certain secondary drives.

Dollard and Miller gave many examples of how secondary drives impact our habitual responses – and by extension our personalities, including anger, social conformity, imitativeness or anxiety, to name a few. In the case of anxiety, Dollard and Miller note that people who generalize the situation in which they experience the anxiety drive will experience anxiety far more than they should. These people are often anxious all the time, and anxiety becomes part of their personality. This example shows how drive theory can have ties with other theories of personality – many of them look at the trait of neuroticism or emotional stability in people, which is strongly linked to anxiety.

There are two major types of personality tests, projective and objective.

"Projective tests" assume personality is primarily unconscious and assess individuals by how they respond to an ambiguous stimulus, such as an ink blot. Projective tests have been in use for about 60 years and continue to be used today. Examples of such tests include the Rorschach test and the Thematic Apperception Test.

The Rorschach Test involves showing an individual a series of note cards with ambiguous ink blots on them. The individual being tested is asked to provide interpretations of the blots on the cards by stating everything that the ink blot may resemble based on their personal interpretation. The therapist then analyzes their responses. Rules for scoring the test have been covered in manuals that cover a wide variety of characteristics such as content, originality of response, location of "perceived images" and several other factors. Using these specific scoring methods, the therapist will then attempt to relate test responses to attributes of the individual's personality and their unique characteristics. The idea is that unconscious needs will come out in the person's response, e.g. an aggressive person may see images of destruction.
The Thematic Apperception Test (also known as the TAT) involves presenting individuals with vague pictures/scenes and asking them to tell a story based on what they see. Common examples of these "scenes" include images that may suggest family relationships or specific situations, such as a father and son or a man and a woman in a bedroom. Responses are analyzed for common themes. Responses unique to an individual are theoretically meant to indicate underlying thoughts, processes, and potentially conflicts present within the individual. Responses are believed to be directly linked to unconscious motives. There is very little empirical evidence available to support these methods.

"Objective tests" assume personality is consciously accessible and that it can be measured by self-report questionnaires. Research on psychological assessment has generally found objective tests to be more valid and reliable than projective tests. Critics have pointed to the Forer effect to suggest some of these appear to be more accurate and discriminating than they really are. Issues with these tests include false reporting because there is no way to tell if an individual is answering a question honestly or accurately.

The Myers-Briggs Type Indicator (also known as the MBTI) is self-reporting questionnaire based on Carl Jung's Type theory.


Psychology has traditionally defined personality through its behavioral patterns, and more recently with neuroscientific studies of the brain. In recent years, some psychologists have turned to the study of inner experiences for insight into personality as well as individuality. Inner experiences are the thoughts and feelings to an immediate phenomenon. Another term used to define inner experiences is qualia. Being able to understand inner experiences assists in understanding how humans behave, act, and respond. Defining personality using inner experiences has been expanding due to the fact that solely relying on behavioral principles to explain one's character may seem incomplete. Behavioral methods allow the subject to be observed by an observer, whereas with inner experiences the subject is its own observer.

Descriptive experience sampling (DES), developed by psychologist Russel Hurlburt. This is an idiographic method that is used to help examine inner experiences. This method relies on an introspective technique that allows an individual's inner experiences and characteristics to be described and measured. A beep notifies the subject to record their experience at that exact moment and 24 hours later an interview is given based on all the experiences recorded. DES has been used in subjects that have been diagnosed with schizophrenia and depression. It has also been crucial to studying the inner experiences of those who have been diagnosed with common psychiatric diseases.

Articulated thoughts in stimulated situations (ATSS): ATSS is a paradigm which was created as an alternative to the TA (think aloud) method. This method assumes that people have continuous internal dialogues that can be naturally attended to. ATSS also assesses a person's inner thoughts as they verbalize their cognitions. In this procedure, subjects listen to a scenario via a video or audio player and are asked to imagine that they are in that specific situation. Later, they are asked to articulate their thoughts as they occur in reaction to the playing scenario. This method is useful in studying emotional experience given that the scenarios used can influence specific emotions. Most importantly, the method has contributed to the study of personality. In a study conducted by Rayburn and Davison (2002), subjects’ thoughts and empathy toward anti-gay hate crimes were evaluated. The researchers found that participants showed more aggressive intentions towards the offender in scenarios which mimicked hate crimes.

Experimental method: This method is an experimental paradigm used to study human experiences involved in the studies of sensation and perception, learning and memory, motivation, and biological psychology. The experimental psychologist usually deals with intact organisms although studies are often conducted with organisms modified by surgery, radiation, drug treatment, or long-standing deprivations of various kinds or with organisms that naturally present organic abnormalities or emotional disorders. Economists and psychologists have developed a variety of experimental methodologies to elicit and assess individual attitudes where each emotion differs for each individual. The results are then gathered and quantified to conclude if specific experiences have any common factors. This method is used to seek clarity of the experience and remove any biases to help understand the meaning behind the experience to see if it can be generalized.




</doc>
<doc id="24985" url="https://en.wikipedia.org/wiki?curid=24985" title="Pronoun">
Pronoun

In linguistics and grammar, a pronoun (abbreviated ) has been theorized to be a word that substitutes for a noun or noun phrase. It is a particular case of a pro-form.

Pronouns have traditionally been regarded as one of the parts of speech, but some modern theorists would not consider them to form a single class, in view of the variety of functions they perform cross-linguistically. An example of a pronoun is "their", which is both plural and singular. Subtypes include personal and possessive pronouns, reflexive and reciprocal pronouns, demonstrative pronouns, relative and interrogative pronouns, and indefinite pronouns.

The use of pronouns often involves anaphora, where the meaning of the pronoun is dependent on an antecedent. For example, in the sentence "That poor man looks as if he needs a new coat", the antecedent of the pronoun "he" is dependent on "that poor man".

The adjective associated with "pronoun" is pronominal. A pronominal is also a word or phrase that acts as a pronoun. For example, in "That's not the one I wanted", the phrase "the one" (containing the prop-word "one") is a pronominal.

Pronouns "(antōnymía)" are listed as one of eight parts of speech in "The Art of Grammar", a treatise on Greek grammar attributed to Dionysius Thrax and dating from the 2nd century BC. The pronoun is described there as "a part of speech substitutable for a noun and marked for a person." Pronouns continued to be regarded as a part of speech in Latin grammar (the Latin term being , from which the English name – through Middle French – ultimately derives), and thus in the European tradition generally.

In more modern approaches, pronouns are less likely to be considered to be a single word class, because of the many different syntactic roles that they play, as represented by the various different types of pronouns listed in the previous sections.

Linguists in particular have trouble classifying pronouns in a single category, and some do not agree that pronouns substitute nouns or noun categories. Certain types of pronouns are often identical or similar in form to determiners with related meaning; some English examples are given in the table on the right. This observation has led some linguists, such as Paul Postal, to regard pronouns as determiners that have had their following noun or noun phrase deleted. (Such patterning can even be claimed for certain personal pronouns; for example, "we" and "you" might be analyzed as determiners in phrases like "we Brits" and "you tennis players".) Other linguists have taken a similar view, uniting pronouns and determiners into a single class, sometimes called "determiner-pronoun", or regarding determiners as a subclass of pronouns or vice versa. The distinction may be considered to be one of subcategorization or valency, rather like the distinction between transitive and intransitive verbs – determiners take a noun phrase complement like transitive verbs do, while pronouns do not. This is consistent with the determiner phrase viewpoint, whereby a determiner, rather than the noun that follows it, is taken to be the head of the phrase. Cross-linguistically, it seems as though pronouns share 3 distinct categories: point of view, person, and number. The breadth of each subcategory however tends to differ among languages.

The use of pronouns often involves anaphora, where the meaning of the pronoun is dependent on another referential element. The referent of the pronoun is often the same as that of a preceding (or sometimes following) noun phrase, called the antecedent of the pronoun. The grammatical behavior of certain types of pronouns, and in particular their possible relationship with their antecedents, has been the focus of studies in binding, notably in the Chomskyan government and binding theory. In this binding context, reflexive and reciprocal pronouns in English (such as "himself" and "each other") are referred to as anaphors (in a specialized restricted sense) rather than as pronominal elements. Under binding theory, specific principles apply to different sets of pronouns. 
In English, reflexive and reciprocal pronouns must adhere to Principle A: an anaphor (reflexive or reciprocal, such as "each other") must be bound in its governing category (roughly, the clause). Therefore, in syntactic structure it must be lower in structure (it must have an antecedant) and have a direct relationship with its referent. This is called a C-command relationship. For instance, we see that "John cut himself" is grammatical, but "Himself cut John" is not, despite having identical arguments, since "himself", the reflexive, must be lower in structure to John, its referent. Additionally, we see examples like "John said that Mary cut himself" are not grammatical because there is an intermediary noun, "Mary", that disallows the two referents from having a direct relationship.
On the other hand, personal pronouns (such as "him" or "them") must adhere to Principle B: a pronoun must be free (i.e., not bound) within its governing category (roughly, the clause). This means that although the pronouns can have a referent, they cannot have a direct relationship with the referent where the referent selects the pronoun. For instance, "John said Mary cut him" is grammatical because the two co-referents, "John" and "him" are separated structurally by "Mary". This is why a sentence like "John cut him" where "him" refers to "John" is ungrammatical.

The type of binding that applies to subsets of pronouns varies cross-linguistically. For instance, in German linguistics, pronouns can be split into two distinct categories — personal pronouns and d-pronouns. Although personal pronouns act identically to that of English personal pronouns (i.e. follow Principle A), d-pronouns follow yet another principle, Principle C, and function similarly to nouns in that they cannot have a direct relationship to an antecedent.

The following sentences give examples of particular types of pronouns used with antecedents:


Some other types, such as indefinite pronouns, are usually used without antecedents. Relative pronouns are used without antecedents in free relative clauses. Even third-person personal pronouns are sometimes used without antecedents ("unprecursed") – this applies to special uses such as dummy pronouns and generic "they", as well as cases where the referent is implied by the context.

The table below lists English pronouns across a number of different syntactic contexts (Subject, Object, Possessive, Reflexive) according to the following features:

In addition to the personal pronouns exemplified in the above table, English also has other pronoun types, including demonstrative, relative, indefinite, and interrogative pronouns, as listed in the following table. For more detailed discussion, see the following subsections.

Personal pronouns may be classified by person, number, gender and case. English has three persons (first, second and third) and two numbers (singular and plural); in the third person singular there are also distinct pronoun forms for male, female and neuter gender. Principal forms are shown in the adjacent table (see also English personal pronouns).

English personal pronouns have two cases, "subject" and "object". Subject pronouns are used in subject position (I like to eat chips, but she does not"). Object pronouns are used for the object of a verb or preposition ("John likes me but not her).

Other distinct forms found in some languages include:


Possessive pronouns are used to indicate possession (in a broad sense). Some occur as independent noun phrases: "mine", "yours", "hers", "ours", "theirs". An example is: "Those clothes are mine." Others act as a determiner and must accompany a noun: "my", "your", "her", "our", "your", "their", as in: "I lost my wallet." ("His" and "its" can fall into either category, although "its" is nearly always found in the second.) Those of the second type have traditionally also been described as possessive adjectives, and in more modern terminology as possessive determiners. The term "possessive pronoun" is sometimes restricted to the first type. Both types replace possessive noun phrases. As an example, Their crusade to capture our attention" could replace The advertisers' crusade to capture our attention."

Reflexive pronouns are used when a person or thing acts on itself, for example, "John cut himself." In English they all end in "-self" or "-selves" and must refer to a noun phrase elsewhere in the same clause.

Reciprocal pronouns refer to a reciprocal relationship ("each other", "one another"). They must refer to a noun phrase in the same clause. An example in English is: "They do not like each other." In some languages, the same forms can be used as both reflexive and reciprocal pronouns.

Demonstrative pronouns (in English, "this", "that" and their plurals "these", "those") often distinguish their targets by pointing or some other indication of position; for example, "I'll take these." They may also be "anaphoric", depending on an earlier expression for context, for example, "A kid actor would try to be all sweet, and who needs that?"

Indefinite pronouns, the largest group of pronouns, refer to one or more unspecified persons or things. One group in English includes compounds of "some-", "any-", "every-" and "no-" with "-thing", "-one" and "-body", for example: "Anyone can do that." Another group, including "many", "more", "both", and "most", can appear alone or followed by "of". In addition,


Relative pronouns in English include "who", "whom", "whose", "what", "which" and "that"). They rely on an antecedent, and refer back to people or things previously mentioned: "People who smoke should quit now." They are used in relative clauses. Relative pronouns can also be used as complementizers.

Relative pronouns can be used in an interrogative setting as interrogative pronouns. Interrogative pronouns ask which person or thing is meant. In reference to a person, one may use "who" (subject), "whom" (object) or "whose" (possessive); for example, "Who did that?" In colloquial speech, "whom" is generally replaced by "who". English non-personal interrogative pronouns ("which" and "what") have only one form.

In English and many other languages (e.g. French and Czech), the sets of relative and interrogative pronouns are nearly identical. Compare English: "Who is that?" (interrogative) and "I know the woman who came" (relative). In some other languages, interrogative pronouns and indefinite pronouns are frequently identical; for example, Standard Chinese means "what?" as well as "something" or "anything".

Though the personal pronouns described above are the "contemporary" English pronouns, older forms of "modern" English (as used by Shakespeare, for example) use a slightly different set of personal pronouns as shown in the table. The difference is entirely in the second person. Though one would rarely find these older forms used in literature from recent centuries, they are nevertheless considered "modern".

Some special uses of personal pronouns include:








</doc>
<doc id="24986" url="https://en.wikipedia.org/wiki?curid=24986" title="Pelagianism">
Pelagianism

Pelagianism, also called the Pelagian heresy, is the Christian theological position that the original sin did not taint human nature and that mortal will is still capable of choosing good or evil without special divine aid or assistance. This theological theory is named after the British monk Pelagius ( – 418), although he denied, at least at some point in his life, many of the doctrines associated with his name. Pelagius taught human will, as created with its abilities by God, was sufficient to live a sinless life, although he believed God's grace assisted every good work. Pelagianism has come to be identified with the view (whether taught by Pelagius or not) human beings can earn salvation by their own efforts.

According to Augustinian theologians, Pelagius rejected the biblical concept of grace. According to his opponents, Pelagius taught moral perfection was attainable in this life without the assistance of divine grace through human free will. Augustine contradicted this by saying perfection was impossible without grace because we are born sinners with a sinful heart and will. The Pelagians charged Augustine with departing from the accepted teaching (e.g.: John 8:11) of the Apostles and the Bible, demonstrating the doctrine of original sin amounted to Manichaeism, which taught that the flesh was in itself sinful (and thus denied Jesus came in the flesh). This charge would have carried added weight since contemporaries knew Augustine had himself been a Manichaean layman before converting to Christianity. Augustine also taught a person's salvation comes solely through a free gift, the efficacious grace of God, but this was a gift one had no free choice to accept or refuse.

An attack on Pelagianism was brought forward in 415 at the Council of Diospolis (also known as Lydda or Lod), which then found Pelagius to be orthodox. But it was later condemned at the Council of Carthage (418) and this condemnation was ratified at the Council of Ephesus in 431. The strict moral teachings of the Pelagians were influential in southern Italy, where they were openly preached until the death of Julian of Eclanum in 455; in Sicily, where the anonymous "Sicilian Briton" wrote; and in Britain until the coming of Saint Germanus of Auxerre c 429. Despite repeated attempts to suppress Pelagianism and similar teachings by orthodox clergy, some followers of Pelagianism were still active in the Ostrogothic Kingdom (493–553), most notably in Picenum and Dalmatia during the rule of Theoderic the Great.

In "De causa Dei contra Pelagium et de virtute causarum", Thomas Bradwardine denounced Pelagianism in the 14th century, as did Gabriel Biel in the 15th century.

Little is known about the life of Pelagius, and although he is frequently referred to as a "British" monk, his origins are by no means certain. ("Pelagius" is derived from the Greek "pelagikos", meaning of the sea.) Augustine says that he lived in Rome "for a very long time" and referred to him as "Brito" to distinguish him from a different man called Pelagius of Tarentum. Bede refers to him as "Pelagius Bretto". St. Jerome suggests he was of Scottish descent which at the time would most certainly have meant he was from Ireland, since in the time of Pelagius, "Scots" referred to the Irish because Scota (source of "Scottish" or "Irish" in the early Middle Ages) was one of their matronyms; the word Irish comes from the matronym Ériu. Other sources place his origins in Brittany. He was certainly well known in the Roman province, both for the harsh asceticism of his public life, as well as the power and persuasiveness of his speech. Augustine, a pillar of the Church, referred to him as "saintly" before their falling out and John Wesley said "he was both a wise and a holy man".

The teachings of Pelagius are generally associated with the rejection of both original sin and infant baptism. Although the writings of Pelagius are no longer extant, the eight canons of the Council of Carthage (418) provided corrections to the perceived errors of the early Pelagians. These corrections include:

Some codices containing a ninth canon: Children dying without baptism do not go to a "middle place" (""), since the non-reception of baptism excludes both from the "kingdom of heaven" and from "eternal life". Pelagianism stands in contrast to the official hamartiological system of the Catholic Church that is based on the theology of Saint Augustine of Hippo. Semipelagianism is a modified form of Pelagianism that was also condemned by the Catholic Church at the Council of Orange (529).

Of far-reaching influence upon the further progress of Pelagianism was the friendship which Pelagius developed in Rome with Caelestius, a lawyer of noble (probably Italian) descent. In the capacity of a lay-monk Caelestius endeavoured to convert the practical maxims learnt from Pelagius, into theoretical principles, which he then propagated in Rome. The denial of the transmission of Original Sin seems to have been introduced into Pelagianism by Rufinus the Syrian, who influenced Pelagius' supporter Celestius. Pelagius' views were sometimes misrepresented by his followers and distorted by his opponents. "Pelagianism has come to mean – unfairly to its founder – the view that human beings can earn salvation by their own efforts."

Pelagius was disturbed by the immorality he encountered in Rome and saw Christians using human frailty as an excuse for their failure to live a Christian life. He taught that the human will, as created with its abilities by God, was sufficient to live a sinless life, although he believed that God's grace assisted every good work. Pelagius did not believe that all humanity was guilty in Adam's sin, but said that Adam had condemned mankind through bad example. The value of Christ's redemption was, in his opinion, limited mainly to instruction and example.

Pelagius wrote:

A follower of Pelagius taught:

Many of the Church Fathers before Augustine taught that humans have the power of free will and the choice over good and evil.


Jerome (d. 420) emerged as one of the chief critics of Pelagianism, because, according to him, sin was an unavoidable part of human nature.

Thomas Bradwardine (c. 1290–1349) wrote "De causa Dei contra Pelagium et de virtute causarum ad suos Mertonenses". Johann Pupper, also known as Johannes von Goch (c. 1400–1475), an Augustinian, recommended a return to the text of the Bible as a remedy for Pelagianism.

Pelagianism became a common accusation during the Protestant Reformation; Reformers often used the epithet to critique what they saw as late-medieval Catholicism's undue emphasis on doing good works. Martin Luther (1483–1546), John Calvin (1509–1564), and Cornelius Jansen (1585–1638) reacted in different ways against Pelagianism, and evaluations of Lutheran, Reformed, and Jansenist theologies have often turned on the question of what is or is not Pelagian.
In the book "Guardare Cristo: Esercizi di fede, speranza e carità" (Looking at Christ: Exercises of faith, hope and charity), Pope Benedict XVI wrote: 

In a June 2013 talk with the leadership of the Religious Confederation of Latin America and the Caribbean (CLAR), Pope Francis alluded to Pelagian tendencies when he referred to "restorationists", one group of whom sent him after his election 3,525 rosaries. The pope said he was "bothered" by this need to count prayers and labeled it "pelagianism." He went on to comment: "these groups return to practices and disciplines I lived – not you, none of you are old – to things that were lived in that moment, but not now, they aren't today ..." The Congregation of the Doctrine of the Faith subsequently emphasised "neo-Pelagianism" in a letter of February 2018 titled "Placuit Deo", stating, "A new form of Pelagianism is spreading in our days, one in which the individual, understood to be radically autonomous, presumes to save oneself, without recognizing that, at the deepest level of being, he or she derives from God and from others."

The second Article of Faith of the Church of Jesus Christ of Latter-day Saints states that "We believe that men will be punished for their own sins, and not for Adam’s transgression." The Book of Mormon states that the "original sin" allowed humanity to progress in the Plan of Salvation.

Mormon philosopher Sterling M. McMurrin, argued that "[t]he theology of Mormonism is completely Pelagian." Mormon theology teaches that the Atonement of Jesus Christ has overcome the effects of "original sin" for all mankind. For example, the Book of Mormon, a sacred text for The Church of Jesus Christ of Latter-day Saints, teaches: "[T]he Messiah cometh in the fullness of time, that he might redeem the children of men from the fall. And because they are redeemed from the fall they have become free forever, knowing good and evil; to act for themselves and not to be acted upon, save it be by the punishment of the law at that great and last day, according to the commandments which God has given." It also teaches: "there is no flesh that can dwell in the presence of God, save it be through the merits, and mercy, and grace of the Holy Messiah". Pelagianism is not the official stance of The Church of Jesus Christ of Latter-day Saints.




</doc>
<doc id="24987" url="https://en.wikipedia.org/wiki?curid=24987" title="Patripassianism">
Patripassianism

In Christian theology, historical patripassianism (as it is referred to in the Western church) is a version of Sabellianism in the Eastern church (and a version of modalism, modalistic monarchianism, or modal monarchism). Modalism is the belief that God the Father, Jesus Christ, and the Holy Spirit are three different "modes" or "aspects" of one monadic God, as perceived by "the believer", rather than three distinct persons within "the Godhead" – that there are no real or substantial differences between the three, such that there is no substantial identity for the Spirit or the Son.

In the West, a version of this belief was known pejoratively as "patripassianism" by its critics (from Latin "patri"- "father" and "passio" "suffering"), because the teaching required that since God the Father had become directly incarnate in Christ, that God literally sacrificed Himself on the Cross.

From the standpoint of the doctrine of the Trinity— one divine being existing in three persons— patripassianism is considered heretical since "it simply cannot make sense of the New Testament's teaching on the interpersonal relationship of Father, Son, and Spirit." In this patripassianism asserts that God the Father—rather than God the Son—became incarnate and suffered on the cross for humanity's redemption. This not only denies the personhood of God-the-Son (Jesus Christ), but is seen by trinitarians as distorting the "spiritual transaction" of atonement that was taking place at the cross, which the Apostle Paul described as follows: "God [the Father] was reconciling the world to himself in Christ [the Son], not counting people’s sins against them. . . . God [the Father] made him who had no sin [God-the-Son] to be sin for us, so that in him [the Son] we might become the righteousness of God [the Father]." (2 Corinthians 5:19, 21)

It is possible, however, to modify patripassianism so as to acknowledge the Divine Being as having feelings toward, and sharing in the experiences of, both Jesus— whom Christians regard as both human and divine— and other human beings. Full-orbed patripassianism denies Trinitarian distinctions, yet it does not contradict Christianity as defined in the Creeds to say that God feels or experiences things, including nonphysical forms of suffering. With regard to the crucifixion of Jesus, they claim it is consistent with Scriptural teaching to say that God the Father suffered—that is, felt emotional and spiritual pain as He watched His Son suffer on the Cross.

Patripassianism began in the third century AD. Patripassianism was referred to as a belief ascribed to those following Sabellianism, after its founder Sabellius, especially by the chief opponent Tertullian. Sabellius, considered a founder of an early movement, was a priest who was excommunicated from the Church by Pope Callixtus I in 220 and lived in Rome. Sabellius advanced the doctrine of one God sometimes referred to as the “economic Trinity” and he opposed the Eastern Orthodox doctrine of the “essential Trinity”. Praxeas and Noetus were some major followers.

Because the writings of Sabellius were destroyed it is hard to know if he did actually believe in Patripassianism, but one early version of the Apostles' Creed, recorded by Rufinus, explicitly states that the Father is 'impassible.' This reading dates to about 390 AD. This addition was made in response to patripassianism, which Rufinus evidently regarded as a heresy.

Cyprian and Tertullian famously accused the Modalistic Monarchians of patripassianism. The Monarchians taught the unity of the Godhead in Christ and that as the Son suffered the Father also experienced the sufferings. They did not teach that the Father died on the cross, though they were sometimes accused of this.

This term has been used by others such as F. L. Cross and E. A. Livingstone to describe other Oneness religions.



</doc>
<doc id="24988" url="https://en.wikipedia.org/wiki?curid=24988" title="Denial of the virgin birth of Jesus">
Denial of the virgin birth of Jesus

Denial of the virgin birth of Jesus is found among various groups and individuals throughout the history of Christianity. These groups and individuals often took an approach to Christology which understands Jesus to be human, the literal son of human parents.

During the 19th century this view was sometimes called Psilanthropism, a term which derives from the combination of the Greek (psilós), "plain", "mere" or "bare", and (ánthrōpos) "human". Psilanthropists then generally denied both the virgin birth of Jesus, and his divinity. Denial of the virgin birth is distinct from adoptionism, and may or may not be present in beliefs described as adoptionist.

The group most closely associated with denial of the virgin birth were the Ebionites. However, Jerome does not say that all Ebionites denied the virgin birth, but only contrasts their view with the acceptance of the doctrine on the part of a related group, the Nazarenes.

The view was rejected by the ecumenical councils, especially in the First Council of Nicaea, which was convened to deal directly with the nature of Christ's divinity.

The turmoil of the Reformation threw up many radical groups and individuals, some of whom were accused of denying, or actually did deny, the virgin birth. For example during the trial of Lorenzo Tizzano before the Inquisition at Venice in 1550, it was charged that the circle of the late Juan de Valdés (died 1541) at Naples had included such individuals. Early Unitarians, often called Socinians, after Laelio Sozzini who first published the first unitarian analysis of John's "Logos" in 1550, were sometimes accused of denying the virgin birth, but mainly only denied the pre-existence of Christ in heaven. For Sozzini's better known nephew Fausto Sozzini the miraculous virgin birth was the element in their belief which removed the need for the pre-existence to which they objected. The Socinians in fact excommunicated from their number the translator of the first Bible in Belarusian, Symon Budny, for his denial of the virgin birth.

A large scale change among Unitarians to acceptance of a human father for Jesus took place only in the time of Joseph Priestley. The young Samuel Taylor Coleridge was an example of what he called "a psilanthropist, one of those who believe our Lord to have been the real son of Joseph" but later in life Coleridge decisively rejected this idea and accepted traditional Christian belief in the virgin birth.

Biblical scholars, churchmen and theologians who have notably rejected the virgin birth include:

The "Divine Principle", the textbook of the Unification movement (also called the Unification Church), a new religious movement founded in South Korea, does not include the teaching that Zechariah was the father of Jesus; however some of its members hold that belief based on the work of British liberal theologian, Leslie Weatherhead.



</doc>
<doc id="24989" url="https://en.wikipedia.org/wiki?curid=24989" title="Pendulum clock">
Pendulum clock

A pendulum clock is a clock that uses a pendulum, a swinging weight, as its timekeeping element. The advantage of a pendulum for timekeeping is that it is a harmonic oscillator: it swings back and forth in a precise time interval dependent on its length, and resists swinging at other rates. From its invention in 1656 by Christiaan Huygens until the 1930s, the pendulum clock was the world's most precise timekeeper, accounting for its widespread use. Throughout the 18th and 19th centuries pendulum clocks in homes, factories, offices and railroad stations served as primary time standards for scheduling daily life, work shifts, and public transportation, and their greater accuracy allowed the faster pace of life which was necessary for the Industrial Revolution. The home pendulum clock was replaced by cheaper synchronous electric clocks in the 1930s and '40s, and they are now kept mostly for their decorative and antique value.

Pendulum clocks must be stationary to operate; any motion or accelerations will affect the motion of the pendulum, causing inaccuracies, so other mechanisms must be used in portable timepieces.

The pendulum clock was invented in 1656 by Dutch scientist and inventor Christiaan Huygens, and patented the following year. Huygens contracted the construction of his clock designs to clockmaker Salomon Coster, who actually built the clock. Huygens was inspired by investigations of pendulums by Galileo Galilei beginning around 1602. Galileo discovered the key property that makes pendulums useful timekeepers: isochronism, which means that the period of swing of a pendulum is approximately the same for different sized swings. Galileo had the idea for a pendulum clock in 1637, which was partly constructed by his son in 1649, but neither lived to finish it. The introduction of the pendulum, the first harmonic oscillator used in timekeeping, increased the accuracy of clocks enormously, from about 15 minutes per day to 15 seconds per day leading to their rapid spread as existing 'verge and foliot' clocks were retrofitted with pendulums.

These early clocks, due to their verge escapements, had wide pendulum swings of 80–100°. In his 1673 analysis of pendulums, "Horologium Oscillatorium", Huygens showed that wide swings made the pendulum inaccurate, causing its period, and thus the rate of the clock, to vary with unavoidable variations in the driving force provided by the movement. Clockmakers' realization that only pendulums with small swings of a few degrees are isochronous motivated the invention of the anchor escapement by Robert Hooke around 1658, which reduced the pendulum's swing to 4–6°. The anchor became the standard escapement used in pendulum clocks. In addition to increased accuracy, the anchor's narrow pendulum swing allowed the clock's case to accommodate longer, slower pendulums, which needed less power and caused less wear on the movement. The seconds pendulum (also called the Royal pendulum), 0.994 m (39.1 in) long, in which the time period is two seconds, became widely used in quality clocks. The long narrow clocks built around these pendulums, first made by William Clement around 1680, became known as grandfather clocks. The increased accuracy resulting from these developments caused the minute hand, previously rare, to be added to clock faces beginning around 1690.

The 18th and 19th century wave of horological innovation that followed the invention of the pendulum brought many improvements to pendulum clocks. The deadbeat escapement invented in 1675 by Richard Towneley and popularized by George Graham around 1715 in his precision "regulator" clocks gradually replaced the anchor escapement and is now used in most modern pendulum clocks. Observation that pendulum clocks slowed down in summer brought the realization that thermal expansion and contraction of the pendulum rod with changes in temperature was a source of error. This was solved by the invention of temperature-compensated pendulums; the mercury pendulum by George Graham in 1721 and the gridiron pendulum by John Harrison in 1726. With these improvements, by the mid-18th century precision pendulum clocks achieved accuracies of a few seconds per week.

Until the 19th century, clocks were handmade by individual craftsmen and were very expensive. The rich ornamentation of pendulum clocks of this period indicates their value as status symbols of the wealthy. The clockmakers of each country and region in Europe developed their own distinctive styles. By the 19th century, factory production of clock parts gradually made pendulum clocks affordable by middle-class families.

During the Industrial Revolution, daily life was organized around the home pendulum clock. More accurate pendulum clocks, called "regulators", were installed in places of business and railroad stations and used to schedule work and set other clocks. The need for extremely accurate timekeeping in celestial navigation to determine longitude drove the development of the most accurate pendulum clocks, called "astronomical regulators". These precision instruments, installed in naval observatories and kept accurate within a second by observation of star transits overhead, were used to set marine chronometers on naval and commercial vessels. Beginning in the 19th century, astronomical regulators in naval observatories served as primary standards for national time distribution services that distributed time signals over telegraph wires. From 1909, US National Bureau of Standards (now NIST) based the US time standard on Riefler pendulum clocks, accurate to about 10 milliseconds per day. In 1929 it switched to the Shortt-Synchronome free pendulum clock before phasing in quartz standards in the 1930s.

Pendulum clocks remained the world standard for accurate timekeeping for 270 years, until the invention of the quartz clock in 1927, and were used as time standards through World War 2. The French Time Service used pendulum clocks as part of their ensemble of standard clocks until 1954. The home pendulum clock began to be replaced as domestic timekeeper during the 1930s and 1940s by the synchronous electric clock, which kept more accurate time because it was synchronized to the oscillation of the electric power grid. The most accurate experimental pendulum clock ever made may be the Littlemore Clock built by Edward T. Hall in the 1990s
(donated in 2003 to the National Watch and Clock Museum, Columbia, Pennsylvania, USA).

The mechanism which runs a mechanical clock is called the movement. The movements of all mechanical pendulum clocks have these five parts:

Additional functions in clocks besides basic timekeeping are called complications. More elaborate pendulum clocks may include these complications:


In "electromechanical pendulum clocks" such as used in mechanical Master clocks the power source is replaced by an electrically powered solenoid that provides the impulses to the pendulum by magnetic force, and the escapement is replaced by a switch or photodetector that senses when the pendulum is in the right position to receive the impulse. These should not be confused with more recent quartz pendulum clocks in which an electronic quartz clock module swings a pendulum. These are not true pendulum clocks because the timekeeping is controlled by a quartz crystal in the module, and the swinging pendulum is merely a decorative simulation.

The pendulum swings with a period that varies with the square root of its effective length. For small swings the period "T", the time for one complete cycle (two swings), is

where "L" is the length of the pendulum and "g" is the local acceleration of gravity. All pendulum clocks have a means of adjusting the rate. This is usually an adjustment nut under the pendulum bob which moves the bob up or down on its rod. Moving the bob up reduces the length of the pendulum, reducing the pendulum's period so the clock gains time. In some pendulum clocks, fine adjustment is done with an auxiliary adjustment, which may be a small weight that is moved up or down the pendulum rod. In some master clocks and tower clocks, adjustment is accomplished by a small tray mounted on the rod where small weights are placed or removed to change the effective length, so the rate can be adjusted without stopping the clock.

The period of a pendulum increases slightly with the width (amplitude) of its swing. The "rate" of error increases with amplitude, so when limited to small swings of a few degrees the pendulum is nearly "isochronous"; its period is independent of changes in amplitude. Therefore, the swing of the pendulum in clocks is limited to 2° to 4°.

A major source of error in pendulum clocks is thermal expansion; the pendulum rod changes in length slightly with changes in temperature, causing changes in the rate of the clock. An increase in temperature causes the rod to expand, making the pendulum longer, so its period increases and the clock loses time. Many older quality clocks used wooden pendulum rods to reduce this error, as wood expands less than metal.

The first pendulum to correct for this error was the "mercury pendulum" invented by George Graham in 1721, which was used in precision regulator clocks into the 20th century. These had a bob consisting of a container of the liquid metal mercury. An increase in temperature would cause the pendulum rod to expand, but the mercury in the container would also expand and its level would rise slightly in the container, moving the center of gravity of the pendulum up toward the pivot. By using the correct amount of mercury, the centre of gravity of the pendulum remained at a constant height, and thus its period remained constant, despite changes in temperature.

The most widely used temperature-compensated pendulum was the gridiron pendulum invented by John Harrison around 1726. This consisted of a "grid" of parallel rods of high-thermal-expansion metal such as zinc or brass and low-thermal-expansion metal such as steel. If properly combined, the length change of the high-expansion rods compensated for the length change of the low-expansion rods, again achieving a constant period of the pendulum with temperature changes. 
This type of pendulum became so associated with quality that decorative "fake" gridirons are often seen on pendulum clocks, that have no actual temperature compensation function.

Beginning around 1900, some of the highest precision scientific clocks had pendulums made of ultra-low-expansion materials such as the nickel steel alloy Invar or fused silica, which required very little compensation for the effects of temperature.

The viscosity of the air through which the pendulum swings will vary with atmospheric pressure, humidity, and temperature. This drag also requires power that could otherwise be applied to extending the time between windings. Traditionally the pendulum bob is made with a narrow streamlined lens shape to reduce air drag, which is where most of the driving power goes in a quality clock. In the late 19th century and early 20th century, pendulums for precision regulator clocks in astronomical observatories were often operated in a chamber that had been pumped to a low pressure to reduce drag and make the pendulum's operation even more accurate by avoiding changes in atmospheric pressure. Fine adjustment of the rate of the clock could be made by slight changes to the internal pressure in the sealed housing.

To keep time accurately, pendulum clocks must be absolutely level. If they are not, the pendulum swings more to one side than the other, upsetting the symmetrical operation of the escapement. This condition can often be heard audibly in the ticking sound of the clock. The ticks or "beats" should be at precisely equally spaced intervals to give a sound of, "tick...tock...tick...tock"; if they are not, and have the sound "tick-tock...tick-tock..." the clock is "out of beat" and needs to be leveled. This problem can easily cause the clock to stop working, and is one of the most common reasons for service calls. A spirit level or watch timing machine can achieve a higher accuracy than relying on the sound of the beat; precision regulators often have a built in spirit level for the task. Older freestanding clocks often have feet with adjustable screws to level them, more recent ones have a leveling adjustment in the movement. Some modern pendulum clocks have 'auto-beat' or 'self-regulating beat adjustment' devices, and don't need this adjustment.

Since the pendulum rate will increase with an increase in gravity, and local gravity varies with latitude and elevation on Earth, precision pendulum clocks must be readjusted to keep time after a move. For example, a pendulum clock moved from sea level to will lose 16 seconds per day. With the most accurate pendulum clocks, even moving the clock to the top of a tall building would cause it to lose measurable time due to lower gravity.

Also called torsion-spring pendulum, this is a wheel-like mass (most often four spheres on cross spokes) suspended from a vertical strip (ribbon) of spring steel, used as the regulating mechanism in torsion pendulum clocks. Rotation of the mass winds and unwinds the suspension spring, with the energy impulse applied to the top of the spring. With a period of 12—15 seconds, compared to the gravity swing pendulum's period of 0.5—2s, it is possible to make clocks that need to be wound only every 30 days, or even only once a year or more. This type is independent of the local force of gravity but is more affected by temperature changes than an uncompensated gravity-swing pendulum. 

A clock requiring only annual winding is sometimes called a "400-Day clock" or "anniversary clock", the latter sometimes given as a wedding memorialisation gift. German firms Schatz and Kieninger & Obergfell (known as "Kundo", from "K und O"), were the main manufacturers of this type of clock. The "perpetual motion" clock, called the Atmos because its mechanism was kept wound by changes in atmospheric temperature, also makes use of a torsion pendulum. In this case the oscillation cycle takes a full 60 seconds.

The escapement is a mechanical linkage that converts the force from the clock's wheel train into impulses that keep the pendulum swinging back and forth. It is the part that makes the "ticking" sound in a working pendulum clock. Most escapements consist of a wheel with pointed teeth called the "escape wheel" which is turned by the clock's wheel train, and surfaces the teeth push against, called "pallets". During most of the pendulum's swing the wheel is prevented from turning because a tooth is resting against one of the pallets; this is called the "locked" state. Each swing of the pendulum a pallet releases a tooth of the escape wheel. The wheel rotates forward a fixed amount until a tooth catches on the other pallet. These releases allow the clock's wheel train to advance a fixed amount with each swing, moving the hands forward at a constant rate, controlled by the pendulum. 

Although the escapement is necessary, its force disturbs the natural motion of the pendulum, and in precision pendulum clocks this was often the limiting factor on the accuracy of the clock. Different escapements have been used in pendulum clocks over the years to try to solve this problem. In the 18th and 19th century escapement design was at the forefront of timekeeping advances. The anchor escapement (see animation) was the standard escapement used until the 1800s when an improved version, the deadbeat escapement took over in precision clocks. It is used in almost all pendulum clocks today. The remontoire, a small spring mechanism rewound at intervals which serves to isolate the escapement from the varying force of the wheel train, was used in a few precision clocks. In tower clocks the wheel train must turn the large hands on the clock face on the outside of the building, and the weight of these hands, varying with snow and ice buildup, put a varying load on the wheel train. Gravity escapements were used in tower clocks. 

By the end of the 19th century specialized escapements were used in the most accurate clocks, called "astronomical regulators", which were employed in naval observatories and for scientific research. The Riefler escapement, used in Clemens-Riefler regulator clocks was accurate to 10 milliseconds per day. Electromagnetic escapements, which used a switch or phototube to turn on a solenoid electromagnet to give the pendulum an impulse without requiring a mechanical linkage, were developed. The most accurate pendulum clock was the Shortt-Synchronome clock, a complicated electromechanical clock with two pendulums developed in 1923 by W.H. Shortt and Frank Hope-Jones, which was accurate to better than one second per year. A slave pendulum in a separate clock was linked by an electric circuit and electromagnets to a master pendulum in a vacuum tank. The slave pendulum performed the timekeeping functions, leaving the master pendulum to swing virtually undisturbed by outside influences. In the 1920s the Shortt-Synchronome briefly became the highest standard for timekeeping in observatories before quartz clocks superseded pendulum clocks as precision time standards.

The indicating system is almost always the traditional dial with moving hour and minute hands. Many clocks have a small third hand indicating seconds on a subsidiary dial. Pendulum clocks are usually designed to be set by opening the glass face cover and manually pushing the minute hand around the dial to the correct time. The minute hand is mounted on a slipping friction sleeve which allows it to be turned on its arbor. The hour hand is driven not from the wheel train but from the minute hand's shaft through a small set of gears, so rotating the minute hand manually also sets the hour hand.

Pendulum clocks were more than simply utilitarian timekeepers; they were status symbols that expressed the wealth and culture of their owners. They evolved in a number of traditional styles, specific to different countries and times as well as their intended use. Case styles somewhat reflect the furniture styles popular during the period. Experts can often pinpoint when an antique clock was made within a few decades by subtle differences in their cases and faces. These are some of the different styles of pendulum clocks:



</doc>
<doc id="24992" url="https://en.wikipedia.org/wiki?curid=24992" title="Programmable logic controller">
Programmable logic controller

A programmable logic controller (PLC) or programmable controller is an industrial digital computer which has been ruggedized and adapted for the control of manufacturing processes, such as assembly lines, or robotic devices, or any activity that requires high reliability control and ease of programming and process fault diagnosis.

PLCs were first developed in the automobile manufacturing industry to provide flexible, ruggedized and easily programmable controllers to replace hard-wired relays, timers and sequencers. Since then, they have been widely adopted as high-reliability automation controllers suitable for harsh environments. A PLC is an example of a "hard" real-time system since output results must be produced in response to input conditions within a limited time, otherwise unintended operation will result.

PLCs can range from small modular devices with tens of inputs and outputs (I/O), in a housing integral with the processor, to large rack-mounted modular devices with a count of thousands of I/O, and which are often networked to other PLC and SCADA systems.

They can be designed for multiple arrangements of digital and analog I/O, extended temperature ranges, immunity to electrical noise, and resistance to vibration and impact. Programs to control machine operation are typically stored in battery-backed-up or non-volatile memory.

It was from the automotive industry in the USA that the PLC was born. Before the PLC, control, sequencing, and safety interlock logic for manufacturing automobiles was mainly composed of relays, cam timers, drum sequencers, and dedicated closed-loop controllers. Since these could number in the hundreds or even thousands, the process for updating such facilities for the yearly model change-over was very time consuming and expensive, as electricians needed to individually rewire the relays to change their operational characteristics.

When digital computers became available, being general-purpose programmable devices, they were soon applied to control sequential and combinatorial logic in industrial processes. However these early computers required specialist programmers and stringent operating environmental control for temperature, cleanliness, and power quality. To meet these challenges the PLC was developed with several key attributes. It would tolerate the shop-floor environment, it would support discrete (bit-form) input and output in an easily extensible manner, it would not require years of training to use, and it would permit its operation to be monitored. Since many industrial processes have timescales easily addressed by millisecond response times, modern (fast, small, reliable) electronics greatly facilitate building reliable controllers, and performance could be traded off for reliability.

In 1968 GM Hydramatic (the automatic transmission division of General Motors) issued a request for proposals for an electronic replacement for hard-wired relay systems based on a white paper written by engineer Edward R. Clark. The winning proposal came from Bedford Associates of Bedford, Massachusetts. The first PLC, designated the 084 because it was Bedford Associates' eighty-fourth project, was the result. Bedford Associates started a new company dedicated to developing, manufacturing, selling, and servicing this new product: , which stood for modular digital controller. One of the people who worked on that project was Dick Morley, who is considered to be the "father" of the PLC. The Modicon brand was sold in 1977 to Gould Electronics, later acquired by German Company AEG, and then by French Schneider Electric, the current owner.

One of the very first 084 models built is now on display at Schneider Electric's facility in North Andover, Massachusetts. It was presented to Modicon by GM, when the unit was retired after nearly twenty years of uninterrupted service. Modicon used the 84 moniker at the end of its product range until the 984 made its appearance.

The automotive industry is still one of the largest users of PLCs.

In a parallel development Odo Josef Struger is sometimes known as the "father of the programmable logic controller" as well. He was involved in the invention of the Allen-Bradley programmable logic controller (PLC) during 1958 to 1960. Struger is credited with creating the PLC acronym. Allen-Bradley (now a brand owned by Rockwell Automation), the manufacturer of the controller, became a major programmable logic controller device manufacturer in the United States during the tenure of Struger.

Early PLCs were designed to replace relay logic systems. Relay systems were large and bulky and had an assortment of issues. The hard-wired nature made it difficult for design engineers to alter the process. Even small changes would require rewiring and careful updating of the documentation. If even one wire were out of place, or one relay failed, the whole system would become faulty. Often times technicians would spend hours troubleshooting by examining the schematics and comparing them to existing wiring. It was for this reason PLCs were programmed in "ladder logic", which strongly resembles a schematic diagram of relay logic. This program notation was chosen to reduce training demands for the existing technicians. Other early PLCs used a form of instruction list programming, based on a stack-based logic solver.

Modern PLCs can be programmed in a variety of ways, from the relay-derived ladder logic to programming languages such as specially adapted dialects of BASIC and C. Another method is state logic, a very high-level programming language designed to program PLCs based on state transition diagrams. The majority of PLC systems today adhere to the IEC 61131/3 control systems programming standard that defines 5 languages: Ladder Diagram (LD), Structured Text (ST), Function Block Diagram (FBD), Instruction List (IL) and sequential function chart (SFC).

Many early PLCs did not have accompanying programming terminals that were capable of graphical representation of the logic, and so the logic was instead represented as a series of logic expressions in some version of Boolean format, similar to Boolean algebra. As programming terminals evolved, it became more common for ladder logic to be used, for the aforementioned reasons and because it was a familiar format used for electro-mechanical control panels. Newer formats such as state logic and Function Block (which is similar to the way logic is depicted when using digital integrated logic circuits) exist, but they are still not as popular as ladder logic. A primary reason for this is that PLCs solve the logic in a predictable and repeating sequence, and ladder logic allows the programmer (the person writing the logic) to see any issues with the timing of the logic sequence more easily than would be possible in other formats.

PLC programs are typically written in a special application on a personal computer, then downloaded by a direct-connection cable or over a network to the PLC. The program is stored in the PLC either in battery-backed-up RAM or some other non-volatile flash memory. Often, a single PLC can be programmed to replace thousands of relays.

Early PLCs, up to the mid-1990s, were programmed using proprietary programming panels or special-purpose programming terminals, which often had dedicated function keys representing the various logical elements of PLC programs. Some proprietary programming terminals displayed the elements of PLC programs as graphic symbols, but plain ASCII character representations of contacts, coils, and wires were common. Programs were stored on cassette tape cartridges. Facilities for printing and documentation were minimal due to lack of memory capacity. The oldest PLCs used non-volatile magnetic core memory.

More recently, PLCs are programmed using application software on personal computers, which now represent the logic in graphic form instead of character symbols. The computer is connected to the PLC through USB, Ethernet, RS-232, RS-485, or RS-422 cabling. The programming software allows entry and editing of the ladder-style logic. In some software packages, it is also possible to view and edit the program in function block diagrams, sequence flow charts and structured text. Generally the software provides functions for debugging and troubleshooting the PLC software, for example, by highlighting portions of the logic to show current status during operation or via simulation. The software will upload and download the PLC program, for backup and restoration purposes. In some models of programmable controller, the program is transferred from a personal computer to the PLC through a programming board which writes the program into a removable chip such as an EPROM.

Under the IEC 61131-3 standard, PLCs can be programmed using standards-based programming languages. The most commonly used programming language is Ladder diagram (LD) also known as Ladder logic. It uses Contact-Coil logic to make programs like an electrical control diagram. A graphical programming notation called Sequential Function Charts is available on certain programmable controllers. A model which emulated electromechanical control panel devices (such as the contact and coils of relays) which PLCs replaced. This model remains common today.

IEC 61131-3 currently defines four programming languages for programmable control systems: function block diagram (FBD), ladder diagram (LD), structured text (ST; similar to the Pascal programming language), and sequential function chart (SFC). Instruction list (IL; similar to assembly language) was deprecated in the third edition of the standard. These techniques emphasize logical organization of operations.

While the fundamental concepts of PLC programming are common to all manufacturers, differences in I/O addressing, memory organization, and instruction sets mean that PLC programs are never perfectly interchangeable between different makers. Even within the same product line of a single manufacturer, different models may not be directly compatible.

This is a programming example in ladder diagram which shows the control system. A ladder diagram is a method of drawing control circuits which pre-dates PLCs. The ladder diagram resembles the schematic diagram of a system built with electromechanical relays.

As an example, say a facility needs to store water in a tank. The water is drawn from the tank by another system, as needed, and our example system must manage the water level in the tank by controlling the valve that refills the tank. Shown are:


In ladder diagram, the contact symbols represent the state of bits in processor memory, which corresponds to the state of physical inputs to the system. If a discrete input is energized, the memory bit is a 1, and a "normally open" contact controlled by that bit will pass a logic "true" signal on to the next element of the ladder. Therefore, the contacts in the PLC program that "read" or look at the physical switch contacts in this case must be "opposite" or open in order to return a TRUE for the closed physical switches. Internal status bits, corresponding to the state of discrete outputs, are also available to the program.

In the example, the physical state of the float switch contacts must be considered when choosing "normally open" or "normally closed" symbols in the ladder diagram. The PLC has two discrete inputs from float switches (Low Level and High Level). Both float switches (normally closed) open their contacts when the water level in the tank is above the physical location of the switch.

When the water level is below both switches, the float switch physical contacts are both closed, and a true (logic 1) value is passed to the Fill Valve output. Water begins to fill the tank. The internal "Fill Valve" contact latches the circuit so that even when the "Low Level" contact opens (as the water passes the lower switch), the fill valve remains on. Since the High Level is also normally closed, water continues to flow as the water level remains between the two switch levels. Once the water level rises enough so that the "High Level" switch is off (opened), the PLC will shut the inlet to stop the water from overflowing; this is an example of seal-in (latching) logic. The output is sealed in until a high level condition breaks the circuit. After that the fill valve remains off until the level drops so low that the Low Level switch is activated, and the process repeats again.
A complete program may contain thousands of rungs, evaluated in sequence. Typically the PLC processor will alternately scan all its inputs and update outputs, then evaluate the ladder logic; input changes during a program scan will not be effective until the next I/O update. A complete program scan may take only a few milliseconds, much faster than changes in the controlled process.

Programmable controllers vary in their capabilities for a "rung" of a ladder diagram. Some only allow a single output bit. There are typically limits to the number of series contacts in line, and the number of branches that can be used. Each element of the rung is evaluated sequentially. If elements change their state during evaluation of a rung, hard-to-diagnose faults can be generated, although sometimes (as above) the technique is useful. Some implementations forced evaluation from left-to-right as displayed and did not allow reverse flow of a logic signal (in multi-branched rungs) to affect the output.

The functionality of the PLC has evolved over the years to include sequential relay control, motion control, process control, distributed control systems, and networking. The data handling, storage, processing power, and communication capabilities of some modern PLCs are approximately equivalent to desktop computers. PLC-like programming combined with remote I/O hardware, allow a general-purpose desktop computer to overlap some PLCs in certain applications. Desktop computer controllers have not been generally accepted in heavy industry because the desktop computers run on less stable operating systems than PLCs, and because the desktop computer hardware is typically not designed to the same levels of tolerance to temperature, humidity, vibration, and longevity as the processors used in PLCs. Operating systems such as Windows do not lend themselves to deterministic logic execution, with the result that the controller may not always respond to changes of input status with the consistency in timing expected from PLCs. Desktop logic applications find use in less critical situations, such as laboratory automation and use in small facilities where the application is less demanding and critical.

The most basic function of a programmable controller is to emulate the functions of electro-mechanical relays. Discrete inputs are given a unique address, and a PLC instruction can test if the input state is on or off. Just as a series of relay contacts perform a logical AND function, not allowing current to pass unless all the contacts are closed, so a series of "examine if on" instructions will energize its output storage bit if all the input bits are on. Similarly, a parallel set of instructions will perform a logical OR. In an electro-mechanical relay wiring diagram, a group of contacts controlling one coil is called a "rung" of a "ladder diagram ", and this concept is also used to describe PLC logic. Some models of PLC limit the number of series and parallel instructions in one "rung" of logic. The output of each rung sets or clears a storage bit, which may be associated with a physical output address or which may be an "internal coil" with no physical connection. Such internal coils can be used, for example, as a common element in multiple separate rungs. Unlike physical relays, there is usually no limit to the number of times an input, output or internal coil can be referenced in a PLC program.

Some PLCs enforce a strict left-to-right, top-to-bottom execution order for evaluating the rung logic. This is different from electro-mechanical relay contacts, which in a sufficiently complex circuit may either pass current left-to-right or right-to-left, depending on the configuration of surrounding contacts. The elimination of these "sneak paths" is either a bug or a feature, depending on programming style.

More advanced instructions of the PLC may be implemented as functional blocks, which carry out some operation when enabled by a logical input and which produce outputs to signal, for example, completion or errors, while manipulating variable internally that may not correspond to discrete logic.

The main function of a timer is to keep an output on for a specific length of time. A good example of this is a garage light, where you want power to be cut off after 2 minutes so as to give someone time to go into the house. The three different types of timers that are commonly used are a Delay-OFF, a Delay-ON, and a Delay-ON-Retentive. A Delay-OFF timer activates immediately when turned on, counts down from a programmed time before cutting off, and is cleared when the enabling input is off. A Delay-ON timer is activated by input and starts accumulating time, counts up to a programmed time before cutting off, and is cleared when the enabling input is turned off. A Delay-ON-Retentive timer is activated by input and starts accumulating time, retains the accumulated value even if the (ladder-logic) rung goes false, and can be reset only by a RESET contact.

Counters are primarily used for counting items such as cans going into a box on an assembly line. This is important because once something is filled to its max the item needs to be moved on so something else can be filled. Many companies use counters in PLC's to count boxes, count how many feet of something is covered, or to count how many pallets are on a truck. There are three types of counters, Up counters, Down counters, and Up/Down counters. Up counters count up to the preset value, turn on the CTU (CounT Up output) when the preset value is reached, and are cleared upon receiving a reset. Down counters count down from a preset value, turns on the CTD (CounT Down output) when 0 is reached, and are cleared upon reset. Up/Down counters count up on CU, count down on CD, turn on CTUD (CounT Up/Down output) when the preset value is reached, and cleared on reset.

In more recent years, small products called PLRs (programmable logic relays), and also by similar names, have become more common and accepted. These are much like PLCs, and are used in light industry where only a few points of I/O (i.e. a few signals coming in from the real world and a few going out) are needed, and low cost is desired. These small devices are typically made in a common physical size and shape by several manufacturers, and branded by the makers of larger PLCs to fill out their low end product range. Popular names include PICO Controller, NANO PLC, and other names implying very small controllers. Most of these have 8 to 12 discrete inputs, 4 to 8 discrete outputs, and up to 2 analog inputs. Size is usually about 4" wide, 3" high, and 3" deep. Most such devices include a tiny postage-stamp-sized LCD screen for viewing simplified ladder logic (only a very small portion of the program being visible at a given time) and status of I/O points, and typically these screens are accompanied by a 4-way rocker push-button plus four more separate push-buttons, similar to the key buttons on a VCR remote control, and used to navigate and edit the logic. Most have a small plug for connecting via RS-232 or RS-485 to a personal computer so that programmers can use simple Windows applications for programming instead of being forced to use the tiny LCD and push-button set for this purpose. Unlike regular PLCs that are usually modular and greatly expandable, the PLRs are usually not modular or expandable, but their price can be two orders of magnitude less than a PLC, and they still offer robust design and deterministic execution of the logics.

The main difference from most other computing devices is that PLCs are intended-for and therefore tolerant-of more severe conditions (such as dust, moisture, heat, cold), while offering extensive input/output (I/O) to connect the PLC to sensors and actuators. PLC input can include simple digital elements such as limit switches, analog variables from process sensors (such as temperature and pressure), and more complex data such as that from positioning or machine vision systems. PLC output can include elements such as indicator lamps, sirens, electric motors, pneumatic or hydraulic cylinders, magnetic relays, solenoids, or analog outputs. The input/output arrangements may be built into a simple PLC, or the PLC may have external I/O modules attached to a fieldbus or computer network that plugs into the PLC.

A PLC program generally loops i.e. executes repeatedly, as long as the controlled system is running. At the start of each execution loop, the status of all physical inputs are copied to an area of memory, sometimes called the "I/O Image Table", which is accessible to the processor. The program then runs from its first instruction rung down to the last rung. It takes some time for the processor of the PLC to evaluate all the rungs and update the I/O image table with the status of outputs. Scan times of a few milliseconds may be encountered for small programs and fast processors, but for older processors and very large programs much longer scan times (on the order of 100 ms) may be encountered. Excessively long scan times may mean the response of the PLC to changing inputs or process conditions is too slow to be useful.

As PLCs became more advanced, methods were developed to change the sequence of ladder execution, and subroutines were implemented. This enhanced programming could be used to save scan time for high-speed processes; for example, parts of the program used only for setting up the machine could be segregated from those parts required to operate at higher speed. Newer PLCs now have the option to run the logic program synchronously with the IO scanning. This means that IO is updated in the background and the logic reads and writes values as required during the logic scanning.

Special-purpose I/O modules may be used where the scan time of the PLC is too long to allow predictable performance. Precision timing modules, or counter modules for use with shaft encoders, are used where the scan time would be too long to reliably count pulses or detect the sense of rotation of an encoder. This allows even a relatively slow PLC to still interpret the counted values to control a machine, as the accumulation of pulses is done by a dedicated module that is unaffected by the speed of program execution on the PLC.

There are 5 main steps in a scan cycle:

A small PLC will have a fixed number of connections built in for inputs and outputs. Typically, expansions are available if the base model has insufficient I/O.

Modular PLCs have a chassis (also called a rack) into which are placed modules with different functions. The processor and selection of I/O modules are customized for the particular application. Several racks can be administered by a single processor, and may have thousands of inputs and outputs. Either a special high speed serial I/O link or comparable communication method is used so that racks can be distributed away from the processor, reducing the wiring costs for large plants. Options are also available to mount I/O points directly to the machine and utilize quick disconnecting cables to sensors and valves, saving time for wiring and replacing components.

PLCs may need to interact with people for the purpose of configuration, alarm reporting, or everyday control. A human-machine interface (HMI) is employed for this purpose. HMIs are also referred to as man-machine interfaces (MMIs) and graphical user interfaces (GUIs). A simple system may use buttons and lights to interact with the user. Text displays are available as well as graphical touch screens. More complex systems use programming and monitoring software installed on a computer, with the PLC connected via a communication interface.

Many models of PLCs have built-in communications ports, using RS-232, RS-422, RS-485, or Ethernet. Various protocols are usually included. Many of these protocols are vendor specific.

Most modern PLCs can communicate over a network to some other system, such as a computer running a SCADA (Supervisory Control And Data Acquisition) system or web browser.

PLCs used in larger I/O systems may have peer-to-peer (P2P) communication between processors. This allows separate parts of a complex process to have individual control while allowing the subsystems to co-ordinate over the communication link. These communication links are also often used for HMI devices such as keypads or PC-type workstations.

Formerly, some manufacturers offered dedicated communication modules as an add-on function where the processor had no network connection built-in.

Prior to the discovery of the Stuxnet computer worm in June 2010, security of PLCs received little attention. Modern PLCs generally contain a real-time operating system such as OS-9 or VxWorks, and exploits for these systems exist much as they do for desktop computer operating systems such as Microsoft Windows. PLCs can also be attacked by gaining control of a computer they communicate with.

In order to properly understand the operation of a PLC, it is necessary to spend considerable time programming, testing, and debugging PLC programs. PLC systems are inherently expensive, and down-time is often very costly. In addition, if a PLC is programmed incorrectly it can result in lost productivity and dangerous conditions. PLC simulation software such as PLCLogix can save time in the design of automated control applications and can also increase the level of safety associated with equipment since many "what if" scenarios can be tried and tested before the system is activated.

Some special processes need to work permanently with minimum unwanted down time. Therefore, it is necessary to design a system which is fault-tolerant and capable of handling the process with faulty modules. In such cases to increase the system availability in the event of hardware component failure, redundant CPU or I/O modules with the same functionality can be added to hardware configuration for preventing total or partial process shutdown due to hardware failure.

PLCs are well adapted to a range of automation tasks. These are typically industrial processes in manufacturing where the cost of developing and maintaining the automation system is high relative to the total cost of the automation, and where changes to the system would be expected during its operational life. PLCs contain input and output devices compatible with industrial pilot devices and controls; little electrical design is required, and the design problem centers on expressing the desired sequence of operations. PLC applications are typically highly customized systems, so the cost of a packaged PLC is low compared to the cost of a specific custom-built controller design. On the other hand, in the case of mass-produced goods, customized control systems are economical. This is due to the lower cost of the components, which can be optimally chosen instead of a "generic" solution, and where the non-recurring engineering charges are spread over thousands or millions of units.

For high volume or very simple fixed automation tasks, different techniques are used. For example, a cheap consumer dishwasher would be controlled by an electromechanical cam timer costing only a few dollars in production quantities.

A microcontroller-based design would be appropriate where hundreds or thousands of units will be produced and so the development cost (design of power supplies, input/output hardware, and necessary testing and certification) can be spread over many sales, and where the end-user would not need to alter the control. Automotive applications are an example; millions of units are built each year, and very few end-users alter the programming of these controllers. However, some specialty vehicles such as transit buses economically use PLCs instead of custom-designed controls, because the volumes are low and the development cost would be uneconomical.

Very complex process control, such as used in the chemical industry, may require algorithms and performance beyond the capability of even high-performance PLCs. Very high-speed or precision controls may also require customized solutions; for example, aircraft flight controls. Single-board computers using semi-customized or fully proprietary hardware may be chosen for very demanding control applications where the high development and maintenance cost can be supported. "Soft PLCs" running on desktop-type computers can interface with industrial I/O hardware while executing programs within a version of commercial operating systems adapted for process control needs.

Programmable controllers are widely used in motion, positioning, or torque control. Some manufacturers produce motion control units to be integrated with PLC so that G-code (involving a CNC machine) can be used to instruct machine movements.

PLCs may include logic for single-variable feedback analog control loop, a proportional, integral, derivative (PID) controller. A PID loop could be used to control the temperature of a manufacturing process, for example. Historically PLCs were usually configured with only a few analog control loops; where processes required hundreds or thousands of loops, a distributed control system (DCS) would instead be used. As PLCs have become more powerful, the boundary between DCS and PLC applications has been blurred.

PLCs have similar functionality as remote terminal units. An RTU, however, usually does not support control algorithms or control loops. As hardware rapidly becomes more powerful and cheaper, RTUs, PLCs, and DCSs are increasingly beginning to overlap in responsibilities, and many vendors sell RTUs with PLC-like features, and vice versa. The industry has standardized on the IEC 61131-3 functional block language for creating programs to run on RTUs and PLCs, although nearly all vendors also offer proprietary alternatives and associated development environments.

In recent years "safety" PLCs have started to become popular, either as standalone models or as functionality and safety-rated hardware added to existing controller architectures (Allen-Bradley Guardlogix, Siemens F-series etc.). These differ from conventional PLC types as being suitable for use in safety-critical applications for which PLCs have traditionally been supplemented with hard-wired safety relays. For example, a safety PLC might be used to control access to a robot cell with trapped-key access, or perhaps to manage the shutdown response to an emergency stop on a conveyor production line. Such PLCs typically have a restricted regular instruction set augmented with safety-specific instructions designed to interface with emergency stops, light screens, and so forth. The flexibility that such systems offer has resulted in rapid growth of demand for these controllers.

The rising popularity of single board computers has also had an influence on the development of PLCs. Traditional PLCs are generally closed platforms, but some newer PLCs (e.g. ctrlX from Bosch Rexroth, PFC200 from Wago, PLCnext from Phoenix Contact, and Revolution Pi from Kunbus) provide the features of traditional PLCs on an open platform.

Discrete (digital) signals behave as binary switches, yielding simply an On or Off signal (1 or 0, True or False, respectively). Push buttons, limit switches, and photoelectric sensors are examples of devices providing a discrete signal. Discrete signals are sent using either voltage or current, where a specific range is designated as "On" and another as "Off". For example, a PLC might use 24 V DC I/O, with values above 22 V DC representing "On", values below 2VDC representing "Off", and intermediate values undefined. Initially, PLCs had only digital I/O.

Analog signals are like volume controls, with a range of values between zero and full-scale. These are typically interpreted as integer values (counts) by the PLC, with various ranges of accuracy depending on the device and the number of bits available to store the data. As PLCs typically use 16-bit signed binary processors, the integer values are limited between -32,768 and +32,767. Pressure, temperature, flow, and weight are often represented by analog signals. Analog signals can use voltage or current with a magnitude proportional to the value of the process signal. For example, an analog 0 to 10 V or 4-20 mA input would be converted into an integer value of 0 to 32767.

Current inputs are less sensitive to electrical noise (e.g. from welders or electric motor starts) than voltage inputs.

PLCs are at the forefront of manufacturing automation. An engineer working in a manufacturing environment will at least encounter some PLCs, if not use them on a regular basis. Electrical engineering students should have basic knowledge of PLCs because of their widespread use in industrial applications.





</doc>
<doc id="24994" url="https://en.wikipedia.org/wiki?curid=24994" title="Peter David">
Peter David

Peter Allen David (born September 23, 1956), often abbreviated PAD, is an American writer of comic books, novels, television, films and video games. His notable comic book work includes an award-winning 12-year run on "The Incredible Hulk", as well as runs on "Aquaman", "Young Justice", "Supergirl", "Fallen Angel", "Spider-Man 2099" and "X-Factor".

His "Star Trek" work includes comic books, novels such as "Imzadi", and co-creation of the "" series. His other novels include film adaptations, media tie-ins, and original works, such as the "Apropos of Nothing" and "Knight Life" series. His television work includes series such as "Babylon 5", "Young Justice", "" and Nickelodeon's "Space Cases", which he co-created with Bill Mumy.

David often jokingly describes his occupation as "Writer of Stuff", and is noted for his prolific writing, characterized by its mingling of real-world issues with humor and references to popular culture, as well as elements of metafiction and self-reference.

David has earned multiple awards for his work, including a 1992 Eisner Award, a 1993 "Wizard" Fan Award, a 1996 Haxtur Award, a 2007 Julie Award and a 2011 GLAAD Media Award.

Peter David's paternal grandparents, Martin and Hela David, and Peter's father, Gunter, came to the United States in the 1930s after the antisemitism in Nazi Germany progressed to the point that Martin's Berlin shoestore became the target of vandalism. David was born September 23, 1956 in Fort Meade, Maryland to Gunter David and Dalia David (née Rojansky), an Israeli-born Jewish mother who had worked with DNA mappers James Watson and Francis Crick, and to whom David credits his sense of humor. He has two siblings, a brother Wally, seven years his junior, who works as an IT Systems Administrator in the financial sector, and a younger sister named Beth.

David first became interested in comics when he was about five years old, reading copies of Harvey Comics' "Casper" and "Wendy" in a barbershop. He became interested in superheroes through the "Adventures of Superman" TV series. Although David's parents approved of his reading Harvey Comics and comics featuring Disney characters, they did not approve of superhero books, especially those published by Marvel Comics, feeling that characters that looked like monsters, such as the Thing or the Hulk, or who wore bug-eyed costumes, like Spider-Man, did not appear heroic. As a result, David read those comics in secret, beginning with his first Marvel book, "Fantastic Four Annual" #3 (November 1965), which saw the wedding of Mister Fantastic and the Invisible Woman. His parents eventually allowed him to start reading superhero titles, his favorite of which was "Superman". He cites John Buscema as his favorite pre-1970s artist. David attended his first comic book convention around the time that Jack Kirby's "New Gods" premiered, after asking his father to take him to one of Phil Seuling's shows in New York, where David obtained Kirby's autograph, his first encounter with a comics professional.

David's earliest interest in writing came through the journalism work of his father, Gunter, who sometimes reviewed movies and took young Peter along (if it were age-appropriate). While Gunter wrote his reviews back at the newspaper's office, David wrote his own, portions of which sometimes found their way into Gunter's published reviews. David began to entertain the notion of becoming a professional writer at age twelve, buying a copy of "The Guide to the Writer's Market", and subscribing to similar-themed magazines, in the hopes of becoming a reporter.

David lived in Bloomfield, New Jersey, in a small house at 11 Albert Terrace, and attended Demarest Elementary School. His family later moved to Verona, New Jersey, where he spent his adolescence. By the time he entered his teens, he had lost interest in comic books, feeling he had outgrown them. David's best friend in junior high and first year in high school, Keith, was gay, and David has described how both of them were targets of ostracism and harassment from homophobes.

Although his family eventually moved to Pennsylvania, his experiences in Verona soured him on that town and shaped his liberal sociopolitical positions regarding LGBT issues. He later made Verona the home location of villain Morgan le Fay in his novel "Knight Life", and has often discussed his progressive views on LGBT issues in his column and on his blog.

David's interest in comics was rekindled when he saw a copy of "Superman vs. Muhammad Ali" (1978) while passing a newsstand, and later, "X-Men" #95 (October 1975), and discovered in that latter book the "All-New, All-Different" team that had first appeared in "Giant-Size X-Men" #1 (May 1975). These two books were the first comics he had purchased in years.

A seminal moment in the course of his aspirations occurred when he met writer Stephen King at a book signing, and told him that he was an aspiring writer. King signed David's copy of "Danse Macabre" with the inscription, "Good luck with your writing career.", which David now inscribes himself onto books presented to him by fans who tell him the same thing. Other authors that David cites as influences include Harlan Ellison, Arthur Conan Doyle, Robert B. Parker, Neil Gaiman, Terry Pratchett, Robert Crais and Edgar Rice Burroughs. Specific books he has mentioned as favorites include "To Kill a Mockingbird", "Tarzan of the Apes", "The Princess Bride", "The Essential Ellison", "A Confederacy of Dunces", "Adams Versus Jefferson", and "Don Quixote". David has singled out Ellison in particular as a writer whom he has tried to emulate.

David attended New York University, where he graduated with a Bachelor of Arts degree in journalism.

David's first professional assignment was covering the World Science Fiction Convention held in Washington in 1974 for the "Philadelphia Bulletin".

David eventually gravitated towards fiction after his attempts at journalism did not meet with success. His first published fiction was in "Asimov's Science Fiction". He sold an op-ed piece to "The New York Times", but overall his submissions were met with rejection that far outnumbered those accepted.

David eventually gave up on a career in writing, and came to work in book publishing. His first publishing job was for the E.P. Dutton imprint Elsevier/Nelson, where he worked mainly as an assistant to the editor-in-chief. He later worked in sales and distribution for Playboy Paperbacks. He subsequently worked for five years in Marvel Comics' Sales Department, first as Assistant Direct Sales Manager under Carol Kalish, who hired him, and then succeeding Kalish as Sales Manager. During this time he made some cursory attempts to sell stories, including submission of some Moon Knight plots to Dennis O'Neil, but his efforts were unfruitful.

Three years into David's tenure as Direct Sales Manager, Jim Owsley became editor of the Spider-Man titles. Although crossing over from sales into editorial was considered a conflict of interest in the Marvel offices, Owsley, whom David describes as a "maverick," was impressed with how David had not previously hesitated to work with him when Owsley was an assistant editor under Larry Hama. When Owsley became an editor, he purchased a Spider-Man story from David, which appeared in "The Spectacular Spider-Man" #103 (June 1985). Owsley subsequently purchased from David "The Death of Jean DeWolff", a violent murder mystery darker in tone than the usually lighter Spider-Man stories that ran in issues #107–110 (October 1985 – January 1986) of that title. Responding to charges of conflict of interest, David made a point of not discussing editorial matters with anyone during his 9-to-5 hours as Direct Sales Manager, and decided not to exploit his position as Sales Manager by promoting the title. Although David attributes the story's poor sales to this decision, he asserts that such crossing over from Sales to Editorial is now common. In the Marvel offices, a rumor circulated that it was actually Owsley who was writing the stories attributed to David. Nonetheless, David says he was fired from "Spectacular Spider-Man" by Owsley due to editorial pressure by Marvel's Editor-in-Chief Jim Shooter, and has commented that the resentment stirred by Owsley's purchase of his stories may have permanently damaged Owsley's career. Months later, Bob Harras offered David "The Incredible Hulk", as it was a struggling title that no one else wanted to write, which gave David free rein to do whatever he wanted with the character.

During his 12-year run on "Hulk", David explored the recurring themes of the Hulk's multiple personality disorder, his periodic changes between the more rageful and less intelligent Green Hulk and the more streetwise, cerebral Gray Hulk, and of being a journeyman hero, which were inspired by "The Incredible Hulk" #312 (October 1985), in which writer Bill Mantlo (and possibly, according to David, Barry Windsor-Smith) had first established that Banner had suffered childhood abuse at the hands of his father. These aspects of the character were later used in the 2003 feature film adaptation by screenwriter Michael France and director Ang Lee. Comic Book Resources credits David with making the formerly poor-selling book "a must-read mega-hit". David collaborated with a number of artists who became fan-favorites on the series, including Todd McFarlane, Dale Keown and Gary Frank. Among the new characters he created during his run on the series were the Riot Squad and the Pantheon. David wrote the first appearance of the Thunderbolts, a team created by Kurt Busiek and Mark Bagley, in "The Incredible Hulk" #449 (January 1997).

It was after he had been freelancing for a year, and into his run on "Hulk", that David felt that his writing career had cemented. After putting out feelers at DC Comics, and being offered the job of writing a four-issue miniseries of The Phantom by editor Mike Gold, David quit his sales position to write full-time. David had a brief tenure writing Green Lantern when the character was exclusive to the short-lived anthology series "Action Comics Weekly" from issues #608–620 in 1988.

David took over "Dreadstar" during its First Comics run, with issue #41 (March 1989) after Jim Starlin left the title, and remained on it until issue #64 (March 1991), the final issue of that run. David's other Marvel Comics work in the late 1980s and 1990s includes runs on "Wolverine", the New Universe series "" and "Justice", a run on the original "X-Factor", and the futuristic series "Spider-Man 2099", about a man in the year 2099 who takes up the mantle of Spider-Man, the title character of which David co-created. David left "X-Factor" after 19 issues, and he wrote the first 44 issues of "Spider-Man 2099" before quitting that book to protest the firing of editor Joey Cavalieri. The book was cancelled two issues later, along with the entire 2099 line.

In 1990, David wrote a seven-issue "Aquaman" miniseries, "The Atlantis Chronicles", for DC Comics, about the history of Aquaman's home of Atlantis, which David has referred to as among the written works of which he is most proud, and his first time writing in the full script format. He later wrote a 1994 "Aquaman" miniseries, "Aquaman: Time and Tide", which led to a relaunched monthly "Aquaman" series, the first 46 issues of which he wrote from 1994–1998. His run on "Aquaman" gained notoriety, for in the book's second issue, Aquaman lost a hand, which was then replaced with a harpoon, a feature of the character that endured for the duration of David's run on the book. More broadly, his run recast the character as an aggressive man of action, one deserving of greater respect, in contrast to the "fish-talking punch line" into which the TV series "Super Friends" had rendered him. David quit that book over creative differences.

David wrote the "Star Trek" comic book for DC from 1988–1991, when that company held the licensing rights to the property, though he has opined that novels are better suited to "Star Trek", whose stories are not highly visual. He and Ron Marz cowrote the "DC vs. Marvel" intercompany crossover in 1996. David enjoyed considerable runs on "Supergirl" and "Young Justice", the latter eventually being canceled so that DC could use that book's characters in a relaunched "Teen Titans" monthly.

David's work for Dark Horse Comics has included the teen spy adventure "SpyBoy", which appeared in a series and a number of miniseries between 1999 and 2004, and the 2007 miniseries "The Scream".

Other 1990s work includes the 1997 miniseries "Heroes Reborn: The Return", for Marvel, and two creator-owned properties: "Soulsearchers and Company", published by Claypool Comics, and the Epic Comics title "Sachs and Violens", which he produced with co-creator/artist George Pérez.

David's early 2000s work includes runs on two volumes of "Captain Marvel" as well as the "Before the Fantastic Four: Reed Richards" limited series.

David and his second wife, Kathleen, wrote the final English-language text for the first four volumes of the manga series "Negima" for Del Rey Manga.

In 2003, David began writing another creator-owned comic, "Fallen Angel", for DC Comics, which he created in order to make use of plans he had devised for Supergirl after the "Many Happy Returns" storyline, but which were derailed by that series' cancellation. That same year, he wrote a "Teenage Mutant Ninja Turtles" series for Dreamwave that tied into the animated television series broadcast that year.

DC canceled "Fallen Angel" after 20 issues, but David restarted the title at IDW Publishing at the end of 2005. Other IDW work included a "" one-shot and the "Spike vs. Dracula" mini-series, both based on the character from the "Buffy the Vampire Slayer" and "Angel" television series.
In 2005, David briefly returned to "The Incredible Hulk", though he left after only 11 issues because of his workload. He started a new series, "Friendly Neighborhood Spider-Man", beginning with a twelve-part crossover storyline called "", which, along with J. Michael Straczynski's run on "The Amazing Spider-Man", and Reginald Hudlin's run on "Marvel Knights Spider-Man," depicted the webslinger as he discovered he was dying, lost an eye during a traumatic fight with Morlun, underwent a metamorphosis and emerged with new abilities and insights into his powers. As tends to be the case when fundamental changes are introduced to long-standing classic comics characters, the storyline caused some controversy among readers for its introduction of retractable stingers in Spider-Man's arms, and the establishment of a "totem" from which his powers are derived. David's final issue of that title was #23.

David wrote a "MadroX" miniseries that year, whose success led to a relaunch of a monthly "X-Factor" volume 3 written by him. This was a revamped version of the title starring both Madrox and other members of the former "X-Factor" title that David had written in the early 1990s, now working as investigators in a detective agency of that name. David's work on the title garnered praise from Ain't it Cool News, and David has stated that the opt in/opt out policy and greater planning with which Marvel now executes crossover storylines has made his second stint on the title far easier. His decision to explicitly establish male characters Shatterstar and Rictor as sharing a sexual attraction to one another (a confirmation of clues that had been established in "X-Force" years earlier in issues such as "X-Force" #25, 34, 43, 49, 56 and "X-Force '99 Annual"), drew criticism from Shatterstar's co-creator, Rob Liefeld, though Editor-in-Chief Joe Quesada supported David's story. David eventually won a 2011 GLAAD Media Award for Outstanding Comic Book for his work on the title.

On February 11, 2006, David announced at the WonderCon convention in California in that he had signed an exclusive contract with Marvel Comics. "Fallen Angel", "Soulsearchers and Company" and David's "Spike" miniseries were "grandfathered" into the contract, so as to not be affected by it. The first new project undertaken by David after entering into the contract, which he announced on April 5, 2006, was writing the dialogue for "", the comic book spin-off of Stephen King's "The Dark Tower" novels, which was to be illustrated by Jae Lee, as well as scripting the subsequent "Dark Tower" comics.

David took over Marvel's "She-Hulk" after writer Dan Slott's departure, beginning with issue #22. His run, which won praise, ended with issue #38, when the series was canceled. He wrote a 2008–09 "Sir Apropos of Nothing" miniseries, based on the character from his novels, which was published by IDW Publishing.

David's other 2000s comics based on licensed or adapted properties include "Halo: Helljumper", a 2009 miniseries based on the "Halo" video game, a 2009 "" manga book published by Del Rey, "Ben Folds Four", a "Little Mermaid" story in Jim Valentino's "Fractured Fables" anthology that was praised by Ain't It Cool News, an adaptation of the 1982 film "Tron" that was released to tie in with that film's , and a "John Carter of Mars" prequel to the 2012 feature film. In 2010, he co-wrote "The Spider-Man Vault: A Museum-in-a-Book with Rare Collectibles Spun from Marvel's Web" with Robert Greenberger. David wrote the script for "Avengers: Season One", an original graphic novel published to promote the DVD release of "The Avengers".

On November 24, 2011, David was one of the balloon handlers who pulled the Spider-Man balloon during the Macy's Thanksgiving Day Parade.
In October 2013, "X-Factor" ended its run with issue #262, concluding the X-Factor Investigations incarnation of the series. The book was then relaunched as "All-New X-Factor", a new series with artist Carmine Di Giandomenico, as a part of the All-New Marvel NOW! initiative announced at the 2013 New York Comic Con. The opening storyline, which continues events from issue #260 of the previous series, establishes the new corporate-sponsored version of the team, and includes Polaris, Quicksilver, and Gambit.

In July 2014, David returned to Spider-Man 2099, writing the second volume of "Spider-Man 2099" with artist Will Sliney. With this series, David was again writing two series, "X-Factor" and "Spider-Man 2099", after having previously done so decades prior, a coincidence that prompted him to joke at the June 2014 Special Edition NYC convention, "I don't know whether to be proud of that or if I'm in a rut!"

In 2014 David wrote a six-part story-arc for "The Phantom" for publishing company Hermes Press, a story that David, reportedly had wanted to write for many years.

In 2015, Simon and Schuster published Stan Lee's autobiographical graphic novel, "Amazing Fantastic Incredible", which David co-wrote, and which became a "New York Times" bestseller in its first week of release.

In April 2017, following the conclusion of the Spider-Man storyline "", which saw the return of Ben Reilly, Marvel premiered the monthly series "", with David as writer. David explained to Syfy Wire that when Marvel offered him the job, he was initially ambivalent, as Ben Reilly had never been his favorite incarnation of Spider-Man, and given Reilly's recent emergence as the villainous Jackal. However, David gave further consideration to the fact that a book whose main character had a skewed, villainous worldview was not something Marvel had historically done much of, and decided that the premise presented itself with opportunities that intrigued him enough to accept the job.

David's career as a novelist developed concurrently with his comic-book writing career. David had been working at a publisher that went out of business, and a former coworker from that publisher became his agent, through whom he sold his first novel, "Knight Life", to Ace Books. Although the sale was made before he wrote any comic books, the novel was not published until eighteen months later, in 1987. The novel depicts the reappearance of King Arthur in modern-day New York City. Another early novel of his, "Howling Mad", is about a wolf that turns into a human being after being bitten by a werewolf. Ace Books hired David to write the "Photon" and "Psi-Man" novels, though they published them under the "house name" David Peters, over David's objections. David updated "Knight Life" years later when Penguin Putnam brought it back into print in 2003, and made it a trilogy with the sequels "One Knight Only" and "Fall of Knight", which were published in 2004 and 2007, respectively. Penguin rereleased "Howling Mad" and the "Psi-Man books" under David's actual name.

David first began writing "Star Trek" novels at the request of Pocket Books editor Dave Stern, who was a fan of David's "Star Trek" comic book work. His "Star Trek" novels are among those for which he is best known, including "Q-in-Law"; "I, Q"; "Vendetta"; "Q-Squared"; and "Imzadi", one of the best-selling Star Trek novels of all time. He created the ongoing novel series, "," a spin-off from "," with John J. Ordover in 1997. "New Frontier" continued until April 2011, with the publication of "Blind Man's Bluff", the final "New Frontier" novel on David's contract at the time, after which the series' future was unclear to David. David's other science fiction tie-in novels include written five "Babylon 5" novels, three of which were originals, and two of which were adaptations of the TV movies "" and "".

His other novel adaptations include those of the movies "The Return of Swamp Thing", "The Rocketeer", "Batman Forever", "Spider-Man", "Spider-Man 2", "Spider-Man 3", "Hulk", "The Incredible Hulk", "Fantastic Four", and "Iron Man". He wrote an original Hulk novel, "The Incredible Hulk: What Savage Beast", and an adaptation of an unused "Alien Nation" television script, "Body and Soul".

David's 2009 novel "Tigerheart" is a re-imagining of Peter Pan with a mix of new and old characters, told as a Victorian bedtime story, much like the classic tale. It was praised by Ain't It Cool News, and honored by the "School Library Journal" as one of 2008's Best Adult Books for High School Students. His "Sir Apropos of Nothing" fantasy trilogy, "Sir Apropos of Nothing", "The Woad to Wuin" and "Tong Lashing", features characters and settings completely of David's own creation, as does his 2007 fantasy novel, "Darkness of the Light", which is the first in a new trilogy of novels titled "The Hidden Earth". The second installment, "The Highness of the Low", was scheduled to be published in September 2009, but David has related on his blog that it has been delayed until the winter of 2012.

David's 2010 novel work includes "Year of the Black Rainbow", a novel cowritten with musician Claudio Sanchez of the band Coheed and Cambria, that was released with the band's album of the same name, and an "Fable" original novel "The Balverine Order", set between the events of "Fable II" and "Fable III". In April 2011, David announced that, in addition to another "Fable" novel, he and a number of other writers, including Glenn Hauman, Mike Friedman and Bob Greenberger, were assembling an electronic publishing endeavor called Crazy Eight Press to publish e-books directly to fans, the first of which would be David's Arthurian story, "The Camelot Papers". David explained that the second book in his "Hidden Earth" trilogy would be published through Crazy Eight. In September 2013, David acknowledged that books published through Crazy Eight are not as lucrative for him as those for publishers that pay him advances, and announced that his then-impending novel, "ARTFUL: Being the Heretofore Secret History of that Unique Individual, The Artful Dodger, Hunter of Vampyres (Amongst Other Things.)", would be published by Amazon.com.

David has stated that he tries to block out different days and different times to work on different projects. He usually works in the morning, for example, on novels, and does comics-related work in the afternoon. Having previously used Smith Corona typewriters, he writes on a Sony Vaio desktop computer, using Microsoft Word for his comics and novel work, and Final Draft for his screenplays. When writing novels, he sometimes outlines the story, and sometimes improvises it as he is writing it. Following his stroke in December 2012, David began using DragonDictate to write. Todd McFarlane's original art for the cover of "The Incredible Hulk" #340, featuring Wolverine, which McFarlane gave to David as a gift, hangs in David's office.

David previously wrote his comic book scripts using the Marvel Method, but due to his tendency to overplot, as during his collaboration with McFarlane on "The Incredible Hulk", he switched to the full script method, which he continues to use . He has stated that he prefers to plot his comics stories in six-month arcs. He has stated that when he works on a particular title, he always does so with a particular person or group of people in mind to which he dedicates it, explaining that he wrote "Supergirl" for his daughters, "Young Justice" for a son he might one day have and "The Incredible Hulk" for his first wife, Myra, who first urged him to accept the job of writing that book. David has further explained that the events of his own life are sometimes reflected in his work, as when, for example, following the breakup of his first marriage, the direction of "The Incredible Hulk" faltered, with the Hulk wandering the world aimlessly, hopelessly looking to be loved.

David has stated that his favorite female character of his own creation is Lee, the protagonist of "Fallen Angel", which he says is derived from the positive female fan reaction to that character. Characters that David has not written but which he has expressed an interest in writing for the comics medium include Batman, Tarzan, Doc Savage, the Dragonriders of Pern, the Steed/Peel Avengers, and Dracula. He has specifically mentioned interest in writing a "Tarzan vs. the Phantom" story.


David has written for several television series and video games. He wrote two scripts for "Babylon 5" (the second-season episodes "Soul Mates" and "There All the Honor Lies"), and the episode "Ruling from the Tomb" for its sequel series, "Crusade". With actor/writer Bill Mumy, he is co-creator of the television series "Space Cases", which ran for two seasons on Nickelodeon, and which proved to be his most lucrative work. David himself appeared as Ben, the father of series regular Bova, in the second-season episode "Long Distance Calls". David's oldest daughter, Shana, later appeared as Pezu, the emotionally disturbed sentient computer in the series finale "A Friend in Need". David has written and co-produced several films for Full Moon Entertainment and has made cameo appearances in some of the films as well.

David wrote an unproduced script for the fifth season of "Babylon 5" called "Gut Reactions", which he wrote with Bill Mumy.

David wrote "In Charm's Way", an episode of "". The script was recorded in early 2009, and the episode premiered November 13, 2009. He later wrote three episodes of the spinoff "", the first of which, "Reflected Glory", premiered October 15, 2010.

David wrote the script for the Xbox 360 video game "Shadow Complex", which debuted in August 2009.

David wrote several episodes of the "Young Justice" animated TV series, which premiered in 2010, and is based on the comic book series he wrote from 1998 to 2003. The first episode he penned is episode #18. The same year, he wrote a graphic novel adaptation of the video game "Epic Mickey", and a prequel digicomic, "Disney's Epic Mickey: Tales of Wasteland".

In 2011 David wrote the video game "".

At the 2012 San Diego Comic-Con International, Stan Lee announced his new YouTube channel, "Stan Lee's World of Heroes", which airs several programs created by Lee and other creators. One of them, "Head Cases", is a superhero sitcom created by David and his wife Kathleen and produced by David M. Uslan. The series centers on Thunderhead, a would-be hero whose inability to utilize his ability to produce loud thunderblasts without injury to himself leads him to become a source of comedic derision in the superhero community. The series, which explores events that occur in between the battles typically seen in comic books, was based on a concept originated by Uslan, and partly inspired by "It's Always Sunny in Philadelphia". David describes "Head Cases" as a 75-minute movie divided into 5-minute webisodes. The series will feature guest appearances by other industry personalities, including Stan Lee, who appears as himself, functioning in a similar manner to Norm Peterson from "Cheers".



On more than one occasion, editorial problems or corporate pressure to modify or re-script his plotlines have prompted David to leave books, particularly his decision to terminate his first run on Marvel's "X-Factor", due to constantly having to constrain his plots to accommodate crossover events with other books. He resigned from "Spider-Man 2099" to protest the firing of editor Joey Cavalieri, and from "Aquaman" over other creative differences. When David abruptly left his first stint on "The Incredible Hulk" due to editorial pressures, some of the plot points of the character that David established were retconned by later creative teams.

In his "But I Digress" column, which began appearing in the "Comics Buyer's Guide" on July 27, 1990, and in his blog, in operation since April 2002, David has been outspoken in many of his views pertaining to the comic book industry and numerous other subjects. He has criticized the low regard in which writers are held, the practice of bagged comics, so-called "poster covers" that showcase a character without indicating anything about the comic's content, the meaninglessness of killing off characters to be eventually revived, the poor commitment on the part of some to maintaining continuity in shared fictional universes, and the emphasis on gearing monthly comics series toward eventual collection into trade paperbacks. David has opined that failure on the part of consumers to purchase the monthly individual issues in favor of waiting for the trade collections hurts the sales of the monthly, and its chances of being collected at all. A father of four daughters, David has worked on a number of series that feature female leads, such as "Supergirl", "Fallen Angel" and "She-Hulk", and has lamented that the American comic book market is not very supportive of such books. David has spoken out about fans who are abusive or threatening to creators, and against copyright infringement, particularly that which is committed through peer-to-peer file sharing and posting literary works in their entirety on the Internet without the permission of the copyright holder.

On many occasions, he has offered criticisms of specific publishers, as when he criticized "Wizard" magazine for ageism. He has criticized companies for not sufficiently compensating the creators of their long-standing and lucrative characters, such as Marvel Comics for its treatment of Blade creator Marv Wolfman and Archie Comics for its treatment of "Josie and the Pussycats" creator Dan DeCarlo. He has criticized publishers for various other business practices, including Marvel and Image Comics. He has defended said companies from criticism he feels is unfounded, as when he defended Marvel from a February 17, 1992 "Barron's" magazine article. He has criticized deletionists on Wikipedia on more than one occasion.

On occasion, he has disagreed publicly with specific industry personalities such as Frank Miller and Jim Shooter. Particularly publicized were his disagreements with "Spawn" creator Todd McFarlane in 1992 and 1993, in the wake of the formation of Image Comics, the company McFarlane co-founded. This came to a head during a public debate they participated in at Philadelphia's Comicfest convention in October 1993, which was moderated by artist George Pérez. McFarlane claimed that Image was not being treated fairly by the media, and by David in particular. The three judges, Maggie Thompson, editor of the "Comics Buyer's Guide", William Christensen of "Wizard Press", and John Danovich of the magazine "Hero Illustrated", voted 2–1 in favor of David, with Danovich voting the debate a tie. David has since criticized McFarlane for other business practices, and has engaged in public disagreements with "The Comics Journal" editor Gary Groth, Erik Larsen, Rob Liefeld, Marvel Editor-In-Chief Joe Quesada, writer/director Kevin Smith, DC Comics Vice President and Executive Editor Dan DiDio, and John Byrne. Despite his differences with Byrne, David has stated that he is still a fan of Byrne's, citing Byrne's work on "X-Men", "Fantastic Four", "Next Men", "Alpha Flight" and "Babe".

Politically, David identifies himself as liberal. He was critical of the George W. Bush administration in general, and the Iraq War in particular, as well as other Republicans and the religious right. He also became a staunch critic of President Donald Trump and his administration, criticizing his policies on a weekly basis. He has spoken out in favor of Israel's right to defend itself from aggressors, and has opined that certain criticisms of Israel indicate bias and double standards. He favors gun control, and holds progressive or liberal views on LGBT issues, including favoring gay marriage and allowing openly homosexual individuals to serve in the military. He opposes capital punishment. He is an advocate of freedom of speech, having criticized various publicized instances of censorship in general, such as the targeting of comic book retailers for prosecution for selling certain comic books, and the Comics Code Authority in particular. He is a promoter and activist for the Comic Book Legal Defense Fund, which comes to the aid of such creators and retailers. He has criticized ideas associated with liberalism or political correctness, such as certain publicized cases of alleged sexual harassment or discrimination that he deems unfounded, and has not shied away from criticizing liberals and Democrats, including Bill Clinton, Al Gore, Hillary Clinton, Michelle Obama, Caroline Kennedy, and Barack Obama.

David met his first wife, Myra Kasman, at a "Star Trek" convention. They married in June 1977, with his childhood friend Keith serving as best man. Together they had three daughters, Shana, Guinevere and Ariel. They separated in late 1996, and were divorced by 1998. David began dating Kathleen O'Shea, a bookseller, puppeteer and writer/editor in 1998. After dating for three years, David proposed to O'Shea at the Adventurers Club in Disney World on September 3, 2000. They married on May 26, 2001 in Atlanta, Georgia. Their daughter, Caroline Helen David, was born on December 5, 2002, and named after David's late friend and coworker, Carol Kalish. David and his family live in Suffolk County, New York, on the south shore of Long Island, where his favorite local comics shop is Fourth World Comics in Smithtown, New York. David's father, Gunter, died of cancer on April 20, 2015. David's mother, Dalia, died May 27, 2017.

David had been a Conservative Jew, but as of October 2003, attends a Reform synagogue. His Hebrew name in patronymic form is Jacob Ben Joachim. He has, however, expressed reservations about organized religion.

David has named "Groo the Wanderer", "Liberty Meadows", "Fables", "", "Strangers in Paradise", "Runaways", "She-Hulk", "Spider-Man Loves Mary Jane", "Knights of the Dinner Table", "The Crossovers" and J. Michael Straczynski's run on "Spider-Man" as comics that he has enjoyed. Other creators whose work he has long-admired include John Romita, Sr., John Buscema, Gene Colan, and others he has stated he presently admires or are friends that he enjoys working with include George Pérez, Andy Kubert, and Rick Leonardi. He has named Pérez as his favorite artistic collaborator, and has named Pérez, Leonard Kirk and Dale Keown as the artists whose art has mostly closely matched the visuals he conceived when writing comic book scripts.

David is an avid fan of bowling, and a bowler himself, as is his daughter Ariel. He is a fan of the New York Mets, and practices tai chi. His favorite music includes The Beatles, and his favorite albums include Harry Chapin's "Verities and Balderdash" and the soundtracks to "Amadeus" and "". His favorite movies include the James Bond films, "The Adventures of Robin Hood", "That", "Casablanca", and the early Johnny Weissmuller "Tarzan" films. His favorite TV shows have included "Doctor Who", "Hill Street Blues", "Charmed", "Carnivale", "Boston Public", "The Practice", "Friends", "Buffy the Vampire Slayer", "Angel", "Alias" and "The West Wing". He is a fan of musicals, in particular "1776", "Man of La Mancha", "Li'l Abner" and "Into the Woods", with a taste for Lerner and Loewe and Stephen Sondheim. He acts in local stage productions.

In June 2010, David's wife announced on his website that he had successfully undergone surgery to relieve serious back pain. He later explained on his site that the pain, which he had been suffering in his hips and knees for three weeks, left him unable to function, and was eventually diagnosed as a herniated disc caused by bone fragments and fluid buildup. He underwent a three-hour discectomy, and was told his full strength would return in six months.

On December 29, 2012, David suffered a stroke while on vacation in Florida. The stroke occurred in the Pons section of David's brain, from which he lost most of the use of his right arm and his right leg, and suffered from blurred vision in his right eye. While a total recovery was indicated to be unlikely, he remained in good spirits, and underwent physical therapy in order to return to his prior routine. Two and a half months later, his condition had improved. His vision problems were gone, and he was able to navigate around his house without a wheelchair, and resume bowling and practicing tai chi. He had made slow and steady progress on his right leg and arm, and was continuing his therapy. Six months after the stroke, David had completed his physical therapy, though he still suffered some pain in his shoulder, and intended to work on improving his reduced endurance. David revealed in January 2015 that he was diagnosed with Type 2 diabetes a year prior.

In March 2017, David announced on his blog that the IRS was demanding that he pay $88,000 USD in unpaid taxes, penalty and interest, which began to accumulate when his divorce from his first wife used up his savings. He started a GoFundMe campaign to raise the money from friends and fans, which raised $68,000 by April 12. David announced that he would begin a Patreon account where he would publish new work, and which would be used to pay taxes, and asked his readers for their content requests. By May 11, having sold some original comics artwork acquired two decades earlier, the Davids' debts were paid off.


 

 


</doc>
<doc id="24998" url="https://en.wikipedia.org/wiki?curid=24998" title="Plenum">
Plenum

Plenum may refer to:




</doc>
<doc id="25002" url="https://en.wikipedia.org/wiki?curid=25002" title="Pretoria">
Pretoria

Pretoria ( ; ; ) is the administrative capital of South Africa. It straddles the Apies River and has spread eastwards into the foothills of the Magaliesberg mountains. It is one of the country's three capital cities, serving as the seat of the administrative branch of government (Cape Town is the legislative capital and Bloemfontein the judicial capital), and of foreign embassies to South Africa. Pretoria has a reputation for being an academic city with three universities, the Tshwane University of Technology (TUT), University of Pretoria (UP), and the University of South Africa (UNISA), also home to the Council for Scientific and Industrial Research (CSIR), and the Human Sciences Research Council. The city also hosts the National Research Foundation and the South African Bureau of Standards making the city a hub for research. Pretoria is the central part of the Tshwane Metropolitan Municipality which was formed by the amalgamation of several former local authorities including Centurion and Soshanguve. There have been proposals to change the name of Pretoria itself to Tshwane and the proposed name change has caused some public controversy.

Pretoria is named after the Voortrekker leader Andries Pretorius, and within South Africa sometimes called the "Jacaranda City" due to the thousands of jacaranda trees planted in its streets, parks and gardens.

Pretoria was founded in 1855 by Marthinus Pretorius, a leader of the Voortrekkers, who named it after his father Andries Pretorius and chose a spot on the banks of the "Apies rivier" (Afrikaans for "Monkeys river") to be the new capital of the South African Republic (; ZAR). The elder Pretorius had become a national hero of the Voortrekkers after his victory over Dingane and the Zulus in the Battle of Blood River in 1838. The elder Pretorius also negotiated the Sand River Convention (1852), in which the United Kingdom acknowledged the independence of the Transvaal. It became the capital of the South African Republic on 1 May 1860.

The founding of Pretoria as the capital of the South African Republic can be seen as marking the end of the Boers' settlement movements of the Great Trek.

During the First Boer War, the city was besieged by Republican forces in December 1880 and March 1881. The peace treaty which ended the war was signed in Pretoria on 3 August 1881 at the Pretoria Convention.

The Second Boer War resulted in the end of the Transvaal Republic and start of British hegemony in South Africa. The city surrendered to British forces under Frederick Roberts on 5 June 1900 and the conflict was ended in Pretoria with the signing of the Peace of Vereeniging on 31 May 1902 at Melrose House.

The Pretoria Forts were built for the defence of the city just prior to the Second Boer War. Though some of these forts are today in ruins, a number of them have been preserved as national monuments.

The Boer Republics of the ZAR and the Orange River Colony were united with the Cape Colony and Natal Colony in 1910 to become the Union of South Africa. Pretoria then became the administrative capital of the whole of South Africa, with Cape Town the legislative capital and Bloemfontein served as the judicial capital. Between 1910 and 1994, the city was also the capital of the province of Transvaal. (As the capital of the ZAR, Pretoria had superseded Potchefstroom in that role.)
On 14 October 1931, Pretoria achieved official city status. When South Africa became a republic in 1961, Pretoria remained its administrative capital.

Pretoria is situated approximately north-northeast of Johannesburg in the northeast of South Africa, in a transitional belt between the plateau of the Highveld to the south and the lower-lying Bushveld to the north. It lies at an altitude of about above sea level, in a warm, sheltered, fertile valley, surrounded by the hills of the Magaliesberg range.

Pretoria has a humid subtropical climate (Köppen: Cwa) with long hot rainy summers and short cool to cold, dry winters. The city experiences the typical winters of South Africa with cold, clear nights and mild to moderately warm days. Although the average lows during winter are mild, it can get cold due to the clear skies, with nighttime low temperatures in recent years in the range of .

The average annual temperature is . This is rather high, considering the city's relatively high altitude of about , and is due mainly to its sheltered valley position, which acts as a heat trap and cuts it off from cool southerly and south-easterly air masses for much of the year.

Rain is chiefly concentrated in the summer months, with drought conditions prevailing over the winter months, when frosts may be sharp. Snowfall is an extremely rare event; snowflakes were spotted in 1959, 1968 and 2012 in the city, but the city has never experienced an accumulation in its history.

During a nationwide heatwave in November 2011, Pretoria experienced temperatures that reached , unusual for that time of the year. Similar record-breaking extreme heat events also occurred in January 2013, when Pretoria experienced temperatures exceeding on several days. The year 2014 was one of the wettest on record for the city. A total of fell up to the end of December, with recorded in this month alone. In 2015, Pretoria saw its worst drought since 1982; the month of November 2015 saw new records broken for high temperatures, with recorded on 11 November after three weeks of temperatures between and . Pretoria reached a new record high of on 7 January 2016.

Depending on the extent of the area understood to constitute "Pretoria", the population ranges from 700,000 to 2.95 million. The main languages spoken in Pretoria are Sepedi, Sesotho, Setswana, Xitsonga, Afrikaans and English. The city of Pretoria has the largest white population in Sub-Saharan Africa. Since its founding, it has been a major Afrikaner population centre, and currently there are roughly 1 million Afrikaners living in or around the city.

Even since the end of Apartheid, Pretoria itself has had a white majority, albeit with an ever-increasing black middle-class. However, in the townships of Soshanguve and Atteridgeville black people make up close to all of the population. The largest white ethnic group are the Afrikaners and the largest black ethnic group are the Northern Sothos.

The lower estimate for the population of Pretoria includes largely former white-designated areas, and there is therefore a white majority. However, including the geographically separate townships increases Pretoria's population beyond a million and makes whites a minority.

Pretoria's Indians were ordered to move from Pretoria to Laudium on 6 June 1958.
Pretoria is known as the "Jacaranda City" due to the approximately 50,000 Jacarandas that line its streets. Purple is a colour often associated with the city and is often included on local council logos and services such as the A Re Yeng rapid bus system and the logo of the local Jacaranda FM radio station.

Pretoria has over the years had very diverse cultural influences and this is reflected in the architectural styles that can be found in the city. It ranges from 19th century Dutch, German and British colonial architecture to modern, postmodern, neomodern, and art deco architecture styles with a good mix of a uniquely South African style.

Some of the notable structures in Pretoria include the late 19th century Palace of Justice, the early 20th century Union Buildings, the post-war Voortrekker Monument, the diverse buildings dotting the main campuses of both the University of Pretoria and the University of South Africa, traditional Cape Dutch style Mahlamba Ndlopfu (the President's House), the more modern Reserve Bank of South Africa (office skyscraper) and the Telkom Lukasrand Tower. Other well-known structures and buildings include the Loftus Versfeld Stadium, The South African State Theatre and the Oliver Tambo building which is the Headquarters of the Department of International Relations and Cooperation.

Despite the many corporate offices, small businesses, shops, and government departments that are situated in Pretoria's sprawling suburbs, its Central Business District still retains its status as the traditional centre of government and commerce. Many banks, businesses, large corporations, shops, shopping centres, and other businesses are situated in the city centre which is towered by several large skyscrapers, the tallest of which is the Poyntons Building ( tall), the ABSA Building ( tall) and the Reserve Bank of South Africa building ( tall).

The area contains a large amount of historical buildings, monuments, and museums that include the Pretoria City Hall, Pretorius Square, Church Square (along with its many historical buildings and statues), and the Ou Raadsaal. There is also the Transvaal Museum (the country's leading natural history museum, which although it has changed venues a number of times, has been around since 1892), the National Zoological Gardens of South Africa (or more colloquially known as the Pretoria Zoo), Melrose House Museum in Jacob Maré Street, the Pretoria Art Museum and the African Window Cultural History Museum.

Several National Departments also have Head Offices in the Central Business district such as the Department of Health, Basic Education, Transport, Higher Education and Training, Sport and Recreation, Justice and Constitutional Development, Public Service and Administration, Water and Environmental Affairs and the National Treasury. The district also has a high number of residential buildings which house people who primarily work in the district.

Pretoria is home to the National Zoological Gardens of South Africa, as well as the Pretoria National Botanical Garden. There are also a number of smaller parks and gardens located throughout the city, including the Austin Roberts Bird Sanctuary, Pretorius Square gardens, the Pretoria Rosarium, Church Square, Pretoria Showgrounds, Springbok Park, Freedom Park, Jan Cilliers Park and Burgers Park, the oldest park in the city and now a national monument. In the suburbs there are also several parks that are notable: Rietondale Park, "Die Proefplaas" in the Queenswood suburb, Magnolia Dell Park, Nelson Mandela Park and Mandela Park Peace Garden and Belgrave Square Park.

Pretoria's nickname "the Jacaranda City" comes from the around 70,000 jacaranda trees that grow in Pretoria and decorate the city each October with their purple blossoms. The first two trees were planted in 1888 in the garden of local gardener, J.D. Cilliers, at Myrtle Lodge on Celliers Street in Sunnyside. He obtained the seedlings from a Cape Town nurseryman who had harvested them in Rio de Janeiro, Brazil. The two trees still stand on the grounds of the Sunnyside Primary School.

The jacaranda comes from tropical South America and belongs to the family Bignoniaceae. There are around fifty species of jacaranda, but the one found most often in the warmer areas of Southern Africa is Jacaranda mimosifolia.

At the end of the 19th century, the flower and tree grower James Clark imported jacaranda seedlings from Australia and began growing them on a large scale. In November 1906, he donated two hundred small saplings to the Pretoria City Council, which planted them on Koch Street (today Bosman Street). The city engineer Walton Jameson, soon known as "Jacaranda Jim," launched a program to plant jacaranda trees throughout Pretoria, and by 1971 there would already be 55,000 of them in the city.

Most jacarandas in Pretoria are lilac in color, but there are also white ones planted on Herbert Baker Street in Groenkloof.

The Jacaranda Carnival is an old tradition that was held from 1939 to 1964. After a hiatus of over twenty years, it resumed in 1985. Festivities include a colorful march and the crowning of the Jacaranda Queen.

Commuter rail services around Pretoria are operated by Metrorail. The routes, originating from the city centre, extend south to Germiston and Johannesburg, west to Atteridgeville, northwest to Ga-Rankuwa, north to Soshanguve and east to Mamelodi.

The Gautrain high-speed railway line runs from the eastern suburb of Hatfield to Pretoria Station and then southwards to Centurion, Midrand, Marlboro, Sandton, OR Tambo International Airport, Rosebank and Johannesburg.

Pretoria Station is a departure point for the Blue Train luxury train. Rovos Rail, a luxury mainline train safari service operates from the colonial-style railway station at Capital Park. The South African Friends of the Rail have recently moved their vintage train trip operations from the Capital Park station to the Hercules station.

Various bus companies exist in Pretoria, of which PUTCO is one of the oldest and most recognised. Tshwane municipality provides the remainder of the bus services.

The N1 is the major freeway that runs through Pretoria. It enters the city from the south as the Ben Schoeman Highway. At the Brakfontein Interchange with the N14 it continues as The N1 Eastern Bypass bisects the large expanse of the eastern suburbs, routing traffic from Johannesburg to Polokwane and the north of the country. The R101 is the original N1, and served the same function before the construction of the highway. It runs through the centre of town rather than the eastern suburbs.

The N4 enters the town as a highway from Witbank in the east, merging with the N1 at the Proefplaas Interchange. It begins again north of the city, branching west from the N1 as the Platinum Highway, forming the Northern Bypass, and heading to Rustenburg. The N4 runs east–west through South Africa, connecting Maputo to Gaborone. Before the Platinum Highway was built, the N4 continued passed the Proefplaas Interchange to the city centre, where it became a regular road, before again becoming a highway west of the city. These roads are now designated the M2 and M4. There is a third, original east–west road: the R104, previously named Church Street. Church Street has been renamed Helen Joseph from Nelson Mandela Church Square, WF Nkomo from Nelson Mandela to R511, Stanza Bopape from Nelson Mandela to the East and Elias Motswaledi from R511 to the West.

The N14 starts in the centre of town from the M4 (former N4). It is a normal road heading south through the centre before becoming the Ben Schoeman highway. At the Brakfontein interchange, the Ben Schoeman highway becomes the N1, but the N14 continues as the intersecting west-south-western highway towards Krugersdorp. The R114 parallels the N14 in its westward journey running just to the north of the highway.

The R21 provides a second north–south highway, further east. It starts from the Fountains Interchange south of the city centre, but is still a road until Monument Park, when it becomes a true highway. It crosses the N1 east of the Brakfontein Interchange at the Flying Saucer Interchange and runs north–south towards Ekurhuleni (specifically Kempton Park and Boksburg). Importantly it links Pretoria with the OR Tambo International Airport in Kempton Park.

A proposed third north–south highway, in the west of the city, the R80 is partially built. At present the highway begins in Soshanguve. It terminates just north of the city centre at an intersection with the M1. Plans have been in place for some time to extend this all the way past the M4 and N14 highways to the N1 in Randburg.

Pretoria is also served by many regional roads. The R55 starts at an interchange with the R80, and runs north–south west of the city to Sandton. The R50 starts from the N1 just after the Flying Saucer Interchange in the south-east of the city, and continues south-east towards Delmas. The R511 runs north–south from Randburg towards Brits and barely by-passes Pretoria to the west. The R514 starts from the M1, north of the city centre, and terminates at the R511. The R513 crosses Pretoria's northern suburbs from east to west. It links Pretoria to Cullinan and Bronkhorstspruit in the east and Hartbeespoort in the west. The R566 takes origin in Pretoria's northern suburbs, and exits the town to the west just north of the R513. It connects Pretoria to Brits. Finally the R573 starts from the R513, just east of the town and heads north-east to Siyabuswa.

Pretoria is also served internally by metropolitan routes.

For scheduled air services, Pretoria is served by Johannesburg's airports: OR Tambo International, south of central Pretoria; and Lanseria, south-west of the city. Wonderboom Airport in the suburb of Wonderboom in the north of Pretoria primarily services light commercial and private aircraft. However, as from August 2015, scheduled flights from Wonderboom Airport to Cape Town International Airport were made available by SA Airlink. There are two military air bases to the south of the city, Swartkop and Waterkloof.

Since Pretoria forms part the Tshwane Metropolitan Municipality, most radio, television and paper media is the same as the rest of the metro area.

There are many radio stations in the greater Pretoria region, some of note are:

Impact Radio, is a Christian Community Radio Station based in Pretoria, and broadcasting on 103FM in the Greater Tshwane Area.

Jacaranda FM, previously known as Jacaranda 94.2, is a commercial South African radio station, broadcasting in English and Afrikaans, with a footprint that covers Gauteng, Limpopo, Mpumalanga and the North West Province and boasts a listening audience of 2 million people a week, and a digital community of more than 1,1 million people a month. The station's format is mainstream adult contemporary with programming constructed around a playlist of hit music from the 1980s, 1990s and now.

Tuks FM is the radio station of the University of Pretoria and one of South Africa's community broadcasters. It was one of the first community broadcasters in South Africa to be given an FM licence. It is known for contemporary music and is operated by UP's student base.

Radio Pretoria is a community-based radio station in Pretoria, South Africa, whose programmes are aimed at Afrikaners. It broadcasts 24 hours a day in stereo on 104.2 FM in the greater Pretoria area. Various other transmitters (with their own frequencies) in South Africa broadcast the station's content further afield, while the station is also available on Sentech's digital satellite platform.

Radio Kuber Kontrei is a community-based Internet (streaming) radio station in Pretoria, South Africa, whose programmes are aimed at Afrikaans-speaking Christians worldwide.

Pretoria is serviced by eTV, SABC and MNET.

The city is serviced by a variety of printed publications namely;

Pretoria News is a daily newspaper established in Pretoria in 1898. It publishes a daily edition from Monday to Friday and a Weekend edition on Saturday and Sunday. It is an independent newspaper in the English language that serves the city and its direct environs. It is available online via the Independent online website.

Beeld is an Afrikaans-language daily newspaper that was launched on 16 September 1974. Beeld is distributed in four provinces of South Africa: Gauteng, Mpumalanga, Limpopo, North West. Die Beeld (English: The Image) was an Afrikaans-language Sunday newspaper in the late 1960s.

Wrapped is an alternative lifestyle magazine from Africa that caters for the entire LGBT community and is not gender-dominated.

Pretoria Sotho (called Sepitori by its speakers) is the urban lingua franca of Pretoria and the Tshwane metropolitan area in South Africa. It is a combination of Tswana and Northern Sotho (Pedi), with influences from Tsotsitaal and other black South African languages. It is a creole language that developed in the city during the years of Apartheid.


A number of popular South African bands and musicians are originally from Pretoria. These include Desmond and the Tutus, Bittereinder, The Black Cat Bones, Seether, popular mostwako rapper JR, Joshua na die Reën and DJ Mujava who was raised in the town of Attridgeville.

The song "Marching to Pretoria" refers to this city. Pretoria was the capital of the South African Republic (a.k.a. Republic of the Transvaal; 1852-1881 and 1884-1902) the principal battleground for the First and Second Boer War, the latter which brought both the Transvaal and the Orange Free State republic under British rule. "Marching to Pretoria" was one of the songs that British soldiers sang as they marched from the Cape Colony, under British Rule since 1814, to the capital of the Southern African Republic (or in Dutch, "Zuid-Afrikaansche Republiek"). As the song's refrain puts it: "We are marching to Pretoria, Pretoria, Pretoria/We are marching to Pretoria, Pretoria, Hurrah."

The opening line of John Lennon's Beatles' song I Am the Walrus, "I am he as you are he as you are me and we are all together," is often believed to be based on the lyric "I'm with you and you're with me and so we are all together" in "Marching to Pretoria." Lennon denied this, insisting his lyrics came from "nothing."

Pretoria is home to an extensive portfolio of public art. A diverse and evolving city, Pretoria boasts a vibrant art scene and a variety of works that range from sculptures to murals to pieces by internationally and locally renowned artists. The Pretoria Art Museum is home to a vast collection of local artworks. After a bequest of 17th century Dutch artworks by Lady Michaelis in 1932 the art collection of Pretoria City Council expanded quickly to include South African works by Henk Pierneef, Pieter Wenning, Frans Oerder, Anton van Wouw and Irma Stern. And according to the museum: "As South African museums in Cape Town and Johannesburg already had good collections of 17th, 18th and 19th century European art, it was decided to focus on compiling a representative collection of South African art" making it somewhat unusual compared to its contemporaries.

Pretoria houses several performing arts venues including:
the South African State Theatre which houses the arts of Opera, musicals, plays and comedic performances.

A 9 metre tall statue of former president Nelson Mandela was unveiled in front of the Union Buildings on 16 December 2013. Since Nelson Mandela's inauguration as South Africa's first majority elected president the Union Buildings have come to represent the new 'Rainbow Nation'. Public art in Pretoria has flourished since the 2010 FIFA World Cup with many areas receiving new public artworks.

One of the most popular sports in Pretoria is rugby union. Loftus Versfeld is home to the Blue Bulls, who compete in the domestic Currie Cup, and also to the Bulls in the international Super Rugby competition. The Bulls Super Rugby team, which is operated by the Blue Bulls, won the competition in 2007, 2009 and 2010. Loftus Versfeld also hosts the football side Mamelodi Sundowns.

Pretoria also hosted matches during the 1995 Rugby World Cup. Loftus Versfeld was used for some matches in the 2010 FIFA World Cup.

Association football is one of the most popular sports in the city. There are currently two football teams in the city playing in South Africa's top-flight football league, the Premier Soccer League. They are Mamelodi Sundowns and Supersport United. Supersport United were the 2008–09 PSL Champions. Following the 2011/2012 season the University of Pretoria F.C. gained promotion to the South African Premier Division, the top domestic league, becoming the third Pretoria-based team in the league. After a poor league finish in the 2015/2016 season, University of Pretoria F.C. were relegated to the National First Division, the second-highest football league in South Africa, in the 2016 Premier Soccer League promotion/relegation play-offs.

Cricket is also a popular game in the city. As there is no international cricket stadium in the city, it does not host any top-class cricket tournaments, although the nearby situated Centurion has Supersport Park which is an international cricket stadium and has hosted many important tournaments such as 2003 Cricket World Cup, 2007 ICC World Twenty20, 2009 IPL and 2009 ICC Champions Trophy. The most local franchise team to Pretoria is the Titans, although Northerns occasionally play in the city in South Africa's provincial competitions. Many Pretoria born cricketers have gone on to play for South Africa, including current captain AB de Villiers and T20 captain Faf du Plessis.

The Pretoria Transnet Blind Cricket Club is situated in Pretoria and is currently the biggest Blind Cricket club in South Africa. Their field is at the Transnet Engineering campus on Lynette Street, home of differently disabled cricket. PTBCC has played many successful blind cricket matches with abled body team such as the South African Indoor Cricket Team and TuksCricket Junior Academy. Northerns Blind Cricket is the Provincial body that governs PTBCC and Filefelfia Secondary School. The Northern Blind Cricket team won the 40 over National Blind Cricket tournament that was held in Cape Town in April 2014.

Among the places of worship, they are predominantly Christian churches and temples : Zion Christian Church, Apostolic Faith Mission of South Africa, Assemblies of God, Baptist Union of Southern Africa (Baptist World Alliance), Methodist Church of Southern Africa (World Methodist Council), Anglican Church of Southern Africa (Anglican Communion), Presbyterian Church of Africa (World Communion of Reformed Churches), Roman Catholic Archdiocese of Pretoria (Catholic Church). There are also Muslim mosques and Hindu temples.

Pretoria has a small Jewish community of around 3,000. Jewish citizens have been in Pretoria since its foundation in the 19th century and played an important role in its industrial and economic growth. A Mr. De Vries, the first Jewish inhabitant of Pretoria, was a prominent citizen and prosecutor, a member of the Volksraad and a pioneer of the Afrikaans language. Another famed Jewish Pretorian was Sammy Marks.

Other early Jewish settlers, many of them immigrants from Lithuania, were not as educated as De Vries and often did not speak Dutch, Afrikaans, or English. Many of them spoke only Yiddish and made a living as shopkeepers in the local retail industry. Most Jewish residents stayed neutral in the Second Boer War, though some joined the South African Republic army.

The first congregation was founded between 1890 and 1895, and in 1898 the first synagogue opened on Paul Kruger Street. A second synagogue, known as the Great Synagogue, opened in 1922. Both synagogues are no longer in operation, but a Reformed synagogue, Temple Menorah, opened in the early 1950s.

The Jewish community of Pretoria's golden age was in the early 20th century, when many Jewish sports clubs, charities, and youth groups flourished. After 1948, many Jews left for Cape Town or Johannesburg.

The synagogue on Paul Kruger Street was purchased by the government in 1952 to become the new home of the High Court where prominent opposition figures in the Anti-Apartheid Movement were tried, including Nelson Mandela, Walter Sisulu, and 26 others were prosecuted for treason from August 1, 1958 to March 29, 1961; the Rivonia Trial was held there in 1963-1964.

Two Jewish schools arose in Pretoria, the Miriam Marks School, which was founded in 1905, and the Carmel School, which opened in 1959. Only the second, currently also operating as a synagogue, remains. Pretoria's Reformed congregation shares a rabbi with the Johannesburg one, though the synagogue no longer operates and services take place in worshipers' private homes.

A Buddhist center, the Jang Chup Chopel Rigme Centre ("Center of Light") was founded in early January 2015 by Duan Pienaar or Gyalten Nyima (his adopted monastic name) in Waverley around Pretoria-Moot. Pienaar is the only Afrikaner ordained in the highly selective Tibetan Tantric Buddhist community in Bylakuppe, in southern India. His instructor Lama Kyabje Choden Rinpoche is the highest tantric master after the Dalai Lama. Pienaar, who studied Buddhist teachers for twenty years, spent two years in India.

The city is a major commercial centre and an important industrial centre. Its main industries are iron and steel works, copper casting, and the manufacture of automobiles, railway carriages and heavy machinery.

Pretoria has a number of industrial areas, business districts and small home businesses. A number of chambers of commerce exist for Pretoria and its business community including Pretoriaweb, a business networking group that meets once a month to discuss the issues of doing business in Pretoria. The members of Pretoriaweb also discuss issues in various social media environments and on the website.

The Pretoria civic arms, designed by Dr. Frans Engelenburg, were granted by the College of Arms on 7 February 1907. They were registered with the Transvaal Provincial Administration in March 1953 and at the Bureau of Heraldry in May 1968. The Bureau provided new artwork, in a more modern style, in 1989.

The arms were: "Gules, on an mimosa tree eradicated proper within an orle of eight bees volant, Or, an inescutcheon Or and thereon a Roman praetor seated proper". In layman's terms : a red shield displaying an uprooted mimosa tree surrounded by a border of eight golden bees, superimposed on the tree is a golden shield depicting a Roman praetor. The tree represented growth, the bees industry, and the praetor (judge) was an heraldic pun on the name.

The crest was a three-towered golden castle; the supporters were an eland and a kudu; and the motto "Praestantia praevaleat Pretoria".
The coat of arms have gone out of favour after the City Council amalgamated with its surrounding councils to form the City of Tshwane Metropolitan Municipality.

Schools for foreign students:

Pretoria is one of South Africa's leading academic cities and is home to both the largest residential university in South Africa, largest distance education university in South Africa and a research intensive university. The three Universities in the city in order of the year founded are as follows:

The University of South Africa (commonly referred to as Unisa), founded in 1873 as the University of the Cape of Good Hope, is the largest university on the African continent and attracts a third of all higher education students in South Africa. It spent most of its early history as an examining agency for Oxford and Cambridge universities and as an incubator from which most other universities in South Africa are descended. In 1946 it was given a new role as a distance education university and in 2012 it had a student headcount of over 300,000 students, including African and international students in 130 countries worldwide, making it one of the world's mega universities. Unisa is a dedicated open distance education institution and offers both vocational and academic programmes.

The University of Pretoria (commonly referred to as UP, Tuks, or Tukkies) is a multi campus public research university. The university was established in 1908 as the Pretoria campus of the Johannesburg based Transvaal University College and is the fourth South African institution in continuous operation to be awarded university status. Established in 1920, the University of Pretoria Faculty of Veterinary Science is the second oldest veterinary school in Africa and the only veterinary school in South Africa. In 1949 the university launched the first MBA programme outside of North America. Since 1997, the university has produced more research outputs every year than any other institution of higher learning in South Africa, as measured by the Department of Education's accreditation benchmark.

The Tshwane University of Technology (commonly referred to as TUT) is a higher education institution, offering vocational oriented diplomas and degrees, and came into being through a merger of Technikon Northern Gauteng, Technikon North-West and Technikon Pretoria. TUT caters for approximately 60,000 students and it has become the largest residential higher education institution in South Africa.

The Council for Scientific and Industrial Research (CSIR) is South Africa's central scientific research and development organisation. It was established by an act of parliament in 1945 and is situated on its own campus in the city. It is the largest research and development organisation in Africa and accounts for about 10% of the entire African R&D budget. It has a staff of approximately 3,000 technical and scientific researchers, often working in multi-disciplinary teams. In 2002, Dr. Sibusiso Sibisi was appointed as the president and CEO of the CSIR

Pretoria has earned a reputation as being the centre of South Africa's Military and is home to several military facilities of the South African National Defence Force:

This complex is the headquarters to the South African Air Force.

A military complex that houses the following:

A military complex located on the corner of Patriot Street and Koraalboom Road that houses the following military headquarters:

This base is situated in the suburb of Salvokop and is divided into two parts:

Thaba Tshwane is a large military area South-West of the Pretoria Central Business District and North of Air Force Base Swartkop. It is the Headquarters of several Army units-

The military base also houses the 1 Military Hospital and the Military Police School. Within Thaba Tshwane a facility known as "TEK Base" exists which houses its own units-

The Wonderboom Military Base is located adjacent to the Wonderboom Airport and is the headquarters of the South African Army Signals Formation. It also houses the School of Signals, 1 Signal Regiment, 2 Signal Regiment, 3 Electronic Workshop, 4 Signal Regiment and 5 Signal Regiment.

The South African Air Force College, the South African Military Health Service School for Military Health Training and the South African Army College are situated in the Thaba Tshwane Military Base and are used to train Commissioned and Non-commissioned Officers to perform effectively in combat/command roles in the various branches of the South African National Defence Force. The South African Defence Intelligence College is also located in the Sterrewag Suburb north of Air Force Base Waterkloof.

While technically not within the city limits of Pretoria, Air Force Base Swartkop and Air Force Base Waterkloof are often used for defence related matters within the city. These may include aerial military transport duties within the city, aerospace monitoring and defence as well as VIP transport to and from the city.

On 26 May 2005 the South African Geographical Names Council (SAGNC), which is linked to the Directorate of Heritage in the Department of Arts and Culture, approved changing the name of Pretoria to Tshwane, which is already the name of the Metropolitan Municipality in which Pretoria, and a number of surrounding towns are located. Although the name change was approved by the SAGNC, it has not yet been approved by the Minister of Arts and Culture. The matter is currently under consideration while he has requested further research on the matter. Should the Minister approve the name change, the name will be published in the Government Gazette, giving the public opportunity to comment on the matter. The Minister can then refer that public response back to the SAGNC, before presenting his recommendation before parliament, who will vote on the change. Various public interest groups have warned that the name change will be challenged in court, should the minister approve the renaming. The long process involved made it unlikely the name would change anytime soon, if ever, even assuming the Minister had approved the change in early 2006.

The Tshwane Metro Council has advertised "Tshwane" as "Africa's leading capital city" since the name change was approved by the SAGNC in 2005. This has led to further controversy, however, as the name of the city had not yet been changed officially, and the council was, at best, acting prematurely. Following a complaint lodged with the Advertising Standards Authority (ASA), it was ruled that such advertisements are deliberately misleading and should be withdrawn from all media. Despite the rulings of the ASA, Tshwane Metro Council failed to discontinue their "City of Tshwane" advertisements. As a result, the ASA requested that Tshwane Metro pay for advertisements in which it admits that it has misled the public. Refusing to abide by the ASA's request, the Metro Council was banned consequently from placing any advertisements in the South African media that refer to Tshwane as the capital. ASA may still place additional sanctions on the Metro Council that would prevent it from placing any advertisements in the South African media, including council notices and employment vacancies.

After the ruling, the Metro Council continued to place "Tshwane" advertisements, but placed them on council-owned advertising boards and busstops throughout the municipal area. In August 2007, an internal memo was leaked to the media in which the Tshwane mayor sought advice from the premier of Gauteng on whether the municipality could be called the "City of Tshwane" instead of just "Tshwane". This could increase confusion about the distinction between the city of Pretoria and the municipality of Tshwane.

In early 2010 it was again rumoured that the South African government would make a decision regarding the name, however, a media briefing regarding name changes, where it may have been discussed, was cancelled shortly before taking place. Rumours of the name change provoked outrage from Afrikaner civil rights and political groups. It later emerged that the registration of the municipality as a geographic place had been published in the government gazette as it had been too late to withdraw the name from the publication, but it was announced that the name had been withdrawn, pending "further work" by officials. The following week, the registration of "Tshwane" was officially withdrawn in the Government Gazette. The retraction had reportedly been ordered at the behest of the Deputy President of South Africa Kgalema Motlanthe, acting on behalf of President Jacob Zuma, as minister of Arts and Culture Lulu Xingwana had acted contrary to the position of the ANC, which is that Pretoria and the municipality are separate entities, which was subsequently articulated by ANC secretary general Gwede Mantashe.

In March 2010, the "Tshwane Royal House Committee", claiming to be descendants of Chief Tshwane, called for the name to be changed, and for the descendants of Chief Tshwane to be recognised, and to be made part of the administration of the municipality.

According to comments made by Mayor Kgosientso Ramokgopa in late 2011, the change would occur in 2012. However, there remained considerable uncertainty about the issue.

, the proposed name change has not occurred.

Pretoria is twinned with:









</doc>
<doc id="25004" url="https://en.wikipedia.org/wiki?curid=25004" title="Psychiatrist">
Psychiatrist

A psychiatrist is a physician who specializes in psychiatry, the branch of medicine devoted to the diagnosis, prevention, study, and treatment of mental disorders. Psychiatrists are medical doctors, unlike psychologists, and must evaluate patients to determine whether their symptoms are the result of a physical illness, a combination of physical and mental ailments, or strictly psychiatric. A psychiatrist usually works as the clinical leader of the multi-disciplinary team, which may comprise psychologists, social workers, occupational therapists and nursing staff. Psychiatrists have broad training in a bio-psycho-social approach to assessment and management of mental illness.

As part of the clinical assessment process, psychiatrists may employ a mental status examination; a physical examination; brain imaging such as a computerized tomography (CT), magnetic resonance imaging (MRI), or positron emission tomography (PET) scan; and blood testing. Psychiatrists prescribe medicine, and may also use psychotherapy, although the vast majority do medical management and refer to a psychologist or other specialized therapist for weekly to bi-monthly psychotherapy.

The field of psychiatry has many subspecialties (also known as fellowships) that require additional training which are certified by the American Board of Psychiatry and Neurology (ABPN) and require Maintenance of Certification Program (MOC) to continue. These include the following: 

Further, other specialties that exist include:

The United Council for Neurologic Subspecialties in the United States offers certification and fellowship program accreditation in the subspecialty 'Behavioral Neurology and Neuropsychiatry' (BNNP) - which is open to both neurologists and psychiatrists.

Some psychiatrists specialize in helping certain age groups. Pediatric psychiatry is the area of the profession working with children in addressing psychological problems. Psychiatrists specializing in geriatric psychiatry work with the elderly and are called geriatric psychiatrists or geropsychiatrists. Those who practice psychiatry in the workplace are called occupational psychiatrists in the United States and occupational psychology is the name used for the most similar discipline in the UK. Psychiatrists working in the courtroom and reporting to the judge and jury, in both criminal and civil court cases, are called forensic psychiatrists, who also treat mentally disordered offenders and other patients whose condition is such that they have to be treated in secure units.

Other psychiatrists and mental health professionals in the field of psychiatry may also specialize in psychopharmacology, psychotherapy, psychiatric genetics, neuroimaging, dementia-related disorders such as Alzheimer's disease, attention deficit hyperactivity disorder (ADHD), sleep medicine, pain medicine, palliative medicine, eating disorders, sexual disorders, women's health, global mental health, early psychosis intervention, mood disorders, and anxiety disorders such as obsessive–compulsive disorder (OCD) and posttraumatic stress disorder (PTSD).

Psychiatrists work in a wide variety of settings. Some are full-time medical researchers, many see patients in private medical practices, consult liaison psychiatrists see patients in hospital settings where psychiatric and other medical conditions interact.

While requirements to become a psychiatrist differ from country to country, all require a medical degree.

In the U.S. and Canada one must first attain the degree of M.D. or D.O., followed by practice as a psychiatric resident for another four years (five years in Canada). This extended period involves comprehensive training in psychiatric diagnosis, psychopharmacology, medical care issues, and psychotherapies. All accredited psychiatry residencies in the United States require proficiency in cognitive-behavioral, brief, psychodynamic, and supportive psychotherapies. Psychiatry residents are required to complete at least four post-graduate months of internal medicine or pediatrics, plus a minimum of two months of neurology during their first year of residency, referred to as an "internship". After completing their training, psychiatrists are eligible to take a specialty board examination to become board-certified. The total amount of time required to complete educational and training requirements in the field of psychiatry in the United States is twelve years after high school. Subspecialists in child and adolescent psychiatry are required to complete a two-year fellowship program, the first year of which can run concurrently with the fourth year of the general psychiatry residency program. This adds one to two years of training.

In the United Kingdom, psychiatrists must hold a medical degree. These degrees are often abbreviated MB BChir, MB BCh, MB ChB, BM BS, or MB BS. Following this, the individual will work as a Foundation House Officer for two additional years in the UK, or one year as Intern in the Republic of Ireland to achieve registration as a basic medical practitioner. Training in psychiatry can then begin and it is taken in two parts: three years of Basic Specialist Training culminating in the MRCPsych exam followed by three years of Higher Specialist Training, referred to as "ST4-6" in the UK and "Senior Registrar Training" in the Republic of Ireland. Candidates with MRCPsych degree and complete basic training must reinterview for higher specialist training. At this stage, the development of speciality interests such as forensic, child/adolescent take place. At the end of 3 years of higher specialist training, candidates are awarded a CCT (UK) or CCST (Ireland), both meaning Certificate of Completion of (Specialist) Training. At this stage, the psychiatrist can register as a specialist and the qualification of CC(S)T is recognized in all EU/EEA states. As such, training in the UK and Ireland is considerably longer than in the US or Canada and frequently takes around 8–9 years following graduation from medical school. Those with a CC(S)T will be able to apply for Consultant posts. Those with training from outside the EU/EEA should consult local/native medical boards to review their qualifications and eligibility for equivalence recognition (for example, those with a US residency and ABPN qualification).

In the Netherlands one must complete medical school after which one is certified as a medical doctor. After a strict selection program one can specialize in psychiatry: a 4.5 year specialization. During this specialization, the resident has to do a 6-month residency in the field of social psychiatry, a 12-month residency in a field of their own choice (which can be child psychiatry, forensic psychiatry, somatic medicine or medical research). To become an adolescent psychiatrist, one has to do an extra specialization period of 2 more years. In short this means that it takes at least 10.5 years of study to become a psychiatrist which can go up to 12.5 years if one becomes a children's and adolescent psychiatrist.

In India MBBS degree is the basic qualification needed to do Psychiatry. After completing MBBS (including internship) one can attend various PG Medical Entrance Exams and take MD in psychiatry which is a 3-year course. Diploma Course in Psychiatry or DNB Psychiatry can also be taken to become a Psychiatrist.

In Pakistan one must complete basic medical education, an MBBS, then get registered with Pakistan Medical and Dental Council as a General Practitioner after one year mandatory internship, House Job. After registration with PMDC, one has to go for FCPS-I exam, after that four-year training in Psychiatry under College of Physicians and Surgeons Pakistan. Training includes rotations in General Medicine, Neurology, and Clinical Psychology for 3 months each, during first two years. There is a mid-exam IMM (Intermediate Module) and a final exam after 4 years.


Pass the Casc (2012, 2018) by Dr Seshni Moodliar for the CASC MRCPsych exam

</doc>
<doc id="25005" url="https://en.wikipedia.org/wiki?curid=25005" title="Peano axioms">
Peano axioms

In mathematical logic, the Peano axioms, also known as the Dedekind–Peano axioms or the Peano postulates, are axioms for the natural numbers presented by the 19th century Italian mathematician Giuseppe Peano. These axioms have been used nearly unchanged in a number of metamathematical investigations, including research into fundamental questions of whether number theory is consistent and complete.

The need to formalize arithmetic was not well appreciated until the work of Hermann Grassmann, who showed in the 1860s that many facts in arithmetic could be derived from more basic facts about the successor operation and induction. In 1881, Charles Sanders Peirce provided an axiomatization of natural-number arithmetic. In 1888, Richard Dedekind proposed another axiomatization of natural-number arithmetic, and in 1889, Peano published a simplified version of them as a collection of axioms in his book, "The principles of arithmetic presented by a new method" ().

The Peano axioms contain three types of statements. The first axiom asserts the existence of at least one member of the set of natural numbers. The next four are general statements about equality; in modern treatments these are often not taken as part of the Peano axioms, but rather as axioms of the "underlying logic". The next three axioms are first-order statements about natural numbers expressing the fundamental properties of the successor operation. The ninth, final axiom is a second order statement of the principle of mathematical induction over the natural numbers. A weaker first-order system called Peano arithmetic is obtained by explicitly adding the addition and multiplication operation symbols and replacing the second-order induction axiom with a first-order axiom schema.

When Peano formulated his axioms, the language of mathematical logic was in its infancy. The system of logical notation he created to present the axioms did not prove to be popular, although it was the genesis of the modern notation for set membership (∈, which comes from Peano's ε) and implication (⊃, which comes from Peano's reversed 'C'.) Peano maintained a clear distinction between mathematical and logical symbols, which was not yet common in mathematics; such a separation had first been introduced in the "Begriffsschrift" by Gottlob Frege, published in 1879. Peano was unaware of Frege's work and independently recreated his logical apparatus based on the work of Boole and Schröder.

The Peano axioms define the arithmetical properties of "natural numbers", usually represented as a set N or formula_1 The non-logical symbols for the axioms consist of a constant symbol 0 and a unary function symbol "S".

The first axiom states that the constant 0 is a natural number:

The next four axioms describe the equality relation. Since they are logically valid in first-order logic with equality, they are not considered to be part of "the Peano axioms" in modern treatments.

The remaining axioms define the arithmetical properties of the natural numbers. The naturals are assumed to be closed under a single-valued "successor" function "S".

Peano's original formulation of the axioms used 1 instead of 0 as the "first" natural number. This choice is arbitrary, as axiom 1 does not endow the constant 0 with any additional properties. However, because 0 is the additive identity in arithmetic, most modern formulations of the Peano axioms start from 0. Axioms 1, 6, 7, 8 define a unary representation of the intuitive notion of natural numbers: the number 1 can be defined as "S"(0), 2 as "S"("S"(0)), etc. However, considering the notion of natural numbers as being defined by these axioms, axioms 1, 6, 7, 8 do not imply that the successor function generates all the natural numbers different from 0. Put differently, they do not guarantee that every natural number other than zero must succeed some other natural number.

The intuitive notion that each natural number can be obtained by applying "successor" sufficiently often to zero requires an additional axiom, which is sometimes called the "axiom of induction".

The induction axiom is sometimes stated in the following form:
In Peano's original formulation, the induction axiom is a second-order axiom. It is now common to replace this second-order principle with a weaker first-order induction scheme. There are important differences between the second-order and first-order formulations, as discussed in the section below.

The Peano axioms can be augmented with the operations of addition and multiplication and the usual total (linear) ordering on N. The respective functions and relations are constructed in set theory or second-order logic, and can be shown to be unique using the Peano axioms.

Addition is a function that maps two natural numbers (two elements of N) to another one. It is defined recursively as:

For example:

The structure is a commutative monoid with identity element 0. is also a cancellative magma, and thus embeddable in a group. The smallest group embedding N is the integers.

Similarly, multiplication is a function mapping two natural numbers to another one. Given addition, it is defined recursively as:

It is easy to see that "S"(0) (or "1", in the familiar language of decimal representation) is the multiplicative right identity:

To show that "S"(0) is also the multiplicative left identity requires the induction axiom due to the way multiplication is defined:


Therefore, by the induction axiom "S"(0) is the multiplicative left identity of all natural numbers. Moreover, it can be shown that multiplication distributes over addition:

Thus, is a commutative semiring.

The usual total order relation ≤ on natural numbers can be defined as follows, assuming 0 is a natural number:

This relation is stable under addition and multiplication: for formula_5, if , then:


Thus, the structure is an ordered semiring; because there is no natural number between 0 and 1, it is a discrete ordered semiring.

The axiom of induction is sometimes stated in the following form that uses a stronger hypothesis, making use of the order relation "≤":

This form of the induction axiom, called "strong induction", is a consequence of the standard formulation, but is often better suited for reasoning about the ≤ order. For example, to show that the naturals are well-ordered—every nonempty subset of N has a least element—one can reason as follows. Let a nonempty be given and assume "X" has no least element.


Thus, by the strong induction principle, for every , . Thus, , which contradicts "X" being a nonempty subset of N. Thus "X" has a least element.

All of the Peano axioms except the ninth axiom (the induction axiom) are statements in first-order logic. The arithmetical operations of addition and multiplication and the order relation can also be defined using first-order axioms. The axiom of induction is in second-order, since it quantifies over predicates (equivalently, sets of natural numbers rather than natural numbers), but it can be transformed into a first-order "axiom schema" of induction. Such a schema includes one axiom per predicate definable in the first-order language of Peano arithmetic, making it weaker than the second-order axiom. The reason that it is weaker is that the number of predicates in first-order language is countable, whereas the number of sets of natural numbers is uncountable. Thus, there exist sets that cannot be described in first-order language (in fact, most sets have this property).

First-order axiomatizations of Peano arithmetic have another technical limitation. In second-order logic, it is possible to define the addition and multiplication operations from the successor operation, but this cannot be done in the more restrictive setting of first-order logic. Therefore, the addition and multiplication operations are directly included in the signature of Peano arithmetic, and axioms are included that relate the three operations to each other.

The following list of axioms (along with the usual axioms of equality), which contains six of the seven axioms of Robinson arithmetic, is sufficient for this purpose:


In addition to this list of numerical axioms, Peano arithmetic contains the induction schema, which consists of a recursively enumerable set of axioms. For each formula in the language of Peano arithmetic, the first-order induction axiom for "φ" is the sentence

where formula_13 is an abbreviation for "y"...,"y". The first-order induction schema includes every instance of the first-order induction axiom, that is, it includes the induction axiom for every formula "φ".

There are many different, but equivalent, axiomatizations of Peano arithmetic. While some axiomatizations, such as the one just described, use a signature that only has symbols for 0 and the successor, addition, and multiplications operations, other axiomatizations use the language of ordered semirings, including an additional order relation symbol. One such axiomatization begins with the following axioms that describe a discrete ordered semiring.

The theory defined by these axioms is known as PA; the theory PA is obtained by adding the first-order induction schema. An important property of PA is that any structure formula_29 satisfying this theory has an initial segment (ordered by formula_30) isomorphic to formula_31. Elements in that segment are called standard elements, while other elements are called nonstandard elements.

A model of the Peano axioms is a triple , where N is a (necessarily infinite) set, and satisfies the axioms above. Dedekind proved in his 1888 book, "The Nature and Meaning of Numbers" (, i.e., “What are the numbers and what are they good for?”) that any two models of the Peano axioms (including the second-order induction axiom) are isomorphic. In particular, given two models and of the Peano axioms, there is a unique homomorphism satisfying

and it is a bijection. This means that the second-order Peano axioms are categorical. This is not the case with any first-order reformulation of the Peano axioms, however.

The Peano axioms can be derived from set theoretic constructions of the natural numbers and axioms of set theory such as ZF. The standard construction of the naturals, due to John von Neumann, starts from a definition of 0 as the empty set, ∅, and an operator "s" on sets defined as:

The set of natural numbers N is defined as the intersection of all sets closed under "s" that contain the empty set. Each natural number is equal (as a set) to the set of natural numbers less than it:

and so on. The set N together with 0 and the successor function satisfies the Peano axioms.

Peano arithmetic is equiconsistent with several weak systems of set theory. One such system is ZFC with the axiom of infinity replaced by its negation. Another such system consists of general set theory (extensionality, existence of the empty set, and the axiom of adjunction), augmented by an axiom schema stating that a property that holds for the empty set and holds of an adjunction whenever it holds of the adjunct must hold for all sets.

The Peano axioms can also be understood using category theory. Let "C" be a category with terminal object 1, and define the category of pointed unary systems, US("C") as follows:


Then "C" is said to satisfy the Dedekind–Peano axioms if US("C") has an initial object; this initial object is known as a natural number object in "C". If is this initial object, and is any other object, then the unique map is such that

This is precisely the recursive definition of 0 and "S".

Although the usual natural numbers satisfy the axioms of PA, there are other models as well (called "non-standard models"); the compactness theorem implies that the existence of nonstandard elements cannot be excluded in first-order logic. The upward Löwenheim–Skolem theorem shows that there are nonstandard models of PA of all infinite cardinalities. This is not the case for the original (second-order) Peano axioms, which have only one model, up to isomorphism. This illustrates one way the first-order system PA is weaker than the second-order Peano axioms.

When interpreted as a proof within a first-order set theory, such as ZFC, Dedekind's categoricity proof for PA shows that each model of set theory has a unique model of the Peano axioms, up to isomorphism, that embeds as an initial segment of all other models of PA contained within that model of set theory. In the standard model of set theory, this smallest model of PA is the standard model of PA; however, in a nonstandard model of set theory, it may be a nonstandard model of PA. This situation cannot be avoided with any first-order formalization of set theory.

It is natural to ask whether a countable nonstandard model can be explicitly constructed. The answer is affirmative as Skolem in 1933 provided an explicit construction of such a nonstandard model. On the other hand, Tennenbaum's theorem, proved in 1959, shows that there is no countable nonstandard model of PA in which either the addition or multiplication operation is computable. This result shows it is difficult to be completely explicit in describing the addition and multiplication operations of a countable nonstandard model of PA. There is only one possible order type of a countable nonstandard model. Letting "ω" be the order type of the natural numbers, "ζ" be the order type of the integers, and "η" be the order type of the rationals, the order type of any countable nonstandard model of PA is , which can be visualized as a copy of the natural numbers followed by a dense linear ordering of copies of the integers.

A cut in a nonstandard model "M" is a nonempty subset "C" of "M" so that "C" is downward closed ("x" < "y" and "y" ∈ "C" ⇒ "x" ∈ "C") and "C" is closed under successor. A proper cut is a cut that is a proper subset of "M". Each nonstandard model has many proper cuts, including one that corresponds to the standard natural numbers. However, the induction scheme in Peano arithmetic prevents any proper cut from being definable. The overspill lemma, first proved by Abraham Robinson, formalizes this fact.

When the Peano axioms were first proposed, Bertrand Russell and others agreed that these axioms implicitly defined what we mean by a "natural number". Henri Poincaré was more cautious, saying they only defined natural numbers if they were "consistent"; if there is a proof that starts from just these axioms and derives a contradiction such as 0 = 1, then the axioms are inconsistent, and don't define anything. In 1900, David Hilbert posed the problem of proving their consistency using only finitistic methods as the second of his twenty-three problems. In 1931, Kurt Gödel proved his second incompleteness theorem, which shows that such a consistency proof cannot be formalized within Peano arithmetic itself.

Although it is widely claimed that Gödel's theorem rules out the possibility of a finitistic consistency proof for Peano arithmetic, this depends on exactly what one means by a finitistic proof. Gödel himself pointed out the possibility of giving a finitistic consistency proof of Peano arithmetic or stronger systems by using finitistic methods that are not formalizable in Peano arithmetic, and in 1958, Gödel published a method for proving the consistency of arithmetic using type theory. In 1936, Gerhard Gentzen gave a proof of the consistency of Peano's axioms, using transfinite induction up to an ordinal called ε. Gentzen explained: "The aim of the present paper is to prove the consistency of elementary number theory or, rather, to reduce the question of consistency to certain fundamental principles". Gentzen's proof is arguably finitistic, since the transfinite ordinal ε can be encoded in terms of finite objects (for example, as a Turing machine describing a suitable order on the integers, or more abstractly as consisting of the finite trees, suitably linearly ordered). Whether or not Gentzen's proof meets the requirements Hilbert envisioned is unclear: there is no generally accepted definition of exactly what is meant by a finitistic proof, and Hilbert himself never gave a precise definition.

The vast majority of contemporary mathematicians believe that Peano's axioms are consistent, relying either on intuition or the acceptance of a consistency proof such as Gentzen's proof. A small number of philosophers and mathematicians, some of whom also advocate ultrafinitism, reject Peano's axioms because accepting the axioms amounts to accepting the infinite collection of natural numbers. In particular, addition (including the successor function) and multiplication are assumed to be total. Curiously, there are self-verifying theories that are similar to PA but have subtraction and division instead of addition and multiplication, which are axiomatized in such a way to avoid proving sentences that correspond to the totality of addition and multiplication, but which are still able to prove all true formula_40 theorems of PA, and yet can be extended to a consistent theory that proves its own consistency (stated as the non-existence of a Hilbert-style proof of "0=1").





</doc>
<doc id="25006" url="https://en.wikipedia.org/wiki?curid=25006" title="Procyon">
Procyon

Procyon is the brightest object in the constellation of Canis Minor and usually the eighth-brightest star in the night sky with a visual apparent magnitude of 0.34. It has the Bayer designation α Canis Minoris, which is Latinised to Alpha Canis Minoris, and abbreviated α CMi or Alpha CMi, respectively. As determined by the European Space Agency Hipparcos astrometry satellite, this system lies at a distance of just , and is therefore one of Earth's nearest stellar neighbours.

A binary star system, Procyon consists of a white-hued main-sequence star of spectral type F5 IV–V, designated component A, in orbit with a faint white dwarf companion of spectral type DQZ, named Procyon B. The pair orbit each other with a period of 40.8 years and an eccentricity of 0.4.

Procyon is usually the eighth-brightest star in the night sky, culminating at midnight on January 14. It forms one of the three vertices of the Winter Triangle asterism, in combination with Sirius and Betelgeuse. The prime period for evening viewing of Procyon is in late winter in the northern hemisphere.

It has a color index of 0.42, and its hue has been described as having a faint yellow tinge to it.

Procyon is a binary star system with a bright primary component, Procyon A, having an apparent magnitude of 0.34, and a faint companion, Procyon B, at magnitude 10.7. The pair orbit each other with a period of 40.82 years along an elliptical orbit with an eccentricity of 0.407, more eccentric than Mercury's. The plane of their orbit is inclined at an angle of 31.1° to the line of sight with the Earth. The average separation of the two components is 15.0 AU, a little less than the distance between Uranus and the Sun, though the eccentric orbit carries them as close as 8.9 AU and as far as 21.0 AU.

The primary has a stellar classification of F5IV–V, indicating that it is a late-stage F-type main-sequence star. Procyon A is bright for its spectral class, suggesting that it is evolving into a subgiant that has nearly fused its hydrogen core into helium, after which it will expand as the nuclear reactions move outside the core. As it continues to expand, the star will eventually swell to about 80 to 150 times its current diameter and become a red or orange color. This will probably happen within 10 to 100 million years.

The effective temperature of the stellar atmosphere is an estimated 6,530 K, giving Procyon A a white hue. It is 1.5 times the solar mass (), twice the solar radius (), and has 7 times the Sun's luminosity (). Both the core and the envelope of this star are convective; the two regions being separated by a wide radiation zone.

In late June 2004, Canada's orbital MOST satellite telescope carried out a 32-day survey of Procyon A. The continuous optical monitoring was intended to confirm solar-like oscillations in its brightness observed from Earth and to permit asteroseismology. No oscillations were detected and the authors concluded that the theory of stellar oscillations may need to be reconsidered. However, others argued that the non-detection was consistent with published ground-based radial velocity observations of solar-like oscillations.

Photometric measurements from the NASA Wide Field Infrared Explorer (WIRE) satellite from 1999 and 2000 showed evidence of granulation (convection near the surface of the star) and solar-like oscillations. Unlike the MOST result, the variation seen in the WIRE photometry was in agreement with radial velocity measurements from the ground.

Like Sirius B, Procyon B is a white dwarf that was inferred from astrometric data long before it was observed. Its existence had been postulated by German astronomer Friedrich Bessel as early as 1844, and, although its orbital elements had been calculated by his countryman Arthur Auwers in 1862 as part of his thesis, Procyon B was not visually confirmed until 1896 when John Martin Schaeberle observed it at the predicted position using the 36-inch refractor at Lick Observatory. It is more difficult to observe from Earth than Sirius B, due to a greater apparent magnitude difference and smaller angular separation from its primary.

At , Procyon B is considerably less massive than Sirius B; however, the peculiarities of degenerate matter ensure that it is larger than its more famous neighbor, with an estimated radius of 8,600 km, versus 5,800 km for Sirius B. The radius agrees with white dwarf models that assume a carbon core. It has a stellar classification of DQZ, having a helium-dominated atmosphere with traces of heavy elements. For reasons that remain unclear, the mass of Procyon B is unusually low for a white dwarf star of its type. With a surface temperature of 7,740 K, it is also much cooler than Sirius B; this is a testament to its lesser mass and greater age. The mass of the progenitor star for Procyon B was about and it came to the end of its life some  billion years ago, after a main-sequence lifetime of  million years.

Attempts to detect X-ray emission from Procyon with nonimaging, soft X-ray–sensitive detectors prior to 1975 failed. Extensive observations of Procyon were carried out with the Copernicus and TD-1A satellites in the late 1970s. The X-ray source associated with Procyon AB was observed on April 1, 1979, with the Einstein Observatory high-resolution imager (HRI). The HRI X-ray pointlike source location is ~4" south of Procyon A, on the edge of the 90% confidence error circle, indicating identification with Procyon A rather than Procyon B which was located about 5" north of Procyon A (about 9" from the X-ray source location).
"α Canis Minoris" (Latinised to "Alpha Canis Minoris") is the star's Bayer designation.

The name "Procyon" comes from the Ancient Greek (""), meaning "before the dog", since it precedes the "Dog Star" Sirius as it travels across the sky due to Earth's rotation. (Although Procyon has a greater right ascension, it also has a more northerly declination, which means it will rise above the horizon earlier than Sirius from most northerly latitudes.) In Greek mythology, Procyon is associated with Maera, a hound belonging to Erigone, daughter of Icarius of Athens. In 2016, the International Astronomical Union organized a Working Group on Star Names (WGSN) to catalog and standardize proper names for stars. The WGSN's first bulletin of July 2016 included a table of the first two batches of names approved by the WGSN; which included "Procyon" for the star α Canis Minoris A.

The two dog stars are referred to in the most ancient literature and were venerated by the Babylonians and the Egyptians, In Babylonian mythology, Procyon was known as Nangar (the Carpenter), an aspect of Marduk, involved in constructing and organising the celestial sky.

The constellations in Macedonian folklore represented agricultural items and animals, reflecting their village way of life. To them, Procyon and Sirius were "Volci" "the wolves", circling hungrily around Orion which depicted a plough with oxen.

Rarer names are the Latin translation of Procyon, "Antecanis", and the Arabic-derived names "Al Shira" and "Elgomaisa". Medieval astrolabes of England and Western Europe used a variant of this, "Algomeiza/Algomeyza". "Al Shira" derives from ', "the Syrian sign" (the other sign being Sirius; "Syria" is supposedly a reference to its northern location relative to Sirius); "Elgomaisa" derives from ' "the bleary-eyed (woman)", in contrast to "the teary-eyed (woman)", which is Sirius. (See Gomeisa.) At the same time this name is synonymous with the Turkish name "Rumeysa", and it is a commonly used name in Turkey.

In Chinese, (), meaning "South River", refers to an asterism consisting of Procyon, ε Canis Minoris and β Canis Minoris. Consequently, Procyon itself is known as (, ). It is part of the Vermilion Bird.

The Hawaiians saw Procyon as part of an asterism "Ke ka o Makali'i" ("the canoe bailer of Makali'i") that helped them navigate at sea. Called "Puana" ("blossom"), it formed this asterism with Capella, Sirius, Castor, and Pollux. In Tahitian lore, Procyon was one of the pillars propping up the sky, known as "Anâ-tahu'a-vahine-o-toa-te-manava" ("star-the-priestess-of-brave-heart"), the pillar for elocution. The Maori knew the star as "Puangahori".

Procyon appears on the flag of Brazil, symbolising the state of Amazonas.
The Kalapalo people of Mato Grosso state in Brazil called Procyon and Canopus "Kofongo" ("Duck"), with Castor and Pollux representing his hands. The asterism's appearance signified the coming of the rainy season and increase in food staple manioc, used at feasts to feed guests.

Known as "Sikuliarsiujuittuq" to the Inuit, Procyon was quite significant in their astronomy and mythology. Its eponymous name means "the one who never goes onto the newly formed sea-ice", and refers to a man who stole food from his village's hunters because he was too obese to hunt on ice. He was killed by the other hunters who convinced him to go on the sea ice. Procyon received this designation because it typically appears red (though sometimes slightly greenish) as it rises during the Arctic winter; this red color was associated with Sikuliarsiujuittuq's bloody end.

Were the Sun to be observed from this star system, it would appear to be a magnitude 2.55 star in the constellation Aquila with the exact opposite coordinates at right ascension , declination . It would be as bright as β Scorpii is in our sky. Canis Minor would obviously be missing its brightest star.

Procyon's closest neighboring star is Luyten's Star, about away, and the latter would appear as a visual magnitude 2.7 star in the night sky of a hypothetical planet orbiting Procyon.




</doc>
<doc id="25008" url="https://en.wikipedia.org/wiki?curid=25008" title="Prisoner of war">
Prisoner of war

A prisoner of war (POW) is a non-combatant—whether a military member, an irregular military fighter, or a civilian—who is held captive by a belligerent power during or immediately after an armed conflict. The earliest recorded usage of the phrase "prisoner of war" dates back to 1610.

Belligerents hold prisoners of war in custody for a range of legitimate and illegitimate reasons, such as isolating them from enemy combatants still in the field (releasing and repatriating them in an orderly manner after hostilities), demonstrating military victory, punishing them, prosecuting them for war crimes, exploiting them for their labour, recruiting or even conscripting them as their own combatants, collecting military and political intelligence from them, or indoctrinating them in new political or religious beliefs.

For most of human history, depending on the culture of the victors, enemy combatants on the losing side in a battle who had surrendered and been taken as prisoners of war could expect to be either slaughtered or enslaved. Early Roman gladiators could be prisoners of war, categorised according to their ethnic roots as Samnites, Thracians, and Gauls ("Galli"). Homer's "Iliad" describes Greek and Trojan soldiers offering rewards of wealth to opposing forces who have defeated them on the battlefield in exchange for mercy, but their offers are not always accepted; see Lycaon for example.

Typically, victors made little distinction between enemy combatants and enemy civilians, although they were more likely to spare women and children. Sometimes the purpose of a battle, if not of a war, was to capture women, a practice known as "raptio"; the Rape of the Sabines involved, according to tradition, a large mass-abduction by the founders of Rome. Typically women had no rights, and were held legally as chattels.

In the fourth century AD, Bishop Acacius of Amida, touched by the plight of Persian prisoners captured in a recent war with the Roman Empire, who were held in his town under appalling conditions and destined for a life of slavery, took the initiative in ransoming them by selling his church's precious gold and silver vessels and letting them return to their country. For this he was eventually canonized.

During Childeric's siege and blockade of Paris in 464, the nun Geneviève (later canonised as the city's patron saint) pleaded with the Frankish king for the welfare of prisoners of war and met with a favourable response. Later, Clovis I liberated captives after Genevieve urged him to do so.

Many French prisoners of war were killed during the Battle of Agincourt in 1415. This was done in retaliation for the French killing of the boys and other non-combatants handling the baggage and equipment of the army, and because the French were attacking again and Henry was afraid that they would break through and free the prisoners to fight again.

In the later Middle Ages, a number of religious wars aimed to not only defeat but eliminate their enemies. In Christian Europe, the extermination of heretics was considered desirable. Examples include the 13th century Albigensian Crusade and the Northern Crusades. When asked by a Crusader how to distinguish between the Catholics and Cathars once they'd taken the city of Béziers, the Papal Legate Arnaud Amalric famously replied, ""Kill them all, God will know His own"".

Likewise, the inhabitants of conquered cities were frequently massacred during the Crusades against the Muslims in the 11th and 12th centuries. Noblemen could hope to be ransomed; their families would have to send to their captors large sums of wealth commensurate with the social status of the captive.

In feudal Japan, there was no custom of ransoming prisoners of war, who were for the most part summarily executed.
The expanding Mongol Empire was famous for distinguishing between cities or towns that surrendered, where the population were spared but required to support the conquering Mongol army, and those that resisted, where their city was ransacked and destroyed, and all the population killed. In Termez, on the Oxus: ""all the people, both men and women, were driven out onto the plain, and divided in accordance with their usual custom, then they were all slain"".

The Aztecs were constantly at war with neighbouring tribes and groups, with the goal of this constant warfare being to collect live prisoners for sacrifice. For the re-consecration of Great Pyramid of Tenochtitlan in 1487, "between 10,000 and 80,400 persons" were sacrificed.

During the early Muslim conquests, Muslims routinely captured large number of prisoners. Aside from those who converted, most were ransomed or enslaved. Christians who were captured during the Crusades were usually either killed or sold into slavery if they could not pay a ransom. During his lifetime, Muhammad made it the responsibility of the Islamic government to provide food and clothing, on a reasonable basis, to captives, regardless of their religion; however if the prisoners were in the custody of a person, then the responsibility was on the individual. The freeing of prisoners was highly recommended as a charitable act. On certain occasions where Muhammad felt the enemy had broken a treaty with the Muslims, he ordered the mass execution of male prisoners, such as the Banu Qurayza. Females and children of this tribe were divided up as "ghanima" (spoils of war) by Muhammad.

The 1648 Peace of Westphalia, which ended the Thirty Years' War, established the rule that prisoners of war should be released without ransom at the end of hostilities and that they should be allowed to return to their homelands.
There also evolved the right of "parole", French for "discourse", in which a captured officer surrendered his sword and gave his word as a gentleman in exchange for privileges. If he swore not to escape, he could gain better accommodations and the freedom of the prison. If he swore to cease hostilities against the nation who held him captive, he could be repatriated or exchanged but could not serve against his former captors in a military capacity.

Early historical narratives of captured colonial Europeans, including perspectives of literate women captured by the indigenous peoples of North America, exist in some number. The writings of Mary Rowlandson, captured in the brutal fighting of King Philip's War, are an example. Such narratives enjoyed some popularity, spawning a genre of the captivity narrative, and had lasting influence on the body of early American literature, most notably through the legacy of James Fenimore Cooper's "The Last of the Mohicans". Some Native Americans continued to capture Europeans and use them both as labourers and bargaining chips into the 19th century; see for example John R. Jewitt, an Englishman who wrote a memoir about his years as a captive of the Nootka people on the Pacific Northwest coast from 1802 to 1805.

The earliest known purposely built prisoner-of-war camp was established at Norman Cross, England in 1797 to house the increasing number of prisoners from the French Revolutionary Wars and the Napoleonic Wars. The average prison population was about 5,500 men. The lowest number recorded was 3,300 in October 1804 and 6,272 on 10 April 1810 was the highest number of prisoners recorded in any official document. Norman Cross was intended to be a model depot providing the most humane treatment of prisoners of war. The British government went to great lengths to provide food of a quality at least equal to that available to locals. The senior officer from each quadrangle was permitted to inspect the food as it was delivered to the prison to ensure it was of sufficient quality. Despite the generous supply and quality of food, some prisoners died of starvation after gambling away their rations. Most of the men held in the prison were low-ranking soldiers and sailors, including midshipmen and junior officers, with a small number of privateers. About 100 senior officers and some civilians "of good social standing", mainly passengers on captured ships and the wives of some officers, were given "parole d'honneur" outside the prison, mainly in Peterborough although some further afield in Northampton, Plymouth, Melrose and Abergavenny. They were afforded the courtesy of their rank within English society. During the Battle of Leipzig both sides used the city's cemetery as lazaret and prisoner camp for around 6000 POWs who lived in the vaults and used the coffins for firewood. Food was scarce and prisoners resorted to eating horses, cats, dogs or even human flesh. The bad conditions inside the graveyard contributed to a city-wide epidemic after the battle.

The extensive period of conflict during the American Revolutionary War and Napoleonic Wars (1793–1815), followed by the Anglo-American War of 1812, led to the emergence of a cartel system for the exchange of prisoners, even while the belligerents were at war. A cartel was usually arranged by the respective armed service for the exchange of like-ranked personnel. The aim was to achieve a reduction in the number of prisoners held, while at the same time alleviating shortages of skilled personnel in the home country.

At the start of the civil war a system of paroles operated. Captives agreed not to fight until they were officially exchanged. Meanwhile, they were held in camps run by their own army where they were paid but not allowed to perform any military duties. The system of exchanges collapsed in 1863 when the Confederacy refused to exchange black prisoners. In the late summer of 1864, a year after the Dix–Hill Cartel was suspended; Confederate officials approached Union General Benjamin Butler, Union Commissioner of Exchange, about resuming the cartel and including the black prisoners. Butler contacted Grant for guidance on the issue, and Grant responded to Butler on 18 August 1864 with his now famous statement. He rejected the offer, stating in essence, that the Union could afford to leave their men in captivity, the Confederacy could not. After that about 56,000 of the 409,000 POWs died in prisons during the American Civil War, accounting for nearly 10% of the conflict's fatalities. Of the 45,000 Union prisoners of war confined in Camp Sumter, located near Andersonville, Georgia, 13,000 (28%) died. At Camp Douglas in Chicago, Illinois, 10% of its Confederate prisoners died during one cold winter month; and Elmira Prison in New York state, with a death rate of 25% (2,963), nearly equalled that of Andersonville.

During the 19th century, there were increased efforts to improve the treatment and processing of prisoners. As a result of these emerging conventions, a number of international conferences were held, starting with the Brussels Conference of 1874, with nations agreeing that it was necessary to prevent inhumane treatment of prisoners and the use of weapons causing unnecessary harm. Although no agreements were immediately ratified by the participating nations, work was continued that resulted in new conventions being adopted and becoming recognized as international law that specified that prisoners of war be treated humanely and diplomatically.

Chapter II of the Annex to the 1907 Hague Convention "IV – The Laws and Customs of War on Land" covered the treatment of prisoners of war in detail. These provisions were further expanded in the 1929 Geneva Convention on the Prisoners of War and were largely revised in the Third Geneva Convention in 1949.

Article 4 of the Third Geneva Convention protects captured military personnel, some guerrilla fighters, and certain civilians. It applies from the moment a prisoner is captured until he or she is released or repatriated. One of the main provisions of the convention makes it illegal to torture prisoners and states that a prisoner can only be required to give their name, date of birth, rank and service number (if applicable).

The ICRC has a special role to play, with regards to international humanitarian law, in restoring and maintaining family contact in times of war, in particular concerning the right of prisoners of war and internees to send and receive letters and cards (Geneva Convention (GC) III, art.71 and GC IV, art.107).

However, nations vary in their dedication to following these laws, and historically the treatment of POWs has varied greatly. During World War II, Imperial Japan and Nazi Germany (towards Soviet POWs and Western Allied commandos) were notorious for atrocities against prisoners of war. The German military used the Soviet Union's refusal to sign the Geneva Convention as a reason for not providing the necessities of life to Soviet POWs; and the Soviets similarly killed Axis prisoners or used them as slave labour. The Germans also routinely executed Western Allied commandos captured behind German lines per the Commando Order. North Korean and North and South Vietnamese forces routinely killed or mistreated prisoners taken during those conflicts.

To be entitled to prisoner-of-war status, captured persons must be lawful combatants entitled to combatant's privilege—which gives them immunity from punishment for crimes constituting lawful acts of war such as killing enemy combatants. To qualify under the Third Geneva Convention, a combatant must be part of a chain of command, wear a "fixed distinctive marking, visible from a distance", bear arms openly, and have conducted military operations according to the laws and customs of war. (The Convention recognizes a few other groups as well, such as "[i]nhabitants of a non-occupied territory, who on the approach of the enemy spontaneously take up arms to resist the invading forces, without having had time to form themselves into regular armed units".)

Thus, uniforms and badges are important in determining prisoner-of-war status; and "francs-tireurs", militias, insurgents, terrorists, saboteurs, mercenaries, and spies generally do not qualify because they do not always follow the laws and customs of war, and often don't wear any insignia. Therefore they fall under the category of unlawful combatants. In practice, these criteria are rarely interpreted strictly. Guerrillas, for example, usually do not wear a uniform or carry arms openly, but captured guerrillas are often granted POW status. 

The criteria are applied primarily to "international" armed conflicts; in civil wars, insurgents are often treated as traitors, terrorists or criminals by government forces and are sometimes executed on spot or tortured. However, in the American Civil War, both sides treated captured troops as POWs presumably out of reciprocity, although the Union regarded Confederate personnel as separatist rebels. However, guerrillas and other irregular combatants generally cannot expect to receive benefits from both civilian and military status simultaneously.

Under the Third Geneva Convention, prisoners of war (POW) must be:


In addition, if wounded or sick on the battlefield, the prisoner will receive help from the International Committee of the Red Cross.

When a country is responsible for breaches of prisoner of war rights, those accountable will be punished accordingly. An example of this is the Nuremberg and Tokyo Trials. German and Japanese military commanders were prosecuted for preparing and initiating a war of aggression, murder, ill treatment, and deportation of individuals, and genocide during World War II. Most were executed or sentenced to life in prison for their crimes.

The United States Military Code of Conduct was promulgated in 1955 via under President Dwight D. Eisenhower to serve as a moral code for United States service members who have been taken prisoner. It was created primarily in response to the breakdown of leadership and organization, specifically when U.S. forces were POWs during the Korean War.

When a military member is taken prisoner, the Code of Conduct reminds them that the chain of command is still in effect (the highest ranking service member eligible for command, regardless of service branch, is in command), and requires them to support their leadership. The Code of Conduct also requires service members to resist giving information to the enemy (beyond identifying themselves, that is, "name, rank, serial number"), receiving special favors or parole, or otherwise providing their enemy captors aid and comfort.

Since the Vietnam War, the official U.S. military term for enemy POWs is EPW (Enemy Prisoner of War). This name change was introduced in order to distinguish between enemy and U.S. captives.

In 2000, the U.S. military replaced the designation "Prisoner of War" for captured American personnel with "Missing-Captured". A January 2008 directive states that the reasoning behind this is since "Prisoner of War" is the international legal recognized status for such people there is no need for any individual country to follow suit. This change remains relatively unknown even among experts in the field and "Prisoner of War" remains widely used in the Pentagon which has a "POW/Missing Personnel Office" and awards the Prisoner of War Medal.

During World War I, about eight million men surrendered and were held in POW camps until the war ended. All nations pledged to follow the Hague rules on fair treatment of prisoners of war, and in general the POWs had a much higher survival rate than their peers who were not captured. Individual surrenders were uncommon; usually a large unit surrendered all its men. At Tannenberg 92,000 Russians surrendered during the battle. When the besieged garrison of Kaunas surrendered in 1915, 20,000 Russians became prisoners. Over half the Russian losses were prisoners as a proportion of those captured, wounded or killed. About 3.3 million men became prisoners.

The German Empire held 2.5 million prisoners; Russia held 2.9 million, and Britain and France held about 720,000, mostly gained in the period just before the Armistice in 1918. The US held 48,000. The most dangerous moment for POWs was the act of surrender, when helpless soldiers were sometimes mistakenly shot down. Once prisoners reached a POW camp conditions were better (and often much better than in World War II), thanks in part to the efforts of the International Red Cross and inspections by neutral nations.

There was however much harsh treatment of POWs in Germany, as recorded by the American ambassador to Germany (prior to America's entry into the war), James W. Gerard, who published his findings in "My Four Years in Germany". Even worse conditions are reported in the book "Escape of a Princess Pat" by the Canadian George Pearson. It was particularly bad in Russia, where starvation was common for prisoners and civilians alike; a quarter of the over 2 million POWs held there died. Nearly 375,000 of the 500,000 Austro-Hungarian prisoners of war taken by Russians perished in Siberia from smallpox and typhus. In Germany, food was short, but only 5% died.

The Ottoman Empire often treated prisoners of war poorly. Some 11,800 British soldiers, most of them Indians, became prisoners after the five-month Siege of Kut, in Mesopotamia, in April 1916. Many were weak and starved when they surrendered and 4,250 died in captivity.

During the Sinai and Palestine campaign 217 Australian and unknown numbers of British, New Zealand and Indian soldiers were captured by Ottoman Empire forces. About 50% of the Australian prisoners were light horsemen including 48 missing believed captured on 1 May 1918 in the Jordan Valley. Australian Flying Corps pilots and observers were captured in the Sinai Peninsula, Palestine and the Levant. One third of all Australian prisoners were captured on Gallipoli including the crew of the submarine AE2 which made a passage through the Dardanelles in 1915. Forced marches and crowded railway journeys preceded years in camps where disease, poor diet and inadequate medical facilities prevailed. About 25% of other ranks died, many from malnutrition, while only one officer died.

The most curious case came in Russia where the Czechoslovak Legion of Czechoslovak prisoners (from the Austro-Hungarian army): they were released in 1917, armed themselves, briefly culminating into a military and diplomatic force during the Russian Civil War.

At the end of the war in 1918 there were believed to be 140,000 British prisoners of war in Germany, including thousands of internees held in neutral Switzerland. The first British prisoners were released and reached Calais on 15 November. Plans were made for them to be sent via Dunkirk to Dover and a large reception camp was established at Dover capable of housing 40,000 men, which could later be used for demobilisation.

On 13 December 1918, the armistice was extended and the Allies reported that by 9 December 264,000 prisoners had been repatriated. A very large number of these had been released "en masse" and sent across Allied lines without any food or shelter. This created difficulties for the receiving Allies and many released prisoners died from exhaustion. The released POWs were met by cavalry troops and sent back through the lines in lorries to reception centres where they were refitted with boots and clothing and dispatched to the ports in trains.

Upon arrival at the receiving camp the POWs were registered and "boarded" before being dispatched to their own homes. All commissioned officers had to write a report on the circumstances of their capture and to ensure that they had done all they could to avoid capture. Each returning officer and man was given a message from King George V, written in his own hand and reproduced on a lithograph. It read as follows:
While the Allied prisoners were sent home at the end of the war, the same treatment was not granted to Central Powers prisoners of the Allies and Russia, many of whom had to serve as forced labour, e.g. in France, until 1920. They were released after many approaches by the ICRC to the Allied Supreme Council.

Historian Niall Ferguson, in addition to figures from Keith Lowe, tabulated the total death rate for POWs in World War II as follows:

The Empire of Japan, which had signed but never ratified the 1929 Geneva Convention on Prisoners of War, did not treat prisoners of war in accordance with international agreements, including provisions of the Hague Conventions, either during the Second Sino-Japanese War or during the Pacific War, because the Japanese viewed surrender as dishonorable. Moreover, according to a directive ratified on 5 August 1937 by Hirohito, the constraints of the Hague Conventions were explicitly removed on Chinese prisoners.

Prisoners of war from China, the United States, Australia, Britain, Canada, India, the Netherlands, New Zealand, and the Philippines held by the Japanese armed forces were subject to murder, beatings, summary punishment, brutal treatment, forced labour, medical experimentation, starvation rations, poor medical treatment and cannibalism. The most notorious use of forced labour was in the construction of the Burma–Thailand Death Railway. After 20 March 1943, the Imperial Navy was under orders to execute all prisoners taken at sea.

According to the findings of the Tokyo Tribunal, the death rate of Western prisoners was 27.1%, seven times that of POWs under the Germans and Italians. The death rate of Chinese was much higher. Thus, while 37,583 prisoners from the United Kingdom, Commonwealth, and Dominions, 28,500 from the Netherlands, and 14,473 from the United States were released after the surrender of Japan, the number for the Chinese was only 56. The 27,465 United States Army and United States Army Air Forces POWs in the Pacific Theater had a 40.4% death rate. The War Ministry in Tokyo issued an order at the end of the war to kill all surviving POWs.

No direct access to the POWs was provided to the International Red Cross. Escapes among Caucasian prisoners were almost impossible because of the difficulty of men of Caucasian descent hiding in Asiatic societies.

Allied POW camps and ship-transports were sometimes accidental targets of Allied attacks. The number of deaths which occurred when Japanese "hell ships"—unmarked transport ships in which POWs were transported in harsh conditions—were attacked by US Navy submarines was particularly high. Gavan Daws has calculated that "of all POWs who died in the Pacific War, one in three was killed on the water by friendly fire". Daves states that 10,800 of the 50,000 POWs shipped by the Japanese were killed at sea while Donald L. Miller states that "approximately 21,000 Allied POWs died at sea, about 19,000 of them killed by friendly fire."

Life in the POW camps was recorded at great risk to themselves by artists such as Jack Bridger Chalker, Philip Meninsky, Ashley George Old, and Ronald Searle. Human hair was often used for brushes, plant juices and blood for paint, and toilet paper as the "canvas". Some of their works were used as evidence in the trials of Japanese war criminals.

Female prisoners (detainees) at Changi prisoner of war camp in Singapore, bravely recorded their defiance in seemingly harmless prison quilt embroidery. 

Research into the conditions of the camps has been conducted by The Liverpool School of Tropical Medicine.

After the French armies surrendered in summer 1940, Germany seized two million French prisoners of war and sent them to camps in Germany. About one third were released on various terms. Of the remainder, the officers and non-commissioned officers were kept in camps and did not work. The privates were sent out to work. About half of them worked for German agriculture, where food supplies were adequate and controls were lenient. The others worked in factories or mines, where conditions were much harsher.

Germany and Italy generally treated prisoners from the British Commonwealth, France, the US, and other western Allies in accordance with the Geneva Convention, which had been signed by these countries. Consequently, western Allied officers were not usually made to work and some personnel of lower rank were usually compensated, or not required to work either. The main complaints of western Allied prisoners of war in German POW camps—especially during the last two years of the war—concerned shortages of food.

Only a small proportion of western Allied POWs who were Jews—or whom the Nazis believed to be Jewish—were killed as part of the Holocaust or were subjected to other antisemitic policies. For example, Major Yitzhak Ben-Aharon, a Palestinian Jew who had enlisted in the British Army, and who was captured by the Germans in Greece in 1941, experienced four years of captivity under entirely normal conditions for POWs.

However, a small number of Allied personnel were sent to concentration camps, for a variety of reasons including being Jewish. As the US historian Joseph Robert White put it: "An important exception ... is the sub-camp for U.S. POWs at Berga an der Elster, officially called "Arbeitskommando 625" [also known as "Stalag IX-B"]. Berga was the deadliest work detachment for American captives in Germany. 73 men who participated, or 21 percent of the detachment, perished in two months. 80 of the 350 POWs were Jews." Another well-known example was a group of 168 Australian, British, Canadian, New Zealand and US aviators who were held for two months at Buchenwald concentration camp; two of the POWs died at Buchenwald. Two possible reasons have been suggested for this incident: German authorities wanted to make an example of "Terrorflieger" ("terrorist aviators") or these aircrews were classified as spies, because they had been disguised as civilians or enemy soldiers when they were apprehended.

Information on conditions in the stalags is contradictory depending on the source. Some American POWs claimed the Germans were victims of circumstance and did the best they could, while others accused their captors of brutalities and forced labour. In any case, the prison camps were miserable places where food rations were meager and conditions squalid. One American admitted "The only difference between the stalags and concentration camps was that we weren't gassed or shot in the former. I do not recall a single act of compassion or mercy on the part of the Germans." Typical meals consisted of a bread slice and watery potato soup which, however, was still more substantial than what Soviet POWs or concentration camp inmates received. Another prisoner stated that "The German plan was to keep us alive, yet weakened enough that we wouldn't attempt escape."

As Soviet ground forces approached some POW camps in early 1945, German guards forced western Allied POWs to walk long distances towards central Germany, often in extreme winter weather conditions. It is estimated that, out of 257,000 POWs, about 80,000 were subject to such marches and up to 3,500 of them died as a result.

In September 1943 after the Armistice, Italian officers and soldiers that in many places waited for clear superior orders, were arrested by Germans and Italian fascists and taken to German internment camps in Germany or Eastern Europe, where they were held for the duration of World War II. The International Red Cross could do nothing for them, as they were not regarded as POWs, but the prisoners held the status of "military internees". Treatment of the prisoners was generally poor. The author Giovannino Guareschi was among those interned and wrote about this time in his life. The book was translated and published as "My Secret Diary". He wrote about the hungers of semi-starvation, the casual murder of individual prisoners by guards and how, when they were released (now from a German camp), they found a deserted German town filled with foodstuffs that they (with other released prisoners) ate.. It is estimated that of the 700,000 Italians taken prisoner by the Germans, around 40,000 died in detention and more than 13,000 lost their lives during the transportation from the Greek islands to the mainland.

Germany did not apply the same standard of treatment to non-western prisoners, especially many Polish and Soviet POWs who suffered harsh conditions and died in large numbers while in captivity.

Between 1941 and 1945 the Axis powers took about 5.7 million Soviet prisoners. About one million of them were released during the war, in that their status changed but they remained under German authority. A little over 500,000 either escaped or were liberated by the Red Army. Some 930,000 more were found alive in camps after the war. The remaining 3.3 million prisoners (57.5% of the total captured) died during their captivity. Between the launching of Operation Barbarossa in the summer of 1941 and the following spring, 2.8 million of the 3.2 million Soviet prisoners taken died while in German hands. According to Russian military historian General Grigoriy Krivosheyev, the Axis powers took 4.6 million Soviet prisoners, of whom 1.8 million were found alive in camps after the war and 318,770 were released by the Axis during the war and were then drafted into the Soviet armed forces again. By comparison, 8,348 Western Allied prisoners died in German camps during 1939–45 (3.5% of the 232,000 total).

Some Soviet POWs and forced labourers whom the Germans had transported to Nazi Germany were, on their return to the USSR, treated as traitors and sent to gulag prison-camps.

According to some sources, the Soviets captured 3.5 million Axis servicemen (excluding Japanese) of which more than a million died. One specific example is that of the German POWs after the Battle of Stalingrad, where the Soviets captured 91,000 German troops in total (completely exhausted, starving and sick) of whom only 5,000 survived the captivity.

German soldiers were kept as forced labour for many years after the war. The last German POWs like Erich Hartmann, the highest-scoring fighter ace in the history of aerial warfare, who had been declared guilty of war crimes but without due process, were not released by the Soviets until 1955, three years after Stalin died.

As a result of the Soviet invasion of Poland in 1939, hundreds of thousands of Polish soldiers became prisoners of war in the Soviet Union. Thousands of them were executed; over 20,000 Polish military personnel and civilians perished in the Katyn massacre. Out of Anders' 80,000 evacuees from Soviet Union gathered in the United Kingdom only 310 volunteered to return to Poland in 1947.

Out of the 230,000 Polish prisoners of war taken by the Soviet army, only 82,000 survived.

With the Soviet invasion of Manchuria, in 1945, Japanese soldiers became prisoners in the Soviet Union, where they, just as other Axis POWs, had to work.

There were stories during the Cold War to the effect that 23,000 Americans who had been held in German POW camps were seized by the Soviets and never repatriated. This myth had been perpetuated after the release of people like John H. Noble. Careful scholarly studies have demonstrated this is a myth based on a misinterpretation of a telegram that was talking about Soviet prisoners held in Italy.

During the war, the armies of Western Allied nations such as Australia, Canada, the UK and the US were ordered to treat Axis prisoners strictly in accordance with the Geneva Convention. Some breaches of the Convention took place, however. According to Stephen E. Ambrose, of the roughly 1,000 US combat veterans that he had interviewed, only one admitted to shooting a prisoner, saying that he "felt remorse, but would do it again". However, one-third told him they had seen US troops kill German prisoners.

In Britain German prisoners, particularly higher ranked officers, were kept in buildings where listening devices were installed. A considerable amount of military intelligence was gained from overhearing what they thought were private casual conversations. Much of the listening was done by German refugees, in many cases Jews. Knowledge of the program was not released by the British government for half a century.

Towards the end of the war in Europe, as large numbers of Axis soldiers surrendered, the US created the designation of Disarmed Enemy Forces (DEF) so as not to treat prisoners as POWs. A lot of these soldiers were kept in open fields in makeshift camps in the Rhine valley ("Rheinwiesenlager"). Controversy has arisen about how Eisenhower managed these prisoners (see "Other Losses").

After the surrender of Germany in May 1945, the POW status of the German prisoners was in many cases maintained, and they were for several years used as forced labour in countries such as the UK and France. Many died when forced to clear minefields in Norway, France etc.; "by September 1945 it was estimated by the French authorities that two thousand prisoners were being maimed and killed each month in accidents"

In 1946, the UK had more than 400,000 German prisoners, many had been transferred from POW camps in the US and Canada. Many of these were for over three years after the German surrender used as forced labour, as a form of "reparations". A public debate ensued in the UK, where words such as "forced labour", "slaves", "slave labour" were increasingly used in the media and in the House of Commons. In 1947 the Ministry of Agriculture argued against repatriation of working German prisoners, since by then they made up 25 percent of the land workforce, and they wanted to use them also in 1948.

The "London Cage", an MI19 prisoner of war facility in the UK used for interrogating prisoners before they were sent to prison camps during and immediately after World War II, was subject to allegations of torture.

After the German surrender, the International Red Cross was prohibited from providing aid such as food or visiting prisoner camps in Germany. However, after making approaches to the Allies in the autumn of 1945 it was allowed to investigate the camps in the British and French occupation zones of Germany, as well as to provide relief to the prisoners held there. On 4 February 1946, the Red Cross was permitted to visit and assist prisoners also in the US occupation zone of Germany, although only with very small quantities of food. "During their visits, the delegates observed that German prisoners of war were often detained in appalling conditions. They drew the attention of the authorities to this fact, and gradually succeeded in getting some improvements made".

The Allies also shipped POWs between them, with for example 6,000 German officers transferred from Western Allied camps to the Sachsenhausen concentration camp that now was under Soviet Union administration. The US also shipped 740,000 German POWs as forced labourers to France from where newspaper reports told of very bad treatment. Judge Robert H. Jackson, Chief US prosecutor in the Nuremberg trials, in October 1945 told US President Harry S Truman that the Allies themselves:
have done or are doing some of the very things we are prosecuting the Germans for. The French are so violating the Geneva Convention in the treatment of prisoners of war that our command is taking back prisoners sent to them. We are prosecuting plunder and our Allies are practicing it.

Hungarians became POWs of the Western Allies. Some of these were, like Germans, used as forced labour in France after the cessation of hostilities.
After the war the POWs were handed over to the Soviets, and after the POWs were transported to the USSR for forced labour. It is called even today in Hungary malenkij robot—little work. András Toma, a Hungarian soldier taken prisoner by the Red Army in 1944, was discovered in a Russian psychiatric hospital in 2000. He was probably the last prisoner of war from World War II to be repatriated.

Although thousands of Japanese were taken prisoner, most fought until they were killed or committed suicide. Of the 22,000 Japanese soldiers present at the beginning of the Battle of Iwo Jima, over 20,000 were killed and only 216 were taken prisoner. Of the 30,000 Japanese troops that defended Saipan, fewer than 1,000 remained alive at battle's end. Japanese prisoners sent to camps fared well; however, some Japanese were killed when trying to surrender or were massacred just after they had surrendered (see Allied war crimes during World War II in the Pacific). In some instances, Japanese prisoners were tortured by a variety of methods. A method of torture used by the Chinese National Revolutionary Army (NRA) included suspending the prisoner by the neck in a wooden cage until they died. In very rare cases, some were beheaded by sword, and a severed head was once used as a football by Chinese National Revolutionary Army (NRA) soldiers.

After the war, many Japanese were kept on as Japanese Surrendered Personnel until mid-1947 and used as forced labour doing menial tasks, while 35,000 were kept on in arms within their wartime military organisation and under their own officers and used in combat alongside British troops seeking to suppress the independence movements in the Dutch East Indies and French Indochina.

In 1943, Italy overthrew Mussolini and became a co-belligerent with the Allies. This did not mean any change in status for Italian POWs however, since due to the labour shortages in the UK, Australia and the US, they were retained as POWs there.

On 11 February 1945, at the conclusion of the Yalta Conference, the United States and the United Kingdom signed a Repatriation Agreement with the USSR. The interpretation of this Agreement resulted in the forcible repatriation of all Soviets (Operation Keelhaul) regardless of their wishes. The forced repatriation operations took place in 1945–1947.

The United States handed over 740,000 German prisoners to France, a signatory of the Geneva Convention. The Soviet Union had not signed the Geneva Convention. According to Edward Peterson, the U.S. chose to hand over several hundred thousand German prisoners to the Soviet Union in May 1945 as a "gesture of friendship". U.S. forces also refused to accept the surrender of German troops attempting to surrender to them in Saxony and Bohemia, and handed them over to the Soviet Union instead. It is also known that 6000 of the German officers who were sent from camps in the West to the Soviets were subsequently imprisoned in the Sachsenhausen concentration camp, which at the time was one of the NKVD special camp.

During the Korean War, the North Koreans developed a reputation for severely mistreating prisoners of war (see Crimes against POWs). Their POWs were housed in three camps, according to their potential usefulness to the North Korean army. Peace camps and reform camps were for POWs that were either sympathetic to the cause or who had valued skills that could be useful in the army and thus these enemy soldiers were indoctrinated and sometimes conscripted into the North Korean army. The regular prisoners of war were usually very poorly treated. POWs in peace camps were reportedly treated with more consideration.

In 1952, the 1952 Inter-Camp P.O.W. Olympics were held during 15 and 27 November 1952, in Pyuktong, North Korea. The Chinese hoped to gain worldwide publicity and while some prisoners refused to participate some 500 P.O.W.s of eleven nationalities took part. They were representative of all the prison camps in North Korea and competed in: football, baseball, softball, basketball, volleyball, track and field, soccer, gymnastics, and boxing. For the P.O.W.s this was also an opportunity to meet with friends from other camps. The prisoners had their own photographers, announcers, even reporters, who after each day's competition published a newspaper, the "Olympic Roundup".

Of about 16,500 French soldiers who fought at the Battle of Dien Bien Phu in French Indochina, more than 3,000 were killed in battle, while almost all of the 11,721 men taken prisoner died in the hands of the Viet Minh on death marches to distant POW camps, and in those camps in the last three months of the war.

The Vietcong and the North Vietnamese Army captured many United States service members as prisoners of war during the Vietnam War, who suffered from mistreatment and torture during the war. Some American prisoners were held in the prison called the Hanoi Hilton.
Communist Vietnamese held in custody by South Vietnamese and American forces were also tortured and badly treated. After the war, millions of South Vietnamese servicemen and government workers were sent to "re-education" camps where many perished.

Like in previous conflicts, there has been speculation without evidence that there were a handful of American pilots captured by the North Koreans and the North Vietnamese who were transferred to the Soviet Union and were never repatriated.

Regardless of regulations determining treatment to prisoners, violations of their rights continue to be reported. Many cases of POW massacres have been reported in recent times, including 13 October massacre in Lebanon by Syrian forces and June 1990 massacre in Sri Lanka.

Indian intervention in Bangladesh liberation war in 1971 led to third Indo-Pakistan war ended up with Indian victory with India having over 90,000 Pakistani POWs.

In 1982, during the Falklands War, prisoners were well treated in general by both parties of the conflict, with military commanders dispatching 'enemy' prisoners back to their homelands in record time.

In 1991, during the Persian Gulf War, American, British, Italian, and Kuwaiti POWs (mostly crew members of downed aircraft and special forces) were tortured by the Iraqi secret police. An American military doctor, Major Rhonda Cornum, a 37-year-old flight surgeon captured when her Blackhawk UH-60 was shot down, was also subjected to sexual abuse.

During the 1990s Yugoslav Wars, Serb paramilitary forces supported by JNA forces killed POWs at Vukovar and Škarbrnja while Bosnian Serb forces killed POWs at Srebrenica.

In 2001, there were reports concerning two POWs that India had taken during the Sino-Indian War, Yang Chen and Shih Liang. The two were imprisoned as spies for three years before being interned in a mental asylum in Ranchi, where they spent the next 38 years under a special prisoner status.<br> The last prisoners of Iran–Iraq War (1980–1988) were exchanged in 2003.

This article is a list of nations with the highest number of POWs since the start of World War II, listed in descending order. These are also the highest numbers in any war since the Convention Relative to the Treatment of Prisoners of War entered into force on 19 June 1931. The USSR had not signed the Geneva convention.









</doc>
<doc id="25009" url="https://en.wikipedia.org/wiki?curid=25009" title="Privacy">
Privacy

Privacy is the ability of an individual or group to seclude themselves, or information about themselves, and thereby express themselves selectively. The boundaries and content of what is considered private differ among cultures and individuals.

When something is private to a "person", it usually means that something is inherently special or sensitive to them. The domain of privacy partially overlaps with security, which can include the concepts of appropriate use, as well as protection of information. Privacy may also take the form of bodily integrity. The right not to be subjected to unsanctioned invasions of privacy by the government, corporations or individuals is part of many countries' privacy laws, and in some cases, constitutions.

In the business world, a person may volunteer personal details, including for advertising, in order to receive some sort of benefit. Public figures may be subject to rules on the public interest. Personal information which is voluntarily shared but subsequently stolen or misused can lead to identity theft.

The concept of universal individual privacy is a modern construct primarily associated with Western culture, British and North American in particular, and remained virtually unknown in some cultures until recent times. Most cultures, however, recognize the ability of individuals to withhold certain parts of their personal information from wider society, such as closing the door to one's home.

In 1890 the United States jurists Samuel D. Warren and Louis Brandeis wrote "The Right to Privacy", an article in which they argued for the "right to be let alone", using that phrase as a definition of privacy. There is extensive commentary over the meaning of being "let alone", and among other ways, it has been interpreted to mean the right of a person to choose seclusion from the attention of others if they wish to do so, and the right to be immune from scrutiny or being observed in private settings, such as one's own home. Although this early vague legal concept did not describe privacy in a way that made it easy to design broad legal protections of privacy, it strengthened the notion of privacy rights for individuals and began a legacy of discussion on those rights.

Limited access refers to a person's ability to participate in society without having other individuals and organizations collect information about them.

Various theorists have imagined privacy as a system for limiting access to one's personal information. Edwin Lawrence Godkin wrote in the late 19th century that "nothing is better worthy of legal protection than private life, or, in other words, the right of every man to keep his affairs to himself, and to decide for himself to what extent they shall be the subject of public observation and discussion." Adopting an approach similar to the one presented by Ruth Gavison Nine years earlier, Sissela Bok said that privacy is "the condition of being protected from unwanted access by others—either physical access, personal information, or attention."

Control over one's personal information is the concept that "privacy is the claim of individuals, groups, or institutions to determine for themselves when, how, and to what extent information about them is communicated to others." Charles Fried said that "Privacy is not simply an absence of information about us in the minds of others; rather it is the control we have over information about ourselves. Nevertheless, in the era of big data, control over information is under pressure.

Alan Westin defined four states—or experiences—of privacy: solitude, intimacy, anonymity, and reserve. Solitude is a physical separation from others. Intimacy is a "close, relaxed, and frank relationship between two or more individuals" that results from the seclusion of a pair or small group of individuals. Anonymity is the "desire of individuals for times of 'public privacy.'" Lastly, reserve is the "creation of a psychological barrier against unwanted intrusion"; this creation of a psychological barrier requires others to respect an individual's need or desire to restrict communication of information concerning himself or herself.

In addition to the psychological barrier of reserve, Kirsty Hughes identified three more kinds of privacy barriers: physical, behavioral, and normative. Physical barriers, such as walls and doors, prevent others from accessing and experiencing the individual. (In this sense, "accessing" an individual includes accessing personal information about him or her.) Behavioral barriers communicate to others—verbally, through language, or non-verbally, through personal space, body language, or clothing—that an individual does not want them to access or experience him or her. Lastly, normative barriers, such as laws and social norms, restrain others from attempting to access or experience an individual.

Privacy is sometimes defined as an option to have secrecy. Richard Posner said that privacy is the right of people to "conceal information about themselves that others might use to their disadvantage".

In various legal contexts, when privacy is described as secrecy, a conclusion if privacy is secrecy then rights to privacy do not apply for any information which is already publicly disclosed. When privacy-as-secrecy is discussed, it is usually imagined to be a selective kind of secrecy in which individuals keep some information secret and private while they choose to make other information public and not private.

Privacy may be understood as a necessary precondition for the development and preservation of personhood. Jeffrey Reiman defined privacy in terms of a recognition of one's ownership of his or her physical and mental reality and a moral right to his or her self-determination. Through the "social ritual" of privacy, or the social practice of respecting an individual's privacy barriers, the social group communicates to the developing child that he or she has exclusive moral rights to his or her body—in other words, he or she has moral ownership of his or her body. This entails control over both active (physical) and cognitive appropriation, the former being control over one's movements and actions and the latter being control over who can experience one's physical existence and when.

Alternatively, Stanley Benn defined privacy in terms of a recognition of oneself as a subject with agency—as an individual with the capacity to choose. Privacy is required to exercise choice. Overt observation makes the individual aware of himself or herself as an object with a "determinate character" and "limited probabilities." Covert observation, on the other hand, changes the conditions in which the individual is exercising choice without his or her knowledge and consent.

In addition, privacy may be viewed as a state that enables autonomy, a concept closely connected to that of personhood. According to Joseph Kufer, an autonomous self-concept entails a conception of oneself as a "purposeful, self-determining, responsible agent" and an awareness of one's capacity to control the boundary between self and other—that is, to control who can access and experience him or her and to what extent. Furthermore, others must acknowledge and respect the self's boundaries—in other words, they must respect the individual's privacy.

The studies of psychologists such as Jean Piaget and Victor Tausk show that, as children learn that they can control who can access and experience them and to what extent, they develop an autonomous self-concept. In addition, studies of adults in particular institutions, such as Erving Goffman's study of "total institutions" such as prisons and mental institutions, suggest that systemic and routinized deprivations or violations of privacy deteriorate one's sense of autonomy over time.

Privacy may be understood as a prerequisite for the development of a sense of self-identity. Privacy barriers, in particular, are instrumental in this process. According to Irwin Altman, such barriers "define and limit the boundaries of the self" and thus "serve to help define [the self]." This control primarily entails the ability to regulate contact with others. Control over the "permeability" of the self's boundaries enables one to control what constitutes the self and thus to define what is the self.

In addition, privacy may be seen as a state that fosters personal growth, a process integral to the development of self-identity. Hyman Gross suggested that, without privacy—solitude, anonymity, and temporary releases from social roles—individuals would be unable to freely express themselves and to engage in self-discovery and self-criticism. Such self-discovery and self-criticism contributes to one's understanding of oneself and shapes one's sense of identity.

In a way analogous to how the personhood theory imagines privacy as some essential part of being an individual, the intimacy theory imagines privacy to be an essential part of the way that humans have strengthened or intimate relationships with other humans. Because part of human relationships includes individuals volunteering to self-disclose some information, but withholding other information, there is a concept of privacy as a part of the process by means of which humans establish relationships with each other.

James Rachels advanced this notion by writing that privacy matters because "there is a close connection between our ability to control who has access to us and to information about us, and our ability to create and maintain different sorts of social relationships with different people." Protecting intimacy is at the core of the concept of sexual privacy, which law professor Danielle Citron argues should be protected as a unique form of privacy.

Physical privacy could be defined as preventing "intrusions into one's physical space or solitude." An example of the legal basis for the right to physical privacy is the U.S. Fourth Amendment, which guarantees "the right of the people to be secure in their persons, houses, papers, and effects, against unreasonable searches and seizures".

Physical privacy may be a matter of cultural sensitivity, personal dignity, and/or shyness. There may also be concerns about safety, if for example one is wary of becoming the victim of crime or stalking.

Government agencies, corporations, groups/societies and other organizations may desire to keep their activities or secrets from being revealed to other organizations or individuals, adopting various security practices and controls in order to keep private information confidential. Organizations may seek legal protection for their secrets. For example, a government administration may be able to invoke executive privilege or declare certain information to be classified, or a corporation might attempt to protect valuable proprietary information as trade secrets.

Privacy has historical roots in philosophical discussions, the most well-known being Aristotle's distinction between two spheres of life: the public sphere of the "polis", associated with political life, and the private sphere of the "oikos", associated with domestic life. More systematic treatises of privacy in the United States did not appear until the 1890s, with the development of privacy law in America.

As technology has advanced, the way in which privacy is protected and violated has changed with it. In the case of some technologies, such as the printing press or the Internet, the increased ability to share information can lead to new ways in which privacy can be breached. It is generally agreed that the first publication advocating privacy in the United States was the article by Samuel Warren and Louis Brandeis, "The Right to Privacy", that was written largely in response to the increase in newspapers and photographs made possible by printing technologies.

New technologies can also create new ways to gather private information. For example, in the United States it was thought that heat sensors intended to be used to find marijuana-growing operations would be acceptable. However, in 2001 in "Kyllo v. United States" (533 U.S. 27) it was decided that the use of thermal imaging devices that can reveal previously unknown information without a warrant does indeed constitute a violation of privacy.

The Internet has brought new concerns about privacy in an age where computers can permanently store records of everything: "where every online photo, status update, Twitter post and blog entry by and about us can be stored forever", writes law professor and author Jeffrey Rosen.

This currently has an effect on employment. Microsoft reports that 75 percent of U.S. recruiters and human-resource professionals now do online research about candidates, often using information provided by search engines, social-networking sites, photo/video-sharing sites, personal web sites and blogs, and Twitter. They also report that 70 percent of U.S. recruiters have rejected candidates based on internet information. This has created a need by many to control various online privacy settings in addition to controlling their online reputations, both of which have led to legal suits against various sites and employers.

The ability to do online inquiries about individuals has expanded dramatically over the last decade. Facebook for example, as of August 2015, was the largest social-networking site, with nearly 1,490 million members, who upload over 4.75 billion pieces of content daily. Over 83.09 million accounts were fake. Twitter has more than 316 million registered users and over 20 million are fake users. The Library of Congress recently announced that it will be acquiring—and permanently storing—the entire archive of public Twitter posts since 2006, reports Rosen.

Importantly, directly observed behaviour, such as browsing logs, search queries, or contents of the Facebook profile can be automatically processed to infer secondary information about an individual, such as sexual orientation, political and religious views, race, substance use, intelligence, and personality.

According to some experts, many commonly used communication devices may be mapping every move of their users. Senator Al Franken has noted the seriousness of iPhones and iPads having the ability to record and store users' locations in unencrypted files, although Apple denied doing so.

Andrew Grove, co-founder and former CEO of Intel Corporation, offered his thoughts on internet privacy in an interview published in May 2000:

As with other concepts about privacy, there are various ways to discuss what kinds of processes or actions remove, challenge, lessen, or attack privacy. In 1960 legal scholar William Prosser created the following list of activities which can be remedied with privacy protection:

Building from this and other historical precedents, Daniel J. Solove presented another classification of actions which are harmful to privacy, including collection of information which is already somewhat public, processing of information, sharing information, and invading personal space to get private information.

In the context of harming privacy, information collection means gathering whatever information can be obtained by doing something to obtain it. Surveillance is an example of this, when someone decides to begin watching and recording someone or something, and interrogation is another example of this, when someone uses another person as a source of information.

It can happen that privacy is not harmed when information is available, but that the harm can come when that information is collected as a set then processed in a way that the collective reporting of pieces of information encroaches on privacy. Actions in this category which can lessen privacy include the following:

Information dissemination is an attack on privacy when information which was shared in confidence is shared or threatened to be shared in a way that harms the subject of the information.

There are various examples of this. Breach of confidentiality is when one entity promises to keep a person's information private, then breaks that promise. Disclosure is making information about a person more accessible in a way that harms the subject of the information, regardless of how the information was collected or the intent of making it available. Exposure is a special type of disclosure in which the information disclosed is emotional to the subject or taboo to share, such as revealing their private life experiences, their nudity, or perhaps private body functions. Increased accessibility means advertising the availability of information without actually distributing it, as in the case of doxxing. Blackmail is making a threat to share information, perhaps as part of an effort to coerce someone. Appropriation is an attack on the personhood of someone, and can include using the value of someone's reputation or likeness to advance interests which are not those of the person being appropriated. Distortion is the creation of misleading information or lies about a person.

Invasion of privacy, a subset of expectation of privacy, is a different concept from the collecting, aggregating, and disseminating information because those three are a misuse of available data, whereas invasion is an attack on the right of individuals to keep personal secrets. An invasion is an attack in which information, whether intended to be public or not, is captured in a way that insults the personal dignity and right to private space of the person whose data is taken.

An intrusion is any unwanted entry into a person's private personal space and solitude for any reason, regardless of whether data is taken during that breach of space. "Decisional interference" is when an entity somehow injects itself into the personal decision making process of another person, perhaps to influence that person's private decisions but in any case doing so in a way that disrupts the private personal thoughts that a person has.

Privacy uses the theory of natural rights, and generally responds to new information and communication technologies. In North America, Samuel D. Warren and Louis D. Brandeis wrote that privacy is the "right to be let alone" (Warren & Brandeis, 1890) focuses on protecting individuals. This citation was a response to recent technological developments, such as photography, and sensationalist journalism, also known as yellow journalism.

In recent years there have been only few attempts to clearly and precisely define a "right to privacy." Some experts assert that in fact the right to privacy "should not be defined as a separate legal right" at all. By their reasoning, existing laws relating to privacy in general should be sufficient. It has therefore proposed a working definition for a "right to privacy":

"The right to privacy is our right to keep a domain around us, which includes all those things that are part of us, such as our body, home, property, thoughts, feelings, secrets and identity. The right to privacy gives us the ability to choose which parts in this domain can be accessed by others, and to control the extent, manner and timing of the use of those parts we choose to disclose."

David Flaherty believes networked computer databases pose threats to privacy. He develops 'data protection' as an aspect of privacy, which involves "the collection, use, and dissemination of personal information". This concept forms the foundation for fair information practices used by governments globally. Flaherty forwards an idea of privacy as information control, "[i]ndividuals want to be left alone and to exercise some control over how information about them is used".

Richard Posner and Lawrence Lessig focus on the economic aspects of personal information control. Posner criticizes privacy for concealing information, which reduces market efficiency. For Posner, employment is selling oneself in the labour market, which he believes is like selling a product. Any 'defect' in the 'product' that is not reported is fraud. For Lessig, privacy breaches online can be regulated through code and law. Lessig claims "the protection of privacy would be stronger if people conceived of the right as a property right", and that "individuals should be able to control information about themselves".

There have been attempts to establish privacy as one of the fundamental human rights, whose social value is an essential component in the functioning of democratic societies. Amitai Etzioni suggests a communitarian approach to privacy. This requires a shared moral culture for establishing social order. Etzioni believes that "[p]rivacy is merely one good among many others", and that technological effects depend on community accountability and oversight (ibid). He claims that privacy laws only increase government surveillance by weakening informal social controls. Furthermore, the government is no longer the only or even principle threat to people's privacy. Etzioni notes that corporate data miners, or "Privacy Merchants," stand to profit by selling massive dossiers personal information, including purchasing decisions and Internet traffic, to the highest bidder. And while some might not find collection of private information objectionable when it is only used commercially by the private sector, the information these corporations amass and process is also available to the government, so that it is no longer possible to protect privacy by only curbing the State.

Priscilla Regan believes that individual concepts of privacy have failed philosophically and in policy. She supports a social value of privacy with three dimensions: shared perceptions, public values, and collective components. Shared ideas about privacy allows freedom of conscience and diversity in thought. Public values guarantee democratic participation, including freedoms of speech and association, and limits government power. Collective elements describe privacy as collective good that cannot be divided. Regan's goal is to strengthen privacy claims in policy making: "if we did recognize the collective or public-good value of privacy, as well as the common and public value of privacy, those advocating privacy protections would have a stronger basis upon which to argue for its protection".

Leslie Regan Shade argues that the human right to privacy is necessary for meaningful democratic participation, and ensures human dignity and autonomy. Privacy depends on norms for how information is distributed, and if this is appropriate. Violations of privacy depend on context. The human right to privacy has precedent in the United Nations Declaration of Human Rights: "Everyone has the right to freedom of opinion and expression; this right includes freedom to hold opinions without interference and to seek, receive and impart information and ideas through any media and regardless of frontiers." Shade believes that privacy must be approached from a people-centered perspective, and not through the marketplace.

Most countries give citizen rights to privacy in their constitutions. Representative examples of this include the "Constitution of Brazil", which says "the privacy, private life, honor and image of people are inviolable"; the "Constitution of South Africa" says that "everyone has a right to privacy"; and the "Constitution of the Republic of Korea" says "the privacy of no citizen shall be infringed." Among most countries whose constitutions do not explicitly describe privacy rights, court decisions have interpreted their constitutions to intend to give privacy rights.

Many countries have broad privacy laws outside their constitutions, including Australia's Privacy Act 1988, Argentina's Law for the Protection of Personal Data of 2000, Canada's 2000 Personal Information Protection and Electronic Documents Act, and Japan's 2003 Personal Information Protection Law.

Beyond national privacy laws, there are international privacy agreements. The United Nations Universal Declaration of Human Rights says "No one shall be subjected to arbitrary interference with his privacy, family, home or correspondence, nor to attacks upon his honor and reputation." The Organisation for Economic Co-operation and Development published its Privacy Guidelines in 1980. The European Union's 1995 Data Protection Directive guides privacy protection in Europe. The 2004 Privacy Framework by the Asia-Pacific Economic Cooperation is a privacy protection agreement for the members of that organization.

In the 1960s people began to consider how changes in technology were bringing changes in the concept of privacy. Vance Packard’s "The Naked Society" was a popular book on privacy from that era and led discourse on privacy at that time.

Approaches to privacy can, broadly, be divided into two categories: free market or consumer protection.

One example of the free market approach is to be found in the voluntary OECD Guidelines on the Protection of Privacy and Transborder Flows of Personal Data. The principles reflected in the guidelines are analysed in an article putting them into perspective with concepts of the GDPR put into law later in the European Union.

In a consumer protection approach, in contrast, it is claimed that individuals may not have the time or knowledge to make informed choices, or may not have reasonable alternatives available. In support of this view, Jensen and Potts showed that most privacy policies are above the reading level of the average person.

The "Privacy Act 1988" is administered by the Office of the Australian Information Commissioner. Privacy law has been evolving in Australia for a number of years. The initial introduction of privacy law in 1998 extended to the public sector, specifically to Federal government departments, under the Information Privacy Principles. State government agencies can also be subject to state based privacy legislation. This built upon the already existing privacy requirements that applied to telecommunications providers (under Part 13 of the "Telecommunications Act 1997"), and confidentiality requirements that already applied to banking, legal and patient / doctor relationships.

In 2008 the Australian Law Reform Commission (ALRC) conducted a review of Australian Privacy Law. The resulting report "For Your Information". This recommendation, and many others, were taken up and implemented by the Australian Government via the Privacy Amendment (Enhancing Privacy Protection) Bill 2012

Although there are comprehensive regulations for data protection, some studies show that despite the laws, there is a lack of enforcement in that no institution feels responsible to control the parties involved and enforce their laws. The European Union is also championing for the 'Right to be Forgotten' concept (which allows individuals to ask that links leading to information about themselves be removed from internet search engine results) to be adopted by other countries.

Due to the introduction of the Aadhaar project inhabitants of India were afraid that their privacy could be invaded. The project was also met with mistrust regarding the safety of the social protection infrastructures. To tackle the fear amongst the people, India's supreme court put a new ruling into action that stated that privacy from then on was seen as a fundamental right.

In Italy the right to privacy is enshrined in Article 15 of the Constitution, which states:

In the United Kingdom, it is not possible to bring an action for invasion of privacy. An action may be brought under another tort (usually breach of confidence) and privacy must then be considered under EC law. In the UK, it is sometimes a defence that disclosure of private information was in the public interest. There is, however, the Information Commissioner's Office (ICO), an independent public body set up to promote access to official information and protect personal information. They do this by promoting good practice, ruling on eligible complaints, giving information to individuals and organisations, and taking action when the law is broken. The relevant UK laws include: Data Protection Act 1998; Freedom of Information Act 2000; Environmental Information Regulations 2004; Privacy and Electronic Communications Regulations 2003. The ICO has also provided a "Personal Information Toolkit" online which explains in more detail the various ways of protecting privacy online.

Although the US Constitution does not explicitly include the right to privacy, individual as well as locational privacy are implicitly granted by the Constitution under the 4th Amendment. The Supreme Court of the United States has found that other guarantees have "penumbras" that implicitly grant a right to privacy against government intrusion, for example in "Griswold v. Connecticut" (1965). In the United States, the right of freedom of speech granted in the First Amendment has limited the effects of lawsuits for breach of privacy. Privacy is regulated in the US by the Privacy Act of 1974, and various state laws. The Privacy Act of 1974 only applies to Federal agencies in the executive branch of the Federal government. Certain privacy rights have been established in the United States via legislation such as the Children's Online Privacy Protection Act (COPPA), the Gramm–Leach–Bliley Act (GLB), and the Health Insurance Portability and Accountability Act (HIPAA).
Unlike the EU and most EU-member states the US does not recognize the right to privacy to others than US citizens.

The Electronic Privacy Information Center's Privacy Index puts Brazil, Australia, Japan and South Africa in the higher level of privacy (around 2.2). On the bottom of the list are the United States and United Kingdom (around 1.4).

There are many means to protect one's privacy on the internet. For example, e-mails can be encrypted (via S/MIME or PGP) and anonymizing proxies or anonymizing networks like I2P and Tor can be used to prevent the internet service providers from knowing which sites one visits and with whom one communicates. Covert collection of personally identifiable information has been identified as a primary concern by the U.S. Federal Trade Commission. Although some privacy advocates recommend the deletion of original and third-party HTTP cookies, Anthony Miyazaki, marketing professor at Florida International University and privacy scholar, warns that the "elimination of third-party cookie use by Web sites can be circumvented by cooperative strategies with third parties in which information is transferred after the Web site's use of original domain cookies." As of December 2010, the Federal Trade Commission is reviewing policy regarding this issue as it relates to behavioral advertising.
Another aspect of privacy on the Internet relates to online social networking. Several online social network sites (OSNs) are among the top 10 most visited websites globally. A review and evaluation of scholarly work regarding the current state of the value of individuals' privacy of online social networking show the following results: "first, adults seem to be more concerned about potential privacy threats than younger users; second, policy makers should be alarmed by a large part of users who underestimate risks of their information privacy on OSNs; third, in the case of using OSNs and its services, traditional one-dimensional privacy approaches fall short". This is exacerbated by the research indicating that personal traits such as sexual orientation, race, religious and political views, personality, or intelligence can be inferred based on the wide variety of digital footprint, such as samples of text, browsing logs, or Facebook Likes.

Increasingly, mobile devices facilitate location tracking. This creates user privacy problems. A user's location and preferences constitute personal information. Their improper use violates that user's privacy. A recent MIT study by de Montjoye et al. showed that 4 spatio-temporal points, approximate places and times, are enough to uniquely identify 95% of 1.5M people in a mobility database. The study
further shows that these constraints hold even when the resolution of the dataset is low. Therefore, even coarse or blurred datasets provide little anonymity.

Several methods to protect user privacy in location-based services have been proposed, including the use of anonymizing servers, blurring of information e.a. Methods to quantify privacy have also been proposed, to calculate the equilibrium between the benefit of providing accurate location information and the drawbacks of risking personal privacy.

In recent years, seen with the increasing importance of mobile devices and paired with the "National Do Not Call Registry", telemarketers have turned attention to mobiles.

Additionally, Apple and Google are constantly improving their privacy. With iOS 13, Apple introduced Sign in with Apple in order to protect the user data being taken and Google introduced allowing location access only when the app is in-use.

Privacy self-synchronization is the mode by which the stakeholders of an enterprise privacy program spontaneously contribute collaboratively to the program's maximum success. The stakeholders may be customers, employees, managers, executives, suppliers, partners or investors. When self-synchronization is reached, the model states that the personal interests of individuals toward their privacy is in balance with the business interests of enterprises who collect and use the personal information of those individuals.

The privacy paradox is a phenomenon in which online users state that they are concerned about their privacy but behave as if they were not. While this term was coined as early as 1998, it wasn't used in its current popular sense until the year 2000.

Susan B. Barnes similarly used the term “privacy paradox” to refer to the ambiguous boundary between private and public space on social media. When compared to adults, young people tend to disclose more information on social media. However, this does not mean that they are not concerned about their privacy. Susan B. Barnes gave a case in her article: in a television interview about Facebook, a student addressed her concerns about disclosing personal information online. However, when the reporter asked to see her Facebook page, she put her home address, phone numbers, and pictures of her young son on the page.

Privacy paradox has been studied and scripted in different research settings. Although several studies have shown this inconsistency between privacy attitudes and behavior among online users, the reason for the paradox still remains unclear. A main explanation for the privacy paradox is that users lack awareness of the risks and the degree of protection. Users may underestimate the harm of disclosing information online. On the other hand, some researchers argue the privacy paradox comes from lack of technology literacy and from the design of sites. For example, users may not know how to change their default settings even though they care about their privacy. Psychologists particularly pointed out that the privacy paradox occurs because users must trade-off between their privacy concerns and impression management.

Decision making within privacy paradox explaining people attitudes and actual behavior is divided into three categories:

•           Rational calculation of risks and benefits is weighting cost and benefit relation regarding the risks while favoring the gains;

•           Irrational risk-benefit calculation characterized by biased risk assessment in a situation where aspects of time inconsistency and heuristic thinking affects the risk-benefit calculation that distorts decision making;

•           Negligent decision making in situation where risk assessment regarding privacy takes no place or is negligent.

Some researchers believe that decision making takes place on irrational level especially when it comes to mobile computing. Mobile applications are built up in a way that decision making is fast. Restricting one’s profile on social networks is the easiest way to protect against privacy threats and security intrusions. However, such protection measures are not easily accessible while downloading and installing apps. Even if there would be mechanisms to protect your privacy then most of the users do not have the knowledge or experience to protective behavior. Mobile applications consumers also have very little knowledge of how their personal data are used, they do not rely on the information provided by application vendors on the collection and use of personal data, when they decide which application to download. Users claim that permissions are important while downloading app, but research shows that users do not value privacy and security related aspects to be important when downloading and installing app. Users value cost, functionality, design, ratings, reviews and downloads more important than requested permissions.

A study by Zafeiropoulou specifically examined location data, which is a form of personal information increasingly used by mobile applications. Their survey also found evidence that supports the existence of privacy paradox for location data. Privacy risk perception in relation to the use of privacy enhancing technologies survey data indicates that a high perception of privacy risk is an insufficient motivator for people to adopt privacy protecting strategies, while knowing they exist. It also raises a question on what the value of data is, as there is no equivalent of a stock-market for personal information.

Results on privacy paradox studies through economic valuation on personal information, indicate that general privacy concerns or individual disclosure concerns do not have a significant influence on the price valuation of personal information. Instead, prior disclosure behavior in specific scenario, like with healthcare providers or social networks, is a better indicator of consumer price valuations.

Experiment aiming to determine the monetary value of several types of personal information showed significantly low evaluations of personal information, on the other hand, it appears that consumers are willing to pay a premium for privacy, albeit a small one.  Users do not always act in accordance with their professed privacy concerns and they are sometimes willing to trade private information for convenience, functionality, or financial gain, even when the gains are very small. One of the studies suggest that people think their browser history is worth the equivalent of a cheap meal.

Concrete solutions on how to solve paradoxical behavior still do not exist. Many efforts are focused on processes of decision making like restricting data access permissions during the applications installation. However, nothing that would solve the gap between user intention and behavior. Susanne Barth and Menno D.T. de Jong believe that for users to make more conscious decisions on privacy matters the design needs to be more user oriented. Meaning, the ownership of data related risks will be better perceived if psychological ownership of data is being considered as ‘mine’ rather than ‘not mine’.

There are many opinions related to privacy paradox. It is also suggested that it should not be considered a paradox anymore. It’s maybe more of a privacy dilemma, because people would like to do more but they also want to use services that would not exist without sharing their data. It is suggested to be, that people do understand that they pay with personal data, but believe they get a fair deal.

Selfies are popular today. A search for photos with the hashtag #selfie retrieves over 23 million results on Instagram and "a whopping 51 million with the hashtag #me" However, due to modern corporate and governmental surveillance, this may pose a risk to privacy. In a research which takes a sample size of 3763, researchers found that for selfies, females generally have greater concerns than male social media users. Users who have greater concerns inversely predict their selfie behavior and activity.





</doc>
<doc id="25010" url="https://en.wikipedia.org/wiki?curid=25010" title="Proton–proton chain reaction">
Proton–proton chain reaction

The proton–proton chain reaction is one of two known sets of nuclear fusion reactions by which stars convert hydrogen to helium. It dominates in stars with masses less than or equal to that of the Sun, whereas the CNO cycle, the other known reaction, is suggested by theoretical models to dominate in stars with masses greater than about 1.3 times that of the Sun.

In general, proton–proton fusion can occur only if the kinetic energy (i.e. temperature) of the protons is high enough to overcome their mutual electrostatic or Coulomb repulsion.

In the Sun, deuterium-producing events are rare. Diprotons are the much more common result of proton–proton reactions within the star, and diprotons almost immediately decay back into two protons. Since the conversion of hydrogen to helium is slow, the complete conversion of the hydrogen in the core of the Sun is calculated to take more than ten billion years.

Although often called the "proton–proton chain reaction", it is not a chain reaction in the normal sense of the word (at least not branch I – in branches II and III, helium, which is the product, also serves as a catalyst). It does not produce particles that go on to induce the reaction to continue (such as neutrons given off during fission). In fact, the rate is self-limiting because the heat produced tends toward reducing the density. It is however a chain (like a decay chain) and a reaction, or more accurately a branched chain of reactions starting with two protons coming together and yielding deuterium.

The theory that proton–proton reactions are the basic principle by which the Sun and other stars burn was advocated by Arthur Eddington in the 1920s. At the time, the temperature of the Sun was considered to be too low to overcome the Coulomb barrier. After the development of quantum mechanics, it was discovered that tunneling of the wavefunctions of the protons through the repulsive barrier allows for fusion at a lower temperature than the classical prediction.

Even so, it was unclear how proton–proton fusion might proceed, because the most obvious product, helium-2 (diproton), is unstable and almost instantly dissociates back into two protons. In 1939, Hans Bethe proposed that one of the protons could decay by beta emission into a neutron via the weak interaction during the brief moment of fusion, making deuterium a vital product in the chain. This idea was part of the body of work in stellar nucleosynthesis for which Bethe won the Nobel Prize in Physics in 1967.

The first step in all the branches is the fusion of two protons into deuterium. As the protons fuse, one of them undergoes beta plus decay, converting into a neutron by emitting a positron and an electron neutrino.

The positron will probably annihilate with an electron from the environment into two gamma rays. Including this annihilation the whole reaction has a "Q" value (released energy) of 1.442 MeV.

This reaction is extremely slow due to it being initiated by the weak nuclear force. The average proton in the core of the Sun waits 9 billion years before it successfully fuses with another proton. It has not been possible to measure the cross-section of this reaction experimentally because of these long time scales.

After it is formed, the deuterium produced in the first stage can fuse with another proton to produce the light isotope of helium, :

This process, mediated by the strong nuclear force rather than the weak force, is extremely fast by comparison to the first step. It is estimated that, under the conditions in the Sun's core, each newly created deuterium nucleus exists for only about four seconds before it is converted to helium-3.

In the Sun, each helium-3 nucleus produced in these reactions exists for only about 400 years before it is converted into helium-4. Once the helium-3 has been produced, there are four possible paths to generate . In p–p I, helium-4 is produced by fusing two helium-3 nuclei; the p–p II and p–p III branches fuse with pre-existing to form beryllium-7, which undergoes further reactions to produce two helium-4 nuclei.

In the Sun, synthesis via branch p–p I occurs with a frequency of 83.30 percent, p–p II with 16.68 percent, and p–p III with 0.02 percent.

There is also the extremely rare p–p IV branch. Other even rarer reactions may occur. The rate of these reactions is very low due to very small cross-sections, or because the number of reacting particles is so low that any reactions that might happen are statistically insignificant. This is partly why no mass-5 or mass-8 elements are seen. While the reactions that would produce them, such as a proton + helium-4 producing lithium-5, or two helium-4 nuclei coming together to form beryllium-8, may "actually" happen, these elements are not detected because there are no stable (or even particle-bound) isotopes of atomic masses 5 or 8; the resulting products immediately decay into their initial reactants.

The overall reaction is:

The complete p–p I chain reaction releases a net energy of . Two percent of this energy is lost to the neutrinos that are produced.
The p–p I branch is dominant at temperatures of 10 to .
Below , the p–p chain does not produce much .

The p–p II branch is dominant at temperatures of 14 to .

Note that the energies in the equation above are not the energy released by the reaction. Rather, they are the energies of the neutrinos that are produced by the reaction. 90 percent of the neutrinos produced in the reaction of to carry an energy of , while the remaining 10 percent carry . The difference is whether the lithium-7 produced is in the ground state or an excited (metastable) state, respectively.

The p–p III chain is dominant if the temperature exceeds .

The p–p III chain is not a major source of energy in the Sun (only 0.11 percent), but it was very important in the solar neutrino problem because it generates very high energy neutrinos (up to ).

This reaction is predicted theoretically, but it has never been observed due to its rarity (about in the Sun). In this reaction, helium-3 captures a proton directly to give helium-4, with an even higher possible neutrino energy (up to 18.8 MeV).

Comparing the mass of the final helium-4 atom with the masses of the four protons reveals that 0.7 percent of the mass of the original protons has been lost. This mass has been converted into energy, in the form of gamma rays and neutrinos released during each of the individual reactions. The total energy yield of one whole chain is .

Energy released as gamma rays will interact with electrons and protons and heat the interior of the Sun. Also kinetic energy of fusion products (e.g. of the two protons and the from the p–p I reaction) increases the temperature of plasma in the Sun. This heating supports the Sun and prevents it from collapsing under its own weight.

Neutrinos do not interact significantly with matter and therefore do not help support the Sun against gravitational collapse. Their energy is lost: the neutrinos in the p–p I, p–p II, and p–p III chains carry away 2.0%, 4.0%, and 28.3% of the energy in those reactions, respectively.

Deuterium can also be produced by the rare pep (proton–electron–proton) reaction (electron capture):

In the Sun, the frequency ratio of the pep reaction versus the p–p reaction is 1:400. However, the neutrinos released by the pep reaction are far more energetic: while neutrinos produced in the first step of the p–p reaction range in energy up to , the pep reaction produces sharp-energy-line neutrinos of . Detection of solar neutrinos from this reaction were reported by the Borexino collaboration in 2012.

Both the pep and p–p reactions can be seen as two different Feynman representations of the same basic interaction, where the electron passes to the right side of the reaction as a positron. This is represented in the figure of proton–proton and electron-capture chain reactions in a star, available at the NDM'06 web site.



</doc>
<doc id="25011" url="https://en.wikipedia.org/wiki?curid=25011" title="Plankton">
Plankton

Plankton are the diverse collection of organisms that live in large bodies of water and are unable to swim against a current. The individual organisms constituting plankton are called plankters. They provide a crucial source of food to many small and large aquatic organisms, such as bivalves, fish and whales.

Planktonic organisms include bacteria, archaea, algae, protozoa and drifting or floating animals that inhabit—for example—the pelagic zone of oceans, seas, or bodies of fresh water. Essentially, plankton are defined by their ecological niche rather than any phylogenetic or taxonomic classification.

Though many planktonic species are microscopic in size, "plankton" includes organisms over a wide range of sizes, including large organisms such as jellyfish.
Technically the term does not include organisms on the surface of the water, which are called "pleuston"—or those that swim actively in the water, which are called "nekton". 

The name "plankton" is derived from the Greek adjective πλαγκτός (), meaning "errant", and by extension, "wanderer" or "drifter", and was coined by Victor Hensen in 1887. While some forms are capable of independent movement and can swim hundreds of meters vertically in a single day (a behavior called diel vertical migration), their horizontal position is primarily determined by the surrounding water movement, and plankton typically flow with ocean currents. This is in contrast to nekton organisms, such as fish, squid and marine mammals, which can swim against the ambient flow and control their position in the environment.

Within the plankton, holoplankton spend their entire life cycle as plankton (e.g. most algae, copepods, salps, and some jellyfish). By contrast, meroplankton are only planktic for part of their lives (usually the larval stage), and then graduate to either a nektic (swimming) or benthic (sea floor) existence. Examples of meroplankton include the larvae of sea urchins, starfish, crustaceans, marine worms, and most fish.

The amount and distribution of plankton depends on available nutrients, the state of water and a large amount of other plankton.

The study of plankton is termed planktology and a planktonic individual is referred to as a plankter. The adjective "planktonic" is widely used in both the scientific and popular literature, and is a generally accepted term. However, from the standpoint of prescriptive grammar, the less-commonly used "planktic" is more strictly the correct adjective. When deriving English words from their Greek or Latin roots, the gender-specific ending (in this case, "-on" which indicates the word is neuter) is normally dropped, using only the root of the word in the derivation.

Plankton are primarily divided into broad functional (or trophic level) groups: 
Recognition of the importance of mixotrophy as an ecological strategy is increasing, as well as the wider role this may play in marine biogeochemistry. Studies have shown that mixotrophs are much more important for the marine ecology than previously assumed, and comprise more than half of all microscopic plankton. Their presence act as a buffer that prevents the collapse of ecosystems during times with little to no light.

Plankton are also often described in terms of size. Usually the following divisions are used:
However, some of these terms may be used with very different boundaries, especially on the larger end. The existence and importance of nano- and even smaller plankton was only discovered during the 1980s, but they are thought to make up the largest proportion of all plankton in number and diversity.

The microplankton and smaller groups are microorganisms and operate at low Reynolds numbers, where the viscosity of water is much more important than its mass or inertia.
Plankton inhabit oceans, seas, lakes, ponds. Local abundance varies horizontally, vertically and seasonally. The primary cause of this variability is the availability of light. All plankton ecosystems are driven by the input of solar energy (but see chemosynthesis), confining primary production to surface waters, and to geographical regions and seasons having abundant light.

A secondary variable is nutrient availability. Although large areas of the tropical and sub-tropical oceans have abundant light, they experience relatively low primary production because they offer limited nutrients such as nitrate, phosphate and silicate. This results from large-scale ocean circulation and water column stratification. In such regions, primary production usually occurs at greater depth, although at a reduced level (because of reduced light).

Despite significant macronutrient concentrations, some ocean regions are unproductive (so-called HNLC regions). The micronutrient iron is deficient in these regions, and adding it can lead to the formation of phytoplankton blooms. Iron primarily reaches the ocean through the deposition of dust on the sea surface. Paradoxically, oceanic areas adjacent to unproductive, arid land thus typically have abundant phytoplankton (e.g., the eastern Atlantic Ocean, where trade winds bring dust from the Sahara Desert in north Africa).

While plankton are most abundant in surface waters, they live throughout the water column. At depths where no primary production occurs, zooplankton and bacterioplankton instead consume organic material sinking from more productive surface waters above. This flux of sinking material, so-called marine snow, can be especially high following the termination of spring blooms.

The local distribution of plankton can be affected by wind-driven Langmuir circulation and the biological effects of this physical process.

Aside from representing the bottom few levels of a food chain that supports commercially important fisheries, plankton ecosystems play a role in the biogeochemical cycles of many important chemical elements, including the ocean's carbon cycle.

Primarily by grazing on phytoplankton, zooplankton provide carbon to the planktic foodweb, either respiring it to provide metabolic energy, or upon death as biomass or detritus. Organic material tends to be denser than seawater, so it sinks into open ocean ecosystems away from the coastlines, transporting carbon along with it. This process, called the "biological pump", is one reason that oceans constitute the largest carbon sink on Earth. However, it has been shown to be influenced by increments of temperature. In 2019, a study indicated that at current rates of seawater acidification, we could see Antarctic phytoplanktons smaller and less effective at storing carbon before the end of the century.

It might be possible to increase the ocean's uptake of carbon dioxide () generated through human activities by increasing plankton production through "seeding", primarily with the micronutrient iron. However, this technique may not be practical at a large scale. Ocean oxygen depletion and resultant methane production (caused by the excess production remineralising at depth) is one potential drawback.

Phytoplankton absorb energy from the Sun and nutrients from the water to produce their own nourishment or energy. In the process of photosynthesis, phytoplankton release molecular oxygen () into the water as a waste byproduct. It is estimated that about 50% of the world's oxygen is produced via phytoplankton photosynthesis. The rest is produced via photosynthesis on land by plants. Furthermore, phytoplankton photosynthesis has controlled the atmospheric / balance since the early Precambrian Eon.

The growth of phytoplankton populations is dependent on light levels and nutrient availability. The chief factor limiting growth varies from region to region in the world's oceans. On a broad scale, growth of phytoplankton in the oligotrophic tropical and subtropical gyres is generally limited by nutrient supply, while light often limits phytoplankton growth in subarctic gyres. Environmental variability at multiple scales influences the nutrient and light available for phytoplankton, and as these organisms form the base of the marine food web, this variability in phytoplankton growth influences higher trophic levels. For example, at interannual scales phytoplankton levels temporarily plummet during El Niño periods, influencing populations of zooplankton, fishes, sea birds, and marine mammals.

The effects of anthropogenic warming on the global population of phytoplankton is an area of active research. Changes in the vertical stratification of the water column, the rate of temperature-dependent biological reactions, and the atmospheric supply of nutrients are expected to have important impacts on future phytoplankton productivity. Additionally, changes in the mortality of phytoplankton due to rates of zooplankton grazing may be significant.

Freshly hatched fish larvae are also plankton for a few days, as long as it takes before they can swim against currents.

Zooplankton are the initial prey item for almost all fish larvae as they switch from their yolk sacs to external feeding. Fish rely on the density and distribution of zooplankton to match that of new larvae, which can otherwise starve. Natural factors (e.g., current variations) and man-made factors (e.g. river dams, ocean acidification, rising temperatures) can strongly affect zooplankton, which can in turn strongly affect larval survival, and therefore breeding success.

The importance of both phytoplankton and zooplankton is also well-recognized in extensive and semi-intensive pond fish farming. Plankton population based pond management strategies for fish rearing have been practised by traditional fish farmers for decades, illustrating the importance of plankton even in man-made environments.





</doc>
<doc id="25013" url="https://en.wikipedia.org/wiki?curid=25013" title="Pi Day">
Pi Day

Pi Day is an annual celebration of the mathematical constant (pi). Pi Day is observed on March 14 (3/14 in the "month/day" format) since 3, 1, and 4 are the first three significant digits of . In 2009, the United States House of Representatives supported the designation of Pi Day.

Pi Approximation Day is observed on July 22 (22/7 in the "day/month" format), since the fraction is a common approximation of, which is accurate to two decimal places and dates from Archimedes.

Two Pi Day, also known as Tau Day, is lightly observed on June 28 (6/28 in the "month/day" format).

In 1988, the earliest known official or large-scale celebration of Pi Day was organized by Larry Shaw at the San Francisco Exploratorium, where Shaw worked as a physicist, with staff and public marching around one of its circular spaces, then consuming fruit pies. The Exploratorium continues to hold Pi Day celebrations.

On March 12, 2009, the U.S. House of Representatives passed a non-binding resolution (), recognizing March 14, 2009 as National Pi Day. For Pi Day 2010, Google presented a Google Doodle celebrating the holiday, with the word Google laid over images of circles and pi symbols; and for the 30th anniversary in 2018, it was a Dominique Ansel pie with the circumference divided by its diameter.

The entire month of March 2014 (3/14) was observed by some as "Pi Month". In the year 2015, March 14 was celebrated as "Super Pi Day". It had special significance, as the date is written as 3/14/15 in month/day/year format. At 9:26:53, the date and time together represented the first 10 digits of .

Pi Day has been observed in many ways, including eating pie, throwing pies and discussing the significance of the number , due to a pun based on the words "pi" and "pie" being homophones in English (), and the coincidental circular shape of many pies. Also, some schools hold competitions as to which student can recall pi to the highest number of decimal places.

Massachusetts Institute of Technology has often mailed its application decision letters to prospective students for delivery on Pi Day. Starting in 2012, MIT has announced it will post those decisions (privately) online on Pi Day at exactly 6:28 pm, which they have called "Tau Time", to honor the rival numbers pi and tau equally. In 2015, the regular decisions were put online at 9:26 am, following that year's "pi minute". June 28 is "Two Pi Day", also known as "Tau Day". 2, also known by the Greek letter tau (τ) is a common multiple in mathematical formulae. Some have argued that τ is the more fundamental constant, and that Tau Day should be celebrated instead. Celebrations of this date jokingly suggest eating "twice the pie".

Princeton, New Jersey, hosts numerous events in a combined celebration of Pi Day and Albert Einstein's birthday, which is also March 14. Einstein lived in Princeton for more than twenty years while working at the Institute for Advanced Study. In addition to pie eating and recitation contests, there is an annual Einstein look-alike contest.




</doc>
<doc id="25017" url="https://en.wikipedia.org/wiki?curid=25017" title="Positivism (disambiguation)">
Positivism (disambiguation)

Positivism is a philosophy which states that the only authentic knowledge is scientific knowledge. Positivism was central to the foundation of academic sociology.

Positivism may also refer to:



</doc>
<doc id="25018" url="https://en.wikipedia.org/wiki?curid=25018" title="Pauli effect">
Pauli effect

The Pauli effect or Pauli's Device Corollary is the supposed tendency of technical equipment to encounter critical failure in the presence of certain people. The term was coined after mysterious anecdotal stories involving Austrian theoretical physicist Wolfgang Pauli, describing numerous instances in which demonstrations involving equipment suffered technical problems only when he was present.

The Pauli effect is not related with the Pauli exclusion principle, which is a bona fide physical phenomenon named after Pauli. However the Pauli effect was humorously tagged as a second Pauli exclusion principle, according to which "a functioning device and Wolfgang Pauli may not occupy the same room". Pauli himself was convinced that the effect named after him was real. Pauli corresponded with Hans Bender and Carl Jung and saw the effect as an example of the concept of synchronicity.

Since the 20th century, the work of physics research has been divided between theorists and experimentalists (see scientific method). Only a few physicists, such as Enrico Fermi, have been successful in both roles. Lacking an aptitude or interest in experimental work, many theorists have earned a reputation for accidentally breaking experimental equipment. Pauli was exceptional in this regard: it was postulated that he was such a good theorist that any experiments would be compromised by virtue of his presence in the vicinity. For fear of the Pauli effect, the experimental physicist Otto Stern banned Pauli from his laboratory located in Hamburg despite their friendship. Pauli was convinced that the effect named after him was real. He corresponded with Carl Jung and Marie-Louise von Franz about the concept of synchronicity and did so as well with Hans Bender, lecturer at Freiburg university Institut für Grenzgebiete der Psychologie und Psychohygiene, the only parapsychology chair in Germany.

Jung and Pauli saw some parallels between physics and depth psychology. Pauli was among the honored guests at the foundation festivities of the C.G. Jung Institute in Zürich 1948. A famous Pauli effect at the ceremony— as he entered, a china flower vase fell on the floor without any obvious reason—caused Pauli to write his article "Background-Physics", in which he tries to find complementary relationships between physics and depth psychology.

An incident occurred in the physics laboratory at the University of Göttingen. An expensive measuring device, for no apparent reason, suddenly stopped working, although Pauli was in fact "absent". James Franck, the director of the institute, reported the incident to his colleague Pauli in Zürich with the humorous remark that at least this time Pauli was innocent. However, it turned out that Pauli had been on a railway journey to Copenhagen and had switched trains in the Göttingen rail station at about the time of the failure. The incident is reported in George Gamow's book "Thirty Years That Shook Physics", where it is also claimed the more talented the theoretical physicist, the stronger the effect.

R. Peierls describes a case when at one reception this effect was to be parodied by deliberately crashing a chandelier upon Pauli's entrance. The chandelier was suspended on a rope to be released, but it stuck instead, thus becoming a real example of the Pauli effect.

In February 1950, when he was at Princeton University, the cyclotron burnt, and he asked himself if this mischief belonged to such a Pauli effect, named after him.





</doc>
<doc id="25020" url="https://en.wikipedia.org/wiki?curid=25020" title="Pat Mills">
Pat Mills

Pat Eamon Mills (born 1949) is a British comics writer and editor who, along with John Wagner, revitalised British boys comics in the 1970s, and has remained a leading light in British comics ever since. He has been called "the godfather of British comics".

His comics are notable for their violence and anti-authoritarianism. He is best known for creating "2000 AD" and playing a major part in the development of "Judge Dredd".

Mills started his career as a sub-editor for D. C. Thomson & Co. Ltd, where he met Wagner. In 1971 both left to go freelance, and were soon writing scripts for IPC's girls' and humour comics. After D.C. Thomson launched "Warlord", a successful war-themed weekly, Mills was asked in 1975 to develop a rival title for IPC. Based in the girls' comics department to avoid the attention of the staff of the boys' department, Mills, along with Wagner and Gerry Finley-Day, worked in secret to create "Battle Picture Weekly". "Battle"'s stories were more violent and its characters more working class than IPC's traditional fare, and it was an immediate hit. Having made the comic ready for launch, Mills resigned as editor. He would later write the celebrated First World War series "Charley's War", drawn by Joe Colquhoun, for the title.

After launching "Battle", Mills began developing a new boys' title, "Action", launched in 1976. "Action"'s mix of violence and anti-authoritarianism proved controversial and the title lasted less than a year before being withdrawn in the face of media protests. It was briefly revived in neutered form before being merged into "Battle".

His next creation was the science fiction-themed weekly "2000 AD", launched in 1977. As with "Battle" and "Action" he developed most of the early series before handing them over to other writers. He took over the development of "Judge Dredd" when creator John Wagner temporarily walked out, and wrote many of the early stories, establishing the character and his world, before Wagner returned.

In 1978 IPC launched "Starlord", a short-lived companion title for "2000 AD". Mills contributed "Ro-Busters", a series about a robot disaster squad, which moved to "2000 AD" when "Starlord" was cancelled. "Ro-Busters" was the beginning of a mini-universe of interrelated stories Mills was to create for "2000 AD", including "ABC Warriors" and "Nemesis the Warlock". Artist Kevin O'Neill was involved in the creation of all three. "Nemesis" in particular, featuring a morally ambiguous alien hero fighting a despotic human empire, allowed Mills to work out his feelings towards religion and imperialism. Another strand of his "2000 AD" work was "Sláine", a barbarian fantasy based on Celtic mythology and neo-paganism, which he co-created with his then wife Angela Kincaid (with whom he also created the children's series of books, "The Butterfly Children").

Mills also had a hand in IPC's line of Horror comics aimed at girls such as "Chiller".

He has had little success in American comics, with the exception of Metalzoic and Marshal Law, published by DC and Epic comics respectively in the late 1980s, both drawn by O'Neill.

In 1986 he edited the short-lived comic "Diceman", which featured characters from "2000 AD". He wrote nearly every story.

In 1988 he was involved in the launch of "Crisis", a politically aware "2000 AD" spin-off aimed at older readers. For it he wrote "Third World War", drawn initially by Carlos Ezquerra, a polemical critique of global capitalism and the ways it exploits the developing world. The title lasted until 1991 and launched the careers of talents such as Garth Ennis, John Smith and Sean Phillips.

In 1991 Mills launched "Toxic!", an independent colour newsstand weekly comic with a violent, anarchic tone, perhaps as a reaction against the politically worthy "Crisis", and a creator-owned ideal. Many of the stories were created by Mills and co-writer Tony Skinner, including "Accident Man", an assassin who makes his hits look like accidents. "Toxic!" lasted less than a year, but gave a start to talents such as Duke Mighten and Martin Emond.

In 1995, he broke in the French market, one of his life's goals, with "Sha", created with French artist Olivier Ledroit.

He continues to write "Sláine", "Bill Savage", "Black Siddha" and "ABC Warriors" for "2000 AD", and also the Franco-Belgian comic "Requiem Vampire Knight", with art by Olivier Ledroit and its spin-off Claudia Chevalier Vampire, with art by Franck Tacito.

Two new series, "Greysuit", a super-powered government agent drawn by John Higgins, and "Defoe", a 17th-century zombie hunter drawn by Leigh Gallagher, began in "2000 AD" prog 1540.

Mills has formed Repeat Offenders with artist Clint Langley and Jeremy Davis "to develop graphic novel concepts with big-screen potential" and the first project is a graphic novel called "American Reaper", serialised in the "Judge Dredd Megazine" (#316-ongoing as of October 2011). It has been optioned by Trudie Styler's Xingu Films and Mills has written the screenplay.

He has also written two "Doctor Who" audio plays, "Dead London" (2008) and "The Scapegoat" (2009) for Big Finish Productions, featuring the Eighth Doctor and Lucie Miller. The first audio play was released as the first part of the second season of the Eighth Doctor Adventures and the second as part of the third season. In 2010 Mills adapted a story that had been started by him and Wagner for Doctor Who in the 1980s and was produced by Big Finish as "The Song of Megaptera".

In 2017 he wrote, with Kevin O'Neill, and published two novels, "Serial Killer" and "Goodnight, John-Boy", part of a planned series of four books. Also in that year, he published his memoirs, "Be Pure! Be Vigilant! Behave! 2000 AD and Judge Dredd: The Secret History" in print and as an e-book. Mills also narrated the audiobook version himself. (The title is the catchphrase of the villain in his series "Nemesis the Warlock".)

In 2018 the film "Accident Man" was released, based on his comic strip for "Toxic!"

As well as his influential role in creating and contributing to numerous of British comics, Mills has produced work in both America and Europe.



 


</doc>
<doc id="25021" url="https://en.wikipedia.org/wiki?curid=25021" title="Pearl Index">
Pearl Index

The Pearl Index, also called the Pearl rate, is the most common technique used in clinical trials for reporting the effectiveness of a birth control and tampon selection.

formula_1

Three kinds of information are needed to calculate a Pearl Index for a particular study:

There are two calculation methods for determining the Pearl Index:

In the first method, the relative number of pregnancies in the study is divided by the number of months of exposure, and then multiplied by 1200.

In the second method, the number of pregnancies in the study is divided by the number of menstrual cycles experienced by women in the study, and then multiplied by 1300. 1300 instead of 1200 is used on the basis that the length of the average menstrual cycle is 28 days, or 13 cycles per year.

The Pearl Index is sometimes used as a statistical estimation of the number of unintended pregnancies in 100 woman-years of exposure (e.g. 100 women over one year of use, or 10 women over 10 years). It is also sometimes used to compare birth control methods, a lower Pearl index representing a lower chance of getting unintentionally pregnant.
Usually two Pearl Indexes are published from studies of birth control methods: 

The index was introduced by Raymond Pearl in 1934. It has remained popular for over eighty years, in large part because of the simplicity of the calculation.

Like all measures of birth control effectiveness, the Pearl Index is a calculation based on the observations of a given sample population. Thus studies of different populations using the same contraceptive will yield different values for the index. The culture and demographics of the population being studied, and the instruction technique used to teach the method, have significant effects on its failure rate.

The Pearl Index has unique shortcomings, however. It assumes a constant failure rate over time. That is an incorrect assumption for two reasons: first, the most fertile couples will get pregnant first. Couples remaining later in the study are, on average, of lower fertility. Second, most birth control methods have better effectiveness in more experienced users. The longer a couple is in the study, the better they are at using the method. So the longer the study length, the lower the Pearl Index will be - and comparisons of Pearl Indexes from studies of different lengths cannot be accurate.

The Pearl Index also provides no information on factors other than accidental pregnancy which may influence effectiveness calculations, such as:

A common misperception is that the highest possible Pearl Index is 100 - i.e. 100% of women in the study conceive in the first year. However, if all the women in the study conceived in the first month, the study would yield a Pearl Index of 1200 or 1300. The Pearl Index is only accurate as a statistical estimation of per-year risk of pregnancy if the pregnancy rate in the study was very low.

In 1966, two birth control statisticians advocated abandonment of the Pearl Index:


</doc>
<doc id="25022" url="https://en.wikipedia.org/wiki?curid=25022" title="Paul Auster">
Paul Auster

Paul Benjamin Auster (born February 3, 1947) is an American writer and film director. His notable works include "The New York Trilogy" (1987), "Moon Palace" (1989), "The Music of Chance" (1990), "The Book of Illusions" (2002), "The Brooklyn Follies" (2005), "Invisible" (2009), "Sunset Park" (2010), "Winter Journal" (2012), and "4 3 2 1" (2017). His books have been translated into more than forty languages.

Paul Auster was born in Newark, New Jersey, to Jewish middle-class parents of Polish descent, Queenie (née Bogat) and Samuel Auster. He grew up in South Orange, New Jersey and Newark and graduated from Columbia High School in Maplewood.

After graduating from Columbia University with B.A. and M.A. degrees in 1970, he moved to Paris, France where he earned a living translating French literature. Since returning to the U.S. in 1974, he has published poems, essays, and novels, as well as translations of French writers such as Stéphane Mallarmé and Joseph Joubert.
Following his acclaimed debut work, a memoir entitled "The Invention of Solitude", Auster gained renown for a series of three loosely connected stories published collectively as "The New York Trilogy". Although these books allude to the detective genre they are not conventional detective stories organized around a mystery and a series of clues. Rather, he uses the detective form to address existential issues and questions of identity, space, language, and literature, creating his own distinctively postmodern (and critique of postmodernist) form in the process. According to Auster, "...the "Trilogy" grows directly out of "The Invention of Solitude"."

The search for identity and personal meaning has permeated Auster's later publications, many of which concentrate heavily on the role of coincidence and random events ("The Music of Chance") or increasingly, the relationships between people and their peers and environment ("The Book of Illusions", "Moon Palace"). Auster's heroes often find themselves obliged to work as part of someone else's inscrutable and larger-than-life schemes. In 1995, Auster wrote and co-directed the films "Smoke" (which won him the Independent Spirit Award for Best First Screenplay) and "Blue in the Face". Auster's more recent works, from "Oracle Night" (2003) to "4 3 2 1" (2017), have also met with critical acclaim.

He was on the PEN American Center Board of Trustees from 2004 to 2009, and Vice President during 2005 to 2007.

In 2012, Auster was quoted as saying in an interview that he would not visit Turkey, in protest of its treatment of journalists. The Turkish Prime Minister Recep Tayyip Erdoğan replied: "As if we need you! Who cares if you come or not?" Auster responded: "According to the latest numbers gathered by International PEN, there are nearly one hundred writers imprisoned in Turkey, not to speak of independent publishers such as Ragıp Zarakolu, whose case is being closely watched by PEN Centers around the world".

Auster's most recent book, "A Life in Words," was published in October 2017 by Seven Stories Press. It brings together three years of conversations with the Danish scholar I.B. Siegumfeldt about each one of his works, both fiction and non-fiction. It is a primary source for understanding Auster's approach to his work.

Auster is willing to give Iranian translators permission to write Persian versions of his works in exchange for a small fee; Iran does not recognize international copyright laws.

Much of the early scholarship about Auster's work saw links between it and the theories of such French writers as Jacques Lacan, Jacques Derrida, and others. Auster himself has denied these influences and has asserted in print that "I've read only one short essay by Lacan, the "Purloined Letter," in the "Yale French Studies" issue on poststructuralism—all the way back in 1966." Other scholars have seen influences in Auster's work of the American transcendentalists of the nineteenth century, as exemplified by Henry David Thoreau and Ralph Waldo Emerson. The transcendentalists believed that the symbolic order of civilization has separated us from the natural order of the world, and that by moving into nature, as Thoreau did, as he described in "Walden", it would be possible to return to this natural order.

Edgar Allan Poe, Samuel Beckett, and Nathaniel Hawthorne have also had a strong influence on Auster's writing. Auster has specifically referred to characters from Poe and Hawthorne in his novels, for example William Wilson in "City of Glass" or Hawthorne's Fanshawe in "The Locked Room", both from "The New York Trilogy".

Paul Auster's reappearing subjects are:

"Over the past twenty-five years," opined Michael Dirda in "The New York Review of Books" in 2008, "Paul Auster has established one of the most distinctive niches in contemporary literature." Dirda also has extolled his loaded virtues in "The Washington Post":

Ever since "City of Glass", the first volume of his "New York Trilogy", Auster has perfected a limpid, confessional style, then used it to set disoriented heroes in a seemingly familiar world gradually suffused with mounting uneasiness, vague menace and possible hallucination. His plots – drawing on elements from suspense stories, existential récit, and autobiography – keep readers turning the pages, but sometimes end by leaving them uncertain about what they've just been through.

Writing about Auster's most recent novel, "4 3 2 1", "Booklist" critic Donna Seaman remarked:Auster has been turning readers' heads for three decades, bending the conventions of storytelling, blurring the line between fiction and autobiography, infusing novels with literary and cinematic allusions, and calling attention to the art of storytelling itself, not with cool, intellectual remove, but rather with wonder, gratitude, daring, and sly humor. ... Auster's fiction is rife with cosmic riddles and rich in emotional complexity. He now presents his most capacious, demanding, eventful, suspenseful, erotic, structurally audacious, funny, and soulful novel to date. ... Auster is conducting a grand experiment, not only in storytelling, but also in the endless nature-versus-nurture debate, the perpetual dance between inheritance and free will, intention and chance, dreams and fate. This elaborate investigation into the big what-if is also a mesmerizing dramatization of the multitude of clashing selves we each harbor within. ... A paean to youth, desire, books, creativity, and unpredictability, it is a four-faceted bildungsroman and an ars poetica, in which Auster elucidates his devotion to literature and art. He writes, 'To combine the strange with the familiar: that was what Ferguson aspired to, to observe the world as closely as the most dedicated realist and yet to create a way of seeing the world through a different, slightly distorting lens.' Auster achieves this and much more in his virtuoso, magnanimous, and ravishing opus.

The English critic James Wood, however, offered Auster little praise:

Clichés, borrowed language, bourgeois bêtises are intricately bound up with modern and postmodern literature. For Flaubert, the cliché and the received idea are beasts to be toyed with and then slain. "Madame Bovary" actually italicizes examples of foolish or sentimental phrasing. Charles Bovary's conversation is likened to a pavement, over which many people have walked; twentieth-century literature, violently conscious of mass culture, extends this idea of the self as a kind of borrowed tissue, full of other people's germs. Among modern and postmodern writers, Beckett, Nabokov, Richard Yates, Thomas Bernhard, Muriel Spark, Don DeLillo, Martin Amis, and David Foster Wallace have all employed and impaled cliché in their work. Paul Auster is probably America's best-known postmodern novelist; his "New York Trilogy" must have been read by thousands who do not usually read avant-garde fiction. Auster clearly shares this engagement with mediation and borrowedness—hence, his cinematic plots and rather bogus dialogue—and yet he does nothing with cliché except use it. This is bewildering, on its face, but then Auster is a peculiar kind of postmodernist. Or is he a postmodernist at all? Eighty per cent of a typical Auster novel proceeds in a manner indistinguishable from American realism; the remaining twenty per cent does a kind of postmodern surgery on the eighty per cent, often casting doubt on the veracity of the plot. Nashe, in "The Music of Chance" (1990), sounds as if he had sprung from a Raymond Carver story (although Carver would have written more interesting prose) ... One reads Auster's novels very fast, because they are lucidly written, because the grammar of the prose is the grammar of the most familiar realism (the kind that is, in fact, comfortingly artificial), and because the plots, full of sneaky turns and surprises and violent irruptions, have what the Times once called "all the suspense and pace of a bestselling thriller." There are no semantic obstacles, lexical difficulties, or syntactical challenges. The books fairly hum along. The reason Auster is not a realist writer, of course, is that his larger narrative games are anti-realist or surrealist.

Wood also bemoaned Auster's 'b-movie dialogue', 'absurdity', 'shallow skepticism', 'fake realism' and 'balsa-wood backstories'. Wood highlighted what he saw as the issues in Auster's fiction in a parody:

Roger Phaedo had not spoken to anyone for ten years. He confined himself to his Brooklyn apartment, obsessively translating and retranslating the same short passage from Rousseau's "Confessions." A decade earlier, a mobster named Charlie Dark had attacked Phaedo and his wife. Phaedo was beaten to within an inch of his life; Mary was set on fire, and survived just five days in the I.C.U. By day, Phaedo translated; at night, he worked on a novel about Charlie Dark, who was never convicted. Then Phaedo drank himself senseless with Scotch. He drank to drown his sorrows, to dull his senses, to forget himself. The phone rang, but he never answered it. Sometimes, Holly Steiner, an attractive woman across the hall, would silently enter his bedroom, and expertly rouse him from his stupor. At other times, he made use of the services of Aleesha, a local hooker. Aleesha's eyes were too hard, too cynical, and they bore the look of someone who had already seen too much. Despite that, Aleesha had an uncanny resemblance to Holly, as if she were Holly's double. And it was Aleesha who brought Roger Phaedo back from the darkness. One afternoon, wandering naked through Phaedo's apartment, she came upon two enormous manuscripts, neatly stacked. One was the Rousseau translation, each page covered with almost identical words; the other, the novel about Charlie Dark. She started leafing through the novel. "Charlie Dark!" she exclaimed. "I knew Charlie Dark! He was one tough cookie. That bastard was in the Paul Auster gang. I'd love to read this book, baby, but I'm always too lazy to read long books. Why don't you read it to me?" And that is how the ten-year silence was broken. Phaedo decided to please Aleesha. He sat down, and started reading the opening paragraph of his novel, the novel you have just read.

Auster was married to the writer Lydia Davis. They have one son together, Daniel Auster.

Auster and his second wife, writer Siri Hustvedt (the daughter of professor and scholar Lloyd Hustvedt), were married in 1981, and they live in Brooklyn. Together they have one daughter, Sophie Auster.

He has said his politics are "far to the left of the Democratic Party" but that he votes Democratic because he doubts a socialist candidate could win. He has described right-wing Republicans as "jihadists" and the election of Donald Trump as "the most appalling thing I've seen in politics in my life."












</doc>
<doc id="25030" url="https://en.wikipedia.org/wiki?curid=25030" title="Plain text">
Plain text

In computing, plain text is a loose term for data (e.g. file contents) that represent only characters of readable material but not its graphical representation nor other objects (floating-point numbers, images, etc.). It may also include a limited number of characters that control simple arrangement of text, such as spaces, line breaks, or tabulation characters (although tab characters can "mean" many different things, so are hardly "plain"). Plain text is different from formatted text, where style information is included; from structured text, where structural parts of the document such as paragraphs, sections, and the like are identified; and from binary files in which some portions must be interpreted as binary objects (encoded integers, real numbers, images, etc.).

The term is sometimes used quite loosely, to mean files that contain "only" "readable" content (or just files with nothing that the speaker doesn't prefer). For example, that could exclude any indication of fonts or layout (such as markup, markdown, or even tabs); characters such as curly quotes, non-breaking spaces, soft hyphens, em dashes, and/or ligatures; or other things.

In principle, plain text can be in any encoding, but occasionally the term is taken to imply ASCII. As Unicode-based encodings such as UTF-8 and UTF-16 become more common, that usage may be shrinking.

Plain text is also sometimes used only to exclude "binary" files: those in which at least some parts of the file cannot be correctly interpreted via the character encoding in effect. For example, a file or string consisting of "hello" (in whatever encoding), following by 4 bytes that express a binary integer that is "not" just a character, is a binary file, not plain text by even the loosest common usages. Put another way, translating a plain text file to a character encoding that uses entirely different number to represent characters, does not change the meaning (so long as you know what encoding is in use), but for binary files such a conversion "does" change the meaning of at least some parts of the file.

Files that contain markup or other meta-data are generally considered plain-text, so long as the markup is also in directly human-readable form (as in HTML, XML, and so on; as Coombs, Renear, and DeRose argue, punctuation is itself markup; and no one considers punctuation to disqualify a file from being plain text).

The use of plain text rather than binary files, enables files to survive much better "in the wild", in part by making them largely immune to computer architecture incompatibilities. For example, all the problems of Endianness can be avoided (with encodings such as UCS-2 rather than UTF-8, endianness matters, but uniformly for every character, rather than for potentially-unknown subsets of it).

According to The Unicode Standard,

Thus, representations such as SGML, RTF, HTML, XML, wiki markup, and TeX, as well as nearly all programming language source code files, are considered plain text. The particular content is irrelevant to whether a file is plain text. For example, an SVG file can express drawings or even bitmapped graphics, but is still plain text.

According to The Unicode Standard, plain text has two main properties in regard to rich text:

Files that contain markup or other meta-data are generally considered plain-text, as long as the entirety remains in directly human-readable form (as in HTML, XML, and so on (as Coombs, Renear, and DeRose argue, punctuation is itself markup). The use of plain text rather than bit-streams to express markup, enables files to survive much better "in the wild", in part by making them largely immune to computer architecture incompatibilities.

According to The Unicode Standard:

For instance, rich text such as SGML, RTF, HTML, XML, wiki markup, and TeX rely on plain text.

According to The Unicode Standard, plain text has two main properties in regard to rich text:

The purpose of using plain text today is primarily independence from programs that require their very own special encoding or formatting or file format. Plain text files can be opened, read, and edited with ubiquitous text editors and utilities.

A command-line interface allows people to give commands in plain text and get a response, also typically in plain text.

Many other computer programs are also capable of processing or creating plain text, such as countless programs in DOS, Windows, classic Mac OS, and Unix and its kin; as well as web browsers (a few browsers such as Lynx and the Line Mode Browser produce only plain text for display) and other e-text readers.

Plain text files are almost universal in programming; a source code file containing instructions in a programming language is almost always a plain text file. Plain text is also commonly used for configuration files, which are read for saved settings at the startup of a program.

Plain text is used for much e-mail.

A comment, a ".txt" file, or a TXT Record generally contains only plain text (without formatting) intended for humans to read.

The best format for storing knowledge persistently is plain text, rather than some binary format.

Before the early 1960s, computers were mainly used for number-crunching rather than for text, and memory was extremely expensive. Computers often allocated only 6 bits for each character, permitting only 64 characters—assigning codes for A-Z, a-z, and 0-9 would leave only 2 codes: nowhere near enough. Most computers opted not to support lower-case letters. Thus, early text projects such as Roberto Busa's Index Thomisticus, the Brown Corpus, and others had to resort to conventions such as keying an asterisk preceding letters actually intended to be upper-case.

Fred Brooks of IBM argued strongly for going to 8-bit bytes, because someday people might want to process text; and won. Although IBM used EBCDIC, most text from then on came to be encoded in ASCII, using values from 0 to 31 for (non-printing) control characters, and values from 32 to 127 for graphic characters such as letters, digits, and punctuation. Most machines stored characters in 8 bits rather than 7, ignoring the remaining bit or using it as a checksum.

The near-ubiquity of ASCII was a great help, but failed to address international and linguistic concerns. The dollar-sign ("$") was not so useful in England, and the accented characters used in Spanish, French, German, and many other languages were entirely unavailable in ASCII (not to mention characters used in Greek, Russian, and most Eastern languages). Many individuals, companies, and countries defined extra characters as needed—often reassigning control characters, or using value in the range from 128 to 255. Using values above 128 conflicts with using the 8th bit as a checksum, but the checksum usage gradually died out.

These additional characters were encoded differently in different countries, making texts impossible to decode without figuring out the originator's rules. For instance, a browser might display ¬A rather than ` if it tried to interpret one character set as another. The International Organisation for Standardisation (ISO) eventually developed several code pages under ISO 8859, to accommodate various languages. The first of these (ISO 8859-1) is also known as "Latin-1", and covers the needs of most (not all) European languages that use Latin-based characters (there was not quite enough room to cover them all). ISO 2022 then provided conventions for "switching" between different character sets in mid-file. Many other organisations developed variations on these, and for many years Windows and Macintosh computers used incompatible variations.

The text-encoding situation became more and more complex, leading to efforts by ISO and by the Unicode Consortium to develop a single, unified character encoding that could cover all known (or at least all currently known) languages. After some conflict, these efforts were unified. Unicode currently allows for 1,114,112 code values, and assigns codes covering nearly all modern text writing systems, as well as many historical ones and for many non-linguistic characters such as printer's dingbats, mathematical symbols, etc.

Text is considered plain-text regardless of its encoding. To properly understand or process it the recipient must know (or be able to figure out) what encoding was used; however, they need not know anything about the computer architecture that was used, or about the binary structures defined by whatever program (if any) created the data.

Perhaps the most common way of explicitly stating the specific encoding of plain text is with a MIME type.
For email and http, the default MIME type is "text/plain" -- plain text without markup.
Another MIME type often used in both email and http is "text/html; charset=UTF-8" -- plain text represented using UTF-8 character encoding with HTML markup.
Another common MIME type is "application/json" -- plain text represented using UTF-8 character encoding with JSON markup.

When a document is received without any explicit indication of the character encoding, some applications use charset detection to attempt to guess what encoding was used.

ASCII reserves the first 32 codes (numbers 0–31 decimal) for control characters known as the "C0 set": codes originally intended not to represent printable information, but rather to control devices (such as printers) that make use of ASCII, or to provide meta-information about data streams such as those stored on magnetic tape. They include common characters like the newline and the tab character.

In 8-bit character sets such as Latin-1 and the other ISO 8859 sets, the first 32 characters of the "upper half" (128 to 159) are also control codes, known as the "C1 set". They are rarely used directly; when they turn up in documents which are ostensibly in an ISO 8859 encoding, their code positions generally refer instead to the characters at that position in a proprietary, system-specific encoding, such as Windows-1252 or Mac OS Roman, that use the codes to instead provide additional graphic characters.

Unicode defines additional control characters, including bi-directional text direction override characters (used to explicitly mark right-to-left writing inside left-to-right writing and the other way around) and variation selectors to select alternate forms of CJK ideographs, emoji and other characters.



</doc>
<doc id="25031" url="https://en.wikipedia.org/wiki?curid=25031" title="Presbyterian Church (USA)">
Presbyterian Church (USA)

The Presbyterian Church (USA), abbreviated PC(USA), is a mainline Protestant Christian denomination in the United States. A part of the Reformed tradition, it is the largest Presbyterian denomination in the US, and known for its relatively progressive stance on doctrine. The PC(USA) was established by the 1983 merger of the Presbyterian Church in the United States, whose churches were located in the Southern and border states, with the United Presbyterian Church in the United States of America, whose congregations could be found in every state. The similarly named Presbyterian Church in America is a separate denomination whose congregations can also trace their history to the various schisms and mergers of Presbyterian churches in the United States.

The denomination had 1,352,678 active members and 19,243 ordained ministers in 9,161 congregations at the end of 2018. This number does not include members who are baptized but who are not confirmed or the inactive members also affiliated. For example, in 2005, the PC(USA) claimed 318,291 baptized, but not confirmed, members and nearly 500,000 inactive members in addition to active members. Its membership has been declining over the past several decades; the trend has significantly accelerated in recent years, partly due to breakaway congregations. Average denominational worship attendance dropped to 565,467 in 2017 from 748,774 in 2013. The PC(USA) is the largest Presbyterian denomination in the United States.

Presbyterians trace their history to the Protestant Reformation in the 16th century. The Presbyterian heritage, and much of its theology, began with the French theologian and lawyer John Calvin (1509–64), whose writings solidified much of the Reformed thinking that came before him in the form of the sermons and writings of Huldrych Zwingli. From Calvin's headquarters in Geneva, the Reformed movement spread to other parts of Europe. John Knox, a former Roman Catholic Priest from Scotland who studied with Calvin in Geneva, took Calvin's teachings back to Scotland and led the Scottish Reformation of 1560. Because of this reform movement, the Church of Scotland embraced Reformed theology and presbyterian polity. The Ulster Scots brought their Presbyterian faith with them to Ireland, where they laid the foundation of what would become the Presbyterian Church in Ireland.

Immigrants from Scotland and Ireland brought Presbyterianism to America as early as 1640, and immigration would remain a large source of growth throughout the colonial era. Another source of growth were a number of New England Puritans who left the Congregational churches because they preferred presbyterian polity. In 1706, seven ministers led by Francis Makemie established the first American presbytery at Philadelphia, which was followed by the creation of the Synod of Philadelphia in 1717.

The First Great Awakening and the revivalism it generated had a major impact on American Presbyterians. Ministers such as William and Gilbert Tennent, a friend of George Whitefield, emphasized the necessity of a conscious conversion experience and pushed for higher moral standards among the clergy. Disagreements over revivalism, itinerant preaching, and educational requirements for clergy led to a division known as the Old Side–New Side Controversy that lasted from 1741 to 1758.

In the South, the Presbyterians were evangelical dissenters, mostly Scotch-Irish, who expanded into Virginia between 1740 and 1758. Spangler (2008) argues they were more energetic and held frequent services better attuned to the frontier conditions of the colony. Presbyterianism grew in frontier areas where the Anglicans had made little impression. Uneducated whites and blacks were attracted to the emotional worship of the denomination, its emphasis on biblical simplicity, and its psalm singing. Some local Presbyterian churches, such as Briery in Prince Edward County, owned slaves. The Briery church purchased five slaves in 1766 and raised money for church expenses by hiring them out to local planters.

After the United States achieved independence from Great Britain, Presbyterian leaders felt that a national Presbyterian denomination was needed, and the Presbyterian Church in the United States of America (PCUSA) was organized. The first General Assembly was held in Philadelphia in 1789. John Witherspoon, president of Princeton University and the only minister to sign the Declaration of Independence, was the first moderator.

Not all American Presbyterians participated in the creation of the PCUSA General Assembly because the divisions then occurring in the Church of Scotland were replicated in America. In 1751, Scottish Covenanters began sending ministers to America, and the Seceders were doing the same by 1753. In 1858, the majority of Covenanters and Seceders merged to create the United Presbyterian Church of North America (UPCNA).

In the decades after independence, many Americans including Calvinists (Presbyterians and Congregationalists), Methodists, and Baptists were swept up in Protestant religious revivals that would later become known as the Second Great Awakening. Presbyterians also helped to shape voluntary societies that encouraged educational, missionary, evangelical, and reforming work. As its influence grew, many non-Presbyterians feared that the PCUSA's informal influence over American life might effectively make it an established church.

The Second Great Awakening divided the PCUSA over revivalism and fear that revivalism was leading to an embrace of Arminian theology. In 1810, frontier revivalists split from the PCUSA and organized the Cumberland Presbyterian Church. Throughout the 1820s, support and opposition to revivalism hardened into well-defined factions, the New School and Old School respectively. By the 1838, the Old School–New School Controversy had divided the PCUSA. There were now two general assemblies each claiming to represent the PCUSA.

In 1858, the New School split along sectional lines when its Southern synods and presbyteries established the pro-slavery United Synod of the Presbyterian Church. Old School Presbyterians followed in 1861 after the start of hostilities in the American Civil War with the formation of the Presbyterian Church in the Confederate States of America. The Presbyterian Church in the CSA absorbed the smaller United Synod in 1864. After the war, this body was renamed the Presbyterian Church in the United States (PCUS) and was commonly nicknamed the "Southern Presbyterian Church" throughout its history. In 1869, the northern PCUSA's Old School and New School factions reunited as well and was known as the "Northern Presbyterian Church".

The early part of the 20th century saw continued growth in both major sections of the church. It also saw the growth of Fundamentalist Christianity (a movement of those who believed in the literal interpretation of the Bible as the fundamental source of the religion) as distinguished from Modernist Christianity (a movement holding the belief that Christianity needed to be re-interpreted in light of modern scientific theories such as evolution or the rise of degraded social conditions brought on by industrialization and urbanization).

Open controversy was sparked in 1922, when Harry Emerson Fosdick, a modernist and a Baptist pastoring a PCUSA congregation in New York City, preached a sermon entitled "Shall the Fundamentalists Win?" The crisis reached a head the following year when, in response to the New York Presbytery's decision to ordain a couple of men who could not affirm the virgin birth, the PCUSA's General Assembly reaffirmed the "five fundamentals": the deity of Christ, the Virgin Birth, the vicarious atonement, the inerrancy of Scripture, and Christ's miracles and resurrection. This move against modernism caused a backlash in the form of the "Auburn Affirmation" — a document embracing liberalism and modernism. The liberals began a series of ecclesiastical trials of their opponents, expelled them from the church and seized their church buildings. Under the leadership of J. Gresham Machen, a former Princeton Theological Seminary New Testament Professor who had founded Westminster Theological Seminary in 1929, and who was a PCUSA minister, many of these conservatives would establish what became known as the Orthodox Presbyterian Church in 1936. Although the 1930s and 1940s and the ensuing neo-orthodox theological consensus mitigated much of the polemics during the mid-20th century, disputes erupted again beginning in the mid-1960s over the extent of involvement in the civil rights movement and the issue of ordination of women, and, especially since the 1990s, over the issue of ordination of homosexuals.

The Presbyterian Church in the United States of America was joined by the majority of the Cumberland Presbyterian Church, mostly congregations in the border and Southern states, in 1906. In 1920, it absorbed the Welsh Calvinist Methodist Church. The United Presbyterian Church of North America merged with the PCUSA in 1958 to form the United Presbyterian Church in the United States of America (UPCUSA).

Under Eugene Carson Blake, the UPCUSA's stated clerk, the denomination entered into a period of social activism and ecumenical endeavors, which culminated in the development of the Confession of 1967 which was the church's first new confession of faith in three centuries. The 170th General Assembly in 1958 authorized a committee to develop a brief contemporary statement of faith. The 177th General Assembly in 1965 considered and amended the draft confession and sent a revised version for general discussion within the church. The 178th General Assembly in 1966 accepted a revised draft and sent it to presbyteries throughout the church for final ratification. As the confession was ratified by more than 90% of all presbyteries, the 178th General Assembly finally adopted it in 1967. The UPCUSA also adopted a "Book of Confessions "in 1967, which would include the Confession of 1967, the Westminster Confession and Shorter Catechism, the Heidelberg Catechism, the Second Helvetic and Scots Confessions and the Barmen Declaration.

An attempt to reunite the United Presbyterian Church in the USA with the Presbyterian Church in the United States in the late 1950s failed when the latter church was unwilling to accept ecclesiastical centralization. In the meantime, a conservative group broke away from the Presbyterian Church in the United States in 1973, mainly over the issues of women's ordination and a perceived drift toward theological liberalism. This group formed the Presbyterian Church in America (PCA).

Attempts at union between the churches (UPCUSA and PCUS) were renewed in the 1970s, culminating in the merger of the two churches to form the Presbyterian Church (USA) on June 10, 1983. At the time of the merger, the churches had a combined membership of 3,121,238. Many of the efforts were spearheaded by the financial and outspoken activism of retired businessman Thomas Clinton who died two years before the merger. A new national headquarters was established in Louisville, Kentucky in 1988 replacing the headquarters of the UPCUSA in New York City and the PCUS located in Atlanta, Georgia.

The merger essentially consolidated moderate-to-liberal American Presbyterians into one body. Other US Presbyterian bodies (the Cumberland Presbyterians being a partial exception) place greater emphasis on doctrinal Calvinism, literalist hermeneutics, and conservative politics.

For the most part, PC(USA) Presbyterians, not unlike similar mainline traditions such as the Episcopal Church and the United Church of Christ, are fairly progressive on matters such as doctrine, environmental issues, sexual morality, and economic issues, though the denomination remains divided and conflicted on these issues. Like other mainline denominations, the PC(USA) has also seen a great deal of demographic aging, with fewer new members and declining membership since 1967.

In the 1990s, 2000s, and 2010s, the General Assembly of PC(USA) adopted several social justice initiatives, which covered a range of topics including: stewardship of God's creation, world hunger, homelessness, and LGBT issues. As of 2011, the PC(USA) no longer excludes Partnered Gay and Lesbian ministers from the ministry. Previously, the PC(USA) required its ministers to remain ""chastely in singleness or with fidelity in marriage"." Currently, the PC(USA) permits teaching elders to perform same-gender marriages. On a congregational basis, individual sessions (congregational governing bodies) may choose to permit same-gender marriages.

These changes have led to several renewal movements and denominational splinters. Some conservative-minded groups in the PC(USA), such as the Confessing Movement and the Presbyterian Lay Committee (formed in the mid-1960s) have remained in the main body, rather than leaving to form new, break-away groups.

Several Presbyterian denominations have split from PC(USA) or its predecessors over the years. For example, the Orthodox Presbyterian Church broke away from the Presbyterian Church in the USA (PC-USA) in 1936.

More recently formed Presbyterian denominations have posed a threat to modern day PC(USA) congregations disenchanted with the direction of the denomination, but wishing to continue in a Reformed, Presbyterian denomination. The Presbyterian Church in America (PCA), which does not allow ordained female clergy, separated from Presbyterian Church in the United States in 1973 and has subsequently become the second largest Presbyterian denomination in the United States. The Evangelical Presbyterian Church (EPC), which gives local presbyteries the option of allowing ordained female pastors, broke away from the United Presbyterian Church and incorporated in 1981. A PC(USA) renewal movement, Fellowship of Presbyterians (FOP) (now The Fellowship Community), held several national conferences serving disaffecting Presbyterians. FOP's organizing efforts culminated with the founding of ECO: A Covenant Order of Evangelical Presbyterians (ECO), a new Presbyterian denomination that allows ordination of women but is more conservative theologically than PC(USA).

In 2013 the presbyteries ratified the General Assembly's 2012 vote to allow the ordination of openly gay persons to the ministry and in 2014 the General Assembly voted to amend the church's constitution to define marriage as the union of two persons instead of the union of a man and woman, which was ratified (by the presbyteries) in 2015. This has led to the departure of several hundred congregations. The majority of churches leaving the Presbyterian Church (USA) have chosen to join the Evangelical Presbyterian Church or ECO. Few have chosen to join the larger more conservative Presbyterian Church in America, which does not permit female clergy.

Since 1983 the Presbyterian Youth Triennium has been held every three years at Purdue University in West Lafayette, Indiana, US, and is open to Presbyterian high school students throughout the world. The very first Youth Triennium was held in 1980 at Indiana University and the conference for teens is an effort of the Presbyterian Church (USA), the largest Presbyterian denomination in the nation; Cumberland Presbyterian Church; and Cumberland Presbyterian Church in America, the first African-American denomination to embrace Presbyterianism in the reformed tradition.

The Constitution of PC(USA) is composed of two portions: Part I, the "Book of Confessions" and Part II, the "Book of Order". The "Book of Confessions" outlines the beliefs of the PC(USA) by declaring the creeds by which the Church's leaders are instructed and led. Complementing that is the "Book of Order" which gives the rationale and description for the organization and function of the Church at all levels. The "Book of Order" is currently divided into four sections – 1) The Foundations of Presbyterian Polity 2) The Form of Government, 3) The Directory For Worship, and 4) The Rules of Discipline.

The Presbyterian Church (USA) has a representative form of government, known as presbyterian polity, with four levels of government and administration, as outlined in the "Book of Order". The councils (governing bodies) are as follows: 

At the congregational level, the governing body is called the "session", from the Latin word "sessio", meaning "a sitting". The session is made up of the pastors of the church and all elders elected and installed to active service. Following a pattern set in the first congregation of Christians in Jerusalem described in the Book of Acts in the New Testament, the church is governed by "presbyters" (a term and category that includes elders and Ministers of Word and Sacrament, historically also referred to as "ruling or canon elders" because they "measure" the spiritual life and work of a congregation and ministers as "teaching elders").

The elders are nominated by a nominating committee of the congregation; in addition, nominations from the floor are permissible. Elders are then elected by the congregation. All elders elected to serve on the congregation's session of elders are required to undergo a period of study and preparation for this order of ministry, after which the session examines the elders-elect as to their personal faith; knowledge of doctrine, government, and discipline contained in the Constitution of the church, and the duties of the office of elder. If the examination is approved, the session appoints a day for the service of ordination and installation. Session meetings are normally moderated by a called and installed pastor and minutes are recorded by a clerk, who is also an ordained presbyter. If the congregation does not have an installed pastor, the Presbytery appoints a minister member or elected member of the presbytery as moderator with the concurrence of the local church session. The moderator presides over the session as first among equals and also serves a "liturgical" bishop over the ordination and installation of elders and deacons within a particular congregation.

The session guides and directs the ministry of the local church, including almost all spiritual and fiduciary leadership. The congregation as a whole has only the responsibility to vote on: 1) the call of the pastor (subject to presbytery approval) and the terms of call (the church's provision for compensating and caring for the pastor); 2) the election of its own officers (elders & deacons); 3) buying, mortgaging, or selling real property. All other church matters such as the budget, personnel matters, and all programs for spiritual life and mission, are the responsibility of the session. In addition, the session serves as an ecclesiastical court to consider disciplinary charges brought against church officers or members.

The session also oversees the work of the deacons, a second body of leaders also tracing its origins to the Book of Acts. The deacons are a congregational-level group whose duty is "to minister to those who are in need, to the sick, to the friendless, and to any who may be in distress both within and beyond the community of faith." In some churches, the responsibilities of the deacons are taken care of by the session, so there is no board of deacons in that church. In some states, churches are legally incorporated and members or elders of the church serve as trustees of the corporation. However, "the power and duties of such trustees shall not infringe upon the powers and duties of the Session or of the board of deacons." The deacons are a ministry board but not a governing body.

A "presbytery" is formed by all the congregations and the Ministers of Word and Sacrament in a geographic area together with elders selected (proportional to congregation size) from each of the congregations. Four special presbyteries are "non-geographical" in that they overlay other English-speaking presbyteries, though they are geographically limited to the boundaries of a particular synod (see below); it may be more accurate to refer to them as "trans-geographical." Three PC(USA) synods have a non-geographical presbytery for Korean language Presbyterian congregations, and one synod has a non-geographical presbytery for Native American congregations, the Dakota Presbytery. There are currently 172 presbyteries for the nearly 10,000 congregations in the PC(USA).

Only the presbytery (not a congregation, session, synod, or General Assembly) has the responsibility and authority to ordain church members to the ordered ministry of Word and Sacrament, also referred to as a Teaching Elder, to install ministers to (and/or remove them from) congregations as pastors, and to remove a minister from the ministry. A Presbyterian minister is a member of a presbytery. The General Assembly cannot ordain or remove a Teaching Elder, but the Office of the General Assembly does maintain and publish a national directory with the help of each presbytery's stated clerk. Bound versions are published bi-annually with the minutes of the General Assembly. A pastor cannot be a member of the congregation he or she serves as a pastor because his or her primary ecclesiastical accountability lies with the presbytery. Members of the congregation generally choose their own pastor with the assistance and support of the presbytery. The presbytery must approve the choice and officially install the pastor at the congregation, or approve the covenant for a temporary pastoral relationship. Additionally, the presbytery must approve if either the congregation or the pastor wishes to dissolve that pastoral relationship.

The presbytery has authority over many affairs of its local congregations. Only the presbytery can approve the establishment, dissolution, or merger of congregations. The presbytery also maintains a Permanent Judicial Commission, which acts as a court of appeal from sessions, and which exercises original jurisdiction in disciplinary cases against minister members of the presbytery.

A presbytery has two elected officers: a moderator and a stated clerk. The Moderator of the presbytery is elected annually and is either a minister member or an elder commissioner from one of the presbytery's congregations. The Moderator presides at all presbytery assemblies and is the chief overseer at the ordination and installation of ministers in that presbytery. The stated clerk is the chief ecclesial officer and serves as the presbytery's executive secretary and parliamentarian in accordance with the church Constitution and Robert's Rules of Order. While the moderator of a presbytery normally serves one year, the stated clerk normally serves a designated number of years and may be re-elected indefinitely by the presbytery. Additionally, an Executive Presbyter (sometimes designated as General Presbyter, Pastor to Presbytery, Transitional Presbyter) is often elected as a staff person to care for the administrative duties of the presbytery, often with the additional role of a pastor to the pastors. Presbyteries may be creative in the designation and assignment of duties for their staff. A presbytery is required to elect a Moderator and a Clerk, but the practice of hiring staff is optional. Presbyteries must meet at least twice a year, but they have the discretion to meet more often and most do.

"See "Map of Presbyteries and Synods"".

Presbyteries are organized within a geographical region to form a "synod". Each synod contains at least three presbyteries, and its elected voting membership is to include both elders and Ministers of Word and Sacrament in equal numbers. Synods have various duties depending on the needs of the presbyteries they serve. In general, their responsibilities (G-12.0102) might be summarized as: developing and implementing the mission of the church throughout the region, facilitating communication between presbyteries and the General Assembly, and mediating conflicts between the churches and presbyteries. Every synod elects a Permanent Judicial Commission, which has original jurisdiction in remedial cases brought against its constituent presbyteries, and which also serves as an ecclesiastical court of appeal for decisions rendered by its presbyteries' Permanent Judicial Commissions. Synods are required to meet at least biennially. Meetings are moderated by an elected synod Moderator with support of the synod's Stated Clerk. There are currently 16 synods in the PC(USA) and they vary widely in the scope and nature of their work. An ongoing current debate in the denomination is over the purpose, function, and need for synods.

See also the List of Presbyterian Church (USA) synods and presbyteries.

The "General Assembly" is the highest governing body of the PC(USA). Until the 216th assembly met in Richmond, Virginia in 2004, the General Assembly met annually; since 2004, the General Assembly has met biennially in even-numbered years. It consists of commissioners elected by presbyteries (not synods), and its voting membership is proportioned with parity between elders and Ministers of Word and Sacrament. There are many important responsibilities of the General Assembly. Among them, "The Book of Order" lists these four:

The General Assembly elects a moderator at each assembly who moderates the rest of the sessions of that assembly meeting and continues to serve until the next assembly convenes (two years later) to elect a new moderator or co-moderator. Currently, the denomination is served by Co-Moderators Denise Anderson and Jan Edmiston who were elected as the first co-moderators of the 222nd General Assembly (2016). At the 223rd Assembly in St Louis, MO, Co-Moderators Elder Vilmarie Cintrón-Olivieri & The Rev. Cindy Kohmann were elected. See a complete listing of past moderators at another Wikipedia Article.

A Stated Clerk is elected to a four-year term and is responsible for the Office of the General Assembly which conducts the ecclesiastical work of the church. The Office of the General Assembly carries out most of the ecumenical functions and all of the constitutional functions at the Assembly. The former Stated Clerk of the General Assembly is Gradye Parsons, who had served in that role since 2008 and was unanimously reelected in 2012. Parsons did not stand for re-election at the 222nd General Assembly meeting in 2016, and J. Herbert Nelson was elected Stated Clerk at the 2016 General Assembly meeting in Portland. Nelson is the first African American to be elected to the office, and is a third-generation Presbyterian pastor.

The Stated Clerk is also responsible for the records of the denomination, a function formalized in 1925 when the General Assembly created the "Department of Historical Research and Conservation" as part of the Office of the General Assembly. The current "Department of History" is also known as the Presbyterian Historical Society.

Six agencies carry out the work of the General Assembly. These are the Office of the General Assembly, the Presbyterian Publishing Corporation, the Presbyterian Investment and Loan Program, the Board of Pensions, the Presbyterian Foundation, and the Presbyterian Mission Agency (formerly known as the General Assembly Mission Council).

The General Assembly elects members of the Presbyterian Mission Agency Board (formerly General Assembly Mission Council). There are 48 elected members of the Presbyterian Mission Agency Board (40 voting members; 17 non-voting delegates), who represent synods, presbyteries, and the church at-large. Members serve one six-year term, with the exception of the present Moderator of the General Assembly (one 2-year term), the past Moderator of the General Assembly (one 2-year term), the moderator of Presbyterian Women (one 3-year term), ecumenical advisory members (one 2-year term, eligible for two additional terms), and stewardship and audit committee at-large members (one 2-year term, eligible for two additional terms). Among the elected members' major responsibilities is the coordination of the work of the program areas in light of General Assembly mission directions, objectives, goals and priorities. The PMAB meets three times a year. The General Assembly elects an Executive Director of the Presbyterian Mission Agency who is the top administrator overseeing the mission work of the PC(USA). Past Executive Director of the PMA is Ruling Elder Linda Bryant Valentine(2006-2015), and Interim RE Tony De La Rosa. Elected in 2018 is Teaching Elder Diane Givens Moffett (2018- ).

The General Assembly Permanent Judicial Commission (GAPJC) is the highest Church court of the denomination. It composed of one member elected by the General Assembly from each of its constituent synods (16). It has ultimate appellate jurisdiction over all Synod Permanent Judicial Commission cases involving issues of Church Constitution, and original jurisdiction over a small range of cases. The General Assembly Permanent Judicial Commission issues Authoritative Interpretations of The Constitution of the Presbyterian Church (USA) through its decisions.

www.ipc-usa.org/worship/

The denomination maintains affiliations with ten seminaries in the United States. These are:

Two other seminaries are related to the PC(USA) by covenant agreement: Auburn Theological Seminary in New York, New York, and Evangelical Seminary of Puerto Rico in San Juan, Puerto Rico.

There are numerous colleges and universities throughout the United States affiliated with PC(USA). For a complete list, see the article Association of Presbyterian Colleges and Universities. For more information, see the article PC(USA) seminaries.

While not affiliated with the PC(USA), the president of Fuller Theological Seminary, Mark Labberton, is an ordained minister of the PC(USA) and the seminary educates many candidates for ministry.

When the United Presbyterian Church in the USA merged with the Presbyterian Church in the United States there were 3,131,228 members. Statistics shows steadily decline since 1983. (The combined membership of the PCUS and United Presbyterian Church peaked in 1965 at 4.25 million communicant members.)
The PC(USA) maintains extensive statistics on its members. In 2005, the PC(USA) claimed 2.3 million active members as well as nearly 500,000 inactive members; the total membership, including all categories of membership, was 3.1 million members. In 2018 PC(USA) reported 1.32 million active members, less than one-third of its peak membership of 4.25 million members in 1965 and down from 1.57 million members in 2015.
Recent declines in numbers are consistent with the trends of most mainline Protestant denominations in America since the late 20 Century. In 2013, Jan Armstrong, Executive Presbyter of the Presbytery of Santa Barbara, said that the most recent informal OGA (Office of the General Assembly) projections are for an anticipated loss of perhaps 500,000 members over the next 3–4 years, roughly 25% of the denomination's membership.
In 2016 PCUSA total membership was 1,482,767, net loss of 89,893 members. The PCUSA dismissed 99 churches to other denominations in 2016, while dissolving 97 congregations. Seventeen churches were organized during the year and no churches were received from other denominations.

The average local Presbyterian Church has 148 members (the mean in 2018). About 37% of the total congregations report between 1 and 50 members. Another 23% report between 51 and 100 members. The average worship attendance of a local Presbyterian congregation is 77 (51.7% of members). The largest congregation in the PC(USA) is Peachtree Presbyterian Church in Atlanta, Georgia, with a reported membership of 8,989 (2009). It was reported that about 31% of the Presbyterian members are over 71 years old (2018). 

Most PC(USA) members are white (92.9%). Other racial and ethnic members include African-Americans (3.1% of the total membership of the denomination), Asians (2.3%), Hispanics (1.2%), Native Americans (0.2%), and others (0.3%). Despite declines in the total membership of the PC(USA), the percentage of racial-ethnic minority members has stayed about the same since 1995. The ratio of female members (58%) to male members (42%) has also remained stable since the mid-1960s. 

Presbyterians are among the wealthiest Christians denomination in the United States, Presbyterians tend also to be better educated and they have a high number of graduate (64%) and post-graduate degrees (26%) per capita.
According to a 2014 study by the Pew Research Center, Presbyterians ranked as the fourth most financially successful religious group in the United States, with 32% of Presbyterians living in households with incomes of at least $100,000.

The session of the local congregation has a great deal of freedom in the style and ordering of worship within the guidelines set forth in the Directory for Worship section of the "Book of Order". Worship varies from congregation to congregation. The order may be very traditional and highly liturgical, or it may be very simple and informal. This variance is not unlike that seen in the "High Church" and "Low Church" styles of the Anglican Church. The "Book of Order" suggests a worship service ordered around five themes: "gathering around the Word, proclaiming the Word, responding to the Word, the sealing of the Word, and bearing and following the Word into the world." Prayer is central to the service and may be silent, spoken, sung, or read in unison (including The Lord's Prayer). Music plays a large role in most PC(USA) worship services and ranges from chant to traditional Protestant hymns, to classical sacred music, to more modern music, depending on the preference of the individual church and is offered prayerfully and not "for entertainment or artistic display." Scripture is read and usually preached upon. An offering is usually taken.

The Directory for Worship in the Book of Order provides the directions for what must be, or may be included in worship. During the 20th century, Presbyterians were offered optional use of liturgical books:

For more information, see Liturgical book of the Presbyterian Church (USA)

In regard to vestments, the Directory for Worship leaves that decision up to the ministers. Thus, on a given Sunday morning service, a congregation may see the minister leading worship in street clothes, Geneva gown, or an alb. Among the Paleo-orthodoxy and emerging church Presbyterians, clergy are moving away from the traditional black Geneva gown and reclaiming not only the more ancient Eucharist vestments of alb and chasuble, but also cassock and surplice (typically a full length Old English style surplice which resembles the Celtic alb, an ungirdled liturgical tunic of the old Gallican Rite).

The Service for the Lord's Day is the name given to the general format or ordering of worship in the Presbyterian Church as outlined in its Constitution's Book of Order. There is a great deal of liberty given toward worship in that denomination, so while the underlying order and components for the Service for the Lord's Day is extremely common, it varies from congregation to congregation, region to region.

Typical Presbyterian Church USA Order of Worship would look like this. This is taken from Madison Avenue Presbyterian Church, NYC
http://www.mapc.com/worship/order-of-worship/

The creation of the Service for the Lord's Day was one of the most positive contributions of the Worshipbook of 1970. The Book of Common Worship of 1993 leaned heavily upon this service.

The Presbyterian Church (USA) has, in the past, been a leading United States denomination in mission work, and many hospitals, clinics, colleges and universities worldwide trace their origins to the pioneering work of Presbyterian missionaries who founded them more than a century ago.

Currently, the church supports about 215 missionaries abroad annually. Many churches sponsor missionaries abroad at the session level, and these are not included in official statistics.

A vital part of the world mission emphasis of the denomination is building and maintaining relationships with Presbyterian, Reformed and other churches around the world, even if this is not usually considered missions.

The PC(USA) is a leader in disaster assistance relief and also participates in or relates to work in other countries through ecumenical relationships, in what is usually considered not missions, but deaconship.

The General Assembly of the Presbyterian Church (USA) determines and approves ecumenical statements, agreements, and maintains correspondence with other Presbyterian and Reformed bodies, other Christians churches, alliances, councils, and consortia. Ecumenical statements and agreements are subject to the ratification of the presbyteries. The following are some of the major ecumenical agreements and partnerships.

The church is committed to "engage in bilateral and multilateral dialogues with other churches and traditions in order to remove barriers of misunderstanding and establish common affirmations." As of 2012 it is in dialog with the Episcopal Church, the Moravian Church, the Korean Presbyterian Church in America, the Cumberland Presbyterian Church, the Cumberland Presbyterian Church in America, and the US Conference of Catholic Bishops. It also participates in international dialogues through the World Council of Churches and the World Communion of Reformed Churches. The most recent international dialogues include Pentecostal churches, the Seventh-day Adventist Church, Orthodox Church in America, and others.

In 2011 the National Presbyterian Church in Mexico, in 2012 the Mizoram Presbyterian Church and in 2015 the Independent Presbyterian Church of Brazil along with the Evangelical Presbyterian and Reformed Church in Peru severed ties with the PCUSA because of the PCUSA's teaching with regard to homosexuality.

The Presbyterian Church (USA) is in corresponding partnership with the National Council of Churches, the World Communion of Reformed Churches, and the World Council of Churches. It is a member of Churches for Middle East Peace.

In 1997 the PCUSA and three other churches of Reformation heritage: the Evangelical Lutheran Church in America, the Reformed Church in America and the United Church of Christ, acted on an ecumenical proposal of historic importance, known as "A Formula of Agreement". The timing reflected a doctrinal consensus which had been developing over the past thirty-two years coupled with an increasing urgency for the church to proclaim a gospel of unity in contemporary society. In light of identified doctrinal consensus, desiring to bear visible witness to the unity of the Church, and hearing the call to engage together in God's mission, it was recommended:

The term "full communion" is understood here to specifically mean that the four churches:


The agreement assumed the doctrinal consensus articulated in A Common Calling:The Witness of Our Reformation Churches in North America Today, and is to be viewed in concert with that document. The purpose of A Formula of Agreement is to elucidate the complementarity of affirmation and admonition as the basic principle of entering into full communion and the implications of that action as described in A Common Calling.

The 209th General Assembly (1997) approved A Formula of Agreement and in 1998 the 210th General Assembly declared full communion among these Protestant bodies.

The Presbyterian Church (USA) is in corresponding partnership with the National Council of Churches, the World Communion of Reformed Churches, Christian Churches Together, and the World Council of Churches.

As of June 2010, the World Alliance of Reformed Churches merged with the Reformed Ecumenical Council to form the World Communion of Reformed Churches. The result was a form of full communion similar to that outline in the Formula of Agreement, including orderly exchange of ministers.

The PC(USA) is one of nine denominations that joined together to form the Consultation on Church Union, which initially sought a merger of the denominations. In 1998 the Seventh Plenary of the Consultation on Church Union approved a document "Churches in Covenant Communion: The Church of Christ Uniting" as a plan for the formation of a covenant communion of churches. In 2002 the nine denominations inaugurated the new relationship and became known as Churches Uniting in Christ. The partnership is considered incomplete until the partnering communions reconcile their understanding of ordination and devise an orderly exchange of clergy.

 Paragraph G-6.0106b of the Book of Order, which was adopted in 1996, prohibited the ordination of those who were not faithful in heterosexual marriage or chaste in singleness. This paragraph was included in the Book of Order from 1997 to 2011, and was commonly referred to by its pre-ratification designation, "Amendment B". Several attempts were made to remove this from the Book of Order, ultimately culminating in its removal in 2011. In 2011, the Presbyteries of the PC(USA) passed Amendment 10-A permitting congregations to ordain openly gay and lesbian elders and deacons, and allowing presbyteries to ordain ministers without reference to the fidelity/chastity provision, saying "governing bodies shall be guided by Scripture and the confessions in applying standards to individual candidates".

Many Presbyterian scholars, pastors, and theologians have been heavily involved in the debate over homosexuality, over the years. The Presbyterian Church of India cooperation with Presbyterian Church (USA) was dissolved in 2012 when the PC(USA) voted to ordain openly gay clergy to the ministry. In 2012, the PC(USA) granted permission, nationally, to begin ordaining openly gay and lesbian clergy.

Since 1980, the More Light Churches Network has served many congregations and individuals within American Presbyterianism who promote the full participation of all people in the PC(USA) regardless of sexual orientation or gender identity. The Covenant Network of Presbyterians was formed in 1997 to support repeal of "Amendment B" and to encourage networking amongst like-minded clergy and congregations. Other organizations of Presbyterians, such as the Confessing Movement and the Alliance of Confessing Evangelicals, have organized on the other side of the issue to support the fidelity/chastity standard for ordination, which was removed in 2011.

The Presbyterian Church (USA) voted to allow same-gender marriages on June 19, 2014 during its 221st General Assembly, making it one of the largest Christian denominations in the world to allow same-sex unions. This vote lifted a previous ban, and allows pastors to perform marriages in jurisdictions where it is legal. Additionally, the Assembly approved to amend the Book of Order that would change the definition of marriage from "between a man and a woman" to "between two people, traditionally between a man and a woman".

The 2006 "Report of the Theological Task Force on Peace, Unity, and Purity of the Church", in theory, attempted to find common ground. Some felt that the adoption of this report provided for a clear local option mentioned, while the Stated Clerk of the General Assembly, Clifton Kirkpatrick went on record as saying, "Our standards have not changed. The rules of the Book of Order stay in force and all ordinations are still subject to review by higher governing bodies." The authors of the report stated that it is a compromise and return to the original Presbyterian culture of local controls. The recommendation for more control by local presbyteries and sessions is viewed by its opposition as a method for bypassing the constitutional restrictions currently in place concerning ordination and marriage, effectively making the constitutional "standard" entirely subjective.

In the General Assembly gathering of June 2006, Presbyterian voting Commissioners passed an "authoritative interpretation", recommended by the Theological Task Force, of the "Book of Order" (the church constitution). Some argued that this gave presbyteries the "local option" of ordaining or not ordaining anyone based on a particular presbytery's reading of the constitutional statute. Others argued that presbyteries have always had this responsibility and that this new ruling did not change but only clarified that responsibility. On June 20, 2006, the General Assembly voted 298 to 221 (or 57% to 43%) to approve such interpretation. In that same session on June 20, the General Assembly also voted 405 to 92 (with 4 abstentions) to uphold the constitutional standard for ordination requiring fidelity in marriage or chastity in singleness.

The General Assembly of 2008 took several actions related to homosexuality. The first action was to adopt a different translation of the Heidelberg Catechism from 1962, removing the words "homosexual perversions" among other changes. This will require the approval of the 2010 and 2012 General Assemblies as well as the votes of the presbyteries after the 2010 Assembly. The second action was to approve a new Authoritative Interpretation of G-6.0108 of the "Book of Order" allowing for the ordaining body to make decisions on whether or not a departure from the standards of belief of practice is sufficient to preclude ordination. Some argue that this creates "local option" on ordaining homosexual persons. The third action was to replace the text of "Amendment B" with new text: "Those who are called to ordained service in the church, by their assent to the constitutional questions for ordination and installation (W-4.4003), pledge themselves to live lives obedient to Jesus Christ the Head of the Church, striving to follow where he leads through the witness of the Scriptures, and to understand the Scriptures through the instruction of the Confessions. In so doing, they declare their fidelity to the standards of the Church. Each governing body charged with examination for ordination and/or installation (G-14.0240 and G-14.0450) establishes the candidate's sincere efforts to adhere to these standards." This would have removed the "fidelity and chastity" clause. This third action failed to obtain the required approval of a majority of the presbyteries by June 2009. Fourth, a resolution was adopted to affirm the definition of marriage from Scripture and the Confessions as being between a man and a woman.

In July 2010, by a vote of 373 to 323, the General Assembly voted to propose to the presbyteries for ratification a constitutional amendment to remove from the Book of Order section G-6.0106.b. which included this explicit requirement for ordination: "Among these standards is the requirement to live either in fidelity within the covenant of marriage between a man and a woman (W-4.9001), or chastity in singleness." This proposal required ratification by a majority of the 173 presbyteries within 12 months of the General Assembly's adjournment. A majority of presbytery votes was reached in May 2011. The constitutional amendment took effect July 10, 2011. This amendment shifted back to the ordaining body the responsibility for making decisions about whom they shall ordain and what they shall require of their candidates for ordination. It neither prevents nor imposes the use of the so-called "fidelity and chastity" requirement, but it removes that decision from the text of the constitution and places that judgment responsibility back upon the ordaining body where it had traditionally been prior to the insertion of the former G-6.0106.b. in 1997. Each ordaining body, the session for deacon or elder and the presbytery for minister, is now responsible to make its own interpretation of what scripture and the confessions require of ordained officers.

In June 2014, the General Assembly approved a change in the wording of its constitution to define marriage a contract "between a woman and a man" to being "between two people, traditionally a man and a woman". It allowed gay and lesbian weddings within the church and further allow clergy to perform same-sex weddings. That revision gave clergy the choice of presiding over same-sex marriages, but clergy was not compelled to perform same-sex marriage.

PC(USA)'s book of order includes a "trust clause", which grants ownership of church property to the presbytery. Under this trust clause, the presbytery may assert a claim to the property of the congregation in the event of a congregational split, dissolution (closing), or disassociation from the PC(USA). This clause does not prevent particular churches from leaving the denomination, but if they do, they may not be entitled to any physical assets of that congregation unless by agreement with the presbytery. Recently this provision has been vigorously tested in courts of law.

In June 2004, the General Assembly met in Richmond, Virginia, and adopted by a vote of 431–62 a resolution that called on the church's committee on Mission Responsibility through Investment (MRTI) "to initiate a process of phased, selective divestment in multinational corporations operating in Israel". The resolution also said "the occupation ... has proven to be at the root of evil acts committed against innocent people on both sides of the conflict". The church statement at the time noted that "divestment is one of the strategies that U.S. churches used in the 1970s and 80s in a successful campaign to end apartheid in South Africa".

A second resolution, calling for an end to the construction of a wall by the state of Israel, passed. The resolution opposed to the construction of the Israeli West Bank barrier, regardless of its location, and opposed the United States government making monetary contribution to the construction. The General Assembly also adopted policies rejecting Christian Zionism and allowing the continued funding of conversionary activities aimed at Jews. Together, the resolutions caused tremendous dissent within the church and a sharp disconnect with the Jewish community. Leaders of several American Jewish groups communicated to the church their concerns about the use of economic leverages that apply specifically to companies operating in Israel. Some critics of the divestment policy accused church leaders of anti-Semitism.

In June 2006, after the General Assembly in Birmingham, Alabama changed policy (details), both pro-Israel and pro-Palestinian groups praised the resolution. Pro-Israel groups, who had written General Assembly commissioners to express their concerns about a corporate engagement/divestment strategy focused on Israel, praised the new resolution, saying that it reflected the church stepping back from a policy that singled out companies working in Israel. Pro-Palestinian groups said that the church maintained the opportunity to engage and potentially divest from companies that support the Israeli occupation, because such support would be considered inappropriate according to the customary MRTI process.

In August 2011, the American National Middle Eastern Presbyterian Caucus (NMEPC) endorsed the boycott, divestment, and sanctions (BDS) campaign against Israel.

In January 2014, The PC(USA) published "Zionism unsettled", which was commended as "a valuable opportunity to explore the political ideology of Zionism". One critic claimed it was anti-Zionist and characterised the Israeli–Palestinian as a conflict fueled by a "pathology inherent in Zionism". The Simon Wiesenthal Center described the study guide as "a hit-piece outside all norms of interfaith dialogue. It is a compendium of distortions, ignorance and outright lies – that tragically has emanated too often from elites within this church". The PC(USA) subsequently withdrew the publication from sale on its website.

On June 20, 2014 the General Assembly in Detroit approved a measure (310–303) calling for divestment from stock in Caterpillar, Hewlett-Packard and Motorola Solutions in protest of Israeli policies on the West Bank. The vote was immediately and sharply criticized by the American Jewish Committee which accused the General Assembly of acting out of anti-Semitic motives. Proponents of the measure strongly denied the accusations.






</doc>
<doc id="25033" url="https://en.wikipedia.org/wiki?curid=25033" title="Piña colada">
Piña colada

The piña colada (; , "pineapple", and , "strained") is a sweet cocktail made with rum, cream of coconut or coconut milk, and pineapple juice, usually served either blended or shaken with ice. It may be garnished with either a pineapple wedge, maraschino cherry, or both. 
There are two versions of the drink's origin, but both say it originated in Puerto Rico.

The name "piña colada" (spanish) literally means "strained pineapple", a reference to the freshly pressed and strained pineapple juice used in the drink's preparation.

The earliest known story states that in the 19th century, Puerto Rican pirate Roberto Cofresí, to boost his crew's morale, gave them a beverage or cocktail that contained coconut, pineapple and white rum. This was what would be later known as the famous piña colada. With his death in 1825, the recipe for the piña colada was lost. Historian Haydée Reichard disputes this version of the story.

In 1950 "The New York Times" reported that "Drinks in the West Indies range from Martinique's famous rum punch to Cuba's pina colada (rum, pineapple and coconut milk)."

The Caribe Hilton Hotel claims Ramón "Monchito" Marrero created the Piña Colada in 1954 while a bartender at the hotel. According to this account, Mr. Marrero finally settled upon the recipe for the Piña Colada, which he felt captured the true nature and essence of Puerto Rico. The hotel was presented with a proclamation in 2004 by Puerto Rico Governor Sila M. Calderón celebrating the drink's 50th anniversary.

Barrachina, a restaurant in Puerto Rico, says that "a traditional Spanish bartender Don Ramon Portas Mingot in 1963 created what became the world's famous drink: the Piña Colada."

In 1978 Puerto Rico proclaimed the cocktail its official drink.

National Piña Colada Day is celebrated on the islands on 10 July.

This cocktail gained fame in Puerto Rico from 1978, and it gained worldwide fame after Rupert Holmes released his 1979 song "Escape (The Piña Colada Song)", which became a popular hit around the world.

Jazz icon and flugelhorn player Chuck Mangione likewise released a tune titled "Piña Colada" on his 1979 album "Fun and Games".

The cocktail serves as part of the title of the Garth Brooks song "Two Piña Coladas".

As recounted by his friends in José L. Díaz de Villegas's book, the original Monchito recipe was to pour 85 grams of cream of coconut, 170 grams of pineapple juice and 43 grams of white rum into a blender or shaker with crushed ice, blend or shake very well until smooth, then pour into chilled glass and garnish with pineapple wedge and/or a maraschino cherry.
Longdrink

There are many recipes for piña colada. The International Bartenders Association specifies it is:

Mix with crushed ice in blender until smooth, then pour into a chilled glass, garnish and serve. Alternately, the three main components can simply be added to a cocktail glass with ice cubes.

In San Juan, Puerto Rico the recipe is:
In a blender, combine cream of coconut, pineapple juice, heavy cream and rum. Add crushed ice and blend for 15 seconds. Pour in a desired 12-ounce container and use a cherry and fresh pineapple for a garnish.

Different proportions of the core ingredients, as well as different types of rum, may all be used in the piña colada. Frozen piña coladas are also served. Other named variations include:


</doc>
<doc id="25034" url="https://en.wikipedia.org/wiki?curid=25034" title="PackBits">
PackBits

PackBits is a fast, simple lossless compression scheme for run-length encoding of data.

Apple introduced the PackBits format with the release of MacPaint on the Macintosh computer. This compression scheme is one of the types of compression that can be used in TIFF-files. TGA-files also use this RLE compression scheme, but treats data stream as pixels instead of bytes.

A PackBits data stream consists of packets with a one-byte header followed by data. The header is a signed byte; the data can be signed, unsigned, or packed (such as <nowiki>MacPaint</nowiki> pixels).

In the following table, "n" is the value of the header byte as a signed integer.
Note that interpreting 0 as positive or negative makes no difference in the output. Runs of two bytes adjacent to non-runs are typically written as literal data. There is no way based on the PackBits data to determine the end of the data stream; that is to say, one must already know the size of the compressed or uncompressed data before reading a PackBits data stream to know where it ends.

Apple Computer (see the external link) provides this short example of packed data:
codice_1

The following code, written in Microsoft VBA, unpacks the data:
The same implementation in JS:



</doc>
<doc id="25036" url="https://en.wikipedia.org/wiki?curid=25036" title="Pub rock (Australia)">
Pub rock (Australia)

Pub rock is a style of Australian rock and roll popular throughout the 1970s and 1980s, and still influencing contemporary Australian music in the 2000s decade. The term came from the venues where most of these bands originally played — inner-city and suburban pubs. These often noisy, hot, small and crowded venues were not always ideal as music venues and favoured loud, simple songs based on drums and electric guitar riffs.

The Australian version of pub rock incorporates hard rock, blues rock, and/or progressive rock. In the "Encyclopedia of Australian Rock and Pop" (1999), Australian musicologist Ian McFarlane described how, in the early 1970s, Billy Thorpe & The Aztecs, Blackfeather, and Buffalo pioneered Australia's pub rock movement. Australian rock music journalist Ed Nimmervoll declared that "[t]he seeds for Australian heavy rock can be traced back to two important sources, Billy Thorpe's Seventies Aztecs and Sydney band Buffalo".

The emergence of the Australian version of the pub rock genre and the related pub circuit was the result of several interconnected factors. From the 1950s to the 1970s, mainly because of restrictive state liquor licensing laws, only a small proportion of live pop and rock music in Australia was performed on licensed premises (mostly private clubs or discotheques); the majority of concerts were held in non-licensed venues like community, church or municipal halls. These concerts and dances were 'all-ages' events—often with adult supervision—and alcohol was not served.

During the 1960s, however, Australian states began liberalising their licensing laws. Sunday Observance Acts were repealed, pub opening hours were extended, discriminatory regulations — such as the long-standing ban on women entering or drinking in public bars — were removed, and in the 1970s the age of legal majority was lowered from 21 to 18. Concurrently, the members of the so-called "Baby Boomer" generation — who were the main audience for pop and rock music — were reaching their late teens and early twenties, and were thus able to enter such licensed premises. Pub owners soon realised that providing live music (which was often free) would draw young people to pubs in large numbers, and regular rock performances soon became a fixture at many pubs.

In the early 1970s Billy Thorpe & The Aztecs, Blackfeather, and Buffalo pioneered Australia's pub rock movement. In March 1970 Billy Thorpe & The Aztecs consisted of Thorpe on lead vocals and guitar, Jimmy Thompson on drums, Paul Wheeler on bass guitar and Lobby Loyde (ex-Purple Hearts, Wild Cherries) on lead guitar. They released a cover version of Willie Dixon's "Good Mornin' Little School Girl". They had developed a heavier sound and in July that year, Warren `Pig' Morgan (piano, backing vocals) had joined and the band recorded "The Hoax Is Over", which was released in January 1971. Thorpe described their sound "[It was] like we were standing on a pair of Boeing 747 engines. It cracked the foundations and broke windows in neighbouring buildings".

By early 1971 Blackfeather consisted of Neale Johns on lead vocals, John Robinson on lead guitar (ex-Lonely Ones, Monday's Children, Dave Miller Set), Robert Fortesque on bass guitar and Alexander Kash on drums. Their debut album, "At the Mountains of Madness", appeared in April 1971. In May they had a hit with "Seasons of Change", which peaked at No. 15 on the "Go-Set" National Top 40 Singles Chart. Buffalo formed in August 1971 by Dave Tice on co-lead vocals (ex-Head) with Paul Balbi on drums, John Baxter on guitar, and Peter Wells on bass guitar. Their debut album, "Dead Forever...", appeared in June the following year. According to Australian rock music journalist, Ed Nimmervoll, "The seeds for Australian heavy rock can be traced back to two important sources, Billy Thorpe's Seventies Aztecs and Sydney band Buffalo".

Many city and suburban pubs gained renown for their support of live music, and many prominent Australian bands — including AC/DC, Cold Chisel, The Angels and The Dingoes — developed their style at these venues in the early days of their careers. Australian musicologist, Ian McFarlane, described how AC/DC took "the raw energy of Aussie pub rock, extend its basic guidelines, serve it up to a teenybop "Countdown" audience and still reap the benefits of the live circuit by packing out the pubs". He found that Cold Chisel "fused a combination of rockabilly, hard rock and rough-house soul'n'blues that was defiantly Australian in outlook". He noted The Angels had "a profound effect on the Australian live music scene of the late 1970s/early 1980s. [They] helped redefine the Australian pub rock tradition ... [their] brand of no-frills, hard-driving boogie rock attracted pub goers in unprecedented numbers". The Dingoes provided a "spirited combination of R&B, country and red-hot rock'n'roll was imbued with a delightful sense of time and place" according to McFarlane.

Notable pub rock venues include the Largs Pier Hotel and the Governor Hindmarsh Hotel in Adelaide, the Royal Antler Hotel in Narrabeen, Sydney and the Civic Hotel in Sydney's city centre, the Star Hotel in Newcastle, New South Wales and the Station Hotel in Prahran, Melbourne, which was one of the premier pub-rock venues in Australia for more than two decades, Poyntons Carlton Club Hotel in Carlton Melbourne's first Sunday night live pub rock venue.

As the pub rock phenomenon expanded, hundreds of hotels in capital cities and major towns began providing regular live music, and a thriving circuit evolved, enabling bands to tour up and down the eastern and southern coast of Australia from North Queensland to South Australia.

It could be argued that the very venues many of the bands played in (pubs), had a major influence on the evolution of their music and sound. The venues were more often than not small and the crowds — alcohol-fuelled — were there for the experience rather than to see a "name band". Thus, an emphasis on simple, rhythm-based songs grew. With the sound in many of the rooms far from ideal for live music, an emphasis on a very loud snare and kick-drum and driving bass-guitar grew. Guitarists tended to rely on simple, repetitive riffs, rather than more complex solos or counter-melodies. This might explain why, even in studios and larger arenas and stadiums, many of the bands who originated in pubs relied on an exaggerated drum sound and fairly simple musical arrangements.

A band like Hunters & Collectors, for example, saw their sound harden from their arty origins (which included a brass-section, experimental percussion and complex arrangements) to a more straightforward rock sound with emphasis on drums, bass and simple guitar riffs; a sound that more suited the beer barns they were to play in over their extensive touring career.

Though Australia has a relatively small population, the proportionally high number of venues that bands could play in, mainly along the Eastern coast, meant that a band could tour extensively, often playing every night for long periods. This would allow bands such as AC/DC, Cold Chisel, INXS, Midnight Oil, Rose Tattoo and others to take their live skills into large venues in the US and Europe with ease.




</doc>
<doc id="25037" url="https://en.wikipedia.org/wiki?curid=25037" title="Phonation">
Phonation

The term phonation has slightly different meanings depending on the subfield of phonetics. Among some phoneticians, "phonation" is the process by which the vocal folds produce certain sounds through quasi-periodic vibration. This is the definition used among those who study laryngeal anatomy and physiology and speech production in general. Phoneticians in other subfields, such as linguistic phonetics, call this process "voicing", and use the term "phonation" to refer to any oscillatory state of any part of the larynx that modifies the airstream, of which voicing is just one example. Voiceless and supra-glottal phonations are included under this definition.

The phonatory process, or voicing, occurs when air is expelled from the lungs through the glottis, creating a pressure drop across the larynx. When this drop becomes sufficiently large, the vocal folds start to oscillate. The minimum pressure drop required to achieve phonation is called the phonation threshold pressure, and for humans with normal vocal folds, it is approximately 2–3 cm HO. The motion of the vocal folds during oscillation is mostly lateral, though there is also some superior component as well. However, there is almost no motion along the length of the vocal folds. The oscillation of the vocal folds serves to modulate the pressure and flow of the air through the larynx, and this modulated airflow is the main component of the sound of most voiced phones.

The sound that the larynx produces is a harmonic series. In other words, it consists of a fundamental tone (called the fundamental frequency, the main acoustic cue for the percept pitch) accompanied by harmonic overtones, which are multiples of the fundamental frequency. According to the source–filter theory, the resulting sound excites the resonance chamber that is the vocal tract to produce the individual speech sounds.

The vocal folds will not oscillate if they are not sufficiently close to one another, are not under sufficient tension or under too much tension, or if the pressure drop across the larynx is not sufficiently large. In linguistics, a phone is called voiceless if there is no phonation during its occurrence. In speech, voiceless phones are associated with vocal folds that are elongated, highly tensed, and placed laterally (abducted) when compared to vocal folds during phonation.

Fundamental frequency, the main acoustic cue for the percept "pitch", can be varied through a variety of means. Large scale changes are accomplished by increasing the tension in the vocal folds through contraction of the cricothyroid muscle. Smaller changes in tension can be effected by contraction of the thyroarytenoid muscle or changes in the relative position of the thyroid and cricoid cartilages, as may occur when the larynx is lowered or raised, either volitionally or through movement of the tongue to which the larynx is attached via the hyoid bone. In addition to tension changes, fundamental frequency is also affected by the pressure drop across the larynx, which is mostly affected by the pressure in the lungs, and will also vary with the distance between the vocal folds. Variation in fundamental frequency is used linguistically to produce intonation and tone.

There are currently two main theories as to how vibration of the vocal folds is initiated: the myoelastic theory and the aerodynamic theory. These two theories are not in contention with one another and it is quite possible that both theories are true and operating simultaneously to initiate and maintain vibration. A third theory, the neurochronaxic theory, was in considerable vogue in the 1950s, but has since been largely discredited.

The myoelastic theory states that when the vocal cords are brought together and breath pressure is applied to them, the cords remain closed until the pressure beneath them, the subglottic pressure, is sufficient to push them apart, allowing air to escape and reducing the pressure enough for the muscle tension recoil to pull the folds back together again. The pressure builds up once again until the cords are pushed apart, and the whole cycle keeps repeating itself. The rate at which the cords open and close, the number of cycles per second, determines the pitch of the phonation.

The aerodynamic theory is based on the Bernoulli energy law in fluids. The theory states that when a stream of breath is flowing through the glottis while the arytenoid cartilages are held together (by the action of the interarytenoid muscles), a push-pull effect is created on the vocal fold tissues that maintains self-sustained oscillation. The push occurs during glottal opening, when the glottis is convergent, and the pull occurs during glottal closing, when the glottis is divergent. Such an effect causes a transfer of energy from the airflow to the vocal fold tissues which overcomes losses by dissipation and sustain the oscillation. The amount of lung pressure needed to begin phonation is defined by Titze as the oscillation threshold pressure. During glottal closure, the air flow is cut off until breath pressure pushes the folds apart and the flow starts up again, causing the cycles to repeat.
The textbook entitled Myoelastic Aerodynamic Theory of Phonation by Ingo Titze credits Janwillem van den Berg as the originator of the theory and provides detailed mathematical development of the theory.

This theory states that the frequency of the vocal fold vibration is determined by the chronaxie of the recurrent nerve, and not by breath pressure or muscular tension. Advocates of this theory thought that every single vibration of the vocal folds was due to an impulse from the recurrent laryngeal nerves and that the acoustic center in the brain regulated the speed of vocal fold vibration. Speech and voice scientists have long since abandoned this theory as the muscles have been shown to not be able to contract fast enough to accomplish the vibration. In addition, persons with paralyzed vocal folds can produce phonation, which would not be possible according to this theory. Phonation occurring in excised larynges would also not be possible according to this theory.

In linguistic phonetic treatments of phonation, such as those of Peter Ladefoged, phonation was considered to be a matter of points on a continuum of tension and closure of the vocal cords. More intricate mechanisms were occasionally described, but they were difficult to investigate, and until recently the state of the glottis and phonation were considered to be nearly synonymous.

If the vocal cords are completely relaxed, with the arytenoid cartilages apart for maximum airflow, the cords do not vibrate. This is voiceless phonation, and is extremely common with obstruents. If the arytenoids are pressed together for glottal closure, the vocal cords block the airstream, producing stop sounds such as the glottal stop. In between there is a sweet spot of maximum vibration. Also, the existence of an optimal glottal shape for ease of phonation has been shown, at which the lung pressure required to initiate the vocal cord vibration is minimum. This is modal voice, and is the normal state for vowels and sonorants in all the world's languages. However, the aperture of the arytenoid cartilages, and therefore the tension in the vocal cords, is one of degree between the end points of open and closed, and there are several intermediate situations utilized by various languages to make contrasting sounds.

For example, Gujarati has vowels with a partially lax phonation called breathy voice or murmured voice (transcribed in IPA with a subscript umlaut ), while Burmese has vowels with a partially tense phonation called creaky voice or laryngealized voice (transcribed in IPA with a subscript tilde ). The Jalapa dialect of Mazatec is unusual in contrasting both with modal voice in a three-way distinction. (Note that Mazatec is a tonal language, so the glottis is making several tonal distinctions simultaneously with the phonation distinctions.)

The following different positions can be found:
A: Glottis closure,
B: phonation position,
C: whisper position,
D: breath position;
E: respiratory position or resting position;
F: deep breathing position

Javanese does not have modal voice in its stops, but contrasts two other points along the phonation scale, with more moderate departures from modal voice, called slack voice and stiff voice. The "muddy" consonants in Shanghainese are slack voice; they contrast with tenuis and aspirated consonants.

Although each language may be somewhat different, it is convenient to classify these degrees of phonation into discrete categories. A series of seven alveolar stops, with phonations ranging from an open/lax to a closed/tense glottis, are:

The IPA diacritics "under-ring" and "subscript wedge", commonly called "voiceless" and "voiced", are sometimes added to the symbol for a voiced sound to indicate more lax/open (slack) and tense/closed (stiff) states of the glottis, respectively. (Ironically, adding the 'voicing' diacritic to the symbol for a voiced consonant indicates "less" modal voicing, not more, because a modally voiced sound is already fully voiced, at its sweet spot, and any further tension in the vocal cords dampens their vibration.)

Alsatian, like several Germanic languages, has a typologically unusual phonation in its stops. The consonants transcribed (ambiguously called "lenis") are partially voiced: The vocal cords are positioned as for voicing, but do not actually vibrate. That is, they are technically voiceless, but without the open glottis usually associated with voiceless stops. They contrast with both modally voiced and modally voiceless in French borrowings, as well as aspirated word initially.

If the arytenoid cartiledges are parted to admit turbulent airflow, the result is whisper phonation if the vocal folds are adducted, and whispery voice phonation (murmur) if the vocal folds vibrate modally. Whisper phonation is heard in many productions of French "oui!", and the "voiceless" vowels of many North American languages are actually whispered.

It has long been noted that in many languages, both phonologically and historically, the glottal consonants do not behave like other consonants. Phonetically, they have no manner or place of articulation other than the state of the glottis: "glottal closure" for , "breathy voice" for , and "open airstream" for . Some phoneticians have described these sounds as neither glottal nor consonantal, but instead as instances of pure phonation, at least in many European languages. However, in Semitic languages they do appear to be true glottal consonants.

In the last few decades it has become apparent that phonation may involve the entire larynx, with as many as six valves and muscles working either independently or together. From the glottis upward, these articulations are:

Until the development of fiber-optic laryngoscopy, the full involvement of the larynx during speech production was not observable, and the interactions among the six laryngeal articulators is still poorly understood. However, at least two supra-glottal phonations appear to be widespread in the world's languages. These are harsh voice ('ventricular' or 'pressed' voice), which involves overall constriction of the larynx, and faucalized voice ('hollow' or 'yawny' voice), which involves overall expansion of the larynx.

The Bor dialect of Dinka has contrastive modal, breathy, faucalized, and harsh voice in its vowels, as well as three tones. The "ad hoc" diacritics employed in the literature are a subscript double quotation mark for faucalized voice, , and underlining for harsh voice, . Examples are,

Other languages with these contrasts are Bai (modal, breathy, and harsh voice), Kabiye (faucalized and harsh voice, previously seen as ±ATR), Somali (breathy and harsh voice).

Elements of laryngeal articulation or phonation may occur widely in the world's languages as phonetic detail even when not phonemically contrastive. For example, simultaneous glottal, ventricular, and arytenoid activity (for something other than epiglottal consonants) has been observed in Tibetan, Korean, Nuuchahnulth, Nlaka'pamux, Thai, Sui, Amis, Pame, Arabic, Tigrinya, Cantonese, and Yi.

In languages such as French, all obstruents occur in pairs, one modally voiced and one voiceless: [b] [d] [g] [v] [z] [ʒ] → [p] [t] [k] [f] [s] [ʃ].

In English, every voiced fricative corresponds to a voiceless one. For the pairs of English stops, however, the distinction is better specified as voice onset time rather than simply voice: In initial position, /b d g/ are only partially voiced (voicing begins during the hold of the consonant), and /p t k/ are aspirated (voicing begins only well after its release). Certain English morphemes have voiced and voiceless allomorphs, such as: the plural, verbal, and possessive endings spelled "-s" (voiced in "kids" but voiceless in "kits" ), and the past-tense ending spelled "-ed" (voiced in "buzzed" but voiceless in "fished" ).

A few European languages, such as Finnish, have no phonemically voiced obstruents but pairs of long and short consonants instead. Outside Europe, the lack of voicing distinctions is common; indeed, in Australian languages it is nearly universal. In languages without the distinction between voiceless and voiced obstruents, they are realized as voiced in voiced environments, such as between vowels, and voiceless elsewhere.

In phonology, a register is a combination of tone and vowel phonation into a single phonological parameter. For example, among its vowels, Burmese combines modal voice with low tone, breathy voice with falling tone, creaky voice with high tone, and glottal closure with high tone. These four registers contrast with each other, but no other combination of phonation (modal, breath, creak, closed) and tone (high, low, falling) is found.

Among vocal pedagogues and speech pathologists, a vocal register also refers to a particular phonation limited to a particular range of pitch, which possesses a characteristic sound quality. The term "register" may be used for several distinct aspects of the human voice:


Four combinations of these elements are identified in speech pathology: the vocal fry register, the modal register, the falsetto register, and the whistle register.




</doc>
<doc id="25039" url="https://en.wikipedia.org/wiki?curid=25039" title="Principal ideal domain">
Principal ideal domain

In abstract algebra, a principal ideal domain, or PID, is an integral domain in which every ideal is principal, i.e., can be generated by a single element. More generally, a principal ideal ring is a nonzero commutative ring whose ideals are principal, although some authors (e.g., Bourbaki) refer to PIDs as principal rings. The distinction is that a principal ideal ring may have zero divisors whereas a principal ideal domain cannot.

Principal ideal domains are thus mathematical objects that behave somewhat like the integers, with respect to divisibility: any element of a PID has a unique decomposition into prime elements (so an analogue of the fundamental theorem of arithmetic holds); any two elements of a PID have a greatest common divisor (although it may not be possible to find it using the Euclidean algorithm). If "x" and "y" are elements of a PID without common divisors, then every element of the PID can be written in the form "ax" + "by".

Principal ideal domains are noetherian, they are integrally closed, they are unique factorization domains and Dedekind domains. All Euclidean domains and all fields are principal ideal domains.

Principal ideal domains appear in the following chain of class inclusions:

Examples include:

Examples of integral domains that are not PIDs:

The key result is the structure theorem: If "R" is a principal ideal domain, and "M" is a finitely
generated "R"-module, then formula_15 is a direct sum of cyclic modules, i.e., modules with one generator. The cyclic modules are isomorphic to formula_16 for some formula_17 (notice that formula_18 may be equal to formula_19, in which case formula_16 is formula_21).

If "M" is a free module over a principal ideal domain "R", then every submodule of "M" is again free. This does not hold for modules over arbitrary rings, as the example formula_22 of modules over formula_23 shows.

In a principal ideal domain, any two elements have a greatest common divisor, which may be obtained as a generator of the ideal .

All Euclidean domains are principal ideal domains, but the converse is not true.
An example of a principal ideal domain that is not a Euclidean domain is the ring formula_24 In this domain no and exist, with , so that formula_25, despite formula_26 and formula_27 having a greatest common divisor of .

Every principal ideal domain is a unique factorization domain (UFD). The converse does not hold since for any UFD , the ring of polynomials in 2 variables is a UFD but is not a PID. (To prove this look at the ideal generated by formula_28 It is not the whole ring since it contains no polynomials of degree 0, but it cannot be generated by any one single element.)


The previous three statements give the definition of a Dedekind domain, and hence every principal ideal domain is a Dedekind domain.

Let "A" be an integral domain. Then the following are equivalent.


A field norm is a Dedekind-Hasse norm; thus, (5) shows that a Euclidean domain is a PID. (4) compares to:
An integral domain is a Bézout domain if and only if any two elements in it have a gcd "that is a linear combination of the two." A Bézout domain is thus a GCD domain, and (4) gives yet another proof that a PID is a UFD.





</doc>
<doc id="25040" url="https://en.wikipedia.org/wiki?curid=25040" title="Pioneer program">
Pioneer program

The Pioneer programs were two series of United States uncrewed space missions for lunar and planetary exploration. The first program, which ran from 1958 to 1960, unsuccessfully attempted to send spacecraft to orbit the Moon, successfully sent one spacecraft to fly by the Moon, and successfully sent one spacecraft to investigate interplanetary space between the orbits of Earth and Venus. The second program, which ran from 1965 to 1992, sent four spacecraft to measure interplanetary space weather, two to explore Jupiter and Saturn, and two to explore Venus. The two outer planet probes, Pioneer 10 and Pioneer 11, became the first artificial objects to leave the Solar System, and carried a golden plaque depicting a man and a woman and information about the origin and the creators of the probes, in case any extraterrestrials find them someday.

Credit for naming the first probe has been attributed to Stephen A. Saliga, who had been assigned to the Air Force Orientation Group, Wright-Patterson AFB, as chief designer of Air Force exhibits. While he was at a briefing, the spacecraft was described to him, as, a "lunar-orbiting vehicle, with an infrared scanning device." Saliga thought the title too long, and lacked theme for an exhibit design. He suggested, "Pioneer", as the name of the probe, since "the Army had already launched and orbited the Explorer satellite, and their Public Information Office was identifying the Army, as, 'Pioneers in Space,'" and, by adopting the name, the Air Force would "make a 'quantum jump' as to who, really, [were] the 'Pioneers' in space.'"

The earliest missions were attempts to achieve Earth's escape velocity, simply to show it was feasible and to study the Moon. This included the first launch by NASA which was formed from the old NACA. These missions were carried out by the US Air Force and Army.



Five years after the early Able space probe missions ended, NASA Ames Research Center used the Pioneer name for a new series of missions, initially aimed at the inner Solar System, before the flyby missions to Jupiter and Saturn. While successful, the missions returned much poorer images than the Voyager program probes would five years later. In 1978, the end of the program saw a return to the inner Solar System, with the Pioneer Venus Orbiter and Multiprobe, this time using orbital insertion rather than flyby missions.

The new missions were numbered beginning with Pioneer 6 (alternate names in parentheses).

The spacecraft in Pioneer missions 6, 7, 8, and 9 comprised a new interplanetary space weather network:
Pioneer 6 and Pioneer 9 are in solar orbits with 0.8 AU distance to the Sun. Their orbital periods are therefore slightly shorter than Earth's. Pioneer 7 and Pioneer 8 are in solar orbits with 1.1 AU distance to the Sun. Their orbital periods are therefore slightly longer than Earth's. Since the probes' orbital periods differ from that of the Earth, from time to time, they face a side of the Sun that cannot be seen from Earth. The probes can sense parts of the Sun several days before the Sun's rotation reveals it to ground-based Earth orbiting observatories.






</doc>
<doc id="25041" url="https://en.wikipedia.org/wiki?curid=25041" title="Lockheed P-38 Lightning">
Lockheed P-38 Lightning

The Lockheed P-38 Lightning is a World War II–era American piston-engined fighter aircraft. Developed for the United States Army Air Corps, the P-38 had distinctive twin booms and a central nacelle containing the cockpit and armament. Allied propaganda claimed it had been nicknamed the fork-tailed devil () by the Luftwaffe and "two planes, one pilot" by the Japanese. Along with its use as a general fighter, the P-38 was utilized in various aerial combat roles including as a highly effective fighter-bomber, a night fighter, and as a long-range escort fighter when equipped with drop tanks. The P-38 was also used as a bomber-pathfinder, guiding streams of medium and heavy bombers; or even other P-38s, equipped with bombs, to their targets. Used in the aerial reconnaissance role, the P-38 would account for 90 percent of the aerial film captured over Europe. 

The P-38 was used most successfully in the Pacific Theater of Operations and the China-Burma-India Theater of Operations as the aircraft of America's top aces, Richard Bong (40 victories), Thomas McGuire (38 victories) and Charles H. MacDonald (27 victories). In the South West Pacific theater, the P-38 was the primary long-range fighter of United States Army Air Forces until the introduction of large numbers of P-51D Mustangs toward the end of the war.

Unusual for a fighter of this time, the exhaust was muffled by the turbo-superchargers, making the P-38's operation relatively quiet. The two turbo-superchargers also provided the P-38 with good high-altitude performance, making it one of the earliest Allied fighters capable of performing at such altitudes. It was extremely forgiving and could be mishandled in many ways, but the rate of roll in the early versions was too low for it to excel as a dogfighter. The P-38 was the only American fighter aircraft in large-scale production throughout American involvement in the war, from Pearl Harbor to Victory over Japan Day. At the end of the war, orders for 1,887 more were cancelled.

Lockheed designed the P-38 in response to a February 1937 specification from the United States Army Air Corps (USAAC). Circular Proposal X-608 was a set of aircraft performance goals authored by First Lieutenants Benjamin S. Kelsey and Gordon P. Saville for a twin-engine, high-altitude "interceptor" having "the tactical mission of interception and attack of hostile aircraft at high altitude." In 1977, Kelsey recalled he and Saville drew up the specification using the word "interceptor" as a way to bypass the inflexible Army Air Corps requirement for pursuit aircraft to carry no more than of armament including ammunition, as well as the restriction of single-seat aircraft to one engine. Kelsey was looking for a minimum of of armament. Kelsey and Saville aimed to get a more capable fighter, better at dog-fighting and at high-altitude combat. Specifications called for a maximum airspeed of at least at altitude, and a climb to within six minutes, the toughest set of specifications USAAC had ever presented. The unbuilt Vultee XP1015 was designed to the same requirement, but was not advanced enough to merit further investigation. A similar single-engine proposal was issued at the same time, Circular Proposal X-609, in response to which the Bell P-39 Airacobra was designed. Both proposals required liquid-cooled Allison V-1710 engines with turbo-superchargers and gave extra points for tricycle landing gear.

The Lockheed design team, under the direction of Hall Hibbard and Clarence "Kelly" Johnson, considered a range of twin-engine configurations, including both engines in a central fuselage with push–pull propellers.

The eventual configuration was rare in terms of contemporary fighter aircraft design, with only the preceding Fokker G.1, the contemporary Focke-Wulf Fw 189 Luftwaffe reconnaissance aircraft, and the later Northrop P-61 Black Widow night fighter having a similar planform. The Lockheed team chose twin booms to accommodate the tail assembly, engines, and turbo-superchargers, with a central nacelle for the pilot and armament. The XP-38 gondola mockup was designed to mount two .50-caliber (12.7 mm) M2 Browning machine guns with 200 rounds per gun (rpg), two .30-caliber (7.62 mm) Brownings with 500 rpg, and a T1 Army Ordnance 23 mm (.90 in) autocannon with a rotary magazine as a substitute for the non-existent 25 mm Hotchkiss aircraft autocannon specified by Kelsey and Saville. In the YP-38s, a 37 mm (1.46 in) M9 autocannon with 15 rounds replaced the T1. The 15 rounds were in three five-round clips, an unsatisfactory arrangement according to Kelsey, and the M9 did not perform reliably in flight. Further armament experiments from March to June 1941 resulted in the P-38E combat configuration of four M2 Browning machine guns, and one Hispano 20 mm (.79 in) autocannon with 150 rounds.

Clustering all the armament in the nose was unusual in U.S. aircraft, which typically used wing-mounted guns with trajectories set up to crisscross at one or more points in a convergence zone. Nose-mounted guns did not suffer from having their useful ranges limited by pattern convergence, meaning that good pilots could shoot much farther. A Lightning could reliably hit targets at any range up to , whereas the wing guns of other fighters were optimized for a specific range. The rate of fire was about 650 rounds per minute for the 20×110 mm cannon round (130-gram shell) at a muzzle velocity of about , and for the .50-caliber machine guns (43-gram rounds), about 850 rpm at velocity. Combined rate of fire was over 4,000 rpm with roughly every sixth projectile a 20 mm shell. The duration of sustained firing for the 20 mm cannon was approximately 14 seconds while the .50-caliber machine guns worked for 35 seconds if each magazine was fully loaded with 500 rounds, or for 21 seconds if 300 rounds were loaded to save weight for long distance flying.

The Lockheed design incorporated tricycle undercarriage and a bubble canopy, and featured two turbosupercharged 12-cylinder Allison V-1710 engines fitted with counter-rotating propellers to eliminate the effect of engine torque, with the turbochargers positioned behind the engines, the exhaust side of the units exposed along the dorsal surfaces of the booms. Counter-rotation was achieved by the use of "handed" engines: the crankshafts of the engines turned in opposite directions, a relatively easy task for the V-1710 modular-design aircraft powerplant.

The P-38 was the first American fighter to make extensive use of stainless steel and smooth, flush-riveted butt-jointed aluminum skin panels. It was also the first military airplane to fly faster than in level flight.

Lockheed won the competition on 23 June 1937 with its Model 22 and was contracted to build a prototype XP-38 for US$163,000, though Lockheed's own costs on the prototype would add up to US$761,000. Construction began in July 1938, and the XP-38 first flew on 27 January 1939 at the hands of Ben Kelsey.

Kelsey then proposed a speed dash to Wright Field on 11 February 1939 to relocate the aircraft for further testing. General Henry "Hap" Arnold, commander of the USAAC, approved of the record attempt and recommended a cross-country flight to New York. The flight set a speed record by flying from California to New York in seven hours and two minutes, not counting two refueling stops, but the aircraft was downed by carburetor icing short of the Mitchel Field runway in Hempstead, New York, and was wrecked. However, on the basis of the record flight, the Air Corps ordered 13 YP-38s on 27 April 1939 for US$134,284 each. (The "Y" in "YP" was the USAAC's designation for a prototype, while the "X" in "XP" was for experimental.) Lockheed's Chief test pilot Tony LeVier angrily characterized the accident as an unnecessary publicity stunt, but according to Kelsey, the loss of the prototype, rather than hampering the program, sped the process by cutting short the initial test series. The success of the aircraft design contributed to Kelsey's promotion to captain in May 1939.
Manufacture of YP-38s fell behind schedule, at least partly because of the need for mass-production suitability making them substantially different in construction from the prototype. Another factor was the sudden required expansion of Lockheed's facility in Burbank, taking it from a specialized civilian firm dealing with small orders to a large government defense contractor making Venturas, Harpoons, Lodestars, Hudsons, and designing the Constellation for TWA. The first YP-38 was not completed until September 1940, with its maiden flight on 17 September. The 13th and final YP-38 was delivered to the Air Corps in June 1941; 12 aircraft were retained for flight testing and one for destructive stress testing. The YPs were substantially redesigned and differed greatly in detail from the hand-built XP-38. They were lighter and included changes in engine fit. The propeller rotation was reversed, with the blades spinning outward (away from the cockpit) at the top of their arc, rather than inward as before. This improved the aircraft's stability as a gunnery platform.

Test flights revealed problems initially believed to be tail flutter. During high-speed flight approaching Mach 0.68, especially during dives, the aircraft's tail would begin to shake violently and the nose would tuck under (see Mach tuck), steepening the dive. Once caught in this dive, the fighter would enter a high-speed compressibility stall and the controls would lock up, leaving the pilot no option but to bail out (if possible) or remain with the aircraft until it got down to denser air, where he might have a chance to pull out. During a test flight in May 1941, USAAC Major Signa Gilkey managed to stay with a YP-38 in a compressibility lockup, riding it out until he recovered gradually using elevator trim. Lockheed engineers were very concerned at this limitation but first had to concentrate on filling the current order of aircraft. In late June 1941, the Army Air Corps was renamed the U.S. Army Air Forces (USAAF), and a total of 65 Lightnings were finished for the service by September 1941 with more on the way for the USAAF, the Royal Air Force (RAF), and the Free French Air Force operating from England.

By November 1941, many of the initial assembly-line challenges had been met, which freed up time for the engineering team to tackle the problem of frozen controls in a dive. Lockheed had a few ideas for tests that would help them find an answer. The first solution tried was the fitting of spring-loaded servo tabs on the elevator trailing edge designed to aid the pilot when control yoke forces rose over , as would be expected in a high-speed dive. At that point, the tabs would begin to multiply the effort of the pilot's actions. The expert test pilot, 43-year-old Ralph Virden, was given a specific high-altitude test sequence to follow and was told to restrict his speed and fast maneuvering in denser air at low altitudes, since the new mechanism could exert tremendous leverage under those conditions. A note was taped to the instrument panel of the test craft underscoring this instruction. On 4 November 1941, Virden climbed into YP-38 #1 and completed the test sequence successfully, but 15 minutes later was seen in a steep dive followed by a high-G pullout. The tail unit of the aircraft failed at about during the high-speed dive recovery; Virden was killed in the subsequent crash. The Lockheed design office was justifiably upset, but their design engineers could only conclude that servo tabs were "not" the solution for loss of control in a dive. Lockheed still had to find the problem; the Army Air Forces personnel were sure it was flutter and ordered Lockheed to look more closely at the tail.

In 1941 flutter was a familiar engineering problem related to a too-flexible tail, but the P-38's empennage was completely skinned in aluminum rather than fabric and was quite rigid. At no time did the P-38 suffer from true flutter. To prove a point, one elevator and its vertical stabilizers were skinned with metal 63% thicker than standard, but the increase in rigidity made no difference in vibration. Army Lieutenant Colonel Kenneth B. Wolfe (head of Army Production Engineering) asked Lockheed to try external mass balances above and below the elevator, though the P-38 already had large mass balances elegantly placed within each vertical stabilizer. Various configurations of external mass balances were equipped, and dangerously steep test flights were flown to document their performance. Explaining to Wolfe in Report No. 2414, Kelly Johnson wrote "the violence of the vibration was unchanged and the diving tendency was naturally the same for all conditions." The external mass balances did not help at all. Nonetheless, at Wolfe's insistence, the additional external balances were a feature of every P-38 built from then on.
Johnson said in his autobiography that he pleaded with NACA to do model tests in its wind tunnel. They already had experience of models thrashing around violently at speeds approaching those requested and did not want to risk damaging their tunnel. Gen. Arnold, head of Army Air Forces, ordered them to run the tests, which were done up to Mach 0.74. The P-38's dive problem was revealed to be the center of pressure moving back toward the tail when in high-speed airflow. The solution was to change the geometry of the wing's lower surface when diving in order to keep lift within bounds of the top of the wing. In February 1943, quick-acting dive flaps were tried and proven by Lockheed test pilots. The dive flaps were installed outboard of the engine nacelles, and in action they extended downward 35° in 1.5 seconds. The flaps did not act as a speed brake; they affected the pressure distribution in a way that retained the wing's lift.

Late in 1943, a few hundred dive flap field modification kits were assembled to give North African, European and Pacific P-38s a chance to withstand compressibility and expand their combat tactics. Unfortunately, these crucial flaps did not always reach their destination. In March 1944, 200 dive flap kits intended for European Theater of Operations (ETO) P-38Js were destroyed in a mistaken identification incident in which an RAF fighter shot down the Douglas C-54 Skymaster (mistaken for an Fw 200) taking the shipment to England. Back in Burbank, P-38Js coming off the assembly line in spring 1944 were towed out to the ramp and modified in the open air. The flaps were finally incorporated into the production line in June 1944 on the last 210 P-38Js. Despite testing having proved the dive flaps effective in improving tactical maneuvers, a 14-month delay in production limited their implementation, with only the final half of all Lightnings built having the dive flaps installed as an assembly-line sequence.

Johnson later recalled:
Buffeting was another early aerodynamic problem. It was difficult to distinguish from compressibility as both were reported by test pilots as "tail shake". Buffeting came about from airflow disturbances ahead of the tail; the airplane would shake at high speed. Leading edge wing slots were tried as were combinations of filleting between the wing, cockpit and engine nacelles. Air tunnel test number 15 solved the buffeting completely and its fillet solution was fitted to every subsequent P-38 airframe. Fillet kits were sent out to every squadron flying Lightnings. The problem was traced to a 40% increase in air speed at the wing-fuselage junction where the thickness/chord ratio was highest. An airspeed of at could push airflow at the wing-fuselage junction close to the speed of sound. Filleting solved the buffeting problem for the P-38E and later models.

Another issue with the P-38 arose from its unique design feature of outwardly rotating (at the "tops" of the propeller arcs) counter-rotating propellers. Losing one of two engines in any twin-engine non-centerline thrust aircraft on takeoff creates sudden drag, yawing the nose toward the dead engine and rolling the wingtip down on the side of the dead engine. Normal training in flying twin-engine aircraft when losing an engine on takeoff is to push the remaining engine to full throttle to maintain airspeed; if a pilot did that in the P-38, regardless of which engine had failed, the resulting engine torque and p-factor force produced a sudden uncontrollable yawing roll, and the aircraft would flip over and hit the ground. Eventually, procedures were taught to allow a pilot to deal with the situation by reducing power on the running engine, feathering the prop on the failed engine, and then increasing power gradually until the aircraft was in stable flight. Single-engine takeoffs were possible, though not with a full fuel and ammunition load.

The engines were unusually quiet because the exhausts were muffled by the General Electric turbo-superchargers on the twin Allison V12s. There were early problems with cockpit temperature regulation; pilots were often too hot in the tropical sun as the canopy could not be fully opened without severe buffeting and were often too cold in northern Europe and at high altitude, as the distance of the engines from the cockpit prevented easy heat transfer. Later variants received modifications (such as electrically heated flight suits) to solve these problems.

On 20 September 1939, before the YP-38s had been built and flight tested, the USAAF ordered 66 initial production P-38 Lightnings, 30 of which were delivered to the USAAF in mid-1941, but not all these aircraft were armed. The unarmed aircraft were subsequently fitted with four .50 in (12.7 mm) machine guns (instead of the two .50 in/12.7 mm and two .30 in/7.62 mm of their predecessors) and a 37 mm (1.46 in) cannon. They also had armored glass, cockpit armor and fluorescent cockpit controls. One was completed with a pressurized cabin on an experimental basis and designated XP-38A. Due to reports the USAAF was receiving from Europe, the remaining 36 in the batch were upgraded with small improvements such as self-sealing fuel tanks and enhanced armor protection to make them combat-capable. The USAAF specified that these 36 aircraft were to be designated P-38D. As a result, there never were any P-38Bs or P-38Cs. The P-38D's main role was to work out bugs and give the USAAF experience with handling the type.

In March 1940, the French and the British, through the Anglo-French Purchasing Committee, ordered a total of 667 P-38s for US$100M, designated Model 322F for the French and Model 322B for the British. The aircraft would be a variant of the P-38E. The overseas Allies wished for complete commonality of Allison engines with the large numbers of Curtiss P-40 Tomahawks both nations had on order, and thus ordered the Model 322 twin right-handed engines instead of counter-rotating ones and without turbo-superchargers. Performance was supposed to be at . After the fall of France in June 1940, the British took over the entire order and gave the aircraft the service name "Lightning." By June 1941, the War Ministry had cause to reconsider their earlier aircraft specifications based on experience gathered in the Battle of Britain and The Blitz. British displeasure with the Lockheed order came to the fore in July, and on 5 August 1941 they modified the contract such that 143 aircraft would be delivered as previously ordered, to be known as "Lightning (Mark) I," and 524 would be upgraded to US-standard P-38E specifications with a top speed of at guaranteed, to be called "Lightning II" for British service. Later that summer an RAF test pilot reported back from Burbank with a poor assessment of the "tail flutter" situation, and the British cancelled all but three of the 143 Lightning Is. As a loss of approximately US$15M was involved, Lockheed reviewed their contracts and decided to hold the British to the original order. Negotiations grew bitter and stalled. Everything changed after the 7 December 1941 attack on Pearl Harbor after which the United States government seized some 40 of the Model 322s for West Coast defense; subsequently all British Lightnings were delivered to the USAAF starting in January 1942. The USAAF lent the RAF three of the aircraft, which were delivered by sea in March 1942 and were test flown no earlier than May at Cunliffe-Owen Aircraft Swaythling, the Aeroplane and Armament Experimental Establishment and the Royal Aircraft Establishment. The A&AEE example was unarmed, lacked turbochargers and restricted to ; though the undercarriage was praised and flight on one engine described as comfortable. These three were subsequently returned to the USAAF; one in December 1942 and the others in July 1943. Of the remaining 140 Lightning Is, 19 were not modified and were designated by the USAAF as RP-322-I ('R' for 'Restricted', because non-counter-rotating propellers were considered more dangerous on takeoff), while 121 were converted to non-turbo-supercharged counter-rotating V-1710F-2 engines and designated P-322-II. All 121 were used as advanced trainers; a few were still serving that role in 1945. A few RP-322s were later used as test modification platforms such as for smoke-laying canisters. The RP-322 was a fairly fast aircraft below and well-behaved as a trainer.

Many of the British order of 524 Lightning IIs were fitted with stronger F-10 Allison engines as they became available, and all were given wing pylons for fuel tanks or bombs. The upgraded aircraft were deployed to the Pacific as USAAC F-5A reconnaissance or P-38G fighter models, the latter used with great effect to shoot down Admiral Yamamoto in April 1943. Robert Petit's G model named "Miss Virginia" was on that mission, borrowed by Rex Barber who was later credited with the kill. Petit had already used "Miss Virginia" to defeat two Nakajima A6M2-N "Rufe" floatplanes in February and to heavily damage a Japanese submarine chaser in March, which he mistakenly claimed as a destroyer sunk. Murray "Jim" Shubin used a less powerful F model he named "Oriole" to down five confirmed and possibly six Zeros over Guadalcanal in June 1943 to become ace in a day.

One result of the failed British/French order was to give the aircraft its name. Lockheed had originally dubbed the aircraft Atalanta from Greek mythology in the company tradition of naming planes after mythological and celestial figures, but the RAF name won out.

The strategic bombing proponents within the USAAF, called the Bomber Mafia by their ideological opponents, had established in the early 1930s a policy against research to create long-range fighters, which they thought would not be practical; this kind of research was not to compete for bomber resources. Aircraft manufacturers understood that they would not be rewarded if they installed subsystems on their fighters to enable them to carry drop tanks to provide more fuel for extended range. Lieutenant Kelsey, acting against this policy, risked his career in late 1941 when he convinced Lockheed to incorporate such subsystems in the P-38E model, without putting his request in writing. It is possible that Kelsey was responding to Colonel George William Goddard's observation that the US sorely needed a high-speed, long-range photo reconnaissance plane. Along with a change order specifying some P-38Es be produced without guns but with photo reconnaissance cameras, to be designated the F-4-1-LO, Lockheed began working out the problems of drop tank design and incorporation. After the attack on Pearl Harbor, eventually about 100 P-38Es were sent to a modification center near Dallas, Texas, or to the new Lockheed assembly plant B-6 (today the Burbank Airport), to be fitted with four K-17 aerial photography cameras. All of these aircraft were also modified to be able to carry drop tanks. P-38Fs were modified as well. Every Lightning from the P-38G onward was drop tank-capable off the assembly line.

In March 1942, General Arnold made an off-hand comment that the US could avoid the German U-boat menace by flying fighters to the UK (rather than packing them onto ships). President Roosevelt pressed the point, emphasizing his interest in the solution. Arnold was likely aware of the flying radius extension work being done on the P-38, which by this time had seen success with small drop tanks in the range of , the difference in capacity being the result of subcontractor production variation. Arnold ordered further tests with larger drop tanks in the range of ; the results were reported by Kelsey as providing the P-38 with a ferrying range. Because of available supply, the smaller drop tanks were used to fly Lightnings to the UK, the plan called Operation Bolero.

Led by two Boeing B-17 Flying Fortresses, the first seven P-38s, each carrying two small drop tanks, left Presque Isle Army Air Field on 23 June 1942 for RAF Heathfield in Scotland. Their first refueling stop was made in far northeast Canada at Goose Bay. The second stop was a rough airstrip in Greenland called Bluie West One, and the third refueling stop was in Iceland at Keflavik. Other P-38s followed this route with some lost in mishaps, usually due to poor weather, low visibility, radio difficulties and navigational errors. Nearly 200 of the P-38Fs (and a few modified Es) were successfully flown across the Atlantic in July–August 1942, making the P-38 the first USAAF fighter to reach Britain and the first fighter ever to be delivered across the Atlantic under its own power. Kelsey himself piloted one of the Lightnings, landing in Scotland on 25 July.

The first unit to receive P-38s was the 1st Fighter Group. After the attack on Pearl Harbor, the unit joined the 14th Pursuit Group in San Diego to provide West Coast defense.

The first Lightning to see active service was the F-4 version, a P-38E in which the guns were replaced by four K17 cameras. They joined the 8th Photographic Squadron in Australia on 4 April 1942. Three F-4s were operated by the Royal Australian Air Force in this theater for a short period beginning in September 1942.

On 29 May 1942, 25 P-38s began operating in the Aleutian Islands in Alaska. The fighter's long range made it well-suited to the campaign over the almost -long island chain, and it was flown there for the rest of the war. The Aleutians were one of the most rugged environments available for testing the new aircraft under combat conditions. More Lightnings were lost due to severe weather and other conditions than enemy action; there were cases where Lightning pilots, mesmerized by flying for hours over gray seas under gray skies, simply flew into the water. On 9 August 1942, two P-38Es of the 343rd Fighter Group, 11th Air Force, at the end of a long-range patrol, happened upon a pair of Japanese Kawanishi H6K "Mavis" flying boats and destroyed them, making them the first Japanese aircraft to be shot down by Lightnings.

After the Battle of Midway, the USAAF began redeploying fighter groups to Britain as part of Operation Bolero and Lightnings of the 1st Fighter Group were flown across the Atlantic via Iceland. On 14 August 1942, Second Lieutenant Elza Shahan of the 27th Fighter Squadron, and Second Lieutenant Joseph Shaffer of the 33rd Squadron operating out of Iceland shot down a Focke-Wulf Fw 200 "Condor" over the Atlantic. Shahan in his P-38F downed the "Condor"; Shaffer, flying either a P-40C or a P-39, had already set an engine on fire. This was the first Luftwaffe aircraft destroyed by the USAAF.

After 347 sorties with no enemy contact, the 1st and 14th Fighter Groups transferred from the UK to the 12th Air Force in North Africa as part of the force being built up for Operation Torch. The Lightning's long range allowed the pilots to fly their fighters over the Bay of Biscay, skirting neutral Spain and Portugal to refuel in Morocco. The P-38s were initially based at Tafaroui airfield in Algeria alongside P-40 Warhawks and the rest of the 12th Air Force. P-38s were first involved in North African combat operations on 11 November 1942. The first North African P-38 kill was on 22 November when Lieutenant Mark Shipman of the 14th downed an Italian airplane with twin engines. Shipman later made two more kills: a Messerschmitt Bf 109 fighter and a very large Me 323 "Gigant" transport.

Early results in the Mediterranean Theater of Operations were mixed. Some P-38 pilots scored multiple kills to become aces, while many others were shot down due to inexperience or tactical strictures. Overall, the P-38 suffered its highest losses in the Mediterranean Theater. The primary function of the P-38 in North Africa was to escort bombers, but the fighters also targeted transport aircraft, and later in the campaign they were sometimes tasked with ground attack missions. When tied to bomber escort duties, the P-38 squadrons were vulnerable to attack from above by German fighters who selected the most advantageous position and timing. The ineffectual early tactical doctrine of the American units required the P-38s to fly near the bombers at all times rather than to defend aggressively or to fly ahead and clear the airspace for the bombers, and many American pilots were downed because of this limitation. Losses mounted, and all available P-38s in the UK were flown to North Africa to restore squadron strength. After this painful experience, the American leadership changed tactics, and in February 1943 the P-38 was given free rein in its battles.

The first German success against the P-38 was on 28 November when Bf 109 pilots of "Jagdgeschwader" 53 claimed seven Lightnings for no loss of their own. Further one-sided German victories were noted on several occasions through January 1943. The first P-38 pilots to achieve ace status were Virgil Smith of the 14th FG and Jack Illfrey of the 1st FG, both credited with five wins by 26 December. Smith got a sixth enemy aircraft on 28 December but was killed two days later in a crash landing, likely after taking fire from "Oberfeldwebel" Herbert Rollwage of JG 53 who survived the war with at least 71 kills. This was Rollwage's first victory over a P-38, and his 35th claim at the time.

The two squadrons of the 14th Fighter Group were reduced so badly in December that the 82nd FG was flown from the UK to North Africa to cover the shortage. The first kill by the 82nd was during a bomber escort mission on 7 January 1943 when William J. "Dixie" Sloan broke formation and turned toward six attacking Bf 109s to shoot one of them down. Known for his maverick style, Sloan racked up 12 victories by July 1943. After another heavy toll in January 1943, 14th FG had to be withdrawn from the front to reorganize, with surviving pilots sent home and the few remaining Lightnings transferred to the 82nd. The 14th was out of action for three months, returning in May.

On 5 April 1943, 26 P-38Fs of the 82nd claimed 31 enemy aircraft destroyed, helping to establish air superiority in the area and earning it the German nickname ""der Gabelschwanz Teufel"" – the Fork-Tailed Devil. The P-38 remained active in the Mediterranean for the rest of the war, continuing to deliver and receive damage in combat. On 25 August 1943, 13 P-38s were shot down in a single sortie by JD 53 Bf 109s. On 2 September, 10 P-38s were shot down, in return for losing one German pilot: 67-victory ace Franz Schieß who had been the leading "Lightning" killer in the Luftwaffe with 17 destroyed.

The Mediterranean Theater saw the first aerial combat between German fighters and P-38s. German fighter pilot appraisal of the P-38 was mixed. Some observers dismissed the P-38 as an easy kill while others gave it high praise, a deadly enemy worthy of respect. Johannes Steinhoff, commander of JG 77 in North Africa, said that the unit's old Bf 109s were "perhaps, a little faster" than the P-38, but a dogfight with the twin-engined fighter was daunting because its turning radius was much smaller, and it could quickly get on the tail of the Bf 109. Franz Stigler, an ace with 28 kills, flew Bf 109s against the P-38 in North Africa. Stigler said the Lightning "could turn inside us with ease and they could go from level flight to climb almost instantaneously. We lost quite a few pilots who tried to make an attack and then pull up... One cardinal rule we never forgot was: avoid fighting the P-38 head on. That was suicide." Stigler said the best defense was to flick-roll the Bf 109 and dive, as the Lightning was slow in the first 10 degrees of roll, and it was not as fast in a dive. Herbert Kaiser, eventually a 68-kill ace, shot down his first P-38 in January 1943. Kaiser said that the P-38 should be respected as a formidable opponent, that it was faster and more maneuverable than the Bf 109G-6 model he flew, especially since the G-6 was slowed by underwing cannon pods. Johann Pichler, another high-scoring ace, said that the P-38 in 1943 was much faster in a climb than the Bf 109. Kurt Bühligen, third-highest scoring German pilot on the Western front with 112 victories, recalled: "The P-38 fighter (and the B-24) were easy to burn. Once in Africa we were six and met eight P-38s and shot down seven. One sees a great distance in Africa and our observers and flak people called in sightings and we could get altitude first and they were low and slow." "General der Jagdflieger" Adolf Galland was unimpressed with the P-38, declaring "it had similar shortcomings in combat to our Bf 110, our fighters were clearly superior to it." Heinz Bäer said that P-38s "were not difficult at all. They were easy to outmaneuver and were generally a sure kill".

On 12 June 1943, a P-38G, while flying a special mission between Gibraltar and Malta or, perhaps, just after strafing the radar station of Capo Pula, landed on the airfield of Capoterra (Cagliari), in Sardinia, from navigation error due to a compass failure. "Regia Aeronautica" chief test pilot "colonnello" (Lieutenant Colonel) Angelo Tondi flew the aircraft to Guidonia airfield where the P-38G was evaluated. On 11 August 1943, Tondi took off to intercept a formation of about 50 bombers, returning from the bombing of Terni (Umbria). Tondi attacked B-17G "Bonny Sue", s.n. 42-30307, that fell off the shore of Torvaianica, near Rome, while six airmen parachuted out. According to US sources, he also damaged three more bombers on that occasion. On 4 September, the 301st BG reported the loss of B-17 "The Lady Evelyn," s.n. 42-30344, downed by "an enemy P-38". War missions for that plane were limited, as the Italian petrol was too corrosive for the Lockheed's tanks. Other Lightnings were eventually acquired by Italy for postwar service.

In a particular case when faced by more agile fighters at low altitudes in a constricted valley, Lightnings suffered heavy losses. On the morning of 10 June 1944, 96 P-38Js of the 1st and 82nd Fighter Groups took off from Italy for Ploiești, the third-most heavily defended target in Europe, after Berlin and Vienna. Instead of bombing from high altitude as had been tried by the Fifteenth Air Force, USAAF planning had determined that a dive-bombing surprise attack, beginning at about with bomb release at or below , performed by 46 82nd Fighter Group P-38s, each carrying one bomb, would yield more accurate results.<ref name="Stanaway ETO/MTO">Stanaway 1998, pp. 43–46.</ref> All of 1st Fighter Group and a few aircraft in 82nd Fighter Group were to fly cover, and all fighters were to strafe targets of opportunity on the return trip; a distance of some , including a circuitous outward route made in an attempt to achieve surprise.

Some 85 or 86 fighters arrived in Romania to find enemy airfields alerted, with a wide assortment of aircraft scrambling for safety. P-38s shot down several, including heavy fighters, transports and observation aircraft. At Ploiești, defense forces were fully alert, the target was concealed by smoke screen, and anti-aircraft fire was very heavy, seven Lightnings were lost to anti-aircraft fire at the target, and two more during strafing attacks on the return flight. German Bf 109 fighters from I./JG 53 and 2./JG 77 fought the Americans. Sixteen aircraft of the 71st Fighter Squadron were challenged by a large formation of Romanian single-seater IAR.81C fighters. The fight took place below in a narrow valley. Herbert Hatch saw two IAR 81Cs that he misidentified as Focke-Wulf Fw 190s hit the ground after taking fire from his guns, and his fellow pilots confirmed three more of his kills. However, the outnumbered 71st Fighter Squadron took more damage than it dished out, losing nine aircraft. In all, the USAAF lost 22 aircraft on the mission. The Americans claimed 23 aerial victories, though Romanian and German fighter units admitted losing only one aircraft each. Eleven enemy locomotives were strafed and left burning, and flak emplacements were destroyed, along with fuel trucks and other targets. Results of the bombing were not observed by the USAAF pilots because of the smoke. The dive-bombing mission profile was not repeated, though the 82nd Fighter Group was awarded the Presidential Unit Citation for its part.

Experiences over Germany had shown a need for long-range escort fighters to protect the Eighth Air Force's heavy bomber operations. The P-38Hs of the 55th Fighter Group were transferred to the Eighth in England in September 1943, and were joined by the 20th, 364th and 479th Fighter Groups soon after. P-38s and Spitfires escorted Fortress raids over Europe.

Because its distinctive shape was less prone to cases of mistaken identity and friendly fire, Lieutenant General Jimmy Doolittle, Commander of the 8th Air Force, chose to pilot a P-38 during the invasion of Normandy so that he could watch the progress of the air offensive over France. At one point in the mission, Doolittle flick-rolled through a hole in the cloud cover, but his wingman, then-Major General Earle E. Partridge, was looking elsewhere and failed to notice Doolittle's quick maneuver, leaving Doolittle to continue on alone on his survey of the crucial battle. Of the P-38, Doolittle said that it was "the sweetest-flying plane in the sky".

A little-known role of the P-38 in the European theater was that of fighter-bomber during the invasion of Normandy and the Allied advance across France into Germany. Assigned to the IX Tactical Air Command, the 370th Fighter Group and its P-38s initially flew missions from England, dive-bombing radar installations, enemy armor, troop concentrations and flak towers. The 370th's group commander Howard F. Nichols and a squadron of his P-38 Lightnings attacked Field Marshal Günther von Kluge's headquarters in July 1944; Nichols himself skipped a bomb through the front door. The 370th later operated from Cardonville France, flying ground attack missions against gun emplacements, troops, supply dumps and tanks near Saint-Lô in July and in the Falaise–Argentan area in August 1944. The 370th participated in ground attack missions across Europe until February 1945 when the unit changed over to the P-51 Mustang.

After some disastrous raids in 1944 with B-17s escorted by P-38s and Republic P-47 Thunderbolts, Jimmy Doolittle, then head of the U.S. Eighth Air Force, went to the Royal Aircraft Establishment, Farnborough, asking for an evaluation of the various American fighters. Test pilot Captain Eric Brown, Fleet Air Arm, recalled:

We had found out that the Bf 109 and the FW 190 could fight up to a Mach of 0.75, three-quarters the speed of sound. We checked the Lightning and it couldn't fly in combat faster than 0.68. So it was useless. We told Doolittle that all it was good for was photo-reconnaissance and had to be withdrawn from escort duties. And the funny thing is that the Americans had great difficulty understanding this because the Lightning had the two top aces in the Far East.

After evaluation tests at Farnborough, the P-38 was kept in fighting service in Europe for a while longer. Although many failings were remedied with the introduction of the P-38J, by September 1944, all but one of the Lightning groups in the Eighth Air Force had converted to the P-51 Mustang. The Eighth Air Force continued to conduct reconnaissance missions using the F-5 variant.

The P-38 was used most extensively and successfully in the Pacific theater, where it proved more suited, combining exceptional range with the reliability of two engines for long missions over water. The P-38 was used in a variety of roles, especially escorting bombers at altitudes of . The P-38 was credited with destroying more Japanese aircraft than any other USAAF fighter. Freezing cockpit temperatures were not a problem at low altitude in the tropics. In fact the cockpit was often too hot since opening a window while in flight caused buffeting by setting up turbulence through the tailplane. Pilots taking low altitude assignments often flew stripped down to shorts, tennis shoes, and parachute. While the P-38 could not out-turn the A6M Zero and most other Japanese fighters when flying below , its superior speed coupled with a good rate of climb meant that it could use energy tactics, making multiple high-speed passes at its target. In addition, its tightly grouped guns were even more deadly to lightly armored Japanese warplanes than to German aircraft. The concentrated, parallel stream of bullets allowed aerial victory at much longer distances than fighters carrying wing guns. Dick Bong, the United States' highest-scoring World War II air ace (40 victories in P-38s), flew directly at his targets to ensure he hit them, in some cases flying through the debris of his target (and on one occasion colliding with an enemy aircraft which was claimed as a "probable" victory). The twin Allison engines performed admirably in the Pacific.

General George C. Kenney, commander of the USAAF 5th Air Force operating in New Guinea, could not get enough P-38s; they had become his favorite fighter in November 1942 when one squadron, the 39th Fighter Squadron of the 35th Fighter Group, joined his assorted P-39s and P-40s. The Lightnings established local air superiority with their first combat action on 27 December 1942. Kenney sent repeated requests to Arnold for more P-38s, and was rewarded with occasional shipments, but Europe was a higher priority in Washington. Despite their small force, Lightning pilots began to compete in racking up scores against Japanese aircraft.

On 2–4 March 1943, P-38s flew top cover for 5th Air Force and Australian bombers and attack aircraft during the Battle of the Bismarck Sea, in which eight Japanese troop transports and four escorting destroyers were sunk. Two P-38 aces from the 39th Fighter Squadron were killed on the second day of the battle: Bob Faurot and Hoyt "Curley" Eason (a veteran with five victories who had trained hundreds of pilots, including Dick Bong). In one notable engagement on 3 March 1943 P-38s escorted 13 B-17s as they bombed the Japanese convoy from a medium altitude of 7,000 feet which dispersed the convoy formation and reduced their concentrated anti-aircraft firepower. A B-17 was shot down and when Japanese Zero fighters machine-gunned some of the B-17 crew members that bailed out in parachutes, three P-38s promptly engaged and shot down five of the Zeros.

The Lightning figured in one of the most significant operations in the Pacific theater: the interception, on 18 April 1943, of Admiral Isoroku Yamamoto, the architect of Japan's naval strategy in the Pacific including the attack on Pearl Harbor. When American codebreakers found out that he was flying to Bougainville Island to conduct a front-line inspection, 16 P-38G Lightnings were sent on a long-range fighter-intercept mission, flying from Guadalcanal at heights of above the ocean to avoid detection. The Lightnings met Yamamoto's two Mitsubishi G4M "Betty" fast bomber transports and six escorting Zeros just as they arrived at the island. The first Betty crashed in the jungle and the second ditched near the coast. Two Zeros were also claimed by the American fighters with the loss of one P-38. Japanese search parties found Yamamoto's body at the jungle crash site the next day.

The P-38's service record shows mixed results, which may reflect more on its employment than on flaws with the aircraft. The P-38's engine troubles at high altitudes only occurred with the Eighth Air Force. One reason for this was the inadequate cooling systems of the G and H models; the improved P-38 J and L had tremendous success flying out of Italy into Germany at all altitudes. Until the -J-25 variant, P-38s were easily avoided by German fighters because of the lack of dive flaps to counter compressibility in dives. German fighter pilots not wishing to fight would perform the first half of a Split S and continue into steep dives because they knew the Lightnings would be reluctant to follow.

On the positive side, having two engines was a built-in insurance policy. Many pilots made it safely back to base after having an engine failure en route or in combat. On 3 March 1944, the first Allied fighters reached Berlin on a frustrated escort mission. Lieutenant Colonel Jack Jenkins of 55th Fighter Group led the group of P-38H pilots, arriving with only half his force after flak damage and engine trouble took their toll. On the way into Berlin, Jenkins reported one rough-running engine, causing him to wonder if he would ever make it back. The B-17s he was supposed to escort never showed up, having turned back at Hamburg. Jenkins and his wingman were able to drop tanks and outrun enemy fighters to return home with three good engines between them.
In the European Theater, P-38s made 130,000 sorties with a loss of 1.3% overall, comparing favorably with P-51s, which posted a 1.1% loss, considering that the P-38s were vastly outnumbered and suffered from poorly thought-out tactics. The majority of the P-38 sorties were made in the period prior to Allied air superiority in Europe, when pilots fought against a very determined and skilled enemy. Lieutenant Colonel Mark Hubbard, a vocal critic of the aircraft, rated it the third best Allied fighter in Europe. The Lightning's greatest virtues were long range, heavy payload, high speed, fast climb and concentrated firepower. The P-38 was a formidable fighter, interceptor and attack aircraft.

In the Pacific theater, the P-38 downed over 1,800 Japanese aircraft, with more than 100 pilots becoming aces by downing five or more enemy aircraft. American fuel supplies contributed to a better engine performance and maintenance record, and range was increased with leaner mixtures. In the second half of 1944, the P-38L pilots out of Dutch New Guinea were flying , fighting for fifteen minutes and returning to base. Such long legs were invaluable until the P-47N and P-51D entered service.

The end of the war left the USAAF with thousands of P-38s rendered obsolete by the jet age. The last P-38s in service with the United States Air Force were retired in 1949. A total of 100 late-model P-38L and F-5 Lightnings were acquired by Italy through an agreement dated April 1946. Delivered, after refurbishing, at the rate of one per month, they finally were all sent to the Aeronautica Militare by 1952. The Lightnings served in the 4° "Stormo" and other units including 3° "Stormo", flying reconnaissance over the Balkans, ground attack, naval cooperation and air superiority missions. Due to old engines, pilot errors and lack of experience in operations, a large number of P-38s were lost in at least 30 accidents, many of them fatal. Despite this, many Italian pilots liked the P-38 because of its excellent visibility on the ground and stability on takeoff. The Italian P-38s were phased out in 1956; none survived the scrapyard.

Surplus P-38s were also used by other foreign air forces with 12 sold to Honduras and 15 retained by China. Six F-5s and two unarmed black two-seater P-38s were operated by the Dominican Air Force based in San Isidro Airbase, Dominican Republic in 1947. The majority of wartime Lightnings present in the continental U.S. at the end of the war were put up for sale for US$1,200 apiece; the rest were scrapped. P-38s in distant theaters of war were bulldozed into piles and abandoned or scrapped; very few avoided that fate.

The CIA "Liberation Air Force" flew one P-38M to support the 1954 Guatemalan coup d'etat. On 27 June 1954, this aircraft dropped napalm bombs that destroyed the British cargo ship , which was loading Guatemalan cotton and coffee for Grace Line in Puerto San José. In 1957, five Honduran P-38s bombed and strafed a village occupied by Nicaraguan forces during a border dispute between these two countries concerning part of Gracias a Dios Department.

P-38s were popular contenders in the air races from 1946 through 1949, with brightly colored Lightnings making screaming turns around the pylons at Reno and Cleveland. Lockheed test pilot Tony LeVier was among those who bought a Lightning, choosing a P-38J model and painting it red to make it stand out as an air racer and stunt flyer. Lefty Gardner, former B-24 and B-17 pilot and associate of the Confederate Air Force, bought a mid-1944 P-38L-1-LO that had been modified into an F-5G. Gardner painted it white with red and blue trim and named it "White Lightnin"; he reworked its turbo systems and intercoolers for optimum low-altitude performance and gave it P-38F style air intakes for better streamlining. "White Lightnin" was severely damaged in a crash landing following an engine fire on a transit flight and was bought and restored with a brilliant polished aluminum finish by the company that owns Red Bull. The aircraft is now located in Austria.

F-5s were bought by aerial survey companies and employed for mapping. From the 1950s on, the use of the Lightning steadily declined, and only a little more than two dozen still exist, with few still flying. One example is a P-38L owned by the Lone Star Flight Museum in Galveston, Texas, painted in the colors of Charles H. MacDonald's "Putt Putt Maru". Two other examples are F-5Gs which were owned and operated by Kargl Aerial Surveys in 1946, and are now located in Chino, California at Yanks Air Museum, and in McMinnville, Oregon at Evergreen Aviation Museum. The earliest-built surviving P-38, "Glacier Girl", was recovered from the Greenland ice cap in 1992, fifty years after she crashed there on a ferry flight to the UK, and after a complete restoration, flew once again ten years after her recovery.

Over 10,000 Lightnings were manufactured, becoming the only U.S. combat aircraft that remained in continuous production throughout the duration of American participation in World War II. The Lightning had a major effect on other aircraft; its wing, in a scaled-up form, was used on the Lockheed Constellation.

Delivered and accepted Lightning production variants began with the P-38D model. The few "hand made" YP-38s initially contracted were used as trainers and test aircraft. There were no Bs or Cs delivered to the government as the USAAF allocated the 'D' suffix to all aircraft with self-sealing fuel tanks and armor. Many secondary but still initial teething tests were conducted using the earliest D variants.

The first combat-capable Lightning was the P-38E (and its photo-recon variant the F-4) which featured improved instruments, electrical, and hydraulic systems. Part-way through production, the older Hamilton Standard Hydromatic hollow steel propellers were replaced by new Curtiss Electric duraluminum propellers. The definitive (and now famous) armament configuration was settled upon, featuring four .50 in (12.7 mm) machine guns with 500 rpg, and a 20 mm (.79 in) Hispano autocannon with 150 rounds.

While the machine guns had been arranged symmetrically in the nose on the P-38D, they were "staggered" in the P-38E and later versions, with the muzzles protruding from the nose in the relative lengths of roughly 1:4:6:2. This was done to ensure a straight ammunition-belt feed into the weapons, as the earlier arrangement led to jamming.

The first P-38E rolled out of the factory in October 1941 as the Battle of Moscow filled the news wires of the world. Because of the versatility, redundant engines, and especially high speed and high altitude characteristics of the aircraft, as with later variants over a hundred P-38Es were completed in the factory or converted in the field to a photoreconnaissance variant, the F-4, in which the guns were replaced by four cameras. Most of these early reconnaissance Lightnings were retained stateside for training, but the F-4 was the first Lightning to be used in action in April 1942.

After 210 P-38Es were built, they were followed, starting in February 1942, by the P-38F, which incorporated racks inboard of the engines for fuel tanks or a total of of bombs. Early variants did not enjoy a high reputation for maneuverability, though they could be agile at low altitudes if flown by a capable pilot, using the P-38's forgiving stall characteristics to their best advantage. From the P-38F-15 model onwards, a "combat maneuver" setting was added to the P-38's Fowler flaps. When deployed at the 8° maneuver setting, the flaps allowed the P-38 to out-turn many contemporary single-engined fighters at the cost of some added drag. However, early variants were hampered by high aileron control forces and a low initial rate of roll, and all such features required a pilot to gain experience with the aircraft, which in part was an additional reason Lockheed sent its representative to England, and later to the Pacific Theater.

The aircraft was still experiencing extensive teething troubles as well as being victimized by "urban legends", mostly involving inapplicable twin engine factors which had been designed out of the aircraft by Lockheed. In addition to these, the early versions had a reputation as a "widow maker" as it could enter an unrecoverable dive due to a sonic surface effect at high sub-sonic speeds. The 527 P-38Fs were heavier, with more powerful engines that used more fuel, and were unpopular in the air war in Northern Europe. Since the heavier engines were having reliability problems and with them, without external fuel tanks, the range of the P-38F was reduced, and since drop tanks themselves were in short supply as the fortunes in the Battle of the Atlantic had not yet swung the Allies' way, the aircraft became relatively unpopular in minds of the bomber command planning staffs despite being the longest ranged fighter first available to the 8th Air Force in sufficient numbers for long range escort duties. Nonetheless, General Spaatz, then commander of the 8th Air Force in the UK, said of the P-38F: "I'd rather have an airplane that goes like hell and has a few things wrong with it, than one that won't go like hell and has a few things wrong with it."
The P-38F was followed in June 1942 by the P-38G, using more powerful Allisons of each and equipped with a better radio. A dozen of the planned P-38G production were set aside to serve as prototypes for what would become the P-38J with further uprated Allison V-1710F-17 engines ( each) in redesigned booms which featured chin-mounted intercoolers in place of the original system in the leading edge of the wings and more efficient radiators. Lockheed subcontractors, however, were initially unable to supply both of Burbank's twin production lines with a sufficient quantity of new core intercoolers and radiators. War Production Board planners were unwilling to sacrifice production, and one of the two remaining prototypes received the new engines but retained the old leading edge intercoolers and radiators.

As the P-38H, 600 of these stop-gap Lightnings with an improved 20 mm cannon and a bomb capacity of were produced on one line beginning in May 1943 while the near-definitive P-38J began production on the second line in August 1943. The Eighth Air Force was experiencing high altitude and cold weather issues which, while not unique to the aircraft, were perhaps more severe as the turbo-superchargers upgrading the Allisons were having their own reliability issues making the aircraft more unpopular with senior officers out of the line. This was a situation unduplicated on all other fronts where the commands were clamoring for as many P-38s as they could get. Both the P-38G and P-38H models' performance was restricted by an intercooler system integral to the wing's leading edge which had been designed for the YP-38's less powerful engines. At the higher boost levels, the new engine's charge air temperature would increase above the limits recommended by Allison and would be subject to detonation if operated at high power for extended periods of time. Reliability was not the only issue, either. For example, the reduced power settings required by the P-38H did not allow the maneuvering flap to be used to good advantage at high altitude. All these problems really came to a head in the unplanned P-38H and sped the Lightning's eventual replacement in the Eighth Air Force; fortunately the Fifteenth Air Force were glad to get them.

Some P-38G production was diverted on the assembly line to F-5A reconnaissance aircraft. An F-5A was modified to an experimental two-seat reconnaissance configuration as the XF-5D, with a plexiglas nose, two machine guns and additional cameras in the tail booms.

The P-38J was introduced in August 1943. The turbo-supercharger intercooler system on previous variants had been housed in the leading edges of the wings and had proven vulnerable to combat damage and could burst if the wrong series of controls were mistakenly activated. In the P-38J series, the streamlined engine nacelles of previous Lightnings were changed to fit the intercooler radiator between the oil coolers, forming a "chin" that visually distinguished the J model from its predecessors. While the P-38J used the same V-1710-89/91 engines as the H model, the new core-type intercooler more efficiently lowered intake manifold temperatures and permitted a substantial increase in rated power. The leading edge of the outer wing was fitted with fuel tanks, filling the space formerly occupied by intercooler tunnels, but these were omitted on early P-38J blocks due to limited availability.

The final 210 J models, designated P-38J-25-LO, alleviated the compressibility problem through the addition of a set of electrically actuated dive recovery flaps just outboard of the engines on the bottom centerline of the wings. With these improvements, a USAAF pilot reported a dive speed of almost , although the indicated air speed was later corrected for compressibility error, and the actual dive speed was lower. Lockheed manufactured over 200 retrofit modification kits to be installed on P-38J-10-LO and J-20-LO already in Europe, but the USAAF C-54 carrying them was shot down by an RAF pilot who mistook the Douglas transport for a German Focke-Wulf Condor. Unfortunately, the loss of the kits came during Lockheed test pilot Tony LeVier's four-month morale-boosting tour of P-38 bases. Flying a new Lightning named "Snafuperman", modified to full P-38J-25-LO specifications at Lockheed's modification center near Belfast, LeVier captured the pilots' full attention by routinely performing maneuvers during March 1944 that common Eighth Air Force wisdom held to be suicidal. It proved too little, too late, because the decision had already been made to re-equip with Mustangs.

The P-38J-25-LO production block also introduced hydraulically boosted ailerons, one of the first times such a system was fitted to a fighter. This significantly improved the Lightning's rate of roll and reduced control forces for the pilot. This production block and the following P-38L model are considered the definitive Lightnings, and Lockheed ramped up production, working with subcontractors across the country to produce hundreds of Lightnings each month.

There were two P-38Ks developed from 1942 to 1943, one official and one an internal Lockheed experiment. The first was actually a battered RP-38E "piggyback" test mule previously used by Lockheed to test the P-38J chin intercooler installation, now fitted with paddle-bladed "high activity" Hamilton Standard Hydromatic propellers similar to those used on the P-47. The new propellers required spinners of greater diameter, and the mule's crude, hand-formed sheet steel cowlings were further stretched to blend the spinners into the nacelles. It retained its "piggyback" configuration that allowed an observer to ride behind the pilot. With Lockheed's AAF representative as a passenger and the maneuvering flap deployed to offset Army Hot Day conditions, the old "K-Mule" still climbed to . With a fresh coat of paint covering its crude hand-formed steel cowlings, this RP-38E acts as stand-in for the "P-38K-1-LO" in the model's only picture.

The 12th G model originally set aside as a P-38J prototype was re-designated P-38K-1-LO and fitted with the aforementioned paddle-blade propellers and new Allison V-1710-75/77 (F15R/L) powerplants rated at at War Emergency Power. These engines were geared 2.36 to 1, unlike the standard P-38 ratio of 2 to 1. The AAF took delivery in September 1943, at Eglin Field. In tests, the P-38K-1 achieved at military power and was predicted to exceed at War Emergency Power with a similar increase in load and range. The initial climb rate was /min and the ceiling was . It reached in five minutes flat; this with a coat of camouflage paint which added weight and drag. Although it was judged superior in climb and speed to the latest and best fighters from all AAF manufacturers, the War Production Board refused to authorize P-38K production due to the two-to-three-week interruption in production necessary to implement cowling modifications for the revised spinners and higher thrust line. Some have also doubted Allison's ability to deliver the F15 engine in quantity. As promising as it had looked, the P-38K project came to a halt.

The P-38L was the most numerous variant of the Lightning, with 3,923 built, 113 by Consolidated-Vultee in their Nashville plant. It entered service with the USAAF in June 1944, in time to support the Allied invasion of France on D-Day. Lockheed production of the Lightning was distinguished by a suffix consisting of a production block number followed by "LO," for example "P-38L-1-LO", while Consolidated-Vultee production was distinguished by a block number followed by "VN," for example "P-38L-5-VN."

The P-38L was the first Lightning fitted with zero-length rocket launchers. Seven high velocity aircraft rockets (HVARs) on pylons beneath each wing, and later, five rockets on each wing on "Christmas tree" launch racks which added to the aircraft. The P-38L also had strengthened stores pylons to allow carriage of bombs or drop tanks.

Lockheed modified 200 P-38J airframes in production to become unarmed F-5B photo-reconnaissance aircraft, while hundreds of other P-38Js and P-38Ls were modified at Lockheed's Dallas Modification Center to become F-5Cs, F-5Es, F-5Fs, or F-5Gs. A few P-38Ls were field-modified to become two-seat TP-38L familiarization trainers. During and after June 1948, the remaining J and L variants were designated ZF-38J and ZF-38L, with the "ZF" designator (meaning "obsolete fighter") replacing the "P for Pursuit" category.

Late model Lightnings were delivered unpainted, as per USAAF policy established in 1944. At first, field units tried to paint them, since pilots worried about being too visible to the enemy, but it turned out the reduction in weight and drag was a minor advantage in combat.

The P-38L-5, the most common sub-variant of the P-38L, had a modified cockpit heating system consisting of a plug-socket in the cockpit into which the pilot could plug his heat-suit wire for improved comfort. These Lightnings also received the uprated V-1710-112/113 (F30R/L) engines, and this dramatically lowered the amount of engine failure problems experienced at high altitude so commonly associated with European operations.

The Lightning was modified for other roles. In addition to the F-4 and F-5 reconnaissance variants, a number of P-38Js and P-38Ls were field-modified as formation bombing "pathfinders" or "droopsnoots", fitted with a Norden bombsight or an H2X radar system. Such pathfinders would lead a formation of medium and heavy bombers; or of other P-38s, each loaded with two bombs; the entire formation releasing their ordinance when the pathfinder did.

A number of Lightnings were modified as night fighters. There were several field or experimental modifications with different equipment fits that finally led to the "formal" P-38M night fighter, or "Night Lightning". A total of 75 P-38Ls were modified to the Night Lightning configuration, painted flat-black with conical flash hiders on the guns, an AN/APS-6 radar pod below the nose, and a second cockpit with a raised canopy behind the pilot's canopy for the radar operator. The headroom in the rear cockpit was limited, requiring radar operators who were preferably short in stature.

One of the initial production P-38s had its turbo-superchargers removed, with a secondary cockpit placed in one of the booms to examine how flightcrew would respond to such an "asymmetric" cockpit layout. One P-38E was fitted with an extended central nacelle to accommodate a tandem-seat cockpit with dual controls, and was later fitted with a laminar flow wing.

Very early in the Pacific War, a scheme was proposed to fit Lightnings with floats to allow them to make long-range ferry flights. The floats would be removed before the aircraft went into combat. There were concerns that saltwater spray would corrode the tailplane, and so in March 1942, P-38E "41-1986" was modified with a tailplane raised some , booms lengthened by two feet and a rearward-facing second seat added for an observer to monitor the effectiveness of the new arrangement. A second version was crafted on the same airframe with the twin booms given greater sideplane area to augment the vertical rudders. This arrangement was removed and a final third version was fabricated that had the booms returned to normal length but the tail raised . All three tail modifications were designed by George H. "Bert" Estabrook. The final version was used for a quick series of dive tests on 7 December 1942 in which Milo Burcham performed the test maneuvers and Kelly Johnson observed from the rear seat. Johnson concluded that the raised floatplane tail gave no advantage in solving the problem of compressibility. At no time was this P-38E testbed airframe actually fitted with floats, and the idea was quickly abandoned as the U.S. Navy proved to have enough sealift capacity to keep up with P-38 deliveries to the South Pacific.

Still another P-38E was used in 1942 to tow a Waco troop glider as a demonstration. However, there proved to be plenty of other aircraft, such as Douglas C-47 Skytrains, available to tow gliders, and the Lightning was spared this duty.

Standard Lightnings were used as crew and cargo transports in the South Pacific. They were fitted with pods attached to the underwing pylons, replacing drop tanks or bombs, that could carry a single passenger in a lying-down position, or cargo. This was a very uncomfortable way to fly. Some of the pods were not even fitted with a window to let the passenger see out or bring in light.

Lockheed proposed a carrier-based Model 822 version of the Lightning for the United States Navy. The Model 822 would have featured folding wings, an arresting hook, and stronger undercarriage for carrier operations. The navy was not interested, as they regarded the Lightning as too big for carrier operations and did not like liquid-cooled engines anyway, and the Model 822 never went beyond the paper stage. However, the navy did operate four land-based F-5Bs in North Africa, inherited from the USAAF and redesignated FO-1.

A P-38J was used in experiments with an unusual scheme for mid-air refueling, in which the fighter snagged a drop tank trailed on a cable from a bomber. The USAAF managed to make this work, but decided it was not practical. A P-38J was also fitted with experimental retractable snow ski landing gear, but this idea never reached operational service either.

After the war, a P-38L was experimentally fitted with armament of three .60 in (15.2 mm) machine guns. The .60 in (15.2 mm) caliber cartridge had been developed early in the war for an infantry anti-tank rifle, a type of weapon developed by a number of nations in the 1930s when tanks were lighter but, by 1942, armor was too tough for this caliber.

Another P-38L was modified after the war as a "super strafer," with eight .50 in (12.7 mm) machine guns in the nose and a pod under each wing with two .50 in (12.7 mm) guns, for a total of 12 machine guns. Nothing came of this conversion either.



Civil

The 5,000th Lightning built, a P-38J-20-LO, "44-23296", was painted bright vermilion red, and had the name "YIPPEE" painted on the underside of the wings in big white letters as well as the signatures of hundreds of factory workers. This and other aircraft were used by a handful of Lockheed test pilots including Milo Burcham, Jimmie Mattern and Tony LeVier in remarkable flight demonstrations, performing such stunts as slow rolls at treetop level with one prop feathered to dispel the myth that the P-38 was unmanageable.

On 15 July 1942, a flight of six P-38s and two B-17 bombers, with a total of 25 crew members on board, took off from Presque Isle Air Base in Maine headed for the UK. What followed was a harrowing and life-threatening landing of the entire squadron on a remote ice cap in Greenland. None of the crew was lost and they were all rescued and returned safely home after spending several days on the ice.

Fifty years later a small group of aviation enthusiasts decided to locate those aircraft, which had come to be known as "The Lost Squadron", and to recover one of the lost P-38s. It turned out to be no easy task, as the planes had been buried under 25 stories of ice and drifted over a mile from their original location. The recovered P-38, dubbed "Glacier Girl", was eventually restored to airworthiness.

This plane crashed in September 1942, and is buried in the sea off the coast of Harlech, Wales, United Kingdom. It has been granted protected status in November 2019 for its historic and archaeological interest by Cadw.

The American ace of aces and his closest competitor both flew Lightnings and tallied 40 and 38 victories respectively. Majors Richard I. "Dick" Bong and Thomas B. "Tommy" McGuire of the USAAF competed for the top position. Both men were awarded the Medal of Honor.

McGuire was killed in air combat in January 1945 over the Philippines, after accumulating 38 confirmed kills, making him the second-ranking American ace. Bong was rotated back to the United States as America's ace of aces, after making 40 kills, becoming a test pilot. He was killed on 6 August 1945, the day the atomic bomb was dropped on Japan, when his Lockheed P-80 Shooting Star jet fighter flamed out on takeoff.

The famed aviator Charles Lindbergh toured the South Pacific as a civilian contractor for United Aircraft Corporation, comparing and evaluating performance of single- and twin-engined fighters for Vought. He worked to improve range and load limits of the Vought F4U Corsair, flying both routine and combat strafing missions in Corsairs alongside Marine pilots.

Everywhere Lindbergh went in the South Pacific, he was accorded the normal preferential treatment of a visiting colonel, although he had resigned his Air Corps Reserve colonel's commission three years before. In Hollandia, Lindbergh attached himself to the 475th FG, flying P-38s. Although new to the aircraft, Lindbergh was instrumental in extending the range of the P-38 through improved throttle settings, or engine-leaning techniques, notably by reducing engine speed to 1,600 rpm, setting the carburetors for auto-lean and flying at indicated airspeed which reduced fuel consumption to 70 gal/h, about 2.6 mpg. This combination of settings had been considered dangerous and would upset the fuel mixture, causing an explosion.

While with the 475th, he held training classes and took part in a number of Army Air Corps combat missions. On 28 July 1944, Lindbergh shot down a Mitsubishi Ki-51 "Sonia" flown by the veteran commander of 73rd Independent Flying Chutai, Imperial Japanese Army Captain Saburo Shimada. In an extended, twisting dogfight in which many of the participants ran out of ammunition, Shimada turned his aircraft directly toward Lindbergh who was just approaching the combat area. Lindbergh fired in a defensive reaction brought on by Shimada's apparent head-on ramming attack. Hit by cannon and machine gun fire, the "Sonia's" propeller visibly slowed, but Shimada held his course. Lindbergh pulled up at the last moment to avoid collision as the damaged "Sonia" went into a steep dive, hit the ocean and sank. Lindbergh's wingman, ace Joseph E. "Fishkiller" Miller, Jr., had also scored hits on the "Sonia" after it had begun its fatal dive, but Miller was certain the kill credit was Lindbergh's. The unofficial kill was not entered in the 475th's war record. On 12 August 1944, Lindbergh left Hollandia to return to the United States.

The seventh-ranking American ace, Charles H. MacDonald, flew a Lightning against the Japanese, scoring 27 kills in his famous aircraft, the "Putt Putt Maru".

Martin James Monti was an American pilot who defected to the Axis powers in a stolen F-5E Lightning, which was handed over to the "Luftwaffe" "Zirkus Rosarius" for testing afterward.

Robin Olds was the last P-38 ace in the Eighth Air Force and the last in the ETO. Flying a P-38J, he downed five German fighters on two separate missions over France and Germany. He subsequently transitioned to P-51s and scored seven more kills. After World War II, he flew F-4 Phantom IIs in Vietnam, ending his career as brigadier general with 16 kills.

Ross is a decorated World War II pilot who flew 96 missions for the U.S. Army Air Forces under the U.S. 8th Air Force's 7th Reconnaissance Group in the 22nd Reconnaissance Squadron. Ross flew the Lockheed P-38 Lightning as a photoreconnaissance pilot out of RAF Mount Farm in England during the war. He received 11 medals and was awarded the Distinguished Flying Cross twice for missions that were integral to Allied victory at the Battle of the Bulge.

At midday on 31 July 1944, the noted aviation pioneer and writer Antoine de Saint-Exupéry ("Night Flight", "Wind, Sand and Stars" and "The Little Prince") vanished in his P-38 of the French "Armée de l'Air's" "Groupe de Chasse II/33", after departing Borgo-Porreta, Corsica. His health, both physically and mentally, had been deteriorating. Saint-Exupéry was said to be intermittently subject to depression and there had been talk of taking him off flying status. He was on a flight over the Mediterranean, from Corsica to mainland France, in an unarmed F-5B photoreconnaissance variant of the P-38J, described as being a "war-weary, non-airworthy craft".

In 2000, a French scuba diver found the partial remnants of a Lightning spread over several thousand square meters of the Mediterranean seabed off the coast of Marseille. In April 2004, the recovered component serial numbers were confirmed as being from Saint-Exupéry's F-5B Lightning. Only a small amount of the aircraft's wreckage was recovered. In June 2004, the recovered parts and fragments were given to the Air and Space Museum of France in Le Bourget, Paris, where Saint-Exupéry's life is commemorated in a special exhibit.

In 1981 and also in 2008, two Luftwaffe fighter pilots, respectively Robert Heichele and Horst Rippert, separately claimed to have shot down Saint-Exupéry's P-38. Both claims were unverifiable and possibly self-promotional, as neither of their units' combat records of action from that period made any note of such a shoot-down.

A P-38 piloted by Clay Tice was the first American aircraft to land in Japan after VJ Day, when he and his wingman set down on Nitagahara because his wingman was low on fuel.

The RAF's notable photoreconnaissance pilot, Wing Commander Adrian Warburton (DSO w/Bar, DFC w/2 Bars) was posted as the RAF Liaison Officer to the USAAF 7th Photographic Reconnaissance Group. On 12 April 1944 he took off in a P-38 with others to photograph targets in Germany. Warburton failed to arrive at the rendezvous point and was never seen again. In 2003, his remains were recovered in Germany from his wrecked aircraft.

Harley Earl arranged for several of his designers to view a YP-38 prototype shortly before World War II, and its design directly inspired the tail fins of the 1948–1949 Cadillac.

The P-38 was also the inspiration for Raymond Loewy and his design team at Studebaker for the 1950 and 1951 model-year Studebakers.

The whine of the speeder bike engines in "Return of the Jedi" was partly achieved by recording the engine noise of a P-38, combined with that of a North American P-51 Mustang.

The Japanese video game company Capcom features the P-38 in its "19XX" series of arcade games, including "", "1942", and "".





</doc>
<doc id="25042" url="https://en.wikipedia.org/wiki?curid=25042" title="Prayer">
Prayer

Prayer is an invocation or act that seeks to activate a rapport with an object of worship through deliberate communication. In the narrow sense, the term refers to an act of supplication or intercession directed towards a deity (a god), or a deified ancestor. More generally, prayer can also have the purpose of thanksgiving or praise, and in comparative religion is closely associated with more abstract forms of meditation and with charms or spells.

Prayer can take a variety of forms: it can be part of a set liturgy or ritual, and it can be performed alone or in groups. Prayer may take the form of a hymn, incantation, formal creedal statement, or a spontaneous utterance in the praying person.

The act of prayer is attested in written sources as early as 5000 years ago. Today, most major religions involve prayer in one way or another; some ritualize the act, requiring a strict sequence of actions or placing a restriction on who is permitted to pray, while others teach that prayer may be practised spontaneously by anyone at any time.

Scientific studies regarding the use of prayer have mostly concentrated on its effect on the healing of sick or injured people. The efficacy of prayer in faith healing has been evaluated in numerous studies, with contradictory results.

The English term "prayer" is from Medieval Latin "precaria" "petition, prayer". The Vulgate Latin is "oratio", which translates Greek προσευχή in turn the Septuagint translation of Biblical Hebrew "tĕphillah".

Various spiritual traditions offer a wide variety of devotional acts. There are morning and evening prayers, graces said over meals, and reverent physical gestures. Some Christians bow their heads and fold their hands. Some Native Americans regard dancing as a form of prayer. Some Sufis whirl. Hindus chant mantras. Jewish prayer may involve swaying back and forth and bowing. Muslims practice "salat" (kneeling and prostration) in their prayers. Quakers keep silent. Some pray according to standardized rituals and liturgies, while others prefer extemporaneous prayers. Still others combine the two.

Friedrich Heiler is often cited in Christian circles for his systematic "Typology of Prayer" which lists six types of prayer: primitive, ritual, Greek cultural, philosophical, mystical, and prophetic. Some forms of prayer require a prior ritualistic form of cleansing or purification such as in ghusl and wudhu.

Prayer may be done privately and individually, or it may be done corporately in the presence of fellow believers. Prayer can be incorporated into a daily "thought life", in which one is in constant communication with a god. Some people pray throughout all that is happening during the day and seek guidance as the day progresses. This is actually regarded as a requirement in several Christian denominations, although enforcement is not possible nor desirable. There can be many different answers to prayer, just as there are many ways to interpret an answer to a question, if there in fact comes an answer. Some may experience audible, physical, or mental epiphanies. If indeed an answer comes, the time and place it comes is considered random.
Some outward acts that sometimes accompany prayer are: anointing with oil; ringing a bell; burning incense or paper; lighting a candle or candles; See, for example, facing a specific direction (i.e. towards Mecca or the East); making the sign of the cross. One less noticeable act related to prayer is fasting.

A variety of body postures may be assumed, often with specific meaning (mainly respect or adoration) associated with them: standing; sitting; kneeling; prostrate on the floor; eyes opened; eyes closed; hands folded or clasped; hands upraised; holding hands with others; a laying on of hands and others. Prayers may be recited from memory, read from a book of prayers, or composed spontaneously as they are prayed. They may be said, chanted, or sung. They may be with musical accompaniment or not. There may be a time of outward silence while prayers are offered mentally. Often, there are prayers to fit specific occasions, such as the blessing of a meal, the birth or death of a loved one, other significant events in the life of a believer, or days of the year that have special religious significance. Details corresponding to specific traditions are outlined below.

Anthropologically, the concept of prayer is closely related to that of surrender and supplication.
The traditional posture of prayer in medieval Europe is kneeling or supine with clasped hands, in antiquity more typically with raised hands. The early Christian prayer posture was standing, looking up to heaven, with outspread arms and bare head. This is the pre-Christian, pagan prayer posture (except for the bare head, which was prescribed for males in Corinthians 11:4, in Roman paganism, the head had to be covered in prayer). Certain Cretan and Cypriote figures of the Late Bronze Age, with arms raised, have been interpreted as worshippers. Their posture is similar to the "flight" posture, a crouching posture with raised hands, observed in schizophrenic patients and related to the universal "hands up" gesture of surrender. The kneeling posture with clasped hands appears to have been introduced only with the beginning high medieval period, presumably adopted from a gesture of feudal homage.

Although prayer in its literal sense is not used in animism, communication with the spirit world is vital to the animist way of life. This is usually accomplished through a shaman who, through a trance, gains access to the spirit world and then shows the spirits' thoughts to the people. Other ways to receive messages from the spirits include using astrology or contemplating fortune tellers and healers.

Some of the oldest extant literature, such as the Sumerian temple hymns of Enheduanna (c. 23rd century BC) are liturgy addressed to deities and thus technically "prayer". The Egyptian Pyramid Texts of about the same period similarly contain spells or incantations addressed to the gods. In the loosest sense, in the form of magical thinking combined with animism, prayer has been argued as representing a human cultural universal, which would have been present since the emergence of behavioral modernity, by anthropologists such as Sir Edward Burnett Tylor and Sir James George Frazer.

Reliable records are available for the polytheistic religions of the Iron Age, most notably Ancient Greek religion (which strongly influenced Roman religion). These religious traditions were direct developments of the earlier Bronze Age religions.
Ceremonial prayer was highly formulaic and ritualized.

In ancient polytheism, ancestor worship is indistinguishable from theistic worship (see also Euhemerism).
Vestiges of ancestor worship persist, to a greater or lesser extent, in modern religious traditions throughout the world, most notably in Japanese Shinto and in Chinese folk religion. The practices involved in Shinto prayer are heavily influenced by Buddhism; Japanese Buddhism has also been strongly influenced by Shinto in turn. Shinto prayers quite frequently consist of wishes or favors asked of the "kami", rather than lengthy praises or devotions. The practice of votive offering is also universal, and is attested at least since the Bronze Age. In Shinto, this takes the form of a small wooden tablet, called an "ema".

Prayers in Etruscan were used in the Roman world by augurs and other oracles long after Etruscan became a dead language. The Carmen Arvale and the Carmen Saliare are two specimens of partially preserved prayers that seem to have been unintelligible to their scribes, and whose language is full of archaisms and difficult passages.

Roman prayers and sacrifices were often envisioned as legal bargains between deity and worshipper. The Roman principle was expressed as "do ut des": "I give, so that you may give." Cato the Elder's treatise on agriculture contains many examples of preserved traditional prayers; in one, a farmer addresses the unknown deity of a possibly sacred grove, and sacrifices a pig in order to placate the god or goddess of the place and beseech his or her permission to cut down some trees from the grove.
Celtic, Germanic and Slavic religions are recorded much later, and much more fragmentarily, than the religions of classical antiquity. They nevertheless show substantial parallels to the better-attested religions of the Iron Age. In the case of Germanic religion, the practice of prayer is reliably attested, but no actual liturgy is recorded from the early (Roman era) period. An Old Norse prayer is on record in the form of a dramatization in skaldic poetry. This prayer is recorded in stanzas2 and3 of the poem "Sigrdrífumál", compiled in the 13th century "Poetic Edda" from earlier traditional sources, where the valkyrie Sigrdrífa prays to the gods and the earth after being woken by the hero Sigurd.
A prayer to Odin is mentioned in chapter2 of the "Völsunga saga" where King Rerir prays for a child. In stanza9 of the poem "Oddrúnargrátr", a prayer is made to "kind wights, Frigg and Freyja, and many gods In chapter 21 of "Jómsvíkinga saga", wishing to turn the tide of the Battle of Hjörungavágr, Haakon Sigurdsson eventually finds his prayers answered by the goddesses Þorgerðr Hölgabrúðr and Irpa.
Folk religion in the medieval period produced syncretisms between pre-Christian and Christian traditions. An example is the 11th-century Anglo-Saxon charm "Æcerbot" for the fertility of crops and land, or the medical "Wið færstice". The 8th-century Wessobrunn Prayer has been proposed as a Christianized pagan prayer and compared to the pagan "Völuspá" and the Merseburg Incantations, the latter recorded in the 9th or 10th century but of much older traditional origins.

In Australian Aboriginal mythology, prayers to the "Great Wit" are performed by the "clever men" and "clever women", or "kadji". These Aboriginal shamans use maban or mabain, the material that is believed to give them their purported magical powers. The Pueblo Indians are known to have used prayer sticks, that is, sticks with feathers attached as supplicatory offerings. The Hopi Indians used prayer sticks as well, but they attached to it a small bag of sacred meal.

The most common form of prayer is to directly appeal to a deity to grant one's requests. Some have termed this as the social approach to prayer.

Atheist arguments against prayer are mostly directed against petitionary prayer in particular. Daniel Dennett argued that petitionary prayer might have the undesirable psychological effect of relieving a person of the need to take active measures.

This potential drawback manifests in extreme forms in such cases as Christian Scientists who rely on prayers instead of seeking medical treatment for family members for easily curable conditions which later result in death.

Christopher Hitchens (2012) argued that praying to a god which is omnipotent and all-knowing would be presumptuous. For example, he interprets Ambrose Bierce's definition of prayer by stating that "the man who prays is the one who thinks that god has arranged matters all wrong, but who also thinks that he can instruct god how to put them right."

In this view, prayer is not a conversation. Rather, it is meant to inculcate certain attitudes in the one who prays, but not to influence. Among Jews, this has been the approach of Rabbenu Bachya, Rabbi Yehuda Halevi, Joseph Albo, Samson Raphael Hirsch, and Joseph B. Soloveitchik. This view is expressed by Rabbi Nosson Scherman in the overview to the Artscroll Siddur (p. XIII).

Among Christian theologians, E.M. Bounds stated the educational purpose of prayer in every chapter of his book, "The Necessity of Prayer". Prayer books such as the Book of Common Prayer are both a result of this approach and an exhortation to keep it.

In this view, the ultimate goal of prayer is to help train a person to focus on divinity through philosophy and intellectual contemplation (meditation). This approach was taken by the Jewish scholar and philosopher Maimonides and the other medieval rationalists. It became popular in Jewish, Christian, and Islamic intellectual circles, but never became the most popular understanding of prayer among the laity in any of these faiths. In all three of these faiths today, a significant minority of people still hold to this approach.

In this approach, the purpose of prayer is to enable the person praying to gain a direct experience of the recipient of the prayer (or as close to direct as a specific theology permits). This approach is very significant in Christianity and widespread in Judaism (although less popular theologically). In Eastern Orthodoxy, this approach is known as hesychasm. It is also widespread in Sufi Islam, and in some forms of mysticism. It has some similarities with the rationalist approach, since it can also involve contemplation, although the contemplation is not generally viewed as being as rational or intellectual. Christian and Roman Catholic traditions also include an experiential approach to prayer within the practice of Lectio Divina, historically a Benedictine practice in which scripture is read aloud; actively meditated upon using the intellect (but not analysis) possibly using the mind to place the listener within a relationship or dialogue with the text that was read; a prayer spoken; and finally concludes with , a more passive experiential approach than the previous meditation, which is characterized by the Catechism of the Catholic Church as an experience of consciously being attentive, and having a silent love toward God, which the individual experiences without demanding to receive an experience. The experience of God within Christian mysticism has been contrasted with the concept of experiential religion or mystical experience because of a long history or authors living and writing about experience with the divine in a manner that identifies God as unknowable and ineffable, the language of such ideas could be characterized paradoxically as "experiential", as well as without the phenomena of experience.

The notion of "religious experience" can be traced back to William James, who used a term called "religious experience" in his book, "The Varieties of Religious Experience". The origins of the use of this term can be dated further back.

In the 18th, 19th, and 20th centuries, several historical figures put forth very influential views that religion and its beliefs can be grounded in experience itself. While Kant held that moral experience justified religious beliefs, John Wesley in addition to stressing individual moral exertion thought that the religious experiences in the Methodist movement (paralleling the Romantic Movement) were foundational to religious commitment as a way of life.

Wayne Proudfoot traces the roots of the notion of "religious experience" to the German theologian Friedrich Schleiermacher (1768–1834), who argued that religion is based on a feeling of the infinite. The notion of "religious experience" was used by Schleiermacher and Albert Ritschl to defend religion against the growing scientific and secular critique, and defend the view that human (moral and religious) experience justifies religious beliefs.

Such religious empiricism would be later seen as highly problematic and was – during the period in-between world wars – famously rejected by Karl Barth. In the 20th century, religious as well as moral experience as justification for religious beliefs still holds sway. Some influential modern scholars holding this liberal theological view are Charles Raven and the Oxford physicist/theologian Charles Coulson.

The notion of "religious experience" was adopted by many scholars of religion, of whom William James was the most influential.

The notion of "experience" has been criticised. Robert Sharf points out that "experience" is a typical Western term, which has found its way into Asian religiosity via western influences. The notion of "experience" introduces a false notion of duality between "experiencer" and "experienced", whereas the essence of kensho is the realisation of the "non-duality" of observer and observed. "Pure experience" does not exist; all experience is mediated by intellectual and cognitive activity. The specific teachings and practices of a specific tradition may even determine what "experience" someone has, which means that this "experience" is not the "proof" of the teaching, but a "result" of the teaching. A pure consciousness without concepts, reached by "cleaning the doors of perception", would be an overwhelming chaos of sensory input without coherence.

In the Hebrew Bible prayer is an evolving means of interacting with God, most frequently through a spontaneous, individual, unorganized form of petitioning and/or thanking. Standardized prayer such as is done today is non-existent, although beginning in Deuteronomy, the Bible lays the groundwork for organized prayer, including basic liturgical guidelines, and by the Bible's later books, prayer has evolved to a more standardized form, although still radically different from the form practiced by modern Jews.

Individual prayer is described by the Tanakh two ways. The first of these is when prayer is described as occurring, and a result is achieved, but no further information regarding a person's prayer is given. In these instances, such as with Isaac, Moses, Samuel, and Job, the act of praying is a method of changing a situation for the better. The second way in which prayer is depicted is through fully fleshed out episodes of prayer, where a person's prayer is related in full. Many famous biblical personalities have such a prayer, including every major character from Hannah to Hezekiah.

In the New Testament prayer is presented as a positive command (; ). The People of God are challenged to include Christian prayer in their everyday life, even in the busy struggles of marriage () as it brings people closer to God.

Jesus encouraged his disciples to pray in secret in their private rooms, using the Lord's Prayer, as a humble response to the prayer of the Pharisees, whose practices in prayer were regarded as impious by the New Testament writers ().

Throughout the New Testament, prayer is shown to be God's appointed method by which we obtain what He has to bestow (; ; . Further, the Book of James says that the lack of blessings in life results from a failure to pray (). Jesus healed through prayer and expected his followers to do so also (; ). The apostle Paul wrote to the churches of Thessalonica to "Pray continually." ()

Observant Jews pray three times a day, Shacharit, Mincha, and Ma'ariv with lengthier prayers on special days, such as the Shabbat and Jewish holidays including Musaf and the reading of the Torah. The siddur is the prayerbook used by Jews all over the world, containing a set order of daily prayers. Jewish prayer is usually described as having two aspects: "kavanah" (intention) and "keva" (the ritualistic, structured elements).

The most important Jewish prayers are the Shema Yisrael ("Hear O Israel") and the Amidah ("the standing prayer").

Communal prayer is preferred over solitary prayer, and a quorum of ten adult males (a "minyan") is considered by Orthodox Judaism a prerequisite for several communal prayers.
There are also many other ritualistic prayers a Jew performs during their day, such as washing before eating bread, washing after one wakes up in the morning, and doing grace after meals.

In this view, the ultimate goal of prayer is to help train a person to focus on divinity through philosophy and intellectual contemplation. This approach was taken by Maimonides and the other medieval rationalists. One example of this approach to prayer is noted by Rabbi Steven Weil, who was appointed the Orthodox Union's Executive-Vice President in 2009. He notes that the word "prayer" is a derivative of the Latin "precari", which means "to beg". The Hebrew equivalent "tefilah", however, along with its root "pelel" or its reflexive "l’hitpallel", means the act of self-analysis or self-evaluation. This approach is sometimes described as the person praying having a dialogue or conversation with God.

In this view, prayer is not a conversation. Rather, it is meant to inculcate certain attitudes in the one who prays, but not to influence. This has been the approach of Rabbenu Bachya, Yehuda Halevy, Joseph Albo, Samson Raphael Hirsch, and Joseph Dov Soloveitchik. This view is expressed by Rabbi Nosson Scherman in the overview to the Artscroll Siddur (p. XIII); note that Scherman goes on to also affirm the Kabbalistic view (see below).

Kabbalah uses a series of "kavanot", directions of intent, to specify the path the prayer ascends in the dialog with God, to increase its chances of being answered favorably. Kabbalists ascribe a higher meaning to the purpose of prayer, which is no less than affecting the very fabric of reality itself, restructuring and repairing the universe in a real fashion. In this view, every word of every prayer, and indeed, even every letter of every word, has a precise meaning and a precise effect. Prayers thus literally affect the mystical forces of the universe, and repair the fabric of creation.

Among Jews, this approach has been taken by the Chassidei Ashkenaz (German pietists of the Middle-Ages), the Arizal's Kabbalist tradition, Ramchal, most of Hassidism, the Vilna Gaon, and Jacob Emden.

Christian prayers are quite varied. They can be completely spontaneous, or read entirely from a text, like the Anglican Book of Common Prayer. The most common prayer among Christians is the Lord's Prayer, which according to the gospel accounts (e.g. ) is how Jesus taught his disciples to pray. The Lord's Prayer is a model for prayers of adoration, confession and petition in Christianity. In medieval England, prayers (particularly the "paternoster") were frequently used as a measure of time in medical and culinary recipe books.

Christians generally pray to God or to the Father. Some Christians (e.g., Catholics, Orthodox) will also ask the righteous in heaven and "in Christ," such as Virgin Mary or other saints to intercede by praying on their behalf (intercession of saints). Formulaic closures include "through our Lord Jesus Christ, Your Son, who lives and reigns with You, in the unity of the Holy Spirit, God, through all the ages of ages," and "in the name of the Father, and the Son, and the Holy Spirit."

It is customary among Protestants to end prayers with "In Jesus' name, Amen" or "In the name of Christ, Amen." However, the most commonly used closure in Christianity is simply "Amen" (from a Hebrew adverb used as a statement of affirmation or agreement, usually translated as "so be it").

In the Western or Latin Rite of the Roman Catholic Church, probably the most common is the Rosary; In the Eastern Church (the Eastern rites of the Catholic Church and Orthodox Church), the Jesus Prayer. The Jesus Prayer is also often repeated as part of the meditative hesychasm practice in Eastern Christianity.

Roman Catholic tradition includes specific prayers and devotions as acts of reparation which do not involve a petition for a living or deceased beneficiary, but aim to repair the sins of others, e.g. for the repair of the sin of blasphemy performed by others.

Other forms of prayer among Catholics would be meditative prayer, contemplative prayer and infused prayer discussed at length by Catholic Saints St. John of the Cross and St. Theresa of Jesus.

In Pentecostal congregations, prayer is often accompanied by speaking in an unknown tongue, a practice now known as glossolalia. Practitioners of Pentecostal glossolalia may claim that the languages they speak in prayer are real foreign languages, and that the ability to speak those languages spontaneously is a gift of the Holy Spirit. Some people outside of the movement, however, have offered dissenting views. George Barton Cutten suggested that glossolalia was a sign of mental illness. Felicitas Goodman suggested that tongue speakers were under a form of hypnosis. Others suggest that it is a learned behaviour. Some of these views have allegedly been refuted.

Christian Science teaches that prayer is a spiritualization of thought or an understanding of God and of the nature of the underlying spiritual creation. Adherents believe that this can result in healing, by bringing spiritual reality into clearer focus in the human scene. The world as it appears to the senses is regarded as a distorted version of the world of spiritual ideas. Prayer can heal the distortion. Christian Scientists believe that prayer does not change the spiritual creation but gives a clearer view of it, and the result appears in the human scene as healing: the human picture adjusts to coincide more nearly with the divine reality. Christian Scientists do not practice intercessory prayer as it is commonly understood, and they generally avoid combining prayer with medical treatment in the belief that the two practices tend to work against each other. Prayer works through love: the recognition of God's creation as spiritual, intact, and inherently lovable.

The Arabic word for prayer is "salah". In Islam, there are five daily obligatory prayers that are considered as one of the pillars of the religion. The command to ritual prayer occurs repeatedly in the Quran. The prayer is performed by the person while they are facing the Kaaba in Mecca. There is the "call for prayer" ("adhan"), where the "muezzin" calls for all the followers to stand together for the prayer. The prayer consists of actions such as glorifying and praising God (such as mentioning ‘Allāhu Akbar’ (God is Great)) while standing, recitation of chapters of the Quran (such as the opening chapter of the book ("Al-Fatiha")), bowing down then praising God, prostrating ("sujud") then again praising God and it ends with the words: "Peace be with you and God’s mercy". During the prayer, a Muslim cannot talk or do anything else besides pray. Once the prayer is complete, one can offer personal prayers or supplications to God for their needs that are known as "dua". There are many standard invocations in Arabic to be recited at various times ("e.g." after the prayer) and for various occasions ("e.g." for one's parents) with manners and etiquette such as before eating. Muslims may also say "dua" in their own words and languages for any issue they wish to communicate with God in the hope that God will answer their prayers. Certain Shi'a sects pray the five daily prayers divided into three separate parts of the day, providing several Hadith as supporting evidence; although according to Shia Islam, it is also permissible to pray at five times.

Bahá'u'lláh, the Báb, and `Abdu'l-Bahá wrote many prayers for general use, and some for specific occasions, including for unity, detachment, spiritual upliftment, and healing among others. Bahá'ís are also required to recite each day one of three obligatory prayers composed by Bahá'u'lláh. The believers have been enjoined to face in the direction of the Qiblih when reciting their Obligatory Prayer. The longest obligatory prayer may be recited at any time during the day; another, of medium length, is recited once in the morning, once at midday, and once in the evening; and the shortest can be recited anytime between noon and sunset. Bahá'ís also read from and meditate on the scriptures every morning and evening.

In both Buddhism and Hinduism, the repetition of mantras is closely related to the practice of repetitive prayer in Western religion (rosary, Jesus prayer). Many of the most widespread Hindu and Buddhist mantras are in origin invocations of deities, e.g. Gayatri Mantra dedicated to Savitr, Pavamana Mantra to Soma Pavamana, and many of the Buddhist Dhāraṇī originate as recitations of lists of names or attributes of deities. Most of the shorter Buddhist mantras originate as the invocation of the name of a specific deity or "bodhisattva", such as "Om mani padme hum" being in origin the invocation of a "bodhisattva" called "Maṇipadma". However, from an early time these mantras were interpreted in the context of mystical sound symbolism. The most extreme example of this is the om syllable, which as early as in the Aitareya Brahmana was claimed as equivalent to the entire Vedas (collection of ritual hymns).

In the earliest Buddhist tradition, the Theravada, and in the later Mahayana tradition of Zen (or Chán), prayer plays only an ancillary role. It is largely a ritual expression of wishes for success in the practice and in helping all beings.

The skillful means (Sanskrit: "upāya") of the transfer of merit (Sanskrit: "pariṇāmanā") is an evocation and prayer. Moreover, indeterminate buddhas are available for intercession as they reside in awoken-fields (Sanskrit: "buddha-kshetra").

The "nirmānakāya" of an awoken-field is what is generally known and understood as a mandala. The opening and closing of the ring (Sanskrit: "maṇḍala") is an active prayer. An active prayer is a mindful activity, an activity in which mindfulness is not just cultivated but "is". A common prayer is "May the merit of my practice, adorn Buddhas' Pure Lands, requite the fourfold kindness from above, and relieve the suffering of the three life-journeys below. Universally wishing sentient beings, Friends, foes, and karmic creditors, all to activate the bodhi mind, and all to be reborn in the Pure Land of Ultimate Bliss." (願以此功德 莊嚴佛淨土 上報四重恩 下濟三途苦 普願諸眾生 冤親諸債主 悉發菩提心 同生極樂國)

The Generation Stage (Sanskrit: "utpatti-krama") of Vajrayana involves prayer elements.

The Tibetan Buddhism tradition emphasizes an instructive and devotional relationship to a guru; this may involve devotional practices known as guru yoga which are congruent with prayer. It also appears that Tibetan Buddhism posits the existence of various deities, but the peak view of the tradition is that the deities or "yidam" are no more existent or real than the continuity (Sanskrit: "santana"; refer mindstream) of the practitioner, environment and activity. But how practitioners engage "yidam" or tutelary deities will depend upon the level or more appropriately "yana" at which they are practicing. At one level, one may pray to a deity for protection or assistance, taking a more subordinate role. At another level, one may invoke the deity, on a more equal footing. And at a higher level one may deliberately cultivate the idea that one has become the deity, whilst remaining aware that its ultimate nature is "śūnyatā". The views of the more esoteric "yana" are impenetrable for those without direct experience and empowerment.

Pure Land Buddhism emphasizes the recitation by devotees of prayer-like mantras, a practice often called "Nembutsu". On one level it is said that reciting these mantras can ensure rebirth into a "Sambhogakāya" land (Sanskrit: "buddha-kshetra") after bodily dissolution, a sheer ball spontaneously co-emergent to a buddha's enlightened intention. According to Shinran, the founder of the Pure Land Buddhism tradition that is most prevalent in the US, "for the long haul nothing is as efficacious as the Nembutsu." On another, the practice is a form of meditation aimed at achieving realization.

But beyond all these practices the Buddha emphasized the primacy of individual practice and experience. He said that supplication to gods or deities was not necessary. Nevertheless, today many lay people in East Asian countries pray to the Buddha in ways that resemble Western prayer—asking for intervention and offering devotion.

Hinduism has incorporated many kinds of prayer (Sanskrit: "prārthanā"), from fire-based rituals to philosophical musings. While chanting involves 'by dictum' recitation of timeless verses or verses with timings and notations, "dhyanam" involves deep meditation (however short or long) on the preferred deity/God. Again the object to which prayers are offered could be a persons referred as "devtas", trinity or incarnation of either "devtas" or trinity or simply plain formless meditation as practiced by the ancient sages. These prayers can be directed to fulfilling personal needs or deep spiritual enlightenment, and also for the benefit of others. Ritual invocation was part and parcel of the Vedic religion and as such permeated their sacred texts. Indeed, the highest sacred texts of the Hindus, the Vedas, are a large collection of mantras and prayer rituals. Classical Hinduism came to focus on extolling a single supreme force, Brahman, that is made manifest in several lower forms as the familiar gods of the Hindu pantheon. Hindus in India have numerous devotional movements. Hindus may pray to the highest absolute God Brahman, or more commonly to its three manifestations, a creator god called Brahma, a preserver god called Vishnu and a destroyer god (so that the creation cycle can start afresh) Shiva, and at the next level to Vishnu's avatars (earthly appearances) Rama and Krishna or to many other male or female deities. Typically, Hindus pray with their hands (the palms) joined together in "pranam". The hand gesture is similar to the popular Indian greeting "namaste".

The "Ardās" (Punjabi: ਅਰਦਾਸ) is a Sikh prayer that is done before performing or after undertaking any significant task; after reciting the daily "Banis" (prayers); or completion of a service like the "Paath" (scripture reading/recitation), "kirtan" (hymn-singing) program or any other religious program. In Sikhism, these prayers are also said before and after eating. The prayer is a plea to God to support and help the devotee with whatever he or she is about to undertake or has done.

The "Ardas" is usually always done standing up with folded hands. The beginning of the "Ardas" is strictly set by the tenth Sikh Guru, Guru Gobind Singh. When it comes to conclusion of this prayer, the devotee uses words like "Waheguru please bless me in the task that I am about to undertake" when starting a new task or "Akal Purakh, having completed the hymn-singing, we ask for your continued blessings so that we can continue with your memory and remember you at all times", etc. The word "Ardās" is derived from Persian word 'Arazdashat', meaning a request, supplication, prayer, petition or an address to a superior authority.

Ardās is a unique prayer based on the fact that it is one of the few well-known prayers in the Sikh religion that was not written in its entirety by the Gurus. The Ardās cannot be found within the pages of the Guru Granth Sahib because it is a continually changing devotional text that has evolved over time in order for it to encompass the feats, accomplishments, and feelings of all generations of Sikhs within its lines. Taking the various derivation of the word Ardās into account, the basic purpose of this prayer is an appeal to Waheguru for his protection and care, as well as being a plea for the welfare and prosperity of all mankind, and a means for the Sikhs to thank Waheguru for all that he has done.

Wiccan prayers can include meditation, rituals and incantations. Wiccans see prayers as a form of communication with the God and Goddess. Such communication may include prayers for "esbat" and "sabbat" celebrations, for dinner, for pre-dawn times or for one's own or others' safety, for healing or for the dead.

In Raëlism rites and practises vary from initiation ceremonies to sensual meditation. An initiation ceremony usually involves a Raelian putting water on the forehead of a new member. Such ceremonies take place on certain special days on the Raelian calendar. Sensual meditation techniques include breathing exercises and various forms of erotic meditation.

In Eckankar, one of the basic forms of prayer includes singing the word "HU" (pronounced as "hue"), a holy name of God. ECKists may do this with eyes closed or open, aloud or silently. Practitioners may experience the divine ECK or Holy Spirit.

Practitioners of theurgy and Western esotericism may practice a form of ritual which utilizes both pre-sanctioned prayers and names of God, and prayers "from the heart" that, when combined, allow the participant to ascend spiritually, and in some instances, induce a trance in which God or other spiritual beings may be realized. Very much as in Hermetic Qabalah and orthodox Kabbalah, it is believed that prayer can influence both the physical and non-physical worlds. The use of ritualistic signs and names are believed to be archetypes in which the subconscious may take form as the Inner God, or another spiritual being, and the "prayer from the heart" to be that spiritual force speaking through the participant.
In Thelema (which includes both theist as well as atheist practitioners) adherents share a number of practices that are forms of individual prayer, including basic yoga; (asana and pranayama); various forms of ritual magick; rituals of one's own devising (often based upon a syncretism of religions, or Western Esotericism, such as the Lesser Banishing Ritual of the Pentagram and Star Ruby); and performance of Liber Resh vel Helios (aka Liber 200), which consists of four daily adorations to the sun (often consisting of four hand/body positions and recitation of a memorized song, normally spoken, addressing different godforms identified with the sun).

While no dogma within Thelema expresses the purpose behind any individual aspirant who chooses to perform "Resh", note that the practice of "Resh" is not a simple petition toward the sun, nor a form of "worshiping" the celestial body that we call the Sun, but instead uses the positioning of that source of light, which enables life on our planet, as well as using mythological images of that solar force, so that the individual can perform the prayer, possibly furthering a self-identification with the sun, so "that repeated application of the Liber Resh adorations expands the consciousness of the individual by compelling him to take a different perspective, by inducing him to 'look at things from the point of view of the Sun' [...]".

Prayer is often used as a means of faith healing in an attempt to use religious or spiritual means to prevent illness, cure disease, or improve health.

Scientific studies regarding the use of prayer have mostly concentrated on its effect on the healing of sick or injured people. Meta-studies have been performed showing evidence only for no effect or a potentially small effect. For instance, a 2006 meta analysis on 14 studies concluded that there is "no discernable effect" while a 2007 systemic review of studies on intercessory prayer reported inconclusive results, noting that seven of 17 studies had "small, but significant, effect sizes" but the review noted that the most methodologically rigorous studies failed to produce significant findings. Some studies have indicated increased medical complications in groups receiving prayer over those without.

The efficacy of petition in prayer for physical healing to a deity has been evaluated in numerous other studies, with contradictory results. There has been some criticism of the way the studies were conducted.

Some attempt to heal by prayer, mental practices, spiritual insights, or other techniques, claiming they can summon divine or supernatural intervention on behalf of the ill. Others advocate that ill people may achieve healing through prayer performed by themselves. According to the varied beliefs of those who practice it, faith healing may be said to afford gradual relief from pain or sickness or to bring about a sudden "miracle cure", and it may be used in place of, or in tandem with, conventional medical techniques for alleviating or curing diseases. Faith healing has been criticized on the grounds that those who use it may delay seeking potentially curative conventional medical care. This is particularly problematic when parents use faith healing techniques on children.

In 1872, Francis Galton conducted a famous statistical experiment to determine whether prayer had a physical effect on the external environment. Galton hypothesized that if prayer was effective, members of the British Royal family would live longer, given that thousands prayed for their wellbeing every Sunday. He therefore compared longevity in the British Royal family with that of the general population, and found no difference. While the experiment was probably intended to satirize, and suffered from a number of confounders, it set the precedent for a number of different studies, the results of which are contradictory.

Two studies claimed that patients who are being prayed for recover more quickly or more frequently although critics have claimed that the methodology of such studies are flawed, and the perceived effect disappears when controls are tightened. One such study, with a double-blind design and about 500 subjects per group, was published in 1988; it suggested that intercessory prayer by born again Christians had a statistically significant positive effect on a coronary care unit population. Critics contend that there were severe methodological problems with this study. Another such study was reported by Harris et al. Critics also claim that the 1988 study was not fully double-blinded, and that in the Harris study, patients actually had a longer hospital stay in the prayer group, if one discounts the patients in both groups who left before prayers began, although the Harris study did demonstrate the prayed for patients on average received lower course scores (indicating better recovery).

One of the largest randomized, blind clinical trials was a remote "retroactive" intercessory prayer study conducted in Israel by Leibovici. This study used 3393 patient records from 1990–96, and blindly assigned some of these to an intercessory prayer group. The prayer group had shorter hospital stays and duration of fever.

Several studies of prayer effectiveness have yielded null results. A 2001 double-blind study of the Mayo Clinic found no significant difference in the recovery rates between people who were (unbeknownst to them) assigned to a group that prayed for them and those who were not. Similarly, the MANTRA study conducted by Duke University found no differences in outcome of cardiac procedures as a result of prayer. In another similar study published in the "American Heart Journal" in 2006, Christian intercessory prayer when reading a scripted prayer was found to have no effect on the recovery of heart surgery patients; however, the study found patients who had knowledge of receiving prayer had slightly higher instances of complications than those who did not know if they were being prayed for or those who did not receive prayer. Another 2006 study suggested that prayer actually had a significant negative effect on the recovery of cardiac bypass patients, resulting in more frequent deaths and slower recovery time for those patient who received prayers.

Many believe that prayer can aid in recovery, not due to divine influence but due to psychological and physical benefits. It has also been suggested that if a person knows that he or she is being prayed for it can be uplifting and increase morale, thus aiding recovery. (See Subject-expectancy effect.) Many studies have suggested that prayer can reduce physical stress, regardless of the god or gods a person prays to, and this may be true for many worldly reasons. According to a study by Centra State Hospital, "the psychological benefits of prayer may help reduce stress and anxiety, promote a more positive outlook, and strengthen the will to live." Other practices such as yoga, t'ai chi, and meditation may also have a positive impact on physical and psychological health.

Others feel that the concept of conducting prayer experiments reflects a misunderstanding of the purpose of prayer. The previously mentioned study published in the "American Heart Journal" indicated that some of the intercessors who took part in it complained about the scripted nature of the prayers that were imposed to them, saying that this is not the way they usually conduct prayer: 

One scientific movement attempts to track the physical effects of prayer through neuroscience. Leaders in this movement include Andrew Newberg, an Associate Professor at the University of Pennsylvania. In Newberg's brain scans, monks, priests, nuns, sisters and gurus alike have exceptionally focused attention and compassion sites. This is a result of the frontal lobe of the brain’s engagement (Newberg, 2009). Newburg believes that anybody can connect to the supernatural with practice. Those without religious affiliations benefit from the connection to the metaphysical as well. Newberg also states that further evidence towards humans' need for metaphysical relationships is that as science had increased spirituality has not decreased. Newburg believes that at the end of the 18th century, when the scientific method began to consume the human mind, religion could have vanished. However, two hundred years later, the perception of spirituality, in many instances, appears to be gaining in strength (2009). Newberg's research also provides the connection between prayer and meditation and health. By understanding how the brain works during religious experiences and practices Newberg's research shows that the brain changes during these practices allowing an understanding of how religion affects psychological and physical health (2009). For example, brain activity during meditation indicates that people who frequently practice prayer or meditation experience lower blood-pressure, lower heart rates, decreased anxiety, and decreased depression.

One study found that prayer combined with IVF treatment nearly doubled the number of women who were successfully pregnant, and more than doubled the number of successful implantations.

Some modalities of alternative medicine employ prayer. A survey released in May 2004 by the National Center for Complementary and Alternative Medicine, part of the National Institutes of Health in the United States, found that in 2002, 43% of Americans pray for their own health, 24% pray for others' health, and 10% participate in a prayer group for their own health.


</doc>
<doc id="25044" url="https://en.wikipedia.org/wiki?curid=25044" title="Punjabi language">
Punjabi language

Punjabi (; , , ) is an Indo-Aryan language with more than 125 million native speakers in the Indian subcontinent and around the world. It is the native language of the Punjabi people, an ethnolinguistic group of the cultural region of Punjab, which encompasses northwest India and eastern Pakistan.

Punjabi is the most widely spoken language in Pakistan, the 11th most widely spoken language in India and the third most-spoken native language in the Indian subcontinent. It is also the fifth most-spoken native language in Canada after English, French, Mandarin and Cantonese.

Punjabi is unusual among Indo-European languages in its use of lexical tone; see below for examples. Gurmukhi is the official script for the language in Punjab, India while Shahmukhi is used in Punjab, Pakistan; other national and local scripts have also been in use historically and currently, as discussed in .

The word "Punjabi" (sometimes spelled "Panjabi") has been derived from the word Panj-āb, Persian for "Five Waters", referring to the five major eastern tributaries of the Indus River. The name of the region was introduced by the Turko-Persian conquerors of South Asia and was a translation of the Sanskrit name for the region, "Panchanada", which means "Land of the Five Rivers". "Panj" is cognate with Sanskrit ("") and Greek ("pénte") and Lithuanian "Penki" - "five", and "āb" is cognate with Sanskrit ("áp") and with the of . The historical Punjab region, now divided between India and Pakistan, is defined physiographically by the Indus River and these five tributaries. One of the five, the Beas River, is a tributary of another, the Sutlej.

Punjabi developed from Sanskrit through Prakrit languages and later (Sanskrit: ; corruption or corrupted speech) From 600 BC Sanskrit gave birth to many regional languages in different parts of India. All these languages are called Prakrit (Sanskrit: ) collectively. Shauraseni Prakrit was one of these Prakrit languages, which was spoken in north and north-western India and Punjabi and western dialects of Hindi developed from this Prakrit. Later in northern India Shauraseni Prakrit gave rise to Shauraseni Aparbhsha, a descendant of Prakrit. Punjabi emerged as an Apabhramsha, a degenerated form of Prakrit, in the 7th century A.D. and became stable by the 10th century. By the 10th century, many Nath poets were associated with earlier Punjabi works. 

Arabic and Persian influence in the historical Punjab region began with the late first millennium Muslim conquests on the Indian subcontinent. The Persian language was introduced in the subcontinent a few centuries later by various Turko-Persian dynasties. Many Persian and Arabic words were incorporated in Punjabi. It is noteworthy that the Hindustani language is divided into Hindi, with more Sanskritisation, and Urdu, with more Persianisation, but in Punjabi both Sanskrit and Persian words are used with a liberal approach to language. Later, it was lexically influenced by Portuguese and English, though these influences have been minor in comparison to Persian and Arabic.



Punjabi is the most widely spoken language in Pakistan, the eleventh -most widely spoken in India and spoken Punjabi diaspora in various countries.

Punjabi is the most widely spoken language in Pakistan, being the native language of % of its population. It is the provincial language in the Punjab Province.

Beginning with the 1981 census, speakers of Saraiki and Hindko were no longer included in the total numbers for Punjabi, which could explain the apparent decrease.

Punjabi is spoken as a native language, second language, or third language by about 30 million people in India. Punjabi is the official language of the Indian state of Punjab. It is additional official in Haryana and Delhi. Some of its major urban centres in northern India are Ambala, Ludhiana, Patiala, Amritsar, Chandigarh, Jalandhar, Bathinda and Delhi.

Punjabi is also spoken as a minority language in several other countries where Punjabi people have emigrated in large numbers, such as the United States, Australia, the United Kingdom, and Canada, where it is the fourth-most-commonly used language.
There were 76 million Punjabi speakers in Pakistan in 2008, 33 million in India in 2011, 368,000 in Canada in 2006, and smaller numbers in other countries.

The Majhi dialect spoken around Amritsar and Lahore is Punjabi's prestige dialect. Majhi is spoken in the heart of Punjab in the region of Majha, which spans Lahore, Amritsar, Gurdaspur, Kasur, Tarn Taran, Faisalabad, Nankana Sahib, Pathankot, Okara, Pakpattan, Sahiwal, Narowal, Sheikhupura, Sialkot, Chiniot, Gujranwala and Gujrat districts. Punjabi official language based on the Majhi.

Majhi retains the nasal consonants and , which have been superseded elsewhere by non-nasals and respectively. 

Shahpuri dialect (also known as Sargodha dialect) is mostly spoken in Pakistani Punjab. Its name is derived from former Shahpur District (now Shahpur Tehsil, being part of Sargodha District). It is spoken throughout a widespread area, spoken in Sargodha and Khushab Districts and also spoken in neighbouring Mianwali and Bhakkar Districts. It is mainly spoken on western end of Indus River to Chenab river crossing Jhelum river.

Malwai is spoken in the southern part of Indian Punjab and also in Bahawalnagar and Vehari districts of Pakistan. Main areas are faridkot, Barnala, Ludhiana, Patiala, Ambala, Bathinda, Mansa, Sangrur, Malerkotla, Fazilka, Ferozepur, Moga. Malwa is the southern and central part of present-day Indian Punjab. It also includes the Punjabi speaking northern areas of Haryana, viz. Ambala, |Hissar], Narnaul etc. Not to be confused with the Malvi language, which shares its name.

Doabi is spoken in both the Indian Punjab as well as parts of Pakistan Punjab owing to post-1947 migration of Muslim populace from East Punjab. The word "Do Aabi" means "the land between two rivers" and this dialect was historically spoken between the rivers of the Beas and the Sutlej in the region called Doaba. Regions it is presently spoken in include the Jalandhar, Hoshiarpur and Kapurthala districts in Indian Punjab, specifically in the areas known as the Dona and Manjki, as well as the Toba Tek Singh and Faisalabad districts in Pakistan Punjab where the dialect is known as Faisalabadi Punjabi.

Puadh is a region of Punjab and parts of Haryana between the Satluj and Ghaggar rivers. The part lying south, south-east and east of Rupnagar adjacent to Ambala District (Haryana) is Puadhi. The Puadh extends from that part of the Rupnagar District which lies near Satluj to beyond the Ghaggar river in the east up to Kala Amb, which is at the border of the states of Himachal pradesh and Haryana. Parts of Fatehgarh Sahib district, and parts of Patiala districts like Rajpura are also part of Puadh. The Puadhi dialect is spoken over a large area in present Punjab as well as Haryana. In Punjab, Kharar, Kurali, Ropar, Nurpurbedi, Morinda, Pail, Rajpura and Samrala are areas where Puadhi is spoken and the dialect area also includes Pinjore, Kalka, Ismailabad, Pehowa to Bangar area in Fatehabad district.

Jhangochi spoken in Khanewal and Jhang districts is actually subdialect of Jatki/Jangli. 'Jhangochi' word has limitations as it doesn't represent whole bar region of Punjab.

Jatki or Jangli is a dialect of native tribes of areas whose names are often suffixed with 'Bar' derived from jungle bar before irrigation system arrived in the start of the 20th century, for example, Sandal Bar, Kirana Bar, Neeli Bar, Ganji Bar. Native people called their dialect as Jatki instead of Jangli. Jatki dialect is mostly spoken by Indigenous peoples of Faisalabad, Jhang, Toba Tek Singh, Chiniot, Nankana Sahib, Hafizabad, Mandi Bahauddin, Sargodha, Sahiwal, Okara, Pakpattan, Bahawalnagar, Vehari and Khanewal districts of Pakistani Punjab. It is also spoken in few areas of Sheikhupura, Muzaffargarh, Lodhran' Bahawalpur districts and Fazilka district of Indian Punjab.

West of Chenaab river in Jhang district of Pakistani Punjab the dialect of Jhangochi merges with Thalochi and resultant dialect is Chenavari. Name is derived from Chenaab river.

While a vowel length distinction between short and long vowels exists, reflected in modern Gurmukhi orthographical conventions, it is secondary to the vowel quality contrast between centralised vowels and peripheral vowels in terms of phonetic significance.
The peripheral vowels have nasal analogues.

The three retroflex consonants do not occur initially, and the nasals occur only as allophones of in clusters with velars and palatals. The well-established phoneme may be realised allophonically as the voiceless retroflex fricative in learned clusters with retroflexes. The phonemic status of the fricatives varies with familiarity with Hindustani norms, with the pairs , , , and systematically distinguished in educated speech. The retroflex lateral is most commonly analysed as an approximant as opposed to a flap.

Punjabi is a tonal language and in many words there is a choice of up to three tones, high-falling, low-rising, and level (neutral):

Level tone is found in about 75% of words and is described by some as absence of tone. There are also some words which are said to have rising tone in the first syllable and falling in the second. (Some writers describe this as a fourth tone.) However, a recent acoustic study of six Punjabi speakers in America found no evidence of a separate falling tone following a medial consonant.

It is considered that these tones arose when voiced aspirated consonants () lost their aspiration. At the beginning of a word they became voiceless unaspirated consonants () followed by a high-falling tone; medially or finally they became voiced unaspirated consonants (), preceded by a low-rising tone. (The development of a high-falling tone apparently did not take place in every word, but only in those which historically had a long vowel.)

The presence of an [h] (although the [h] is now silent or very weakly pronounced except word-initially) word-finally (and sometimes medially) also often causes a rising tone before it, for example "" "tea".

The Gurmukhi script which was developed in the 16th century has separate letters for voiced aspirated sounds, so it is thought that the change in pronunciation of the consonants and development of tones may have taken place since that time.

Some other languages in Pakistan have also been found to have tonal distinctions, including Burushaski, Gujari, Hindko, Kalami, Shina, and Torwali.

Punjabi has a canonical word order of SOV (subject–object–verb). It has postpositions rather than prepositions.

Punjabi distinguishes two genders, two numbers, and five cases of direct, oblique, vocative, ablative, and locative/instrumental. The ablative occurs only in the singular, in free variation with oblique case plus ablative postposition, and the locative/instrumental is usually confined to set adverbial expressions.

Adjectives, when declinable, are marked for the gender, number, and case of the nouns they qualify. There is also a T-V distinction.
Upon the inflectional case is built a system of particles known as postpositions, which parallel English's prepositions. It is their use with a noun or verb that is what necessitates the noun or verb taking the oblique case, and it is with them that the locus of grammatical function or "case-marking" then lies. 
The Punjabi verbal system is largely structured around a combination of aspect and tense/mood. Like the nominal system, the Punjabi verb takes a single inflectional suffix, and is often followed by successive layers of elements like auxiliary verbs and postpositions to the right of the lexical base.

The grammar of the Punjabi language concerns the word order, case marking, verb conjugation, and other morphological and syntactic structures of the Punjabi language.

The Punjabi language is written in multiple scripts (a phenomenon known as synchronic digraphia). Each of the major scripts currently in use is typically associated with a particular religious group, although the association is not absolute or exclusive.
In India, Punjabi Sikhs use Gurmukhi, a script of the Brahmic family, which has official status in the state of Punjab. In Pakistan, Punjabi Muslims use Shahmukhi, a variant of the Perso-Arabic script and closely related to the Urdu alphabet. The Punjabi Hindus in India had a preference for Devanagari, another Brahmic script also used for Hindi, and in the first decades since independence raised objections to the uniform adoption of Gurmukhi in the state of Punjab, but most have now switched to Gurmukhi and so the use of Devanagari is rare.

Historically, various local Brahmic scripts including Laṇḍā and its descendants were also in use.

The Punjabi Braille is used by the visually impaired.

This sample text was taken from the Punjabi Wikipedia article on Lahore.

Gurmukhi: ਲਹੌਰ ਪਾਕਿਸਤਾਨੀ ਪੰਜਾਬ ਦੀ ਰਾਜਧਾਨੀ ਹੈ । ਲੋਕ ਗਿਣਤੀ ਦੇ ਨਾਲ ਕਰਾਚੀ ਤੋਂ ਬਾਅਦ ਲਹੌਰ ਦੂਜਾ ਸਭ ਤੋਂ ਵੱਡਾ ਸ਼ਹਿਰ ਹੈ । ਲਹੌਰ ਪਾਕਿਸਤਾਨ ਦਾ ਸਿਆਸੀ, ਰਹਤਲੀ ਅਤੇ ਪੜ੍ਹਾਈ ਦਾ ਗੜ੍ਹ ਹੈ ਅਤੇ ਇਸੇ ਲਈ ਇਹਨੂੰ ਪਾਕਿਸਤਾਨ ਦਾ ਦਿਲ ਵੀ ਕਿਹਾ ਜਾਂਦਾ ਹੈ । ਲਹੌਰ ਰਾਵੀ ਦਰਿਆ ਦੇ ਕੰਢੇ 'ਤੇ ਵਸਦਾ ਹੈ । ਇਸਦੀ ਲੋਕ ਗਿਣਤੀ ਇੱਕ ਕਰੋੜ ਦੇ ਨੇੜੇ ਹੈ |

Shahmukhi:

Transliteration: lahaur pākistānī panjāb dī rājtā̀ni/dārul hakūmat ài. lok giṇtī de nāḷ karācī tõ bāad lahaur dūjā sáb tõ vaḍḍā šáir ài. lahaur pākistān dā siāsī, rátalī ate paṛā̀ī dā gáṛ ài te ise laī ínū̃ pākistān dā dil vī kihā jāndā ài. lahaur rāvī dariā de káṇḍè te vasdā ài. isdī lok giṇtī ikk karoṛ de neṛe ài.

IPA: 

Translation: Lahore is the capital city of Pakistani Punjab. After Karachi, Lahore is the second largest city. Lahore is Pakistan's political, cultural, and educational hub, and so it is also said to be the heart of Pakistan. Lahore lies on the bank of the Ravi River. Its population is close to ten million people.

The "Janamsakhis", stories on the life and legend of Guru Nanak (1469–1539), are early examples of Punjabi prose literature.


The Victorian novel, Elizabethan drama, free verse and Modernism entered Punjabi literature through the introduction of British education during the Raj. Nanak Singh (1897–1971), Vir Singh, Ishwar Nanda, Amrita Pritam (1919–2005), Puran Singh (1881–1931), Dhani Ram Chatrik (1876–1957), Diwan Singh (1897–1944) and Ustad Daman (1911–1984), Mohan Singh (1905–78) and Shareef Kunjahi are some legendary Punjabi writers of this period.
After independence of Pakistan and India Najm Hossein Syed, Fakhar Zaman and Afzal Ahsan Randhawa, Shafqat Tanvir Mirza, Ahmad Salim, and Najm Hosain Syed, Munir Niazi, Pir Hadi Abdul Mannan enriched Punjabi literature in Pakistan, whereas Amrita Pritam (1919–2005), Jaswant Singh Rahi (1930–1996), Shiv Kumar Batalvi (1936–1973), Surjit Patar (1944–) and Pash (1950–1988) are some of the more prominent poets and writers from India.

Despite Punjabi's rich literary history, it was not until 1947 that it would be recognised as an official language. Previous governments in the area of the Punjab had favoured Persian, Hindustani, or even earlier standardised versions of local registers as the language of the court or government. After the annexation of the Sikh Empire by the British East India Company following the Second Anglo-Sikh War in 1849, the British policy of establishing a uniform language for administration was expanded into the Punjab. The British Empire employed Hindi and Urdu in its administration of North-Central and North-West India, while in the North-East of India, Bengali was used as the language of administration. Despite its lack of official sanction, the Punjabi language continued to flourish as an instrument of cultural production, with rich literary traditions continuing until modern times. The Sikh religion, with its Gurmukhi script, played a special role in standardising and providing education in the language via Gurdwaras, while writers of all religions continued to produce poetry, prose, and literature in the language.

In India, Punjabi is one of the 22 scheduled languages of India. It is the first official language of the Indian State of Punjab. Punjabi also has second language official status in Delhi along with Urdu, and in Haryana. 
In Pakistan, no regional ethnic language has been granted official status at the national level, and as such Punjabi is not an official language at the national level, even though it is the most spoken language in Pakistan after Urdu, the national language of Pakistan. It is, however, the official provincial language of Punjab, Pakistan, the second largest and the most populous province of Pakistan as well as in Islamabad Capital Territory. The only two official national languages in Pakistan are Urdu and English, which are considered the lingua francas of Pakistan.

When Pakistan was created in 1947, although Punjabi was the majority language in West Pakistan and Bengali the majority in East Pakistan and Pakistan as whole, English and Urdu were chosen as the national languages. The selection of Urdu was due to its association with South Asian Muslim nationalism and because the leaders of the new nation wanted a unifying national language instead of promoting one ethnic group's language over another. Broadcasting in Punjabi language by Pakistan Broadcasting Corporation decreased on TV and radio after 1947. Article 251 of the Constitution of Pakistan declares that these two languages would be the only official languages at the national level, while provincial governments would be allowed to make provisions for the use of other languages. However, in the 1950s the constitution was amended to include the Bengali language. Eventually, Punjabi was granted status as a provincial language in Punjab Province, while the Sindhi language was given official status in 1972 after 1972 Language violence in Sindh.

Despite gaining official recognition at the provincial level, Punjabi is not a language of instruction for primary or secondary school students in Punjab Province (unlike Sindhi and Pashto in other provinces). Pupils in secondary schools can choose the language as an elective, while Punjabi instruction or study remains rare in higher education. One notable example is the teaching of Punjabi language and literature by the University of the Punjab in Lahore which began in 1970 with the establishment of its Punjabi Department.

In the cultural sphere, there are many books, plays, and songs being written or produced in the Punjabi-language in Pakistan. Until the 1970s, there were a large number of Punjabi-language films being produced by the Lollywood film industry, however since then Urdu has become a much more dominant language in film production. Additionally, television channels in Punjab Province (centred on the Lahore area) are broadcast in Urdu. The preeminence of Urdu in both broadcasting and the Lollywood film industry is seen by critics as being detrimental to the health of the language.

The use of Urdu and English as the near exclusive languages of broadcasting, the public sector, and formal education have led some to fear that Punjabi in Pakistan is being relegated to a low-status language and that it is being denied an environment where it can flourish. Several prominent educational leaders, researchers, and social commentators have echoed the opinion that the intentional promotion of Urdu and the continued denial of any official sanction or recognition of the Punjabi language amounts to a process of "Urdu-isation" that is detrimental to the health of the Punjabi language In August 2015, the Pakistan Academy of Letters, International Writer’s Council (IWC) and World Punjabi Congress (WPC) organised the "Khawaja Farid Conference" and demanded that a Punjabi-language university should be established in Lahore and that Punjabi language should be declared as the medium of instruction at the primary level. In September 2015, a case was filed in Supreme Court of Pakistan against Government of Punjab, Pakistan as it did not take any step to implement the Punjabi language in the province. Additionally, several thousand Punjabis gather in Lahore every year on International Mother Language Day. Thinktanks, political organisations, cultural projects, and individuals also demand authorities at the national and provincial level to promote the use of the language in the public and official spheres.

At the federal level, Punjabi has official status via the Eighth Schedule to the Indian Constitution, earned after the Punjabi Suba movement of the 1950s. At the state level, Punjabi is the sole official language of the state of Punjab, while it has secondary official status in the states of Haryana and Delhi.

Both federal and state laws specify the use of Punjabi in the field of education. The state of Punjab uses the Three Language Formula, and Punjabi is required to be either the medium of instruction, or one of the three languages learnt in all schools in Punjab. Punjabi is also a compulsory language in Haryana, and other states with a significant Punjabi speaking minority are required to offer Punjabi medium education.

There are vibrant Punjabi language movie and news industries in India, however Punjabi serials have had a much smaller presence within the last few decades in television due to market forces. Despite Punjabi having far greater official recognition in India, "where the Punjabi language is officially admitted in all necessary social functions, while in Pakistan it is used only in a few radio and TV programs," attitudes of the English-educated elite towards the language are ambivalent as they are in neighbouring Pakistan. There are also claims of state apathy towards the language in non-Punjabi majority areas like Haryana and Delhi.<ref name="http://www.hindustantimes.com/ 2015"></ref>


The Punjabi Sahit academy, Ludhiana, established in 1954 is supported by the Punjab state government and works exclusively for promotion of the Punjabi language, as does the Punjabi academy in Delhi. The Jammu and Kashmir academy of art, culture and literature in Jammu and Kashmir UT, India works for Punjabi and other regional languages like Urdu, Dogri, Gojri etc. Institutions in neighbouring states as well as in Lahore, Pakistan also advocate for the language.







</doc>
<doc id="25054" url="https://en.wikipedia.org/wiki?curid=25054" title="Power associativity">
Power associativity

In mathematics, specificaly in abstract algebra, power associativity is a property of a binary operation that is a weak form of associativity.

An algebra (or more generally a magma) is said to be power-associative if the subalgebra generated by any element is associative. Concretely, this means that if an element formula_1 is performed an operation formula_2 by itself several times, it doesn't matter in which order the operations are carried out, so for instance formula_3.

Every associative algebra is power-associative, but so are all other alternative algebras (like the octonions, which are non-associative) and even some non-alternative algebras like the sedenions and Okubo algebras. Any algebra whose elements are idempotent is also power-associative.

Exponentiation to the power of any positive integer can be defined consistently whenever multiplication is power-associative. For example, there is no need to distinguish whether "x" should be defined as ("xx")"x" or as "x"("xx"), since these are equal. Exponentiation to the power of zero can also be defined if the operation has an identity element, so the existence of identity elements is useful in power-associative contexts.

Over a field of characteristic 0, an algebra is power-associative if and only if it satisfies formula_4 and formula_5, where formula_6 is the associator (Albert 1948).
Over a field of prime characteristic formula_7 there is no finite set of identities that characterizes power-associativity, but there are infinite independent sets, as described by Gainov (1970):


A substitution law holds for real power-associative algebras with unit, which basically asserts that multiplication of polynomials works as expected. For "f" a real polynomial in "x", and for any "a" in such an algebra define "f"("a") to be the element of the algebra resulting from the obvious substitution of "a" into "f". Then for any two such polynomials "f" and "g", we have that .




</doc>
<doc id="25055" url="https://en.wikipedia.org/wiki?curid=25055" title="Pierre de Coubertin">
Pierre de Coubertin

Charles Pierre de Frédy, Baron de Coubertin (; born Pierre de Frédy; 1 January 1863 – 2 September 1937, also known as Pierre de Coubertin and Baron de Coubertin) was a French educator and historian, founder of the International Olympic Committee, and its second President. He is known as the father of the modern Olympic Games.

Born into a French aristocratic family, he became an academic and studied a broad range of topics, most notably education and history. He graduated with a degree in law and public affairs Paris Institute of Political Studies (Sciences Po). It was at Sciences Po that he came up with the idea of the Summer Olympic Games.

The Pierre de Coubertin medal (also known as the Coubertin medal or the True Spirit of Sportsmanship medal) is an award given by the International Olympic Committee to athletes who demonstrate the spirit of sportsmanship in the Olympic Games.

Pierre de Frédy was born in Paris on 1 January 1863, into an aristocratic family. He was the fourth child of Baron Charles Louis de Frédy, Baron de Coubertin and Marie–Marcelle Gigault de Crisenoy. Family tradition held that the Frédy name had first arrived in France in the early 15th century, and the first recorded title of nobility granted to the family was given by Louis XI to an ancestor, also named Pierre de Frédy, in 1477. But other branches of his family tree delved even further into French history, and the annals of both sides of his family included nobles of various stations, military leaders and associates of kings and princes of France.
His father Charles was a staunch royalist and accomplished artist whose paintings were displayed and given prizes at the Parisian salon, at least in those years when he was not absent in protest of the rise to power of Louis Napoleon. His paintings often centred on themes related to the Roman Catholic Church, classicism, and nobility, which reflected those things he thought most important. In a later semi-fictional autobiographical piece called "Le Roman d'un rallié", Coubertin describes his relationship with both his mother and his father as having been somewhat strained during his childhood and adolescence. His memoirs elaborated further, describing as a pivotal moment his disappointment upon meeting Henri, Count of Chambord, whom the elder Coubertin believed to be the rightful king.

Coubertin grew up in a time of profound change in France: France's defeat in the Franco-Prussian War, the Paris Commune, and the establishment of the French Third Republic, and later the Dreyfus affair. But while these events were the setting of his childhood, his school experiences were just as formative. In October 1874, his parents enrolled him in a new Jesuit school called "Externat de la rue de Vienne", which was still under construction for his first five years there. While many of the school's attendees were day students, Coubertin boarded at the school under the supervision of a Jesuit priest, which his parents hoped would instill him with a strong moral and religious education. There, he was among the top three students in his class, and was an officer of the school's elite academy made up of its best and brightest. This suggests that despite his rebelliousness at home, Coubertin adapted well to the strict rigors of a Jesuit education.

As an aristocrat, Coubertin had a number of career paths from which to choose, including potentially prominent roles in the military or politics. But he chose instead to pursue a career as an intellectual, studying and later writing on a broad range of topics, including education, history, literature and sociology.

The subject which he seems to have been most deeply interested in was education, and his study focused in particular on physical education and the role of sport in schooling. In 1883, he visited England for the first time, and studied the program of physical education instituted by Thomas Arnold at the Rugby School. Coubertin credited these methods with leading to the expansion of British power during the 19th century and advocated their use in French institutions. The inclusion of physical education in the curriculum of French schools would become an ongoing pursuit and passion of Coubertin's.

Coubertin is thought to have exaggerated the importance of sport to Thomas Arnold, whom he viewed as "one of the founders of athletic chivalry". The character-reforming influence of sport with which Coubertin was so impressed is more likely to have originated in the novel "Tom Brown's School Days" rather than exclusively in the ideas of Arnold himself. Nonetheless, Coubertin was an enthusiast in need of a cause and he found it in England and in Thomas Arnold. "Thomas Arnold, the leader and classic model of English educators," wrote Coubertin, "gave the precise formula for the role of athletics in education. The cause was quickly won. Playing fields sprang up all over England".

Intrigued by what he had read about English public schools, in 1883, at the age of twenty, Frédy went to Rugby and to other English schools to see for himself. He described the results in a book, "L'Education en Angleterre", which was published in Paris in 1888. This hero of his book is Thomas Arnold, and on his second visit in 1886, Coubertin reflected on Arnold's influence in the chapel at Rugby School.

What Coubertin saw on the playing fields of Rugby and the other English schools he visited was how "organised sport can create moral and social strength". Not only did organised games help to set the mind and body in equilibrium, it also prevented the time being wasted in other ways. First developed by the ancient Greeks, it was an approach to education that he felt the rest of the world had forgotten and to whose revival he was to dedicate the rest of his life.

As a historian and a thinker on education, Coubertin romanticised ancient Greece. Thus, when he began to develop his theory of physical education, he naturally looked to the example set by the Athenian idea of the gymnasium, a training facility that simultaneously encouraged physical and intellectual development. He saw in these gymnasia what he called a triple unity between old and young, between disciplines, and between different types of people, meaning between those whose work was theoretical and those whose work was practical. Coubertin advocated for these concepts, this triple unity, to be incorporated into schools.

But while Coubertin was certainly a romantic, and while his idealised vision of ancient Greece would lead him later to the idea of reviving the Olympic Games, his advocacy for physical education was based on practical concerns as well. He believed that men who received physical education would be better prepared to fight in wars, and better able to win conflicts like the Franco-Prussian War, in which France had been humiliated. He also saw sport as democratic, in that sports competition crossed class lines, although it did so without causing a mingling of classes, which he did not support.

Unfortunately for Coubertin, his efforts to incorporate more physical education into French schools failed. The failure of this endeavour, however, was closely followed by the development of a new idea, the revival of the ancient Olympic Games, the creation of a festival of international athleticism.

He was the referee of the first ever French championship rugby union final on 20 March 1892, between Racing Club de France and Stade Français.

Coubertin is the instigator of the modern Olympic movement, a man whose vision and political skill led to the revival of the Olympic Games which had been practised in antiquity. Coubertin idealized the Olympic Games as the ultimate ancient athletic competition.

Thomas Arnold, the Head Master of Rugby School, was an important influence on Coubertin's thoughts about education, but his meetings with William Penny Brookes also influenced his thinking about athletic competition to some extent. A trained physician, Brookes believed that the best way to prevent illness was through physical exercise. In 1850, he had initiated a local athletic competition that he referred to as "Meetings of the Olympian Class" at the Gaskell recreation ground at Much Wenlock, Shropshire. Along with the Liverpool Athletic Club, who began holding their own Olympic Festival in the 1860s, Brookes created a National Olympian Association which aimed to encourage such local competition in cities across Britain. These efforts were largely ignored by the British sporting establishment. Brookes also maintained communication with the government and sporting advocates in Greece, seeking a revival of the Olympic Games internationally under the auspices of the Greek government. There, the philanthropist cousins Evangelos and Konstantinos Zappas had used their wealth to fund Olympics within Greece, and paid for the restoration of the Panathinaiko Stadium that was later used during the 1896 Summer Olympics. The efforts of Brookes to encourage the internationalization of these games came to naught. However, Dr. Brookes did organize a national Olympic Games in London, at Crystal Palace, in 1866 and this was the first Olympics to resemble an Olympic Games to be held outside of Greece. But while others had created Olympic contests within their countries, and broached the idea of international competition, it was Coubertin whose work would lead to the establishment of the International Olympic Committee and the organisation of the first modern Olympic Games.

In 1888, Coubertin founded the Comité pour la Propagation des Exercises Physiques more well known as the Comité Jules Simon. Coubertin's earliest reference to the modern notion of Olympic Games criticizes the idea. The idea for reviving the Olympic Games as an international competition came to Coubertin in 1889, apparently independently of Brookes, and he spent the following five years organizing an international meeting of athletes and sports enthusiasts that might make it happen. Dr Brookes had organised a national Olympic Games that was held at Crystal Palace in London in 1866. In response to a newspaper appeal, Brookes wrote to Coubertin in 1890, and the two began an exchange of letters on education and sport. Although he was too old to attend the 1894 Congress, Brookes would continue to support Coubertin's efforts, most importantly by using his connections with the Greek government to seek its support in the endeavour. While Brookes' contribution to the revival of the Olympic Games was recognised in Britain at the time, Coubertin in his later writings largely neglected to mention the role the Englishman played in their development. He did mention the roles of Evangelis Zappas and his cousin Konstantinos Zappas, but drew a distinction between their founding of athletic Olympics and his own role in the creation of an international contest. However, Coubertin together with A. Mercatis, a close friend of Konstantinos, encouraged the Greek government to utilise part of Konstantinos' legacy to fund the 1896 Athens Olympic Games separately and in addition to the legacy of Evangelis Zappas that Konstantinos had been executor of. Moreover, George Averoff was invited by the Greek government to fund the second refurbishment of the Panathinaiko Stadium that had already been fully funded by Evangelis Zappas forty years earlier.

Coubertin's advocacy for the Games centred on a number of ideals about sport. He believed that the early ancient Olympics encouraged competition among amateur rather than professional athletes, and saw value in that. The ancient practice of a sacred truce in association with the Games might have modern implications, giving the Olympics a role in promoting peace. This role was reinforced in Coubertin's mind by the tendency of athletic competition to promote understanding across cultures, thereby lessening the dangers of war. In addition, he saw the Games as important in advocating his philosophical ideal for athletic competition: that the competition itself, the struggle to overcome one's opponent, was more important than winning. Coubertin expressed this ideal thus:
"L'important dans la vie ce n'est point le triomphe, mais le combat, l'essentiel ce n'est pas d'avoir vaincu mais de s'être bien battu."

"The important thing in life is not the triumph but the struggle, the essential thing is not to have conquered but to have fought well."
As Coubertin prepared for his Congress, he continued to develop a philosophy of the Olympic Games. While he certainly intended the Games to be a forum for competition between amateur athletes, his conception of amateurism was complex. By 1894, the year the Congress was held, he publicly criticised the type of amateur competition embodied in English rowing contests, arguing that its specific exclusion of working-class athletes was wrong. While he believed that athletes should not be paid to be such, he did think that compensation was in order for the time when athletes were competing and would otherwise have been earning money. Following the establishment of a definition for an amateur athlete at the 1894 Congress, he would continue to argue that this definition should be amended as necessary, and as late as 1909 would argue that the Olympic movement should develop its definition of amateurism gradually.

Along with the development of an Olympic philosophy, Coubertin invested time in the creation and development of a national association to coordinate athletics in France, the Union des Sociétés Françaises de Sports Athlétiques (USFSA). In 1889, French athletics associations had grouped together for the first time and Coubertin founded a monthly magazine "La Revue Athletique", the first French periodical devoted exclusively to athletics and modelled on "The Athlete", an English journal established around 1862. Formed by seven sporting societies with approximately 800 members, by 1892 the association had expanded to 62 societies with 7,000 members.

That November, at the annual meeting of the USFSA, Coubertin first publicly suggested the idea of reviving the Olympics. His speech met general applause, but little commitment to the Olympic ideal he was advocating for, perhaps because sporting associations and their members tended to focus on their own area of expertise and had little identity as sportspeople in a general sense. This disappointing result was prelude to a number of challenges he would face in organising his international conference. In order to develop support for the conference, he began to play down its role in reviving Olympic Games and instead promoted it as a conference on amateurism in sport which, he thought, was slowly being eroded by betting and sponsorships. This led to later suggestions that participants were convinced to attend under false pretenses. Little interest was expressed by those he spoke to during trips to the United States in 1893 and London in 1894, and an attempt to involve the Germans angered French gymnasts who did not want the Germans invited at all. Despite these challenges, the USFSA continued its planning for the games, adopting in its first program for the meeting eight articles to address, only one of which had to do with the Olympics. A later program would give the Olympics a much more prominent role in the meeting.

The congress was held on 23 June 1894 at the Sorbonne in Paris. Once there, participants divided the congress into two commissions, one on amateurism and the other on reviving the Olympics. A Greek participant, Demetrius Vikelas, was appointed to head the commission on the Olympics, and would later become the first President of the International Olympic Committee. Along with Coubertin, C. Herbert of Britain's Amateur Athletic Association and W.M. Sloane of the United States helped lead the efforts of the commission. In its report, the commission proposed that Olympic Games be held every four years and that the program for the Games be one of modern rather than ancient sports. They also set the date and location for the first modern Olympic Games, the 1896 Summer Olympics in Athens, Greece, and the second, the 1900 Summer Olympics in Paris. Coubertin had originally opposed the choice of Greece, as he had concerns about the ability of a weakened Greek state to host the competition, but was convinced by Vikelas to support the idea. The commission's proposals were accepted unanimously by the congress, and the modern Olympic movement was officially born. The proposals of the other commission, on amateurism, were more contentious, but this commission also set important precedents for the Olympic Games, specifically the use of heats to narrow participants and the banning of prize money in most contests.

Following the Congress, the institutions created there began to be formalized into the International Olympic Committee (IOC), with Demetrius Vikelas as its first President. The work of the IOC increasingly focused on the planning the 1896 Athens Games, and de Coubertin played a background role as Greek authorities took the lead in logistical organisation of the Games in Greece itself, offering technical advice such as a sketch of a design of a velodrome to be used in cycling competitions. He also took the lead in planning the program of events, although to his disappointment neither polo, football, or boxing were included in 1896. The Greek organizing committee had been informed that four foreign football teams were to participate however not one foreign football team showed up and despite Greek preparations for a football tournament it was cancelled during the Games.

The Greek authorities were frustrated that he could not provide an exact estimate of the number of attendees more than a year in advance. In France, Coubertin's efforts to elicit interest in the Games among athletes and the press met difficulty, largely because the participation of German athletes angered French nationalists who begrudged Germany their victory in the Franco-Prussian War. Germany also threatened not to participate after rumours spread that Coubertin had sworn to keep Germany out, but following a letter to the Kaiser denying the accusation, the German National Olympic Committee decided to attend. Coubertin himself was frustrated by the Greeks, who increasingly ignored him in their planning and who wanted to continue to hold the Games in Athens every four years, against de Coubertin's wishes. The conflict was resolved after he suggested to the King of Greece that he hold pan-Hellenic games in between Olympiads, an idea which the King accepted, although Coubertin would receive some angry correspondence even after the compromise was reached and the King did not mention him at all during the banquet held in honour of foreign athletes during the 1896 Games.

Coubertin took over the IOC presidency when Demetrius Vikelas stepped down after the Olympics in his own country. Despite the initial success, the Olympic Movement faced hard times, as the 1900 (in De Coubertin's own Paris) and 1904 Games were both swallowed by World's Fairs in the same cities, and received little attention. The Paris Games were not organised by Coubertin or the IOC nor were they called Olympics at that time. The St. Louis Games was hardly internationalized.

The 1906 Summer Olympics revived the momentum, and the Olympic Games have come to be regarded as the world's foremost sports competition. Coubertin created the modern pentathlon for the 1912 Olympics, and subsequently stepped down from his IOC presidency after the 1924 Olympics in Paris, which proved much more successful than the first attempt in that city in 1900. He was succeeded as president, in 1925, by Belgian Henri de Baillet-Latour.

Years later Coubertin came out of retirement to lend his prestige to assisting Berlin to land the 1936 games. In exchange, Germany nominated him for the Nobel Peace Prize. The 1935 winner, however, was the anti-Nazi Carl von Ossietzky.

Coubertin won the gold medal for literature at the 1912 Summer Olympics for his poem "Ode to Sport".

In 1911, Pierre de Coubertin founded the inter-religious Scouting organisation aka "Éclaireurs Français" (EF) in France, which later merged to form the Éclaireuses et Éclaireurs de France.

In 1895 Pierre de Coubertin had married Marie Rothan, the daughter of family friends. Their son Jacques (1896–1952) became ill after being in the sun too long when he was a little child. Their daughter Renée (1902–1968) suffered emotional disturbances and never married. Marie and Pierre tried to console themselves with two nephews, but they were killed at the front in World War I. Coubertin died of a heart attack in Geneva, Switzerland on 2 September 1937. Marie died in 1963.

Pierre was the last person to the family name. In the words of his biographer John MacAloon, "The last of his lineage, Pierre de Coubertin was the only member of it whose fame would outlive him."

A number of scholars have criticized Coubertin's legacy. David C. Young believes that Coubertin's assertion that ancient Olympic athletes were amateurs was incorrect. The issue is the subject of scholarly debate. Young and others argue that the athletes of the ancient Games were professional, while opponents led by Pleket argue that the earliest Olympic athletes were in fact amateur, and that the Games only became professionalized after about 480 BC. Coubertin agreed with this latter view, and saw this professionalization as undercutting the morality of the competition.

Further, Young asserts that the effort to limit international competition to amateur athletes, which Coubertin was a part of, was in fact part of efforts to give the upper classes greater control over athletic competition, removing such control from the working classes. Coubertin may have played a role in such a movement, but his defenders argue that he did so unconscious of any class repercussions.

However, it is clear that his romanticized vision of the Olympic Games was fundamentally different from that described in the historical record. For example, Coubertin's idea that participation is more important than winning ("L'important c'est de participer") is at odds with the ideals of the Greeks. The Apostle Paul, writing in the first century to Christians in the city of Corinth where the Isthmian Games were held, reflects this in his writings when he says, "Do you not know that in a race all the runners run, but only one gets the prize? Run in such a way as to get the prize" (1 Corinthians 9:24).

Coubertin's assertion that the Games were the impetus for peace was also an exaggeration; the peace which he spoke of only existed to allow athletes to travel safely to Olympia, and neither prevented the outbreak of wars nor ended ongoing ones.

Scholars have critiqued the idea that athletic competition might lead to greater understanding between cultures and, therefore, to peace. Christopher Hill claims that modern participants in the Olympic movement may defend this particular belief, "in a spirit similar to that in which the Church of England remains attached to the Thirty-Nine Articles of Religion, which a Priest in that Church must sign." In other words, that they may not wholly believe it but hold to it for historical reasons.

Questions have also been raised about the veracity of Coubertin's account of his role in the planning of the 1896 Athens Games. Reportedly, Coubertin played little role in planning, despite entreaties by Vikelas. Young suggests that the story about Coubertin's having sketched the velodrome were untrue, and that he had in fact given an interview in which he suggested he did not want Germans to participate. Coubertin later denied this.

The Olympic motto "Citius, Altius, Fortius" (Faster, Higher, Stronger) was proposed by Coubertin in 1894 and has been official since 1924. The motto was coined by Henri Didon OP, a friend of Coubertin, for a Paris youth gathering of 1891.

The Pierre de Coubertin medal (also known as the Coubertin medal or the True Spirit of Sportsmanship medal) is an award given by the International Olympic Committee to those athletes that demonstrate the spirit of sportsmanship in the Olympic Games. This medal is considered by many athletes and spectators to be the highest award that an Olympic athlete can receive, even greater than a gold medal. The International Olympic Committee considers it as its highest honour.

A minor planet, 2190 Coubertin, was discovered in 1976 by Soviet astronomer Nikolai Stepanovich Chernykh and is named in his honour.

The street where the Olympic Stadium in Montreal is located (which hosted the 1976 Summer Olympic Games) was named after Pierre de Coubertin, giving the stadium the address 4549 Pierre de Coubertin Avenue. It is the only Olympic Stadium in the world that lies on a street named after Coubertin. There are also two schools in Montreal named after Pierre de Coubertin.

He was portrayed by Louis Jourdan in the 1984 NBC miniseries, "".

In 2007, he was inducted into the World Rugby Hall of Fame for his services to the sport of rugby union.

This is a listing of Pierre de Coubertin's books. In addition to these, he wrote numerous articles for journals and magazines:






</doc>
<doc id="25056" url="https://en.wikipedia.org/wiki?curid=25056" title="Polish notation">
Polish notation

Polish notation (PN), also known as normal Polish notation (NPN), Łukasiewicz notation, Warsaw notation, Polish prefix notation or simply prefix notation, is a mathematical notation in which operators "precede" their operands, in contrast to the more common infix notation, in which operators are placed "between" operands, as well as reverse Polish notation (RPN), in which operators "follow" their operands. It does not need any parentheses as long as each operator has a fixed number of operands. The description "Polish" refers to the nationality of logician Jan Łukasiewicz, who invented Polish notation in 1924.

The term "Polish notation" is sometimes taken (as the opposite of "infix notation") to also include reverse Polish notation.

When Polish notation is used as a syntax for mathematical expressions by programming language interpreters, it is readily parsed into abstract syntax trees and can, in fact, define a one-to-one representation for the same. Because of this, Lisp (see below) and related programming languages define their entire syntax in prefix notation (and others use postfix notation).

A quotation from a paper by Jan Łukasiewicz, "Remarks on Nicod's Axiom and on "Generalizing Deduction"", page 180, states how the notation was invented:
I came upon the idea of a parenthesis-free notation in 1924. I used that notation for the first time in my article Łukasiewicz(1), p. 610, footnote.

The reference cited by Łukasiewicz is apparently a lithographed report in Polish. The referring paper by Łukasiewicz "Remarks on Nicod's Axiom and on "Generalizing Deduction"" was reviewed by Henry A. Pogorzelski in the "Journal of Symbolic Logic" in 1965. Heinrich Behmann, editor in 1924 of the article of Moses Schönfinkel, already had the idea of eliminating parentheses in logic formulas.

Alonzo Church mentions this notation in his classic book on mathematical logic as worthy of remark in notational systems even contrasted to Alfred Whitehead and Bertrand Russell's logical notational exposition and work in Principia Mathematica.

In Łukasiewicz's 1951 book, "Aristotle's Syllogistic from the Standpoint of Modern Formal Logic", he mentions that the principle of his notation was to write the functors before the arguments to avoid brackets and that he had employed his notation in his logical papers since 1929. He then goes on to cite, as an example, a 1930 paper he wrote with Alfred Tarski on the sentential calculus.

While no longer used much in logic, Polish notation has since found a place in computer science.

The expression for adding the numbers 1 and 2 is written in Polish notation as (pre-fix), rather than as (in-fix). In more complex expressions, the operators still precede their operands, but the operands may themselves be expressions including again operators and their operands. For instance, the expression that would be written in conventional infix notation as
can be written in Polish notation as
Assuming a given arity of all involved operators (here the "−" denotes the binary operation of subtraction, not the unary function of sign-change), any well formed prefix representation thereof is unambiguous, and brackets within the prefix expression are unnecessary. As such, the above expression can be further simplified to

The processing of the product is deferred until its two operands are available (i.e., 5 minus 6, and 7). As with "any" notation, the innermost expressions are evaluated first, but in Polish notation this "innermost-ness" can be conveyed by the sequence of operators and operands rather than by bracketing.

In the conventional infix notation, parentheses are required to override the standard precedence rules, since, referring to the above example, moving them
or removing them
changes the meaning and the result of the expression. This version is written in Polish notation as

When dealing with non-commutative operations, like division or subtraction, it is necessary to coordinate the sequential arrangement of the operands with the definition of how the operator takes its arguments, i.e., from left to right. For example, , with 10 left to 5, has the meaning of 10 ÷ 5 (read as "divide 10 by 5"), or , with 7 left to 6, has the meaning of 7 - 6 (read as "subtract from 7 the operand 6").

Prefix/postfix notation is especially popular for its innate ability to express the intended order of operations without the need for parentheses and other precedence rules, as are usually employed with infix notation. Instead, the notation uniquely indicates which operator to evaluate first. The operators are assumed to have a fixed arity each, and all necessary operands are assumed to be explicitly given. A valid prefix expression always starts with an operator and ends with an operand. Evaluation can either proceed from left to right, or in the opposite direction. Starting at the left, the input string, consisting of tokens denoting operators or operands, is pushed token for token on a stack, until the top entries of the stack contain the number of operands that fits to the top most operator (immediately beneath). This group of tokens at the stacktop (the last stacked operator and the according number of operands) is replaced by the result of executing the operator on these/this operand(s). Then the processing of the input continues in this manner. The rightmost operand in a valid prefix expression thus empties the stack, except for the result of evaluating the whole expression. When starting at the right, the pushing of tokens is performed similarly, just the evaluation is triggered by an operator, finding the appropriate number of operands that fits its arity already at the stacktop. Now the leftmost token of a valid prefix expression must be an operator, fitting to the number of operands in the stack, which again yields the result. As can be seen from the description, a push-down store with no capability of arbitrary stack inspection suffices to implement this parsing.

The above sketched stack manipulation works –with mirrored input– also for expressions in reverse Polish notation.

The table below shows the core of Jan Łukasiewicz's notation for sentential logic. Some letters in the Polish notation table stand for particular words in Polish, as shown:

Note that the quantifiers ranged over propositional values in Łukasiewicz's work on many-valued logics.

Bocheński introduced a system of Polish notation that names all 16 binary connectives of classical propositional logic. For classical propositional logic, it is a compatible extension of the notation of Łukasiewicz. But the notations are incompatible in the sense that Bocheński uses L and M (for nonimplication and converse nonimplication) in propositional logic and Łukasiewicz uses L and M in modal logic.

Prefix notation has seen wide application in Lisp s-expressions, where the brackets are required since the operators in the language are themselves data (first-class functions). Lisp functions may also be variadic. The Tcl programming language, much like Lisp also uses Polish notation through the mathop library. The Ambi programming language uses Polish notation for arithmetic operations and program construction.

Postfix notation is used in many stack-oriented programming languages like PostScript and Forth. CoffeeScript syntax also allows functions to be called using prefix notation, while still supporting the unary postfix syntax common in other languages.

The number of return values of an expression equals the difference between the number of operands in an expression and the total arity of the operators minus the total number of return values of the operators.

Polish notation, usually in postfix form, is the chosen notation of certain calculators, notably from Hewlett-Packard. At a lower level, postfix operators are used by some stack machines such as the Burroughs large systems.




</doc>
<doc id="25058" url="https://en.wikipedia.org/wiki?curid=25058" title="Primary school">
Primary school

A primary school, junior school (in UK), elementary school or grade school (in US & Canada) is a school for children from about four to eleven years old, in which they receive primary or elementary education. It can refer to both the physical structure (buildings) and the organisation. Typically it comes after preschool, and before secondary school.

The International Standard Classification of Education considers primary education as a single phase where programmes are typically designed to provide fundamental skills in reading, writing and mathematics and to establish a solid foundation for learning. This is ISCED Level 1: Primary education or first stage of basic education.

During Greek and Roman times, boys were educated by their mothers until the age of seven, then according to the culture of their location and times, would start a formal education. In Sparta until twelve, it would be at a military academy building up physical fitness and combat skills, but also reading, writing and arithmetic while in Athens the emphasis would be on understanding the laws of the polis, reading, writing, arithmetic and music with gymnastics and athletics, and learning the moral stories of Homer. Girls received all their education at home. In Rome the primary school was called the "ludus"; the curriculum developed over the centuries featuring the learning of both Latin and Greek. In AD 94, Quintilian published the systematic educational work, "Institutio oratoria". He distinguished between teaching and learning, and that a child aged between 7 and 14 learned by sense experience, learns to form ideas, develops language and memory. He recommended that teachers should motivate their pupils by making the teaching interesting, rather than by corporal punishment. The trivium (grammar, rhetoric and logic) and quadrivium (arithmetic, geometry, astronomy and music) were legacies of the Roman curriculum.

As the Roman influence waned the great cathedral schools were established to provide a source of choristers and clergy. Kings School, Canterbury dates from 597. The Council of Rome in 853 specified that each parish should provide elementary education: religious ritual but also reading and writing Latin. 
The purpose of education was pass on salvation not social change. The church had a monopoly on education and the feudal lords concurred and allowed their sons to be educated at the few church schools. The economy was agrarian and the children of serfs started work as soon as they were able. It was a truth that man was created by God in the image of Adam with his share of original sin and a boy was born sinful. Only the teaching of the church and the sacraments could redeem him. The parishes provide elementary education- but had no requirement to provide it to every child. The need was to produce priests, and in a stable kingdom such as that of Charlemagne, administrators with elementary writing skills in Latin and the arithmetic needed to collect taxes and administer them. Alcuin (735–804) developed teaching material that were based on the catechetical method- repeating and memorizing questions and answers, though often not understanding. These skills were also needed in the great abbeys such as Cluny. There was a divergence between the needs of town and monasteries and we see the development of parish, chantry, monastic and cathedral schools. With the entry of women into church life, convents were established and with them convent schools. Girls entered here at the age of eight and were taught Latin grammar, religious doctrine and music, and the women's arts of spinning, weaving, tapestry, painting and embroidery. Bede entered the monastic school at Jarrow at the age of seven and became a writer and historian. Chantry schools were the result of a charitable donations and educated the poor. Parishes had to have a school from 804, and cathedrals had to establish schools after the Lateran Council of 1179. Elementary education was mainly to teach the Latin needed for the trivium and the quadrivium that formed the basis of the secondary curriculum.

While Humanism had a great change on the secondary curriculum, the primary curriculum was unaffected. It was believed that by studying the works of the greats, ancients who had governed empires, one became fit to succeed in any field. Renaissance boys from the age of five learned Latin grammar using the same books as the Roman child. There were the grammars of Donatus and Priscian followed by "Caesar's Commentaries" and then St Jerome's Latin Vulgate.

Wealthy boys were educated by tutors. Others were educated in schools attached to the parishes, cathedrals or abbeys. From the 13th century, wealthy merchants endowed money for priests to "establish as school to teach grammar". These early grammar schools were to teach basic, or elementary grammar, to boys. No age limit was specified. Early examples in England included Lancaster Royal Grammar School, Royal Latin School, Buckingham, and Stockport Grammar School. The Reformation and the Dissolution of the Monasteries (1548) disrupted the funding of many schools. The schools petitioned the King, Edward VI, for an endowment. Examples of schools receiving endowments are King Edward VI Grammar School, Louth, King Edward VI Grammar School, Norwich and King Edward VI School, Stratford-upon-Avon, where William Shakespeare was thought to be pupil from the age of 7 to 14.

Though the Grammar schools which were set up to deliver elementary education, they did require their entrants to already have certain skills. In particular, they expected them to be able to read and write in the vernacular. There was a need for something more basic.

This was addressed by Dame schools, then charity schools, often set up by the churches (C of E schools), Bell's British Schools and 
Joseph Lancaster's National Schools. 

Certain movements in education had a relevance in all of Europe and its diverging colonies. The Americans were interested in the thoughts of Pestalozzi, Joseph Lancaster, Owen and the Prussian schools.

Within the English speaking world, there are three widely used systems to describe the age of the child. The first is the "equivalent ages", then countries that base their education systems on the "English model" use one of two methods to identify the year group, while countries that base their systems on the "American K–12 model" refer to their year groups as "grades". Canada also follows the American model, although its names for year groups are put the number after the grade: For instance, "Grade 1" in Canada, rather than "First Grade" in the United States. This terminology extends into research literature.

In Canada, education is a Provincial, not a Federal responsibility. For example, the province of Ontario also had a "Grade 13," designed to help students enter the workforce or post-secondary education, but this was phased out in the year 2003.

In most parts of the world, primary education is the first stage of compulsory education, and is normally available without charge, but may also be offered by fee-paying independent schools. The term grade school is sometimes used in the US, although this term may refer to both primary education and secondary education.

The term "primary school" is derived from the French "école primaire", which was first used in an English text in 1802. In the United Kingdom, "elementary education" was taught in "elementary schools" until 1944, when free elementary education was proposed for students over 11: there were to be primary elementary schools and secondary elementary schools; these became known as primary schools and secondary schools.


In some parts of the United States, "primary school" refers to a school covering kindergarten through to second grade or third grade (K through 2 or 3); the "elementary school" includes grade three through five or grades four to six. In Canada, "elementary school" almost everywhere refers to Grades 1 through 6; with Kindergarten being referred to as "preschool."

Though often used as a synonym, "elementary school" has specific meanings in different locations.


School building design does not happen in isolation. The building (or school campus) needs to accommodate:

Each country will have a different education system and priorities. Schools need to accommodate students, staff, storage, mechanical and electrical systems, storage, support staff, ancillary staff and administration. The number of rooms required can be determined from the predicted roll of the school and the area needed.

According to standards used in the United Kingdom, a general classroom for 30 reception class or infant (Keystage 1) students needs to be 62 m, or 55 m for juniors (Keystage 2). Examples are given on how this can be configured for a 210 place primary with attached 26 place nursery and two-storey 420 place (two form entry) primary school with attached 26 place nursery.

The building providing the education has to fulfil the needs of: The students, the teachers, the non-teaching support staff, the administrators and the community. It has to meet general government building guidelines, health requirements, minimal functional requirements for classrooms, toilets and showers, electricity and services, preparation and storage of textbooks and basic teaching aids. An optimum school will meet the minimum conditions and will have:


Government accountants having read the advice then publish minimum guidelines on schools. These enable environmental modelling and establishing building costs. Future design plans are audited to ensure that these standards are met but not exceeded. Government ministries continue to press for the 'minimum' space and cost standards to be reduced.

The UK government published this downwardly revised space formula for primary schools in 2014. It said the floor area should be 350 m + 4.1 m/pupil place. The external finishes were to be downgraded to meet a build cost of £1113/m.

There are three main ways of funding a school: it can funded by the state through general taxation, it can be funded by a pressure group such as the mosque or the church, it can be funded by a charity or it can be funded by contributions from the parents or a combination of these methods. Day to day oversight of the school can through a board of governors, the pressure group or by the owner.

The United Kingdom allowed most elementary education to be delivered in church schools whereas in France this was illegal as there is strict separation of church and state.

This can be through informal assessment by the staff and governors such as in Finland, or by a state run testing regime such as Ofsted in the United Kingdom.




</doc>
<doc id="25060" url="https://en.wikipedia.org/wiki?curid=25060" title="Preprocessing">
Preprocessing

Preprocessing can refer to the following topics in computer science:



</doc>
<doc id="25061" url="https://en.wikipedia.org/wiki?curid=25061" title="Piedmont">
Piedmont

Piedmont ( ; , ; Piedmontese, Occitan and , ) is a region in northwest Italy, one of the 20 regions of the country. It borders the Liguria region to the south, the Lombardy and Emilia-Romagna regions to the east and the Aosta Valley region to the northwest; it also borders Switzerland to the northeast and France to the west. It has an area of and a population of 4,377,941 as of 30 November 2017. The capital of Piedmont is Turin.

The name Piedmont comes from medieval Latin Pedemontium or Pedemontis, i.e., "ad pedem montium", meaning "at the foot of the mountains" (the Alps) attested in documents of the end of the 12th century.

Other towns of Piedmont with more than 20,000 inhabitants sorted by population :

Piedmont is surrounded on three sides by the Alps, including Monviso, where the Po rises, and Monte Rosa. It borders with France (Auvergne-Rhône-Alpes and Provence-Alpes-Côte d'Azur), Switzerland (Ticino and Valais) and the Italian regions of Lombardy, Liguria, Aosta Valley and for a very small fragment with Emilia Romagna.
The geography of Piedmont is 43.3% mountainous, along with extensive areas of hills (30.3%) and plains (26.4%).

Piedmont is the second largest of Italy's 20 regions, after Sicily. It is broadly coincident with the upper part of the drainage basin of the river Po, which rises from the slopes of Monviso in the west of the region and is Italy's largest river. The Po drains the semicircle formed by the (Alps and Apennines), which surround the region on three sides.

From the highest peaks, the land slopes down to hilly areas, (sometimes with a brusque transition from mountain to plain) and then to the upper, and then to the lower great Padan Plain. The boundary between the two is characterised by resurgent springs—typical of the Padan Plain—which supply fresh water to the rivers and a dense network of irrigation canals.

The countryside is very diverse: from the rugged peaks of the massifs of Monte Rosa and of Gran Paradiso to the damp rice paddies of Vercelli and Novara, from the gentle hillsides of the Langhe, Roero and Montferrat to the plains. 7.6% of the entire territory is considered protected area. There are 56 different national or regional parks, one of the most famous is the Gran Paradiso National Park located between Piedmont and the Aosta Valley.

Piedmont was inhabited in early historic times by Celtic-Ligurian tribes such as the Taurini and the Salassi. They were later subdued by the Romans (c. 220 BC), who founded several colonies there including "Augusta Taurinorum "(Turin) and "Eporedia" (Ivrea). After the fall of the Western Roman Empire, the region was successively invaded by the Burgundians, the Ostrogoths (5th century), East Romans, Lombards (6th century), and Franks (773).

In the 9th–10th centuries there were further incursions by the Magyars, Saracens and Muslim Moors. At the time Piedmont, as part of the Kingdom of Italy within the Holy Roman Empire, was subdivided into several marches and counties.

In 1046, Oddo of Savoy added Piedmont to their main territory of Savoy, with a capital at Chambéry (now in France). Other areas remained independent, such as the powerful "comuni" (municipalities) of Asti and Alessandria and the marquisates of Saluzzo and Montferrat. The County of Savoy was elevated to a duchy in 1416, and Duke Emanuele Filiberto moved the seat to Turin in 1563. In 1720, the Duke of Savoy became King of Sardinia, founding what evolved into the Kingdom of Sardinia and increasing Turin's importance as a European capital.

The Republic of Alba was created in 1796 as a French client republic in Piedmont. A new client republic, the Piedmontese Republic, existed between 1798 and 1799 before it was reoccupied by Austrian and Russian troops. In June 1800 a third client republic, the Subalpine Republic, was established in Piedmont. It fell under full French control in 1801 and it was annexed by France in September 1802. In the Congress of Vienna, the Kingdom of Sardinia was restored, and furthermore received the Republic of Genoa to strengthen it as a barrier against France.

Piedmont was a springboard for Italy's unification in 1859–1861, following earlier unsuccessful wars against the Austrian Empire in 1820–1821 and 1848–1849. This process is sometimes referred to as "Piedmontisation". However, the efforts were later countered by the efforts of rural farmers.

The House of Savoy became Kings of Italy, and Turin briefly became the capital of Italy. However, when the Italian capital was moved to Florence, and then to Rome, the administrative and institutional importance of Piedmont was deeply reduced and the only remaining recognition to Piedmont's historical role was that the crown prince of Italy was known as the Prince of Piedmont. After Italian unification, Piedmont was one of the most important regions in the first Italian industrialization.

Lowland Piedmont is a fertile agricultural region. The main agricultural products in Piedmont are cereals, including rice, representing more than 10% of national production, maize, grapes for wine-making, fruit and milk. With more than 800,000 head of cattle in 2000, livestock production accounts for half of final agricultural production in Piedmont.

Piedmont is one of the great winegrowing regions in Italy. More than half of its of vineyards are registered with DOC designations. It produces prestigious wines as Barolo, Barbaresco, from the Langhe near Alba, and the Moscato d'Asti as well as the sparkling Asti from the vineyards around Asti. Indigenous grape varieties include Nebbiolo, Barbera, Dolcetto, Freisa, Grignolino and Brachetto.

The region contains major industrial centres, the main of which is Turin, home to the FIAT automobile works. Olivetti, once a major electronics industry whose plant was in Scarmagno, near Ivrea, has now turned into a small-scale computer service company. Biella produces tissues and silks. The city of Asti is located about 55 kilometres (34 miles) east of Turin in the plain of the Tanaro River and is one of the most important centres of Montferrat, one of the best known Italian wine districts in the world, declared officially on 22 June 2014 a UNESCO World Heritage site.

Alba is the home of Ferrero's chocolate factories and some mechanical industries. There are links with neighbouring France via the Fréjus and the Colle di Tenda tunnels as well as the Montgenèvre Pass. Piedmont also connects with Switzerland with the Simplon and Great St Bernard passes. It is possible to reach Switzerland via a normal road that crosses Oriental Piedmont starting from Arona and ending in Locarno, on the border with Italy. The region's airport, Turin-Caselle, caters domestic and international flights.
The region has the longest motorway network amongst the Italian regions (about 800 km). It radiates from Turin, connecting it with the other provinces in the region, as well as with the other regions in Italy. In 2001, the number of passenger cars per 1,000 inhabitants was 623 (above the national average of 575).

Tourism in Piedmont employs 75,534 people and currently comprises 17,367 companies operating in the hospitality and catering sector, with 1,473 hotels and tourist accommodations. The sector generates a turnover of €2,671 million, 3.3% of the €80,196 million, which represents the total estimated spending on tourism in Italy. The region enjoys almost the same level of popularity among Italians and visitors from oversea. In 2002 there were 2,651,068 total arrivals. International visitors to Piedmont in 2002 accounted for 42% of the total number of tourists with 1,124,696 arrivals. The traditional leading areas for tourism in Piedmont are the Lake District – "Piedmont's riviera", which accounts for 32.84% of total overnight stays, and the metropolitan area of Turin, which accounts for 26.51%.

In 2006, Turin hosted the XX Olympic Winter Games and in 2007 it hosted the XXIII Universiade. Alpine tourism tends to concentrate in a few highly developed stations like Alagna Valsesia and Sestriere. Around 1980, the long-distance trail Grande Traversata delle Alpi (GTA) was created to draw more attention to the manyfold of remote, sparsely inhabited valleys.

Since 2006, the Piedmont region has benefited from the start of the Slow Food movement and Terra Madre, events that highlighted the rich agricultural and viticultural value of the Po valley and northern Italy. In the same year, Piemonte Agency for Investments, Export and Tourism strives to strengthen the international role of the area and its potential. It was the first Italian institution to bring together all activities carried out by pre-existing local organizations operating for the internationalization of the territory.

The unemployment rate stood at 8.2% in 2018.

The economy of Piedmont is anchored on a rich history of state support for excellence in higher education, including some of the leading universities in Italy. The Piedmont valley is home to the famous University of Turin, the Polytechnic University of Turin, the University of Eastern Piedmont and, more recently the United Nations Interregional Crime and Justice Research Institute.

The population density in Piedmont is lower than the national average. In 2008 it was equal to 174 inhabitants per km, compared to a national figure of about 200. It rises however to 335 inhabitants per km when just the Metropolitan City of Turin is considered, whereas Verbano-Cusio-Ossola is the less densely populated province (72 inhabitants per km).

The population of Piedmont followed a downward trend throughout the 1980s. This drop is the result of the natural negative balance (of some 3 to 4% per year), while the migratory balance since 1986 has again become positive because of an excess of new immigration over a stable figure for emigration.
The population as a whole has remained stable in the 1990s, although this is the result of a negative natural balance and a positive net migration.

The Turin metro area grew rapidly in the 1950s and 1960s due to an increase of immigrants from southern Italy and Veneto and today it has a population of approximately two million. , the Italian national institute of statistics (ISTAT) estimated that 310,543 foreign-born immigrants live in Piedmont, equal to 7.0% of the total regional population. Most immigrants come from Eastern Europe (mostly from Romania, Albania, and Ukraine) with smaller communities of African immigrants.

The Regional Government ("Giunta Regionale") is presided by the President of the Region ("Presidente della Regione"), who is elected for a five-year term and is composed by the President and the Ministers, who are currently 14, including a Vice President ("Vice Presidente").
In the last regional election, which took place on 29–30 March 2010, Roberto Cota (Lega Nord) defeated incumbent Mercedes Bresso (Democratic Party). In 2014 Cota chose not to stand again for President and the parties composing his coalition failed to agree on a single candidate, resulting in a landslide victory for Sergio Chiamparino, a Democrat who had been Mayor of Turin from 2001 to 2011.

Piedmont is divided into eight provinces:

As in the rest of Italy, Italian is the official national language. The main local languages are Piedmontese, Insubric (spoken in the eastern part of the region), Occitan (spoken by a minority in the Occitan Valleys situated in the Province of Cuneo and the Metropolitan City of Turin), and Franco-Provençal (spoken by another minority in the alpine heights of the Metropolitan City of Turin), like in the Susa valley and Walser (spoken by a minority in the Province of Vercelli and Province of Verbano-Cusio-Ossola).

Turin hosted the 2006 Winter Olympics.

In football, notable clubs in Piedmont include Turin-based Juventus and Torino, who have won 38 official top-flight league championships (as of the 2014-15 season) between them, more than any other city in Italy. Other smaller teams include the old "Piedmont Quadrilateral" components Novara, Alessandria, Casale, Pro Vercelli. With the pre-World War II success of Pro Vercelli and the dominance of Torino during the "Grande Torino" years and Juventus in more recent times, the region is the most successful in terms of championships won. Also Casale and Novese contributed with one "scudetto" each.

Other local teams include volleyball teams Cuneo (male) and AGIL Novara (female), basketball teams Biella Basketball and Junior Casale, ice hockey team Hockey Club Turin, and roller hockey side Amatori Vercelli, who have won three league titles, an Italian Cup and two CERS Cups.





</doc>
<doc id="25062" url="https://en.wikipedia.org/wiki?curid=25062" title="Palestinian views on the peace process">
Palestinian views on the peace process

Palestinian views on the peace process with Israel are wide ranging. The goal that unites Palestinians is the end of the Israeli occupation of the West Bank. Some Palestinians want a two-state solution where the West Bank and the Gaza Strip form a distinct Palestinian state, whereas other Palestinians want a one-state solution (Palestinian or binational) with equal rights for all citizens whether they are Muslims, Christians or Jews. In this scenario, Palestinian refugees may be allowed to resettle the land they were forced to flee in the 1948 Palestinian exodus. However, Anti-semitic sentiments in Palestinian society and in Palestinian militants have hindered the peace process.

Palestinians have held diverse views and perceptions of the peace process. A key starting point for understanding these views is an awareness of the differing objectives sought by advocates of the Palestinian cause. 'New Historian' Israeli academic Ilan Pappe says the cause of the conflict from a Palestinian point of view dates back to 1948 with the creation of Israel (rather than Israel’s views of 1967 being the crucial point and the return of occupied territories being central to peace negotiations), and that the conflict has been a fight to bring home refugees to a Palestinian state. Therefore, this for some was the ultimate aim of the peace process, and for groups such as Hamas still is. However, Jerome Slater says that this ‘maximalist’ view of a destruction of Israel in order to regain Palestinian lands, a view held by Arafat and the PLO initially, has steadily moderated from the late 1960s onwards to a preparedness to negotiate and instead seek a two-state solution. The Oslo Accords demonstrated the recognition of this acceptance by the then Palestinian leadership of the state of Israel’s right to exist in return for the withdrawal of Israeli forces from the Gaza Strip and West Bank. However, there are recurrent themes prevalent throughout peace process negotiations including a feeling that Israel offers too little and a mistrust of its actions and motives. Yet, the demand for the "Right of Return" (ROR) by descendants of Palestinian refugees to Israel has remained a cornerstone of the Palestinian view and has been repeatedly enunciated by Palestinian president Mahmud Abbas who is leading the Palestinian peace effort.

The PLO has complex, often contradictory attitudes toward the peace process. Officially, the PLO acceptance of Israel's right to exist in peace was the first of the PLO's obligations in the Oslo Accords. In Yasser Arafat's September 9, 1993 letter to Israeli Prime Minister Yitzhak Rabin, as part of the first Oslo accord, Arafat stated that "The PLO recognizes the right of the State of Israel to exist in peace and security." Remarks from Arafat a shift away from one of the PLO's primary aims—the destruction of Israel.

However, evidence throughout history and even during the 1990s and 2000s have shown that the PLO leadership considered any peace made with Israel to be temporary until the dream of Israel's destruction could be realized. Arafat often spoke of the peace process in terms of "justice" for the Palestinians; terms historian Efraim Karsh described as "euphemisms rooted in Islamic and Arabic history for the liberation of the whole of Palestine from 'foreign occupiers.'" When describing his views of the peace process among Arab leaders and in the media of the Arab world, Arafat's rhetoric became noticeably more bellicose than it was when among Western leaders and media outside of the Arab world. The period saw a disconnect between what the PLO's second in command Abu Iyad referred to as "the language of peace" and support of Palestinian terrorism.

Since the 1990s, there has been a debate within the PLO as to whether to halt terrorist activities completely or to continue attacking Israel as well as negotiate diplomatically with Israel. In practice, terrorism was never fully banned. Furthermore, assassination attempts by radical Palestinian factions within the PLO since the early years of the peace process kept Arafat from expressing full, public support of the peace process or condemnation of terrorism without risking further danger to his own life.

In 2000, after Yasser Arafat rejected the offer made to him by Ehud Barak based on the two-state solution and declined to negotiate for a more favorable offer, it became clear that Arafat would not make a deal with Israel unless it included the full Palestinian right of return, which would demographically destroy the Jewish character of the State of Israel. For this reason, critics of Arafat claim that he put his desire to destroy the Jewish state above his dream of building an autonomous Palestinian state.

The stated goal of Hamas and the Palestinian Islamic Jihad is to conquer Israel and replace it with an Islamist state. Both groups reject the Oslo Accords and other plans for peace with Israel. Throughout the 1990s and 2000s, the two groups worked together to derail the peace process by attacking Israeli civilians. Hamas undertook a ceasefire with Israel in August 2004. The Palestinian Islamic Jihad was unhappy with the ceasefire. In September 2005, Hamas was criticized by Islamic Jihad for calling off rocket attacks on Israel from Gaza.

In 2008, Hamas publicly offered a long-term hudna (truce) with Israel if Israel agreed to return to its 1967 borders and to grant the "right of return" to all Palestinian refugees. In 2010, Ismail Haniyeh announced that Hamas would accept the outcome of a Palestinian referendum on a peace treaty with Israel even if the results were not in line with their ideology. This represented a departure from their earlier insistence that they would not be bound by any such result. In 2012, Mousa Abu Marzook, a high-ranking Hamas official in competition with Haniyeh for Hamas' top leadership post, gave an interview in which he expressed a range of opinions, some of which differed from the organisation's actual stance. He said that Hamas will not recognize Israel and will not feel bound to understand a peace treaty negotiated by Fatah as a recognition of Israel, calling instead for a "hudna" (temporary truce). Abu Marzook echoed Haniyeh's demand that Palestinians should be given the unconditional right to return into what is now Israel proper.

Rashid Abu Shbak, a senior PA security official declared, "The light which has shone over Gaza and Jericho [when the PA assumed control over those areas] will also reach the Negev and the Galilee [which constitute a large portion of pre-1967 Israel]."

The PA's Voice of Palestine radio station broadcast a Friday prayer sermon by Yusuf Abu Sneineh, official preacher at Jerusalem's Al-Aqsa Mosque, over the radio. In it, he asserted, "The struggle we are waging is an ideological struggle and the question is: where has the Islamic land of Palestine gone? Where [are] Haifa and Jaffa, Lod and Ramle, Acre, Safed and Tiberias? Where is Hebron and Jerusalem?"

PA cabinet minister Abdul Aziz Shaheen told the official PA newspaper, "Al-Havat Al-Jadida", on January 4, 1998, "The Oslo accord was a preface for the Palestinian Authority and the Palestinian Authority will be a preface for the Palestinian state which, in its turn, will be a preface for the liberation of the entire Palestinian land."

Faisal Husseini, former Palestinian Authority Minister for Jerusalem, compared the al-Aqsa intifada following the Oslo peace process to the tactic of coming out of the Trojan Horse used by the Greeks in the myth of the Trojan War.




</doc>
<doc id="25063" url="https://en.wikipedia.org/wiki?curid=25063" title="Product ring">
Product ring

In mathematics, it is possible to combine several rings into one large product ring. This is done by giving the Cartesian product of a (possibly infinite) family of rings coordinatewise addition and multiplication. The resulting ring is called a direct product of the original rings.

An important example is the ring Z/"n"Z of integers modulo "n". If "n" is written as a product of prime powers (see fundamental theorem of arithmetic),

where the "p" are distinct primes, then Z/"n"Z is naturally isomorphic to the product ring

This follows from the Chinese remainder theorem.

If is a product of rings, then for every "i" in "I" we have a surjective ring homomorphism which projects the product on the "i"th coordinate. The product "R", together with the projections "p", has the following universal property: 
This shows that the product of rings is an instance of products in the sense of category theory. 

When "I" is finite, the underlying additive group of coincides with the direct sum of the additive groups of the "R". In this case, some authors call "R" the "direct sum of the rings "R"" and write , but this is incorrect from the point of view of category theory, since it is usually not a coproduct in the category of rings: for example, when two or more of the "R" are nonzero, the inclusion map fails to map 1 to 1 and hence is not a ring homomorphism.

Direct products are commutative and associative (up to isomorphism), meaning that it doesn't matter in which order one forms the direct product.

If "A" is an ideal of "R" for each "i" in "I", then is an ideal of "R". If "I" is finite, then the converse is true, i.e., every ideal of "R" is of this form. However, if "I" is infinite and the rings "R" are non-zero, then the converse is false: the set of elements with all but finitely many nonzero coordinates forms an ideal which is not a direct product of ideals of the "R". The ideal "A" is a prime ideal in "R" if all but one of the "A" are equal to "R" and the remaining "A" is a prime ideal in "R". However, the converse is not true when "I" is infinite. For example, the direct sum of the "R" form an ideal not contained in any such "A", but the axiom of choice gives that it is contained in some maximal ideal which is a fortiori prime.

An element "x" in "R" is a unit if and only if all of its components are units, i.e., if and only if is a unit in "R" for every "i" in "I". The group of units of "R" is the product of the groups of units of "R".

A product of two or more non-zero rings always has nonzero zero divisors: if "x" is an element of the product whose coordinates are all zero except , and "y" is an element of the product with all coordinates zero except where , then in the product ring.




</doc>
<doc id="25064" url="https://en.wikipedia.org/wiki?curid=25064" title="Posthumanism">
Posthumanism

Posthumanism or post-humanism (meaning "after humanism" or "beyond humanism") is a term with at least seven definitions according to philosopher Francesca Ferrando:

Philosopher Ted Schatzki suggests there are two varieties of posthumanism of the philosophical kind:

One, which he calls 'objectivism', tries to counter the overemphasis of the subjective or intersubjective that pervades humanism, and emphasises the role of the nonhuman agents, whether they be animals and plants, or computers or other things.

A second prioritizes practices, especially social practices, over individuals (or individual subjects) which, they say, constitute the individual.

There may be a third kind of posthumanism, propounded by the philosopher Herman Dooyeweerd. Though he did not label it as 'posthumanism', he made an extensive and penetrating immanent critique of Humanism, and then constructed a philosophy that presupposed neither Humanist, nor Scholastic, nor Greek thought but started with a different religious ground motive. Dooyeweerd prioritized law and meaningfulness as that which enables humanity and all else to exist, behave, live, occur, etc. ""Meaning" is the "being" of all that has been "created"," Dooyeweerd wrote, "and the nature even of our selfhood." Both human and nonhuman alike function subject to a common 'law-side', which is diverse, composed of a number of distinct law-spheres or "aspects". The temporal being of both human and non-human is multi-aspectual; for example, both plants and humans are bodies, functioning in the biotic aspect, and both computers and humans function in the formative and lingual aspect, but humans function in the aesthetic, juridical, ethical and faith aspects too. The Dooyeweerdian version is able to incorporate and integrate both the objectivist version and the practices version, because it allows nonhuman agents their own subject-functioning in various aspects and places emphasis on aspectual functioning.

Ihab Hassan, theorist in the academic study of literature, once stated:

This view predates most currents of posthumanism which have developed over the late 20th century in somewhat diverse, but complementary, domains of thought and practice. For example, Hassan is a known scholar whose theoretical writings expressly address postmodernity in society. Beyond postmodernist studies, posthumanism has been developed and deployed by various cultural theorists, often in reaction to problematic inherent assumptions within humanistic and enlightenment thought.

Theorists who both complement and contrast Hassan include Michel Foucault, Judith Butler, cyberneticists such as Gregory Bateson, Warren McCullouch, Norbert Wiener, Bruno Latour, Cary Wolfe, Elaine Graham, N. Katherine Hayles, Benjamin H. Bratton, Donna Haraway, Peter Sloterdijk, Stefan Lorenz Sorgner, Evan Thompson, Francisco Varela, Humberto Maturana and Douglas Kellner. Among the theorists are philosophers, such as Robert Pepperell, who have written about a "posthuman condition", which is often substituted for the term "posthumanism".

Posthumanism differs from classical humanism by relegating humanity back to one of many natural species, thereby rejecting any claims founded on anthropocentric dominance. According to this claim, humans have no inherent rights to destroy nature or set themselves above it in ethical considerations "a priori". Human knowledge is also reduced to a less controlling position, previously seen as the defining aspect of the world. Human rights exist on a spectrum with animal rights and posthuman rights. The limitations and fallibility of human intelligence are confessed, even though it does not imply abandoning the rational tradition of humanism.

Proponents of a posthuman discourse, suggest that innovative advancements and emerging technologies have transcended the traditional model of the human, as proposed by Descartes among others associated with philosophy of the Enlightenment period. In contrast to humanism, the discourse of posthumanism seeks to redefine the boundaries surrounding modern philosophical understanding of the human. Posthumanism represents an evolution of thought beyond that of the contemporary social boundaries and is predicated on the seeking of truth within a postmodern context. In so doing, it rejects previous attempts to establish 'anthropological universals' that are imbued with anthropocentric assumptions. Recently, critics have sought to describe the emergence of posthumanism as a critical moment in modernity, arguing for the origins of key posthuman ideas in modern fiction, in Nietzsche, or in a modernist response to the crisis of historicity.

The philosopher Michel Foucault placed posthumanism within a context that differentiated humanism from enlightenment thought. According to Foucault, the two existed in a state of tension: as humanism sought to establish norms while Enlightenment thought attempted to transcend all that is material, including the boundaries that are constructed by humanistic thought. Drawing on the Enlightenment’s challenges to the boundaries of humanism, posthumanism rejects the various assumptions of human dogmas (anthropological, political, scientific) and takes the next step by attempting to change the nature of thought about what it means to be human. This requires not only decentering the human in multiple discourses (evolutionary, ecological, technological) but also examining those discourses to uncover inherent humanistic, anthropocentric, normative notions of humanness and the concept of the human.

Posthumanistic discourse aims to open up spaces to examine what it means to be human and critically question the concept of "the human" in light of current cultural and historical contexts In her book "How We Became Posthuman", N. Katherine Hayles, writes about the struggle between different versions of the posthuman as it continually co-evolves alongside intelligent machines. Such coevolution, according to some strands of the posthuman discourse, allows one to extend their subjective understandings of real experiences beyond the boundaries of embodied existence. According to Hayles's view of posthuman, often referred to as technological posthumanism, visual perception and digital representations thus paradoxically become ever more salient. Even as one seeks to extend knowledge by deconstructing perceived boundaries, it is these same boundaries that make knowledge acquisition possible. The use of technology in a contemporary society is thought to complicate this relationship.

Hayles discusses the translation of human bodies into information (as suggested by Hans Moravec) in order to illuminate how the boundaries of our embodied reality have been compromised in the current age and how narrow definitions of humanness no longer apply. Because of this, according to Hayles, posthumanism is characterized by a loss of subjectivity based on bodily boundaries. This strand of posthumanism, including the changing notion of subjectivity and the disruption of ideas concerning what it means to be human, is often associated with Donna Haraway’s concept of the cyborg. However, Haraway has distanced herself from posthumanistic discourse due to other theorists’ use of the term to promote utopian views of technological innovation to extend the human biological capacity (even though these notions would more correctly fall into the realm of transhumanism).

While posthumanism is a broad and complex ideology, it has relevant implications today and for the future. It attempts to redefine social structures without inherently humanly or even biological origins, but rather in terms of social and psychological systems where consciousness and communication could potentially exist as unique disembodied entities. Questions subsequently emerge with respect to the current use and the future of technology in shaping human existence, as do new concerns with regards to language, symbolism, subjectivity, phenomenology, ethics, justice and creativity.

Sociologist James Hughes comments that there is considerable confusion between the two terms. In the introduction to their book on post- and transhumanism, Robert Ranisch and Stefan Sorgner address the source of this confusion, stating that posthumanism is often used as an umbrella term that includes both transhumanism and critical posthumanism.

Although both subjects relate to the future of humanity, they differ in their view of anthropocentrism. Pramod Nayar, author of "Posthumanism", states that posthumanism has two main branches: ontological and critical. Ontological posthumanism is synonymous with transhumanism. The subject is regarded as “an intensification of humanism.” Transhumanist thought suggests that humans are not post human yet, but that human enhancement, often through technological advancement and application, is the passage of becoming post human. Transhumanism retains humanism’s focus on the homo sapien as the center of the world but also considers technology to be an integral aid to human progression. Critical posthumanism, however, is opposed to these views. Critical posthumanism “rejects both human exceptionalism (the idea that humans are unique creatures) and human instrumentalism (that humans have a right to control the natural world).” These contrasting views on the importance of human beings are the main distinctions between the two subjects.

Transhumanism is also more ingrained in popular culture than critical posthumanism, especially in science fiction. The term is referred to by Pramod Nayar as "the pop posthumanism of cinema and pop culture."

Some critics have argued that all forms of posthumanism, including transhumanism, have more in common than their respective proponents realize. Linking these different approaches, Paul James suggests that 'the key political problem is that, in effect, the position allows the human as a category of being to flow down the plughole of history':

However, some posthumanists in the humanities and the arts are critical of transhumanism (the brunt of Paul James's criticism), in part, because they argue that it incorporates and extends many of the values of Enlightenment humanism and classical liberalism, namely scientism, according to performance philosopher Shannon Bell:
While many modern leaders of thought are accepting of nature of ideologies described by posthumanism, some are more skeptical of the term. Donna Haraway, the author of "A Cyborg Manifesto", has outspokenly rejected the term, though acknowledges a philosophical alignment with posthumanism. Haraway opts instead for the term of companion species, referring to nonhuman entities with which humans coexist.

Questions of race, some argue, are suspiciously elided within the "turn" to posthumanism. Noting that the terms "post" and "human" are already loaded with racial meaning, critical theorist Zakiyyah Iman Jackson argues that the impulse to move "beyond" the human within posthumanism too often ignores "praxes of humanity and critiques produced by black people", including Frantz Fanon and Aime Cesaire to Hortense Spillers and Fred Moten. Interrogating the conceptual grounds in which such a mode of “beyond” is rendered legible and viable, Jackson argues that it is important to observe that ""blackness conditions and constitutes the very nonhuman disruption and/or disruption"" which posthumanists invite. In other words, given that race in general and blackness in particular constitutes the very terms through which human/nonhuman distinctions are made, for example in enduring legacies of scientific racism, a gesture toward a “beyond” actually “returns us to a Eurocentric transcendentalism long challenged”.



</doc>
<doc id="25065" url="https://en.wikipedia.org/wiki?curid=25065" title="Parameter">
Parameter

A parameter (from the Ancient Greek παρά, "para": "beside", "subsidiary"; and μέτρον, "metron": "measure"), generally, is any characteristic that can help in defining or classifying a particular system (meaning an event, project, object, situation, etc.). That is, a parameter is an element of a system that is useful, or critical, when identifying the system, or when evaluating its performance, status, condition, etc.

"Parameter" has more specific meanings within various disciplines, including mathematics, computer programming, engineering, statistics, logic and linguistics.

When a system is modeled by equations, the values that describe the system are called "parameters". For example, in mechanics, the masses, the dimensions and shapes (for solid bodies), the densities and the viscosities (for fluids), appear as parameters in the equations modeling movements. There are often several choices for the parameters, and choosing a convenient set of parameters is called "parametrization". 

For example, if one were considering the movement of an object on the surface of a sphere much larger than the object (e.g. the Earth), there are two commonly used parametrizations of its position: angular coordinates (like latitude/longitude), which neatly describe large movements along circles on the sphere, and directional distance from a known point (e.g. "10km NNW of Toronto" or equivalently "8km due North, and then 6km due West, from Toronto" ), which are often simpler for movement confined to a (relatively) small area, like within a particular country or region. Such parametrizations are also relevant to the modelization of geographic areas (i.e. map drawing).

Mathematical functions have one or more arguments that are designated in the definition by variables. A function definition can also contain parameters, but unlike variables, parameters are not listed among the arguments that the function takes. When parameters are present, the definition actually defines a whole family of functions, one for every valid set of values of the parameters. For instance, one could define a general quadratic function by declaring

Here, the variable "x" designates the function's argument, but "a", "b", and "c" are parameters that determine which particular quadratic function is being considered. A parameter could be incorporated into the function name to indicate its dependence on the parameter. For instance, one may define the base-"b" logarithm by the formula
where "b" is a parameter that indicates which logarithmic function is being used. It is not an argument of the function, and will, for instance, be a constant when considering the derivative formula_3.

In some informal situations it is a matter of convention (or historical accident) whether some or all of the symbols in a function definition are called parameters. However, changing the status of symbols between parameter and variable changes the function as a mathematical object. For instance, the notation for the falling factorial power
defines a polynomial function of "n" (when "k" is considered a parameter), but is not a polynomial function of "k" (when "n" is considered a parameter). Indeed, in the latter case, it is only defined for non-negative integer arguments. More formal presentations of such situations typically start out with a function of several variables (including all those that might sometimes be called "parameters") such as
as the most fundamental object being considered, then defining functions with fewer variables from the main one by means of currying.

Sometimes it is useful to consider all functions with certain parameters as "parametric family", i.e. as an indexed family of functions. Examples from probability theory are given further below.


W.M. Woods ... a mathematician ... writes ... "... a variable is one of the many things a "parameter" is not." ... The dependent variable, the speed of the car, depends on the independent variable, the position of the gas pedal.

[Kilpatrick quoting Woods] "Now ... the engineers ... change the lever arms of the linkage ... the speed of the car ... will still depend on the pedal position ..." but in a ... different manner". You have changed a parameter"


In the context of a mathematical model, such as a probability distribution, the distinction between variables and parameters was described by Bard as follows:

In analytic geometry, curves are often given as the image of some function. The argument of the function is invariably called "the parameter". A circle of radius 1 centered at the origin can be specified in more than one form:
Hence these equations, which might be called functions elsewhere are in analytic geometry characterized as parametric equations and the independent variables are considered as parameters.

In mathematical analysis, integrals dependent on a parameter are often considered. These are of the form
In this formula, "t" is the argument of the function "F", and on the right-hand side the "parameter" on which the integral depends. When evaluating the integral, "t" is held constant, and so it is considered to be a parameter. If we are interested in the value of "F" for different values of "t", we then consider "t" to be a variable. The quantity "x" is a "dummy variable" or "variable of integration" (confusingly, also sometimes called a "parameter of integration").

In statistics and econometrics, the probability framework above still holds, but attention shifts to estimating the parameters of a distribution based on observed data, or testing hypotheses about them. In frequentist estimation parameters are considered "fixed but unknown", whereas in Bayesian estimation they are treated as random variables, and their uncertainty is described as a distribution.

In estimation theory of statistics, "statistic" or estimator refers to samples, whereas "parameter" or estimand refers to populations, where the samples are taken from. A statistic is a numerical characteristic of a sample that can be used as an estimate of the corresponding parameter, the numerical characteristic of the population from which the sample was drawn.

For example, the sample mean (estimator), denoted formula_9, can be used as an estimate of the "mean" parameter (estimand), denoted "μ", of the population from which the sample was drawn. Similarly, the sample variance (estimator), denoted "S", can be used to estimate the "variance" parameter (estimand), denoted "σ", of the population from which the sample was drawn. (Note that the sample standard deviation ("S") is not an unbiased estimate of the population standard deviation ("σ"): see Unbiased estimation of standard deviation.)

It is possible to make statistical inferences without assuming a particular parametric family of probability distributions. In that case, one speaks of "non-parametric statistics" as opposed to the parametric statistics just described. For example, a test based on Spearman's rank correlation coefficient would be called non-parametric since the statistic is computed from the rank-order of the data disregarding their actual values (and thus regardless of the distribution they were sampled from), whereas those based on the Pearson product-moment correlation coefficient are parametric tests since it is computed directly from the data values and thus estimates the parameter known as the population correlation.

In probability theory, one may describe the distribution of a random variable as belonging to a "family" of probability distributions, distinguished from each other by the values of a finite number of "parameters". For example, one talks about "a Poisson distribution with mean value λ". The function defining the distribution (the probability mass function) is:
This example nicely illustrates the distinction between constants, parameters, and variables. "e" is Euler's number, a fundamental mathematical constant. The parameter λ is the mean number of observations of some phenomenon in question, a property characteristic of the system. "k" is a variable, in this case the number of occurrences of the phenomenon actually observed from a particular sample. If we want to know the probability of observing "k" occurrences, we plug it into the function to get formula_11. Without altering the system, we can take multiple samples, which will have a range of values of "k", but the system is always characterized by the same λ.

For instance, suppose we have a radioactive sample that emits, on average, five particles every ten minutes. We take measurements of how many particles the sample emits over ten-minute periods. The measurements exhibit different values of "k", and if the sample behaves according to Poisson statistics, then each value of "k" will come up in a proportion given by the probability mass function above. From measurement to measurement, however, λ remains constant at 5. If we do not alter the system, then the parameter λ is unchanged from measurement to measurement; if, on the other hand, we modulate the system by replacing the sample with a more radioactive one, then the parameter λ would increase.

Another common distribution is the normal distribution, which has as parameters the mean μ and the variance σ².

In these above examples, the distributions of the random variables are completely specified by the type of distribution, i.e. Poisson or normal, and the parameter values, i.e. mean and variance. In such a case, we have a parameterized distribution.

It is possible to use the sequence of moments (mean, mean square, ...) or cumulants (mean, variance, ...) as parameters for a probability distribution: see Statistical parameter.

In computer programming, two notions of parameter are commonly used, and are referred to as parameters and arguments—or more formally as a formal parameter and an actual parameter.

For example, in the definition of a function such as
"x" is the "formal parameter" (the "parameter") of the defined function.

When the function is evaluated for a given value, as in
3 is the "actual parameter" (the "argument") for evaluation by the defined function; it is a given value (actual value) that is substituted for the "formal parameter" of the defined function. (In casual usage the terms "parameter" and "argument" might inadvertently be interchanged, and thereby used incorrectly.)

These concepts are discussed in a more precise way in functional programming and its foundational disciplines, lambda calculus and combinatory logic. Terminology varies between languages; some computer languages such as C define parameter and argument as given here, while Eiffel uses an alternative convention.

In engineering (especially involving data acquisition) the term "parameter" sometimes loosely refers to an individual measured item. This usage isn't consistent, as sometimes the term "channel" refers to an individual measured item, with "parameter" referring to the setup information about that channel.

"Speaking generally, properties are those physical quantities which directly describe the physical attributes of the system; parameters are those combinations of the properties which suffice to determine the response of the system. Properties can have all sorts of dimensions, depending upon the system being considered; parameters are dimensionless, or have the dimension of time or its reciprocal."

The term can also be used in engineering contexts, however, as it is typically used in the physical sciences.

In environmental science and particularly in chemistry and microbiology, a parameter is used to describe a discrete chemical or microbiological entity that can be assigned a value: commonly a concentration, but may also be a logical entity (present or absent), a statistical result such as a 95%ile value or in some cases a subjective value.

Within linguistics, the word "parameter" is almost exclusively used to denote a binary switch in a Universal Grammar within a Principles and Parameters framework.

In logic, the parameters passed to (or operated on by) an "open predicate" are called "parameters" by some authors (e.g., Prawitz, "Natural Deduction"; Paulson, "Designing a theorem prover"). Parameters locally defined within the predicate are called "variables". This extra distinction pays off when defining substitution (without this distinction special provision must be made to avoid variable capture). Others (maybe most) just call parameters passed to (or operated on by) an open predicate "variables", and when defining substitution have to distinguish between "free variables" and "bound variables".

In music theory, a parameter denotes an element which may be manipulated (composed), separately from the other elements. The term is used particularly for pitch, loudness, duration, and timbre, though theorists or composers have sometimes considered other musical aspects as parameters. The term is particularly used in serial music, where each parameter may follow some specified series. Paul Lansky and George Perle criticized the extension of the word "parameter" to this sense, since it is not closely related to its mathematical sense, but it remains common. The term is also common in music production, as the functions of audio processing units (such as the attack, release, ratio, threshold, and other variables on a compressor) are defined by parameters specific to the type of unit (compressor, equalizer, delay, etc.).



</doc>
<doc id="25066" url="https://en.wikipedia.org/wiki?curid=25066" title="Procedure">
Procedure

Procedure may refer to:




</doc>
<doc id="25071" url="https://en.wikipedia.org/wiki?curid=25071" title="Paavo Nurmi">
Paavo Nurmi

Paavo Johannes Nurmi (; 13 June 1897 – 2 October 1973) was a Finnish middle-distance and long-distance runner. He was called the "Flying Finn" or the "Phantom Finn", as he dominated distance running in the early 20th century. Nurmi set 22 official world records at distances between 1500 metres and 20 kilometres, and won nine gold and three silver medals in his twelve events in the Olympic Games. At his peak, Nurmi was undefeated for 121 races at distances from 800 m upwards. Throughout his 14-year career, he remained unbeaten in cross country events and the 10,000 m.

Born into a working-class family, Nurmi left school at the age of twelve to provide for his family. In 1912, he was inspired by the Olympic feats of Hannes Kolehmainen and began developing a strict training program. Nurmi started to flourish during his military service, setting national records en route to his international debut at the 1920 Summer Olympics. After winning a silver medal in the 5000 m, he took gold in the 10,000 m and the cross country events. In 1923, Nurmi became the first runner to hold simultaneous world records in the mile, the 5000 m and the 10,000 m races, a feat which has never since been repeated. He set new world records for the 1500 m and the 5000 m with just an hour between the races, and took gold medals in both distances in less than two hours at the 1924 Olympics. Seemingly unaffected by the Paris heat wave, Nurmi won all his races and returned home with five gold medals, although he was frustrated that Finnish officials had refused to enter him for the 10,000 m.

Struggling with injuries and motivation issues after his exhaustive U.S. tour in 1925, Nurmi found his long-time rivals Ville Ritola and Edvin Wide ever more serious challengers. At the 1928 Summer Olympics, Nurmi recaptured the 10,000 m title but was beaten for the gold in the 5000 m and the 3000 m steeplechase. He then turned his attention to longer distances, breaking the world records for events such as the one hour run and the 25-mile marathon. Nurmi intended to end his career with a marathon gold medal, as his idol Kolehmainen had done. In a controversial case that strained Finland–Sweden relations and sparked an inter-IAAF battle, Nurmi was suspended before the 1932 Games by an IAAF council that questioned his amateur status; two days before the opening ceremonies, the council rejected his entries. Although he was never declared a professional, Nurmi's suspension became definite in 1934 and he retired from running.

Nurmi later coached Finnish runners, raised funds for Finland during the Winter War, and worked as a haberdasher, building contractor, and share trader, eventually becoming one of Finland's richest people. In 1952, he was the lighter of the Olympic Flame at the Summer Olympics in Helsinki. Nurmi's running speed and elusive personality spawned nicknames such as the "Phantom Finn", while his achievements, training methods and running style influenced future generations of middle- and long-distance runners. Nurmi, who rarely ran without a stopwatch in his hand, has been credited for introducing the "even pace" strategy and analytic approach to running, and for making running a major international sport.

Nurmi was born in Turku, Finland, to carpenter Johan Fredrik Nurmi and his wife Matilda Wilhelmiina Laine. Nurmi's siblings, Siiri, Saara, Martti and Lahja, were born in 1898, 1902, 1905 and 1908, respectively. In 1903, the Nurmi family moved from Raunistula into a 40-square-meter apartment in central Turku, where Paavo Nurmi would live until 1932. The young Nurmi and his friends were inspired by the English long-distance runner Alfred Shrubb. They regularly ran or walked six kilometres (four miles) to swim in Ruissalo, and back, sometimes twice a day. By the age of eleven, Nurmi ran the 1500 metres in 5:02. Nurmi's father Johan died in 1910 and his sister Lahja a year later. The family struggled financially, renting out their kitchen to another family and living in a single room. Nurmi, a talented student, left school to work as an errand boy for a bakery. Although he stopped running actively, he got plenty of exercise pushing heavy carts up the steep slopes in Turku. He later credited these climbs for strengthening his back and leg muscles.

At 15, Nurmi rekindled his interest in athletics after being inspired by the performances of Hannes Kolehmainen, who was said to "have run Finland onto the map of the world" at the 1912 Summer Olympics. He bought his first pair of sneakers a few days later. Nurmi trained primarily by doing cross country running in the summers and cross country skiing in the winters. In 1914, Nurmi joined the sports club Turun Urheiluliitto and won his first race on the 3000 metres. Two years later, he revised his training program to include walking, sprints and calisthenics. He continued to provide for his family through his new job at the Ab. H. Ahlberg & Co workshop in Turku, where he worked until he started his military service at a machine gun company in the Pori Brigade in April 1919. During the Finnish Civil War in 1918, Nurmi remained politically passive and concentrated on his work and his Olympic ambitions. After the war, he decided not to join the newly founded Finnish Workers' Sports Federation, but wrote articles for the federation's chief organ and criticized the discrimination against many of his fellow workers and athletes.
In the army, Nurmi quickly impressed in the athletic competitions: While others marched, Nurmi ran the whole distances with a rifle on his shoulder and a backpack full of sand. Nurmi's stubbornness caused him difficulties with his non-commissioned officers, but he was favoured by the superior officers, despite his refusal to take the soldier's oath. As the unit commander Hugo Österman was a known sports aficionado, Nurmi and few other athletes were given free time to practice. Nurmi improvised new training methods in the army barracks; he ran behind trains, holding on to the rear bumper, to stretch his stride, and used heavy iron-clad army boots to strengthen his legs. Nurmi soon began setting personal bests and got close for the Olympic selection. In March 1920, he was promoted to corporal ("alikersantti"). On 29 May 1920, he set his first national record on the 3000 m and went on to win the 1500 m and the 5000 m at the Olympic trials in July.

Nurmi made his international debut in August at the 1920 Summer Olympics in Antwerp, Belgium. He took his first medal by finishing second to Frenchman Joseph Guillemot in the 5000 m. This would remain the only time that Nurmi lost to a non-Finnish runner in the Olympics. He went on to win gold medals in his other three events: the 10,000 m, sprinting past Guillemot on the final curve and improving his personal best by over a minute, the cross country race, beating Sweden's Eric Backman, and the cross country team event where he helped Heikki Liimatainen and Teodor Koskenniemi defeat the British and Swedish teams. Nurmi's success brought electric lighting and running water for his family in Turku. Nurmi, however, was given a scholarship to study at the Teollisuuskoulu industrial school in Helsinki.

Buoyed by his defeat to Guillemot, Nurmi's races became a series of experiments which he analyzed meticulously. Previously known for his blistering pace on the first few laps, Nurmi started to carry a stopwatch and spread his efforts more uniformly over the distance. He aimed to perfect his technique and tactics to a point where the performances of his rivals would be rendered meaningless. Nurmi set his first world record on the 10,000 m in Stockholm in 1921. In 1922, he broke the world records for the 2000 m, the 3000 m and the 5000 m. A year later, Nurmi added the records for the 1500 m and the mile. His feat of holding the world records for the mile, the 5000 m and the 10,000 m at the same time has not been matched by any other athlete before or since. Nurmi also tested his speed in the 800 m, winning the 1923 Finnish Championships with a new national record. After excelling in mathematics, Nurmi graduated as an engineer in 1923 and returned home to prepare for the upcoming Olympic Games.

Nurmi's trip to the 1924 Summer Olympics was endangered by a knee injury in the spring of 1924, but he recovered and resumed training twice a day. On 19 June, Nurmi tried out the 1924 Olympic schedule at the Eläintarha Stadium in Helsinki by running the 1500 m and the 5000 m inside an hour, setting new world records for both distances. In the 1500 m final at the Olympics in Paris, Nurmi ran the first 800 m almost three seconds faster. His only challenger, Ray Watson of the United States, gave up before the last lap and Nurmi was able to slow down and coast to victory ahead of Willy Schärer, H. B. Stallard and Douglas Lowe, still breaking the Olympic record by three seconds. The 5000 m final started in less than two hours, and Nurmi faced a tough challenge from countryman Ville Ritola, who had already won the 3000 m steeplechase and the 10,000 m. Ritola and Edvin Wide figured that Nurmi must be tired and tried to burn him off by running at world-record pace. Realizing that he was now racing the two men and not the clock, Nurmi tossed his stopwatch onto the grass. The Finns later passed the Swede as his pace faded and continued their duel. On the home straight, Ritola sprinted from the outside but Nurmi increased his pace to keep his rival a metre behind.

In the cross country events, the heat of 45 °C (113 °F), caused all but 15 of the 38 competitors to abandon the race. Eight finishers were taken away on stretchers. One athlete began to run in tiny circles after reaching the stadium, until setting off into the stands and knocking himself unconscious. Early leader Wide was among those who blacked out along the course, and was incorrectly reported to have died at the hospital. Nurmi exhibited only slight signs of exhaustion after beating Ritola to the win by nearly a minute and a half. As Finland looked to have lost the team medal, the disoriented Liimatainen staggered into the stadium, but was barely moving forward. An athlete ahead of him fainted 50 metres from the finish, and Liimatainen stopped and tried to find his way off the track, thinking he had reached the finish line. After having ignored shouts and kept the spectators in suspense for a while, he turned into the right direction, realised his situation and reached the finish in 12th place and secured team gold. Those present at the stadium were shocked by what they had witnessed, and Olympic officials decided to ban cross country running from future Games.

In the 3000 m team race on the next day, Nurmi and Ritola again finished first and second, and Elias Katz secured the gold medal for the Finnish team by finishing fifth. Nurmi had won five gold medals in five events, but he left the Games embittered as the Finnish officials had allocated races between their star runners and prevented him from defending his title in the 10,000 m, the distance that was dearest to him. After returning to Finland, Nurmi set a 10,000 m world record that would last for almost 13 years. He now held the 1500 m, the mile, the 3000 m, the 5000 m and the 10,000 m world records simultaneously.

In early 1925, Nurmi embarked on a widely publicised tour of the United States. He competed in 55 events (45 indoors) during a five-month period, starting at a sold-out Madison Square Garden on 6 January. His debut was a copy of his feats in Helsinki and Paris. Nurmi defeated Joie Ray and Lloyd Hahn to win the mile and Ritola to win the 5000 m, again setting new world records for both distances. Nurmi broke ten more indoor world records in regular events and set several new best times for rarer distances. He won 51 of the events, abandoned one race and lost two handicap races along with his final event; a half-mile race at the Yankee Stadium, where he finished second to American track star Alan Helffrich. Helffrich's victory ended Nurmi's 121-race, four-year win streak in individual scratch races at distances from 800 m upwards. Although he hated losing more than anything, Nurmi was the first to congratulate Helffrich. The tour made Nurmi extremely popular in the United States, and the Finn agreed to meet President Calvin Coolidge at the White House. Nurmi left America fearing that he had competed too often and burned himself out.

Nurmi struggled to maintain motivation for running, heightened by his rheumatism and Achilles tendon problems. He quit his job as a machinery draughtsman in 1926 and began studying business intensively. As Nurmi started a new career as a share dealer, his financial advisors included Risto Ryti, director of the Bank of Finland. In 1926, Nurmi broke Wide's world record for the 3000 m in Berlin and then improved the record in Stockholm, despite Nils Eklöf repeatedly trying to slow his pace down in an effort to aid Wide. Nurmi was furious at the Swedes and vowed never to race Eklöf again. In October 1926, he lost a 1500 m race along with his world record to Germany's Otto Peltzer. This marked the first time in over five years and 133 races that Nurmi had been defeated at a distance over 1000 m. In 1927, Finnish officials barred him from international competition for refusing to run against Eklöf at the Finland-Sweden international, cancelling the Peltzer rematch scheduled for Vienna. Nurmi ended his season and threatened, until late November, to withdraw from the 1928 Summer Olympics. At the 1928 Olympic trials, Nurmi was left third in the 1500 m by eventual gold and bronze medalists Harri Larva and Eino Purje, and he decided to concentrate on the longer distances. He added steeplechase to his program, although he had only tried the event twice before, the latest being a two-mile steeplechase victory at the 1922 British Championships.

At the 1928 Olympics in Amsterdam, Nurmi competed in three events. He won the 10,000 m by staying right behind Ritola until sprinting past him on the home straight. Before the 5000 m final, Nurmi injured himself in his qualifying heat for the 3000 m steeplechase. He fell on his back at the water jump, spraining his hip and foot. Lucien Duquesne stopped to help him up, and Nurmi thanked the Frenchman by pacing him past the field and offered him the heat win, which Duquesne gracefully refused. In the 5000 m, Nurmi tried to repeat his move on Ritola but had to watch his teammate pull away instead. Nurmi, looking more exhausted than ever before, only barely managed to keep Wide behind and take silver. Nurmi had little time to rest or nurse his injuries as the 3000 m steeplechase started the next day. Struggling with the hurdles, Nurmi let Finland's steeplechase specialist Toivo Loukola escape into the distance. On the final lap, he sprinted clear of the others and finished nine seconds behind the world-record setting Loukola; Nurmi's time also bettered the previous record. Although Ritola did not finish, Ove Andersen completed a Finnish sweep of the medals.

Nurmi stated to a Swedish newspaper that "this is absolutely my last season on the track. I am beginning to get old. I have raced for fifteen years and have had enough of it." However, Nurmi continued running, turning his attention to longer distances. In October, he broke the world records for the 15 km, the 10 miles and the one hour run in Berlin. Nurmi's one-hour record stood for 17 years, until Viljo Heino ran 129 metres further in 1945. In January 1929, Nurmi started his second U.S. tour from Brooklyn. He suffered his first-ever defeat in the mile to Ray Conger at the indoor Wanamaker Mile. Nurmi was seven seconds slower than in his world record run in 1925, and it was immediately speculated if the mile had become too short a distance for him. In 1930, he set a new world record for the 20 km. In July 1931, Nurmi showed he still had pace for the shorter distances by beating Lauri Lehtinen, Lauri Virtanen and Volmari Iso-Hollo, and breaking the world record on the now-rare two miles. He was the first runner to complete the distance in less than nine minutes. Nurmi planned to compete only in the 10,000 m and the marathon in the 1932 Summer Olympics in Los Angeles, stating that he "won't enter the 5000 metres for Finland has at least three excellent men for that event."

In April 1932, the executive council of the International Amateur Athletics Federation (IAAF) suspended Nurmi from international athletics events pending an investigation into his amateur status by the Finnish Athletics Federation. The Finnish authorities criticized the IAAF for acting without a hearing, but agreed to launch an investigation. It was customary of the IAAF to accept the final decision of its national branch, and the Associated Press wrote that "there is little doubt that if the Finnish federation clears Nurmi the international body will accept its decision without question." A week later, the Finnish Athletics Federation ruled in favor of Nurmi, finding no evidence for the allegations of professionalism. Nurmi was hopeful that his suspension would be lifted in time for the Games.
On 26 June 1932 Nurmi started his first marathon at the Olympic trials. Not drinking a drop of liquid, he ran the old-style 'short marathon' of 40.2 km (25 miles) in 2:22:03.8 — on the pace to finish in about 2:29:00, just under Albert Michelsen's marathon world record of 2:29:01.8. At the time, he led Armas Toivonen, the eventual Olympic bronze medalist, by six minutes. Nurmi's time was the new unofficial world record for the short marathon. Confident that he had done enough, Nurmi stopped and retired from the race owing to problems with his Achilles tendon. The Finnish Olympic Committee entered Nurmi for both the 10,000 m and the marathon. "The Guardian" reported that "some of his trial times were almost unbelievable," and Nurmi went on to train at the Olympic Village in Los Angeles despite his injury. Nurmi had set his heart on ending his career with a marathon gold medal, as Kolehmainen had done shortly after the First World War.

Less than three days before the 10,000 m, a special commission of the IAAF, consisting of the same seven members that had suspended Nurmi, rejected the Finn's entries and barred him from competing in Los Angeles. Sigfrid Edström, president of the IAAF and chairman of its executive council, stated that the full congress of the IAAF, which was scheduled to start the next day, could not reinstate Nurmi for the Olympics but merely review the phases and political angles related to the case. The AP called this "one of the slickest political maneuvers in international athletic history", and wrote that the Games would now be "like Hamlet without the celebrated Dane in the cast." Thousands protested against the action in Helsinki. Details of the case were not released to the press, but the evidence against Nurmi was believed be the sworn statements from German race promoters that Nurmi had received $250–500 per race when running in Germany in autumn 1931. The statements were produced by Karl Ritter von Halt, after Edström had sent him increasingly threatening letters warning that if evidence against Nurmi were not provided he would be "unfortunately obliged to take stringent action against the German Athletics Association."

On the eve of the marathon, all the entrants of the race except for the Finns, whose positions were known, filed a petition asking Nurmi's entry to be accepted. Edström's right-hand man Bo Ekelund, secretary general of the IAAF and head of the Swedish Athletics Federation, approached the Finnish officials and stated that he might be able to arrange for Nurmi to participate in the marathon outside the competition. However, Finland maintained that as long as the athlete is not declared a professional, he must have the right to participate in the race officially. Although he had been diagnosed with a pulled Achilles tendon two weeks earlier, Nurmi stated he would have won the event by five minutes. The congress concluded without Nurmi being declared a professional, but the council's authority to disbar an athlete was upheld on a 13–12 vote. However, due to the close vote, the matter was postponed until the 1934 meet in Stockholm. Finns charged that the Swedish officials had used devious tricks in their campaign against Nurmi's amateur status, and ceased all athletic relations with Sweden. A year earlier, controversies on the track and in the press had led Finland to withdraw from the Finland-Sweden athletics international. After Nurmi's suspension, Finland did not agree to return to the event until 1939.

Nurmi refused to turn professional, and continued running as amateur in Finland. In 1933, he ran his first 1500 m in three years and won the national title with his best time since 1926. At the IAAF meet in August 1934, Finland launched two proposals that lost. The council then brought forward its resolution empowering it to suspend athletes that it finds in violation of the IAAF amateur code. With a 12–5 vote, with many not voting, Nurmi's suspension from international amateur athletics became definite. Less than three weeks later, Nurmi retired from running with a 10,000 m victory in Viipuri on 16 September 1934. Nurmi remained undefeated in the distance throughout his 14-year top-level career. In cross country running, his win streak lasted 19 years.

While active as a runner, Nurmi was known to be secretive about his training methods. Always running alone, he upped his pace and quickly exhausted anyone who was bold enough to join him. Even his club mate Harri Larva had learned little from him. After ending his career, Nurmi became a coach for the Finnish Athletics Federation and trained runners for the 1936 Summer Olympics in Berlin. In 1935, Nurmi along with the entire board of directors quit the federation after a heated 40–38 vote to resume athletic relations with Sweden. However, Nurmi returned to coaching three months later and the Finnish distance runners went on to take three gold medals, three silvers and a bronze at the Games. In 1936, Nurmi also opened a men's clothing store (haberdashery) in Helsinki. It became a popular tourist attraction, and Emil Zátopek was among those who visited the store trying to meet Nurmi. The Finn spent his time in the back room, running another new business venture; construction. As a contractor, Nurmi built forty apartment buildings in Helsinki with about a hundred flats in each. Within five years, he was rated a millionaire. His fiercest rival Ritola ended up living in one of Nurmi's flats, at half price. Nurmi also made money on the stock market, eventually becoming one of Finland's richest people.

In February 1940, during the Winter War between Finland and the Soviet Union, Nurmi returned to the United States with his protégé Taisto Mäki, who had become the first man to run the 10,000 m under 30 minutes, to raise funds and rally support to the Finnish cause. The relief drive, directed by former president Herbert Hoover, included a coast-to-coast tour by Nurmi and Mäki. Hoover welcomed the two as "ambassadors of the greatest sporting nation in the world." While in San Francisco, Nurmi received news that one of his apprentices, 1936 Olympic champion Gunnar Höckert, had been killed in action. Nurmi left for Finland in late April, and later served in the Continuation War in a delivery company and as a trainer in the military staff. Before he was discharged in January 1942, Nurmi was promoted first to a staff sergeant ("ylikersantti") and later to a sergeant first class ("vääpeli").
In 1952, Nurmi was persuaded by Urho Kekkonen, Prime Minister of Finland and former chairman of the Finnish Athletics Federation, to carry the Olympic torch into the Olympic Stadium at the 1952 Summer Olympics in Helsinki. His appearance astonished the spectators, and "Sports Illustrated" wrote that "his celebrated stride was unmistakable to the crowd. When he came into view, waves of sound began to build throughout the stadium, rising to a roar, then to a thunder. When the national teams, assembled in formation on the infield, saw the flowing figure of Nurmi, they broke ranks like excited schoolchildren, dashing toward the edge of the track." After lighting the flame in the Olympic Cauldron, Nurmi passed the torch to his idol Kolehmainen, who lighted the beacon in the tower. In the cancelled 1940 Summer Olympics, Nurmi had been planned to lead a group of fifty Finnish gold medal winners.

Nurmi felt that he got too much credit as an athlete and too little as a businessman, but his interest in running never died. He even returned to the track himself a few times. In 1946, he faced his old rival Edvin Wide in Stockholm in a benefit for the victims of the Greek Civil War. Nurmi ran for the last time on 18 February 1966 at the Madison Square Garden, invited by the New York Athletic Club. In 1962, Nurmi predicted that welfare countries would start to struggle in the distance events: "The higher the standard of living in a country, the weaker the results often are in the events which call for work and trouble. I would like to warn this new generation: 'Do not let this comfortable life make you lazy. Do not let the new means of transport kill your instinct for physical exercise. Too many young people get used to driving in a car even for small distances.'" In 1966, he took the microphone in front of 300 sports club guests and criticised the state of distance running in Finland, reproaching the sports executives as publicity seekers and tourists, and demanding athletes sacrifice everything to accomplish something. Nurmi lived to see the renaissance of Finnish running in the 1970s, led by athletes such as the 1972 Olympic gold medalists Lasse Virén and Pekka Vasala. He had complimented the running style of Virén, and advised Vasala to concentrate on Kipchoge Keino.

Although he accepted an invitation from President Lyndon B. Johnson to revisit the White House in 1964, Nurmi lived a very secluded life until the late 1960s when he began granting some press interviews. On his 70th birthday, Nurmi agreed to an interview for Yle, Finland's national public-broadcasting company, only after learning that President Kekkonen would act as the interviewer. Suffering from health problems, with at least one heart attack, a stroke and failing eyesight, Nurmi at times spoke bitterly about sports, calling it a waste of time compared to science and art. He died in 1973 in Helsinki and was given a state funeral. Kekkonen attended the funeral and praised Nurmi: "People explore the horizons for a successor. But none comes and none will, for his class is extinguished with him." At the request of Nurmi, who enjoyed classical music and played the violin, Konsta Jylhä's "Vaiennut viulu" ("The Silenced Violin") was played during the ceremony. Nurmi's last record fell in 1996; his 1925 world record for the indoor 2000 m lasted as the Finnish national record for 71 years.

Nurmi was married to socialite Sylvi Laaksonen (1907-1968) from 1932 to 1935. Laaksonen, who was not interested in athletics, opposed Nurmi raising their newborn son Matti to be a runner and stated to the Associated Press in 1933, "[H]is concentration on athletics at last forced me to go to the judge for a divorce." Matti Nurmi did become a middle-distance runner, and later a "self-made" businessman. Nurmi's relationship with his son was termed "uneasy". Matti admired his father more as a businessman than as an athlete, and the two never discussed his running career. As a runner, Matti was at his best in the 3000 m, where he equalled his father's time. In the famous race on 11 July 1957 when the "three Olavis" (Salsola, Salonen and Vuorisalo) broke the world record for the 1500 m, Matti Nurmi finished a distant ninth with his personal best, 2.2 seconds slower than his father's world record from 1924. Hollywood actress Maila Nurmi, best known as the horror icon "Vampira", was often referred to as Paavo Nurmi's niece. However, the kinship is not supported by official documents.

Nurmi enjoyed the Finnish sports massage and sauna-bathing traditions, crediting the Finnish sauna for his performances during the Paris heat wave in 1924. He had a versatile diet, although he had practiced vegetarianism between the ages of 15 and 21. Nurmi, who identified as neurasthenic, was known to be "taciturn", "stony-faced" and "stubborn". He was not believed to have had any close friends, but he had occasionally socialized and showed his "sarcastic sense of humour" among the small circles he knew. Acclaimed the biggest sporting figure in the world at his peak, Nurmi was averse to publicity and the media, stating later on his 75th birthday, "[W]orldly fame and reputation are worth less than a rotten lingonberry." French journalist Gabriel Hanot questioned Nurmi's intensive approach to sports and wrote in 1924 that Nurmi "is ever more serious, reserved, concentrated, pessimistic, fanatic. There is such coldness in him and his self-control is so great that never for a moment does he show his feelings." Some contemporary Finns nicknamed him "Suuri vaikenija" (The Great Silent One), and Ron Clarke noted that Nurmi's persona remained a mystery even to Finnish runners and journalists: "Even to them, he was never quite real. He was enigmatic, sphinx-like, a god in a cloud. It was as if he was all the time playing a role in a drama."

Nurmi was more responsive to his fellow athletes than to the media. He exchanged ideas with sprinter Charley Paddock and even trained with his rival Otto Peltzer. Nurmi told Peltzer to forget his opponents: "Conquering yourself is the greatest challenge of an athlete." Nurmi was known to emphasize the importance of psychological strength: "Mind is everything; muscle, pieces of rubber. All that I am, I am because of my mind." Regarding Nurmi's track antics, Peltzer found that "in his impenetrability he was a Buddha gliding on the track. Stopwatch in hand, lap after lap, he ran towards the tape, subject only to the laws of a mathematical table." Marathoner Johnny Kelley, who first met his idol at the 1936 Olympics, said that while Nurmi appeared cold to him at first, the two chatted for quite a while after Nurmi had asked for his name: "He grabbed ahold of me — he was so excited. I couldn't believe it!"

Nurmi's speed and elusive personality led to nicknames such as the "Phantom Finn", the "King of Runners" and "Peerless Paavo", while his mathematical prowess and use of a stopwatch led the press to characterize him as a running machine. One newspaperman dubbed Nurmi "a mechanical Frankenstein created to annihilate time." Phil Cousineau noted that "his own innovation — the tactic of pacing himself with a stopwatch — both inspired and troubled people in an era when the robot was becoming symbolic of the modern soulless human being." Among the popular newspaper rumours about Nurmi was that he had a "freakish heart" with a very low pulse rate. During the debate over his amateur status, Nurmi was joked to have "the lowest heartbeat and the highest asking price of any athlete in the world."

Nurmi broke 22 official world records on distances between 1500 m and 20 km; a record in running. He also set many more unofficial ones for a total of 58. His indoor world records were all unofficial as the IAAF did not ratify indoor records until the 1980s. Nurmi's record for most Olympic gold medals was matched by gymnast Larisa Latynina in 1964, swimmer Mark Spitz in 1972 and fellow track and field athlete Carl Lewis in 1996, and broken by swimmer Michael Phelps in 2008. Nurmi's record for most medals in the Olympic Games stood until Edoardo Mangiarotti won his 13th medal in fencing in 1960. "Time" selected Nurmi as the greatest Olympian of all time in 1996, and IAAF named him among the first twelve athletes to be inducted into the IAAF Hall of Fame in 2012.

Nurmi introduced the "even pace" strategy to running, pacing himself with a stopwatch and spreading his energy uniformly over the race. He reasoned that "when you race against time, you don't have to sprint. Others can't hold the pace if it is steady and hard all through to the tape." Archie Macpherson stated that "with the stopwatch always in his hand, he elevated athletics to a new plane of intelligent application of effort and was the harbinger of the modern scientifically prepared athlete." Nurmi was considered a pioneer also in regards to training; he developed a systematic all-year-round training program that included both long-distance work and interval running. Peter Lovesey wrote in "The Kings of Distance: A Study of Five Great Runners" that Nurmi "accelerated the progress of world records; developed and actually came to personify the analytic approach to running; and he was a profound influence not only in Finland, but throughout the world of athletics. Nurmi, his style, technique and tactics were held to be infallible, and really seemed so, as successive imitators in Finland steadily improved the records." Cordner Nelson, founder of "Track & Field News", credited Nurmi for popularizing running as a spectator sport: "His imprint on the track world was greater than any man’s before or after. He, more than any man, raised track to the glory of a major sport in the eyes of international fans, and they honored him as one of the truly great athletes of all sports.

Nurmi's achievements and training methods inspired future track stars of many generations. Emil Zátopek chanted "I am Nurmi! I am Nurmi!" when he trained as a child, and based his training system on what he was able to find out about Nurmi's methods. Lasse Virén idolized Nurmi and was scheduled to meet him for the first time on the day that Nurmi died. Hicham El Guerrouj was inspired to become a runner so that he could "repeat the achievements of the great man of whom his grandfather spoke." He became the first man after Nurmi to win the 1500 m and the 5000 m at the same Games. Nurmi's influence stretched further than running on the Olympic arena. At the 1928 Olympics, Kazimierz Wierzyński won the lyric gold medal with his poem "Olympic Laurel" that included a verse on Nurmi. In 1936, Ludwig Stubbendorf and his horse "Nurmi" won the individual and team gold medals in eventing.
A bronze statue of Nurmi was sculpted by Wäinö Aaltonen in 1925. The original is held at the art museum Ateneum, but copies cast from the original mould exist in Turku, in Jyväskylä, in front of the Helsinki Olympic Stadium and at the Olympic Museum in Lausanne, Switzerland. In a widely publicized prank by the students of the Helsinki University of Technology, a miniature copy of the statue was discovered from the 300-year-old wreck of the Swedish war ship "Vasa" when it was lifted from the bottom of the sea in 1961. Statues of Nurmi were also sculpted by Renée Sintenis in 1926 and by Carl Eldh, whose 1937 work "Löpare" ("Runners") depicts a battle between Nurmi and Edvin Wide. "Boken om Nurmi" ("The Book about Nurmi"), released in Sweden in 1925, was the first biographical book on a Finnish sportsman. Finnish astronomer Yrjö Väisälä named the main belt asteroid 1740 Paavo Nurmi after Nurmi in 1939, while Finnair named its first DC-8 "Paavo Nurmi" in 1969. Nurmi's former rival Ville Ritola boarded the plane when he moved back to Finland in 1970.

Paavo Nurmi Marathon, held annually since 1969, is the oldest marathon in Wisconsin and the second-oldest in the American Midwest. In Finland, another marathon bearing the name has been held in Nurmi's hometown of Turku since 1992, along with the athletics competition Paavo Nurmi Games that was started in 1957. Finlandia University, an American college with Finnish roots, named their athletic center after Nurmi. A ten-mark bill featuring a portrait of Nurmi was issued by the Bank of Finland in 1987. The other revised bills honored architect Alvar Aalto, composer Jean Sibelius, Enlightenment thinker Anders Chydenius and author Elias Lönnrot, respectively. The Nurmi bill was replaced by a new 20-mark note featuring Väinö Linna in 1993. In 1997, a historic stadium in Turku was renamed the "Paavo Nurmi Stadium". Twenty world records have been set at the stadium, including John Landy's records on the 1500 m and the mile, Nurmi's record on the 3000 m and Zátopek's record on the 10,000 m. In fiction, Nurmi appears in William Goldman's 1974 novel "Marathon Man" as the idol of the protagonist, who aims to become a greater runner than Nurmi. The opera on Nurmi, "Paavo the Great. Great Race. Great Dream.", written by Paavo Haavikko and composed by Tuomas Kantelinen, debuted at the Helsinki Olympic Stadium in 2000. In a 2005 episode of "The Simpsons", Mr. Burns brags that he once outraced Nurmi in his antique motorcar.

The starts figure excludes heats, handicap races, relays, and events where Nurmi raced alone against relay teams.
The starts figure excludes heats, handicap races, relays, and events where Nurmi raced alone against relay teams.



 


</doc>
<doc id="25072" url="https://en.wikipedia.org/wiki?curid=25072" title="Purple Heart">
Purple Heart

The Purple Heart is a United States military decoration awarded in the name of the President to those wounded or killed while serving, on or after April 5, 1917, with the U.S. military. With its forerunner, the Badge of Military Merit, which took the form of a heart made of purple cloth, the Purple Heart is the oldest military award still given to U.S. military members – the only earlier award being the obsolete Fidelity Medallion. The National Purple Heart Hall of Honor is located in New Windsor, New York.

The original blak

On October 10, 1927, Army Chief of Staff General Charles Pelot Summerall directed that a draft bill be sent to Congress "to revive the Badge of Military Merit". The bill was withdrawn and action on the case ceased January 3, 1928, but the office of the Adjutant General was instructed to file all materials collected for possible future use. A number of private interests sought to have the medal re-instituted in the Army; this included the board of directors of the Fort Ticonderoga Museum in Ticonderoga, New York.

On January 7, 1931, Summerall's successor, General Douglas MacArthur, confidentially reopened work on a new design, involving the Washington Commission of Fine Arts. Elizabeth Will, an Army heraldic specialist in the Office of the Quartermaster General, was named to redesign the newly revived medal, which became known as the Purple Heart. Using general specifications provided to her, Will created the design sketch for the present medal of the Purple Heart. The new design, which exhibits a bust and profile of George Washington, was issued on the bicentennial of Washington's birth. Will's obituary, in the edition of February 8, 1975 of "The Washington Post" newspaper, reflects her many contributions to military heraldry.

The Commission of Fine Arts solicited plaster models from three leading sculptors for the medal, selecting that of John R. Sinnock of the Philadelphia Mint in May 1931. By Executive Order of the President of the United States, the Purple Heart was revived on the 200th Anniversary of George Washington's birth, out of respect to his memory and military achievements, by War Department , dated February 22, 1932. 
The criteria were announced in a War Department circular dated February 22, 1932, and authorized award to soldiers, upon their request, who had been awarded the Meritorious Service Citation Certificate, Army Wound Ribbon, or were authorized to wear Wound Chevrons subsequent to April 5, 1917, the day before the United States entered World War I. The first Purple Heart was awarded to MacArthur. During the early period of American involvement in World War II (December 8, 1941 – September 22, 1943), the Purple Heart was awarded both for wounds received in action against the enemy and for meritorious performance of duty. With the establishment of the Legion of Merit, by an Act of Congress, the practice of awarding the Purple Heart for meritorious service was discontinued. By , dated December 3, 1942, the decoration was applied to all services; the order required reasonable uniform application of the regulations for each of the Services. This executive order also authorized the award only for wounds received. For both military and civilian personnel during the World War II era, to meet eligibility for the Purple Heart, AR 600-45, dated September 22, 1943, and May 3, 1944, required identification of circumstances.

After the award was re-authorized in 1932 some U.S. Army wounded from conflicts prior to the first World War applied for, and were awarded, the Purple Heart: "...veterans of the Civil War and Indian Wars, as well as the Spanish–American War, China Relief Expedition (Boxer Rebellion), and Philippine Insurrection also were awarded the Purple Heart. This is because the original regulations governing the award of the Purple Heart, published by the Army in 1932, provided that any soldier who had been wounded in any conflict involving U.S. Army personnel might apply for the new medal. There were but two requirements: the applicant had to be alive at the time of application (no posthumous awards were permitted) and he had to prove that he had received a wound that necessitated treatment by a medical officer."

Subject to approval of the Secretary of Defense, , dated February 12, 1952, revised authorizations to include the Service Secretaries. Dated April 25, 1962, , included provisions for posthumous award of the Purple Heart. Dated February 23, 1984, , authorized award of the Purple Heart as a result of terrorist attacks, or while serving as part of a peacekeeping force, subsequent to March 28, 1973.

On June 13, 1985, the Senate approved an amendment to the 1985 Defense Authorization Bill, which changed the precedence of the Purple Heart award, from immediately above the Good Conduct Medal to immediately above the Meritorious Service Medals. Public Law 99-145 authorized the award for wounds received as a result of friendly fire. Public Law 104-106 expanded the eligibility date, authorizing award of the Purple Heart to a former prisoner of war who was wounded after April 25, 1962. The National Defense Authorization Act for Fiscal Year 1998 (Public Law 105-85) changed the criteria to delete authorization for award of the Purple Heart to any non-military U.S. national serving under competent authority in any capacity with the Armed Forces. This change was effective May 18, 1998.

During World War II, 1,506,000 Purple Heart medals were manufactured, many in anticipation of the estimated casualties resulting from the planned Allied invasion of Japan. By the end of the war, even accounting for medals lost, stolen or wasted, nearly 500,000 remained. To the present date, total combined American military casualties of the seventy years following the end of World War II—including the Korean and Vietnam Wars—have not exceeded that number. In 2000, there remained 120,000 Purple Heart medals in stock. The existing surplus allowed combat units in Iraq and Afghanistan to keep Purple Hearts on-hand for immediate award to soldiers wounded in the field.

The "History" section of the November 2009 edition of "National Geographic" estimated the number of Purple Hearts given. Above the estimates, the text reads, "Any tally of Purple Hearts is an estimate. Awards are often given during conflict; records aren't always exact" (page 33). The estimates are as follows:


August 7 of every year is recognized as "National Purple Heart Day."

The Purple Heart is awarded in the name of the President of the United States to any member of the Armed Forces of the United States who, while serving under competent authority in any capacity with one of the U.S. Armed Services after April 5, 1917, has been wounded or killed. Specific examples of services which warrant the Purple Heart includes:

The two letters c) and e) were added by on April 25, 1962, as U.S. service personnel were being sent to South Vietnam during the Vietnam War as military advisors rather than combatants. As many were being killed or wounded while serving in that capacity in South Vietnam, and because the United States was not formally a participant of the war (until 1965), there was no “enemy” to satisfy the requirement of a wound or death received “in action against an enemy.” In response, President John F. Kennedy signed the executive order that awarded to any person wounded or killed “while serving with friendly foreign forces” or “as a result of action by a hostile foreign force.”

After March 28, 1973, it may be awarded as a result of an international terrorist attack against the United States or a foreign nation friendly to the United States, recognized as such an attack by the Secretary of the Army, or jointly by the Secretaries of the separate armed services concerned if persons from more than one service are wounded in the attack. Also, it may be awarded as a result of military operations while serving outside the territory of the United States as part of a peacekeeping force.

The Purple Heart differs from most other decorations in that an individual is not "recommended" for the decoration; rather he or she is entitled to it upon meeting specific criteria. A Purple Heart is awarded for the first wound suffered under conditions indicated above, but for each subsequent award an oak leaf cluster or 5/16 inch star is worn in lieu of another medal. Not more than one award will be made for more than one wound or injury received at the same instant.

A "wound" is defined as an injury to any part of the body from an outside force or agent sustained under one or more of the conditions listed above. A physical lesion is not required; however, the wound for which the award is made must have required treatment by a medical officer and records of medical treatment for wounds or injuries received in action must have been made a matter of official record. When contemplating an award of this decoration, the key issue that commanders must take into consideration is the degree to which the enemy caused the injury. The fact that the proposed recipient was participating in direct or indirect combat operations is a necessary prerequisite, but is not sole justification for award. The Purple Heart is not awarded for non-combat injuries.

Enemy-related injuries which "justify" the award of the Purple Heart include: injury caused by enemy bullet, shrapnel, or other projectile created by enemy action; injury caused by enemy placed land mine, naval mine, or trap; injury caused by enemy released chemical, biological, or nuclear agent; injury caused by vehicle or aircraft accident resulting from enemy fire; and, concussion injuries caused as a result of enemy generated explosions.

Injuries or wounds which "do not qualify" for award of the Purple Heart include frostbite or trench foot injuries; heat stroke; food poisoning not caused by enemy agents; chemical, biological, or nuclear agents not released by the enemy; battle fatigue; disease not directly caused by enemy agents; accidents, to include explosive, aircraft, vehicular, and other accidental wounding not related to or caused by enemy action; self-inflicted wounds (e.g., a soldier accidentally or intentionally fires their own gun and the bullet strikes his or her leg), except when in the heat of battle, and not involving gross negligence; post-traumatic stress disorders; and jump injuries not caused by enemy action.

It is not intended that such a strict interpretation of the requirement for the wound or injury to be caused by direct result of hostile action be taken that it would preclude the award being made to deserving personnel. Commanders must also take into consideration the circumstances surrounding an injury, even if it appears to meet the criteria. In the case of an individual injured while making a parachute landing from an aircraft that had been brought down by enemy fire; or, an individual injured as a result of a vehicle accident caused by enemy fire, the decision will be made in favor of the individual and the award will be made. As well, individuals wounded or killed as a result of "friendly fire" in the "heat of battle" will be awarded the Purple Heart as long as the "friendly" projectile or agent was released with the full intent of inflicting damage or destroying enemy troops or equipment. Individuals injured as a result of their own negligence, such as by driving or walking through an unauthorized area known to have been mined or placed off limits or searching for or picking up unexploded munitions as war souvenirs, will not be awarded the Purple Heart as they clearly were not injured as a result of enemy action, but rather by their own negligence.

Animals are generally not eligible for the Purple Heart; however, there have been rare instances when animals holding military rank were honored with the award. An example includes the horse Sergeant Reckless during the Korean War.

From 1942 to 1997, non-military personnel serving or closely affiliated with the armed forces—as government employees, Red Cross workers, war correspondents, and the like—were eligible to receive the Purple Heart whether in peacetime or armed conflicts. Among the earliest to receive the award were nine Honolulu Fire Department (HFD) firefighters killed or wounded in peacetime while fighting fires at Hickam Field during the attack on Pearl Harbor. About 100 men and women received the award, the most famous being newspaperman Ernie Pyle who was awarded a Purple Heart posthumously by the Army after being killed by Japanese machine gun fire in the Pacific Theater, near the end of World War II. Before his death, Pyle had seen and experienced combat in the European Theater, while accompanying and writing about infantrymen for the folks back home. Those serving in the Merchant Marine are not eligible for the award. During World War II, members of this service who met the Purple Heart criteria received a Merchant Marine Mariner's Medal instead.

The most recent Purple Hearts presented to non-military personnel occurred after the terrorist attacks at Khobar Towers, Saudi Arabia, in 1996—for their injuries, about 40 U.S. civil service employees received the award.

However, in 1997, at the urging of the Military Order of the Purple Heart, Congress passed legislation prohibiting future awards of the Purple Heart to non-military personnel. Civilian employees of the U.S. Department of Defense who are killed or wounded as a result of hostile action may receive the new Defense of Freedom Medal. This award was created shortly after the terrorist attacks of September 11, 2001.

The Purple Heart award is a heart-shaped medal within a gold border, wide, containing a profile of General George Washington. Above the heart appears a shield of the coat of arms of George Washington (a white shield with two red bars and three red stars in chief) between sprays of green leaves. The reverse consists of a raised bronze heart with the words below the coat of arms and leaves.

The ribbon is wide and consists of the following stripes: white 67101; purple 67115; and white 67101.

Additional awards of the Purple Heart are denoted by oak leaf clusters in the Army and Air Force, and additional awards of the Purple Heart Medal are denoted by inch stars in the Navy, Marine Corps, and Coast Guard.

Current active duty personnel are awarded the Purple Heart upon recommendation from their chain of command, stating the injury that was received and the action in which the service member was wounded. The award authority for the Purple Heart is normally at the level of an Army Brigade, Marine Corps Division, Air Force Wing, or Navy Task Force. While the award of the Purple Heart is considered automatic for all wounds received in combat, each award presentation must still be reviewed to ensure that the wounds received were as a result of enemy action. Modern day Purple Heart presentations are recorded in both hardcopy and electronic service records. The annotation of the Purple Heart is denoted both with the service member's parent command and at the headquarters of the military service department. An original citation and award certificate are presented to the service member and filed in the field service record.

During the Vietnam War, Korean War, and World War II, the Purple Heart was often awarded on the spot, with occasional entries made into service records. In addition, during mass demobilizations following each of America's major wars of the 20th century, it was common occurrence to omit mention from service records of a Purple Heart award. This occurred due to clerical errors, and became problematic once a service record was closed upon discharge. In terms of keeping accurate records, it was commonplace for some field commanders to engage in bedside presentations of the Purple Heart. This typically entailed a general entering a hospital with a box of Purple Hearts, pinning them on the pillows of wounded service members, then departing with no official records kept of the visit, or the award of the Purple Heart. Service members, themselves, complicated matters by unofficially leaving hospitals, hastily returning to their units to rejoin battle so as to not appear a malingerer. In such cases, even if a service member had received actual wounds in combat, both the award of the Purple Heart, as well as the entire visit to the hospital, was unrecorded in official records.

Service members requesting retroactive awards of the Purple Heart must normally apply through the National Personnel Records Center. Following a review of service records, qualified Army members are awarded the Purple Heart by the U.S. Army Human Resources Command in Fort Knox, Kentucky. Air Force veterans are awarded the Purple Heart by the Awards Office of Randolph Air Force Base, while Navy, Marine Corps, and Coast Guard, present Purple Hearts to veterans through the Navy Liaison Officer at the National Personnel Records Center. Simple clerical errors, where a Purple Heart is denoted in military records, but was simply omitted from a (WD AGO Form 53-55 (predecessor to the) DD Form 214 (Report of Separation), are corrected on site at the National Personnel Records Center through issuance of a DD-215 document.

Because the Purple Heart did not exist prior to 1932, decoration records are not annotated in the service histories of veterans wounded, or killed, by enemy action, prior to establishment of the medal. The Purple Heart is, however, retroactive to 1917 meaning it may be presented to veterans as far back as the First World War. Prior to 2006, service departments would review all available records, including older service records, and service histories, to determine if a veteran warranted a retroactive Purple Heart. As of 2008, such records are listed as "Archival", by the National Archives and Records Administration, meaning they have been transferred from the custody of the military, and can no longer be loaned and transferred for retroactive medals determination. In such cases, requestors asking for a Purple Heart (especially from records of the First World War) are provided with a complete copy of all available records (or reconstructed records in the case of the 1973 fire) and advised the Purple Heart may be privately purchased if the requestor feels it is warranted.

A clause to the archival procedures was revised in mid-2008, where if a veteran, or, if deceased, an immediate member of the family, requested the Purple Heart, on an Army or Air Force record, the medal could still be granted by the National Archives. In such cases, where a determination was required made by the military service department, photocopies of the archival record, (but not the record itself), would be forwarded to the headquarters of the military branch in question. This stipulation was granted only for the Air Force and Army; Marine Corps, Navy, and Coast Guard archival medals requests are still typically only offered a copy of the file and told to purchase the medal privately. For requests directly received from veterans, these are routed through a Navy Liaison Office, on site at 9700 Page Avenue, St. Louis, MO 63132-5100 (the location of the Military Personnel Records Center).

Due to the 1973 National Archives Fire, many retroactive Purple Heart requests are difficult to verify because all records to substantiate the award may have been destroyed. As a solution to deal with Purple Heart requests, where service records were destroyed in the 1973 fire, the National Personnel Records Center maintains a separate office. In such cases, NPRC searches through unit records, military pay records, and records of the Department of Veterans Affairs. If a Purple Heart is warranted, all available alternate records sources are forwarded to the military service department for final determination of issuance.

The loaning of fire related records to the military has declined since 2006 because many such records now fall into the "archival records" category of military service records. This means the records were transferred from the military to the National Archives, and in such cases, the Purple Heart may be privately purchased by the requestor (see above section of retroactive requests for further details) but is no longer provided by the military service department.

Ten Purple Hearts:

Nine Purple Hearts:

Eight Purple Hearts:





</doc>
<doc id="25073" url="https://en.wikipedia.org/wiki?curid=25073" title="Polyatomic ion">
Polyatomic ion

A molecular ion, is a charged chemical species (ion) composed of two or more atoms covalently bonded or of a metal complex that can be considered to be acting as a single unit. The prefix "poly-" means "many," in Greek, but even ions of two atoms are commonly referred to as polyatomic. In older literature, a polyatomic ion is also referred to as a radical, and less commonly, as a radical group. In contemporary usage, the term radical refers to free radicals that are (not necessarily charged) species with an unpaired electron.

An example of a polyatomic ion is the hydroxide ion; consisting of one oxygen atom and one hydrogen atom, hydroxide has a charge of −1. Its chemical formula is . An ammonium ion consists of one nitrogen atom and four hydrogen atoms: it has a charge of +1, and its chemical formula is .

Polyatomic ions are often useful in the context of acid-base chemistry or in the formation of salts. A polyatomic ion can often be considered as the conjugate acid or base of a neutral molecule. For example, the conjugate base of sulfuric acid (HSO) is the polyatomic hydrogen sulfate anion (). The removal of another hydrogen ion yields the sulfate anion ().

There are two "rules" that can be used for learning the nomenclature of polyatomic anions. First, when the prefix "bi" is added to a name, a hydrogen is added to the ion's formula and its charge is increased by 1, the latter being a consequence of the hydrogen ion's +1 charge. An alternative to the "bi-" prefix is to use the word hydrogen in its place: the anion derived from + , , can be called either bicarbonate or hydrogencarbonate.

Most of the common polyatomic anions are oxyanions, conjugate bases of oxyacids (acids derived from the oxides of non-metallic elements). For example, the sulfate anion, , is derived from , which can be regarded as + .

The second rule looks at the number of oxygens in an ion. Consider the chlorine oxyanion family:
First, think of the "-ate" ion as being the "base" name, in which case the addition of a "per-" prefix adds an oxygen. Changing the "-ate" suffix to "-ite" will reduce the oxygens by one, and keeping the suffix "-ite" and adding the prefix "hypo-" reduces the number of oxygens by one more. In all situations, the charge is not affected. The naming pattern follows within many different oxyanion series based on a standard root for that particular series. The "-ite" has one less oxygen than the "-ate", but different "-ate" anions might have different numbers of oxygen atoms.

These rules do not work with all polyatomic anions, but they do work with the most common ones. Following table give examples for some of these common anion groups.

The following tables give additional examples of commonly encountered polyatomic ions. Only a few representatives are given, as the number of polyatomic ions encountered in practice is very large.




</doc>
<doc id="25074" url="https://en.wikipedia.org/wiki?curid=25074" title="Persecution of Christians">
Persecution of Christians

The persecution of Christians can be historically traced from the first century of the Christian era to the present day. Early Christians were persecuted for their faith at the hands of both the Jews from whose religion Christianity arose and the Romans who controlled many of the lands across which early Christianity was spread. Early in the fourth century, a form of the religion was legalized by the Edict of Milan, and it eventually became the State church of the Roman Empire.

Christian missionaries as well as converts to Christianity have been the target of persecution ever since the emergence of Christianity, sometimes to the point of being martyred for their faith.

The schisms of the Middle Ages and especially the Protestant Reformation, sometimes provoked severe conflicts between Christian denominations to the point of persecuting each other.

In the 20th century, Christians were persecuted by various governments including the Ottoman Empire in the form of the Armenian Genocide, the Assyrian Genocide and the Greek Genocide, as well as by atheistic states such as the Soviet Union, Communist Albania and North Korea.

Early Christianity began as a sect among Second Temple Jews, and according to the New Testament account, Pharisees, including Paul of Tarsus prior to his conversion to Christianity, persecuted early Christians. The early Christians preached the second coming of a Messiah which did not conform to their religious teachings. However, feeling that their beliefs were supported by Jewish scripture, Christians had been hopeful that their countrymen would accept their faith. Despite individual conversions, the vast majority of Judean Jews did not become Christians.

Claudia Setzer asserts that, "Jews did not see Christians as clearly separate from their own community until at least the middle of the second century." Thus, acts of Jewish persecution of Christians fall within the boundaries of synagogue discipline and were so perceived by Jews acting and thinking as the established community. The Christians, on the other hand, saw themselves as persecuted rather than "disciplined."
Inter-communal dissension began almost immediately with the teachings of Stephen at Jerusalem, who was considered an apostate. According to the Acts of the Apostles, a year after the Crucifixion of Jesus, Stephen was stoned for his alleged transgression of the faith, with Saul (who later converted and was renamed "Paul") looking on.

In 41 AD, when Agrippa I, who already possessed the territory of Antipas and Phillip, obtained the title of "King of the Jews", in a sense re-forming the Kingdom of Herod, he was reportedly eager to endear himself to his Jewish subjects and continued the persecution in which James the Greater lost his life, Peter narrowly escaped and the rest of the apostles took flight.

After Agrippa's death, the Roman procuratorship began (before 41 they were Prefects in Iudaea Province) and those leaders maintained a neutral peace, until the procurator Festus died and the high priest Annas II took advantage of the power vacuum to attack the Church and executed James the Just, then leader of Jerusalem's Christians. The New Testament states that Paul was himself imprisoned on several occasions by the Roman authorities, stoned by the Pharisees and left for dead on one occasion, and was eventually taken to Rome as a prisoner. Peter and other early Christians were also imprisoned, beaten and harassed. The great Jewish revolt, spurred by the Roman killing of 3,000 Jews, led to the destruction of Jerusalem in 70 AD, the end of Second Temple Judaism (and the subsequent slow rise of Rabbinic Judaism ), and the disempowering of the Jewish persecutors. According to an old church tradition, which is mostly doubted by historians, the early Christian community had fled Jerusalem beforehand, to the already pacified region of Pella.

Luke T. Johnson nuances the harsh portrayal of the Jews in the Gospels by contextualizing the polemics within the rhetoric of contemporaneous philosophical debate, showing how rival schools of thought routinely insulted and slandered their opponents. These attacks were formulaic and stereotyped, crafted to define who was the enemy in the debates, but not used with the expectation that their insults and accusations would be taken literally, as they would be centuries later, resulting in millennia of Christian antisemitism.

By the 4th century, John Chrysostom argued that the Pharisees alone, not the Romans, were responsible for the murder of Jesus. However, according to Walter Laqueur, "Absolving Pilate from guilt may have been connected with the missionary activities of early Christianity in Rome and the desire not to antagonize those they want to convert."

The first documented case of imperially supervised persecution of Christians in the Roman Empire begins with Nero (54–68). In 64 AD, a great fire broke out in Rome, destroying portions of the city and economically devastating the Roman population. Some people suspected that Nero himself was the arsonist, as Suetonius reported, claiming that he played the lyre and sang the 'Sack of Ilium' during the fires. In the "Annals" of Tacitus, we read: This passage in Tacitus constitutes the only independent attestation that Nero blamed Christians for the Great Fire of Rome, and while it is generally believed to be authentic and reliable, some modern scholars have cast doubt on this view, largely because there is no further reference to Nero's blaming of Christians for the fire until the late 4th century. Suetonius, later to the period, does not mention any persecution after the fire, but in a previous paragraph unrelated to the fire, mentions punishments inflicted on Christians, defined as men following a new and malefic superstition. Suetonius, however, does not specify the reasons for the punishment; he simply lists the fact together with other abuses put down by Nero.

In the first two centuries Christianity was a relatively small sect which was not a significant concern of the Emperor. The Church was not in a struggle for its existence during its first centuries, before its adoption by the Roman Empire as its national religion. Persecutions of Christians were sporadic and locally inspired.

One traditional account of killing is the Persecution in Lyon in which Christians were purportedly mass-slaughtered by being thrown to wild beasts under the decree of Roman officials for reportedly refusing to renounce their faith according to St. Irenaeus. The sole source for this event is early Christian historian Eusebius of Caesarea's "Church History", an account written in Egypt in the 4th century. Tertullian's "Apologeticus" of 197 was ostensibly written in defense of persecuted Christians and was addressed to Roman governors.

Trajan's policy towards Christians was no different from the treatment of other sects, that is, they would only be punished if they refused to worship the emperor and the gods, but they were not to be sought out. The "edict of Septimius Severus" touted in the Augustan History is considered unreliable by historians. According to Eusebius, the Imperial household of Maximinus' predecessor, Alexander, had contained many Christians. Eusebius states that, hating his predecessor's household, Maximinus ordered that the leaders of the churches should be put to death. According to Eusebius, this persecution of 235 sent Hippolytus of Rome and Pope Pontian into exile but other evidence suggests that the persecutions of 235 were local to the provinces where they occurred rather than happening under the direction of the Emperor.

Under the reign of Emperor Decius, a decree was issued requiring public sacrifice, a formality equivalent to a testimonial of allegiance to the Emperor and the established order. Decius authorized roving commissions visiting the cities and villages to supervise the execution of the sacrifices and to deliver written certificates to all citizens who performed them. Christians were often given opportunities to avoid further punishment by publicly offering sacrifices or by burning incense to Roman gods, and were accused by the Romans of impiety when they refused. Refusal was punished by arrest, imprisonment, torture, and executions. Christians fled to safe havens in the countryside and some purchased their certificates, called "libelli." Several councils held at Carthage debated the extent to which the community should accept these lapsed Christians. 
The Christian church, despite no indication in the surviving texts that the edict targeted any specific group, never forgot the reign of Decius whom they labelled as that "fierce tyrant".

Some early Christians sought out and welcomed martyrdom. Roman authorities tried hard to avoid Christians because they "goaded, chided, belittled and insulted the crowds until they demanded their death."

According to Droge and Tabor, "in 185 the proconsul of Asia, Arrius Antoninus, was approached by a group of Christians demanding to be executed. The proconsul obliged some of them and then sent the rest away, saying that if they wanted to kill themselves there was plenty of rope available or cliffs they could jump off." Such seeking after death is found in Tertullian's "Scorpiace" and in the letters of Saint Ignatius of Antioch but was not the only view of martyrdom in the early Christian church. The 2nd-century text "Martyrdom of Polycarp" relates the story of Polycarp, bishop of Smyrna, who did not desire death, but died a martyr, bound and burned at the stake, then stabbed when the fire miraculously failed to touch him. The "Martyrdom of Polycarp" advances an argument for a particular understanding of martyrdom, with Polycarp's death as its prized example. The example of the Phrygian Quintus, who actively sought out martyrdom, is repudiated.

According to two different Christian traditions, Simon bar Kokhba, the leader of the second Jewish revolt against Rome (132–136 AD) who was proclaimed Messiah, persecuted the Christians: Justin Martyr claims that Christians were punished if they did not deny and blaspheme Jesus Christ, while Eusebius asserts that Bar Kokhba harassed them because they refused to join his revolt against the Romans. The latter is likely true, and Christians' refusal to take part in the revolt against the Roman Empire was a key event in the schism of Early Christianity and Judaism.

These persecutions culminated with the reign of Diocletian and Galerius at the end of the third century and the beginning of the 4th century. The Great Persecution is considered the largest. Beginning with a series of four edicts banning Christian practices and ordering the imprisonment of Christian clergy, the persecution intensified until all Christians in the empire were commanded to sacrifice to the Roman gods or face immediate execution. According to legend, one of the martyrs during the Diocletian persecution was Saint George, a Roman soldier who loudly renounced the Emperor's edict, and in front of his fellow soldiers and tribunes claimed to be a Christian by declaring his worship of Jesus Christ. Though Diocletian zealously persecuted Christians in the Eastern part of the empire, his co-emperors in the West did not follow the edicts so Christians in Gaul, Spain, and Britannia were virtually unmolested.

This persecution lasted until Constantine I came to power in 313 and legalized Christianity. It was not until Theodosius I in the later 4th century that Christianity would become the official religion of the Empire. Between these two events Julian II temporarily restored the traditional Roman religion and established broad religious tolerance renewing Pagan and Christian hostilities.

Martyrs were considered uniquely exemplary of the Christian faith, and few early saints were not also martyrs.

The "New Catholic Encyclopedia" states that "Ancient, medieval and early modern hagiographers were inclined to exaggerate the number of martyrs. Since the title of martyr is the highest title to which a Christian can aspire, this tendency is natural". Attempts at estimating the numbers involved are inevitably based on inadequate sources, but one historian of the persecutions estimates the overall numbers as between 5,500 and 6,500., a number also adopted by later writers including Yuval Noah Harari: In the 300 years from the crucifixion of Christ to the conversion of Emperor Constantine, polytheistic Roman emperors initiated no more than four general persecutions of Christians. Local administrators and governors incited some anti-Christian violence of their own. Still, if we combine all the victims of all these persecutions, it turns out that in these three centuries, the polytheistic Romans killed no more than a few thousand Christians.

The Sassanian policy shifted from tolerance of other religions under Shapur I to intolerance under Vahrans and apparently a return to the policy of Shapur until the reign of Shapur II. The persecution at that time was initiated by Constantine's conversion to Christianity which followed that of Armenian king Tiridates in about 301 A.D. The Christians were thus viewed with suspicions of secretly being partisans of Roman Empire. This didn't change until the fifth century when the Nestorian Church broke off from the Church of Antioch. 
Zoroastrian elites continued viewing the Christians with enmity and distrust throughout the fifth century with threat of persecution remaining significant, especially during war against the Romans.

Kartir in his "Kaba'yi Zartust" inscription dated about 280, refers to persecution ("zatan" – "to beat, kill") of Christians ("Nazareans "n'zl'y" and Christians "klstyd'n""). Kartir took Christianity as a serious opponent. The use of the double expression may be indicative of the Greek-speaking Christians deported by Shapur I from Antioch and other cities during his war against the Romans. Constantine's efforts to protect the Persian Christians made them a target of accusations of disloyalty to Sasanians. With the resumption of Roman-Sasanian conflict under Constantius II, the Christian position became untenable. Zoroastrian priests targeted clergy and ascetics of local Christians to eliminate the leaders of the church. A Syriac manuscript in Edessa in 411 documents dozens executed in various parts of western Sasanian Empire.

In 341, Shapur II ordered the persecution of all Christians. In response to their subversive attitude and support of Romans, Shahpur II doubled the tax on Christians. Shemon Bar Sabbae informed him that he could not pay the taxes demanded from him and his community. He was martyred and a forty-year-long period of persecution of Christians began. The Council of Seleucia-Ctesiphon gave up choosing bishops since it would result in death. The local mobads with the help of satraps organized slaughters of Christians in Adiabene, Beth Garmae, Khuzistan and many other provinces.

Yazdegerd I showed tolerance towards Jews and Christians for much of his rule. He allowed Christians to practice their religion freely, demolished monasteries and churches were rebuilt and missionaries were allowed to operate freely. He reversed his policies during the later part of his reign however, suppressing missionary activities. Bahram V continued and intensified their persecution, resulting in many of them fleeing to the Byzantine Empire. Bahram demanded their return, sparking a war between the two. The war ended in 422 with agreement of freedom of religion for Christians in Iran with that of Mazdaism in Byzantium. Meanwhile, Christians suffered destruction of churches,
renounced the faith, had their private property confiscated and many were expelled.

Shah Yazdegerd II (439–457) had ordered all his subjects to embrace Mazdeism in an attempt to unite his empire ideologically. The Caucasus rebelled to defend Christianity which had become integrated in their local culture, with Armenian aristocrats turning to the Romans for help. The rebels were however defeated in a battle on the Avaryr Plain. Yeghishe in his "The History of Vardan and the Armenian War", pays a tribute to the battles waged to defend Christianity. Another revolt was waged from 481–483 which was suppressed. However, the Armenians succeeded in gaining freedom of religion among other improvements.

Accounts of executions for apostasy of Zoroastrians who converted to Christianity during Sasanian rule proliferated from the fifth to early seventh century, and continued to be produced even after collapse of Sasanians. The punishment of apostates increased under Yazdegerd I and continued under successive kings. It was normative for apostates who were brought to the notice of authorities to be executed, although the prosecution of apostasy depended on political circumstances and Zoroastrian jurisprudence. Per Richard E. Payne, the executions were meant to create a mutually recognised boundary between interactions of the people of the two religions and preventing one religion challenging another's viability. Although the violence on Christians was selective and especially carried out on elites, it served to keep Christian communities in a subordinate and yet viable position in relation to Zoroastrianism. Christians were allowed to build religious buildings and serve in the government as long as they didn't expand their institutions and population at the expense of Zoroastrianism.

Khosrow I was generally regarded as tolerant of Christians and interested in the philosophical and theological disputes during his reign. Sebeos claimed he had converted to Christianity on his deathbed. John of Ephesus describes an Armenian revolt where he claims that Khusrow had attempted to impose Zoroastrianism in Armenia. The account, however, is very similar to the one of Armenian revolt of 451. In addition, Sebeos doesn't mention any religious persecution in his account of the revolt of 571. Story about Hormizd IV's tolerance is preserved by the historian al-Tabari. Upon being asked why he tolerated Christians, he replied, "Just as our royal throne cannot stand upon its front legs without its two back ones, our kingdom cannot stand or endure firmly if we cause the Christians and adherents of other faiths, who differ in belief from ourselves, to become hostile to us."

In AD 516, a tribal unrest broke out in Yemen and several tribal elites fought for power. One of those elites was Joseph Dhu Nuwas or "Yousef Asa'ar", a Jewish warlord mentioned in ancient south Arabian inscriptions. Syriac and Byzantine sources claim that he fought his war because Christians in Yemen refused to renounce Christianity. In 2009, a documentary that aired on the BBC defended the claim that the villagers had been offered the choice between conversion to Judaism or death and that 20,000 Christians were then massacred stating that "The production team spoke to many historians over 18 months, among them Nigel Groom, who was our consultant, and Professor Abdul Rahman Al-Ansary, a former professor of archaeology at the King Saud University in Riyadh." Inscriptions documented by Yousef himself show the great pride that he expressed after killing more than 22,000 Christians in Zafar and Najran. Historian Glen Bowersock described this as a "savage pogrom that the Jewish king of the Arabs launched against the Christians in the city of Najran. The king himself reported in excruciating detail to his Arab and Persian allies about the massacres that he had inflicted on all Christians who refused to convert to Judaism."

In the 4th century, the Terving king Athanaric in ca. 375 ordered a persecution of Christians.

The Protestant Reformation provoked a number of persecutions of Christians by other Christians, including false allegations of witchcraft.

Several months after the Persian conquest in AD 614, a riot occurred in Jerusalem, and the Jewish governor of Jerusalem Nehemiah was killed by a band of young Christians along with his "council of the righteous" while he was making plans for the building of the Third Temple. At this time the Christians had allied themselves with the Eastern Roman Empire. Shortly afterward, the events escalated into a full-scale Christian rebellion, resulting in a battle against the Jews and Christians who were living in Jerusalem. In the battle's aftermath, many Jews were killed and the survivors fled to Caesarea, which was still being held by the Persian Army.

The Judeo-Persian reaction was ruthless—Persian Sasanian general Xorheam assembled Judeo-Persian troops and went and encamped around Jerusalem and besieged it for 19 days. Eventually, digging beneath the foundations of the Jerusalem, they destroyed the wall and on the 19th day of the siege, the Judeo-Persian forces took Jerusalem.

According to the account of Sebeos, the siege resulted in a total Christian death toll of 17,000, the earliest and thus most commonly accepted figure. Per Antiochus, 4,518 prisoners alone were massacred near Mamilla reservoir. A cave containing hundreds of skeletons near the Jaffa Gate, 200 metres east of the large Roman-era pool in Mamilla, correlates with the massacre of Christians at hands of the Persians mentioned by Antiochius Strategius. While reinforcing the evidence of massacre of Christians, the archaeological evidence seem less conclusive on the destruction of Christian churches and monasteries in Jerusalem.

According to the later account of Antiochus Strategos, whose perspective appears to be that of a Byzantine Greek and shows an antipathy towards the Jews, thousands of Christians were massacred during the conquest of the city. Estimates based on varying copies of Strategos's manuscripts range from 4,518 to 66,509 killed. Strategos wrote that the Jews offered to help them escape death if they "become Jews and deny Christ", and the Christian captives refused. In anger the Jews allegedly purchased Christians to kill them. In 1989, a mass burial grave at Mamilla cave was discovered in by Israeli archeologist Ronny Reich, near the site where Antiochus recorded the massacre took place. The human remains were in poor condition containing a minimum of 526 individuals.

From the many excavations carried out in the Galilee, it is clear that all churches had been destroyed during the period between the Persian invasion and the Arab conquest in 637. The church at Shave Ziyyon was destroyed and burnt in 614. Similar fate befell churches at Evron, Nahariya, 'Arabe and monastery of Shelomi. The monastery at Kursi was damaged in the invasion.

At the time of the Arab Islamic conquest of the mid 7th century AD the populations of Mesopotamia and Assyria (modern-day Iraq, north east Syria, south east Turkey and Kuwait), Syria, Phoenicia (modern-day Lebanon and coastal Syria), Egypt, Jordan, North Africa (modern-day Sudan, Tunisia, Morocco, Libya and Algeria), Asia Minor (modern-day Turkey) and Armenia were predominantly Christian and non-Arab.

As People of the Book Christians were given dhimmi status (along with Jews, Samaritans, Gnostics and Mandeans), which was inferior to the status of Muslims. Christians thus faced Religious discrimination and Religious persecution in that they were banned from proselytising (spreading or promoting Christianity) in lands conquered by the Muslims on pain of death, they were banned from bearing arms and undertaking certain professions. Under sharia, non-Muslims were obligated to pay jizya and al-kharaj taxes, together with periodic heavy ransom levied upon Christian communities by Muslim rulers in order to fund military campaigns, all of which contributed a significant proportion of income to the Islamic states while conversely reducing many Christians to poverty, and these financial and social hardships forced many Christians to convert to Islam. Christians unable to pay these taxes were forced to surrender their children to the Muslim rulers as payment who would sell them as slaves to Muslim households where they were forced into Islam According to the Hanafi school of sharia, the testimony of a non-Muslim (such as a Christian) was not considered valid against the testimony of a Muslim in legal or civil matters. Islamic law forbid Muslim women from marrying Christian men, but Muslim men were permitted to marry Christian women.
Christians under Islamic rule had the right to convert to Islam or any other religion, while conversely a murtad, or an apostate from Islam, faced severe penalties or even hadd, which could include the death penalty. In general, Christians subject to Islamic rule were allowed to practice their religion with some notable limitations stemming from the Pact of Umar. This treaty, enacted in 717 AD, forbade Christians from publicly displaying the cross on church buildings, from summoning congregants to prayer with a bell, from re-building or repairing churches and monasteries after they had been destroyed or damaged, and imposed other restrictions relating to occupations, clothing and weapons. The Umayyad Caliphate persecuted many Berber Christians in the seventh and eighth centuries, who slowly converted to Islam.

Native Christian communities are subject to persecution in several Muslim-majority countries such as Egypt. Pakistan,

Tamerlane instigated large scale massacres of Christians in Mesopotamia, Persia, Asia Minor and Syria in the 14th century AD. Most of the victims were indigenous Assyrians and Armenians, members of the Assyrian Church of the East and Orthodox Churches, which led to the decimation of the hitherto majority Assyrian population in northern Mesopotamia and the abandonment of the ancient Assyrian city of Assur. Other massacres were perpetrated by Helugu Khan against the Assyrians, particularly in and around the ancient Assyrian city of Arbela (modern Erbil).
Before the late 16th century, Albania, despite being under Ottoman rule, had remained overwhelmingly Christian, unlike other regions such as Bosnia, Bulgaria and Northern Greece, and mountainous Albania was a frequent site of revolts against the Ottoman Empire, often incurring enormous human costs such as the decimation of entire villages. To handle this problem, the Ottomans their usual policy of toleration of Christians as second class citizens to one aimed at reducing the Christian population through Islamization, beginning in restive Christian regions of Reka and Elbasan in 1570. The pressures associated with this campaign included particularly harsh economic conditions opposed on the Christian population; while earlier taxes on the Christian were around 45 "akçes" a year, by the middle of the 17th century the rate had been multiplied by 27 to 780 "akçes" a year. Albanian elders often opted to save their clans and villages from hunger and economic ruin by advocating village-wide and region-wide conversions to Islam, with many individuals often continuing to practice Christianity in private. A failed Catholic rebellion in 1596 as well as the support by the Albanian population for Austro-Hungary in the Great Turkish War, and the Venetians in the 1644 Venetian-Ottoman War as well as the Orlov Revolt were all factors that led to punitive measures mixing outright force with economic incentives depending on the region, and ended up forcing the conversion of large Christian populations to Islam in Albania. In the case of the Great Turkish War, in the aftermath, massive punitive measures resulted in the flight of most of Kosovo's Catholic Albanian population into Hungary around Budapest, where most died of disease and starvation. After the Orthodox Serbian population subsequently also fled from Kosovo, the pasha of Ipek (Peja/Pec) forced Albanian Catholic mountaineers to repopulate Kosovo by deporting them to Kosovo, and also forced them adopt Islam. In the 17th and 18th centuries, South Albania also saw numerous instances of violence directed by local newly converted Muslims against those who remained Christian, ultimately resulting in many more conversions out of fear as well as flight by the Christian population to faraway lands.

The Dechristianisation of France during the French Revolution is a conventional description of a campaign, conducted by various Robespierre-era governments of France beginning with the start of the French Revolution in 1789, to eliminate any symbol that might be associated with the past, especially the monarchy.

The program included the following policies:

The climax was reached with the celebration of the Goddess "Reason" in Notre Dame Cathedral on 10 November.

Under threat of death, imprisonment, military conscription or loss of income, about 20,000 constitutional priests were forced to abdicate or hand over their letters of ordination and 6,000 – 9,000 were coerced to marry, many ceasing their ministerial duties. Some of those who abdicated covertly ministered to the people. By the end of the decade, approximately 30,000 priests were forced to leave France, and thousands who did not leave were executed. Most of France was left without the services of a priest, deprived of the sacraments and any nonjuring priest faced the guillotine or deportation to French Guiana.

The March 1793 conscription requiring Vendeans to fill their district's quota of 300,000 enraged the populace, who took up arms as "The Catholic Army", "Royal" being added later, and fought for "above all the reopening of their parish churches with their former priests." 
With these massacres came formal orders for forced evacuation; also, a 'scorched earth' policy was initiated: farms were destroyed, crops and forests burned and villages razed. There were many reported atrocities and a campaign of mass killing universally targeted at residents of the Vendée regardless of combatant status, political affiliation, age or gender. By July 1796, the estimated Vendean dead numbered between 117,000 and 500,000, out of a population of around 800,000. Some historians call these mass killings the first modern genocide, specifically because intent to exterminate the Catholic Vendeans was clearly stated, though others have rejected these claims.

Beginning in the late 17th century, Christianity was banned for at least a century in China by the Kangxi Emperor of the Qing dynasty after Pope Clement XI forbade Chinese Catholics from venerating their relatives or Confucius.

During the Boxer Rebellion, Muslim unit Kansu Braves serving in the Chinese army attacked Christians.

During the Northern Expedition, the Kuomintang incited anti-foreign, anti-Western sentiment. Portraits of Sun Yat-sen replaced the crucifix in several churches, KMT posters proclaimed "Jesus Christ is dead. Why not worship something alive such as Nationalism?". Foreign missionaries were attacked and anti-foreign riots broke out. In 1926, Muslim General Bai Chongxi attempted to drive out foreigners in Guangxi, attacking American, European, and other foreigners and missionaries, and generally making the province unsafe for foreigners. Westerners fled from the province, and some Chinese Christians were also attacked as imperialist agents.

From 1894 to 1938, there were many Uighur Muslim converts to Christianity. They were killed, tortured and jailed. Christian missionaries were expelled.

Relations between Muslims and Christians have occasionally been turbulent. With the advent of European colonialism in India throughout the 16th, 17th and 18th centuries, Christians were systematically persecuted in a few Muslim ruled kingdoms in India. Modern-day persecution also exists and is carried out by Hindu nationalists. A report by Human Rights Watch stated that there is a rise in anti-Christian violence due to Hindu nationalism and Smita Narula, Researcher, Asia Division of Human Rights Watch stated "Christians are the new scapegoat in India's political battles. Without immediate and decisive action by the government, communal tensions will continue to be exploited for political and economic ends."

Muslim Tipu Sultan, the ruler of the Kingdom of Mysore, took action against the Mangalorean Catholic community from Mangalore and the South Canara district on the southwestern coast of India. Tipu was widely reputed to be anti-Christian. He took Mangalorean Catholics into captivity at Seringapatam on 24 February 1784 and released them on 4 May 1799.

Soon after the Treaty of Mangalore in 1784, Tipu gained control of Canara. He issued orders to seize the Christians in Canara, confiscate their estates, and deport them to Seringapatam, the capital of his empire, through the Jamalabad fort route. There were no priests among the captives. Together with Fr. Miranda, all the 21 arrested priests were issued orders of expulsion to Goa, fined Rs 2 lakhs, and threatened death by hanging if they ever returned. Tipu ordered the destruction of 27 Catholic churches.

According to Thomas Munro, a Scottish soldier and the first collector of Canara, around 60,000 of them, nearly 92 percent of the entire Mangalorean Catholic community, were captured. 7,000 escaped. Observer Francis Buchanan reports that 70,000 were captured, from a population of 80,000, with 10,000 escaping. They were forced to climb nearly through the jungles of the Western Ghat mountain ranges. It was from Mangalore to Seringapatam, and the journey took six weeks. According to British Government records, 20,000  of them died on the march to Seringapatam. According to James Scurry, a British officer, who was held captive along with Mangalorean Catholics, 30,000 of them were forcibly converted to Islam. The young women and girls were forcibly made wives of the Muslims living there and later distributed and sold in prostitution. The young men who offered resistance were disfigured by cutting their noses, upper lips, and ears. According to Mr. Silva of Gangolim, a survivor of the captivity, if a person who had escaped from Seringapatam was found, the punishment under the orders of Tipu was the cutting off of the ears, nose, the feet and one hand.

The Archbishop of Goa wrote in 1800, ""It is notoriously known in all Asia and all other parts of the globe of the oppression and sufferings experienced by the Christians in the Dominion of the King of Kanara, during the usurpation of that country by Tipu Sultan from an implacable hatred he had against them who professed Christianity.""

Tipu Sultan's invasion of the Malabar Coast had an adverse impact on the Saint Thomas Christian community of the Malabar coast. Many churches in Malabar and Cochin were damaged. The old Syrian Nasrani seminary at Angamaly which had been the center of Catholic religious education for several centuries was razed to the ground by Tipu's soldiers. Many centuries-old religious manuscripts were lost forever. The church was later relocated to Kottayam where it still exists to this date. The Mor Sabor church at Akaparambu and the Martha Mariam Church attached to the seminary were destroyed as well. Tipu's army set fire to the church at Palayoor and attacked the Ollur Church in 1790. Furthernmore, the Arthat church and the Ambazhakkad seminary was also destroyed. Over the course of this invasion, many Saint Thomas Christians were killed or forcibly converted to Islam. Most of the coconut, arecanut, pepper and cashew plantations held by the Saint Thomas Christian farmers were also indiscriminately destroyed by the invading army. As a result, when Tipu's army invaded Guruvayur and adjacent areas, the Syrian Christian community fled Calicut and small towns like Arthat to new centres like Kunnamkulam, Chalakudi, Ennakadu, Cheppadu, Kannankode, Mavelikkara, etc. where there were already Christians. They were given refuge by Sakthan Tamburan, the ruler of Cochin and Karthika Thirunal, the ruler of Travancore, who gave them lands, plantations and encouraged their businesses. Colonel Macqulay, the British resident of Travancore also helped them.

Tipu's persecution of Christians also extended to captured British soldiers. For instance, there were a significant amount of forced conversions of British captives between 1780 and 1784. Following their disastrous defeat at the battle of Pollilur, 7,000 British men along with an unknown number of women were held captive by Tipu in the fortress of Seringapatnam. Of these, over 300 were circumcised and given Muslim names and clothes and several British regimental drummer boys were made to wear "ghagra cholis" and entertain the court as "nautch" girls or dancing girls. After the 10-year-long captivity ended, James Scurry, one of those prisoners, recounted that he had forgotten how to sit in a chair and use a knife and fork. His English was broken and stilted, having lost all his vernacular idiom. His skin had darkened to the swarthy complexion of negroes, and moreover, he had developed an aversion to wearing European clothes.

During the surrender of the Mangalore fort which was delivered in an armistice by the British and their subsequent withdrawal, all the Mestizos and remaining non-British foreigners were killed, together with 5,600 Mangalorean Catholics. Those condemned by Tipu Sultan for treachery were hanged instantly, the gibbets being weighed down by the number of bodies they carried. The Netravati River was so putrid with the stench of dying bodies, that the local residents were forced to leave their riverside homes.

Tokugawa Ieyasu assumed control over Japan in 1600. Like Toyotomi Hideyoshi, he disliked Christian activities in Japan. The Tokugawa shogunate finally decided to ban Catholicism, in 1614 and in the mid-17th century it demanded the expulsion of all European missionaries and the execution of all converts. This marked the end of open Christianity in Japan. The Shimabara Rebellion, led by a young Japanese Christian boy named Amakusa Shirō Tokisada, took place in 1637. After the Hara Castle fell, the shogunate's forces beheaded an estimated 37,000 rebels and sympathizers. Amakusa Shirō's severed head was taken to Nagasaki for public display, and the entire complex at Hara Castle was burned to the ground and buried together with the bodies of all the dead.

Many of the Christians in Japan continued for two centuries to maintain their religion as Kakure Kirishitan, or hidden Christians, without any priests or pastors. Some of those who were killed for their Faith are venerated as the Martyrs of Japan.

Christianity was later allowed during the Meiji era. The Meiji Constitution of 1890 introduced separation of church and state and permitted freedom of religion.

Relations between Muslims and Christians in the Ottoman Empire during the modern era were shaped in no small part by broader dynamics related to European colonial and neo-imperialist activity in the region, dynamics that frequently (though by no means always) generated tensions between the two. Too often, growing European influence in the region during the nineteenth century seemed to disproportionately benefit Christians, thus producing resentment on the part of many Muslims, likewise a suspicion that Christians were colluding with the European powers in order to weaken the Islamic world. Further exacerbating relations was the fact that Christians seemed to benefit disproportionately from efforts at reform (one aspect of which generally sought to elevate the political status of non-Muslims), likewise, the various Christian nationalist uprisings in the Empire's European territories, which often had the support of the European powers.

Since the time of the Austro-Turkish war (1683–1699) relations between Muslims and Christians in the European provinces of the Ottoman Empire gradually took more extreme forms and resulted in occasional calls by some Muslim religious leaders for the expulsion or extermination of local Christians. As a result of Ottoman oppression, the destruction of Churches and Monasteries, and violence against the non-Muslim civilian population, Serbian Christians and their church leaders, headed by Serbian Patriarch Arsenije III, sided with the Austrians in 1689 and again in 1737 under Serbian Patriarch Arsenije IV. In the following punitive campaigns, Ottoman forces conducted systematic atrocities against the Christian population in the Serbian regions, resulted in the Great Migrations of the Serbs.
Similar persecutions and forced migrations of Christian populations were induced by Ottoman forces during the 18th and 19th centuries in the European and Asian provinces of the Ottoman Empire. The Massacres of Badr Khan were conducted by Kurdish and Ottoman forces against the Assyrian Christian population of the Ottoman Empire between 1843 and 1847, resulting in the slaughter of more than 10,000 indigenous Assyrian civilians of the Hakkari region, with many thousands more being sold into slavery.

During the Bulgarian Uprising (1876) against Ottoman rule, and the Russo-Turkish War (1877–1878), the persecution of the Bulgarian Christian population was conducted by Ottoman soldiers. The principal locations were Panagurishte, Perushtitza, and Bratzigovo. Over 15,000 non-combatant Bulgarian civilians were killed by the Ottoman army between 1876 and 1878, with the worst single instance being the Batak massacre.
During the war, whole cities including the largest Bulgarian one (Stara Zagora) were destroyed and most of their inhabitants were killed, the rest being expelled or enslaved. The atrocities included impaling and grilling people alive. Similar attacks were undertaken by Ottoman troops against Serbian Christians during the Serbian-Turkish War (1876–1878).

Between 1894 and 1896 a series of ethno-religiously motivated Anti-Christian pogroms known as the Hamidian massacres were conducted against the ancient Armenian and Assyrian Christian populations by the forces of the Ottoman Empire. The motives for these massacres were an attempt to reassert Pan-Islamism in the Ottoman Empire, resentment of the comparative wealth of the ancient indigenous Christian communities, and a fear that they would attempt to secede from the tottering Ottoman Empire. The massacres mainly took place in what is today southeastern Turkey, northeastern Syria and northern Iraq. Assyrians and Armenians were massacred in Diyarbakir, Hasankeyef, Sivas and other parts of Anatolia and northern Mesopotamia, by Sultan Abdul Hamid II. The death toll is estimated to have been as high as 325,000 people, with a further 546,000 Armenians and Assyrians made destitute by forced deportations of survivors from cities, and the destruction or theft of almost 2500 of their farmsteads towns and villages. Hundreds of churches and monasteries were also destroyed or forcibly converted into mosques. These attacks caused the death of over thousands of Assyrians and the forced "Ottomanisation" of the inhabitants of 245 villages. The Ottoman troops looted the remains of the Assyrian settlements and these were later stolen and occupied by south-east Anatolian tribes. Unarmed Assyrian women and children were raped, tortured and murdered. According to H. Aboona, the independence of the Assyrians was destroyed not directly by the Turks but by their neighbours under Ottoman auspices.

The Adana massacre occurred in the Adana Vilayet of the Ottoman Empire in April 1909. A massacre of Armenian and Assyrian Christians in the city of Adana and its surrounds amidst the Ottoman countercoup of 1909 led to a series of anti-Christian pogroms throughout the province. Reports estimated that the Adana Province massacres resulted in the death of as many as 30,000 Armenians and 1,500 Assyrians.

Between 1915 and 1921 the Young Turks government of the collapsing Ottoman Empire persecuted Eastern Christian populations in Anatolia, Persia, Northern Mesopotamia and The Levant. The onslaught by the Ottoman army, which included Kurdish, Arab and Circassian irregulars resulted in an estimated 3.4 million deaths, divided between roughly 1.5 million Armenian Christians, 0.75 million Assyrian Christians, 0.90 million Greek Orthodox Christians and 0.25 million Maronite Christians (see Great Famine of Mount Lebanon); groups of Georgian Christians were also killed. The massive ethnoreligious cleansing expelled from the empire or killed the Armenians and the Bulgarians who had not converted to Islam, and it came to be known as the Armenian Genocide, Assyrian Genocide, Greek Genocide. and Great Famine of Mount Lebanon. which accounted for the deaths of Armenian, Assyrian, Greek and Maronite Christians, and the deportation and destitution of many more. The Genocide led to the devastation of ancient indigenous Christian populations who had existed in the region for thousands of years.

The Assyrians suffered a further series of persecutions during the Simele massacre in 1933, with the death of approximately 3000 Assyrian civilians at the hands of the Iraqi Army.

After the Russian Revolution of 1917, the Bolsheviks undertook a massive program to remove the influence of the Russian Orthodox Church from the government while outlawing antisemitism in Russian society, and promoting atheism. Tens of thousands of churches were destroyed or converted to other uses, and many members of the clergy were murdered, publicly executed and imprisoned for what the government termed "anti-government activities." An extensive educational and propaganda campaign was launched in order to convince people, especially children and youths, to abandon their religious beliefs. This persecution resulted in the intentional murder of 500,000 Orthodox followers by the government of the Soviet Union during the 20th century.

Under the doctrine of state atheism in the Soviet Union, a "government-sponsored program of forced conversion to atheism" was conducted by the Communists. The Communist Party destroyed churches, mosques and temples, ridiculed, harassed, incarcerated and executed religious leaders, flooded the schools and media with anti-religious teachings, and it introduced a belief system called "scientific atheism," with its own rituals, promises and proselytizers. Many priests were killed and imprisoned; thousands of churches were closed. In 1925 the government founded the League of Militant Atheists in order to intensify the persecution. The League of Militant Atheists was also a "nominally independent organization established by the Communist Party to promote atheism".

The state established atheism as the only scientific truth. Soviet authorities forbade the criticism of atheism and agnosticism until 1936 or of the state's anti-religious policies; such criticism could lead to forced retirement. Militant atheism became central to the ideology of the Communist Party of the Soviet Union and a high priority policy of all Soviet leaders. Christopher Marsh, a professor at the Baylor University writes that "Tracing the social nature of religion from Schleiermacher and Feurbach to Marx, Engles, and Lenin...the idea of religion as a social product evolved to the point of policies aimed at the forced conversion of believers to atheism."

Before and after the October Revolution of 7 November 1917 (25 October Old Calendar) there was a movement within the Soviet Union to unite all of the people of the world under Communist rule (see Communist International). This included the Eastern European bloc countries as well as the Balkan States. Since some of these Slavic states tied their ethnic heritage to their ethnic churches, both the people and their churches were targeted for ethnic and political genocide by the Soviets and their form of State atheism. The Soviets' official religious stance was one of "religious freedom or tolerance", though the state established atheism as the only scientific truth (see also the Soviet or committee of the All-Union Society for the Dissemination of Scientific and Political Knowledge or Znanie which was until 1947 called The League of the Militant Godless and various Intelligentsia groups). Criticism of atheism was strictly forbidden and sometimes resulted in imprisonment. Some of the more high-profile individuals who were executed include Metropolitan Benjamin of Petrograd, Priest and scientist Pavel Florensky and Bishop Gorazd Pavlik.

Across Eastern Europe following World War II, the parts of the Nazi Empire conquered by the Soviet Red Army and Yugoslavia became one-party Communist states and the project of coercive conversion to atheism continued. The Soviet Union ended its war time truce with the Russian Orthodox Church, and extended its persecutions to the newly Communist Eastern bloc: "In Poland, Hungary, Lithuania and other Eastern European countries, Catholic leaders who were unwilling to be silent were denounced, publicly humiliated or imprisoned by the Communists. Leaders of the national Orthodox Churches in Romania and Bulgaria had to be cautious and submissive", wrote Geoffrey Blainey. While the churches were generally not treated as severely as they had been in the USSR, nearly all of their schools and many of their churches were closed, and they lost their formally prominent roles in public life. Children were taught atheism, and clergy were imprisoned by the thousands. In the Eastern Bloc, Christian churches, along with Jewish synagogues and Islamic mosques were forcibly "converted into museums of atheism." According to James M. Nelson a psychology professor at East Carolina University, the total number of Christian victims under the Soviet regime may have been around 12 million, while Todd Johnson and Gina Zurlo of Gordon-Conwell Theological Seminary at Boston University estimate a figure of 15–20 million.

The Communist regime confiscated church property, ridiculed religion, harassed believers, and propagated atheism in the schools. Actions towards particular religions, however, were determined by State interests, and most organized religions were never outlawed. It is estimated that 500,000 Russian Orthodox Christians were martyred in the gulags by the Soviet government, excluding the members of other Christian denominations who were also tortured or killed.

Along with execution, some other actions against Orthodox priests and believers included torture, being sent to prison camps, labour camps or mental hospitals. In the first five years after the Bolshevik revolution, 28 bishops and 1,200 priests were executed.
The main target of the anti-religious campaign in the 1920s and 1930s was the Russian Orthodox Church, which had the largest number of faithful worshippers. A very large segment of its clergy, and many of its believers, were shot or sent to labor camps. Theological schools were closed, and church publications were prohibited. In the period between 1927 and 1940, the number of Orthodox Churches in the Russian Republic fell from 29,584 to less than 500. Between 1917 and 1940, 130,000 Orthodox priests were arrested.
The widespread persecution and internecine disputes within the church hierarchy lead to the seat of Patriarch of Moscow being vacant from 1925 to 1943.

After Nazi Germany's attack on the Soviet Union in 1941, Joseph Stalin revived the Russian Orthodox Church in order to intensify patriotic support for the war effort. By 1957, about 22,000 Russian Orthodox churches had become active. But in 1959, Nikita Khrushchev initiated his own campaign against the Russian Orthodox Church and forced the closure of about 12,000 churches. By 1985, fewer than 7,000 churches remained active.

In the Soviet Union, in addition to the methodical closure and destruction of churches, the charitable and social work formerly done by ecclesiastical authorities was taken over by the state. As with all private property, Church owned property was confiscated by the state and converted to public use. The few places of worship left to the Church were legally viewed as state property which the government permitted the church to use. After the advent of state funded universal education, the Church was not permitted to carry on educational, instructional activity for children. For adults, only training for church-related occupations was allowed. With the exception of sermons during the celebration of the divine liturgy, it could not instruct the faithful or evangelise the youth. Catechism classes, religious schools, study groups, Sunday schools and religious publications were all declared illegal and banned. This caused many religious tracts to be circulated as illegal literature or samizdat. This persecution continued, even after the death of Stalin until the dissolution of the Soviet Union in 1991. Since the fall of the Soviet Union, the Russian Orthodox Church has recognized a number of New Martyrs as saints, some of whom were executed during the Mass operations of the NKVD under directives like NKVD Order No. 00447.

In the 19th century, Mexican President Benito Juárez confiscated church lands. The Mexican government's campaign against the Catholic Church after the Mexican Revolution culminated in the 1917 constitution which contained numerous articles which Catholics perceived as violating their civil rights: outlawing monastic religious orders, forbidding public worship outside of church buildings, restricted religious organizations' rights to own property, and taking away basic civil rights of members of the clergy (priests and religious leaders were prevented from wearing their habits, were denied the right to vote, and were not permitted to comment on public affairs in the press and were denied the right to trial for violation of anticlerical laws). When the first embassy of the Soviet Union in any country was opened in Mexico, the Soviet ambassador remarked that "no other two countries show more similarities than the Soviet Union and Mexico".

When the Church publicly condemned the anticlerical measures which had not been strongly enforced, the atheist President Plutarco Calles sought to vigorously enforce the provisions and enacted additional anti-Catholic legislation known as the Calles Law. At this time, some in the United States government, considering Calles' regime Bolshevik, started to refer to Mexico as "Soviet Mexico".

Weary of the persecution, in many parts of the country a popular rebellion called the Cristero War began (so named because the rebels felt they were fighting for Christ himself). The effects of the persecution on the Church were profound. Between 1926 and 1934 at least 40 priests were killed. Where there were 4,500 priests serving the people before the rebellion, in 1934 there were 334 priests licensed by the government to serve fifteen million people, the rest having been eliminated by emigration, expulsion and assassination. By 1935, 17 states had no priest at all. In the second Cristero rebellion (1932), the Cristeros took particular exception to the socialist education, which Calles had also implemented but which President Cardenas had added to the 1917 Mexican Constitution.

The Latter Day Saint Movement, (Mormons) have been persecuted since their founding in the 1830s. This persecution drove them from New York and Ohio to Missouri, where they continued to suffer violent attacks. In 1838, Gov. Lilburn Boggs declared that Mormons had made war on the state of Missouri, and "must be treated as enemies, and must be exterminated or driven from the state" At least 10,000 were expelled from the State. In the most violent of the altercations at this time, the Haun's mill Massacre, 17 were murdered by an anti-Mormon mob and 13 were wounded. The Extermination Order signed by Governor Boggs was not formally invalidated until 25 June 1976, 137 years after being signed.

The Mormons subsequently fled to Nauvoo, Illinois, where hostilities again escalated. In Carthage, Ill., where Joseph Smith was being held on the charge of treason, a mob stormed the jail and killed him. Smith's brother, Hyrum, was also killed. After a succession crisis, most united under Brigham Young, who organized an evacuation from the United States after the federal government refused to protect them. 70,000 Mormon pioneers crossed the Great Plains to settle in the Salt Lake Valley and surrounding areas. After the Mexican–American War, the area became the US territory of Utah. Over the next 63 years, several actions by the federal government were directed against Mormons in the Mormon Corridor, including the Utah War, the Morrill Anti-Bigamy Act, the Poland Act, "Reynolds v. United States", the Edmunds Act, the Edmunds–Tucker Act, and the Reed Smoot hearings.

Queen Ranavalona I (reigned 1828–1861) issued a royal edict prohibiting the practice of Christianity in Madagascar, expelled British missionaries from the island, and sought to stem the growth of conversion to Christianity within her realm. Far more, however, were punished in other ways: many were required to undergo the "tangena" ordeal, while others were condemned to hard labor or the confiscation of their land and property, and many of these consequently died. The tangena ordeal was commonly administered to determine the guilt or innocence of an accused person for any crime, including the practice of Christianity, and involved ingestion of the poison contained within the nut of the tangena tree ("Cerbera odollam"). Survivors were deemed innocent, while those who perished were assumed guilty.

In 1838, it was estimated that as many as 100,000 people in Imerina died as a result of the "tangena" ordeal, constituting roughly 20% of the population. contributing to a strongly unfavorable view of Ranavalona's rule in historical accounts. Malagasy Christians would remember this period as "ny tany maizina", or "the time when the land was dark". Persecution of Christians intensified in 1840, 1849 and 1857; in 1849, deemed the worst of these years by British missionary to Madagascar W.E. Cummins (1878), 1,900 people were fined, jailed or otherwise punished in relation to their Christian faith, including 18 executions.

The Second Republic proclaimed in 1931 attempted to establish a regime with a separation between State and Church as it had happened in France (1905). When established, the Republic passed a number of laws that prompted progress in education, but also challenged the power of the Church, entrenched values and traditional public ceremonies. A process of political polarisation had characterised the Spanish Second Republic, party divisions became increasingly embittered and questions of religious identity came to assume a major political significance. Different Church institutions presented the situation resulting from the proclamation of the 2nd Republic as an anti-Catholic, Masonic, Jewish, and Communist international conspiracy that heralded a clash between God and atheism, chaos and harmony, Good and Evil. The Church's high-ranking officials like Isidro Goma, bishop of Tudela, reminded their Christian subjects of their obligation to vote "for the righteous", and their priests to "educate the consciences."

A similar approach is attested in 1912, when the bishop of Almería José Ignacio de Urbina (founder of the National anti-Masonic and anti-Semitic League) announced 'a decisive battle that must be unleashed' between the "light" and "darkness." Since the early stages of the 2nd Spanish Republic, far-right forces imbued with an ultra-Catholic spirit attempted to overthrow the Republic. Carlists, Africanistas, and Catholic theologians fostered an atmosphere of social and racial hatred in their speeches and writings.

Stanley Payne suggested that persecution of right-wingers and people associated with Catholic church before and at the beginning of the Spanish Civil War involved the murder of priests and other clergy, as well as thousands of lay people, by sections of nearly all the leftist groups, while a killing spree unleashed also across the Nationalist zone. During the Spanish Civil War of 1936–1939, and especially in the early months of the conflict, individual clergymen and entire religious communities were executed by leftists, which included communists and anarchists. The death toll of the clergy alone included 13 bishops, 4,172 diocesan priests and seminarians, 2,364 monks and friars and 283 nuns, for a total of 6,832 clerical victims.

In addition to murders of clergy and the faithful, destruction of churches and desecration of sacred sites and objects were widespread. On the night of 19 July 1936 alone, some fifty churches were burned. In Barcelona, out of the 58 churches, only the Cathedral was spared, and similar desecrations occurred almost everywhere in Republican Spain.

Exceptions were Biscay and Gipuzkoa where the Christian Democratic Basque Nationalist Party, after some hesitation, supported the Republic while halting persecution in the areas held by the Basque Government. All Catholic churches in the Republican zone were closed. The desecration was not limited to Catholic churches, as synagogues and Protestant churches were also pillaged and closed, but some small Protestant churches were spared. The rising Franco's regime would keep Protestant churches and synagogues closed, as he only permitted Catholic church.

Payne called the terror the "most extensive and violent persecution of Catholicism in Western History, in some way even more intense than that of the French Revolution."
The persecution drove Catholics to the Nationalists, even more than would have been expected, as these defended their religious interests and survival.

Hitler and the Nazis received some support from Christian communities, mainly due to their common cause against the anti-religious Communists, as well as their mutual Judeophobia and anti-Semitism. Once in power, the Nazis moved to consolidate their power over the German churches and bring them in line with Nazi ideals. Some historians say that Hitler had a general covert plan, which some say existed even before the Nazis' rise to power, to destroy Christianity within the Reich, which was to be accomplished through control and subversion of the churches and which would be completed after the war. The Third Reich founded its own version of Christianity called Positive Christianity which made major changes in the interpretation of the Bible by saying that Jesus Christ was the son of God, but not a Jew and it also argued that Jesus despised Jews, and the Jews were the ones who were solely responsible for Jesus's death. Thus, the Nazi government consolidated religious power, using its allies in order to consolidate the Protestant churches into the Protestant Reich Church. The syncretist project of Positive Christianity was abandoned in 1940.

Like other intelligentsia, Christian leaders were sometimes persecuted for their anti-Nazi political activities. Between 1939 and 1945, an estimated 3,000 members, 18% of the Polish clergy, were murdered for their suspected ties to the Polish Resistance or left-wing groups, or for sheltering Jews (punishable by death).

Outside mainstream Christianity, the Jehovah's Witnesses were targets of Nazi Persecution, for their refusal to swear allegiance to the Nazi government. In Nazi Germany in the 1930s and early 1940s, Jehovah's Witnesses refused to renounce their political neutrality and they were placed in concentration camps as a result. The Nazi government gave detained Jehovah's Witnesses the option of release if they signed a document which indicated their renouncement of their faith, their submission to state authority, and their support of the German military. Historian Hans Hesse said, "Some five thousand Jehovah's Witnesses were sent to concentration camps where they alone were 'voluntary prisoners', so termed because the moment they recanted their views, they could be freed. Some lost their lives in the camps, but few renounced their faith".

The Nazi Dissolution of the Bruderhof was also carried out by the Nazi government because the Bruderhof refused to pledge allegiance to Hitler. In 1937 their property was confiscated and the group fled to England.

At times, political and religious animosity against Jehovah's Witnesses has led to mob action and government oppression in various countries, including Cuba, the United States, Canada and Singapore. The religion's doctrine of political neutrality has led to the imprisonment of members who refused conscription (for example in Britain during World War II and afterwards during the period of compulsory national service).

Religion in Albania was subordinated to the interests of Marxism during the rule of the country's communist party when all religions were suppressed. This was used to justify the communist stance of state atheism from 1967 to 1991. The Agrarian Reform Law of August 1945 nationalized most of the property which belonged to religious institutions, including the estates of mosques, monasteries, orders, and dioceses. Many clergy and believers were tried and some of them were executed. All foreign Roman Catholic priests, monks, and nuns were expelled in 1946. Churches, cathedrals and mosques were seized by the military and converted into basketball courts, movie theaters, dance halls, and the like; with members of the Clergy being stripped of their titles and imprisoned. Around 6,000 Albanians were disappeared by agents of the Communist government, with their bodies having never been found or identified. Albanians continued to be imprisoned, tortured and killed for their religious practices well into 1991.

Religious communities or branches that had their headquarters outside the country, such as the Jesuit and Franciscan orders, were henceforth ordered to terminate their activities in Albania. Religious institutions were forbidden to have anything to do with the education of the young, because that had been made the exclusive province of the state. All religious communities were prohibited from owning real estate and they were also prohibited from operating philanthropic and welfare institutions and hospitals. Enver Hoxha's overarching goal was the eventual destruction of all organized religion in Albania, despite some variance in approach.

According to Pope Emeritus Benedict XVI, Christians are the most persecuted group in the contemporary world. The Holy See has reported that over 100,000 Christians are violently killed annually because of some relation to their faith. According to the World Evangelical Alliance, over 200 million Christians are denied fundamental human rights solely because of their faith. Of the 100–200 million Christians alleged to be under assault, the majority are persecuted in Muslim-dominated nations. Paul Vallely has said that Christians suffer numerically more than any other faith group or any group without faith in the world. Of the world's three largest religions Christians are allegedly the most persecuted with 80% of all acts of religious discrimination being directed at Christians who only make up 33% of the world's population.

Every year, the Christian non-profit organization Open Doors publishes the World Watch List – a list of the top 50 countries which it designates as the most dangerous for Christians. The 2018 World Watch List has the following countries as its top ten: North Korea, Afghanistan, Somalia, Sudan, Pakistan, Eritrea, Libya, Iraq, Yemen, Iran.

Christians have faced increasing levels of persecution in the Muslim world. Muslim-majority nations in which Christian populations have suffered acute discrimination, persecution, repression, violence and in some cases death, mass murder or ethnic cleansing include; Iraq, Iran, Syria, Pakistan, Afghanistan, Saudi Arabia, Yemen, Somalia, Qatar, Kuwait, Indonesia, Malaysia, the Maldives.

Furthermore, any Muslim person—including any person born into a Muslim family or any person who became a Muslim at a given point in his or her life—who converts to Christianity or re-converts to it, is considered an apostate. Apostasy, the conscious abandonment of Islam by a Muslim in word or deed, including conversion to Christianity, is punishable as a crime under applications of the Sharia (countries in the graph). There are, however, cases in which a Muslim will adopt the Christian faith, secretly without declaring his/her apostasy. As a result, they are practising Christians, but they are still legally Muslims, and they can face the death penalty according to the Sharia. Meriam Ibrahim, a Sudanese woman, was sentenced to death for apostasy in 2014, because the government of Sudan classified her as a Muslim, even though she was raised as a Christian.

A report by the international catholic charity organisation Aid to the Church in Need said that the religiously motivated ethnic cleansing of Christians is so severe that they are set to disappear completely from parts of the Middle-East within a decade.

A report commissioned by the British foreign secretary Jeremy Hunt and published in May 2019 stated that the level and nature of persecution of Christians in the Middle East "is arguably coming close to meeting the international definition of genocide, according to that adopted by the UN.” The report coted Algeria, Egypt, Iran, Iraq, Syria and Saudi Arabia where "the situation of Christians and other minorities has reached an alarming stage." The report attributed the sources of persecution to both extremist groups and the failure of state institutions.

In Afghanistan, Abdul Rahman, a 41-year-old citizen, was charged in 2006 with rejecting Islam, a crime punishable by death under Sharia law. He has since been released into exile in the West under intense pressure from Western governments.
In 2008, the Taliban killed a British charity worker, Gayle Williams, "because she was working for an organization which was preaching Christianity in Afghanistan" even though she was extremely careful not to try to convert Afghans.

On the night of 26–27 March 1996, seven monks from the monastery of Tibhirine in Algeria, belonging to the Roman Catholic Trappist Order of Cistercians of the Strict Observance (O.C.S.O.), were kidnapped in the Algerian Civil War. They were held for two months and were found dead on 21 May 1996. The circumstances of their kidnapping and death remain controversial; the Armed Islamic Group (GIA) allegedly took responsibility for both, but the then French military attaché, retired General Francois Buchwalter, reports that they were accidentally killed by the Algerian army in a rescue attempt, and claims have been made that the GIA itself was a cat's paw of Algeria's secret services (DRS).

A Muslim gang allegedly looted and burned to the ground, a Pentecostal church in Tizi Ouzou on 9 January 2010. The pastor was quoted as saying that worshipers fled when local police supposedly left a group of local protestors unchecked. Many Bibles were burnt.

Foreign missionaries are allowed in the country if they restrict their activities to social improvements and refrain from proselytizing. Particularly in Upper Egypt, the rise in extremist Islamist groups such as the Gama'at Islamiya during the 1980s was accompanied by increased attacks on Copts and on Coptic Orthodox churches; these have since declined with the decline of those organizations, but still continue. The police have been accused of siding with the attackers in some of these cases.

There have been periodic acts of violence against Christians since, including attacks on Coptic Orthodox churches in Alexandria in April 2006, and sectarian violence in Dahshur in July 2012. From 2011 to 2013, more than 150 kidnappings, for ransom, of Christians had been reported in the Minya governorate. Christians have been convicted for "contempt of religion", such as poet Fatima Naoot in 2016.

Although Christians are minority in Indonesia, Christianity is one of the six official religions of Indonesia and religious freedom is permitted. But there are some religious tensions and persecutions in the country, and most of the tensions and persecutions are civil and not by state.

In January 1999 tens of thousands died when Muslim gunmen terrorized Christians who had voted for independence in East Timor. These events came toward the end of the East Timor genocide, which began around 1975.

In Indonesia, religious conflicts have typically occurred in Western New Guinea, Maluku (particularly Ambon), and Sulawesi. The presence of Muslims in these traditionally Christian regions is in part a result of the "transmigrasi" program of population re-distribution. Conflicts have often occurred because of the aims of radical Islamist organizations such as Jemaah Islamiah or Laskar Jihad to impose Sharia, with such groups attacking Christians and destroying over 600 churches. In 2005 three Christian girls were beheaded as retaliation for previous Muslim deaths in Christian-Muslim rioting. The men were imprisoned for the murders, including Jemaah Islamiyah's district ringleader Hasanuddin. On going to jail, Hasanuddin said, "It's not a problem (if I am being sentenced to prison), because this is a part of our struggle." Later in November 2011, another fight between Christians against Muslims happen in Ambon. Muslims allegedly set fire to several Christian houses, forcing the occupants to leave the buildings.

In December 2011, a second church in Bogor, West Java was ordered to halt its activities by the local mayor. Another Catholic church had been built there in 2005. Previously a Christian church, GKI Taman Yasmin, had been sealed. Local authorities refused to lift a ban on the activities of the church, despite an order from the Supreme Court of Indonesia. Local authorities have persecuted the Christian church for three years. While the state has ordered religious toleration, it has not enforced these orders.

In Aceh Province, the only province in Indonesia with autonomous Islamic Shari'a Law, 20 churches in Singkil Regency face threat of demolition due to gubernatorial decree requires the approval of 150 worshippers, while the ministrial decree also requires the approval of 60 local residents of different faiths. On 30 April 2012, all the 20 churches (17 Protestant churches, 2 Catholic churches and one place of worship belonging to followers of a local nondenominational faith) have been closed down by order, from the Acting Regent which also ordered members of the congregations to tear down the churches by themselves. Most of the churches slated for demolition were built in the 1930s and 1940s. The regency has 2 churches open, both built after 2000.

On 9 May 2017, Christian governor of Jakarta Basuki Tjahaja Purnama has been sentenced to two years in prison by the North Jakarta District Court after being found guilty of committing a criminal act of blasphemy.

Though Iran recognizes Assyrian and Armenian Christians as ethnic and religious minorities (along with Jews and Zoroastrians) and they have representatives in the Parliament, they are nonetheless forced to adhere to Iran's strict interpretation of Islamic law. After the 1979 Revolution, Muslim converts to Christianity (typically to Protestant Christianity) have been arrested and sometimes executed. Youcef Nadarkhani is an Iranian Christian pastor who was arrested on charges of apostasy in October 2009 and was subsequently sentenced to death. In June 2011 the Iranian Supreme Court overruled his death sentence on condition that he recant, which he refused to do. In a reversal on 8 September 2012 he was acquitted of the charges of apostasy and extortion, and sentenced to time served for the charge of "propaganda against the regime," and immediately released.

According to UNHCR, although Christians (almost exclusively ethnic Assyrians and Armenians) now represent less than 5% of the total Iraqi population, they make up 40% of the refugees now living in nearby countries.

In 1987, the last Iraqi census counted 1.4 million Christians. They were tolerated under the secular regime of Saddam Hussein, who even made one of them, Tariq Aziz his deputy. However persecution by Saddam Hussein continued against the Christians on an ethnic, cultural and racial level, as the vast majority are Mesopotamian Eastern Aramaic-speaking Ethnic Assyrians (aka Chaldo-Assyrians). The Assyro-Aramaic language and script was repressed, the giving of Hebraic/Aramaic Christian names or Akkadian/Assyro-Babylonian names forbidden (Tariq Aziz's real name was Michael Youhanna for example), and Saddam exploited religious differences between Assyrian denominations such as Chaldean Catholics, Assyrian Church of the East, Syriac Orthodox Church, Assyrian Pentecostal Church and Ancient Church of the East, in an attempt to divide them. Many Assyrians and Armenians were ethnically cleansed from their towns and villages under the al Anfal Campaign in 1988, despite this campaign being aimed primarily at Kurds.

In 2004, five churches were destroyed by bombing, and Christians were targeted by kidnappers and Islamic extremists, leading to tens of thousands of Christians fleeing to Assyrian regions in the north or leaving the country altogether.

In 2006, the number of Assyrian Christians dropped to between 500,000 and 800,000, of whom 250,000 lived in Baghdad. An exodus to the Assyrian homeland in northern Iraq, and to neighboring countries of Syria, Jordan, Lebanon and Turkey left behind closed parishes, seminaries and convents. As a small minority, who until recently were without a militia of their own, Assyrian Christians were persecuted by both Shi'a and Sunni Muslim militias, Kurdish Nationalists, and also by criminal gangs.

As of 21 June 2007, the UNHCR estimated that 2.2 million Iraqis had been displaced to neighbouring countries, and 2 million were displaced internally, with nearly 100,000 Iraqis fleeing to Syria and Jordan each month. A 25 May 2007 article notes that in the past seven months 69 people from Iraq have been granted refugee status in the United States.

In 2007, Chaldean Catholic Church priest Fr. Ragheed Aziz Ganni and subdeacons Basman Yousef Dawid, Wahid Hanna Esho, and Gassan Isam Bidawed were killed in the ancient city of Mosul. Ganni was driving with his three deacons when they were stopped and demanded to convert to Islam, when they refused they were shot. Ganni was the pastor of the Chaldean Church of the Holy Spirit in Mosul and a graduate from the Pontifical University of Saint Thomas Aquinas, "Angelicum" in Rome in 2003 with a licentiate in ecumenical theology. Six months later, the body of Paulos Faraj Rahho, archbishop of Mosul, was found buried near Mosul. He was kidnapped on 29 February 2008 when his bodyguards and driver were killed. See 2008 attacks on Christians in Mosul for more details.

In 2010 there was an attack on the Our Lady of Salvation Syriac Catholic cathedral of Baghdad, Iraq, that took place during Sunday evening Mass on 31 October 2010. The attack left at least 58 people dead, after more than 100 had been taken hostage. The al-Qaeda-linked Sunni insurgent group The Islamic State of Iraq claimed responsibility for the attack; though Shia cleric Ayatollah Ali al-Sistani, amongst others condemned the attack.

In 2013, Assyrian Christians were departing for their ancestral heartlands in the Nineveh plains, around Mosul, Erbil and Kirkuk. Assyrian militias were established to protect villages and towns.

During the 2014 Northern Iraq offensive, the Islamic State of Iraq issued a decree in July that all indigenous Assyrian Christians in the area of its control must leave the lands they have occupied for 5000 years, be subject to extortion in the form of a special tax of approximately $470 per family, convert to Islam, or be murdered. Many of them took refuge in nearby Kurdish-controlled regions of Iraq. Christian homes have been painted with the Arabic letter ن ("nūn") for "Nassarah" (an Arabic word Christian) and a declaration that they are the "property of the Islamic State". On 18 July, ISIS militants seemed to have changed their minds and announced that all Christians would need to leave or be killed. Most of those who left had their valuable possessions stolen by the Islamic terrorists. According to Patriarch Louis Sako, there are no Christians remaining in the once Christian dominated city of Mosul for the first time in the nation's history, although this situation has not been verified.

During an attack on the Assyrian Christian town of Qaraqosh, a 5-year-old boy, who's the son of a founding member of St. George's Anglican Church in Baghdad, was slaughtered by Islamic State terrorists, better known as ISIS, who cut the boy in half.

In Malaysia, although Islam is the official religion, Christianity is tolerated under Article 3 and Article 11 of the Malaysian constitution. But at some point, the spread of Christianity is a particular sore point for the Muslim majority, the Malaysian government has also persecuted Christian groups who were perceived to be attempting to proselytize Muslim audiences. Those showing interest in the Christian faith or other faith practices not considered orthodox by state religious authorities are usually sent either by the police or their family members to state funded "Faith Rehabilitation Centres" () where they are counseled to remain faithful to Islam and some states have provisions for penalties under their respective Shariah legislations for apostasy from Islam.

It has been the practice of the church in Malaysia to not actively proselytize to the Muslim community. Christian literature is required by law to carry a caption "for non-Muslims only". Article 11(4) of the Federal Constitution of Malaysia allows the states to prohibit the propagation of other religions to Muslims, and most (with the exception of Penang, Sabah, Sarawak and the Federal Territories) have done so. There is no well-researched agreement on the actual number of Malaysian Muslim converts to Christianity in Malaysia. According to the latest population census released by the Malaysian Statistics Department, there are none, according to Ustaz Ridhuan Tee, they are 135 and according to Tan Sri Dr Harussani Zakaria, they are 260,000. See also Status of religious freedom in Malaysia.

There are, however, cases in which a Muslim will adopt the Christian faith without declaring his/her apostasy openly. In effect, they are practicing Christians, but legally Muslims.

In the 11 Northern states of Nigeria that have introduced the Islamic system of law, the Sharia, sectarian clashes between Muslims and Christians have resulted in many deaths, and some churches have been burned. More than 30,000 Christians were displaced from their homes in Kano, the largest city in northern Nigeria.

The Boko Haram Islamist group has bombed churches and killed numerous Christians who they regard as kafirs (infidels). Some Muslim aid organisations in Nigeria reportedly reserve aid for Muslims displaced by Boko Haram. Christian Bishop William Naga reported to Open Doors UK that, "They will give food to the refugees, but if you are a Christian they will not give you food. They will openly tell you that the relief is not for Christians."

In Pakistan, 1.5% of the population are Christian. Pakistani law mandates that "blasphemies" of the Qur'an are to be met with punishment. At least a dozen Christians have been given death sentences, and half a dozen murdered after being accused of violating blasphemy laws. In 2005, 80 Christians were behind bars due to these laws. The Pakistani-American author Farahnaz Ispahani has called treatment of Christians in Pakistan a "drip-drip genocide."

Ayub , a Christian, was convicted of blasphemy and sentenced to death in 1998. He was accused by a neighbor of stating that he supported British writer Salman Rushdie, author of "The Satanic Verses". Lower appeals courts upheld the conviction. However, before the Pakistan Supreme Court, his lawyer was able to prove that the accuser had used the conviction to force family off their land and then acquired control of the property. has been released.

In October 2001, gunmen on motorcycles opened fire on a Protestant congregation in the Punjab, killing 18 people. The identities of the gunmen are unknown. Officials think it might be a banned Islamic group.

In March 2002, five people were killed in an attack on a church in Islamabad, including an American schoolgirl and her mother.

In August 2002, masked gunmen stormed a Christian missionary school for foreigners in Islamabad; six people were killed and three injured. None of those killed were children of foreign missionaries.

In August 2002, grenades were thrown at a church in the grounds of a Christian hospital in north-west Pakistan, near Islamabad, killing three nurses.

On 25 September 2002, two terrorists entered the "Peace and Justice Institute", Karachi, where they separated Muslims from the Christians, and then murdered seven Christians by shooting them in the head. All of the victims were Pakistani Christians. Karachi police chief Tariq Jamil said the victims had their hands tied and their mouths had been covered with tape.

In December 2002, three young girls were killed when a hand grenade was thrown into a church near Lahore on Christmas Day.

In November 2005, 3,000 Muslims attacked Christians in Sangla Hill in Pakistan and destroyed Roman Catholic, Salvation Army and United Presbyterian churches. The attack was over allegations of violation of blasphemy laws by a Pakistani Christian named Yousaf . The attacks were widely condemned by some political parties in Pakistan.

On 5 June 2006, a Pakistani Christian, Nasir Ashraf, was assaulted for the "sin" of using public drinking water facilities near Lahore.

One year later, in August 2007, a Christian missionary couple, Rev. Arif and Kathleen Khan, were gunned down by Muslim terrorists in Islamabad. Pakistani police believed that the murders was committed by a member of Khan's parish over alleged sexual harassment by Khan. This assertion is widely doubted by Khan's family as well as by Pakistani Christians.

In August 2009, six Christians, including four women and a child, were burnt alive by Muslim militants and a church set ablaze in Gojra, Pakistan when violence broke out after alleged desecration of a Qur'an in a wedding ceremony by Christians.

On 8 November 2010, a Christian woman from Punjab Province, Asia Noreen Bibi, was sentenced to death by hanging for violating Pakistan's blasphemy law. The accusation stemmed from a 2009 incident in which Bibi became involved in a religious argument after offering water to thirsty Muslim farm workers. The workers later claimed that she had blasphemed the Muhammed. Until 2019, Bibi was in solitary confinement. A cleric had offered $5,800 to anyone who killed her. As of May 2019, Bibi and her family have left Pakistan and now reside in Canada.

On 2 March 2011, the only Christian minister in the Pakistan government was shot dead. Shahbaz Bhatti, Minister for Minorities, was in his car along with his niece. Around 50 bullets struck the car. Over 10 bullets hit Bhatti. Before his death, he had publicly stated that he was not afraid of the Taliban's threats and was willing to die for his faith and beliefs. He was targeted for opposing the anti-free speech "blasphemy" law, which punishes insulting Islam or its Prophet. A fundamentalist Muslim group claimed responsibility.

On 27 March 2016, a suicide bomber from a Pakistani Taliban faction killed at least 60 people and injured 300 others in an attack at Gulshan-e-Iqbal Park in Lahore, Pakistan, and the group claimed responsibility for the attack, saying it intentionally targeted Christians celebrating Easter Sunday.

Saudi Arabia is an Islamic state that practices Wahhabism and restricts all other religions, including the possession of religious items such as the Bible, crucifixes, and Stars of David. Christians are arrested and lashed in public for practicing their faith openly. Strict sharia is enforced. Muslims are forbidden to convert to another religion. If one does so and does not recant, they can be executed.

Christians in Somalia face persecution associated with the ongoing civil war in that country.

In September 2011 militants sworn to eradicate Christianity from Somalia beheaded two Christian converts. A third Christian convert was beheaded in Mogadishu in early 2012.

In 1992 there were mass arrests and torture of local priests. Prior to partition, southern Sudan had a number of Christian villages. These were subsequently wiped out by Janjaweed militias.

Syria has been home to Christianity from the 1st to 3rd centuries CE onwards. The majority of Syrian Christians are once Western Aramaic speaking but now largely Arabic speaking Arameans-Syriacs, with smaller minorities of Eastern Aramaic speaking Assyrians and Armenians also extant. While religious persecution has been relatively low level compared to other Middle Eastern nations, many of the Christians have been pressured into identifying as Arab Christians, with the Assyrian and Armenian groups retaining their native languages.

On 17 October 1850 the Muslim majority began rioting against the Uniate Catholics – a minority that lived in the communities of Judayda, in the city of Aleppo.

Christians make up approximately 10% of Syria's population of 17.2 million people.

In FY 2016, when the US dramatically increased the number of refugees admitted from Syria, the US let in 12,587 refugees from the country. Less than 1% were Christian according to the Pew Research Center analysis of State Department Refugee Processing Center data.

The Ecumenical Patriarchate of Constantinople is still in a difficult position. Turkish law requires the Ecumenical Patriarch to be an ethnic Greek who holds Turkish citizenship since birth, although most members of Turkey's Greek minority have been expelled. The state's expropriation of church property is an additional difficulty faced by the Church of Constantinople. In November 2007, a 17th-century chapel of "Our Lord's Transfiguration" at the Halki seminary was almost totally demolished by the Turkish forestry authority. There was no advance warning given for the demolition work and it was only stopped after appeals were filed by the Ecumenical Patriarch.

The difficulties currently experienced by the Assyrians and Armenian Orthodox minorities in Turkey are the result of an anti-Armenian and anti-Christian attitude which is espoused by ultra-nationalist groups such as the Grey Wolves. According to the Minority Rights Group, the Turkish government recognizes Armenians and Assyrians as minorities but in Turkey, this term is used to denote second-class status.} In the aftermath of the Sheikh Said rebellion, the Syriac Orthodox Church and the Assyrian Church of the East were subjected to harassment by Turkish authorities, on the grounds that some Assyrians allegedly collaborated with the rebelling Kurds. Consequently, mass deportations took place and Assyrian Patriarch Mar Ignatius Elias III was expelled from the Mor Hananyo Monastery which was turned into a Turkish barrack. The patriarchal seat was then temporarily transferred to Homs.

In February 2006, Father Andrea Santoro was murdered in Trabzon. on 18 April 2007 in the Zirve Publishing House, Malatya, Turkey Three employees of the Bible publishing house were attacked, tortured and murdered by five Sunni Muslim assailants.

The Christian presence in Yemen dates back to the fourth century AD when a number of Himyarites embrace Christianity due to the efforts of Theophilos the Indian. Currently, there are no official statistics on their numbers, but they are estimated to be between 3,000 and 25,000 people, and most of them are either refugees or temporary residents. Freedom of worship, conversion from Islam  and establishing facilities dedicated for worship are not recognized as rights in the country's Constitution and laws. At the same time, Wahabbi activities linked to Al-Islah was being facilitated, financed and encouraged from multiple fronts including the Ministry of Endowments and Guidance, which says that its tasks "to contribute to the development of Islamic awareness and circulation of the publication Education and Islamic morals and consolidation in the life of public and private citizens."

The Missionaries of Charity founded by Mother Teresa has worked in Aden since 1992, and it has three other centers in Sana'a, Taiz and Hodeidah. Three Catholic nuns were killed in Hodeidah in 1998, two of them were from India and the third was from the Philippines at the hands of a member of Al-Islah named Abdullah al-Nashiri, who argued that they were calling Muslims to convert to Christianity. In 2002, three Americans were killed in Baptists Hospital at the hands of another Al-Islah member named Abed Abdul Razak Kamel. Survivors say that the suspect (Al-Islah) was "a political football" who had been raised by Islamists, who talked  about it often in mosques and who described hospital workers as "spies." But they emphasized that these views are only held by a minority of Yemenis. In December 2015, an old Catholic church in Aden was destroyed.

Since the escalation of the Yemeni crisis in March 2015, six priests from John Bosco remained, and twenty workers for charitable missions in the country, described by Pope Francis by the courage to fortitude amid war and conflict. He called the Apostolic Vicar of Southern Arabia to pray for all the oppressed and tortured, expelled from their homes, and killed unjustly. In all cases, regardless of the values and ethics of the warring forces in Yemen on religious freedom, it is proved that the Missionaries of Charity were not active in the field of evangelization according to the testimonies of beneficiaries of its services.

On 4 March 2016, an incident named Mother Teresa's Massacre in Aden occurred, 16 were killed including 4 Indian Catholic nuns, 2 from Rwanda, and the rest were from India and Kenya, along with a YemenI, 2 Guards, a cook, 5 Ethiopian women, and all of them were volunteers. One Indian priest named Tom Ozhonaniel was kidnapped. The identities of the attackers are unknown, and media outlets published a statement attributed to Ansar al-Sharia, one of the many jihadist organizations currently active in the country, but the group denies its involvement in the incident.

Bhutan is a conservative Buddhist country. Article 7 of the 2008 constitution guarantees religious freedom, but also forbids conversion "by means of coercion or inducement". According to Open Doors, to many Bhutanese this hinders the ability of Christians to proselytize.


During the Cultural Revolution, Christian churches, monasteries, and cemeteries were closed down and sometimes converted to other uses, looted, and destroyed.

The communist government of the People's Republic of China tries to maintain tight control over all religions, so the only legal Christian Churches (Three-Self Patriotic Movement and Chinese Patriotic Catholic Association) are those under the Communist Party of China control. Churches which are not controlled by the government are shut down, and their members are imprisoned. Gong Shengliang, head of the South China Church, was sentenced to death in 2001. Although his sentence was commuted to a jail sentence, Amnesty International reports that he has been tortured. A Christian lobby group says that about 300 Christians caught attending unregistered house churches were in jail in 2004.

In January 2016, a prominent Christian church leader Rev Gu Yuese who criticised the mass removal of church crucifixes by the government was arrested for "embezzling funds". Chinese authorities have taken down hundreds of crosses in Zhejiang Province known as "China's bible belt". Gu led China's largest authorised church with capacity of 5,000 in Hangzhou, capital of Zhejiang.

The Associated Press reported in 2018 that China's President Xi Jinping "is waging the most severe systematic suppression of Christianity in the country since religious freedom was written into the Chinese constitution in 1982.", which has involved "destroying crosses, burning bibles, shutting churches and ordering followers to sign papers renouncing their faith".

Muslims in India who convert to Christianity have been subjected to harassment, intimidation, and attacks by Muslims. In Jammu and Kashmir, a Christian convert and missionary, Bashir Tantray, was killed, allegedly by Islamic militants in 2006.
A Christian priest, K.K. Alavi, a 1970 convert from Islam, thereby raised the ire of his former Muslim community and received many death threats. An Islamic terrorist group named "The National Development Front" actively campaigned against him. In the southern state of India, Kerala which has an ancient pre-Islamic community of Eastern Rite Christians, Islamic Terrorists chopped off the hand of Professor T.J. Joseph due to allegation of blasphemy of Muhammad.

The organisations involved in persecution of Christians have stated that the violence is an expression of "spontaneous anger" of "vanvasis" against "forcible conversion" activities undertaken by missionaries. These claims have been disputed by Christians a belief described as mythical and propaganda by Sangh Parivar; the opposing organisations objects in any case to all conversions as a "threat to national unity". Religious scholar Cyril Veliath of Sophia University stated that the attacks by Hindus on Christians were the work of individuals motivated by "disgruntled politicians or phony religious leaders" and where religion is concerned the typical Hindu is an "exceptionally amicable and tolerant person (...) Hinduism as a religion could well be one of the most accommodating in the world. Rather than confront and destroy, it has a tendency to welcome and assimilate." According to Rudolf C Heredia, religious conversion was a critical issue even before the creation of the modern state. Mohandas K. Gandhi opposed the Christian missionaries calling them as the remnants of colonial Western culture. He claimed that by converting into Christianity, Hindus have changed their nationality.

In its controversial annual human rights reports for 1999, the United States Department of State criticised India for "increasing societal violence against Christians." The report listed over 90 incidents of anti-Christian violence, ranging from damage of religious property to violence against Christians pilgrims. In 1997, twenty-four such incidents were reported. Recent waves of anti-conversion laws passed by some Indian states like Chhattisgarh, Gujarat, Madhya Pradesh is claimed to be a gradual and continuous institutionalization of Hindutva by the Bureau of Democracy, Human Rights and Labour of the US State Department.

North Korea is an atheist state where the public practice of religion is discouraged. "The Oxford Handbook of Atheism" states that "North Korea maintains a state-sanctioned and enforced atheism".

North Korea leads the list of the 50 countries in which Christians are persecuted the most at the current time according to a watchlist by Open Doors. It is currently estimated that more than 50,000 Christians are locked inside concentration camps because of their faith, where they are systematically subjected to mistreatment such as unrestrained torture, mass-starvation and even imprisonment and death by asphyxiation in gas chambers. This means that 20% of North Korea's Christian community lives in concentration camps. The number of Christians who are being murdered for their faith seems to be increasing as time goes on because in 2013 the death toll was 1,200 and in 2014, this figure doubled, rendering it close to 2,400 martyred Christians. North Korea has earned the top spot 12 years in a row.

The establishment of French Indochina once led to a high Christian population. Regime changes throughout the 19th and 20th centuries led to increased persecutions of minority religious groups. The Center for Public Policy Analysis has claimed that killings, torture or imprisonment and forced starvation of local groups are common in parts of Vietnam and Laos. In more recent years they have said there is growing persecution of Christians.





</doc>
<doc id="25079" url="https://en.wikipedia.org/wiki?curid=25079" title="Pet">
Pet

A pet, or companion animal, is an animal kept primarily for a person's company, entertainment or as an act of compassion such as taking in and protecting a stray cat, rather than as a working animal, livestock or laboratory animal. Popular pets are often considered to have attractive appearances, intelligence and relatable personalities, but some pets may be taken in on an altruistic basis and accepted as they are.

Two of the most popular pets are dogs and cats. The technical term for a cat lover is an ailurophile, and for a dog lover, a cynophile. Other animals commonly kept include: rabbits; ferrets; pigs; rodents, such as gerbils, hamsters, chinchillas, rats, mice, and guinea pigs; avian pets, such as parrots, passerines and fowls; reptile pets, such as turtles, alligators, crocodiles, lizards, and snakes; aquatic pets, such as fish, freshwater and saltwater snails, amphibians like frogs and salamanders; and arthropod pets, such as tarantulas and hermit crabs. Small pets may be grouped together as pocket pets, while the equine and bovine group include the largest companion animals.

Pets provide their owners (or "guardians") both physical and emotional benefits. Walking a dog can provide both the human and the dog with exercise, fresh air and social interaction. Pets can give companionship to people who are living alone or elderly adults who do not have adequate social interaction with other people. There is a medically approved class of therapy animals, mostly dogs or cats, that are brought to visit confined humans, such as children in hospitals or elders in nursing homes. Pet therapy utilizes trained animals and handlers to achieve specific physical, social, cognitive or emotional goals with patients.

People most commonly get pets for companionship, to protect a home or property or because of the beauty or attractiveness of the animals. Aside from lack of desire, the most common reasons for not owning a pet are lack of time, lack of suitable housing and lack of ability to care for the pet when traveling. Some scholars, ethicists and animal rights organizations have raised concerns over keeping pets because of the lack of autonomy and objectification of non-human animals.
In China, spending on domestic animals has grown from an estimated $3.12 billion in 2010 to $25 billion in 2018. The Chinese people own 51 million dogs and 41 million cats, with pet owners often preferring to source pet food internationally. There are a total of 755 million pets, increased from 389 million in 2013.

According to a survey promoted by Italian family associations in 2009, it is estimated that there are approximately 45 million pets in Italy. This includes 7 million dogs, 7.5 million cats, 16 million fish, 12 million birds, and 10 million snakes.

A 2007 survey by the University of Bristol found that 26% of UK households owned cats and 31% owned dogs, estimating total domestic populations of approximately 10.3 million cats and 10.5 million dogs in 2006. The survey also found that 47.2% of households with a cat had at least one person educated to degree level, compared with 38.4% of homes with dogs.

Sixty-eight percent of U.S. households, or about 85 million families, own a pet, according to the 2017-2018 National Pet Owners Survey conducted by the American Pet Products Association (APPA). This is up from 56 percent of U.S. households in 1988, the first year the survey was conducted.There are approximately 86.4 million pet cats and approximately 78.2 million pet dogs in the United States, and a United States 2007–2008 survey showed that dog-owning households outnumbered those owning cats, but that the total number of pet cats was higher than that of dogs. The same was true for 2011. In 2013, pets outnumbered children four to one in the United States.

Keeping animals as pets may be detrimental to their health if certain requirements are not met. An important issue is inappropriate feeding, which may produce clinical effects. The consumption of chocolate or grapes by dogs, for example, may prove fatal.

Certain species of houseplants can also prove toxic if consumed by pets. Examples include philodendrons and Easter lilies (which can cause severe kidney damage to cats) and poinsettias, begonia, and aloe vera (which are mildly toxic to dogs).

Housepets, particularly dogs and cats in industrialized societies, are also highly susceptible to obesity. Overweight pets have been shown to be at a higher risk of developing diabetes, liver problems, joint pain, kidney failure, and cancer. Lack of exercise and high-caloric diets are considered to be the primary contributors to pet obesity.

It is widely believed among the public, and among many scientists, that pets probably bring mental and physical health benefits to their owners; a 1987 NIH statement cautiously argued that existing data was "suggestive" of a significant benefit. A recent dissent comes from a 2017 RAND study, which found that at least in the case of children, having a pet "per se" failed to improve physical or mental health by a statistically significant amount; instead, the study found children who were already prone to being healthy were more likely to get pets in the first place. Unfortunately, conducting long-term randomized trials to settle the issue would be costly or infeasible.

Pets might have the ability to stimulate their caregivers, in particular the elderly, giving people someone to take care of, someone to exercise with, and someone to help them heal from a physically or psychologically troubled past. Animal company can also help people to preserve acceptable levels of happiness despite the presence of mood symptoms like anxiety or depression. Having a pet may also help people achieve health goals, such as lowered blood pressure, or mental goals, such as decreased stress. There is evidence that having a pet can help a person lead a longer, healthier life. In a 1986 study of 92 people hospitalized for coronary ailments, within a year, 11 of the 29 patients without pets had died, compared to only 3 of the 52 patients who had pets. Having pet(s) was shown to significantly reduce triglycerides, and thus heart disease risk, in the elderly. A study by the National Institute of Health found that people who owned dogs were less likely to die as a result of a heart attack than those who did not own one. There is some evidence that pets may have a therapeutic effect in dementia cases. Other studies have shown that for the elderly, good health may be a requirement for having a pet, and not a result. Dogs trained to be guide dogs can help people with vision impairment. Dogs trained in the field of Animal-Assisted Therapy (AAT) can also benefit people with other disabilities.

People residing in a long-term care facility, such as a hospice or nursing home, may experience health benefits from pets. Pets help them to cope with the emotional issues related to their illness. They also offer physical contact with another living creature, something that is often missing in an elder's life. Pets for nursing homes are chosen based on the size of the pet, the amount of care that the breed needs, and the population and size of the care institution. Appropriate pets go through a screening process and, if it is a dog, additional training programs to become a therapy dog. There are three types of therapy dogs: facility therapy dogs, animal-assisted therapy dogs, and therapeutic visitation dogs. The most common therapy dogs are therapeutic visitation dogs. These dogs are household pets whose handlers take time to visit hospitals, nursing homes, detention facilities, and rehabilitation facilities. Different pets require varying amounts of attention and care; for example, cats may have lower maintenance requirements than dogs.

In addition to providing health benefits for their owners, pets also impact the social lives of their owners and their connection to their community. There is some evidence that pets can facilitate social interaction. Assistant Professor of Sociology at the University of Colorado at Boulder, Leslie Irvine has focused her attention on pets of the homeless population. Her studies of pet ownership among the homeless found that many modify their life activities for fear of losing their pets. Pet ownership prompts them to act responsibly, with many making a deliberate choice not to drink or use drugs, and to avoid contact with substance abusers or those involved in any criminal activity for fear of being separated from their pet. Additionally, many refuse to house in shelters if their pet is not allowed to stay with them.

Health risks that are associated with pets include:

States, cities, and towns in Western nations commonly enact local ordinances to limit the number or kind of pets a person may keep personally or for business purposes. Prohibited pets may be specific to certain breeds (such as pit bulls or Rottweilers), they may apply to general categories of animals (such as livestock, exotic animals, wild animals, and canid or felid hybrids), or they may simply be based on the animal's size. Additional or different maintenance rules and regulations may also apply. Condominium associations and owners of rental properties also commonly limit or forbid tenants' keeping of pets.

The keeping of animals as pets can cause concerns with regard to animal rights and welfare. Pets have commonly been considered private property, owned by individual persons. However, many legal protections have existed (historically and today) with the intention of safeguarding pets' (and other animals') well-being. Since the year 2000, a small but increasing number of jurisdictions in North America have enacted laws redefining pet's "owners" as "guardians". Intentions have been characterized as simply changing attitudes and perceptions (but not legal consequences) to working toward legal personhood for pets themselves. Some veterinarians and breeders have opposed these moves. The question of pets' legal status can arise with concern to purchase or adoption, custody, divorce, estate and inheritance, injury, damage, and veterinary malpractice.

Pets have a considerable environmental impact, especially in countries where they are common or held in high densities. For instance, the 163 million dogs and cats kept in the United States consume about 20% of the amount of dietary energy that humans do and an estimated 33% of the animal-derived energy. They produce about 30% ± 13%, by mass, as much feces as Americans, and through their diet, constitute about 25–30% of the environmental impacts from animal production in terms of the use of land, water, fossil fuel, phosphate, and biocides. Dog and cat animal product consumption is responsible for the release of up to 64 ± 16 million tons CO-equivalent methane and nitrous oxide, two powerful greenhouse gasses. Americans are the largest pet owners in the world, but pet ownership in the US has considerable environmental costs.

While many people have kept many different species of animals in captivity over the course of human history, only a relative few have been kept long enough to be considered domesticated. Other types of animals, notably monkeys, have never been domesticated but are still sold and kept as pets. There are also inanimate objects that have been kept as "pets", either as a form of a game or humorously (e.g. the Pet Rock or Chia Pet).Some wild animals are kept as pets, such as tigers, even though this is illegal. There is a market for illegal pets.

Domesticated pets are the most common types of pet. A "domesticated animal" is any animal that has been tamed and made fit for a human environment by being consistently kept in captivity and selectively bred over a long enough period of time that it exhibits marked differences in behavior and appearance from its wild relatives.





Wild animals are kept as pets. The term “wild” in this context specifically applies to any species of animal which has not undergone a fundamental change in behavior to facilitate a close co-existence with humans. Some species may have been bred in captivity for a considerable length of time, but are still not recognized as domesticated.

Generally, wild animals are recognized as not suitable to keep as pets, and this practice is completely banned in many places. In other areas, certain species are allowed to be kept, and it is usually required for the owner to obtain a permit. It is considered animal cruelty by some, as most often, wild animals require precise and constant care that is very difficult to meet in captive conditions. Many large and instinctively aggressive animals are extremely dangerous, and numerous times have they killed their handlers.

Archaeology suggests that human ownership of dogs as pets may date back to at least 12,000 years ago.
Ancient Greeks and Romans would openly grieve for the loss of a dog, evidenced by inscriptions left on tombstones commemorating their loss. The surviving epitaphs dedicated to horses are more likely to reference a gratitude for the companionship that had come from war horses rather than race horses. The latter may have chiefly been commemorated as a way to further the owner's fame and glory. In Ancient Egypt, dogs and baboons were kept as pets and buried with their owners. Dogs were given names, which is significant as Egyptians considered names to have magical properties. 

Throughout the seventeenth and eighteenth-century pet keeping in the modern sense gradually became accepted throughout Britain. Initially, aristocrats kept dogs for both companionship and hunting. Thus, pet keeping was a sign of elitism within society. By the nineteenth century, the rise of the middle class stimulated the development of pet keeping and it became inscribed within the bourgeois culture.

As the popularity of pet-keeping in the modern sense rose during the Victorian era, animals became a fixture within urban culture as commodities and decorative objects. Pet keeping generated a commercial opportunity for entrepreneurs. By the mid-nineteenth century, nearly twenty thousand street vendors in London dealt with live animals. Also, the popularity of animals developed a demand for animal goods such as accessories and guides for pet keeping. Pet care developed into a big business by the end of the nineteenth century.

Profiteers also sought out pet stealing as a means for economic gain. Utilizing the affection that owners had for their pets, professional dog stealers would capture animals and hold them for ransom. The development of dog stealing reflects the increased value of pets. Pets gradually became defined as the property of their owners. Laws were created that punished offenders for their burglary.

Pets and animals also had social and cultural implications throughout the nineteenth century. The categorization of dogs by their breeds reflected the hierarchical, social order of the Victorian era. The pedigree of a dog represented the high status and lineage of their owners and reinforced social stratification. Middle-class owners, however, valued the ability to associate with the upper-class through ownership of their pets. The ability to care for a pet signified respectability and the capability to be self-sufficient. According to Harriet Ritvo, the identification of “elite animal and elite owner was not a confirmation of the owner’s status but a way of redefining it.”

The popularity of dog and pet keeping generated animal fancy. Dog fanciers showed enthusiasm for owning pets, breeding dogs, and showing dogs in various shows. The first dog show took place on 28 June 1859 in Newcastle and focused mostly on sporting and hunting dogs. However, pet owners produced an eagerness to demonstrate their pets as well as have an outlet to compete. Thus, pet animals gradually were included within dog shows. The first large show, which would host one thousand entries, took place in Chelsea in 1863. The Kennel Club was created in 1873 to ensure fairness and organization within dog shows. The development of the "Stud Book" by the Kennel Club defined policies, presented a national registry system of purebred dogs, and essentially institutionalized dog shows.

Pet ownership by animals in the wild, as an analogue to the human phenomenon, has not been observed and is likely non-existent in nature. One group of capuchin monkeys was observed appearing to care for a marmoset, a fellow New World monkey species, however observations of chimpanzees apparently "playing" with small animals like hyraxes have ended with the chimpanzees killing the animals and tossing the corpses around.

A 2010 study states that human relationships with animals have an exclusive human cognitive component and that pet-keeping is a fundamental and ancient attribute of the human species. Anthropomorphism, or the projection of human feelings, thoughts and attributes on to animals, is a defining feature of human pet-keeping. The study identifies it as the same trait in evolution responsible for domestication and concern for animal welfare. It is estimated to have arisen at least 100,000 years before present (ybp) in "Homo sapiens sapiens".

It is debated whether this redirection of human nurturing behaviour towards non-human animals, in the form of pet-keeping, was maladaptive, due to being biologically costly, or whether it was positively selected for. Two studies suggest that the human ability to domesticate and keep pets came from the same fundamental evolutionary trait and that this trait provided a material benefit in the form of domestication that was sufficiently adaptive to be positively selected for. A 2011 study suggests that the practical functions that some pets provide, such as assisting hunting or removing pests, could've resulted in enough evolutionary advantage to allow for the persistence of this behaviour in humans and outweigh the economic burden held by pets kept as playthings for immediate emotional rewards. Two other studies suggest that the behaviour constitutes an error, side effect or misapplication of the evolved mechanisms responsible for human empathy and theory of mind to cover non-human animals which has not sufficiently impacted its evolutionary advantage in the long run.

Animals in captivity, with the help of caretakers, have been considered to have owned "pets". Examples of this include Koko the gorilla and several pet cats, Tonda the orangutan and a pet cat and Tarra the elephant and a dog named Bella.





</doc>
