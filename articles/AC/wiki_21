<doc id="26284" url="https://en.wikipedia.org/wiki?curid=26284" title="Richard III of England">
Richard III of England

Richard III (2 October 145222 August 1485) was King of England and Lord of Ireland from 1483 until his death in 1485. He was the last king of the House of York and the last of the Plantagenet dynasty. His defeat and death at the Battle of Bosworth Field, the last decisive battle of the Wars of the Roses, marked the end of the Middle Ages in England. He is the protagonist of "Richard III", one of William Shakespeare's history plays.

When his brother Edward IV died in April 1483, Richard was named Lord Protector of the realm for Edward's eldest son and successor, the 12-year-old Edward V. Arrangements were made for Edward's coronation on 22 June 1483. Before the king could be crowned, the marriage of his parents was declared bigamous and therefore invalid. Now officially illegitimate, their children were barred from inheriting the throne. On 25 June, an assembly of lords and commoners endorsed a declaration to this effect and proclaimed Richard as the rightful king. He was crowned on 6 July 1483. The young princes, Edward and his younger brother Richard, Duke of York, were not seen in public after August and accusations circulated that they had been murdered on Richard's orders.

There were two major rebellions against Richard during his reign. In October 1483, an unsuccessful revolt was led by staunch allies of Edward IV and Richard's former ally, Henry Stafford, 2nd Duke of Buckingham. Then in August 1485, Henry Tudor and his uncle, Jasper Tudor, landed in southern Wales with a contingent of French troops and marched through Pembrokeshire, recruiting soldiers. Henry's forces defeated Richard's army near the Leicestershire town of Market Bosworth. Richard was slain, making him the last English king to die in battle. Henry Tudor then ascended the throne as Henry VII.

Richard's corpse was taken to the nearby town of Leicester and buried without pomp. His original tomb monument is believed to have been removed during the English Reformation, and his remains were lost, as they were believed to have been thrown into the River Soar. In 2012, an archaeological excavation was commissioned by the Richard III Society on the site previously occupied by Greyfriars Priory Church. The University of Leicester identified the skeleton found in the excavation as that of Richard III as a result of radiocarbon dating, comparison with contemporary reports of his appearance, and comparison of his mitochondrial DNA with that of two matrilineal descendants of Richard III's eldest sister, Anne of York. He was reburied in Leicester Cathedral on 26 March 2015.

Richard was born on 2 October 1452 at Fotheringhay Castle in Northamptonshire, the eleventh of the twelve children of Richard, Duke of York, and Cecily Neville, and the youngest to survive infancy. His childhood coincided with the beginning of what has traditionally been labelled the 'Wars of the Roses', a period of political instability and periodic open civil war in England during the second half of the fifteenth century, between the Yorkists, who supported Richard's father (a potential claimant to the throne of King Henry VI from birth), and opposed the regime of Henry VI and his wife, Margaret of Anjou, and the Lancastrians, who were loyal to the crown. In 1459, his father and the Yorkists were forced to flee England, whereupon Richard and his older brother George were placed in the custody of their aunt the Duchess of Buckingham, and possibly of the Archbishop of Canterbury.

When their father and elder brother Edmund, Earl of Rutland, were killed at the Battle of Wakefield on 30 December 1460, Richard and George were sent by their mother to the Low Countries. They returned to England following the defeat of the Lancastrians at the Battle of Towton. They participated in the coronation of Richard's eldest brother as King Edward IV on 28 June 1461, when Richard was named Duke of Gloucester and made both a Knight of the Garter and a Knight of the Bath. Edward appointed him the sole Commissioner of Array for the Western Counties in 1464 when he was 11. By the age of 17, he had an independent command.

Richard spent several years during his childhood at Middleham Castle in Wensleydale, Yorkshire, under the tutelage of his cousin the Earl of Warwick, later known as 'the Kingmaker' because of his role in the Wars of the Roses. Warwick supervised Richard's training as a knight; in the autumn of 1465 Edward IV granted Warwick Â£1000 for the expenses of his younger brother's tutelage. With some interruptions, Richard stayed at Middleham either from late 1461 until early 1465, when he was 12 or from 1465 until his coming of age in 1468, when he turned 16. While at Warwick's estate, it is likely that he met both Francis Lovell, who would be his firm supporter later in his life, and Warwick's younger daughter, his future wife Anne Neville.

It is possible that even at this early stage Warwick was considering the king's brothers as strategic matches for his daughters, Isabel and Anne: young aristocrats were often sent to be raised in the households of their intended future partners, as had been the case for the young dukes' father, Richard of York. As the relationship between the king and Warwick became strained, Edward IV opposed the match. During Warwick's lifetime, George was the only royal brother to marry one of his daughters, the eldest, Isabel, on 12 July 1469, without the king's permission. George joined his father-in-law's revolt against the king, while Richard remained loyal to Edward, even though rumour coupled Richard's name with Anne Neville until August 1469.

Richard and Edward were forced to flee to Burgundy in October 1470 after Warwick defected to the side of the former Lancastrian queen Margaret of Anjou. In 1468, Richard's sister Margaret had married Charles the Bold, the Duke of Burgundy, and the brothers could expect a welcome there. Edward was restored to the throne in the spring of 1471, following the battles of Barnet and Tewkesbury, in both of which the eighteen-year-old Richard played a crucial role.

During his adolescence, and due to a cause that is unknown, Richard developed a sideways curvature of the spine. In 2014, after the discovery of Richard's remains, the osteoarchaeologist Dr. Jo Appleby, of Leicester University's School of Archaeology and Ancient History, imaged the spinal column and reconstructed a model using 3D printing, and concluded that though the spinal scoliosis looked dramatic, it probably did not cause any major physical deformity that could not be disguised by clothing.

Following a decisive Yorkist victory over the Lancastrians at the Battle of Tewkesbury, Richard married Anne Neville, the younger daughter of the Earl of Warwick, on 12 July 1472. By the end of 1470 Anne had previously been wedded to Edward of Westminster, only son of Henry VI, to seal her father's allegiance to the Lancastrian party. Edward died at the Battle of Tewkesbury on 4 May 1471, while Warwick had died at the Battle of Barnet on 14 April 1471. Richard's marriage plans brought him into conflict with his brother George. John Paston's letter of 17 February 1472 makes it clear that George was not happy about the marriage but grudgingly accepted it on the basis that "he may well have my Lady his sister-in-law, but they shall part no livelihood". The reason was the inheritance Anne shared with her elder sister Isabel, whom George had married in 1469. It was not only the earldom that was at stake; Richard Neville had inherited it as a result of his marriage to Anne Beauchamp, who was still alive (and outlived both her daughters) and was technically the owner of the substantial Beauchamp estates, her own father having left no male heirs.

The Croyland Chronicle records that Richard agreed to a prenuptial contract in the following terms: "the marriage of the Duke of Gloucester with Anne before-named was to take place, and he was to have such and so much of the earl's lands as should be agreed upon between them through the mediation of arbitrators; while all the rest were to remain in the possession of the Duke of Clarence".

The date of Paston's letter suggests the marriage was still being negotiated in February 1472. In order to win his brother George's final consent to the marriage, Richard renounced most of Warwick's land and property including the earldoms of Warwick (which the Kingmaker had held in his wife's right) and Salisbury and surrendered to Clarence the office of Great Chamberlain of England. Richard retained Neville's forfeit estates he had already been granted in the summer of 1471: Penrith, Sheriff Hutton and Middleham, where he later established his marital household.

The requisite Papal dispensation was obtained dated 22 April 1472. Michael Hicks has suggested that the terms of the dispensation deliberately understated the degrees of consanguinity between the couple, and the marriage was therefore illegal on the ground of first degree consanguinity following George's marriage to Anne's sister Isabel. First-degree consanguinity applied in the case of Henry VIII and his brother's widow Catherine of Aragon. In their case, the papal dispensation was obtained after Catherine declared the first marriage had not been consummated. In Richard's case, there would have been first-degree consanguinity if Richard had sought to marry Isabel (in case of widowhood) after she had married his brother George, but no such consanguinity applied for Anne and Richard. Richard's marriage to Anne was never declared null, and it was public to everyone including secular and canon lawyers for 13 years.

In June 1473, Richard persuaded his mother-in-law to leave the sanctuary and come to live under his protection at Middleham. Later in the year, under the terms of the 1473 Act of Resumption, George lost some of the property he held under royal grant and made no secret of his displeasure. John Paston's letter of November 1473 says that the king planned to put both his younger brothers in their place by acting as "a stifler atween them".

Early in 1474, Parliament assembled and King Edward attempted to reconcile his brothers by stating that both men, and their wives, would enjoy the Warwick inheritance just as if the Countess of Warwick "was naturally dead". The doubts cast by Clarence on the validity of Richard and Anne's marriage were addressed by a clause protecting their rights in the event they were divorced (i.e. of their marriage being declared null and void by the Church) and then legally remarried to each other, and also protected Richard's rights while waiting for such a valid second marriage with Anne. The following year, Richard was rewarded with all the Neville lands in the north of England, at the expense of Anne's cousin, George Neville. From this point, Clarence seems to have fallen steadily out of King Edward's favour, his discontent coming to a head in 1477 when, following Isabel's death, he was denied the opportunity to marry Mary of Burgundy, the stepdaughter of his sister Margaret, even though Margaret approved the proposed match. There is no evidence of Richard's involvement in George's subsequent conviction and execution on a charge of treason.

Richard was granted the Duchy of Gloucester on 1 November 1461, and on 12 August the next year was awarded large estates in northern England, including the lordships of Richmond in Yorkshire, and Pembroke in Wales. He gained the forfeited lands of the Lancastrian John de Vere, Earl of Oxford, in East Anglia. In 1462, on his birthday, he was made Constable of Gloucester and Corfe Castles and Admiral of England, Ireland and Aquitaine and appointed Governor of the North, becoming the richest and most powerful noble in England. On 17 October 1469, he was made Constable of England. In November, he replaced William Hastings, 1st Baron Hastings, as Chief Justice of North Wales. The following year, he was appointed Chief Steward and Chamberlain of Wales. On 18 May 1471, Richard was named Great Chamberlain and Lord High Admiral of England. Other positions followed: High Sheriff of Cumberland for life, Lieutenant of the North and Commander-in-Chief against the Scots and hereditary Warden of the West March. Two months later, on 14 July, he gained the Lordships of the strongholds Sheriff Hutton and Middleham in Yorkshire and Penrith in Cumberland, which had belonged to Warwick the Kingmaker. It is possible that the grant of Middleham seconded Richard's personal wishes.

During the latter part of Edward IV's reign, Richard demonstrated his loyalty to the king, in contrast to their brother George who had allied himself with Warwick when the earl rebelled towards the end of the 1460s. Following Warwick's 1470 rebellion, before which he had made peace with Margaret of Anjou and promised the restoration of Henry VI to the English throne, Richard, William, Lord Hastings and Anthony Woodville, Earl Rivers escaped capture at Doncaster by Warwick's brother, Lord Montague. On 2 October they sailed from King's Lynn in two ships; Edward landed at Marsdiep and Richard at Zeeland. It was said that, having left England in such haste as to possess almost nothing, Edward was forced to pay their passage with his fur cloak; certainly, Richard borrowed three pounds from Zeeland's town bailiff. They were attainted by Warwick's only Parliament on 26 November. They resided in Bruges with Louis de Gruthuse, who had been the Burgundian Ambassador to Edward's court, but it was not until Louis XI of France declared war on Burgundy that Charles, Duke of Burgundy, assisted their return, providing, along with the Hanseatic merchants, Â£20,000, 36 ships and 1200 men. They departed Flushing for England on 11 March 1471. Warwick's arrest of local sympathisers prevented them from landing in Yorkist East Anglia and on 14 March, after being separated in a storm, their ships ran ashore at Holderness. The town of Hull refused him entry, and Edward gained entry to York by using the same claim as Henry of Bolingbroke had before deposing Richard II in 1399; that is, that he was merely reclaiming the Dukedom of York rather than the crown. It was in Edward's attempt to regain his throne that Gloucester began to demonstrate his skill as a military commander.

Once Edward had regained the support of Clarence, he mounted a swift and decisive campaign to regain the Crown through combat; it is believed that Richard was his principal lieutenant as some of the king's earliest support came from members of Richard's affinity, including Sir James Harrington and Sir William Parr, who brought 600 men-at-arms to them at Doncaster. He may have led the vanguard at the Battle of Barnet, in his first command, on 14 April 1471, where he outflanked the Duke of Exeter's wing, although the degree to which his command was fundamental may have been exaggerated. That his personal household sustained losses indicates he was in the thick of the fighting. A contemporary source is clear about his holding the vanguard for Edward at Tewkesbury, deployed against the Lancastrian vanguard under the Duke of Somerset on 4 May 1471, and his role two days later, as Constable of England, sitting alongside John Howard as Earl Marshal, in the trial and sentencing of leading Lancastrians captured after the battle.

At least in part resentful of the French king's previous support of his Lancastrian opponents, and possibly in support of his brother-in-law Charles the Bold, Duke of Burgundy, Edward went to parliament in October 1472 for funding a military campaign, and eventually landed in Calais on 4 July 1475. Richard's was the largest private contingent of his army. Although well known to have publicly been against the eventual treaty signed with Louis XI at Picquigny (and absent from the negotiations, in which one of his rank would have been expected to take a leading role), he acted as Edward's witness when the king instructed his delegates to the French court, and received 'some very fine presents' from Louis on a visit to the French king at Amiens. In refusing other gifts, which included 'pensions' in the guise of 'tribute', he was joined only by Cardinal Bourchier. He supposedly disapproved of Edward's policy of personally benefittingâpolitically and financiallyâfrom a campaign paid for out of a parliamentary grant, and hence out of public funds. Any military prowess was therefore not to be revealed further until the last years of Edward's reign.

Richard controlled the north of England until Edward IV's death. There, and especially in the city of York, he was highly regarded; although it has been questioned whether this view was reciprocated by Richard. Edward IV set up the Council of the North as an administrative body in 1472 to improve government control and economic prosperity and benefit the whole of Northern England. Kendall and later historians have suggested that this was with the intention of making Richard the "Lord of the North"; Peter Booth, however, has argued that "instead of allowing his brother the Duke of Gloucester "carte blanche", [Edward] restricted his influence by using his own agent, Sir William Parr." Richard served as its first Lord President from 1472 until his accession to the throne. On his accession, he made his nephew John de la Pole, 1st Earl of Lincoln, president and formally institutionalised it as an offshoot of the royal Council; all its letters and judgements were issued on behalf of the king and in his name. The council had a budget of 2000 marks per annum (approximately Â£1320) and had issued "Regulations" by July of that year: councillors to act impartially and declare vested interests, and to meet at least every three months. Its main focus of operations was Yorkshire and the north-east, and its primary responsibilities were land disputes, keeping of the king's peace, and punishing lawbreakers.

Richard's increasing role in the north from the mid-1470s to some extent explains his withdrawal from the royal court. He had been Warden of the West March on the Scottish border since 10 September 1470, and again from May 1471; he used Penrith as a base while 'taking effectual measures' against the Scots, and 'enjoyed the revenues of the estates' of the Forest of Cumberland while doing so. It was at the same time that the duke was appointed sheriff of Cumberland five consecutive years, being described as 'of Penrith Castle' in 1478. By 1480, war with Scotland was looming; on 12 May that year he was appointed Lieutenant-General of the North (a position created for the occasion) as fears of a Scottish invasion grew. Louis XI of France had attempted to negotiate a military alliance with Scotland (in the tradition of the "Auld Alliance"), with the aim of attacking England, according to a contemporary French chronicler. Richard had the authority to summon the Border Levies and issue Commissions of Array to repel the Border raids. Together with the Earl of Northumberland, he launched counter-raids, and when the king and council formally declared war in November 1480, he was granted Â£10,000 for wages. The king failed to arrive to lead the English army and the result was intermittent skirmishing until early 1482. Richard witnessed the treaty with Alexander, Duke of Albany, brother of the Scottish king James III. Northumberland, Stanley, Dorset, Sir Edward Woodville, and Richard with approximately 20,000 men took the town of Berwick almost immediately. The castle held until 24 August 1482, when Richard recaptured Berwick-upon-Tweed from the Kingdom of Scotland. Although it is debatable whether the English victory was due more to internal Scottish divisions rather than any outstanding military prowess by Richard, it was the last time that the Royal Burgh of Berwick changed hands between the two realms.

On the death of Edward IV on 9 April 1483, his 12-year-old son, Edward V, succeeded him. Richard was named Lord Protector of the Realm and at William Hastings' urging, Richard assumed his role and left his base in Yorkshire for London. On 29 April, as previously agreed, Richard and his cousin, the Duke of Buckingham, met Queen Elizabeth's brother, Anthony Woodville, 2nd Earl Rivers, at Northampton. At the queen's request, Earl Rivers was escorting the young king to London with an armed escort of 2000 men, while Richard and Buckingham's joint escort was 600 men.

The young king himself had been sent further south to Stony Stratford. At first convivial, Richard had Earl Rivers, his nephew Richard Grey and his associate, Thomas Vaughan, arrested. They were taken to Pontefract Castle, where they were executed on 25 June on the charge of treason against the Lord Protector after appearing before a tribunal led by Henry Percy, 4th Earl of Northumberland. Earl Rivers had appointed Richard as executor of his will.

After having Earl Rivers arrested, Richard and Buckingham moved to Stony Stratford, where Richard informed the young king of a plot aimed at denying him his role as protector and whose perpetrators had been dealt with. He proceeded to escort the king to London. They entered the city on 4 May, displaying the carriages of weapons Earl Rivers had taken with his 2000-man army. Richard first accommodated Edward in the Bishop's apartments; then, on Buckingham's suggestion, the king was moved to the royal apartments of the Tower of London, where kings customarily awaited their coronation.

On hearing the news of her brother's 30 April arrest, the dowager queen fled to sanctuary in Westminster Abbey. Joining her were her son by her first marriage, Thomas Grey, 1st Marquess of Dorset; her five daughters; and her youngest son, Richard, Duke of York.

On 10/11 June, Richard wrote to Ralph, Lord Neville, the City of York and others asking for their support against "the Queen, her blood adherents and affinity," whom he suspected of plotting his murder. At a council meeting on 13 June at the Tower of London, Richard accused Hastings and others of having conspired against him with the Woodvilles and accusing Jane Shore, lover to both Hastings and Thomas Grey, of acting as a go-between. According to Thomas More, Hastings was taken out of the council chambers and summarily executed in the courtyard, while others, like Lord Thomas Stanley and John Morton, Bishop of Ely, were arrested. Hastings was not attainted and Richard sealed an indenture that placed Hastings' widow, Katherine, directly under his own protection. Bishop Morton was released into the custody of Buckingham.

On 16 June, the dowager queen agreed to hand over the Duke of York to the Archbishop of Canterbury so that he might attend his brother Edward's coronation, still planned for 22 June.

A clergyman is said to have informed Richard that Edward IV's marriage to Elizabeth Woodville was invalid because of Edward's earlier union with Eleanor Butler, making Edward V and his siblings illegitimate. The identity of the informant, known only through the memoirs of French diplomat Philippe de Commines, was Robert Stillington, the Bishop of Bath and Wells. On 22 June, a sermon was preached outside Old St. Paul's Cathedral declaring Edward IV's children bastards and Richard the rightful king. Shortly after, the citizens of London, both nobles and commons, convened and drew up a petition asking Richard to assume the throne. He accepted on 26 June and was crowned at Westminster Abbey on 6 July. His title to the throne was confirmed by Parliament in January 1484 by the document "Titulus Regius".

The princes, who were still lodged in the royal residence of the Tower of London at the time of Richard's coronation, disappeared from sight after the summer of 1483. Although after his death Richard III was accused of having Edward and his brother killed, notably by More and in Shakespeare's play, the facts surrounding their disappearance remain unknown. Other culprits have been suggested, including Buckingham and even Henry VII, although Richard remains a suspect.

After the coronation ceremony, Richard and Anne set out on a royal progress to meet their subjects. During this journey through the country, the king and queen endowed King's College and Queens' College at Cambridge University, and made grants to the church. Still feeling a strong bond with his northern estates, Richard later planned the establishment of a large chantry chapel in York Minster with over 100 priests. Richard also founded the College of Arms.

In 1483, a conspiracy arose among a number of disaffected gentry, many of whom had been supporters of Edward IV and the "whole Yorkist establishment". The conspiracy was nominally led by Richard's former ally and first cousin once removed Henry Stafford, 2nd Duke of Buckingham, although it had begun as a Woodville-Beaufort conspiracy (being "well underway" by the time of the duke's involvement). Indeed, Davies has suggested that it was "only the subsequent parliamentary attainder that placed Buckingham at the centre of events", in order to blame a single disaffected magnate motivated by greed, rather than "the embarrassing truth" that those opposing Richard were actually "overwhelmingly Edwardian loyalists". It is possible that they planned to depose Richard III and place Edward V back on the throne, and that when rumours arose that Edward and his brother were dead, Buckingham proposed that Henry Tudor should return from exile, take the throne and marry Elizabeth of York, elder sister of the Tower Princes. However, it has also been pointed out that as this narrative stems from Richard's own parliament of 1484, it should probably be treated "with caution". For his part, Buckingham raised a substantial force from his estates in Wales and the Marches. Henry, in exile in Brittany, enjoyed the support of the Breton treasurer Pierre Landais, who hoped Buckingham's victory would cement an alliance between Brittany and England.

Some of Henry Tudor's ships ran into a storm and were forced to return to Brittany or Normandy, while Henry himself anchored off Plymouth for a week before learning of Buckingham's failure. Buckingham's army was troubled by the same storm and deserted when Richard's forces came against them. Buckingham tried to escape in disguise, but was either turned in by a retainer for the bounty Richard had put on his head, or was discovered in hiding with him. He was convicted of treason and beheaded in Salisbury, near the Bull's Head Inn, on 2 November. His widow, Catherine Woodville, later married Jasper Tudor, the uncle of Henry Tudor, who was in the process of organising another rebellion.

Richard made overtures to Landais, offering military support for Landais's weak regime under Duke Francis II of Brittany in exchange for Henry. Henry fled to Paris, where he secured support from the French regent Anne of Beaujeu, who supplied troops for an invasion in 1485. The French government, recalling Richard's effective disowning of the Treaty of Picquigny and refusal to accept the accompanying French pension, would not have welcomed the accession of one known to be unfriendly to France.

On 22 August 1485, Richard met the outnumbered forces of Henry Tudor at the Battle of Bosworth Field. Richard rode a white courser. The size of Richard's army has been estimated at 8,000 and Henry's at 5,000, but exact numbers are not known. All that can be said is that the Royal army 'substantially' outnumbered Tudor's. The traditional view of the king's famous cries of "Treason!" before falling was that during the battle Richard was abandoned by Lord Stanley (made Earl of Derby in October), Sir William Stanley, and Henry Percy, 4th Earl of Northumberland. However, the role of Northumberland is unclear; his position was with the reserveâbehind the king's lineâand he could not easily have moved forward without a general royal advance, which did not take place. Indeed, the physical confines behind the crest of Ambion Hill, combined with a difficulty of communications, probably physically hampered any attempt he made to join the fray. Despite appearing "a pillar of the Ricardian regime", and his previous loyalty to Edward IV, Lord Stanley's wife, Lady Margaret Beaufort, was Henry Tudor's mother, and Stanley's inaction, combined with his brother's entering the battle on Tudor's behalf was fundamental to Richard's defeat. The death of John Howard, Duke of Norfolk, his close companion, may have had a demoralising effect on Richard and his men. Either way, Richard led a cavalry charge deep into the enemy ranks in an attempt to end the battle quickly by striking at Henry Tudor himself.

Accounts note that King Richard fought bravely and ably during this manoeuvre, unhorsing Sir John Cheyne, a well-known jousting champion, killing Henry's standard bearer Sir William Brandon and coming within a sword's length of Henry Tudor before being surrounded by Sir William Stanley's men and killed. The Burgundian chronicler Jean Molinet says that a Welshman struck the death-blow with a halberd while Richard's horse was stuck in the marshy ground. It was said that the blows were so violent that the king's helmet was driven into his skull. The contemporary Welsh poet Guto'r Glyn implies a leading Welsh Lancastrian Rhys ap Thomas, or one of his men, killed the king, writing that he "killed the boar, shaved his head". The identification in 2013 of King Richard's body shows that the skeleton had 11 wounds, eight of them to the skull, clearly inflicted in battle and suggesting he had lost his helmet. Professor Guy Rutty, from the University of Leicester, said: "The most likely injuries to have caused the king's death are the two to the inferior aspect of the skullâa large sharp force trauma possibly from a sword or staff weapon, such as a halberd or bill, and a penetrating injury from the tip of an edged weapon." The skull showed that a blade had hacked away part of the rear of the skull. Richard III was the last English king to be killed in battle.

Polydore Vergil, Henry Tudor's official historian, recorded that "King Richard, alone, was killed fighting manfully in the thickest press of his enemies". Richard's naked body was then carried back to Leicester tied to a horse, and early sources strongly suggest that it was displayed in the collegiate Church of the Annunciation of Our Lady of the Newarke, prior to being buried at Greyfriars Church in Leicester. In 1495, Henry VII paid for a marble and alabaster monument. According to a discredited tradition, during the Dissolution of the Monasteries, his body was thrown into the River Soar, although other evidence suggests that a memorial stone was visible in 1612, in a garden built on the site of Greyfriars. The exact location was then lost, owing to more than 400 years of subsequent development, until archaeological investigations in 2012 (see the Discovery of remains section) revealed the site of the garden and Greyfriars church. There was a memorial ledger stone in the choir of the cathedral, since replaced by the tomb of the king, and a stone plaque on Bow Bridge where tradition had falsely suggested that his remains had been thrown into the river.

According to another tradition, Richard consulted a seer in Leicester before the battle who foretold that "where your spur should strike on the ride into battle, your head shall be broken on the return". On the ride into battle, his spur struck the bridge stone of Bow Bridge in the city; legend states that as his corpse was carried from the battle over the back of a horse, his head struck the same stone and was broken open.

Henry Tudor succeeded Richard to become Henry VII and sought to cement the succession by marrying the Yorkist heiress Elizabeth of York, Edward IV's daughter and Richard III's niece.

Richard and Anne produced one son, Edward, who was born between 1474 and 1476. He was created Earl of Salisbury on 15 February 1478, and Prince of Wales on 24 August 1483, and died in March 1484, less than two months after he had been formally declared heir apparent. After his son's death, he named his nephew Edward, Earl of Warwick as his heir. After his wife's death, he named his nephew John de la Pole, Earl of Lincoln, the son of his sister Elizabeth as his successor, and commenced negotiations with John II of Portugal to marry John's sister, Joanna, a pious young woman who had already turned down several suitors because of her preference for the religious life.

Richard had two acknowledged illegitimate children, John of Gloucester and Katherine Plantagenet. Also known as 'John of Pontefract', John of Gloucester was appointed Captain of Calais in 1485. Katherine married William Herbert, 2nd Earl of Pembroke in 1484. Neither the birth dates nor the names of the mothers of either of the children is known. Katherine was old enough to be wedded in 1484, when the age of consent was twelve, and John was knighted in September 1483 in York Minster, and so most historians agree that they were both fathered when Richard was a teenager. There is no evidence of infidelity on Richard's part after his marriage to Anne Neville in 1472 when he was around 20. This has led to a suggestion by the historian A. L. Rowse that Richard "had no interest in sex".

Michael Hicks and Josephine Wilkinson have suggested that Katherine's mother may have been Katherine Haute, on the basis of the grant of an annual payment of 100 shillings made to her in 1477. The Haute family was related to the Woodvilles through the marriage of Elizabeth Woodville's aunt, Joan Woodville, to William Haute. One of their children was Richard Haute, Controller of the Prince's Household. Their daughter, Alice, married Sir John Fogge; they were ancestors to queen consort Catherine Parr, sixth wife of King Henry VIII. They also suggest that John's mother may have been Alice Burgh. Richard visited Pontefract from 1471, in April and October 1473, and in early March 1474, for a week. On 1 March 1474, he granted Alice Burgh Â£20 a year for life "for certain special causes and considerations". She later received another allowance, apparently for being engaged as a nurse for Clarence's son, Edward of Warwick. Richard continued her annuity when he became king. John Ashdown-Hill has suggested that John was conceived during Richard's first solo expedition to the eastern counties in the summer of 1467 at the invitation of John Howard and that the boy was born in 1468 and named after his friend and supporter. Richard himself noted John was still a minor (not being yet 21) when he issued the royal patent appointing him Captain of Calais on 11 March 1485, possibly on his seventeenth birthday.

Both of Richard's illegitimate children survived him, but they seem to have died without issue and their fate after Richard's demise at Bosworth is not certain. John received a Â£20 annuity from Henry VII, but there are no mentions of him in contemporary records after 1487 (the year of the Battle of Stoke Field). He may have been executed in 1499, though no record of this exists beyond an assertion by George Buck over a century later. Katherine apparently died before her cousin Elizabeth of York's coronation on 25 November 1487, since her husband Sir William Herbert is described as a widower by that time. Katherine's burial place was located in the London parish church of St James Garlickhithe, between Skinner's Lane and Upper Thames Street. The mysterious Richard Plantagenet, who was first mentioned in Francis Peck's "Desiderata Curiosa" (a two-volume miscellany published 1732â1735) was said to be a possible illegitimate child of Richard III and is sometimes referred to as "Richard the Master-Builder" or "Richard of Eastwell", but it has also been suggested he could have been Richard, Duke of York, one of the missing Princes in the Tower. He died in 1550.

Richard's Council of the North, described as his "one major institutional innovation", derived from his ducal council following his own viceregal appointment by Edward IV; when Richard himself became king, he maintained the same conciliar structure in his absence. It officially became part of the royal council machinery under the presidency of John de la Pole, Earl of Lincoln in April 1484, based at Sandal Castle in Wakefield. It is considered to have greatly improved conditions for northern England, as it was, in theory at least, intended to keep the peace and punish lawbreakers, as well as resolving land disputes. Bringing regional governance directly under the control of central government, it has been described as the king's "most enduring monument", surviving unchanged until 1641.

In December 1483, Richard instituted what later became known as the Court of Requests, a court to which poor people who could not afford legal representation could apply for their grievances to be heard. He also improved bail in January 1484, to protect suspected felons from imprisonment before trial and to protect their property from seizure during that time. He founded the College of Arms in 1484, he banned restrictions on the printing and sale of books, and he ordered the translation of the written Laws and Statutes from the traditional French into English. He ended the arbitrary benevolences (a device by which Edward IV raised funds), made it punishable to conceal from a buyer of land that a part of the property had already been disposed of to somebody else, required that land sales be published, laid down property qualifications for jurors, restricted the abusive Courts of Piepowders, regulated cloth sales, instituted certain forms of trade protectionism, prohibited the sale of wine and oil in fraudulent measure, and prohibited fraudulent collection of clergy dues, among others. Churchill implies he improved the law of trusts.

Richard's death at Bosworth resulted in the end of the Plantagenet dynasty, which had ruled England since the succession of Henry II in 1154. The last legitimate male Plantagenet, Richard's nephew, Edward, Earl of Warwick (son of Richard III's brother Clarence), was executed by Henry VII in 1499. The only extant direct male line of Plantagenets is the House of Beaufort, headed today by Henry Somerset, 12th Duke of Beaufort, but the Beaufort line was barred from the succession by Henry IV.

There are numerous contemporary, or near-contemporary, sources of information about the reign of Richard III. These include the "Croyland Chronicle", Commines' "MÃ©moires", the report of Dominic Mancini, the Paston Letters, the Chronicles of Robert Fabyan and numerous court and official records, including a few letters by Richard himself. However, the debate about Richard's true character and motives continues, both because of the subjectivity of many of the written sources, reflecting the generally partisan nature of writers of this period, and because of the fact that none was written by men with an intimate knowledge of Richard, even if they had met him in person.

During Richard's reign, the historian John Rous praised him as a "good lord" who punished "oppressors of the commons", adding that he had "a great heart". In 1483 the Italian observer Mancini reported that Richard enjoyed a good reputation and that both "his private life and public activities powerfully attracted the esteem of strangers". His bond to the City of York, in particular, was such that on hearing of Richard's demise at the battle of Bosworth the City Council officially deplored the King's death, at the risk of facing the victor's wrath.

During his lifetime he was the subject of some attacks. Even in the North in 1482 a man was prosecuted for offences against the Duke of Gloucester, saying he did 'nothing but grin at' the city of York. In 1484 the discreditory actions took the form of hostile placards, the only surviving one being William Collingbourne's lampoon of July 1484 "The Cat, the Rat, and Lovell the Dog, all rule England under a Hog" which was pinned to the door of St. Paul's Cathedral and referred to the King himself (the Hog) and his most trusted councillors William Catesby, Richard Ratcliffe and Francis Viscount Lovell. On 30 March 1485 Richard felt forced to summon the Lords and London City Councillors to publicly deny the rumours that he had poisoned Queen Anne and that he had planned a marriage to his niece Elizabeth, at the same time ordering the Sheriff of London to imprison anyone spreading such slanders. The same orders were issued throughout the realm, including York where the royal pronouncement recorded in the City Records dates 5 April 1485 and carries specific instructions to suppress seditious talk and remove and destroy evidently hostile placards unread.

As for Richard's physical appearance, most contemporary descriptions bear out the evidence that aside from having one shoulder higher than the other (with chronicler Rous not able to correctly remember which one, as slight as the difference was), Richard had no other noticeable bodily deformity. John Stow talked to old men who, remembering him, said "that he was of bodily shape comely enough, only of low stature" and a German traveller, Nicolas von Poppelau, who spent ten days in Richard's household in May 1484, describes him as "three fingers taller than himself...much more lean, with delicate arms and legs and also a great heart." Six years after Richard's death, in 1491, a schoolmaster named William Burton, on hearing a defence of Richard, launched into a diatribe, accusing the dead King of being 'a hypocrite and a crookback...who was deservedly buried in a ditch like a dog.'

Richard's death encouraged the furtherance of this later negative image by his Tudor successors due to the fact that it helped to legitimise Henry VII's seizure of the throne. The Richard III Society contends that this means that 'a lot of what people thought they knew about Richard III was pretty much propaganda and myth building.' The Tudor characterisation culminated in the famous fictional portrayal of him in Shakespeare's play "Richard III" as a physically deformed, Machiavellian villain, ruthlessly committing numerous murders in order to claw his way to power; Shakespeare's intention perhaps being to use Richard III as a vehicle for creating his own Marlowesque protagonist. Rous himself, in his "History of the Kings of England", written during Henry VII's reign, initiated the process. He reversed his earlier position, and now portrayed Richard as a freakish individual who was born with teeth and shoulder-length hair after having been in his mother's womb for two years. His body was stunted and distorted, with one shoulder higher than the other, and he was "slight in body and weak in strength". Rous also attributes the murder of Henry VI to Richard, and claims that he poisoned his own wife. Jeremy Potter, a former Chair of the Richard III Society, claims that "At the bar of history Richard III continues to be guilty because it is impossible to prove him innocent. The Tudors ride high in popular esteem."

Polydore Vergil and Thomas More expanded on this portrayal, emphasising Richard's outward physical deformities as a sign of his inwardly twisted mind. More describes him as "little of stature, ill-featured of limbs, crook-backedÂ ... hard-favoured of visage". Vergil also says he was "deformed of bodyÂ ... one shoulder higher than the right". Both emphasise that Richard was devious and flattering, while planning the downfall of both his enemies and supposed friends. Richard's good qualities were his cleverness and bravery. All these characteristics are repeated by Shakespeare, who portrays him as having a hunch, a limp and a withered arm. With regard to the "hunch", the second quarto edition of "Richard III" (1598) used the term "hunched-backed" but in the First Folio edition (1623) it became "bunch-backed".

Richard's reputation as a promoter of legal fairness persisted, however. William Camden in his "Remains Concerning Britain" (1605) states that Richard, "albeit he lived wickedly, yet made good laws". Francis Bacon also states that he was "a good lawmaker for the ease and solace of the common people". In 1525, Cardinal Wolsey upbraided the aldermen and Mayor of London for relying on a statute of Richard to avoid paying an extorted tax (benevolence) but received the reply 'although he did evil, yet in his time were many good acts made.'

Despite this, the image of Richard as a ruthless power-grabber remained dominant in the 18th and 19th centuries. The 18th century philosopher and historian David Hume described him as a man who used dissimulation to conceal "his fierce and savage nature" and who had "abandoned all principles of honour and humanity". Hume acknowledged that some historians have argued "that he was well qualified for government, had he legally obtained it; and that he committed no crimes but such as were necessary to procure him possession of the crown", but he dismissed this view on the grounds that Richard's exercise of arbitrary power encouraged instability. The most important late 19th-century biographer of the king was James Gairdner, who also wrote the entry on Richard in the "Dictionary of National Biography". Gairdner stated that he had begun to study Richard with a neutral viewpoint, but became convinced that Shakespeare and More were essentially correct in their view of the king, despite some exaggerations.

Richard was not without his defenders, the first of whom was George Buck, a descendant of one of the king's supporters, who completed a historical account of Richard's life in 1619. Buck attacked the "improbable imputations and strange and spiteful scandals" related by Tudor writers, including Richard's alleged deformities and murders. He located lost archival material, including the "Titulus Regius", but also claimed to have seen a letter written by Elizabeth of York, according to which Elizabeth sought to marry the king. Though the book was published in 1646, Elizabeth's supposed letter was never produced. Documents which later emerged from the Portuguese Royal archives show that after Queen Anne's death, Richard's ambassadors were sent on a formal errand to negotiate a double marriage between Richard and the Portuguese King's sister Joana, of Lancastrian descent, and between Elizabeth of York and Joana's cousin Duke Manuel (later King of Portugal).

Significant among Richard's defenders was Horace Walpole. In "Historic Doubts on the Life and Reign of King Richard the Third" (1768), Walpole disputed all the alleged murders and argued that Richard may have acted in good faith. He also argued that any physical abnormality was probably no more than a minor distortion of the shoulders. However, he retracted his views in 1793 after the Terror, stating he now believed that Richard could have committed the crimes he was charged with, although Pollard observes that this retraction is frequently overlooked by later admirers of Richard. Other defenders of Richard include the noted explorer Clements Markham, whose "Richard III: His Life and Character" (1906) replied to the work of Gairdner. He argued that Henry VII killed the princes and that the bulk of evidence against Richard was nothing more than Tudor propaganda. An intermediate view was provided by Alfred Legge in "The Unpopular King" (1885). Legge argued that Richard's "greatness of soul" was eventually "warped and dwarfed" by the ingratitude of others.

Some twentieth-century historians have been less inclined to moral judgement, seeing Richard's actions as a product of the unstable times. In the words of Charles Ross, "the later fifteenth century in England is now seen as a ruthless and violent age as concerns the upper ranks of society, full of private feuds, intimidation, land-hunger, and litigiousness, and consideration of Richard's life and career against this background has tended to remove him from the lonely pinnacle of Villainy Incarnate on which Shakespeare had placed him. Like most men, he was conditioned by the standards of his age." The Richard III Society, founded in 1924 as "The Fellowship of the White Boar", is the oldest of several groups dedicated to improving his reputation. Other contemporary historians still describe him as, a "power-hungry and ruthless politician" who was still most probably "ultimately responsible for the murder of his nephews."

Apart from Shakespeare, Richard appears in many other works of literature. Two other plays of the Elizabethan era predated Shakespeare's work. The Latin-language drama "Richardus Tertius" (first known performance in 1580) by Thomas Legge is believed to be the first history play written in England. The anonymous play "The True Tragedy of Richard III" (c. 1590), performed in the same decade as Shakespeare's work, was probably an influence on Shakespeare. Neither of the two plays places any emphasis on Richard's physical appearance, though the "True Tragedy" briefly mentions that he is "A man ill shaped, crooked backed, lame armed" adding that he is "valiantly minded, but tyrannous in authority". Both portray him as a man motivated by personal ambition, who uses everyone around him to get his way. Ben Jonson is also known to have written a play "Richard Crookback" in 1602, but it was never published and nothing is known about its portrayal of the king.

Marjorie Bowen's 1929 novel "Dickon" set the trend for pro-Ricardian literature. Particularly influential was "The Daughter of Time" (1951) by Josephine Tey, in which a modern detective concludes that Richard III is innocent in the death of the Princes. Other novelists such as Valerie Anand in the novel "Crown of Roses" (1989) have also offered alternative versions to the theory that he murdered them. Sharon Kay Penman, in her historical novel "The Sunne in Splendour", attributes the death of the Princes to the Duke of Buckingham. In the mystery novel "The Murders of Richard III" by Elizabeth Peters (1974) the central plot revolves around the debate as to whether Richard III was guilty of these and other crimes. A sympathetic portrayal of Richard III is given in "The Founding" (1980), the first volume in "The Morland Dynasty" series by Cynthia Harrod-Eagles.

One film adaptation of Shakespeare's play "Richard III" is the 1955 version directed and produced by Laurence Olivier, who also played the lead role. Also notable are the 1995 film version starring Ian McKellen, set in a fictional 1930s fascist England, and "Looking for Richard", a 1996 documentary film directed by Al Pacino, who plays the title character as well as himself. The play has been adapted for television on several occasions.
On 24 August 2012, the University of Leicester and Leicester City Council, in association with the Richard III Society, announced that they had joined forces to begin a search for the remains of King Richard. The search for Richard III was led by Philippa Langley of the Society's "Looking For Richard" Project with the archaeological work led by University of Leicester Archaeological Services (ULAS). Experts set out to locate the lost site of the former Greyfriars Church (demolished during Henry VIII's dissolution of the monasteries), and to discover whether his remains were still interred there. By comparing fixed points between maps in a historical sequence, the search located the Church of the Grey Friars, where Richard's body had been hastily buried without pomp in 1485, its foundations identifiable beneath a modern-day city centre car park.

On 5 September 2012, the excavators announced that they had identified Greyfriars church and two days later that they had identified the location of Robert Herrick's garden, where the memorial to Richard III stood in the early 17th century. A human skeleton was found beneath the Church's choir.

Improbably, the excavators found the remains in the first location in which they dug at the car park. Coincidentally, they lay almost directly under a roughly painted "R" on the tarmac. This had existed since the early 2000s to signify a reserved parking space.

On 12 September, it was announced that the skeleton discovered during the search might be that of Richard III. Several reasons were given: the body was of an adult male; it was buried beneath the choir of the church; and there was severe scoliosis of the spine, possibly making one shoulder higher than the other (to what extent depended on the severity of the condition). Additionally, there was an object that appeared to be an arrowhead embedded in the spine; and there were perimortem injuries to the skull. These included a relatively shallow orifice, which is most likely to have been caused by a rondel dagger, and a scooping depression to the skull, inflicted by a bladed weapon, most probably a sword. Additionally, the bottom of the skull presented a gaping hole, where a halberd had cut away and entered it. 

Forensic pathologist Dr Stuart Hamilton stated that this injury would have left the individual's brain visible, and most certainly would have been the cause of death. Dr Jo Appleby, the osteo-archaeologist who excavated the skeleton, concurred and described the latter as "a mortal battlefield wound in the back of the skull". The base of the skull also presented another fatal wound in which a bladed weapon had been thrust into it, leaving behind a jagged hole. Closer examination of the interior of the skull revealed a mark opposite this wound, showing that the blade penetrated to a depth of . 

In total, the skeleton presented ten wounds: four minor injuries on the top of the skull, one dagger blow on the cheekbone, one cut on the lower jaw, two fatal injuries on the base of the skull, one cut on a rib bone, and one final wound on the pelvis, most probably inflicted after death. It is generally accepted that postmortem, Richard's naked body was tied to the back of a horse, with his arms slung over one side and his legs and buttocks over the other. This presented a tempting target for onlookers, and the angle of the blow on the pelvis suggests that one of them stabbed Richard's right buttock with substantial force, as the cut extends from the back all the way to the front of the pelvic bone and was most probably an act of humiliation. It is also possible that Richard suffered other injuries which left no trace on the skeleton.

British historian John Ashdown-Hill had used genealogical research in 2004 to trace matrilineal descendants of Anne of York, Richard's elder sister. A British-born woman who emigrated to Canada after the Second World War, Joy Ibsen (), was found to be a 16th-generation great-niece of the king in the same direct maternal line. Joy Ibsen's mitochondrial DNA was tested and belongs to mitochondrial DNA haplogroup J, which by deduction, should also be the mitochondrial DNA haplogroup of Richard III. Joy Ibsen died in 2008. Her son Michael Ibsen gave a mouth-swab sample to the research team on 24 August 2012. His mitochondrial DNA passed down the direct maternal line was compared to samples from the human remains found at the excavation site and used to identify King Richard.

On 4 February 2013, the University of Leicester confirmed that the skeleton was beyond reasonable doubt that of King Richard III. This conclusion was based on mitochondrial DNA evidence, soil analysis, and dental tests (there were some molars missing as a result of caries), as well as physical characteristics of the skeleton which are highly consistent with contemporary accounts of Richard's appearance. The team announced that the "arrowhead" discovered with the body was a Roman-era nail, probably disturbed when the body was first interred. However, there were numerous perimortem wounds on the body, and part of the skull had been sliced off with a bladed weapon; this would have caused rapid death. The team concluded that it is unlikely that the king was wearing a helmet in his last moments. Soil taken from the remains was found to contain microscopic roundworm eggs. Several eggs were found in samples taken from the pelvis, where the king's intestines were, but not from the skull and only very small numbers were identified in soil surrounding the grave. The findings suggest that the higher concentration of eggs in the pelvic area probably arose from a roundworm infection the King suffered in his life, rather than from human waste dumped in the area at a later date, researchers said. The Mayor of Leicester announced that the king's skeleton would be re-interred at Leicester Cathedral in early 2014, but a judicial review of that decision delayed the reinterment for a year. A museum to Richard III was opened in July 2014 in the Victorian school buildings next to the Greyfriars grave site.

The proposal to have King Richard buried in Leicester attracted some controversy. Those who challenged the decision included fifteen "collateral [non-direct] descendants of Richard III", represented by the Plantagenet Alliance, who believed that the body should be reburied in York, as they claim the king wished. In August 2013, they filed a court case in order to contest Leicester's claim to re-inter the body within its cathedral, and propose the body be buried in York instead. However, Michael Ibsen, who gave the DNA sample that identified the king, gave his support to Leicester's claim to re-inter the body in their cathedral. On 20 August, a judge ruled that the opponents had the legal standing to contest his burial in Leicester Cathedral, despite a clause in the contract which had authorized the excavations requiring his burial there. He urged the parties, though, to settle out of court in order to "avoid embarking on the Wars of the Roses, Part Two". The Plantagenet Alliance, and the supporting fifteen collateral descendants, also faced the challenge that "Basic maths shows Richard, who had no surviving children but five siblings, could have millions of 'collateral' descendants" undermining the group's claim to represent "the only people who can speak on behalf of him". A ruling in May 2014 decreed that there are "no public law grounds for the Court interfering with the decisions in question". The remains were taken to Leicester Cathedral on 22 March 2015 and reinterred on 26 March.

On 5 February 2013 Professor Caroline Wilkinson of the University of Dundee conducted a facial reconstruction of Richard III, commissioned by the Richard III Society, based on 3D mappings of his skull. The face is described as "warm, young, earnest and rather serious". On 11 February 2014 the University of Leicester announced the project to sequence the entire genome of Richard III and one of his living relatives, Michael Ibsen, whose mitochondrial DNA confirmed the identification of the excavated remains. Richard III thus became the first ancient person of known historical identity to have their genome sequenced.

In November 2014, the results of the testing were announced, confirming that the maternal side was as previously thought. The paternal side, however, demonstrated some variance from what had been expected, with the DNA showing no links to the purported descendants of Richard's great-great-grandfather Edward III of England through Henry Somerset, 5th Duke of Beaufort. This could be the result of covert illegitimacy that does not reflect the accepted genealogies between Richard and Edward III or between Edward III and the 5th Duke of Beaufort.
In 1485, following his death in battle against Henry Tudor at Bosworth Field, Richard III's body was buried in Greyfriars Church in Leicester.

Following the discoveries of Richard's remains in 2012, it was decided that they should be reburied at Leicester Cathedral, despite feelings in some quarters that he should have been reburied in York Minster. His remains were carried in procession to the cathedral on 22 March 2015, and reburied on 26 March 2015 at a religious re-burial service at which both the Right Reverend Tim Stevens, the Bishop of Leicester, and the Most Reverend Justin Welby, the Archbishop of Canterbury, officiated. The British royal family was represented by the Duke and Duchess of Gloucester and the Countess of Wessex. The actor Benedict Cumberbatch, who is a distant relation of the king and later portrayed him in "The Hollow Crown" television series, read a poem by poet laureate Carol Ann Duffy.

His cathedral tomb was designed by the architects van Heyningen and Haward. The tombstone is deeply incised with a cross, and consists of a rectangular block of white Swaledale fossil stone, quarried in North Yorkshire. It sits on a low plinth made of dark Kilkenny marble, incised with Richard's name, dates and motto ("Loyaulte me lie" â loyalty binds me). The plinth also carries his coat of arms in pietra dura. The remains of Richard III are in a lead-lined inner casket, inside an outer English oak coffin crafted by Michael Ibsen, a direct descendant of Richard's sister Anne of York, and laid in a brick-lined vault below the floor, and below the plinth and tombstone. The original 2010 raised tomb design had been proposed by Langley's "Looking For Richard Project" and fully funded by members of the Richard III Society. The proposal was publicly launched by the Society on 13 February 2013 but rejected by Leicester Cathedral in favour of a memorial slab. However, following a public outcry, the Cathedral changed its position and on 18 July 2013 announced its agreement to give King Richard III a raised tomb monument.

On 1 November 1461, Richard gained the title of Duke of Gloucester; in late 1461, he was invested as a Knight of the Garter. Following the death of King Edward IV, he was made Lord Protector of England. Richard held this office from 30 April to 26 June 1483, when he made himself king of the realm. As King of England, Richard was styled "Dei Gratia Rex Angliae et Franciae et Dominus Hiberniae" ("by the Grace of God, King of England and France and Lord of Ireland").

Informally, he may have been known as "Dickon", according to a sixteenth-century legend of a note, warning of treachery, that was sent to the Duke of Norfolk on the eve of Bosworth:
As Duke of Gloucester, Richard used the Royal Arms of England quartered with the Royal Arms of France, differenced by a label argent of three points ermine, on each point a canton gules, supported by a blue boar. As sovereign, he used the arms of the kingdom undifferenced, supported by a white boar and a lion. His motto was "Loyaulte me lie", "Loyalty binds me"; and his personal device was a white boar.





</doc>
<doc id="26285" url="https://en.wikipedia.org/wiki?curid=26285" title="Restriction fragment length polymorphism">
Restriction fragment length polymorphism

In molecular biology, restriction fragment length polymorphism (RFLP) is a technique that exploits variations in homologous DNA sequences, known as polymorphisms, in order to distinguish individuals, populations, or species or to pinpoint the locations of genes within a sequence.The term may refer to a polymorphism itself, as detected through the differing locations of restriction enzyme sites, or to a related laboratory technique by which such differences can be illustrated. In RFLP analysis, a DNA sample is digested into fragments by one or more restriction enzymes, and the resulting "restriction fragments" are then separated by gel electrophoresis according to their size.

Although now largely obsolete due to the emergence of inexpensive DNA sequencing technologies, RFLP analysis was the first DNA profiling technique inexpensive enough to see widespread application. RFLP analysis was an important early tool in genome mapping, localization of genes for genetic disorders, determination of risk for disease, and paternity testing.

The basic technique for the detection of RFLPs involves fragmenting a sample of DNA with the application of a restriction enzyme, which can selectively cleave a DNA molecule wherever a short, specific sequence is recognized in a process known as a restriction digest. The DNA fragments produced by the digest are then separated by length through a process known as agarose gel electrophoresis and transferred to a membrane via the Southern blot procedure. Hybridization of the membrane to a labeled DNA probe then determines the length of the fragments which are complementary to the probe. A restriction fragment length polymorphism is said to occur when the length of a detected fragment varies between individuals, indicating non-identical sequence homologies. Each fragment length is considered an allele, whether it actually contains a coding region or not, and can be used in subsequent genetic analysis.

There are two common mechanisms by which the size of a particular restriction fragment can vary. In the first schematic, a small segment of the genome is being detected by a DNA probe (thicker line). In allele "A", the genome is cleaved by a restriction enzyme at three nearby sites (triangles), but only the rightmost fragment will be detected by the probe. In allele "a", restriction site 2 has been lost by a mutation, so the probe now detects the larger fused fragment running from sites 1 to 3. The second diagram shows how this fragment size variation would look on a Southern blot, and how each allele (two per individual) might be inherited in members of a family.

In the third schematic, the probe and restriction enzyme are chosen to detect a region of the genome that includes a variable number tandem repeat (VNTR) segment (boxes in schematic diagram). In allele "c", there are five repeats in the VNTR, and the probe detects a longer fragment between the two restriction sites. In allele "d", there are only two repeats in the VNTR, so the probe detects a shorter fragment between the same two restriction sites. Other genetic processes, such as insertions, deletions, translocations, and inversions, can also lead to polymorphisms. RFLP tests require much larger samples of DNA than do short tandem repeat (STR) tests.

Analysis of RFLP variation in genomes was formerly a vital tool in genome mapping and genetic disease analysis. If researchers were trying to initially determine the chromosomal location of a particular disease gene, they would analyze the DNA of members of a family afflicted by the disease, and look for RFLP alleles that show a similar pattern of inheritance as that of the disease (see genetic linkage). Once a disease gene was localized, RFLP analysis of other families could reveal who was at risk for the disease, or who was likely to be a carrier of the mutant genes. RFLP test is used in identification and differentiation of organisms by analyzing unique patterns in genome. It is also used in identification of recombination rate in the loci between restriction sites.

RFLP analysis was also the basis for early methods of genetic fingerprinting, useful in the identification of samples retrieved from crime scenes, in the determination of paternity, and in the characterization of genetic diversity or breeding patterns in animal populations.

The technique for RFLP analysis is, however, slow and cumbersome. It requires a large amount of sample DNA, and the combined process of probe labeling, DNA fragmentation, electrophoresis, blotting, hybridization, washing, and autoradiography can take up to a month to complete. A limited version of the RFLP method that used oligonucleotide probes was reported in 1985. The results of the Human Genome Project have largely replaced the need for RFLP mapping, and the identification of many single-nucleotide polymorphisms (SNPs) in that project (as well as the direct identification of many disease genes and mutations) has replaced the need for RFLP disease linkage analysis (see SNP genotyping). The analysis of VNTR alleles continues, but is now usually performed by polymerase chain reaction (PCR) methods. For example, the standard protocols for DNA fingerprinting involve PCR analysis of panels of more than a dozen VNTRs.

RFLP is still used in marker-assisted selection. Terminal restriction fragment length polymorphism (TRFLP or sometimes T-RFLP) is a technique initially developed for characterizing bacterial communities in mixed-species samples. The technique has also been applied to other groups including soil fungi. TRFLP works by PCR amplification of DNA using primer pairs that have been labeled with fluorescent tags. The PCR products are then digested using RFLP enzymes and the resulting patterns visualized using a DNA sequencer. The results are analyzed either by simply counting and comparing bands or peaks in the TRFLP profile, or by matching bands from one or more TRFLP runs to a database of known species. The technique is similar in some aspects to temperature gradient or denaturing gradient gel electrophoresis (TGGE and DGGE).

The sequence changes directly involved with an RFLP can also be analyzed more quickly by PCR. Amplification can be directed across the altered restriction site, and the products digested with the restriction enzyme. This method has been called Cleaved Amplified Polymorphic Sequence (CAPS). Alternatively, the amplified segment can be analyzed by allele-specific oligonucleotide (ASO) probes, a process that can often be done by a simple dot blot.




</doc>
<doc id="26286" url="https://en.wikipedia.org/wiki?curid=26286" title="Rocket-propelled grenade">
Rocket-propelled grenade

A rocket-propelled grenade (often abbreviated RPG) is a shoulder-fired anti-tank weapon system that fires rockets equipped with an explosive warhead. Most RPGs can be carried by an individual soldier. These warheads are affixed to a rocket motor which propels the RPG towards the target and they are stabilized in flight with fins. Some types of RPG are reloadable with new rocket-propelled grenades, while others are single-use. RPGs, with some exceptions, are generally loaded from the muzzle.

RPGs with high explosive anti-tank warheads (HEAT) are very effective against armored vehicles such as armored personnel carriers (APCs). However, heavily armored vehicles from the 2010s, such as main battle tanks, are generally too well armored (with thick composite and/or reactive armor) to be penetrated by an RPG, unless less armored sections of vehicle are exploited. Various warheads are also capable of causing secondary damage to vulnerable systems (especially sights, tracks, rear and roof of turrets) and other unarmored targets.

The term "rocket-propelled grenade" is, strictly speaking, a backronym; it stems from the Russian language Ð ÐÐ or ÑÑÑÐ½Ð¾Ð¹ Ð¿ÑÐ¾ÑÐ¸Ð²Ð¾ÑÐ°Ð½ÐºÐ¾Ð²ÑÐ¹ Ð³ÑÐ°Ð½Ð°ÑÐ¾Ð¼ÑÑ (transliterated as ""ruchnoy protivotankovy granatomyot""), meaning "hand-held anti-tank grenade launcher", the name given to early Russian designs.

The static nature of trench warfare in World War I encouraged the use of shielded defenses, even including personal armor, that were impenetrable by standard rifle ammunition. This led to some isolated experiments with higher caliber rifles, similar to elephant guns, using armor-piercing ammunition. The very first tanks, the British Mark I, could be penetrated by these weapons under the right conditions. Mark IV tanks, however, had slightly thicker armor. In response, the German rushed to create an upgraded version of these early anti-armor rifles, the Tankgewehr M1918, the first anti-tank rifle. In the inter-war years, tank armor continued to increase overall, to the point that anti-tank rifles could no longer be effective against anything but light tanks; any rifle made powerful enough for heavier tanks would exceed the ability of a soldier to carry and fire the weapon.

Even with the first tanks, artillery officers often used field guns depressed to fire directly at armored targets. However, this practice expended much valuable ammunition and was of increasingly limited effectiveness as tank armor became thicker. This led to the concept of anti-tank guns, a form of artillery specifically designed to destroy armored fighting vehicles, normally from static defensive positions (that is, immobile during a battle).

The first dedicated anti-tank artillery began appearing in the 1920s, and by World War II was a common appearance in most armies. In order to penetrate armor they fired specialized ammunition from proportionally longer barrels to achieve a higher muzzle velocity than field guns. Most anti-tank guns were developed in the 1930s as improvements in tanks were noted, and nearly every major arms manufacturer produced one type or another.

Anti-tank guns deployed during World War II were manned by specialist infantry rather than artillery crews, and issued to infantry units accordingly. The anti-tank guns of the 1930s were of small caliber; nearly all major armies possessing them used 37mm ammunition, except for the British Army, which had developed the 40mm Ordnance QF 2-pounder. As World War II progressed, the appearance of heavier tanks rendered these weapons obsolete and anti-tank guns likewise began firing larger calibre and more effective armor-piercing shells. Although a number of large caliber guns were developed during the war that were capable of knocking out the most heavily armored tanks, they proved slow to set up and difficult to conceal. The latter generation of low-recoil anti-tank weapons, which allowed projectiles the size of an artillery shell to be fired from a man's shoulder, was considered a far more viable option for arming infantrymen.

The RPG has its roots in the 20th century with the early development of the explosive shaped charge, in which the explosive is made with a conical hollow, which concentrates its power on the impact point. Before the adoption of the shaped charge, anti-tank guns and tank guns relied primarily on kinetic energy of metal shells to defeat armor. Soldier-carried anti-tank rifles such as the Boys anti-tank rifle could be used against lightly-armored tankettes and light armored vehicles. However, as tank armor increased in thickness and effectiveness, the anti-tank guns needed to defeat them became increasingly heavy, cumbersome and expensive. During WW II, as tank armor got thicker, larger calibre anti-tank guns were developed to defeat this thicker armor. 

While larger anti-tank guns were more effective, the weight of these anti-tank guns meant that they increasingly were mounted on wheeled, towed platforms. This meant that if the infantry was on foot, they might not have access to these wheeled, vehicle-towed anti-tank guns. This led to situations where infantry could find themselves defenseless against tanks and unable to attack tanks. Armies found that they needed to give infantry a human-portable (i.e., can be carried by one soldier) weapon to defeat enemy armor when no wheeled anti-tank guns were available, since anti tank rifles were no longer effective. Initial attempts to put such weapons in the hands of the infantry resulted in weapons like the Soviet RPG-40 "blast effect" hand grenade (where "RPG" stood for "ruchnaya protivotankovaya granata", meaning hand-held anti-tank grenade). The later RPG-43 and RPG-6 used shaped charges, the chemical energy of their explosive being used more efficiently to enable the defeat of thicker armor; however, being hand thrown weapons, they still had to be deployed at suicidally close range to be effective. What was needed was a means of delivering the shaped charge warhead from a distance. Different approaches to this goal would lead to the anti-tank spigot mortar, the recoilless rifle and, from the development of practical rocketry, the rocket propelled grenade.

Research occasioned by World War II produced such weapons as the American Bazooka and German Panzerfaust, which combined portability with effectiveness against armored vehicles, such as tanks. The Soviet-developed RPG-7 is the most widely distributed, recognizable and used RPG in the world. The basic design of this RPG was developed by the Soviets shortly after World War II in the form of the RPG-2, which is similar in function to the Bazooka (due to the reloadability) and the Panzerfaust (due to an oversized grenade that protrudes outside of a smaller launch tube and the recoilless launch), though the rounds it fires lack a form of propulsion in addition to the launch charge (unlike the RPG-7 rounds, which also feature a sustainer motor, effectively making the rounds rocket propelled grenades).
Soviet RPGs were used extensively during the Vietnam War (by the Vietnam People's Army and Vietcong), as well as during the Soviet invasion of Afghanistan by the Mujahideen and against South Africans in Angola and Namibia (formerly South West Africa) by SWAPO guerillas during what the South Africans called the South African Border War. In the 2000s, they were still being used widely in conflict areas such as Chechnya, Iraq, and Sri Lanka. Militants have also used RPGs against helicopters: Taliban fighters shot down U.S. CH-47 Chinook helicopters in June 2005 and August 2011; and Somali militiamen shot down two U.S. UH-60 Black Hawk helicopters during the Battle of Mogadishu in 1993.
The RPG warhead being used against tanks and other armor often has a shaped charge explosive warhead. A shaped charge is an explosive charge shaped to focus the effect of the explosive's energy. Various types are used to penetrate tank armor; typical modern lined shaped charge can penetrate steel armor to a depth of seven or more times the diameter of the charge (charge diameters, CD), though greater depths of 10 CD and above have been achieved. Despite the popular misconception that shaped charges "melt" tank armor, the shaped charge does not depend in any way on heating or melting for its effectiveness; that is, the superplastic metal jet from a shaped charge impact on armor forms mainly due to a sudden and intense mechanical stress and does not melt its way through armor, as its effect is purely due to kinetic energy in nature.

An RPG comprises two main parts: the launcher and a rocket equipped with a warhead. The most common types of warheads are high explosive (HE) and high explosive anti-tank (HEAT) rounds. HE rounds can be used against troops or unarmored structures or vehicles. HEAT rounds can be used against armored vehicles. These warheads are affixed to a rocket motor and stabilized in flight with fins. Some types of RPG are single-use disposable units, such as the RPG-22 and M72 LAW; with these units, once the rocket is fired, the entire launcher is disposed of. Others are reloadable, such as the Soviet RPG-7 and the Israeli B-300. With reloadable RPGs, a new rocket can be inserted into the muzzle of the weapon after firing. 

The launcher is designed so that the rocket exits the launcher without discharging an exhaust that would be dangerous to the operator (an issue that tended to affect the earliest RPG weapon systems such as the German Panzerschreck, which featured a metal shield for the operator attached to the launch tube). In the case of the RPG-7, the rocket is launched by a gunpowder booster charge, and the rocket motor ignites only after 10Â metres. In some other designs, the propellant charge burns completely within the tube.

An RPG is an inexpensive way of delivering an explosive payload or warhead over a distance with moderate accuracy. Substantially more expensive guided anti-tank missiles are used at larger distances or when accuracy is paramount. Some anti-tank missiles, such as the Sagger, can be guided after firing by the operator. An RPG is not normally guided towards the target by heat sensors or IR signatures. Nor can most RPG rockets be controlled in flight after being aimed and launched. While the lack of active targeting technologies or after-firing guidance input can be viewed as a challenge or weak point, it also makes it hard to defend against RPGs with electronic countermeasures, jamming or similar approaches. For example, if a soldier or other fighter launches an RPG at a hovering helicopter, even if the helicopter releases chaff flares, engages in signal jamming or releases radar-fooling foil, this will have no effect on a typical RPG warhead in flight, even if these measures might protect against more sophisticated surface-to-air missiles.

The HEAT (high explosive anti-tank) round is a standard shaped charge warhead, similar in concept to those used in many tank cannon rounds. In this type of warhead, the shape of the explosive material within the warhead focuses the explosive energy on a copper (or similar metal) lining. This heats the metal lining and propels some of it forward at a very high velocity in a highly plastic state. The resulting narrow jet of metal can defeat armor equivalent to several hundred millimeters of RHA, such as that used in light and medium armored vehicles. However, heavily armored vehicles, such as main battle tanks, are generally too well armored to be penetrated by an RPG, unless weaker sections of the armor are exploited. Various warheads are also capable of causing secondary damage to vulnerable systems (especially sights, tracks, rear and roof of turrets) and other soft targets. The warhead detonates on impact or when the fuse runs out; usually the fuse is set to the maximum burn of the rocket motor, but it can be shortened for improvised anti aircraft purposes.

Specialized warheads are available for illumination, smoke, tear gas, and white phosphorus. Russia, China, and many former Warsaw Pact nations have also developed a fuel-air explosive (thermobaric) warhead. Another recent development is a tandem HEAT warhead capable of penetrating reactive armor.

So-called PRIGs (Propelled Recoilless Improvised Grenade) were improvised warheads used by the Provisional IRA.

The RPG-29 uses a tandem-charge high explosive anti-tank warhead to penetrate explosive reactive armor (ERA) as well as composite armor behind it. It is capable of penetrating MBTs, such as the M1 Abrams, older model Mark II version of the Merkava, Challenger 2 and T-90.

In August 2006, in al-Amarah, in Iraq, a Soviet RPG-29 damaged the front underside of a Challenger 2 tank, detonating ERA in the area of the driver's cabin. The driver lost part of a foot and two more of the crew were injured, but the driver was able to reverse to an aid post. The incident was not made public until May 2007; in response to accusations, the MoD said "We have never claimed that the Challenger 2 is impenetrable." Since then, the ERA has been replaced with a Dorchester block and the steel underbelly lined with armor, as part of the 'Streetfighter' upgrade, which was a direct response to this incident. In May 2008, "The New York Times" disclosed that an American M1 tank had also been damaged by an RPG-29 in Iraq. The American army is ranking the RPG-29 threat to American armor as high; they have refused to allow the newly formed Iraqi army to buy it, fearing that it would fall into the hands of insurgents.

Various armies and manufacturers have developed add-on tank armor and other systems for urban combat, such as the Tank Urban Survival Kit (TUSK) for M1 Abrams, slat armor for the Stryker, ERA kit for the FV432, AZUR for Leclerc, and others. Similar solutions are active protection systems (APS), engaging and destroying closing projectiles, such as the Russian Drozd and Arena, as well as the recent Israeli TROPHY Active Protection System.

The RPG-30 was designed to address the threat of active protection systems on tanks by using a false target to trick the APS. The RPG-30 shares a close resemblance with the RPG-27 in that it is a man-portable, disposable anti-tank rocket launcher with a single shot capacity. However, unlike the RPG-27, there is a smaller diameter precursor round in a smaller side barrel tube in addition to the main round in the main tube. This precursor round acts as a false target, tricking the target's active protection system into engaging it, allowing the main round a clear path into the target, while the APS is stuck in the 0.2â0.4 second delay it needs to start its next engagement. Recent German systems were able to reduce reaction delay to mere milliseconds, cancelling this advantage.

The PG-30 is the main round of the RPG-30. The round is a 105-mm tandem shaped charge with a weight of 10.3-kg (22.7-lb) and has a range of 200 meters and a stated penetration capability in excess of 600-mm (24-in) rolled homogeneous armor (RHA) (after ERA), 1500-mm reinforced concrete, 2000-mm brick and 3700-mm of soil. Reactive armor, including explosive reactive armor (ERA), can be defeated with multiple hits into the same place, such as by tandem-charge weapons, which fire two or more shaped charges in rapid succession.

An early method of disabling shaped charges developed during World War II was to apply thin skirt armor or meshwire at a distance around the hull and turret of the tank. The skirt or mesh armor (cage armor) triggers the RPG on contact and much of the molten jet that a shaped charge produces dissipates before coming into contact with the main armor of the vehicle. Well-sloped armor also gives some protection because the shaped charge is forced to penetrate a greater amount of armor due to the oblique angle. The benefits of cage armor are still considered great in modern battlefields in the Middle East, and although similar effects can be obtained using spaced armor, either as a part of the original design or as appliquÃ© armor fitted later, cage armor is preferable due to its low weight and ease of repair.

Today, technologically advanced armies have implemented composite armors such as Chobham armor, which provide superior protection to steel. For added protection, vehicles may be retrofitted with reactive armor; on impact, reactive tiles explode or deform, disrupting the normal function of the shaped charge. Russian and Israeli vehicles also use active protection systems such as Drozd, Arena APS or Trophy. Such a system detects and shoots down incoming projectiles before they reach the vehicle. As in all arms races, these developments in armor countermeasures have led to the development of RPG rounds designed specifically to defeat them, with methods such as a tandem-charge warhead, which has two shaped charges, of which the first is meant to activate any reactive armor, and the second to penetrate the vehicle.

The United States Army developed a lightweight antitank weapon (LAW) in the middle 1950s. By 1961, the M72 LAW was in use. It is a shoulder-fired, disposable rocket launcher with HEAT warhead. It is a recoilless weapon, which is easy to use, and effective against armored vehicles. It was used during the Vietnam War, and is still in use today. It uses a fin-stabilized rocket. In response to the threat of thicker armor, this weapon was replaced by the AT4 recoilless rifle, a larger & non-collapsibleÂ â albeit still single-shot weapon.

The United States Marine Corps uses a different launcher, which is reloadableÂ â the Shoulder-Launched Multipurpose Assault Weapon (SMAW). Unlike the RPG, it is reloaded from the breech-end rather than the muzzle.


Specific types of RPGs (current, past and under development) include:














One of the first instances the weapon was used by militants was on 13 January 1975 at Orly Airport in France, when Carlos the Jackal, together with another member from the PFLP, used two Soviet RPG-7 grenades to attack an Israeli El Al airliner. Both missed the target, with one hitting a Yugoslav Airlines's DC-9 instead.

In Afghanistan, Mujahideen guerrillas used RPG-7s to destroy Soviet vehicles. To assure a kill, two to four RPG shooters would be assigned to each vehicle. Each armored-vehicle hunter-killer team can have as many as 15 RPGs. In areas where vehicles were confined to a single path (a mountain road, swamps, snow, urban areas), RPG teams trapped convoys by destroying the first and last vehicles in line, preventing movement of the other vehicles. This tactic was especially effective in cities. Convoys learned to avoid approaches with overhangs and to send infantrymen forward in hazardous areas to detect the RPG teams.

Multiple shooters were also effective against heavy tanks with reactive armor: The first shot would be against the driver's viewing prisms. Following shots would be in pairs, one to set off the reactive armor, the second to penetrate the tank's armor. Favored weak spots were the top and rear of the turret.

Afghans sometimes used RPG-7s at extreme range, exploded by their 4.5-second self-destruct timer, which translates to roughly 950m flight distance, as a method of long distance approach denial for infantry and reconnaissance. The most noteworthy use of RPGs against aircraft in Afghanistan occurred on 6 August 2011 when Taliban fighters shot down a U.S. CH-47 Chinook helicopter killing all 38 personnel on board including SEAL Team 6 from a range of 220 meters. An earlier anti-aircraft kill by the Taliban occurred during Operation Red Wings, on 28 June 2005 when a Chinook helicopter was destroyed by unguided rocket propelled grenades.

In the period following the 2003 invasion of Iraq, the RPG became a favorite weapon of the insurgent forces fighting U.S. troops. Since most of the readily-available RPG-7 rounds cannot penetrate M1 Abrams tank armor from almost any angle, it is primarily effective against soft-skinned or lightly armored vehicles, and infantry. Even if the RPG hit does not completely disable the tank or kill the crew, it can still damage external equipment, lowering the tank's effectiveness or forcing the crew to abandon and destroy it. Newer RPG-7 rounds are more capable, and in August 2006, an RPG-29 round penetrated the frontal ERA of a Challenger 2 tank during an engagement in al-Amarah, Iraq, and wounded several crew members.

RPGs were a main tool used by the FMLN's guerrilla forces in the Salvadoran Civil War. For example, during the June 19, 1986 overrun of the San Miguel Army base, FMLN sappers dressed only in black shorts, their faces blacked out with grease, sneaked through barbed wire at night, avoiding the searchlights, they made it to within firing range of the outer wall. Using RPGs to initiate the attack, they blew through the wall and killed a number of Salvadorean soldiers. They eliminated the outermost sentries and searchlights with the rockets, then made it into the inner wall, which they also punched through. They were then able to create mayhem as their comrades attacked from the outside.

During the First (1994â1996) and Second Chechen Wars (1999â2009), Chechen rebels used RPGs to attack Russian tanks from basements and high rooftops. This tactic was effective because tank main guns could not be depressed or raised far enough to return fire, in addition, armor on the very top and bottom of tanks is usually the weakest. Russian forces had to rely on artillery suppression, good crew gunners and infantry screens to prevent such attacks. Tank columns were eventually protected by attached self-propelled anti-aircraft guns (ZSU-23-4 Shilka, 9K22 Tunguska) used in the ground role to suppress and destroy Chechen ambushes. Chechen fighters formed independent "cells" that worked together to destroy a specific Russian armored target. Each cell contained small arms and some form of RPG (RPG-7V or RPG-18, for example). The small arms were used to button the tank up and keep any infantry occupied, while the RPG gunner struck at the tank. While doing so, other teams would attempt to fire at the target in order to overwhelm the Russians' ability to effectively counter the attack. To further increase the chance of success, the teams took up positions at different elevations where possible. Firing from the third and higher floors allowed good shots at the weakest armor (the top). When the Russians began moving in tanks fitted with explosive reactive armor (ERA), the Chechens had to adapt their tactics, because the RPGs they had access to were unlikely to result in the destruction of the tank.

Using RPGs as improvized anti-aircraft batteries has proved successful in Somalia, Afghanistan and Chechnya. Helicopters are typically ambushed as they land, take off or hover. In Afghanistan, the Mujahideen often modified RPGs for use against Soviet helicopters by adding a curved pipe to the rear of the launcher tube, which diverted the backblast, allowing the RPG to be fired upward at aircraft from a prone position. This made the operator less visible prior to firing and decreased the risk of injury from hot exhaust gases. The Mujahideen also utilized the 4.5-second timer on RPG rounds to make the weapon function as part of a flak battery, using multiple launchers to increase hit probabilities. At the time, Soviet helicopters countered the threat from RPGs at landing zones by first clearing them with anti-personnel saturation fire. The Soviets also varied the number of accompanying helicopters (two or three) in an effort to upset Afghan force estimations and preparation. In response, the Mujahideen prepared dug-in firing positions with top cover, and again, Soviet forces altered their tactics by using air-dropped thermobaric fuel-air bombs on such landing zones. As the U.S.-supplied Stinger surface-to-air missiles became available to them, the Afghans abandoned RPG attacks as the smart missiles proved especially efficient in the destruction of unarmed Soviet transport helicopters, such as Mil Mi-17. In Somalia, both of the UH-60 Black Hawk helicopters lost by U.S. forces during the Battle of Mogadishu in 1993 were downed by RPG-7s.




</doc>
<doc id="26287" url="https://en.wikipedia.org/wiki?curid=26287" title="Roy Jenkins">
Roy Jenkins

Roy Harris Jenkins, Baron Jenkins of Hillhead, (11 November 1920Â â 5 January 2003), was a British politician and the President of the European Commission from 1977 to 1981. He was at various times a member of the Labour Party, Social Democratic Party and the Liberal Democrats.

The son of a Welsh coal-miner and trade unionist, himself later a Labour MP, Jenkins was educated at the University of Oxford and served as an intelligence officer during the Second World War. Elected to Parliament as a Labour MP in 1948, he went on to serve as both Chancellor of the Exchequer and Home Secretary under the Labour Governments of Harold Wilson and James Callaghan. In his first period as Home Secretary he sought to build what he described as "a civilised society", with measures such as the effective abolition in Britain of both capital punishment and theatre censorship, the partial decriminalisation of homosexuality, relaxing of divorce law, suspension of birching and the liberalisation of abortion law. As Chancellor of the Exchequer he pursued a tight fiscal policy. He was elected Deputy Leader of the Labour Party in 1970, but resigned in 1972 because he supported entry to the European Communities, which the party opposed.

He later chose to leave British politics in 1976, being appointed President of the European Commission the following year, serving until 1981. He was the first and only British holder of this office. He returned to British politics in 1981; dismayed with the Labour Party's left-ward movement under Michael Foot, he was one of the "Gang of Four"âcentrist Labour figures who formed the Social Democratic Party (SDP). In 1982, Jenkins won a by-election to return to Parliament, taking the seat from the Conservatives in a famous result. He was formally made Leader of the SDP ahead of the 1983 general election, during the SDP-Liberal Alliance. However, after disappointment with the performance of the SDP, he resigned as leader.
In 1987 he was elected to succeed Harold Macmillan as Chancellor of the University of Oxford following the latter's death; he held this position until his own death sixteen years later. A few months after becoming Chancellor he was defeated at the 1987 general election by the Labour candidate, George Galloway. Jenkins accepted a life peerage shortly afterwards, and sat in the House of Lords as a Liberal Democrat. In the late 1990s he was an adviser to Prime Minister Tony Blair and chaired the Jenkins Commission on electoral reform. Jenkins died in 2003, aged 82.

In addition to his political career he was also a noted historian, biographer and writer. His "A Life at the Centre" (1991) is regarded as one of the best autobiographies of the later 20th century, which "will be read with pleasure long after most examples of the genre have been forgotten".

Born in Abersychan, Monmouthshire, in south-eastern Wales, as an only child, Roy Jenkins was the son of a National Union of Mineworkers official, Arthur Jenkins. His father was imprisoned during the 1926 General Strike for his alleged involvement in disturbances. Arthur Jenkins later became President of the South Wales Miners' Federation and Member of Parliament for Pontypool, Parliamentary Private Secretary to Clement Attlee, and briefly a minister in the 1945 Labour government. Roy Jenkins' mother, Hattie Harris, was the daughter of a steelworks foreman.

Jenkins was educated at Pentwyn Primary School, Abersychan County Grammar School, University College, Cardiff, and at Balliol College, Oxford, where he was twice defeated for the Presidency of the Oxford Union but took First-Class Honours in Politics, Philosophy and Economics (PPE). His university colleagues included Tony Crosland, Denis Healey and Edward Heath, and he became friends with all three, although he was never particularly close to Healey. In John Campbell's biography "A Well-Rounded Life" a romantic relationship between Jenkins and Crosland was detailed.

During the Second World War, Jenkins received his officer training at Alton Towers and was posted to the 55th West Somerset Yeomanry at West Lavington. Through the influence of his father, in April 1944 Jenkins was sent to Bletchley Park to work as a codebreaker.

Having failed to win Solihull in 1945, he was elected to the House of Commons in a 1948 by-election as the Member of Parliament for Southwark Central, becoming the "Baby of the House". His constituency was abolished in boundary changes for the 1950 general election, when he stood instead in the new Birmingham Stechford constituency. He won the seat, and represented the constituency until 1977.

In 1947 he edited a collection of Clement Attlee's speeches, published under the title "Purpose and Policy". Attlee then granted Jenkins access to his private papers so that he could write his biography, which appeared in 1948 ("Mr Attlee: An Interim Biography"). The reviews were generally favourable, including George Orwell's in "Tribune".

In 1951 "Tribune" published his pamphlet "Fair Shares for the Rich". Here, Jenkins advocated the abolition of large private incomes by taxing them, graduating from 50 per cent for incomes between Â£20,000 and Â£30,000 to 95 per cent for incomes over Â£100,000. He also proposed further nationalisations and said: "Future nationalisations will be more concerned with equality than with planning, and this means that we can leave the monolithic public corporation behind us and look for more intimate forms of ownership and control". He later described this "almost Robespierrean" pamphlet as "the apogee of my excursion to the left".

Jenkins contributed an essay on 'Equality' to the 1952 collection "New Fabian Essays". In 1953 appeared "Pursuit of Progress", a work intended to counter Bevanism. Retreating from what he had demanded in "Fair Shares for the Rich", Jenkins now argued that the redistribution of wealth would occur over a generation. However, he still proposed further nationalisations: "It is quite impossible to advocate both the abolition of great inequalities of wealth and the acceptance of a one-quarter public sector and three-quarters private sector arrangement. A mixed economy there will undoubtedly be, certainly for many decades and perhaps permanently, but it will need to be mixed in very different proportions from this". He also opposed the Bevanites' neutralist foreign policy platform: "Neutrality is essentially a conservative policy, a policy of defeat, of announcing to the world that we have nothing to say to which the world will listen. ... Neutrality could never be acceptable to anyone who believes that he has a universal faith to preach". Jenkins argued that the Labour leadership needed to take on and defeat the neutralists and pacifists in the party; it would be better to risk a split in the party than face "the destruction, by schism, perhaps for a generation, of the whole progressive movement in the country".

Between 1951 and 1956 he wrote a weekly column for the Indian newspaper "The Current". Here he advocated progressive reforms such as equal pay, the decriminalisation of homosexuality, the liberalisation of the obscenity laws and the abolition of capital punishment. "Mr Balfour's Poodle", a short account of the House of Lords crisis of 1911 that culminated in the Parliament Act 1911, was published in 1954. Favourable reviewers included A. J. P. Taylor, Harold Nicolson, Leonard Woolf and Violet Bonham Carter. After a suggestion by Mark Bonham Carter, Jenkins then wrote a biography of the Victorian radical, Sir Charles Dilke, which was published in October 1958.

During the 1956 Suez Crisis, Jenkins denounced Anthony Eden's "squalid imperialist adventure" at a Labour rally in Birmingham Town Hall. Three years later he claimed that "Suez was a totally unsuccessful attempt to achieve unreasonable and undesirable objectives by methods which were at once reckless and immoral; and the consequences, as was well deserved, were humiliating and disastrous".

Jenkins praised Anthony Crosland's 1956 work "The Future of Socialism" as "the most important book on socialist theory" since Evan Durbin's "The Politics of Democratic Socialism" (1940). With much of the economy now nationalised, Jenkins argued, socialists should concentrate on eliminating the remaining pockets of poverty and on the removal of class barriers, as well as promoting libertarian social reforms. Jenkins was principal sponsor, in 1959, of the bill which became the liberalising Obscene Publications Act, responsible for establishing the "liable to deprave and corrupt" criterion as a basis for a prosecution of suspect material and for specifying literary merit as a possible defence.

In July 1959 Penguin published Jenkins' "The Labour Case", timed to anticipate the upcoming election. Jenkins argued that Britain's chief danger was that of "living sullenly in the past, of believing that the world has a duty to keep us in the station to which we are accustomed, and showing bitter resentment if it does not do so". He added: "Our neighbours in Europe are roughly our economic and military equals. We would do better to live gracefully with them than to waste our substance by trying unsuccessfully to keep up with the power giants of the modern world". Jenkins claimed that the Attlee government concentrated "too much towards the austerity of fair shares, and too little towards the incentives of free consumers' choice". Although he still believed in the elimination of poverty and more equality, Jenkins now argued that these aims could be achieved by economic growth. In the final chapter ('Is Britain Civilised?') Jenkins set out a list of necessary progressive social reforms: the abolition of the death penalty, decriminalisation of homosexuality, abolition of the Lord Chamberlain's powers of theatre censorship, liberalisation of the licensing and betting laws, liberalisation of the divorce laws, legalisation of abortion, decriminalisation of suicide and more liberal immigration laws. Jenkins concluded:

Let us be on the side of those who want people to be free to live their own lives, to make their own mistakes, and to decide, in an adult way and provided they do not infringe the rights of others, the code by which they wish to live; and on the side of experiment and brightness, of better buildings and better food, of better music (jazz as well as Bach) and better books, of fuller lives and greater freedom. In the long run these things will be more important than the most perfect of economic policies.

In the aftermath of Labour's 1959 defeat, Jenkins appeared on "Panorama" and argued that Labour should abandon further nationalisation, question its connection with the trade unions and not dismiss a closer association with the Liberal Party. In November he delivered a Fabian Society lecture in which he blamed Labour's defeat on the unpopularity of nationalisation and he repeated this in an article for "The Spectator". His "Spectator" article also called for Britain to accept its diminished place in the world, to grant colonial freedom, to spend more on public services and to promote the right of individuals to live their own lives free from the constraints of popular prejudices and state interference. Jenkins later called it a "good radical programme, although...not a socialist one".

In May 1960 Jenkins joined the Campaign for Democratic Socialism, a Gaitskellite pressure group designed to fight against left-wing domination of the Labour Party. In July 1960 Jenkins resigned from his frontbench role in order to be able to campaign freely for British membership of the Common Market. At the 1960 Labour Party conference in Scarborough, Jenkins advocated rewriting Clause IV of the party's constitution but he was booed. In November he wrote in "The Spectator" that "unless the Labour Party is determined to abdicate its role as a mass party and become nothing more than a narrow sectarian society, its paramount task is to represent the whole of the Leftward-thinking half of the countryâand to offer the prospect of attracting enough marginal support to give that half some share of power".

During 1960â62 his main campaign was British membership of the Common Market, where he became Labour's leading advocate of entry. When Harold Macmillan initiated the first British application to join the Common Market in 1961, Jenkins became deputy chairman of the all-party Common Market Campaign and then chairman of the Labour Common Market Committee. At the 1961 Labour Party conference Jenkins spoke in favour of Britain's entry.

Since 1959 Jenkins had been working on a biography of the Liberal Prime Minister, H. H. Asquith. For Jenkins, Asquith ranked with Attlee as the embodiment of the moderate, liberal intelligence in politics that he most admired. Through Asquith's grandson, Mark Bonham Carter, Jenkins had access to Asquith's letters to his mistress, Venetia Stanley. Kenneth Rose, Michael Foot, Asa Briggs and John Grigg all favourably reviewed the book when it was published in October 1964. However, Violet Bonham Carter wrote a defence of her father in "The Times" against the few criticisms of Asquith in the book, and Robert Rhodes James wrote in "The Spectator" that "Asquith was surely a tougher, stronger, more acute man...than Mr. Jenkins would have us believe. The fascinating enigma of his complete decline is never really analysed, nor even understood. ... We required a Sutherland: but we have got an Annigoni". John Campbell claims that "for half a century it has remained unchallenged as the best biography and is rightly regarded as a classic".

Like Healey and Crosland, he had been a close friend of Hugh Gaitskell and for them Gaitskell's death and the elevation of Harold Wilson as Labour Party leader was a setback. For Jenkins, Gaitskell would remain his political hero. After the 1964 general election Jenkins was appointed Minister of Aviation and was sworn of the Privy Council. While at Aviation he oversaw the high-profile cancellations of the BAC TSR-2 and Concorde projects (although the latter was later reversed after strong opposition from the French Government). In January 1965 Patrick Gordon Walker resigned as Foreign Secretary and in the ensuing reshuffle Wilson offered Jenkins the Department for Education and Science; however, he declined it, preferring to stay at Aviation.

In the summer of 1965 Jenkins eagerly accepted an offer to replace Frank Soskice as Home Secretary. However Wilson, dismayed by a sudden bout of press speculation about the potential move, delayed Jenkins' appointment until December. Once Jenkins took office â the youngest Home Secretary since Churchill â he immediately set about reforming the operation and organisation of the Home Office. The Principal Private Secretary, Head of the Press and Publicity Department and Permanent Under-Secretary were all replaced. He also redesigned his office, famously replacing the board on which condemned prisoners were listed with a fridge.

After the 1966 general election, in which Labour won a comfortable majority, Jenkins pushed through a series of police reforms which reduced the number of separate forces from 117 to 49. "The Times" called it "the greatest upheaval in policing since the time of Peel". His visit to Chicago in September (to study their policing methods) convinced him of the need to introduce two-way radios to the police; whereas the Metropolitan Police possessed 25 radios in 1965, Jenkins increased this to 2,500, and provided similar numbers of radios to the rest of the country's police forces. Jenkins also provided the police with more car radios, which made the police more mobile but reduced the amount of time they spent patrolling the streets. His Criminal Justice Act 1967 introduced more stringent controls on the purchase of shotguns, outlawed last-minute alibis and introduced majority verdicts in juries in England and Wales. The Act was also designed to lower the prison population by the introduction of release under licence, easier bail, suspended sentences and earlier parole.

Immigration was a divisive and provocative issue during the late 1960s and on 23 May 1966 Jenkins delivered a speech on race relations, which is widely considered to be one of his best. Addressing a London meeting of the National Committee for Commonwealth Immigrants he notably defined Integration:

Before going on to ask:

And concluding that:
By the end of 1966, Jenkins was the Cabinet's rising star; the "Guardian" called him the best Home Secretary of the century "and quite possibly the best since Peel", the "Sunday Times" called him Wilson's most likeliest successor and the "New Statesman" labelled him "Labour's Crown Prince".

In a speech to the London Labour Conference in May 1967, Jenkins said his vision was of "a more civilised, more free and less hidebound society" and he further claimed that "to enlarge the area of individual choice, socially, politically and economically, not just for a few but for the whole community, is very much what democratic socialism is about". He gave strong personal support to David Steel's Private Member's Bill for the legalisation of abortion, which became the Abortion Act 1967, telling the Commons that "the existing law on abortion is uncertain and...harsh and archaic", adding that "the law is consistently flouted by those who have the means to do so. It is, therefore, very much a question of one law for the rich and one law for the poor". When the Bill looked likely to be dropped due to insufficient time, Jenkins helped ensure that it received enough parliamentary time to pass and he voted for it in every division.

Jenkins also supported Leo Abse's bill for the decriminalisation of homosexuality, which became the Sexual Offences Act 1967. Jenkins told the Commons: "It would be a mistake to think...that by what we are doing tonight we are giving a vote of confidence or congratulation to homosexuality. Those who suffer from this disability carry a great weight of loneliness, guilt and shame. The crucial question...is, should we add to those disadvantages the full rigour of the criminal law? By its overwhelming decisions, the House has given a fairly clear answer, and I hope that the Bill will now make rapid progress towards the Statute Book. It will be an important and civilising Measure".

Jenkins also abolished the use of flogging in prisons. In July 1967 Jenkins recommended to the Home Affairs Select Committee a bill to end the Lord Chamberlain's power to censor the theatre. This was passed as the Theatres Act 1968 under Jenkins' successor as Home Secretary, James Callaghan. Jenkins also announced that he would introduce legislation banning racial discrimination in employment, which was embodied in the Race Relations Act 1968 passed under Callaghan. In October 1967 Jenkins planned to introduce legislation that would enable him to keep out the 20,000 Kenyan Asians who held British passports (this was passed four months later under Callaghan as the Commonwealth Immigrants Act 1968, which was based on Jenkins' draft).

Jenkins is often seen as responsible for the most wide-ranging social reforms of the late 1960s, with popular historian Andrew Marr claiming "the greatest changes of the Labour years" were thanks to Jenkins. These reforms would not have happened when they did, earlier than in most other European countries, if Jenkins had not supported them. In a speech in Abingdon in July 1969, Jenkins said that the "permissive society" had been allowed to become a dirty phrase: "A better phrase is the 'civilized society', based on the belief that different individuals will wish to make different decisions about their patterns of behaviour and that, provided these do not restrict the freedom of others, they should be allowed to do so within a framework of understanding and tolerance". Jenkins' words were immediately reported in the press as "The permissive society is the civilised society", which he later wrote "was not all that far from my meaning".

For some conservatives, such as Peter Hitchens, Jenkins' reforms remain objectionable. In his book "The Abolition of Britain", Hitchens accuses him of being a "cultural revolutionary" who takes a large part of the responsibility for the decline of "traditional values" in Britain. During the 1980s Margaret Thatcher and Norman Tebbit would blame Jenkins for family breakdowns, the decline of respect for authority and the decline of social responsibility. Jenkins replied by pointing out that Thatcher, with her large parliamentary majorities, never attempted to reverse his reforms.

From 1967 to 1970 Jenkins served as Chancellor of the Exchequer, replacing James Callaghan following the devaluation crisis of November 1967. Jenkins' ultimate goal as Chancellor was economic growth, which depended on restoring stability to sterling at its new value after devaluation. This could only be achieved by ensuring a surplus in the balance of payments, which had been in a deficit for the previous five years. Therefore, Jenkins pursued deflation, including cuts in public expenditure and increases in taxation, in order to ensure that resources went into exports rather than domestic consumption. Jenkins warned the House of Commons in January 1968 that there was "two years of hard slog ahead".

He quickly gained a reputation as a particularly tough Chancellor with his 1968 budget increasing taxes by Â£923Â million, more than twice the increase of any previous budget to date. Jenkins had warned the Cabinet that a second devaluation would occur in three months if his budget did not restore confidence in sterling. He restored prescription charges (which had been abolished when Labour returned to office in 1964) and postponed the raising of the school leaving age to 16 to 1973 instead of 1971. Housing and road building plans were also heavily cut, and he also accelerated Britain's withdrawal East of Suez. Jenkins ruled out increasing the income tax and so raised the taxes on: drinks and cigarettes (except on beer), purchase tax, petrol duty, road tax, a 50 per cent rise in Selective Employment Tax and a one-off Special Charge on personal incomes. He also paid for an increase in family allowances by cutting child tax allowances.

Despite Edward Heath claiming it was a "hard, cold budget, without any glimmer of warmth" Jenkins' first budget broadly received a warm reception, with Harold Wilson remarking that "it was widely acclaimed as a speech of surpassing quality and elegance" and Barbara Castle that it "took everyone's breath away". Richard Crossman said it was "genuinely based on socialist principles, fair in the fullest sense by really helping people at the bottom of the scale and by really taxing the wealthy". In his budget broadcast on 19 March, Jenkins said that Britain had been living in a "fool's paradise" for years and that it was "importing too much, exporting too little and paying ourselves too much", with a lower standard of living than France or West Germany.

Jenkins' supporters in the Parliamentary Labour Party became known as the "Jenkinsites". These were usually younger, middle-class and university-educated ex-Gaitskellites such as Bill Rodgers, David Owen, Roy Hattersley, Dick Taverne, John Mackintosh and David Marquand. In MayâJuly 1968 some of his supporters, led by Patrick Gordon Walker and Christopher Mayhew, plotted to replace Wilson with Jenkins as Labour leader but he declined to challenge Wilson. A year later his supporters again attempted to persuade Jenkins to challenge Wilson for the party leadership but he again declined. He later wrote in his memoirs that the 1968 plot was "for me...the equivalent of the same season of 1953 for Rab Butler. Having faltered for want of single-minded ruthlessness when there was no alternative to himself, he then settled down to a career punctuated by increasingly wide misses of the premiership. People who effectively seize the prime ministership â Lloyd George, Macmillan, Mrs Thatcher â do not let such moments slip".

In April 1968, with Britain's reserves declining by approximately Â£500 million every quarter, Jenkins went to Washington to obtain a $1,400 million loan from the International Monetary Fund. Following a further sterling crisis in November 1968 Jenkins was forced to raise taxes by a further Â£250Â million. After this the currency markets slowly began to settle and his 1969 budget represented more of the same with a Â£340Â million increase in taxation to further limit consumption.

By May 1969 Britain's current account position was in surplus, thanks to a growth in exports, a drop in overall consumption and, in part, the Inland Revenue correcting a previous underestimation in export figures. In July Jenkins was also able to announce that the size of Britain's foreign currency reserves had been increased by almost $1Â billion since the beginning of the year. It was at this time that he presided over Britain's only excess of government revenue over expenditure in the period 1936-7 to 1987â8. Thanks in part to these successes there was a high expectation that the 1970 budget would be a more generous one. Jenkins, however, was cautious about the stability of Britain's recovery and decided to present a more muted and fiscally neutral budget. It is often argued that this, combined with a series of bad trade figures, contributed to the Conservative victory at the 1970 general election. Historians and economists have often praised Jenkins for presiding over the transformation in Britain's fiscal and current account positions towards the end of the 1960s. Andrew Marr, for example, described him as one of the 20th century's "most successful chancellors". Alec Cairncross considered Jenkins "the ablest of the four Chancellors I served".

Public expenditure as a proportion of GDP rose from 44 per cent in 1964 to around 50 per cent in 1970. Despite Jenkins' warnings about inflation, wage settlements in 1969â70 increased on average by 13 per cent and contributed to the high inflation of the early 1970s and consequently negated most of Jenkins' efforts to obtain a balance of payments surplus.

After Labour unexpectedly lost power in 1970 Jenkins was appointed Shadow Chancellor of the Exchequer by Harold Wilson. Jenkins was also subsequently elected to the deputy leadership of the Labour Party in July 1970, defeating future Labour Leader Michael Foot and former Leader of the Commons Fred Peart at the first ballot. At this time he appeared the natural successor to Harold Wilson, and it appeared to many only a matter of time before he inherited the leadership of the party, and the opportunity to become Prime Minister.

This changed completely, however, as Jenkins refused to accept the tide of anti-European feeling that became prevalent in the Labour Party in the early 1970s. After a special conference on the EEC was held by the Labour Party on 17 July 1971, but from which Jenkins was forbidden from addressing, he delivered one of the most powerful speeches of his career. Jenkins told a meeting of the Parliamentary Labour Party on 19 July: "At conference the only alternative [to the EEC] we heard was 'socialism in one country'. That is always good for a cheer. Pull up the drawbridge and revolutionize the fortress. That's not a policy either: it's just a slogan, and it is one which becomes not merely unconvincing but hypocritical as well when it is dressed up as our best contribution to international socialism". This reopened the old BevaniteâGaitskellite divide in the Party; Wilson told Tony Benn the day after Jenkins' speech that he was determined to smash the Campaign for Democratic Socialism.

At the 1971 Labour Party conference in Brighton, the NEC's motion to reject the "Tory terms" of entry into the EEC was carried by a large majority. Jenkins told a fringe meeting that this would have no effect on his continued support for Britain's entry. Benn said Jenkins was "the figure dominating this Conference; there is no question about it". On 28 October 1971, he led 69 Labour MPs through the division lobby in support of the Heath government's motion to take Britain into the EEC. In so-doing they were defying a three-line whip and a five-to-one vote at the Labour Party annual conference. Jenkins later wrote: "I was convinced that it was one of the decisive votes of the century, and had no intention of spending the rest of my life answering the question of what did I do in the great division by saying 'I abstained'. I saw it in the context of the first Reform Bill, the repeal of the Corn Laws, Gladstone's Home Rule Bills, the Lloyd George Budget and the Parliament Bill, the Munich Agreement and the May 1940 votes".

Jenkins' action gave the European cause a legitimacy that would have otherwise been absent had the issue been considered solely as a party political matter. However, he was now regarded by the left as a "traitor". James Margach wrote in the "Sunday Times": "The unconcealed objective of the Left now is either to humiliate Roy Jenkins and his allies into submission â or drive them from the party". At this stage, however, Jenkins would not fully abandon his position as a political insider, and chose to stand again for deputy leader, an act his colleague David Marquand claimed he later came to regret. Jenkins promised not to vote with the government again and he narrowly defeated Michael Foot on a second ballot.

In accordance with the party whip, Jenkins voted against European Communities Bill 55 times. However, he resigned both the deputy leadership and his shadow cabinet position in April 1972, after the party committed itself to holding a referendum on Britain's membership of the EEC. This led to some former admirers, including Roy Hattersley, choosing to distance themselves from Jenkins. Hattersley later claimed that Jenkins' resignation was "the moment when the old Labour coalition began to collapse and the eventual formation of a new centre party became inevitable". In his resignation letter to Wilson, Jenkins said that if there were a referendum "the Opposition would form a temporary coalition of those who, whatever their political views, were against the proposed action. By this means we would have forged a more powerful continuing weapon against progressive legislation than anything we have known in this country since the curbing of the absolute powers of the old House of Lords".

Jenkins' lavish lifestyleÂ â Wilson once described him as "more a socialite than a socialist"Â â had already alienated much of the Labour Party from him. Wilson accused him of having an affair with socialite Ann Fleming - and it was true.

In May 1972 he collected the Charlemagne Prize, which he had been awarded for promoting European unity. In September an ORC opinion poll found that there was considerable public support for an alliance between the 'moderate' wing of the Labour Party and the Liberals; 35 per cent said they would vote for a LabourâLiberal alliance, 27 per cent for the Conservatives and 23.5 per cent for 'Socialist Labour'. "The Times" claimed that there were "twelve million Jenkinsites". During the spring and summer of 1972, Jenkins delivered a series of speeches designed to set out his leadership credentials. These were published in September under the title "What Matters Now", which sold well. In the book's postscript, Jenkins said that Labour should not be a narrow socialist party advocating unpopular left-wing policies but must aim to "represent the hopes and aspirations of the whole leftward thinking half of the country", adding that a "broad-based, international, radical, generous-minded party could quickly seize the imagination of a disillusioned and uninspired British public".

After Dick Taverne's victory in the 1973 Lincoln by-election, where he stood as "Democratic Labour" in opposition to the official Labour candidate, Jenkins gave a speech to the Oxford University Labour Club denouncing the idea of a new centre party. Jenkins was elected to the shadow cabinet in November 1973 as Shadow Home Secretary. During the February 1974 election, Jenkins rallied to Labour and his campaign was described by David Butler and Dennis Kavanagh as sounding "a note of civilised idealism". Jenkins was disappointed that the Liberal candidate in his constituency won 6000 votes; he wrote in his memoirs that "I already regarded myself as such a closet Liberal that I naÃ¯vely thought they ought nearly all to have come to me".

Jenkins wrote a series of biographical essays that appeared in "The Times" during 1971â74 and which were published as "Nine Men of Power" in 1974. Jenkins chose Gaitskell, Ernest Bevin, Stafford Cripps, Adlai Stevenson II, Robert F. Kennedy, Joseph McCarthy, Lord Halifax, LÃ©on Blum and John Maynard Keynes. In 1971 Jenkins delivered three lectures on foreign policy at Yale University, published a year later as "Afternoon on the Potomac?"

When Labour returned to power in early 1974, Jenkins was appointed Home Secretary for the second time. Earlier, he had been promised the treasury; however, Wilson later decided to appoint Denis Healey as Chancellor instead. Upon hearing from Bernard Donoughue that Wilson had reneged on his promise, Jenkins reacted angrily. Despite being on a public staircase, he is reported to have shouted "You tell Harold Wilson he must bloody well come to see meÂ ...and if he doesn't watch out, I won't join his bloody governmentÂ ... This is typical of the bloody awful way Harold Wilson does things!" The Jenkinsites were dismayed by Jenkins' refusal to insist upon the Chancellorship and began to look elsewhere for leadership, thus ending the Jenkinsites as a united group.

Jenkins served from 1974 to 1976. Whereas during his first period as Home Secretary in the 1960s the atmosphere had been optimistic and confident, the climate of the 1970s was much more fractious and disillusioned. After two Northern Irish sisters, Marian Price and Dolours Price, were imprisoned for 20 years for the 1973 Old Bailey bombing, they went on hunger strike in order to be transferred to a prison in Northern Ireland. In a television broadcast in June 1974, Jenkins announced that he would refuse to give in to their demands, although in March 1975 he discreetly transferred them to a Northern Irish prison.

He undermined his previous liberal credentials to some extent by pushing through the controversial Prevention of Terrorism Act in the aftermath of the Birmingham pub bombings of November 1974, which, among other things, extended the length of time suspects could be held in custody and instituted exclusion orders. Jenkins also resisted calls for the death penalty to be restored for terrorist murderers. On 4 December he told the Cabinet committee on Northern Ireland that "everything he heard made him more convinced that Northern Ireland had nothing to do with the rest of the UK". When reviewing Garret FitzGerald's memoirs in 1991, Jenkins proclaimed: "My natural prejudices, such as they are, are much more green than orange. I am a poor unionist, believing intuitively that even Paisley and Haughey are better at dealing with each other than the English are with either".

The Sex Discrimination Act 1975 (which legislated for gender equality and set up the Equal Opportunities Commission) and the Race Relations Act 1976 (which extended to private clubs the outlawing of racial discrimination and founded the Commission for Racial Equality) were two notable achievements during his second time as Home Secretary.

Jenkins opposed Michael Foot's attempts to grant pickets the right to stop lorries during strikes and he was dismayed by Anthony Crosland's decision to grant an amnesty to the 11 Labour councillors at Clay Cross who had been surcharged for refusing to increase council rents in accordance with the Conservatives' Housing Finance Act 1972. After two trade unionists, Ricky Tomlinson and Des Warren (known as the "Shrewsbury Two"), were imprisoned for intimidation and affray for their part in a strike, Jenkins refused to accede to demands from the labour movement that they should be released. This demonstrated Jenkins' increasing estrangement from much of the labour movement and for a time he was heckled in public by people chanting "Free the Two". Jenkins also unsuccessfully tried to persuade the Cabinet to adopt electoral reform in the form of proportional representation and to have the Official Secrets Act 1911 liberalised to facilitate more open government.

Although becoming increasingly disillusioned during this time by what he considered the party's drift to the left, he was the leading Labour figure in the EEC referendum of June 1975 (and was also president of the 'Yes' campaign). In September 1974 he had followed Shirley Williams in stating that he "could not stay in a Cabinet which had to carry out withdrawal" from the EEC. During the referendum campaign, Tony Benn claimed that 500,000 jobs had been lost due to Britain's membership; Jenkins replied on 27 May that "I find it increasingly difficult to take Mr Benn seriously as an economics minister". He added that Britain outside the EEC would enter "an old people's home for fading nations. ... I do not even think it would be a comfortable or agreeable old people's home. I do not much like the look of some of the prospective wardens". The two men debated Britain's membership together on "Panorama", which was chaired by David Dimbleby. According to David Butler and Uwe Kitzinger, "they achieved a decidedly more lucid and intricate level of discussion than is commonly seen on political television". Jenkins found it congenial to work with the centrists of all parties in the campaign and the 'Yes' campaign won by two to one.

After the referendum, Wilson demoted Benn to Energy Secretary and attempted to balance the downgrading of Benn with the dismissal of the right-wing minister Reg Prentice from the Department of Education, despite already promising Jenkins that he had no intention of sacking Prentice. Jenkins threatened to resign if Prentice was sacked, telling Wilson that he was "a squalid little man who was using squalid little arguments in order to explain why he was performing so much below the level of events". Wilson quickly backed down. In September Jenkins delivered a speech in Prentice's constituency of Newham to demonstrate solidarity with him after he was threatened with deselection by left-wingers in the constituency party. Jenkins was heckled by both far-left and far-right demonstrators and he was hit in the chest by a flour bomb thrown by a member of the National Front. Jenkins warned that if Prentice was deselected "it is not just the local party that is undermining its own foundations by ignoring the beliefs and feelings of ordinary people, the whole legitimate Labour Party, left as well as right, is crippled if extremists have their way". He added that if "tolerance is shattered formidable consequences will follow. Labour MPs will either have to become creatures of cowardice, concealing their views, trimming their sails, accepting orders, stilling their consciences, or they will all have to be men far far to the left of those whose votes they seek. Either would make a mockery of parliamentary democracy".

In January 1976 he further distanced himself from the left with a speech in Anglesey, where he repudiated ever-higher public spending: "I do not think you can push public expenditure significantly above 60 per cent [of GNP] and maintain the values of a plural society with adequate freedom of choice. We are here close to one of the frontiers of social democracy". A former supporter, Roy Hattersley, distanced himself from Jenkins after this speech.

In May 1976 he told the Police Federation conference to "be prepared first to look at the evidence and to recognize how little the widespread use of prison reduces our crime or deals effectively with many of the individuals concerned". He also responded to the Federation's proposals on law and order: "I respect your right to put them to me. You will no doubt respect my right to tell you that I do not think all the points in sum amount to a basis for a rational penal policy".

When Wilson suddenly resigned as Prime Minister in March 1976, Jenkins was one of six candidates for the leadership of the Labour Party but came third in the first ballot, behind Callaghan and Michael Foot. Realising that his vote was lower than expected, and sensing that the parliamentary party was in no mood to overlook his actions five years before, he immediately withdrew from the contest. On issues such as the EEC, trade union reform and economic policy he had proclaimed views opposite to those held by the majority of Labour Party activists, and his libertarian social views were at variance with the majority of Labour voters. A famous story alleged that when one of Jenkins' supporters canvassed a group of miners' MPs in the Commons' tea-room, he was told: "Nay, lad, we're all Labour here".

Jenkins had wanted to become Foreign Secretary, but Foot warned Callaghan that the party would not accept the pro-European Jenkins as Foreign Secretary. Callaghan instead offered Jenkins the Treasury in six months' time (when it would be possible to move Denis Healey to the Foreign Office). Jenkins turned the offer down. Jenkins then accepted an appointment as President of the European Commission (succeeding FranÃ§ois-Xavier Ortoli) after Callaghan appointed Anthony Crosland to the Foreign Office.

In an interview with "The Times" in January 1977, Jenkins said that: "My wish is to build an effective united Europe. ... I want to move towards a more effectively organized Europe politically and economically and as far as I am concerned I want to go faster, not slower". The main development overseen by the Jenkins Commission was the development of the Economic and Monetary Union of the European Union from 1977, which began in 1979 as the European Monetary System, a forerunner of the Single Currency or Euro. His biographer calls Jenkins "the godfather of the euro" and claims that among his successors only Jacques Delors has made more impact.

In speech in Florence in October 1977, Jenkins argued that monetary union would facilitate "a more efficient and developed rationalisation of industry and commerce than is possible under a Customs Union alone". He added that "a major new international currency" would form "a joint and alternative pillar of the world monetary system" which would lead to greater international stability. Monetary union would also combat inflation by controlling the money supply. Jenkins conceded that this would involve the diminution of national sovereignty but he pointed out that "governments which do not discipline themselves already find themselves accepting very sharp surveillance" from the IMF. Monetary union would also promote employment and diminish regional differences. Jenkins ended the speech by quoting Jean Monnet's statement that politics was "not only the art of the possible, but...the art of making possible tomorrow what may seem impossible today".

President Jenkins was the first President to attend a G8 summit on behalf of the Community. He received an Honorary Degree (Doctor of Laws) from the University of Bath in 1978.

In October 1978 "Tribune" reported (falsely) that Jenkins and his wife had not paid their Labour Party subscription for several years. After this was repeated in the national press, Jenkins' drafted his wife's letter to "The Times" that refuted the allegation. Jenkins blamed the story on a "malicious Trot in the North Kensington Labour Party". Jenkins was disillusioned with the Labour Party and he was almost certain that he could not stand again as a Labour candidate; in January 1979 he told Shirley Williams that the "big mistake we had made was not to go and support Dick Taverne in 1973; everything had got worse since then".

He did not vote in the 1979 election. After the Conservatives won the election Margaret Thatcher contemplated appointing Jenkins Chancellor of the Exchequer on the strength of his success at cutting public expenditure when he was Chancellor. However, his friend Woodrow Wyatt claimed that Jenkins "had other and fresh fish to fry".

The Director-General of the BBC, Ian Trethowan, invited Jenkins to deliver the Richard Dimbleby Lecture for 1979, which he did on 22 November. The title Jenkins gave to his lecture, "Home Thoughts from Abroad", derived from a Robert Browning poem. He delivered it in the Royal Society of Arts and it was broadcast live on television. Jenkins analysed the decline of the two-party system since 1951 and criticised the excessive partisanship of British politics, which he claimed alienated the bulk of voters, who were more centrist. He advocated proportional representation and the acceptance of "the broad line of division between the public and private sectors", a middle way between Thatcherism and Bennism. Jenkins said that the private sector should be encouraged without too much interference to create as much wealth as possible "but use the wealth so created both to give a return for enterprise and to spread the benefits throughout society in a way that avoids the disfigurements of poverty, gives a full priority to public education and health services, and encourages co-operation and not conflict in industry and throughout society". He then reiterated his long-standing commitment to libertarianism:

You also make sure that the state knows its place...in relation to the citizen. You are in favour of the right of dissent and the liberty of private conduct. You are against unnecessary centralization and bureaucracy. You want to devolve decision-making wherever you sensibly can. ... You want the nation to be self-confident and outward-looking, rather than insular, xenophobic and suspicious. You want the class system to fade without being replaced either by an aggressive and intolerant proletarianism or by the dominance of the brash and selfish values of a 'get rich quick' society. ... These are some of the objectives which I believe could be assisted by a strengthening of the radical centre.

"The Listener" reprinted the text along with assessments by Enoch Powell, Paul Johnson, Jack Jones, J. A. G. Griffith, Bernard Crick, Neil Kinnock and Jo Grimond. They were all critical; Kinnock thought him misguided as Britain had already suffered from centrist rule for thirty years and Grimond complained that Jenkins' clarion call had come 20 years too late.

Jenkins' last year as President of the Commission was dominated by Margaret Thatcher's fight for a rebate on Britain's contribution to the EEC budget. He believed that the quarrel was unnecessary and regretted that it soured Britain's relationship with the Community for years. In November 1980 Jenkins delivered the Winston Churchill memorial lecture in Luxembourg, where he proposed a solution to the British budgetary question. The proportion of the Community's budget spent on agriculture should be reduced by extending Community spending into new areas where Britain would receive more benefit, such as regional spending. The size of the Community's budget would, in his scheme, be tripled by transferring from the nation states to the Community competence over social and industrial policy.

After his Dimbleby Lecture, Jenkins increasingly favoured the formation of a new social democratic party. He publicly aired these views in a speech to the Parliamentary Press Gallery in June 1980, where he repeated his criticisms of the two-party system and attacked Labour's move to the left. At the previous month's Wembley conference, Labour had adopted a programme which included non-cooperation with the EEC and "a near neutralist and unilateralist" defence policy that would, Jenkins argued, render meaningless Britain's NATO membership. Labour's proposals for further nationalisation and anti-private enterprise policies, Jenkins claimed, were more extreme than in any other democratic country and it was not "by any stretch of the imagination a social democratic programme". He added that a new party could reshape politics and lead to the "rapid revival of liberal social democratic Britain".

The Labour Party conference at Blackpool in September 1980 adopted a unilateralist defence policy, withdrawal from the EEC and further nationalisation, along with Tony Benn's demands for the mandatory reselection of MPs and an electoral college to elect the party leader. In November Labour MPs elected the left-winger Michael Foot over the right-wing Denis Healey and in January 1981 Labour's Wembley conference decided that the electoral college that would elect the leader would give the trade unions 40 per cent of the vote, with MPs and constituency parties 30 per cent each. Jenkins then joined David Owen, Bill Rodgers and Shirley Williams (known as the "Gang of Four") in issuing the Limehouse Declaration. This called for the "realignment of British politics". They then formed the Social Democratic Party (SDP) on 26 March.

Jenkins delivered a series of speeches setting out the SDP's alternative to Thatcherism and Bennism and argued that the solution to Britain's economic troubles lay in the revenue from North Sea oil, which should be invested in public services. He attempted to re-enter Parliament at the Warrington by-election in July 1981 and campaigned on a six-point programme which he put forward as a Keynesian alternative to Thatcherism and Labour's "siege economy", but Labour retained the seat with a small majority. Despite it being a defeat, the by-election demonstrated that the SDP was a serious force. Jenkins said after the count that it was the first parliamentary election that he had lost but it was "by far the greatest victory in which I have ever participated".

At the SDP's first annual conference in October 1981, Jenkins called for "an end to the futile frontier war between public and private sectors" and proposed an "inflation tax" on excessive pay rises that would restrain spiralling wages and prices. After achieving this, an SDP government would be able to embark on economic expansion to reduce unemployment.

In March 1982 he fought the Glasgow Hillhead by-election, which had previously been a Conservative-held seat. Polls at the beginning of the campaign put Jenkins in third place but after a series of ten well-attended public meetings which Jenkins addressed, the tide began to turn in Jenkins' favour and he was elected with a majority of just over 2000 on a swing of 19 per cent. Jenkins' first intervention in the House of Commons following his election, on 31 March, was seen as a disappointment. The Conservative MP Alan Clark wrote in his diary:

Jenkins, with excessive and almost unbearable gravitas, asked three very heavy statesman-like non-party-political questions of the PM. I suppose he is very formidable, but he was so portentous and long-winded that he started to lose the sympathy of the House about half way through and the barracking resumed. The Lady replied quite brightly and freshly, as if she did not particularly know who he was, or care.

Whereas earlier in his career Jenkins had excelled in the traditional set-piece debates from the dispatch box, the focus of parliamentary reporting had now moved to the point-scoring of Prime Minister's Questions, which he struggled with. Seated in the traditional place for third parties in the Commons (the second or third row below the gangway), Jenkins was situated near (and shared the same microphone with) Labour's "awkward squad" that included Dennis Skinner and Bob Cryer, who regularly heckled abuse ("Roy, your flies are undone").

Seven days after Jenkins' by-election victory Argentina invaded the Falklands and the subsequent Falklands War transformed British politics, increased substantially the public's support for the Conservatives and ended any chance that Jenkins' election would reinvigorate the SDP's support. In the SDP leadership election, Jenkins was elected with 56.44 of the vote, with David Owen coming second. During the 1983 election campaign his position as the prime minister-designate for the SDP-Liberal Alliance was questioned by his close colleagues, as his campaign style was now regarded as ineffective; the Liberal leader David Steel was considered to have a greater rapport with the electorate.

After the general election Owen succeeded him unopposed. Jenkins was disappointed with Owen's move to the right, and his acceptance and backing of some of Thatcher's policies. At heart, Jenkins remained an unrepentant Keynesian. In his July 1984 Tawney Lecture, Jenkins said that the "whole spirit and outlook" of the SDP "must be profoundly opposed to Thatcherism. It could not go along with the fatalism of the Government's acceptance of massive unemployment". He also delivered a series of speeches in the Commons attacking the Thatcherite policies of the Chancellor, Nigel Lawson. Jenkins called for more government intervention to support industry and for North Sea oil revenues to be channelled into a major programme of rebuilding Britain's infrastructure and into educating a skilled workforce. He also attacked the Thatcher government for failing to join the European Exchange Rate Mechanism.

In 1985 he wrote to "The Times" to advocate the closing down of the political surveillance role of MI5. During the controversy surrounding Peter Wright's "Spycatcher", in which he alleged that Harold Wilson had been a Soviet spy, Jenkins rubbished the allegation and reiterated his call for the end of MI5's powers of political survelliance.

In 1986 he won "The Spectator"'s Parliamentarian of the Year award. He continued to serve as SDP Member of Parliament for Glasgow Hillhead until his defeat at the 1987 general election by the Labour candidate George Galloway, after boundary changes in 1983 had changed the character of the constituency.

In 1986 appeared his biography of Harry S. Truman and the following year his biography of Stanley Baldwin was published.

From 1987, Jenkins remained in politics as a member of the House of Lords as a life peer with the title Baron Jenkins of Hillhead, of Pontypool in the County of Gwent. Also in 1987, Jenkins was elected Chancellor of the University of Oxford. He was leader of the Liberal Democrats in the Lords from 1988 until 1997.

In 1988 he fought and won an amendment to the Education Reform Act 1988, guaranteeing academic freedom of speech in further and higher education establishments. This affords and protects the right of students and academics to "question and test received wisdom" and has been incorporated into the statutes or articles and instruments of governance of all universities and colleges in Britain.

In 1991 his memoirs, "A Life at the Centre", was published by Macmillan, who paid Jenkins an Â£130,000 advance. He was magnanimous to most of those colleagues with whom he had clashed in the past, except for David Owen, who he blamed for destroying the idealism and cohesion of the SDP. In the last chapter ('Establishment Whig or Persistent Radical?') he reaffirmed his radicalism, placing himself "somewhat to the left of James Callaghan, maybe Denis Healey and certainly of David Owen". He also proclaimed his political credo:

My broad position remains firmly libertarian, sceptical of official cover-ups and uncompromisingly internationalist, believing sovereignty to be an almost total illusion in the modern world, although both expecting and welcoming the continuance of strong differences in national traditions and behaviour. I distrust the deification of the enterprise culture. I think there are more limitations to the wisdom of the market than were dreamt of in Mrs Thatcher's philosophy. I believe that levels of taxation on the prosperous, having been too high for many years (including my own period at the Treasury), are now too low for the provision of decent public services. And I think the privatisation of near monopolies is about as irrelevant as (and sometimes worse than) were the Labour Party's proposals for further nationalisation in the 1970s and early 1980s.

"A Life at the Centre" was generally favourably reviewed: in the "Times Literary Supplement" John Grigg said it was a "marvellous account of high politics by a participant writing with honesty, irony and sustained narrative verve". In "The Spectator" Anthony Quinton remarked that Jenkins was "not afraid to praise himself and earns the right to do so by unfudged self-criticism". However, there were critical voices: John Smith in "The Scotsman" charged that Jenkins never had any loyalty to the Labour Party and was an ambitious careerist intent only on furthering his career. John Campbell claims that "A Life at the Centre" is now generally recognised as one of the best political memoirs. David Cannadine ranked it alongside Duff Cooper's "Old Men Forget", R. A. Butler's "The Art of the Possible" and Denis Healey's "The Time of My Life" as one of the four best political memoirs of the post-war period.

In 1993, he was appointed to the Order of Merit. Also that year, his "Portraits and Miniatures" was published. The main body of the book is a set of 6 biographical essays (Rab Butler, Aneurin Bevan, Iain Macleod, Dean Acheson, Konrad Adenauer, Charles de Gaulle), along with lectures, articles and book reviews.
A television documentary about Jenkins was made by Michael Cockerell, titled "Roy Jenkins: A Very Social Democrat", and broadcast on 26 May 1996. Although an admiring portrait overall, Cockerell was frank about Jenkins' affairs and both Jenkins and his wife believed that Cockerell had betrayed their hospitality.

Jenkins hailed Tony Blair's election as Labour Party leader in July 1994 as "the most exciting Labour choice since the election of Hugh Gaitskell". He argued that Blair should stick "to a constructive line on Europe, in favour of sensible constitutional innovation...and in favour of friendly relations with the Liberal Democrats". He added that he hoped Blair would not move Labour further to the right: "Good work has been done in freeing it from nationalisation and other policies. But the market cannot solve everything and it would be a pity to embrace the stale dogmas of Thatcherism just when their limitations are becoming obvious".

Jenkins and Blair had been in touch since the latter's time as Shadow Home Secretary, when he admired Jenkins' reforming tenure at the Home Office. Jenkins told Paddy Ashdown in October 1995: "I think Tony treats me as a sort of father figure in politics. He comes to me a lot for advice, particularly about how to construct a Government". Jenkins tried to persuade Blair that the division in the centre-left vote between the Labour and Liberal parties had enabled the Conservatives to dominate the 20th century, whereas if the two left-wing parties entered into an electoral pact and adopted proportional representation, they could dominate the 21st century. Jenkins was an influence on the thinking of New Labour and both Peter Mandelson and Roger Liddle in their 1996 work "The Blair Revolution" and Philip Gould in his "Unfinished Revolution" recognised Jenkins' influence.

Before the 1997 election, Blair had promised an enquiry into electoral reform. In December 1997, Jenkins was appointed chair of a Government-appointed Independent Commission on the Voting System, which became known as the "Jenkins Commission", to consider alternative voting systems for the UK. The Jenkins Commission reported in favour of a new uniquely British mixed-member proportional system called "Alternative vote top-up" or "limited AMS" in October 1998, although no action was taken on this recommendation. Blair told Ashdown that Jenkins' recommendations would not pass the Cabinet.

British membership of the European single currency, Jenkins believed, was the supreme test of Blair's statesmanship. However, he was disappointed with Blair's timidity in taking on the Eurosceptic tabloid press. He told Blair in October 1997: "You have to choose between leading Europe or having Murdoch on your side. You can have one but not both". Jenkins was also critical of New Labour's authoritarianism, such as the watering down of the Freedom of Information Act 2000 and their intention to ban fox hunting. By the end of his life Jenkins believed that Blair had wasted his enormous parliamentary majority and would not be recorded in history as a great Prime Minister; he ranked him between Harold Wilson and Stanley Baldwin.

After Gordon Brown attacked Oxford University for indulging in "old school tie" prejudices because it rejected a state-educated pupil, Laura Spence, Jenkins told the House of Lords in June 2000 that "Brown's diatribe was born of prejudice out of ignorance. Nearly every fact he adduced was false". Jenkins voted for the equalisation of the homosexual age of consent and for repealing Section 28.

Jenkins wrote 19 books, including a biography of Gladstone (1995), which won the 1995 Whitbread Award for Biography, and a much-acclaimed biography of Winston Churchill (2001). His then-designated official biographer, Andrew Adonis, was to have finished the Churchill biography had Jenkins not survived the heart surgery he underwent towards the end of its writing. The popular historian Paul Johnson called it the best one-volume biography on its subject.

Jenkins underwent heart surgery in the form of an heart valve replacement on 12 October 2000 and postponed his 80th birthday celebrations whilst recovering, by having a celebratory party on 7 March 2001. He died on 5 January 2003, after suffering a heart attack at his home at East Hendred, in Oxfordshire. His last words, to his wife, were, "Two eggs, please, lightly poached". At the time of his death Jenkins was starting work on a biography of US President Franklin D. Roosevelt.

After his death, Blair paid tribute to "one of the most remarkable people ever to grace British politics", who had "intellect, vision and an integrity that saw him hold firm to his beliefs of moderate social democracy, liberal reform and the cause of Europe throughout his life. He was a friend and support to me". James Callaghan and Edward Heath also paid tribute and Tony Benn said that as "a founder of the SDP he was probably the grandfather of New Labour". However, he was strongly criticised by others including Denis Healey, who condemned the SDP split as a "disaster" for the Labour Party which prolonged their time in opposition and allowed the Tories to have an unbroken run of 18 years in government.

The Professor of Government at Oxford University, Vernon Bogdanor, provided an assessment in "The Guardian":

Roy Jenkins was both radical and contemporary; and this made him the most influential exponent of the progressive creed in politics in postwar Britain. Moreover, the political creed for which he stood belongs as much to the future as to the past. For Jenkins was the prime mover in the creation of a form of social democracy which, being internationalist, is peculiarly suited to the age of globalisation and, being liberal, will prove to have more staying power than the statism of Lionel Jospin or the corporatist socialism of Gerhard SchrÃ¶der. ... Roy Jenkins was the first leading politician to appreciate that a liberalised social democracy must be based on two tenets: what Peter Mandelson called an aspirational society (individuals must be allowed to regulate their personal lives without interference from the state); and that a post-imperial country like Britain could only be influential in the world as part of a wider grouping (the EU).

His alma mater, Cardiff University, honoured the memory of Roy Jenkins by naming one of its halls of residence Roy Jenkins Hall.

On 20 January 1945, Jenkins married Mary Jennifer (Jennifer) Morris (18 January 1921 â 2 February 2017) They were married for almost 58 years until his death, although he had "several affairs", including one with Jackie Kennedy's sister Lee Radziwill.

She was made a DBE for services to ancient and historical buildings. They had two sons, Charles and Edward, and a daughter, Cynthia.

Early in his life Jenkins had a relationship with Anthony Crosland.





</doc>
<doc id="26288" url="https://en.wikipedia.org/wiki?curid=26288" title="List of Polish monarchs">
List of Polish monarchs

Poland was ruled at various times either by dukes and princes (the 10thâ14th century) or by kings (the 11th18th centuries). During the latter period, a tradition of free election of monarchs made it a uniquely electable position in Europe (16thâ18th centuries).

The first known Polish ruler is Duke Mieszko I who adopted Christianity under the authority of Rome in the year 966. He was succeeded by his son, BolesÅaw I the Brave, who greatly expanded the boundaries of the Polish state and ruled as the first king in 1025. The following centuries gave rise to the mighty Piast dynasty, consisting of both kings such as Mieszko II Lambert, PrzemysÅ II or WÅadysÅaw I the Elbow-high and dukes like BolesÅaw III Wrymouth. The dynasty ceased to exist with the death of Casimir III the Great in 1370. In the same year, the Capetian House of Anjou became the ruling house with Louis I as king of both Poland and Hungary. His daughter, Jadwiga, later married Jogaila, the pagan Grand Duke of Lithuania, who in 1386 was baptized and crowned as WÅadysÅaw II JagieÅÅo, thus creating the Jagiellonian dynasty and a personal union between Poland and Lithuania.

During the reign of Casimir IV Jagiellon and Sigismund I the Old, culture flourished and cities developed. This era of progress, also known as the Polish Renaissance, continued until the Union of Lublin under Sigismund II Augustus, which unofficially marked the end of the Polish Golden Age. After the death of last Jagiellonian king, the united PolishâLithuanian Commonwealth became an elective monarchy with mostly foreigners elected as monarchs such as Henry III of France, who witnessed the introduction of Golden Liberty and Stephen BÃ¡thory, a great military commander who strengthened the nation. The meaningful rule of the Vasa dynasty initially expanded the Commonwealth, developing the arts and crafts, as well as trade and commerce. King Sigismund III Vasa, a talented but somewhat despotic ruler, involved the country in many wars, which subsequently resulted in the successful capture of Moscow and loss of Livonia to Sweden. His son, WÅadysÅaw IV Vasa, fiercely defended the Commonwealth's borders and continued the policy of his father until death, unlike John II Casimir whose tragic rule forced his abdication.

The election of John III Sobieski to the Polish throne was a great success. His brilliant military tactics led to the victory at Vienna in 1683 and partial recapture of land from the Ottoman Empire. However, the years that followed were not as successful; the long and ineffective rule of the Wettin dynasty (Augustus II the Strong and Augustus III) placed the Commonwealth under the influence of Saxony and the Russian Empire. Additional feuds with rebelled nobility (szlachta) and most notably StanisÅaw I LeszczyÅski and France diminished the influence of Poland-Lithuania in the region. This led to the partitions that occurred under King StanisÅaw II Augustus, yet another enlightened, but ineffective monarch.

The last sovereign was Frederick Augustus I as Duke of Warsaw, who throughout his political career attempted at rehabilitating the Polish state. After Poland declared independence in 1918, the monarchy was abolished and a parliamentary republican authority was established.

"See: Poland in the Early Middle Ages"

Most of these rulers appear for the first time in chronicles from the 13th century

Several historians tend to believe that three legendary rulers of early Poland before Mieszko I might actually be historical persons. They appear in the oldest Polish chronicle, "Gesta principum Polonorum" from the early 12th century.







</doc>
<doc id="26289" url="https://en.wikipedia.org/wiki?curid=26289" title="Richard Henry Lee">
Richard Henry Lee

Richard Henry Lee (January 20, 1732June 19, 1794) was an American statesman and Founding Father from Virginia best known for the June 1776 Lee Resolution, the motion in the Second Continental Congress calling for the colonies' independence from Great Britain leading to the United States Declaration of Independence, which he signed. He also served a one-year term as the President of the Continental Congress, was a signatory to the Articles of Confederation, and was a United States Senator from Virginia from 1789 to 1792, serving during part of that time as the second President "pro tempore" of the upper house.

He was a member of the Lee family, a historically influential family in Virginia politics.

He was born in Westmoreland County, Virginia to Col. Thomas Lee and Hannah Harrison Ludwell Lee on January 20, 1732. He was raised and came from a line of military officers, diplomats, and legislators. His father, Thomas Lee, was the governor of Virginia before his death in 1750. Lee spent most of his early life in Stratford, Virginia with his family at Stratford Hall. Here he was tutored and taught in a variety of skills, and witnessed the very beginning of political career as his father sent him around to neighboring planters with the intention for Lee to become associated with neighboring men of like prominence. In 1748, at 16, Lee left Virginia for Yorkshire, England, to complete his formal education at Queen Elizabeth Grammar School, Wakefield. Both of his parents died in 1750 and, in 1753, after touring Europe, he returned to Virginia to help his brothers settle the estate his parents had left behind.

In 1757, Lee was appointed justice of the peace in Westmoreland County. In 1758 he was elected to the Virginia House of Burgesses, where he met Patrick Henry. An early advocate of independence, Lee became one of the first to create Committees of Correspondence among the many independence-minded Americans in the various colonies. In 1766, almost ten years before the American Revolutionary War, Lee is credited with having authored the Westmoreland Resolution which was publicly signed by prominent landowners who met at Leedstown, Westmoreland County, Virginia on February 27, 1766. This resolution was signed by four brothers of George Washington as well as Gilbert Campbell.

In August 1774, Lee was chosen as a delegate to the First Continental Congress in Philadelphia. In Lee's Resolution on June 7, 1776 during the Second Continental Congress, Lee put forth the motion to the Continental Congress to declare Independence from Great Britain, which read (in part):

Resolved: That these United Colonies are, and of right ought to be, free and independent States, that they are absolved from all allegiance to the British Crown, and that all political connection between them and the State of Great Britain is, and ought to be, totally dissolved.

Lee had returned to Virginia by the time Congress voted on and adopted the Declaration of Independence, but he signed the document when he returned to Congress.

Lee was elected sixth president of Congress under the Articles of Confederation on November 30, 1784, in the French Arms Tavern, Trenton, New Jersey. Congress convened on January 11, 1785, in the old New York City Hall, with Lee presiding until November 23, 1785. Although he was not paid a salary, his household expenses were covered in the amount of $12,203.13.

Lee abhorred the notion of imposing federal taxes and believed that continuing to borrow foreign money was imprudent. Throughout his term, he maintained that the states should relinquish their claims in the Northwest Territory, enabling the federal government to fund its obligations though land sales. He wrote to friend and colleague Samuel Adams:

I hope we shall shortly finish our plan for disposing of the western Lands to discharge the oppressive public debt created by the war & I think that if this source of revenue be rightly managed, that these republics may soon be discharged from that state of oppression and distress that an indebted people must invariably feel.

Debate began on the expansion of the Ordinance of 1784 and Thomas Jefferson's survey method; namely, "hundreds of ten geographical miles square, each mile containing 6086 and 4-10ths of a foot" and "sub-divided into lots of one mile square each, or 850 and 4-10ths of an acre" on April 14. On May 3, 1785, William Grayson of Virginia made a motion, seconded by James Monroe, to change "seven miles square" to "six miles square." 

The Land Ordinance of 1785 passed on May 20, 1785, yet the federal government lacked the resources to manage the newly surveyed lands. Not only did Native Americans refuse to relinquish their hold on the platted territory, but much of the remaining land was occupied by squatters. With Congress unable to muster magistrates or troops to enforce the dollar-per-acre title fee, Lee's plan ultimately failed, although the survey system developed under the Land Ordinance of 1785 has endured.


Lee was the son of Col. Thomas Lee, Hon. (1690â1750) of "Stratford Hall", Westmoreland Co., Virginia. Thomas married Hannah Harrison Ludwell (1701â1750).

Lee married first on December 5, 1757, Anne Aylett (1738â1768), daughter of William Aylett and Elizabeth Eskridge (1719). Anne died December 12, 1768 at Chantille, Westmoreland Co., Virginia. The couple had six children, four of whom survived infancy.

Lee remarried in June or July 1769 to Anne (Gaskins) Pinckard. The couple had seven children, five of whom survived infancy.

Lee honored his brother, Francis Lightfoot Lee (another signer of the Articles of Confederation and the Declaration of Independence), by naming his fourth son after him.

Richard Henry Lee died on June 19, 1794 at the age of 62.

Lee is recognized as a Founding Father of the United States. Richard Henry Lee Elementary School in Rossmoor, California and Richard Henry Lee School in Chicago, Illinois are named in his honor. Richard Henry Lee Elementary in Glen Burnie, Maryland is also named after him.

Late in 1941, a Liberty Ship was named for him.

The Chantilly Archaeological Site was listed on the National Register of Historic Places in 1971.

Lee is portrayed as a character in the 1969 musical "1776". He was portrayed by Ron Holgate in both the Broadway cast and in the 1972 film. In one scene, Lee performs a song called "The Lees of Old Virginia," in which he explains how he knows he will be able to convince the Virginia House of Burgesses to allow him to propose independence and celebrates his own status as a Lee, one of the First Families of Virginia. The character is presented as vain, but not very bright, serving the play as a comic device rather than a historically based portrayal of Lee.

Lee is portrayed by Paul Fitzgerald in the 2008 HBO miniseries "John Adams." Although Lee had returned to Virginia, and thus was not present to vote on the Resolution for Independence, the miniseries portrays him as being present and casting the vote for the Virginia delegation. The miniseries does show the fact that Lee always had his hand wrapped in black silk to hide the deformation caused by a hunting accident.



</doc>
<doc id="26291" url="https://en.wikipedia.org/wiki?curid=26291" title="Rajasthan">
Rajasthan

Rajasthan ( ; literally, "Land of Kings") is a state in northern India. The state covers an area of or 10.4 percent of the total geographical area of India. It is the largest Indian state by area and the seventh largest by population. Rajasthan is located on the northwestern side of India, where it comprises most of the wide and inhospitable Thar Desert (also known as the "Great Indian Desert") and shares a border with the Pakistani provinces of Punjab to the northwest and Sindh to the west, along the Sutlej-Indus river valley. Elsewhere it is bordered by five other Indian states: Punjab to the north; Haryana and Uttar Pradesh to the northeast; Madhya Pradesh to the southeast; and Gujarat to the southwest.

Major features include the ruins of the Indus Valley Civilisation at Kalibanga and Balathal, the Dilwara Temples, a Jain pilgrimage site at Rajasthan's only hill station, Mount Abu, in the ancient Aravalli mountain range and in eastern Rajasthan, the Keoladeo National Park near Bharatpur, a World Heritage Site known for its bird life. Rajasthan is also home to three national tiger reserves, the Ranthambore National Park in Sawai Madhopur, Sariska Tiger Reserve in Alwar and Mukundra Hill Tiger Reserve in Kota.

The state was formed on 30 March 1949 when Rajputanathe name adopted by the British Raj for its dependencies in the regionwas merged into the Dominion of India. Its capital and largest city is Jaipur. Other important cities are Jodhpur, Kota, Bikaner, Ajmer and Udaipur. The economy of Rajasthan is the ninth-largest state economy in India with in gross domestic product and a per capita GDP of . Rajasthan ranks 22nd among Indian states in human development index.

Rajasthan literally means "Land of Kings"."" The oldest reference to Rajasthan is found in a stone inscription dated back to 625 A.D. The print mention of the name "Rajasthan" appears in the 1829 publication "Annals and Antiquities of Rajast'han or the Central and Western Rajpoot States of India", while the earliest known record of "Rajputana" as a name for the region is in George Thomas's 1800 memoir "Military Memories". John Keay, in his book "India: A History", stated that "Rajputana" was coined by the British in 1829, John Briggs, translating Ferishta's history of early Islamic India, used the phrase "Rajpoot (Rajput) princes" rather than "Indian princes".

Parts of what is now Rajasthan were partly part of the Vedic Civilisation and Indus Valley Civilization. Kalibangan, in Hanumangarh district, was a major provincial capital of the Indus Valley Civilization. Another archaeological excavation at Balathal site in Udaipur district shows a settlement contemporary with the Harrapan civilisation dating back to 3000 â 1500 BC.

Stone Age tools dating from 5,000 to 200,000 years were found in Bundi and Bhilwara districts of the state.

Matsya Kingdom of the Vedic civilisation of India, is said to roughly corresponded to the former state of Jaipur in Rajasthan and included the whole of Alwar with portions of Bharatpur. The capital of Matsya was at Viratanagar (modern Bairat), which is said to have been named after its founder king Virata.

Bhargava identifies the two districts of Jhunjhunu and Sikar and parts of Jaipur district along with Haryana districts of Mahendragarh and Rewari as part of Vedic state of Brahmavarta. Bhargava also locates the present day Sahibi River as the Vedic Drishadwati River, which along with Saraswati River formed the borders of the Vedic state of Brahmavarta. Manu and Bhrigu narrated the Manusmriti to a congregation of seers in this area only. Ashrams of Vedic seers Bhrigu and his son Chayvan Rishi, for whom Chyawanprash was formulated, were near Dhosi Hill part of which lies in Dhosi village of Jhunjhunu district of Rajasthan and part lies in Mahendragarh district of Haryana.

The Western Kshatrapas (405â35 BC), the Saka rulers of the western part of India, were successors to the Indo-Scythians, and were contemporaneous with the Kushans, who ruled the northern part of the Indian subcontinent. The Indo-Scythians invaded the area of Ujjain and established the Saka era (with their calendar), marking the beginning of the long-lived Saka Western Satraps state.

Gurjars ruled for many dynasties in this part of the country, the region was known as "Gurjaratra". Up to the 10th century AD, almost all of North India acknowledged the supremacy of the Gurjars, with their seat of power at Kannauj.

The Gurjar Pratihar Empire acted as a barrier for Arab invaders from the 8th to the 11th century. The chief accomplishment of the Gurjara-Pratihara Empire lies in its successful resistance to foreign invasions from the west, starting in the days of Junaid. Historian R. C. Majumdar says that this was openly acknowledged by the Arab writers. He further notes that historians of India have wondered at the slow progress of Muslim invaders in India, as compared with their rapid advance in other parts of the world. Now there seems little doubt that it was the power of the Gurjara Pratihara army that effectively barred the progress of the Arabs beyond the confines of Sindh, their only conquest for nearly 300 years.

Traditionally the Rajputs, Gurjars, Jats, Meenas, Bhils, Rajpurohits, Charans, Yadavs, Bishnois, Meghwals, Sermals, Rajput Malis (Sainis) and other tribes made a great contribution in building the state of Rajasthan. All these tribes suffered great difficulties in protecting their culture and the land. Millions of them were killed trying to protect their land. Brahmins, according to "Outlook" constituted 8% to 10% of the population of Rajasthan as per a 2003 report, but only 7% in a 2007 report. According to a 2007 DNA India report, 12.5% of the state are Brahmins.

Prithviraj Chauhan defeated the invading Muhammad Ghori in the First Battle of Tarain in 1191. In 1192 CE, Muhammad Ghori decisively defeated Prithviraj at the Second Battle of Tarain. After the defeat of Chauhan in 1192 CE, a part of Rajasthan came under Muslim rulers. The principal centers of their powers were Nagaur and Ajmer. Ranthambhore was also under their suzerainty. At the beginning of the 13th century, the most prominent and powerful state of Rajasthan was Mewar. The Rajputs resisted the Muslim incursions into India, although a number of Rajput kingdoms eventually became subservient to the Delhi Sultanate.
The Rajputs put up resistance to the Islamic invasions with their warfare and chivalry for centuries. The Rana's of Mewar led other kingdoms in its resistance to outside rule. Rana Hammir Singh, defeated the Tughlaq dynasty and recovered a large portion of Rajasthan. The indomitable Rana Kumbha defeated the Sultans of Malwa and Gujarat and made Mewar the most powerful Rajput Kingdom in India. The ambitious Rana Sanga united the various Rajput clans and fought against the foreign powers in India. Rana Sanga defeated the Afghan Lodi Empire of Delhi and crushed the Turkic Sultanates of Malwa and Gujarat. Rana Sanga then tried to create an Indian empire but was defeated by the first Mughal Emperor Babur at Khanua. The defeat was due to betrayal by the Tomar king Silhadi of Raisen. After Rana Sangas death there was no one who could check the rapid expansion of the Mughal Empire.

Hem Chandra Vikramaditya, the Hindu Emperor, was born in the village of Machheri in Alwar District in 1501. He won 22 battles against Afghans, from Punjab to Bengal including states of Ajmer and Alwar in Rajasthan, and defeated Akbar's forces twice at Agra and Delhi in 1556 at Battle of Delhi before acceding to the throne of Delhi and establishing the "Hindu Raj" in North India, albeit for a short duration, from Purana Quila in Delhi. Hem Chandra was killed in the battlefield at Second Battle of Panipat fighting against Mughals on 5 November 1556.
During Akbar's reign most of the Rajput kings accepted Mughal suzerainty, but the rulers of Mewar (Rana Udai Singh II) and Marwar (Rao Chandrasen Rathore) refused to have any form of alliance with the Mughals. To teach the Rajputs a lesson Akbar attacked Udai Singh and killed Rajput commander Jaimal of Chitor and the citizens of Mewar in large numbers. Akbar killed 20 â 25,000 unarmed citizens in Chittor on the grounds that they had actively helped in the resistance.

Maharana Pratap took an oath to avenge the citizens of Chittor, he fought the Mughal empire till his death and liberated most of Mewar apart from Chittor itself. Maharana Pratap soon became the most celebrated warrior of Rajasthan and became famous all over India for his sporadic warfare and noble actions. According to Satish Chandra, "Rana Pratap's defiance of the mighty Mughal empire, almost alone and unaided by the other Rajput states, constitutes a glorious saga of Rajput valour and the spirit of self-sacrifice for cherished principles. Rana Pratap's methods of sporadic warfare was later elaborated further by Malik Ambar, the Deccani general, and by Shivaji".

Rana Amar Singh I continued his ancestors war against the Mughals under Jehangir, he repelled the Mughal armies at Dewar. Later an expedition was again sent under leadership of Prince Khurram, which caused much damage to life and property of Mewar. Many temples were destroyed, several villages were put on fire and ladies and children were captured and tortured to make Amar Singh accept surrender.

During Aurangzeb's rule Rana Raj Singh I and Veer Durgadas Rathore were chief among those who defied the intolerant emperor of Delhi. They took advantage of the Aravalli hills and caused heavy damage on the Mughal armies that were trying to occupy Rajasthan.

After Aurangzebs death Bahadur Shah I tried to subjugate Rajasthan like his ancestors but his plan backfired when the three Rajput Raja's of Amber, Udaipur and Jodhpur made a joint resistance to the Mughals. The Rajputs first expelled the commandants of Jodhpur and Bayana and recovered Amer by a night attack. They next killed Sayyid Hussain Khan Barha, the commandant of Mewat and many other Mughal officers. Bahadur Shah I, then in the Deccan was forced to patch up a truce with the Rajput Rajas. The Jats, under Suraj Mal, overran the Mughal garrison at Agra and plundered the city taking with them the two great silver doors of the entrance of the famous Taj Mahal which were then melted down by Suraj Mal in 1763.

Over the years, the Mughals began to have internal disputes which greatly distracted them at times. The Mughal Empire continued to weaken, and with the decline of the Mughal Empire in the late 18th century, Rajputana came under the influence of the Marathas. The Maratha Empire, which had replaced the Mughal Empire as the overlord of the subcontinent, was finally replaced by the British Empire in 1818.

In the 19th century the Rajput kingdoms were exhausted, they had been drained financially and in manpower after continuous wars and due to heavy tributes exacted by the Maratha Empire. To save their kingdoms from instability, rebellions and banditry the Rajput kings concluded treaties with the British in the early 19th century, accepting British suzerainty and control over their external affairs in return for internal autonomy.

Modern Rajasthan includes most of Rajputana, which comprises the erstwhile nineteen princely states, two chiefships, and the British district of Ajmer-Merwara. Jaisalmer, Marwar (Jodhpur), Bikaner, Mewar (Chittorgarh), Alwar and Dhundhar (Jaipur) were some of the main Rajput princely states. Bharatpur and Dholpur were Jat princely states whereas Tonk was a princely state under Pathans.

The geographic features of Rajasthan are the Thar Desert and the Aravalli Range, which runs through the state from southwest to northeast, almost from one end to the other, for more than . Mount Abu lies at the southwestern end of the range, separated from the main ranges by the West Banas River, although a series of broken ridges continues into Haryana in the direction of Delhi where it can be seen as outcrops in the form of the Raisina Hill and the ridges farther north. About three-fifths of Rajasthan lies northwest of the Aravallis, leaving two-fifths on the east and south direction.

The Aravalli Range runs across the state from the southwest peak Guru Shikhar (Mount Abu), which is in height, to Khetri in the northeast. This range divides the state into 60% in the northwest of the range and 40% in the southeast. The northwest tract is sandy and unproductive with little water but improves gradually from desert land in the far west and northwest to comparatively fertile and habitable land towards the east. The area includes the Thar Desert. The south-eastern area, higher in elevation (100 to 350Â m above sea level) and more fertile, has a very diversified topography. in the south lies the hilly tract of Mewar. In the southeast, a large area within the districts of Kota and Bundi forms a tableland. To the northeast of these districts is a rugged region (badlands) following the line of the Chambal River. Farther north the country levels out; the flat plains of the northeastern Bharatpur district are part of an alluvial basin. Merta City lies in the geographical centre of Rajasthan.

The Aravalli Range and the lands to the east and southeast of the range are generally more fertile and better watered. This region is home to the Kathiawar-Gir dry deciduous forests ecoregion, with tropical dry broadleaf forests that include teak, "Acacia", and other trees. The hilly Vagad region, home to the cities of Dungarpur and Banswara lies in southernmost Rajasthan, on the border with Gujarat and Madhya Pradesh. With the exception of Mount Abu, Vagad is the wettest region in Rajasthan, and the most heavily forested. North of Vagad lies the Mewar region, home to the cities of Udaipur and Chittaurgarh. The Hadoti region lies to the southeast, on the border with Madhya Pradesh. North of Hadoti and Mewar lies the Dhundhar region, home to the state capital of Jaipur. Mewat, the easternmost region of Rajasthan, borders Haryana and Uttar Pradesh. Eastern and southeastern Rajasthan is drained by the Banas and Chambal rivers, tributaries of the Ganges.

The northwestern portion of Rajasthan is generally sandy and dry. Most of this region is covered by the Thar Desert which extends into adjoining portions of Pakistan. The Aravalli Range does not intercept the moisture-giving southwest monsoon winds off the Arabian Sea, as it lies in a direction parallel to that of the coming monsoon winds, leaving the northwestern region in a rain shadow. The Thar Desert is thinly populated; the town of Jodhpur is the largest city in the desert and known as the gateway of the Thar desert. The desert has some major districts like Jodhpur, Jaisalmer, Barmer, Bikaner and Nagour. This area is also important defence point of view. Jodhpur airbase is India's largest airbase and military, BSF bases are also situated here. A single civil airport is also situated in Jodhpur. 

The Northwestern thorn scrub forests lie in a band around the Thar Desert, between the desert and the Aravallis. This region receives less than 400Â mm of rain in an average year. Temperatures can sometimes exceed 54Â Â°C in the summer months or and drop below freezing in the winter. The Godwar, Marwar, and Shekhawati regions lie in the thorn scrub forest zone, along with the city of Jodhpur. The Luni River and its tributaries are the major river system of Godwar and Marwar regions, draining the western slopes of the Aravallis and emptying southwest into the great Rann of Kutch wetland in neighbouring Gujarat. This river is saline in the lower reaches and remains potable only up to Balotara in Barmer district. The Ghaggar River, which originates in Haryana, is an intermittent stream that disappears into the sands of the Thar Desert in the northern corner of the state and is seen as a remnant of the primitive Sarasvati river.

Though a large percentage of the total area is desert with little forest cover, Rajasthan has a rich and varied flora and fauna. The natural vegetation is classed as Northern Desert Thorn Forest (Champion 1936). These occur in small clumps scattered in a more or less open form. The density and size of patches increase from west to east following the increase in rainfall.

The Desert National Park in Jaisalmer is spread over an area of , is an excellent example of the ecosystem of the Thar Desert and its diverse fauna. Seashells and massive fossilised tree trunks in this park record the geological history of the desert. The region is a haven for migratory and resident birds of the desert. One can see many eagles, harriers, falcons, buzzards, kestrels and vultures. Short-toed snake eagles "(Circaetus gallicus)", tawny eagles "(Aquila rapax)", spotted eagles "(Aquila clanga)", laggar falcons "(Falco jugger)" and kestrels are the commonest of these.

The Ranthambore National Park located in Sawai Madhopur, one of the well known tiger reserves in the country, became a part of Project Tiger in 1973.

The Dhosi Hill located in the district of Jhunjunu, known as 'Chayvan Rishi's Ashram', where 'Chyawanprash' was formulated for the first time, has unique and rare herbs growing.

The Sariska Tiger Reserve located in Alwar district, from Delhi and from Jaipur, covers an area of approximately . The area was declared a national park in 1979.

Tal Chhapar Sanctuary is a very small sanctuary in Sujangarh, Churu District, from Jaipur in the Shekhawati region. This sanctuary is home to a large population of blackbuck. Desert foxes and the caracal, an apex predator, also known as the "desert lynx", can also be spotted, along with birds such as the partridge, harriers, Eastern Imperial Eagle, Pale Harrier, Marsh Harrier, Short-toed Eagle, Tawny Eagle, Sparrow Hawk, Crested Lark, Demoiselle Crane, Skylarks, Green Bee-eater, Brown Dove, Black Ibis and sand grouse. The Great Indian bustard, known locally as the "godavan", and which is a state bird, has been classed as critically endangered since 2011.

Rajasthan is also noted for its national parks and wildlife sanctuaries. There are four national park and wildlife sanctuaries: Keoladeo National Park of Bharatpur, Sariska Tiger Reserve of Alwar, Ranthambore National Park of Sawai Madhopur, and Desert National Park of Jaisalmer. A national level institute, Arid Forest Research Institute (AFRI) an autonomous institute of the ministry of forestry is situated in Jodhpur and continuously work on desert flora and their conservation.

Ranthambore National Park is 7Â km from Sawai Madhopur Railway Station. it is known worldwide for its tiger population and is considered by both wilderness lovers and photographers as one of the best places in India to spot tigers. At one point, due to poaching and negligence, tigers became extinct at Sariska, but five tigers have been relocated there. Prominent among the wildlife sanctuaries are Mount Abu Sanctuary, Bhensrod Garh Sanctuary, Darrah Sanctuary, Jaisamand Sanctuary, Kumbhalgarh Wildlife Sanctuary, Jawahar Sagar sanctuary, and Sita Mata Wildlife Sanctuary.

Major ISP and telecom companies are present in Rajasthan including Airtel, Data Infosys Limited, Reliance Limited, Jio, RAILTEL, Software Technology Parks of India (STPI), Tata Telecom and Vodafone. Data Infosys was the first Internet Service Provider (ISP) to bring internet in Rajasthan in April 1999 and OASIS was first private mobile telephone company.

The politics of Rajasthan is dominated mainly by the Bharatiya Janata Party and the Indian National Congress.

Rajasthan is divided into 33 districts within seven divisions:
Rajasthan's economy is primarily agricultural and pastoral. Wheat and barley are cultivated over large areas, as are pulses, sugarcane, and oilseeds. Cotton and tobacco are the state's cash crops. Rajasthan is among the largest producers of edible oils in India and the second largest producer of oilseeds. Rajasthan is also the biggest wool-producing state in India and the main opium producer and consumer. There are mainly two crop seasons. The water for irrigation comes from wells and tanks. The Indira Gandhi Canal irrigates northwestern Rajasthan.
The main industries are mineral based, agriculture-based, and textile based. Rajasthan is the second largest producer of polyester fibre in India. Several prominent chemical and engineering companies are located in the city of Kota, in southern Rajasthan. Rajasthan is pre-eminent in quarrying and mining in India. The Taj Mahal was built from the white marble which was mined from a town called Makrana. The state is the second largest source of cement in India. It has rich salt deposits at Sambhar, copper mines at Khetri, Jhunjhunu, and zinc mines at Dariba, Zawar mines and Rampura Agucha (opencast) near Bhilwara. Dimensional stone mining is also undertaken in Rajasthan. Jodhpur sandstone is mostly used in monuments, important buildings, and residential buildings. This stone is termed as "chittar patthar". Jodhpur leads in Handicraft and Guar Gum industry.
Rajasthan is also a part of the Mumbai-Delhi Industrial corridor is set to benefit economically. The State gets 39% of the DMIC, with major districts of Jaipur, Alwar, Kota and Bhilwara benefiting.

Rajasthan also has reserves of low-silica limestone.

Rajasthan is the largest producer of barley, mustard, pearl millet, coriander, fenugreek and guar in India. Rajasthan produces over 72% of guar of the world and 60% of India's barley. Rajasthan is major producer of aloe vera, amla, oranges leading producer of maize, groundnut. Rajasthan government had initiated olive cultivation with technical support from Israel. The current production of olives in the state is around 100â110 tonnes annually. Rajasthan is India's second largest producer of milk. Rajasthan has 13800 dairy co-operative societies.

Rajasthan is connected by many national highways. Most renowned being NH 8, which is India's first 4â8 lane highway. Rajasthan also has an inter-city surface transport system both in terms of railways and bus network. All chief cities are connected by air, rail, and road.

There are six main airports at Rajasthan â Jaipur International Airport, Jodhpur Airport, Udaipur Airport and the recently started Ajmer Airport, Bikaner Airport and Jaisalmer Airport. These airports connect Rajasthan with the major cities of India such as Delhi and Mumbai. There is another airport in Kota but is not open for commercial/civilian flights yet.

Rajasthan is connected with the main cities of India by rail. Jaipur, Kota, Ajmer, Jodhpur, Bharatpur, Bikaner, Alwar, Abu Road, and Udaipur are the principal railway stations in Rajasthan. Kota City is the only electrified section served by three Rajdhani Expresses and trains to all major cities of India. There is also an international railway, the Thar Express from Jodhpur (India) to Karachi (Pakistan). However, this is not open to foreign nationals.

Rajasthan is well connected to the main cities of the country including Delhi, Ahmedabad and Indore by state and national highways and served by Rajasthan State Road Transport Corporation (RSRTC) and private operators. Now in March 2017, 75 percent of all national highways being built in Rajasthan according to the public works minister of Rajasthan.

According to final results of 2011 Census of India, Rajasthan has a total population of 68,548,437. The native Rajasthani people make up the majority of the state's population. The state of Rajasthan is also populated by Sindhis, who came to Rajasthan from Sindh province (now in Pakistan) during the India-Pakistan separation in 1947. As for religion, Rajasthan's residents are mainly Hindus, who account for 88.49% of the population. Muslims make up 9.07%, Sikhs 1.27% and Jains 0.91% of the population.

Hindi is the official and the most widely spoken language in the state (90.97% of the population as per the 2001 census), followed by Bhili (4.60%), Punjabi (2.01%), and Urdu (1.17%).
Rajasthani is one of the main spoken languages in the state. Rajasthani and various Rajasthani dialects are counted under Hindi in the national census. In the 2001 census, standard Rajasthani had over 18 million speakers, as well as millions of other speakers of Rajasthani dialects, such as Marwari.

The languages taught under the three-language formula are:

First Language: Hindi
Second Language: English
Third Language: Gujarati, Punjabi, Sanskrit, Sindhi or Urdu

Rajasthan is culturally rich and has artistic and cultural traditions that reflect the ancient Indian way of life. There is rich and varied folk culture from villages which are often depicted as a symbol of the state. Highly cultivated classical music and dance with its own distinct style is part of the cultural tradition of Rajasthan. The music has songs that depict day-to-day relationships and chores, often focused around fetching water from wells or ponds.

Rajasthani cooking was influenced by both the war-like lifestyles of its inhabitants and the availability of ingredients in this arid region. Food that could last for several days and could be eaten without heating was preferred. The scarcity of water and fresh green vegetables have all had their effect on the cooking. It is known for its snacks like Bikaneri Bhujia. Other famous dishes include "bajre ki roti" (millet bread) and "lahsun ki chutney" (hot garlic paste), "mawa kachori" Mirchi Bada, Pyaaj Kachori and ghevar from Jodhpur, Alwar ka Mawa (milk cake), "Kadhi kachori" from Ajmer, "malpauas" from Pushkar, Daal kachori (Kota kachori) from Kota and rassgollas from Bikaner. Originating from the Marwar region of the state is the concept of Marwari Bhojnalaya, or vegetarian restaurants, today found in many parts of India, which offer vegetarian food of the Marwari people.

Dal-Bati-Churma is very popular in Rajasthan. The traditional way to serve it is to first coarsely mash the Baati then pour pure ghee on top of it. It is served with the daal (lentils) and spicy garlic chutney. Also served with besan (gram flour) ki kadi. It is commonly served at all festivities, including religious occasions, wedding ceremonies, and birthday parties in Rajasthan.

The Ghoomar dance from Jaipur Jodhpur Marwar and Kalbeliya dance of kalbeliya tribe have gained international recognition. Folk music is a large part of Rajasthani culture. Kathputli, Bhopa, Chang, Teratali, Ghindr, Kachchhighori, and Tejaji are examples of traditional Rajasthani culture. Folk songs are commonly ballads which relate heroic deeds and love stories; and religious or devotional songs known as bhajans and banis which are often accompanied by musical instruments like dholak, sitar, and sarangi are also sung.

Rajasthan is known for its traditional, colourful art. The block prints, tie and dye prints, gota patti (main), Bagaru prints, Sanganer prints, and Zari embroidery are major export products from Rajasthan. Handicraft items like wooden furniture and crafts, carpets, and blue pottery are commonly found here. Shopping reflects the colourful culture, Rajasthani clothes have a lot of mirror work and embroidery. A Rajasthani traditional dress for females comprises an ankle-length skirt and a short top, known as "chaniya choli"Mainly pure owned by traditional people . A piece of cloth is used to cover the head, both for protection from heat and maintenance of modesty. Rajasthani dresses are usually designed in bright colours like blue, yellow and orange.

The main religious festivals are Deepawali, Holi, Gangaur, Teej, Gogaji, Shri Devnarayan Jayanti, Makar Sankranti and Janmashtami, as the main religion is Hinduism. Rajasthan's desert festival is held once a year during winter. Dressed in costumes, the people of the desert dance and sing ballads. There are fairs with snake charmers, puppeteers, acrobats, and folk performers. Camels play a role in this festival.

During recent years, Rajasthan has worked on improving education. The state government has been making sustained efforts to raise the education standard.

In recent decades, the literacy rate of Rajasthan has increased significantly. In 1991, the state's literacy rate was only 38.55% (54.99% male and 20.44% female). In 2001, the literacy rate increased to 60.41% (75.70% male and 43.85% female). This was the highest leap in the percentage of literacy recorded in India (the rise in female literacy being 23%). At the Census 2011, Rajasthan had a literacy rate of 67.06% (80.51% male and 52.66% female). Although Rajasthan's literacy rate is below the national average of 74.04% and although its female literacy rate is the lowest in the country, the state has been praised for its efforts and achievements in raising literacy rates.

In rural areas of Rajasthan, the literacy rate is 76.16% for males and 45.8% for females. This has been debated across all the party level, when the governor of Rajasthan set a minimum educational qualification for the village panchayat elections.

Rajasthan attracted a total of 45.9 million domestic and 1.6 million foreign tourists in 2017, which is the tenth highest in terms of domestic visitors and fifth highest in foreign tourists. The tourism industry in Rajasthan is growing effectively each year and is becoming one of the major income sources for the state government. Rajasthan is home to attractions for domestic and foreign travellers, including the forts and palaces of Jaipur, lakes of Udaipur, Temples of Rajsamand and Pali, sand dunes of Jaisalmer and Bikaner, Havelis of Mandawa and Fatehpur, Rajasthan, wildlife of Sawai Madhopur, the scenic beauty of Mount Abu, tribes of Dungarpur and Banswara, and the cattle fair of Pushkar.

Rajasthan is known for its custom culture colours, majestic forts, and palaces, folk dances and music, local festivals, local food, sand dunes, carved temples, beautiful havelis. Rajasthan's Jaipur Jantar Mantar, Mehrangarh Fort and Stepwell of Jodhpur, Dilwara Temples, Chittor Fort, Lake Palace, miniature paintings in Bundi, and numerous city palaces and havelis are part of the architectural heritage of India. Jaipur, the "Pink City", is noted for the ancient houses made of a type of sandstone dominated by a pink hue. In Jodhpur, maximum houses are painted blue. At Ajmer, there is white marble Bara-dari on the Anasagar lake and Soniji Ki Nasiyan. Jain Temples dot Rajasthan from north to south and east to west. Dilwara Temples of Mount Abu, Shrinathji Temple of Nathdwara, Ranakpur Jain temple dedicated to Lord Adinath in Pali District, Jain temples in the fort complexes of Chittor, Jaisalmer and Kumbhalgarh, Lodurva Jain temples, Mirpur Jain Temple of Sirohi, Sarun Mata Temple at Kotputli, Bhandasar and Karni Mata Temple of Bikaner and Mandore of Jodhpur are some of the best examples. Keoladeo National Park, Ranthambore National Park, Sariska Tiger Reserve, Tal Chhapar Sanctuary, are wildlife attractions of Rajasthan. Mewar festival of Udaipur, Teej festival and Gangaur festival in Jaipur, Desert festival of Jodhpur, Brij Holi of Bharatpur, Matsya festival of Alwar, Kite festival of Jodhpur, Kolayat fair in Bikaner are some of the most popular fairs and festivals of Rajasthan.





</doc>
<doc id="26292" url="https://en.wikipedia.org/wiki?curid=26292" title="Raphael of Brooklyn">
Raphael of Brooklyn

Saint Raphael of Brooklyn (), born RufÄÊ¾Ä«l HawÄwÄ«nÄ« (Raphael Hawaweeny; ; November 20, 1860 â February 27, 1915), was bishop of the Russian Orthodox Church, auxiliary bishop of Brooklyn, vicar of the Northern-American diocese, and head of the Antiochian Levantine Christian Greek Orthodox mission. He was the first Orthodox Christian bishop consecrated on American soil.

He was born in Beirut, modern-day Lebanon, to Damascene Syrian parents of the Antiochian Orthodox faith who had come to Beirut fleeing a massacre of Christians in Damascus. He was first educated at the Damascus Patriarchal School that had become the leading Greek Orthodox institution of higher learning in the Levant under the leadership of Saint Joseph of Damascus. He furthered his study of Christian theology at the Patriarchical Halki seminary in Constantinople, and at the Theological Academy in Kiev, Russian Empire (now Ukraine).
Father Raphael was sent to New York City in 1895 by Tsar Nicholas II of Russia to administer the local Orthodox Christian community which then included mainly Russian, Greek, and Levantine immigrants.

In 1904 he became the first Orthodox bishop to be consecrated in North America; the consecration was performed in New York City by Saint Archbishop Tikhon (Bellavin) and Bishop Innocent (Pustynsky). He served as Bishop of Brooklyn until his death.

During the course of his ministry as an auxiliary bishop of the Russian Orthodox Church in America, St. Raphael founded the present-day cathedral of the Antiochian Orthodox Archdiocese of North America, established twenty-nine parishes and assisted in the founding of St. Tikhon's Orthodox Monastery.

Father Raphael founded the official magazine of the Antiochian Orthodox Archdiocese, "The Word", in 1905 in Arabic (Ø§ÙÙÙÙØ©).

Saint Raphael was originally buried in New York until August 1989 when his relics were translated to the Antiochian Village Camp in Ligonier, Pennsylvania, on property of the Antiochian Archdiocese, along with several other bishops and clergy.

Bishop Raphael was glorified by the Holy Synod of the Orthodox Church in America (OCA) in its March 2000 session. He is commemorated by the OCA on February 27, the anniversary of his death and by the Antiochian Orthodox Church on the first Saturday of November.

In 2015, the Antiochian Archdiocese, OCA and ROCOR celebrated the 100th Anniversary of the dormition of St. Raphael.





</doc>
<doc id="26294" url="https://en.wikipedia.org/wiki?curid=26294" title="Reflux suppressant">
Reflux suppressant

A reflux suppressant is any one of a number of drugs used to combat oesophageal reflux. Commonly, following ingestion a 'raft' of alginic acid is created, floating on the stomach contents by carbon dioxide released by the drug. This forms a mechanical barrier to further reflux. Some preparations also contain antacids to protect the oesophagus.

Reflux can also be coincidentally reduced by the and antidopaminergics.


</doc>
<doc id="26295" url="https://en.wikipedia.org/wiki?curid=26295" title="Russian Civil War">
Russian Civil War

The Russian Civil War (; 7 November 1917 â 25 October 1922) was a multi-party civil war in the former Russian Empire immediately after the two Russian Revolutions of 1917, as many factions vied to determine Russia's political future. The two largest combatant groups were the Red Army, fighting for the Bolshevik form of socialism led by Vladimir Lenin, and the loosely allied forces known as the White Army, which included diverse interests favouring political monarchism, economic capitalism and alternative forms of socialism, each with democratic and anti-democratic variants. In addition, rival militant socialists and non-ideological Green armies fought against both the Bolsheviks and the Whites. Eight foreign nations intervened against the Red Army, notably the former Allied military forces from the World War and the pro-German armies. The Red Army eventually defeated the White Armed Forces of South Russia in Ukraine and the army led by Admiral Alexander Kolchak to the east in Siberia in 1919. The remains of the White forces commanded by Pyotr Wrangel were beaten in Crimea and evacuated in late 1920. Lesser battles of the war continued on the periphery for two more years, and minor skirmishes with the remnants of the White forces in the Far East continued well into 1923. The war ended in 1923 in the sense that Bolshevik communist control of the newly formed Soviet Union was now assured, although armed national resistance in Central Asia was not completely crushed until 1934. There were an estimated 7,000,000â12,000,000 casualties during the war, mostly civilians.

Many pro-independence movements emerged after the break-up of the Russian Empire and fought in the war. Several parts of the former Russian EmpireâFinland, Estonia, Latvia, Lithuania, and Polandâwere established as sovereign states, with their own civil wars and wars of independence. The rest of the former Russian Empire was consolidated into the Soviet Union shortly afterwards.

The Russian Empire fought in World War I from 1914 alongside France and the United Kingdom (Triple Entente) against Germany, Austria-Hungary and the Ottoman Empire (Central Powers).

The February Revolution of 1917 resulted in abdication of Tsar Nicholas II of Russia. As a result, the Russian Provisional Government was established, and soviets, elected councils of workers, soldiers, and peasants, were organized throughout the country, leading to a situation of dual power. Russia was proclaimed a republic in September of the same year.

The Provisional Government, led by Socialist Revolutionary Party politician Alexander Kerensky, was unable to solve the most pressing issues of the country, most importantly to end the war with the Central Powers. A failed military coup by General Lavr Kornilov in September 1917 led to a surge in support for the Bolshevik party, who gained majorities in the soviets, which until then had been controlled by the Socialist Revolutionaries. Promising an end to the war and "all power to the Soviets," the Bolsheviks then ended dual power by suppressing the Provisional Government in late October, on the eve of the Second All-Russian Congress of Soviets, in what would be the second Revolution of 1917. Despite the Bolsheviks' seizure of power, they lost to the Socialist Revolutionary Party in the 1917 Russian Constituent Assembly election, and the Constituent Assembly was dissolved by the Bolsheviks. The Bolsheviks soon lost the support of other far-left allies such as the Left Socialist-Revolutionaries due to their acceptance of the terms of the Treaty of Brest-Litovsk presented by Germany. 

From mid-1917 onwards, the Russian Army, the successor-organisation of the old Imperial Russian Army, started to disintegrate; the Bolsheviks used the volunteer-based Red Guards as their main military force, augmented by an armed military component of the Cheka (the Bolshevik state-security apparatus). In January 1918, after significant Bolshevik reverses in combat, the future People's Commissar for Military and Naval Affairs, Leon Trotsky headed the reorganization of the Red Guards into a "Workers' and Peasants' Red Army" in order to create a more effective fighting force. The Bolsheviks appointed political commissars to each unit of the Red Army to maintain morale and to ensure loyalty.

In June 1918, when it had become apparent that a revolutionary army composed solely of workers would not suffice, Trotsky instituted mandatory conscription of the rural peasantry into the Red Army. The Bolsheviks overcame opposition of rural Russians to Red-Army conscription units by taking hostages and shooting them when necessary in order to force compliance, exactly the same practices used by the White Army officers. The Red Army utilized former Tsarist officers as "military specialists" ("voenspetsy"); sometimes their families were taken hostage in order to ensure their loyalty. At the start of the civil war, former Tsarist officers comprised three-quarters of the Red Army officer-corps. By its end, 83% of all Red Army divisional and corps commanders were ex-Tsarist soldiers. The forced conscription drive had mixed results, successfully creating a large army with numerical superiority over the Whites but becoming composed of members indifferent towards Marxist-Leninist ideology. 

While resistance to the Red Guard began on the very day after the Bolshevik uprising, the Treaty of Brest-Litovsk and the instinct of one party rule became a catalyst for the formation of anti-Bolshevik groups both inside and outside Russia, pushing them into action against the new Soviet government.
A loose confederation of anti-Bolshevik forces aligned against the Communist government, including landowners, republicans, conservatives, middle-class citizens, reactionaries, pro-monarchists, liberals, army generals, non-Bolshevik socialists who still had grievances and democratic reformists voluntarily united only in their opposition to Bolshevik rule. Their military forces, bolstered by forced conscriptions and terror as well as foreign influence, under the leadership of General Nikolai Yudenich, Admiral Alexander Kolchak and General Anton Denikin, became known as the White movement (sometimes referred to as the "White Army") and controlled significant parts of the former Russian Empire for most of the war.

A Ukrainian nationalist movement was active in Ukraine during the war. More significant was the emergence of an anarchist political and military movement known as the Revolutionary Insurrectionary Army of Ukraine or the Anarchist Black Army led by Nestor Makhno. The Black Army, which counted numerous Jews and Ukrainian peasants in its ranks, played a key part in halting Denikin's White Army offensive towards Moscow during 1919, later ejecting White forces from Crimea.

The remoteness of the Volga Region, the Ural Region, Siberia and the Far East was favorable for the anti-Bolshevik forces, and the Whites set up a number of organizations in the cities of these regions. Some of the military forces were set up on the basis of clandestine officers' organizations in the cities.

The Czechoslovak Legions had been part of the Russian Army and numbered around 30,000 troops by October 1917. They had an agreement with the new Bolshevik government to be evacuated from the Eastern Front via the port of Vladivostok to France. The transport from the Eastern Front to Vladivostok slowed down in the chaos, and the troops became dispersed all along the Trans-Siberian Railway. Under pressure from the Central Powers, Trotsky ordered the disarming and arrest of the legionaries, which created tensions with the Bolsheviks.

The Western Allies armed and supported opponents of the Bolsheviks. They were worried about a possible Russo-German alliance, the prospect of the Bolsheviks making good on their threats to default on Imperial Russia's massive foreign loans, and the possibility that Communist revolutionary ideas would spread (a concern shared by many Central Powers). Hence, many of these countries expressed their support for the Whites, including the provision of troops and supplies. Winston Churchill declared that Bolshevism must be "strangled in its cradle". The British and French had supported Russia during World War I on a massive scale with war materials. After the treaty, it looked like much of that material would fall into the hands of the Germans. Under this pretext began the Allied intervention in the Russian Civil War with the United Kingdom and France sending troops into Russian ports. There were violent clashes with troops loyal to the Bolsheviks.

The German Empire created several short-lived satellite buffer states within its sphere of influence after the Treaty of Brest-Litovsk: the United Baltic Duchy, Duchy of Courland and Semigallia, Kingdom of Lithuania, Kingdom of Poland, the Belarusian People's Republic, and the Ukrainian State. Following the defeat of Germany in World War I in November 1918, these states were abolished.

Finland was the first republic that declared its independence from Russia in December 1917 and established itself in the ensuing Finnish Civil War from JanuaryâMay 1918. The Second Polish Republic, Lithuania, Latvia and Estonia formed their own armies immediately after the abolition of the Brest-Litovsk Treaty and the start of the Soviet westward offensive in November 1918.

In the European part of Russia the war was fought across three main fronts: the eastern, the southern and the northwestern. It can also be roughly split into the following periods.

The first period lasted from the Revolution until the Armistice. Already on the date of the Revolution, Cossack General Alexey Kaledin refused to recognize it and assumed full governmental authority in the Don region, where the Volunteer Army began amassing support. The signing of the Treaty of Brest-Litovsk also resulted in direct Allied intervention in Russia and the arming of military forces opposed to the Bolshevik government. There were also many German commanders who offered support against the Bolsheviks, fearing a confrontation with them was impending as well.

During this first period the Bolsheviks took control of Central Asia out of the hands of the Provisional Government and White Army, setting up a base for the Communist Party in the Steppe and Turkestan, where nearly two million Russian settlers were located.

Most of the fighting in this first period was sporadic, involving only small groups amid a fluid and rapidly shifting strategic situation. Among the antagonists were the Czechoslovak Legion, the Poles of the 4th and 5th Rifle Divisions and the pro-Bolshevik Red Latvian riflemen.

The second period of the war lasted from January to November 1919. At first the White armies' advances from the south (under Denikin), the east (under Kolchak) and the northwest (under Yudenich) were successful, forcing the Red Army and its allies back on all three fronts. In July 1919 the Red Army suffered another reverse after a mass defection of units in the Crimea to the anarchist Black Army under Nestor Makhno, enabling anarchist forces to consolidate power in Ukraine. Leon Trotsky soon reformed the Red Army, concluding the first of two military alliances with the anarchists. In June the Red Army first checked Kolchak's advance. After a series of engagements, assisted by a Black Army offensive against White supply lines, the Red Army defeated Denikin's and Yudenich's armies in October and November.

The third period of the war was the extended siege of the last White forces in the Crimea. General Wrangel had gathered the remnants of Denikin's armies, occupying much of the Crimea. An attempted invasion of southern Ukraine was rebuffed by the Black Army under Makhno's command. Pursued into the Crimea by Makhno's troops, Wrangel went over to the defensive in the Crimea. After an abortive move north against the Red Army, Wrangel's troops were forced south by Red Army and Black Army forces; Wrangel and the remains of his army were evacuated to Constantinople in November 1920.

In the October Revolution the Bolshevik Party directed the Red Guard (armed groups of workers and Imperial army deserters) to seize control of Petrograd (Saint Petersburg) and immediately began the armed takeover of cities and villages throughout the former Russian Empire. In January 1918 the Bolsheviks dissolved the Russian Constituent Assembly and proclaimed the Soviets (workers' councils) as the new government of Russia.

The first attempt to regain power from the Bolsheviks was made by the Kerensky-Krasnov uprising in October 1917. It was supported by the Junker Mutiny in Petrograd but was quickly put down by the Red Guard, notably including the Latvian Rifle Division.

The initial groups that fought against the Communists were local Cossack armies that had declared their loyalty to the Provisional Government. Kaledin of the Don Cossacks and General Grigory Semenov of the Siberian Cossacks were prominent among them. The leading Tsarist officers of the Imperial Russian Army also started to resist. In November, General Mikhail Alekseev, the Tsar's Chief of Staff during the First World War, began to organize the Volunteer Army in Novocherkassk. Volunteers of this small army were mostly officers of the old Russian army, military cadets and students. In December 1917 Alekseev was joined by General Lavr Kornilov, Denikin and other Tsarist officers who had escaped from the jail, where they had been imprisoned following the abortive Kornilov affair just before the Revolution. At the beginning of December 1917 groups of volunteers and Cossacks captured Rostov.

Having stated in the November 1917 "Declaration of Rights of Nations of Russia" that any nation under imperial Russian rule should be immediately given the power of self-determination, the Bolsheviks had begun to usurp the power of the Provisional Government in the territories of Central Asia soon after the establishment of the Turkestan Committee in Tashkent. In April 1917 the Provisional Government set up this committee, which was mostly made up of former Tsarist officials. The Bolsheviks attempted to take control of the Committee in Tashkent on 12 September 1917 but it was unsuccessful, and many leaders were arrested. However, because the Committee lacked representation of the native population and poor Russian settlers, they had to release the Bolshevik prisoners almost immediately due to public outcry, and a successful takeover of this government body took place two months later in November. The Leagues of Mohammedam Working People, which Russian settlers and natives who had been sent to work behind the lines for the Tsarist government in 1916 formed in March 1917, had led numerous strikes in the industrial centers throughout September 1917. However, after the Bolshevik destruction of the Provisional Government in Tashkent, Muslim elites formed an autonomous government in Turkestan, commonly called the "Kokand autonomy" (or simply Kokand). The White Russians supported this government body, which lasted several months because of Bolshevik troop isolation from Moscow. In January 1918 the Soviet forces under Lt. Col. Muravyov invaded Ukraine and invested Kiev, where the Central Council of the Ukrainian People's Republic held power. With the help of the Kiev Arsenal Uprising, the Bolsheviks captured the city on 26 January.

The Bolsheviks decided to immediately make peace with the German Empire and the Central Powers, as they had promised the Russian people before the Revolution. Vladimir Lenin's political enemies attributed that decision to his sponsorship by the Foreign Office of Wilhelm II, German Emperor, offered to Lenin in hope that, with a revolution, Russia would withdraw from World War I. That suspicion was bolstered by the German Foreign Ministry's sponsorship of Lenin's return to Petrograd. However, after the military fiasco of the summer offensive (June 1917) by the Russian Provisional Government, and in particular after the failed summer offensive of the Provisional Government had devastated the structure of the Russian Army, it became crucial that Lenin realize the promised peace. Even before the failed summer offensive the Russian population was very skeptical about the continuation of the war. Western socialists had promptly arrived from France and from the UK to convince the Russians to continue the fight, but could not change the new pacifist mood of Russia.

On 16 December 1917 an armistice was signed between Russia and the Central Powers in Brest-Litovsk and peace talks began. As a condition for peace, the proposed treaty by the Central Powers conceded huge portions of the former Russian Empire to the German Empire and the Ottoman Empire, greatly upsetting nationalists and conservatives. Leon Trotsky, representing the Bolsheviks, refused at first to sign the treaty while continuing to observe a unilateral cease-fire, following the policy of "No war, no peace".

In view of this, on 18 February 1918 the Germans began Operation Faustschlag on the Eastern Front, encountering virtually no resistance in a campaign that lasted 11 days. Signing a formal peace treaty was the only option in the eyes of the Bolsheviks because the Russian Army was demobilized, and the newly formed Red Guard was incapable of stopping the advance. They also understood that the impending counterrevolutionary resistance was more dangerous than the concessions of the treaty, which Lenin viewed as temporary in the light of aspirations for a world revolution. The Soviets acceded to a peace treaty, and the formal agreement, the Treaty of Brest-Litovsk, was ratified on 6 March. The Soviets viewed the treaty as merely a necessary and expedient means to end the war. Therefore, they ceded large amounts of territory to the German Empire.

In Ukraine the German-Austrian Operation Faustschlag had by April 1918 removed the Bolsheviks from Ukraine. The German and Austro-Hungarian victories in Ukraine were due to the apathy of the locals and the inferior fighting skills of Bolsheviks troops compared to their Austro-Hungarian and German counterparts.

Under Soviet pressure, the Volunteer Army embarked on the epic Ice March from Yekaterinodar to Kuban on 22 February 1918, where they joined with the Kuban Cossacks to mount an abortive assault on Yekaterinodar. The Soviets recaptured Rostov on the next day. Kornilov was killed in the fighting on 13 April, and Denikin took over command. Fighting off its pursuers without respite, the army succeeded in breaking its way through back towards the Don, where the Cossack uprising against Bolsheviks had started.

The Baku Soviet Commune was established on 13 April. Germany landed its Caucasus Expedition troops in Poti on 8 June. The Ottoman Army of Islam (in coalition with Azerbaijan) drove them out of Baku on 26 July 1918. Subsequently, the Dashanaks, Right SRs and Mensheviks started negotiations with Gen. Dunsterville, the commander of the British troops in Persia. The Bolsheviks and their Left SR allies were opposed to it, but on 25 July the majority of the Soviet voted to call in the British and the Bolsheviks resigned. The Baku Soviet Commune ended its existence and was replaced by the Central Caspian Dictatorship.

In June 1918 the Volunteer Army, numbering some 9,000 men, started its Second Kuban campaign. Yekaterinodar was encircled on 1 August and fell on the 3rd. In SeptemberâOctober, heavy fighting took place at Armavir and Stavropol. On 13 October Gen. Kazanovich's division took Armavir, and on 1 November Gen. Pyotr Wrangel secured Stavropol. This time Red forces had no escape, and by the beginning of 1919 the whole Northern Caucasus was controlled by the Volunteer Army.

In October Gen. Alekseev, the leader of the White armies in southern Russia, died of a heart attack. An agreement was reached between Denikin, head of the Volunteer Army, and Pyotr Krasnov, Ataman of the Don Cossacks, which united their forces under the sole command of Denikin. The Armed Forces of South Russia were thus created.

The revolt of the Czechoslovak Legion broke out in May 1918, and the legionaries took control of Chelyabinsk in June. Simultaneously Russian officers' organisations overthrew the Bolsheviks in Petropavlovsk (in present-day Kazakhstan) and in Omsk. Within a month the Whites controlled most of the Trans-Siberian Railroad between Lake Baikal and the Ural regions. During the summer Bolshevik power in Siberia was eliminated. The Provisional Government of Autonomous Siberia formed in Omsk. By the end of July the Whites had extended their gains westwards, capturing Ekaterinburg on 26 July 1918. Shortly before the fall of Yekaterinburg on 17 July 1918, the former Tsar and his family were murdered by the Ural Soviet to prevent them from falling into the hands of the Whites.
The Mensheviks and Socialist-Revolutionaries supported peasants fighting against Soviet control of food supplies. In May 1918, with the support of the Czechoslovak Legion, they took Samara and Saratov, establishing the Committee of Members of the Constituent Assemblyâknown as the "Komuch". By July the authority of the Komuch extended over much of the area controlled by the Czechoslovak Legion. The Komuch pursued an ambivalent social policy, combining democratic and socialist measures, such as the institution of an eight-hour working day, with "restorative" actions, such as returning both factories and land to their former owners. After the fall of Kazan, Vladimir Lenin called for the dispatch of Petrograd workers to the Kazan Front: "We must send down the "maximum" number of Petrograd workers: (1) a few dozen 'leaders' like Kayurov; (2) a few thousand militants 'from the ranks'".

After a series of reverses at the front, the Bolsheviks' War Commissar, Trotsky, instituted increasingly harsh measures in order to prevent unauthorised withdrawals, desertions and mutinies in the Red Army. In the field the Cheka special investigations forces, termed the "Special Punitive Department of the All-Russian Extraordinary Commission for Combat of Counter-Revolution and Sabotage" or "Special Punitive Brigades", followed the Red Army, conducting field tribunals and summary executions of soldiers and officers who deserted, retreated from their positions or failed to display sufficient offensive zeal. Trotsky extended the use of the death penalty to the occasional political commissar whose detachment retreated or broke in the face of the enemy. In August, frustrated at continued reports of Red Army troops breaking under fire, Trotsky authorised the formation of barrier troops - stationed behind unreliable Red Army units and given orders to shoot anyone withdrawing from the battle line without authorisation.

In September 1918 Komuch, the Siberian Provisional Government and other local anti-Soviet governments met in Ufa and agreed to form a new Provisional All-Russian Government in Omsk, headed by a Directory of five: two Socialist-Revolutionaries (Nikolai Avksentiev and Vladimir Zenzinov), two Kadets (V. A. Vinogradov and PV Vologodskii) and General Vasily Boldyrev.

By the fall of 1918 anti-Bolshevik White forces in the east included the People's Army (Komuch), the Siberian Army (of the Siberian Provisional Government) and insurgent Cossack units of Orenburg, Ural, Siberia, Semirechye, Baikal, Amur and Ussuri Cossacks, nominally under the orders of Gen. V.G. Boldyrev, Commander-in-Chief, appointed by the Ufa Directorate.

On the Volga, Col. Kappel's White detachment captured Kazan on 7 August, but the Reds re-captured the city on 8 September 1918 following a counteroffensive. On the 11th Simbirsk fell, and on 8 October Samara. The Whites fell back eastwards to Ufa and Orenburg.

In Omsk the Russian Provisional Government quickly came under the influence - then the dominance - of its new War Minister, Rear-Admiral Kolchak. On 18 November a coup d'Ã©tat established Kolchak as dictator. The members of the Directory were arrested and Kolchak proclaimed the "Supreme Ruler of Russia". By mid-December 1918 White armies had to leave Ufa, but they balanced this failure with a successful drive towards Perm, which they took on 24 December.

In February 1918 the Red Army overthrew the White Russian-supported Kokand autonomy of Turkestan. Although this move seemed to solidify Bolshevik power in Central Asia, more troubles soon arose for the Red Army as the Allied Forces began to intervene. British support of the White Army provided the greatest threat to the Red Army in Central Asia during 1918. Great Britain sent three prominent military leaders to the area. One was Lt. Col. Bailey, who recorded a mission to Tashkent, from where the Bolsheviks forced him to flee. Another was Gen. Malleson, leading the Malleson Mission, who assisted the Mensheviks in Ashkhabad (now the capital of Turkmenistan) with a small Anglo-Indian force. However, he failed to gain control of Tashkent, Bukhara and Khiva. The third was Maj. Gen. Dunsterville, who the Bolsheviks drove out of Central Asia only a month after his arrival in August 1918. Despite setbacks due to British invasions during 1918, the Bolsheviks continued to make progress in bringing the Central Asian population under their influence. The first regional congress of the Russian Communist Party convened in the city of Tashkent in June 1918 in order to build support for a local Bolshevik Party.

In July two Left SR and Cheka employees, Blyumkin and Andreyev, assassinated the German ambassador, Count Mirbach. In Moscow a Left SR uprising was put down by the Bolsheviks, using Cheka military detachments. Lenin personally apologized to the Germans for the assassination. Mass arrests of Socialist-Revolutionaries followed.

Estonia cleared its territory of the Red Army by January 1919. Baltic German volunteers captured Riga from the Red Latvian Riflemen on 22 May, but the Estonian 3rd Division defeated the Baltic Germans a month later, aiding the establishment of the Republic of Latvia.

This rendered possible another threat to the Red Armyâone from Gen. Yudenich, who had spent the summer organizing the Northwestern Army in Estonia with local and British support. In October 1919 he tried to capture Petrograd in a sudden assault with a force of around 20,000 men. The attack was well-executed, using night attacks and lightning cavalry maneuvers to turn the flanks of the defending Red Army. Yudenich also had six British tanks, which caused panic whenever they appeared. The Allies gave large quantities of aid to Yudenich, who, however, complained that he was receiving insufficient support.

By 19 October Yudenich's troops had reached the outskirts of the city. Some members of the Bolshevik central committee in Moscow were willing to give up Petrograd, but Trotsky refused to accept the loss of the city and personally organized its defenses. Trotsky himself declared, "It is impossible for a little army of 15,000 ex-officers to master a working-class capital of 700,000 inhabitants." He settled on a strategy of urban defense, proclaiming that the city would "defend itself on its own ground" and that the White Army would be lost in a labyrinth of fortified streets and there "meet its grave".

Trotsky armed all available workers, men and women, ordering the transfer of military forces from Moscow. Within a few weeks the Red Army defending Petrograd had tripled in size and outnumbered Yudenich three to one. At this point Yudenich, short of supplies, decided to call off the siege of the city and withdrew, repeatedly asking permission to withdraw his army across the border to Estonia. However, units retreating across the border were disarmed and interned by order of the Estonian government, which had entered into peace negotiations with the Soviet Government on 16 September and had been informed by the Soviet authorities of their 6 November decision that, should the White Army be allowed to retreat into Estonia, it would be pursued across the border by the Reds. In fact, the Reds attacked Estonian army positions and fighting continued until a cease-fire went into effect on 3 January 1920. Following the Treaty of Tartu most of Yudenich's soldiers went into exile. Former Imperial Russian and now Finnish Gen. Mannerheim planned an intervention to help the Whites in Russia capture Petrograd. He did not, however, gain the necessary support for the endeavour. Lenin considered it "completely certain, that the slightest aid from Finland would have determined the fate of [the city]".

The British occupied Murmansk and, alongside the Americans, seized Arkhangelsk. With the retreat of Kolchak in Siberia, they pulled their troops out of the cities before the winter trapped them in the port. The remaining White forces under Yevgeny Miller evacuated the region in February 1920.

At the beginning of March 1919 the general offensive of the Whites on the eastern front began. Ufa was retaken on 13 March; by mid-April, the White Army stopped at the GlazovâChistopolâBugulmaâBuguruslanâSharlyk line. Reds started their counteroffensive against Kolchak's forces at the end of April. The Red 5th Army, led by the capable commander Tukhachevsky, captured Elabuga on 26 May, Sarapul on 2 June and Izevsk on the 7th and continued to push forward. Both sides had victories and losses, but by the middle of summer the Red Army was larger than the White Army and had managed to recapture territory previously lost.

Following the abortive offensive at Chelyabinsk, the White armies withdrew beyond the Tobol. In September 1919 a White offensive was launched against the Tobol front, the last attempt to change the course of events. However, on 14 October the Reds counterattacked, and thus began the uninterrupted retreat of the Whites to the east.

On 14 November 1919 the Red Army captured Omsk. Adm. Kolchak lost control of his government shortly after this defeat; White Army forces in Siberia essentially ceased to exist by December. Retreat of the eastern front by White armies lasted three months, until mid-February 1920, when the survivors, after crossing Lake Baikal, reached Chita area and joined Ataman Semenov's forces.

The Cossacks had been unable to organise and capitalise on their successes at the end of 1918. By 1919 they had begun to run short of supplies. Consequently, when the Soviet counteroffensive began in January 1919 under the Bolshevik leader Antonov-Ovseenko, the Cossack forces rapidly fell apart. The Red Army captured Kiev on 3 February 1919.

General Denikin's military strength continued to grow in the spring of 1919. During several months in winter and spring of 1919, hard fighting with doubtful outcomes took place in the Donbass, where the attacking Bolsheviks met White forces. At the same time Denikin's Armed Forces of South Russia (AFSR) completed the elimination of Red forces in the northern Caucasus and advanced towards Tsaritsyn. At the end of April and beginning of May the AFSR attacked on all fronts from the Dnepr to the Volga, and by the beginning of the summer they had won numerous battles. French forces landed in Odessa but, after having done almost no fighting, withdrew on 8 April 1919. By mid-June the Reds were chased from the Crimea and the Odessa area. Denikin's troops took the cities of Kharkov and Belgorod. At the same time White troops under Wrangel's command took Tsaritsyn on 17 June 1919. On 20 June Denikin issued his Moscow directive, ordering all AFSR units to prepare for a decisive offensive to take Moscow.

Although Great Britain had withdrawn its own troops from the theatre, it continued to give significant military aid (money, weapons, food, ammunition and some military advisers) to the White Armies during 1919. Major Ewen Cameron Bruce of the British Army had volunteered to command a British tank mission assisting the White Army. He was awarded the Distinguished Service Order for his bravery during the June 1919 battle of Tsaritsyn for single-handedly storming and capturing the fortified city of Tsaritsyn, under heavy shell fire in a single tank; this led to the capture of over 40,000 prisoners. The fall of Tsaritsyn is viewed "as one of the key battles of the Russian Civil War" which greatly helped the White Russian cause. Notable historian Sir Basil Henry Liddell Hart comments that Bruce's tank action during this battle is to be seen as "one of the most remarkable feats in the whole history of the Tank Corps".

After the capture of Tsaritsyn, Wrangel pushed towards Saratov but Trotsky, seeing the danger of the union with Kolchak, against whom the Red command was concentrating large masses of troops, repulsed his attempts with heavy losses. When Kolchak's army in the east began to retreat in June and July, the bulk of the Red Army, free now from any serious danger from Siberia, was directed against Denikin.

Denikin's forces constituted a real threat and for a time threatened to reach Moscow. The Red Army, stretched thin by fighting on all fronts, was forced out of Kiev on 30 August. Kursk and Orel were taken, on 20 September and 14 October, respectively. The latter, only from Moscow, was the closest the AFSR would come to its target. The Cossack Don Army under the command of Gen. Vladimir Sidorin continued north towards Voronezh, but there Semyon Budyonny's cavalrymen defeated them on 24 October. This allowed the Red Army to cross the Don River, threatening to split the Don and Volunteer Armies. Fierce fighting took place at the key rail junction of Kastornoye, which was taken on 15 November; Kursk was retaken two days later.

The high tide of the White movement against the Soviets had been reached in September 1919. By this time Denikin's forces were dangerously overextended. The White front had no depth or stabilityâit had become a series of patrols with occasional columns of slowly advancing troops without reserves. Lacking ammunition, artillery and fresh reinforcements, Denikin's army was decisively defeated in a series of battles in October and November 1919. The Red Army recaptured Kiev on 17 December and the defeated Cossacks fled back towards the Black Sea.

While the White armies were being routed in Central Russia and the east, they had succeeded in driving Nestor Makhno's anarchist Black Army (formally known as the Revolutionary Insurrectionary Army of Ukraine) out of part of southern Ukraine and the Crimea. Despite this setback, Moscow was loath to aid Makhno and the Black Army and refused to provide arms to anarchist forces in Ukraine. The main body of White forces, the Volunteers and the Don Army, pulled back towards the Don, to Rostov. The smaller body (Kiev and Odessa troops) withdrew to Odessa and the Crimea, which it had managed to protect from the Bolsheviks during the winter of 1919â1920.

By February 1919 the British government had pulled its military forces out of Central Asia. Despite this success for the Red Army, the White Army's assaults in European Russia and other areas broke communication between Moscow and Tashkent. For a time Central Asia was completely cut off from Red Army forces in Siberia. Although this communication failure weakened the Red Army, the Bolsheviks continued their efforts to gain support for the Bolshevik Party in Central Asia by holding a second regional conference in March. During this conference a regional bureau of Muslim organisations of the Russian Bolshevik Party was formed. The Bolshevik Party continued to try to gain support among the native population by giving them the impression of better representation for the Central Asian population and throughout the end of the year were able to maintain harmony with the Central Asian people.

Communication difficulties with Red Army forces in Siberia and European Russia ceased to be a problem by mid-November 1919. Due to Red Army successes north of Central Asia, communication with Moscow was re-established and the Bolsheviks were able to claim victory over the White Army in Turkestan.

In the Ural-Guryev operation of 1919â1920, the Red Turkestan Front defeated the Ural Army. During the winter 1920, Ural Cossacks and their families, totaling about 15,000 people, headed south along the eastern coast of the Caspian Sea towards Fort Alexandrovsk. Only a few hundred of them reached Persia in June 1920. The Orenburg Independent Army was formed from Orenburg Cossacks and others troops which rebelled against the Bolsheviks. During the winter 1919â20, the Orenburg Army retreated to Semirechye in what is known as the Starving March, as half of the participants perished. In March 1920 her remnants crossed the border into the Northwestern region of China.

By the beginning of 1920 the main body of the Armed Forces of South Russia was rapidly retreating towards the Don, to Rostov. Denikin hoped to hold the crossings of the Don, then rest and reform his troops, but the White Army was not able to hold the Don area, and at the end of February 1920 started a retreat across Kuban towards Novorossiysk. Slipshod evacuation of Novorossiysk proved to be a dark event for the White Army. Russian and Allied ships evacuated about 40,000 of Denikin's men from Novorossiysk to the Crimea, without horses or any heavy equipment, while about 20,000 men were left behind and either dispersed or captured by the Red Army. Following the disastrous Novorossiysk evacuation, Denikin stepped down and the military council elected Wrangel as the new Commander-in-Chief of the White Army. He was able to restore order to the dispirited troops and reshape an army that could fight as a regular force again. This remained an organized force in the Crimea throughout 1920.

After Moscow's Bolshevik government signed a military and political alliance with Nestor Makhno and the Ukrainian anarchists, the Black Army attacked and defeated several regiments of Wrangel's troops in southern Ukraine, forcing him to retreat before he could capture that year's grain harvest.

Stymied in his efforts to consolidate his hold, Wrangel then attacked north in an attempt to take advantage of recent Red Army defeats at the close of the PolishâSoviet War of 1919â1920. The Red Army eventually halted this offensive, and Wrangel's troops had to retreat to Crimea in November 1920, pursued by both the Red and Black cavalry and infantry. Wrangel's fleet evacuated him and his army to Constantinople on 14 November 1920, ending the struggle of Reds and Whites in Southern Russia.
After the defeat of Wrangel, the Red Army immediately repudiated its 1920 treaty of alliance with Nestor Makhno and attacked the anarchist Black Army; the campaign to liquidate Makhno and the Ukrainian anarchists began with an attempted assassination of Makhno by Cheka agents. Anger at continued repression by the Bolshevik Communist government and at its liberal use of the Cheka to put down anarchist elements led to a naval mutiny at Kronstadt in March 1921, followed by peasant revolts. Red Army attacks on the anarchist forces and their sympathisers increased in ferocity throughout 1921.

In Siberia, Admiral Kolchak's army had disintegrated. He himself gave up command after the loss of Omsk and designated Gen. Grigory Semyonov as the new leader of the White Army in Siberia. Not long after this Kolchak was arrested by the disaffected Czechoslovak Corps as he traveled towards Irkutsk without the protection of the army, and turned over to the socialist Political Centre in Irkutsk. Six days later this regime was replaced by a Bolshevik-dominated Military-Revolutionary Committee. On 6â7 February Kolchak and his prime minister Victor Pepelyaev were shot and their bodies thrown through the ice of the frozen Angara River, just before the arrival of the White Army in the area.

Remnants of Kolchak's army reached Transbaikalia and joined Semyonov's troops, forming the Far Eastern army. With the support of the Japanese army it was able to hold Chita, but after withdrawal of Japanese soldiers from Transbaikalia, Semenov's position became untenable, and in November 1920 he was driven by the Red Army from Transbaikalia and took refuge in China. The Japanese, who had plans to annex the Amur Krai, finally pulled their troops out as Bolshevik forces gradually asserted control over the Russian Far East. On 25 October 1922 Vladivostok fell to the Red Army, and the Provisional Priamur Government was extinguished.

In Central Asia, Red Army troops continued to face resistance into 1923, where "basmachi" (armed bands of Islamic guerrillas) had formed to fight the Bolshevik takeover. The Soviets engaged non-Russian peoples in Central Asia, like Magaza Masanchi, commander of the Dungan Cavalry Regiment, to fight against the Basmachis. The Communist Party did not completely dismantle this group until 1934.

General Anatoly Pepelyayev continued armed resistance in the Ayano-Maysky District until June 1923. The regions of Kamchatka and Northern Sakhalin remained under Japanese occupation until their treaty with the Soviet Union in 1925, when their forces were finally withdrawn.

The results of the civil war were momentous. Soviet demographer Boris Urlanis estimated the total number of men killed in action in the Civil War and PolishâSoviet War as 300,000 (125,000 in the Red Army, 175,500 White armies and Poles) and the total number of military personnel dead from disease (on both sides) as 450,000. Boris Sennikov estimated the total losses among the population of Tambov region in 1920 to 1922 resulting from the war, executions, and imprisonment in concentration camps as approximately 240,000.
During the Red Terror, estimates of Cheka executions range from 12,733 to 1.7 million. William Henry Chamberlin suspected that there were about 50,000. Evan Mawdsley suspected that there were more than 12,733, and less than 200,000. Some sources claimed at least 250,000 summary executions of "enemies of the people" with estimates reaching above a million. More modest estimates put the numbers executed by the Bolsheviks between December 1917 and February 1922 at around 28,000 per year, with roughly 10,000 executions during the Red Terror.

Some 300,000â500,000 Cossacks were killed or deported during Decossackization, out of a population of around three million. An estimated 100,000 Jews were killed in Ukraine, mostly by the White Army. Punitive organs of the All Great Don Cossack Host sentenced 25,000 people to death between May 1918 and January 1919. Kolchak's government shot 25,000 people in Ekaterinburg province alone. The White Terror, as it would become known, killed about 300,000 people in total.

At the end of the Civil War the Russian SFSR was exhausted and near ruin. The droughts of 1920 and 1921, as well as the 1921 famine, worsened the disaster still further. Disease had reached pandemic proportions, with 3,000,000 dying of typhus in 1920 alone. Millions more also died of widespread starvation, wholesale massacres by both sides and pogroms against Jews in Ukraine and southern Russia. By 1922 there were at least 7,000,000 street children in Russia as a result of nearly ten years of devastation from the Great War and the civil war.

Another one to two million people, known as the White Ã©migrÃ©s, fled Russia, many with General Wrangelâsome through the Far East, others west into the newly independent Baltic countries. These Ã©migrÃ©s included a large percentage of the educated and skilled population of Russia.

The Russian economy was devastated by the war, with factories and bridges destroyed, cattle and raw materials pillaged, mines flooded and machines damaged. The industrial production value descended to one-seventh of the value of 1913 and agriculture to one-third. According to "Pravda", "The workers of the towns and some of the villages choke in the throes of hunger. The railways barely crawl. The houses are crumbling. The towns are full of refuse. Epidemics spread and death strikesâindustry is ruined." It is estimated that the total output of mines and factories in 1921 had fallen to 20% of the pre-World War level, and many crucial items experienced an even more drastic decline. For example, cotton production fell to 5%, and iron to 2%, of pre-war levels.

War Communism saved the Soviet government during the Civil War, but much of the Russian economy had ground to a standstill. The peasants responded to requisitions by refusing to till the land. By 1921 cultivated land had shrunk to 62% of the pre-war area, and the harvest yield was only about 37% of normal. The number of horses declined from 35 million in 1916 to 24 million in 1920 and cattle from 58 to 37 million. The exchange rate with the US dollar declined from two rubles in 1914 to 1,200 in 1920.

With the end of the war the Communist Party no longer faced an acute military threat to its existence and power. However, the perceived threat of another intervention, combined with the failure of socialist revolutions in other countriesâmost notably the German Revolutionâcontributed to the continued militarisation of Soviet society. Although Russia experienced extremely rapid economic growth in the 1930s, the combined effect of World War I and the Civil War left a lasting scar on Russian society and had permanent effects on the development of the Soviet Union.

British historian Orlando Figes has contended that the root of the Whites' defeat was their inability to dispel the popular image that they were not only associated with Tsarist Russia, but supportive of a Tsarist restoration, as well.







</doc>
<doc id="26296" url="https://en.wikipedia.org/wiki?curid=26296" title="Ralph Abercromby">
Ralph Abercromby

Sir Ralph Abercromby (sometimes spelt Abercrombie) (7 October 173428 March 1801) was a Scottish soldier and politician. He twice served as MP for Clackmannanshire, rose to the rank of lieutenant-general in the British Army, was appointed Governor of Trinidad, served as Commander-in-Chief, Ireland, and was noted for his services during the French Revolutionary Wars.

Abercromby was the eldest son of Mary Dundas (d. 1767), daughter of Ralph Dundas of Manour, Perthshire and George Abercromby of Tullibody House, Clackmannanshire. He was brother of the advocate Alexander Abercromby, Lord Abercromby and General Robert Abercromby. He was born at Menstrie Castle in Clackmannanshire.

Abercromby's education was begun by a private tutor, then continued at the school of Mr Moir in Alloa, then considered one of the best in Scotland despite its Jacobite leanings. After passing some time there, Ralph was sent to Rugby School, where he remained until he was 18. He then became a student at the University of Edinburgh. There he studied moral and natural philosophy and civil law, and was regarded by his professors as sound rather than brilliant. He completed his studies at Leipzig University in Germany, from 1754, taking more detailed studies in civil law with a view to a career as an advocate.

Abercromby was a Freemason. He was Initiated into Scottish Freemasonry in Lodge Canongate Kilwinning, No. 2, (Edinburgh, Scotland) on 25 May 1753.

On returning from the continent, Abercromby expressed a strong preference for the military profession, and a cornet's commission was accordingly obtained for him (March 1756) in the 3rd Dragoon Guards. He served with his regiment in the Seven Years' War, and thus, the opportunity afforded him of studying the methods of Frederick the Great, which moulded his military character and formed his tactical ideas.

Abercromby rose through the intermediate grades to the rank of lieutenant-colonel of the regiment (1773) and brevet colonel in 1780, and in 1781, he became colonel of the newly raised King's Irish infantry. When that regiment was disbanded in 1783, he retired on half pay. He also entered Parliament as MP for Clackmannanshire (1774â1780).

Abercromby was a strong supporter of the American cause in the American Revolutionary War, and remained in Ireland to avoid having to fight against the colonists.

When France declared war against Great Britain in 1793, Abercromby resumed his duties. He was appointed command of a brigade under the Duke of York for service in the Netherlands, where he commanded the advanced guard in the action at Le Cateau. During the 1794 withdrawal to Holland, he commanded the allied forces in the action at Boxtel and was wounded directing operations at Fort St Andries on the Waal. In 1795, he was appointed a Knight of the Bath for his services.

That same year, he was appointed to succeed Sir Charles Grey as commander-in-chief of the British forces in the West Indies. In 1796, Grenada was suddenly attacked and taken by a detachment of the army under his orders. Afterwards, Abercromby secured possession of the settlements of Demerara and Essequibo in South America, the islands of Saint Lucia, Saint Vincent and Trinidad. A major assault on the port of San Juan, Puerto Rico, in April 1797 failed after fierce fighting where both sides suffered heavy losses.

Abercromby returned to Europe and, in reward for his services, was appointed colonel of the 2nd (Royal North British) Regiment of Dragoons. He was also made Lieutenant-Governor of the Isle of Wight, Governor of Fort George and Fort Augustus in the Scottish Highlands, and promoted to the rank of Lieutenant-general. He again entered Parliament as member for Clackmannanshire from 1796 to 1798. From 1797 to 1798, he was Commander-in-Chief of the forces in Ireland.

To quote the biographic entry in the 1888 EncyclopÃ¦dia Britannica, 

After holding for a short period the office of commander-in-chief in Scotland, Abercromby, when the enterprise against the Dutch Batavian Republic was resolved upon in 1799, was again called to command under the Duke of York. The Anglo-Russian invasion of Holland in 1799 ended in disaster, but friend and foe alike confessed that the most decisive victory could not have more conspicuously proved the talents of this distinguished officer.

In 1801, Abercromby was sent with an army to recover Egypt from France. His experience in the Netherlands and the West Indies particularly fitted him for this new command, as was proved when he carried his army in health, in spirits, and with the requisite supplies to the destined scene of action despite great difficulties. The debarkation of the troops at Abukir, in the face of strenuous opposition, is justly ranked among the most daring and brilliant exploits of the British army.

In 1800 Abercromby commanded the expedition to the Mediterranean, and after some brilliant operations defeated the French in the Battle of Alexandria, 21 March 1801. During the action he was struck by a musket-ball in the thigh; but not until the battle was won and he saw the enemy retreating did he show any sign of pain. He was borne from the field in a hammock, cheered by the blessings of the soldiers as he passed, and conveyed on board the flag-ship HMS "Foudroyant" which was moored in the harbour. The ball could not be extracted; mortification ensued, and seven days later, on 28 March 1801, he died.

Abercromby's old friend and commander, the Duke of York, paid tribute to Abercromby's memory in general orders: "His steady observance of discipline, his ever-watchful attention to the health and wants of his troops, the persevering and unconquerable spirit which marked his military career, the splendour of his actions in the field and the heroism of his death, are worthy the imitation of all who desire, like him, a life of heroism and a death of glory." He was buried on St John's Bastion within Fort Saint Elmo in Valletta, Malta. The British military renamed it "Abercrombie's Bastion" in his honour. The adjacent curtain wall linking this bastion to the fortifications of Valletta, originally called Santa Ubaldesca Curtain, was also renamed "Abercrombie's Curtain".

By a vote of the House of Commons, a monument was erected in Abercromby's honour in St Paul's Cathedral in London. His widow was created Baroness Abercromby of Tullibody and Aboukir Bay, and a pension of Â£2,000 a year was settled on her and her two successors in the title.

Abercromby Place in Edinburgh's New Town is named in his honour.

On 17 November 1767, Abercromby married Mary Anne, daughter of John Menzies and Ann, daughter of Patrick Campbell. They had seven children. Of four sons, all four entered Parliament, and two saw military service.

A public house in central Manchester, the 'Sir Ralph Abercromby', is named after him. There is also a 'General Abercrombie' pub with his portrait by John Hoppner as the sign off of the Blackfriars Bridge Road in London.

Three ships have been named HMS "Abercrombie" after the general but using the variant spelling of his name.

Abercrombie Street in Port of Spain, Trinidad honours his name.

Abercromby Primary School in Tullibody is named after him.

Abercromby Place in Edinburgh's New Town is named after him.






</doc>
<doc id="26297" url="https://en.wikipedia.org/wiki?curid=26297" title="Ripe">
Ripe

Ripe or RIPE may refer to:




</doc>
<doc id="26298" url="https://en.wikipedia.org/wiki?curid=26298" title="Radiometric dating">
Radiometric dating

Radiometric dating, radioactive dating or radioisotope dating is a technique which is used to date materials such as rocks or carbon, in which trace radioactive impurities were selectively incorporated when they were formed. The method compares the abundance of a naturally occurring radioactive isotope within the material to the abundance of its decay products, which form at a known constant rate of decay. The use of radiometric dating was first published in 1907 by Bertram Boltwood and is now the principal source of information about the absolute age of rocks and other geological features, including the age of fossilized life forms or the age of the Earth itself, and can also be used to date a wide range of natural and man-made materials.

Together with stratigraphic principles, radiometric dating methods are used in geochronology to establish the geologic time scale. Among the best-known techniques are radiocarbon dating, potassiumâargon dating and uraniumâlead dating. By allowing the establishment of geological timescales, it provides a significant source of information about the ages of fossils and the deduced rates of evolutionary change. Radiometric dating is also used to date archaeological materials, including ancient artifacts.

Different methods of radiometric dating vary in the timescale over which they are accurate and the materials to which they can be applied.

All ordinary matter is made up of combinations of chemical elements, each with its own atomic number, indicating the number of protons in the atomic nucleus. Additionally, elements may exist in different isotopes, with each isotope of an element differing in the number of neutrons in the nucleus. A particular isotope of a particular element is called a nuclide. Some nuclides are inherently unstable. That is, at some point in time, an atom of such a nuclide will undergo radioactive decay and spontaneously transform into a different nuclide. This transformation may be accomplished in a number of different ways, including alpha decay (emission of alpha particles) and beta decay (electron emission, positron emission, or electron capture). Another possibility is spontaneous fission into two or more nuclides.

While the moment in time at which a particular nucleus decays is unpredictable, a collection of atoms of a radioactive nuclide decays exponentially at a rate described by a parameter known as the half-life, usually given in units of years when discussing dating techniques. After one half-life has elapsed, one half of the atoms of the nuclide in question will have decayed into a "daughter" nuclide or decay product. In many cases, the daughter nuclide itself is radioactive, resulting in a decay chain, eventually ending with the formation of a stable (nonradioactive) daughter nuclide; each step in such a chain is characterized by a distinct half-life. In these cases, usually the half-life of interest in radiometric dating is the longest one in the chain, which is the rate-limiting factor in the ultimate transformation of the radioactive nuclide into its stable daughter. Isotopic systems that have been exploited for radiometric dating have half-lives ranging from only about 10 years (e.g., tritium) to over 100 billion years (e.g., samarium-147).

For most radioactive nuclides, the half-life depends solely on nuclear properties and is essentially constant. This is known because decay constants measured by different techniques give consistent values within analytical errors and the ages of the same materials are consistent from one method to another. It is not affected by external factors such as temperature, pressure, chemical environment, or presence of a magnetic or electric field. The only exceptions are nuclides that decay by the process of electron capture, such as beryllium-7, strontium-85, and zirconium-89, whose decay rate may be affected by local electron density. For all other nuclides, the proportion of the original nuclide to its decay products changes in a predictable way as the original nuclide decays over time.

This predictability allows the relative abundances of related nuclides to be used as a clock to measure the time from the incorporation of the original nuclides into a material to the present. Nature has conveniently provided us with radioactive nuclides that have half-lives which range from considerably longer than the age of the universe, to less than a zeptosecond. This allows one to measure a very wide range of ages. Isotopes with very long half-lives are called "stable isotopes," and isotopes with very short half-lives are known as "extinct isotopes."

The radioactive decay constant, the probability that an atom will decay per year, is the solid foundation of the common measurement of radioactivity. The accuracy and precision of the determination of an age (and a nuclide's half-life) depends on the accuracy and precision of the decay constant measurement. The in-growth method is one way of measuring the decay constant of a system, which involves accumulating daughter nuclides. Unfortunately for nuclides with high decay constants (which are useful for dating very old samples), long periods of time (decades) are required to accumulate enough decay products in a single sample to accurately measure them. A faster method involves using particle counters to determine alpha, beta or gamma activity, and then dividing that by the number of radioactive nuclides. However, it is challenging and expensive to accurately determine the number of radioactive nuclides. Alternatively, decay constants can be determined by comparing isotope data for rocks of known age. This method requires at least one of the isotope systems to be very precisely calibrated, such as the Pb-Pb system.

The basic equation of radiometric dating requires that neither the parent nuclide nor the daughter product can enter or leave the material after its formation. The possible confounding effects of contamination of parent and daughter isotopes have to be considered, as do the effects of any loss or gain of such isotopes since the sample was created. It is therefore essential to have as much information as possible about the material being dated and to check for possible signs of alteration. Precision is enhanced if measurements are taken on multiple samples from different locations of the rock body. Alternatively, if several different minerals can be dated from the same sample and are assumed to be formed by the same event and were in equilibrium with the reservoir when they formed, they should form an isochron. This can reduce the problem of contamination. In uraniumâlead dating, the concordia diagram is used which also decreases the problem of nuclide loss. Finally, correlation between different isotopic dating methods may be required to confirm the age of a sample. For example, the age of the Amitsoq gneisses from western Greenland was determined to be 3.60 Â± 0.05 Ga (billion years ago) using uraniumâlead dating and 3.56 Â± 0.10 Ga (billion years ago) using leadâlead dating, results that are consistent with each other.

Accurate radiometric dating generally requires that the parent has a long enough half-life that it will be present in significant amounts at the time of measurement (except as described below under "Dating with short-lived extinct radionuclides"), the half-life of the parent is accurately known, and enough of the daughter product is produced to be accurately measured and distinguished from the initial amount of the daughter present in the material. The procedures used to isolate and analyze the parent and daughter nuclides must be precise and accurate. This normally involves isotope-ratio mass spectrometry.

The precision of a dating method depends in part on the half-life of the radioactive isotope involved. For instance, carbon-14 has a half-life of 5,730 years. After an organism has been dead for 60,000 years, so little carbon-14 is left that accurate dating cannot be established. On the other hand, the concentration of carbon-14 falls off so steeply that the age of relatively young remains can be determined precisely to within a few decades.

The closure temperature or blocking temperature represents the temperature below which the mineral is a closed system for the studied isotopes. If a material that selectively rejects the daughter nuclide is heated above this temperature, any daughter nuclides that have been accumulated over time will be lost through diffusion, resetting the isotopic "clock" to zero. As the mineral cools, the crystal structure begins to form and diffusion of isotopes is less easy. At a certain temperature, the crystal structure has formed sufficiently to prevent diffusion of isotopes. Thus an igneous or metamorphic rock or melt, which is slowly cooling, does not begin to exhibit measurable radioactive decay until it cools below the closure temperature. The age that can be calculated by radiometric dating is thus the time at which the rock or mineral cooled to closure temperature. This temperature varies for every mineral and isotopic system, so a system can be closed for one mineral but open for another. Dating of different minerals and/or isotope systems (with differing closure temperatures) within the same rock can therefore enable the tracking of the thermal history of the rock in question with time, and thus the history of metamorphic events may become known in detail. These temperatures are experimentally determined in the lab by artificially resetting sample minerals using a high-temperature furnace. This field is known as thermochronology or thermochronometry.

The mathematical expression that relates radioactive decay to geologic time is

where

The equation is most conveniently expressed in terms of the measured quantity "N"("t") rather than the constant initial value "N".

To calculate the age, it is assumed that the system is closed (neither parent nor daughter isotopes have been lost from system), "D" must be either negligible or can be accurately estimated, "Î»" is known to a high precision, and one has accurate and precise measurements of D* and "N"("t").

The above equation makes use of information on the composition of parent and daughter isotopes at the time the material being tested cooled below its closure temperature. This is well-established for most isotopic systems. However, construction of an isochron does not require information on the original compositions, using merely the present ratios of the parent and daughter isotopes to a standard isotope. An isochron plot is used to solve the age equation graphically and calculate the age of the sample and the original composition.

Radiometric dating has been carried out since 1905 when it was invented by Ernest Rutherford as a method by which one might determine the age of the Earth. In the century since then the techniques have been greatly improved and expanded. Dating can now be performed on samples as small as a nanogram using a mass spectrometer. The mass spectrometer was invented in the 1940s and began to be used in radiometric dating in the 1950s. It operates by generating a beam of ionized atoms from the sample under test. The ions then travel through a magnetic field, which diverts them into different sampling sensors, known as "Faraday cups", depending on their mass and level of ionization. On impact in the cups, the ions set up a very weak current that can be measured to determine the rate of impacts and the relative concentrations of different atoms in the beams.

Uraniumâlead radiometric dating involves using uranium-235 or uranium-238 to date a substance's absolute age. This scheme has been refined to the point that the error margin in dates of rocks can be as low as less than two million years in two-and-a-half billion years. An error margin of 2â5% has been achieved on younger Mesozoic rocks.

Uraniumâlead dating is often performed on the mineral zircon (ZrSiO), though it can be used on other materials, such as baddeleyite, as well as monazite (see: monazite geochronology). Zircon and baddeleyite incorporate uranium atoms into their crystalline structure as substitutes for zirconium, but strongly reject lead. Zircon has a very high closure temperature, is resistant to mechanical weathering and is very chemically inert. Zircon also forms multiple crystal layers during metamorphic events, which each may record an isotopic age of the event. "In situ" micro-beam analysis can be achieved via laser ICP-MS or SIMS techniques.

One of its great advantages is that any sample provides two clocks, one based on uranium-235's decay to lead-207 with a half-life of about 700 million years, and one based on uranium-238's decay to lead-206 with a half-life of about 4.5 billion years, providing a built-in crosscheck that allows accurate determination of the age of the sample even if some of the lead has been lost. This can be seen in the concordia diagram, where the samples plot along an errorchron (straight line) which intersects the concordia curve at the age of the sample.

This involves the alpha decay of Sm to Nd with a half-life of 1.06 x 10 years. Accuracy levels of within twenty million years in ages of two-and-a-half billion years are achievable.

This involves electron capture or positron decay of potassium-40 to argon-40. Potassium-40 has a half-life of 1.3 billion years, so this method is applicable to the oldest rocks. Radioactive potassium-40 is common in micas, feldspars, and hornblendes, though the closure temperature is fairly low in these materials, about 350Â Â°C (mica) to 500Â Â°C (hornblende).

This is based on the beta decay of rubidium-87 to strontium-87, with a half-life of 50 billion years. This scheme is used to date old igneous and metamorphic rocks, and has also been used to date lunar samples. Closure temperatures are so high that they are not a concern. Rubidium-strontium dating is not as precise as the uranium-lead method, with errors of 30 to 50 million years for a 3-billion-year-old sample.

A relatively short-range dating technique is based on the decay of uranium-234 into thorium-230, a substance with a half-life of about 80,000 years. It is accompanied by a sister process, in which uranium-235 decays into protactinium-231, which has a half-life of 32,760 years.

While uranium is water-soluble, thorium and protactinium are not, and so they are selectively precipitated into ocean-floor sediments, from which their ratios are measured. The scheme has a range of several hundred thousand years. A related method is ioniumâthorium dating, which measures the ratio of ionium (thorium-230) to thorium-232 in ocean sediment.

 Radiocarbon dating is also simply called carbon-14 dating. Carbon-14 is a radioactive isotope of carbon, with a half-life of 5,730 years (which is very short compared with the above isotopes), and decays into nitrogen. In other radiometric dating methods, the heavy parent isotopes were produced by nucleosynthesis in supernovas, meaning that any parent isotope with a short half-life should be extinct by now. Carbon-14, though, is continuously created through collisions of neutrons generated by cosmic rays with nitrogen in the upper atmosphere and thus remains at a near-constant level on Earth. The carbon-14 ends up as a trace component in atmospheric carbon dioxide (CO).

A carbon-based life form acquires carbon during its lifetime. Plants acquire it through photosynthesis, and animals acquire it from consumption of plants and other animals. When an organism dies, it ceases to take in new carbon-14, and the existing isotope decays with a characteristic half-life (5730 years). The proportion of carbon-14 left when the remains of the organism are examined provides an indication of the time elapsed since its death. This makes carbon-14 an ideal dating method to date the age of bones or the remains of an organism. The carbon-14 dating limit lies around 58,000 to 62,000 years.

The rate of creation of carbon-14 appears to be roughly constant, as cross-checks of carbon-14 dating with other dating methods show it gives consistent results. However, local eruptions of volcanoes or other events that give off large amounts of carbon dioxide can reduce local concentrations of carbon-14 and give inaccurate dates. The releases of carbon dioxide into the biosphere as a consequence of industrialization have also depressed the proportion of carbon-14 by a few percent; conversely, the amount of carbon-14 was increased by above-ground nuclear bomb tests that were conducted into the early 1960s. Also, an increase in the solar wind or the Earth's magnetic field above the current value would depress the amount of carbon-14 created in the atmosphere.

This involves inspection of a polished slice of a material to determine the density of "track" markings left in it by the spontaneous fission of uranium-238 impurities. The uranium content of the sample has to be known, but that can be determined by placing a plastic film over the polished slice of the material, and bombarding it with slow neutrons. This causes induced fission of U, as opposed to the spontaneous fission of U. The fission tracks produced by this process are recorded in the plastic film. The uranium content of the material can then be calculated from the number of tracks and the neutron flux.

This scheme has application over a wide range of geologic dates. For dates up to a few million years micas, tektites (glass fragments from volcanic eruptions), and meteorites are best used. Older materials can be dated using zircon, apatite, titanite, epidote and garnet which have a variable amount of uranium content. Because the fission tracks are healed by temperatures over about 200Â Â°C the technique has limitations as well as benefits. The technique has potential applications for detailing the thermal history of a deposit.

Large amounts of otherwise rare Cl (half-life ~300ky) were produced by irradiation of seawater during atmospheric detonations of nuclear weapons between 1952 and 1958. The residence time of Cl in the atmosphere is about 1 week. Thus, as an event marker of 1950s water in soil and ground water, Cl is also useful for dating waters less than 50 years before the present. Cl has seen use in other areas of the geological sciences, including dating ice and sediments.

Luminescence dating methods are not radiometric dating methods in that they do not rely on abundances of isotopes to calculate age. Instead, they are a consequence of background radiation on certain minerals. Over time, ionizing radiation is absorbed by mineral grains in sediments and archaeological materials such as quartz and potassium feldspar. The radiation causes charge to remain within the grains in structurally unstable "electron traps". Exposure to sunlight or heat releases these charges, effectively "bleaching" the sample and resetting the clock to zero. The trapped charge accumulates over time at a rate determined by the amount of background radiation at the location where the sample was buried. Stimulating these mineral grains using either light (optically stimulated luminescence or infrared stimulated luminescence dating) or heat (thermoluminescence dating) causes a luminescence signal to be emitted as the stored unstable electron energy is released, the intensity of which varies depending on the amount of radiation absorbed during burial and specific properties of the mineral.

These methods can be used to date the age of a sediment layer, as layers deposited on top would prevent the grains from being "bleached" and reset by sunlight. Pottery shards can be dated to the last time they experienced significant heat, generally when they were fired in a kiln.

Other methods include:

Absolute radiometric dating requires a measurable fraction of parent nucleus to remain in the sample rock. For rocks dating back to the beginning of the solar system, this requires extremely long-lived parent isotopes, making measurement of such rocks' exact ages imprecise. To be able to distinguish the relative ages of rocks from such old material, and to get a better time resolution than that available from long-lived isotopes, short-lived isotopes that are no longer present in the rock can be used.

At the beginning of the solar system, there were several relatively short-lived radionuclides like Al, Fe, Mn, and I present within the solar nebula. These radionuclidesâpossibly produced by the explosion of a supernovaâare extinct today, but their decay products can be detected in very old material, such as that which constitutes meteorites. By measuring the decay products of extinct radionuclides with a mass spectrometer and using isochronplots, it is possible to determine relative ages of different events in the early history of the solar system. Dating methods based on extinct radionuclides can also be calibrated with the U-Pb method to give absolute ages. Thus both the approximate age and a high time resolution can be obtained. Generally a shorter half-life leads to a higher time resolution at the expense of timescale.

 beta-decays to with a half-life of 16 million years. The iodine-xenon chronometer is an isochron technique. Samples are exposed to neutrons in a nuclear reactor. This converts the only stable isotope of iodine () into via neutron capture followed by beta decay (of ). After irradiation, samples are heated in a series of steps and the xenon isotopic signature of the gas evolved in each step is analysed. When a consistent / ratio is observed across several consecutive temperature steps, it can be interpreted as corresponding to a time at which the sample stopped losing xenon.

Samples of a meteorite called Shallowater are usually included in the irradiation to monitor the conversion efficiency from to . The difference between the measured / ratios of the sample and Shallowater then corresponds to the different ratios of / when they each stopped losing xenon. This in turn corresponds to a difference in age of closure in the early solar system.

Another example of short-lived extinct radionuclide dating is the â chronometer, which can be used to estimate the relative ages of chondrules. decays to with a half-life of 720 000 years. The dating is simply a question of finding the deviation from the natural abundance of (the product of decay) in comparison with the ratio of the stable isotopes /.

The excess of (often designated *) is found by comparing the / ratio to that of other Solar System materials.

The â chronometer gives an estimate of the time period for formation of primitive meteorites of only a few million years (1.4 million years for Chondrule formation).




</doc>
<doc id="26301" url="https://en.wikipedia.org/wiki?curid=26301" title="Rocket">
Rocket

A rocket (from Italian "rocchetto" "bobbin") is a missile, spacecraft, aircraft or other vehicle that obtains thrust from a rocket engine. Rocket engine exhaust is formed entirely from propellant carried within the rocket. Rocket engines work by action and reaction and push rockets forward simply by expelling their exhaust in the opposite direction at high speed, and can therefore work in the vacuum of space.

In fact, rockets work more efficiently in space than in an atmosphere. Multistage rockets are capable of attaining escape velocity from Earth and therefore can achieve unlimited maximum altitude. Compared with airbreathing engines, rockets are lightweight and powerful and capable of generating large accelerations. To control their flight, rockets rely on momentum, airfoils, auxiliary reaction engines, gimballed thrust, momentum wheels, deflection of the exhaust stream, propellant flow, spin, or gravity.

Rockets for military and recreational uses date back to at least 13th-century China. Significant scientific, interplanetary and industrial use did not occur until the 20th century, when rocketry was the enabling technology for the Space Age, including setting foot on the Earth's moon. Rockets are now used for fireworks, weaponry, ejection seats, launch vehicles for artificial satellites, human spaceflight, and space exploration.

Chemical rockets are the most common type of high power rocket, typically creating a high speed exhaust by the combustion of fuel with an oxidizer. The stored propellant can be a simple pressurized gas or a single liquid fuel that disassociates in the presence of a catalyst (monopropellants), two liquids that spontaneously react on contact (hypergolic propellants), two liquids that must be ignited to react, a solid combination of fuel with oxidizer (solid fuel), or solid fuel with liquid oxidizer (hybrid propellant system). Chemical rockets store a large amount of energy in an easily released form, and can be very dangerous. However, careful design, testing, construction and use minimizes risks.

The first gunpowder-powered rockets evolved in medieval China under the Song dynasty by the 13th century. The Mongols adopted Chinese rocket technology and the invention spread via the Mongol invasions to the Middle East and to Europe in the mid-13th century. Rockets are recorded in use by the Song navy in a military exercise dated to 1245. Internal-combustion rocket propulsion is mentioned in a reference to 1264, recording that the "ground-rat", a type of firework, had frightened the Empress-Mother Gongsheng at a feast held in her honor by her son the Emperor Lizong. Subsequently, rockets are included in the military treatise "Huolongjing", also known as the Fire Drake Manual, written by the Chinese artillery officer Jiao Yu in the mid-14th century. This text mentions the first known multistage rocket, the 'fire-dragon issuing from the water' (Huo long chu shui), thought to have been used by the Chinese navy.

Medieval and early modern rockets were used militarily as incendiary weapons in sieges. Between 1270 and 1280, Hasan al-Rammah wrote "al-furusiyyah wa al-manasib al-harbiyya" ("The Book of Military Horsemanship and Ingenious War Devices"), which included 107 gunpowder recipes, 22 of them for rockets.
In Europe, Konrad Kyeser described rockets in his military treatise "Bellifortis" around 1405.
The name "rocket" comes from the Italian "rocchetta", meaning "bobbin" or "little spindle", given due to the similarity in shape to the bobbin or spool used to hold the thread to be fed to a spinning wheel.
Leonhard Fronsperger and Conrad Haas adopted the Italian term into German in the mid-16th century; "rocket" appears in English by the early 17th century.
"Artis Magnae Artilleriae pars prima", an important early modern work on rocket artillery, by Kazimierz Siemienowicz, was first printed in Amsterdam in 1650.

The Mysorean rockets were the first successful iron-cased rockets, developed in the late 18th century in the Kingdom of Mysore (part of present-day India) under the rule of Hyder Ali. The Congreve rocket was a British weapon designed and developed by Sir William Congreve in 1804. This rocket was based directly on the Mysorean rockets, used compressed powder and was fielded in the Napoleonic Wars. It was Congreve rockets that Francis Scott Key was referring to when he wrote of the "rockets' red glare" while held captive on a British ship that was laying siege to Fort McHenry in 1814. Together, the Mysorean and British innovations increased the effective range of military rockets from 100 to 2,000 yards.

The first mathematical treatment of the dynamics of rocket propulsion is due to William Moore (1813). In 1815 Alexander Dmitrievich Zasyadko constructed rocket-launching platforms, which allowed rockets to be fired in salvos (6 rockets at a time), and gun-laying devices. William Hale in 1844 greatly increased the accuracy of rocket artillery. Edward Mounier Boxer further improved the Congreve rocket in 1865.

William Leitch first proposed the concept of using rockets to enable human spaceflight in 1861. Konstantin Tsiolkovsky later (in 1903) also conceived this idea, and extensively developed a body of theory that has provided the foundation for subsequent spaceflight development. In 1920, Professor Robert Goddard of Clark University published proposed improvements to rocket technology in "A Method of Reaching Extreme Altitudes". In 1923, Hermann Oberth (1894â1989) published "Die Rakete zu den PlanetenrÃ¤umen" ("The Rocket into Planetary Space")

Modern rockets originated in 1926 when Goddard attached a supersonic (de Laval) nozzle to the combustion chamber of a liquid-propellant rocket. These nozzles turn the hot gas from the combustion chamber into a cooler, hypersonic, highly directed jet of gas, more than doubling the thrust and raising the engine efficiency from 2% to 64%.
Use of liquid propellants instead of gunpowder greatly improved the effectiveness of rocket artillery in World War II, and opened up the possibility of human spaceflight after 1945.

In 1943 production of the V-2 rocket began in Germany.
In parallel with the German guided-missile programme, rockets were also used on aircraft, either for assisting horizontal take-off (RATO), vertical take-off (Bachem Ba 349 "Natter") or for powering them (Me 163, see list of World War II guided missiles of Germany). The Allies' rocket programs were less technological, relying mostly on unguided missiles like the Soviet Katyusha rocket.
The Americans captured a large number of German rocket scientists, including Wernher von Braun, in 1945, and brought them to the United States as part of Operation Paperclip. After World War II scientists used rockets to study high-altitude conditions, by radio telemetry of temperature and pressure of the atmosphere, detection of cosmic rays, and further techniques; note too the Bell X-1, the first crewed vehicle to break the sound barrier (1947). Independently, in the Soviet Union's space program research continued under the leadership of the chief designer Sergei Korolev (1907â1966).

During the Cold War rockets became extremely important militarily with the development of modern intercontinental ballistic missiles (ICBMs).
The 1960s saw rapid development of rocket technology, particularly in the Soviet Union (Vostok, Soyuz, Proton) and in the United States (e.g. the X-15). Rockets came into use for space exploration. American crewed programs (Project Mercury, Project Gemini and later the Apollo programme) culminated in 1969 with the first crewed landing on the Moon â using equipment launched by the Saturn V rocket.


Rocket vehicles are often constructed in the archetypal tall thin "rocket" shape that takes off vertically, but there are actually many different types of rockets including:
A rocket design can be as simple as a cardboard tube filled with black powder, but to make an efficient, accurate rocket or missile involves overcoming a number of difficult problems. The main difficulties include cooling the combustion chamber, pumping the fuel (in the case of a liquid fuel), and controlling and correcting the direction of motion.

Rockets consist of a propellant, a place to put propellant (such as a propellant tank), and a nozzle. They may also have one or more rocket engines, directional stabilization device(s) (such as fins, vernier engines or engine gimbals for thrust vectoring, gyroscopes) and a structure (typically monocoque) to hold these components together. Rockets intended for high speed atmospheric use also have an aerodynamic fairing such as a nose cone, which usually holds the payload.

As well as these components, rockets can have any number of other components, such as wings (rocketplanes), parachutes, wheels (rocket cars), even, in a sense, a person (rocket belt). Vehicles frequently possess navigation systems and guidance systems that typically use satellite navigation and inertial navigation systems.

Rocket engines employ the principle of jet propulsion. The rocket engines powering rockets come in a great variety of different types; a comprehensive list can be found in rocket engine. Most current rockets are chemically powered rockets (usually internal combustion engines, but some employ a decomposing monopropellant) that emit a hot exhaust gas. A rocket engine can use gas propellants, solid propellant, liquid propellant, or a hybrid mixture of both solid and liquid. Some rockets use heat or pressure that is supplied from a source other than the chemical reaction of propellant(s), such as steam rockets, solar thermal rockets, nuclear thermal rocket engines or simple pressurized rockets such as water rocket or cold gas thrusters. With combustive propellants a chemical reaction is initiated between the fuel and the oxidizer in the combustion chamber, and the resultant hot gases accelerate out of a rocket engine nozzle (or nozzles) at the rearward-facing end of the rocket. The acceleration of these gases through the engine exerts force ("thrust") on the combustion chamber and nozzle, propelling the vehicle (according to Newton's Third Law). This actually happens because the force (pressure times area) on the combustion chamber wall is unbalanced by the nozzle opening; this is not the case in any other direction. The shape of the nozzle also generates force by directing the exhaust gas along the axis of the rocket.

Rocket propellant is mass that is stored, usually in some form of propellant tank or casing, prior to being used as the propulsive mass that is ejected from a rocket engine in the form of a fluid jet to produce thrust. For chemical rockets often the propellants are a fuel such as liquid hydrogen or kerosene burned with an oxidizer such as liquid oxygen or nitric acid to produce large volumes of very hot gas. The oxidiser is either kept separate and mixed in the combustion chamber, or comes premixed, as with solid rockets.

Sometimes the propellant is not burned but still undergoes a chemical reaction, and can be a 'monopropellant' such as hydrazine, nitrous oxide or hydrogen peroxide that can be catalytically decomposed to hot gas.

Alternatively, an inert propellant can be used that can be externally heated, such as in steam rocket, solar thermal rocket or nuclear thermal rockets.

For smaller, low performance rockets such as attitude control thrusters where high performance is less necessary, a pressurised fluid is used as propellant that simply escapes the spacecraft through a propelling nozzle.

Rockets or other similar reaction devices carrying their own propellant must be used when there is no other substance (land, water, or air) or force (gravity, magnetism, light) that a vehicle may usefully employ for propulsion, such as in space. In these circumstances, it is necessary to carry all the propellant to be used.

However, they are also useful in other situations:

Some military weapons use rockets to propel warheads to their targets. A rocket and its payload together are generally referred to as a "missile" when the weapon has a guidance system (not all missiles use rocket engines, some use other engines such as jets) or as a "rocket" if it is unguided. Anti-tank and anti-aircraft missiles use rocket engines to engage targets at high speed at a range of several miles, while intercontinental ballistic missiles can be used to deliver multiple nuclear warheads from thousands of miles, and anti-ballistic missiles try to stop them. Rockets have also been tested for reconnaissance, such as the Ping-Pong rocket, which was launched to surveil enemy targets, however, recon rockets have never come into wide use in the military.

Sounding rockets are commonly used to carry instruments that take readings from to above the surface of the Earth.

Rocket engines are also used to propel rocket sleds along a rail at extremely high speed. The world record for this is Mach 8.5.

Larger rockets are normally launched from a launch pad that provides stable support until a few seconds after ignition. Due to their high exhaust velocityâârockets are particularly useful when very high speeds are required, such as orbital speed at approximately . Spacecraft delivered into orbital trajectories become artificial satellites, which are used for many commercial purposes. Indeed, rockets remain the only way to launch spacecraft into orbit and beyond. They are also used to rapidly accelerate spacecraft when they change orbits or de-orbit for landing. Also, a rocket may be used to soften a hard parachute landing immediately before touchdown (see retrorocket).

Rockets were used to propel a line to a stricken ship so that a Breeches buoy can be used to rescue those on board. Rockets are also used to launch emergency flares.

Some crewed rockets, notably the Saturn V and Soyuz have launch escape systems. This is a small, usually solid rocket that is capable of pulling the crewed capsule away from the main vehicle towards safety at a moments notice. These types of systems have been operated several times, both in testing and in flight, and operated correctly each time.

This was the case when the Safety Assurance System (Soviet nomenclature) successfully pulled away the L3 capsule during three of the four failed launches of the Soviet moon rocket, N1 vehicles 3L, 5L and 7L. In all three cases the capsule, albeit uncrewed, was saved from destruction. Only the three aforementioned N1 rockets had functional Safety Assurance Systems. The outstanding vehicle, 6L, had dummy upper stages and therefore no escape system giving the N1 booster a 100% success rate for egress from a failed launch.

A successful escape of a crewed capsule occurred when Soyuz T-10, on a mission to the Salyut 7 space station, exploded on the pad.

Solid rocket propelled ejection seats are used in many military aircraft to propel crew away to safety from a vehicle when flight control is lost.

A model rocket is a small rocket designed to reach low altitudes (e.g., for model) and be recovered by a variety of means.

According to the United States National Association of Rocketry (nar) Safety Code, model rockets are constructed of paper, wood, plastic and other lightweight materials. The code also provides guidelines for motor use, launch site selection, launch methods, launcher placement, recovery system design and deployment and more. Since the early 1960s, a copy of the Model Rocket Safety Code has been provided with most model rocket kits and motors. Despite its inherent association with extremely flammable substances and objects with a pointed tip traveling at high speeds, model rocketry historically has proven to be a very safe hobby and has been credited as a significant source of inspiration for children who eventually become scientists and engineers.

Hobbyists build and fly a wide variety of model rockets. Many companies produce model rocket kits and parts but due to their inherent simplicity some hobbyists have been known to make rockets out of almost anything. Rockets are also used in some types of consumer and professional fireworks. A water rocket is a type of model rocket using water as its reaction mass. The pressure vessel (the engine of the rocket) is usually a used plastic soft drink bottle. The water is forced out by a pressurized gas, typically compressed air. It is an example of Newton's third law of motion.

The scale of amateur rocketry can range from a small rocket launched in one's own backyard to a rocket that reached space. Amateur rocketry is split into three categories according to total engine impulse: low-power, mid-power, and high-power.

Hydrogen peroxide rockets are used to power jet packs, and have been used to power cars and a rocket car holds the all time (albeit unofficial) drag racing record.

Corpulent Stump is the most powerful non-commercial rocket ever launched on an Aerotech engine in the United Kingdom.

Rocket exhaust generates a significant amount of acoustic energy. As the supersonic exhaust collides with the ambient air, shock waves are formed. The sound intensity from these shock waves depends on the size of the rocket as well as the exhaust velocity. The sound intensity of large, high performance rockets could potentially kill at close range.

The Space Shuttle generated 180Â dB of noise around its base. To combat this, NASA developed a sound suppression system which can flow water at rates up to 900,000 gallons per minute (57Â m/s) onto the launch pad. The water reduces the noise level from 180Â dB down to 142Â dB (the design requirement is 145Â dB). Without the sound suppression system, acoustic waves would reflect off of the launch pad towards the rocket, vibrating the sensitive payload and crew. These acoustic waves can be so severe as to damage or destroy the rocket.

Noise is generally most intense when a rocket is close to the ground, since the noise from the engines radiates up away from the jet, as well as reflecting off the ground. This noise can be reduced somewhat by flame trenches with roofs, by water injection around the jet and by deflecting the jet at an angle.

For crewed rockets various methods are used to reduce the sound intensity for the passengers, and typically the placement of the astronauts far away from the rocket engines helps significantly. For the passengers and crew, when a vehicle goes supersonic the sound cuts off as the sound waves are no longer able to keep up with the vehicle.

The effect of the combustion of propellant in the rocket engine is to increase the internal energy of the resulting gases, utilizing the stored chemical energy in the fuel. As the internal energy increases, pressure increases, and a nozzle is utilized to convert this energy into a directed kinetic energy. This produces thrust against the ambient environment to which these gases are released. The ideal direction of motion of the exhaust is in the direction so as to cause thrust. At the top end of the combustion chamber the hot, energetic gas fluid cannot move forward, and so, it pushes upward against the top of the rocket engine's combustion chamber. As the combustion gases approach the exit of the combustion chamber, they increase in speed. The effect of the convergent part of the rocket engine nozzle on the high pressure fluid of combustion gases, is to cause the gases to accelerate to high speed. The higher the speed of the gases, the lower the pressure of the gas (Bernoulli's principle or conservation of energy) acting on that part of the combustion chamber. In a properly designed engine, the flow will reach Mach 1 at the throat of the nozzle. At which point the speed of the flow increases. Beyond the throat of the nozzle, a bell shaped expansion part of the engine allows the gases that are expanding to push against that part of the rocket engine. Thus, the bell part of the nozzle gives additional thrust. Simply expressed, for every action there is an equal and opposite reaction, according to Newton's third law with the result that the exiting gases produce the reaction of a force on the rocket causing it to accelerate the rocket.
In a closed chamber, the pressures are equal in each direction and no acceleration occurs. If an opening is provided in the bottom of the chamber then the pressure is no longer acting on the missing section. This opening permits the exhaust to escape. The remaining pressures give a resultant thrust on the side opposite the opening, and these pressures are what push the rocket along.

The shape of the nozzle is important. Consider a balloon propelled by air coming out of a tapering nozzle. In such a case the combination of air pressure and viscous friction is such that the nozzle does not push the balloon but is "pulled" by it. Using a convergent/divergent nozzle gives more force since the exhaust also presses on it as it expands outwards, roughly doubling the total force. If propellant gas is continuously added to the chamber then these pressures can be maintained for as long as propellant remains. Note that in the case of liquid propellant engines, the pumps moving the propellant into the combustion chamber must maintain a pressure larger than the combustion chamber â typically on the order of 100 atmospheres.

As a side effect, these pressures on the rocket also act on the exhaust in the opposite direction and accelerate this exhaust to very high speeds (according to Newton's Third Law). From the principle of conservation of momentum the speed of the exhaust of a rocket determines how much momentum increase is created for a given amount of propellant. This is called the rocket's "specific impulse". Because a rocket, propellant and exhaust in flight, without any external perturbations, may be considered as a closed system, the total momentum is always constant. Therefore, the faster the net speed of the exhaust in one direction, the greater the speed of the rocket can achieve in the opposite direction. This is especially true since the rocket body's mass is typically far lower than the final total exhaust mass.

The general study of the forces on a rocket is part of the field of ballistics. Spacecraft are further studied in the subfield of astrodynamics.

Flying rockets are primarily affected by the following:

In addition, the inertia and centrifugal pseudo-force can be significant due to the path of the rocket around the center of a celestial body; when high enough speeds in the right direction and altitude are achieved a stable orbit or escape velocity is obtained.

These forces, with a stabilizing tail (the "empennage") present will, unless deliberate control efforts are made, naturally cause the vehicle to follow a roughly parabolic trajectory termed a gravity turn, and this trajectory is often used at least during the initial part of a launch. (This is true even if the rocket engine is mounted at the nose.) Vehicles can thus maintain low or even zero angle of attack, which minimizes transverse stress on the launch vehicle, permitting a weaker, and hence lighter, launch vehicle.

Drag is a force opposite to the direction of the rocket's motion relative to any air it is moving through. This slows the speed of the vehicle and produces structural loads. The deceleration forces for fast-moving rockets are calculated using the drag equation.

Drag can be minimised by an aerodynamic nose cone and by using a shape with a high ballistic coefficient (the "classic" rocket shapeâlong and thin), and by keeping the rocket's angle of attack as low as possible.

During a rocket launch, as the vehicle speed increases, and the atmosphere thins, there is a point of maximum aerodynamic drag called Max Q. This determines the minimum aerodynamic strength of the vehicle, as the rocket must avoid buckling under these forces.

A typical rocket engine can handle a significant fraction of its own mass in propellant each second, with the propellant leaving the nozzle at several kilometres per second. This means that the thrust-to-weight ratio of a rocket engine, and often the entire vehicle can be very high, in extreme cases over 100. This compares with other jet propulsion engines that can exceed 5 for some of the better engines.

It can be shown that the net thrust of a rocket is:

where:

The effective exhaust velocity formula_4 is more or less the speed the exhaust leaves the vehicle, and in the vacuum of space, the effective exhaust velocity is often equal to the actual average exhaust speed along the thrust axis. However, the effective exhaust velocity allows for various losses, and notably, is reduced when operated within an atmosphere.

The rate of propellant flow through a rocket engine is often deliberately varied over a flight, to provide a way to control the thrust and thus the airspeed of the vehicle. This, for example, allows minimization of aerodynamic losses and can limit the increase of "g"-forces due to the reduction in propellant load.

Impulse is defined as a force acting on an object over time, which in the absence of opposing forces (gravity and aerodynamic drag), changes the momentum (integral of mass and velocity) of the object. As such, it is the best performance class (payload mass and terminal velocity capability) indicator of a rocket, rather than takeoff thrust, mass, or "power". The total impulse of a rocket (stage) burning its propellant is:

When there is fixed thrust, this is simply:

The total impulse of a multi-stage rocket is the sum of the impulses of the individual stages.
As can be seen from the thrust equation, the effective speed of the exhaust controls the amount of thrust produced from a particular quantity of fuel burnt per second.

An equivalent measure, the net impulse per weight unit of propellant expelled, is called specific Impulse, formula_7, and this is one of the most important figures that describes a rocket's performance. It is defined such that it is related to the effective exhaust velocity by:

where:

Thus, the greater the specific impulse, the greater the net thrust and performance of the engine. formula_7 is determined by measurement while testing the engine. In practice the effective exhaust velocities of rockets varies but can be extremely high, ~4500Â m/s, about 15 times the sea level speed of sound in air.

The delta-v capacity of a rocket is the theoretical total change in velocity that a rocket can achieve without any external interference (without air drag or gravity or other forces).

When formula_12 is constant, the delta-v that a rocket vehicle can provide can be calculated from the Tsiolkovsky rocket equation:

where:

When launched from the Earth practical delta-vs for a single rockets carrying payloads can be a few km/s. Some theoretical designs have rockets with delta-vs over 9Â km/s.

The required delta-v can also be calculated for a particular manoeuvre; for example the delta-v to launch from the surface of the Earth to Low earth orbit is about 9.7Â km/s, which leaves the vehicle with a sideways speed of about 7.8Â km/s at an altitude of around 200Â km. In this manoeuvre about 1.9Â km/s is lost in air drag, gravity drag and gaining altitude.

The ratio formula_18 is sometimes called the "mass ratio".

Almost all of a launch vehicle's mass consists of propellant. Mass ratio is, for any 'burn', the ratio between the rocket's initial mass and its final mass. Everything else being equal, a high mass ratio is desirable for good performance, since it indicates that the rocket is lightweight and hence performs better, for essentially the same reasons that low weight is desirable in sports cars.

Rockets as a group have the highest thrust-to-weight ratio of any type of engine; and this helps vehicles achieve high mass ratios, which improves the performance of flights. The higher the ratio, the less engine mass is needed to be carried. This permits the carrying of even more propellant, enormously improving the delta-v. Alternatively, some rockets such as for rescue scenarios or racing carry relatively little propellant and payload and thus need only a lightweight structure and instead achieve high accelerations. For example, the Soyuz escape system can produce 20g.

Achievable mass ratios are highly dependent on many factors such as propellant type, the design of engine the vehicle uses, structural safety margins and construction techniques.

The highest mass ratios are generally achieved with liquid rockets, and these types are usually used for orbital launch vehicles, a situation which calls for a high delta-v. Liquid propellants generally have densities similar to water (with the notable exceptions of liquid hydrogen and liquid methane), and these types are able to use lightweight, low pressure tanks and typically run high-performance turbopumps to force the propellant into the combustion chamber.

Some notable mass fractions are found in the following table (some aircraft are included for comparison purposes):

Thus far, the required velocity (delta-v) to achieve orbit has been unattained by any single rocket because the propellant, tankage, structure, guidance, valves and engines and so on, take a particular minimum percentage of take-off mass that is too great for the propellant it carries to achieve that delta-v carrying reasonable payloads. Since Single-stage-to-orbit has so far not been achievable, orbital rockets always have more than one stage.

For example, the first stage of the Saturn V, carrying the weight of the upper stages, was able to achieve a mass ratio of about 10, and achieved a specific impulse of 263 seconds. This gives a delta-v of around 5.9Â km/s whereas around 9.4Â km/s delta-v is needed to achieve orbit with all losses allowed for.

This problem is frequently solved by stagingâthe rocket sheds excess weight (usually empty tankage and associated engines) during launch. Staging is either "serial" where the rockets light after the previous stage has fallen away, or "parallel", where rockets are burning together and then detach when they burn out.

The maximum speeds that can be achieved with staging is theoretically limited only by the speed of light. However the payload that can be carried goes down geometrically with each extra stage needed, while the additional delta-v for each stage is simply additive.

From Newton's second law, the acceleration, formula_19, of a vehicle is simply:

Where m is the instantaneous mass of the vehicle and formula_21 is the net force acting on the rocket (mostly thrust but air drag and other forces can play a part.)

As the remaining propellant decreases, rocket vehicles become lighter and their acceleration tends to increase until the propellant is exhausted. This means that much of the speed change occurs towards the end of the burn when the vehicle is much lighter. However, the thrust can be throttled to offset or vary this if needed. Discontinuities in acceleration also occur when stages burn out, often starting at a lower acceleration with each new stage firing.

Peak accelerations can be increased by designing the vehicle with a reduced mass, usually achieved by a reduction in the fuel load and tankage and associated structures, but obviously this reduces range, delta-v and burn time. Still, for some applications that rockets are used for, a high peak acceleration applied for just a short time is highly desirable.

The minimal mass of vehicle consists of a rocket engine with minimal fuel and structure to carry it. In that case the thrust-to-weight ratio of the rocket engine limits the maximum acceleration that can be designed. It turns out that rocket engines generally have truly excellent thrust to weight ratios (137 for the NK-33 engine, some solid rockets are over 1000), and nearly all really high-g vehicles employ or have employed rockets.

The high accelerations that rockets naturally possess means that rocket vehicles are often capable of vertical takeoff, and in some cases, with suitable guidance and control of the engines, also vertical landing. For these operations to be done it is necessary for a vehicle's engines to provide more than the local gravitational acceleration.

Rocket launch vehicles take-off with a great deal of flames, noise and drama, and it might seem obvious that they are grievously inefficient. However, while they are far from perfect, their energy efficiency is not as bad as might be supposed.

The energy density of a typical rocket propellant is often around one-third that of conventional hydrocarbon fuels; the bulk of the mass is (often relatively inexpensive) oxidizer. Nevertheless, at take-off the rocket has a great deal of energy in the fuel and oxidizer stored within the vehicle. It is of course desirable that as much of the energy of the propellant end up as kinetic or potential energy of the body of the rocket as possible.

Energy from the fuel is lost in air drag and gravity drag and is used for the rocket to gain altitude and speed. However, much of the lost energy ends up in the exhaust.

In a chemical propulsion device, the engine efficiency is simply the ratio of the kinetic power of the exhaust gases and the power available from the chemical reaction:

100% efficiency within the engine (engine efficiency formula_23) would mean that all the heat energy of the combustion products is converted into kinetic energy of the jet. This is not possible, but the near-adiabatic high expansion ratio nozzles that can be used with rockets come surprisingly close: when the nozzle expands the gas, the gas is cooled and accelerated, and an energy efficiency of up to 70% can be achieved. Most of the rest is heat energy in the exhaust that is not recovered. The high efficiency is a consequence of the fact that rocket combustion can be performed at very high temperatures and the gas is finally released at much lower temperatures, and so giving good Carnot efficiency.

However, engine efficiency is not the whole story. In common with the other jet-based engines, but particularly in rockets due to their high and typically fixed exhaust speeds, rocket vehicles are extremely inefficient at low speeds irrespective of the engine efficiency. The problem is that at low speeds, the exhaust carries away a huge amount of kinetic energy rearward. This phenomenon is termed propulsive efficiency (formula_24).

However, as speeds rise, the resultant exhaust speed goes down, and the overall vehicle energetic efficiency rises, reaching a peak of around 100% of the engine efficiency when the vehicle is travelling exactly at the same speed that the exhaust is emitted. In this case the exhaust would ideally stop dead in space behind the moving vehicle, taking away zero energy, and from conservation of energy, all the energy would end up in the vehicle. The efficiency then drops off again at even higher speeds as the exhaust ends up traveling forwards â trailing behind the vehicle.

From these principles it can be shown that the propulsive efficiency formula_24 for a rocket moving at speed formula_26 with an exhaust velocity formula_27 is:

And the overall (instantaneous) energy efficiency formula_29 is:

For example, from the equation, with an formula_31 of 0.7, a rocket flying at Mach 0.85 (which most aircraft cruise at) with an exhaust velocity of Mach 10, would have a predicted overall energy efficiency of 5.9%, whereas a conventional, modern, air-breathing jet engine achieves closer to 35% efficiency. Thus a rocket would need about 6x more energy; and allowing for the specific energy of rocket propellant being around one third that of conventional air fuel, roughly 18x more mass of propellant would need to be carried for the same journey. This is why rockets are rarely if ever used for general aviation.

Since the energy ultimately comes from fuel, these considerations mean that rockets are mainly useful when a very high speed is required, such as ICBMs or orbital launch. For example, NASA's space shuttle fires its engines for around 8.5 minutes, consuming 1,000Â tonnes of solid propellant (containing 16% aluminium) and an additional 2,000,000Â litres of liquid propellant (106,261Â kg of liquid hydrogen fuel) to lift the 100,000Â kg vehicle (including the 25,000Â kg payload) to an altitude of 111Â km and an orbital velocity of 30,000Â km/h. At this altitude and velocity, the vehicle has a kinetic energy of about 3Â TJ and a potential energy of roughly 200Â GJ. Given the initial energy of 20Â TJ, the Space Shuttle is about 16% energy efficient at launching the orbiter.

Thus jet engines, with a better match between speed and jet exhaust speed (such as turbofansâin spite of their worse formula_31)âdominate for subsonic and supersonic atmospheric use, while rockets work best at hypersonic speeds. On the other hand, rockets serve in many short-range "relatively" low speed military applications where their low-speed inefficiency is outweighed by their extremely high thrust and hence high accelerations.

One subtle feature of rockets relates to energy. A rocket stage, while carrying a given load, is capable of giving a particular delta-v. This delta-v means that the speed increases (or decreases) by a particular amount, independent of the initial speed. However, because kinetic energy is a square law on speed, this means that the faster the rocket is travelling before the burn the more orbital energy it gains or loses.

This fact is used in interplanetary travel. It means that the amount of delta-v to reach other planets, over and above that to reach escape velocity can be much less if the delta-v is applied when the rocket is travelling at high speeds, close to the Earth or other planetary surface; whereas waiting until the rocket has slowed at altitude multiplies up the effort required to achieve the desired trajectory.

The reliability of rockets, as for all physical systems, is dependent on the quality of engineering design and construction.

Because of the enormous chemical energy in rocket propellants (greater energy by weight than explosives, but lower than gasoline), consequences of accidents can be severe. Most space missions have some problems. In 1986, following the Space Shuttle Challenger disaster, American physicist Richard Feynman, having served on the Rogers Commission estimated that the chance of an unsafe condition for a launch of the Shuttle was very roughly 1%; more recently the historical per person-flight risk in orbital spaceflight has been calculated to be around 2% or 4%.

The costs of rockets can be roughly divided into propellant costs, the costs of obtaining and/or producing the 'dry mass' of the rocket, and the costs of any required support equipment and facilities.

Most of the takeoff mass of a rocket is normally propellant. However propellant is seldom more than a few times more expensive than gasoline per kilogram (as of 2009 gasoline was about or less), and although substantial amounts are needed, for all but the very cheapest rockets, it turns out that the propellant costs are usually comparatively small, although not completely negligible. With liquid oxygen costing and liquid hydrogen , the Space Shuttle in 2009 had a liquid propellant expense of approximately $1.4 million for each launch that cost $450 million from other expenses (with 40% of the mass of propellants used by it being liquids in the external fuel tank, 60% solids in the SRBs).

Even though a rocket's non-propellant, dry mass is often only between 5â20% of total mass, nevertheless this cost dominates. For hardware with the performance used in orbital launch vehicles, expenses of $2000â$10,000+ per kilogram of dry weight are common, primarily from engineering, fabrication, and testing; raw materials amount to typically around 2% of total expense. For most rockets except reusable ones (shuttle engines) the engines need not function more than a few minutes, which simplifies design.

Extreme performance requirements for rockets reaching orbit correlate with high cost, including intensive quality control to ensure reliability despite the limited safety factors allowable for weight reasons. Components produced in small numbers if not individually machined can prevent amortization of R&D and facility costs over mass production to the degree seen in more pedestrian manufacturing. Amongst liquid-fueled rockets, complexity can be influenced by how much hardware must be lightweight, like pressure-fed engines can have two orders of magnitude lesser part count than pump-fed engines but lead to more weight by needing greater tank pressure, most often used in just small maneuvering thrusters as a consequence.

To change the preceding factors for orbital launch vehicles, proposed methods have included mass-producing simple rockets in large quantities or on large scale, or developing reusable rockets meant to fly very frequently to amortize their up-front expense over many payloads, or reducing rocket performance requirements by constructing a non-rocket spacelaunch system for part of the velocity to orbit (or all of it but with most methods involving some rocket use).

The costs of support equipment, range costs and launch pads generally scale up with the size of the rocket, but vary less with launch rate, and so may be considered to be approximately a fixed cost.

Rockets in applications other than launch to orbit (such as military rockets and rocket-assisted take off), commonly not needing comparable performance and sometimes mass-produced, are often relatively inexpensive.

Since the early 2010s, new private options for obtaining spaceflight services emerged, bringing substantial price pressure into the existing market.

Lists

General Rocketry

Propulsion and Propellant

Recreational Rockets

Recreational Pyrotechnic Rocketry

Weaponry

Rockets for Research

Misc

<br>

Governing agencies

Information sites


</doc>
<doc id="26304" url="https://en.wikipedia.org/wiki?curid=26304" title="Royal Botanic Gardens, Kew">
Royal Botanic Gardens, Kew

Royal Botanic Gardens, Kew (brand name Kew) is a non-departmental public body in the United Kingdom sponsored by the Department for Environment, Food and Rural Affairs. An internationally important botanical research and education institution, it employs 1,100 staff. Its board of trustees is chaired by Dame Amelia Fawcett. 

The organisation manages botanic gardens at Kew in Richmond upon Thames in southwest London, and at Wakehurst, a National Trust property in Sussex which is home to the internationally important Millennium Seed Bank, whose scientists work with partner organisations in more than 95 countries. Kew, jointly with the Forestry Commission, founded Bedgebury National Pinetum in Kent in 1923, specialising in growing conifers. In 1994 the Castle Howard Arboretum Trust, which runs the Yorkshire Arboretum, was formed as a partnership between Kew and the Castle Howard Estate.

In 2018 the organisation had 1,858,513 public visitors at Kew, and 354,957 at Wakehurst. Its site at Kew has 40 historically important buildings; it became a UNESCO World Heritage Site on 3 July 2003. The collections at Kew and Wakehurst include over 27,000 taxa of living plants, 8.3 million plant and fungal herbarium specimens, and over 40,000 species in the seed bank.

Kew is governed by a board of trustees which comprises a chairman and eleven members. Ten members and the chairman are appointed by the Secretary of State for Environment, Food and Rural Affairs. Her Majesty the Queen appoints her own trustee on the recommendation of the Secretary of State. the Board members are:

The Director of Science is Professor Alexandre Antonelli. Professor Monique Simmonds is Deputy Director of Science. Professor Mark Chase is Senior Research Professor.

The Harvard University Herbaria and the Australian National Herbarium co-operate with Kew in the IPNI (International Plant Names Index) database, a project which was launched in 1999 to produce an authoritative source of information on botanical nomenclature including publication details. The IPNI includes information from the "Index Kewensis", a project which began in the 19th century to provide an "Index to the Names and Authorities of all known flowering plants and their countries".

Kew also cooperates with the Missouri Botanical Garden in a related project called The Plant List; unlike the IPNI, it provides information on which names are currently accepted. The Plant List is an Internet encyclopedia project which was launched in 2010 to compile a comprehensive list of botanical nomenclature. The Plant List has 1,064,035 scientific plant names of species rank of which 350,699 are accepted species names. In addition, the list has 642 plant families and 17,020 plant genera.




</doc>
<doc id="26306" url="https://en.wikipedia.org/wiki?curid=26306" title="Radon difluoride">
Radon difluoride

Radon difluoride () is a compound of radon, a noble gas. Radon reacts readily with fluorine to form a solid compound, but this decomposes on attempted vaporization and its exact composition is uncertain. Calculations suggest that it may be ionic, unlike all other known binary noble gas compounds. The usefulness of radon compounds is limited because of the radioactivity of radon. The longest-lived isotope, radon-222, has a half-life of only 3.82 days, which decays by Î±-emission to yield polonium-218.


</doc>
<doc id="26307" url="https://en.wikipedia.org/wiki?curid=26307" title="Robert Penn Warren">
Robert Penn Warren

Robert Penn Warren (April 24, 1905 â September 15, 1989) was an American poet, novelist, and literary critic and was one of the founders of New Criticism. He was also a charter member of the Fellowship of Southern Writers. He founded the literary journal "The Southern Review" with Cleanth Brooks in 1935. He received the 1947 Pulitzer Prize for the Novel for his novel "All the King's Men" (1946) and the Pulitzer Prize for Poetry in 1958 and 1979. He is the only person to have won Pulitzer Prizes for both fiction and poetry.

Warren was born in Guthrie, Kentucky, very near the Tennessee-Kentucky border, to Robert Warren and Anna Penn. Warren's mother's family had roots in Virginia, having given their name to the community of Penn's Store in Patrick County, Virginia, and she was a descendant of Revolutionary War soldier Colonel Abram Penn. 

Robert Penn Warren graduated from Clarksville High School in Clarksville, Tennessee; Vanderbilt University ("summa cum laude", Phi Beta Kappa) in 1925; and the University of California, Berkeley (M.A.) in 1926. Warren pursued further graduate study at Yale University from 1927 to 1928 and obtained his B.Litt. as a Rhodes Scholar from New College, Oxford, in England in 1930. He also received a Guggenheim Fellowship to study in Italy during the rule of Benito Mussolini. That same year he began his teaching career at Southwestern College (now Rhodes College) in Memphis, Tennessee.

While still an undergraduate at Vanderbilt University, Warren became associated with the group of poets there known as the Fugitives, and somewhat later, during the early 1930s, Warren and some of the same writers formed a group known as the Southern Agrarians. He contributed "The Briar Patch" to the Agrarian manifesto "I'll Take My Stand" along with 11 other Southern writers and poets (including fellow Vanderbilt poet/critics John Crowe Ransom, Allen Tate, and Donald Davidson). In "The Briar Patch" the young Warren defends racial segregation, in line with the political leanings of the Agrarian group, although Davidson deemed Warren's stances in the essay so progressive that he argued for excluding it from the collection. However, Warren recanted these views in an article on the civil rights movement, "Divided South Searches Its Soul", which appeared in the July 9, 1956 issue of "Life" magazine. A month later, Warren published an expanded version of the article as a small book titled "Segregation: The Inner Conflict in the South". He subsequently adopted a high profile as a supporter of racial integration. In 1965, he published "Who Speaks for the Negro?", a collection of interviews with black civil rights leaders including Malcolm X and Martin Luther King, thus further distinguishing his political leanings from the more conservative philosophies associated with fellow Agrarians such as Tate, Cleanth Brooks, and particularly Davidson. Warren's interviews with civil rights leaders are at the Louie B. Nunn Center for Oral History at the University of Kentucky.

Warren's best-known work is "All the King's Men", a novel that won the Pulitzer Prize in 1947. Main character Willie Stark resembles Huey Pierce Long (1893â1935), the radical populist governor of Louisiana whom Warren was able to observe closely while teaching at Louisiana State University in Baton Rouge from 1933 to 1942. "All the King's Men" became a highly successful film, starring Broderick Crawford and winning the Academy Award for Best Picture in 1949. A 2006 film adaptation by writer/director Steven Zaillian featured Sean Penn as Willie Stark and Jude Law as Jack Burden. The opera "Willie Stark" by Carlisle Floyd to his own libretto based on the novel was first performed in 1981.

Warren served as the Consultant in Poetry to the Library of Congress, 1944â1945 (later termed Poet Laureate), and won two Pulitzer Prizes in poetry, in 1958 for "Promises: Poems 1954â1956" and in 1979 for "Now and Then". "Promises" also won the annual National Book Award for Poetry.

In 1974, the National Endowment for the Humanities selected him for the Jefferson Lecture, the U.S. federal government's highest honor for achievement in the humanities. Warren's lecture was entitled "Poetry and Democracy" (subsequently published under the title "Democracy and Poetry"). In 1977, Warren was awarded the St. Louis Literary Award from the Saint Louis University Library Associates. In 1980, Warren was presented with the Presidential Medal of Freedom by President Jimmy Carter. In 1981, Warren was selected as a MacArthur Fellow and later was named as the first U.S. Poet Laureate Consultant in Poetry on February 26, 1986. In 1987, he was awarded the National Medal of Arts.

Warren was co-author, with Cleanth Brooks, of "Understanding Poetry", an influential literature textbook. It was followed by other similarly co-authored textbooks, including "Understanding Fiction", which was praised by Southern Gothic and Roman Catholic writer Flannery O'Connor, and "Modern Rhetoric", which adopted what can be called a New Critical perspective.

His first marriage was to Emma Brescia. His second marriage was in 1952 to Eleanor Clark, with whom he had two children, Rosanna Phelps Warren (born 1953) and Gabriel Penn Warren (born 1955). During his tenure at Louisiana State University he resided at Twin Oaks (otherwise known as the Robert Penn Warren House) in Prairieville, Louisiana. He lived the latter part of his life in Fairfield, Connecticut, and Stratton, Vermont where he died of complications from prostate cancer. He is buried at Stratton, Vermont, and, at his request, a memorial marker is situated in the Warren family gravesite in Guthrie, Kentucky.

In April 2005, the United States Postal Service issued a commemorative stamp to mark the 100th anniversary of Warren's birth. Introduced at the post office in his native Guthrie, it depicts the author as he appeared in a 1948 photograph, with a background scene of a political rally designed to evoke the setting of "All the King's Men". His son and daughter, Gabriel and Rosanna Warren, were in attendance.

Vanderbilt University houses the Robert Penn Warren Center for the Humanities, which is sponsored by the College of Arts and Science. It began its programs in January 1988, and in 1989 received a $480,000 Challenge Grant from the National Endowment for the Humanities. The center promotes "interdisciplinary research and study in the humanities, social sciences, and natural sciences."

The high school that Robert Penn Warren attended, Clarksville High School (Tennessee), was renovated into an apartment complex in 1982. The original name of the apartments was changed to The Penn Warren in 2010.





</doc>
<doc id="26308" url="https://en.wikipedia.org/wiki?curid=26308" title="Rudyard Kipling">
Rudyard Kipling

Joseph Rudyard Kipling ( ; 30 December 1865 â 18 January 1936) was an English journalist, short-story writer, poet, and novelist. He was born in India, which inspired much of his work.

Kipling's works of fiction include "The Jungle Book" (1894), "Kim" (1901), and many short stories, including "The Man Who Would Be King" (1888). His poems include "Mandalay" (1890), "Gunga Din" (1890), "The Gods of the Copybook Headings" (1919), "The White Man's Burden" (1899), and "Ifâ" (1910). He is seen as an innovator in the art of the short story. His children's books are classics; one critic noted "a versatile and luminous narrative gift." 

Kipling in the late 19th and early 20th centuries was among the United Kingdom's most popular writers. Henry James said, "Kipling strikes me personally as the most complete man of genius, as distinct from fine intelligence, that I have ever known." In 1907, he was awarded the Nobel Prize in Literature, as the first English-language writer to receive the prize, and at 41, its youngest recipient to date. He was also sounded for the British Poet Laureateship and several times for a knighthood, but declined both. Following his death in 1936, his ashes were interred at Poets' Corner, part of the South Transept of Westminster Abbey.

Kipling's subsequent reputation has changed with the political and social climate of the age. The contrasting views of him continued for much of the 20th century. George Orwell saw Kipling as "a jingo imperialist," who was "morally insensitive and aesthetically disgusting." Literary critic Douglas Kerr wrote: "[Kipling] is still an author who can inspire passionate disagreement and his place in literary and cultural history is far from settled. But as the age of the European empires recedes, he is recognised as an incomparable, if controversial, interpreter of how empire was experienced. That, and an increasing recognition of his extraordinary narrative gifts, make him a force to be reckoned with."

Rudyard Kipling was born on 30 December 1865 in Bombay, in the Bombay Presidency of British India, to Alice Kipling (nÃ©e MacDonald) and John Lockwood Kipling. Alice (one of the four noted MacDonald sisters) was a vivacious woman, of whom Lord Dufferin would say, "Dullness and Mrs Kipling cannot exist in the same room." Lockwood Kipling, a sculptor and pottery designer, was the Principal and Professor of Architectural Sculpture at the newly founded Sir Jamsetjee Jeejebhoy School of Art in Bombay.

John Lockwood and Alice had met in 1863 and courted at Rudyard Lake in Rudyard, Staffordshire, England. They married and moved to India in 1865. They had been so moved by the beauty of the Rudyard Lake area that they named their first child after it. Two of Alice's sisters were married to artists: Georgiana to the painter Edward Burne-Jones, and her sister Agnes to Edward Poynter. Kipling's most prominent relative was his first cousin, Stanley Baldwin, who was Conservative Prime Minister three times in the 1920s and 1930s.

Kipling's birth home on the campus of the J. J. School of Art in Bombay was for many years used as the Dean's residence. Although a cottage bears a plaque noting it as his birth site, the original one may have been torn down and replaced decades ago. Some historians and conservationists take the view that the bungalow marks a site merely close to the home of Kipling's birth, as it was built in 1882 â about 15 years after Kipling was born. Kipling seems to have said as much to the Dean when visiting J. J. School in the 1930s.
Kipling wrote of Bombay:
<poem>Mother of Cities to me,
For I was born in her gate,
Between the palms and the sea,
Where the world-end steamers wait.</poem>

According to Bernice M. Murphy, "Kipling's parents considered themselves 'Anglo-Indians' [a term used in the 19th century for people of British origin living in India] and so too would their son, though he spent the bulk of his life elsewhere. Complex issues of identity and national allegiance would become prominent in his fiction."

Kipling referred to such conflicts. For example: "In the afternoon heats before we took our sleep, she (the Portuguese "ayah", or nanny) or Meeta (the Hindu "bearer", or male attendant) would tell us stories and Indian nursery songs all unforgotten, and we were sent into the dining-room after we had been dressed, with the caution 'Speak English now to Papa and Mamma.' So one spoke 'English', haltingly translated out of the vernacular idiom that one thought and dreamed in."

Kipling's days of "strong light and darkness" in Bombay ended when he was five. As was the custom in British India, he and his three-year-old sister Alice ("Trix") were taken to the United Kingdom â in their case to Southsea, Portsmouth â to live with a couple who boarded children of British nationals living abroad. For the next six years (from October 1871 to April 1877), the children lived with the couple â Captain Pryse Agar Holloway, once an officer in the merchant navy, and Sarah Holloway â at their house, Lorne Lodge, 4 Campbell Road, Southsea.

In his autobiography published 65 years later, Kipling recalled the stay with horror, and wondered if the combination of cruelty and neglect which he experienced there at the hands of Mrs Holloway might not have hastened the onset of his literary life: "If you cross-examine a child of seven or eight on his day's doings (specially when he wants to go to sleep) he will contradict himself very satisfactorily. If each contradiction be set down as a lie and retailed at breakfast, life is not easy. I have known a certain amount of bullying, but this was calculated torture â religious as well as scientific. Yet it made me give attention to the lies I soon found it necessary to tell: and this, I presume, is the foundation of literary effort." 
Trix fared better at Lorne Lodge; Mrs Holloway apparently hoped that Trix would eventually marry the Holloways' son. The two Kipling children, however, had no relatives in England they could visit, except that they spent a month each Christmas with a maternal aunt Georgiana ("Georgy") and her husband, Edward Burne-Jones, at their house, The Grange, in Fulham, London, which Kipling called "a paradise which I verily believe saved me."

In the spring of 1877, Alice returned from India and removed the children from Lorne Lodge. Kipling remembers, "Often and often afterwards, the beloved Aunt would ask me why I had never told any one how I was being treated. Children tell little more than animals, for what comes to them they accept as eternally established. Also, badly-treated children have a clear notion of what they are likely to get if they betray the secrets of a prison-house before they are clear of it."

Alice took the children during Spring 1877 to Goldings Farm at Loughton, where a carefree summer and autumn was spent on the farm and adjoining Forest, some of the time with Stanley Baldwin. In January 1878, Kipling was admitted to the United Services College at Westward Ho!, Devon, a school recently founded to prepare boys for the army. It proved rough going for him at first, but later led to firm friendships and provided the setting for his schoolboy stories "Stalky & Co." (1899). While there, Kipling met and fell in love with Florence Garrard, who was boarding with Trix at Southsea (to which Trix had returned.) Florence became the model for Maisie in Kipling's first novel, "The Light That Failed" (1891).

Near the end of his schooling, it was decided that Kipling did not have the academic ability to get into Oxford University on a scholarship. His parents lacked the wherewithal to finance him, and so Kipling's father obtained him a job in Lahore, where the father served as Principal of the Mayo College of Art and Curator of the Lahore Museum. Kipling was to be assistant editor of a local newspaper, the "Civil and Military Gazette".

He sailed for India on 20 September 1882 and arrived in Bombay on 18 October. He described the moment years later: "So, at sixteen years and nine months, but looking four or five years older, and adorned with real whiskers which the scandalised Mother abolished within one hour of beholding, I found myself at Bombay where I was born, moving among sights and smells that made me deliver in the vernacular sentences whose meaning I knew not. Other Indian-born boys have told me how the same thing happened to them." This arrival changed Kipling, as he explains: "There were yet three or four days' rail to Lahore, where my people lived. After these, my English years fell away, nor ever, I think, came back in full strength." 

From 1883 to 1889, Kipling worked in British India for local newspapers such as the "Civil and Military Gazette" in Lahore and "The Pioneer" in Allahabad.

The former, which was the newspaper Kipling was to call his "mistress and most true love," appeared six days a week throughout the year, except for one-day breaks for Christmas and Easter. Stephen Wheeler, the editor, worked Kipling hard, but Kipling's need to write was unstoppable. In 1886, he published his first collection of verse, "Departmental Ditties." That year also brought a change of editors at the newspaper; Kay Robinson, the new editor, allowed more creative freedom and Kipling was asked to contribute short stories to the newspaper.

In an article printed in the "Chums" boys' annual, an ex-colleague of Kipling's stated that "he never knew such a fellow for ink â he simply revelled in it, filling up his pen viciously, and then throwing the contents all over the office, so that it was almost dangerous to approach him." The anecdote continues: "In the hot weather when he (Kipling) wore only white trousers and a thin vest, he is said to have resembled a Dalmatian dog more than a human being, for he was spotted all over with ink in every direction."

In the summer of 1883, Kipling visited Shimla, then Simla, a well-known hill station and the summer capital of British India. By then it was the practice for the Viceroy of India and government to move to Simla for six months, and the town became a "centre of power as well as pleasure." Kipling's family became annual visitors to Simla, and Lockwood Kipling was asked to serve in Christ Church there. Rudyard Kipling returned to Simla for his annual leave each year from 1885 to 1888, and the town featured prominently in many stories he wrote for the "Gazette". "My month's leave at Simla, or whatever Hill Station my people went to, was pure joy â every golden hour counted. It began in heat and discomfort, by rail and road. It ended in the cool evening, with a wood fire in one's bedroom, and next morn â thirty more of them ahead! â the early cup of tea, the Mother who brought it in, and the long talks of us all together again. One had leisure to work, too, at whatever play-work was in one's head, and that was usually full."

Back in Lahore, 39 of his stories appeared in the "Gazette" between November 1886 and June 1887. Kipling included most of them in "Plain Tales from the Hills", his first prose collection, published in Calcutta in January 1888, a month after his 22nd birthday. Kipling's time in Lahore, however, had come to an end. In November 1887, he was moved to the "Gazette"s larger sister newspaper, "The Pioneer", in Allahabad in the United Provinces, where worked as assistant editor and lived in Belvedere House from 1888 to 1889.
Kipling's writing continued at a frenetic pace. In 1888, he published six collections of short stories: "Soldiers Three", "The Story of the Gadsbys", "In Black and White", "Under the Deodars", "The Phantom Rickshaw", and "Wee Willie Winkie". These contain a total of 41 stories, some quite long. In addition, as "The Pioneer"s special correspondent in the western region of Rajputana, he wrote many sketches that were later collected in "Letters of Marque" and published in "From Sea to Sea and Other Sketches, Letters of Travel".

Kipling was discharged from "The Pioneer" in early 1889 after a dispute. By this time, he had been increasingly thinking of his future. He sold the rights to his six volumes of stories for Â£200 and a small royalty, and the "Plain Tales" for Â£50; in addition, he received six-months' salary from "The Pioneer", "in lieu" of notice.

Kipling decided to use the money to move to London, as the literary centre of the British Empire. On 9 March 1889, he left India, travelling first to San Francisco via Rangoon, Singapore, Hong Kong, and Japan. Kipling was favourably impressed by Japan, calling its people "gracious folk and fair manners." 

Kipling later wrote that he "had lost his heart" to a geisha whom he called O-Toyo, writing while in the United States during the same trip across the Pacific, "I had left the innocent East far behind... Weeping softly for O-Toyo... O-Toyo was a darling." Kipling then travelled through the United States, writing articles for "The Pioneer" that were later published in "From Sea to Sea and Other Sketches, Letters of Travel".

Starting his North American travels in San Francisco, Kipling went north to Portland, Oregon, then Seattle, Washington, up to Victoria and Vancouver, British Columbia, through Medicine Hat, Alberta, back into the US to Yellowstone National Park, down to Salt Lake City, then east to Omaha, Nebraska and on to Chicago, Illinois, then to Beaver, Pennsylvania on the Ohio River to visit the Hill family. From there, he went to Chautauqua with Professor Hill, and later to Niagara Falls, Toronto, Washington, D.C., New York, and Boston.

In the course of this journey he met Mark Twain in Elmira, New York, and was deeply impressed. Kipling arrived unannounced at Twain's home, and later wrote that as he rang the doorbell, "It occurred to me for the first time that Mark Twain might possibly have other engagements other than the entertainment of escaped lunatics from India, be they ever so full of admiration."

As it was, Twain gladly welcomed Kipling and had a two-hour conversation with him on trends in Anglo-American literature and about what Twain was going to write in a sequel to "Tom Sawyer", with Twain assuring Kipling that a sequel was coming, although he had not decided upon the ending: either Sawyer would be elected to Congress or he would be hanged. Twain also passed along the literary advice that an author should "get your facts first and then you can distort 'em as much as you please." Twain, who rather liked Kipling, later wrote of their meeting: "Between us, we cover all knowledge; he covers all that can be known and I cover the rest." Kipling then crossed the Atlantic to Liverpool in October 1889. He soon made his dÃ©but in the London literary world, to great acclaim.

In London, Kipling had several stories accepted by magazines. He found a place to live for the next two years at Villiers Street, near Charing Cross (in a building subsequently named Kipling House):
Meantime, I had found me quarters in Villiers Street, Strand, which forty-six years ago was primitive and passionate in its habits and population. My rooms were small, not over-clean or well-kept, but from my desk I could look out of my window through the fanlight of Gatti's Music-Hall entrance, across the street, almost on to its stage. The Charing Cross trains rumbled through my dreams on one side, the boom of the Strand on the other, while, before my windows, Father Thames under the Shot tower walked up and down with his traffic.

In the next two years, he published a novel, "The Light That Failed", had a nervous breakdown, and met an American writer and publishing agent, Wolcott Balestier, with whom he collaborated on a novel, "The Naulahka" (a title which he uncharacteristically misspelt; see below). In 1891, as advised his doctors, Kipling took another sea voyage, to South Africa, Australia, New Zealand, and once again India. He cut short his plans to spend Christmas with his family in India when he heard of Balestier's sudden death from typhoid fever and decided to return to London immediately. Before his return, he had used the telegram to propose to and be accepted by Wolcott's sister Caroline Starr Balestier (1862â1939), called "Carrie," whom he had met a year earlier, and with whom he had apparently been having an intermittent romance. Meanwhile, late in 1891, a collection of his short stories on the British in India, "Life's Handicap", was published in London.

On 18 January 1892, Carrie Balestier (aged 29) and Rudyard Kipling (aged 26) married in London, in the "thick of an influenza epidemic, when the undertakers had run out of black horses and the dead had to be content with brown ones." The wedding was held at All Souls Church, Langham Place. Henry James gave the bride away.

Kipling and his wife settled upon a honeymoon that took them first to the United States (including a stop at the Balestier family estate near Brattleboro, Vermont) and then to Japan. On arriving in Yokohama, they discovered that their bank, The New Oriental Banking Corporation, had failed. Taking this loss in their stride, they returned to the US, back to Vermont â Carrie by this time was pregnant with their first child â and rented a small cottage on a farm near Brattleboro for $10 a month. According to Kipling, "We furnished it with a simplicity that fore-ran the hire-purchase system. We bought, second or third hand, a huge, hot-air stove which we installed in the cellar. We cut generous holes in our thin floors for its eight-inch [20 cm] tin pipes (why we were not burned in our beds each week of the winter I never can understand) and we were extraordinarily and self-centredly content."

In this house, which they called "Bliss Cottage", their first child, Josephine, was born "in three-foot of snow on the night of 29 December 1892. Her Mother's birthday being the 31st and mine the 30th of the same month, we congratulated her on her sense of the fitness of things..."
It was also in this cottage that the first dawnings of "The Jungle Books" came to Kipling: "The workroom in the Bliss Cottage was seven feet by eight, and from December to April, the snow lay level with its window-sill. It chanced that I had written a tale about Indian Forestry work which included a boy who had been brought up by wolves. In the stillness, and suspense, of the winter of '92 some memory of the Masonic Lions of my childhood's magazine, and a phrase in Haggard's "Nada the Lily", combined with the echo of this tale. After blocking out the main idea in my head, the pen took charge, and I watched it begin to write stories about Mowgli and animals, which later grew into the two "Jungle Books"."

With Josephine's arrival, "Bliss Cottage" was felt to be congested, so eventually the couple bought land â on a rocky hillside overlooking the Connecticut River â from Carrie's brother Beatty Balestier and built their own house. Kipling named this Naulakha, in honour of Wolcott and of their collaboration, and this time the name was spelt correctly. From his early years in Lahore (1882â87), Kipling had become enamoured with the Mughal architecture, especially the Naulakha pavilion situated in Lahore Fort, which eventually inspired the title of his novel as well as the house. The house still stands on Kipling Road, three miles (5Â km) north of Brattleboro in Dummerston, Vermont: a big, secluded, dark-green house, with shingled roof and sides, which Kipling called his "ship," and which brought him "sunshine and a mind at ease." His seclusion in Vermont, combined with his healthy "sane clean life," made Kipling both inventive and prolific.

In a mere four years he produced, along with the "Jungle Books", a book of short stories ("The Day's Work"), a novel ("Captains Courageous"), and a profusion of poetry, including the volume "The Seven Seas". The collection of "Barrack-Room Ballads" was issued in March 1892, first published individually for the most part in 1890, and contained his poems "Mandalay" and "Gunga Din." He especially enjoyed writing the "Jungle Books" and also corresponding with many children who wrote to him about them.

The writing life in "Naulakha" was occasionally interrupted by visitors, including his father, who visited soon after his retirement in 1893, and the British writer Arthur Conan Doyle, who brought his golf clubs, stayed for two days, and gave Kipling an extended golf lesson. Kipling seemed to take to golf, occasionally practising with the local Congregational minister and even playing with red-painted balls when the ground was covered in snow. However, winter golf was "not altogether a success because there were no limits to a drive; the ball might skid two miles (3 km) down the long slope to Connecticut river." 

Kipling loved the outdoors, not least of whose marvels in Vermont was the turning of the leaves each fall. He described this moment in a letter: "A little maple began it, flaming blood-red of a sudden where he stood against the dark green of a pine-belt. Next morning there was an answering signal from the swamp where the sumacs grow. Three days later, the hill-sides as fast as the eye could range were afire, and the roads paved, with crimson and gold. Then a wet wind blew, and ruined all the uniforms of that gorgeous army; and the oaks, who had held themselves in reserve, buckled on their dull and bronzed cuirasses and stood it out stiffly to the last blown leaf, till nothing remained but pencil-shadings of bare boughs, and one could see into the most private heart of the woods."
In February 1896, Elsie Kipling was born, the couple's second daughter. By this time, according to several biographers, their marital relationship was no longer light-hearted and spontaneous. Although they would always remain loyal to each other, they seemed now to have fallen into set roles. In a letter to a friend who had become engaged around this time, the 30âyearâold Kipling offered this sombre counsel: marriage principally taught "the tougher virtues â such as humility, restraint, order, and forethought."

The Kiplings loved life in Vermont and might have lived out their lives there, were it not for two incidents â one of global politics, the other of family discord. By the early 1890s, the United Kingdom and Venezuela were in a border dispute involving British Guiana. The US had made several offers to arbitrate, but in 1895, the new American Secretary of State Richard Olney upped the ante by arguing for the American "right" to arbitrate on grounds of sovereignty on the continent (see the Olney interpretation as an extension of the Monroe Doctrine). This raised hackles in Britain, and the situation grew into a major Anglo-American crisis, with talk of war on both sides.

Although the crisis eased into greater USâBritish cooperation, Kipling was bewildered by what he felt was persistent anti-British sentiment in the US, especially in the press. He wrote in a letter that it felt like being "aimed at with a decanter across a friendly dinner table." By January 1896, he had decided to end his family's "good wholesome life" in the US and seek their fortunes elsewhere.

A family dispute became the final straw. For some time, relations between Carrie and her brother Beatty Balestier had been strained, owing to his drinking and insolvency. In May 1896, an inebriated Beatty encountered Kipling on the street and threatened him with physical harm. The incident led to Beatty's eventual arrest, but in the subsequent hearing and the resulting publicity, Kipling's privacy was destroyed, and he was left feeling miserable and exhausted. In July 1896, a week before the hearing was to resume, the Kiplings packed their belongings, left the United States and returned to England.

By September 1896, the Kiplings were in Torquay, Devon, on the south-western coast of England, in a hillside home overlooking the English Channel. Although Kipling did not much care for his new house, whose design, he claimed, left its occupants feeling dispirited and gloomy, he managed to remain productive and socially active.

Kipling was now a famous man, and in the previous two or three years had increasingly been making political pronouncements in his writings. The Kiplings had welcomed their first son, John, in August 1897. Kipling had begun work on two poems, "Recessional" (1897) and "The White Man's Burden" (1899), which were to create controversy when published. Regarded by some as anthems for enlightened and duty-bound empire-building (capturing the mood of the Victorian era), the poems were seen by others as propaganda for brazen-faced imperialism and its attendant racial attitudes; still others saw irony in the poems and warnings of the perils of empire.

<poem>Take up the White Man's burdenâ
Send forth the best ye breedâ
Go, bind your sons to exile
To serve your captives' need;
To wait, in heavy harness,
On fluttered folk and wildâ
Your new-caught sullen peoples,
Half devil and half child.
â"The White Man's Burden"
</poem>

There was also foreboding in the poems, a sense that all could yet come to naught.

<poem>Far-called, our navies melt away;
On dune and headland sinks the fire:
Lo, all our pomp of yesterday
Is one with Nineveh and Tyre!
Judge of the Nations, spare us yet.
Lest we forget â lest we forget!
â"Recessional"</poem>

A prolific writer during his time in Torquay, he also wrote "Stalky & Co.", a collection of school stories (born of his experience at the United Services College in Westward Ho!), whose juvenile protagonists display a know-it-all, cynical outlook on patriotism and authority. According to his family, Kipling enjoyed reading aloud stories from "Stalky & Co." to them and often went into spasms of laughter over his own jokes.

In early 1898, the Kiplings travelled to South Africa for their winter holiday, so beginning an annual tradition which (except the following year) would last until 1908. They would stay in "The Woolsack," a house on Cecil Rhodes's estate at Groote Schuur (now a student residence for the University of Cape Town), within walking distance of Rhodes' mansion.

With his new reputation as "Poet of the Empire", Kipling was warmly received by some of the influential politicians of the Cape Colony, including Rhodes, Sir Alfred Milner, and Leander Starr Jameson. Kipling cultivated their friendship and came to admire the men and their politics. The period 1898â1910 was crucial in the history of South Africa and included the Second Boer War (1899â1902), the ensuing peace treaty, and the 1910 formation of the Union of South Africa. Back in England, Kipling wrote poetry in support of the British cause in the Boer War and on his next visit to South Africa in early 1900, became a correspondent for "The Friend" newspaper in Bloemfontein, which had been commandeered by Lord Roberts for British troops.

Although his journalistic stint was to last only two weeks, it was Kipling's first work on a newspaper staff since he left "The Pioneer" in Allahabad more than ten years before. At "The Friend", he made lifelong friendships with Perceval Landon, H. A. Gwynne, and others. He also wrote articles published more widely expressing his views on the conflict. Kipling penned an inscription for the Honoured Dead Memorial (Siege memorial) in Kimberley.

In 1897, Kipling moved from Torquay to Rottingdean, East Sussex â first to "North End House" and then to "The Elms". In 1902, Kipling bought Bateman's, a house built in 1634 and located in rural Burwash.

Bateman's was Kipling's home from 1902 until his death in 1936. The house and its surrounding buildings, the mill and , were bought for Â£9,300. It had no bathroom, no running water upstairs and no electricity, but Kipling loved it: "Behold us, lawful owners of a grey stone lichened house â A.D. 1634 over the door â beamed, panelled, with old oak staircase, and all untouched and unfaked. It is a good and peaceable place. We have loved it ever since our first sight of it" (from a November 1902 letter).

In the non-fiction realm, he became involved in the debate over the British response to the rise in German naval power known as the Tirpitz Plan, to build a fleet to challenge the Royal Navy, publishing a series of articles in 1898 collected as "A Fleet in Being". On a visit to the United States in 1899, Kipling and his daughter Josephine developed pneumonia, from which she eventually died.
In the wake of his daughter's death, Kipling concentrated on collecting material for what became "Just So Stories for Little Children", published in 1902, the year after "Kim". The American literary scholar David Scott has argued that "Kim" disproves the claim by Edward Said about Kipling as a promoter of Orientalism as Kipling â who was deeply interested in Buddhism â as he presented Tibetan Buddhism in a fairly sympathetic light and aspects of the novel appeared to reflect a Buddhist understanding of the universe. Kipling was offended by the German Emperor Wilhelm II's "Hun speech ()" in 1900, urging German troops being sent to China to crush the Boxer Rebellion to behave like "Huns" and take no prisoners.

In a 1902 poem, "The Rowers", Kipling attacked the Kaiser as a threat to Britain and made the first use of the term "Hun" as an anti-German insult, using Wilhelm's own words and the actions of German troops in China to portray Germans as essentially barbarian. In an interview with the French newspaper "Le Figaro", the Francophile Kipling called Germany a menace and called for an Anglo-French alliance to stop it. In another letter at the same time, Kipling described the ""unfrei" peoples of Central Europe" as living in "the Middle Ages with machine guns." 

Kipling wrote a number of speculative fiction short stories, including "The Army of a Dream," in which he sought to show a more efficient and responsible army than the hereditary bureaucracy of England at the time, and two science fiction stories: "With the Night Mail" (1905) and "As Easy As A.B.C." (1912). Both were set in the 21st century in Kipling's Aerial Board of Control universe. They read like modern hard science fiction, and introduced the literary technique known as indirect exposition, which would later become one of science fiction writer Robert Heinlein's hallmarks. This technique is one that Kipling picked up in India, and used to solve the problem of his English readers not understanding much about Indian society, when writing "The Jungle Book".

In 1907, he was awarded the Nobel Prize for Literature, having been nominated in that year by Charles Oman, professor at the University of Oxford. The prize citation said it was "in consideration of the power of observation, originality of imagination, virility of ideas and remarkable talent for narration which characterize the creations of this world-famous author." Nobel prizes had been established in 1901 and Kipling was the first English-language recipient. At the award ceremony in Stockholm on 10 December 1907, the Permanent Secretary of the Swedish Academy, Carl David af WirsÃ©n, praised both Kipling and three centuries of English literature:

The Swedish Academy, in awarding the Nobel Prize in Literature this year to Rudyard Kipling, desires to pay a tribute of homage to the literature of England, so rich in manifold glories, and to the greatest genius in the realm of narrative that that country has produced in our times.

To "book-end" this achievement came the publication of two connected poetry and story collections: "Puck of Pook's Hill" (1906), and "Rewards and Fairies" (1910). The latter contained the poem "Ifâ." In a 1995 BBC opinion poll, it was voted the UK's favourite poem. This exhortation to self-control and stoicism is arguably Kipling's most famous poem.
Such was Kipling's popularity that he was asked by his friend Max Aitken to intervene in the 1911 Canadian election on behalf of the Conservatives. In 1911, the major issue in Canada was a reciprocity treaty with the United States signed by the Liberal Prime Minister Sir Wilfrid Laurier and vigorously opposed by the Conservatives under Sir Robert Borden. On 7 September 1911, the "Montreal Daily Star" newspaper published a front-page appeal against the agreement by Kipling, who wrote: "It is her own soul that Canada risks today. Once that soul is pawned for any consideration, Canada must inevitably conform to the commercial, legal, financial, social, and ethical standards which will be imposed on her by the sheer admitted weight of the United States." At the time, the "Montreal Daily Star" was Canada's most read newspaper. Over the next week, Kipling's appeal was reprinted in every English newspaper in Canada and is credited with helping to turn Canadian public opinion against the Liberal government.

Kipling sympathised with the anti-Home Rule stance of Irish Unionists, who opposed Irish autonomy. He was friends with Edward Carson, the Dublin-born leader of Ulster Unionism, who raised the Ulster Volunteers to prevent Home Rule in Ireland. Kipling wrote in a letter to a friend that Ireland was not a nation, and that before the English arrived in 1169, the Irish were a gang of cattle thieves living in savagery and killing each other while "writing dreary poems" about it all. In his view it was only British rule that allowed Ireland to advance. A visit to Ireland in 1911 confirmed Kipling's prejudices. He wrote that the Irish countryside was beautiful, but spoiled by what he called the ugly homes of Irish farmers, with Kipling adding that God had made the Irish into poets having "deprived them of love of line or knowledge of colour." In contrast, Kipling had nothing but praise for the "decent folk" of the Protestant majority and Unionist Ulster.

Kipling wrote the poem ""Ulster"" in 1912, reflecting his Unionist politics. Kipling often referred to the Irish Unionists as "our party." Kipling had no sympathy or understanding for Irish nationalism, seeing Home Rule as an act of treason by the government of the Liberal Prime Minister H. H. Asquith that would plunge Ireland into the Dark Ages and allow the Irish Catholic majority to oppress the Protestant minority. The scholar David Gilmour wrote that Kipling's lack of understanding of Ireland could be seen in his attack on John Redmond â the Anglophile leader of the Irish Parliamentary Party who wanted Home Rule because he believed it was the best way of keeping the United Kingdom together â as a traitor working to break up the United Kingdom. "Ulster" was first publicly read at an Unionist rally in Belfast, where the largest Union Jack ever made was unfolded. Kipling admitted it was meant to strike a "hard blow" against the Asquith government's Home Rule bill: "Rebellion, rapine, hate, Oppression, wrong and greed, Are loosed to rule our fate, By England's act and deed." "Ulster" generated much controversy with the Conservative MP Sir Mark Sykes â who as a Unionist was opposed to the Home Rule bill â condemning "Ulster" in "The Morning Post" as a "direct appeal to ignorance and a deliberate attempt to foster religious hate." 

Kipling was a staunch opponent of Bolshevism, a position which he shared with his friend Henry Rider Haggard. The two had bonded on Kipling's arrival in London in 1889 largely due to their shared opinions, and remained lifelong friends.

According to the English magazine "Masonic Illustrated", Kipling became a Freemason in about 1885, before the usual minimum age of 21, being initiated into Hope and Perseverance Lodge No. 782 in Lahore. He later wrote to "The Times", "I was Secretary for some years of the Lodge... which included Brethren of at least four creeds. I was entered [as an Apprentice] by a member from Brahmo Somaj, a Hindu, passed [to the degree of Fellow Craft] by a Mohammedan, and raised [to the degree of Master Mason] by an Englishman. Our Tyler was an Indian Jew." Kipling received not only the three degrees of Craft Masonry but also the side degrees of Mark Master Mason and Royal Ark Mariner.

Kipling so loved his Masonic experience that he memorialised its ideals in his poem "The Mother Lodge," and used the fraternity and its symbols as vital plot devices in his novella "The Man Who Would Be King".

At the beginning of the First World War, like many other writers, Kipling wrote pamphlets and poems enthusiastically supporting the UK war aims of restoring Belgium, after it had been occupied by Germany, together with generalised statements that Britain was standing up for the cause of good. In September 1914, Kipling was asked by the government to write propaganda, an offer that he accepted. Kipling's pamphlets and stories were popular with the British people during the war, his major themes being to glorify the British military as "the" place for heroic men to be, while citing German atrocities against Belgian civilians and the stories of women brutalised by a horrific war unleashed by Germany, yet surviving and triumphing in spite of their suffering.

Kipling was enraged by reports of the Rape of Belgium together with the sinking of the in 1915, which he saw as a deeply inhumane act, which led him to see the war as a crusade for civilisation against barbarism. In a 1915 speech, Kipling declared, "There was no crime, no cruelty, no abomination that the mind of men can conceive of which the German has not perpetrated, is not perpetrating, and will not perpetrate if he is allowed to go on... Today, there are only two divisions in the world... human beings and Germans."

Alongside his passionate antipathy towards Germany, Kipling was privately deeply critical of how the war was being fought by the British Army, complaining as early as October 1914 that Germany should have been defeated by now, and something must be wrong with the British Army. Kipling, who was shocked by the heavy losses that the British Expeditionary Force had taken by the autumn of 1914, blamed the entire pre-war generation of British politicians who, he argued, had failed to learn the lessons of the Boer War. Thus thousands of British soldiers were now paying with their lives for their failure in the fields of France and Belgium.

Kipling had scorn for men who shirked duty in the First World War. In "The New Army in Training" (1915), Kipling concluded by saying:
This much we can realise, even though we are so close to it, the old safe instinct saves us from triumph and exultation. But what will be the position in years to come of the young man who has deliberately elected to outcaste himself from this all-embracing brotherhood? What of his family, and, above all, what of his descendants, when the books have been closed and the last balance struck of sacrifice and sorrow in every hamlet, village, parish, suburb, city, shire, district, province, and Dominion throughout the Empire?

Kipling's son John was killed in action at the Battle of Loos in September 1915, at age 18. John had initially wanted to join the Royal Navy, but having had his application turned down after a failed medical examination due to poor eyesight, he opted to apply for military service as an army officer. But again, his eyesight was an issue during the medical examination. In fact, he tried twice to enlist, but was rejected. His father had been lifelong friends with Lord Roberts, former commander-in-chief of the British Army, and colonel of the Irish Guards, and at Rudyard's request, John was accepted into the Irish Guards.

John Kipling was sent to Loos two days into the battle in a reinforcement contingent. He was last seen stumbling through the mud blindly, with a possible facial injury. A body identified as his was found in 1992, although that identification has been challenged. In 2015, the Commonwealth War Grave Commission confirmed that they had correctly identified the burial place of John Kipling; they record his date of death as 27 September 1915, and that he is buried at St Mary's A.D.S. Cemetery, Haisnes.

After his son's death, in a poem entitled "Epitaphs of the War," Kipling wrote, "If any question why we died / Tell them, because our fathers lied." Critics have speculated that these words may express Kipling's guilt over his role in arranging John's commission. Professor Tracy Bilsing contends that the line refers to Kipling's disgust that British leaders failed to learn the lessons of the Boer War, and were unprepared for the struggle with Germany in 1914, with the "lie" of the "fathers" being that the British Army was prepared for any war when it was not.

John's death has been linked to Kipling's 1916 poem "My Boy Jack," notably in the play "My Boy Jack" and its subsequent television adaptation, along with the documentary "". However, the poem was originally published at the head of a story about the Battle of Jutland and appears to refer to a death at sea; the "Jack" referred to is probably a generic "Jack Tar." In the Kipling family, Jack was the name of the family dog, while John Kipling was always John, making the identification of the protagonist of "My Boy Jack" with John Kipling somewhat questionable. However, Kipling was indeed emotionally devastated by the death of his son. He is said to have assuaged his grief by reading the novels of Jane Austen aloud to his wife and daughter. During the war, he wrote a booklet "The Fringes of the Fleet" containing essays and poems on various nautical subjects of the war. Some of these were set to music by the English composer Edward Elgar.

Kipling became friends with a French soldier named Maurice Hammoneau, whose life had been saved in the First World War when his copy of "Kim", which he had in his left breast pocket, stopped a bullet. Hammoneau presented Kipling with the book, with bullet still embedded, and his Croix de Guerre as a token of gratitude. They continued to correspond, and when Hammoneau had a son, Kipling insisted on returning the book and medal.

On 1 August 1918, a poem, "The Old Volunteer," appeared under his name in "The Times". The next day, he wrote to the newspaper to disclaim authorship and a correction appeared. Although "The Times" employed a private detective to investigate, the detective appears to have suspected Kipling himself of being the author, and the identity of the hoaxer was never established.

Partly in response to John's death, Kipling joined Sir Fabian Ware's Imperial War Graves Commission (now the Commonwealth War Graves Commission), the group responsible for the garden-like British war graves that can be found to this day dotted along the former Western Front and the other places in the world where British Empire troops lie buried. His main contributions to the project were his selection of the biblical phrase, "Their Name Liveth For Evermore" (Ecclesiasticus 44.14, KJV), found on the Stones of Remembrance in larger war cemeteries, and his suggestion of the phrase "Known unto God" for the gravestones of unidentified servicemen. He also chose the inscription "The Glorious Dead" on the Cenotaph, Whitehall, London. Additionally, he wrote a two-volume history of the Irish Guards, his son's regiment, published in 1923 and seen as one of the finest examples of regimental history.

Kipling's short story "The Gardener" depicts visits to the war cemeteries, and the poem "The King's Pilgrimage" (1922) a journey which King George V made, touring the cemeteries and memorials under construction by the Imperial War Graves Commission. With the increasing popularity of the automobile, Kipling became a motoring correspondent for the British press, writing enthusiastically of trips around England and abroad, though he was usually driven by a chauffeur.

After the war, Kipling was sceptical of the Fourteen Points and the League of Nations, but had hopes that the United States would abandon isolationism and the post-war world be dominated by an Anglo-French-American alliance. He hoped the United States would take on a League of Nations mandate for Armenia as the best way of preventing isolationism, and hoped that Theodore Roosevelt, whom Kipling admired, would again become president. Kipling was saddened by Roosevelt's death in 1919, believing him to be the only American politician capable of keeping the United States in the "game" of world politics.

Kipling was hostile towards communism, writing of the Bolshevik take-over in 1917 that one sixth of the world had "passed bodily out of civilization." In a 1918 poem, Kipling wrote of Soviet Russia that everything good in Russia had been destroyed by the Bolsheviks â all that was left was "the sound of weeping and the sight of burning fire, and the shadow of a people trampled into the mire." 

In 1920, Kipling co-founded the Liberty League with Haggard and Lord Sydenham. This short-lived enterprise focused on promoting classic liberal ideals as a response to the rising power of communist tendencies within Great Britain, or as Kipling put it, "to combat the advance of Bolshevism." 
In 1922, Kipling, having referred to the work of engineers in some of his poems, such as "The Sons of Martha," "Sappers," and "McAndrew's Hymn," and in other writings, including short-story anthologies such as "The Day's Work", was asked by a University of Toronto civil engineering professor, Herbert E. T. Haultain, for assistance in developing a dignified obligation and ceremony for graduating engineering students. Kipling was enthusiastic in his response and shortly produced both, formally entitled "The Ritual of the Calling of an Engineer." Today engineering graduates all across Canada are presented with an iron ring at a ceremony to remind them of their obligation to society. In 1922 Kipling became Lord Rector of St Andrews University in Scotland, a three-year position.

Kipling, as a Francophile, argued strongly for an Anglo-French alliance to uphold the peace, calling Britain and France in 1920 the "twin fortresses of European civilization." Similarly, Kipling repeatedly warned against revising the Treaty of Versailles in Germany's favour, which he predicted would lead to a new world war. An admirer of Raymond PoincarÃ©, Kipling was one of few British intellectuals who supported the French Occupation of the Ruhr in 1923, at a time when the British government and most public opinion was against the French position. In contrast to the popular British view of PoincarÃ© as a cruel bully intent on impoverishing Germany with unreasonable reparations, Kipling argued that he was rightfully trying to preserve France as a great power in the face of an unfavourable situation. Kipling argued that even before 1914, Germany's larger economy and higher birth rate had made that country stronger than France; with much of France devastated by war and the French suffering heavy losses meant that its low birth rate would give it trouble, while Germany was mostly undamaged and still with a higher birth rate. So he reasoned that the future would bring German domination if Versailles were revised in Germany's favour, and it was madness for Britain to pressurise France into doing so.
In 1924, Kipling was opposed to the Labour government of Ramsay MacDonald as "Bolshevism without bullets." He believed that Labour was a communist front organisation, and "excited orders and instructions from Moscow" would expose Labour as such to the British people. Kipling's views were on the right. Though he admired Benito Mussolini to some extent in the 1920s, he was against fascism, calling Oswald Mosley was "a bounder and an "arriviste"." By 1935, he was calling Mussolini a deranged and dangerous egomaniac and in 1933 wrote, "The Hitlerites are out for blood." 

Despite his anti-communism, the first major translations of Kipling into Russian took place under Lenin's rule in the early 1920s, and Kipling was popular with Russian readers in the interwar period. Many younger Russian poets and writers, such as Konstantin Simonov, were influenced by him. Kipling's clarity of style, use of colloquial language and employment of rhythm and rhyme were seen as major innovations in poetry that appealed to many younger Russian poets.
Though it was obligatory for Soviet journals to begin translations of Kipling with an attack on him as a "fascist" and an "imperialist," such was Kipling's popularity with Russian readers that his works were not banned in the Soviet Union until 1939, with the signing of the MolotovâRibbentrop Pact. The ban was lifted in 1941 after Operation Barbarossa, when Britain become a Soviet ally, but imposed for good with the Cold War in 1946.

Many older editions of Rudyard Kipling's books have a swastika printed on the cover, associated with a picture of an elephant carrying a lotus flower, reflecting the influence of Indian culture. Kipling's use of the swastika was based on the Indian sun symbol conferring good luck and the Sanskrit word meaning "fortunate" or "well-being." He used the swastika symbol in both right and left-facing forms, and it was in general use by others at the time.

In a note to Edward Bok after the death of Lockwood Kipling in 1911, Rudyard said: "I am sending with this for your acceptance, as some little memory of my father to whom you were so kind, the original of one of the plaques that he used to make for me. I thought it being the Swastika would be appropriate for your Swastika. May it bring you even more good fortune." Once the Nazis came to power and usurped the swastika, Kipling ordered that it should no longer adorn his books. Less than a year before his death, Kipling gave a speech (titled "An Undefended Island") to the Royal Society of St George on 6 May 1935, warning of the danger which Nazi Germany posed to Britain.

Kipling scripted the first Royal Christmas Message, delivered via the BBC's Empire Service by George V in 1932. In 1934, he published a short story in "The Strand Magazine", "Proofs of Holy Writ," postulating that William Shakespeare had helped to polish the prose of the King James Bible.

Kipling kept writing until the early 1930s, but at a slower pace and with less success than before. On the night of 12 January 1936 he suffered a haemorrhage in his small intestine. He underwent surgery, but died less than a week later on 18 January 1936, at the age of 70 of a perforated duodenal ulcer. His death had previously been incorrectly announced in a magazine, to which he wrote, "I've just read that I am dead. Don't forget to delete me from your list of subscribers."

The pallbearers at the funeral included Kipling's cousin, Prime Minister Stanley Baldwin, and the marble casket was covered by a Union Jack. Kipling was cremated at Golders Green Crematorium in north-west London, and his ashes interred at Poets' Corner, part of the South Transept of Westminster Abbey, next to the graves of Charles Dickens and Thomas Hardy. Kipling's will was proven on 6 April, with his estate valued at Â£168,141 2s. 11d. (roughly equivalent to Â£ in ).

In 2010, the International Astronomical Union approved that a crater on the planet Mercury should be named after Kipling â one of ten newly discovered impact craters observed by the MESSENGER spacecraft in 2008â2009. In 2012, an extinct species of crocodile, "Goniopholis kiplingi", was named in his honour "in recognition for his enthusiasm for natural sciences." 

More than 50 unpublished poems by Kipling, discovered by the American scholar Thomas Pinney, were released for the first time in March 2013.

Kipling's writing has strongly influenced that of others. His stories for adults remain in print and have garnered high praise from writers as different as Poul Anderson, Jorge Luis Borges, and Randall Jarrell, who wrote, "After you have read Kipling's fifty or seventy-five best stories you realize that few men have written this many stories of this much merit, and that very few have written more and better stories."

His children's stories remain popular and his "Jungle Books" made into several films. The first was made by producer Alexander Korda. Other films have been produced by The Walt Disney Company. A number of his poems were set to music by Percy Grainger. A series of short films based on some of his stories was broadcast by the BBC in 1964. Kipling's work is still popular today.

The poet T. S. Eliot edited "A Choice of Kipling's Verse" (1941) with an introductory essay. Eliot was aware of the complaints that had been levelled against Kipling and he dismissed them one by one: that Kipling is "a Tory" using his verse to transmit right wing political views, or "a journalist" pandering to popular taste; while Eliot writes, "I cannot find any justification for the charge that he held a doctrine of race superiority." Eliot finds instead,
Of Kipling's verse, such as his "Barrack-Room Ballads", Eliot writes "of a number of poets who have written great poetry, only... a very few whom I should call great verse writers. And unless I am mistaken, Kipling's position in this class is not only high, but unique."

In response to Eliot, George Orwell wrote a long consideration of Kipling's work for "Horizon" in 1942, noting that although as a "jingo imperialist" Kipling was "morally insensitive and aesthetically disgusting," his work had many qualities which ensured that while "every enlightened person has despised him... nine-tenths of those enlightened persons are forgotten and Kipling is in some sense still there.":
In 1939, the poet W.H. Auden celebrated KIpling in a similarly left-handed way in his elegy for William Butler Yeats. Auden deleted this section from more recent editions of his poems.
<poem>
Time, that is intolerant
Of the brave and innocent,
And indifferent in a week
To a beautiful physique,

Worships language, and forgives
Everyone by whom it lives;
Pardons cowardice, conceit,
Lays its honours at his feet.

Time, that with this strange excuse,
Pardons Kipling and his views,
And will pardon Paul Claudel,
Pardons him for writing well. 
</poem>

The poet Alison Brackenbury writes, "Kipling is poetry's Dickens, an outsider and journalist with an unrivalled ear for sound and speech."

The English folk singer Peter Bellamy was a lover of Kipling's poetry, much of which he believed to have been influenced by English traditional folk forms. He recorded several albums of Kipling's verse set to traditional airs, or to tunes of his own composition written in traditional style. However, in the case of the bawdy folk song, "The Bastard King of England," which is commonly credited to Kipling, it is believed that the song is actually misattributed.

Kipling is often quoted in discussions of contemporary British political and social issues. In 1911, Kipling wrote the poem "The Reeds of Runnymede" that celebrated Magna Carta, and summoned up a vision of the "stubborn Englishry" determined to defend their rights. In 1996, the following verses of the poem were quoted by former Prime Minister Margaret Thatcher warning against the encroachment of the European Union on national sovereignty:
<poem>At Runnymede, at Runnymede,
Oh, hear the reeds at Runnymede:
âYou musnât sell, delay, deny,
A freemanâs right or liberty.
It wakes the stubborn Englishry,
We saw âem roused at Runnymede!

â¦ And still when Mob or Monarch lays
Too rude a hand on English ways,
The whisper wakes, the shudder plays,
Across the reeds at Runnymede.
And Thames, that knows the mood of kings,
And crowds and priests and suchlike things,
Rolls deep and dreadful as he brings
Their warning down from Runnymede!
</poem>

Political singer-songwriter Billy Bragg, who attempts to build a left-wing English nationalism in contrast with the more common right-wing English nationalism, has attempted to 'reclaim' Kipling for an inclusive sense of Englishness. Kipling's enduring relevance has been noted in the United States, as it has become involved in Afghanistan and other areas about which he wrote.

In 1903, Kipling gave permission to Elizabeth Ford Holt to borrow themes from the "Jungle Books" to establish Camp Mowglis, a summer camp for boys on the shores of Newfound Lake in New Hampshire. Throughout their lives, Kipling and his wife Carrie maintained an active interest in Camp Mowglis, which still continues the traditions that Kipling inspired. Buildings at Mowglis have names such as Akela, Toomai, Baloo, and Panther. The campers are referred to as "the Pack," from the youngest "Cubs" to the oldest living in "Den." 

Kipling's links with the Scouting movements were also strong. Robert Baden-Powell, founder of Scouting, used many themes from "Jungle Book" stories and "Kim" in setting up his junior Wolf Cubs. These ties still exist, such as the popularity of "Kim's Game." The movement is named after Mowgli's adopted wolf family, and adult helpers of Wolf Cub Packs take names from "The Jungle Book", especially the adult leader called "Akela" after the leader of the Seeonee wolf pack.

After the death of Kipling's wife in 1939, his house, Bateman's in Burwash, East Sussex, where he had lived from 1902 until 1936, was bequeathed to the National Trust. It is now a public museum dedicated to the author. Elsie Bambridge, his only child who lived to maturity, died childless in 1976, and bequeathed her copyrights to the National Trust, which in turn donated them to the University of Sussex to ensure better public access.

Novelist and poet Sir Kingsley Amis wrote a poem, "Kipling at Bateman's," after visiting Burwash (where Amis's father lived briefly in the 1960s) as part of a BBC television series on writers and their houses.

In 2003, actor Ralph Fiennes read excerpts from Kipling's works from the study in Bateman's, including, "The Jungle Book", "Something of Myself", "Kim", and "The Just So Stories", and poems, including "If ..." and "My Boy Jack," for a CD published by the National Trust.

In modern-day India, whence he drew much of his material, Kipling's reputation remains controversial, especially amongst modern nationalists and some post-colonial critics. Rudyard Kipling was a prominent supporter of Colonel Reginald Dyer, who was responsible for the Jallianwala Bagh massacre in Amritsar (in the province of Punjab). Kipling called Dyer "the man who saved India" and initiated collections for the latter's homecoming prize. However, Subhash Chopra writes in his book "Kipling Sahib â the Raj Patriot" that the benefit fund was started by "The Morning Post" newspaper, not by Kipling, and that Kipling made no contribution to the Dyer fund. While Kipling's name was conspicuously absent from the list of donors as published in "The Morning Post", he clearly admired Dyer.

Other contemporary Indian intellectuals such as Ashis Nandy have taken a more nuanced view. Jawaharlal Nehru, the first Prime Minister of independent India, often described Kipling's novel "Kim" as one of his favourite books.

G. V. Desani, an Indian writer of fiction, had a more negative opinion of Kipling. He alludes to Kipling in his novel, "All About H. Hatterr":
Indian writer Khushwant Singh wrote in 2001 that he considers Kipling's "Ifâ" "the essence of the message of The Gita in English," referring to the Bhagavad Gita, an ancient Indian scripture.

Indian writer R. K. Narayan said, "Kipling, the supposed expert writer on India, showed a better understanding of the mind of the animals in the jungle than of the men in an Indian home or the marketplace."

In November 2007, it was announced that Kipling's birth home in the campus of the J. J. School of Art in Mumbai would be turned into a museum celebrating the author and his works.

Kipling's bibliography includes fiction (including novels and short stories), non-fiction, and poetry. Several of his works were collaborations.







</doc>
<doc id="26309" url="https://en.wikipedia.org/wiki?curid=26309" title="Regency dance">
Regency dance

Regency dance is the term for historical dances of the period ranging roughly from 1790 to 1825. Some feel that the popular use of the term "Regency dance" is not technically correct, as the actual English Regency (the future George IV ruling on behalf of mad King George III) lasted only from 1811 until 1820. However, the term "Regency" has been used to refer to a much broader period than the historical Regency for a very long time, particularly in areas such as the history of art and architecture, literature, and clothing. This is because there are consistencies of style over this period which make having a single term useful.

Most popular exposure to this era of dance comes in the works of Jane Austen. Balls occur in her novels and are discussed in her letters, but specifics are few. Films based on her works tend to incorporate modern revival English Country Dance; however, they rarely incorporate dances actually of the period and do them without the appropriate footwork and social style which make them accurate to the period. Dances of this era were lively and bouncy, not the smooth and stately style seen in films. Steps ranging from simple skipping to elaborate ballet-style movements were used.

In the early part of this period, up to the early 1810s, the ballroom was dominated by the country dance, the cotillion, and the scotch reel. 

In the longways Country Dance, a line of couples perform figures with each other, progressing up and down the line. Regency country dances were often proceeded by a brief March by the couples, then begun by the top lady in the set and her partner, who would dance down the set to the bottom. Each couple in turn as they reached the top would likewise dance down until the entire set had returned to its original positions. This could be a lengthy process, easily taking an hour in a long set. An important social element was the calling of the dance by the leading lady (a position of honor), who would determine the figures, steps, and music to be danced. The rest of the set would listen to the calling dancing master or pick up the dance by observing the leading couple. Austen mentions in her letters instances in which she and her partner called the dance.

The cotillion was a French import, performed in a square using more elaborate footwork. It consisted of a "chorus" figure unique to each dance which was danced alternately with a standard series of up to ten "changes", which were simple figures such as a right hand moulinet (star) common to cotillions in general.

The scotch reel of the era consisted of alternate heying (interlacing) and setting (fancy steps danced in place) by a line of three or four dancers. More complex reels appear in manuals as well but it's unclear if they ever actually caught on. A sixsome reel is mentioned in a description of Scottish customs in the early 1820s and eightsome reels (danced in squares like cotillions) occur in some dance manuscripts of the era.

In the 1810s, the era of the Regency proper, English dance began an important transition with the introduction of the quadrille and the waltz.

The Waltz was first imported to England around 1810, but it was not considered socially acceptable until continental visitors at the post-Napoleonic-Wars celebrations danced it in Londonâand even then it remained the subject of anti-waltz diatribes, caricatures, and jokes. Even the decadent Lord Byron was scandalized by the prospect of people "embracing" on the dance floor. The Regency version is relatively slow, and done up on the balls of the feet with the arms in a variety of graceful positions. The Sauteuse is a leaping waltz commonly done in 2/4 rather than 3/4 time, similar in pattern (leap-glide-close) to the Redowa and Waltz Galop of the later nineteenth century.

First imported from France by Lady Jersey in 1815, the Quadrille was a shorter version of the earlier cotillions. Figures from individual cotillions were assembled into sets of five or six figures, and the changes were left out, producing much shorter dances. By the late 1810s, it was not uncommon to dance a series of quadrilles during the evening, generally consisting of the same first three figures combined with a variety of different fourth and fifth figures. Jane Austen's niece Fanny danced quadrilles and in their correspondence Jane mentions that she finds them much inferior to the cotillions of her own youth.

By the late 1810s, under siege from the Quadrille, dancing masters began to invent "new" forms of country dance, often with figures borrowed from the Quadrille, and giving them exotic names such as the Danse Ecossoise and Danse Espagnuole which suggested entire new dances but actually covered very minor variations in the classic form. A few of these dances became sufficiently popular that they survived through the entire 19th century. One example of this is the "Spanish dance" popular in vintage dance circles, which is a solitary survivor of its entire genre of Regency-era dances.

"La Boulangere", the only dance mentioned by name in Jane Austen's writings, is a simple circle dance for a group of couples. Sir Roger de Coverly, mentioned by Charles Dickens, is the ancestor of America's Virginia Reel.

Numerous instruction manuals survive from the Regency era. Several by Thomas Wilson are in the US Library of Congress online collection. The Scotch Reel is described by Francis Peacock, whose manual is also available in the LC collection.

The first major revival of English Country Dance, one of the major types of Regency dance, was by Englishman Cecil Sharp in the early 20th century. Various other revivals have followed, most using at least some of Sharp's research. Today, there are many groups around the world which perform a variety of English period dances, including many of the types of dance which were popular during the English Regency.

Regency dance has gained popularity at science fiction conventions, in part due to the efforts of John Hertz. Reconstructed dances from the era are taught to newcomers and experienced dancers alike. Some authorsânotably, Larry Nivenâhave added their personal enthusiasm to the trend.

In Silicon Valley, the Bay Area English Regency Society sponsors local dance classes and formal balls in churches, community centers, and other venues. In Pasadena, California, the Valley Area English Regency Society hosts teas and Regency dance parties in a local church. Both societies were founded by Laura Brodian Freas Beraha.
Some enthusiasts go to extremes: Cisco Systems founders Sandra Lerner and Len Bosack created a foundation that bought a Regency-era country house once owned by Jane Austen's brother. In Australia, Earthly Delights Historic Dance Academy and John Gardiner-Garden run a Regency Dance School in conjunction with Jane Austen Festival Australia every April.



</doc>
<doc id="26310" url="https://en.wikipedia.org/wiki?curid=26310" title="Reproduction">
Reproduction

Reproduction (or procreation or breeding) is the biological process by which new individual organisms â "offspring" â are produced from their "parents". Reproduction is a fundamental feature of all known life; each individual organism exists as the result of reproduction. There are two forms of reproduction: asexual and sexual.

In asexual reproduction, an organism can reproduce without the involvement of another organism. Asexual reproduction is not limited to single-celled organisms. The cloning of an organism is a form of asexual reproduction. By asexual reproduction, an organism creates a genetically similar or identical copy of itself. The evolution of sexual reproduction is a major puzzle for biologists. The two-fold cost of sexual reproduction is that only 50% of organisms reproduce and organisms only pass on 50% of their genes.

Sexual reproduction typically requires the sexual interaction of two specialized organisms, called gametes, which contain half the number of chromosomes of normal cells and are created by meiosis, with typically a male fertilizing a female of the same species to create a fertilized zygote. This produces offspring organisms whose genetic characteristics are derived from those of the two parental organisms.

Asexual reproduction is a process by which organisms create genetically similar or identical copies of themselves without the contribution of genetic material from another organism. Bacteria divide asexually via binary fission; viruses take control of host cells to produce more viruses; Hydras (invertebrates of the order "Hydroidea") and yeasts are able to reproduce by budding. These organisms often do not possess different sexes, and they are capable of "splitting" themselves into two or more copies of themselves. Most plants have the ability to reproduce asexually and the ant species Mycocepurus smithii is thought to reproduce entirely by asexual means.

Some species that are capable of reproducing asexually, like hydra, yeast (See Mating of yeasts) and jellyfish, may also reproduce sexually. For instance, most plants are capable of vegetative reproductionâreproduction without seeds or sporesâbut can also reproduce sexually. Likewise, bacteria may exchange genetic information by conjugation.

Other ways of asexual reproduction include parthenogenesis, fragmentation and spore formation that involves only mitosis. Parthenogenesis is the growth and development of embryo or seed without fertilization by a male. Parthenogenesis occurs naturally in some species, including lower plants (where it is called apomixis), invertebrates (e.g. water fleas, aphids, some bees and parasitic wasps), and vertebrates (e.g. some
reptiles, fish, and, very rarely, birds and sharks). It is sometimes also used to describe reproduction modes in hermaphroditic species which can self-fertilize.

Sexual reproduction is a biological process that creates a new organism by combining the genetic material of two organisms in a process that starts with meiosis, a specialized type of cell division. Each of two parent organisms contributes half of the offspring's genetic makeup by creating haploid gametes. Most organisms form two different types of gametes. In these anisogamous species, the two sexes are referred to as male (producing sperm or microspores) and female (producing ova or megaspores). In isogamous species, the gametes are similar or identical in form (isogametes), but may have separable properties and then may be given other different names (see isogamy). For example, in the green alga, "Chlamydomonas reinhardtii", there are so-called "plus" and "minus" gametes. A few types of organisms, such as many fungi and the ciliate "Paramecium aurelia", have more than two "sexes", called syngens.
Most animals (including humans) and plants reproduce sexually. Sexually reproducing organisms have different sets of genes for every trait (called alleles). Offspring inherit one allele for each trait from each parent. Thus, offspring have a combination of the parents' genes. It is believed that "the masking of deleterious alleles favors the evolution of a dominant diploid phase in organisms that alternate between haploid and diploid phases" where recombination occurs freely.

Bryophytes reproduce sexually, but the larger and commonly-seen organisms are haploid and produce gametes. The gametes fuse to form a zygote which develops into a sporangium, which in turn produces haploid spores. The diploid stage is relatively small and short-lived compared to the haploid stage, i.e. "haploid dominance". The advantage of diploidy, heterosis, only exists in the diploid life generation. Bryophytes retain sexual reproduction despite the fact that the haploid stage does not benefit from heterosis. This may be an indication that the sexual reproduction has advantages other than heterosis, such as genetic recombination between members of the species, allowing the expression of a wider range of traits and thus making the population more able to survive environmental variation.

Allogamy is the fertilization of the combination of gametes from two parents, generally the ovum from one individual with the spermatozoa of another. (In isogamous species, the two gametes will not be defined as either sperm or ovum.)

Self-fertilization, also known as autogamy, occurs in hermaphroditic organisms where the two gametes fused in fertilization come from the same individual, e.g., many vascular plants, some foraminiferans, some ciliates. The term "autogamy" is sometimes substituted for autogamous pollination (not necessarily leading to successful fertilization) and describes self-pollination within the same flower, distinguished from geitonogamous pollination, transfer of pollen to a different flower on the same flowering plant, or within a single monoecious Gymnosperm plant.

Mitosis and meiosis are types of cell division. Mitosis occurs in somatic cells, while meiosis occurs in gametes.

Mitosis
The resultant number of cells in mitosis is twice the number of original cells. The number of chromosomes in the offspring cells is the same as that of the parent cell.

Meiosis
The resultant number of cells is four times the number of original cells. This results in cells with half the number of chromosomes present in the parent cell. A diploid cell duplicates itself, then undergoes two divisions (tetraploid to diploid to haploid), in the process forming four haploid cells. This process occurs in two phases, meiosis I and meiosis II.
In recent decades, developmental biologists have been researching and developing techniques to facilitate same-sex reproduction. The obvious approaches, subject to a growing amount of activity, are female sperm and male eggs, with female sperm closer to being a reality for humans, given that Japanese scientists have already created female sperm for chickens. "However, the ratio of produced W chromosome-bearing (W-bearing) spermatozoa fell substantially below expectations. It is therefore concluded that most of the W-bearing PGC could not differentiate into spermatozoa because of restricted spermatogenesis." In 2004, by altering the function of a few genes involved with imprinting, other Japanese scientists combined two mouse eggs to produce daughter mice and in 2018 Chinese scientists created 29 female mice from two female mice mothers but were unable to produce viable offspring from two father mice.

There are a wide range of reproductive strategies employed by different species. Some animals, such as the human and northern gannet, do not reach sexual maturity for many years after birth and even then produce few offspring. Others reproduce quickly; but, under normal circumstances, most offspring do not survive to adulthood. For example, a rabbit (mature after 8 months) can produce 10â30 offspring per year, and a fruit fly (mature after 10â14 days) can produce up to 900 offspring per year. These two main strategies are known as K-selection (few offspring) and r-selection (many offspring). Which strategy is favoured by evolution depends on a variety of circumstances. Animals with few offspring can devote more resources to the nurturing and protection of each individual offspring, thus reducing the need for many offspring. On the other hand, animals with many offspring may devote fewer resources to each individual offspring; for these types of animals it is common for many offspring to die soon after birth, but enough individuals typically survive to maintain the population. Some organisms such as honey bees and fruit flies retain sperm in a process called sperm storage thereby increasing the duration of their fertility.


Organisms that reproduce through asexual reproduction tend to grow in number exponentially. However, because they rely on mutation for variations in their DNA, all members of the species have similar vulnerabilities. Organisms that reproduce sexually yield a smaller number of offspring, but the large amount of variation in their genes makes them less susceptible to disease.

Many organisms can reproduce sexually as well as asexually. Aphids, slime molds, sea anemones, some species of starfish (by fragmentation), and many plants are examples. When environmental factors are favorable, asexual reproduction is employed to exploit suitable conditions for survival such as an abundant food supply, adequate shelter, favorable climate, disease, optimum pH or a proper mix of other lifestyle requirements. Populations of these organisms increase exponentially via asexual reproductive strategies to take full advantage of the rich supply resources.

When food sources have been depleted, the climate becomes hostile, or individual survival is jeopardized by some other adverse change in living conditions, these organisms switch to sexual forms of reproduction. Sexual reproduction ensures a mixing of the gene pool of the species. The variations found in offspring of sexual reproduction allow some individuals to be better suited for survival and provide a mechanism for selective adaptation to occur. The meiosis stage of the sexual cycle also allows especially effective repair of DNA damages (see Meiosis). In addition, sexual reproduction usually results in the formation of a life stage that is able to endure the conditions that threaten the offspring of an asexual parent. Thus, seeds, spores, eggs, pupae, cysts or other "over-wintering" stages of sexual reproduction ensure the survival during unfavorable times and the organism can "wait out" adverse situations until a swing back to suitability occurs.

The existence of life without reproduction is the subject of some speculation. The biological study of how the origin of life produced reproducing organisms from non-reproducing elements is called abiogenesis. Whether or not there were several independent abiogenetic events, biologists believe that the last universal ancestor to all present life on Earth lived about 3.5 billion years ago.

Scientists have speculated about the possibility of creating life non-reproductively in the laboratory. Several scientists have succeeded in producing simple viruses from entirely non-living materials. However, viruses are often regarded as not alive. Being nothing more than a bit of RNA or DNA in a protein capsule, they have no metabolism and can only replicate with the assistance of a hijacked cell's metabolic machinery.

The production of a truly living organism (e.g. a simple bacterium) with no ancestors would be a much more complex task, but may well be possible to some degree according to current biological knowledge. A synthetic genome has been transferred into an existing bacterium where it replaced the native DNA, resulting in the artificial production of a new "M. mycoides" organism.

There is some debate within the scientific community over whether this cell can be considered completely synthetic on the grounds that the chemically synthesized genome was an almost 1:1 copy of a naturally occurring genome and, the recipient cell was a naturally occurring bacterium. The Craig Venter Institute maintains the term "synthetic bacterial cell" but they also clarify "...we do not consider this to be "creating life from scratch" but rather we are creating new life out of already existing life using synthetic DNA". Venter plans to patent his experimental cells, stating that "they are pretty clearly human inventions". Its creators suggests that building 'synthetic life' would allow researchers to learn about life by building it, rather than by tearing it apart. They also propose to stretch the boundaries between life and machines until the two overlap to yield "truly programmable organisms". Researchers involved stated that the creation of "true synthetic biochemical life" is relatively close in reach with current technology and cheap compared to the effort needed to place man on the Moon.

Sexual reproduction has many drawbacks, since it requires far more energy than asexual reproduction and diverts the organisms from other pursuits, and there is some argument about why so many species use it. George C. Williams used lottery tickets as an analogy in one explanation for the widespread use of sexual reproduction. He argued that asexual reproduction, which produces little or no genetic variety in offspring, was like buying many tickets that all have the same number, limiting the chance of "winning" â that is, producing surviving offspring. Sexual reproduction, he argued, was like purchasing fewer tickets but with a greater variety of numbers and therefore a greater chance of success. The point of this analogy is that since asexual reproduction does not produce genetic variations, there is little ability to quickly adapt to a changing environment. The lottery principle is less accepted these days because of evidence that asexual reproduction is more prevalent in unstable environments, the opposite of what it predicts.





</doc>
<doc id="26311" url="https://en.wikipedia.org/wiki?curid=26311" title="Rudyard Kipling bibliography">
Rudyard Kipling bibliography

This is a bibliography of works by Rudyard Kipling, including books, short stories, poems, and collections of his works.




Some of Kipling's works were collected by him; some others were collected by publishers of "unauthorised" editions ("Abaft the Funnel", "From Sea to Sea", for example). Still others of his works were never collected. The lists given below include all the collections that Kipling acknowledged as his own work. However, it is possible to find other works that appeared in American but not English editions, works that only appeared in an original periodical publication, and some others that only appeared in the Sussex and Burwash editions.







The last two of these editions include volume(s) of "uncollected prose".

Collections issued during his lifetime by the poet himself include:


Posthumous collections of Kipling's poems include:

Some of Kipling's many poems are:



</doc>
<doc id="26313" url="https://en.wikipedia.org/wiki?curid=26313" title="Roget's Thesaurus">
Roget's Thesaurus

Roget's Thesaurus is a widely used English-language thesaurus, created in 1805 by Peter Mark Roget (1779â1869), British physician, natural theologian and lexicographer. It was released to the public on 29 April 1852. The original edition had 15,000 words, and each new edition has been larger. Roget was inspired by the Utilitarian teachings of Jeremy Bentham and wished to help "those who are painfully groping their way and struggling with the difficulties of composition [...] this work processes to hold out a helping hand". The Karpeles Library Museum houses the original manuscript in its collection.

The name "Roget" is trademarked in parts of the world, such as the United Kingdom. By itself, it is not protected in the United States, where use of the name "Roget" in the title of a thesaurus does not necessarily indicate any relationship to Roget directly; it has come to be seen as a generic thesaurus name. With its hegemonic status, it became "a mark of civility". J.M. Barrie stated "[Captain Hook] is not wholly evil [h]e has a Thesaurus in his cabin". Indeed, Sylvia Plath considered it her desert island book over the Bible.

Roget described his thesaurus in the foreword to the first edition:

It is now nearly fifty years since I first projected a system of verbal classification similar to that on which the present work is founded. Conceiving that such a compilation might help to supply my own deficiencies, I had, in the year 1805, completed a classed catalogue of words on a small scale, but on the same principle, and nearly in the same form, as the Thesaurus now published.
"Roget's Thesaurus" is composed of six primary classes. Each class is composed of multiple divisions and then sections. This may be conceptualized as a tree containing over a thousand branches for individual "meaning clusters" or semantically linked words. Although these words are not strictly synonyms, they can be viewed as colours or connotations of a meaning or as a spectrum of a concept. One of the most general words is chosen to typify the spectrum as its headword, which labels the whole group.

Roget's schema of classes and their subdivisions is based on the philosophical work of Leibniz (see LeibnizâSymbolic thought), itself following a long tradition of epistemological work starting with Aristotle. Some of Aristotle's Categories are included in Roget's first class "abstract relations". 

The book is updated regularly and each edition is heralded as a gauge to contemporary terms; but each edition keeps true to the original classifications established by Roget.





</doc>
<doc id="26316" url="https://en.wikipedia.org/wiki?curid=26316" title="Racial segregation">
Racial segregation

Racial segregation is the systemic separation of people into racial or other ethnic groups in daily life. Segregation can involve spatial separation of the races, and mandatory use of different institutions, such as schools and hospitals by people of different races. Specifically, it may apply to activities such as eating in a restaurant, drinking from a water fountain, using a public toilet, attending school, going to the movies, riding on a bus, or in the rental or purchase of a home or of hotel rooms. In addition, segregation often allowed close contact in hierarchical situations, such as allowing a person of one race to work as a servant for a member of another race.

Segregation is defined by the European Commission against Racism and Intolerance as "the act by which a (natural or legal) person separates other persons on the basis of one of the enumerated grounds without an objective and reasonable justification, in conformity with the proposed definition of discrimination. As a result, the voluntary act of separating oneself from other people on the basis of one of the enumerated grounds does not constitute segregation". According to the UN Forum on Minority Issues, "The creation and development of classes and schools providing education in minority languages should not be considered impermissible segregation, if the assignment to such classes and schools is of a voluntary nature".

Racial segregation has been generally outlawed worldwide. In the United States, segregation was mandated by law in some states (such as the Jim Crow laws) and came with anti-miscegenation laws (prohibitions against interracial marriage), until the U.S. Supreme Court led by Chief Justice Earl Warren started a liberal Constitutional Revolution in 1950s and 1960s which outlawed racial segregation throughout the United States. However, racial segregation may exist "de facto" through social norms, even when there is no strong individual preference for it, as suggested by Thomas Schelling's models of segregation and subsequent work. Segregation may be maintained by means ranging from discrimination in hiring and in the rental and sale of housing to certain races to vigilante violence (such as lynchings). Generally, a situation that arises when members of different races mutually prefer to associate and do business with members of their own race would usually be described as "separation" or "de facto separation" of the races rather than "segregation".

Wherever there have been multiracial communities, there has been racial segregation. Only areas with extensive miscegenation, or mixing, such as Hawaii and Brazil, despite some social stratification, seem to be exempt.

Several laws enforcing racial segregation of foreigners from Chinese were passed by the Han Chinese during the Tang dynasty. In 779 the Tang dynasty issued an edict which forced Uighurs to wear their ethnic dress, stopped them from marrying Chinese females, and banned them from pretending to be Chinese. Chinese disliked Uighurs because they practiced usury. The magistrate who issued the orders may have wanted to protect "purity" in Chinese custom. In 836, when Lu Chun was appointed as governor of Canton, he was disgusted to find Chinese living with foreigners and intermarriage between Chinese and foreigners. Lu enforced separation, banning interracial marriages, and made it illegal for foreigners to own property. Lu Chun believed his principles were just and upright. The 836 law specifically banned Chinese from forming relationships with "Dark peoples" or "People of colour", which was used to describe foreigners, such as "Iranians, Sogdians, Arabs, Indians, Malays, Sumatrans", among others.

The Qing Dynasty was founded not by the Han Chinese who form the majority of the Chinese population, but the Manchus, who are today an ethnic minority of China. The Manchus were keenly aware of their minority status, however, it was only later in the dynasty that they banned intermarriage.

Han defectors played a massive role in the Qing conquest of China. Han Chinese Generals who defected to the Manchu were often given women from the Imperial Aisin Gioro family in marriage while the ordinary soldiers who defected were given non-royal Manchu women as wives. The Manchu leader Nurhaci married one of his granddaughters to the Ming General Li Yongfang after he surrendered Fushun in Liaoning to the Manchu in 1618. Jurchen (Manchu) women married most the Han Chinese defectors in Liaodong. Aisin Gioro women were married to the sons of the Han Chinese Generals Sun Sike (Sun Ssu-k'o), Geng Jimao (Keng Chi-mao), Shang Kexi (Shang K'o-hsi), and Wu Sangui (Wu San-kuei).

A mass marriage of Han Chinese officers and officials to Manchu women numbering 1,000 couples was arranged by Prince Yoto and Hongtaiji in 1632 to promote harmony between the two ethnic groups.

Geng Zhongming, a Han bannerman, was awarded the title of Prince Jingnan, and his son Geng Jingmao managed to have both his sons Geng Jingzhong and Geng Zhaozhong become court attendants under Shunzhi and get married to Aisin Gioro women, with Haoge's (a son of Hong Taiji) daughter marrying Geng Jingzhong and Prince Abatai's (Hong Taiji) granddaughter marrying Geng Zhaozhong.

The Qing differentiated between Han Bannermen and ordinary Han civilians. Han Bannermen were made out of Han Chinese who defected to the Qing up to 1644 and joined the Eight Banners, giving them social and legal privileges in addition to being acculturated to Manchu culture. So many Han defected to the Qing and swelled up the ranks of the Eight Banners that ethnic Manchus became a minority within the Banners, making up only 16% in 1648, with Han Bannermen dominating at 75%. It was this multi-ethnic force in which Manchus were only a minority, which conquered China for the Qing.

It was Han Chinese Bannermen who were responsible for the successful Qing conquest of China, they made up the majority of governors in the early Qing and were the ones who governed and administered China after the conquest, stabilizing Qing rule. Han Bannermen dominated the post of governor-general in the time of the Shunzhi and Kangxi Emperors, and also the post of governors, largely excluding ordinary Han civilians from the posts.

To promote ethnic harmony, a 1648 decree from the Manchu Shunzhi Emperor allowed Han Chinese civilian men to marry Manchu women from the Banners with the permission of the Board of Revenue if they were registered daughters of officials or commoners or the permission of their banner company captain if they were unregistered commoners, it was only later in the dynasty that these policies allowing intermarriage were done away with.

The Qing implemented a policy of segregation between the Bannermen of the Eight Banners (Manchu Bannermen, Mongol Bannermen, Han Bannermen) and Han Chinese civilians. This ethnic segregation had cultural and economic reasons: intermarriage was forbidden to keep up the Manchu heritage and minimize sinicization. Han Chinese civilians and Mongol civilians were banned from settling in Manchuria. Han civilians and Mongol civilians were banned from crossing into each other's lands. Ordinary Mongol civilians in Inner Mongolia were banned from even crossing into other Mongol Banners. (A banner in Inner Mongolia was an administrative division and not related to the Mongol Bannermen in the Eight Banners)

These restrictions did not apply Han Bannermen, who were settled in Manchuria by the Qing. Han bannermen were differentiated from Han civilians by the Qing and treated differently.

The Qing Dynasty started colonizing Manchuria with Han Chinese later on in the dynasty's rule, but the Manchu area was still separated from modern-day Inner Mongolia by the Outer Willow Palisade, which kept the Manchu and the Mongols in the area separate.

The policy of segregation applied directly to the banner garrisons, most of which occupied a separate walled zone within the cities in which they were stationed. Manchu Bannermen, Han Bannermen, and Mongol Bannermen were separated from the Han civilian population. While the Manchus followed the governmental structure of the preceding Ming dynasty, their ethnic policy dictated that appointments were split between Manchu noblemen and Han Chinese civilian officials who had passed the highest levels of the state examinations, and because of the small number of Manchus, this insured that a large fraction of them would be government officials.

Spanish colonists created caste systems in Latin American countries based on classification by race and race mixture. An extensive nomenclature developed, including the terms "mulatto", "mestizo", and "zambo" (the latter the origin of "sambo"). The Spanish had practiced a form of caste system in Hispania before their expulsion of the Jews and Muslims. While many Latin American countries have long since rendered the system officially illegal through legislation, usually at the time of independence, prejudice based on degrees of perceived racial distance from European ancestry combined with one's socioeconomic status remain, an echo of the colonial caste system.

The Land Apportionment Act of 1930 passed in Southern Rhodesia (now known as Zimbabwe) was a segregationist measure that governed land allocation and acquisition in rural areas, making distinctions between blacks and whites.

One highly publicized legal battle occurred in 1960 involving the opening of a new theatre that was to be open to all races; the proposed unsegregated public toilets at the newly built Reps Theatre in 1959 caused an argument called "The Battle of the Toilets".

Following its conquest of Ottoman controlled Algeria in 1830, for well over a century France maintained colonial rule in the territory which has been described as "quasi-apartheid". The colonial law of 1865 allowed Arab and Berber Algerians to apply for French citizenship only if they abandoned their Muslim identity; Azzedine Haddour argues that this established "the formal structures of a political apartheid". Camille Bonora-Waisman writes that, "in contrast with the Moroccan and Tunisian protectorates", this "colonial apartheid society" was unique to Algeria.

This "internal system of apartheid" met with considerable resistance from the Muslims affected by it, and is cited as one of the causes of the 1954 insurrection and ensuing independence war.

Though there were no specific laws imposing racial segregation and barring blacks from establishments frequented by whites, "de facto" segregation operated in most areas. For example, initially, the city centers were reserved to the white population only, while the black population was organized in "citÃ©s indigÃ¨nes" (indigenous neighbourhoods called 'le belge'). Hospitals, department stores and other facilities were often reserved for either whites or blacks.

The black population in the cities could not leave their houses from 9Â pm to 4Â am. This type of segregation began to disappear gradually only in the 1950s, but even then the Congolese remained or felt treated in many respects as second-rate citizens (for instance in political and legal terms).

From 1953, and even more so after the triumphant visit of King Baudouin to the colony in 1955, Governor-General LÃ©on PÃ©tillon (1952â1958) worked to create a "Belgian-Congolese community", in which blacks and whites were to be treated as equals. Regardless, anti-miscegenation laws remained in place, and between 1959 and 1962 thousands of mixed-race Congolese children were forcibly deported from the Congo by the Belgian government and the Catholic Church and taken to Belgium.

Jews in Europe were generally forced, by decree or informal pressure, to live in highly segregated ghettos and shtetls. In 1204 the papacy required Jews to segregate themselves from Christians and wear distinctive clothing. Forced segregation of Jews spread throughout Europe during the 14th and 15th centuries. In the Russian Empire, Jews were restricted to the so-called Pale of Settlement, the Western frontier of the Russian Empire which roughly corresponds to the modern-day countries of Poland, Lithuania, Belarus, Moldova and Ukraine. By the early 20th century, the majority of Europe's Jews lived in the Pale of Settlement.

From the beginning of the 15th century, Jewish populations in Morocco were confined to mellahs. In cities, a "mellah" was surrounded by a wall with a fortified gateway. In contrast, rural "mellahs" were separate villages whose sole inhabitants were Jews.

In the middle of the 19th century, J. J. Benjamin wrote about the lives of Persian Jews:
On 16 May 1940, the "AdministrasjonsrÃ¥det" asked the Rikskommisariatet why radio receivers had been confiscated from Jews in Norway. "AdministrasjonsrÃ¥det" thereafter "quietly" accepted racial segregation between Norwegian citizens, has been claimed by Tor Bomann-Larsen. Furthermore, he claimed that this segregation "created a precedent. 2 years later (with "NS-styret" in the ministries of Norway) Norwegian police arrested citizens at the addresses where radios had previously been confiscated from Jews.

German praise for America's institutional racism, previously found in Hitler's "Mein Kampf", was continuous throughout the early 1930s, and radical Nazi lawyers were advocates of the use of American models. Race based U.S. citizenship laws and anti-miscegenation laws directly inspired the two principal Nuremberg Lawsâthe Citizenship Law and the Blood Law. The ban on interracial marriage (anti-miscegenation) prohibited sexual relations and marriages between people classified as "Aryan" and "non-Aryan". Such relationships were called "Rassenschande" (race defilement). At first the laws were aimed primarily at Jews but were later extended to "Gypsies, Negroes and their bastard offspring". Aryans found guilty could face incarceration in a Nazi concentration camp, while non-Aryans could face the death penalty. To preserve the so-called purity of the German blood, after the war began, the Nazis extended the race defilement law to include all foreigners (non-Germans).

Under the General Government of occupied Poland in 1940, the Nazis divided the population into different groups, each with different rights, food rations, allowed housing strips in the cities, public transportation, etc. In an effort to split Polish identity they attempted to establish ethnic divisions of Kashubians and Gorals (Goralenvolk), based on these groups' alleged "Germanic component".

During the 1930s and 1940s, Jews in Nazi-controlled states were made to wear something that identified them as Jewish, such as a yellow ribbon or star of David, and were, along with Romas (Gypsies), discriminated against by the racial laws. Jewish doctors were not allowed to treat Aryan patients nor were Jewish professors permitted to teach Aryan pupils. In addition, Jews were not allowed to use any public transportation, besides the ferry, and were able to shop only from 3â5 pm in Jewish stores. After "Kristallnacht" ("The Night of Broken Glass"), the Jews were fined 1,000,000 marks for damages done by the Nazi troops and SS members.

Jews and Roma were subjected to genocide as "undesirable" racial groups in the Holocaust. The Nazis established ghettos to confine Jews and sometimes Romas into tightly packed areas of the cities of Eastern Europe, turning them into "de facto" concentration camps. The Warsaw Ghetto was the largest of these ghettos, with 400,000 people. The ÅÃ³dÅº Ghetto was the second largest, holding about 160,000.

Between 1939 and 1945, at least 1.5 million Polish citizens were transported to the Reich for forced labour (in all, about 12 million forced laborers were employed in the German war economy inside Nazi Germany). Although Nazi Germany also used forced laborers from Western Europe, Poles, along with other Eastern Europeans viewed as racially inferior, were subject to deeper discriminatory measures. They were forced to wear a yellow with purple border and letter "P" (for Polen/Polish) cloth identifying tag sewn to their clothing, subjected to a curfew, and banned from public transportation.

While the treatment of factory workers or farm hands often varied depending on the individual employer, Polish laborers as a rule were compelled to work longer hours for lower wages than Western Europeans â in many cities, they were forced to live in segregated barracks behind barbed wire. Social relations with Germans outside work were forbidden, and sexual relations ("Rassenschande" or "racial defilement") were punishable by death.

In 1938, the fascist regime led by Benito Mussolini, under pressure from the Nazis, introduced a series of Italian Racial Laws instituting an official segregationist policy in the Italian Empire, especially aimed against Jews. This policy enforced various segregationist norms, like the prohibition for Jews to teach or study in ordinary schools and universities, to own industries reputed of major national interest, to work as journalists, to enter the military, and to wed non-Jews.
Some of the immediate consequences of the introduction of the 'provvedimenti per la difesa della razza' (norms for the defence of the race) included many of the best Italian scientists leaving their job, or even Italy. Amongst these, world-renowned physicists Emilio SegrÃ¨, Enrico Fermi (whose wife was Jewish), Bruno Pontecorvo, Bruno Rossi, Tullio Levi-Civita, mathematicians Federigo Enriques and Guido Fubini and even the fascist propaganda director, art critic and journalist Margherita Sarfatti, who was one of Mussolini's mistresses. Rita Levi-Montalcini, who would successively win the Nobel Prize for Medicine, was forbidden to work at the university. Albert Einstein, upon approval of the racial law, resigned from honorary membership of the Accademia dei Lincei.

After 1943, when Northern Italy was occupied by the Nazis, Italian Jews were rounded up for the Holocaust.

In fifteenth-century north-east Germany, people of Wendish, i.e. Slavic, origin were not allowed to join some guilds. According to Wilhelm Raabe, "down into the eighteenth century no German guild accepted a Wend."

After Jim Crow laws were passed that segregated African Americans and Whites, the lives of those who were negatively affected saw no progress in their quest for equality. Racial segregation was not a new phenomenon, as almost four million blacks had been slaves before the Civil War. The laws passed segregated African Americans from Whites in order to enforce a system of white supremacy. Signs were used to show non whites where they could legally walk, talk, drink, rest, or eat. For those places that were racially mixed, blacks had to wait until all White customers were dealt with. Rules were also enforced that restricted African Americans from entering white stores. Segregated facilities extended from white only schools to white only graveyards. 

After the Thirteenth Amendment abolished slavery in America, racial discrimination became regulated by the so-called Jim Crow laws, which mandated strict segregation of the races. Though many such laws were instituted shortly after fighting ended, they only became formalized after the 1877 end of the Reconstruction period. The period that followed is known as the nadir of American race relations. The legislation (or in some states, such as Florida, the state constitutions) that mandated segregation lasted at least until a 1968 ruling by the Supreme Court outlawing all forms of segregation. 

While the U.S. Supreme Court majority in the 1896 "Plessy v. Ferguson" case explicitly permitted "separate but equal" facilities (specifically, transportation facilities), Justice John Marshall Harlan, in his dissent, protested that the decision was an expression of white supremacy; he predicted that segregation would "stimulate aggressions â¦ upon the admitted rights of colored citizens", "arouse race hate", and "perpetuate a feeling of distrust between [the] races. Feelings between whites and blacks were so tense, even the jails were segregated."
Elected in 1912, President Woodrow Wilson tolerated the extension of segregation throughout the federal government that was already underway. In World War I, blacks were drafted and served in the United States Army in segregated units. Black soldiers were often poorly trained and equipped, and were often put on the frontlines in suicide missions. The U.S. military was still heavily segregated in World War II. The air force and the marines had no blacks enlisted in their ranks. There were blacks in the Navy Seabees. The army had only five African-American officers. In addition, no African-American would receive the Medal of Honor during the war, and their tasks in the war were largely reserved to noncombat units. Black soldiers had to sometimes give up their seats in trains to the Nazi prisoners of war. 
American sports were racially segregated until the mid-twentieth century. In baseball, the "Negro leagues" were established by Rube Foster for non-white players, such as Negro league baseball, which ran through the early 1950s. In basketball, the Black Fives (all-black teams) were established in 1904, and emerged in New York City, Washington, D.C., Chicago, Pittsburgh, Philadelphia, and other cities. Racial segregation in basketball lasted until 1950, when the NBA became racially integrated. 

On September 11, 1964, John Lennon announced The Beatles would not play to a segregated audience in Jacksonville, Florida. City officials relented following this announcement. A contract for a 1965 Beatles concert at the Cow Palace in California specifies that the band "not be required to perform in front of a segregated audience".

In the reception to honor his Olympic success Jesse Owens was not permitted to enter through the main doors of the Waldorf Astoria New York and instead forced to travel up to the event in a freight elevator. The first black Oscar recipient Hattie McDaniel was not permitted to attend the premiere of "Gone with the Wind" with Georgia being racially segregated, and at the Oscars ceremony in Los Angeles she was required to sit at a segregated table at the far wall of the room; the hotel had a no-blacks policy, but allowed McDaniel in as a favor.

Many U.S. states banned interracial marriage. While opposed to slavery in the U.S, in a speech in Charleston, Illinois in 1858, Abraham Lincoln stated, "I am not, nor ever have been in favor of bringing about in any way the social and political equality of the white and black races, that I am not, nor ever have been in favor of making voters or jurors of negroes, nor of qualifying them to hold office, nor to intermarry with white people. I as much as any man am in favor of the superior position assigned to the white race". In 1967, Mildred Loving, a black woman, and Richard Loving, a white man, were sentenced to a year in prison in Virginia for marrying each other. Their marriage violated the state's anti-miscegenation statute, the Racial Integrity Act of 1924, which prohibited marriage between people classified as white and people classified as "colored" (persons of non-white ancestry). In the "Loving v. Virginia" case in 1967, the Supreme Court invalidated laws prohibiting interracial marriage in the U.S.

Institutionalized racial segregation was ended as an official practice during the civil rights movement by the efforts of such civil rights activists as Clarence M. Mitchell Jr., Rosa Parks, Martin Luther King Jr. and James Farmer working for social and political freedom during the period from the end of World War II through the Interstate Commerce Commission desegregation order of 1961, the passage of the Civil Rights Act in 1964 and the Voting Rights Act in 1965 supported by President Lyndon B. Johnson. Many of their efforts were acts of non-violent civil disobedience aimed at disrupting the enforcement of racial segregation rules and laws, such as refusing to give up a seat in the black part of the bus to a white person (Rosa Parks), or holding sit-ins at all-white diners.

By 1968, all forms of segregation had been declared unconstitutional by the Supreme Court under Chief Justice Earl Warren, and by 1970 support for formal legal segregation had dissolved. The Warren Court's decision on landmark case "Brown v. Board of Education" of Topeka, Kansas in 1954 outlawed segregation in public schools, and its decision on "Heart of Atlanta Motel, Inc. v. United States" in 1964 prohibits racial segregation and discrimination in public institutions and public accommodations. The Fair Housing Act of 1968, administered and enforced by the Office of Fair Housing and Equal Opportunity, prohibited discrimination in the sale and rental of housing on the basis of race, color, national origin, religion, sex, familial status, and disability. Formal racial discrimination became illegal in school systems, businesses, the American military, other civil services and the government.

The apartheid system carried out by Afrikaner minority rule enacted a nationwide social policy "separate development" with the National Party victory in 1948, following the "colour bar"-discriminatory legislation dating back to the beginning of the Union of South Africa and the Boer republics before which, while repressive to black South Africans along with other minorities, had not gone nearly so far.

Apartheid laws can be generally divided into following acts. Firstly, the Population Registration Act in 1950 classified residents in South Africa into four racial groups: "black", "white", "Coloured", and "Indian" and noted their racial identities on their identifications. Secondly, the Group Areas Act in 1950 assigned different regions according to different races. People were forced to live in their corresponding regions and the action of passing the boundaries without a permit was made illegal, extending pass laws that had already curtailed black movement. Thirdly, under the Reservation of Separate Amenities Act in 1953, amenities in public areas, like hospitals, universities and parks, were labeled separately according to particular races. In addition, the Bantu Education Act in 1953 segregated national education in South Africa as well. Additionally, the government of the time enforced the pass laws, which deprived black South Africans of their right to travel freely within their own country. Under this system black people were severely restricted from urban areas, requiring authorisation from a white employer to enter.

Uprisings and protests against apartheid appeared immediately when apartheid arose. As early as 1949, the youth wing of the African National Congress (ANC) advocated the ending of apartheid and suggested fighting against racial segregation by various methods. During the following decades, hundreds of anti-apartheid actions occurred, including those of the Black Consciousness Movement, students' protests, labor strikes, and church group activism etc. In 1991, the Abolition of Racially Based Land Measures Act was passed, repealing laws enforcing racial segregation, including the Group Areas Act. In 1994, Nelson Mandela won in the first multiracial democratic election in South Africa. His success fulfilled the ending of apartheid in South African history.

On 28 April 2007, the lower house of Bahraini Parliament passed a law banning unmarried migrant workers from living in residential areas. To justify the law MP Nasser Fadhala, a close ally of the government said "bachelors also use these houses to make alcohol, run prostitute rings or to rape children and housemaids".

Sadiq Rahma, technical committee head, who is a member of Al Wefaq said: "The rules we are drawing up are designed to protect the rights of both the families and the Asian bachelors (..) these labourers often have habits which are difficult for families living nearby to tolerate (..) they come out of their homes half dressed, brew alcohol illegally in their homes, use prostitutes and make the neighbourhood dirty (..) these are poor people who often live in groups of 50 or more, crammed into one house or apartment," said Mr Rahma. "The rules also state that there must be at least one bathroom for every five people (..) there have also been cases in which young children have been sexually molested."

Bahrain Centre for Human Rights issued a press release condemning this decision as discriminatory and promoting negative racist attitudes towards migrant workers. Nabeel Rajab, then BCHR vice president, said: "It is appalling that Bahrain is willing to rest on the benefits of these people's hard work, and often their suffering, but that they refuse to live with them in equality and dignity. The solution is not to force migrant workers into ghettos, but to urge companies to improve living conditions for workers â and not to accommodate large numbers of workers in inadequate space, and to improve the standard of living for them."

Since the 1970s, there has been a concern expressed by some academics that major Canadian cities are becoming more segregated on income and ethnic lines. Reports have indicated that the inner suburbs of post-merger Toronto and the southern bedroom communities of Greater Vancouver have become steadily more immigrant and visible minority dominated communities and have lagged behind other neighbourhoods in average income. A CBC panel in Vancouver in 2012 discussed the growing public fear that the proliferation of ethnic enclaves in Greater Vancouver (such as Han Chinese in Richmond and Punjabis in Surrey) amounted to a type of self-segregation. In response to these fears, many minority activists have pointed out that most Canadian neighbourhoods remain predominately White, and yet Whites are never accused of "self-segregation".

The Mohawk tribe of Kahnawake has been criticized for evicting non-Mohawks from the Mohawk reserve. Mohawks who marry outside of their tribal nation lose their right to live in their homelands. The Mohawk government claims that its policy of nationally exclusive membership is for the preservation of its identity, but there is no exemption for those who adopt Mohawk language or culture. The policy is based on a 1981 moratorium which was made law in 1984. All interracial couples are sent eviction notices regardless of how long they have lived on the reserve. The only exemption is for mixed national couples married before the 1981 moratorium.

Although some concerned Mohawk citizens contested the nationally exclusive membership policy, the Canadian Human Rights Tribunal ruled that the Mohawk government may adopt policies it deems necessary to ensure the survival of its people.

A long-standing practice of national segregation has also been imposed upon the commercial salmon fishery in British Columbia since 1992 when separate commercial fisheries were created for select aboriginal groups on three B.C. river systems. Canadians of other nations who fish in the separate fisheries have been arrested, jailed and prosecuted. Although the fishermen who were prosecuted were successful at trial (see the decision in R. v. Kapp), the decision was overturned on appeal. On final appeal, the Supreme Court of Canada ruled in favour of the program on the grounds that segregation of this workplace is a step towards equality in Canada. Affirmative action programs in Canada are protected from equality rights challenges by s. 15(2) of the Canadian Charter of Rights and Freedoms. Segregation continues today, but more than 35% of the fishermen in the BC commercial fishery are of aboriginal ancestry, yet Canadians of aboriginal ancestry comprise less than 4% of BC's population.

Two military coups in Fiji in 1987 removed a democratically elected government led by an Indo-Fijians. The coup was supported principally by the ethnic Fijian population. A new constitution was promulgated in 1990, establishing Fiji as a republic, with the offices of President, Prime Minister, two-thirds of the Senate, and a clear majority of the House of Representatives reserved for ethnic Fijians; ethnic Fijian ownership of the land was also entrenched in the constitution. Most of these provisions were ended with the promulgation of the 1997 Constitution, although the President, and 14 of the 32 Senators were still selected by the all-indigenous Great Council of Chiefs. The last of these distinctions were removed by the 2013 Constitution.

Fiji's case is a situation of de facto ethnic segregation. Fiji has a long complex history with more than 3500 years as a divided tribal nation. Unification under the British rule as a colony for 96 years brought other racial groups, particularly immigrants from the Indian subcontinent.

Israeli Declaration of Independence proclaims equal rights to all citizens regardless of ethnicity, denomination or race. Israel has a substantial list of laws that demand racial equality (such as prohibition of discrimination, equality in Employment, libel based on race or ethnicity.). There is however, in practice, significant institutional, legal, and societal discrimination against the country's Arab citizens.

In 2010, the Israeli supreme court sent a message against racial segregation in a case involving the Slonim Hassidic sect of the Ashkenazi Jews, ruling that segregation between Ashkenazi and Sephardi students in a school is illegal. They argue that they seek "to maintain an equal level of religiosity, not from racism". Responding to the charges, the Slonim Haredim invited Sephardi girls to school, and added in a statement: "All along, we said it's not about race, but the High Court went out against our rabbis, and therefore we went to prison."

Due to many cultural differences, and animosity towards a minority perceived to wish to annihilate Israel, a system of passively co-existing communities, segregated along ethnic lines has emerged in Israel, with Arab-Israeli minority communities being left "marooned outside the mainstream". This de facto segregation also exists between different Jewish ethnic groups (""edot"") such as Sepharadim, Ashkenazim and Beta Israel (Jews of Ethiopian descent), which leads to de facto segregated schools, housing and public policy. The government has embarked on a program to shut down such schools, in order to force integration, but some in the Ethiopian community complained that not all such schools have been closed. In a 2007 poll commissioned by the Center Against Racism and conducted by the GeoCartographia Institute, 75% of Israeli Jews would not agree to live in a building with Arab residents, 60% would not accept any Arab visitors at their homes, 40% believed that Arabs should be stripped of their right to vote, and 59% believe that the culture of Arabs is primitive. In 2012, a public opinion poll showed that 53% of the polled Israeli Jews said they would not object to an Arab living in their building, while 42% said they would. Asked whether they would object to Arab children being in their child's class in school, 49% said they would not, 42% said they would. The secular Israeli public was found to be the most tolerant, while the religious and Haredi respondents were the most discriminatory.

The end of British colonial rule in Kenya in 1964 led to an inadvertent increase in ethnic segregation. Through private purchases and government schemes, farm land previously held by European farmers was transferred to African owners. These farms were further sub-divided into smaller localities, and, due to joint migration, many adjacent localities were occupied by members of different ethnic groups. This separation along these boundaries persists today. Kimuli Kasara, in a study of recent ethnic violence in the wake of the disputed 2007/2008 Kenyan elections, used these post-colonial boundaries as an instrument for the degree of ethnic segregation. Through a 2 Stage Least Squares Regression analysis, Kasara showed that increased ethnic segregation in Kenya's Rift Valley Province is associated with an increase in ethnic violence.

Liberian Constitution limits Liberian nationality to Negro people (see also Liberian nationality law).

For example, Lebanese and Indian nationals are active in trading, as well as in the retail and service sectors. Europeans and Americans work in the mining and agricultural sectors. These minority groups have long tenured residence in the Republic, but many are precluded from becoming citizens as a result of their race.

Malaysia has an article in its constitution which distinguishes the ethnic Malays and indigenous peoples of Malaysiaâi.e. bumiputraâfrom the non-Bumiputra such as ethnic Chinese and Indians under the social contract, of which by law would guarantee the former certain special rights and privileges. To question these rights and privileges however is strictly prohibited under the Internal Security Act, legalised by the 10th Article(IV) of the Constitution of Malaysia. The privileges mentioned herein coversâfew of whichâthe economical and education aspects of Malaysians, e.g. the Malaysian New Economic Policy; an economic policy recently criticised by Thierry Rommelâwho headed a European Commission's delegation to Malaysiaâas an excuse for "significant protectionism" and a quota maintaining higher access of Malays into public universities.

While legal racial segregation in daily life is not practiced, self-segregation does exist.

Slavery in Mauritania was finally criminalized in August 2007. It was already abolished in 1980, although it was still affecting the black Africans. The number of slaves in the country was not known exactly, but it was estimated to be up to 600,000 men, women and children, or 20% of the population.

For centuries, the so-called Haratin lower class, mostly poor black Africans living in rural areas, have been considered natural slaves by white Moors of Arab/Berber ancestry. Many descendants of the Arab and Berber tribes today still adhere to the supremacist ideology of their ancestors. This ideology has led to oppression, discrimination and even enslavement of other groups in the region of Sudan and Western Sahara. 

The United Kingdom has no legally sanctioned system of racial segregation and has a substantial list of laws that demand racial equality. However, due to many cultural differences between the pre-existing system of passively co-existing communities, segregation along racial lines has emerged in parts of the United Kingdom, with minority communities being left "marooned outside the mainstream".

The affected and 'ghettoised' communities are often largely representative of Pakistanis, Indians and other Sub-Continentals, and has been thought to be the basis of ethnic tensions, and a deterioration of the standard of living and levels of education and employment among ethnic minorities in poorer areas. These factors are considered by some to have been a cause of the 2001 race riots in Bradford, Oldham and Burnley in the north of England which have large Asian communities.

There may be some indication that such segregation, particularly in residential terms, seems to be the result of the unilateral 'steering' of ethnic groups into particular areas as well as a culture of vendor discrimination and distrust of ethnic minority clients by some estate agents and other property professionals. This may be indicative of a market preference amongst the more wealthy to reside in areas of less ethnic mixture; less ethnic mixture being perceived as increasing the value and desirability of a residential area. This is likely as other theories such as "ethnic self segregation" have sometimes been shown to be baseless, and a majority of ethnic respondents to a few surveys on the matter have been in favour of wider social and residential integration.

De facto segregation in the United States has increased since the civil rights movement. The Supreme Court ruled in Milliken v. Bradley (1974) that de facto racial segregation was acceptable, as long as schools were not actively making policies for racial exclusion; since then, schools have been segregated due to myriad indirect factors.

Redlining is part of how white communities maintained racist segregation. It is the practice of denying or increasing the cost of services, such as mortgages, banking, insurance, access to jobs, access to health care, or even supermarkets to residents in certain, often racially determined, areas. The most devastating form of redlining, and the most common use of the term, refers to mortgage discrimination. Over the next twenty years, a succession of further court decisions and federal laws, including the "Home Mortgage Disclosure Act" and measure to end mortgage discrimination in 1975, would completely invalidate "de jure" racial segregation and discrimination in the U.S., although "de facto" segregation and discrimination have proven more resilient. According to the Civil Rights Project at Harvard University, the actual de facto desegregation of U.S. public schools peaked in the late 1980s; since that time, the schools have, in fact, become more segregated mainly due to the ethnic segregation of the nation with whites dominating the suburbs and minorities the urban centers. According to Rajiv Sethi, an economist at Columbia University, black-white segregation in housing is slowly declining for most metropolitan areas in the US. Racial segregation or separation can lead to social, economic and political tensions. Thirty years (the year 2000) after the civil rights era, the United States remained in many areas a residentially segregated society, in which blacks, whites and Hispanics inhabit different neighborhoods of vastly different quality.

Dan Immergluck writes that in 2002 small businesses in black neighborhoods still received fewer loans, even after accounting for businesses density, businesses size, industrial mix, neighborhood income, and the credit quality of local businesses. Gregory D. Squires wrote in 2003 that it is clear that race has long affected and continues to affect the policies and practices of the insurance industry. Workers living in American inner cities have a harder time finding jobs than suburban workers.

The desire of many whites to avoid having their children attend integrated schools has been a factor in white flight to the suburbs. A 2007 study in San Francisco showed that groups of homeowners of all races tended to self-segregate in order to be with people of the same education level and race. By 1990, the legal barriers enforcing segregation had been mostly replaced by decentralized racism, where white people pay more than black people to live in predominantly white areas. Today, many whites are willing to pay a premium to live in a predominantly white neighborhood. Equivalent housing in white areas commands a higher rent. These higher rents are largely attributable to exclusionary zoning policies that restrict the supply of housing. Regulations ensure that all housing units are expensive enough to prevent access by undesirable groups. By bidding up the price of housing, many white neighborhoods effectively shut out black people, because they may be unwilling, or unable, to pay the premium to buy entry into these expensive neighborhoods. Conversely, equivalent housing in black neighborhoods is far more affordable to those who are unable or unwilling to pay a premium to live in white neighborhoods. Through the 1990s, residential segregation remained at its extreme and has been called "hypersegregation" by some sociologists or "American Apartheid".

In February 2005, the U.S. Supreme Court ruled in "Johnson v. California" that the California Department of Corrections' unwritten practice of racially segregating prisoners in its prison reception centersâwhich California claimed was for inmate safety (gangs in California, as throughout the U.S., usually organize on racial lines)âis to be subject to strict scrutiny, the highest level of constitutional review.

In Yemen, the Arab elite practices a form of discrimination against the lower class Al-Akhdam people based on their racial system.






</doc>
<doc id="26317" url="https://en.wikipedia.org/wiki?curid=26317" title="Range">
Range

Range may refer to:










</doc>
<doc id="26318" url="https://en.wikipedia.org/wiki?curid=26318" title="Roslagen">
Roslagen

Roslagen is the name of the coastal areas of Uppland province in Sweden, which also constitutes the northern part of the Stockholm archipelago.

Historically, it was the name for all the coastal areas of the Baltic Sea, including the eastern parts of lake MÃ¤laren, belonging to Svealand. The name was first mentioned in the year 1493 as "Rodzlagen". Before that the area was known as "Roden", which is the coastal equivalent to inland Hundreds. When the king would issue a call to leidang, the Viking Age equivalent of military conscript service, Roden districts were responsible for raising a number of ships for the leidang navy.

The name comes from the "rodslag", which is an old coastal Uppland word for a rowing crew of warrior oarsmen. Etymologically, Roden, or Roslagen, is the source of the Finnish and Estonian names for Sweden: ' and '.

A person from Roslagen is called a "Rospigg" which means "inhabitant of Ros". Swedes from the Roslagen area, that is "the people of Ros", gave their name to the Rus' people and thus to the states of Russia and Belarus (see Rus' (name)).

The area also gives its name to the endangered domesticated Roslag sheep, which originated from the area centuries ago. It is served by the Roslagsbanan, a narrow-gauge railway network from Stockholm.




</doc>
<doc id="26321" url="https://en.wikipedia.org/wiki?curid=26321" title="Ramjet">
Ramjet

A ramjet, sometimes referred to as a flying stovepipe or an athodyd (aero thermodynamic duct), is a form of airbreathing jet engine that uses the engine's forward motion to compress incoming air without an axial compressor or a centrifugal compressor. Because ramjets cannot produce thrust at zero airspeed, they cannot move an aircraft from a standstill. A ramjet-powered vehicle, therefore, requires an assisted take-off like a rocket assist to accelerate it to a speed where it begins to produce thrust. Ramjets work most efficiently at supersonic speeds around . This type of engine can operate up to speeds of .

Ramjets can be particularly useful in applications requiring a small and simple mechanism for high-speed use, such as missiles. The US, Canada, and UK had widespread ramjet powered missile defenses during the 1960s onward, such as the CIM-10 Bomarc and Bloodhound. Weapon designers are looking to use ramjet technology in artillery shells to give added range; a 120Â mm mortar shell, if assisted by a ramjet, is thought to be able to attain a range of . They have also been used successfully, though not efficiently, as tip jets on the ends of helicopter rotors.

Ramjets differ from pulsejets, which use an intermittent combustion; ramjets employ a continuous combustion process.

As speed increases, the efficiency of a ramjet starts to drop as the air temperature in the inlet increases due to compression. As the inlet temperature gets closer to the exhaust temperature, less energy can be extracted in the form of thrust. To produce a usable amount of thrust at yet higher speeds, the ramjet must be modified so that the incoming air is not compressed (and therefore heated) nearly as much. This means that the air flowing through the combustion chamber is still moving very fast (relative to the engine), in fact it will be supersonicâhence the name supersonic-combustion ramjet, or scramjet.

"L'Autre Monde: ou les Ãtats et Empires de la Lune (Comical History of the States and Empires of the Moon)" (1657) was the first of three satirical novels written by Cyrano de Bergerac, that are considered among the first science fiction stories. Arthur C Clarke credited this book with inventing the ramjet, and being the first example of a rocket-powered space flight.

The ramjet was conceived in 1913 by French inventor RenÃ© Lorin, who was granted a patent for his device. Attempts to build a prototype failed due to inadequate materials.

In 1915, Hungarian inventor Albert FonÃ³ devised a solution for increasing the range of artillery, comprising a gun-launched projectile which was to be united with a ramjet propulsion unit, thus giving a long range from relatively low muzzle velocities, allowing heavy shells to be fired from relatively lightweight guns. FonÃ³ submitted his invention to the Austro-Hungarian Army, but the proposal was rejected. After World War I, FonÃ³ returned to the subject of jet propulsion, in May 1928 describing an "air-jet engine" which he described as being suitable for high-altitude supersonic aircraft, in a German patent application. In an additional patent application, he adapted the engine for subsonic speed. The patent was granted in 1932 after four years of examination (German Patent No. 554,906, 1932-11-02).

In the Soviet Union, a theory of supersonic ramjet engines was presented in 1928 by Boris Stechkin. Yuri Pobedonostsev, chief of GIRD's 3rd Brigade, carried out a great deal of research into ramjet engines. The first engine, the GIRD-04, was designed by I.A. Merkulov and tested in April 1933. To simulate supersonic flight, it was fed by air compressed to , and was fueled with hydrogen. The GIRD-08 phosphorus-fueled ramjet was tested by firing it from an artillery cannon. These shells may have been the first jet-powered projectiles to break the speed of sound.

In 1939, Merkulov did further ramjet tests using a two-stage rocket, the R-3. That August, he developed the first ramjet engine for use as an auxiliary motor of an aircraft, the DM-1. The world's first ramjet-powered airplane flight took place in December 1940, using two DM-2 engines on a modified Polikarpov I-15. Merkulov designed a ramjet fighter "Samolet D" in 1941, which was never completed. Two of his DM-4 engines were installed on the Yak-7 PVRD fighter, during World War II. In 1940, the Kostikov-302 experimental plane was designed, powered by a liquid fuel rocket for take-off and ramjet engines for flight. That project was cancelled in 1944.

In 1947, Mstislav Keldysh proposed a long-range antipodal bomber, similar to the SÃ¤nger-Bredt bomber, but powered by ramjet instead of rocket. In 1954, NPO Lavochkin and the Keldysh Institute began development of a Mach 3 ramjet-powered cruise missile, "Burya". This project competed with the R-7 ICBM being developed by Sergei Korolev, and was cancelled in 1957.

On March 1, 2018 President Vladimir Putin announced Russia had developed a (presumed) nuclear powered ramjet cruise missile capable of extended long range flight.

In 1936, Hellmuth Walter constructed a test engine powered by natural gas. Theoretical work was carried out at BMW and Junkers, as well as DFL. In 1941, Eugen SÃ¤nger of DFL proposed a ramjet engine with a very high combustion chamber temperature. He constructed very large ramjet pipes with and diameter and carried out combustion tests on lorries and on a special test rig on a Dornier Do 17Z at flight speeds of up to . Later, with petrol becoming scarce in Germany due to wartime conditions, tests were carried out with blocks of pressed coal dust as a fuel, which were not successful due to slow combustion.

The US Navy developed a series of air-to-air missiles under the name of "Gorgon" using different propulsion mechanisms, including ramjet propulsion on the Gorgon IV. The ramjet Gorgon IVs, made by Glenn Martin, were tested in 1948 and 1949 at Naval Air Station Point Mugu. The ramjet engine itself was designed at the University of Southern California and manufactured by the Marquardt Aircraft Company. The engine was long and in diameter and was positioned below the missile.

In the early 1950s the US developed a Mach 4+ ramjet under the Lockheed X-7 program. This was developed into the Lockheed AQM-60 Kingfisher. Further development resulted in the Lockheed D-21 spy drone. 

In the late 1950s the US Navy introduced a system called the RIM-8 Talos, which was a long range surface to air missile fired from ships. It successfully shot down several enemy fighters during the Vietnam war, and was the first ship launched missile to ever successfully destroy an enemy aircraft in combat. On May 23, 1968, a Talos fired from USS Long Beach shot down a Vietnamese MiG at a range of about 65 miles. It was also used as a surface to surface weapon, and was also successfully modified to destroy land based radar systems. 

Using the technology proven by the AQM-60, In the late 1950s and early 1960s the US produced a widespread defense system called the CIM-10 Bomarc, which was equipped with hundreds of nuclear armed ramjet missiles with a range of several hundred miles. It was powered by the same engines as the AQM-60, but with improved materials to withstand the longer flight times. The system was withdrawn in the 1970s as the threat from bombers was reduced. 

In the early 1960s the US developed the Lockheed A-12, a Mach 3 capable spy plane. This was developed into a missile armed interceptor called the Lockheed YF-12. The YF-12 was later developed into the famous Lockheed SR-71 Blackbird, which holds numerous world speed records to this day.

In the late 1950s and early 1960s the UK developed several ramjet missiles. 

A project called Blue Envoy was supposed to equip the country with a long range ramjet powered air defense against bombers, but the system was eventually cancelled. 

It was replaced by a much shorter range ramjet missile system called the Bloodhound. The system was designed as a second line of defense in case attackers were able to bypass the fleet of defending English Electric Lightning fighters. 

In the 1960s the Royal Navy developed and deployed a ramjet powered surface to air missile for ships called the Sea Dart. It had a range of 40-80 miles and a speed of Mach 3. It was use successfully in combat against multiple types of aircraft during the Falklands War. 

Eminent Swiss astrophysicist Fritz Zwicky was research director at Aerojet and holds many patents in jet propulsion. U.S. patents 5121670 and 4722261 are for ram accelerators. The U.S. Navy would not allow Fritz Zwicky to publicly discuss his own invention, U.S. Patent 2,461,797 for the Underwater Jet, a ram jet that performs in a fluid medium. "Time" magazine reported Fritz Zwicky's work in the articles "Missed Swiss" on July 11, 1955 and "Underwater Jet" in the March 14, 1949 issue.

In France, the works of RenÃ© Leduc were notable. Leduc's Model, the Leduc 0.10 was one of the first ramjet-powered aircraft to fly, in 1949.

The Nord 1500 Griffon reached in 1958.

The Brayton cycle is a thermodynamic cycle that describes the workings of the gas turbine engine, the basis of the airbreathing jet engine and others. It is named after George Brayton, the American engineer who developed it, although it was originally proposed and patented by Englishman John Barber in 1791. It is also sometimes known as the Joule cycle.

A ramjet is designed around its inlet. An object moving at high speed through air generates a high pressure region upstream. A ramjet uses this high pressure in front of the engine to force air through the tube, where it is heated by combusting some of it with fuel. It is then passed through a nozzle to accelerate it to supersonic speeds. This acceleration gives the ramjet forward thrust.

A ramjet is sometimes referred to as a "flying stovepipe", a very simple device comprising an air intake, a combustor, and a nozzle. Normally, the only moving parts are those within the turbopump, which pumps the fuel to the combustor in a liquid-fuel ramjet. Solid-fuel ramjets are even simpler.

By way of comparison, a turbojet uses a gas turbine-driven fan to compress the air further. This gives greater compression and efficiency and far more power at low speeds (where the ram effect is weak), but is more complex, heavier, expensive, and the temperature limits of the turbine section limit the top speed and thrust at high speed.

Ramjets try to exploit the very high dynamic pressure within the air approaching the intake lip. An efficient intake will recover much of the freestream stagnation pressure, which is used to support the combustion and expansion process in the nozzle.

Most ramjets operate at supersonic flight speeds and use one or more conical (or oblique) shock waves, terminated by a strong normal shock, to slow down the airflow to a subsonic velocity at the exit of the intake. Further diffusion is then required to get the air velocity down to a suitable level for the combustor.
Subsonic ramjets do not need such a sophisticated inlet, since the airflow is already subsonic, and a simple hole is usually used. This would also work at slightly supersonic speeds, but as the air will choke at the inlet, this is inefficient.

The inlet is divergent, to provide a constant inlet speed of .

As with other jet engines, the combustor's job is to create hot air, by burning a fuel with the air at essentially constant pressure. The airflow through the jet engine is usually quite high, so sheltered combustion zones are produced by using "flame holders" to stop the flames from blowing out.

Since there is no downstream turbine, a ramjet combustor can safely operate at stoichiometric fuel:air ratios, which implies a combustor exit stagnation temperature of the order of for kerosene. Normally, the combustor must be capable of operating over a wide range of throttle settings, for a range of flight speeds/altitudes. Usually, a sheltered pilot region enables combustion to continue when the vehicle intake undergoes high yaw/pitch during turns. Other flame stabilization techniques make use of flame holders, which vary in design from combustor cans to simple flat plates, to shelter the flame and improve fuel mixing. Overfuelling the combustor can cause the normal shock within a supersonic intake system to be pushed forward beyond the intake lip, resulting in a substantial drop in engine airflow and net thrust.

The propelling nozzle is a critical part of a ramjet design, since it accelerates exhaust flow to produce thrust.

For a ramjet operating at a subsonic-flight Mach number, exhaust flow is accelerated through a converging nozzle. For a supersonic-flight Mach number, acceleration is typically achieved by a convergentâdivergent nozzle.

Although ramjets have been run as slow as , below about they give little thrust and are highly inefficient due to their low pressure ratios.

Above this speed, given sufficient initial flight velocity, a ramjet will be self-sustaining. Indeed, unless the vehicle drag is extremely high, the engine/airframe combination will tend to accelerate to higher and higher flight speeds, substantially increasing the air intake temperature. As this could have a detrimental effect on the integrity of the engine and/or airframe, the fuel control system must reduce engine fuel flow to stabilize the flight Mach number and, thereby, air intake temperature to reasonable levels.

Due to the stoichiometric combustion temperature, efficiency is usually good at high speeds (around ), whereas at low speeds the relatively poor pressure ratio means the ramjets are outperformed by turbojets, or even rockets.

Ramjets can be classified according to the type of fuel, liquid or solid; and the booster.

In a liquid fuel ramjet (LFRJ), hydrocarbon fuel (typically) is injected into the combustor ahead of a flameholder which stabilises the flame resulting from the combustion of the fuel with the compressed air from the intake(s). A means of pressurizing and supplying the fuel to the ramcombustor is required, which can be complicated and expensive. AÃ©rospatiale-Celerg designed an LFRJ where the fuel is forced into the injectors by an elastomer bladder which inflates progressively along the length of the fuel tank. Initially, the bladder forms a close-fitting sheath around the compressed air bottle from which it is inflated, which is mounted lengthwise in the tank. This offers a lower-cost approach than a regulated LFRJ requiring a turbopump and associated hardware to supply the fuel.

A ramjet generates no static thrust and needs a booster to achieve a forward velocity high enough for efficient operation of the intake system. The first ramjet-powered missiles used external boosters, usually solid-propellant rockets, either in tandem, where the booster is mounted immediately aft of the ramjet, e.g. Sea Dart, or wraparound where multiple boosters are attached alongside the outside of the ramjet, e.g. 2K11 Krug. The choice of booster arrangement is usually driven by the size of the launch platform. A tandem booster increases the overall length of the system, whereas wraparound boosters increase the overall diameter. Wraparound boosters will usually generate higher drag than a tandem arrangement.

Integrated boosters provide a more efficient packaging option, since the booster propellant is cast inside the otherwise empty combustor. This approach has been used on solid, for example 2K12 Kub, liquid, for example ASMP, and ducted rocket, for example Meteor, designs. Integrated designs are complicated by the different nozzle requirements of the boost and ramjet phases of flight. Due to the higher thrust levels of the booster, a differently shaped nozzle is required for optimum thrust compared to that required for the lower thrust ramjet sustainer. This is usually achieved via a separate nozzle, which is ejected after booster burnout. However, designs such as Meteor feature nozzleless boosters. This offers the advantages of elimination of the hazard to launch aircraft from the ejected boost nozzle debris, simplicity, reliability, and reduced mass and cost, although this must be traded against the reduction in performance compared with that provided by a dedicated booster nozzle.

A slight variation on the ramjet uses the supersonic exhaust from a rocket combustion process to compress and react with the incoming air in the main combustion chamber. This has the advantage of giving thrust even at zero speed.

In a solid fuel integrated rocket ramjet (SFIRR), the solid fuel is cast along the outer wall of the ramcombustor. In this case, fuel injection is through ablation of the propellant by the hot compressed air from the intake(s). An aft mixer may be used to improve combustion efficiency. SFIRRs are preferred over LFRJs for some applications because of the simplicity of the fuel supply, but only when the throttling requirements are minimal, i.e. when variations in altitude or Mach number are limited.

In a ducted rocket, a solid fuel gas generator produces a hot fuel-rich gas which is burnt in the ramcombustor with the compressed air supplied by the intake(s). The flow of gas improves the mixing of the fuel and air and increases total pressure recovery. In a throttleable ducted rocket, also known as a variable flow ducted rocket, a valve allows the gas generator exhaust to be throttled allowing control of the thrust. Unlike an LFRJ, solid propellant ramjets cannot flame out. The ducted rocket sits somewhere between the simplicity of the SFRJ and the unlimited throttleability of the LFRJ.

Ramjets generally give little or no thrust below about half the speed of sound, and they are inefficient (less than 600 seconds) until the airspeed exceeds due to low compression ratios. Due to lacking subsonic thrust, ramjet equipped aircraft sometimes struggle to break the sound barrier to ignite their ramjets. The turbine engines on the SR-71 blackbird had problems reaching supersonic speed when the aircraft was fully loaded, and so the pilots would sometimes have to climb subsonically to gain altitude, then dive the aircraft at supersonic speeds in order to ignite the ramjets. After its ramjets engaged the SR-71 had such high thrust that it was capable of accelerating beyond mach 2.6 while in a climb. This required special attention from the pilots to avoid overshooting the intended cruise altitude at such great speeds. 

Even above the minimum speed, a wide flight envelope (range of flight conditions), such as low to high speeds and low to high altitudes, can force significant design compromises, and they tend to work best optimised for one designed speed and altitude (point designs). However, ramjets generally outperform gas turbine-based jet engine designs and work best at supersonic speeds (Mach 2â4). Although inefficient at slower speeds, they are more fuel-efficient than rockets over their entire useful working range up to at least . 
The performance of conventional ramjets falls off above Mach 6 due to dissociation and pressure loss caused by shock as the incoming air is slowed to subsonic velocities for combustion. In addition, the combustion chamber's inlet temperature increases to very high values, approaching the dissociation limit at some limiting Mach number.

An air turboramjet has a compressor powered by a gas heated via a heat exchanger within the combustion chamber.

Ramjets always slow the incoming air to a subsonic velocity within the combustor. Scramjets are similar to ramjets, but some of the air goes through the entire engine at supersonic speeds. This increases the stagnation pressure recovered from the freestream and improves net thrust. Thermal choking of the exhaust is avoided by having a relatively high supersonic air velocity at combustor entry. Fuel injection is often into a sheltered region below a step in the combustor wall. Although scramjet engines have been studied for many decades, only recently have small experimental units been flight tested and then only very briefly (e.g. the Boeing X-43).

As of May 2010, this engine has been tested to attain for 200 seconds on the X-51A Waverider.

A variant of the pure ramjet is the 'combined cycle' engine, intended to overcome the limitations of the pure ramjet. One example of this is the SABRE engine; this uses a precooler, behind which is the ramjet and turbine machinery.

The ATREX engine developed in Japan is an experimental implementation of this concept. It uses liquid hydrogen fuel in a fairly exotic single-fan arrangement. The liquid hydrogen fuel is pumped through a heat exchanger in the air intake, simultaneously heating the liquid hydrogen and cooling the incoming air. This cooling of the incoming air is critical to achieving a reasonable efficiency. The hydrogen then continues through a second heat exchanger position after the combustion section, where the hot exhaust is used to further heat the hydrogen, turning it into a very high pressure gas. This gas is then passed through the tips of the fan to provide driving power to the fan at subsonic speeds. After mixing with the air, it is burned in the combustion chamber.

The Reaction Engines Scimitar has been proposed for the LAPCAT hypersonic airliner, and the Reaction Engines SABRE for the Reaction Engines Skylon spaceplane.

During the Cold War, the United States designed and ground-tested a nuclear-powered ramjet called Project Pluto. This system, intended for use in a cruise missile, used no combustion; a high-temperature, unshielded nuclear reactor heated the air instead. The ramjet was predicted to be able to fly at supersonic speeds for months. Because the reactor was unshielded, it was dangerous to anyone in or around the flight path of the low-flying vehicle (although the exhaust itself wasn't radioactive). The project was ultimately cancelled because ICBMs seemed to serve the purpose better.

The upper atmosphere above about contains monatomic oxygen produced by the sun through photochemistry. A concept was created by NASA for recombining this thin gas back to diatomic molecules at orbital speeds to power a ramjet.

The Bussard ramjet is a spacecraft propulsion concept intended to fuse interstellar wind and exhaust it at high speed from the rear of the vehicle.




</doc>
<doc id="26324" url="https://en.wikipedia.org/wiki?curid=26324" title="Ranma Â½">
Ranma Â½

"Ranma Â½" has a comedic formula and a sex-changing main character, who often willfully transforms into a girl to advance his goals. The series also contains many other characters, whose intricate relationships with each other, unusual characteristics, and eccentric personalities drive most of the stories. Although the characters and their relationships are complicated, they rarely change once they are firmly introduced and settled into the series.

The manga has been adapted into two anime series created by Studio Deen: "Ranma Â½" and , which together were broadcast on Fuji Television from 1989 to 1992. In addition, they developed 12 original video animations and three films. In 2011, a live-action television special was produced and aired on Nippon Television. The manga and anime series were licensed by Viz Media for English-language releases in North America. Madman Entertainment released the manga, part of the anime series and the first two movies in Australasia, while MVM Films released the first two movies in the United Kingdom. The "Ranma Â½" manga has over 53 million copies in print in Japan. Both the manga and anime are cited as some of the first of their mediums to have become popular in the United States.

On a training journey in the Bayankala Mountain Range in the Qinghai Province of China, Ranma Saotome and his father Genma fall into the cursed springs at . When someone falls into a cursed spring, they take the physical form of whatever drowned there hundreds or thousands of years ago whenever they come into contact with cold water. The curse will revert when exposed to hot water until their next cold water exposure. Genma fell into the spring of a drowned panda while Ranma fell into the spring of a drowned girl.

Soun Tendo is a fellow practitioner of or "Anything-Goes School" of martial arts and owner of a dojo. Genma and Soun agreed years ago that their children would marry and carry on the Tendo Dojo. Soun has three teenaged daughters: the polite and easygoing Kasumi, the greedy and indifferent Nabiki and the short-tempered, martial arts practicing Akane. Akane, who is Ranma's age, is appointed for bridal duty by her sisters with the reasoning that they are the older sisters and can dump the duty on her, and that they all dislike the arranged engagement and think Akane's dislike of men is the right way to express it to the fathers. At the appointed time they are surprised when a panda comes in and puts a girl in front of their father. The Tendo girls all laugh. It takes several more pages for the situation to be explained to Soun Tendo and his daughters. Both Ranma and Akane refuse the engagement initially, having not been consulted on the decision, but the fathers are insistent and they are generally treated as betrothed and end up helping or saving each other on some occasions. They are frequently found in each other's company and are constantly arguing in their trademark awkward love-hate manner that is a franchise focus.

Ranma goes to school with Akane at , where he meets his recurring opponent Tatewaki Kuno, the conceited kendo team captain who aggressively pursues Akane, but also falls in love with Ranma's female form without ever discovering his curse (despite most other characters eventually knowing it). Nerima serves as a backdrop for more martial arts mayhem with the introduction of Ranma's regular rivals, such as the eternally lost Ryoga Hibiki who traveled halfway across Japan getting from the front of his house to the back, where Ranma spent three days waiting for him. Ryoga, seeking revenge on Ranma, followed him to Jusenkyo where he ultimately fell into the Spring of the Drowned Piglet. Now when splashed with cold water he takes the form of a little black pig. Not knowing this, Akane takes the piglet as a pet and names it P-chan, but Ranma knows and hates him for keeping this secret and taking advantage of the situation. Another rival is the nearsighted Mousse, who also fell into a cursed spring and becomes a duck when he gets wet, and finally, there is Genma and Soun's impish grandmaster, Happosai, who spends his time stealing the underwear of schoolgirls.

Ranma's prospective paramours include the martial arts rhythmic gymnastics champion Kodachi Kuno, and his second fiancÃ©e and childhood friend Ukyo Kuonji the okonomiyaki vendor, along with the Chinese Amazon Shampoo, supported by her great-grandmother Cologne. As the series progresses, the school becomes more eccentric with the return of the demented, Hawaii-obsessed Principal Kuno and the placement of the power-leeching alternating child/adult Hinako Ninomiya as Ranma's English teacher. Ranma's indecision to choose his true love causes chaos in his romantic and school life.

Rumiko Takahashi stated that "Ranma Â½" was conceived to be a martial arts manga that connects all aspects of everyday life to martial arts. Because her previous series had female protagonists, the author decided that she wanted a male this time. However, she was worried about writing a male main character, and therefore decided to make him half-female. Before deciding on water for initiating his changes, she considered Ranma changing every time he was punched. It was after deciding this that she felt Jusenkyo had to be set in China, as it is the only place that could have such mysterious springs. She drew inspiration for "Ranma Â½" from a variety of real-world objects. Some of the places frequently seen in the series are modeled after actual locations in Nerima, Tokyo (both the home of Takahashi and the setting of "Ranma Â½").

In a 1990 interview with "Amazing Heroes", Takahashi stated that she had four assistants that draw the backgrounds, panel lines and tone, while she creates the story and layout, and pencils and inks the characters. All her assistants are female; Takahashi stated that "I don't use male assistants so that the girls will work more seriously if they aren't worried about boys." In 1992, she explained her process as beginning with laying out the chapter in the evening so as to finish it by dawn, and resting for a day before calling her assistants. They finish it in two or three nights, usually utilizing five days for a chapter.

Takahashi purposefully aimed the series to be popular with women and children. In 1993, an "Animerica" interviewer talking with Takahashi asked her if she intended the sex-changing theme "as an effort to enlighten a male-dominated society." Takahashi said that she does not think in terms of societal agendas and that she created the "Ranma Â½" concept from simply wanting "a simple, fun idea". She added that she, as a woman and while recalling what manga she liked to read as a child, felt that "humans turning into animals might also be fun and ... you know, like a fairy tale." In 2013, she revealed that at the start of "Ranma" her editor told her to make it more dramatic, but she felt that was something she could not do. However, she admitted that drama did start to appear at the end. She also sat in on the voice actor auditions for the anime, where she insisted that male and female Ranma be voiced by different actors whose gender corresponded to that of the part.

Written and illustrated by Rumiko Takahashi, "Ranma Â½" began publication in "Weekly ShÅnen Sunday" issue #36 published on August 19, 1987, following the ending of her series "Urusei Yatsura". From August 1987 until March 1996, the manga was published on a near weekly basis with the occasional colored page to spruce up the usually black and white stories. After nearly a decade of storylines, the final chapter was published in "Weekly ShÅnen Sunday" issue #12 on March 6, 1996. The 407 chapters were periodically collected and published by Shogakukan into a total of 38 black and white "tankÅbon" volumes from 1988 to 1996. They were reassembled into 38 "shinsÅban" from April 2002 to October 2003.

North American publisher Viz Media originally released "Ranma Â½" in a monthly comic book format that contained two chapters each from 1992 to 2003, and had the images "flipped" to read left-to-right, causing the art to be mirrored. These were periodically collected into graphic novels. On March 18, 2004, after releasing 21 volumes, Viz announced that it would reprint a number of its graphic novels. The content remained the same, but the novels moved to a smaller format with different covers and a price drop. Each volume covers roughly the same amount of material as the Japanese volumes, but retained its left-to-right format and had minor differences in grouping so that it spans 36 volumes rather than the original 38. The final volume was released in stores on November 14, 2006, thus making it Viz's longest running manga, spanning over 13 years. At Anime Expo on July 7, 2013, Viz Media announced re-release of the manga in a format that combines two individual volumes into a single large one, and restores the original right-to-left reading order (a first in North America for this series). The first 2-in-1 book (volumes 1-2) was published on March 11, 2014; the final (volumes 35-36) in January, 2017. Madman Entertainment publishes the two-in-one version in Australasia.

Together with "Spriggan", it was the first manga published in Portugal, by Texto Editora in 1995.

An anime television series was created by Studio Deen and aired weekly between April 15, 1989, and September 16, 1989, on Fuji TV for 18 episodes, before being canceled due to low ratings. The series was then reworked by most of the same staff, retitled and launched in a different time slot, running for 143 episodes from October 20, 1989, to September 25, 1992. The anime stays true to the original manga but does differ by keeping Ranma's sex transformation a secret from the high school students, at least throughout most of its length. It also does not introduce Hikaru Gosunkugi until very late in the series, instead, Sasuke Sarugakure, the diminutive ninja retainer of the Kuno family fills a number of Gosunkugi's roles in early storylines but is a major character in his own right. The anime also alters the placement of many story arcs and contains numerous original episodes and characters not adapted from the manga.

Viz Media licensed both anime series in 1993, making "Ranma Â½" one of the very first anime titles licensed by Viz. The English dub produced for the series was recorded by The Ocean Group in Vancouver, British Columbia. They released the series on VHS from their own "Viz Video" label, and on DVD a few years later in association with Pioneer Home Entertainment. Their releases collected both anime series as one, separated episodes into what they call "seasons", and changed the ordering of many of the episodes. Viz themselves re-released it on DVD in 2007 using their own DVD production company. At Otakon 2013, Viz announced that they re-acquired the TV series for Blu-ray and DVD release in 2014. The show is streamed on their anime channel service Neon Alley since Autumn 2013. Madman Entertainment licensed some of the series for release in Australasia, although their rights expired after releasing only the first four "seasons" as one series.

Studio Deen also created three theatrical films; "The Battle of Nekonron, China! A Battle to Defy the Rules!" on November 2, 1991; "Battle at Togenkyo! Get Back the Brides" on August 1, 1992; and "Super Indiscriminate Decisive Battle! Team Ranma vs. the Legendary Phoenix" on August 20, 1994. The first two movies are feature length, but the third was originally shown in theaters with two other movies: "Ghost Sweeper Mikami" and "Heisei Dog Stories: Bow".

Following the ending of the TV series, 11 original video animations were released directly to home video, the earliest on December 7, 1993, and the eleventh on June 4, 1996. All but one are based on stories originally in the manga. Twelve years later, a "Ranma" animation was created for the "It's a Rumic World" exhibition of Rumiko Takahashi's artwork. Based on the "Nightmare! Incense of Deep Sleep" manga story from volume 34, it was shown on odd numbered days at the exhibition in Tokyo from July 30 to August 11, 2008. But it was not released until January 29, 2010, when it was put in a DVD box set with the "Urusei Yatsura" and "Inuyasha" specials that premiered at the same exhibit. It was then released on DVD and Blu-ray by itself on October 20, 2010. Viz Media also licensed all three movies, and the original 11 OVAs for distribution in North America (however they released the third movie as an OVA). MVM Films has released the first two movies in the United Kingdom, while Madman Entertainment released them in Australasia.

There have been fifteen video games based on the "Ranma Â½" franchise. While most are fighting games, there have been several RPGs and puzzle games. Only two have been released in Western countries. "Ranma Â½: ChÅnai GekitÅhen" was released in the US as "Street Combat"; the characters were Americanized, having their appearances completely changed, and the music was changed as well. However, "" was released in both North America and Europe unaltered.

A live action television adaption of "Ranma Â½" aired on Nippon TV, in a two-hour time-slot, on December 9, 2011. Although it was initially reported that the special would contain an original story, the movie does take its main plot from one of the manga's early stories with several other early scenes mixed in. The special stars Yui Aragaki as Akane, with Kento Kaku and Natsuna Watanabe playing male and female Ranma respectively. RyÅsei Tayama is cast as the antagonist, the new original character Okamada. The all-girl pop group 9nine contribute "Chikutakuâ2Nite" as the theme song. It was released on both DVD and Blu-ray on March 21, 2012.

"The Ranma Â½ Memorial Book" was published just as the manga ended in 1996. Acting as an end-cap to the series, it collects various illustrations from the series, features an interview with Takahashi, and includes tidbits about Ranma: summaries of his battles, his daily schedule, trivia, and a few exclusive illustrations. 
A "Movie + OVA Visual Comic" was released to illustrate the theatrical film "Super Indiscriminate Decisive Battle! Team Ranma vs. the Legendary Phoenix" and the OVA episodes "The One to Carry On" (both parts). It also included information on the voice actors, character designs, and a layout of the Tendo dojo.

Additionally, guidebooks were released for three of the "Ranma Â½" video games; these included not only strategies, but also interviews. Two books including interviews with the cast of the live-action TV drama, and some select stories, were released in 2011.

The music from the "Ranma Â½" TV series, films and OVAs have been released on various CDs. Four from the TV series, two from the first movie, one from the second, one from the third movie and OVAs, and three compiling the music by DoCo used in the OVAs. DoCo is a pop group composed of the anime's main female characters' voice actresses. Several compilation albums were also released, some composed of the opening and closing theme songs and others of image songs. Many of the image songs were first released as singles.

Rumiko Takahashi said that after "Urusei Yatsura", which was popular with high school and college students, she purposefully aimed "Ranma Â½" to be popular among women and children. Both series' peak readership figures were with 15-year-olds, but the distribution of "Ranma Â½" readers was skewed towards younger females. By November 2006, it was reported that the series had sold over 49 million manga volumes in Japan. Shogakukan has printed 53 million copies as of November 2011. Although Lum from Takahashi's first series "Urusei Yatsura" is often cited as the first "tsundere" character in anime and manga, Theron Martin of Anime News Network stated that "Ranma Â½"s Akane Tendo is closer to how they would later typically be portrayed in the 2000s. He also suggested that one could argue "Ranma" is an early example of a harem or reverse harem series, due to the main character attracting suitors in both genders. The series's publication in North America proved highly successful as well, being many Americans' first introduction to manga and its anime adaptation one of the first Japanese animation shows to achieve popularity in the US. Western comic book artists that have cited "Ranma Â½" as an influence include Canadian Bryan Lee O'Malley on his series "Scott Pilgrim" and American Colleen Coover on her erotic series "Small Favors". Matt Bozon, creator of the "Shantae" video game series, cited "Ranma Â½" as a big influence on his work. The title of the fourth game, "", is also a tribute to the series.

In an overview of the series, Jason Thompson called "Ranma Â½" "the direct ancestor of all comedy-action manga, like "Sumomomo Momomo" and "History's Strongest Disciple Kenichi"", although noted that it was not the first, but only spanned the period when manga and anime sales were at their height. Relating it to Takahashi's other works, he summed the series up as "At the start, the fighting is minimal and it's almost a semi-serious relationship comedy, like "Maison Ikkoku"; then it turns completely ridiculous; and by the climax, when Ranma fights the evil bird-people of Phoenix Mountain in an excessively long and un-funny shonen fight scene, it's like a warmup for "Inuyasha"." He states that "Eventually Takahashi adds too many characters, and the manga starts repeating itself. Because of the lack of a strong story arc, a lot of people stop reading "Ranma Â½" at some point in the middle". Reviewing Viz Media's final English volume of the manga, Anime News Network remarked that "Every dimension of Rumiko Takahashi's storytelling skills come into play here: comedy, romance and introspection, and of course, high-flying fantasy martial-arts action." However, they felt some of the action scenes were hard to follow and noted that the mirroring to left-to-right format caused errors with the art.

The "Ranma Â½" anime was ranked number 17 on "Anime Insider"'s 2001 list of the Top 50 Anime, although the list was limited to series that were released in North America. It ranked 36th on TV Asahi's 2006 list of Japan's 100 favorite animated TV series, which is based on an online poll of the Japanese people, up from the previous year's list where it ranked 45th. In November 2006, the New York Comic Con announced that it would host the first-ever American Anime Awards. Fans had the chance to vote for their favorite anime online during the month of January 2007. Only the five nominees receiving the most votes for each category were announced on February 5. Among the 12 different categories, "Ranma Â½" was voted into the "Best Comedy Anime" category, and the "Ranma Â½" OVAs were voted into the "Best Short Series" category. In their review of Viz Media's season five DVD box set, Anime News Network praised the Japanese cast's performance and the animation, but criticized the English version's slight script changes and minor voice actors while praising its main cast. They also remarked that while "Ranma Â½" is a classic, after a hundred episodes, the same jokes are just not funny anymore. THEM Anime Reviews' Raphael See called the television series and the OVAs "one of the funniest things [he's] ever seen, anime or otherwise" and also praised the English dub as some of the best. However, he was much more critical of the first two movies particularly for both using the same damsel in distress plot. Mike Toole of ANN included "Big Trouble in Nekronon, China" at number 83 on The Other 100 Best Anime Movies of All Time, a list of "lesser-known, lesser-loved classics," calling it "a solid action-comedy and a good, well-rounded example of the appeal of "Ranma Â½""



</doc>
<doc id="26327" url="https://en.wikipedia.org/wiki?curid=26327" title="Royal Australian Navy">
Royal Australian Navy

The Royal Australian Navy (RAN) is the naval branch of the Australian Defence Force. Following the Federation of Australia in 1901, the ships and resources of the separate colonial navies were integrated into a national force, called the Commonwealth Naval Forces. Originally intended for local defence, the navy was granted the title of 'Royal Australian Navy' in 1911, and became increasingly responsible for defence of the region.

Britain's Royal Navyâs Australian Squadron was assigned to the Australia Station and provided support to the RAN. The Australian and New Zealand governments helped to fund the Australian Squadron until 1913, while the Admiralty committed itself to keeping the Squadron at a constant strength. The Australian Squadron ceased on 4 October 1913, when RAN ships entered Sydney Harbour for the first time.

The Royal Navy continued to provide blue-water defence capability in the Pacific up to the early years of the Second World War. Then, rapid wartime expansion saw the acquisition of large surface vessels and the building of many smaller warships. In the decade following the war, the RAN acquired a small number of aircraft carriers, the last of which was decommissioned in 1982.

Today, the RAN consists of 48 commissioned vessels, 3 non-commissioned vessels and over 16,000 personnel. The navy is one of the largest and most sophisticated naval forces in the South Pacific region, with a significant presence in the Indian Ocean and worldwide operations in support of military campaigns and peacekeeping missions. The current Chief of Navy is Vice Admiral Michael Noonan.

The Commonwealth Naval Forces were established on 1 March 1901, two months after the federation of Australia, when the naval forces of the separate Australian colonies were amalgamated. A period of uncertainty followed as the policy makers sought to determine the newly established force's requirements and purpose, with the debate focusing upon whether Australia's naval force would be structured mainly for local defence or whether it would be designed to serve as a fleet unit within a larger imperial force, controlled centrally by the British Admiralty. In 1908â09, the decision was made to pursue a compromise solution, and the Australian government agreed to establish a force that would be used for local defence but which would be capable of forming a fleet unit within the imperial naval strategy, albeit without central control. As a result, the navy's force structure was set at "one battlecruiser, three light cruisers, six destroyers and three submarines".

On 10 July 1911, King George V granted the service the title of "Royal Australian Navy". The first of the RAN's new vessels, the destroyer "Yarra", was completed in September 1910 and by the outbreak of the First World War the majority of the RAN's planned new fleet had been realised. The Australian Squadron was placed under control of the British Admiralty, and initially it was tasked with capturing many of Germany's South Pacific colonies and protecting Australian shipping from the German East Asia Squadron. Later in the war, most of the RAN's major ships operated as part of Royal Navy forces in the Mediterranean and North Seas, and then later in the Adriatic, and then the Black Sea following the surrender of the Ottoman Empire.

In 1919, the RAN received a force of six destroyers, three sloops and six submarines from the Royal Navy, but throughout the 1920s and early 1930s, the RAN was drastically reduced in size due to a variety of factors including political apathy and economic hardship as a result of the Great Depression. In this time the focus of Australia's naval policy shifted from defence against invasion to trade protection, and several fleet units were sunk as targets or scrapped. By 1923, the size of the navy had fallen to eight vessels, and by the end of the decade it had fallen further to five, with just 3,500 personnel. In the late 1930s, as international tensions increased, the RAN was modernised and expanded, with the service receiving primacy of funding over the Army and Air Force during this time as Australia began to prepare for war.

Early in the Second World War, RAN ships again operated as part of Royal Navy formations, many serving with distinction in the Mediterranean, the Red Sea, the Persian Gulf, the Indian Ocean, and off the West African coast. Following the outbreak of the Pacific War and the virtual destruction of British naval forces in south-east Asia, the RAN operated more independently, or as part of United States Navy formations. As the navy took on an even greater role, it was expanded significantly and at its height the RAN was the fourth-largest navy in the world, with 39,650 personnel operating 337 warships. A total of 34 vessels were lost during the war, including three cruisers and four destroyers.

After the Second World War, the size of the RAN was again reduced, but it gained new capabilities with the acquisition of two aircraft carriers, "Sydney" and "Melbourne". The RAN saw action in many Cold Warâera conflicts in the Asia-Pacific region and operated alongside the Royal Navy and United States Navy off Korea, Malaysia, and Vietnam. Since the end of the Cold War, the RAN has been part of Coalition forces in the Persian Gulf and Indian Ocean, operating in support of Operation Slipper and undertaking counter piracy operations. It was also deployed in support of Australian peacekeeping operations in East Timor and the Solomon Islands.

The high demand for personnel in the Second World War led to the establishment of the Women's Royal Australian Naval Service (WRANS) branch in 1942, where over 3,000 women served in shore-based positions. The WRANS was disbanded in 1947, but then re-established in 1951 during the Cold War. It was given permanent status in 1959, and the RAN was the final branch to integrate women in the Australian military in 1985.

The strategic command structure of the RAN was overhauled during the New Generation Navy changes. The RAN is commanded through Naval Headquarters (NHQ) in Canberra. The professional head is the Chief of Navy (CN), who holds the rank of vice admiral. NHQ is responsible for implementing policy decisions handed down from the Department of Defence and for overseeing tactical and operational issues that are the purview of the subordinate commands.

Beneath NHQ are two subordinate commands:

Fleet Command was previously made up of seven Force Element Groups, but after the New Generation Navy changes, this was restructured into four Force Commands:

As of October 2018, the RAN fleet consisted of 48 warships, including destroyers, frigates, submarines, patrol boats and auxiliary ships. Ships commissioned into the RAN are given the prefix HMAS (His/Her Majesty's Australian Ship).

The RAN has two primary bases for its fleet:

In addition, three other bases are home to the majority of the RAN's minor war vessels:

The RAN currently operates 45 commissioned vessels, made up of eight ship classes and three individual ships, plus three non-commissioned vessels. In addition, DMS Maritime operates a large number of civilian-crewed vessels under contract to the Australian Defence Force.

The Fleet Air Arm (previously known as the Australian Navy Aviation Group) provides the RAN's aviation capability. As of 2018, the FAA consists of two front line helicopter squadrons (one focused on anti-submarine and anti-shipping warfare and the other a transport unit), two training squadrons and a trials squadron.

In addition to the helicopter squadrons of the Fleet Air Arm, the RAN operated an additional flying unit that came under the operational responsibility of the Australian Hydrographic Service. The Laser Airborne Depth Sounder (LADS) Flight was the sole remaining fixed-wing aircraft operated by the RAN, and was based at in Cairns, Queensland. The final LADS flight was conducted in November 2019. The capability will be replaced by commercial hydrographic companies through the HydroScheme Industry Partnership Program (HIPP).

The Clearance Diving Branch is composed of two "Clearance Diving Teams" (CDT) that serve as parent units for naval clearance divers:

When clearance divers are sent into combat, Clearance Diving Team Three (AUSCDT THREE) is formed.

The CDTs have two primary roles:

There are currently several major projects underway that will see upgrades to RAN capabilities:

The RAN currently has forces deployed on four major operations:

As of June 2011, the RAN has 14,215 permanent full-time personnel, 161 gap year personnel, and 2,150 reserve personnel. The permanent full-time force consisted of 3,357 commissioned officers, and 10,697 enlisted personnel. In June 2010, male personnel made up 82% of the permanent full-time force, while female personnel made up 18%. The RAN has the highest percentage of women in the ADF, compared to the RAAF's 17.8% and the Army's 9.7%.

The following are the current senior Royal Australian Navy officers:

The uniforms of the Royal Australian Navy are very similar in cut, colour and insignia to their British Royal Navy forerunners. However, beginning with the Second World War, all RAN personnel began wearing shoulder flashes reading "Australia", a practice continuing today. These are cloth arcs at shoulder height on uniforms, metallic gold on officers' shoulder boards, and embroidered on shoulder slip-ons.

Commissioned officers of the Australian Navy have pay grades ranging from S-1 to O-11. The only O-11 position in the navy is honorary and has only ever been held by royalty, currently being held by The Duke of Edinburgh. The highest position occupied in the current Royal Australian Navy structure is O-9, a vice admiral who serves as the Chief of the Navy. O-8 (rear admiral) to O-11 (admiral of the fleet) are referred to as flag officers, O-5 (commander) and above are referred to as senior officers, while S-1 (midshipman) to O-4 (lieutenant commander) are referred to as junior officers. All officers of the navy receive a commission from Her Majesty Queen Elizabeth II, Queen of Australia. The commissioning scroll issued in recognition of the commission is signed by the Governor General of Australia as Commander-in-Chief and the serving Minister for Defence.

Naval officers are trained at the Royal Australian Naval College (HMAS "Creswell") in Jervis Bay and the Australian Defence Force Academy in Canberra.

Chaplains in the Royal Australian Navy are commissioned officers who complete the same training as other officers in the RAN at the Royal Australian Naval College, HMAS Creswell. RAN regulations group RAN chaplains with commanders for purposes of protocol such as marks of respect (saluting); however, RAN chaplains have no other rank other than "chaplain", and their rank emblem is identifiable by a Maltese cross with gold anchor. Senior chaplains are grouped with captains, and principal chaplains are grouped with commodores, but their chaplain rank slide remains the same. Principal chaplains, however, have gold braid on the peak of their white service cap. 

Royal Australian Navy Other Ranks wear "right arm rates" insignia, called "Category Insignia" to indicate speciality training qualifications. The use pattern mirrors that of the Royal Navy, and has since formation. Stars or a Crown are added to these to indicate higher qualifications.

The Warrant Officer of the Navy (WO-N) is an appointment held by the most senior sailor in the RAN, and holds the rank of warrant officer (WO). However, the WO-N does not wear the WO rank insignia; instead, they wear the special insignia of the appointment. The WO-N appointment has similar equivalent appointments in the other services, each holding the rank of warrant officer, each being the most senior sailor/soldier/airman in that service, and each wearing their own special insignia rather than their rank insignia. The Australian Army equivalent is the Regimental Sergeant Major of the Army (RSM-A) and the Royal Australian Air Force equivalent is the Warrant Officer of the Air Force (WOFF-AF).





</doc>
<doc id="26328" url="https://en.wikipedia.org/wiki?curid=26328" title="Royal Australian Air Force">
Royal Australian Air Force

The Royal Australian Air Force (RAAF), formed in March 1921, is the aerial warfare branch of the Australian Defence Force (ADF). It operates the majority of the ADF's fixed wing aircraft, although both the Australian Army and Royal Australian Navy also operate aircraft in various roles. It directly continues the traditions of the Australian Flying Corps (AFC), formed on 22 October 1912. The RAAF provides support across a spectrum of operations such as air superiority, precision strikes, intelligence, surveillance and reconnaissance, air mobility, space surveillance, and humanitarian support.

The RAAF took part in many of the 20th century's major conflicts. During the early years of the Second World War a number of RAAF bomber, fighter, reconnaissance and other squadrons served in Britain, and with the Desert Air Force located in North Africa and the Mediterranean. From 1942, many RAAF units were formed in Australia, and fought in South West Pacific Area. Thousands of Australians also served with other Commonwealth air forces in Europe, including during the bomber offensive against Germany. By the time the war ended, a total of 216,900 men and women served in the RAAF, of whom 10,562 were killed in action.

Later the RAAF served in the Berlin Airlift, Korean War, Malayan Emergency, IndonesiaâMalaysia Confrontation and Vietnam War. More recently, the RAAF has participated in operations in East Timor, the Iraq War, the War in Afghanistan, and the military intervention against the Islamic State of Iraq and the Levant (ISIL).

The RAAF has 259 aircraft, of which 110 are combat aircraft.

The RAAF traces its history back to the Imperial Conference held in London in 1911, where it was decided aviation should be developed within the armed forces of the British Empire. Australia implemented this decision, the first dominion to do so, by approving the establishment of the "Australian Aviation Corps". This initially consisted of the Central Flying School at Point Cook, Victoria, opening on 22 October 1912. By 1914 the corps was known as the "Australian Flying Corps".

Soon after the outbreak of war in 1914, the Australian Flying Corps sent aircraft to assist in capturing German colonies in what is now north-east New Guinea. However, these colonies surrendered quickly, before the planes were even unpacked. The first operational flights did not occur until 27 May 1915, when the Mesopotamian Half Flight was called upon to assist the Indian Army in protecting British oil interests in what is now Iraq.

The corps later saw action in Egypt, Palestine and on the Western Front throughout the remainder of the First World War. By the end of the war, four squadronsâNos. 1, 2, 3 and 4âhad seen operational service, while another four training squadronsâNos. 5, 6, 7 and 8âhad also been established. A total of 460 officers and 2,234 other ranks served in the AFC, whilst another 200 men served as aircrew in the British flying services. Casualties included 175 dead, 111 wounded, 6 gassed and 40 captured.

The Australian Flying Corps remained part of the Australian Army until 1919, when it was disbanded along with the First Australian Imperial Force (AIF). Although the Central Flying School continued to operate at Point Cook, military flying virtually ceased until 1920, when the Australian Air Corps (AAC) was formed. The Australian Air Force was formed on 31 March 1921. King George V approved the prefix "Royal" in June 1921 and became effective on 31 August 1921. The RAAF then became the second Royal air arm to be formed in the British Commonwealth, following the British Royal Air Force. When formed the RAAF had more aircraft than personnel, with 21 officers and 128 other ranks and 153 aircraft.

In September 1939, the Australian Air Board directly controlled the Air Force via RAAF Station Laverton, RAAF Station Richmond, RAAF Station Pearce, No. 1 Flying Training School RAAF at Point Cook, RAAF Station Rathmines and five smaller units.

In 1939, just after the outbreak of the Second World War, Australia joined the Empire Air Training Scheme, under which flight crews received basic training in Australia before travelling to Canada for advanced training. A total of 17 RAAF bomber, fighter, reconnaissance and other squadrons served initially in Britain and with the Desert Air Force located in North Africa and the Mediterranean. Thousands of Australians also served with other Commonwealth air forces in Europe during the Second World War. About nine percent of the personnel who served under British RAF commands in Europe and the Mediterranean were RAAF personnel.

With British manufacturing targeted by the German Luftwaffe, in 1941 the Australian government created the Department of Aircraft Production (DAP; later known as the Government Aircraft Factories) to supply Commonwealth air forces, and the RAAF was eventually provided with large numbers of locally built versions of British designs such as the DAP Beaufort torpedo bomber, Beaufighters and Mosquitos, as well as other types such as Wirraways, Boomerangs, and Mustangs.

In the European theatre of the war, RAAF personnel were especially notable in RAF Bomber Command: although they represented just two percent of all Australian enlistments during the war, they accounted for almost twenty percent of those killed in action. This statistic is further illustrated by the fact that No. 460 Squadron RAAF, mostly flying Avro Lancasters, had an official establishment of about 200 aircrew and yet had 1,018 combat deaths. The squadron was therefore effectively wiped out five times over. Total RAAF casualties in Europe were 5,488 killed or missing.

The beginning of the Pacific Warâand the rapid advance of Japanese forcesâthreatened the Australian mainland for the first time in its history. The RAAF was quite unprepared for the emergency, and initially had negligible forces available for service in the Pacific. In 1941 and early 1942, many RAAF airmen, including Nos. 1, 8, 21 and 453 Squadrons, saw action with the RAF Far East Command in the Malayan, Singapore and Dutch East Indies campaigns. Equipped with aircraft such as the Brewster Buffalo, and Lockheed Hudsons, the Australian squadrons suffered heavily against Japanese Zeros.

During the fighting for Rabaul in early 1942, No. 24 Squadron RAAF fought a brief, but ultimately futile defence as the Japanese advanced south towards Australia. The devastating air raids on Darwin on 19 February 1942 increased concerns about the direct threat facing Australia. In response, some RAAF squadrons were transferred from the northern hemisphereâalthough a substantial number remained there until the end of the war. Shortages of fighter and ground attack planes led to the acquisition of US-built Curtiss P-40 Kittyhawks and the rapid design and manufacture of the first Australian fighter, the CAC Boomerang. RAAF Kittyhawks came to play a crucial role in the New Guinea and Solomon Islands campaigns, especially in operations like the Battle of Milne Bay. As a response to a possible Japanese chemical warfare threat the RAAF imported hundreds of thousands of chemical weapons into Australia.

In the Battle of the Bismarck Sea, imported Bristol Beaufighters proved to be highly effective ground attack and maritime strike aircraft. Beaufighters were later made locally by the DAP from 1944. Although it was much bigger than Japanese fighters, the Beaufighter had the speed to outrun them. The RAAF operated a number of Consolidated PBY Catalina as long range bombers and scouts. The RAAF's heavy bomber force was predominantly made up of 287 B-24 Liberators, equipping seven squadrons, which could bomb Japanese targets as far away as Borneo and the Philippines from airfields in Australia and New Guinea. By late 1945, the RAAF had received or ordered about 500 P-51 Mustangs, for fighter/ground attack purposes. The Commonwealth Aircraft Corporation initially assembled US-made Mustangs, but later manufactured most of those used.

By mid-1945, the RAAF's main operational formation in the Pacific, the First Tactical Air Force (1st TAF), consisted of over 21,000 personnel, while the RAAF as a whole consisted of about 50 squadrons and 6,000 aircraft, of which over 3,000 were operational. The 1st TAF's final campaigns were fought in support of Australian ground forces in Borneo, but had the war continued some of its personnel and equipment would likely have been allocated to the invasion of the Japanese mainland, along with some of the RAAF bomber squadrons in Europe, which were to be grouped together with British and Canadian squadrons as part of the proposed Tiger Force. However, the war was brought to a sudden end by the US nuclear attacks on Japan. The RAAF's casualties in the Pacific were around 2,000 killed, wounded or captured.

By the time the war ended, a total of 216,900 men and women served in the RAAF, of whom 10,562 were killed in action; a total of 76 squadrons were formed. With over 152,000 personnel operating nearly 6,000 aircraft it was the world's fourth largest air force.

During the Berlin Airlift, in 1948â49, the RAAF Squadron Berlin Air Lift aided the international effort to fly in supplies to the stricken city; two RAF Avro York aircraft were also crewed by RAAF personnel. Although a small part of the operation, the RAAF contribution was significant, flying 2,062 sorties and carrying 7,030 tons of freight and 6,964 passengers.

In the Korean War, from 1950â53, North American Mustangs from No. 77 Squadron RAAF, stationed in Japan with the British Commonwealth Occupation Force, were among the first United Nations aircraft to be deployed, in ground support, combat air patrol, and escort missions. When the UN planes were confronted by North Korean Mikoyan-Gurevich MiG-15 jet fighters, 77 Sqn acquired Gloster Meteors, however the MiGs remained superior and the Meteors were relegated to ground support missions as the North Koreans gained experience. The air force also operated transport aircraft during the conflict. No. 77 Squadron flew 18,872 sorties, claiming the destruction of 3,700 buildings, 1,408 vehicles, 16 bridges, 98 railway carriages and an unknown number of enemy personnel. Three MiG-15s were confirmed destroyed, and two others probably destroyed. RAAF casualties included 41 killed and seven captured; 66 aircraftÂ â 22 Mustangs and 44 MeteorsÂ â were lost.

In July 1952, No. 78 Wing RAAF was deployed to Malta in the Mediterranean where it formed part of a British force which sought to counter the Soviet Union's influence in the Middle East as part of Australia's Cold War commitments. Consisting of No. 75 and 76 Squadrons equipped with de Havilland Vampire jet fighters, the wing provided an air garrison for the island for the next two and half years, returning to Australia in late 1954.

In 1953, a Royal Air Force officer, Air Marshal Sir Donald Hardman, was brought out to Australia to become Chief of the Air Staff. He reorganised the RAAF into three commands: Home Command, Maintenance Command, and Training Command. Five years later, Home Command was renamed Operational Command, and Training Command and Maintenance Command were amalgamated to form Support Command.

In the Malayan Emergency, from 1950â60, six Avro Lincolns from No. 1 Squadron RAAF and a flight of Douglas Dakotas from No. 38 Squadron RAAF took part in operations against the communist guerrillas (labelled as "Communist Terrorists" by the British authorities) as part of the RAF Far East Air Force. The Dakotas were used on cargo runs, in troop movement and in paratroop and leaflet drops within Malaya. The Lincolns, operating from bases in Singapore and from Kuala Lumpur, formed the backbone of the air war against the CTs, conducting bombing missions against their jungle bases. Although results were often difficult to assess, they allowed the government to harass CT forces, attack their base camps when identified and keep them on the move. Later, in 1958, Canberra bombers from No. 2 Squadron RAAF were deployed to Malaya and took part in bombing missions against the CTs.

During the Vietnam War, from 1964â72, the RAAF contributed Caribou STOL transport aircraft as part of the RAAF Transport Flight Vietnam, later redesignated No. 35 Squadron RAAF, UH-1 Iroquois helicopters from No. 9 Squadron RAAF, and English Electric Canberra bombers from No. 2 Squadron RAAF. The Canberras flew 11,963 bombing sorties, and two aircraft were lost. One went missing during a bombing raid. The wreckage of the aircraft was recovered in April 2009, and the remains of Flying Officer Michael Herbert and Pilot Officer Robert Carver were found in late July 2009. The other was shot down by a surface-to-air missile, although both crew were rescued. They dropped 76,389 bombs and were credited with 786 enemy personnel confirmed killed and a further 3,390 estimated killed, 8,637 structures, 15,568 bunkers, 1,267 sampans and 74 bridges destroyed. RAAF transport aircraft also supported anti-communist ground forces. The UH-1 helicopters were used in many roles including medical evacuation and close air support. RAAF casualties in Vietnam included six killed in action, eight non-battle fatalities, 30 wounded in action and 30 injured. A small number of RAAF pilots also served in United States Air Force units, flying F-4 Phantom fighter-bombers or serving as forward air controllers.
Military airlifts were conducted for a number of purposes in the intervening decades, such as the peacekeeping operations in East Timor from 1999. Australia's combat aircraft were not used again in combat until the Iraq War in 2003, when 14 F/A-18s from No. 75 Squadron RAAF operated in the escort and ground attack roles, flying a total of 350 sorties and dropping 122 laser-guided bombs. A detachment of AP-3C Orion maritime patrol aircraft were deployed in the Middle East between 2003 and 2012. These aircraft conducted maritime surveillance patrols over the Persian Gulf and North Arabian Sea in support of Coalition warships and boarding parties, as well as conducting extensive overland flights of Iraq and Afghanistan on intelligence, surveillance and reconnaissance missions, and supporting counter-piracy operations in Somalia.
From 2007 to 2009, a detachment of No. 114 Mobile Control and Reporting Unit RAAF was on active service at Kandahar Airfield in southern Afghanistan.
Approximately 75 personnel deployed with the AN/TPS-77 radar assigned the responsibility to co-ordinate coalition air operations. A detachment of IAI Heron unmanned aerial vehicles has been deployed in Afghanistan since January 2010.

In late September 2014, an Air Task Group consisting of up to eight F/A-18F Super Hornets, a KC-30A Multi Role Tanker Transport, an E-7A Wedgetail Airborne Early Warning & Control aircraft and 400 personnel was deployed to Al Minhad Air Base in the United Arab Emirates as part of the coalition to combat Islamic State forces in Iraq. Operations began on 1 October. A number of C-17 and C-130J Super Hercules transport aircraft based in the Middle East have also been used to conduct airdrops of humanitarian aid and to airlift arms and munitions since August.

In June 2017 two RAAF AP-3C Orion maritime patrol aircraft were deployed to the southern Philippines in response to the Marawi crisis.

The RAAF established the Women's Auxiliary Australian Air Force (WAAAF) in March 1941, which then became the Women's Royal Australian Air Force (WRAAF) in 1951. The service merged with the RAAF in 1977; however, all women in the Australian military were barred from combat-related roles until 1990. Women have been eligible for flying roles in the RAAF since 1987, with the RAAF's first women pilots awarded their "wings" in 1988. In 2016, the remaining restrictions on women in frontline combat roles were removed, and the first two female RAAF fast jet fighter pilots graduated in December 2017.

The rank structure of the nascent RAAF was established to ensure that the service remained separate from the Army and Navy. The service's predecessors, the AFC and the AAC, had used the Army's rank structure. In November 1920 it was decided by the Air Board that the RAAF would adopt the structure adopted by the RAF the previous year. As a result, the RAAF's rank structure came to be: Aircraftman, Leading Aircraftman, Corporal, Sergeant, Flight Sergeant, Warrant Officer, Officer Cadet, Pilot Officer, Flying Officer. Flight Lieutenant, Squadron Leader, Wing Commander, Group Captain, Air Commodore, Air Vice Marshal, Air Marshal, Air Chief Marshal, Marshal of the RAAF.

In 1922, the colour of the RAAF winter uniform was determined by Air Marshal Sir Richard Williams on a visit to the Geelong Wool Mill. He asked for one dye dip fewer than the RAN blue (three indigo dips rather than four). There was a change to a lighter blue when an all-seasons uniform was introduced in the 1970s. The original colour and style were re-adopted around 2005. Slip-on rank epaulettes, known as "Soft Rank Insignia" (SRI), displaying the word are worn on the shoulders of the service dress uniform. When not in the service dress or "ceremonial" uniform, RAAF personnel wear the General Purpose Uniform (GPU) as a working dress, which is a blue version of the Australian Multicam Pattern.

Originally, the air force used the red, white and blue roundel of the RAF. However, during the Second World War the inner red circle, which was visually similar to the Japanese "hinomaru", was removed after a No. 11 Squadron Catalina was mistaken for a Japanese aircraft and attacked by a Grumman Wildcat of VMF-212 of the United States Marine Corps on 27 June 1942.

After the war, a range of options for the RAAF roundel was proposed, including the Southern Cross, a boomerang, a sprig of wattle, and a red kangaroo. On 2 July 1956, the current version of the roundel was formally adopted. This consists of a white inner circle with a red kangaroo surrounded by a royal blue circle. The kangaroo faces left, except when used on aircraft or vehicles, when the kangaroo should always face forward. Low visibility versions of the roundel exist, with the white omitted and the red and blue replaced with light or dark grey.

The RAAF badge was accepted by the Chester Herald in 1939. The badge is composed of the imperial crown mounted on a circle featuring the words Royal Australian Air Force, beneath which scroll work displays the Latin motto "Per Ardua Ad Astra", which it shares with the Royal Air Force. Surmounting the badge is a wedge-tailed eagle. "Per Ardua Ad Astra" is attributed with the meaning "Through Adversity to the Stars" and is from Sir Henry Rider Haggard's novel "The People of the Mist".

As of June 2018, the RAAF had 14,313 permanent full-time personnel and 5,499 part-time active reserve personnel.



The Roulettes are the RAAF's formation aerobatic display team. They perform around Australia and South-east Asia, and are part of the RAAF Central Flying School (CFS) at RAAF Base East Sale, Victoria. The Roulettes use the Pilatus PC-21 and formations for shows are done in a group of six aircraft. The pilots learn many formations including loops, rolls, corkscrews, and ripple roles. Most of the performances are done at the low altitude of 500 feet (150 metres).

This list includes aircraft on order or a requirement which has been identified:


Lists:

Memorials and Museums:




</doc>
<doc id="26329" url="https://en.wikipedia.org/wiki?curid=26329" title="Responsible government">
Responsible government

Responsible government is a conception of a system of government that embodies the principle of parliamentary accountability, the foundation of the Westminster system of parliamentary democracy. Governments (the equivalent of the executive branch) in Westminster democracies are responsible to parliament rather than to the monarch, or, in a colonial context, to the imperial government, and in a republican context, to the president, either in full or in part. If the parliament is bicameral, then the government is responsible first to the parliament's lower house, which is more representative than the upper house, as it usually has more members and they are always directly elected.

Responsible government of parliamentary accountability manifests itself in several ways. Ministers account to Parliament for their decisions and for the performance of their departments. This requirement to make announcements and to answer questions in Parliament means that ministers must have the privileges of the "floor", which are only granted to those who are members of either house of Parliament. Secondly, and most importantly, although ministers are officially appointed by the authority of the head of state and can theoretically be dismissed at the pleasure of the sovereign, they concurrently retain their office subject to their holding the confidence of the lower house of Parliament. When the lower house has passed a motion of no confidence in the government, the government must immediately resign or submit itself to the electorate in a new general election.

Lastly, the head of state is in turn required to effectuate their executive power only through these responsible ministers. They must never attempt to set up a "shadow" government of executives or advisors and attempt to use them as instruments of government, or to rely upon their "unofficial" advice. They are bound to take no decision or action that is put into effect under the colour of their executive power without that action being as a result of the counsel and advisement of their responsible ministers. Their ministers are required to counsel them (i.e., explain to them and be sure they understand any issue that they will be called upon to decide) and to form and have recommendations for them (i.e., their advice or advisement) to choose from, which are the ministers' formal, reasoned, recommendations as to what course of action should be taken.

An exception to this is Israel, which operates under a simplified version of the Westminster system.

In the Canadian system, responsible government was developed between 1846 and 1850, with the executive Council formulating policy with the assistance of the legislative branch, the legislature voting approval or disapproval, and the appointed governor enacting those policies that it had approved. It was a transition from the older system whereby the governor took advice from an executive Council, and used the legislature chiefly to raise money. After the formation of elected legislative assemblies starting with Nova Scotia in 1758, governors and their executive councils did not require the consent of elected legislators in order to carry out all their roles. It was only in the decades leading up to Canadian Confederation in 1867 that the governing councils of those British North American colonies became responsible to the elected representatives of the people.

Responsible government was a major element of the gradual development of Canada towards independence. The concept of responsible government is associated in Canada more with self-government than with parliamentary accountability; hence there is the notion that the Dominion of Newfoundland "gave up responsible government" when it suspended its self-governing status in 1933, as a result of financial problems. It did not regain responsible government until it became a province of Canada in 1948.

In the aftermath of the American Revolution, based on the perceived shortcomings of virtual representation, the British government became more sensitive to unrest in its remaining colonies with large populations of European-descended colonists. Elected assemblies were introduced to both Upper Canada and Lower Canada with the Constitutional Act of 1791. Many reformers thought that these assemblies should have some control over the executive power, leading to political unrest between the governors and assemblies in both Upper and Lower Canada. The Lieutenant Governor of Upper Canada Sir Francis Bond Head wrote in one dispatch to London that if responsible government were implemented "Democracy, in the worst possible Form, will prevail in our Colonies." 

After the 1837 Lower Canada Rebellion led by Louis-Joseph Papineau, and the 1837â1838 Upper Canada Rebellion led by William Lyon Mackenzie, Lord Durham was appointed governor general of British North America and had the task of examining the issues and determining how to defuse tensions. In his report, one of his recommendations was that colonies which were developed enough should be granted "responsible government". This term specifically meant the policy that British-appointed governors should bow to the will of elected colonial assemblies.

The first instance of responsible government in the British Empire outside of the United Kingdom itself was achieved by the colony of Nova Scotia in JanuaryâFebruary 1848 through the efforts of Joseph Howe. Howe's push for responsible government was inspired by the work of Thomas McCulloch and Jotham Blanchard almost two decades earlier. The plaque in the Nova Scotia House of Assembly erected by the Historic Sites and Monuments Board of Canada reads:
First Responsible Government in the British Empire.<br>
The first Executive Council chosen exclusively from the party having a majority in the representative branch of a colonial legislature was formed in Nova Scotia on 2 February 1848. Following a vote of want of confidence in the preceding Council, James Boyle Uniacke, who had moved the resolution, became Attorney General and leader of the Government. Joseph Howe, the long-time campaigner for this "Peaceable Revolution", became Provincial Secretary. Other members of the Council were Hugh Bell, Wm. F. Desbarres, Lawrence O.C. Doyle, Herbert Huntingdon, James McNab, Michael Tobin, and George R. Young.

The colony of New Brunswick soon followed in May 1848 when Lieutenant Governor Edmund Walker Head brought in a more balanced representation of Members of the Legislative Assembly to the Executive Council and ceded more powers to that body.

In the Province of Canada, responsible government was introduced with the ministry of Louis-Hippolyte LaFontaine and Robert Baldwin in spring 1848; it was put to the test in 1849, when Reformers in the legislature passed the Rebellion Losses Bill. This was a law that provided compensation to French-Canadians who suffered losses during the Rebellions of 1837â1838 in Lower-Canada. 

The Governor General, Lord Elgin, had serious misgivings about the bill but nonetheless assented to it despite demands from the Tories that he refuse to do so. Elgin was physically assaulted by an English-speaking mob for this, and the Montreal Parliament building was burned to the ground in the ensuing riots. Nonetheless, the Rebellion Losses Bill helped entrench responsible government into Canadian politics.

In time, the granting of responsible government became the first step on the road to complete independence. Canada gradually gained greater and greater autonomy over a considerable period of time through inter imperial and commonwealth diplomacy, including the British North America Act of 1867, the Statute of Westminster of 1931, and even as late as the patriation of the Constitution Act in 1982 (see Constitution of Canada).

While the various colonies in Australia were either sparsely populated or penal settlements or both, executive power was in the hands of the Governors, who, because of the great distance from their superiors in London and the resulting very slow communication, necessarily exercised vast powers.
However, the early colonists, coming mostly from the United Kingdom, were familiar with the Westminster system and made efforts to reform it to increase the opportunity for ordinary men to participate.

The Governors and London therefore set in motion a gradual process of establishing a Westminster system in the colonies, not so fast as to get ahead of population or economic growth, nor so slow as to provoke clamouring for revolutionary change as happened in America. Initially, this took the form of appointed or partially elected Legislative Councils. Then, during the 1850s, all Australian colonies except Western Australia, along with New Zealand, established both representative and responsible government; Western Australia did the same in 1890.

The Cape Colony, in Southern Africa, was under responsible self-government from 1872 until 1910 when it became the Cape Province of the new Union of South Africa.

Under its previous system of representative government, the Ministers of the Cape Government reported directly to the British Imperial Governor, and not to the locally elected representatives in the Cape Parliament. Among Cape citizens of all races, growing anger at their powerlessness in influencing unpopular imperial decisions had repeatedly led to protests and rowdy political meetings â especially during the early "Convict Crisis" of the 1840s.
A popular political movement for responsible government soon emerged, under local leader John Molteno. A protracted struggle was then conducted over the ensuing years as the movement (known informally as "the responsibles") grew increasingly powerful, and used their parliamentary majority to put pressure on the British Governor, withholding public finances from him, and conducting public agitations. Not everyone favoured responsible government though, and pro-imperial press outlets even accused the movement of constituting "crafts and assaults of the devil".

Supporters believed that the most effective means of instituting responsible government was simply to change the section of the constitution which prevented government officials from being elected to parliament or members of parliament from serving in executive positions. The conflict therefore centred on the changing of this specific section. "Although responsible government merely required an amendment to s.79 of the constitution, it transpired only after nearly twenty years in 1872 when the so-called "responsibles" under Molteno were able to command sufficient support in both houses to secure the passage of the necessary bill." Finally, with a parliamentary majority and with the Colonial Office and new Governor Henry Barkly won over, Molteno instituted responsible government, making the Ministers directly responsible to the Cape Parliament, and becoming the Cape's first Prime Minister.

The ensuing period saw an economic recovery, a massive growth in exports and an expansion of the colony's frontiers. Despite political complications that arose from time to time (such as an ill-fated scheme by the British Colonial Office to enforce a confederation in Southern Africa in 1878, and tensions with the Afrikaner-dominated Government of Transvaal over trade and railroad construction), economic and social progress in the Cape Colony continued at a steady pace until a renewed attempt to extend British control over the hinterland caused the outbreak of the Anglo-Boer Wars in 1899.

An important feature of the Cape Colony under responsible government was that it was the only state in southern Africa (and one of very few in the world at the time) to have a non-racial system of voting.

Later however â following the South Africa Act 1909 to form the Union of South Africa â this multi-racial universal suffrage was steadily eroded, and eventually abolished by the Apartheid government in 1948.


In the early 1860s, the Prussian Prime Minister Otto von Bismarck was involved in a bitter dispute with the Liberals, who sought to institute a system of responsible government modeled on that of Britain. Bismarck, who strongly opposed that demand, managed to deflect the pressure by embarking energetically and successfully on the unification of Germany. The Liberals, who were also strong German nationalists, backed Bismarck's unification efforts and tacitly accepted that the Constitution of Imperial Germany, crafted by Bismarck, did not include a responsible government â the Chancellor being accountable solely to the emperor and needing no parliamentary confidence. Germany gained a responsible government only with the Weimar Republic and more securely with the creation of the German Federal Republic. Historians account the lack of responsible government in the formative decades of united Germany as one of the factors contributing to the prolonged weakness of German democratic institutions, lasting also after such a government was finally instituted.




</doc>
<doc id="26332" url="https://en.wikipedia.org/wiki?curid=26332" title="Rural flight">
Rural flight

Rural flight (or rural exodus) is the migratory pattern of peoples from rural areas into urban areas. It is urbanization seen from the rural perspective.

In modern times, it often occurs in a region following the industrialization of agricultureâwhen fewer people are needed to bring the same amount of agricultural output to marketâand related agricultural services and industries are consolidated. Rural flight is exacerbated when the population decline leads to the loss of rural services (such as business enterprises and schools), which leads to greater loss of population as people leave to seek those features.

Prior to the Industrial Revolution, rural flight occurred in mostly localized regions. Pre-industrial societies did not experience large rural-urban migration flows primarily due to the inability of cities to support large populations. Lack of large employment industries, high urban mortality, and low food supplies all served as checks keeping pre-industrial cities much smaller than their modern counterparts. Ancient Athens and Rome, scholars estimate, had peak populations of 80,000 and 500,000.

The onset of the Industrial Revolution in Europe in the late 19th century removed many of these checks. As food supplies increased and stabilized and industrialized centers arose, cities began to support larger populations, sparking the start of rural flight on a massive scale. The United Kingdom went from having 20% of the population living in urban areas in 1800 to more than 70% by 1925. While the late 19th century and early 20th century saw much of rural flight focused in Western Europe and the United States, as industrialization spread throughout the world during the 20th century, rural flight and urbanization followed quickly behind. Today, rural flight is an especially distinctive phenomenon in some of the newer urbanized areas including China and more recently sub-Saharan Africa.

The shift from mixed subsistence farming to commodity crops and livestock began in the late 19th century. New capital market systems and the railroad network began the trend towards larger farms that employed fewer people per acre. These larger farms used more efficient technologies such as steel plows, mechanical reapers, and higher-yield seed stock, which reduced human input per unit of production. The other issue on the Great Plains was that people were using inappropriate farming techniques for the soil and weather conditions. Most homesteaders had family farms generally considered too small to survive (under 320 acres), and European-American subsistence farming could not continue as it was then practiced.

During the Dust Bowl and the Great Depression of the 1930s, large numbers of people fled rural areas of the Great Plains and the Midwest due to depressed commodity prices and high debt loads exacerbated by several years of drought and large dust storms. Rural flight from the Great Plains has been depicted in literature, such as John Steinbeck's novel "The Grapes of Wrath" (1939), in which a family from the Great Plains migrates to California during the Dust Bowl period of the 1930s.

Post-World War II rural flight has been caused primarily by the spread of industrialized agriculture. Small, labor-intensive family farms have grown into, or have been replaced by, heavily mechanized and specialized industrial farms. While a small family farm typically produced a wide range of crop, garden, and animal productsâall requiring substantial laborâlarge industrial farms typically specialize in just a few crop or livestock varieties, using large machinery and high-density livestock containment systems that require a fraction of the labor per unit produced. For example, Iowa State University reports the number of hog farmers in Iowa dropped from 65,000 in 1980 to 10,000 in 2002, while the number of hogs per farm increased from 200 to 1,400.

The consolidation of the feed, seed, processed grain, and livestock industries has meant that there are fewer small businesses in rural areas. This decrease in turn exacerbated the decreased demand for labor. Rural areas that used to be able to provide employment for all young adults willing to work in challenging conditions, increasingly provide fewer opportunities for young adults. The situation is made worse by the decrease in services such as schools, business, and cultural opportunities that accompany the decline in population, and the increasing age of the remaining population further stresses the social service system of rural areas.

The rise of corporate agricultural structures directly affects small rural communities, resulting in decreased populations, decreased incomes for some segments, increased income inequality, decreased community participation, fewer retail outlets and less retail trade, and increased environmental pollution. "Human dehabitation" of rural settlements is a megatrend in aging societies across the globe, perhaps partially reversing a historic boom in land use for settlements that coincided with population growth that began in earnest alongside the spread of the industrial revolution and curative medicine. China has used school mergers to centralized village, town, or county schools in rural areas to address some of these very problems since the 1990s. Chernobyl is one example of how human abandonment of land can lead to the return of abundant animal life.

There are several determinants, push and pull, that contribute to rural flight: lower levels of (perceived) economic opportunity in rural communities versus urban ones, lower levels of government investment in rural communities, greater education opportunities in cities, marriages, increased social acceptance in urban areas, and higher levels of rural fertility.

Some migrants choose to leave rural communities out of the desire to pursue greater economic opportunity in urban areas. Greater economic opportunities can be real or perceived. According to the Harris-Todaro Model, migration to urban areas will continue as long as "expected urban real income at the margin exceeds real agricultural product" (127). However, sociologist Josef Gugler points out that while individual benefits of increased wages may outweigh the costs of migration, if enough individuals follow this rationale, it can produce harmful effects such as overcrowding and unemployment on a national level. This phenomenon, when the rate of urbanization outpaces the rate of economic growth, is known as overurbanization. Since the industrialization of agriculture, mechanization has reduced the number of jobs present in rural communities. Some scholars have also attributed rural flight to the effects of globalization as the demand for increased economic competitiveness leads people to choose capital over labor. At the same time, rural fertility rates have historically been higher than urban fertility rates. The combination of declining rural jobs and a persistently high rural fertility rate has led to rural-urban migration streams. Rural flight also contains a positive feedback loop where previous migrants from rural communities assist new migrants in adjusting to city life. Also known as chain migration, migrant networks lower barriers to rural flight. For example, an overwhelming majority of rural migrants in China located jobs in urban areas through migrant networks.

Some families choose to send their children to cities as a form of investment for the future. A study conducted by Bates and Bennett (1974) concluded that rural communities in Zambia that had other viable investment opportunities, like livestock for instance, had lower rates of rural-urban migration as compared to regions without viable investment opportunities. Sending their children into cities can serve as long-term investments with the hope that their children will be able to send remittances back home after getting a job in the city.

There are severe challenges faced by poorer people in the agriculture sector because of diminishing access to productive farmland. Foreign investors through Foreign Direct Investment (FDI) schemes have been encouraged to lease land in rural areas in Cambodia and Ethiopia. This has led to the loss of farmland, range land, woodlands and water sources from local communities. Large-scale agricultural projects funded by FDI only employed a few experts specialized in the relevant new technologies.

In other instances, rural flight may occur in response to social determinants. A study conducted in 2012 indicated that a significant proportion of rural flight in India occurred due to social factors such as migration with household, marriage, and education. Migration with households and marriage affect women in particular as most often they are the ones required to move with households and move for marriage, especially in developing regions. 
Rural youth may choose to leave their rural communities as a method of transitioning into adulthood, seeking avenues to greater prosperity. With the stagnation of the rural economy and encouragement from their parents, rural youth may choose to migrate to cities out of social norms â demonstrating leadership and self-respect. With this societal encouragement combined with depressed rural economies, rural youth form a large proportion of the migrants moving to urban areas. In Sub-Saharan Africa, a study conducted by Touray in 2006 indicated that about 15% (26 million) of urban migrants were youth. 
Lastly, natural disasters can often be single-point events that lead to temporarily massive rural-urban migration flows. The 1930s Dust Bowl in the United States, for example, led to the flight of 2.5 million people from the Plains by 1940, many to the new cities in the West. It is estimated that as many as one out of every four residents in the Plains States left during the 1930s. More recently, drought in Syria from 2006-2011 has prompted a rural exodus to major urban centers. Massive influxes in urban areas, combined with difficult living conditions, have prompted some scholars to link the drought to the arrival of the Arab Spring in Syria.

The terms are used in the United States and Canada to describe the flight of people from rural areas in the Great Plains and Midwest regions, and to a lesser extent rural areas of the northeast and southeast and Appalachia. It is also particularly noticeable in parts of Atlantic Canada (especially Newfoundland), since the collapse of Atlantic cod fishing fields in 1992.

China, like many other currently industrializing countries, has had a relatively late start to rural flight. Until 1983, the Chinese government, through the hukou system, greatly restricted the ability of their citizens to internally migrate. Since 1983, the Chinese government has progressively lifted the restrictions on internal migration. This has led to a great increase in the number of people migrating to urban areas. However, even today, the hukou system limits the ability of rural migrants to receive full access to urban social services at the urban subsidized costs.

As with most examples of rural flight, several factors have led towards Chinaâs massive urbanization. Income disparity, family pressure, surplus labor in rural areas due to higher average fertility rates, and improved living conditions all play a role in contributing to the flows of migrants from rural to urban areas. Approximately, 250 million rural migrants now live in cities with 54% of the total Chinese population living in urban areas.

A focus by landowners on efficient production led to the enclosure of the commons in the 16th and 17th centuries. This created unrest in rural areas as tenants were then unable to graze their livestock. They sometimes resorted to illegal means to support their families.. This was followed, in turn, by penal transportation which sent offenders out of the country, often Australia. Eventually, economic measures produced the British Agricultural Revolution.

Rural flight has been occurring to some degree in Germany since the 11th century. A corresponding principle of German law is "Stadtluft macht frei" ("city air makes you free"), in longer form "Stadtluft macht frei nach Jahr und Tag" ("city air makes you free after a year and a day"): by custom and, from 1231/32, by statute, a serf who had spent a year and a day in a city was free, and could not be reclaimed by their former master.

"Landflucht" ("flight from the land") refers to the mass migration of peasants into the cities that occurred in Germany (and throughout most of Europe) in the late 19th century.

In 1870 the rural population of Germany constituted 64% of the population; by 1907 it had shrunk to 33%. In 1900 alone, the Prussian provinces of East Prussia, West Prussia, Posen, Silesia, and Pomerania lost about 1,600,000 people to the cities, where these former agricultural workers were absorbed into the rapidly growing factory labor class; One of the causes of this mass-migration was the decrease in rural income compared to the rates of pay in the cities.

Landflucht resulted in a major transformation of the German countryside and agriculture. Mechanized agriculture and migrant workers, particularly Poles from the east (SachsengÃ¤nger), became more common. This was especially true in the province of Posen that was gained by Prussia when Poland was partitioned. The Polish population of eastern Germany was one of the justifications for the creation of the "Polish corridor" after World War I and the absorption of the land east of the Oder-Neisse line into Poland after World War II. Also, some labor-intensive enterprises were replaced by much less labor-intensive ones such as game preserves.

The word "Landflucht" has negative connotations in German, as it was coined by agricultural employers, often of the German aristocracy, who were lamenting their labor shortages.

The rural exodus of Scotland followed that of England, but delayed by several centuries. Consolidation of farms and elimination of inefficient tenants occurred over about 110 years from the 18th to the 19th centuries. Samuel Johnson encountered this in 1773 and documented it in his work "A Journey to the Western Islands of Scotland." He deplored the exodus but did not have the information to analyze the problem.

Rural flight and out-migration in Sweden can be traced in two distinct waves. The first, beginning in the 1850s when 82% of the Swedish population lived in rural areas, and continuing till the late 1880s, was mostly due to push factors in the countryside related to poverty, unemployment, low agricultural wages, debt peonage, semi-feudalism, and religious oppression by the State church. Most of the migration was ad-hoc and directed towards emigration to the three big cities of Sweden, America, Denmark, or Germany. Many of these first emigrants were unskilled, barely literate laborers who sought farm work or daily wage labour in the cities.

The second wave started from the late 1890s and reached its peak between 1922 and 1967, with the highest rates of rural flight occurring in the 1920s and the 1950s. This was mostly "pull factors" due to the economic boom and industrial prosperity in Sweden wherein the massive economic expansion and wage increases in the urban areas pulled young people to migrate for work and at the same time drove down work opportunities in the countryside. Between 1925 and 1965, Sweden's GDP per capita increased from USD 850 to USD 6200. Simultaneously, the percentage of the population living in rural areas decreased drastically from 54% in 1925 to 21% in 1965.

Rural flight began later for Russia and the former states of the USSR than in Western Europe. In 1926 only 18% of Russians lived in urban areas, compared to over 75% at the same time in the United Kingdom. Although the process began later, throughout World War II and the decades immediately proceeding, rural flight proceeded at a rapid pace. By 1965, 53% of Russians lived in urban areas. Statistics compiled by M. Ya Sonin, a Soviet author, in 1959, demonstrate the rapid urbanization of the USSR. Between 1939 and 1959, the rural population declined by 21.3 million, while that of urban centers increased by 39.4 million. Of this dramatic shift in population, rural flight accounts for more than 60% of the change. Generally, most rural migrants tended to settle in cities and towns within their district. Rural flight persisted through the majority of the 20th century. However, with the end of the Soviet Union, rural flight reversed as political and economic instability in the cities prompted many urban dwellers to return to rural villages. 
Rural flight did not occur uniformly throughout the USSR. Western Russia and Ukraine experienced the greatest declines in rural population, 30% and 17% respectively. Conversely, peripheral regions of the USSR, like Central Asia, experienced gains, contradicting the general pattern of rural-urban migration of this period. Increased diversification of crops and labor shortages were primary contributors to the gains in rural population in the periphery.

Rural flight in Russia and the former USSR had several major determinants. The industrialization of agriculture, which came later in Russia and the former USSR, led to declines in available rural jobs. Lower living standards and tough work also motivated some peasants to migrate to urban areas. In particular, the Soviet "kolkhoz" system (the collective farms in the Soviet Union) aided in maintaining low living standards for Soviet peasants. Beginning around 1928, the kolkhoz system replaced family farms throughout the Soviet Union. Forced to work long hours for low pay at rates fixed by the government and often unadjusted to inflation, Russian peasants experienced quite low living-conditions - especially compared to urban life. While Brezhnev's wage reforms in 1965 ameliorated the low wages received by peasants, rural life remained suffocating, especially for the skilled and the educated. 
Although migrants came from all segments of society, several groups were more likely to migrate than others. Like other examples of rural flight, the young were more likely than the old to migrate to the cities. Young women under 20 were the most likely segment of the population to leave rural life. This exodus of young women further exacerbated the demographic transitions occurring in rural communities as the rate of natural increase dropped precipitously over the course of the 20th century. Lastly, the skilled and educated were also likely to migrate to urban areas.

Rural flight in Mexico occurred throughout the 1930s up until the present day. Like other developing nations, the beginning of industrialization in Mexico quickly accelerated the rate of rural flight.

In the 1930s, President Cardenas implemented a series of agricultural reforms that led to massive redistribution of agricultural land among the rural peasants. Some commentators have subsequently dubbed the period from 1940-1965 as the "Golden Era for Mexican Migration." During this period, Mexican agriculture grew at an average rate of 5.7% outpacing the natural increase of 3% of the rural population. Concurrently, government policies favoring industrialization led to a massive increase of industrial jobs in the cities. Statistics compiled in Mexico City demonstrate this trend with over 1.8 million jobs created over the course of the 1940s, 50s, and 60s. Young people with schooling were the segment of population most likely to migrate away from rural life to urban life, attracted by the promise of many jobs and a more modern lifestyle as compared to the conservative conditions in rural villages. Additionally, due to the large demand for new workers, many of these jobs had low entrance requirements that also provided on-site job training opening the avenue for migration to many rural residents. From 1940 to about 1965, rural flight occurred in a slow, yet steady pace with both agriculture and industry growing concurrently.

However, as government policies increasingly favored industry over agriculture, rural conditions began to deteriorate. In 1957, the Mexican government began to regulate the price of maize through massive imports in order to keep low urban food costs. This regulation severely undercut the market price of maize lowering the profit margins of small farmers. At the same time, the Green Revolution had entered into Mexican agriculture. Inspired by the work of Norman Borlaug, farmers that employed hybrid seeds and fertilizer supplements were able to double or even triple their yields per acre. Unfortunately, these products came at a relatively high cost, out of the reach of many farmers struggling after the devaluation of the price of maize. The combined effects of the maize price regulation and the Green Revolution was the consolidation of small farms into larger estates. A 1974 study conducted by Osorio concluded that in 1960, about 50.3% of the individual land plots in Mexico contained less than 5 hectares of land. In contrast, the top 0.5% of estates by land spanned 28.3% of all arable land. As many small farmers lost land, they either migrated to the cities or became migrant workers roving from large estate to large estate. Between 1950 and 1970, the proportion of migrant workers increased from 36.7% to 54% of the total population. The centralized pattern of industrial development and government policies overwhelmingly favoring industrialization contributed to massive rural flight in Mexico beginning in the late 1960s until the present day.

Rural migrants to cities face several challenges that may hinder their quality of life upon moving into urbanized areas. Many migrants do not have the education or skills to acquire decent jobs in cities and are then forced into unstable, low paying jobs. The steady stream of new rural migrants worsens underemployment and unemployment, common among rural migrants. Employers offer lower wages and poorer labor conditions to rural migrants, who must compete with each other for limited jobs, often unaware of their labor rights. Rural migrants often experience poor living conditions as well. Many cities have exploded in population; services and infrastructure, in these cities, are unable to keep up with population growth. Massive influxes in rural population can lead to severe housing shortages, inadequate water and energy supply, and general slum-like conditions throughout cities.

Additionally, rural migrants often struggle adjusting to city life. In some instances, there are cultural differences between the rural and urban areas of a region. Lost in urban regions, it becomes difficult for them to continue holding onto their cultural traditions. Urban residents may also look down upon these newcomers to the city who are often unaware of city social norms. Both marginalized and separated from their home cultures, migrants face many social challenges when moving to cities.

Women, in particular, face a unique set of challenges. Some women undergo rural flight to escape domestic abuse or forced early marriages. Some parents choose to send women to cities to find jobs in order to send remittances back home. Once in the city, employers may attempt to take advantage of these women preying on their unfamiliarity with labor laws and social networks on which to rely. In the worst of cases, destitution may force women into prostitution, exposing them to social stigma and the risks of sexually transmitted diseases.




</doc>
<doc id="26333" url="https://en.wikipedia.org/wiki?curid=26333" title="Robotech">
Robotech

Robotech is a science fiction franchise that began with an 85-episode anime television series produced by Harmony Gold USA in association with Tatsunoko Production and first released in the United States in 1985.
It was adapted from three original and distinct, though visually similar, Japanese anime television series ("Super Dimension Fortress Macross", "Super Dimension Cavalry Southern Cross", and "Genesis Climber MOSPEADA") to make a series suitable for syndication.

In the series, "Robotechnology" refers to the scientific advances discovered in an alien starship that crashed on a South Pacific island. With this technology, Earth developed robotic technologies, such as transformable mecha, to fight three successive extraterrestrial invasions.

Prior to the release of the TV series, the name "Robotech" was used by model kit manufacturer Revell on their "Robotech Defenders" line in the mid-1980s. The line consisted of mecha model kits imported from Japan and featured in anime titles such as "Super Dimension Fortress Macross" (1982), "Super Dimension Century Orguss" (1983) and "Fang of the Sun Dougram" (1981). The kits were originally intended to be a marketing tie-in to a similarly named comic book series by DC Comics, which was cancelled after only two issues.

At the same time, Harmony Gold licensed the "Macross" TV series for direct-to-video distribution in 1984, but their merchandising plans were compromised by Revell's prior distribution of the "Macross" kits. In the end, both parties signed a co-licensing agreement and the "Robotech" name was adopted for the TV syndication of "Macross" combined with "Super Dimension Cavalry Southern Cross" (1984) and "Genesis Climber MOSPEADA" (1983).

"The "Robotech" chronology, according to Harmony Gold, is illustrated below:

Note: Asterisked works are now considered 'secondary continuity'âthat is, that their events exist in the continuity of "Robotech", but 'don't count' when conflicts arise with the primary continuity that comprises the three-part "Robotech" TV series and 2006's "".

In 2002, with the publication of the WildStorm (DC) comics, Harmony Gold officially decided to retcon the "Robotech" Universe. The following "Robotech" material is now relegated to the status of secondary continuity:


While these materials are not precisely 'retired' or 'removed' from the continuity, their events are subject to critical review, and are strictly subordinate to the 'official' events of the 85-episode animated series.

"Robotech" (1985) is an original story adapted with edited content and revised dialogue from the animation of three different mecha anime series:

Harmony Gold's cited reasoning for combining these unrelated series was its decision to market "Macross" for American weekday syndication television, which required a minimum of 65 episodes at the time (thirteen weeks at five episodes per week). "Macross" and the two other series each had fewer episodes than required, since they originally aired in Japan as weekly series. On some television stations, the syndicated run was preceded by the broadcast premiere of "", a feature-length pilot.

This combination resulted in a storyline that spans three generations, as mankind must fight three destructive 'Robotech Wars' in succession with various invading forces, each of which is motivated in one way or another by a desire for a powerful energy source called 'protoculture'. While each of the three animated series used for its footage informs its content, the Robotech storyline is distinct and separate from each of them.


"Robotech: The Movie", also called "Robotech: The Untold Story", is a feature film and was the first new "Robotech" adventure created after the premiere of the original series. It uses footage from the "Megazone 23 â Part 1" OVA (original video animation; made-for-video animated feature) combined with scenes from "Southern Cross" and additional original animation produced for the film.

The original plan for the film was to have it set during the Macross Saga, parallel to the SDF-1's return to Earth from Pluto. The film would also have served as a prequel to the Sentinels, as both projects were initially meant to share many characters. Harmony Gold producer Carl Macek worked with the OVA's original creators to make the story and the new ending work. The film had to be changed again after the distributor of the film, Cannon Films, saw an incomplete rough cut of the film and were upset by it. They ordered Macek to remove multiple scenes from the film and to add more violence (most of the scenes removed were scenes setting up characters and showing female characters interacting). Macek reluctantly did what they ordered, and created a new script and rough edit for the film in less than 24 hours. When the distributors saw Macek act out the new film, they were much more pleased with the new cut. The opening night in Texas received a positive response, but Cannon Films pulled out after noting that most attendants were adults; the bulk of the scheduled advertising for the series was targeted to children. The film had limited success in Argentina and Belgium.

In 2011, A&E Home Video released, as a part of their "Robotech: The Complete Series" collection, a 29-minute version of "Robotech: The Movie" containing only footage used from "Southern Cross". There was no attempt to remaster the footage.

This aborted American-produced series would have followed the continuing adventures of Rick and Lisa Hunter and the Robotech Expedition during the events of "The Masters" and "The New Generation". The feature-length pilot is composed of the first three (and only) episodes that were produced. "The Sentinels" featured characters from all three "Robotech" sagas and introduced the SDF-3 along with an overview of their new mission. The series was planned to have a total of 65 episodes.

In "Robotech Art 3: The Sentinels", Carl Macek blamed the cancellation of the series on the crash of the Yen/Dollar exchange rate, which caused toy partner Matchbox to withdraw from the project. Harmony Gold lacked the funds to produce the series on its own, and production ceased after only three episodes.

"Robotech II: The Sentinels" was released on VHS by Palladium Books. In 2011, a "remastered" version was released on the A&E DVD set, "Robotech: The Complete Original Series" DVD. This version has opening titles resembling those found on the "Robotech Remastered" DVDs, as well as a new ending with text explaining the fate of the SDF-3. Also, all of the flashback footage used from "The Macross Saga" has been removed, including the re-used footage from the episode "Wedding Bells".

In 2002, Tommy Yune announced development of a new sequel film, which was untitled until 2004 as "Robotech: Shadow Force". The storyline overlaps with and continues from the unresolved ending of the original series. The title of the story arc was soon changed to "". The first trailers with finished animation were shown at Anime Expo and Comic-Con International in 2005. It was not until February 2006, when Kevin McKeever, operations coordinator at Harmony Gold, was able to confirm that the pilot movie had been completed. After a series of delays, FUNimation Entertainment was finally announced as the home video, broadcast, and theatrical distributor at the 2006 Comic-Con International in San Diego with the possibility of producing further sequels. Harmony Gold premiered the movie at various film festivals in 2006, and it was first seen by a public audience at MechaCon on August 9, 2006, where it was showcased as a charity screening to help raise funds for the ongoing Hurricane Katrina and Hurricane Rita recovery effort. A limited theatrical run followed in January 2007, and the film was released on DVD on February 6, 2007. A two-disc collector's edition was released in November 2007.

First revealed in late 2011 in the final minutes of "Carl Macek's Robotech Universe", a documentary on the making of "Robotech" dedicated to the then-recent passing of Macek, "Love Live Alive" is an adaptation of the 1985 "Genesis Climber Mospeada" OVA, "Love Live Alive", incorporating some brand-new animation. The film was released on DVD on July 23, 2013, by Lionsgate Home Entertainment in North America.

This promotional VHS tape created by Matchbox was included with their "Robotech Wars" playset. This video includes two episodes cobbled together from clips of "The Macross Saga". Titled "To the End of the Universe" and "Battle Royale", these episodes contain no new footage, and are not meant to follow any continuity established in the TV series.

Carl Macek revealed ideas for another proposed series, "Robotech: The Odyssey", which would have picked up where "The New Generation" and end of "Robotech: The Sentinels" left off, and eventually created a circular storyline that would end where the original "Robotech" began in a giant 260-episode cycle to fill up all the weekdays in a year. According to Macek, "The Odyssey" would have involved the SDF-3 travelling back into the past to the days before the birth of Zor (as well as Scott Bernard's search for the SDF-3). The SDF-3's crew would become citizens of the Robotech Masters' homeworld and change time by becoming a part of its history. Ultimately, it would be revealed that Lynn Minmei was the mother of Zor, making Minmei the focal point of Robotech. The final episode of the Odyssey would be of Zor dying and his Super Dimension Fortress (the SDF-1) being launched into space, and eventually crash landing on Earth in 1999. The next episode after that would be "Boobytrap", episode 1 of the original series which in turn will create an endless loop within the "Robotech" universe. After the failure of "Sentinels", "Odyssey" never went into development, although some of its ideas were worked into the final Jack McKinney novel "The End of the Circle", which wrapped up all of the outstanding plot threads left by the original series and the previous "Robotech" novels.

Fan publication "Macross Life" interviewed Harmony Gold executive Richard Firth in 1986, where he revealed that Macek had "plans through "ROBOTECH V", which would give us an episode for each day of the year for a year and a half." He also said that these two installments would have brought the series to 285 episodes. Regarding the plot, Firth mentioned a "retired Commodore Hunter, whomever that may be, could very well be speaking at the graduation of the later day cadets or whatever, and they ask him to tell them the story all over again: it comes back [to the first episode of the series]."

Macek himself described a fourth and fifth series envisioned for Robotech in Chris Meadow's Space Station Liberty podcast in 2007. Macek mentioned the original series as the first, The Sentinels as Robotech II, The Odyssey as Robotech III, and then 2 further series detailing the evolution of Zor, bringing the combined series' total to approximately 300 episodes.

Macek attempted another sequel with the development of "Robotech 3000". This all-CGI series would have been set a millennium in the future of the "Robotech" universe and feature none of the old series' characters. In the three-minute trailer, an expedition is sent to check on a non-responsive mining outpost and is attacked by "infected" Veritech mecha. The idea was abandoned midway into production after negative reception within the company, negative fan reactions at the FanimeCon anime convention in 2000, and financial difficulties within Netter Digital who was animating the show. The trailer is hosted on the official "Robotech" website, and was included in the 2007 release of the "Robotech: The Shadow Chronicles" 2-disc collector's DVD, along with behind-the-scenes motion capture footage.

In October 2004, veteran animation writer and producer Greg Weisman revealed that he wrote developed an animated spin-off series titled "Robotech: Mars Force". When asked about the project, Weisman said that he was under a non-disclosure agreement with Harmony Gold and was only allowed to mention that he developed the series.

In 2006, Harmony Gold Creative Director Tommy Yune elaborated on the project in the Space Station Liberty Podcast, saying that Mars Force was a series geared at younger audiences, following the children Robotech Expeditionary Force. A similar plot would later be used for canceled 2014 spin-off, "Robotech Academy".

A sixty-second public service announcement for the 60th anniversary of the United Nations, featuring Scott Bernard and Ariel, was animated during the production of "The Shadow Chronicles". Although it did not use the original voice actors and the dialogue was somewhat out-of-character, it nonetheless marked the first fully completed "Robotech" footage in many years.

On July 27, 2007, at their Comic-Con International panel, Harmony Gold and Yune unveiled the second entry of the "Shadow Chronicles" production, titled "Robotech: Shadow Rising" and was to be a co-production with FUNimation Entertainment. Pre-production reportedly began on February 2007 and a projected release date of sometime in 2009 was originally expected. Production ceased after Harmony Gold terminated their deal with FUNimation Entertainment due to creative differences.

At Comic-Con 2012, Tommy Yune announced that "Love Live Alive" would pave the way for "Shadow Rising". As of 2015, the Shadow Rising trademark remains abandoned since 2007.

On July 5, 2014, Harmony Gold started a Kickstarter project for "Robotech Academy", which Macek had developed before he died. The goal of this project was to raise US$500,000 to produce a new 24-minute pilot episode. The crowdfunding project was to have closed on August 9, 2014; however, on August 2, the project was canceled with a pledge level of US$194,574, or 39% of its target. Harmony Gold, however, announced that further plans to fund the project were being explored. At the 2014 Long Beach Comic Con, it was announced that the producers at Harmony Gold were in talks with at least one new media network on the prospect of producing the show. As of December 7, 2015, the project remains abandoned.

In the 1990s, Seishun Shitemasu, an anime fandubbing group, produced the parodies "Robotech III: Not Necessarily the Sentinels" and "Robotech IV: Khyron's Counterattack", using footage from, respectively, "Gunbuster" and "", continuing the tradition of the original Robotech's adaptation of unrelated anime series into a single continuity.

On July 2, 2010, Ecuadorian animator Patricio "Pat" Mosquera uploaded to YouTube a teaser for "Robotech Skull Knights". On August 17, 2010, second teaser revealed Rick Hunter standing in front of an image of the VF-4 shown in the final episodes of the original series. "Robotech Skull Knights" has not been released yet. In July 2013, Patricio Mosquera was included as an animation director in the staff list in the IMDb page of "Love Live Alive".

On December 31, 2012, Cesar Turturro uploaded to YouTube an Argentinian fan trailer for "Robotech Valkyrie Project". On December, 2013 the first episode was uploaded to YouTube, and in January 2014, the second episode was also uploaded. The series was cancelled after Harmony Gold issued a "cease and desist" letter to the producers. The team was, however, hired to do the CGI effects for "Robotech: Academy".

On September 7, 2007, "The Hollywood Reporter" stated that Warner Bros. had acquired the film rights to "Robotech" and would be producing a live-action film with an as-yet-unknown release date. Tobey Maguire is producing the film through his Maguire Entertainment banner and is pursuing the lead role, in what the studio plans to be a tentpole science fiction franchise. Maguire stated, "We are very excited to bring "Robotech" to the big screen. There is a rich mythology that will be a great foundation for a sophisticated, smart and entertaining film."

In an interview, Harmony Gold representative Kevin McKeever said that Warner Bros. had approached Harmony Gold about the project, that Harmony Gold would have "a say" in its creative direction, and that it was not expected to affect the production schedule for "". He was unable to confirm any details of budget, casting, expected release date, or storyline, explaining that it was too early in the life of the project for these things to have been decided.

In June 2008, it was reported that Lawrence Kasdan had been hired to write the film, with Charles Roven and Akiva Goldsman joining Tobey Maguire as producers. During the Robotech Panel at Anime Expo 2008, the involvement of Maguire and Kasdan was confirmed, with Kasdan writing the script for the live-action film. Tommy Yune also revealed that the film is planned as a re-imagining of the original "Robotech" universe (with new updated mecha and character designs) and will take place several years in the future, departing from the original cartoon's 2009 setting.

As of November 2008, Alfred Gough and Miles Millar (who both worked in "Smallville", "Spider-Man 2", "", and "") are the writers for the film.

Roven is currently no longer working on the proposed film adaptation of the "Robotech" animated series, but he wished the remaining producers Goldsman and Maguire "fantastic luck" on the project.

The Mania.com website reported on June 23, 2009, that British television writer and novelist Tom Rob Smith "has taken over writing duties" for the proposed film adaptation. Smith wrote for the British soaps "Family Affairs" and "Bad Girls" before writing the critically acclaimed crime suspense novel "Child 44". Smith will be the fourth writer or writing team to be reportedly attached to the upcoming film's pre-production.

In early 2013, "The Hollywood Reporter" announced that Warner Bros. was in talks with commercial director Nic Mathieu to direct the film. On July 24, 2013, it was reported that Leonardo DiCaprio had turned down a role in "" and has shown interest to star as a main character in the upcoming big screen version of "Robotech". DiCaprio is a longtime friend of Tobey Maguire; they co-starred in "The Great Gatsby". Maguire will probably participate in the film as another one of the lead actorsâwhile Nic Mathieu will direct.
On February 4, 2015, Deadline.com reported Gianni Nunori and Mark Canton selected Michael B. Gordon to write the film's script and are looking at Andy Muschietti to direct it.

On March 25, 2015, Variety announced that the "Robotech" franchise had been acquired by Sony Pictures, who views "Robotech" as a potential film franchise. On April 29, 2015, Deadline reported that James Wan is in talks to direct the film. On June 3, 2015, "The Hollywood Reporter" reported that Wan is confirmed to direct the film.

On July 3, 2015, Kevin McKeever of Harmony Gold announced at Anime Expo that Sony has the rights to release this film worldwide, with the exception of Japan.

On March 27, 2016, Wan told IGN that the film will follow the roots of the franchise.

As of April 4, 2016, Harmony Gold's Kevin McKeever revealed on the official Robotech Facebook page that their deal with Sony is still not finalized.

On July 17, 2017, it was reported by The Hollywood Reporter that Argentine filmmaker Andy Muschietti will direct the project, after Wan dropped out to work on "Aquaman".

On September 12, 2017, Jason Fuchs was reportedly hired by the studio to write the script for the film.

In September 2019, when asked about which project he would choose to direct next, director Andy Muschietti told the Argentinian news agency TÃ©lam that Robotech is a âcomplicatedâ property, citing its lack of popularity in the United States compared to other properties, and its requirement of a $100 million budget.Â  He did, however, say that the script is completed.

At the time of its broadcast, Harmony Gold also launched "Robotech" through a popular line of comics to be followed by novels, role-playing games, toys, and other consumer products. With the cancellation of "Robotech II: The Sentinels", many of these licensed products were discontinued, and led to a drought of "Robotech" product through much of the 1990s, except for publishers who continued "The Sentinels" storyline in print.

In 1986, Starblaze Graphics published "Robotech Art 1", a reference book containing artwork, Japanese production designs, and episode guides from the original television series. This was followed by "Robotech Art 2", which was largely a collection of art by various American artists and fans. In 1988, Carl Macek collected much of the unused designs from "Robotech II: The Sentinels" into "Robotech Art 3: The Sentinels", which also included his story outline for the rest of the unfinished series, with an explanation behind its cancellation. In 2007, Stone Bridge Press published "The Art of Robotech: The Shadow Chronicles".

"Robotech" comics were first published in 1984 with DC Comics' short-lived "Robotech Defenders" and Comico's adaptation of the first episode of the Japanese version of "Macross". However, the first adaptation of the "Robotech" television series did not arrive until 1985 with Comico's "Robotech: The Macross Saga" Number 2, which continued from the first "Macross" issue.

The various comic publishers include:


The first "Robotech" collectible card game was released in 2006 by Hero Factory, which had previously produced "Robotech" trading cards.

Various "Robotech" soundtracks have been released on records, cassettes, and compact discs since 1988.


Since 1987, "Robotech" was adapted into novel form by "Jack McKinney", a pseudonym for the team of James Luceno and the late Brian Daley, a pair of writers who had been working with Macek since they had collaborated on the animated series "Galaxy Rangers". Using fictitious epigraphs in the style of "Dune", McKinney's novels fleshed out the chronology (including adapting the incomplete "Sentinels" source material) in far greater detail than the original animation. Many "Robotech" fans consider the McKinney series to be an unofficial canon of its own, despite notable divergences in the writing from Harmony Gold's current official animation-based canon. Despite no longer being considered core-continuity by Harmony Gold, the novels have been recently re-issued by Del Rey Books as Omnibus compilations.

In 1986, Palladium Books published a role-playing game based on the "Robotech" series, including several books covering the "Sentinels" portion of the storyline. The original "Robotech" RPG line went out of print as of June 30, 2001, but Harmony Gold and Palladium Books signed an agreement in 2007 to produce a new line of Robotech RPG books, beginning with a book covering and promoting the feature-length film "The Shadow Chronicles". The "" sourcebook first book was released on March 21, 2008, followed by sourcebooks covering the Macross, Masters, and New Generation chapters of Robotech (redrafted to reflect the Harmony Gold canon). Other sourcebooks and supplements are reflected in the Palladium Books production pipeline.

On April 18, 2013, Palladium started a campaign on the crowdfunding site Kickstarter for a tabletop miniatures game based on the Robotech RPG called "Robotech: RPG Tactics". The miniatures are being produced by Ninja Division (combining sculpting talents from Soda Pop Miniatures and Cipher Studios), and will feature multi part plastic miniatures that can be posed during assembly. The campaign reached its goal in 3 hours, and was initially scheduled to release in December 2013, but delays have persisted into 2018.

In May 2019, under licencing from Harmony Gold and Strange Machine Games, Battlefield Press International produced a game book for the new Savage Worlds Adventure Edition.

Action figures in the size of the three "Robotech" generations were initially released in 1985 by Matchbox toy company, but then reissued in 1992 by Harmony Gold (Lunk and Corg were only released by Matchbox and Lynn Minmei was only released by Harmony Gold). Each included a weapon and helmet where appropriate. Matchbox also released figures of Zentraedi characters from the first generation. These figures were supposed to represent the size difference between the Humans and the giant Zentraedi forces, but to be correct these figures would have to have been made about tall. None of the larger figures came with weapons but the Armored Zentraedi came with a removable helmet.

Also many toys depicting the vehicles and mecha from the series were released by Matchbox in 1985, Harmony Gold in 1992 and Playmates Toys in 1994 (under the Exosquad line). There were major differences in packaging, toy stickers and colors between the different releases. The vehicles were designed to be used only with the 3Â¾-inch figures. The SDF-1 Playset was only released under the Matchbox line in the 1980s and could be used with both the 3Â¾- and six-inch figures.

Harmony Gold and Matchbox were unable to sell the 1/55 VF-1 Valkyrie toy originally sold in Japan by Takatoku Toys due to Hasbro licensing it as Jetfire in the Transformers toy line. Because of this, they settled with manufacturing a non-transformable Veritech Fighter that could fit any of the 3Â¾-inch action figures, as well as importing the transformable super deformed Veritech Fighters (originally manufactured in Japan by Bandai as "Macross" VF-1 Valkyrie "Joke machines").

Since the late 1990s, there has been a resurgence of "Robotech"-related toys. In 2001, Toynami released the "Robotech Masterpiece Collection" line, featuring replicas of the Veritech Fighters of "The Macross Saga". Since then, Toynami has become the exclusive toy manufacturer of the "Robotech" franchiseâhaving covered mecha from "The Macross Saga", "The New Generation" and "The Shadow Chronicles".

"Robotech" spawned five video game licenses, of which the most recent three were released:


"Robotech" is often a polarizing subject amongst anime fans. Some critics look down upon the show for its extensive edits to the source material (Westernizing character names, editing for content and chiefly, forging a connection between previously unrelated series), while supporters of the adaptation have pointed out that the weaving of three unrelated series into a contiguous whole necessarily required reworking, and that it helped to maintain a slow but continuous rise in the consumption of anime in the US.

Series writer/actor Gregory Snegoff said in an interview on the now-defunct "Shadow Chronicles News" fansite that, "afterward, we received compliments from the Japanese who thought our dialogue and stories were better than the original," likely a reference to the creators of the latter two series, both of whom worked with the team on "The Sentinels". The producers of "Megazone 23 â Part 1" were very happy with the original plans for "" (where the incomplete film would have been added to the "Robotech" mythos to play part in "The Sentinels" storyline), and worked closely with Carl Macek to plan the new ending and animation. When the film reached a limited release, the new ending was released on a LaserDisc of "Megazone 23", with the title "Present For You." However, "Animag" magazine (issue 11) and "Animerica" magazine (issue 9, volume 4) reports that the staff of "Macross" at Studio Nue and Artland, such as the original story creator and mecha designer ShÅji Kawamori and chief director Noboru Ishiguro, expressed their concern over the "Robotech" adaptation, and surprise at its differences.

In 2009, "IGN" ranked "Robotech" as the 34th-greatest animated show of all time in their Top 100 list.

Following the original broadcast, the series enjoyed popularity on home video in VHS and DVD formats from the following distributors:



</doc>
<doc id="26340" url="https://en.wikipedia.org/wiki?curid=26340" title="Red China">
Red China

Red China may refer to:



</doc>
<doc id="26341" url="https://en.wikipedia.org/wiki?curid=26341" title="Radioteletype">
Radioteletype

Radioteletype (RTTY) is a telecommunications system consisting originally of two or more electromechanical teleprinters in different locations connected by radio rather than a wired link. These machines were superseded by personal computers (PCs) running software to emulate teleprinters. Radioteletype evolved from earlier landline teleprinter operations that began in the mid-1800s. The US Navy Department successfully tested printing telegraphy between an airplane and ground radio station in 1922. Later that year, the Radio Corporation of America successfully tested printing telegraphy via their Chatham, Massachusetts, radio station to the R.M.S. Majestic. Commercial RTTY systems were in active service between San Francisco and Honolulu as early as April 1932 and between San Francisco and New York City by 1934. The US military used radioteletype in the 1930s and expanded this usage during World War II. From the 1980s, teleprinters were replaced by computers running teleprinter emulation software.

The term radioteletype is used to describe both the original radioteletype system, sometimes described as "Baudot", as well as the entire family of systems connecting two or more teleprinters or PCs using software to emulate teleprinters, over radio, regardless of alphabet, link system or modulation.

In some applications, notably military and government, radioteletype is known by the acronym RATT (Radio Automatic Teletype).

Landline teleprinter operations began in 1849 when a circuit was put in service between Philadelphia and New York City. Ãmile Baudot designed a system using a five unit code in 1874 that is still in use today. Teleprinter system design was gradually improved until, at the beginning of World War II, it represented the principal distribution method used by the news services.

Radioteletype evolved from these earlier landline teleprinter operations. The US Department of the Navy successfully tested printing telegraphy between an airplane and ground radio station in August 1922. Later that year, the Radio Corporation of America successfully tested printing telegraphy via their Chatham, MA radio station to the R.M.S. Majestic. An early implementation of the Radioteletype was the Watsongraph, named after Detroit inventor Glenn Watson in March 1931. Commercial RTTY systems were in active service between San Francisco and Honolulu as early as April 1932 and between San Francisco and New York City by 1934. The US Military used radioteletype in the 1930s and expanded this usage during World War II. The Navy called radioteletype "RATT" (Radio Automatic Teletype) and the Army Signal Corps called radioteletype "SCRT", an abbreviation of Single-Channel Radio Teletype. The military used frequency shift keying technology and this technology proved very reliable even over long distances.

From the 1980s, teleprinters were replaced by computers running teleprinter emulation software.

A radioteletype station consists of three distinct parts: the Teletype or teleprinter, the modem and the radio.

The Teletype or teleprinter is an electromechanical or electronic device. The word "Teletype" was a trademark of the Teletype Corporation, so the terms "TTY", "RTTY", "RATT" and "teleprinter" are usually used to describe a generic device without reference to a particular manufacturer.

Electromechanical teleprinters were heavy, complex and noisy, and have been replaced with electronic units. The teleprinter includes a keyboard, which is the main means of entering text, and a printer or visual display unit (VDU). An alternative input device is a perforated tape reader and, more recently, computer storage media (such as floppy disks). Alternative output devices are tape perforators and computer storage media.

The line output of a teleprinter can be at either digital logic levels (+5Â V signifies a logical "1" or "mark" and 0Â V signifies a logical "0" or "space") or line levels (â80Â V signifies a "1" and +80Â V a "0"). When no traffic is passed, the line idles at the "mark" state.

When a key of the teleprinter keyboard is pressed, a 5-bit character is generated. The teleprinter converts it to serial format and transmits a sequence of a "start bit" (a logical 0 or space), then one after the other the 5 data bits, finishing with a "stop bit" (a logical 1 or mark, lasting 1, 1.5 or 2 bits). When a sequence of start bit, 5 data bits and stop bit arrives at the input of the teleprinter, it is converted to a 5-bit word and passed to the printer or VDU. With electromechanical teleprinters, these functions required complicated electromechanical devices, but they are easily implemented with standard digital electronics using shift registers. Special integrated circuits have been developed for this function, for example the Intersil 6402 and 6403. These are stand-alone UART devices, similar to computer serial port peripherals.

The 5 data bits allow for only 32 different codes, which cannot accommodate the 26 letters, 10 figures, space, a few punctuation marks and the required control codes, such as carriage return, new line, bell, etc. To overcome this limitation, the teleprinter has two "states", the "unshifted" or "letters" state and the "shifted" or "numbers" or "figures" state. The change from one state to the other takes place when the special control codes "LETTERS" and "FIGURES" are sent from the keyboard or received from the line. In the "letters" state the teleprinter prints the letters and space while in the shifted state it prints the numerals and punctuation marks. Teleprinters for languages using other alphabets also use an additional "third shift" state, in which they print letters in the alternative alphabet.

The modem is sometimes called the terminal unit and is an electronic device which is connected between the teleprinter and the radio transceiver. The transmitting part of the modem converts the digital signal transmitted by the teleprinter or tape reader to one or the other of a pair of audio frequency tones, traditionally 2295/2125Â Hz (US) or 2125/1955Â Hz (Europe). One of the tones corresponds to the "mark" condition and the other to the "space" condition. These audio tones, then, modulate an SSB transmitter to produce the final audio-frequency shift keying (AFSK) radio frequency signal. Some transmitters are capable of direct frequency-shift keying (FSK) as they can directly accept the digital signal and change their transmitting frequency according to the "mark" or "space" input state. In this case the transmitting part of the modem is bypassed.

On reception, the FSK signal is converted to the original tones by mixing the FSK signal with a local oscillator called the BFO or "beat frequency oscillator". These tones are fed to the demodulator part of the modem, which processes them through a series of filters and detectors to recreate the original digital signal. The FSK signals are audible on a communications radio receiver equipped with a BFO, and have a distinctive "beedle-eeeedle-eedle-eee" sound, usually starting and ending on one of the two tones ("idle on mark").

The transmission speed is a characteristic of the teleprinter while the shift (the difference between the tones representing mark and space) is a characteristic of the modem. These two parameters are therefore independent, provided they have satisfied the minimum shift size for a given transmission speed. Electronic teleprinters can readily operate in a variety of speeds, but mechanical teleprinters require the change of gears in order to operate at different speeds.

Today, both functions can be performed with modern computers equipped with digital signal processors or sound cards. The sound card performs the functions of the modem and the CPU performs the processing of the digital bits. This approach is very common in amateur radio, using specialized computer programs like fldigi, MMTTY or MixW.

Before the computer mass storage era, most RTTY stations stored text on paper tape using paper tape punchers and readers. The operator would type the message on the TTY keyboard and punch the code onto the tape. The tape could then be transmitted at a steady, high rate, without typing errors. A tape could be reused, and in some cases - especially for use with ASCII on NC Machines - might be made of plastic or even very thin metal material in order to be reused many times.

The most common test signal is a series of "RYRYRY" characters, as these form an alternating tone pattern exercising all bits and are easily recognized. Pangrams are also transmitted on RTTY circuits as test messages, the most common one being "The quick brown fox jumps over the lazy dog", and in French circuits, "Voyez le brick gÃ©ant que j'examine prÃ¨s du wharf"

The original (or "Baudot") radioteletype system is based almost invariably on the Baudot code or ITA-2 5 bit alphabet. The link is based on character asynchronous transmission with 1 start bit and 1, 1.5 or 2 stop bits. Transmitter modulation is normally FSK (F1B). Occasionally, an AFSK signal modulating an RF carrier (A2B, F2B) is used on VHF or UHF frequencies. Standard transmission speeds are 45.45, 50, 75, 100, 150 and 300 baud.

Common carrier shifts are 85Â Hz (used on LF and VLF frequencies), 170Â Hz, 425Â Hz, 450Â Hz and 850Â Hz, although some stations use non-standard shifts. There are variations of the standard Baudot alphabet to cover languages written in Cyrillic, Arabic, Greek etc., using special techniques.

Some combinations of speed and shift are standardized for specific services using the original radioteletype system:


After World War II, amateur radio operators in the US started to receive obsolete but usable Teletype Model 26 equipment from commercial operators with the understanding that this equipment would not be used for or returned to commercial service. "The Amateur Radioteletype and VHF Society" was founded in 1946 in Woodside, NY. This organization soon changed its name to "The VHF Teletype Society" and started US Amateur Radio operations on 2 meters using audio frequency shift keying (AFSK). The first two-way amateur radioteletype QSO of record took place in May 1946 between Dave Winters, W2AUF, Brooklyn, NY and W2BFD, John Evans Williams, Woodside Long Island, NY. On the west coast, amateur RTTY also started on 2 meters. Operation on 80 meters, 40 meters and the other High Frequency (HF) amateur radio bands was initially accomplished using make and break keying since frequency shift keying (FSK) was not yet authorized. In early 1949, the first American transcontinental two-way RTTY QSO was accomplished on 11 meters using AFSK between Tom McMullen (W1QVF) operating at W1AW and Johnny Agalsoff, W6PSW. The stations effected partial contact on January 30, 1949, and repeated more successfully on January 31. On February 1, 1949, the stations exchanged solid print congratulatory message traffic and rag-chewed. Earlier, on January 23, 1949, William T. Knott, W2QGH, Larchmont, NY, had been able to make rough copy of W6PSW's test transmissions. While QSOs could be accomplished, it was quickly realized that FSK was technically superior to make and break keying. Due to the efforts of Merrill Swan, W6AEE, of "The RTTY Society of Southern California" publisher of "RTTY" and Wayne Green, W2NSD, of "CQ Magazine", Amateur Radio operators successfully petitioned the U.S. Federal Communications Commission (FCC) to amend Part 12 of the Regulations, which was effective on February 20, 1953. The amended Regulations permitted FSK in the non-voice parts of the 80, 40 and 20 meter bands and also specified the use of single channel 60 words-per-minute five unit code corresponding to ITA2. A shift of 850 hertz plus or minus 50 hertz was specified. Amateur Radio operators also had to identify their station callsign at the beginning and the end of each transmission and at ten-minute intervals using International Morse code. Use of this wide shift proved to be a problem for Amateur Radio operations. Commercial operators had already discovered that narrow shift worked best on the HF bands. After investigation and a petition to the FCC, Part 12 was amended, in March 1956, to allow Amateur Radio Operators to use any shift that was less than 900 hertz.

The FCC Notice of Proposed Rule Making (NPRM) that resulted in the authorization of Frequency Shift Keying (FSK) in the amateur high frequency (HF) bands responded to petitions by the American Radio Relay League (ARRL), the National Amateur Radio Council and Mr. Robert Weinstein. The NPRM specifically states this, and this information may be found in its entirety in the December 1951 Issue of QST. While the New RTTY Handbook gives ARRL no credit, it was published by CQ Magazine and its author was a CQ columnist (CQ generally opposed ARRL at that time).

The first RTTY Contest was held by the RTTY Society of Southern California from October 31 to November 1, 1953. Named the RTTY Sweepstakes Contest, twenty nine participants exchanged messages that contained a serial number, originating station call, check or RST report of two or three numbers, ARRL section of originator, local time (0000-2400 preferred) and date. Example: NR 23 W0BP CK MINN 1325 FEB 15. By the late 1950s, the contest exchange was expanded to include band used. Example: NR 23 W0BP CK MINN 1325 FEB 15 FORTY METERS. The contest was scored as follows: one point for each message sent and received entirely by RTTY and one point for each message received and acknowledged by RTTY. The final score was computed by multiplying the total number of message points by the number of ARRL sections worked. Two stations could exchange messages again on a different band for added points, but the section multiplier did not increase when the same section was reworked on a different band. Each DXCC entity was counted as an additional ARRL section for RTTY multiplier credit.

"RTTY", later named "RTTY Journal", also published the first listing of stations, mostly located in the continental US, that were interested in RTTY in 1956. Amateur Radio operators used this callbook information to contact other operators both inside and outside the United States. For example, the first recorded USA to New Zealand two-way RTTY QSO took place in 1956 between W0BP and ZL1WB.

By the late 1950s, new organizations focused on amateur radioteletype started to appear. The "British Amateur Radio Teletype Group", BARTG, now known as the "British Amateur Radio Teledata Group" was formed in June 1959. The Florida RTTY Society was formed in September 1959. Amateur Radio operators outside of Canada and the United States began to acquire surplus teleprinter and receive permission to get on the air. The first recorded RTTY QSO in the UK occurred in September 1959 between G2UK and G3CQE. A few weeks later, G3CQE had the first G/VE RTTY QSO with VE7KX. This was quickly followed up by G3CQE QSOs with VK3KF and ZL3HJ. Information on how to acquire surplus teleprinter equipment continued to spread and before long it was possible to work all continents on RTTY.

Amateur Radio operators used various equipment designs to get on the air using RTTY in the 1950s and 1960s. Amateurs used their existing receivers for RTTY operation but needed to add a terminal unit, sometimes called a demodulator, to convert the received audio signals to DC signals for the teleprinter.

Most of the terminal unit equipment used for receiving RTTY signals was homebuilt, using designs published in amateur radio publications. These original designs can be divided into two classes of terminal units: audio-type and intermediate frequency converters. The audio-type converters proved to be more popular with amateur radio operators. The Twin City, W2JAV and W2PAT designs were examples of typical terminal units that were used into the middle 1960s. The late 1960s and early 1970s saw the emergence of terminal units designed by W6FFC, such as the TT/L-2, ST-3, ST-5, and ST-6. These designs were first published in "RTTY Journal" starting in September 1967 and ending in 1970.

Amateur Radio operators needed to modify their transmitters to allow for HF RTTY operation. This was accomplished by adding a frequency shift keyer that used a diode to switch a capacitor in and out of the circuit, shifting the transmitterâs frequency in synchronism with the teleprinter signal changing from mark to space to mark. A very stable transmitter was required for RTTY. The typical frequency multiplication type transmitter that was popular in the 1950s and 1960s would be relatively stable on 80 meters but become progressively less stable on 40 meters, 20 meters and 15 meters. By the middle 1960s, transmitter designs were updated, mixing a crystal-controlled high frequency oscillator with a variable low frequency oscillator, resulting in better frequency stability across all Amateur Radio HF bands.

During the early days of Amateur RTTY, the Worked All Continents â RTTY Award was conceived by the RTTY Society of Southern California and issued by RTTY Journal. The first Amateur Radio station to achieve this WAC â RTTY Award was VE7KX. The first stations recognized as having achieved single band WAC RTTY were W1MX (3.5Â MHz); DL0TD (7.0Â MHz); K3SWZ (14.0Â MHz); W0MT (21.0Â MHz) and FG7XT (28.0Â MHz). The ARRL began issuing WAC RTTY certificates in 1969.

By the early 1970s, Amateur Radio RTTY had spread around the world and it was finally possible to work more than 100 countries via RTTY. FG7XT was the first Amateur Radio station to claim to achieve this honor. However, Jean did not submit his QSL cards for independent review. ON4BX, in 1971, was the first Amateur Radio station to submit his cards to the DX Editor of RTTY Journal and to achieve this honor. The ARRL began issuing DXCC RTTY Awards on November 1, 1976. Prior to that date, an award for working 100 countries on RTTY was only available via RTTY Journal.

In the 1950s through the 1970s, "RTTY art" was a popular on-air activity. This consisted of (sometimes very elaborate and artistic) pictures sent over rtty through the use of lengthy punched tape transmissions and then printed by the receiving station on paper.

On January 7, 1972, the FCC amended Part 97 to allow faster RTTY speeds. Four standard RTTY speeds were authorized, namely, 60 (45 baud), 67 (50 baud), 75 (56.25 baud) and 100 (75 baud) words per minute. Many Amateur Radio operators had equipment that was capable of being upgraded to 75 and 100 words per minute by changing teleprinter gears. While there was an initial interest in 100 words per minute operation, many Amateur Radio operators moved back to 60 words per minute. Some of the reasons for the failure of 100 words per minute HF RTTY included poor operation of improperly maintained mechanical teleprinters, narrow bandwidth terminal units, continued use of 170Â Hz shift at 100 words per minute and excessive error rates due to multipath distortion and the nature of ionospheric propagation.

The FCC approved the use of ASCII by Amateur Radio stations on March 17, 1980 with speeds up to 300 baud from 3.5 to 21.25Â MHz and 1200 baud between 28 and 225Â MHz. Speeds up to 19.2 kilobaud was authorized on Amateur frequencies above 420Â MHz.

The requirement for Amateur Radio operators in the United States to identify their station callsign at the beginning and the end of each digital transmission and at ten-minute intervals using International Morse code was finally lifted by the FCC on June 15, 1983.

RTTY has a typical baud rate for Amateur operation of 45.45 baud (approximately 60 words per minute). It remains popular as a "keyboard to keyboard" mode in Amateur Radio. RTTY has declined in commercial popularity as faster, more reliable alternative data modes have become available, using satellite or other connections.

For its transmission speed, RTTY has low spectral efficiency. The typical RTTY signal with 170Â Hz shift at 45.45 baud requires around 250Â Hz receiver bandwidth, more than double that required by PSK31. In theory, at this baud rate, the shift size can be decreased to 22.725Â Hz, reducing the overall band footprint substantially. Because RTTY, using either AFSK or FSK modulation, produces a waveform with constant power, a transmitter does not need to use a linear amplifier, which is required for many digital transmission modes. A more efficient Class C amplifier may be used.

RTTY, using either AFSK or FSK modulation, is moderately resistant to vagaries of HF propagation and interference, however modern digital modes, such as MFSK, use Forward Error Correction to provide much better data reliability.

Principally, the primary users are those who need robust shortwave communications. Examples are:

One regular service transmitting RTTY meteorological information is the German Meteorological Service (Deutscher Wetterdienst or DWD). The DWD regularly transmit two programs on various frequencies on LF and HF in standard RTTY (ITA-2 alphabet). The list of callsigns, frequencies, baudrates and shifts are as follows:

The DWD signals can be easily received in Europe, North Africa and parts of North America.

RTTY (in English) may be spoken as "radioteletype", by its letters: R-T-T-Y, or simply as "ritty".





</doc>
<doc id="26344" url="https://en.wikipedia.org/wiki?curid=26344" title="Register transfer language">
Register transfer language

In computer science, register transfer language (RTL) is a kind of intermediate representation (IR) that is very close to assembly language, such as that which is used in a compiler. It is used to describe data flow at the register-transfer level of an architecture. Academic papers and textbooks often use a form of RTL as an architecture-neutral assembly language. RTL is used as the name of a specific intermediate representation in several compilers, including the GNU Compiler Collection (GCC), Zephyr, and the European compiler projects CerCo and CompCert.

In GCC, RTL is generated from the GIMPLE representation, transformed by various passes in the GCC 'middle-end', and then converted to assembly language.

GCC's RTL is usually written in a form which looks like a Lisp S-expression:

This "side-effect expression" says "sum the contents of register 138 with the contents of register 139 and store the result in register 140". The SI specifies the access mode for each register. In the example it is "SImode", i.e. "access the register as 32-bit integer".

The sequence of RTL generated has some dependency on the characteristics of the processor for which GCC is generating code. However, the meaning of the RTL is more-or-less independent of the target: it would usually be possible to read and understand a piece of RTL without knowing what processor it was generated for. Similarly, the meaning of the RTL doesn't usually depend on the original high-level language of the program.

A register transfer language is a system for expressing in symbolic form the microoperation sequences among the registers of a digital module. It is a convenient tool for describing the internal organization of digital computers in concise and precise manner. It can also be used to facilitate the design process of digital systems.

The idea behind RTL was first described in:
Davidson and Fraser; The Design and Application of a Retargetable Peephole Optimizer; ToPLaS v2(2) 191-202 (April 1980)




</doc>
<doc id="26346" url="https://en.wikipedia.org/wiki?curid=26346" title="Remote procedure call">
Remote procedure call

In distributed computing, a remote procedure call (RPC) is when a computer program causes a procedure (subroutine) to execute in a different address space (commonly on another computer on a shared network), which is coded as if it were a normal (local) procedure call, without the programmer explicitly coding the details for the remote interaction. That is, the programmer writes essentially the same code whether the subroutine is local to the executing program, or remote. This is a form of clientâserver interaction (caller is client, executor is server), typically implemented via a requestâresponse message-passing system. In the object-oriented programming paradigm, RPC calls are represented by remote method invocation (RMI). The RPC model implies a level of location transparency, namely that calling procedures is largely the same whether it is local or remote, but usually they are not identical, so local calls can be distinguished from remote calls. Remote calls are usually orders of magnitude slower and less reliable than local calls, so distinguishing them is important.

RPCs are a form of inter-process communication (IPC), in that different processes have different address spaces: if on the same host machine, they have distinct virtual address spaces, even though the physical address space is the same; while if they are on different hosts, the physical address space is different. Many different (often incompatible) technologies have been used to implement the concept.

Requestâresponse protocols date to early distributed computing in the late 1960s, theoretical proposals of remote procedure calls as the model of network operations date to the 1970s, and practical implementations date to the early 1980s. Bruce Jay Nelson is generally credited with coining the term "remote procedure call" in 1981.

Remote procedure calls used in modern operating systems trace their roots back to the RC 4000 multiprogramming system, which used a request-response communication protocol for process synchronization. The idea of treating network operations as remote procedure calls goes back at least to the 1970s in early ARPANET documents. In 1978, Per Brinch Hansen proposed Distributed Processes, a language for distributed computing based on "external requests" consisting of procedure calls between processes.

One of the earliest practical implementations was in 1982 by Brian Randell and colleagues for their Newcastle Connection between UNIX machines. This was soon followed by "Lupine" by Andrew Birrell and Bruce Nelson in the Cedar environment at Xerox PARC. Lupine automatically generated stubs, providing type-safe bindings, and used an efficient protocol for communication. One of the first business uses of RPC was by Xerox under the name "Courier" in 1981. The first popular implementation of RPC on Unix was Sun's RPC (now called ONC RPC), used as the basis for Network File System (NFS).

In the 1990s, with the popularity of object-oriented programming, an alternative model of remote method invocation (RMI) was widely implemented, such as in Common Object Request Broker Architecture (CORBA, 1991) and Java remote method invocation. RMIs in turn fell in popularity with the rise of the internet, particularly in the 2000s.

RPC is a requestâresponse protocol. An RPC is initiated by the "client", which sends a request message to a known remote "server" to execute a specified procedure with supplied parameters. The remote server sends a response to the client, and the application continues its process. While the server is processing the call, the client is blocked (it waits until the server has finished processing before resuming execution), unless the client sends an asynchronous request to the server, such as an XMLHttpRequest. There are many variations and subtleties in various implementations, resulting in a variety of different (incompatible) RPC protocols.

An important difference between remote procedure calls and local calls is that remote calls can fail because of unpredictable network problems. Also, callers generally must deal with such failures without knowing whether the remote procedure was actually invoked. Idempotent procedures (those that have no additional effects if called more than once) are easily handled, but enough difficulties remain that code to call remote procedures is often confined to carefully written low-level subsystems.


To let different clients access servers, a number of standardized RPC systems have been created. Most of these use an interface description language (IDL) to let various platforms call the RPC. The IDL files can then be used to generate code to interface between the client and servers.

Notable RPC implementations and analogues include:







</doc>
<doc id="26347" url="https://en.wikipedia.org/wiki?curid=26347" title="Russian submarine Kursk (K-141)">
Russian submarine Kursk (K-141)

K-141 "Kursk" (, transl. , meaning "Nuclear-powered submarine "Kursk"") was an Oscar II-class nuclear-powered cruise missile submarine of the Russian Navy.

On 12 August 2000, K-141 "Kursk" was lost when it sank in the Barents Sea, killing all 118 personnel on board.

K-141 "Kursk" was a Project 949A class "Antey" () submarine of the Oscar class, known as the Oscar II by its NATO reporting name, and was the penultimate submarine of the Oscar II class designed and approved in the Soviet Union. Construction began in 1990 at the Soviet Navy military shipyards in Severodvinsk, near Arkhangelsk, in the northern Russian SFSR. During the construction of K-141, the Soviet Union collapsed; work continued, and she became one of the first naval vessels completed after the collapse. K-141 was inherited by Russia and launched in 1994, before being commissioned by the Russian Navy on December 30, as part of the Russian Northern Fleet. K-141 was named "Kursk" after the city, following the naming system for Soviet submarines.

"Kursk" was assigned to the home port of Vidyayevo, Murmansk Oblast.

The Antey design represented the highest achievement of Soviet nuclear submarine technology. They are the second-largest cruise missile submarines ever built, after some ballistic missile submarines were converted to carry cruise missiles in 2007. It was built to defeat an entire United States aircraft carrier group. A single Type 65 torpedo carried a warhead powerful enough to sink an aircraft carrier. Both missiles and torpedoes could be equipped with nuclear warheads. She was longer than the preceding Oscar I-class of submarines. The senior officers had individual staterooms and the entire crew had access to a gymnasium.

The outer hull, made of high-nickel, high-chromium stainless steel thick, had exceptionally good resistance to corrosion and a weak magnetic signature which helped prevent detection by U.S. magnetic anomaly detector (MAD) systems. There was a gap to the -thick steel pressure hull. She was designed to remain submerged for up to 120 days. The sail superstructure was reinforced to allow it to break through the Arctic ice.
The submarine was armed with 24 SS-N-19/P-700 Granit cruise missiles, and eight torpedo tubes in the bow: four and four . The Granit missiles with a range of , were capable of supersonic flight at altitudes over . They were designed to swarm enemy vessels and intelligently choose individual targets which terminated with a dive onto the target. The torpedo tubes could be used to launch either torpedoes or anti-ship missiles with a range of . Her weapons included 18 SS-N-16 "Stallion" anti-submarine missiles.

"Kursk" was part of Russia's Northern Fleet, which had suffered funding cutbacks throughout the 1990s. Many of its submarines were anchored and rusting in Zapadnaya Litsa Naval Base, from Murmansk. Little work to maintain all but the most essential front-line equipment, including search and rescue equipment, had occurred. Northern Fleet sailors had gone unpaid in the mid-1990s.

During her five years of service, "Kursk" completed only one mission, a six-month deployment to the Mediterranean Sea during the summer of 1999 to monitor the United States Sixth Fleet responding to the Kosovo crisis. This was due to a lack of funds for fuel. As a result, many of her crew had spent little time at sea and were inexperienced.

"Kursk" joined the "Summer-X" exercise, the first large-scale naval exercise planned by the Russian Navy in more than a decade, on 10 August 2000. It included 30 ships including the fleet's flagship "Pyotr Velikiy" ("Peter the Great"), four attack submarines, and a flotilla of smaller ships. The crew had recently won a citation for its excellent performance and been recognized as the best submarine crew in the Northern Fleet. While it was on an exercise, "Kursk" loaded a full complement of combat weapons. It was one of the few ships authorized to carry a combat load at all times.

On the first day of the exercise, "Kursk" successfully launched a Granit missile armed with a dummy warhead. Two days later, on the morning of 12 August, "Kursk" prepared to fire dummy torpedoes at the ("Peter The Great"). These practice torpedoes had no explosive warheads and were manufactured and tested at a much lower quality standard. On 12 August 2000, at 11:28 local time (07:28 UTC), there was an explosion while preparing to fire. The Russian Navy's final report on the disaster concluded the explosion was due to the failure of one of "Kursk"'s hydrogen peroxide-fueled Type 65 torpedoes. A subsequent investigation concluded that high-test peroxide (HTP), a form of highly concentrated hydrogen peroxide used as propellant for the torpedo, seeped through a faulty weld in the torpedo casing. When HTP comes into contact with a catalyst, it rapidly expands by a factor of 5000, generating vast quantities of steam and oxygen. The pressure produced by the expanding HTP ruptured the kerosene fuel tank in the torpedo and set off an explosion equal to of TNT. The submarine sank in relatively shallow water, bottoming at about off Severomorsk, at . A second explosion 135 seconds after the initial event was equivalent to 3-7 tons of TNT. The explosions blew a large hole in the hull and caused the first three compartments of the submarine to collapse, killing or incapacitating all but 23 of the 118 personnel on board.

The British and Norwegian navies offered assistance, but Russia initially refused all help. All 118 sailors and officers aboard "Kursk" died. The Russian Admiralty initially told the public that the majority of the crew died within minutes of the explosion, but on 21 August, Norwegian and Russian divers found 24 bodies in the ninth compartment, the turbine room at the stern of the boat. Captain-lieutenant Dmitri Kolesnikov wrote a note listing the names of 23 sailors who were alive in the compartment after the ship sank.

"Kursk" carried a potassium superoxide cartridge of a chemical oxygen generator; these are used to absorb carbon dioxide and chemically release oxygen during an emergency. However, the cartridge became contaminated with sea water and the resulting chemical reaction caused a flash fire which consumed the available oxygen. The investigation showed that some men temporarily survived the fire by plunging under water, as fire marks on the bulkheads indicated the water was at waist level at the time. Ultimately, the remaining crew burned to death or suffocated.

Russian President Vladimir Putin, though immediately informed of the tragedy, was told by the navy that they had the situation under control and that rescue was imminent. He waited for five days before he ended his holiday at a presidential resort in Sochi on the Black Sea. Putin was only four months into his tenure as President, and the public and media were extremely critical of his decision to remain at a seaside resort. His highly favourable ratings dropped dramatically. The President's response appeared callous and the government's actions looked incompetent. A year later he said, "I probably should have returned to Moscow, but nothing would have changed. I had the same level of communication both in Sochi and in Moscow, but from a PR point of view I could have demonstrated some special eagerness to return."

A consortium formed by the Dutch companies Mammoet and Smit International was awarded a contract by Russia to raise the vessel, excluding the bow. They modified the barge "Giant 4" which raised "Kursk" and recovered the remains of the sailors.

During salvage operations in 2001, the team first cut the bow off the hull using a tungsten carbide-studded cable. As this tool had the potential to cause sparks which could ignite remaining pockets of reactive gases, such as hydrogen, the operation was executed with care. Most of the bow was abandoned and the rest of the vessel was towed to Severomorsk and placed in a floating dry dock for analysis.

The remains of "Kursk"s reactor compartment were towed to Sayda Bay on Russia's northern Kola Peninsula, where more than 50 reactor compartments were afloat at pier points, after a shipyard had removed all the fuel from the boat in early 2003.

Some torpedo and torpedo tube fragments from the bow were recovered and the rest was destroyed by explosives in 2002.

Notwithstanding the navy's oft-stated position that a collision with a foreign vessel had triggered the event, a report issued by the government attributed the disaster to a torpedo explosion caused when high-test peroxide (HTP), a form of highly concentrated hydrogen peroxide, leaked from a faulty weld in the torpedo's casing. The report found that the initial explosion destroyed the torpedo room compartment and killed everyone in the first compartment. The blast entered the second and perhaps the third and fourth compartments through an air conditioning vent. All of the 36 men in the command post located in the second compartment were immediately incapacitated by the blast wave and possibly killed. The first explosion caused a fire that raised the temperature of the compartment to more than . The heat caused the warheads of between five and seven additional torpedoes to detonate, creating an explosion equivalent to 2â3 tons of TNT that measured 4.2 on the Richter magnitude scale on seismographs across Europe and was detected as far away as Alaska.

Vice-Admiral Valery Ryazantsev differed with the government's official conclusion. He cited inadequate training, poor maintenance, and incomplete inspections that caused the crew to mishandle the weapon. During the examination of the wrecked sub, investigators recovered a partially burned copy of the safety instructions for loading HTP torpedoes, but the instructions were for a significantly different type of torpedo and failed to include essential steps for testing an air valve. The 7th Division, 1st Submarine Flotilla never inspected "Kursk"s crew's qualifications and readiness to fire HTP torpedoes. "Kursk"s crew had no prior experience with HTP-powered torpedoes and had not been trained in handling or firing HTP-powered torpedoes. Due to their inexperience and lack of training, compounded by incomplete inspections and oversight, and because the "Kursk"s crew followed faulty instructions when loading the practice torpedo, Ryazantsev believes they set off a chain of events that led to the explosion.








</doc>
<doc id="26350" url="https://en.wikipedia.org/wiki?curid=26350" title="Radiation therapy">
Radiation therapy

Radiation therapy or radiotherapy, often abbreviated RT, RTx, or XRT, is a therapy using ionizing radiation, generally as part of cancer treatment to control or kill malignant cells and normally delivered by a linear accelerator. Radiation therapy may be curative in a number of types of cancer if they are localized to one area of the body. It may also be used as part of adjuvant therapy, to prevent tumor recurrence after surgery to remove a primary malignant tumor (for example, early stages of breast cancer). Radiation therapy is synergistic with chemotherapy, and has been used before, during, and after chemotherapy in susceptible cancers. The subspecialty of oncology concerned with radiotherapy is called radiation oncology.

Radiation therapy is commonly applied to the cancerous tumor because of its ability to control cell growth. Ionizing radiation works by damaging the DNA of cancerous tissue leading to cellular death. To spare normal tissues (such as skin or organs which radiation must pass through to treat the tumor), shaped radiation beams are aimed from several angles of exposure to intersect at the tumor, providing a much larger absorbed dose there than in the surrounding, healthy tissue. Besides the tumour itself, the radiation fields may also include the draining lymph nodes if they are clinically or radiologically involved with tumor, or if there is thought to be a risk of subclinical malignant spread. It is necessary to include a margin of normal tissue around the tumor to allow for uncertainties in daily set-up and internal tumor motion. These uncertainties can be caused by internal movement (for example, respiration and bladder filling) and movement of external skin marks relative to the tumor position.

Radiation oncology is the medical specialty concerned with prescribing radiation, and is distinct from radiology, the use of radiation in medical imaging and diagnosis. Radiation may be prescribed by a radiation oncologist with intent to cure ("curative") or for adjuvant therapy. It may also be used as palliative treatment (where cure is not possible and the aim is for local disease control or symptomatic relief) or as therapeutic treatment (where the therapy has survival benefit and it can be curative). It is also common to combine radiation therapy with surgery, chemotherapy, hormone therapy, immunotherapy or some mixture of the four. Most common cancer types can be treated with radiation therapy in some way.

The precise treatment intent (curative, adjuvant, neoadjuvant therapeutic, or palliative) will depend on the tumor type, location, and stage, as well as the general health of the patient. Total body irradiation (TBI) is a radiation therapy technique used to prepare the body to receive a bone marrow transplant. Brachytherapy, in which a radioactive source is placed inside or next to the area requiring treatment, is another form of radiation therapy that minimizes exposure to healthy tissue during procedures to treat cancers of the breast, prostate and other organs. Radiation therapy has several applications in non-malignant conditions, such as the treatment of trigeminal neuralgia, acoustic neuromas, severe thyroid eye disease, pterygium, pigmented villonodular synovitis, and prevention of keloid scar growth, vascular restenosis, and heterotopic ossification. The use of radiation therapy in non-malignant conditions is limited partly by worries about the risk of radiation-induced cancers.

Different cancers respond to radiation therapy in different ways.

The response of a cancer to radiation is described by its radiosensitivity.
Highly radiosensitive cancer cells are rapidly killed by modest doses of radiation. These include leukemias, most lymphomas and germ cell tumors.
The majority of epithelial cancers are only moderately radiosensitive, and require a significantly higher dose of radiation (60-70Â Gy) to achieve a radical cure.
Some types of cancer are notably radioresistant, that is, much higher doses are required to produce a radical cure than may be safe in clinical practice. Renal cell cancer and melanoma are generally considered to be radioresistant but radiation therapy is still a palliative option for many patients with metastatic melanoma. Combining radiation therapy with immunotherapy is an active area of investigation and has shown some promise for melanoma and other cancers.

It is important to distinguish the radiosensitivity of a particular tumor, which to some extent is a laboratory measure, from the radiation "curability" of a cancer in actual clinical practice. For example, leukemias are not generally curable with radiation therapy, because they are disseminated through the body. Lymphoma may be radically curable if it is localised to one area of the body. Similarly, many of the common, moderately radioresponsive tumors are routinely treated with curative doses of radiation therapy if they are at an early stage. For example: non-melanoma skin cancer, head and neck cancer, breast cancer, non-small cell lung cancer, cervical cancer, anal cancer, and prostate cancer. Metastatic cancers are generally incurable with radiation therapy because it is not possible to treat the whole body.

Before treatment, a CT scan is often performed to identify the tumor and surrounding normal structures. The patient receives small skin marks to guide the placement of treatment fields. Patient positioning is crucial at this stage as the patient will have to be set-up in the identical position during treatment. Many patient positioning devices have been developed for this purpose, including masks and cushions which can be molded to the patient.

The response of a tumor to radiation therapy is also related to its size. Due to complex radiobiology, very large tumors respond less well to radiation than smaller tumors or microscopic disease. Various strategies are used to overcome this effect. The most common technique is surgical resection prior to radiation therapy. This is most commonly seen in the treatment of breast cancer with wide local excision or mastectomy followed by adjuvant radiation therapy. Another method is to shrink the tumor with neoadjuvant chemotherapy prior to radical radiation therapy. A third technique is to enhance the radiosensitivity of the cancer by giving certain drugs during a course of radiation therapy. Examples of radiosensitizing drugs include: Cisplatin, Nimorazole, and Cetuximab.

The impact of radiotherapy varies between different types of cancer and different groups. For example, for breast cancer after breast-conserving surgery, radiotherapy has been found to halve the rate at which the disease recurs.

Radiation therapy is in itself painless. Many low-dose palliative treatments (for example, radiation therapy to bony metastases) cause minimal or no side effects, although short-term pain flare-up can be experienced in the days following treatment due to oedema compressing nerves in the treated area. Higher doses can cause varying side effects during treatment (acute side effects), in the months or years following treatment (long-term side effects), or after re-treatment (cumulative side effects). The nature, severity, and longevity of side effects depends on the organs that receive the radiation, the treatment itself (type of radiation, dose, fractionation, concurrent chemotherapy), and the patient.

Most side effects are predictable and expected. Side effects from radiation are usually limited to the area of the patient's body that is under treatment. Side effects are dose- dependent; for example higher doses of head and neck radiation can be associated with cardiovascular complications, thyroid dysfunction, and pituitary axis dysfunction. Modern radiation therapy aims to reduce side effects to a minimum and to help the patient understand and deal with side effects that are unavoidable.

The main side effects reported are fatigue and skin irritation, like a mild to moderate sun burn. The fatigue often sets in during the middle of a course of treatment and can last for weeks after treatment ends. The irritated skin will heal, but may not be as elastic as it was before.


Late side effects occur months to years after treatment and are generally limited to the area that has been treated. They are often due to damage of blood vessels and connective tissue cells. Many late effects are reduced by fractionating treatment into smaller parts.


Cumulative effects from this process should not be confused with long-term effectsâwhen short-term effects have disappeared and long-term effects are subclinical, reirradiation can still be problematic. These doses are calculated by the radiation oncologist and many factors are taken into account before the subsequent radiation takes place.

During the first two weeks after fertilization, radiation therapy is lethal but not teratogenic. High doses of radiation during pregnancy induce anomalies, impaired growth and intellectual disability, and there may be an increased risk of childhood leukemia and other tumours in the offspring.

In males previously having undergone radiotherapy, there appears to be no increase in genetic defects or congenital malformations in their children conceived after therapy. However, the use of assisted reproductive technologies and micromanipulation techniques might increase this risk.

Hypopituitarism commonly develops after radiation therapy for sellar and parasellar neoplasms, extrasellar brain tumours, head and neck tumours, and following whole body irradiation for systemic malignancies. Radiation-induced hypopituitarism mainly affects growth hormone and gonadal hormones. In contrast, adrenocorticotrophic hormone (ACTH) and thyroid stimulating hormone (TSH) deficiencies are the least common among people with radiation-induced hypopituitarism. Changes in prolactin-secretion is usually mild, and vasopressin deficiency appears to be very rare as a consequence of radiation.

There are rigorous procedures in place to minimise the risk of accidental overexposure of radiation therapy to patients. However, mistakes do occasionally occur; for example, the radiation therapy machine Therac-25 was responsible for at least six accidents between 1985 and 1987, where patients were given up to one hundred times the intended dose; two people were killed directly by the radiation overdoses. From 2005 to 2010, a hospital in Missouri overexposed 76 patients (most with brain cancer) during a five-year period because new radiation equipment had been set up incorrectly.

Although medical errors are exceptionally rare, radiation oncologists, medical physicists and other members of the radiation therapy treatment team are working to eliminate them. ASTRO has launched a safety initiative called Target Safely that, among other things, aims to record errors nationwide so that doctors can learn from each and every mistake and prevent them from happening. ASTRO also publishes a list of questions for patients to ask their doctors about radiation safety to ensure every treatment is as safe as possible.

Radiation therapy is used to treat early stage Dupuytren's disease and Ledderhose disease. When Dupuytren's disease is at the nodules and cords stage or fingers are at a minimal deformation stage of less than 10 degrees, then radiation therapy is used to prevent further progress of the disease. Radiation therapy is also used post surgery in some cases to prevent the disease continuing to progress. Low doses of radiation are used typically three gray of radiation for five days, with a break of three months followed by another phase of three gray of radiation for five days.

Radiation therapy works by damaging the DNA of cancerous cells. This DNA damage is caused by one of two types of energy, photon or charged particle. This damage is either direct or indirect ionization of the atoms which make up the DNA chain. Indirect ionization happens as a result of the ionization of water, forming free radicals, notably hydroxyl radicals, which then damage the DNA.

In photon therapy, most of the radiation effect is through free radicals. Cells have mechanisms for repairing single-strand DNA damage and double-stranded DNA damage. However, double-stranded DNA breaks are much more difficult to repair, and can lead to dramatic chromosomal abnormalities and genetic deletions. Targeting double-stranded breaks increases the probability that cells will undergo cell death. Cancer cells are generally less differentiated and more stem cell-like; they reproduce more than most healthy differentiated cells, and have a diminished ability to repair sub-lethal damage. Single-strand DNA damage is then passed on through cell division; damage to the cancer cells' DNA accumulates, causing them to die or reproduce more slowly.

One of the major limitations of photon radiation therapy is that the cells of solid tumors become deficient in oxygen. Solid tumors can outgrow their blood supply, causing a low-oxygen state known as hypoxia. Oxygen is a potent radiosensitizer, increasing the effectiveness of a given dose of radiation by forming DNA-damaging free radicals. Tumor cells in a hypoxic environment may be as much as 2 to 3 times more resistant to radiation damage than those in a normal oxygen environment.
Much research has been devoted to overcoming hypoxia including the use of high pressure oxygen tanks, hyperthermia therapy (heat therapy which dilates blood vessels to the tumor site), blood substitutes that carry increased oxygen, hypoxic cell radiosensitizer drugs such as misonidazole and metronidazole, and hypoxic cytotoxins (tissue poisons), such as tirapazamine. Newer research approaches are currently being studied, including preclinical and clinical investigations into the use of an oxygen diffusion-enhancing compound such as trans sodium crocetinate (TSC) as a radiosensitizer.

Charged particles such as protons and boron, carbon, and neon ions can cause direct damage to cancer cell DNA through high-LET (linear energy transfer) and have an antitumor effect independent of tumor oxygen supply because these particles act mostly via direct energy transfer usually causing double-stranded DNA breaks. Due to their relatively large mass, protons and other charged particles have little lateral side scatter in the tissueâthe beam does not broaden much, stays focused on the tumor shape, and delivers small dose side-effects to surrounding tissue. They also more precisely target the tumor using the Bragg peak effect. See proton therapy for a good example of the different effects of intensity-modulated radiation therapy (IMRT) vs. charged particle therapy. This procedure reduces damage to healthy tissue between the charged particle radiation source and the tumor and sets a finite range for tissue damage after the tumor has been reached. In contrast, IMRT's use of uncharged particles causes its energy to damage healthy cells when it exits the body. This exiting damage is not therapeutic, can increase treatment side effects, and increases the probability of secondary cancer induction. This difference is very important in cases where the close proximity of other organs makes any stray ionization very damaging (example: head and neck cancers).
This x-ray exposure is especially bad for children, due to their growing bodies, and they have a 30% chance of a second malignancy after 5 years post initial RT.

The amount of radiation used in photon radiation therapy is measured in grays (Gy), and varies depending on the type and stage of cancer being treated. For curative cases, the typical dose for a solid epithelial tumor ranges from 60 to 80Â Gy, while lymphomas are treated with 20 to 40Â Gy.

Preventive (adjuvant) doses are typically around 45â60Â Gy in 1.8â2Â Gy fractions (for breast, head, and neck cancers.) Many other factors are considered by radiation oncologists when selecting a dose, including whether the patient is receiving chemotherapy, patient comorbidities, whether radiation therapy is being administered before or after surgery, and the degree of success of surgery.

Delivery parameters of a prescribed dose are determined during treatment planning (part of dosimetry). Treatment planning is generally performed on dedicated computers using specialized treatment planning software. Depending on the radiation delivery method, several angles or sources may be used to sum to the total necessary dose. The planner will try to design a plan that delivers a uniform prescription dose to the tumor and minimizes dose to surrounding healthy tissues.

In radiation therapy, three-dimensional dose distributions may be evaluated using the dosimetry technique known as gel dosimetry.


The total dose is fractionated (spread out over time) for several important reasons. Fractionation allows normal cells time to recover, while tumor cells are generally less efficient in repair between fractions. Fractionation also allows tumor cells that were in a relatively radio-resistant phase of the cell cycle during one treatment to cycle into a sensitive phase of the cycle before the next fraction is given. Similarly, tumor cells that were chronically or acutely hypoxic (and therefore more radioresistant) may reoxygenate between fractions, improving the tumor cell kill.

Fractionation regimens are individualised between different radiation therapy centers and even between individual doctors. In North America, Australia, and Europe, the typical fractionation schedule for adults is 1.8 to 2Â Gy per day, five days a week. In some cancer types, prolongation of the fraction schedule over too long can allow for the tumor to begin repopulating, and for these tumor types, including head-and-neck and cervical squamous cell cancers, radiation treatment is preferably completed within a certain amount of time. For children, a typical fraction size may be 1.5 to 1.8Â Gy per day, as smaller fraction sizes are associated with reduced incidence and severity of late-onset side effects in normal tissues.

In some cases, two fractions per day are used near the end of a course of treatment. This schedule, known as a concomitant boost regimen or hyperfractionation, is used on tumors that regenerate more quickly when they are smaller. In particular, tumors in the head-and-neck demonstrate this behavior.

Patients receiving palliative radiation to treat uncomplicated painful bone metastasis should not receive more than a single fraction of radiation. A single treatment gives comparable pain relief and morbidity outcomes to multiple-fraction treatments, and for patients with limited life expectancy, a single treatment is best to improve patient comfort.

One fractionation schedule that is increasingly being used and continues to be studied is hypofractionation. This is a radiation treatment in which the total dose of radiation is divided into large doses. Typical doses vary significantly by cancer type, from 2.2Â Gy/fraction to 20Â Gy/fraction, the latter being typical of stereotactic treatments (stereotactic ablative body radiotherapy, or SABR â also known as SBRT, or stereotactic body radiotherapy) for subcranial lesions, or SRS (stereotactic radiosurgery) for intracranial lesions. The rationale of hypofractionation is to reduce the probability of local recurrence by denying clonogenic cells the time they require to reproduce and also to exploit the radiosensitivity of some tumors. In particular, stereotactic treatments are intended to destroy clonogenic cells by a process of ablation â "i.e." the delivery of a dose intended to destroy clonogenic cells directly, rather than to interrupt the process of clonogenic cell division repeatedly (apoptosis), as in routine radiotherapy.

Different cancer types have different radiation sensitivity. However, predicting the sensitivity based on genomic or proteomic analyses of biopsy samples has proved difficult. An alternative approach to genomics and proteomics was offered by the discovery that radiation protection in microbes is offered by non-enzymatic complexes of manganese and small organic metabolites. The content and variation of manganese (measurable by electron paramagnetic resonance) were found to be good predictors of radiosensitivity, and this finding extends also to human cells. An association was confirmed between total cellular manganese contents and their variation, and clinically-inferred radioresponsiveness in different tumor cells, a finding that may be useful for more precise radiodosages and improved treatment of cancer patients.

Historically, the three main divisions of radiation therapy are :
The differences relate to the position of the radiation source; external is outside the body, brachytherapy uses sealed radioactive sources placed precisely in the area under treatment, and systemic radioisotopes are given by infusion or oral ingestion. Brachytherapy can use temporary or permanent placement of radioactive sources. The temporary sources are usually placed by a technique called afterloading. In afterloading a hollow tube or applicator is placed surgically in the organ to be treated, and the sources are loaded into the applicator after the applicator is implanted. This minimizes radiation exposure to health care personnel.

Particle therapy is a special case of external beam radiation therapy where the particles are protons or heavier ions.

The following three sections refer to treatment using x-rays.

Historically conventional external beam radiation therapy (2DXRT) was delivered via two-dimensional beams using kilovoltage therapy x-ray units or medical linear accelerators which generate high energy x-rays. 2DXRT mainly consists of a single beam of radiation delivered to the patient from several directions: often front or back, and both sides.

"Conventional" refers to the way the treatment is "planned" or "simulated" on a specially calibrated diagnostic x-ray machine known as a simulator because it recreates the linear accelerator actions (or sometimes by eye), and to the usually well-established arrangements of the radiation beams to achieve a desired "plan". The aim of simulation is to accurately target or localize the volume which is to be treated. This technique is well established and is generally quick and reliable. The worry is that some high-dose treatments may be limited by the radiation toxicity capacity of healthy tissues which lie close to the target tumor volume.

An example of this problem is seen in radiation of the prostate gland, where the sensitivity of the adjacent rectum limited the dose which could be safely prescribed using 2DXRT planning to such an extent that tumor control may not be easily achievable. Prior to the invention of the CT, physicians and physicists had limited knowledge about the true radiation dosage delivered to both cancerous and healthy tissue. For this reason, 3-dimensional conformal radiation therapy has become the standard treatment for almost all tumor sites. More recently other forms of imaging are used including MRI, PET, SPECT and Ultrasound.

Stereotactic radiation is a specialized type of external beam radiation therapy. It uses focused radiation beams targeting a well-defined tumor using extremely detailed imaging scans. Radiation oncologists perform stereotactic treatments, often with the help of a neurosurgeon for tumors in the brain or spine.

There are two types of stereotactic radiation. Stereotactic radiosurgery (SRS) is when doctors use a single or several stereotactic radiation treatments of the brain or spine. Stereotactic body radiation therapy (SBRT) refers to one or several stereotactic radiation treatments with the body, such as the lungs.

Some doctors say an advantage to stereotactic treatments is that they deliver the right amount of radiation to the cancer in a shorter amount of time than traditional treatments, which can often take 6 to 11 weeks. Plus treatments are given with extreme accuracy, which should limit the effect of the radiation on healthy tissues. One problem with stereotactic treatments is that they are only suitable for certain small tumors.

Stereotactic treatments can be confusing because many hospitals call the treatments by the name of the manufacturer rather than calling it SRS or SBRT. Brand names for these treatments include Axesse, Cyberknife, Gamma Knife, Novalis, Primatom, Synergy, X-Knife, TomoTherapy, Trilogy and Truebeam. This list changes as equipment manufacturers continue to develop new, specialized technologies to treat cancers.

The planning of radiation therapy treatment has been revolutionized by the ability to delineate tumors and adjacent normal structures in three dimensions using specialized CT and/or MRI scanners and planning software.

Virtual simulation, the most basic form of planning, allows more accurate placement of radiation beams than is possible using conventional X-rays, where soft-tissue structures are often difficult to assess and normal tissues difficult to protect.

An enhancement of virtual simulation is 3-dimensional conformal radiation therapy (3DCRT), in which the profile of each radiation beam is shaped to fit the profile of the target from a beam's eye view (BEV) using a multileaf collimator (MLC) and a variable number of beams. When the treatment volume conforms to the shape of the tumor, the relative toxicity of radiation to the surrounding normal tissues is reduced, allowing a higher dose of radiation to be delivered to the tumor than conventional techniques would allow.

Intensity-modulated radiation therapy (IMRT) is an advanced type of high-precision radiation that is the next generation of 3DCRT. IMRT also improves the ability to conform the treatment volume to concave tumor shapes, for example when the tumor is wrapped around a vulnerable structure such as the spinal cord or a major organ or blood vessel. Computer-controlled x-ray accelerators distribute precise radiation doses to malignant tumors or specific areas within the tumor. The pattern of radiation delivery is determined using highly tailored computing applications to perform optimization and treatment simulation (Treatment Planning). The radiation dose is consistent with the 3-D shape of the tumor by controlling, or modulating, the radiation beam's intensity. The radiation dose intensity is elevated near the gross tumor volume while radiation among the neighboring normal tissues is decreased or avoided completely. This results in better tumor targeting, lessened side effects, and improved treatment outcomes than even 3DCRT.

3DCRT is still used extensively for many body sites but the use of IMRT is growing in more complicated body sites such as CNS, head and neck, prostate, breast, and lung. Unfortunately, IMRT is limited by its need for additional time from experienced medical personnel. This is because physicians must manually delineate the tumors one CT image at a time through the entire disease site which can take much longer than 3DCRT preparation. Then, medical physicists and dosimetrists must be engaged to create a viable treatment plan. Also, the IMRT technology has only been used commercially since the late 1990s even at the most advanced cancer centers, so radiation oncologists who did not learn it as part of their residency programs must find additional sources of education before implementing IMRT.

Proof of improved survival benefit from either of these two techniques over conventional radiation therapy (2DXRT) is growing for many tumor sites, but the ability to reduce toxicity is generally accepted. This is particularly the case for head and neck cancers in a series of pivotal trials performed by Professor Christopher Nutting of the Royal Marsden Hospital. Both techniques enable dose escalation, potentially increasing usefulness. There has been some concern, particularly with IMRT, about increased exposure of normal tissue to radiation and the consequent potential for secondary malignancy. Overconfidence in the accuracy of imaging may increase the chance of missing lesions that are invisible on the planning scans (and therefore not included in the treatment plan) or that move between or during a treatment (for example, due to respiration or inadequate patient immobilization). New techniques are being developed to better control this uncertaintyâfor example, real-time imaging combined with real-time adjustment of the therapeutic beams. This new technology is called image-guided radiation therapy (IGRT) or four-dimensional radiation therapy.

Another technique is the real-time tracking and localization of one or more small implantable electric devices implanted inside or close to the tumor. There are various types of medical implantable devices that are used for this purpose. It can be a magnetic transponder which senses the magnetic field generated by several transmitting coils, and then transmits the measurements back to the positioning system to determine the location. The implantable device can also be a small wireless transmitter sending out an RF signal which then will be received by a sensor array and used for localization and real-time tracking of the tumor position.

A well-studied issue with IRMT is the "tongue and groove effect" which results in unwanted underdosing, due to irradiating through extended tongues and grooves of overlapping MLC (multileaf collimator) leaves. While solutions to this issue have been developed, which either reduce the TG effect to negligible amounts or remove it completely, they depend upon the method of IMRT being used and some of them carry costs of their own. Some texts distinguish "tongue and groove error" from "tongue or groove error", according as both or one side of the aperture is occluded.

Volumetric modulated arc therapy (VMAT) is a radiation technique introduced in 2007 which can achieve highly conformal dose distributions on target volume coverage and sparing of normal tissues. The specificity of this technique is to modify three parameters during the treatment. VMAT delivers radiation by rotating gantry (usually 360Â° rotating fields with one or more arcs), changing speed and shape of the beam with a multileaf collimator (MLC) ("sliding window" system of moving) and fluence output rate (dose rate) of the medical linear accelerator. VMAT has an advantage in patient treatment, compared with conventional static field intensity modulated radiotherapy (IMRT), of reduced radiation delivery times. Comparisons between VMAT and conventional IMRT for their sparing of healthy tissues and Organs at Risk (OAR) depends upon the cancer type. In the treatment of nasopharyngeal, oropharyngeal and hypopharyngeal carcinomas VMAT provides equivalent or better OAR protection. In the treatment of prostate cancer the OAR protection result is mixed with some studies favoring VMAT, others favoring IMRT.

Automated treatment planning has become an integrated part of radiotherapy treatment planning. There are in general two approaches of automated planning. 1) Knowledge based planning where the treatment planning system has a library of high quality plans, from which it can predict the target and OAR DVH. 2) The other approach is commonly called protocol based planning, where the treatment planning system tried to mimic an experienced treatment planner and through an iterative process evaluates the plan quality from on the basis of the protocol. 

In particle therapy (proton therapy being one example), energetic ionizing particles (protons or carbon ions) are directed at the target tumor. The dose increases while the particle penetrates the tissue, up to a maximum (the Bragg peak) that occurs near the end of the particle's range, and it then drops to (almost) zero. The advantage of this energy deposition profile is that less energy is deposited into the healthy tissue surrounding the target tissue.

Auger therapy (AT) makes use of a very high dose of ionizing radiation in situ that provides molecular modifications at an atomic scale. AT differs from conventional radiation therapy in several aspects; it neither relies upon radioactive nuclei to cause cellular radiation damage at a cellular dimension, nor engages multiple external pencil-beams from different directions to zero-in to deliver a dose to the targeted area with reduced dose outside the targeted tissue/organ locations. Instead, the in situ delivery of a very high dose at the molecular level using AT aims for in situ molecular modifications involving molecular breakages and molecular re-arrangements such as a change of stacking structures as well as cellular metabolic functions related to the said molecule structures.

Contact x-ray brachytherapy (also called "CXB", "electronic brachytherapy" or the "Papillon Technique") is a type of radiation therapy using kilovoltage X-rays applied close to the tumour to treat rectal cancer. The process involves inserting the x-ray tube through the anus into the rectum and placing it against the cancerous tissue, then high doses of X-rays are emitted directly into the tumor at two weekly intervals. It is typically used for treating early rectal cancer in patients who may not be candidates for surgery. A 2015 NICE review found the main side effect to be bleeding that occurred in about 38% of cases, and radiation-induced ulcer which occurred in 27% of cases.

Brachytherapy is delivered by placing radiation source(s) inside or next to the area requiring treatment. Brachytherapy is commonly used as an effective treatment for cervical, prostate, breast, and skin cancer and can also be used to treat tumours in many other body sites.

In brachytherapy, radiation sources are precisely placed directly at the site of the cancerous tumour. This means that the irradiation only affects a very localized area â exposure to radiation of healthy tissues further away from the sources is reduced. These characteristics of brachytherapy provide advantages over external beam radiation therapy â the tumour can be treated with very high doses of localized radiation, whilst reducing the probability of unnecessary damage to surrounding healthy tissues. A course of brachytherapy can often be completed in less time than other radiation therapy techniques. This can help reduce the chance of surviving cancer cells dividing and growing in the intervals between each radiation therapy dose.

As one example of the localized nature of breast brachytherapy, the SAVI device delivers the radiation dose through multiple catheters, each of which can be individually controlled. This approach decreases the exposure of healthy tissue and resulting side effects, compared both to external beam radiation therapy and older methods of breast brachytherapy.

Systemic radioisotope therapy (RIT) is a form of targeted therapy. Targeting can be due to the chemical properties of the isotope such as radioiodine which is specifically absorbed by the thyroid gland a thousandfold better than other bodily organs. Targeting can also be achieved by attaching the radioisotope to another molecule or antibody to guide it to the target tissue. The radioisotopes are delivered through infusion (into the bloodstream) or ingestion. Examples are the infusion of metaiodobenzylguanidine (MIBG) to treat neuroblastoma, of oral iodine-131 to treat thyroid cancer or thyrotoxicosis, and of hormone-bound lutetium-177 and yttrium-90 to treat neuroendocrine tumors (peptide receptor radionuclide therapy).

Another example is the injection of radioactive yttrium-90 or holmium-166 microspheres into the hepatic artery to radioembolize liver tumors or liver metastases. These microspheres are used for the treatment approach known as selective internal radiation therapy. The microspheres are approximately 30Â Âµm in diameter (about one-third of a human hair) and are delivered directly into the artery supplying blood to the tumors. These treatments begin by guiding a catheter up through the femoral artery in the leg, navigating to the desired target site and administering treatment. The blood feeding the tumor will carry the microspheres directly to the tumor enabling a more selective approach than traditional systemic chemotherapy. There are currently three different kinds of microspheres: SIR-Spheres, TheraSphere and QuiremSpheres.

A major use of systemic radioisotope therapy is in the treatment of bone metastasis from cancer. The radioisotopes travel selectively to areas of damaged bone, and spare normal undamaged bone. Isotopes commonly used in the treatment of bone metastasis are radium-223, strontium-89 and samarium (Sm) lexidronam.

In 2002, the United States Food and Drug Administration (FDA) approved ibritumomab tiuxetan (Zevalin), which is an anti-CD20 monoclonal antibody conjugated to yttrium-90.
In 2003, the FDA approved the tositumomab/iodine (I) tositumomab regimen (Bexxar), which is a combination of an iodine-131 labelled and an unlabelled anti-CD20 monoclonal antibody.
These medications were the first agents of what is known as radioimmunotherapy, and they were approved for the treatment of refractory non-Hodgkin's lymphoma.

Intraoperative radiation therapy (IORT) is applying therapeutic levels of radiation to a target area, such as a cancer tumor, while the area is exposed during surgery.

The rationale for IORT is to deliver a high dose of radiation precisely to the targeted area with minimal exposure of surrounding tissues which are displaced or shielded during the IORT. Conventional radiation techniques such as external beam radiotherapy (EBRT) following surgical removal of the tumor have several drawbacks: The tumor bed where the highest dose should be applied is frequently missed due to the complex localization of the wound cavity even when modern radiotherapy planning is used. Additionally, the usual delay between the surgical removal of the tumor and EBRT may allow a repopulation of the tumor cells. These potentially harmful effects can be avoided by delivering the radiation more precisely to the targeted tissues leading to immediate sterilization of residual tumor cells. Another aspect is that wound fluid has a stimulating effect on tumor cells. IORT was found to inhibit the stimulating effects of wound fluid.

Deep inspiration breath-hold (DIBH) is a method of delivering radiotherapy while limiting radiation exposure to the heart and lungs. It is used primarily for treating left-sided breast cancer. The technique involves a patient holding their breath during treatment. There are two basic methods of performing DIBH: free-breathing breath-hold and spirometry-monitored deep inspiration breath hold.

Medicine has used radiation therapy as a treatment for cancer for more than 100 years, with its earliest roots traced from the discovery of x-rays in 1895 by Wilhelm RÃ¶ntgen. Emil Grubbe of Chicago was possibly the first American physician to use x-rays to treat cancer, beginning in 1896.

The field of radiation therapy began to grow in the early 1900s largely due to the groundbreaking work of Nobel Prizeâwinning scientist Marie Curie (1867â1934), who discovered the radioactive elements polonium and radium in 1898. This began a new era in medical treatment and research. Through the 1920s the hazards of radiation exposure were not understood, and little protection was used. Radium was believed to have wide curative powers and radiotherapy was applied to many diseases.

Prior to World War 2, the only practical sources of radiation for radiotherapy were radium, its "emanation", radon gas, and the x-ray tube. External beam radiotherapy (teletherapy) began at the turn of the century with relatively low voltage (<150Â kV) x-ray machines. It was found that while superficial tumors could be treated with low voltage x-rays, more penetrating, higher energy beams were required to reach tumors inside the body, requiring higher voltages. Orthovoltage X-rays, which used tube voltages of 200-500Â kV, began to be used during the 1920s. To reach the most deeply buried tumors without exposing intervening skin and tissue to dangerous radiation doses required rays with energies of 1Â MV or above, called "megavolt" radiation. Producing megavolt x-rays required voltages on the x-ray tube of 3 to 5 million volts, which required huge expensive installations. Megavoltage x-ray units were first built in the late 1930s but because of cost were limited to a few institutions. One of the first, installed at St. Bartholomew's hospital, London in 1937 and used until 1960, used a 30 foot long x-ray tube and weighed 10 tons. Radium produced megavolt gamma rays, but was extremely rare and expensive due to its low occurrence in ores. In 1937 the entire world supply of radium for radiotherapy was 50 grams, valued at Â£800,000, or $50 million in 2005 dollars.

The invention of the nuclear reactor in the Manhattan Project during World War 2 made possible the production of artificial radioisotopes for radiotherapy. Cobalt therapy, teletherapy machines using megavolt gamma rays emitted by cobalt-60, a radioisotope produced by irradiating ordinary cobalt metal in a reactor, revolutionized the field between the 1950s and the early 1980s. Cobalt machines were relatively cheap, robust and simple to use, although due to its 5.27 year half-life the cobalt had to be replaced about every 5 years.

Medical linear particle accelerators, developed since the 1940s, began replacing x-ray and cobalt units in the 1980s and these older therapies are now declining. The first medical linear accelerator was used at the Hammersmith Hospital in London in 1953. Linear accelerators can produce higher energies, have more collimated beams, and do not produce radioactive waste with its attendant disposal problems like radioisotope therapies.

With Godfrey Hounsfieldâs invention of computed tomography (CT) in 1971, three-dimensional planning became a possibility and created a shift from 2-D to 3-D radiation delivery. CT-based planning allows physicians to more accurately determine the dose distribution using axial tomographic images of the patient's anatomy. The advent of new imaging technologies, including magnetic resonance imaging (MRI) in the 1970s and positron emission tomography (PET) in the 1980s, has moved radiation therapy from 3-D conformal to intensity-modulated radiation therapy (IMRT) and to image-guided radiation therapy (IGRT) tomotherapy. These advances allowed radiation oncologists to better see and target tumors, which have resulted in better treatment outcomes, more organ preservation and fewer side effects.

While access to radiotherapy is improving globally, more than half of patients in low and middle income countries still do not have available access to the therapy as of 2017.







</doc>
<doc id="26354" url="https://en.wikipedia.org/wiki?curid=26354" title="Ronald Coase">
Ronald Coase

Ronald Harry Coase (; 29 December 1910 â 2 September 2013) was a British economist and author. He was the Clifton R. Musser Professor of Economics at the University of Chicago Law School, where he arrived in 1964 and remained for the rest of his life. He received the Nobel Memorial Prize in Economic Sciences in 1991.

Coase, who believed economists should study real markets and not theoretical ones, established the case for the corporation as a means to pay the costs of operating a marketplace. Coase is best known for two articles in particular: "The Nature of the Firm" (1937), which introduces the concept of transaction costs to explain the nature and limits of firms; and "The Problem of Social Cost" (1960), which suggests that well-defined property rights could overcome the problems of externalities (see Coase theorem). Additionally, Coase's transaction costs approach is currently influential in modern organizational economics, where it was reintroduced by Oliver E. Williamson.

Ronald Harry Coase was born in Willesden, a suburb of London, on 29 December 1910. His father, Henry Joseph Coase (1884â1973) was a telegraphist for the post office, as was his mother, Rosalie Elizabeth Coase (nÃ©e Giles; 1882â1972), before marriage. As a child, Coase had a weakness in his legs, for which he was required to wear leg-irons. Due to this problem, he attended the school for physical defectives. At the age of 12, he was able to enter the Kilburn Grammar School on scholarship. At Kilburn, he studied for the intermediate examination of the University of London as an external student in 1927â29. Coase married Marion Ruth Hartung of Chicago, Illinois in Willesden, England, 7 August 1937. Although they were unable to have children, they were married 75 years until her death in 2012, making him one of the longest-married Nobel Prize laureates.

Coase attended the London School of Economics, where he took courses with Arnold Plant and received a bachelor of commerce degree in 1932. During his undergraduate studies, Coase received the Sir Ernest Cassel Travelling Scholarship, awarded by the University of London. He used this to visit the University of Chicago in 1931â1932 and studied with Frank Knight and Jacob Viner. Coase's colleagues would later admit that they did not remember this first visit. Between 1932â34, Coase was an assistant lecturer at the Dundee School of Economics and Commerce, which later became part of the University of Dundee. Subsequently, Coase was an assistant lecturer in commerce at the University of Liverpool between 1934â1935 before returning to London School of Economics as a member of staff until 1951. He then started to work at the University at Buffalo and retained his British citizenship after moving to the United States in the 1950s. In 1958, he moved to the University of Virginia. Coase settled at the University of Chicago in 1964 and became the co-editor of the "Journal of Law and Economics" with Aaron Director. He was also for a time a trustee of the Philadelphia Society. He received the Nobel Prize in Economics in 1991.

Nearing his 100th birthday, Coase was working on a book concerning the rise of the economies of China and Vietnam. In an interview, Coase explained the mission of the Coase China Society and his vision of economics and the part to be played by Chinese economists. This became "How China Became Capitalist" (2012) co-authored with Ning Wang. Coase was honoured and received an honorary doctorate from the University at Buffalo Department of Economics in May 2012.

Coase died in Chicago on 2 September 2013 at the age of 102. His wife had died on 17 October 2012. He was praised across the political spectrum, with Slate Magazine calling him "one of the most distinguished economists in the world" and "Forbes" magazine calling him "the greatest of the many great University of Chicago economists". The Washington Post called his work over eight decades "impossible to summarize" while recommending five of his papers to read.

In "The Nature of the Firm" (1937), a brief but highly influential essay, Coase attempts to explain why the economy features a number of business firms instead of consisting exclusively of a multitude of independent, self-employed people who contract with one another. Given that "production could be carried on without any organization [that is, firms] at all", Coase asks, why and under what conditions should we expect firms to emerge?

Since modern firms can only emerge when an entrepreneur of some sort begins to hire people, Coase's analysis proceeds by considering the conditions under which it makes sense for an entrepreneur to seek hired help instead of contracting out for some particular task.

The traditional economic theory of the time (in the tradition of Adam Smith) suggested that, because the market is "efficient" (that is, those who are best at providing each good or service most cheaply are already doing so), it should always be cheaper to contract out than to hire.

Coase noted, however, a number of transaction costs involved in using the market; the cost of obtaining a good or service via the market actually exceeds the price of the good. Other costs, including search and information costs, bargaining costs, keeping trade secrets, and policing and enforcement costs, can all potentially add to the cost of procuring something from another party. This suggests that firms will arise which can internalise the production of goods and services required to deliver a product, thus avoiding these costs. This argument sets the stage for the later contributions by Oliver Williamson: markets and hierarchies are alternative co-ordination mechanisms for economic transactions. 
There is a natural limit to what a firm can produce internally, however. Coase notices "decreasing returns to the entrepreneur function", including increasing overhead costs and increasing propensity for an overwhelmed manager to make mistakes in resource allocation. These factors become countervailing costs to the use of the firm.

Coase argues that the size of a firm (as measured by how many contractual relations are "internal" to the firm and how many "external") is a result of finding an optimal balance between the competing tendencies of the costs outlined above. In general, making the firm larger will initially be advantageous, but the decreasing returns indicated above will eventually kick in, preventing the firm from growing indefinitely.

Other things being equal, therefore, a firm will tend to be larger:

The first two costs will increase with the spatial distribution of the transactions organised and the dissimilarity of the transactions. This explains why firms tend to either be in different geographic locations or to perform different functions. Additionally, technology changes that mitigate the cost of organising transactions across space may allow firms to become larger â the advent of the telephone and of cheap air travel, for example, would be expected to increase the size of firms.

A further exploration of the dichotomy between markets and hierarchies as co-ordination mechanisms for economic transactions, derived a third alternative way called Commons based peer production, in which individuals successfully collaborate on large-scale projects following a diverse cluster of motivational drives and social signals.

Upon publishing his article The Federal Communications Commission in 1959, Coase received negative feedback from the faculty at the University of Chicago over his conclusions and apparent conflicts with A. C. Pigou. According to Coase, "What I said was thought to run counter to Pigou's analysis by a number of economists at the University of Chicago and was therefore, according to them, wrong. At a meeting in Chicago I was able to convince these economists that I was right and Pigou's analysis faulty." Coase had presented his paper in 1960 during a seminar in Chicago, to twenty senior economist including George Stigler and Milton Friedman. He gradually won over the usually skeptic audience, in what has later been considered a "paradigm-shifting moment" in the genesis of Chicago Law and Economics. Coase would join the Chicago faculty four years later.

Published in the "Journal of Law and Economics" in 1960, while Coase was a member of the Economics department at the University of Virginia, "The Problem of Social Cost" provided the key insight that it is unclear where the blame for externalities lies. The example he gave was of a rancher whose cattle stray onto the cropland of his neighbour. If the rancher is made to restrict his cattle, he is harmed just as the farmer is if the cattle remain unrestrained.

Coase argued that without transaction costs the initial assignment of property rights makes no difference to whether or not the farmer and rancher can achieve the economically efficient outcome. If the cost of restraining cattle by, say, building a fence, is less than the cost of crop damage, the fence will be built. The initial assignment of property rights determines who builds the fence. If the farmer is responsible for the crop damage, the farmer will pay for the fence (as long the fence costs less than the crop damage). The allocation of property rights is primarily an equity issue, with consequences for the distribution of income and wealth, rather than an efficiency issue.

With sufficient transaction costs, initial property rights matter for both equity and efficiency. From the point of view of economic efficiency, property rights should be assigned such that the owner of the rights wants to take the economically efficient action. To elaborate, if it is efficient not to restrict the cattle, the rancher should be given the rights (so that cattle can move about freely), whereas if it is efficient to restrict the cattle, the farmer should be given the rights over the movement of the cattle (so the cattle are restricted).

This seminal argument forms the basis of the famous Coase theorem as labelled by Stigler.

Though trained as an economist, Coase spent much of his career working in a law school. He is a central figure in the development of the subfield of law and economics. He viewed law and economics as having two parts, the first "using the economists' approach and concepts to analyze the working of the legal system, often called the economic analysis of the law"; and the second "a study of the influence of the legal system on the working of the economic system." Coase said that the second part "is the part of law and economics in which I am most interested."

In his Simons Lecture celebrating the centennial of the University of Chicago, titled "Law and Economics at Chicago", Coase noted that he only accidentally wandered into the field:

Despite wandering accidentally into law and economics, the opportunity to edit the Journal of Law and Economics was instrumental in bringing him to the University of Chicago:

Coase believed that the University of Chicago was the intellectual center of law and economics. He concluded his Simons lecture by stating:

I am very much aware that, in concentrating in this lecture on law and economics at Chicago, I have neglected other significant contributions to the subject made elsewhere such as those by Guido Calabresi at Yale, by Donald Turner at Harvard, and by others. But it can hardly be denied that in the emergence of the subject of law and economics, Chicago has played a very significant part and one of which the University can be proud.

Another important contribution of Coase is the Coase conjecture, which states that an informal argument that durable-goods monopolists do not have market power because they are unable to commit to not lowering their prices in future periods.

When asked what he considered his politics to be, Coase stated,

I really don't know. I don't reject any policy without considering what its results are. If someone says there's going to be regulation, I don't say that regulation will be bad. Let's see. What we discover is that most regulation does produce, or has produced in recent times, a worse result. But I wouldn't like to say that all regulation would have this effect because one can think of circumstances in which it doesn't.

Coase admitted that early in life, he aligned himself with socialism.

Guido Calabresi wrote that Coase's focus on transaction costs in "The Nature of the Firm" was the result of his socialist beliefs. Reflecting on this, Coase wrote: "It is very difficult to know where one's ideas come from but for all I know he may well be right." Coase continued:

Coase was research advisor to the Ronald Coase Institute, an organisation that promotes research on institutions and organizations â the laws, rules, customs, and norms â that govern real economic systems, with particular support for young scholars from developing and transitional countries.

The University of Chicago Law School carries on the legacy of Ronald Coase through the mission of the Coase-Sandor Institute for Law and Economics. Each year, the University of Chicago Law School hosts the Coase Lecture, which was delivered in 2003 by Ronald Coase himself.





</doc>
<doc id="26360" url="https://en.wikipedia.org/wiki?curid=26360" title="Robert Gordis">
Robert Gordis

Robert Gordis (February 6, 1908 â 1992) was an American leading Conservative rabbi. He founded the first Conservative Jewish day school, served as President of the Rabbinical Assembly and the Synagogue Council of America, and was a professor at Jewish Theological Seminary of America from 1940 to 1992.

He wrote one of the first pamphlets explaining Conservative ideology in 1946, and in 1988 he chaired the Commission on the Philosophy of Conservative Judaism which produced the official statement of Conservative ideology "Emet Ve-Emunah".

Gordis was the founding editor in 1951 of the quarterly journal "Judaism".

"Love and Sex: A Modern Jewish Perspective (Farrar Straus Giroux, 1978)"




</doc>
<doc id="26361" url="https://en.wikipedia.org/wiki?curid=26361" title="Richard R. Ernst">
Richard R. Ernst

Richard Robert Ernst (born 14 August 1933) is a Swiss physical chemist and Nobel Laureate.

Born in Winterthur, Switzerland, Ernst was awarded the Nobel Prize in Chemistry in 1991 for his contributions towards the development of Fourier transform Nuclear Magnetic Resonance (NMR) spectroscopy while at Varian Associates, Palo Alto and the subsequent development of multi-dimensional NMR techniques. These underpin applications to both to chemistry with NMR spectroscopy and to medicine with Magnetic Resonance Imaging (MRI).

Ernst received both his diploma in chemistry in 1957 and his Ph.D. in physical chemistry in 1962 from ETH Zurich.

Ernst is a foreign fellow of the Estonian Academy of Sciences (elected 2002) and Bangladesh Academy of Sciences. He was elected a Foreign Member of the Royal Society (ForMemRS) in 1993. He was awarded the John Gamble Kirkwood Medal in 1989.
The Nobel Prize in Chemistry 1991 was awarded to Richard R. Ernst "for his contributions to the development of the methodology of high resolution nuclear magnetic resonance (NMR) spectroscopy" A strong proponent of Ernst's nomination was the long-time Danish colleague and member of the Nobel Committee Professor BÃ¸rge Bak.

He holds Honorary Doctorates from the Technical University of Munich and University of Zurich.

Ernst is member of the World Knowledge Dialogue Scientific Board. Ernst was awarded the Louisa Gross Horwitz Prize of Columbia University in 1991. He was also awarded the Tadeus Reichstein Medal in 2000 and the Order of the Star of Romania in 2004.

The 2009 Bel Air Film Festival featured the world premiere of a documentary film on Ernst "Science Plus Dharma Equals Social Responsibility". Produced by Carlo Burton, the film takes place in Ernst's hometown in Switzerland.


</doc>
<doc id="26363" url="https://en.wikipedia.org/wiki?curid=26363" title="RIPEMD">
RIPEMD

RIPEMD (RIPE Message Digest) is a family of cryptographic hash functions developed in 1992 (the original RIPEMD) and 1996 (other variants). There are five functions in the family: RIPEMD, RIPEMD-128, RIPEMD-160, RIPEMD-256, and RIPEMD-320, of which RIPEMD-160 is the most common.

The original RIPEMD, as well as RIPEMD-128, is not considered secure because 128-bit result is too small and also (for the original RIPEMD) because of design weaknesses. The 256- and 320-bit versions of RIPEMD provide the same level of security as RIPEMD-128 and RIPEMD-160, respectively; they are designed for applications where the security level is sufficient but longer hash result is necessary.

While RIPEMD functions are less popular than SHA-1 and SHA-2, they are used, among others, in Bitcoin and other cryptocurrencies based on Bitcoin.

The original RIPEMD function was designed in the framework of the EU project RIPE (RACE Integrity Primitives Evaluation) in 1992. Its design was based on the MD4 hash function. In 1996, in response to security weaknesses found in the original RIPEMD, Hans Dobbertin, Antoon Bosselaers and Bart Preneel at the COSIC research group at the Katholieke Universiteit Leuven in Leuven, Belgium published four strengthened variants: RIPEMD-128, RIPEMD-160, RIPEMD-256, and RIPEMD-320.

In August 2004, a collision was reported for the original RIPEMD. This does not apply to RIPEMD-160.

The 160-bit RIPEMD-160 hashes (also termed RIPE "message digests") are typically represented as 40-digit hexadecimal numbers. The following demonstrates a 43-byte ASCII input and the corresponding RIPEMD-160 hash:

RIPEMD-160 behaves with the desired avalanche effect of cryptographic hash functions (small changes, e.g. changing d to c, result in a completely different hash):

The hash of a zero-length string is:

Below is a list of cryptography libraries that support RIPEMD (specifically RIPEMD-160):





</doc>
<doc id="26364" url="https://en.wikipedia.org/wiki?curid=26364" title="Roman law">
Roman law

Roman law is the legal system of ancient Rome, including the legal developments spanning over a thousand years of jurisprudence, from the Twelve Tables (c. 449 BC), to the "Corpus Juris Civilis" (AD 529) ordered by Eastern Roman Emperor Justinian I. Roman law forms the basic framework for civil law, the most widely used legal system today, and the terms are sometimes used synonymously. The historical importance of Roman law is reflected by the continued use of Latin legal terminology in many legal systems influenced by it, including common law.

After the dissolution of the Western Roman Empire, the Roman law remained in effect in the Eastern Roman Empire. From the 7th century onward, the legal language in the East was Greek.

"Roman law" also denoted the legal system applied in most of Western Europe until the end of the 18th century. In Germany, Roman law practice remained in place longer under the Holy Roman Empire (963â1806). Roman law thus served as a basis for legal practice throughout Western continental Europe, as well as in most former colonies of these European nations, including Latin America, and also in Ethiopia. English and Anglo-American common law were influenced also by Roman law, notably in their Latinate legal glossary (for example, "stare decisis", "culpa in contrahendo", "pacta sunt servanda"). Eastern Europe was also influenced by the jurisprudence of the "Corpus Juris Civilis", especially in countries such as medieval Romania (Wallachia, Moldavia, and some other medieval provinces/historical regions) which created a new system, a mixture of Roman and local law. Also, Eastern European law was influenced by the "Farmer's Law" of the medieval Byzantine legal system.

Before the Twelve Tables (754â449 BC), private law comprised the Roman civil law ("ius civile Quiritium") that applied only to Roman citizens, and was bonded to religion; undeveloped, with attributes of strict formalism, symbolism, and conservatism, e.g. the ritual practice of mancipatio (a form of sale). The jurist Sextus Pomponius said, "At the beginning of our city, the people began their first activities without any fixed law, and without any fixed rights: all things were ruled despotically, by kings". It is believed that Roman Law is rooted in the Etruscan religion, emphasizing ritual.

The first legal text is the Law of the Twelve Tables, dating from the mid-5th century BC. The plebeian tribune, C. Terentilius Arsa, proposed that the law should be written, in order to prevent magistrates from applying the law arbitrarily. After eight years of political struggle, the plebeian social class convinced the patricians to send a delegation to Athens, to copy the Laws of Solon; they also dispatched delegations to other Greek cities for like reason. In 451 BC, according to the traditional story (as Livy tells it), ten Roman citizens were chosen to record the laws ("decemviri legibus scribundis"). While they were performing this task, they were given supreme political power ("imperium"), whereas the power of the magistrates was restricted. In 450 BC, the "decemviri" produced the laws on ten tablets ("tabulae"), but these laws were regarded as unsatisfactory by the plebeians. A second decemvirate is said to have added two further tablets in 449 BC. The new Law of the Twelve Tables was approved by the people's assembly.

Modern scholars tend to challenge the accuracy of Roman historians. They generally do not believe that a second decemvirate ever took place. The decemvirate of 451 is believed to have included the most controversial points of customary law, and to have assumed the leading functions in Rome. Furthermore, the question on the Greek influence found in the early Roman Law is still much discussed. Many scholars consider it unlikely that the patricians sent an official delegation to Greece, as the Roman historians believed. Instead, those scholars suggest, the Romans acquired Greek legislations from the Greek cities of Magna Graecia, the main portal between the Roman and Greek worlds. The original text of the Twelve Tables has not been preserved. The tablets were probably destroyed when Rome was conquered and burned by the Gauls in 387 BC.

The fragments which did survive show that it was not a law code in the modern sense. It did not provide a complete and coherent system of all applicable rules or give legal solutions for all possible cases. Rather, the tables contained specific provisions designed to change the then-existing customary law. Although the provisions pertain to all areas of law, the largest part is dedicated to private law and civil procedure.

Many laws include "Lex Canuleia" (445 BC; which allowed the marriageâ"ius connubii"âbetween patricians and plebeians), "Leges Licinae Sextiae" (367 BC; which made restrictions on possession of public landsâ"ager publicus"âand also made sure that one of the consuls was plebeian), "Lex Ogulnia" (300 BC; plebeians received access to priest posts), and "Lex Hortensia" (287 BC; verdicts of plebeian assembliesâ"plebiscita"ânow bind all people).

Another important statute from the Republican era is the "Lex Aquilia" of 286 BC, which may be regarded as the root of modern tort law. However, Rome's most important contribution to European legal culture was not the enactment of well-drafted statutes, but the emergence of a class of professional jurists ("prudentes", sing. "prudens", or "jurisprudentes") and of a legal science. This was achieved in a gradual process of applying the scientific methods of Greek philosophy to the subject of law, a subject which the Greeks themselves never treated as a science.

Traditionally, the origins of Roman legal science are connected to Gnaeus Flavius. Flavius is said to have published around the year 300 BC the formularies containing the words which had to be spoken in court to begin a legal action. Before the time of Flavius, these formularies are said to have been secret and known only to the priests. Their publication made it possible for non-priests to explore the meaning of these legal texts. Whether or not this story is credible, jurists were active and legal treatises were written in larger numbers before the 2nd century BC. Among the famous jurists of the republican period are Quintus Mucius Scaevola who wrote a voluminous treatise on all aspects of the law, which was very influential in later times, and Servius Sulpicius Rufus, a friend of Marcus Tullius Cicero. Thus, Rome had developed a very sophisticated legal system and a refined legal culture when the Roman republic was replaced by the monarchical system of the principate in 27 BC.

In the period between about 201 to 27 BC, we can see the development of more flexible laws to match the needs of the time. In addition to the old and formal "ius civile" a new juridical class is created: the "ius honorarium", which can be defined as "The law introduced by the magistrates who had the right to promulgate edicts in order to support, supplement or correct the existing law." With this new law the old formalism is being abandoned and new more flexible principles of "ius gentium" are used.

The adaptation of law to new needs was given over to juridical practice, to magistrates, and especially to the praetors. A praetor was not a legislator and did not technically create new law when he issued his edicts ("magistratuum edicta"). In fact, the results of his rulings enjoyed legal protection ("actionem dare") and were in effect often the source of new legal rules. A Praetor's successor was not bound by the edicts of his predecessor; however, he did take rules from edicts of his predecessor that had proved to be useful. In this way a constant content was created that proceeded from edict to edict ("edictum traslatitium").

Thus, over the course of time, parallel to the civil law and supplementing and correcting it, a new body of praetoric law emerged. In fact, praetoric law was so defined by the famous Roman jurist Papinian (Amilius Papinianus d. 212 AD): ""Ius praetorium est quod praetores introduxerunt adiuvandi vel supplendi vel corrigendi iuris civilis gratia propter utilitatem publicam"" ("praetoric law is that law introduced by praetors to supplement or correct civil law for public benefit"). Ultimately, civil law and praetoric law were fused in the "Corpus Juris Civilis".

The first 250 years of the current era are the period during which Roman law and Roman legal science reached its greatest degree of sophistication. The law of this period is often referred to as the "classical period of Roman law". The literary and practical achievements of the jurists of this period gave Roman law its unique shape.

The jurists worked in different functions: They gave legal opinions at the request of private parties. They advised the magistrates who were entrusted with the administration of justice, most importantly the praetors. They helped the praetors draft their edicts, in which they publicly announced at the beginning of their tenure, how they would handle their duties, and the formularies, according to which specific proceedings were conducted. Some jurists also held high judicial and administrative offices themselves.

The jurists also produced all kinds of legal punishments. Around AD 130 the jurist Salvius Iulianus drafted a standard form of the praetor's edict, which was used by all praetors from that time onwards. This edict contained detailed descriptions of all cases, in which the praetor would allow a legal action and in which he would grant a defense. The standard edict thus functioned like a comprehensive law code, even though it did not formally have the force of law. It indicated the requirements for a successful legal claim. The edict therefore became the basis for extensive legal commentaries by later classical jurists like Paulus and Ulpian. The new concepts and legal institutions developed by pre-classical and classical jurists are too numerous to mention here. Only a few examples are given here:

The Roman Republic had three different branches:


The Assemblies could decide whether war or peace. The Senate had complete control over the Treasury, and the Consuls had the highest juridical power.

By the middle of the 3rd century, the conditions for the flourishing of a refined legal culture had become less favourable. The general political and economic situation deteriorated as the emperors assumed more direct control of all aspects of political life. The political system of the principate, which had retained some features of the republican constitution, began to transform itself into the absolute monarchy of the dominate. The existence of a legal science and of jurists who regarded law as a science, not as an instrument to achieve the political goals set by the absolute monarch, did not fit well into the new order of things. The literary production all but ended. Few jurists after the mid-3rd century are known by name. While legal science and legal education persisted to some extent in the eastern part of the Empire, most of the subtleties of classical law came to be disregarded and finally forgotten in the west. Classical law was replaced by so-called vulgar law.


The Roman Republic's constitution or "mos maiorum" ("custom of the ancestors") was an unwritten set of guidelines and principles passed down mainly through precedent. Concepts that originated in the Roman constitution live on in constitutions to this day. Examples include checks and balances, the separation of powers, vetoes, filibusters, quorum requirements, term limits, impeachments, the powers of the purse, and regularly scheduled elections. Even some lesser used modern constitutional concepts, such as the block voting found in the electoral college of the United States, originate from ideas found in the Roman constitution.

The constitution of the Roman Republic was not formal or even official. Its constitution was largely unwritten, and was constantly evolving throughout the life of the Republic. Throughout the 1st century BC, the power and legitimacy of the Roman constitution was progressively eroding. Even Roman constitutionalists, such as the senator Cicero, lost a willingness to remain faithful to it towards the end of the republic. When the Roman Republic ultimately fell in the years following the Battle of Actium and Mark Antony's suicide, what was left of the Roman constitution died along with the Republic. The first Roman Emperor, Augustus, attempted to manufacture the appearance of a constitution that still governed the Empire, by utilising that constitution's institutions to lend legitimacy to the Principate, e.g. reusing prior grants of greater imperium to substantiate Augustus' greater imperium over the Imperial provinces and the prorogation of different magistracies to justify Augustus' receipt of tribunician power. The belief in a surviving constitution lasted well into the life of the Roman Empire.

"Stipulatio" was the basic form of contract in Roman law. It was made in the format of question and answer. The precise nature of the contract was disputed, as can be seen below.

"Rei vindicatio" is a legal action by which the plaintiff demands that the defendant return a thing that belongs to the plaintiff. It may only be used when plaintiff owns the thing, and the defendant is somehow impeding the plaintiff's possession of the thing. The plaintiff could also institute an "actio furti" (a personal action) to punish the defendant. If the thing could not be recovered, the plaintiff could claim damages from the defendant with the aid of the "condictio furtiva" (a personal action). With the aid of the "actio legis Aquiliae" (a personal action), the plaintiff could claim damages from the defendant. "Rei vindicatio" was derived from the ius civile, therefore was only available to Roman citizens.

To describe a person's position in the legal system, Romans mostly used the expression "togeus". The individual could have been a Roman citizen ("status civitatis") unlike foreigners, or he could have been free ("status libertatis") unlike slaves, or he could have had a certain position in a Roman family ("status familiae") either as the head of the family ("pater familias"), or some lower "member"â"alieni iuris"âwhich lives by someone else's law. Two status types were senator and emperor.

The history of Roman Law can be divided into three systems of procedure: that of "legis actiones", the "formulary system", and "cognitio extra ordinem". The periods in which these systems were in use overlapped one another and did not have definitive breaks, but it can be stated that the legis actio system prevailed from the time of the XII Tables (c. 450 BC) until about the end of the 2nd century BC, that the formulary procedure was primarily used from the last century of the Republic until the end of the classical period (c. AD 200), and that of cognitio extra ordinem was in use in post-classical times. Again, these dates are meant as a tool to help understand the types of procedure in use, not as a rigid boundary where one system stopped and another began.

During the republic and until the bureaucratization of Roman judicial procedure, the judge was usually a private person ("iudex privatus"). He had to be a Roman male citizen. The parties could agree on a judge, or they could appoint one from a list, called "album iudicum". They went down the list until they found a judge agreeable to both parties, or if none could be found they had to take the last one on the list.

No one had a legal obligation to judge a case. The judge had great latitude in the way he conducted the litigation. He considered all the evidence and ruled in the way that seemed just. Because the judge was not a jurist or a legal technician, he often consulted a jurist about the technical aspects of the case, but he was not bound by the jurist's reply. At the end of the litigation, if things were not clear to him, he could refuse to give a judgment, by swearing that it wasn't clear. Also, there was a maximum time to issue a judgment, which depended on some technical issues (type of action, etc.).

Later on, with the bureaucratization, this procedure disappeared, and was substituted by the so-called "extra ordinem" procedure, also known as cognitory. The whole case was reviewed before a magistrate, in a single phase. The magistrate had obligation to judge and to issue a decision, and the decision could be appealed to a higher magistrate.

When the centre of the Empire was moved to the Greek East in the 4th century, many legal concepts of Greek origin appeared in the official Roman legislation. The influence is visible even in the law of persons or of the family, which is traditionally the part of the law that changes least. For example, Constantine started putting restrictions on the ancient Roman concept of "patria potestas", the power held by the male head of a family over his descendants, by acknowledging that persons "in potestate", the descendants, could have proprietary rights. He was apparently making concessions to the much stricter concept of paternal authority under Greek-Hellenistic law. The "Codex Theodosianus" (438 AD) was a codification of Constantian laws. Later emperors went even further, until Justinian finally decreed that a child "in potestate" became owner of everything it acquired, except when it acquired something from its father.

The codes of Justinian, particularly the "Corpus Juris Civilis" (529â534) continued to be the basis of legal practice in the Empire throughout its so-called "Byzantine" history. Leo III the Isaurian issued a new code, the "Ecloga", in the early 8th century. In the 9th century, the emperors Basil I and Leo VI the Wise commissioned a combined translation of the Code and the Digest, parts of Justinian's codes, into Greek, which became known as the "Basilica". Roman law as preserved in the codes of Justinian and in the Basilica remained the basis of legal practice in Greece and in the courts of the Eastern Orthodox Church even after the fall of the Byzantine Empire and the conquest by the Turks, and, along with the Syro-Roman law book, also formed the basis for much of the "Fetha Negest", which remained in force in Ethiopia until 1931.

In the west, Justinian's political authority never went any farther than certain portions of the Italian and Hispanic peninsulas. In Law codes were issued by the Germanic kings, however, the influence of early Eastern Roman codes on some of these is quite discernible. In many early Germanic states, Roman citizens continued to be governed by Roman laws for quite some time, even while members of the various Germanic tribes were governed by their own respective codes.

The "Codex Justinianus" and the Institutes of Justinian were known in Western Europe, and along with the earlier code of Theodosius II, served as models for a few of the Germanic law codes; however, the "Digest" portion was largely ignored for several centuries until around 1070, when a manuscript of the "Digest" was rediscovered in Italy. This was done mainly through the works of glossars who wrote their comments between lines ("glossa interlinearis"), or in the form of marginal notes ("glossa marginalis"). From that time, scholars began to study the ancient Roman legal texts, and to teach others what they learned from their studies. The center of these studies was Bologna. The law school there gradually developed into Europe's first university.

The students who were taught Roman law in Bologna (and later in many other places) found that many rules of Roman law were better suited to regulate complex economic transactions than were the customary rules, which were applicable throughout Europe. For this reason, Roman law, or at least some provisions borrowed from it, began to be re-introduced into legal practice, centuries after the end of the Roman empire. This process was actively supported by many kings and princes who employed university-trained jurists as counselors and court officials and sought to benefit from rules like the famous "Princeps legibus solutus est" ("The sovereign is not bound by the laws", a phrase initially coined by Ulpian, a Roman jurist).

There are several reasons that Roman law was favored in the Middle Ages. Roman law regulated the legal protection of property and the equality of legal subjects and their wills, and it prescribed the possibility that the legal subjects could dispose their property through testament.

By the middle of the 16th century, the rediscovered Roman law dominated the legal practice of many European countries. A legal system, in which Roman law was mixed with elements of canon law and of Germanic custom, especially feudal law, had emerged. This legal system, which was common to all of continental Europe (and Scotland) was known as "Ius Commune". This "Ius Commune" and the legal systems based on it are usually referred to as civil law in English-speaking countries.

Only England and the Nordic countries did not take part in the wholesale reception of Roman law. One reason for this is that the English legal system was more developed than its continental counterparts by the time Roman law was rediscovered. Therefore, the practical advantages of Roman law were less obvious to English practitioners than to continental lawyers. As a result, the English system of common law developed in parallel to Roman-based civil law, with its practitioners being trained at the Inns of Court in London rather than receiving degrees in Canon or Civil Law at the Universities of Oxford or Cambridge. Elements of Romano-canon law were present in England in the ecclesiastical courts and, less directly, through the development of the equity system. In addition, some concepts from Roman law made their way into the common law. Especially in the early 19th century, English lawyers and judges were willing to borrow rules and ideas from continental jurists and directly from Roman law.

The practical application of Roman law, and the era of the European "Ius Commune", came to an end when national codifications were made. In 1804, the French civil code came into force. In the course of the 19th century, many European states either adopted the French model or drafted their own codes. In Germany, the political situation made the creation of a national code of laws impossible. From the 17th century, Roman law in Germany had been heavily influenced by domestic (customary) law, and it was called "usus modernus Pandectarum". In some parts of Germany, Roman law continued to be applied until the German civil code (BÃ¼rgerliches Gesetzbuch, BGB) went into effect in 1900.

Colonial expansion spread the civil law system.

Today, Roman law is no longer applied in legal practice, even though the legal systems of some countries like South Africa and San Marino are still based on the old "jus commune". However, even where the legal practice is based on a code, many rules deriving from Roman law apply: no code completely broke with the Roman tradition. Rather, the provisions of the Roman law were fitted into a more coherent system and expressed in the national language. For this reason, knowledge of the Roman law is indispensable to understand the legal systems of today. Thus, Roman law is often still a mandatory subject for law students in civil law jurisdictions.

As steps towards a unification of the private law in the member states of the European Union are being taken, the old "jus commune", which was the common basis of legal practice everywhere in Europe, but allowed for many local variants, is seen by many as a model.






</doc>
<doc id="26366" url="https://en.wikipedia.org/wiki?curid=26366" title="Reuben James">
Reuben James

Reuben James ( 1776 â 3 December 1838) was a boatswain's mate of the United States Navy, famous for his heroism in the First Barbary War.

Born in Delaware around 1776, James joined the United States Navy and served on several ships, including the frigate . During the First Barbary War, the American frigate was captured by the Barbary pirates when it ran aground in the city of Tripoli, on the southern shores of the Mediterranean Sea. During the course of the naval blockade of the harbor, there were numerous engagements, the most intense being the Gunboat Battle of August 3, 1804. During the battle, Lieutenant Stephen Decatur boarded a Tripolitan gunboat that he believed was crewed by the men who had mortally wounded his brother after supposedly surrendering. While Lieutenant Decatur was locked in hand-to-hand combat with the Tripolitan commander, another Tripolitan sailor swung his saber at him. According to early accepted accounts, Reuben James interposed himself between the descending sword and his commander, taking the blow on his head. The blow did not kill him, and he recovered later to continue serving in the Navy.

This account, though, is now considered to be in error. No one by the name of James is recorded as having received medical treatment after the battle. Another of Decatur's crewmen, Daniel Frazier, did receive medical treatment for a serious saber slash to the head. This supports some initial accounts that it was Frazier, not James, who saved Decatur's life.

James continued his Naval career, serving many years with Decatur. He was forced to retire in January 1836 because of ill health. He died in 1838 at the U.S. Naval Hospital in Washington, DC.

Three warships of the Navy have been named "Reuben James" in his honor:

James Island of Washington state was named for James.

Wheelan, Joseph. "Jefferson's War: American's First War on Terror 1801--1805", New York: Carroll & Graf Publishers, 2003.



</doc>
<doc id="26367" url="https://en.wikipedia.org/wiki?curid=26367" title="Rockwell International">
Rockwell International

Rockwell International was a major American manufacturing conglomerate in the latter half of the 20th century, involved in aircraft, the space industry, both defense-oriented and commercial electronics, light & heavy vehicles components in the automotive industry, printing presses, avionics, power tools, valves and meters, and industrial automation. Rockwell International's predecessor was founded in 1919 by Willard Rockwell. At its peak in the 1990s, Rockwell International was No. 27 on the "Fortune" 500 list, with assets of over $8Â billion, sales of $27Â billion and 115,000 employees.

Boston-born Willard Rockwell (1888â1978) made his fortune with the invention and successful launch of a new bearing system for truck axles in 1919. He merged his Oshkosh, Wisconsin-based operation with the Timken-Detroit Axle Company in 1928, rising to become chairman of its board in 1940.

In 1945, Rockwell Manufacturing Company acquired Delta Machinery and renamed it the Delta Power Tool Division of Rockwell Manufacturing Company and continued to manufacture in Milwaukee. In 1966, Rockwell invented the world's first power miter saw. In 1981, Rockwell's power tool group was acquired by Pentair and re-branded Delta Machinery. Pentair's Tools group was acquired by Black & Decker in 2005. Since 1994, Rockwell power tools are now manufactured by Positec Tool Corporation

In 1956, Rockwell Manufacturing Co. bought Walker-Turner from Kearney and Trecker. In 1957, Walker-Turner operations were closed down in Plainfield, New Jersey and moved to Bellefontaine, Ohio and Tupelo, Mississippi.

Timken-Detroit merged in 1953 with the Standard Steel Spring Company, forming the Rockwell Spring and Axle Company. After various mergers with automotive suppliers, it comprised about 10 to 20 factories in the Upper Midwestern U.S. and southern Ontario, and in 1958 renamed itself Rockwell-Standard Corporation.

Pittsburgh-based Rockwell Standard then acquired and merged with Los Angeles-based North American Aviation to form North American Rockwell in September 1967. It then purchased Miehle-Goss-Dexter, the largest supplier of printing presses, and in 1973, acquired Collins Radio, a major avionics supplier. 

In 1968, Sterling Faucet Company was bought by Rockwell Manufacturing Co. and it became a subsidiary of the company for the following years. 

In 1973, North American Rockwell merged with Rockwell Manufacturing, run by Willard Rockwell, Jr., to form Rockwell International. In the same year, the company acquired Admiral Radio and TV for $500Â million. In 1979, the appliance division was sold to Magic Chef.

Rockwell International also drew on the strengths of several of George Westinghouse's concerns, and Westinghouse is considered a co-founder of the company.

With the death of company founder and first CEO Willard F. Rockwell in 1978, and the stepping down of his son Willard Rockwell, Jr. in 1979 as the second CEO, Bob Anderson became CEO and led the company through the 1980s when it became the largest U.S. defense contractor and largest NASA contractor. Rockwell acquired the privately held Allen-Bradley Company for $1.6Â billion in February 1985Â â $1Â billion of which was cashÂ â and became a producer of industrial automation hardware and software.

During the 1980s, Anderson, his CFO Bob dePalma, and the Rockwell management team built the company to #27 on the "Fortune" 500 list. It boasted sales of $12Â billion, roughly $32 billion in 2019, and assets of over $8Â billion, roughly $21 billion in 2019. Its workforce of over 115,000 was organized into nine major divisionsÂ â Space, Aircraft, Defense Electronics, Commercial Electronics, Light Duty Automotive Components, Heavy Duty Automotive Components, Printing Presses, Valves and Meters, and Industrial Automation. Rockwell International was a major employer in Southern California, northern Ohio, northern Georgia, eastern Oklahoma, Michigan, west Texas, Iowa, Illinois, Wisconsin, and western Pennsylvania.

Anderson stepped down as CEO in February 1988, leaving the company to president Donald R. Beall. The completion of the Space Shuttle program and the completion of the B-1 bomber program had led to a decline in revenues, and Beall sought to diversify the company away from government contracts. The end of the Cold War and the perceived "peace dividend", however, prompted accelerated divestitures and sweeping management reforms. From 1988 to 2001 the company moved its headquarters four times: from Pittsburgh, Pennsylvania where it had been for decades to El Segundo, California to Seal Beach, California to Costa Mesa, California to Milwaukee, Wisconsin.

At the end of the 1980s, the company sold its valve and meter division, formerly Rockwell Manufacturing, to British Tyre & Rubber. Although Rockwell was the #1 Defense and NASA Contractor, the "peace dividend" perceived after the fall of the Soviet bloc, led the company to sell its defense and aerospace business, including what was once North American Aviation, the Defense Electronics Division and Rocketdyne, to Boeing Integrated Defense Systems in December 1996. In the 1990s, the company spun off its semiconductor products as Conexant Technologies (CNXT), which is publicly traded and based in Newport Beach, California. Rockwell International also spun off its two automotive divisions (light vehicles div. & heavy vehicles div.) as one publicly traded company, Meritor Automotive, based in Troy, Michigan, which then merged with Arvin Industries to form Arvin Meritor. That company is now known as Meritor, Inc. In 1996, Rockwell International sold Graphic Systems (formerly Miehle-Goss-Dexter), an Illinois-based newspaper and commercial printing press manufacturer, to its internal management team Stonington Partners as part of a new corporation for $600 million.

In 2001, what remained of Rockwell International was split into two publicly-traded companies, Rockwell Automation and Rockwell Collins, ending the run of what had once been a massive and diverse conglomerate. The split was structured so that Rockwell Automation was the legal successor of the old Rockwell International, while Rockwell Collins was the spin-off.

At the end, the result had been four spin-offs and three sales combined from Rockwell's nine divisions.

The various Rockwell companies list a large number of firsts in their histories, including the World War II-era P-51 Mustang fighter and the B-25 Mitchell bomber, and the Korean War-era F-86 Sabre fighter jet, as well as the Apollo spacecraft, the B-1 Lancer bomber, the Space Shuttle orbiter, and most of the Navstar Global Positioning System satellites.

Rocketdyne, which had been spun off by North American in 1955, was re-merged into Rockwell, and by that time produced most of the rocket engines used in the United States. Rockwell also purchased the Aero Design and Engineering Company from William and Rufus Travis Amis. Rockwell redesigned the company's Aero Commander aircraft, introducing its new design as the Rockwell Commander 112 and Commander 114.

The company developed a desktop calculator based on a MOSFET chip for use by its engineers. In 1967 Rockwell set up its own manufacturing plant to produce them, starting North American Rockwell MicroElectronics Corp. (called NARMEC). This would later become Rockwell Semiconductor. One of its major successes came in the early 1990s when it introduced the first low-cost 14.4 kbit/s modem chipset, which was used in a huge number of modems.

Collins radios were fitted to 80% of the airliners which were based in First World Countries. Collins designed and built the radios that communicated the Apollo moon landings and the high frequency radio network that allows worldwide communication with U.S. military aircraft. Rockwell's Rocketdyne division designed and built the third stage of the Minuteman intercontinental ballistic missile, and the Advanced Inertial Reference Sphere inertial navigation system that provided its navigation. It also built inertial navigation systems for the fleet of ballistic missile submarines. 

In addition to the manufacture of nuclear missiles and bombers, Rockwell also produced key components of the bombs they carried, including plutonium triggers at the Rocky Flats Plant in Colorado. Rockwell ran the weapons plant from 1975 to 1990.

Rockwell built heavy-duty truck axles and drive-trains in the U.S., along with power windows, seats and locks. The Rockwell Tripmaster trip recording system for commercial vehicles was released along with the Logtrak module for DOT log recording for fleets who successfully petitioned the DOT for paper logbook exemptions. Rockwell also built yachts and business jets and owned large amounts of real estate.

It was also involved in providing custom electronic intelligence equipment to the Imperial Iranian Air Force as part of Project Ibex and paid bribes to the Shah of Iran in order to secure contracts there.








For a more extensive list, see 



Rockwell International had a major research laboratory complex in Thousand Oaks, Ventura County, California. It was founded and built by North American Aviation in 1962, as the North American Science Center. In 1973 it became the Rockwell International Science Center.

The laboratory did independent contract research for the U.S. Government, and also provided research services for the company's business units. It was famous for its research in: advanced materials, particularly ceramics ; for its infrared imagers; for its research in liquid-crystal displays; and for its high-speed electronics. The laboratory invented Metalorganic vapour-phase epitaxy (MOVPE), also commonly known as Metal Organic Chemical Vapor Deposition (MOCVD). It also achieved fame in selected areas of information science, notably human-computer interaction, augmented reality, multimedia systems, and diagnostics. Rockwell Science Center led the United States Army Research Laboratory's Advanced Displays Federated Laboratory Consortium in the late 1990s. In 2000, the infrared imaging division of the laboratory moved into a new building in Camarillo, California.

After Rockwell International's breakup in 2001, the laboratory was spun off as a semi-autonomous company called Rockwell Scientific, half owned by Rockwell Collins and half owned by Rockwell Automation. In 2006, the main laboratory and infrared imaging division were sold to Teledyne Corporation. Teledyne made the laboratory complex in Thousand Oaks into its corporate headquarters. A reduced but active research and development operation continues there, under the name Teledyne Scientific & Imaging, LLC.



</doc>
<doc id="26368" url="https://en.wikipedia.org/wiki?curid=26368" title="Richard I of England">
Richard I of England

Richard I (8 September 1157Â â 6 April 1199) was King of England from 1189 until his death. He was the second king of the House of Plantagenet. He also ruled as Duke of Normandy, Aquitaine and Gascony, Lord of Cyprus, Count of Poitiers, Anjou, Maine, and Nantes, and was overlord of Brittany at various times during the same period. He was the third of five sons of King Henry II of England and Duchess Eleanor of Aquitaine and seemed unlikely to become king, but all of his brothers except the youngest, John, predeceased their father. Richard was known as or Richard the Lionheart because of his reputation as a great military leader and warrior. He was also known in (), because of his reputation for terseness.

By the age of 16, Richard had taken command of his own army, putting down rebellions in Poitou against his father. Richard was a central Christian commander during the Third Crusade, leading the campaign after the departure of Philip II of France and achieving considerable victories against his Muslim counterpart, Saladin, although he did not retake Jerusalem from Saladin.

Richard spoke both French and Occitan. He was born in England, where he spent his childhood; before becoming king, however, he lived most of his adult life in the Duchy of Aquitaine, in the southwest of France. Following his accession, he spent very little time, perhaps as little as six months, in England. Most of his life as king was spent on Crusade, in captivity, or actively defending his lands in France. Rather than regarding his kingdom as a responsibility requiring his presence as ruler, he has been perceived as preferring to use it merely as a source of revenue to support his armies. Nevertheless, he was seen as a pious hero by his subjects. He remains one of the few kings of England remembered more commonly by his epithet than his regnal number, and is an enduring iconic figure both in England and in France.

Richard was born on 8 September 1157, probably at Beaumont Palace, in Oxford, England, son of King Henry II and Eleanor, Duchess of Aquitaine. He was a younger brother of Henry the Young King and Matilda, Duchess of Saxony. As a younger son of King Henry II, he was not expected to ascend to the throne. He was also an elder brother of Geoffrey II, Duke of Brittany; Queen Eleanor of Castile; Queen Joan of Sicily; and John, Count of Mortain, who succeeded him as king. Richard was the younger maternal half-brother of Marie of France, Countess of Champagne, and Alix of France, Countess of Blois. Henry II and Eleanor's eldest son William IX, Count of Poitiers, died before Richard's birth. Richard is often depicted as having been the favourite son of his mother. His father was Angevin-Norman and great-grandson of William the Conqueror. Contemporary historian Ralph of Diceto traced his family's lineage through Matilda of Scotland to the Anglo-Saxon kings of England and Alfred the Great, and from there legend linked them to Noah and Woden. According to Angevin family tradition, there was even 'infernal blood' in their ancestry, with a claimed descent from the fairy, or female demon, Melusine.

While his father visited his lands from Scotland to France, Richard probably spent his childhood in England. His first recorded visit to the European continent was in May 1165, when his mother took him to Normandy. His wet nurse was Hodierna of St Albans, whom he gave a generous pension after he became king. Little is known about Richard's education. Although he was born in Oxford and brought up in England up to his eighth year, it is not known to what extent he used or understood English; he was an educated man who composed poetry and wrote in Limousin ("") and also in French. During his captivity, English prejudice against foreigners was used in a calculated way by his brother John to help destroy the authority of Richard's chancellor, William Longchamp, who was a Norman. One of the specific charges laid against Longchamp, by John's supporter Hugh Nonant, was that he could not speak English. This indicates that by the late 12th century a knowledge of English was expected of those in positions of authority in England.

Richard was said to be very attractive; his hair was between red and blond, and he was light-eyed with a pale complexion. According to Clifford Brewer, he was , though that is unverifiable since his remains have been lost since at least the French Revolution. John, his youngest brother, was known to be . The , a Latin prose narrative of the Third Crusade, states that: "He was tall, of elegant build; the colour of his hair was between red and gold; his limbs were supple and straight. He had long arms suited to wielding a sword. His long legs matched the rest of his body".

From an early age, Richard showed significant political and military ability, becoming noted for his chivalry and courage as he fought to control the rebellious nobles of his own territory. His elder brother Henry was crowned king of England during his father's lifetime.

Marriage alliances were common among medieval royalty: they led to political alliances and peace treaties and allowed families to stake claims of succession on each other's lands. In March 1159 it was arranged that Richard would marry one of the daughters of Ramon Berenguer IV, Count of Barcelona; however, these arrangements failed, and the marriage never took place. Henry the Young King was married to Margaret, daughter of Louis VII of France, on 2 November 1160. Despite this alliance between the Plantagenets and the Capetians, the dynasty on the French throne, the two houses were sometimes in conflict. In 1168, the intercession of Pope Alexander III was necessary to secure a truce between them. Henry II had conquered Brittany and taken control of Gisors and the Vexin, which had been part of Margaret's dowry.

Early in the 1160s there had been suggestions Richard should marry Alys, Countess of the Vexin, fourth daughter of Louis VII; because of the rivalry between the kings of England and France, Louis obstructed the marriage. A peace treaty was secured in January 1169 and Richard's betrothal to Alys was confirmed. Henry II planned to divide his and Eleanor's territories among their three eldest surviving sons: Henry would become King of England and have control of Anjou, Maine, and Normandy; Richard would inherit Aquitaine and Poitiers from his mother; and Geoffrey would become Duke of Brittany through marriage with Constance, heir presumptive of Conan IV. At the ceremony where Richard's betrothal was confirmed, he paid homage to the King of France for Aquitaine, thus securing ties of vassalage between the two.

After Henry II fell seriously ill in 1170, he enacted his plan to divide his kingdom, although he would retain overall authority over his sons and their territories. In 1171 Richard left for Aquitaine with his mother, and Henry II gave him the duchy of Aquitaine at the request of Eleanor. Richard and his mother embarked on a tour of Aquitaine in 1171 in an attempt to pacify the locals. Together they laid the foundation stone of St Augustine's Monastery in Limoges. In June 1172, at age 12, Richard was formally recognised as the Duke of Aquitaine and Count of Poitou when he was granted the lance and banner emblems of his office; the ceremony took place in Poitiers and was repeated in Limoges, where he wore the ring of St Valerie, who was the personification of Aquitaine.

According to Ralph of Coggeshall, Henry the Young King instigated rebellion against Henry II; he wanted to reign independently over at least part of the territory his father had promised him, and to break away from his dependence on Henry II, who controlled the purse strings. There were rumors that Eleanor might have encouraged her sons to revolt against their father.

Henry the Young King abandoned his father and left for the French court, seeking the protection of Louis VII; his younger brothers, Richard and Geoffrey, soon followed him, while the five-year-old John remained in England. Louis gave his support to the three brothers and even knighted Richard, tying them together through vassalage.
Jordan Fantosme, a contemporary poet, described the rebellion as a "war without love".
The brothers made an oath at the French court that they would not make terms with Henry II without the consent of Louis VII and the French barons. With the support of Louis, Henry the Young King attracted many barons to his cause through promises of land and money; one such baron was Philip I, Count of Flanders, who was promised Â£1,000 and several castles. The brothers also had supporters ready to rise up in England. Robert de Beaumont, 3rd Earl of Leicester, joined forces with Hugh Bigod, 1st Earl of Norfolk, Hugh de Kevelioc, 5th Earl of Chester, and William I of Scotland for a rebellion in Suffolk. The alliance with Louis was initially successful, and by July 1173 the rebels were besieging Aumale, Neuf-MarchÃ©, and Verneuil, and Hugh de Kevelioc had captured Dol in Brittany. Richard went to Poitou and raised the barons who were loyal to himself and his mother in rebellion against his father. Eleanor was captured, so Richard was left to lead his campaign against Henry II's supporters in Aquitaine on his own. He marched to take La Rochelle but was rejected by the inhabitants; he withdrew to the city of Saintes, which he established as a base of operations.

In the meantime, Henry II had raised a very expensive army of more than 20,000 mercenaries with which to face the rebellion. He marched on Verneuil, and Louis retreated from his forces. The army proceeded to recapture Dol and subdued Brittany. At this point Henry II made an offer of peace to his sons; on the advice of Louis the offer was refused. Henry II's forces took Saintes by surprise and captured much of its garrison, although Richard was able to escape with a small group of soldiers. He took refuge in ChÃ¢teau de Taillebourg for the rest of the war. Henry the Young King and the Count of Flanders planned to land in England to assist the rebellion led by the Earl of Leicester. Anticipating this, Henry II returned to England with 500 soldiers and his prisoners (including Eleanor and his sons' wives and fiancÃ©es), but on his arrival found out that the rebellion had already collapsed. William I of Scotland and Hugh Bigod were captured on 13 and 25 July respectively. Henry II returned to France and raised the siege of Rouen, where Louis VII had been joined by Henry the Young King after abandoning his plan to invade England. Louis was defeated and a peace treaty was signed in September 1174, the Treaty of Montlouis.

When Henry II and Louis VII made a truce on 8 September 1174, its terms specifically excluded Richard. Abandoned by Louis and wary of facing his father's army in battle, Richard went to Henry II's court at Poitiers on 23 September and begged for forgiveness, weeping and falling at the feet of Henry, who gave Richard the kiss of peace. Several days later, Richard's brothers joined him in seeking reconciliation with their father. The terms the three brothers accepted were less generous than those they had been offered earlier in the conflict (when Richard was offered four castles in Aquitaine and half of the income from the duchy): Richard was given control of two castles in Poitou and half the income of Aquitaine; Henry the Young King was given two castles in Normandy; and Geoffrey was permitted half of Brittany. Eleanor remained Henry II's prisoner until his death, partly as insurance for Richard's good behaviour.

After the conclusion of the war, the process of pacifying the provinces that had rebelled against Henry II began. The King travelled to Anjou for this purpose, and Geoffrey dealt with Brittany. In January 1175 Richard was dispatched to Aquitaine to punish the barons who had fought for him. The historian John Gillingham notes that the chronicle of Roger of Howden is the main source for Richard's activities in this period. According to the chronicle, most of the castles belonging to rebels were to be returned to the state they were in 15Â days before the outbreak of war, while others were to be razed. Given that by this time it was common for castles to be built in stone, and that many barons had expanded or refortified their castles, this was not an easy task. Roger of Howden records the two-month siege of Castillon-sur-Agen; while the castle was "notoriously strong", Richard's siege engines battered the defenders into submission. On this campaign, Richard acquired the name "the Lion" or "the Lionheart" due to his noble, brave and fierce leadership.He is referred to as "this our lion" (') as early as 1187 in the ' of , while the byname "lionheart" (') is first recorded in Ambroise's ' in the context of the Accon campaign of 1191.

Henry seemed unwilling to entrust any of his sons with resources that could be used against him. It was suspected that Henry had appropriated Alys, Richard's betrothed, the daughter of Louis VII of France by his second wife, as his mistress. This made a marriage between Richard and Alys technically impossible in the eyes of the Church, but Henry prevaricated: he regarded Alys's dowry, Vexin in the Ãle-de-France, as valuable. Richard was discouraged from renouncing Alys because she was the sister of King Philip II of France, a close ally.
After his failure to overthrow his father, Richard concentrated on putting down internal revolts by the nobles of Aquitaine, especially in the territory of Gascony. The increasing cruelty of his rule led to a major revolt there in 1179. Hoping to dethrone Richard, the rebels sought the help of his brothers Henry and Geoffrey. The turning point came in the Charente Valley in the spring of 1179. The well-defended fortress of Taillebourg seemed impregnable. The castle was surrounded by a cliff on three sides and a town on the fourth side with a three-layer wall. Richard first destroyed and looted the farms and lands surrounding the fortress, leaving its defenders no reinforcements or lines of retreat. The garrison sallied out of the castle and attacked Richard; he was able to subdue the army and then followed the defenders inside the open gates, where he easily took over the castle in two days. Richard the Lionheart's victory at Taillebourg deterred many barons from thinking of rebelling and forced them to declare their loyalty to him. It also won Richard a reputation as a skilled military commander.

In 1181â1182 Richard faced a revolt over the succession to the county of AngoulÃªme. His opponents turned to Philip II of France for support, and the fighting spread through the Limousin and PÃ©rigord. The excessive cruelty of Richard's punitive campaigns aroused even more hostility. However, with support from his father and from the Young King, Richard the Lionheart eventually succeeded in bringing the Viscount Aimar V of Limoges and Count Elie of PÃ©rigord to terms.

After Richard had subdued his rebellious barons he again challenged his father. From 1180 to 1183 the tension between Henry and Richard grew, as King Henry commanded Richard to pay homage to Henry the Young King, but Richard refused. Finally, in 1183 Henry the Young King and Geoffrey, Duke of Brittany, invaded Aquitaine in an attempt to subdue Richard. Richard's barons joined in the fray and turned against their duke. However, Richard and his army succeeded in holding back the invading armies, and they executed any prisoners. The conflict paused briefly in June 1183 when the Young King died. With the death of Henry the Young King, Richard became the eldest surviving son and therefore heir to the English crown. King Henry demanded that Richard give up Aquitaine (which he planned to give to his youngest son John as his inheritance). Richard refused, and conflict continued between them. Henry II soon gave John permission to invade Aquitaine.

To strengthen his position, in 1187, Richard allied himself with 22-year-old Philip II, the son of Eleanor's ex-husband Louis VII by Adele of Champagne. Roger of Howden wrote:

The King of England was struck with great astonishment, and wondered what [this alliance] could mean, and, taking precautions for the future, frequently sent messengers into France for the purpose of recalling his son Richard; who, pretending that he was peaceably inclined and ready to come to his father, made his way to Chinon, and, in spite of the person who had the custody thereof, carried off the greater part of his father's treasures, and fortified his castles in Poitou with the same, refusing to go to his father.

Overall, Howden is chiefly concerned with the politics of the relationship between Richard and King Philip. Gillingham has addressed theories suggesting that this political relationship was also sexually intimate, which he posits probably stemmed from an official record announcing that, as a symbol of unity between the two countries, the kings of England and France had slept overnight in the same bed. Gillingham has characterized this as "an accepted political act, nothing sexual about it;... a bit like a modern-day photo opportunity".

In exchange for Philip's help against his father, Richard promised to concede to him his rights to both Normandy and Anjou. Richard paid homage to Philip in November 1187. With news arriving of the Battle of Hattin, he took the cross at Tours in the company of other French nobles.

In 1188 Henry II planned to concede Aquitaine to his youngest son John. But Richard objected. He felt that Aquitaine was his and that John was unfit to take over the land once belonging to his mother. This refusal is what finally made Henry II bring Queen Eleanor out of prison. He sent her to Aquitaine and demanded that Richard give up his lands to his mother who would once again rule over those lands.

The following year, Richard attempted to take the throne of England for himself by joining Philip's expedition against his father. On 4 July 1189, the forces of Richard and Philip defeated Henry's army at Ballans. Henry, with John's consent, agreed to name Richard his heir apparent. Two days later Henry II died in Chinon, and Richard the Lionheart succeeded him as King of England, Duke of Normandy, and Count of Anjou. Roger of Howden claimed that Henry's corpse bled from the nose in Richard's presence, which was assumed to be a sign that Richard had caused his death.

Richard I was officially invested as Duke of Normandy on 20 July 1189 and crowned king in Westminster Abbey on 3 September 1189. Tradition barred all Jews and women from the investiture, but some Jewish leaders arrived to present gifts for the new king. According to Ralph of Diceto, Richard's courtiers stripped and flogged the Jews, then flung them out of court.

When a rumour spread that Richard had ordered all Jews to be killed, the people of London attacked the Jewish population. Many Jewish homes were destroyed by arsonists, and several Jews were forcibly converted. Some sought sanctuary in the Tower of London, and others managed to escape. Among those killed was Jacob of OrlÃ©ans, a respected Jewish scholar. Roger of Howden, in his "", claimed that the jealous and bigoted citizens started the rioting, and that Richard punished the perpetrators, allowing a forcibly converted Jew to return to his native religion. Baldwin of Forde, Archbishop of Canterbury, reacted by remarking, "If the King is not God's man, he had better be the devil's".

Realising that the assaults could destabilise his realm on the eve of his departure on crusade, Richard ordered the execution of those responsible for the most egregious murders and persecutions, including rioters who had accidentally burned down Christian homes. He distributed a royal writ demanding that the Jews be left alone. The edict was only loosely enforced, however, and the following March further violence occurred, including a massacre at York.

Richard had already taken the cross as Count of Poitou in 1187. His father and Philip II had done so at Gisors on 21 January 1188 after receiving news of the fall of Jerusalem to Saladin. After Richard became king, he and Philip agreed to go on the Third Crusade, since each feared that during his absence the other might usurp his territories.

Richard swore an oath to renounce his past wickedness in order to show himself worthy to take the cross. He started to raise and equip a new crusader army. He spent most of his father's treasury (filled with money raised by the Saladin tithe), raised taxes, and even agreed to free King William I of Scotland from his oath of subservience to Richard in exchange for marks (Â£). To raise still more revenue he sold the right to hold official positions, lands, and other privileges to those interested in them. Those already appointed were forced to pay huge sums to retain their posts. William Longchamp, Bishop of Ely and the King's chancellor, made a show of bidding Â£ to remain as Chancellor. He was apparently outbid by a certain Reginald the Italian, but that bid was refused.

Richard made some final arrangements on the continent. He reconfirmed his father's appointment of William Fitz Ralph to the important post of seneschal of Normandy. In Anjou, Stephen of Tours was replaced as seneschal and temporarily imprisoned for fiscal mismanagement. Payn de Rochefort, an Angevin knight, became seneschal of Anjou. In Poitou the ex-provost of Benon, Peter Bertin, was made seneschal, and finally, the household official Helie de La Celle was picked for the seneschalship in Gascony. After repositioning the part of his army he left behind to guard his French possessions, Richard finally set out on the crusade in summer 1190. (His delay was criticised by troubadours such as Bertran de Born.) He appointed as regents Hugh de Puiset, Bishop of Durham, and William de Mandeville, 3rd Earl of Essexâwho soon died and was replaced by William Longchamp. Richard's brother John was not satisfied by this decision and started scheming against William Longchamp. When Richard was raising funds for his crusade, he was said to declare, "I would have sold London if I could find a buyer".

In September 1190 Richard and Philip arrived in Sicily. After the death of King William II of Sicily in 1189 his cousin had seized power as King Tancred of Sicily, although the legal heir was William's aunt Constance, wife of Henry VI, Holy Roman Emperor. Tancred had imprisoned William's widow, Queen Joan, who was Richard's sister and did not give her the money she had inherited in William's will. When Richard arrived he demanded that his sister be released and given her inheritance; she was freed on 28 September, but without the inheritance. The presence of foreign troops also caused unrest: in October, the people of Messina revolted, demanding that the foreigners leave. Richard attacked Messina, capturing it on 4 October 1190. After looting and burning the city Richard established his base there, but this created tension between Richard and Philip Augustus. He remained there until Tancred finally agreed to sign a treaty on 4 March 1191. The treaty was signed by Richard, Philip, and Tancred. Its main terms were:

The two kings stayed on in Sicily for a while, but this resulted in increasing tensions between them and their men, with Philip Augustus plotting with Tancred against Richard. The two kings finally met to clear the air and reached an agreement, including the end of Richard's betrothal to Philip's sister Alys.

In April 1191 Richard left Messina for Acre, but a storm dispersed his large fleet. After some searching, it was discovered that the ship carrying his sister Joan and his new fiancÃ©e, Berengaria of Navarre, was anchored on the south coast of Cyprus, along with the wrecks of several other vessels, including the treasure ship. Survivors of the wrecks had been taken prisoner by the island's ruler, Isaac Komnenos.

On 1 May 1191 Richard's fleet arrived in the port of Lemesos (Limassol) on Cyprus. He ordered Isaac to release the prisoners and treasure. Isaac refused, so Richard landed his troops and took Limassol. Various princes of the Holy Land arrived in Limassol at the same time, in particular Guy of Lusignan. All declared their support for Richard provided that he support Guy against his rival, Conrad of Montferrat.

The local magnates abandoned Isaac, who considered making peace with Richard, joining him on the crusade, and offering his daughter in marriage to the person named by Richard. Isaac changed his mind, however, and tried to escape. Richard's troops, led by Guy de Lusignan, conquered the whole island by 1 June. Isaac surrendered and was confined with silver chains because Richard had promised that he would not place him in irons. Richard named Richard de Camville and Robert of Thornham as governors. He later sold the island to the master of Knights Templar, Robert de SablÃ©, and it was subsequently acquired, in 1192, by Guy of Lusignan and became a stable feudal kingdom.

The rapid conquest of the island by Richard is more important than it may seem. The island occupies a key strategic position on the maritime lanes to the Holy Land, whose occupation by the Christians could not continue without support from the sea. Cyprus remained a Christian stronghold until the battle of Lepanto (1571). Richard's exploit was well publicised and contributed to his reputation, and he also derived significant financial gains from the conquest of the island. Richard left Cyprus for Acre on 5 June with his allies.

Before leaving Cyprus on crusade, Richard married Berengaria, the first-born daughter of King Sancho VI of Navarre. Richard first grew close to her at a tournament held in her native Navarre. The wedding was held in Limassol on 12 May 1191 at the Chapel of St George and was attended by Richard's sister Joan, whom he had brought from Sicily. The marriage was celebrated with great pomp and splendour, many feasts and entertainments, and public parades and celebrations followed commemorating the event. When Richard married Berengaria he was still officially betrothed to Alys, and he pushed for the match in order to obtain the Kingdom of Navarre as a fief, as Aquitaine had been for his father. Further, Eleanor championed the match, as Navarre bordered Aquitaine, thereby securing the southern border of her ancestral lands. Richard took his new wife on crusade with him briefly, though they returned separately. Berengaria had almost as much difficulty in making the journey home as her husband did, and she did not see England until after his death. After his release from German captivity, Richard showed some regret for his earlier conduct, but he was not reunited with his wife. The marriage remained childless.

King Richard landed at Acre on 8 June 1191. He gave his support to his Poitevin vassal Guy of Lusignan, who had brought troops to help him in Cyprus. Guy was the widower of his father's cousin Sibylla of Jerusalem and was trying to retain the kingship of Jerusalem, despite his wife's death during the Siege of Acre the previous year. Guy's claim was challenged by Conrad of Montferrat, second husband of Sibylla's half-sister, Isabella: Conrad, whose defence of Tyre had saved the kingdom in 1187, was supported by Philip of France, son of his first cousin Louis VII of France, and by another cousin, Leopold V, Duke of Austria. Richard also allied with Humphrey IV of Toron, Isabella's first husband, from whom she had been forcibly divorced in 1190. Humphrey was loyal to Guy and spoke Arabic fluently, so Richard used him as a translator and negotiator.

Richard and his forces aided in the capture of Acre, despite Richard's serious illness. At one point, while sick from scurvy, he is said to have picked off guards on the walls with a crossbow, while being carried on a stretcher. Eventually, Conrad of Montferrat concluded the surrender negotiations with Saladin's forces inside Acre and raised the banners of the kings in the city. Richard quarrelled with Leopold of Austria over the deposition of Isaac Komnenos (related to Leopold's Byzantine mother) and his position within the crusade. Leopold's banner had been raised alongside the English and French standards. This was interpreted as arrogance by both Richard and Philip, as Leopold was a vassal of the Holy Roman Emperor (although he was the highest-ranking surviving leader of the imperial forces). Richard's men tore the flag down and threw it in the moat of Acre. Leopold left the crusade immediately. Philip also left soon afterwards, in poor health and after further disputes with Richard over the status of Cyprus (Philip demanded half the island) and the kingship of Jerusalem. Richard, suddenly, found himself without allies.

Richard had kept 2,700 Muslim prisoners as hostages against Saladin fulfilling all the terms of the surrender of the lands around Acre. Philip, before leaving, had entrusted his prisoners to Conrad, but Richard forced him to hand them over to him. Richard feared his forces being bottled up in Acre as he believed his campaign could not advance with the prisoners in train. He, therefore, ordered all the prisoners executed. He then moved south, defeating Saladin's forces at the Battle of Arsuf north of Jaffa on 7 September 1191. Saladin attempted to harass Richard's army into breaking its formation in order to defeat it in detail. Richard maintained his army's defensive formation, however, until the Hospitallers broke ranks to charge the right wing of Saladin's forces. Richard then ordered a general counterattack, which won the battle. Arsuf was an important victory. The Muslim army was not destroyed, despite the considerable casualties it suffered, but it did rout; this was considered shameful by the Muslims and boosted the morale of the Crusaders. In November 1191, following the fall of Jaffa, the Crusader army advanced inland towards Jerusalem. The army then marched to Beit Nuba, only 12 miles from Jerusalem. Muslim morale in Jerusalem was so low that the arrival of the Crusaders would probably have caused the city to fall quickly. However, the weather was appallingly bad, cold with heavy rain and hailstorms; this, combined with the fear that the Crusader army, if it besieged Jerusalem, might be trapped by a relieving force, led to the decision to retreat back to the coast. Richard attempted to negotiate with Saladin, but this was unsuccessful. In the first half of 1192, he and his troops refortified Ascalon.

An election forced Richard to accept Conrad of Montferrat as King of Jerusalem, and he sold Cyprus to his defeated protÃ©gÃ©, Guy. Only days later, on 28 April 1192, Conrad was stabbed to death by Hashshashin (Assassins) before he could be crowned. Eight days later Richard's own nephew Henry II of Champagne was married to the widowed Isabella, although she was carrying Conrad's child. The murder has never been conclusively solved, and Richard's contemporaries widely suspected his involvement.

The crusader army made another advance on Jerusalem, and in June 1192 it came within sight of the city before being forced to retreat once again, this time because of dissension amongst its leaders. In particular, Richard and the majority of the army council wanted to force Saladin to relinquish Jerusalem by attacking the basis of his power through an invasion of Egypt. The leader of the French contingent, Hugh III, Duke of Burgundy, however, was adamant that a direct attack on Jerusalem should be made. This split the Crusader army into two factions, and neither was strong enough to achieve its objective. Richard stated that he would accompany any attack on Jerusalem but only as a simple soldier; he refused to lead the army. Without a united command the army had little choice but to retreat back to the coast.

There commenced a period of minor skirmishes with Saladin's forces, punctuated by another defeat in the field for the Ayyubid army at the Battle of Jaffa. Baha' al-Din, a contemporary Muslim soldier and biographer of Saladin, recorded a tribute to Richard's martial prowess at this battle: "I have been assured ... that on that day the king of England, lance in hand, rode along the whole length of our army from right to left, and not one of our soldiers left the ranks to attack him. The Sultan was wroth thereat and left the battlefield in anger...". Both sides realised that their respective positions were growing untenable. Richard knew that both Philip and his own brother John were starting to plot against him, and the morale of Saladin's army had been badly eroded by repeated defeats. However, Saladin insisted on the razing of Ascalon's fortifications, which Richard's men had rebuilt, and a few other points. Richard made one last attempt to strengthen his bargaining position by attempting to invade EgyptâSaladin's chief supply-baseâbut failed. In the end, time ran out for Richard. He realised that his return could be postponed no longer since both Philip and John were taking advantage of his absence. He and Saladin finally came to a settlement on 2 September 1192. The terms provided for the destruction of Ascalon's fortifications, allowed Christian pilgrims and merchants access to Jerusalem, and initiated a three-year truce. Richard, being ill with scurvy, left for England on October 9, 1192.

Bad weather forced Richard's ship to put in at Corfu, in the lands of Byzantine Emperor Isaac II Angelos, who objected to Richard's annexation of Cyprus, formerly Byzantine territory. Disguised as a Knight Templar, Richard sailed from Corfu with four attendants, but his ship was wrecked near Aquileia, forcing Richard and his party into a dangerous land route through central Europe. On his way to the territory of his brother-in-law Henry the Lion, Richard was captured shortly before Christmas 1192 near Vienna by Leopold of Austria, who accused Richard of arranging the murder of his cousin Conrad of Montferrat. Moreover, Richard had personally offended Leopold by casting down his standard from the walls of Acre.

Leopold kept Richard prisoner at DÃ¼rnstein Castle under the care of Leopold's Hadmar of Kuenring. His mishap was soon known to England, but the regents were for some weeks uncertain of his whereabouts. While in prison, Richard wrote ' or ' ("No man who is imprisoned"), which is addressed to his half-sister Marie de Champagne. He wrote the song, in French and Occitan versions, to express his feelings of abandonment by his people and his sister. The detention of a crusader was contrary to public law, and on these grounds Pope Celestine III excommunicated Duke Leopold.

On 28 March 1193 Richard was brought to Speyer and handed over to Holy Roman Emperor Henry VI, who imprisoned him in Trifels Castle. Henry VI was aggrieved by the support the Plantagenets had given to the family of Henry the Lion and by Richard's recognition of Tancred in Sicily. Henry VI needed money to raise an army and assert his rights over southern Italy and continued to hold Richard for ransom. In response, Pope Celestine III excommunicated Henry VI, as he had Duke Leopold, for the continued wrongful imprisonment of Richard. Richard famously refused to show deference to the Emperor and declared to him, "". Despite his complaints, the conditions of his captivity were not severe.

The Emperor demanded that marks (100,000 pounds of silver) be delivered to him before he would release the King, the same amount raised by the Saladin tithe only a few years earlier, and 2â3 times the annual income for the English Crown under Richard. Richard's mother, Eleanor, worked to raise the ransom. Both clergy and laymen were taxed for a quarter of the value of their property, the gold and silver treasures of the churches were confiscated, and money was raised from the scutage and the carucage taxes. At the same time, John, Richard's brother, and King Philip of France offered marks for Henry VI to hold Richard prisoner until Michaelmas 1194. Henry turned down the offer. The money to rescue the King was transferred to Germany by the Emperor's ambassadors, but "at the king's peril" (had it been lost along the way, Richard would have been held responsible), and finally, on 4 February 1194 Richard was released. Philip sent a message to John: "Look to yourself; the devil is loose".

In Richard's absence, his brother John revolted with the aid of Philip; amongst Philip's conquests in the period of Richard's imprisonment was Normandy. Richard forgave John when they met again and named him as his heir in place of their nephew, Arthur. At Winchester, on 11 March 1194, Richard was crowned a second time to nullify the shame of his captivity.

Richard began his reconquest of Normandy. The fall of the ChÃ¢teau de Gisors to the French in 1193 opened a gap in the Norman defences. The search began for a fresh site for a new castle to defend the duchy of Normandy and act as a base from which Richard could launch his campaign to take back the Vexin from French control. A naturally defensible position was identified perched high above the River Seine, an important transport route, in the manor of Andeli. Under the terms of the Treaty of Louviers (December 1195) between Richard and Philip II, neither king was allowed to fortify the site; despite this, Richard intended to build the vast ChÃ¢teau Gaillard. Richard tried to obtain the manor through negotiation. Walter de Coutances, Archbishop of Rouen, was reluctant to sell the manor as it was one of the diocese's most profitable, and other lands belonging to the diocese had recently been damaged by war. When Philip besieged Aumale in Normandy, Richard grew tired of waiting and seized the manor, although the act was opposed by the Catholic Church. The archbishop issued an interdict against performing church services in the duchy of Normandy; Roger of Howden detailed "unburied bodies of the dead lying in the streets and square of the cities of Normandy". The interdict was still in force when work began on the castle, but Pope Celestine III repealed it in April 1197 after Richard made gifts of land to the archbishop and the diocese of Rouen, including two manors and the prosperous port of Dieppe.

Royal expenditure on castles declined from the levels spent under Henry II, attributed to a concentration of resources on Richard's war with the king of France. However, the work at ChÃ¢teau Gaillard was some of the most expensive of its time and cost an estimated Â£15,000 to Â£20,000 between 1196 and 1198. This was more than double Richard's spending on castles in England, an estimated Â£7,000. Unprecedented in its speed of construction, the castle was mostly complete in two years when most construction on such a scale would have taken the best part of a decade. According to William of Newburgh, in May 1198 Richard and the labourers working on the castle were drenched in a "rain of blood". While some of his advisers thought the rain was an evil omen, Richard was undeterred.
As no master-mason is mentioned in the otherwise detailed records of the castle's construction, military historian Allen Brown has suggested that Richard himself was the overall architect; this is supported by the interest Richard showed in the work through his frequent presence. In his final years, the castle became Richard's favourite residence, and writs and charters were written at ChÃ¢teau Gaillard bearing """ (at the Fair Castle of the Rock).

ChÃ¢teau Gaillard was ahead of its time, featuring innovations that would be adopted in castle architecture nearly a century later. Allen Brown described ChÃ¢teau Gaillard as "one of the finest castles in Europe", and military historian Sir Charles Oman wrote that it was considered "the masterpiece of its time. The reputation of its builder, CÅur de Lion, as a great military engineer might stand firm on this single structure. He was no mere copyist of the models he had seen in the East, but introduced many original details of his own invention into the stronghold".

Determined to resist Philip's designs on contested Angevin lands such as the Vexin and Berry, Richard poured all his military expertise and vast resources into the war on the French King. He organised an alliance against Philip, including Baldwin IX of Flanders, Renaud, Count of Boulogne, and his father-in-law King Sancho VI of Navarre, who raided Philip's lands from the south. Most importantly, he managed to secure the Welf inheritance in Saxony for his nephew, Henry the Lion's son, who was elected Otto IV of Germany in 1198.

Partly as a result of these and other intrigues, Richard won several victories over Philip. At FrÃ©teval in 1194, just after Richard's return to France from captivity and money-raising in England, Philip fled, leaving his entire archive of financial audits and documents to be captured by Richard. At the Battle of Gisors (sometimes called Courcelles) in 1198, Richard took "â"God and my Right"âas his motto (still used by the British monarchy today), echoing his earlier boast to Emperor Henry that his rank acknowledged no superior but God.

In March 1199, Richard was in Limousin suppressing a revolt by Viscount Aimar V of Limoges. Although it was Lent, he "devastated the Viscount's land with fire and sword". He besieged the puny, virtually unarmed castle of ChÃ¢lus-Chabrol. Some chroniclers claimed that this was because a local peasant had uncovered a treasure trove of Roman gold.

In the early evening of 25 March 1199, Richard was walking around the castle perimeter without his armour, investigating the progress of sappers on the castle walls. Missiles were occasionally shot from the castle walls, but these were given little attention. One defender, in particular, amused the King greatlyâa man standing on the walls, crossbow in one hand, the other clutching a frying pan he had been using all day as a shield to beat off missiles. He deliberately aimed at Richard, which the King applauded; however, another crossbowman then struck Richard in the left shoulder near the neck. He tried to pull this out in the privacy of his tent but failed; a surgeon, called a "butcher" by Howden, removed it, "carelessly mangling" the King's arm in the process.

The wound swiftly became gangrenous. Richard asked to have the crossbowman brought before him; called alternatively Pierre (or Peter) Basile, John Sabroz, Dudo, and Bertrand de Gourdon (from the town of Gourdon) by chroniclers, the man turned out (according to some sources, but not all) to be a boy. He said Richard had killed his father and two brothers, and that he had killed Richard in revenge. He expected to be executed, but as a final act of mercy Richard forgave him, saying "Live on, and by my bounty behold the light of day", before he ordered the boy to be freed and sent away with 100 shillings. It is unclear whether the pardon was upheld following his death. Richard then set his affairs in order, bequeathing all his territory to his brother John and his jewels to his nephew Otto.
Richard died on 6 April 1199 in the arms of his mother, and thus "ended his earthly day". Because of the nature of Richard's death, it was later referred to as "the Lion by the Ant was slain". According to one chronicler, Richard's last act of chivalry proved fruitless when the infamous mercenary captain Mercadier had the crossbowman flayed alive and hanged as soon as Richard died.

Richard's heart was buried at Rouen in Normandy, his entrails in ChÃ¢lus (where he died), and the rest of his body at the feet of his father at Fontevraud Abbey in Anjou. In 2012, scientists analysed the remains of Richard's heart and found that it had been embalmed with various substances, including frankincense, a symbolically important substance because it had been present both at the birth and embalming of the Christ.

Henry Sandford, Bishop of Rochester (1226â1235), announced that he had seen a vision of Richard ascending to Heaven in March 1232 (along with Stephen Langton, the former Archbishop of Canterbury), the King having presumably spent 33 years in purgatory as expiation for his sins.

Richard produced no legitimate heirs and acknowledged only one illegitimate son, Philip of Cognac. As a result, he was succeeded by his brother John as king. However, his French territories initially rejected John as a successor, preferring his nephew Arthur, whose claim was by modern standards better than John's. The lack of any direct heirs from Richard was the first step in the dissolution of the Angevin Empire.

Contemporaries considered Richard as both a king and a knight famed for personal martial prowess; this was, apparently, the first such instance of this combination. He was known as a valiant, competent military leader and individual fighter who was courageous and generous. At the same time, he was considered prone to the sins of lust, pride, greed, and above all excessive cruelty. Ralph of Coggeshall, summarising Richard's career, deplores that the King was one of "the immense cohort of sinners". He was criticised by clergy chroniclers for having taxed the clergy both for the Crusade and for his ransom, whereas the church and the clergy were usually exempt from taxes.

Richard was a patron and a protector of the trouvÃ¨res and troubadours of his entourage; he was also a poet himself. He was interested in writing and music, and two poems are attributed to him. The first one is a sirventes in Old French, "Dalfin je us voill desrenier", and the second one is a lament that he wrote during his imprisonment at DÃ¼rnstein Castle, "Ja nus hons pris", with a version in Old Occitan and a version in Old French.

In the historiography of the second half of the 20th century, much interest was shown in Richard's sexuality, in particular whether there was evidence of homosexuality. The topic had not been raised by Victorian or Edwardian historians, a fact which was itself denounced as a "conspiracy of silence" by John Harvey (1948). The argument primarily drew on accounts of Richard's behaviour, as well as of his confessions and penitences, and of his childless marriage. Richard did have at least one illegitimate child, and there are reports on his sexual relations with local women during his campaigns. Historians remain divided on the question of Richard's sexuality. Harvey argued in favour of his homosexuality but has been disputed by other historians, most notably John Gillingham (1994), who argues that Richard was probably heterosexual. Flori (1999) again argued in favour of Richard's homosexuality, based on Richard's two public confessions and penitences (in 1191 and 1195) which, according to Flori, "must have" referred to the sin of sodomy. Flori, however, concedes that contemporary accounts of Richard taking women by force exist, concluding that he probably had sexual relations with both men and women.
Flori and Gillingham nevertheless agree that accounts of bed-sharing do not support the suggestion that Richard had a sexual relationship with King Philip II, as had been suggested by other modern authors.

The second Great Seal of Richard I (1198) shows him bearing a shield depicting "three lions passant-guardant". This is the first instance of the appearance of this blazon, which later became established as the Royal Arms of England. It is likely, therefore, that Richard introduced this heraldic design. In his earlier Great Seal of 1189, he had used either one "lion rampant" or two "lions rampants combatants", which arms he may have adopted from his father.

Richard is also credited with having originated the English crest of a "lion statant" (now "statant-guardant"). The coat of three lions continues to represent England on several coins of the pound sterling, forms the basis of several emblems of English national sports teams (such as the England national football team, and the team's "Three Lions" anthem), and endures as one of the most recognisable national symbols of England.

Around the middle of the 13th century, various legends developed that, after Richard's capture, his minstrel Blondel travelled Europe from castle to castle, loudly singing a song known only to the two of them (they had composed it together). Eventually, he came to the place where Richard was being held, and Richard heard the song and answered with the appropriate refrain, thus revealing where the King was incarcerated. The story was the basis of AndrÃ© Ernest Modeste GrÃ©try's opera "" and seems to be the inspiration for the opening to Richard Thorpe's film version of "Ivanhoe". It seems unconnected to the real Jean 'Blondel' de Nesle, an aristocratic . It also does not correspond to the historical reality, since the King's jailers did not hide the fact; on the contrary, they publicised it.

At some time around the 16th century, tales of Robin Hood started to mention him as a contemporary and supporter of King Richard the Lionheart, Robin being driven to outlawry, during the misrule of Richard's evil brother John, while Richard was away at the Third Crusade.

Richard's reputation over the years has "fluctuated wildly", according to historian John Gillingham.
While contemporary sources emphasize his stern and unforgiving nature and his excessive cruelty, his image is already transformed into romance, depicting him as generous-hearted ', a few decades after his death.

Richard left an indelible imprint on the imagination extending to the present, in large part because of his military exploits, and his popular image tended to be dominated by the positive qualities of chivalry and military competence. This is reflected in Steven Runciman's final verdict of Richard I: "he was a bad son, a bad husband, and a bad king, but a gallant and splendid soldier" ("History of the Crusades" Vol. III). Meanwhile, Muslim writers during the Crusades period and after wrote of him: "Never have we had to face a bolder or more subtle opponent".

Victorian England was divided on Richard: many admired him as a crusader and man of God, erecting an heroic statue to him outside the Houses of Parliament. The late-Victorian scholar William Stubbs, on the other hand, thought him "a bad son, a bad husband, a selfish ruler, and a vicious man". During his ten years' reign, he was in England for no more than six months, and was totally absent for the last five years. Stubbs argued that:

He was a bad king: his great exploits, his military skill, his splendour and extravagance, his poetical tastes, his adventurous spirit, do not serve to cloak his entire want of sympathy, or even consideration, for his people. He was no Englishman, but it does not follow that he gave to Normandy, Anjou, or Aquitaine the love or care that he denied to his kingdom. His ambition was that of a mere warrior: he would fight for anything whatever, but he would sell everything that was worth fighting for. The glory that he sought was that of victory rather than conquest.

In World War I, when British troops commanded by General Edmund Allenby captured Jerusalem, the British press printed cartoons of Richard looking down from the heavens with the caption reading, "At last my dream has come true". General Allenby protested against his campaign being presented as a latter-day Crusade, however, stating "The importance of Jerusalem lay in its strategic importance, there was no religious impulse in this campaign".





</doc>
<doc id="26369" url="https://en.wikipedia.org/wiki?curid=26369" title="RFPolicy">
RFPolicy

The RFPolicy states a method of contacting vendors about security vulnerabilities found in their products. It was originally written by hacker and security consultant Rain Forest Puppy.

The policy gives the vendor five working days to respond to the reporter of the bug. If the vendor fails to contact the reporter in those five days, the issue is recommended to be disclosed to the general community. The reporter should help the vendor reproduce the bug and work out a fix. The reporter should delay notifying the general community about the bug if the vendor provides feasible reasons for requiring so.

If the vendor fails to respond or shuts down communication with the reporter of the problem in more than five working days, the reporter should disclose the issue to the general community. When issuing an alert or fix, the vendor should give the reporter proper credits about reporting the bug.



</doc>
<doc id="26370" url="https://en.wikipedia.org/wiki?curid=26370" title="Robert Jordan">
Robert Jordan

James Oliver Rigney Jr. (October 17, 1948 â September 16, 2007), better known by his pen name Robert Jordan, was an American author of epic fantasy. He is best known for the "Wheel of Time" series, which was finished by Brandon Sanderson upon Jordan's death, which comprises 14 books and a prequel novel. He is one of several writers to have written original Conan the Barbarian novels; his are highly acclaimed to this day. Rigney also wrote historical fiction under his pseudonym Reagan O'Neal, a western as Jackson O'Reilly, and dance criticism as Chang Lung. Additionally, he ghostwrote an "international thriller" that is still believed to have been written by someone else.

Jordan was born in Charleston, South Carolina. He served two tours in Vietnam (from 1968 to 1970) with the United States Army as a helicopter gunner. He was awarded the Distinguished Flying Cross with oak leaf cluster, the Bronze Star with "V" and oak leaf cluster, and two Vietnamese Gallantry Crosses with palm. After returning from Vietnam he attended The Citadel, where he received an undergraduate degree in physics; after graduating he was employed by the United States Navy as a nuclear engineer. He began writing in 1977.

He was a history buff and enjoyed hunting, fishing, sailing, poker, chess, pool, and pipe-collecting. He described himself as a "High Church" Episcopalian and received communion more than once a week. He lived with his wife, Harriet McDougal, who works as a book editor (currently with Tor Books; she was also Jordan's editor) in a house built in 1797.

On March 23, 2006, Jordan disclosed in a statement that he had been diagnosed with cardiac amyloidosis, and that with treatment, his median life expectancy was four years, though he said he intended to beat the statistics. He later posted on his Dragonmount blog to encourage his fans not to worry about him and announce that he intended to have a long and fully creative life.

He began chemotherapy treatment at Mayo Clinic in Rochester, Minnesota, in early April 2006. Jordan was enrolled in a study using the drug Revlimid just approved for multiple myeloma but not yet tested on primary amyloidosis.

Jordan died at approximately 2:45Â p.m. EDT on September 16, 2007, and his funeral service was held on Wednesday, September 19, 2007. Jordan was cremated and his ashes buried in the churchyard of St. James Church in Goose Creek, outside Charleston, South Carolina.

Jordan's papers can be found at the Special Collections at the College of Charleston.




</doc>
<doc id="26371" url="https://en.wikipedia.org/wiki?curid=26371" title="Ratatoskr">
Ratatoskr

In Norse mythology, Ratatoskr (Old Norse, generally considered to mean "drill-tooth" or "bore-tooth") is a squirrel who runs up and down the world tree Yggdrasil to carry messages between the eagle perched atop Yggdrasil, and the serpent NÃ­Ã°hÃ¶ggr, who dwells beneath one of the three roots of the tree. Ratatoskr is attested in the "Poetic Edda", compiled in the 13th century from earlier traditional sources, and the "Prose Edda", written in the 13th century by Snorri Sturluson. 

The name "Ratatoskr" contains two elements: "rata-" and "-toskr". The element "toskr" is generally held to mean "tusk". GuÃ°brandur VigfÃºsson theorized that the "rati-" element means "the traveller". He says that the name of the legendary drill Rati may feature the same term. According to VigfÃºsson, "Ratatoskr" means "tusk the traveller" or "the climber tusk."

Sophus Bugge theorized that the name "Ratatoskr" is a loanword from Old English meaning "Rat-tooth." Bugge's basis hinges on the fact that the "-toskr" element of the compound does not appear anywhere else in Old Norse. Bugge proposed that the "-toskr" element is a reformation of the Old English word "tÅ«sc" (Old Frisian "tusk") and, in turn, that the element "Rata-" represents Old English "rÃ¦t" ("rat").

According to Albert Sturtevant, "[as] far as the element "Rata-" is concerned, Bugge's hypothesis has no valid foundation in view of the fact that the [Old Norse] word "Rata" (gen. form of "Rati"*) is used in "HÃ¡v[amÃ¡l]" (106, 1) to signify the instrument which Odin employed for "boring" his way through the rocks in quest of the poet's mead [...]" and that ""Rati*" must then be considered a native [Old Norse] word meaning "The Borer, Gnawer" [...]".

Sturtevant says that Bugge's theory regarding the element "-toskr" may appear to be supported by the fact that the word does not appear elsewhere in Old Norse. Sturtevant, however, disagrees. Sturtevant says that the Old Norse proper name "Tunne" (derived from Proto-Norse "*TunÃ¾Ä") refers to "a person who is characterized as having some peculiar sort of "tooth"" and theorizes a Proto-Germanic form of "-toskr". Sturtevant concludes that "the fact that the [Old Norse] word occurs only in the name "Rata-toskr" is no valid evidence against this assumption, for there are many [Old Norse] "hapax legomena" of native origin, as is attested by the equivalents in the Mod[ern] Scandinavian dialects." Modern scholars have accepted this etymology, listing the name "Ratatoskr" as meaning "drill-tooth" (Jesse Byock, Andy Orchard, Rudolf Simek) or "bore-tooth" (John Lindow).

In the "Poetic Edda" poem "GrÃ­mnismÃ¡l", the god Odin (disguised as "GrÃ­mnir") says that Ratatoskr runs up and down Yggdrasil bringing messages between the eagle perched atop it and NÃ­Ã°hÃ¶ggr below it:

Ratatoskr is described in the "Prose Edda"s "Gylfaginning" chapter 16, in which High states that

An eagle sits at the top of the ash, and it has knowledge of many things. Between its eyes sits the hawk called Vedrfolnir [...]. The squirrel called Ratatosk [...] runs up and down the ash. He tells slanderous gossip, provoking the eagle and Nidhogg.

According to Rudolf Simek, "the squirrel probably only represents an embellishing detail to the mythological picture of the world-ash in "GrÃ­mnismÃ¡l". Hilda Ellis Davidson, describing the world tree, states the squirrel is said to gnaw at itâfurthering a continual destruction and re-growth cycle, and posits the tree symbolizes ever-changing existence. John Lindow points out that Yggdrasil is described as rotting on one side and as being chewed on by four harts and NÃ­Ã°hÃ¶ggr, and that, according to the account in "Gylfaginning", it also bears verbal hostility in the fauna it supports. Lindow adds that "in the sagas, a person who helps stir up or keep feuds alive by ferrying words of malice between the participants is seldom one of high status, which may explain the assignment of this role in the mythology to a relatively insignificant animal".

Richard W. Thorington Jr. and Katie Ferrell theorize that "the role of Ratatosk probably derived from the habit of European tree squirrels ("Sciurus vulgaris") to give a scolding alarm call in response to danger. It takes little imagination for you to think that the squirrel is saying nasty things about you."


</doc>
<doc id="26374" url="https://en.wikipedia.org/wiki?curid=26374" title="Reel (dance)">
Reel (dance)

The reel is a folk dance type as well as the accompanying dance tune type. Of Scottish origin, reels are also an important part of the repertoire of the fiddle traditions of the British Isles and North America. In Scottish country dancing, the reel is one of the four traditional dances, the others being the jig, the strathspey and the waltz, and is also the name of a dance figure (see below).
In Irish dance, a reel is any dance danced to music in "reel time" (see below). In Irish stepdance, the reel is danced in soft shoes and is one of the first dances taught to students. There is also a treble reel, danced in hard shoes to reel music.

The reel is indigenous to Scotland. The earliest reference was in a witchcraft trial of 1590, where the accused was reported to have "daunced this reill or short dance." However, the form may go back to the Middle Ages. The name is probably of Old Norse origins, cognate with Suio-Gothic "rulla", meaning "to whirl." This became Anglo-Saxon "hreol" and Gaelic "ruidhle" or "ruidhleadh", which is the origin of the word now.

After being introduced to Ireland in the late eighteenth century it thrived. Later it was introduced to North America by English, Scottish, and Irish colonists and immigrants. In the United States, reels remain central in the traditions Anglo & African American Old-time music and square dancing, as well as Cajun and Zydeco. In Canada, they are important parts of Cape Breton, Acadian, Quebecois, and MÃ©tis repertoires.

Reel music is notated in simple metre, either as or . For example, the same reel "Rakish Paddy" is notated in a time signature in "O'Neill's Music of Ireland, New & Revisited," but in time in "English, Welsh, Scottish & Irish Fiddle Tunes," with no change to the note lengths. 

All reels have the same structure, consisting largely of quaver (eighth note) movement with an accent on the first and third beats of the bar. A reel is distinguished from a hornpipe in two ways. Firstly they are played with even beats, without an implied dotted rhythm. Secondly they are played twice as fast, implied by the time signature. Like most dance music originating in the British Isles, reels are usually composed in binary form, meaning they have two parts (A and B); in most reels each part is repeated (AABB), but in others it is not (ABAB). Each part (A and B) typically has eight bars, which in turn are divisible into four-bar and two-bar phrases. (An exception is the "auld reel" of Shetland which tends to irregular structure and may have been influenced by the Norwegian halling.) The example of Jimmy Shand performing Mairi's Wedding follows the pattern ABABB, giving a pattern of 40 bars. The group of 32 bars (four times eight) is itself repeated three or four times before a second reel is introduced. The grouping of two or more tunes in medleys or "sets" is typical in Celtic dance music. Today many Irish reels are supplemented with new compositions and by tunes from other traditions which are easily adapted as reels. It is the most popular tune-type within the Irish dance music tradition.

Reels are popular in the folk music of South West England. It crossed the Atlantic ocean with Irish and British immigration and thus entered the musical tradition of Atlantic and French-speaking Canada including that of Quebecers and Acadians. Reels are featured in many pieces of Quebec singers and bands; for example: La Bolduc, La Bottine Souriante and even the more modern "nÃ©o-trad" group Les Cowboys Fringants (like the song "Mon Pays suivi du Reel des aristocrates").


</doc>
<doc id="26376" url="https://en.wikipedia.org/wiki?curid=26376" title="Remedy">
Remedy

Remedy, Remedies, The Remedy or Remediation may refer to:











</doc>
<doc id="26377" url="https://en.wikipedia.org/wiki?curid=26377" title="Reichsmarine">
Reichsmarine

The Reichsmarine (, ) was the name of the German Navy during the Weimar Republic and first two years of Nazi Germany. It was the naval branch of the "Reichswehr", existing from 1919 to 1935. In 1935, it became known as the "Kriegsmarine", a branch of the "Wehrmacht"; a change implemented by Adolf Hitler. Many of the administrative and organizational tenets of the "Reichsmarine" were then carried over into the organization of the "Kriegsmarine".

The "VorlÃ¤ufige Reichsmarine" (Provisional Imperial Navy) was formed after the end of World War I from the Imperial German Navy.

The provisions of the Treaty of Versailles restricted the German Navy to 15,000 men and no submarines, while the fleet was limited to six pre-dreadnought battleships, six light cruisers, twelve destroyers, and twelve torpedo boats. Replacements for the outdated battleships were restricted to a maximum size of 10,000 tons.

The "Reichsmarine" was considered the armed naval force of the "Reichswehrministerium" (Ministry of the Reichswehr) which was headed by a civilian minister appointed by the government of the Weimar Republic. The senior most naval officer was known until 1920 as the "Chef der AdmiralitÃ¤t" (Chief of the Admiralty), after which the title changed to the Chief of the Naval Command ("Chef der Marineleitung").

The naval commander oversaw a headquarters office known as the "Marinekommandiertenabteilung" which was headquartered in Berlin. The Naval Command also maintained a headquarters intelligence office ("Marinenachrichtenoffizier") and a naval archives. Internal to the naval headquarters five offices known as the:


The following officers served as head of the "Reichsmarine" from 1918 to 1935



The fleet command of the Reichsmarine ("Flottenkommando") was headquartered at Kiel and consisted of a flag staff and fleet commander embarked on board the flagship of the German fleet. During the 1920s, the German flagship was the "SMS Schleswig-Holstein" with two naval officers serving as fleet commander, "Vizeadmiral" Hans Zenker and Konrad Mommsen, between 1923 and 1927. The fleet commander position was then left vacant, but the flag staff remained.

The purpose of fleet command was to oversee the four major type commanders of German naval vessels. These commands were in turn responsible for the administration of various German ship classes to include equipment development, vessel deployments, and personnel assignment. Once at sea, operational control of the vessels switched to the commanders of the two main Naval Sea Stations. The four type commands were:


The Reichsmarine did not maintain traditional at-sea fleets, but instead assigned two geographical areas (known as "Marinestation") which oversaw all vessels operationally deployed in the North and Baltic Seas. Each naval station maintained a headquarters staff, general naval inspectorate, training department, artillery arsenal inspector, as well as a medical command unit. The naval stations also served as a senior officer for the commanders of the various German navy ports.

Naval stations of the Reichsmarine


The Treaty of Versailles limited the size and armament of the "Reichsmarine" and prevented it from introducing new technologies. The restrictions were intended to prevent the German Navy from becoming a threat to the Allied powers. On the other hand, the Allies had made certain that the "Reichsmarine" would be in the foreseeable future the strongest power in the Baltic Sea, in order to serve as a counterweight against the new Soviet Union, which was viewed with distrust by the Allies.

Germany was only allowed six battleships, six cruisers, twelve destroyers, and twelve torpedo boats. The "Reichsmarine" tried to meet the arms restrictions with secret armament and technical innovations such as the introduction of the pocket battleship.

List of "Reichsmarine" ships:




</doc>
<doc id="26378" url="https://en.wikipedia.org/wiki?curid=26378" title="Rift Valley fever">
Rift Valley fever

Rift Valley fever (RVF) is a viral disease that can cause mild to severe symptoms. The mild symptoms may include: fever, muscle pains, and headaches which often last for up to a week. The severe symptoms may include: loss of sight beginning three weeks after the infection, infections of the brain causing severe headaches and confusion, and bleeding together with liver problems which may occur within the first few days. Those who have bleeding have a chance of death as high as 50%.
The disease is caused by the RVF virus, which is of the "Phlebovirus" type. It is spread by either touching infected animal blood, breathing in the air around an infected animal being butchered, drinking raw milk from an infected animal, or the bite of infected mosquitoes. Animals such as cows, sheep, goats, and camels may be affected. In these animals it is spread mostly by mosquitoes. It does not appear that one person can infect another person. The disease is diagnosed by finding antibodies against the virus or the virus itself in the blood.
Prevention of the disease in humans is accomplished by vaccinating animals against the disease. This must be done before an outbreak occurs because if it is done during an outbreak it may worsen the situation. Stopping the movement of animals during an outbreak may also be useful, as may decreasing mosquito numbers and avoiding their bites. There is a human vaccine; however, as of 2010 it is not widely available. There is no specific treatment and medical efforts are supportive.
Outbreaks of the disease have only occurred in Africa and Arabia. Outbreaks usually occur during periods of increased rain which increase the number of mosquitoes. The disease was first reported among livestock in Rift Valley of Kenya in the early 1900s, and the virus was first isolated in 1931.

In humans, the virus can cause several syndromes. Usually, sufferers have either no symptoms or only a mild illness with fever, headache, muscle pains, and liver abnormalities. In a small percentage of cases (< 2%), the illness can progress to hemorrhagic fever syndrome, meningoencephalitis (inflammation of the brain and tissues lining the brain), or affect the eye. Patients who become ill usually experience fever, generalised weakness, back pain, dizziness, and weight loss at the onset of the illness. Typically, people recover within two to seven days after onset.

About 1% of people with the disease die of it. In livestock, the fatality level is significantly higher. Pregnant livestock infected with RVF abort virtually 100% of foetuses. An epizootic (animal disease epidemic) of RVF is usually first indicated by a wave of unexplained abortions.

Other signs in livestock include vomiting and diarrhoea, respiratory disease, fever, lethargy, anorexia and sudden death in young animals.

The virus belongs to the "Bunyavirales" order. This is an order of enveloped negative single stranded RNA viruses. All Bunyaviruses have an outer lipid envelope with two glycoproteinsâG(N) and G(C)ârequired for cell entry. They deliver their genome into the host-cell cytoplasm by fusing their envelope with an endosomal membrane.

The virus' G(C) protein has a class II membrane fusion protein architecture similar to that found in flaviviruses and alphaviruses. This structural similarity suggests that there may be a common origin for these viral families.

The virus' 11.5 kb tripartite genome is composed of single-stranded RNA. As a "Phlebovirus," it has an ambisense genome. Its L and M segments are negative-sense, but its S segment is ambisense. These three genome segments code for six major proteins: L protein (viral polymerase), the two glycoproteins G(N) and G(C), the nucleocapsid N protein, and the nonstructural NSs and NSm proteins.

The virus is transmitted through mosquito vectors, as well as through contact with the tissue of infected animals. Two speciesâ"Culex tritaeniorhynchus" and "Aedes vexans"âare known to transmit the virus. Other potential vectors include "Aedes caspius", "Aedes mcintosh", "Aedes ochraceus," "Culex pipiens", "Culex antennatus", "Culex perexiguus", "Culex zombaensis" and "Culex quinquefasciatus". Contact with infected tissue is considered to be the main source of human infections. The virus has been isolated from two bat species: the Peter's epauletted fruit bat ("Micropteropus pusillus") and the aba roundleaf bat ("Hipposideros abae"), which are believed to be reservoirs for the virus.

Although many components of the RVFV's RNA play an important role in the virusâ pathology, the nonstructural protein encoded on the S segment (NSs) is the only component that has been found to directly affect the host. NSs is hostile and combative against the hosts interferon (IFNs) antiviral response. IFNs are essential in order for the immune system to fight off viral infections in a host. This inhibitory mechanism is believed to be due to a number of reasons, the first being, competitive inhibition of the formation of the transcription factor. On this transcription factor, NSs interacts with and binds to a subunit that is needed for RNA polymerase I and II. This interaction cause competitive inhibition with another transcription factor component and prevents the assembly process of the transcription factor complex, which results in the suppression of the host antiviral response. Transcription suppression is believed to be another mechanism of this inhibitory process. This occurs when an area of NSs interacts with and binds to the host's protein, SAP30 and forms a complex. This complex causes histone acetylation to regress, which is needed for transcriptional activation of the IFN promoter. This causes IFN expression to be obstructed. Lastly, NSs has also been known to affect regular activity of double-stranded RNA-dependent protein kinase R.. This protein is involved in cellular antiviral responses in the host. When RVFV is able to enter the hosts DNA, NSs forms a filamentous structure in the nucleus. This allows the virus to interact with specific areas of the hosts DNA that relates to segregation defects and induction of chromosome continuity. This increases host infectivity and decreases the host's antiviral response.

Diagnosis relies on viral isolation from tissues, or serological testing with an ELISA. Other methods of diagnosis include Nucleic Acid Testing (NAT), cell culture, and IgM antibody assays. As of September 2016, the Kenya Medical Research Institute (KEMRI) has developed a product called Immunoline, designed to diagnose the disease in humans much faster than in previous methods.

A person's chances of becoming infected can be reduced by taking measures to decrease contact with blood, body fluids, or tissues of infected animals and protection against mosquitoes and other bloodsucking insects. Use of mosquito repellents and bed nets are two effective methods. For persons working with animals in RVF-endemic areas, wearing protective equipment to avoid any exposure to blood or tissues of animals that may potentially be infected is an important protective measure. Potentially, establishing environmental monitoring and case surveillance systems may aid in the prediction and control of future RVF outbreaks.

No vaccines are currently available for humans. While a vaccines have been developed for humans, it has only been used experimentally for scientific personnel in high-risk environments. Trials of a number of vaccines, such as NDBR-103 and TSI-GSD 200, are ongoing. Different types of vaccines for veterinary use are available. The killed vaccines are not practical in routine animal field vaccination because of the need of multiple injections. Live vaccines require a single injection but are known to cause birth defects and abortions in sheep and induce only low-level protection in cattle. The live-attenuated vaccine, MP-12, has demonstrated promising results in laboratory trials in domesticated animals, but more research is needed before the vaccine can be used in the field. The live-attenuated clone 13 vaccine was recently registered and used in South Africa. Alternative vaccines using molecular recombinant constructs are in development and show promising results.

A vaccine has been conditionally approved for use in animals in the US. It has been shown that knockout of the NSs and NSm nonstructural proteins of this virus produces an effective vaccine in sheep as well.

RVF outbreaks occur across sub-Saharan Africa, with outbreaks occurring elsewhere infrequently. In Egypt in 1977â78, an estimated 200,000 people were infected and there were at least 594 deaths.

Outbreaks of this disease usually correspond with the warm phases of the EI NiÃ±o/Southern Oscillation. During this time there is an increase in rainfall, flooding and greenness of vegetation index, which leads to an increase in mosquito vectors. RVFV can be transmitted vertically in mosquitos, meaning that the virus can be passed from the mother to her offspring. During dry conditions, the virus can remain viable for a number of years in the egg. Mosquitos lay their eggs in water, where they eventually hatch. As water is essential for mosquito eggs to hatch, rainfall and flooding cause an increase in the mosquito population and an increased potential for the virus.

In November 2006, a Rift Valley fever outbreak started in Kenya. The cases were from the North Eastern Province and Coast Province of Kenya, which had received heavy rain, causing floods and creating breeding grounds for mosquitoes, which spread the virus of the fever from infected livestock to humans.

By 7 January 2007, about 75 people had died and another 183 were infected. The outbreak forced the closure of livestock markets in the North Eastern Province, affecting the economy of the region.

The outbreak was subsequently reported to have moved into Maragua and Kirinyaga districts of Central Province of Kenya.

On 20 January 2007, the outbreak was reported to have crossed into Somalia from Kenya and killed 14 people in the Lower Jubba region.

As of 23 January 2007, cases had started to crop up at the Kenyan capital, Nairobi. Businesses were suffering large losses, as customers were shunning the common meat joints for the popular "nyama choma" (roast meat), as it was believed to be spreading the fever.

In December 2006 and again in January 2007, Taiwan International Health Action (Taiwan IHA) began operating missions in Kenya consisting of medical experts assisting in training laboratory and health facility personnel, and included donations of supplies, such as mosquito sprays. The United States Centers for Disease Control also set up an assistance mission and laboratory in Kenya.

By the end of January, 2007, some 148 people had died since the outbreak began in December.

On 14 March 2007, the Kenyan government declared RVF cases to be diminished after spending an estimated $2.5 million in vaccine and deployment costs. It also lifted the ban on cattle movement in the affected areas. The final death toll in this outbreak was more than 150 people.

However, on 08 June 2018, the Ministry of Health in Kenya declared another outbreak of RVF.

As of 2 November 2007, 125 cases, including 60 deaths, had been reported from more than 10 localities of White Nile, Sinnar, and Gezira states in Sudan. Young adult males were predominantly affected. More than 25 human samples have been found positive for RVF by PCR or ELISA.

As of 8 April 2010, the Ministry of Health South Africa had reported 87 human cases infected with Rift Valley fever (RVF), including two deaths in Free State, Eastern Cape and Northern Cape provinces. Most of these cases reported direct contact with RVFV-infected livestock and or were linked to farms with confirmed animal cases of RVF. The human cases were among farmers, veterinarians and farm workers. All cases were confirmed with RVF by test conducted at the National Institute of Communicable Diseases (NICD) in Johannesburg, South Africa.

An outbreak of Rift Valley fever virus (RVFV) infection affected sheep, goats, cattle and wildlife on farms within Free State, Eastern Cape, Northern Cape, Western Cape, Mpumalanga, North West, and Gauteng provinces. As of 29 March 2010, about 78 farms reported laboratory-confirmed animal cases, with extensive livestock deaths.

Before the 2010 outbreak, sporadic cases of RVFV infection in animals had been documented in South Africa. The last major outbreak of the disease in humans occurred between 1974 and 1976, where an estimated 10,000 to 20,000 cases were recorded.

On March 2016, a male butcher from Kabale District in western Uganda reported to a local hospital with symptoms of headache, fever, fatigue and bleeding, subsequently testing positive for Rift Valley Fever. CDC sent epidemiologists to the District to assist the Ugandan Ministry of Health with the epidemiologic investigation of this small, localized outbreak of 3 confirmed and 2 probable cases. Working with the Uganda Virus Research Institute (UVRI) and the Uganda Ministry of Health, the CDC team conducted a serologic study in animals and humans and also assessed residentsâ knowledge, attitudes, and practices related to Rift Valley Fever. The team collected samples from cows, goats and sheep, and interviewed and tested 650 district residents. A coordinated educational campaign targeting the general population, farmers, herders, and butchers was initiated and informational posters were created targeting these groups.

As of 16 June 2018, an outbreak of Rift Valley fever is ongoing in northern Kenya, with 26 suspected human cases including 6 deaths in Wajir County (24 cases) and Marsabit County (2 cases); 7 cases have been confirmed. There have also been numerous deaths and abortions in camels, goats and other livestock across a wider area of the country.

As of 3 May 2019, an outbreak is ongoing in the French Mayotte Islands, part of the Comoro group off Mozambique. The first human case showed symptoms on 22 November 2018, and there have been a total of 129 confirmed human cases, as well as more than a hundred foci in livestock. The outbreak has led to restrictions on the sale of uncooked milk, as well as the sale and export of cattle and uncooked meat. WHO noted that mosquito transmission should decrease as the rainy season ends in April, although Cyclone Kenneth has been associated with increased rain.

Rift Valley fever was one of more than a dozen agents that the United States researched as potential biological weapons before the nation suspended its biological weapons program in 1969.

The disease is one of several identified by WHO as a likely cause of a future epidemic in a new plan developed after the Ebola epidemic for urgent research and development toward new diagnostic tests, vaccines and medicines.



</doc>
<doc id="26383" url="https://en.wikipedia.org/wiki?curid=26383" title="Rogue state">
Rogue state

Rogue state or outlaw state is a term applied by some international theorists to states they consider threatening to the world's peace. This means being seen to meet certain criteria, such as being ruled by authoritarian or totalitarian governments that severely restrict human rights, sponsoring terrorism and seeking to proliferate weapons of mass destruction. The term is used most by the United States (though the US State Department officially stopped using the term in 2000), and in his speech at the United Nations (UN) in 2017, Donald Trump reiterated this phrase. However, it has been applied by other countries as well.

As early as July 1985, President Ronald Reagan stated that "we are not going to tolerate â¦ attacks from outlaw states by the strangest collection of misfits, looney tunes, and squalid criminals since the advent of the Third Reich," but it fell to the Clinton administration to elaborate on this concept. In the 1994 issue of "Foreign Affairs", U.S. National Security Advisor Anthony Lake labelled five nations as "rogue states": North Korea, Cuba, Iran, Libya under Muammar Gaddafi, and Ba'athist Iraq. He described these regimes as "recalcitrant and outlaw states that not only choose to remain outside the family [of democratic nations] but also assault its basic values". In theory, to be classified as a "rogue state", a state had to do the following: seek to obtain weapons of mass destruction, support terrorism, and severely abuse its own citizens. While four of the listed countries met all these conditions, Cuba, though known from repressing it citizens and its vocal criticism of the United States, was put on the list solely because of the political influence of the Cuban-American community and specifically that of the Cuban American National Foundation (pre-Jorge Mas Santos), whereas Syria and Pakistan avoided being added to the list because the United States hoped that Damascus could play a constructive role in the Arab-Israeli peace process, and because Washington had long maintained close relations with Islamabadâa vestige of the Cold War.

Three other nations, the Federal Republic of Yugoslavia, Sudan and the Islamic Emirate of Afghanistan, were treated as "rogue states" as well. The US State Department at times labelled Yugoslavia as a "rogue state" because its leader, Slobodan MiloÅ¡eviÄ, had been accused of violating the rights of his nation's citizens, including but not limited to attempted genocide in Croatia and orchestrating the Srebrenica massacre in eastern Bosnia.

The United States employed several tools to isolate and punish "rogue states". Tough unilateral economic sanctions, often at congressional behest, were imposed on or tightened against Iran, Libya, Cuba, Sudan, and Afghanistan. After the conclusion of the Gulf War in 1991, the United States selectively used airpower against Iraq for years during the Iraqi no-fly zones to force them in complying with various United Nations Security Council resolutions regarding disarmament (i.e., Resolution 687) and human rights (i.e., Resolution 688). Cruise missiles were fired at Afghanistan and Sudan in retaliation for terrorist attacks against U.S. embassies in Kenya and Tanzania in August 1998. In March 1999, NATO launched a massive air-bombing campaign against Yugoslavia in response to the Yugoslav Army's crackdown on ethnic Albanian separatists in the province of Kosovo.

In the last six months of the Clinton administration, U.S. Secretary of State Madeleine Albright announced that the term "rogue state" would be abolished in June 2000, in favour of the term "states of concern", as three of the nations listed as "rogue states" (Libya, Iran, and North Korea) no longer met the conditions established to define a "rogue state".

Libya was removed from the State Sponsors of Terrorism list in 2006 after achieving success through diplomacy. Relations with Libya also became more mutual following the eight month Libyan Civil War in 2011, which resulted in the National Transitional Council ousting longtime Libyan leader Muammar Gaddafi from power.

In 2015, after the US reopened its embassy in Cuba and restarted diplomatic relations with the Cuban government, Cuba was removed from the list of State sponsors of terrorism and was no longer referred to as a "rogue state".

More recently, the Donald Trump administration labelled Venezuela a "rogue state" due to its gross human rights violations, economic collapse and rampant excess deaths, anti-American stances and its reported involvement in international drug trafficking. During the 2017 UN general assembly, UN ambassador Nikki Haley called Venezuela a global threat and a "dangerous narco-state". Some figures of the Venezuelan government, like Vice-president Tareck el Aissami and minister of defense Vladimir Padrino LÃ³pez, were permanently banned from entering US territory, due to their involvement with human rights abuses and drug cartels. Later in the year, the US government banned all high ranking Venezuelan government officials from entering US territory. Currently, due to the 2019 Venezuelan presidential crisis, Nicolas Maduro's government (which controls Venezuela "de facto") is not recognized as legitimate by the United States or any other state in the Western Hemisphere, with the exceptions of Nicaragua, Uruguay, and Cuba.

In the aftermath of the September 11 attacks, the Bush administration returned to using a similar term. The concept of "rogue states" was replaced by the Bush administration with the "Axis of Evil" concept (gathering Iraq, Iran, and North Korea). U.S. President George W. Bush first spoke of this "Axis of Evil" during his January 2002 State of the Union Address. More terms, such as "Beyond the Axis of Evil" and "Outposts of Tyranny", would follow suit.

As the U.S. government remains the most active proponent of the expression "rogue state", the term has received much criticism from those who disagree with U.S. foreign policy. Both the concepts of "rogue states" and the "Axis of Evil" have been criticized by certain scholars, including philosopher Jacques Derrida and linguist Noam Chomsky, who considered it more or less a justification of imperialism and a useful word for propaganda. Some critics charge that "rogue state" merely means any state that is generally hostile to the U.S., or even one that opposes the U.S. without necessarily posing a wider threat. Others, such as author William Blum, have written that the term is also applicable to the U.S. and Israel. In his "", Blum makes the case that the United States defines itself as a rogue state through its foreign policy.

In 23 February 1999, Turkish President SÃ¼leyman Demirel described Greece as a "rogue state" because of its alleged support to PKK. Demirel said that: "Greece serves as a sanctuary for members of the PKK seeking shelter and provides training facilities and logistics to the terrorists." 

On June 28, 2012, after the shooting down of a Turkish warplane by the Syrian Army during the Syrian Civil War, Turkish Prime Minister Recep Tayyip ErdoÄan declared Syria to be a "rogue state".

Commentator Robert Ellis, writing in the British newspaper "The Independent" in 2016, wrote that Turkey under President Recep Tayyip Erdogan risks "being regarded as a rogue state" due to its increasingly authoritarian government, the deterioration of the human rights in the country, the Turkish government's involvement in Syria and its alleged support of terrorist groups.





</doc>
<doc id="26384" url="https://en.wikipedia.org/wiki?curid=26384" title="Rebol">
Rebol

Rebol ( ; historically REBOL) is a cross-platform data exchange language and a multi-paradigm dynamic programming language designed by Carl Sassenrath for network communications and distributed computing. It introduces the concept of dialecting: small, optimized, domain-specific languages for code and data, which is also the most notable property of the language according to its designer Carl Sassenrath:

Douglas Crockford, known for his involvement in the development of JavaScript, has described Rebol as "a more modern language, but with some very similar ideas to Lisp, in that it's all built upon a representation of data which is then executable as programs" and as one of JSON's influences.

Originally, the language and its official implementation were proprietary and closed source, developed by REBOL Technologies. Following discussion with Lawrence Rosen, the Rebol version 3 interpreter was released under the Apache 2.0 license on December 12, 2012. Older versions are only available in binary form, and no source release for them is planned.

Rebol has been used to program Internet applications (both client- and server-side), database applications, utilities, and multimedia applications.

Rebol was initially an acronym for Relative Expression Based Object Language written in all caps. To align with modern trends in language naming represented, e.g. by the change replacing historical name "LISP" by "Lisp", programmers ceased the practice of writing "REBOL" in all caps. Sassenrath eventually put the naming question to the community debate on his blog. In subsequent writing, Sassenrath adopted the convention of writing the language name as "Rebol".

First released in 1997, Rebol was designed over a 20-year period by Carl Sassenrath, the architect and primary developer of AmigaOS, based on his study of denotational semantics and using concepts from the programming languages Lisp, Forth, Logo, and Self.


One of the Rebol design principles is "to do simple things in simple ways". In the following example the "Visual interface dialect" is used to describe a simple Hello world program with a graphical user interface:

This is how a similar example looks in R3-GUI:

Rebol domain-specific languages, called "dialects", are micro-languages optimized for a specific purpose. Dialects can be used to define business rules, graphical user interfaces or sequences of screens during the installation of a program. Users can define their own dialects, reusing any existing Rebol word and giving it a specific meaning in that dialect. Dialects are interpreted by functions processing Rebol blocks (or parsing strings) in a specific way.

An example of Rebol's dialecting abilities can be seen with the word codice_1. In the "data exchange dialect" codice_1 is just a word not having any specific meaning. In the "do dialect", codice_1 is a global variable referring to a native function passing back a function result value. In the "visual interface dialect (VID)", codice_1 is a keyword causing the layout engine to simulate a carriage return, moving the "rendering pen" down to the beginning of the next line.

A Rebol interpreter with graphical abilities must understand and interpret many dialects. The table below lists the most important ones in order of significance.
Rebol syntax is free-form, not requiring specific positioning. However, indentation is recommended to better convey the structure of the text to human readers.

Syntactic properties of different dialects may differ. The common platform for all Rebol dialects is the "data exchange dialect"; other dialects are usually derived from it. In addition to being the common platform for all dialects, the "data exchange dialect" is directly used to represent data and metadata, populate data structures, send data over Internet, and save them in data storage.

In contrast to programming languages like C, the "data exchange dialect" does not consist of declarations, statements, expressions or keywords. A valid "data exchange dialect" text stream is a tree data structure consisting of blocks (the root block is implicit, subblocks are delimited by square brackets), parens (delimited by round brackets), strings (delimited by double quotes or curly brackets suitable for multi-line strings; caret notation is used for unprintable characters), URLs, e-mail addresses, files, paths or other composite values. Unlike ALGOL blocks, Rebol blocks are composite values similar to quoted s-expressions in Lisp. The fact that code is written in the form of Rebol blocks makes the language homoiconic.

Blocks as well as parens may contain other composite values (a block may contain subblocks, parens, strings, ...) or scalar values like words, set-words (words suffixed by the colon), get-words (words prefixed by the colon), lit-words (words prefixed by the apostrophe), numbers, money, characters, etc., separated by whitespace. Note that special characters are allowed in words, so codice_5 is a word unlike codice_6, which is a sequence of three words separated by spaces.

Comments may appear following the semicolon until the end of the line. Multi-line comments or comments not ignored by the lexical parser can be written using "ordinary" datatypes like multi-line strings.

Blocks containing domain-specific language can be submitted as arguments to specific "evaluator" functions.

The most frequently used evaluator is the codice_7 function. It is used by default to interpret the text input to the interpreter console.

The "do dialect" interpreted by the codice_7 function, is an expression-oriented sublanguage of the "data exchange dialect". The main semantic unit of the language is the expression. In contrast to imperative programming languages descending from ALGOL, the "do dialect" has neither keywords, nor statements.

Words are used as case-insensitive variables. Like in all dynamically typed languages, variables don't have an associated type, type is associated with values. The result, i.e. the evaluation of a word is returned, when a word is encountered by the codice_7 function. The set-word form of a word can be used for assignment. While not having statements, assignment, together with functions with side-effects can be used for imperative programming.

Subblocks of the root block evaluate to themselves. This property is used to handle data blocks, for structured programming by submitting blocks as arguments to control functions like codice_10, codice_11, codice_12, etc., and for dialecting, when a block is passed to a specific interpreter function.

A specific problem worth noting is that composite values, assigned to variables, are not copied. To make a copy, the value must be passed to the codice_13 function.

The codice_7 function normally follows a prefix style of evaluation, where a function processes the arguments that follow it. However, infix evaluation using infix operators exists too. Infix evaluation takes precedence over the prefix evaluation. For example,
returns 1, since the infix addition takes precedence over the computation of the absolute value. When evaluating infix expressions, the order of evaluation is left to right, no operator takes precedence over another. For example,

returns 20, while an evaluation giving precedence to multiplication would yield 14. All operators have prefix versions. codice_15 usually evaluates arguments before passing them to a function. So, the below expression:

first reads the Wikipedia Rebol page and then passes the result to the codice_16 function. Parentheses can be used to change the order of evaluation. Using prefix notation, the usage of parentheses in expressions can be avoided.

The simple precedence rules are both an advantage:
as well as a disadvantage:

The codice_17 function is preferably used to specify, validate, transform and interpret dialects. It does so by matching "parse expressions" at run time.

"Parse expressions" are written in the "parse dialect", which, like the "do dialect", is an expression-oriented sublanguage of the "data exchange dialect". Unlike the "do dialect", the "parse dialect" uses keywords representing operators and the most important nonterminals, infix parsing operators don't have prefix equivalents and use precedence rules ("sequence" has higher precedence than "choice").

Actions can be included to be taken during the parsing process as well and the codice_17 function can be used to process blocks or strings. At the "string parsing" level codice_17 must handle the "low level" parsing, taking into account characters and delimiters. "Block parsing" is higher level, handling the scanning at the level of Rebol values.

The parse dialect belongs to the family of grammars represented by the top-down parsing language or the parsing expression grammar (PEG). The main similarity is the presence of the "sequence" and "choice" operators all the family members have. Parse dialect syntax and the similarities between the parse dialect and the PEG are illustrated by this transliteration of a PEG example that parses an arithmetic expression:
The official Rebol 2.7.8 implementation is available in several editions ("/Core", "/View", "/Command", "/SDK" and "/IOS"). Both "/Core" and "/View" editions are freely redistributable software.

The runtime environment is stored in a single executable file. "Rebol/Core" 2.7.8, the console edition, is about 300Â KB and "Rebol/View" 2.7.8, the graphical user interface edition, is about 650Â KB in size.

"Rebol/View" provides platform-independent graphics and sound access, and comes with its own windowing toolkit and extensible set of styles (GUI widgets). Extended editions, such as "Rebol/Command" 2.7.8 or "Rebol/SDK" 2.7.8 require a paid license; they add features like ODBC data access, and the option to create standalone executable files.






</doc>
<doc id="26386" url="https://en.wikipedia.org/wiki?curid=26386" title="Red Hat">
Red Hat

Red Hat, Inc. is an American multinational software company providing open source software products to the enterprise community. Founded in 1993, Red Hat has its corporate headquarters in Raleigh, North Carolina, with other offices worldwide. It became a subsidiary of IBM on July 9, 2019.

Red Hat has become associated to a large extent with its enterprise operating system Red Hat Enterprise Linux. With the acquisition of open-source enterprise middleware vendor JBoss, Red Hat also offers Red Hat Virtualization (RHV), an enterprise virtualization product. Red Hat provides storage, operating system platforms, middleware, applications, management products, and support, training, and consulting services.

Red Hat creates, maintains, and contributes to many free software projects. It has acquired several proprietary software product codebases through corporate mergers and acquisitions and has released such software under open source licenses. , Red Hat is the second largest corporate contributor to the Linux kernel version 4.14 after Intel.

On October 28, 2018, IBM announced its intent to acquire Red Hat for $34 billion. The acquisition closed on July 9, 2019. Red Hat's lead financial adviser in the transaction was Guggenheim Securities.

In 1993, Bob Young incorporated the ACC Corporation, a catalog business that sold Linux and Unix software accessories. In 1994, Marc Ewing created his own Linux distribution, which he named Red Hat Linux (Ewing had worn a red Cornell University lacrosse hat, given to him by his grandfather, while attending Carnegie Mellon University). Ewing released the software in October, and it became known as the Halloween release. Young bought Ewing's business in 1995, and the two merged to become Red Hat Software, with Young serving as chief executive officer (CEO).

Red Hat went public on August 11, 1999, achieving the eighth-biggest first-day gain in the history of Wall Street. Matthew Szulik succeeded Bob Young as CEO in December of that year. Bob Young went on to found the online print on demand and self-publishing company, Lulu in 2002.

On November 15, 1999, Red Hat acquired Cygnus Solutions. Cygnus provided commercial support for free software and housed maintainers of GNU software products such as the GNU Debugger and GNU Binutils. One of the founders of Cygnus, Michael Tiemann, became the chief technical officer of Red Hat and the vice president of open-source affairs. Later Red Hat acquired WireSpeed, C2Net and Hell's Kitchen Systems.

In February 2000, "InfoWorld" awarded Red Hat its fourth consecutive "Operating System Product of the Year" award for Red Hat Linux 6.1. Red Hat acquired Planning Technologies, Inc in 2001 and AOL's iPlanet directory and certificate-server software in 2004.

Red Hat moved its headquarters from Durham to North Carolina State University's Centennial Campus in Raleigh, North Carolina in February 2002. In the following month Red Hat introduced Red Hat Linux Advanced Server, later renamed Red Hat Enterprise Linux (RHEL). Dell, IBM, HP and Oracle Corporation announced their support of the platform.

In December 2005, "CIO Insight" magazine conducted its annual "Vendor Value Survey", in which Red Hat ranked #1 in value for the second year in a row. Red Hat stock became part of the NASDAQ-100 on December 19, 2005.

Red Hat acquired open-source middleware provider JBoss on June 5, 2006, and JBoss became a division of Red Hat. On September 18, 2006, Red Hat released the Red Hat Application Stack, which integrated the JBoss technology and which was certified by other well-known software vendors. On December 12, 2006, Red Hat stock moved from trading on NASDAQ (RHAT) to the New York Stock Exchange (RHT). In 2007 Red Hat acquired MetaMatrix and made an agreement with Exadel to distribute its software.

On March 15, 2007, Red Hat released Red Hat Enterprise Linux 5, and in June acquired Mobicents. On March 13, 2008, Red Hat acquired Amentra, a provider of systems integration services for service-oriented architecture, business process management, systems development and enterprise data services.

On July 27, 2009, Red Hat replaced CIT Group in Standard and Poor's 500 stock index, a diversified index of 500 leading companies of the U.S. economy. This was reported as a major milestone for Linux.

On December 15, 2009, it was reported that Red Hat will pay to settle a class action lawsuit related to the restatement of financial results from July 2004. The suit had been pending in U.S. District Court for the Eastern District of North Carolina. Red Hat reached the proposed settlement agreement and recorded a one-time charge of for the quarter that ended Nov. 30.

On January 10, 2011, Red Hat announced that it would expand its headquarters in two phases, adding 540 employees to the Raleigh operation, and investing over . The state of North Carolina is offering up to in incentives. The second phase involves "expansion into new technologies such as software virtualization and technology cloud offerings".

On August 25, 2011, Red Hat announced it would move about 600 employees from the N.C. State Centennial Campus to Two Progress Plaza downtown. A ribbon cutting ceremony was held June 24, 2013, in the re-branded Red Hat Headquarters.

In 2012, Red Hat became the first one-billion dollar open-source company, reaching in annual revenue during its fiscal year. Red Hat passed the $2 billion benchmark in 2015. the company's annual revenue was nearly $3 billion.

On October 16, 2015, Red Hat announced its acquisition of IT automation startup Ansible, rumored for an estimated US$100 million.

On June 2017, Red Hat announced Red Hat Hyperconverged Infrastructure (RHHI) 1.0 software product

In May 2018, Red Hat acquired CoreOS.

On October 28, 2018, IBM announced its intent to acquire Red Hat for US$34 billion, in one of its largest-ever acquisitions. The company will operate out of IBM's Hybrid Cloud division.

Six months later, on May 3, 2019, the US Department of Justice concluded its review of IBM's proposed Red Hat acquisition, and according to Steven J. Vaughan-Nichols "essentially approved the IBM/Red Hat deal". The acquisition was closed on July 9, 2019.

Red Hat sponsors the Fedora Project, a community-supported free software project that aims to promote the rapid progress of free and open-source software and content. Fedora aims for rapid innovation using open processes and public forums.

The Fedora Project Board, which comprises community leaders and representatives of Red Hat, leads the project and steers the direction of the project and of Fedora, the Linux distribution it develops. Red Hat employees work with the code alongside community members, and many innovations within the Fedora Project make their way into new releases of Red Hat Enterprise Linux.

Red Hat operates on a professional open-source business model based on open-source software, development within a community, professional quality assurance, and subscription-based customer support. They produce open-source code so that more programmers can make adaptations and improvements.

Red Hat sells subscriptions for the support, training, and integration services that help customers in using their open-source software products. Customers pay one set price for unlimited access to services such as Red Hat Network and up to 24/7 support.

In September 2014, however, CEO Jim Whitehurst announced that Red Hat was "in the midst of a major shift from client-server to cloud-mobile".

Rich Bynum, a member of Red Hat's legal team, attributes Linux's success and rapid development partially to open-source business models, including Red Hat's.

Red Hat engineers worked with the One Laptop per Child initiative (a non-profit organization established by members of the MIT Media Lab) to design and produce an inexpensive laptop and try to provide every child in the world with access to open communication, open knowledge, and open learning. The XO-4 laptop, the machine of this project, runs a slimmed-down version of Fedora 17 as its operating system.

Red Hat is the largest contributor to the GNOME desktop environment. It has several employees working full-time on Evolution, the official personal information manager for GNOME.

Dogtail, an open-source automated graphical user interface (GUI) test framework initially developed by Red Hat, consists of free software released under the GNU General Public License (GPL) and is written in Python. It allows developers to build and test their applications. Red Hat announced the release of Dogtail at the 2006 Red Hat Summit.

Red Hat MRG is a clustering product intended for integrated high-performance computing (HPC). The acronym MRG stands for "Messaging Realtime Grid".

Red Hat Enterprise MRG replaces the Red Hat Enterprise Linux RHEL, a Linux distribution developed by Red Hat, kernel in order to provide extra support for real-time computing, together with middleware support for message brokerage and scheduling workload to local or remote virtual machines, grid computing, and cloud computing.

, Red Hat works with the Condor High-Throughput Computing System community and also provides support for the software.

The Tuna performance-monitoring tool runs in the MRG environment.

Red Hat produces the online publication Opensource.com since January 20, 2010. The site highlights ways open-source principles apply in domains other than software development. The site tracks the application of open-source philosophy to business, education, government, law, health, and life.

The company originally produced a newsletter called Under the Brim. Wide Open magazine first appeared in March 2004, as a means for Red Hat to share technical content with subscribers on a regular basis. The Under the Brim newsletter and Wide Open magazine merged in November 2004, to become "Red Hat Magazine". In January 2010, "Red Hat Magazine" became Opensource.com.

In 2007, Red Hat announced that it had reached an agreement with some free software and open-source (FOSS) companies that allowed it to make a distribution portal called Red Hat Exchange, reselling FOSS software with the original branding intact. However, by 2010, Red Hat had abandoned the Exchange program to focus their efforts more on their Open Source Channel Alliance which began in April 2009.

Red Hat Single Sign On is a software product to allow single sign-on with Identity Management and Access Management aimed at modern applications and services. There is an ongoing Open source project alongside Red Hat SSO, that is Keycloak. Keycloak is basically the community version from Red Hat SSO. Red Hat Single Sign On 7.3 is the latest version available.

Red Hat Subscription Management (RHSM) combines content delivery with subscription management.

Red Hat operates OpenShift, a cloud computing platform as a service, supporting applications written in Node.js, PHP, Perl, Python, Ruby, JavaEE and more.

On July 31, 2018, Red Hat announced the release of Istio 1.0, a microservices management program used in tandem with the Kubernetes platform. The software purports to provide "traffic management, service identity and security, policy enforcement and telemetry" services in order to streamline Kubernetes use under the various Fedora-based operating systems. Red Hat's Brian Redbeard Harring described Istio as "aiming to be a control plane, similar to the Kubernetes control plane, for configuring a series of proxy servers that get injected between application components".

Red Hat markets a version of OpenStack which helps manage a data center in the manner of cloud computing.

Red Hat CloudForms provides management of virtual machines, instances and containers based on VMware vSphere, Red Hat Virtualization, Microsoft Hyper-V, OpenStack, Amazon EC2, Google Cloud Platform, Microsoft Azure, and Red Hat OpenShift. CloudForms is based on the ManageIQ project that Red Hat open sourced. Code in ManageIQ is from the over acquisition of ManageIQ in 2012.

Red Hat contributes, with several software developers, to LibreOffice, a free and open-source office suite.

Red Hat has some employees working full-time on other free and open-source software projects that are not Red Hat products, such as two full-time employees working on the free software "radeon" (David Airlie and Jerome Glisse) and one full-time employee working on the free software "nouveau" graphic drivers. Another such project is AeroGear, an open-source project that brings security and development expertise to cross-platform enterprise mobile development.

Red Hat also organises "Open Source Day" events where multiple partners show their open-source technologies.

Subscribers have access to:

Over and above Red Hat's major products and acquisitions, Red Hat programmers have produced software programming-tools and utilities to supplement standard Unix and Linux software. Some of these Red Hat "products" have found their way from specifically Red Hat operating environments via open-source channels to a wider community. Such utilities include:

The Red Hat website lists the organization's major involvements in free and open-source software projects.

Community projects under the aegis of Red Hat include:

In 2000, Red Hat created the subsidiary Red Hat India to deliver Red Hat software, support, and services to Indian customers. Colin Tenwick, vice president and general manager of Red Hat EMEA said Red Hat India was opened "in response to the rapid adoption of Red Hat Linux in the subcontinent. Demand for open-source solutions from the Indian markets is rising and Red Hat wants to play a major role in this region." Red Hat India has worked with local companies to enable adoption of open-source technology in both government and education.

In 2006, Red Hat India had a distribution network of more than 70 channel partners spanning 27 cities across India. Red Hat India's channel partners included MarkCraft Solutions, Ashtech Infotech Pvt Ltd, Efensys Technologies, Embee Software, Allied Digital Services, and Softcell Technologies. Distributors include Integra Micro Systems and Ingram Micro.

Red Hat's first major acquisition involved Delix Computer GmbH-Linux Div, the Linux-based operating-system division of Delix Computer, a German computer company, on July 30, 1999.

Red Hat acquired Cygnus Solutions, a company that provided commercial support for free software, on January 11, 2000 â it was the company's largest acquisition, for . Michael Tiemann, co-founder of Cygnus, served as the chief technical officer of Red Hat after the acquisition. Red Hat made the most acquisitions in 2000 with five: Cygnus Solutions, Bluecurve, Wirespeed Communications, Hell's Kitchen Systems, and C2Net. On June 5, 2006, Red Hat acquired open-source middleware provider JBoss for and integrated it as its own division of Red Hat.

On December 14, 1998, Red Hat made its first divestment, when Intel and Netscape acquired undisclosed minority stakes in the company. The next year, on March 9, 1999, Compaq, IBM, Dell and Novell each acquired undisclosed minority stakes in Red Hat.



</doc>
<doc id="26388" url="https://en.wikipedia.org/wiki?curid=26388" title="Reno, Nevada">
Reno, Nevada

Reno ( ) is a city in the northwest section of the U.S. state of Nevada, approximately from Lake Tahoe, known as "The Biggest Little City in the World". Known for its casino & tourism industry, Reno is the county seat and largest city of Washoe County and sits in a high desert river valley at the foot of the Sierra Nevada and its downtown area (along with Sparks) occupies a valley informally known as the Truckee Meadows, which due to large-scale investments from Seattle & Bay Area, such as Amazon, Tesla, Panasonic, Microsoft, Apple and many more (most recently Google) has become a new major technology hub in the United States. The city is named after Union Major General Jesse L. Reno, who was killed in action during the American Civil War at the Battle of South Mountain on Fox's Gap.

Reno is part of the RenoâSparks metropolitan area, 2nd most populous in Nevada after Las Vegas-Henderson, both of which are part of the Las Vegas Valley. Greater Reno, which consists of Washoe, Storey, and Lyon counties plus Carson City (the capital of Nevada), is the second largest metropolitan area in Nevada.

Archaeological finds place the eastern border for the prehistoric Martis people in the Reno area. As early as the mid 1850s a few pioneers settled in the Truckee Meadows, a relatively fertile valley through which the Truckee River made its way from Lake Tahoe to Pyramid Lake. In addition to subsistence farming, these early residents could pick up business from travelers along the California Trail, which followed the Truckee westward, before branching off towards Donner Lake, where the formidable obstacle of the Sierra Nevada began.

Gold was discovered in the vicinity of Virginia City in 1850, and a modest mining community developed, but the discovery of silver in 1859 at the Comstock Lode led to a mining rush, and thousands of emigrants left their homes, bound for the West, hoping to find a fortune.
To provide the necessary connection between Virginia City and the California Trail, Charles W. Fuller built a log toll bridge across the Truckee River in 1859. A small community that would service travelers soon grew near the bridge. After two years, Fuller sold the bridge to Myron C. Lake, who continued to develop the community by adding a grist mill, kiln, and livery stable to the hotel and eating house. He renamed it "Lake's Crossing". Most of what is present-day western Nevada was formed as the Nevada Territory from part of Utah Territory in 1861.

By January 1863, the Central Pacific Railroad (CPRR) had begun laying tracks east from Sacramento, California, eventually connecting with the Union Pacific Railroad at Promontory, Utah, to form the First Transcontinental Railroad. Lake deeded land to the CPRR in exchange for its promise to build a depot at Lake's Crossing. In 1864, Washoe County was consolidated with Roop County, and Lake's Crossing became the county's largest town. Lake had earned himself the title "founder of Reno". Once the railroad station was established, the town of Reno officially came into being on May 9, 1868. CPRR construction superintendent Charles Crocker named the community after Major General Jesse Lee Reno, a Union officer killed in the American Civil War at the Battle of South Mountain.

In 1871, Reno became the county seat of the newly expanded Washoe County, replacing the county seat in Washoe City. However, political power in Nevada remained with the mining communities, first Virginia City and later Tonopah and Goldfield.

The extension of the Virginia and Truckee Railroad to Reno in 1872 provided a boost to the new city's economy. In the following decades, Reno continued to grow and prosper as a business and agricultural center and became the principal settlement on the transcontinental railroad between Sacramento and Salt Lake City.
As the mining boom waned early in the 20th century, Nevada's centers of political and business activity shifted to the non-mining communities, especially Reno and Las Vegas, and today the former mining metropolises stand as little more than ghost towns. Despite this, Nevada is still the third-largest gold producer in the world, after South Africa and Australia; the state yielded 6.9 percent of the world's supply in 2005 world gold production.

The "Reno Arch" was erected on Virginia Street in 1926 to promote the upcoming Transcontinental Highways Exposition of 1927. The arch included the words "Nevada's Transcontinental Highways Exposition" and the dates of the exposition. After the exposition, the Reno City Council decided to keep the arch as a permanent downtown gateway, and Mayor E.E. Roberts asked the citizens of Reno to suggest a slogan for the arch. No acceptable slogan was received until a $100 prize was offered, and G.A. Burns of Sacramento was declared the winner on March 14, 1929, with "Reno, The Biggest Little City in the World".

Reno took a leap when the state of Nevada legalized open-gambling on March 19, 1931, along with the passage of even more liberal divorce laws than places like Hot Springs, Arkansas, offered. No other state offered what Nevada had in the 1930s, and casinos like the Bank Club and Palace were popular.

Within a few years, the Bank Club, owned by George Wingfield, Bill Graham, and Jim McKay, was the state's largest employer and the largest casino in the world. Wingfield owned most of the buildings in town that housed gaming and took a percentage of the profits, along with his rent.

Ernie Pyle once wrote in one of his columns, "All the people you saw on the streets in Reno were obviously there to get divorces." In Ayn Rand's novel "The Fountainhead", published in 1943, the New York-based female protagonist tells a friend, "I am going to Reno," which is taken as a different way of saying "I am going to divorce my husband." Among others, the Belgian-French writer Georges Simenon, at the time living in the U.S., came to Reno in 1950 in order to divorce his first wife.
The divorce business eventually died as the other states fell in line by passing their own laws easing the requirements for divorce, but gambling continued as a major Reno industry. While gaming pioneers like "Pappy" and Harold Smith of Harold's Club and Bill Harrah of the soon-to-dominate Harrah's casino set up shop in the 1930s, the war years of the 1940s cemented Reno as the place to play for two decades. Beginning in the 1950s, the need for economic diversification beyond gaming fueled a movement for more lenient business taxation.

A disaster occurred on the afternoon of February 5, 1957, when an explosion ripped through the heart of downtown. At 1:03Â pm, two explosions, caused by natural gas leaking into the maze of pipes and ditches under the city, and an ensuing fire destroyed five buildings in the vicinity of Sierra and First streets along the Truckee River. The disaster killed two people and injured forty-nine. The first explosion hit under the block of shops on the west side of Sierra Street (now the site of the Century Riverside), the second, across Sierra Street, now the site of the Palladio.

The presence of a main east-west rail line, the emerging interstate highway system, favorable state tax climate, and relatively inexpensive land created good conditions for warehousing and distribution of goods.

In the 1980s, Indian gaming rules were relaxed, and starting in 2000, Californian Native casinos began to cut into casino revenues. Major new construction projects have been completed in the Reno and Sparks areas. A few new luxury communities were recently built in Truckee, California, approximately west of Reno on Interstate 80. Reno also is an outdoor recreation destination, due to its close proximity to the Sierra Nevada, Lake Tahoe, and numerous ski resorts in the region.

Wetlands are an important part of the Reno/Tahoe area. They act as a natural filter for the solids that come out of the water treatment plant. Plant roots absorb nutrients from the water and naturally filter it. Wetlands are home to over 75% of the species in the Great Basin. However, the area's wetlands are at risk of being destroyed due to development around the city. While developers build on top of the wetlands they fill them with dirt, destroying the habitat they create for the plants and animals. Washoe County has devised a plan that will help protect these ecosystems: mitigation. In the future, when developers try to build over a wetland, they will be responsible for creating another wetland near Washoe Lake.

The Truckee River is Reno's primary source of drinking water. It supplies Reno with of water a day during the summer, and of water per day in the winter. Before the water goes to the homes around the Reno area, it must go to one of two water treatment plants, Chalk Bluff or Glendale Water Treatment Plant. To help save water, golf courses in Reno have been using treated effluent water rather than treated water from one of Reno's water plants.

The Reno-Sparks wastewater treatment plant discharges tertiary treated effluent to the Truckee River. In the 1990s this capacity was increased from 20 to 30Â million U.S. gallons (70 to 110Â million liters) per day. While treated, the effluent contains suspended solids, nitrogen, and phosphorus, aggravating water quality concerns of the river and its receiving waters of Pyramid Lake. Local agencies working with the Environmental Protection Agency have developed several watershed management strategies to accommodate this expanded discharge. To accomplish this successful outcome, the DSSAM Model was developed and calibrated for the Truckee River to analyze the most cost-effective available management strategy set. The resulting management strategies included measures such as land use controls in the Lake Tahoe basin, urban runoff controls in Reno and Sparks, and best management practices for wastewater discharge.

The Reno area is often subject to wildfires that cause property damage and sometimes loss of life. In August 1960, the Donner Ridge fire resulted in a loss of electricity to the city for four days. In November 2011, arcing from powerlines caused a fire in Caughlin in southwest Reno that destroyed 26 homes and killed one man. Just two months later, in January 2012, a fire in Washoe Drive sparked by fireplace ashes destroyed 29 homes and killed one woman. Around 10,000 residents were evacuated, and a state of emergency was declared. The fires came at the end of Reno's longest recorded dry spell.

Reno is just east of the Sierra Nevada on the western edge of the Great Basin at an elevation of about above sea level. Numerous faults exist throughout the region. Most of these are normal (vertical motion) faults associated with the uplift of the various mountain ranges, including the Sierra Nevada.

In February 2008, an earthquake swarm began to occur, lasting for several months, and with the largest quake registering at 4.9 on the Richter magnitude scale, although some geologic estimates put it at 5.0. The earthquakes were centered on the Somersett community in western Reno near Mogul and Verdi. Many homes in these areas were damaged.

Reno sits in the rain shadow of the Sierra Nevada mountain range. Annual rainfall averages . Reno features a semi-arid climate (KÃ¶ppen: "BSk)" due to its low evapotranspiration. The city experiences cool to cold winters, and hot summers. Annual precipitation has ranged from in 1947 to in 1983. The most precipitation in one month was in December 1955 and the most precipitation in 24 hours was on January 21, 1943. Winter has snowfall which is usually light to moderate but can be heavy some days, averaging annually. Snowfall varies with the lowest amounts (roughly 19â23Â inches annually) at the lowest part of the valley at and east of the RenoâTahoe International Airport at , while the foothills of the Carson Range to the west ranging from in elevation just a few miles west of downtown can receive up to two to three times as much annual snowfall. The mountains of the Virginia Range to the east can receive more summer thunderstorms and precipitation, and around twice as much annual snowfall above . However, snowfall increases in the Virginia Range are less dramatic as elevation climbs than in the Carson Range to the west, because the Virginia Range is well within the rain shadow of the Sierra Nevada and Carson Range. The most snowfall in the city in one year was in 1971, and the most snowfall in one month was in March 1952.

Most rainfall occurs in winter and spring. The city has 300 days of sunshine per year. Summer thunderstorms can occur between April and October. The eastern side of town and the mountains east of Reno tend to be prone to thunderstorms more often, and these storms may be severe because an afternoon downslope west wind, called a "Washoe Zephyr", can develop in the Sierra Nevada, causing air to be pulled down in the Sierra Nevada and Reno, destroying or preventing thunderstorms, but the same wind can push air upward against the Virginia Range and other mountain ranges east of Reno, creating powerful thunderstorms.

The monthly daily average temperature ranges from in December to in July, with the diurnal temperature variation reaching in summer, still lower than much of the high desert to the east. There are 3.9 days of + highs, 58 days of + highs, and 2.5 nights with sub- lows annually; the temperature does not rise above freezing on only 5.1 days. The all-time record high temperature is , which occurred on July 10 and 11, 2002, and again on July 5, 2007. The all-time record low temperature is , which occurred on January 21, 1916. In addition, the region is windy throughout the year; observers such as Mark Twain have commented about the "Washoe Zephyr", northwestern Nevada's distinctive wind.

As of the census of 2010, there were 225,221 people, 90,924 households, and 51,112 families residing in the city. The population density was 2,186.6 per square mile (844.2/kmÂ²). There were 102,582 housing units at an average density of 995.9 per square mile (384.5/kmÂ²). The city's racial makeup was 74.2% White, 2.9% African American, 1.3% Native American, 6.3% Asian, 0.7% Pacific Islander, 10.5% some other race, and 4.2% from two or more races. Hispanic or Latino of any race were 24.3% of the population. Non-Hispanic Whites were 62.5% of the population in 2010, down from 88.5% in 1980.
At the 2010 census, there were 90,924 households, of which 29.8% had children under the age of 18 living with them, 38.4% were headed by married couples living together, 11.8% had a female householder with no husband present, and 43.8% were non-families. 32.1% of all households were made up of individuals, and 9.7% were someone living alone who was 65 years of age or older. The average household size was 2.43, and the average family size was 3.10.

In the city, the 2010 population was spread out with 22.8% under the age of 18, 12.5% from 18 to 24, 28.2% from 25 to 44, 24.9% from 45 to 64, and 11.7% who were 65 years of age or older. The median age was 34.6 years. For every 100 females, there were 103.4 males. For every 100 females age 18 and over, there were 102.7 males.

In 2011 the city's estimated median household income was $44,846, and the median family income was $53,896. Males had a median income of $42,120 versus $31,362 for females. The city's per capita income was $25,041. About 9.6% of families and 14.4% of the population were below the poverty line, including 15.1% of those under age 18 and 12.8% of those age 65 or over. The population was 180,480 at the 2000 census; in 2010, its population had risen to 225,221, making it the third-largest city in the state after Las Vegas and Henderson, and the largest outside Clark County. Reno lies north of the Nevada state capital, Carson City, and northeast of Lake Tahoe in a shrub-steppe environment. Reno shares its eastern border with the city of Sparks and is the larger of the principal cities of the RenoâSparks, Nevada Metropolitan Statistical Area (MSA), a metropolitan area that covers Storey and Washoe counties. The MSA had a combined population of 425,417 at the 2010 census. The MSA is combined with the Fernley Micropolitan Statistical Area and the Carson City MSA to form the Reno-Carson City-Fernley Combined Statistical Area, which had a population of 477,397 at the 2010 census.

Before the late 1950s, Reno was the gambling capital of the United States, but Las Vegas' rapid growth, American Airlines' 2000 buyout of Reno Air, and the growth of Native American gaming in California have reduced its business. Older casinos were torn down (Mapes Hotel, Fitzgerald's Nevada Club, Primadonna, Horseshoe Club, Harold's Club, Palace Club), or smaller casinos like the Comstock, Sundowner, Golden Phoenix, Kings Inn, Money Tree, Virginian, and Riverboat were either closed or were converted into condos.

Because of its location, Reno has traditionally drawn the majority of its California tourists and gamblers from the San Francisco Bay Area and Sacramento, while Las Vegas has historically served more tourists from Southern California and the Phoenix area.

Several local large hotel casinos have shown significant growth and have moved gaming further away from the downtown core. These larger hotel casinos are the Atlantis, the Peppermill and the Grand Sierra Resort. The Peppermill was chosen as the most outstanding Reno gaming/hotel property by "Casino Player" and "Nevada" magazines. In 2005, the Peppermill Reno began a $300Â million Tuscan-themed expansion.

Reno holds several events throughout the year to draw tourists to the area. They include Hot August Nights (a classic car convention), Street Vibrations (a motorcycle fan gathering and rally), The Great Reno Balloon Race, a Cinco de Mayo celebration, bowling tournaments (held in the National Bowling Stadium), and the Reno Air Races.

Several large commercial developments were constructed during the mid-2000s boom, such as The Summit in 2007 and Legends at Sparks Marina in 2008.

Reno is the location of the corporate headquarters for several companies, including Braeburn Capital, Hamilton, Server Technology, EE Technologies, and Port of Subs. International Game Technology, Bally Technologies and GameTech have a development and manufacturing presence.

Since the turn of the 21st century, greater Reno saw an influx of technology companies entering the area, following major initiatives and investments by investors from Seattle & the Bay Area. After the Great Recession, the state placed an increased focus on economic development. Thousands of new jobs were created.

Tesla's Gigafactory is at the Tahoe Reno Industrial Center, and it is the largest building in the world. The Gigafactory purportedly covers 5.8 million square feet.

The arrival of several data centers at the Tahoe Reno Industrial Center is further diversifying a region that was best known for distribution and logistics outside gaming and tourism. Switch 's new SuperNAP campus at the Tahoe Reno Industrial Center is shaping up to be the largest data center in the world once completed. Apple is expanding its data center at the adjacent Reno Technology Park and recently built a warehouse on land in downtown Reno. Rackspace is also building a $422 million data center next to Apple.

The greater Reno area also hosts distribution facilities for Amazon, Walmart, Petsmart and Zulily.

According to Reno's 2016 Comprehensive Annual Financial Report, the top employers in the city are:

Reno has several museums. The Nevada Museum of Art is the only American Alliance of Museums (AAM) accredited art museum in Nevada. The National Automobile Museum contains 200 cars that were from the collection of William F. Harrah, including Elvis Presley's 1973 Cadillac Eldorado.

Reno also hosts a number of music venues, such as the Nevada Opera, the Pioneer Center for the Performing Arts, the Reno Philharmonic Orchestra, and the Reno Pops Orchestra. The Reno Youth Symphony Orchestra (YSO), affiliated with the Reno Philharmonic, gives talented youth the opportunity to play advanced music and perform nationwide. In 2016 they had the honor of performing at Carnegie Hall.

Reno has a public library, a branch of the Washoe County Library System. The Downtown branch of the Washoe County Library was listed on the National Register of Historic Places in 2013.

Reno is home to the Reno Aces, the minor league baseball Triple-A affiliate of the Arizona Diamondbacks, playing in Greater Nevada Field, a downtown ballpark opened in 2009. Reno has hosted multiple professional baseball teams in the past, most under the Reno Silver Sox name. The Reno Astros, a former professional, unaffiliated baseball team, played at Moana Stadium until 2009.

In basketball, the Reno Bighorns of the NBA G League played at the Reno Events Center from 2008 to 2018. They were primarily an affiliate of the Sacramento Kings throughout its existence. The Sacramento Kings bought the team in 2016 and moved the franchise to become the Stockton Kings in 2018.

Reno is host to both amateur and professional combat sporting events such as mixed martial arts and boxing. The "Fight of the Century" between Jack Johnson and James J. Jeffries was held in Reno in 1910. Boxer Ray Mancini fought four of his last five fights in Reno against Bobby Chacon, Livingstone Bramble, Hector Camacho, and Greg Haugen.

Reno expected to be the future home of an ECHL ice hockey team, named the Reno Raiders, but construction on a suitable arena never began. The franchise was dormant since 1998, when it was named the Reno Rage, and earlier the Reno Renegades, and played in the now-defunct West Coast Hockey League (WCHL). In 2016, Reno was removed from the ECHL's Future Markets page.

The RenoâTahoe Open is northern Nevada's only PGA Tour event, held at MontrÃªux Golf & Country Club in Reno. As part of the FedEx Cup, the tournament follows 132 PGA Tour professionals competing for a share of the event's $3Â million purse. The Reno-Tahoe Open Foundation has donated more than $1.8Â million to local charities.

Reno has a college sports scene, with the Nevada Wolf Pack appearing in football bowl games and an Associated Press and Coaches Poll Top Ten ranking in basketball in 2018.
In 2004, the city completed a $1.5Â million whitewater park on the Truckee River in downtown Reno which hosts whitewater events throughout the year. The course runs Class 2 and 3 rapids with year-round public access. The north channel features more aggressive rapids, drop pools and "holes" for rodeo kayak-type maneuvers. The milder south channel is set up as a kayak slalom course and a beginner area.

Reno is home to two roller derby teams, the Battle Born Derby Demons and the Reno Roller Girls. The Battle Born Derby Demons compete on flat tracks locally and nationally. They are the only derby team locally to compete in a national Derby league.

Reno is the home of the National Bowling Stadium, which hosts the United States Bowling Congress (USBC) Open Championships every three years.

Reno is home to a variety of recreation activities including both seasonal and year-round. In the summer, Reno locals can be found near three major bodies of water: Lake Tahoe, the Truckee River, and Pyramid Lake. The Truckee River originates at Lake Tahoe and flows west to east through the center of downtown Reno before terminating at Pyramid Lake to the north. The river is a major part of Artown, held in the summer at Wingfield Park. Washoe Lake is a popular kite and windsurfing location because of its high wind speeds during the summer.

Skiing and snowboarding are among the most popular winter sports and draw many tourists. There are 18 ski resorts (8 major resorts) as close as and as far as from the RenoâTahoe International Airport, including Northstar California, Sierra-at-Tahoe, Alpine Meadows, Squaw Valley, Sugar Bowl, Diamond Peak, Heavenly Mountain, and Mount Rose. Other popular Reno winter activities include snowshoeing, ice skating, and snowmobiling. There are many bike paths to ride in the summer time. Lake Tahoe hosts international bike competitions each summer.

The Reno Air Races, also known as the National Championship Air Races, are held each September at the Reno Stead Airport.

Reno has a democratic municipal government. The city council is the core of the government, with seven members. Five of these council people represent districts of Reno, and are vetted in the primary by the citizens of each district. In general, the top two vote earners in each ward make the ballot for the citywide election. The other two council members are the at-large member, who represents the entire city, and the mayor, who is elected by the people of the city. The council has several duties, including setting priorities for the city, promoting communication with the public, planning development, and redevelopment.

There is an elected city attorney who is responsible for civil and criminal cases. The City Attorney represents the city government in court, and prosecutes misdemeanors.

The city's charter calls for a council-manager form of government, meaning the council appoints only two positions, the city manager, who implements and enforces the policies and programs the council approves, and the city clerk. The city manager is in charge of the budget and workforce for all city programs. The city clerk, who records the proceedings of the council, makes appointments for the council, and makes sure efficient copying and printing services are available.

In 2010, there was a ballot question asking whether the Reno city government and the Washoe County government should explore the idea of becoming one combined governmental body. Fifty-fourÂ percent of voters approved of the ballot measure to make an inquiry into consolidating the governments.

The city of Reno is protected by the Reno Fire Department (RFD) manning 14 fire stations.

The Reno Fire Department (RFD) provides all-risk emergency service to the City of Reno residents. All-risk emergency service is the national model of municipal fire departments, providing the services needed in the most efficient way possible.

The department provides paramedic-level service to the citizens and visitors of Reno. This is the highest level of emergency medical care available in the field.

In addition to responding to fires, whether they occur in structures, vegetation/brush or vehicles, the fire department also provides rescue capabilities for almost any type of emergency situation.

This includes quick and efficient emergency medical care for the citizens; a hazardous materials team capable of identifying unknown materials and controlling a release disaster; and preparedness and management of large-scale incidents.

Maintaining this level of service requires nearly constant training of personnel. This training maintains both the skills needed to operate safely in emergency environments and the physical fitness necessary to reduce the likelihood and severity of injuries.

The minimum annual-training requirement to maintain firefighting and medical skills is 240 hours per year. Special teams and company-level drills add significantly to that number of hours.


Public education is provided by the Washoe County School District.

Reno has many charter schools, which include Academy for Career Education, serving grades 10â12, opened 2002; Alpine Academy Charter High School, serving grades 9â12, opened 2009; Bailey Charter Elementary School, serving grades K-6, opened 2001; Coral Academy of Science, serving grades K-12; Davidson Academy, serving grades 6â12, opened 2006; High Desert Montessori School, serving grades PreK-7, opened 2002; I Can Do Anything Charter School, serving grades 9â12, opened 2000; Rainshadow Community Charter High School, serving grades 9â12, opened 2003; Sierra Nevada Academy Charter School, serving grades PreK-8, opened 1999; and TEAM A (Together Everyone Achieves More Academy), serving grades 9â12, opened 2004.

Reno has a few private elementary schools such as Legacy Christian School, Excel Christian School, St. Nicholas Orthodox Academy, Lamplight Christian School, and Nevada Sage Waldorf School as well as private high schools, the largest of which are Bishop Manogue High School and Sage Ridge School.

Reno was historically served by the Victory Highway and a branch of the Lincoln Highway. After the formation of the U.S. Numbered Highways system, U.S. Route 40 was routed along 4th Street through downtown Reno, before being replaced by Interstate 80. The primary north-south highway through Reno is U.S. Route 395/Interstate 580.

The Regional Transportation Commission of Washoe County (RTC) has a bus system that provides intracity buses, intercity buses to Carson City, and an on-demand shuttle service for disabled persons. The system has its main terminal on 4th Street in downtown Reno and secondary terminals in Sparks and at Meadowood Mall in south Reno.

Numerous shuttle and excursion services are offered connecting the RenoâTahoe International Airport to various destinations:

Greyhound stops at a downtown terminal. Megabus stopped at the Silver Legacy Reno, but has since discontinued service to Reno.

Reno was historically a stopover along the First Transcontinental Railroad; the modern Overland Route continues to run through Reno. Reno was additionally the southern terminus of the NevadaâCaliforniaâOregon Railway (NCO) and the northern terminus of the Virginia and Truckee Railroad. Using the NCO depot and right of way, the Western Pacific Railroad also provided rail service to Reno. In the early 20th century, Reno also had a modest streetcar system. Downtown Reno has two historic train depots, the inactive Nevada-California-Oregon Railroad Depot and the still active Amtrak depot, originally built by the Southern Pacific Railroad.

Amtrak provides daily passenger service to Reno via the "California Zephyr" and multiple Amtrak Thruway Motorcoaches connecting to trains departing from Sacramento.

The city is served by RenoâTahoe International Airport, with general aviation traffic handled by Reno Stead Airport. RenoâTahoe International Airport is the second busiest commercial airport in the state of Nevada after McCarran International Airport in Las Vegas. Reno was the hub and headquarters of the defunct airline Reno Air.

The Truckee Meadows Water Authority provides potable water for the city. The Truckee River is the primary water source, with purification occurring at two plants, Chalk Bluff and Glendale. The Chalk Bluff plant's main intakes are west of Reno in Verdi, with the water flowing through a series of flumes and ditches to the plant. Alternative intakes are below the plant along the banks of the Truckee River itself. The Glendale plant is alongside the river, and is fed by a rock and concrete rubble diversion dam a short distance upstream.

Sewage treatment for most of the Truckee Meadows region takes place at the Truckee Meadows Water Reclamation Facility at the eastern edge of the valley. Treated effluent returns to the Truckee River by way of Steamboat Creek.

NV Energy, formerly Sierra Pacific, provides electric power and natural gas. Power comes from multiple sources, including Tracy-Clark Station to the east, and the Steamboat Springs binary cycle power plants at the southern end of town.

Movies filmed in Reno include:

Music videos filmed in Reno include:

The young adult author Ellen Hopkins has written a series of novels called "Crank" set in Reno. Also, many of the short stories included in Claire Vaye Watkins' collection "Battleborn" are set in the city.

American songwriter Richard FariÃ±a composed a song named "Reno Nevada"; it was first released on Richard & Mimi FariÃ±a's debut album "Celebrations For A Grey Day" in 1965. The song was famously covered by Fairport Convention in 1968 and by Iain Matthews in 1971.
Thomas Dolby composed a song named "Road to Reno" as part of his "A Map of the Floating City" album, released in 2011.

Reno has eight sister cities:





</doc>
<doc id="26390" url="https://en.wikipedia.org/wiki?curid=26390" title="Riemann integral">
Riemann integral

In the branch of mathematics known as real analysis, the Riemann integral, created by Bernhard Riemann, was the first rigorous definition of the integral of a function on an interval. It was presented to the faculty at the University of GÃ¶ttingen in 1854, but not published in a journal until 1868. For many functions and practical applications, the Riemann integral can be evaluated by the fundamental theorem of calculus or approximated by numerical integration.

The Riemann integral is unsuitable for many theoretical purposes. Some of the technical deficiencies in Riemann integration can be remedied with the RiemannâStieltjes integral, and most disappear with the Lebesgue integral.

Let be a non-negative real-valued function on the interval , and let

be the region of the plane under the graph of the function and above the interval (see the figure on the top right). We are interested in measuring the area of . Once we have measured it, we will denote the area by:

The basic idea of the Riemann integral is to use very simple approximations for the area of . By taking better and better approximations, we can say that "in the limit" we get exactly the area of under the curve.

Note that where can be both positive and negative, the definition of is modified so that the integral corresponds to the "signed area" under the graph of : that is, the area above the -axis minus the area below the -axis.

A partition of an interval is a finite sequence of numbers of the form

Each is called a sub-interval of the partition. The mesh or norm of a partition is defined to be the length of the longest sub-interval, that is,

A tagged partition of an interval is a partition together with a finite sequence of numbers subject to the conditions that for each , . In other words, it is a partition together with a distinguished point of every sub-interval. The mesh of a tagged partition is the same as that of an ordinary partition.

Suppose that two partitions and are both partitions of the interval . We say that is a refinement of if for each integer , with , there exists an integer such that and such that for some with . Said more simply, a refinement of a tagged partition breaks up some of the sub-intervals and adds tags to the partition where necessary, thus it "refines" the accuracy of the partition.

We can define a partial order on the set of all tagged partitions by saying that one tagged partition is greater or equal to another if the former is a refinement of the latter.

Let be a real-valued function defined on the interval . The "Riemann sum" of with respect to the tagged partition together with is

Each term in the sum is the product of the value of the function at a given point and the length of an interval. Consequently, each term represents the (signed) area of a rectangle with height and width . The Riemann sum is the (signed) area of all the rectangles.

Closely related concepts are the "lower and upper Darboux sums". These are similar to Riemann sums, but the tags are replaced by the infimum and supremum (respectively) of on each sub-interval:

If is continuous, then the lower and upper Darboux sums for an untagged partition are equal to the Riemann sum for that partition, where the tags are chosen to be the minimum or maximum (respectively) of on each subinterval. (When is discontinuous on a subinterval, there may not be a tag that achieves the infimum or supremum on that subinterval.) The Darboux integral, which is similar to the Riemann integral but based on Darboux sums, is equivalent to the Riemann integral.

Loosely speaking, the Riemann integral is the limit of the Riemann sums of a function as the partitions get finer. If the limit exists then the function is said to be integrable (or more specifically Riemann-integrable). The Riemann sum can be made as close as desired to the Riemann integral by making the partition fine enough.

One important requirement is that the mesh of the partitions must become smaller and smaller, so that in the limit, it is zero. If this were not so, then we would not be getting a good approximation to the function on certain subintervals. In fact, this is enough to define an integral. To be specific, we say that the Riemann integral of equals if the following condition holds:

For all , there exists such that for any tagged partition and whose mesh is less than , we have

Unfortunately, this definition is very difficult to use. It would help to develop an equivalent definition of the Riemann integral which is easier to work with. We develop this definition now, with a proof of equivalence following. Our new definition says that the Riemann integral of equals if the following condition holds:

For all , there exists a tagged partition and such that for any tagged partition and which is a refinement of and , we have

Both of these mean that eventually, the Riemann sum of with respect to any partition gets trapped close to . Since this is true no matter how close we demand the sums be trapped, we say that the Riemann sums converge to . These definitions are actually a special case of a more general concept, a net.

As we stated earlier, these two definitions are equivalent. In other words, works in the first definition if and only if works in the second definition. To show that the first definition implies the second, start with an , and choose a that satisfies the condition. Choose any tagged partition whose mesh is less than . Its Riemann sum is within of , and any refinement of this partition will also have mesh less than , so the Riemann sum of the refinement will also be within of .

To show that the second definition implies the first, it is easiest to use the Darboux integral. First, one shows that the second definition is equivalent to the definition of the Darboux integral; for this see the article on Darboux integration. Now we will show that a Darboux integrable function satisfies the first definition. Fix , and choose a partition such that the lower and upper Darboux sums with respect to this partition are within of the value of the Darboux integral. Let

If , then is the zero function, which is clearly both Darboux and Riemann integrable with integral zero. Therefore, we will assume that . If , then we choose such that

If , then we choose to be less than one. Choose a tagged partition and with mesh smaller than . We must show that the Riemann sum is within of .

To see this, choose an interval . If this interval is contained within some , then

where and are respectively, the infimum and the supremum of "f" on . If all intervals had this property, then this would conclude the proof, because each term in the Riemann sum would be bounded by a corresponding term in the Darboux sums, and we chose the Darboux sums to be near . This is the case when , so the proof is finished in that case.

Therefore, we may assume that . In this case, it is possible that one of the is not contained in any . Instead, it may stretch across two of the intervals determined by . (It cannot meet three intervals because is assumed to be smaller than the length of any one interval.) In symbols, it may happen that

(We may assume that all the inequalities are strict because otherwise we are in the previous case by our assumption on the length of .) This can happen at most times.

To handle this case, we will estimate the difference between the Riemann sum and the Darboux sum by subdividing the partition at . The term in the Riemann sum splits into two terms:

Suppose, without loss of generality, that . Then

so this term is bounded by the corresponding term in the Darboux sum for . To bound the other term, notice that

It follows that, for some (indeed any) ,

Since this happens at most times, the distance between the Riemann sum and a Darboux sum is at most . Therefore, the distance between the Riemann sum and is at mostÂ .

Let formula_17 be the function which takes the value 1 at every point. Any Riemann sum of on will have the value 1, therefore the Riemann integral of on is 1.

Let formula_18 be the indicator function of the rational numbers in ; that is, formula_19 takes the value 1 on rational numbers and 0 on irrational numbers. This function does not have a Riemann integral. To prove this, we will show how to construct tagged partitions whose Riemann sums get arbitrarily close to both zero and one.

To start, let and be a tagged partition (each is between and ). Choose . The have already been chosen, and we can't change the value of at those points. But if we cut the partition into tiny pieces around each , we can minimize the effect of the . Then, by carefully choosing the new tags, we can make the value of the Riemann sum turn out to be within of either zero or one.

Our first step is to cut up the partition. There are of the , and we want their total effect to be less than . If we confine each of them to an interval of length less than , then the contribution of each to the Riemann sum will be at least and at most . This makes the total sum at least zero and at most . So let be a positive number less than . If it happens that two of the are within of each other, choose smaller. If it happens that some is within of some , and is not equal to , choose smaller. Since there are only finitely many and , we can always choose sufficiently small.

Now we add two cuts to the partition for each . One of the cuts will be at , and the other will be at . If one of these leaves the interval [0, 1], then we leave it out. will be the tag corresponding to the subinterval

If is directly on top of one of the , then we let be the tag for both intervals:

We still have to choose tags for the other subintervals. We will choose them in two different ways. The first way is to always choose a rational point, so that the Riemann sum is as large as possible. This will make the value of the Riemann sum at least . The second way is to always choose an irrational point, so that the Riemann sum is as small as possible. This will make the value of the Riemann sum at most .

Since we started from an arbitrary partition and ended up as close as we wanted to either zero or one, it is false to say that we are eventually trapped near some number , so this function is not Riemann integrable. However, it is Lebesgue integrable. In the Lebesgue sense its integral is zero, since the function is zero almost everywhere. But this is a fact that is beyond the reach of the Riemann integral.

There are even worse examples. formula_19 is equivalent (that is, equal almost everywhere) to a Riemann integrable function, but there are non-Riemann integrable bounded functions which are not equivalent to any Riemann integrable function. For example, let be the SmithâVolterraâCantor set, and let be its indicator function. Because is not Jordan measurable, is not Riemann integrable. Moreover, no function equivalent to is Riemann integrable: , like , must be zero on a dense set, so as in the previous example, any Riemann sum of has a refinement which is within of 0 for any positive numberÂ . But if the Riemann integral of exists, then it must equal the Lebesgue integral of , which is . Therefore, is not Riemann integrable.

It is popular to define the Riemann integral as the Darboux integral. This is because the Darboux integral is technically simpler and because a function is Riemann-integrable if and only if it is Darboux-integrable.

Some calculus books do not use general tagged partitions, but limit themselves to specific types of tagged partitions. If the type of partition is limited too much, some non-integrable functions may appear to be integrable.

One popular restriction is the use of "left-hand" and "right-hand" Riemann sums. In a left-hand Riemann sum, for all , and in a right-hand Riemann sum, for all . Alone this restriction does not impose a problem: we can refine any partition in a way that makes it a left-hand or right-hand sum by subdividing it at each . In more formal language, the set of all left-hand Riemann sums and the set of all right-hand Riemann sums is cofinal in the set of all tagged partitions.

Another popular restriction is the use of regular subdivisions of an interval. For example, the th regular subdivision of consists of the intervals

Again, alone this restriction does not impose a problem, but the reasoning required to see this fact is more difficult than in the case of left-hand and right-hand Riemann sums.

However, combining these restrictions, so that one uses only left-hand or right-hand Riemann sums on regularly divided intervals, is dangerous. If a function is known in advance to be Riemann integrable, then this technique will give the correct value of the integral. But under these conditions the indicator function formula_19 will appear to be integrable on with integral equal to one: Every endpoint of every subinterval will be a rational number, so the function will always be evaluated at rational numbers, and hence it will appear to always equal one. The problem with this definition becomes apparent when we try to split the integral into two pieces. The following equation ought to hold:

If we use regular subdivisions and left-hand or right-hand Riemann sums, then the two terms on the left are equal to zero, since every endpoint except 0 and 1 will be irrational, but as we have seen the term on the right will equal 1.

As defined above, the Riemann integral avoids this problem by refusing to integrate formula_26 The Lebesgue integral is defined in such a way that all these integrals are 0.

The Riemann integral is a linear transformation; that is, if and are Riemann-integrable on and and are constants, then

Because the Riemann integral of a function is a number, this makes the Riemann integral a linear functional on the vector space of Riemann-integrable functions.

A bounded function on a compact interval is Riemann integrable if and only if it is continuous almost everywhere (the set of its points of discontinuity has measure zero, in the sense of Lebesgue measure). This is known as the or Lebesgue's criterion for Riemann integrability or the RiemannâLebesgue theorem. The criterion has "nothing to do" with the Lebesgue integral. It is due to Lebesgue and uses his measure zero, but makes use of neither Lebesgue's general measure or integral.

The integrability condition can be proven in various ways, one of which is sketched below.

In particular, any set that is at most countable has Lebesgue measure zero, and thus a bounded function (on a compact interval) with only finitely or countably many discontinuities is Riemann integrable.

An indicator function of a bounded set is Riemann-integrable if and only if the set is Jordan measurable. The Riemann integral can be interpreted measure-theoretically as the integral with respect to the Jordan measure.

If a real-valued function is monotone on the interval it is Riemann-integrable, since its set of discontinuities is at most countable, and therefore of Lebesgue measure zero.

If a real-valued function on is Riemann-integrable, it is Lebesgue-integrable. That is, Riemann-integrability is a "stronger" (meaning more difficult to satisfy) condition than Lebesgue-integrability.

If is a uniformly convergent sequence on with limit , then Riemann integrability of all implies Riemann integrability of , and

However, the Lebesgue monotone convergence theorem (on a monotone pointwise limit) does not hold. In Riemann integration, taking limits under the integral sign is far more difficult to logically justify than in Lebesgue integration.

It is easy to extend the Riemann integral to functions with values in the Euclidean vector space formula_29 for any . The integral is defined component-wise; in other words, if then

In particular, since the complex numbers are a real vector space, this allows the integration of complex valued functions.

The Riemann integral is only defined on bounded intervals, and it does not extend well to unbounded intervals. The simplest possible extension is to define such an integral as a limit, in other words, as an improper integral:

This definition carries with it some subtleties, such as the fact that it is not always equivalent to compute the Cauchy principal value

For example, consider the function which is 0 at , 1 for , and â1 for . By symmetry,

always, regardless of . But there are many ways for the interval of integration to expand to fill the real line, and other ways can produce different results; in other words, the multivariate limit does not always exist. We can compute

In general, this improper Riemann integral is undefined. Even standardizing a way for the interval to approach the real line does not work because it leads to disturbingly counterintuitive results. If we agree (for instance) that the improper integral should always be

then the integral of the translation is â2, so this definition is not invariant under shifts, a highly undesirable property. In fact, not only does this function not have an improper Riemann integral, its Lebesgue integral is also undefined (it equals ).

Unfortunately, the improper Riemann integral is not powerful enough. The most severe problem is that there are no widely applicable theorems for commuting improper Riemann integrals with limits of functions. In applications such as Fourier series it is important to be able to approximate the integral of a function using integrals of approximations to the function. For proper Riemann integrals, a standard theorem states that if is a sequence of functions that converge uniformly to on a compact set , then

On non-compact intervals such as the real line, this is false. For example, take to be on and zero elsewhere. For all we have:

The sequence converges uniformly to the zero function, and clearly the integral of the zero function is zero. Consequently,

This demonstrates that for integrals on unbounded intervals, uniform convergence of a function is not strong enough to allow passing a limit through an integral sign. This makes the Riemann integral unworkable in applications (even though the Riemann integral assigns both sides the correct value), because there is no other general criterion for exchanging a limit and a Riemann integral, and without such a criterion it is difficult to approximate integrals by approximating their integrands.

A better route is to abandon the Riemann integral for the Lebesgue integral. The definition of the Lebesgue integral is not obviously a generalization of the Riemann integral, but it is not hard to prove that every Riemann-integrable function is Lebesgue-integrable and that the values of the two integrals agree whenever they are both defined. Moreover, a function defined on a bounded interval is Riemann-integrable if and only if it is bounded and the set of points where is discontinuous has Lebesgue measure zero.

An integral which is in fact a direct generalization of the Riemann integral is the HenstockâKurzweil integral.

Another way of generalizing the Riemann integral is to replace the factors in the definition of a Riemann sum by something else; roughly speaking, this gives the interval of integration a different notion of length. This is the approach taken by the RiemannâStieltjes integral.

In multivariable calculus, the Riemann integrals for functions from formula_39 are multiple integrals.




</doc>
<doc id="26392" url="https://en.wikipedia.org/wiki?curid=26392" title="Run-length encoding">
Run-length encoding

Run-length encoding (RLE) is a form of lossless data compression in which "runs" of data (sequences in which the same data value occurs in many consecutive data elements) are stored as a single data value and count, rather than as the original run. This is most useful on data that contains many such runs. Consider, for example, simple graphic images such as icons, line drawings, Conwayâs Game of Life, and animations. It is not useful with files that don't have many runs as it could greatly increase the file size.

RLE may also be used to refer to an early graphics file format supported by CompuServe for compressing black and white images, but was widely supplanted by their later Graphics Interchange Format (GIF). RLE also refers to a little-used image format in Windows 3.x, with the extension codice_1, which is a Run Length Encoded Bitmap, used to compress the Windows 3.x startup screen.

For example, consider a screen containing plain black text on a solid white background. There will be many long runs of white pixels in the blank space, and many short runs of black pixels within the text. A hypothetical scan line, with B representing a black pixel and W representing white, might read as follows:

With a run-length encoding (RLE) data compression algorithm applied to the above hypothetical scan line, it can be rendered as follows:

This can be interpreted as a sequence of twelve Ws, one B, twelve Ws, three Bs, etc.,

The run-length code represents the original 67 characters in only 18. While the actual format used for the storage of images is generally binary rather than ASCII characters like this, the principle remains the same. Even binary data files can be compressed with this method; file format specifications often dictate repeated bytes in files as padding space. However, newer compression methods such as DEFLATE often use LZ77-based algorithms, a generalization of run-length encoding that can take advantage of runs of strings of characters (such as codice_4).

Run-length encoding can be expressed in multiple ways to accommodate data properties as well as additional compression algorithms. For instance, one popular method encodes run lengths for runs of two or more characters only, using an "escape" symbol to identify runs, or using the character itself as the escape, so that any time a character appears twice it denotes a run. On the previous example, this would give the following:

This would be interpreted as a run of twelve Ws, a B, a run of twelve Ws, a run of three Bs, etc. In data where runs are less frequent, this can significantly improve the compression rate.

One other matter is the application of additional compression algorithms. Even with the runs extracted, the frequencies of different characters may be large, allowing for further compression; however, if the run lengths are written in the file in the locations where the runs occurred, the presence of these numbers interrupts the normal flow and makes it harder to compress. To overcome this, some run-length encoders separate the data and escape symbols from the run lengths, so that the two can be handled independently. For the example data, this would result in two outputs, the string "codice_6" and the numbers (codice_7).

Run-length encoding (RLE) schemes were employed in the transmission of analog television signals as far back as 1967. In 1983, run-length encoding was patented by Hitachi. RLE is particularly well suited to palette-based bitmap images such as computer icons, and was a popular image compression method on early online services such as CompuServe before the advent of more sophisticated formats such as GIF. It does not work well on continuous-tone images such as photographs, although JPEG uses it on the coefficients that remain after transforming and quantizing image blocks.

Common formats for run-length encoded data include Truevision TGA, PackBits, PCX and ILBM. The International Telecommunication Union also describes a standard to encode run-length-colour for fax machines, known as T.45. The standard, which is combined with other techniques into Modified Huffman coding, is relatively efficient because most faxed documents are generally white space, with occasional interruptions of black.




</doc>
<doc id="26397" url="https://en.wikipedia.org/wiki?curid=26397" title="Redâblack tree">
Redâblack tree

A redâblack tree is a kind of self-balancing binary search tree in computer science. Each node of the binary tree has an extra bit, and that bit is often interpreted as the color (red or black) of the node. These color bits are used to ensure the tree remains approximately balanced during insertions and deletions.

Balance is preserved by painting each node of the tree with one of two colors in a way that satisfies certain properties, which collectively constrain how unbalanced the tree can become in the worst case. When the tree is modified, the new tree is subsequently rearranged and repainted to restore the coloring properties. The properties are designed in such a way that this rearranging and recoloring can be performed efficiently.

The balancing of the tree is not perfect, but it is good enough to allow it to guarantee searching in time, where "n" is the total number of elements in the tree. The insertion and deletion operations, along with the tree rearrangement and recoloring, are also performed in time.

Tracking the color of each node requires only 1 bit of information per node because there are only two colors. The tree does not contain any other data specific to its being a redâblack tree so its memory footprint is almost identical to a classic (uncolored) binary search tree. In many cases, the additional bit of information can be stored at no additional memory cost.

In 1972, Rudolf Bayer invented a data structure that was a special order-4 case of a B-tree. These trees maintained all paths from root to leaf with the same number of nodes, creating perfectly balanced trees. However, they were not binary search trees. Bayer called them a "symmetric binary B-tree" in his paper and later they became popular as 2-3-4 trees or just 2-4 trees.

In a 1978 paper, "A Dichromatic Framework for Balanced Trees", Leonidas J. Guibas and Robert Sedgewick derived the red-black tree from the symmetric binary B-tree. The color "red" was chosen because it was the best-looking color produced by the color laser printer available to the authors while working at Xerox PARC. Another response from Guibas states that it was because of the red and black pens available to them to draw the trees.

In 1993, Arne Andersson introduced the idea of right leaning tree to simplify insert and delete operations.

In 1999, Chris Okasaki showed how to make the insert operation purely functional. Its balance function needed to take care of only 4 unbalanced cases and one default balanced case.

The original algorithm used 8 unbalanced cases, but reduced that to 6 unbalanced cases. Sedgewick showed that the insert operation can be implemented in just 46 lines of Java code.
In 2008, Sedgewick proposed the left-leaning redâblack tree, leveraging Andersson's idea that simplified algorithms. Sedgewick originally allowed nodes whose two children are red, making his trees more like 2-3-4 trees, but later this restriction was added, making new trees more like 2-3 trees. Sedgewick implemented the insert algorithm in just 33 lines, significantly shortening his original 46 lines of code.

A redâblack tree is a special type of binary tree, used in computer science to organize pieces of comparable data, such as text fragments or numbers.

The leaf nodes of redâblack trees do not contain data. These leaves need not be explicit in computer memoryâa null child pointer (like NIL in the figure "An example of a redâblack tree" below) can encode the fact that this child is a leaf. However, in the description of this figure, the leaves are considered to be explicit nodesâa view which may simplify the description and the understanding of some algorithms for operating on redâblack trees. Now, in order to save a marginal amount of execution time (see there), these NIL-leaves may be implemented as sentinel nodes (instead of null pointers). On the other hand, in order to save (main) memory, a single sentinel node (instead of many individuals) may perform the role of all leaf nodes: all references (pointers) from internal nodes to leaf nodes then point to this unique sentinel node.

Redâblack trees, like all binary search trees, allow efficient in-order traversal (that is: in the order LeftâRootâRight) of their elements. The search-time results from the traversal from root to leaf, and therefore a balanced tree of "n" nodes, having the least possible tree height, results in search time.

In addition to the requirements imposed on a binary search tree the following must be satisfied by a 


Note that, except from the fifth constraint, there is no restriction imposed on the children of black nodes. In particular, a black node (like a leaf node) can be a child of a black node; for example, every perfect binary tree that consists only of black nodes is a red-black tree.

The black depth of a node is defined as the number of black nodes from the root to that node (i.e. the number of black ancestors). The black height of a redâblack tree is the number of black nodes in any path from the root to the leaves, which, by the fifth constraint, is constant (alternatively, it could be defined as the black depth of any leaf node).

These constraints enforce a critical property of redâblack trees: "the path from the root to the farthest leaf is no more than twice as long as the path from the root to the nearest leaf". The result is that the tree is roughly height-balanced. Since operations such as inserting, deleting, and finding values require worst-case time proportional to the height of the tree, this theoretical upper bound on the height allows redâblack trees to be efficient in the worst case, unlike ordinary binary search trees.

To see why this is guaranteed, it suffices to consider the effect of properties 4 and 5 together. For a redâblack tree "T", let "B" be the number of black nodes in "property 5". Let the shortest possible path from the root of "T" to any leaf consist of "B" black nodes. Longer possible paths may be constructed by inserting red nodes. However, property 4 makes it impossible to insert more than one consecutive red node. Therefore, ignoring any black NIL leaves, the longest possible path consists of "2*B " nodes, alternating black and red (this is the worst case). Counting the black NIL leaves, the longest possible path consists of "2*B-1" nodes.

"The shortest possible path has all black nodes, and the longest possible path alternates between red and black nodes". Since all maximal paths have the same number of black nodes, by property 5, this shows that "no path is more than twice as long as any other path".

A redâblack tree is similar in structure to a B-tree of order 4, where each node can contain between 1 and 3 values and (accordingly) between 2 and 4 child pointers. In such a B-tree, each node will contain only one value matching the value in a black node of the redâblack tree, with an optional value before and/or after it in the same node, both matching an equivalent red node of the redâblack tree.

One way to see this equivalence is to "move up" the red nodes in a graphical representation of the redâblack tree, so that they align horizontally with their parent black node, by creating together a horizontal cluster. In the B-tree, or in the modified graphical representation of the redâblack tree, all leaf nodes are at the same depth.

The redâblack tree is then structurally equivalent to a B-tree of order 4, with a minimum fill factor of 33% of values per cluster with a maximum capacity of 3 values.

This B-tree type is still more general than a redâblack tree though, as it allows ambiguity in a redâblack tree conversionâmultiple redâblack trees can be produced from an equivalent B-tree of order 4. If a B-tree cluster contains only 1 value, it is the minimum, black, and has two child pointers. If a cluster contains 3 values, then the central value will be black and each value stored on its sides will be red. If the cluster contains two values, however, either one can become the black node in the redâblack tree (and the other one will be red).

So the order-4 B-tree does not maintain which of the values contained in each cluster is the root black tree for the whole cluster and the parent of the other values in the same cluster. Despite this, the operations on redâblack trees are more economical in time because you don't have to maintain the vector of values. It may be costly if values are stored directly in each node rather than being stored by reference. B-tree nodes, however, are more economical in space because you don't need to store the color attribute for each node. Instead, you have to know which slot in the cluster vector is used. If values are stored by reference, e.g. objects, null references can be used and so the cluster can be represented by a vector containing 3 slots for value pointers plus 4 slots for child references in the tree. In that case, the B-tree can be more compact in memory, improving data locality.

The same analogy can be made with B-trees with larger orders that can be structurally equivalent to a colored binary tree: you just need more colors. Suppose that you add blue, then the blueâredâblack tree defined like redâblack trees but with the additional constraint that no two successive nodes in the hierarchy will be blue and all blue nodes will be children of a red node, then it becomes equivalent to a B-tree whose clusters will have at most 7 values in the following colors: blue, red, blue, black, blue, red, blue (For each cluster, there will be at most 1 black node, 2 red nodes, and 4 blue nodes).

For moderate volumes of values, insertions and deletions in a colored binary tree are faster compared to B-trees because colored trees don't attempt to maximize the fill factor of each horizontal cluster of nodes (only the minimum fill factor is guaranteed in colored binary trees, limiting the number of splits or junctions of clusters). B-trees will be faster for performing rotations (because rotations will frequently occur within the same cluster rather than with multiple separate nodes in a colored binary tree). For storing large volumes, however, B-trees will be much faster as they will be more compact by grouping several children in the same cluster where they can be accessed locally.

All optimizations possible in B-trees to increase the average fill factors of clusters are possible in the equivalent multicolored binary tree. Notably, maximizing the average fill factor in a structurally equivalent B-tree is the same as reducing the total height of the multicolored tree, by increasing the number of non-black nodes. The worst case occurs when all nodes in a colored binary tree are black, the best case occurs when only a third of them are black (and the other two thirds are red nodes).

Redâblack trees offer worst-case guarantees for insertion time, deletion time, and search time. Not only does this make them valuable in time-sensitive applications such as real-time applications, but it makes them valuable building blocks in other data structures which provide worst-case guarantees; for example, many data structures used in computational geometry can be based on redâblack trees, and the Completely Fair Scheduler used in current Linux kernels and epoll system call implementation uses redâblack trees.

The AVL tree is another structure supporting search, insertion, and removal. AVL trees can be colored red-black, thus are a subset of RB trees. Worst-case height is 0.720 times the worst-case height of RB trees, so AVL trees are more rigidly balanced. The performance measurements of Ben Pfaff with realistic test cases in 79 runs find AVL to RB ratios between 0.677 and 1.077, median at 0.947, and geometric mean 0.910. WAVL trees have a performance in between those two.

Redâblack trees are also particularly valuable in functional programming, where they are one of the most common persistent data structures, used to construct associative arrays and sets which can retain previous versions after mutations. The persistent version of redâblack trees requires space for each insertion or deletion, in addition to time.

For every 2-4 tree, there are corresponding redâblack trees with data elements in the same order. The insertion and deletion operations on 2-4 trees are also equivalent to color-flipping and rotations in redâblack trees. This makes 2-4 trees an important tool for understanding the logic behind redâblack trees, and this is why many introductory algorithm texts introduce 2-4 trees just before redâblack trees, even though 2-4 trees are not often used in practice.

In 2008, Sedgewick introduced a simpler version of the redâblack tree called the left-leaning redâblack tree by eliminating a previously unspecified degree of freedom in the implementation. The LLRB maintains an additional invariant that all red links must lean left except during inserts and deletes. Redâblack trees can be made isometric to either 2-3 trees, or 2-4 trees, for any sequence of operations. The 2-4 tree isometry was described in 1978 by Sedgewick. With 2-4 trees, the isometry is resolved by a "color flip," corresponding to a split, in which the red color of two children nodes leaves the children and moves to the parent node.

The original description of the tango tree, a type of tree optimized for fast searches, specifically uses redâblack trees as part of its data structure.

In the version 8 of Java, the HashMap has been modified such that instead of using a LinkedList to store different elements with colliding hashcodes, a red-black tree is used. This results in the improvement of time complexity of searching such an element from to .

Read-only operations on a redâblack tree require no modification from those used for binary search trees, because every redâblack tree is a special case of a simple binary search tree. However, the immediate result of an insertion or removal may violate the properties of a redâblack tree. Restoring the redâblack properties requires a small number ( or amortized) of color changes (which are very quick in practice) and no more than three tree rotations (two for insertion). Although insert and delete operations are complicated, their times remain .

If the example implementation below is not suitable, other implementations with explanations may be found in Ben Pfaff's annotated C library GNU libavl (v2.0.3 as of June 2019).

The details of the insert and removal operations will be demonstrated with example C++ code. The example code may call upon the helper functions below to find the parent, sibling, uncle and grandparent nodes and to rotate a node left or right:


Insertion begins by adding the node in a very similar manner as a standard binary search tree insertion and by coloring it red. The big difference is that in the binary search tree a new node is added as a leaf, whereas leaves contain no information in the redâblack tree, so instead the new node replaces an existing leaf and then has two black leaves of its own added.

What happens next depends on the color of other nearby nodes. There are several cases of redâblack tree insertion to handle:

Note that:

Case 1: The current node N is at the root of the tree. In this case, it is repainted black to satisfy property 2 (the root is black). Since this adds one black node to every path at once, property 5 (all paths from any given node to its leaf nodes contain the same number of black nodes) is not violated.

Case 2: The current node's parent P is black, so property 4 (both children of every red node are black) is not invalidated. In this case, the tree is still valid. Property 5 (all paths from any given node to its leaf nodes contain the same number of black nodes) is not threatened, because the current node N has two black leaf children, but because N is red, the paths through each of its children have the same number of black nodes as the path through the leaf it replaced, which was black, and so this property remains satisfied.

Note that inserting is actually in-place, since all the calls above use tail recursion.

In the algorithm above, all cases are called only once, except in Case 3 where it can recurse back to Case 1 with the grandparent node, which is the only case where an iterative implementation will effectively loop. Because the problem of repair in that case is escalated two levels higher each time, it takes maximally iterations to repair the tree (where is the height of the tree). Because the probability for escalation decreases exponentially with each iteration the average insertion cost is practically constant.

In a regular binary search tree when deleting a node with two non-leaf children, we find either the maximum element in its left subtree (which is the in-order predecessor) or the minimum element in its right subtree (which is the in-order successor) and move its value into the node being deleted (as shown here). We then delete the node we copied the value from, which must have fewer than two non-leaf children. (Non-leaf children, rather than all children, are specified here because unlike normal binary search trees, redâblack trees can have leaf nodes anywhere, which are actually the sentinel Nil, so that all nodes are either internal nodes with two children or leaf nodes with, by definition, zero children. In effect, internal nodes having two leaf children in a redâblack tree are like the leaf nodes in a regular binary search tree.) Because merely copying a value does not violate any redâblack properties, this reduces to the problem of deleting a node with at most one non-leaf child. Once we have solved that problem, the solution applies equally to the case where the node we originally want to delete has at most one non-leaf child as to the case just considered where it has two non-leaf children.

Therefore, for the remainder of this discussion we address the deletion of a node with at most one non-leaf child. We use the label M to denote the node to be deleted; C will denote a selected child of M, which we will also call "its child". If M does have a non-leaf child, call that its child, C; otherwise, choose either leaf as its child, C.

If M is a red node, we simply replace it with its child C, which must be black by property 4. (This can only occur when M has two leaf children, because if the red node M had a black non-leaf child on one side but just a leaf child on the other side, then the count of black nodes on both sides would be different, thus the tree would violate property 5.) All paths through the deleted node will simply pass through one fewer red node, and both the deleted node's parent and child must be black, so property 3 (all leaves are black) and property 4 (both children of every red node are black) still hold.

Another simple case is when M is black and C is red. Simply removing a black node could break Properties 4 (âBoth children of every red node are blackâ) and 5 (âAll paths from any given node to its leaf nodes contain the same number of black nodesâ), but if we repaint C black, both of these properties are preserved.

The complex case is when both M and C are black. (This can only occur when deleting a black node which has two leaf children, because if the black node M had a black non-leaf child on one side but just a leaf child on the other side, then the count of black nodes on both sides would be different, thus the tree would have been an invalid redâblack tree by violation of property 5.) We begin by replacing M with its child C â we recall that in this case "its child C" is either child of M, both being leaves. We will "relabel" this child C (in its new position) N, and its sibling (its new parent's other child) S. (S was previously the sibling of M.)
In the diagrams below, we will also use P for N's new parent (M's old parent), S for S's left child, and S for S's right child (S cannot be a leaf because if M and C were black, then P's one subtree which included M counted two black-height and thus P's other subtree which includes S must also count two black-height, which cannot be the case if S is a leaf node).

We can perform the steps outlined above with the following code, where the function codice_1 substitutes codice_2 into codice_3's place in the tree. For convenience, code in this section will assume that null leaves are represented by actual node objects rather than NULL (the code in the "Insertion" section works with either representation).

If both N and its original parent are black, then deleting this original parent causes paths which proceed through N to have one fewer black node than paths that do not. As this violates property 5 (all paths from any given node to its leaf nodes contain the same number of black nodes), the tree must be rebalanced. There are several cases to consider:

Case 1: N is the new root. In this case, we are done. We removed one black node from every path, and the new root is black, so the properties are preserved.

Again, the function calls all use tail recursion, so the algorithm is in-place.

In the algorithm above, all cases are chained in order, except in delete case 3 where it can recurse to case 1 back to the parent node: this is the only case where an iterative implementation will effectively loop. No more than loops back to case 1 will occur (where is the height of the tree). And because the probability for escalation decreases exponentially with each iteration the average removal cost is constant.

Additionally, no tail recursion ever occurs on a child node, so the tail recursion loop can only move from a child back to its successive ancestors. If a rotation occurs in case 2 (which is the only possibility of rotation within the loop of cases 1â3), then the parent of the node N becomes red after the rotation and we will exit the loop. Therefore, at most one rotation will occur within this loop. Since no more than two additional rotations will occur after exiting the loop, at most three rotations occur in total.

A red black tree which contains "n" internal nodes has a height of .

Definitions:


Lemma: A subtree rooted at node "v" has at least formula_1 internal nodes.

Proof of Lemma (by induction height):

Basis: h("v") = 0

If "v" has a height of zero then it must be "null", therefore bh("v") = 0. So:

Inductive Step: "v" such that h("v") = k, has at least formula_1 internal nodes implies that formula_4 such that h(formula_4) = k+1 has at least formula_6 internal nodes.

Since formula_4 has h(formula_4) > 0 it is an internal node. As such it has two children each of which have a black-height of either bh(formula_4) or bh(formula_4)-1 (depending on whether the child is red or black, respectively). By the inductive hypothesis each child has at least formula_11 internal nodes, so formula_4 has at least:

internal nodes.

Using this lemma we can now show that the height of the tree is logarithmic. Since at least half of the nodes on any path from the root to a leaf are black (property 4 of a redâblack tree), the black-height of the root is at least h(root)/2. By the lemma we get:

Therefore, the height of the root is .

In addition to the single-element insert, delete and lookup operations, several set operations have been defined on red-black trees: union, intersection and set difference. Then fast "bulk" operations on insertions or deletions can be implemented based on these set functions. These set operations rely on two helper operations, "Split" and "Join". With the new operations, the implementation of red-black trees can be more efficient and highly-parallelizable. This implementation allows a red root.



The join algorithm is as follows:

Here formula_16 of a node formula_17 means twice the black height of a black node, and the twice the black height of a red node. expose(v)=(l,â¨k,câ©,r) means to extract a tree node formula_17's left child formula_19, the key of the node formula_20, the color of the node formula_21 and the right child formula_22. Node(l,â¨k,câ©,r) means to create a node of left child formula_19, key formula_20, color formula_21 and right child formula_22.

The split algorithm is as follows:

The union of two red-black trees and representing sets and , is a red-black tree that represents . The following recursive function computes this union:

Here, "Split" is presumed to return two trees: one holding the keys less its input key, one holding the greater keys. (The algorithm is non-destructive, but an in-place destructive version exists as well.)

The algorithm for intersection or difference is similar, but requires the "Join2" helper routine that is the same as "Join" but without the middle key. Based on the new functions for union, intersection or difference, either one key or multiple keys can be inserted to or deleted from the red-black tree. Since "Split" calls "Join" but does not deal with the balancing criteria of red-black trees directly, such an implementation is usually called the "join-based" implementation.

The complexity of each of union, intersection and difference is formula_27 for two red-black trees of sizes formula_28 and formula_29. This complexity is optimal in terms of the number of comparisons. More importantly, since the recursive calls to union, intersection or difference are independent of each other, they can be executed in parallel with a parallel depth formula_30. When formula_31, the join-based implementation has the same computational directed acyclic graph (DAG) as single-element insertion and deletion if the root of the larger tree is used to split the smaller tree.

Parallel algorithms for constructing redâblack trees from sorted lists of items can run in constant time or time, depending on the computer model, if the number of processors available is asymptotically proportional to the number of items where . Fast search, insertion, and deletion parallel algorithms are also known.

The join-based algorithms for red-black trees are parallel for bulk operations, including union, intersection, construction, filter, map-reduce, and so on.

Basic operations like insertion, removal or update can be parallelized by defining operations that process bulks of multiple elements.
It is also possible to process bulks with several basic operations, for example bulks may contain elements to insert and also elements to remove from the tree.

The algorithms for bulk operations aren't just applicable to the red-black tree, but can be adapted to other sorted sequence data structures as well, like the 2-3 tree, 2-3-4 tree and (a,b)-tree.
In the following different algorithms for bulk insert will be explained, but the same algorithms can also be applied to removal and update.
Bulk insert is an operation that inserts each element of a sequence formula_32 into a tree formula_33.

This approach can be applied to every sorted sequence data structure that supports efficient join- and split-operations.
The general idea is to split formula_32 and formula_33 in multiple parts and perform the insertions on these parts in parallel.


Note that in Step 3 the constraints for splitting formula_32 assure that in Step 5 the trees can be joined again and the resulting sequence is sorted.
The pseudo code shows a simple divide-and-conquer implementation of the join-based algorithm for bulk-insert.
Both recursive calls can be executed in parallel.
The join operation used here differs from the version explained in this article, instead join2 is used which misses the second parameter k.

Sorting formula_32 is not considered in this analysis.

This can be improved by using parallel algorithms for splitting and joining.
In this case the execution time is formula_52.

Another method of parallelizing bulk operations is to use a pipelining approach.
This can be done by breaking the task of processing a basic operation up into a sequence of subtasks.
For multiple basic operations the subtasks can be processed in parallel by assigning each subtask to a separate processor.

Sorting formula_32 is not considered in this analysis.
Also, formula_83 is assumed to be smaller than formula_84, otherwise it would be more sufficient to construct the resulting tree from scratch.
A red-black-tree was referenced correctly in an episode of Missing (Canadian TV series) as noted by Robert Sedgewick in one of his lectures:





</doc>
<doc id="26399" url="https://en.wikipedia.org/wiki?curid=26399" title="RMS Laconia">
RMS Laconia

Two different ocean liners of the Cunard Steamship Lines have been named RMS "Laconia". Although one was launched ten years after the other, and was the subject of a TV movie, they are easily confused; they had similar careers, looked the same, and met similar fates.



</doc>
<doc id="26400" url="https://en.wikipedia.org/wiki?curid=26400" title="Retroactive continuity">
Retroactive continuity

Retroactive continuity, or retcon for short, is a literary device in which established facts in a fictional work are adjusted, ignored, or contradicted by a subsequently published work which breaks continuity with the former.

There are various motivations for applying retroactive continuity, including:

Retcons are used by authors to increase their creative freedom, on the assumption that the changes are unimportant to the audience compared to the new story which can be told. For instance, by retroactively setting a prior story in a parallel universe, departed popular characters can be reintroduced. More subtly, a minor plot point might be retroactively expunged (for instance, the heroine leaving home without any food), removing an obstacle to further storytelling (that she should be getting hungry).

Retcons are common in pulp fiction, and especially in comic books published by long-established publishers such as DC and Marvel. The long history of popular titles and the number of writers who contribute stories can often create situations that demand clarification or revision. Retcons also often appear in manga, soap operas, serial dramas, movie sequels, cartoons, professional wrestling angles, video games, radio series, and other forms of serial fiction.

The first published use of the phrase "retroactive continuity" is found in theologian E. Frank Tupper's 1973 book "The Theology of Wolfhart Pannenberg": "Pannenberg's conception of retroactive continuity ultimately means that history flows fundamentally from the future into the past, that the future is not basically a product of the past."

The first known printed use of "retroactive continuity" referring to the altering of history in a fictional work is in "All-Star Squadron" #18 (February 1983) from DC Comics. The series was set on DC's Earth-Two, an alternate universe in which Golden Age comic characters age in real time. "All-Star Squadron" was set during World War II on Earth-Two; as it was in the past of an alternate universe, all its events had repercussions on the contemporary continuity of the DC multiverse. Each issue changed the history of the fictional world in which it was set. In the letters column, a reader remarked that the comic "must make you [the creators] feel at times as if you're painting yourself into a corner", and, "Your matching of Golden Age comics history with new plotlines has been an artistic (and I hope financial!) success." Writer Roy Thomas responded, "we like to think that an enthusiastic ALL-STAR booster at one of Adam Malin's Creation Conventions in San Diego came up with the best name for it a few months back: 'Retroactive Continuity'. Has kind of a ring to it, don't you think?" The term then took firm root in the consciousness of fans of American superhero comics.

At some point, "retroactive continuity" was shortened to "retcon", reportedly by Damian Cugley in 1988 on Usenet. Hard evidence of Cugley's abbreviation has yet to surface, though in a Usenet posting on August 18, 1990, Cugley posted a reply in which he identified himself as "the originator of the word "retcon"". Cugley used the neologism to describe a development in the comic book "Saga of the Swamp Thing", which reinterprets the events of the title character's origin by revealing facts that previously were not part of the narrative and were not intended by earlier writers.

Retcons sometimes do not contradict previously established facts but instead fill in missing background details, usually to support current plot points. Thomas referred to "retroactive continuity" in this sense, as a purely additive process that did not undo any previous work; such additions were common in "All-Star Squadron". Kurt Busiek took a similar approach with "Untold Tales of Spider-Man", a series which told stories that specifically fit between issues of the original "The Amazing Spider-Man" series, sometimes explaining discontinuities between those earlier stories. John Byrne used a similar structure with "". Possibly the earliest Marvel Comics example of new stories placed between long-established stories was the 1977-8 magazine "The Rampaging Hulk". In "The Godfather Part II", the character Frank Pentangeli is introduced as an old friend of the family though he is not referenced in the first movie; similarly Don Altobello is one of the "old time" Dons, though he is not mentioned until "The Godfather Part III". Neither addition affects the plot line of the previous films. The addition, in later seasons, of an attic to the family's home in "Full House" stands as a similar additive example.

A similar concept is that of secret history, in which the events of a story occur within the bounds of already-established events (especially real-world ones), revealing different interpretations of the events. Some of Tim Powers' novels use secret history, such as "Last Call", which suggests that Bugsy Siegel's actions were due to his being a modern-day Fisher King.

Alan Moore's additional information about the Swamp Thing's origins â revealing that Swamp Thing was not actually scientist Alec Holland converted into a plant, but actually a plant that had absorbed Holland's body and consciousness so that it merely thought it was Holland â did not contradict or change any of the events depicted in the character's previous appearances, but instead changed the reader's interpretation of them. Such additions and reinterpretations are very common in "Doctor Who".

In the "Star Wars" franchise, one of the most cited plot holes is that the Galactic Empire's superweapon, the Death Star, has a glaring, poorly defended weak point, the exhaust port. However, the prequel, "Star Wars: Rogue One," presents the design flaw as deliberate: Galen Erso, the head engineer of the Death Star project, designed the reactors to be unstable, thus needing an exhaust port, and gave the plans to the Rebel Alliance in order to sabotage the Empire and to secretly show the Rebels how to destroy the Death Star.

Retcons sometimes add information that seemingly contradicts previous information. This frequently takes the form of a character who was shown to have died but is later revealed to have somehow survived. This is a common practice in horror films, which may end with the death of a monster that goes on to appear in one or more sequels. The technique is so common in superhero comics that the term "comic book death" has been coined for it. An early example of this type of retcon is the return of Sherlock Holmes, whom writer Arthur Conan Doyle apparently killed off in "The Final Problem" in 1893, only to bring him back, in large part because of readers' responses, with "The Empty House" in 1903. Another example is the character Phil Coulson, who was killed off in the Marvel Studios film "The Avengers" (2012), but is later shown to have survived in the television series "Agents of S.H.I.E.L.D".

In many of his detective novels, Rex Stout implies that his character Nero Wolfe was born in Montenegro, giving some details of his early life in the Balkans around World War I. But in 1939's "Over My Dead Body", Wolfe tells an FBI agent that he was born in the United States. Stout revealed the reason for the change in a letter obtained by his authorized biographer, John McAleer: "In the original draft of "Over My Dead Body" Nero was a Montenegrin by birth, and it all fitted previous hints as to his background; but violent protests from "The American Magazine", supported by Farrar & Rinehart, caused his cradle to be transported five thousand miles."

In the 1940s and 1950s, Isaac Asimov placed the planet Trantor, capital of the Galactic Empire, at the "center of the galaxy", but later astronomical research indicated that the actual Galactic Center might be occupied by a supermassive black hole, making human life there impossible; in later works, Asimov adjusted his galaxy and Trantor's location in it.

When E.E. "Doc" Smith wrote the original "The Skylark of Space", space flight was a completely theoretical proposition. However, the last book of the series, "Skylark DuQuesne", was written in 1963, when the United States and the Soviet Union were involved in the space race. Smith adjusted the past of his series accordingly, mentioning an American base and a Soviet one being established on the Moon prior to the protagonist Seaton discovering faster-than-light flight.

Alan Moore's retcons often involve false memories. He has used this technique in the "Marvelman" series, "Swamp Thing" and "".

Retconning can bring back characters who were initially killed off. An example of this occurs on the CBS comedy "Two and a Half Men". The character Charlie Harper (Charlie Sheen) was killed in a train accident and briefly returns as a ghost (played by Kathy Bates) in the ninth season. Despite numerous instances that confirm his demise including the fact that a mutilated body was in his coffin, the season twelve series finale "Of Course He's Dead", it is revealed that Charlie survived the ordeal and has been held captive against his will for over four years. It is mentioned that there was no body only random body parts. It is also common in soap operas. On "The Bold and the Beautiful", Taylor Forrester (Hunter Tylo) was shown to flatline and have a funeral. When Tylo reprised the character in 2005, a retcon explained that Taylor had actually gone into a coma.

The TV series "Dallas" annulled its entire Season 9 as being just the dream of another character, Pam Ewing. Writers did this to offer a supposedly plausible reason for the major character of Bobby Ewing, who had died onscreen at the end of Season 8, to be still alive when actor Patrick Duffy wanted to return to the series. This season is sometimes referred to as the "Dream Season" and was referred to humorously in later TV series such as "Family Guy".

In "Beverly Hills 90210", Kelly Taylor starts out in the first season initially not knowing Dylan McKay. Later when Brenda Walsh is sent to Paris with Donna Martin Kelly Taylor has suddenly known him since kindergarten. This apparent retooling of the storyline contradicted years of prior character development and was apparently done to prepare viewers for Shannen Doherty's exit from the series. 

Marvel Comics' Beyonder was originally stated to be omnipotent and the most powerful being in Marvel Universe, coming from the Beyond Realm. However, after his creator, Jim Shooter, left Marvel, writer-editor Tom DeFalco re-tooled the Beyonder, diminishing his power greatly: he was no longer omnipotent, as certain other cosmic entities were retroactively vastly upgraded to transcend the scale of infinity on which the character worked. Even after this, Beyonder was still one of the most powerful beings in Marvel, with several characters exceeding him.

In 2003, in the title of DC Comics' Teen Titans, Geoff Johns changed the entire genetic code of Kon-El (the modern version of Superboy) from a genetically altered human clone that was designed to be as Kryptonian as possible into a hybrid clone of both Superman and Lex Luthor. This change contradicted years of continuity and various facts that proved that Kon-El was human and in the process mostly ignored his unique ability of tactile telekinesis that made his powers very different from those of Superman.

In "Boy Meets World", both Shawn Hunter and Topanga Lawrence have siblings in the first season but later in the series are retconned to be only children (though Shawn's half-brother Jack is introduced in later seasons). The ages of the characters of "Boy Meets World" are altered notably where Cory is age 11 in 6th grade during season 1 to age 13 and 8th grade in season 2. This happens again in high school skipping another grade. The age gap between Cory and Eric also narrows from 4 years apart in age to 2 years apart in age. Another prominent retcon during that series was that of the character of Morgan Matthews, who was portrayed by two actresses during the show's run; in the series finale of the sequel series "Girl Meets World", the continuity suggests that they were two separate people who both appeared together for the only time during that episode.

Unpopular or embarrassing stories are sometimes later ignored by publishers, and effectively erased from a series's continuity. Later stories may contradict the previous ones or explicitly establish that they never happened.

A notable example of subtractive retconning is the "X-Men" film series. The 2014 film "" features the character Wolverine traveling in time to 1973 to prevent an assassination that, if carried out, would lead to the creation of a new weapons system called the Sentinels that threatens the existence of mutants â and potentially, all of humanity. The events of this film retconned those of two previous films in the series:
The film, a loose adaptation of "The Dark Phoenix Saga" from the "Uncanny X-Men" comic book series, featured the unceremonious deaths of select key characters (including Cyclops), triggering a mixed fan response from those who felt the deaths were sudden and under-explored. "Days of Future Past" erased these deaths and the characters are shown to have survived at the end of the film. "The Dark Phoenix Saga" would subsequently be adapted a second time in "Dark Phoenix" (2019).
The film featured the character Deadpool, who is created by the character Colonel William Stryker as an amalgamation of several other mutants. He is referred to as "the Deadpool" due to having the other mutants' abilities "pooled" together. This version of the character was poorly received by fans due to his appearance and origin, both of which were considered unfaithful to the comics version of the character. The events of "Days of Future Past" allowed a more faithful version of the character to be adapted in "Deadpool" (2016) and its 2018 sequel, both of which were positively received by fans and critics.

An unpopular retcon may itself be retconned away, as happened with John Byrne's "".

Film sequels often employ temporal compression to maintain a sense of urgency in each installment, despite more time having elapsed diegetically ("in-universe") between one installment and another than has elapsed in the real world. For example, despite the implied contemporaneity in each of the films of "The Omen" series, the lead character ages some 15 or 20 years across three films released over a period of less than 6 years.

Retroactive continuity is similar to, but not the same as, plot inconsistencies introduced accidentally or through lack of concern for continuity; retconning, by comparison, is done deliberately. For example, the ongoing continuity contradictions on episodic TV series such as "The Simpsons" (in which the timeline of the family's history must be continually shifted forward to explain they are not getting any older) reflects intentionally lost continuity, not genuine retcons. However, in series with generally tight continuity, retcons are sometimes created after the fact to explain continuity errors, such was the case in "The Flintstones", where Wilma Flintstone was mistakenly given two separate maiden names, "Pebble" and "Slaghoople", over the course of the series. Upon discovering the discrepancy, the producers settled on "Slaghoople" and retconned it into later series in the franchise.

Retconning is also generally distinct from replacing the actor who plays a part in an ongoing series, which is more commonly an example of "loose continuity" rather than retroactively changing past continuity. The different appearance of the character is either ignored (as was done with the characters of Darrin Stephens and Gladys Kravitz on the television series "Bewitched") or explained within the series, such as with "regeneration" in "Doctor Who", or the Oracle in "The Matrix Revolutions". Sometimes, there are referential, inside jokes on actor changes in the show, such as with "My Wife & Kids" and "Roseanne", where there was a change of actresses playing a role (characters Claire Kyle and Becky Conner, respectively). In the latter, another character observes that children can change as they reach adulthood, remarking that when Becky came back from college (played by a new actress), they could not even recognize her. When the actor playing Rory was replaced in "Mrs Brown's Boys", the new actor first appeared on set bandaged up, supposedly following cosmetic surgery on his face. When the bandages were removed, the other characters claimed not to notice any difference. A similar set up gag was used with the character of Herr Flick in the BBC sitcom "Allo Allo".

Retconning also differs from direct revision. For example, when George Lucas re-edited the original "Star Wars" trilogy, he made changes directly to the source material, rather than introducing new source material that contradicted the contents of previous material.

Retconning is not the same as a reboot or reimagining which completely discards the original timeline, such as in "Battlestar Galactica". However, there have been partial reboots of franchises where the core of the franchise is still canonical but the expanded universe is relegated to a secondary continuity which, while not completely invalid, is subject to revision and critical review. "Robotech" is an example of this. With the release of the 2006 sequel film "Robotech The Shadow Chronicles", Harmony Gold established that only the original 1985 animated series and the 2006 sequel film are considered canonical relegating the aborted "", comics, and novels from the 80s and 90s to secondary continuity and, if elements are used from them, they are subject to selective revision and updating as appropriate to mesh with future canonical productions and to prevent conflict with the original animated series. While the Jack McKinney "Robotech" novel "End of the Circle" is evidently no longer canon, the prequel comic "" establishes that the general storyline of The Sentinels still occurred in some fashion, but various elements, including the timeline, specific unfolding of events, and some characterizations are different from what was previously depicted in earlier comics and novels. In such cases, the franchise producer may state that there is no intention to address the changes through remakes or direct retellings of such stories. It is essentially left to the viewer's imagination as to how differently the revised story unfolded.




</doc>
<doc id="26401" url="https://en.wikipedia.org/wiki?curid=26401" title="Rochester">
Rochester

Rochester refers to:










In the United States:

In the United Kingdom:





</doc>
<doc id="26403" url="https://en.wikipedia.org/wiki?curid=26403" title="RosÃ³Å">
RosÃ³Å

RosÃ³Å is a traditional Polish meat soup. Its most popular variety is the "rosÃ³Å z kury", or clear chicken soup. It is commonly served with capellini pasta. A vegetarian version can be made, substituting meat with oil or butter.

It is one of the most popular Polish soups and is served during family dinners as well as a traditional soup for weddings. It is also said to be a great remedy if one catches a cold. The name ""rosÃ³Å"" derives from a dish made of salted meat (an old conservation method) cooked in water to make it more edible. Later on, fresh meat was used instead. Over time the dish evolved to that of cooked meat in a soup that is commonly known today.

There are many types of "rosÃ³Å", as:
"RosÃ³Å KrÃ³lewski" (The royal rosÃ³Å), made of three meats: beef or veal, white poultry (hen, turkey or chicken) and dark poultry as duck, goose (crop only), just a couple of dried king boletes, one single cabbage leaf and a variety of vegetables such as parsley, celery, carrot, and leek. The cooking must take at least six hours of sensitive boiling over a small fire. At the end, softly burnt onion is added to the soup.

"RosÃ³Å myÅliwski" (The hunter's rosÃ³Å) is made of a variety of wild birds as well as pheasant, capercaillie, wood grouse, black grouse, or grey partridge, with a small addition of roe deer meat, a couple of wild mushrooms, and 2-3 juniper fruits. Instead of wild poultry, helmeted guinea fowl can also be used.

The most important thing about making "rosÃ³Å" is that there can be no addition of pork, since that would no longer make the broth clear. It cannot be boiled too quickly for the same reason.

This is the way to cook Polish rosÃ³Å: take beef meat or veal,
hazel grouse or partridge, and whatever meat that in rosÃ³Å can be cooked.
Soak it, lay in pot, then strain and pour over meat, add parsley, butter, salt, and skim well.
One has to know what to put in the rosÃ³Å for it not to smell.
that is parsley, dill, onion or garlic, nutmeg or rosmarin or pepper to taste.
Lime would not spoil any rosÃ³Å as well.


</doc>
<doc id="26404" url="https://en.wikipedia.org/wiki?curid=26404" title="Risk management">
Risk management

Risk management is the identification, evaluation, and prioritization of risks (defined in ISO 31000 as "the effect of uncertainty on objectives") followed by coordinated and economical application of resources to minimize, monitor, and control the probability or impact of unfortunate events or to maximize the realization of opportunities.

Risks can come from various sources including uncertainty in financial markets, threats from project failures (at any phase in design, development, production, or sustaining of life-cycles), legal liabilities, credit risk, accidents, natural causes and disasters, deliberate attack from an adversary, or events of uncertain or unpredictable root-cause. There are two types of events i.e. negative events can be classified as risks while positive events are classified as opportunities. Risk management standards have been developed by various institutions, including the Project Management Institute, the National Institute of Standards and Technology, actuarial societies, and ISO standards. Methods, definitions and goals vary widely according to whether the risk management method is in the context of project management, security, engineering, industrial processes, financial portfolios, actuarial assessments, or public health and safety.

Strategies to manage threats (uncertainties with negative consequences) typically include avoiding the threat, reducing the negative effect or probability of the threat, transferring all or part of the threat to another party, and even retaining some or all of the potential or actual consequences of a particular threat, and the opposites for opportunities (uncertain future states with benefits).

Certain risk management standards have been criticized for having no measurable improvement on risk, whereas the confidence in estimates and decisions seems to increase. For example, one study found that one in six IT projects were "black swans" with gigantic overruns (cost overruns averaged 200%, and schedule overruns 70%).

A widely used vocabulary for risk management is defined by "ISO Guide 73:2009", "Risk management. Vocabulary."

In ideal risk management, a prioritization process is followed whereby the risks with the greatest loss (or impact) and the greatest probability of occurring are handled first, and risks with lower probability of occurrence and lower loss are handled in descending order. In practice the process of assessing overall risk can be difficult, and balancing resources used to mitigate between risks with a high probability of occurrence but lower loss versus a risk with high loss but lower probability of occurrence can often be mishandled.

Intangible risk management identifies a new type of a risk that has a 100% probability of occurring but is ignored by the organization due to a lack of identification ability. For example, when deficient knowledge is applied to a situation, a knowledge risk materializes. Relationship risk appears when ineffective collaboration occurs. Process-engagement risk may be an issue when ineffective operational procedures are applied. These risks directly reduce the productivity of knowledge workers, decrease cost-effectiveness, profitability, service, quality, reputation, brand value, and earnings quality. Intangible risk management allows risk management to create immediate value from the identification and reduction of risks that reduce productivity.

Opportunity cost represents a unique challenge for risk managers. It can be difficult to determine when to put resources toward risk management and when to use those resources elsewhere. Again, ideal risk management minimizes spending (or manpower or other resources) and also minimizes the negative effects of risks.

Risk is defined as the possibility that an event will occur that adversely affects the achievement of an objective. Uncertainty, therefore, is a key aspect of risk. Systems like the Committee of Sponsoring Organizations of the Tradeway Commission Enterprise Risk Management (COSO ERM), can assist managers in mitigating risk factors. Each company may have different internal control components, which leads to different outcomes. For example, the framework for ERM components includes Internal Environment, Objective Setting, Event Identification, Risk Assessment, Risk Response, Control Activities, Information and Communication, and Monitoring.

For the most part, these methods consist of the following elements, performed, more or less, in the following order.


The International Organization for Standardization (ISO) identifies the following principles of risk management:

Risk management should:

According to the standard ISO 31000 "Risk management â Principles and guidelines on implementation," the process of risk management consists of several steps as follows:

This involves:


After establishing the context, the next step in the process of managing risk is to identify potential risks. Risks are about events that, when triggered, cause problems or benefits. Hence, risk identification can start with the source of our problems and those of our competitors (benefit), or with the problem consequenses.
Examples of risk sources are: stakeholders of a project, employees of a company or the weather over an airport.
When either source or problem is known, the events that a source may trigger or the events that can lead to a problem can be investigated. For example: stakeholders withdrawing during a project may endanger funding of the project; confidential information may be stolen by employees even within a closed network; lightning striking an aircraft during takeoff may make all people on board immediate casualties.

The chosen method of identifying risks may depend on culture, industry practice and compliance. The identification methods are formed by templates or the development of templates for identifying source, problem or event. Common risk identification methods are:

Once risks have been identified, they must then be assessed as to their potential severity of impact (generally a negative impact, such as damage or loss) and to the probability of occurrence. These quantities can be either simple to measure, in the case of the value of a lost building, or impossible to know for sure in the case of an unlikely event, the probability of occurrence of which is unknown. Therefore, in the assessment process it is critical to make the best educated decisions in order to properly prioritize the implementation of the risk management plan.

Even a short-term positive improvement can have long-term negative impacts. Take the "turnpike" example. A highway is widened to allow more traffic. More traffic capacity leads to greater development in the areas surrounding the improved traffic capacity. Over time, traffic thereby increases to fill available capacity. Turnpikes thereby need to be expanded in a seemingly endless cycles. There are many other engineering examples where expanded capacity (to do any function) is soon filled by increased demand. Since expansion comes at a cost, the resulting growth could become unsustainable without forecasting and management.

The fundamental difficulty in risk assessment is determining the rate of occurrence since statistical information is not available on all kinds of past incidents and is particularly scanty in the case of catastrophic events, simply because of their infrequency. Furthermore, evaluating the severity of the consequences (impact) is often quite difficult for intangible assets. Asset valuation is another question that needs to be addressed. Thus, best educated opinions and available statistics are the primary sources of information. Nevertheless, risk assessment should produce such information for senior executives of the organization that the primary risks are easy to understand and that the risk management decisions may be prioritized within overall company goals. Thus, there have been several theories and attempts to quantify risks. Numerous different risk formulae exist, but perhaps the most widely accepted formula for risk quantification is: "Rate (or probability) of occurrence multiplied by the impact of the event equals risk magnitude."

Risk mitigation measures are usually formulated according to one or more of the following major risk options, which are:


Later research has shown that the financial benefits of risk management are less dependent on the formula used but are more dependent on the frequency and how risk assessment is performed.

In business it is imperative to be able to present the findings of risk assessments in financial, market, or schedule terms. Robert Courtney Jr. (IBM, 1970) proposed a formula for presenting risks in financial terms. The Courtney formula was accepted as the official risk analysis method for the US governmental agencies. The formula proposes calculation of ALE (annualized loss expectancy) and compares the expected loss value to the security control implementation costs (cost-benefit analysis).

Once risks have been identified and assessed, all techniques to manage the risk fall into one or more of these four major categories:


Ideal use of these risk control strategies may not be possible. Some of them may involve trade-offs that are not acceptable to the organization or person making the risk management decisions. Another source, from the US Department of Defense (see link), Defense Acquisition University, calls these categories ACAT, for Avoid, Control, Accept, or Transfer. This use of the ACAT acronym is reminiscent of another ACAT (for Acquisition Category) used in US Defense industry procurements, in which Risk Management figures prominently in decision making and planning.

This includes not performing an activity that could present risk. Refusing to purchase a property or business to avoid legal liability is one such example. Avoiding airplane flights for fear of hijacking. Avoidance may seem like the answer to all risks, but avoiding risks also means losing out on the potential gain that accepting (retaining) the risk may have allowed. Not entering a business to avoid the risk of loss also avoids the possibility of earning profits. Increasing risk regulation in hospitals has led to avoidance of treating higher risk conditions, in favor of patients presenting with lower risk.

Risk reduction or "optimization" involves reducing the severity of the loss or the likelihood of the loss from occurring. For example, sprinklers are designed to put out a fire to reduce the risk of loss by fire. This method may cause a greater loss by water damage and therefore may not be suitable. Halon fire suppression systems may mitigate that risk, but the cost may be prohibitive as a strategy.

Acknowledging that risks can be positive or negative, optimizing risks means finding a balance between negative risk and the benefit of the operation or activity; and between risk reduction and effort applied. By effectively applying Health, Safety and Environment (HSE) management standards, organizations can achieve tolerable levels of residual risk.

Modern software development methodologies reduce risk by developing and delivering software incrementally. Early methodologies suffered from the fact that they only delivered software in the final phase of development; any problems encountered in earlier phases meant costly rework and often jeopardized the whole project. By developing in iterations, software projects can limit effort wasted to a single iteration.

Outsourcing could be an example of risk sharing strategy if the outsourcer can demonstrate higher capability at managing or reducing risks. For example, a company may outsource only its software development, the manufacturing of hard goods, or customer support needs to another company, while handling the business management itself. This way, the company can concentrate more on business development without having to worry as much about the manufacturing process, managing the development team, or finding a physical location for a center.

Briefly defined as "sharing with another party the burden of loss or the benefit of gain, from a risk, and the measures to reduce a risk."

The term of 'risk transfer' is often used in place of risk sharing in the mistaken belief that you can transfer a risk to a third party through insurance or outsourcing. In practice if the insurance company or contractor go bankrupt or end up in court, the original risk is likely to still revert to the first party. As such in the terminology of practitioners and scholars alike, the purchase of an insurance contract is often described as a "transfer of risk." However, technically speaking, the buyer of the contract generally retains legal responsibility for the losses "transferred", meaning that insurance may be described more accurately as a post-event compensatory mechanism. For example, a personal injuries insurance policy does not transfer the risk of a car accident to the insurance company. The risk still lies with the policy holder namely the person who has been in the accident. The insurance policy simply provides that if an accident (the event) occurs involving the policy holder then some compensation may be payable to the policy holder that is commensurate with the suffering/damage.

Some ways of managing risk fall into multiple categories. Risk retention pools are technically retaining the risk for the group, but spreading it over the whole group involves transfer among individual members of the group. This is different from traditional insurance, in that no premium is exchanged between members of the group up front, but instead losses are assessed to all members of the group.

Risk retention involves accepting the loss, or benefit of gain, from a risk when the incident occurs. True self-insurance falls in this category. Risk retention is a viable strategy for small risks where the cost of insuring against the risk would be greater over time than the total losses sustained. All risks that are not avoided or transferred are retained by default. This includes risks that are so large or catastrophic that either they cannot be insured against or the premiums would be infeasible. War is an example since most property and risks are not insured against war, so the loss attributed to war is retained by the insured. Also any amounts of potential loss (risk) over the amount insured is retained risk. This may also be acceptable if the chance of a very large loss is small or if the cost to insure for greater coverage amounts is so great that it would hinder the goals of the organization too much.

Select appropriate controls or countermeasures to mitigate each risk. Risk mitigation needs to be approved by the appropriate level of management. For instance, a risk concerning the image of the organization should have top management decision behind it whereas IT management would have the authority to decide on computer virus risks.

The risk management plan should propose applicable and effective security controls for managing the risks. For example, an observed high risk of computer viruses could be mitigated by acquiring and implementing antivirus software. A good risk management plan should contain a schedule for control implementation and responsible persons for those actions.

According to ISO/IEC 27001, the stage immediately after completion of the risk assessment phase consists of preparing a Risk Treatment Plan, which should document the decisions about how each of the identified risks should be handled. Mitigation of risks often means selection of security controls, which should be documented in a Statement of Applicability, which identifies which particular control objectives and controls from the 
standard have been selected, and why.

Implementation follows all of the planned methods for mitigating the effect of the risks. Purchase insurance policies for the risks that it has been decided to transferred to an insurer, avoid all risks that can be avoided without sacrificing the entity's goals, reduce others, and retain the rest.

Initial risk management plans will never be perfect. Practice, experience, and actual loss results will necessitate changes in the plan and contribute information to allow possible different decisions to be made in dealing with the risks being faced.

Risk analysis results and management plans should be updated periodically. There are two primary reasons for this: 

Prioritizing the "risk management processes" too highly could keep an organization from ever completing a project or even getting started. This is especially true if other work is suspended until the risk management process is considered complete.

It is also important to keep in mind the distinction between risk and uncertainty. Risk can be measured by impacts Ã probability.

If risks are improperly assessed and prioritized, time can be wasted in dealing with risk of losses that are not likely to occur. Spending too much time assessing and managing unlikely risks is to be avoided. Unlikely events do occur but if the risk is unlikely enough to occur it may be better to simply retain the risk and deal with the result if the loss does in fact occur. Qualitative risk assessment is subjective and lacks consistency. The primary justification for a formal risk assessment process is legal and bureaucratic.

As applied to corporate finance, "risk management" is the technique for measuring, monitoring and controlling the financial or operational risk on a firm's balance sheet, a traditional measure is the value at risk (VaR), but there also other measures like profit at risk (PaR) or margin at risk. The Basel II framework breaks risks into market risk (price risk), credit risk and operational risk and also specifies methods for calculating capital requirements for each of these components.

In Information Technology, Risk management includes "Incident Handling", an action plan for dealing with intrusions, cyber-theft, denial of service, fire, floods, and other security-related events. According to the SANS Institute, it is a six step process: Preparation, Identification, Containment, Eradication, Recovery, and Lessons Learned.

In enterprise risk management, a risk is defined as a possible event or circumstance that can have negative influences on the enterprise in question. Its impact can be on the very existence, the resources (human and capital), the products and services, or the customers of the enterprise, as well as external impacts on society, markets, or the environment. In a financial institution, enterprise risk management is normally thought of as the combination of credit risk, interest rate risk or asset liability management, liquidity risk, market risk, and operational risk.

In the more general case, every probable risk can have a pre-formulated plan to deal with its possible consequences (to ensure "contingency" if the risk becomes a "liability").

From the information above and the average cost per employee over time, or cost accrual ratio, a project manager can estimate:


Risk in a project or process can be due either to Special Cause Variation or Common Cause Variation and requires appropriate treatment. That is to re-iterate the concern about extremal cases not being equivalent in the list immediately above.

ESRM is a security program management approach that links security activities to an enterprise's mission and business goals through risk management methods. The security leader's role in ESRM is to manage risks of harm to enterprise assets in partnership with the business leaders whose assets are exposed to those risks. ESRM involves educating business leaders on the realistic impacts of identified risks, presenting potential strategies to mitigate those impacts, then enacting the option chosen by the business in line with accepted levels of business risk tolerance

For medical devices, risk management is a process for identifying, evaluating and mitigating risks associated with harm to people and damage to property or the environment. Risk management is an integral part of medical device design and development, production processes and evaluation of field experience, and is applicable to all types of medical devices. The evidence of its application is required by most regulatory bodies such as the US FDA. The management of risks for medical devices is described by the International Organization for Standardization (ISO) in ISO 14971:2007, Medical DevicesâThe application of risk management to medical devices, a product safety standard. The standard provides a process framework and associated requirements for management responsibilities, risk analysis and evaluation, risk controls and lifecycle risk management.

The European version of the risk management standard was updated in 2009 and again in 2012 to refer to the Medical Devices Directive (MDD) and Active Implantable Medical Device Directive (AIMDD) revision in 2007, as well as the In Vitro Medical Device Directive (IVDD). The requirements of EN 14971:2012 are nearly identical to ISO 14971:2007. The differences include three "(informative)" Z Annexes that refer to the new MDD, AIMDD, and IVDD. These annexes indicate content deviations that include the requirement for risks to be reduced "as far as possible", and the requirement that risks be mitigated by design and not by labeling on the medical device (i.e., labeling can no longer be used to mitigate risk).

Typical risk analysis and evaluation techniques adopted by the medical device industry include hazard analysis, fault tree analysis (FTA), failure mode and effects analysis (FMEA), hazard and operability study (HAZOP), and risk traceability analysis for ensuring risk controls are implemented and effective (i.e. tracking risks identified to product requirements, design specifications, verification and validation results etc.). FTA analysis requires diagramming software. FMEA analysis can be done using a spreadsheet program. There are also integrated medical device risk management solutions.

Through a draft guidance, the FDA has introduced another method named "Safety Assurance Case" for medical device safety assurance analysis. The safety assurance case is structured argument reasoning about systems appropriate for scientists and engineers, supported by a body of evidence, that provides a compelling, comprehensible and valid case that a system is safe for a given application in a given environment. With the guidance, a safety assurance case is expected for safety critical devices (e.g. infusion devices) as part of the pre-market clearance submission, e.g. 510(k). In 2013, the FDA introduced another draft guidance expecting medical device manufacturers to submit cybersecurity risk analysis information.

Project risk management must be considered at the different phases of acquisition. In the beginning of a project, the advancement of technical developments, or threats presented by a competitor's projects, may cause a risk or threat assessment and subsequent evaluation of alternatives (see Analysis of Alternatives). Once a decision is made, and the project begun, more familiar project management applications can be used:


Megaprojects (sometimes also called "major programs") are large-scale investment projects, typically costing more than $1 billion per project. Megaprojects include major bridges, tunnels, highways, railways, airports, seaports, power plants, dams, wastewater projects, coastal flood protection schemes, oil and natural gas extraction projects, public buildings, information technology systems, aerospace projects, and defense systems. Megaprojects have been shown to be particularly risky in terms of finance, safety, and social and environmental impacts. Risk management is therefore particularly pertinent for megaprojects and special methods and special education have been developed for such risk management.

It is important to assess risk in regard to natural disasters like floods, earthquakes, and so on. Outcomes of natural disaster risk assessment are valuable when considering future repair costs, business interruption losses and other downtime, effects on the environment, insurance costs, and the proposed costs of reducing the risk. The Sendai Framework for Disaster Risk Reduction is a 2015 international accord that has set goals and targets for disaster risk reduction in response to natural disasters. There are regular International Disaster and Risk Conferences in Davos to deal with integral risk management.

The management of risks to persons and property in wilderness and remote natural areas has developed with increases in outdoor recreation participation and decreased social tolerance for loss. Organizations providing commercial wilderness experiences can now align with national and international consensus standards for training and equipment such as ANSI/NASBLA 101-2017 (boating), UIAA 152 (ice climbing tools), and European Norm 13089:2015 + A1:2015 (mountaineering equipment). The Association for Experiential Education offers accreditation for wilderness adventure programs. The Wilderness Risk Management Conference provides access to best practices, and specialist organizations provide wilderness risk management consulting and training.

In his book, "Outdoor Leadership and Education", climber, outdoor educator, and author, Ari Schneider, notes that outdoor recreation is inherently risky, and there is no way to completely eliminate risk. However, he explains how that can be a good thing for outdoor education programs. According to Schneider, optimal adventure is achieved when real risk is managed and perceived risk is maintained in order to keep actual danger low and a sense of adventure high.

One popular models for risk assessment is the Risk Assessment and Safety Management (RASM) Model developed by Rick Curtis, author of The Backpacker's Field Manual. The formula for the RASM Model is: Risk = Probability of Accident Ã Severity of Consequences. The RASM Model weighs negative riskâthe potential for loss, against positive riskâthe potential for growth.

IT risk is a risk related to information technology. This is a relatively new term due to an increasing awareness that information security is simply one facet of a multitude of risks that are relevant to IT and the real world processes it supports. "Cybersecurity is tied closely to the advancement of technology. It lags only long enough for incentives like black markets to evolve and new exploits to be discovered. There is no end in sight for the advancement of technology, so we can expect the same from cybersecurity."

ISACA's "Risk IT" framework ties IT risk to enterprise risk management.

Duty of Care Risk Analysis (DoCRA) evaluates risks and their safeguards and considers the interests of all parties potentially affected by those risks.

CIS RAM provides a method to design and evaluate the implementation of the CIS Controlsâ¢.

For the offshore oil and gas industry, operational risk management is regulated by the safety case regime in many countries. Hazard identification and risk assessment tools and techniques are described in the international standard ISO 17776:2000, and organisations such as the IADC (International Association of Drilling Contractors) publish guidelines for Health, Safety and Environment (HSE) Case development which are based on the ISO standard. Further, diagrammatic representations of hazardous events are often expected by governmental regulators as part of risk management in safety case submissions; these are known as bow-tie diagrams (see Network theory in risk assessment). The technique is also used by organisations and regulators in mining, aviation, health, defence, industrial and finance.

The principles and tools for quality risk management are increasingly being applied to different aspects of pharmaceutical quality systems. These aspects include development, manufacturing, distribution, inspection, and submission/review processes throughout the lifecycle of drug substances, drug products, biological and biotechnological products (including the use of raw materials, solvents, excipients, packaging and labeling materials in drug products, biological and biotechnological products). Risk management is also applied to the assessment of microbiological contamination in relation to pharmaceutical products and cleanroom manufacturing environments.

Risk communication is a complex cross-disciplinary academic field related to core values of the targeted audiences. Problems for risk communicators involve how to reach the intended audience, how to make the risk comprehensible and relatable to other risks, how to pay appropriate respect to the audience's values related to the risk, how to predict the audience's response to the communication, etc. A main goal of risk communication is to improve collective and individual decision making. Risk communication is somewhat related to crisis communication. Some experts coincide that risk is not only enrooted in the communication process but also it cannot be dissociated from the use of language. Though each culture develops its own fears and risks, these construes apply only by the hosting culture.




</doc>
<doc id="26408" url="https://en.wikipedia.org/wiki?curid=26408" title="Rainer Maria Rilke">
Rainer Maria Rilke

RenÃ© Karl Wilhelm Johann Josef Maria Rilke (4 December 1875Â â 29 December 1926), better known as Rainer Maria Rilke (), was a Bohemian-Austrian poet and novelist. He is "widely recognized as one of the most lyrically intense German-language poets". He wrote both verse and highly lyrical prose. Several critics have described Rilke's work as "mystical". His writings include one novel, several collections of poetry and several volumes of correspondence in which he invokes images that focus on the difficulty of communion with the ineffable in an age of disbelief, solitude and anxiety. These themes position him as a transitional figure between traditional and modernist writers.

Rilke travelled extensively throughout Europe (including Russia, Spain, Germany, France and Italy) and, in his later years, settled in SwitzerlandÂ â settings that were key to the genesis and inspiration for many of his poems. While Rilke is most known for his contributions to German literature, over 400 poems were originally written in French and dedicated to the canton of Valais in Switzerland. Among English-language readers, his best-known works include the poetry collections "Duino Elegies" (') and "Sonnets to Orpheus" ('), the semi-autobiographical novel "The Notebooks of Malte Laurids Brigge" ('), and a collection of ten letters that was published after his death under the title "Letters to a Young Poet" ('). In the later 20th century, his work found new audiences through use by New Age theologians and self-help authors and frequent quotations by television programs, books and motion pictures. In the United States, Rilke remains among the more popular, best-selling poets.

He was born RenÃ© Karl Wilhelm Johann Josef Maria Rilke in Prague, capital of Bohemia (then part of Austria-Hungary, now part of the Czech Republic). His childhood and youth in Prague were not especially happy. His father, Josef Rilke (1838â1906), became a railway official after an unsuccessful military career. His mother, Sophie ("Phia") Entz (1851â1931), came from a well-to-do Prague family, the Entz-Kinzelbergers, who lived in a house on the Herrengasse (PanskÃ¡) 8, where RenÃ© also spent many of his early years. The relationship between Phia and her only son was coloured by her mourning for an earlier child, a daughter who had died only one week old. During Rilke's early years, Phia acted as if she sought to recover the lost girl through the boy by treating him as if he were a girl. According to Rilke, he had to wear "fine clothes" and "was a plaything [for his mother], like a big doll". His parents' marriage failed in 1884. His parents pressured the poetically and artistically talented youth into entering a military academy in Sankt PÃ¶lten, Lower Austria, which he attended from 1886 until 1891, when he left owing to illness. He moved to Linz, where he attended trade school. Expelled from school in May 1892, the 16-year-old prematurely returned to Prague. From 1892 to 1895, he was tutored for the university entrance exam, which he passed in 1895. Until 1896, he studied literature, art history, and philosophy in Prague and Munich.

In 1897 in Munich, Rainer Maria Rilke met and fell in love with the widely travelled, intellectual woman of letters, Lou Andreas-SalomÃ©. Rilke changed his first name from "RenÃ©" to "Rainer" at SalomÃ©'s urging, because she thought that name to be more masculine, forceful, and Germanic. His relationship with this married woman, with whom he undertook two extensive trips to Russia, lasted until 1900. Even after their separation, SalomÃ© continued to be Rilke's most important confidante until the end of his life. Having trained from 1912 to 1913 as a psychoanalyst with Sigmund Freud, she shared her knowledge of psychoanalysis with Rilke.

In 1898, Rilke undertook a journey lasting several weeks to Italy. In 1899, he travelled with Lou and her husband, Friedrich Carl Andreas, to Moscow where he met the novelist Leo Tolstoy. Between May and August 1900, a second journey to Russia, accompanied only by Lou, again took him to Moscow and Saint Petersburg, where he met the family of Boris Pasternak and Spiridon Drozhzhin, a peasant poet. Author Anna A. Tavis cites the cultures of Bohemia and Russia as the key influences on Rilke's poetry and consciousness.

In 1900, Rilke stayed at the artists' colony at Worpswede. (Later, his portrait would be painted by the proto-expressionist Paula Modersohn-Becker, whom he got to know at Worpswede.) It was here that he got to know the sculptor Clara Westhoff, whom he married the following year. Their daughter Ruth (1901â1972) was born in December 1901.

In the summer of 1902, Rilke left home and travelled to Paris to write a monograph on the sculptor Auguste Rodin. Before long his wife left their daughter with her parents and joined Rilke there. The relationship between Rilke and Clara Westhoff continued for the rest of his life; a mutually-agreed-upon effort towards a divorce was bureaucratically hindered by the fact that Rilke was a Catholic, albeit a non-practising one.

At first, Rilke had a difficult time in Paris, an experience that he called upon in the first part of his only novel, "The Notebooks of Malte Laurids Brigge". At the same time his encounter with modernism was very stimulating: Rilke became deeply involved with the sculpture of Rodin and then the work of Paul CÃ©zanne. For a time, he acted as Rodin's secretary, also lecturing and writing a long essay on Rodin and his work. Rodin taught him the value of objective observation and, under this influence, Rilke dramatically transformed his poetic style from the subjective and sometimes incantatory language of his earlier work into something quite new in European literature. The result was the "New Poems", famous for the "thing-poems" expressing Rilke's rejuvenated artistic vision. During these years, Paris increasingly became the writer's main residence.

The most important works of the Paris period were "Neue Gedichte" ("New Poems") (1907), "Der Neuen Gedichte Anderer Teil" ("Another Part of the New Poems") (1908), the two "Requiem" poems (1909), and the novel "The Notebooks of Malte Laurids Brigge", started in 1904 and completed in January 1910.

During the later part of this decade, Rilke spent extended periods in Ronda, the famous bullfighting centre in southern Spain. There he kept from December 1912 to February 1913 a permanent room at the Hotel Reina Victoria

Between October 1911 and May 1912, Rilke stayed at the Castle Duino, near Trieste, home of Princess Marie of Thurn und Taxis. There, in 1912, he began the poem cycle called the "Duino Elegies", which would remain unfinished for a decade because of a long-lasting creativity crisis. Rilke had developed an admiration for El Greco as early as 1908, so he visited Toledo during the winter of 1912/13 to see Greco's paintings. It has been suggested that Greco's manner of depicting angels has influenced the conception of the angel in the Duino Elegies. The outbreak of World War I surprised Rilke during a stay in Germany. He was unable to return to Paris, where his property was confiscated and auctioned. He spent the greater part of the war in Munich. From 1914 to 1916 he had a turbulent affair with the painter Lou Albert-Lasard. Rilke was called up at the beginning of 1916 and had to undertake basic training in Vienna. Influential friends interceded on his behalfÂ â he was transferred to the War Records Office and discharged from the military on 9 June 1916. He returned to Munich, interrupted by a stay on Gut Bockel in Westphalia. The traumatic experience of military service, a reminder of the horrors of the military academy, almost completely silenced him as a poet.

On 11 June 1919, Rilke travelled from Munich to Switzerland. The outward motive was an invitation to lecture in Zurich, but the real reason was the wish to escape the post-war chaos and take up his work on the "Duino Elegies" once again. The search for a suitable and affordable place to live proved to be very difficult. Among other places, Rilke lived in Soglio, Locarno and Berg am Irchel. Only in mid-1921 was he able to find a permanent residence in the ChÃ¢teau de Muzot in the commune of Veyras, close to Sierre in Valais. In an intense creative period, Rilke completed the "Duino Elegies" in several weeks in February 1922. Before and after, Rilke rapidly wrote both parts of the poem cycle "Sonnets to Orpheus" containing 55 entire sonnets. Together, these two have often been taken as constituting the high points of Rilke's work. In May 1922, Rilke's patron Werner Reinhart bought and renovated Muzot so that Rilke could live there rent-free.

During this time, Reinhart introduced Rilke to his protÃ©gÃ©e, the Australian violinist Alma Moodie. Rilke was so impressed with her playing that he wrote in a letter: "What a sound, what richness, what determination. That and the "Sonnets to Orpheus", those were two strings of the same voice. And she plays mostly Bach! Muzot has received its musical christeningÂ ..."

From 1923 on, Rilke increasingly had to struggle with health problems that necessitated many long stays at a sanatorium in Territet, near Montreux, on Lake Geneva. His long stay in Paris between January and August 1925 was an attempt to escape his illness through a change in location and living conditions. Despite this, numerous important individual poems appeared in the years 1923â1926 (including "Gong" and "Mausoleum"), as well as the abundant lyrical work in French. His book of French poems "Vergers" was published in 1926.

In 1924, Erika Mitterer began writing poems to Rilke, who wrote back with approximately 50 poems of his own and called her verse a "Herzlandschaft" (landscape of the heart). This was the only time Rilke had a productive poetic collaboration throughout all his work. Mitterer also visited Rilke. In 1950, her "Correspondence in Verse" with Rilke was published, and received much praise.

Rilke supported the Russian Revolution in 1917 as well as the Bavarian Soviet Republic in 1919. He became friends with Ernst Toller and mourned the deaths of Rosa Luxemburg, Kurt Eisner, and Karl Liebknecht. He confided that of the five or six newspapers he read daily, those on the far left came closest to his own opinions. He developed a reputation for supporting left-wing causes, and thus, out of fear for his own safety, became more reticent about politics after the Bavarian Republic was crushed by the right-wing Freikorps. In January and February 1926, Rilke wrote three letters to the Mussolini-adversary Aurelia Gallarati in which he praised Benito Mussolini and described fascism as a healing agent.

Shortly before his death, Rilke's illness was diagnosed as leukemia. He suffered ulcerous sores in his mouth, pain troubled his stomach and intestines, and he struggled with increasingly low spirits. Open-eyed, he died in the arms of his doctor on December 29, 1926, in the Valmont Sanatorium in Switzerland. He was buried on January 2, 1927, in the Raron cemetery to the west of Visp.

Rilke had chosen as his own epitaph this poem:

<poem>Rose, oh reiner Widerspruch, Lust, Niemandes Schlaf zu sein unter soviel Lidern.</poem>

<poem>Rose, o pure contradiction, desire
to be no one's sleep beneath so many
lids.</poem>
A myth developed surrounding his death and roses. It was said: "To honour a visitor, the Egyptian beauty Nimet Eloui Bey, Rilke gathered some roses from his garden. While doing so, he pricked his hand on a thorn. This small wound failed to heal, grew rapidly worse, soon his entire arm was swollen, and his other arm became affected as well", and so he died.

Rilke published the three complete cycles of poems that constitute "The Book of Hours" ("") in April 1905. These poems explore the Christian search for God and the nature of Prayer, using symbolism from Saint Francis and Rilke's observation of Orthodox Christianity during his travels in Russia in the early years of the twentieth century.

Rilke wrote his only novel, "" (translated as "The Notebooks of Malte Laurids Brigge"), while living in Paris, completing the work in 1910. This semi-autobiographical novel adopts the style and technique that became associated with Expressionism, which entered European fiction and art in the early 20th century. Rilke was inspired by SigbjÃ¸rn Obstfelder's work "A Priest's Diary" and Jens Peter Jacobsen's second novel "Niels Lyhne" (1880), which traces the fate of an atheist in a merciless world. Rilke addresses existential themes, profoundly probing the quest for individuality, the significance of death, and reflection on the experience of time as death approaches. Rilke draws considerably on the writings of Nietzsche, whose work he came to know through Lou Andreas-SalomÃ©. His work also incorporates impressionistic techniques that were influenced by CÃ©zanne and Rodin (to whom Rilke was secretary in 1905â1906). He combines these techniques and motifs to conjure images of mankind's anxiety and alienation in the face of an increasingly scientific, industrial, reified world.

Rilke began writing the elegies in 1912 while a guest of Princess Marie von Thurn und Taxis (1855â1934) at Duino Castle, near Trieste on the Adriatic Sea. During this ten-year period, the elegies languished incomplete for long stretches of time as Rilke suffered frequently from severe depression, some of which was caused by the events of World War I and his conscripted military service. Aside from brief episodes of writing in 1913 and 1915, Rilke did not return to the work until a few years after the war ended. With a sudden, renewed inspirationÂ â writing in a frantic pace he described as "a savage creative storm"Â â he completed the collection in February 1922 while staying at ChÃ¢teau de Muzot in Veyras, in Switzerland's RhÃ´ne Valley. After their publication and his death shortly thereafter, the "Duino Elegies" were quickly recognized by critics and scholars as Rilke's most important work.

The "Duino Elegies" are intensely religious, mystical poems that weigh beauty and existential suffering. The poems employ a rich symbolism of angels and salvation but not in keeping with typical Christian interpretations. Rilke begins the first elegy in an invocation of philosophical despair, asking: "Who, if I cried out, would hear me among the hierarchies of angels?" ("Wer, wenn ich schriee, hÃ¶rte mich denn aus der Engel Ordnungen?") and later declares that "every angel is terrifying" ("Jeder Engel ist schrecklich"). While labelling of these poems as "elegies" would typically imply melancholy and lamentation, many passages are marked by their positive energy and "unrestrained enthusiasm". Together, the "Duino Elegies" are described as a metamorphosis of Rilke's "ontological torment" and an "impassioned monologue about coming to terms with human existence" discussing themes of "the limitations and insufficiency of the human condition and fractured human consciousnessÂ ... man's loneliness, the perfection of the angels, life and death, love and lovers, and the task of the poet".

With news of the death of his daughter's friend, Wera Knoop (1900â1919), Rilke was inspired to create and set to work on "Sonnets to Orpheus". Within a few days, between February 2 and 5, 1922, he had completed the first section of 26 sonnets. For the next few days, he focused on the "Duino Elegies", completing them on the evening of February 11. Immediately after, he returned to work on the "Sonnets" and completed the following section of 29 sonnets in less than two weeks. Throughout the "Sonnets", Wera is frequently referenced, both directly by name and indirectly in allusions to a "dancer" and the mythical Eurydice. Although Rilke claimed that the entire cycle was inspired by Wera, she appears as a character in only one of the poems. He insisted, however, that "Wera's own figureÂ ... nevertheless governs and moves the course of the whole."

The sonnets' contents are, as is typical of Rilke, highly metaphorical. The character of Orpheus (whom Rilke refers to as the "god with the lyre") appears several times in the cycle, as do other mythical characters such as Daphne. There are also biblical allusions, including a reference to Esau. Other themes involve animals, peoples of different cultures, and time and death.

In 1929, a minor writer, Franz Xaver Kappus (1883â1966), published a collection of ten letters that Rilke had written to him when he was a 19-year-old officer cadet studying at the Theresian Military Academy in Wiener Neustadt. The young Kappus wrote to Rilke, who had also attended the academy, between 1902 and 1908 when he was uncertain about his future career as a military officer or as a poet. Initially, he sought Rilke's advice as to the quality of his poetry, and whether he ought to pursue writing as a career. While he declined to comment on Kappus's writings, Rilke advised Kappus on how a poet should feel, love, and seek truth in trying to understand and experience the world around him and engage the world of art. These letters offer insight into the ideas and themes that appear in Rilke's poetry and his working process. Further, these letters were written during a key period of Rilke's early artistic development after his reputation as a poet began to be established with the publication of parts of "Das Stunden-Buch" ("The Book of Hours") and "Das Buch der Bilder" ("The Book of Images").

Figures from Greek mythology (such as Apollo, Hermes and Orpheus) recur as motifs in his poems and are depicted in original interpretations (e.g. in the poem "Orpheus. Eurydice. Hermes", Rilke's Eurydice, numbed and dazed by death, does not recognize her lover Orpheus, who descended to hell to recover her). Other recurring figures in Rilke's poems are angels, roses and a character of a poet and his creative work.

Rilke often worked with metaphors, metonymy and contradictions. For example, in his epitaph, the rose is a symbol of sleepÂ â rose petals are reminiscent of closed eyelids.

Rilke's little-known 1898 poem, "Visions of Christ" depicted Mary Magdalene as the mother to Jesus' child. Quoting Susan Haskins: "But it was his [Rilke's] explicit belief that Christ was not divine, was entirely human, and deified only on Calvary, expressed in an unpublished poem of 1893, and referred to in other poems of the same period, which allowed him to portray Christ's love for Mary Magdalen, though remarkable, as entirely human."

In the United States, Rilke is one of the more popular, best-selling poets. In popular culture, Rilke is frequently quoted or referenced in television programs, motion pictures, music and other works when these works discuss the subject of love or angels. His work is often described as "mystical" and has been seized by the New Age community and self-help books. Rilke has been reinterpreted "as a master who can lead us to a more fulfilled and less anxious life".

Rilke's work (specifically the "Duino Elegies") has deeply influenced several poets and writers, including William H. Gass, Galway Kinnell, Sidney Keyes, Stephen Spender, Robert Bly, W. S. Merwin, John Ashbery, novelist Thomas Pynchon and philosophers Ludwig Wittgenstein and Hans-Georg Gadamer. British poet W. H. Auden (1907â1973) has been described as "Rilke's most influential English disciple" and he frequently "paid homage to him" or used the imagery of angels in his work.




Collected letters

Other volumes of letters






</doc>
<doc id="26409" url="https://en.wikipedia.org/wiki?curid=26409" title="Richard Doyle">
Richard Doyle

Richard Doyle may refer to:



</doc>
