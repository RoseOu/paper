<doc id="26179" url="https://en.wikipedia.org/wiki?curid=26179" title="Ron Popeil">
Ron Popeil

Ronald M. Popeil (; born May 3, 1935) is an American inventor and marketing personality, best known for his direct response marketing company Ronco. He is well known for his appearances in infomercials for the Showtime Rotisserie and the coined phrase "Set it, and forget it!" as well as popularizing the phrase, "But wait, there's more!" on television as early as the mid-1950s.

Popeil was born to a Jewish family in New York City in 1935. When he was 6 his parents divorced and he and his brother went to live in Florida with their grandparents. At age 17 in 1952, Ron went with his grandparents to work for his father, Samuel Popeil, at his company's (Popeil Brothers) manufacturing facility in Chicago. His grandparents later returned to Florida and Ron remained with his father.

Popeil learned his trade from his father, who was also an inventor and salesman of numerous kitchen-related gadgets such as the Chop-O-Matic and the Veg-O-Matic to major department stores. The Chop-O-Matic retailed for US$3.98 and sold over two million units. It indirectly spurred Ron Popeil's move into television, as it was so efficient at chopping vegetables it was impractical for salesmen to carry all they needed for their pitches. The solution was to tape the demonstration. Once done, the leap to infomercial followed.

Ron initially operated as a distributor of his father's kitchen products and later formed his own company (Ronco) in 1964. He continued as a distributor for his father and added additional products from other manufacturers. Ron and his father (Samuel) became competitors in the 1970s for the same retail store business.

Popeil received the Ig Nobel Prize in Consumer Engineering in 1993. The awards committee described him as the "incessant inventor and perpetual pitchman of late night television" and awarded the prize in recognition of his "redefining the industrial revolution" with his devices. He is a past member of the board of directors Mirage Resorts where he served for 22 years under Steve Wynn as well as a past member of the board of directors of MGM Hotels for 7 years under Kirk Kerkorian. He became the recipient of the Electronic Retail Association's Lifetime Achievement award in 2001 and he is listed in the Direct Response Hall of Fame.

He is currently a member of the advisory board for University of California Los Angeles' Business, Management and Legal Programs. In August 2005, he sold his company, Ronco, to Fi-Tek VII, a Denver holding company, for US$55 million, with plans to continue serving as the spokesman and inventor while being able to spend more time with his family.

In 1956, he married Marilyn Greene, with whom he had two daughters; they divorced in 1963. He married Lisa Boehne sometime after this and has one daughter with her. He and Boehne divorced sometime before 1995, when he married Robin Angers, with whom he has two more daughters.

As of 2006, he lived in Beverly Hills, California, with his wife, Robin Popeil, and two of his five daughters. Ashley Tisdale and Jennifer Tisdale are his cousins.

Popeil is noted for marketing and in some cases inventing a wide variety of products. Among the better known and more successful are the Chop-O-Matic hand food processor ("Ladies and gentlemen, I'm going to show you the greatest kitchen appliance ever madeÂ ... All your onions chopped to perfection without shedding a single tear."), the Dial-O-Matic successor to the Veg-O-Matic ("Slice a tomato so thin it only has one side."), and the Ronco Pocket Fisherman. Popeil is also well known for his housewares inventions like his Giant Dehydrator and Beef Jerky Machine, his Electric Pasta Maker and his Showtime Rotisserie & BBQ. His Showtime Rotisserie & BBQ sold over 8 million units in the US alone, helping Ronco's housewares sales exceed $1 billion in profits. After retiring, Ron continued to invent products including the 5in1 Turkey Fryer & Food Cooking System which he has been developing for over ten years.

Ron Popeil's success in infomercials, memorable marketing personality, and ubiquity on American television have allowed him and his products to appear in a variety of popular media environments including cameo appearances on television shows such as "The X-Files", "Futurama", "King of the Hill", "The Simpsons", "Sex and the City", "The Daily Show" and "The West Wing". Parodies of Popeil's infomercials were done on the comedy show "Saturday Night Live" by Dan Aykroyd and Eddie Murphy and the "Veg-O-Matic" may have provided comedian Gallagher inspiration for the "Sledge-O-Matic" routine since the 1980s. The animated series "VeggieTales" once featured a parody of the "Veg-O-Matic" dubbed as the "Forgive-O-Matic". "Additionally, the professional wrestling tag team The Midnight Express dubbed their finishing move the Veg-O-Matic. 

Popeil was voted by "Self" Magazine readers as one of the 25 people who have changed the way we eat, drink and think about food.

Popeil has been referenced in the music of Alice Cooper, the Beastie Boys, and "Weird Al" Yankovic. Yankovic's song "Mr. Popeil" was a tribute to Ron's father, Samuel Popeil (and featured Ron's sister Lisa Popeil on backing vocals). Ron Popeil later used this song in some of his infomercials.

In Malcolm Gladwell's book "", Ron Popeil is interviewed and many of his products, most notably the Veg-O-Matic and Showtime Rotisserie, are discussed. Malcolm Gladwell's New Yorker piece "The Pitchman" about Ron Popeil won Gladwell the 2001 National Magazine award. The article was first published in "The New Yorker" in 2000.




</doc>
<doc id="26180" url="https://en.wikipedia.org/wiki?curid=26180" title="REO Speedwagon">
REO Speedwagon

REO Speedwagon (originally styled as R.E.O. Speedwagon) is an American rock band from Champaign, Illinois. Formed in 1967, the band cultivated a following during the 1970s and achieved significant commercial success throughout the 1980s. "Hi Infidelity" (1980) contained four US Top 40 hits and is the group's best-selling album, with over 10 million copies sold.

Over the course of its career, the band has sold more than 40 million records and has charted 13 Top 40 hits, including the number ones "Keep On Loving You" and "Can't Fight This Feeling". REO Speedwagon's mainstream popularity waned in the late 1980s, but the band remains a popular live act.

In the fall of 1966, Neal Doughty entered the electrical engineering program at the University of Illinois in Champaign, Illinois, as a junior. On his first night, he met fellow student Alan Gratzer. They held an impromptu jam session in the basement of their Illinois Street Residence Hall dormitory and soon started a rock band. Gratzer had been a drummer since high school, and was playing in a local group on the weekends, while Doughty had learned some Beatles songs on his parents' piano.

Doughty began to follow Gratzer's band, eventually sitting in on a song or two. The keyboard player was the leader, but several other band members were unhappy with the situation. On the last day of the university's spring semester, guitarist Joe Matt called the band's leader and told him that he, drummer Gratzer, and bassist Mike Blair had decided to leave the band to start a new one with Doughty.

They made a list of songs to learn over the summer break, and Doughty landed a summer job to buy his first keyboard. On his Farfisa organ, he learned "Light My Fire" by The Doors. The members returned to school in the fall of 1967, and had their first rehearsal before classes started. They named the band REO Speedwagon, from the REO Speed Wagon, a 1915 truck that was designed by Ransom Eli Olds. Doughty had seen the name written across the blackboard when he walked into his History of Transportation class on the first day they had decided to look for a name. Rather than pronouncing REO as a single word as the motor company did, they chose to spell out the name with the individual letters each pronounced ("R-E-O"). An advertisement in the school newspaper produced their first job, a fraternity party that turned into a food fight. They continued to perform cover songs in campus bars, fraternity parties, and university events. The first lineup consisted of Doughty on keyboards, Gratzer on drums and vocals, Joe Matt on guitar and vocals, Mike Blair on bass and vocals.

In early 1968, Terry Luttrell became lead singer, and Bob Crownover joined as the guitar player, replacing Matt. When Mike Blair left the band in the summer of 1968, Gregg Philbin replaced Blair, Marty Shepard played trumpet and Joe McCabe played sax until McCabe moved to Southern Illinois University. Crownover played guitar for the group until the summer of 1969 when Bill Fiorio replaced him. Fiorio then departed in late 1969, eventually assuming the name Duke Tumatoe, and went on to form the All Star Frogs. Steve Scorfina (who would go on to found progressive rock/album-oriented rock band Pavlov's Dog) came aboard for over a year, composing with the band and performing live, before being replaced by Gary Richrath in late 1970.

Richrath was a Peoria, Illinois-based guitarist and prolific songwriter who brought fresh original material to the band. Richrath had driven 100 miles to see the band and become a part of it. He is quoted as saying "I'm going to be a part of that band whether they like it or not", and then went about making it happen. With Richrath on board, the regional popularity of the band grew tremendously. The Midwestern United States was the original REO Speedwagon fan stronghold and is pivotal in this period of the band's history.

The band signed to Epic Records in 1971. Paul Leka, an East Coast record producer, brought the band to his recording studio in Bridgeport, Connecticut where it recorded original material for its first album. The lineup on the first album consisted of Richrath, Gratzer, Doughty, Philbin, and Luttrell.

With their equipment being hauled to dates in a friend's station wagon, REO played bars and clubs all over the Midwest. The band's debut album, "R.E.O. Speedwagon", was released on Epic Records in 1971. The most popular track on this record was "157 Riverside Avenue". The title refers to the Westport, Connecticut address, where the band stayed while recording in Leka's studio in Bridgeport and remains an in-concert favorite.

Although the rest of the band's lineup remained stable, REO Speedwagon switched lead vocalists three times for their first three albums. Luttrell left the band in early 1972, eventually becoming the vocalist for Starcastle. He was replaced by Kevin Cronin. Cronin recorded one album with the band, 1972's "R.E.O./T.W.O." but left the band during the recording sessions for 1973's "Ridin' the Storm Out" because of internal conflicts. "Ridin' the Storm Out" was completed with Michael Bryan Murphy on lead vocal, and featured Neal Doughty's "wailing storm siren" entrance on the title track. Murphy stayed on for two more albums, "Lost in a Dream" and "This Time We Mean It", before Cronin returned to the fold in January 1976 and recorded "R.E.O.", which was released that same year.

Cronin's return came after Greg X. Volz turned down the position for lead vocalist after becoming a born-again Christian.

In 1977, REO convinced Epic Records that their strength was in their live performances. Epic agreed to let them produce their first live album, "", which was eventually certified platinum. That same year, the band moved to Los Angeles, California.

In 1977, bassist Gregg Philbin left the band. Depending upon which band member is expressing an opinion, it was either because Philbin was disenchanted with the new corporate-structure REO where Cronin and Richrath got bigger slices of the pie instead of the equal credit they once shared as a "garage band", or he was asked to leave over his lifestyle issues affecting the music quality. Philbin was replaced with another Champaign, Illinois musician, Centennial High School alumnus, Bruce Hall, to record "You Can Tune a Piano but You Can't Tuna Fish". The album was released in 1978 and has received FM radio airplay over the years, thanks to songs like "Roll with the Changes" and "Time for Me to Fly". The album was REO's first to make the Top 40, peaking at #29. The album went on to sell over two million copies in the US, ultimately achieving double platinum status.

In 1979, the band took a turn back to hard rock with the release of "Nine Lives".

On November 21, 1980, Epic released "Hi Infidelity", which represented a change in sound, going from hard rock to more pop-oriented material. "Hi Infidelity" spawned four hit singles written by Richrath and Cronin, including the chart-topping "Keep On Loving You" (Cronin), plus "Take It on the Run" (#5) (Richrath), "In Your Letter" (#20) (Richrath), and "Don't Let Him Go" (#24) (Cronin), and remained on the charts for 65 weeks, 32 of which were spent in the top ten, including 15 weeks atop the "Billboard" 200. "Hi Infidelity" sold over 10 million copies.

The band's follow-up album, "Good Trouble", was released in June 1982. Although it was not as successful as its predecessor, the album performed moderately well commercially, featuring the hit singles "Keep the Fire Burnin'" (U.S. #7), "Sweet Time" (U.S. #26) and the Album Rock chart hit "The Key."

The band came storming back two years later with "Wheels Are Turnin'", an album that included the #1 hit single "Can't Fight This Feeling" plus three more hits: "I Do' Wanna Know" (U.S. #29), "One Lonely Night" (U.S. #19), and "Live Every Moment" (U.S. #34).

REO Speedwagon toured the US in 1985, including a sold-out concert in Madison, Wisconsin in May. On July 13, on the way to a show in Milwaukee, the band made a stop in Philadelphia to play at the US leg of Live Aid, which broke a record for number of viewers. They performed "Can't Fight This Feeling" and "Roll With the Changes," which featured members of the Beach Boys, the band members' families, and Paul Shaffer on stage for backing vocals.

1987's "Life as We Know It" saw a decline in sales, but still managed to provide the band with the top-20 hits "That Ain't Love" (U.S. #16) and "In My Dreams" (U.S. #19). "The Hits" (1988) is a compilation album from REO Speedwagon. It contains the new tracks "Here With Me" and "I Don't Want to Lose You." They were the last songs recorded with Gary Richrath and Alan Gratzer. "Here with Me" cracked the top 20 on the Billboard Hot 100 and the top ten on the Adult Contemporary chart.

By the late 1980s, the band's popularity was starting to decline. Original drummer Alan Gratzer left in September 1988 after he decided to retire from music to open a restaurant. In early 1989, Gary Richrath quit after tensions between he and Kevin Cronin boiled over. Cronin had been playing in The Strolling Dudes, a jazz ensemble that included jazz trumpet player Rick Braun (who had co-written the abovementioned "Here With Me" with Cronin), Miles Joseph on lead guitar and Graham Lear on drums. Lear had already been invited to join REO in September 1988 as Gratzer's successor and Joseph was brought in as a temporary stand-in for Richrath. Back up singers Carla Day and Melanie Jackson were also added. This lineup did only one show, on January 7, 1989 in ViÃ±a del Mar, Chile, where it won the award for best group at the city's annual International Song Festival. After that, Miles Joseph and the back up singers were dropped in favor of former Ted Nugent guitarist Dave Amato (who was brought aboard in May 1989) and keyboardist/songwriter/producer Jesse Harms.

The 1990 release "The Earth, a Small Man, His Dog and a Chicken", with Bryan Hitt (formerly of Wang Chung) on drums, was a commercial disappointment. The album produced only one, and - to date - the band's last "Billboard" Hot 100 single, "Love Is a Rock," which peaked at #65. Harms, disenchanted by the album's failure, left the group in early 1991.

Shortly after his departure, Richrath assembled former members of the Midwestern band Vancouver to form a namesake band, Richrath. After touring for several years, the Richrath band released "Only the Strong Survive" in 1992 on the GNP Crescendo label. Richrath (the band) continued to perform for several years before disbanding in the late 1990s. In September 1998, Gary Richrath briefly joined REO onstage at the County Fair in Los Angeles to play on the band's encore song, "157 Riverside Avenue". He then joined REO once again in Los Angeles in May 2000 for the same encore but no serious plans for a reunion ever materialized.

Having lost their recording contract with Epic, REO Speedwagon ended up releasing "Building the Bridge" (1996) on the Priority/Rhythm Safari label. When that label went bankrupt, the album was released on Castle Records, which also experienced financial troubles. REO Speedwagon ultimately self-financed this effort, which failed to chart. The title track did make R&R's AC Top 30 chart.

The commercial failure of the band's newer material with its revised lineup demanded a change in marketing strategy. As a consequence, Epic began re-releasing recordings from older albums with updated artwork and design.

From 1995 to the present, the label released over a dozen compilation albums featuring greatest hits, including 1999's "The Ballads". In 2000, REO teamed up with Styx for an appearance at Riverport Amphitheater in St. Louis, which was released as a live concert video "". The REO portion of the show was released again under three separate titles: "Live - Plus" (2001), "Live Plus 3" (2001) and "Extended Versions" (2001) (which was certified gold by the RIAA on April 26, 2006). REO once again teamed with Styx in 2003 for the Classic Rock's Main Event tour which also included another band from their common rock era, Journey.

The band released a self-financed album entitled "Find Your Own Way Home" in April 2007. Though it did not chart as an album, it produced two singles which appeared on Billboard's Adult Contemporary radio chart.

REO Speedwagon continues to tour regularly, performing mostly their classic hits. They teamed up with Styx to record a new single entitled "Can't Stop Rockin'", released in March 2009, as well as for a full tour that included special guest .38 Special.

In November 2009 REO Speedwagon released a Christmas album, "Not So Silent Night...Christmas with REO Speedwagon." On December 2, the band released an online video game, "Find Your Own Way Home", produced by digital design agency Curious Sense. The game was the first "downloadable casual game" produced with a rock band and was cited by numerous publications including "The New York Times" as an innovative marketing product for a music act. In Summer 2010, the band â then touring with Pat Benatar â announced that it would release a 30th anniversary deluxe edition reissue of "Hi Infidelity".

REO Speedwagon headlined on the M&I Classic Rock Stage at the Milwaukee Summerfest on June 30, 2011. On March 11, 2012, Kevin Cronin appeared on the Canadian reality TV series "Star AcadÃ©mie". He sang a sampling of REO's hits with the show's singing finalists.

On November 22, 2013 they announced a benefit concert with Styx titled "Rock to the Rescue" to raise money for the affected families of the tornadoes in central Illinois. The concert was held on December 4, 2013 in Bloomington, Illinois. Richard Marx joined REO on stage for a joint performance of two of his hit songs. Gary Richrath reunited with REO one final time for a performance of "Ridin' the Storm Out" to end REO's set at the sold-out concert. Richrath stayed on stage to help with the encore of "With a Little Help From My Friends" along with REO, Styx, Richard Marx, and others. Richrath was originally from the town of East Peoria which was damaged during the storm. Families impacted by the storm and first responders sat near the stage for this special REO concert.

In early 2014, it was announced that REO Speedwagon and Chicago would be teaming up for 15 dates throughout 2014. Gary Richrath died on September 13, 2015, due to complications from surgery. In 2016 the band went on tour with Def Leppard and Tesla.

The band performed with Pitbull the song "Messin' Around" live on the ABC TV show "Greatest Hits in 2016"; that version of the song was also released as a single on iTunes. The band toured the UK arena circuit with Status Quo in December 2016. The band toured the US with Styx and Don Felder on the "United We Rock" tour, debuting June 20, 2017 at the Sunlight Supply Amphitheater. In 2017 the "Hi Infidelity" album received the Diamond Award for official U.S. sales of over 10 million copies. REO and Chicago once again teamed up for tour dates during the summer of 2018.

Current members

Former members

Studio albums




</doc>
<doc id="26181" url="https://en.wikipedia.org/wiki?curid=26181" title="Ray Bradbury">
Ray Bradbury

Ray Douglas Bradbury (; August 22, 1920June 5, 2012) was an American author and screenwriter. He worked in a variety of genres, including fantasy, science fiction, horror, and mystery fiction.

Predominantly known for writing the iconic dystopian novel "Fahrenheit 451" (1953), and his science-fiction and horror-story collections, "The Martian Chronicles" (1950), "The Illustrated Man" (1951), and "I Sing the Body Electric" (1969), Bradbury was one of the most celebrated 20th- and 21st-century American writers. While most of his best known work is in fantasy fiction, he also wrote in other genres, such as the coming-of-age novel "Dandelion Wine" (1957) and the fictionalized memoir "Green Shadows, White Whale" (1992).

Recipient of numerous awards, including a 2007 Pulitzer Citation, Bradbury also wrote and consulted on screenplays and television scripts, including "Moby Dick" and "It Came from Outer Space". Many of his works were adapted to comic book, television, and film formats.

Upon his death in 2012, "The New York Times" called Bradbury "the writer most responsible for bringing modern science fiction into the literary mainstream".

Bradbury was born on August 22, 1920, in Waukegan, Illinois, to Esther (nÃ©e Moberg) Bradbury (1888â1966), a Swedish immigrant, and Leonard Spaulding Bradbury (1890â1957), a power and telephone lineman of English ancestry. He was given the middle name "Douglas" after the actor Douglas Fairbanks. Bradbury was related to the U.S. Shakespeare scholar Douglas Spaulding and descended from Mary Bradbury, who was tried at one of the Salem witch trials in 1692.

Bradbury was surrounded by an extended family during his early childhood and formative years in Waukegan. An aunt read him short stories when he was a child. This period provided foundations for both the author and his stories. In Bradbury's works of fiction, 1920s Waukegan becomes "Green Town", Illinois.

The Bradbury family lived in Tucson, Arizona, during 1926â1927 and 1932â1933 while their father pursued employment, each time returning to Waukegan. They eventually settled in Los Angeles in 1934 when Bradbury was 14 years old. The family arrived with only US$40 (), which paid for rent and food until his father finally found a job making wire at a cable company for $14 a week (). This meant that they could stay, and Bradbury, who was in love with Hollywood, was ecstatic.

Bradbury attended Los Angeles High School and was active in the drama club. He often roller-skated through Hollywood in hopes of meeting celebrities. Among the creative and talented people Bradbury met were special-effects pioneer Ray Harryhausen and radio star George Burns. Bradbury's first pay as a writer, at age 14, was for a joke he sold to George Burns to use on the " Burns and Allen" radio show.

Throughout his youth, Bradbury was an avid reader and writer and knew at a young age that he was "going into one of the arts." Bradbury began writing his own stories at age 11 (1931), during the Great Depression â sometimes writing on the only available paper, butcher paper.

In his youth, he spent much time in the Carnegie library in Waukegan, reading such authors as H. G. Wells, Jules Verne, and Edgar Allan Poe. At 12, Bradbury began writing traditional horror stories and said he tried to imitate Poe until he was about 18. In addition to comics, he loved Edgar Rice Burroughs, creator of "Tarzan of the Apes", especially Burroughs' John Carter of Mars series. "The Warlord of Mars" impressed him so much that at the age of 12, he wrote his own sequel. The young Bradbury was also a cartoonist and loved to illustrate. He wrote about Tarzan and drew his own Sunday panels. He listened to the radio show "Chandu the Magician", and every night when the show went off the air, he would sit and write the entire script from memory.

As a teen in Beverly Hills, he often visited his mentor and friend science-fiction writer Bob Olsen, sharing ideas and maintaining contact. In 1936, at a secondhand bookstore in Hollywood, Bradbury discovered a handbill promoting meetings of the Los Angeles Science Fiction Society. Excited to find there were others sharing his interest, Bradbury joined a weekly Thursday-night conclave at age 16.

Bradbury cited H. G. Wells and Jules Verne as his primary science-fiction influences. Bradbury identified with Verne, saying, "He believes the human being is in a strange situation in a very strange world, and he believes that we can triumph by behaving morally".

In young adulthood Bradbury read stories published in "Astounding Science Fiction", and read everything by Robert A. Heinlein, Arthur C. Clarke, and the early writings of Theodore Sturgeon and A. E. van Vogt.

The family lived about four blocks from the Fox Uptown Theatre on Western Avenue in Los Angeles, the flagship theater for MGM and Fox. There, Bradbury learned how to sneak in and watched previews almost every week. He rollerskated there, as well as all over town, as he put it, "hell-bent on getting autographs from glamorous stars. It was glorious." Among stars the young Bradbury was thrilled to encounter were Norma Shearer, Laurel and Hardy, and Ronald Colman. Sometimes, he spent all day in front of Paramount Pictures or Columbia Pictures and then skated to the Brown Derby to watch the stars who came and went for meals. He recounted seeing Cary Grant, Marlene Dietrich, and Mae West, whom he learned made a regular appearance every Friday night, bodyguard in tow.

Bradbury relates the following meeting with Sergei Bondarchuk, director of Soviet epic film series "War and Peace", at a Hollywood award ceremony in Bondarchuk's honor:

Bradbury's first published story was "Hollerbochen's Dilemma", which appeared in the January 1938 number of Forrest J. Ackerman's fanzine "Imagination!". In July 1939, Ackerman and his then-girlfriend Morojo gave 19-year-old Bradbury the money to head to New York for the First World Science Fiction Convention in New York City, and funded Bradbury's fanzine, titled "Futuria Fantasia". Bradbury wrote most of its four issues, each limited to under 100 copies. Between 1940 and 1947, he was a contributor to Rob Wagner's film magazine, "Script".

Bradbury was free to start a career in writing when, owing to his bad eyesight, he was rejected admission into the military during World War II. Having been inspired by science-fiction heroes such as Flash Gordon and Buck Rogers, Bradbury began to publish science-fiction stories in fanzines in 1938. Bradbury was invited by Forrest J. Ackerman to attend the Los Angeles Science Fiction Society, which at the time met at Clifton's Cafeteria in downtown Los Angeles. This was where he met the writers Robert A. Heinlein, Emil Petaja, Fredric Brown, Henry Kuttner, Leigh Brackett, and Jack Williamson.

In 1939, Bradbury joined Laraine Day's Wilshire Players Guild, where for two years, he wrote and acted in several plays. They were, as Bradbury later described, "so incredibly bad" that he gave up playwriting for two decades. Bradbury's first paid piece, "Pendulum", written with Henry Hasse, was published in the pulp magazine "Super Science Stories" in November 1941, for which he earned $15.

Bradbury sold his first story, "The Lake", for $13.75 at 22, and became a full-time writer by 24. His first collection of short stories, "Dark Carnival", was published in 1947 by Arkham House, a small press in Sauk City, Wisconsin, owned by writer August Derleth. Reviewing "Dark Carnival" for the "New York Herald Tribune", Will Cuppy proclaimed Bradbury "suitable for general consumption" and predicted that he would become a writer of the caliber of British fantasy author John Collier.

After a rejection notice from the pulp "Weird Tales", Bradbury submitted "Homecoming" to "Mademoiselle", which was spotted by a young editorial assistant named Truman Capote. Capote picked the Bradbury manuscript from a slush pile, which led to its publication. "Homecoming" won a place in the O. Henry Award Stories of 1947.

In UCLA's Powell Library, in a study room with typewriters for rent, Bradbury wrote his classic story of a book burning future, "The Fireman", which was about 25,000 words long. It was later published at about 50,000 words under the name "Fahrenheit 451", for a total cost of $9.80, due to the library's typewriter-rental fees of ten cents per half-hour.

A chance encounter in a Los Angeles bookstore with the British expatriate writer Christopher Isherwood gave Bradbury the opportunity to put "The Martian Chronicles" into the hands of a respected critic. Isherwood's glowing review followed.

Bradbury attributed his lifelong habit of writing every day to two incidents. The first of these, occurring when he was three years old, was his mother's taking him to see Lon Chaney's performance in "The Hunchback of Notre Dame". The second incident occurred in 1932, when a carnival entertainer, one Mr. Electrico, touched the young man on the nose with an electrified sword, made his hair stand on end, and shouted, "Live forever!" Bradbury remarked, "I felt that something strange and wonderful had happened to me because of my encounter with Mr. Electrico...[he] gave me a future...I began to write, full-time. I have written every single day of my life since that day 69 years ago." At that age, Bradbury first started to do magic, which was his first great love. If he had not discovered writing, he would have become a magician.

Bradbury claimed a wide variety of influences, and described discussions he might have with his favorite poets and writers Robert Frost, William Shakespeare, John Steinbeck, Aldous Huxley, and Thomas Wolfe. From Steinbeck, he said he learned "how to write objectively and yet insert all of the insights without too much extra comment". He studied Eudora Welty for her "remarkable ability to give you atmosphere, character, and motion in a single line". Bradbury's favorite writers growing up included Katherine Anne Porter, who wrote about the American South, Edith Wharton, and Jessamyn West.

Bradbury was once described as a "Midwest surrealist" and is often labeled a science-fiction writer, which he described as "the art of the possible." Bradbury resisted that categorization, however:

Bradbury recounted when he came into his own as a writer, the afternoon he wrote a short story about his first encounter with death. When he was a boy, he met a young girl at the beach and she went out into the water and never came back. Years later, as he wrote about it, tears flowed from him. He recognized he had taken the leap from emulating the many writers he admired to connecting with his voice as a writer.

When later asked about the lyrical power of his prose, Bradbury replied, "From reading so much poetry every day of my life. My favorite writers have been those who've said things well." He is quoted, "If you're reluctant to weep, you won't live a full and complete life."

In high school, Bradbury was active in both the poetry club and the drama club, continuing plans to become an actor, but becoming serious about his writing as his high school years progressed. Bradbury graduated from Los Angeles High School, where he took poetry classes with Snow Longley Housh, and short-story writing courses taught by Jeannet Johnson. The teachers recognized his talent and furthered his interest in writing, but he did not attend college. Instead, he sold newspapers at the corner of South Norton Avenue and Olympic Boulevard. In regard to his education, Bradbury said:
He told "The Paris Review", "You can't learn to write in college. It's a very bad place for writers because the teachers always think they know more than you do â and they don't."

Bradbury described his inspiration as, "My stories run up and bite me in the legâI respond by writing them downâeverything that goes on during the bite. When I finish, the idea lets go and runs off".

A reinvention of Waukegan, Green Town is a symbol of safety and home, which is often juxtaposed as a contrasting backdrop to tales of fantasy or menace. It serves as the setting of his semiautobiographical classics "Dandelion Wine", "Something Wicked This Way Comes", and "Farewell Summer", as well as in many of his short stories. In Green Town, Bradbury's favorite uncle sprouts wings, traveling carnivals conceal supernatural powers, and his grandparents provide room and board to Charles Dickens. Perhaps the most definitive usage of the pseudonym for his hometown, in "Summer Morning, Summer Night", a collection of short stories and vignettes exclusively about Green Town, Bradbury returns to the signature locale as a look back at the rapidly disappearing small-town world of the American heartland, which was the foundation of his roots.

Bradbury wrote many short essays on the culture and the arts, attracting the attention of critics in this field, but he used his fiction to explore and criticize his culture and society. Bradbury observed, for example, that "Fahrenheit 451" touches on the alienation of people by media:
Bradbury stated the novel worked as a critique of the later development of political correctness:
In a 1982 essay, he wrote, "People ask me to predict the Future, when all I want to do is prevent it". This intent had been expressed earlier by other authors, who sometimes attributed it to him.

On May 24, 1956, Bradbury appeared on television in Hollywood on the popular quiz show "You Bet Your Life" hosted by Groucho Marx. During his introductory comments and on-air banter with Marx, Bradbury briefly discussed some of his books and other works, including giving an overview of "The Veldt", his short story published six years earlier in "The Saturday Evening Post" under the title "The World the Children Made".

Bradbury was a consultant for the American Pavilion at the 1964 New York World's Fair and for the original exhibit housed in Epcot's Spaceship Earth geosphere at Walt Disney World. Bradbury concentrated on detective fiction in the 1980s. In the latter half of the 1980s and early 1990s, he also hosted "The Ray Bradbury Theater", a televised anthology series based on his short stories.

Bradbury was a strong supporter of public library systems, raising money to prevent the closure of several libraries in California facing budgetary cuts. He said "libraries raised me", and shunned colleges and universities, comparing his own lack of funds during the Depression with poor contemporary students. His opinion varied on modern technology. In 1985 Bradbury wrote, "I see nothing but good coming from computers. When they first appeared on the scene, people were saying, 'Oh my God, I'm so afraid.' I hate people like that â I call them the neo-Luddites", and "In a sense, [computers] are simply books. Books are all over the place, and computers will be, too". He resisted the conversion of his work into e-books, saying in 2010, "We have too many cellphones. We've got too many internets. We have got to get rid of those machines. We have too many machines now". When the publishing rights for "Fahrenheit 451" came up for renewal in December 2011, Bradbury permitted its publication in electronic form provided that the publisher, Simon & Schuster, allowed the e-book to be digitally downloaded by any library patron. The title remains the only book in the Simon & Schuster catalog where this is possible.

Several comic-book writers have adapted Bradbury's stories. Particularly noted among these were EC Comics' line of horror and science-fiction comics. Initially, the writers plagiarized his stories, but a diplomatic letter from Bradbury about it led to the company paying him and negotiating properly licensed adaptations of his work. The comics featuring Bradbury's stories included "Tales from the Crypt", "Weird Science", "Weird Fantasy", "Crime Suspenstories", and "Haunt of Fear".

Bradbury remained an enthusiastic playwright all his life, leaving a rich theatrical legacy, as well as literary. Bradbury headed the Pandemonium Theatre Company in Los Angeles for many years and had a five-year relationship with the Fremont Centre Theatre in South Pasadena.

Bradbury is featured prominently in two documentaries related to his classic 1950s-1960s era: Jason V Brock's "Charles Beaumont: The Life of Twilight Zone's Magic Man", which details his troubles with Rod Serling, and his friendships with writers Charles Beaumont, George Clayton Johnson, and most especially his dear friend William F. Nolan, as well as Brock's "The AckerMonster Chronicles!", which delves into the life of former Bradbury agent, close friend, mega-fan, and "Famous Monsters of Filmland" editor Forrest J Ackerman.

Bradbury's legacy was celebrated by the bookstore Fahrenheit 451 Books in Laguna Beach, California, in the 1970s and 1980s. The grand opening of an annex to the store was attended by Bradbury and his favorite illustrator, Joseph Mugnaini, in the mid-1980s. The shop closed its doors in 1987, but in 1990, another shop with the same name (with different owners) opened in Carlsbad, California.

In the 1980s and 90s, Bradbury served on the advisory board of the Los Angeles Student Film Institute.

Bradbury was married to Marguerite McClure (January 16, 1922Â â November 24, 2003) from 1947 until her death; they had four daughters: Susan, Ramona, Bettina, and Alexandra. Bradbury never obtained a driver's license, but relied on public transportation or his bicycle. He lived at home until he was 27 and married. His wife of 56 years, Maggie, as she was affectionately called, was the only woman Bradbury ever dated.

He was raised Baptist by his parents, who were themselves infrequent churchgoers. As an adult, Bradbury considered himself a "delicatessen religionist" who resisted categorization of his beliefs and took guidance from both Eastern and Western faiths. He felt that his career was "a God-given thing, and I'm so grateful, so, so grateful. The best description of my career as a writer is 'At play in the fields of the Lord.'"

Bradbury was a close friend of Charles Addams, and Addams illustrated the first of Bradbury's stories about the Elliotts, a family that resembled Addams' own Addams Family placed in rural Illinois. Bradbury's first story about them was "Homecoming", published in the 1946 Halloween issue of "Mademoiselle", with Addams' illustrations. Addams and he planned a larger collaborative work that would tell the family's complete history, but it never materialized, and according to a 2001 interview, they went their separate ways. In October 2001, Bradbury published all the Family stories he had written in one book with a connecting narrative, "From the Dust Returned", featuring a wraparound Addams cover of the original "Homecoming" illustration.

Another close friend was animator Ray Harryhausen, who was best man at Bradbury's wedding. During a BAFTA 2010 awards tribute in honor of Ray Harryhausen's 90th birthday, Bradbury spoke of his first meeting Harryhausen at Forrest J Ackerman's house when they were both 18 years old. Their shared love for science fiction, "King Kong", and the King Vidor-directed film "The Fountainhead", written by Ayn Rand, was the beginning of a lifelong friendship. These early influences inspired the pair to believe in themselves and affirm their career choices. After their first meeting, they kept in touch at least once a month, in a friendship that spanned over 70 years.

Late in life, Bradbury retained his dedication and passion despite what he described as the "devastation of illnesses and deaths of many good friends." Among the losses that deeply grieved Bradbury was the death of "Star Trek" creator Gene Roddenberry, who was an intimate friend for many years. They remained close friends for nearly three decades after Roddenberry asked him to write for "Star Trek", which Bradbury never did, objecting that he "never had the ability to adapt other people's ideas into any sensible form."

Bradbury suffered a stroke in 1999 that left him partially dependent on a wheelchair for mobility. Despite this, he continued to write, and had even written an essay for "The New Yorker", about his inspiration for writing, published only a week prior to his death. Bradbury made regular appearances at science-fiction conventions until 2009, when he retired from the circuit.
Bradbury chose a burial place at Westwood Village Memorial Park Cemetery in Los Angeles, with a headstone that reads "Author of Fahrenheit 451". On February 6, 2015, "The New York Times" reported that the house that Bradbury lived and wrote in for 50 years of his life, at 10265 Cheviot Drive in Cheviot Hills, Los Angeles, California, had been demolished by the buyer, architect Thom Mayne.

Bradbury died in Los Angeles, California, on June 5, 2012, at the age of 91, after a lengthy illness. Bradbury's personal library was willed to the Waukegan Public Library, where he had many of his formative reading experiences.

"The New York Times" called Bradbury "the writer most responsible for bringing modern science fiction into the literary mainstream." The "Los Angeles Times" credited Bradbury with the ability "to write lyrically and evocatively of lands an imagination away, worlds he anchored in the here and now with a sense of visual clarity and small-town familiarity". Bradbury's grandson, Danny Karapetian, said Bradbury's works had "influenced so many artists, writers, teachers, scientists, and it's always really touching and comforting to hear their stories". "The Washington Post" noted several modern day technologies that Bradbury had envisioned much earlier in his writing, such as the idea of banking ATMs and earbuds and Bluetooth headsets from "Fahrenheit 451", and the concepts of artificial intelligence within "I Sing the Body Electric".

On June 6, 2012, in an official public statement from the White House Press Office, President Barack Obama said:

Numerous Bradbury fans paid tribute to the author, noting the influence of his works on their own careers and creations. Filmmaker Steven Spielberg stated that Bradbury was "[his] muse for the better part of [his] sci-fi career... On the world of science fiction and fantasy and imagination he is immortal". Writer Neil Gaiman felt that "the landscape of the world we live in would have been diminished if we had not had him in our world". Author Stephen King released a statement on his website saying, "Ray Bradbury wrote three great novels and three hundred great stories. One of the latter was called 'A Sound of Thunder'. The sound I hear today is the thunder of a giant's footsteps fading away. But the novels and stories remain, in all their resonance and strange beauty."

Bradbury is credited with writing 27 novels and over 600 short stories. More than eight million copies of his works, published in over 36 languages, have been sold around the world.

In 1949, Bradbury and his wife were expecting their first child. He took a Greyhound bus to New York and checked into a room at the YMCA for 50 cents a night. He took his short stories to a dozen publishers and no one wanted them. Just before getting ready to go home, Bradbury had dinner with an editor at Doubleday. When Bradbury recounted that everyone wanted a novel and he did not have one, the editor, coincidentally named Walter Bradbury, asked if the short stories might be tied together into a book-length collection. The title was the editor's idea; he suggested, "You could call it "The Martian Chronicles"." Bradbury liked the idea and recalled making notes in 1944 to do a book set on Mars. That evening, he stayed up all night at the YMCA and typed out an outline. He took it to the Doubleday editor the next morning, who read it and wrote Bradbury a check for $750. When Bradbury returned to Los Angeles, he connected all the short stories that became "The Martian Chronicles."

What was later issued as a collection of stories and vignettes, "Summer Morning, Summer Night", started out to be Bradbury's first true novel. The core of the work was Bradbury's witnessing of the American small-town life in the American heartland.

In the winter of 1955â56, after a consultation with his Doubleday editor, Bradbury deferred publication of a novel based on Green Town, the pseudonym for his hometown. Instead, he extracted 17 stories and, with three other Green Town tales, bridged them into his 1957 book "Dandelion Wine". Later, in 2006, Bradbury published the original novel remaining after the extraction, and retitled it "Farewell Summer". These two titles show what stories and episodes Bradbury decided to retain as he created the two books out of one.

The most significant of the remaining unpublished stories, scenes, and fragments were published under the originally intended name for the novel, "Summer Morning, Summer Night", in 2007.

From 1950 to 1954, 31 of Bradbury's stories were adapted by Al Feldstein for EC Comics (seven of them uncredited in six stories, including "Kaleidoscope" and "Rocket Man" being combined as "Home To Stay" - for which Bradbury was retroactively paid - and EC's first version of "The Handler" under the title "A Strange Undertaking") and 16 of these were collected in the paperbacks, "The Autumn People" (1965) and "Tomorrow Midnight" (1966), both published by Ballantine Books with cover illustrations by Frank Frazetta.
Also in the early 1950s, adaptations of Bradbury's stories were televised in several anthology shows, including "Tales of Tomorrow", "Lights Out", "Out There", "Suspense", "CBS Television Workshop", "Jane Wyman's Fireside Theatre", "Star Tonight", "Windows" and "Alfred Hitchcock Presents". "The Merry-Go-Round", a half-hour film adaptation of Bradbury's "The Black Ferris", praised by "Variety", was shown on "Starlight Summer Theater" in 1954 and NBC's "Sneak Preview" in 1956. During that same period, several stories were adapted for radio drama, notably on the science fiction anthologies "Dimension X" and its successor "X Minus One".

Producer William Alland first brought Bradbury to movie theaters in 1953 with "It Came from Outer Space", a Harry Essex screenplay developed from Bradbury's screen treatment "Atomic Monster". Three weeks later came the release of EugÃ¨ne LouriÃ©'s "The Beast from 20,000 Fathoms" (1953), which featured one scene based on Bradbury's "The Fog Horn", about a sea monster mistaking the sound of a fog horn for the mating cry of a female. Bradbury's close friend Ray Harryhausen produced the stop-motion animation of the creature. Bradbury later returned the favor by writing a short story, "Tyrannosaurus Rex", about a stop-motion animator who strongly resembled Harryhausen. Over the next 50 years, more than 35 features, shorts, and TV movies were based on Bradbury's stories or screenplays.
Bradbury was hired in 1953 by director John Huston to work on the screenplay for his film version of Melville's "Moby Dick" (1956), which stars Gregory Peck as Captain Ahab, Richard Basehart as Ishmael, and Orson Welles as Father Mapple. A significant result of the film was Bradbury's book "Green Shadows, White Whale", a semifictionalized account of the making of the film, including Bradbury's dealings with Huston and his time in Ireland, where exterior scenes that were set in New Bedford, Massachusetts, were filmed.

Bradbury's short story "I Sing the Body Electric" (from the book of the same name) was adapted for the 100th episode of "The Twilight Zone". The episode was first aired on May 18, 1962.

Bradbury and director Charles Rome Smith co-founded the Pandemonium Theatre Company in 1964. Its first production was "The World of Ray Bradbury", consisting of one-act adaptations of "The Pedestrian", "The Veldt", and "To the Chicago Abyss". It ran for four months at the Coronet Theatre in Los Angeles (October 1964 - February 1965); an off-Broadway production was presented in October 1965. Another Pandemonium Theatre Company production was mounted at the Coronet Theatre in 1965, again presenting adaptations of three Bradbury short stories: "The Wonderful Ice Cream Suit," "The Day It Rained Forever," and "Device Out of Time." (The last was adapted from his 1957 novel "Dandelion Wine"). The original cast for this production featured Booth Coleman, Joby Baker, Fredric Villani, Arnold Lessing, Eddie Sallia, Keith Taylor, Richard Bull, Gene Otis Shane, Henry T. Delgado, F. Murray Abraham, Anne Loos, and Len Lesser. The director, again, was Charles Rome Smith.

Oskar Werner and Julie Christie starred in "Fahrenheit 451" (1966), an adaptation of Bradbury's novel directed by FranÃ§ois Truffaut.

In 1966, Bradbury helped Lynn Garrison create "AVIAN", a specialist aviation magazine. For the first issue, Bradbury wrote a poem, "Planes That Land on Grass".

In 1969, "The Illustrated Man" was brought to the big screen, starring Rod Steiger, Claire Bloom, and Robert Drivas. Containing the prologue and three short stories from the book, the film received mediocre reviews. The same year, Bradbury approached composer Jerry Goldsmith, who had worked with Bradbury in dramatic radio of the 1950s and later scored the film version, to compose a cantata "Christus Apollo" based on Bradbury's text. The work premiered in late 1969, with the California Chamber Symphony performing with narrator Charlton Heston at UCLA.

"The Martian Chronicles" became a three-part TV miniseries starring Rock Hudson, which was first broadcast by NBC in 1980. Bradbury found the miniseries "just boring".

The 1982 television movie "The Electric Grandmother" was based on Bradbury's short story "I Sing the Body Electric".

The 1983 horror film "Something Wicked This Way Comes", starring Jason Robards and Jonathan Pryce, is based on the Bradbury novel of the same name.

In 1984, Michael McDonough of Brigham Young University produced "Bradbury 13", a series of 13 audio adaptations of famous stories from Bradbury, in conjunction with National Public Radio. The full-cast dramatizations featured adaptations of "The Ravine", "Night Call, Collect", "The Veldt", "There Was an Old Woman", "Kaleidoscope", "Dark They Were, and Golden-Eyed", "The Screaming Woman", "A Sound of Thunder", "The Man", "The Wind", "The Fox and the Forest", "Here There Be Tygers", and "The Happiness Machine". Voiceover actor Paul Frees provided narration, while Bradbury was responsible for the opening voiceover; Greg Hansen and Roger Hoffman scored the episodes. The series won a Peabody Award and two Gold Cindy awards, and was released on CD on May 1, 2010. The series began airing on BBC Radio 4 Extra on June 12, 2011.

From 1985 to 1992, Bradbury hosted a syndicated anthology television series, "The Ray Bradbury Theater", for which he adapted 65 of his stories. Each episode began with a shot of Bradbury in his office, gazing over mementoes of his life, which he states (in narrative) are used to spark ideas for stories. During the first two seasons, Bradbury also provided additional voiceover narration specific to the featured story and appeared on screen.

Deeply respected in the USSR, Bradbury's fiction has been adapted into five episodes of the Soviet science-fiction TV series "This Fantastic World" which adapted the stories film version of "I Sing The Body Electric", "Fahrenheit 451", "A Piece of Wood", "To the Chicago Abyss", and "Forever and the Earth". In 1984 a cartoon adaptation of There Will Come Soft Rains (Â«ÐÑÐ´ÐµÑ Ð»Ð°ÑÐºÐ¾Ð²ÑÐ¹ Ð´Ð¾Ð¶Ð´ÑÂ») came out by Uzbek director Nazim Tyuhladziev. He made a film adaptation of "The Veldt" in 1987. In 1989, a cartoon adaptation of "Here There Be Tygers" (Â«ÐÐ´ÐµÑÑ Ð¼Ð¾Ð³ÑÑ Ð²Ð¾Ð´Ð¸ÑÑÑÑ ÑÐ¸Ð³ÑÑÂ») by director Vladimir Samsonov came out.

Bradbury wrote and narrated the 1993 animated television version of "The Halloween Tree", based on his 1972 novel.

The 1998 film "The Wonderful Ice Cream Suit", released by Touchstone Pictures, was written by Bradbury. It was based on his story "The Magic White Suit" originally published in "The Saturday Evening Post" in 1957. The story had also previously been adapted as a play, a musical, and a 1958 television version.

In 2002, Bradbury's own Pandemonium Theatre Company production of "Fahrenheit 451" at Burbank's Falcon Theatre combined live acting with projected digital animation by the Pixel Pups. In 1984, Telarium released a game for Commodore 64 based on "Fahrenheit 451".

In 2005, the film "A Sound of Thunder" was released, loosely based upon the short story of the same name. The film "The Butterfly Effect" revolves around the same theory as "A Sound of Thunder" and contains many references to its inspiration. Short film adaptations of "A Piece of Wood" and "The Small Assassin" were released in 2005 and 2007, respectively.

In 2005, it was reported that Bradbury was upset with filmmaker Michael Moore for using the title "Fahrenheit 9/11", which is an allusion to Bradbury's "Fahrenheit 451", for his documentary about the George W. Bush administration. Bradbury expressed displeasure with Moore's use of the title, but stated that his resentment was not politically motivated, though Bradbury was conservative-leaning politically. Bradbury asserted that he did not want any of the money made by the movie, nor did he believe that he deserved it. He pressured Moore to change the name, but to no avail. Moore called Bradbury two weeks before the film's release to apologize, saying that the film's marketing had been set in motion a long time ago and it was too late to change the title.

In 2008, the film "Ray Bradbury's Chrysalis" was produced by Roger Lay Jr. for Urban Archipelago Films, based upon the short story of the same name. The film won the best feature award at the International Horror and Sci-Fi Film Festival in Phoenix. The film has international distribution by Arsenal Pictures and domestic distribution by Lightning Entertainment.

In 2010, "The Martian Chronicles" was adapted for radio by "Colonial Radio Theatre on the Air".

Bradbury's works and approach to writing are documented in Terry Sanders' film "Ray Bradbury: Story of a Writer" (1963).

Bradbury's poem "Groon" was voiced as a tribute in 2012.

The Ray Bradbury Award for excellency in screenwriting was occasionally presented by the Science Fiction and Fantasy Writers of America â presented to six people on four occasions from 1992 to 2009. Beginning 2010, the Ray Bradbury Award for Outstanding Dramatic Presentation is presented annually according to Nebula Awards rules and procedures, although it is not a Nebula Award. The revamped Bradbury Award replaced the Nebula Award for Best Script.


Bradbury appeared in the documentary "The Fantasy Film Worlds of George Pal" (1985), produced and directed by Arnold Leibovit.




</doc>
<doc id="26184" url="https://en.wikipedia.org/wiki?curid=26184" title="Radio Row">
Radio Row

Radio Row is a nickname for an urban street or district specializing in the sale of radio and electronic equipment and parts. Radio Rows arose in many cities with the 1920s rise of broadcasting and declined after the middle of the 20th century.

New York City's Radio Row, which existed from 1921 to 1966, was a warehouse district on the Lower West Side of Manhattan, New York City. Major firms that started there include Arrow Electronics, Avnet (founded by Charles Avnet in 1921), and Schweber Electronics.

The first of many radio-related stores was City Radio, opened in 1921 by Harry Schneck on Cortlandt Street, which became the central axis of a several-block area of electronics stores.

"The New York Times" made an early reference to "Radio Row" in 1927, when Cortlandt Street celebrated a "Radio Jubilee". The "Times" reported that "Today ... Cortlandt Street is 'Radio Row,' while Broadway is just a thoroughfare." The street was closed and decorated with flags and bunting, and the "Times" reported plans for New York's acting mayor Joseph V. McKee to present a "key to Cortland Street" to the then-reigning Miss New York, Frieda Louise Mierse, while a contest was held to name a "Miss Downtown Radio."

Pete Hamill recalled that, as a child, "On Saturday mornings, I used to venture from Brooklyn with my father to Radio Row on Cortlandt Street in Lower Manhattan, where he and hundreds of other New York men moved from stall to stall in search of the elusive tube that would make the radio work again. Later, my brothers went there with him in search of television components. Radio Row was a piece of all our interior maps."

In 1930, the "Times" described Radio Row as located on Greenwich Street "where Cortlandt Street intersects it and the Ninth Avenue Elevated forms a canopy over the roadway. ... The largest concentration is in the block bounded by Dey Street on the north and Cortlandt on the south, but Radio Row does not stop there; it overflows around the corner, around several corners, embracing in all some five crowded blocks." It estimated 40 or 50 stores in the vicinity, "all going full blast at the same time. There may be regulations prohibiting this vociferous practice, but if the radio dealers have anything to say it about it, it will never have the slightest effect along Radio Row. ... The clamor is heard even as one walks through the subway tunnel to the street exit. ... The first impression, and in fact the only one, is auditory, a reverberating bedlam, a confusion of sounds which only an army of loudspeakers could produce." It noted, in addition to merchants selling radio sets, "others display mostly accessories ... one shopkeeper last week featured a crystal set small enough to fit into a pocket, and another gave prominent position to a bucket of condensers about an inch in side."

World War II was unkind to Radio Row, and in 1944 the "Times" lamented that the "one-time repository of nearly everything from a tube socket to a complete radio station" was "bargainless and practically setless, too, due to wartime scarcities" but that it still catered to "tinkerers and engineers" and that an "old spirit" and "magical quality" were still there. One shop said it was practically able to stay in business just by "making repairs on the electric meters burned out by the students of the city schools who were studying radio," and all were optimistic about growing public interest in "two new kinds of radio: FM and television."

But Radio Row rebounded. The used radios, war surplus electronics (e.g., ARC-5 radios), junk, and parts often piled so high they would spill out onto the street, attracting collectors and scroungers. According to a business writer, it also was the origin of the electronic component distribution business.

Radio Row was torn down in 1966 to make room for the World Trade Center.

Planning for its demise began five years earlier, when the Port Authority of New York and New Jersey rejected a proposal to build the new complex on the east side of Lower Manhattan. Instead, officials chose a site on the west side, near the Hudson and Manhattan Railroad terminals, and began planning to use eminent domain to remove the shops in the area bounded by Vesey, Church, Liberty, and West streets.

Local opposition arose to the decision to raze the streets on the west side for the World Trade Center. Sam Slate reported on this for WCBS Radio in 1962: The city also objected to the compensation given for the streets themselves obscured by the superblock.

A committee of small business owners led by Oscar Nadel took exception to the Port Authority's offer of $30,000 to any business in the condemned area, regardless of its size or age. Nadel's group, who estimated that businesses in the area employed 30,000 people and generated $300 million per year, sued the Port Authority. But the court ultimately threw out the case, called "Courtesy Sandwich Shop v. Port of New York Authority," in November 1963 ""for want of a substantial federal question"".

After the closing of these stores, the concentration of radio retailers was not duplicated elsewhere in New York. Some clusters of radio and electronics stores were created or added to in the Canal Street and Union Square areas.

A large black-and-white photo mural of Radio Row can be viewed at the World Trade Center Port Authority Trans-Hudson station.

In the 1950s and 1960s, Arch Street from 6th to 11th Streets was known as "Radio Row", after its electronic-goods stores.

In 1923, "The Boston Globe" reported that a section of the North End had been dubbed "Radio Row" because of its many radio antennas. "The hurdy-gurdy has a rival," wrote the "Globe". "No skyline anywhere else in the city or the suburbs is filled with so many antennae as the blocks stretching along some sections of Hanover and Salem sts. Many residents have three or four aerialsâone has sixâwith wires leading down to receiving sets of all descriptions, in the homes of the foreign-born residents. It has all come about in a few months...All stairways lead to the roof, where [some residents] are arranging to rig up a loudspeaker, connected with instruments below. A survey of housetops...shows a whole population getting ready."
In Los Angeles of the 1940s and 1950s, "Radio Row" referred to the area near the intersection of Sunset Boulevard and Vine Street in Hollywood, where all four major radio networks had broadcasting facilities.

In the second half of the 20th century and early 21st century, various Asian cities developed electronics districts.

Radio Row may also refer to a large grouping of sports talk radio stations that broadcast from the Super Bowl media center during the week before the annual major football game.




</doc>
<doc id="26185" url="https://en.wikipedia.org/wiki?curid=26185" title="Ralph Cudworth">
Ralph Cudworth

The Rev. Prof. Ralph Cudworth (1617Â â 26 June 1688) was an English Anglican clergyman, Christian Hebraist, classicist, theologian and philosopher, and a leading figure among the Cambridge Platonists. From a family background embedded in the early nonconformist environment of Emmanuel College where he studied (1630â45), he became 11th Regius Professor of Hebrew (1645â88), 26th Master of Clare Hall (1645â54), and 14th Master of Christ's College (1654â88). He was a leading opponent of Thomas Hobbes's political and philosophical views, and his "magnum opus" was his "The True Intellectual System of the Universe" (1678).

Cudworth's family reputedly originated in Cudworth (near Barnsley), Yorkshire, moving to Lancashire with the marriage (1377) of John de Cudworth (d.1384) and Margery (d.1384), daughter of Richard de Oldham (living 1354), lord of the manor of Werneth, Oldham. The Cudworths of Werneth Hall, Oldham, were lords of the manor of Werneth/Oldham, until 1683. Ralph Cudworth (the philosopher)âs father, Ralph Cudworth (Snr) was the posthumous-born second son of Ralph Cudworth (d.1572) of Werneth Hall, Oldham.

The philosopher's father, The Rev. Dr Ralph Cudworth (1572/3â1624), was educated at Emmanuel College, Cambridge, where he graduated BA (1592/93, MA (1596). Emmanuel College (founded by Sir Walter Mildmay (1584), and under the direction of its first Master, Laurence Chaderton) was, from its inception, a stronghold of Reformist, Puritan and Calvinist teaching, which shaped the development of puritan ministry, and contributed largely to the emigrant ministry in America.

Ordained in 1599 and elected to a college fellowship by 1600, Cudworth Snr was much influenced by William Perkins, whom he succeeded, in 1602, as Lecturer of the Parish Church of St Andrew the Great, Cambridge. He was awarded the degree of Bachelor of Divinity in 1603. He edited Perkins's "Commentary" on St Paul's Epistle to the Galatians (1604), with a dedication to Robert, 3rd Lord Rich (later 1st Earl of Warwick), adding a commentary of his own with dedication to Sir Bassingbourn Gawdy. Lord Rich presented him to the Vicariate of Coggeshall, Essex (1606) to replace the deprived minister Thomas Stoughton, but he resigned this position (March 1608), and was licensed to preach from the pulpit by the Chancellor and Scholars of the University of Cambridge (November 1609). He then applied for the Rectoriate of Aller, Somerset (an Emmanuel College living) and, resigning his fellowship, was appointed to it in 1610.

His marriage (1611) to Mary Machell ("c".1582â1634), (who had been "nutrix" â nurse, or preceptor â to Henry Frederick, Prince of Wales) brought important connections. Cudworth Snr was appointed as one of James I's chaplains. Mary's mother (or aunt) was the sister of Sir Edward Lewknor, a central figure (with the Jermyn and Heigham families) among the puritan East Anglian gentry, whose children had attended Emmanuel College. Mary's Lewknor and Machell connections with the Rich family included her first cousins Sir Nathaniel Rich and his sister Dame Margaret Wroth, wife of Sir Thomas Wroth of Petherton Park near Bridgwater, Somerset, influential promoters of colonial enterprise (and later of nonconformist emigration) in New England. Aller was immediately within their sphere.

Ralph Snr and Mary settled at Aller, where their children (listed below) were christened during the following decade. Cudworth continued to study, working on a complete survey of Case-Divinity, "The Cases of Conscience in Family, Church and Commonwealth" while suffering from the agueish climate at Aller. He was awarded the degree of Doctor of Divinity (1619), and was among the dedicatees of Richard Bernard's 1621 edition of "The Faithfull Shepherd". Ralph Snr died at Aller declaring a nuncupative will (7 August 1624) before Anthony Earbury and Dame Margaret Wroth.

The children of Ralph Cudworth Snr and Mary (nÃ©e Machell) Cudworth ("c".1582â1634) were:


The second son, and third of five (probably six) children, Ralph Cudworth (Jnr) was born at Aller, Somerset, where he was baptised (13 July 1617). Following the death of his father, Ralph Cudworth Snr (1624), The Rev. Dr John Stoughton (1593â1639), (son of Thomas Stoughton of Coggeshall; also a Fellow of Emmanuel College), succeeded as Rector of Aller, and married the widow Mary (nÃ©e Machell) Cudworth ("c".1582â1634). Dr Stoughton paid careful attention to his stepchildren's education, which Ralph later described as a "diet of Calvinism". Letters, to Stoughton, by both brothers James and Ralph Cudworth make this plain; and, when Ralph matriculated at Emmanuel College, Cambridge (1632), Stoughton thought him "as wel grounded in Schol-Learning as any Boy of his Age that went to the University". Stoughton was appointed Curate and Preacher at St Mary Aldermanbury, London (1632), and the family left Aller. Ralph's elder brother, James Cudworth, married and emigrated to Scituate, Plymouth Colony, New England (1634). Mary Machell Cudworth Stoughton died during summer 1634, and Dr Stoughton married a daughter of John Browne of Frampton and Dorchester.

A diligent student, Cudworth was admitted (as a pensioner) to Emmanuel College, Cambridge (1630), matriculated (1632), and graduated (BA (1635/6); MA (1639)). After some misgivings (which he confided in his stepfather), he was elected a Fellow of Emmanuel (1639), and became a successful tutor, delivering the Rede Lecture (1641). He published a tract entitled "The Union of Christ and the Church, in a Shadow" (1642), and another, "A Discourse concerning the True Notion of the Lord's Supper" (1642), in which his readings of Karaite manuscripts (stimulated by meetings with Johann Stephan Rittangel) were influential.

Following sustained correspondence with John Selden (to whom he supplied Karaite literature), he was elected (aged 28) as 11th Regius Professor of Hebrew (1645). In 1645, Thomas Paske had been ejected as Master of Clare Hall for his Anglican allegiances, and Cudworth (despite his immaturity) was selected as his successor, as 26th Master (but not admitted until 1650). Similarly, his fellow-theologian Benjamin Whichcote was installed as 19th Provost of King's College. Cudworth attained the degree of Bachelor of Divinity (1646), and preached a sermon before the House of Commons of England (on 1 John 2, 3â4), which was later published with a Letter of Dedication to the House (1647). Despite these distinctions and his presentation, by Emmanuel College, to the Rectoriate of North Cadbury, Somerset (3 October 1650), he remained comparatively impoverished. He was awarded the degree of Doctor of Divinity (1651), and, in January 1651/2, his friend Dr John Worthington wrote of him, "If through want of maintenance he should be forced to leave Cambridge, for which place he is so eminently accomplished with what is noble and Exemplarily Academical, it would be an ill omen."

Cudworth was elected (29 October 1654) and admitted (2 November 1654), as 14th Master of Christ's College. His appointment coincided with his marriage to Damaris (d.1695), daughter (by his first wife, Damaris) of Matthew Cradock (d.1641), first Governor of the Massachusetts Bay Company. Hence Worthington commented "After many tossings Dr Cudworth is through God's good Providence returned to Cambridge and settled in Christ's College, and by his marriage more settled and fixed."

In his Will (1641), Matthew Cradock had divided his estate beside the Mystic River at Medford, Massachusetts (which he had never visited, and was managed on his behalf) into two moieties: one was bequeathed to his daughter Damaris Cradock (d.1695), (later wife of Ralph Cudworth Jnr); and one was to be enjoyed by his widow Rebecca (during her lifetime), and afterwards to be inherited by his brother, Samuel Cradock (1583â1653), and his heirs male. Samuel Cradock's son, Samuel Cradock Jnr (1621â1706), was admitted to Emmanuel (1637), graduated (BA (1640â1); MA (1644); BD (1651)), was later a Fellow (1645â56), and pupil of Benjamin Whichcote. After part of the Medford estate was rented to Edward Collins (1642), it was placed in the hands of an attorney; the widow Rebecca Cradock (whose second and third husbands were Richard Glover and Benjamin Whichcote, respectively), petitioned the General Court of Massachusetts, and the legatees later sold the estate to Collins (1652).

The marriage of the widow Rebecca Cradock, to Cudworth's colleague Benjamin Whichcote laid the way for the union between Cudworth and her stepdaughter, Damaris (d.1695), thereby reinforcing the connections between the two scholars through a familial bond. Damaris had married, firstly (1642), Thomas Andrewes Jnr (d.1653) of London and Feltham, son of Sir Thomas Andrewes (d.1659), (Lord Mayor of London, 1649, 1651â2), which union had produced several children. The Andrewes family were also engaged in the Massachusetts project, and strongly supported puritan causes.

Cudworth emerged as a central figure among that circle of theologians and philosophers known as the Cambridge Platonists, who were (more or less) in sympathy with the Commonwealth: during the later 1650s, Cudworth was consulted by John Thurloe, Oliver Cromwell's Secretary to the Council of State, with regard to certain university and government appointments and various other matters. During 1657, Cudworth advised Bulstrode Whitelocke's sub-committee of the Parliamentary "Grand Committee for Religion" on the accuracy of editions of the English Bible. Cudworth was appointed Vicar of Great Wilbraham, and Rector of Toft, Cambridgeshire Ely diocese (1656), but surrendered these livings (1661 and 1662, respectively) when he was presented, by Dr Gilbert Sheldon, Bishop of London, to the Hertfordshire Rectory of Ashwell (1 December 1662).
Given Cudworth's close cooperation with prominent figures in Oliver Cromwell's regime (such as John Thurloe), Cudworth's continuance as Master of Christ's was challenged at the Restoration but, ultimately, he retained this post until his death. He and his family are believed to have resided in private lodgings at the "Old Lodge" (which stood between Hobson Street and the College Chapel), and various improvements were made to the College rooms in his time.

In 1665, Cudworth almost quarrelled with his fellow-Platonist, Henry More, because of the latter's composition of an ethical work which Cudworth feared would interfere with his own long-contemplated treatise on the same subject. To avoid any difficulties, More published his "Enchiridion ethicum" (1666â69), in Latin; However, Cudworth's planned treatise was never published. His own majestic work, "The True Intellectual System of the Universe" (1678), was conceived in three parts of which only the first was completed; he wrote: "there is no reason why this volume should therefore be thought imperfect and incomplete, because it hath not all the Three Things at first Designed by us: it containing all that belongeth to its own particular Title and Subject, and being in that respect no Piece, but a Whole."
Cudworth was installed as Prebendary of Gloucester (1678). His colleague, Benjamin Whichcote, died at Cudworth's house in Cambridge (1683), and Cudworth himself died (26 June 1688), and was buried in the Chapel of Christ's College. An oil portrait of Cudworth (from life) hangs in the Hall of Christ's College. During Cudworth's time an outdoor Swimming Pool was created at Christ's College (which still exists), and a carved bust of Cudworth there accompanies those of John Milton and Nicholas Saunderson.

Cudworth's widow, Damaris (nÃ©e Cradock) Andrewes Cudworth (d.1695), maintained close connections with her daughter, Damaris Cudworth Masham, at High Laver, Essex, which was where she died, and was commemorated in the church with a carved epitaph reputedly composed by the philosopher John Locke.

The children of Ralph Cudworth and Damaris (nÃ©e Cradock) Andrewes Cudworth (d.1695) were:


The stepchildren of Ralph Cudworth (children of Damaris (nÃ©e Cradock) Andrewes (d.1695) and Thomas Andrewes (d.1653) were:


Cudworth's works included "The Union of Christ and the Church, in a Shadow" (1642); "A Sermon preached before the House of Commons" (1647); and "A Discourse concerning the True Notion of the Lord's Supper" (1670). Much of Cudworth's work remains in manuscript. However, certain surviving works have been published posthumously, such as "A Treatise concerning eternal and immutable Morality, and A Treatise of Freewill. "

Cudworth's "Treatise on eternal and immutable Morality", published with a preface by Edward Chandler (1731), is about the historical development of British moral philosophy. It answers, from the standpoint of Platonism, Hobbes's famous doctrine that moral distinctions are created by the state: just as knowledge contains a permanent intelligible element over and above the flux of sense-impressions, so there exist eternal and immutable ideas of morality. Cudworth's ideas (like those of Plato) have "a constant and never-failing entity of their own" (such as we see in geometrical figures); but, unlike Plato's ideas, they exist in the mind of God, whence they are communicated to finite understandings. Hence "it is evident that wisdom, knowledge and understanding are eternal and self-subsistent things, superior to matter and all sensible beings, and independent upon them"; and so also are moral good and evil. Cudworth does not attempt to give any list of Moral Ideas. It is, indeed, the cardinal weakness of this form of intuitionism that no satisfactory list can be given, and that no moral principles have the "constant and never-failing entity" (or the definiteness) of the concepts of geometry (these attacks are not uncontestedÂ â for example, see "Common Sense" tradition from Thomas Reid to James McCosh and the Oxford Realists Harold Prichard and Sir William David Ross). Henry More's "Enchiridion ethicum", attempts to enumerate the ""noemata moralia""; but, so far from being self-evident, most of his moral axioms are open to serious controversy.

Another posthumous publication was Cudworth's "A Treatise of Freewill", edited by John Allen (1838). Both this and the "Treatise on eternal and immutable Morality" are connected with the design of his "magnum opus", "The True Intellectual System of the Universe".

In 1678, Cudworth published "The True Intellectual System of the Universe: the first part, wherein all the reason and philosophy of atheism is confuted and its impossibility demonstrated", which had been given an Imprimatur for publication (29 May 1671).
The "Intellectual System" arose, so Cudworth informs us, from a discourse refuting "fatal necessity", or determinism. Enlarging his plan, he proposed to prove three matters:

These three comprise, collectively, the intellectual (as opposed to the physical) system of the universe; and they are opposed, respectively, by three false principles: atheism, religious fatalism (which refers all moral distinctions to the will of God), and the fatalism of the ancient Stoics (who recognized God and yet identified Him with nature). The immense fragment dealing with atheism was all that was published, perhaps because of the theological clamour raised against this first part.

Cudworth criticizes two main forms of materialistic atheism: the atomic (adopted by Democritus, Epicurus and Hobbes); and the hylozoic (attributed to Strato of Lampsacus, which explains everything by the supposition of an inward self-organizing life in matter). Atomic atheism is by far the more important, if only because Hobbes (the great antagonist whom Cudworth always has in view), is supposed to have held this view. It arises from the combination of two principles, neither of which is, individually, atheistic (namely atomism and corporealism (or the doctrine that nothing exists but body)). The example of Stoicism, as Cudworth suggests, shows that corporealism may be theistic.

Cudworth plunges into the history of atomism with vast erudition. It is, in its purely physical application (a theory that he fully accepts), he holds that atomism was taught by Pythagoras, Empedocles (and, in fact, nearly all the ancient philosophers), and was only perverted to atheism by Democritus. Cudworth believes that atomism was first invented before the Trojan war by a Sidonian thinker named Moschus or Mochus (identical with Moses in the Old Testament). In dealing with atheism, Cudworth's method was to marshal the atheistic arguments elaborately, so elaborately that Dryden remarked "he has raised such objections against the being of a God and Providence that many think he has not answered them"; then, in his last chapter (which, by itself, is the length of an ordinary treatise), he confutes the arguments with all the reasons that his reading could supply. A subordinate matter in the book which attracted much attention at the time was the conception of the "Plastic Medium" (a mere revival of Plato's "World-Soul," which is intended to explain the existence and laws of nature without referring to the direct operation of God), which occasioned a long-drawn controversy, between Pierre Bayle and Le Clerc (the former maintaining; the latter denying), that the Plastic Medium is favourable to atheism.

Andrew Dickson White wrote in his "A History of the Warfare of Science with Theology in Christendom" (1896):
In 1678 Ralph Cudworth published his "Intellectual System of the Universe". To this day he remains, in breadth of scholarship, in strength of thought, in tolerance, and in honesty, one of the greatest glories of the English Church... He purposed to build a fortress which should protect Christianity against all dangerous theories of the universe, ancient or modern. ...while genius marked every part of it, features appeared which gave the rigidly orthodox serious misgivings. From the old theories of direct personal action on the universe by the Almighty he broke utterly. He dwelt on the action of law, rejected the continuous exercise of miraculous intervention, pointed out the fact that in the natural world there are "errors" and "bungles" and argued vigorously in favor of the origin and maintenance of the universe as a slow and gradual development of Nature in obedience to an inward principle.



 


</doc>
<doc id="26186" url="https://en.wikipedia.org/wiki?curid=26186" title="Roswell, New Mexico">
Roswell, New Mexico

Roswell is a city in, and the seat of, Chaves County in the U.S. state of New Mexico, the county forms the entirety of the Roswell micropolitan area. As of the 2010 census it had a population of 48,411, making it the fifth-largest city in New Mexico. It is home of New Mexico Military Institute (NMMI), founded in 1891. The city is also the location of an Eastern New Mexico University campus. Bitter Lake National Wildlife Refuge is located a few miles northeast of the city on the Pecos River. Bottomless Lakes State Park is located east of Roswell on US 380.

The Roswell UFO incident was named after the town, though the crash site of the alleged UFO was some from Roswell and closer to Corona. The investigation and debris recovery was handled by the local Roswell Army Air Field. In the 1930s, Roswell was a site for much of Robert H. Goddard's early rocketry work. The Roswell Museum and Art Center maintains an exhibit which includes a recreation of Goddard's rocket engine development workshop.

Roswell's tourism industry is based on aerospace engineering and ufology museums and businesses, as well as alien-themed and spacecraft-themed iconography. The city also relies on New Mexico and Americana related tourism. New Mexican cuisine restaurants, such as Martin's Capitol CafÃ©, are located near downtown on Main Street, near the International UFO Museum and Research Center. Other New Mexican cuisine restaurants are located near the New Mexico Military Institute and Eastern New Mexico University campuses, including Burrito Express locations. Local American folk and New Mexico music performances occur near Pioneer Plaza and in parks around the city. It is a center for acequia-similar irrigated farming, dairying, and ranching, it also the location of several manufacturing, distribution, and petroleum related facilities. This regional pride has resulted in Roswell receiving the All-America City Award multiple times, in 1978â79 and 2002.

The first non-indigenous settlers of the area around Roswell were a group of pioneers from Missouri, who attempted to start a settlement southwest of what is now Roswell in 1865, but were forced to abandon the site because of a lack of water. It was called Missouri Plaza. It also had many Hispanic people from Lincoln, New Mexico. John Chisum had his famous Jingle Bob Ranch about from the center of Roswell, at South Spring Acres. At the time, it was the largest ranch in the United States.

Van C. Smith, a businessman from Omaha, Nebraska, and his partner, Aaron Wilburn, constructed two adobe buildings in 1869 that began what is now Roswell. The two buildings became the settlement's general store, post office, and sleeping quarters for paying guests. In 1871, Smith filed a claim with the federal government for the land around the buildings, and on August 20, 1873, he became the town's first postmaster. Smith was the son of Roswell Smith, a prominent lawyer in Lafayette, Indiana, and Annie Ellsworth, daughter of U.S. Patent Commissioner Henry Leavitt Ellsworth. He called the town Roswell, after his father's first name.

In 1877, Captain Joseph Calloway Lea and his family bought out Smith and Wilburn's claim and became the owners of most of the land of Roswell and the area surrounding it. The town was relatively quiet during the Lincoln County War (1877â1879). A major aquifer was discovered when merchant Nathan Jaffa had a well drilled in his back yard on Richardson Avenue in 1890, resulting in the area's first major growth and development spurt. The growth continued when a railroad was built through town in 1893.

During World War II, a prisoner-of-war camp was located in nearby Orchard Park. The German prisoners of war were used to do major infrastructure work in Roswell, such as paving the banks of the North Spring River. Some POWs used rocks of different sizes to create the outline of an iron cross among the stones covering the north bank. Later, the iron cross was covered with a thin layer of concrete. In the 1980s, a crew cleaning the river bed cleared off the concrete and revealed the outline once more. The small park just south of the cross was then known as Iron Cross Park. On November 11, 1996, the park was renamed POW/MIA Park. The park displays a piece of the Berlin Wall, presented to the city of Roswell by the German Air Force.

Roswell was a location of military importance from 1941 to 1967. In 1967, the Walker Air Force Base was decommissioned. After the closure of the base, Roswell capitalized on its pleasant climate and reinvented itself as a retirement community.

Roswell has benefited from interest in the alleged UFO incident of 1947. It was the report of an object that crashed in the general vicinity in June or July 1947, allegedly an extraterrestrial spacecraft and its alien occupants. Since the late 1970s, the incident has been the subject of intense controversy and of a conspiracy theory regarding a classified program named "Mogul". Many UFO proponents maintain that an alien craft was found and its occupants were captured, and that the military then engaged in a cover-up. In recent times, the business community has deliberately sought out tourists interested in UFOs, science fiction, and aliens.

Roswell hosted the record-breaking skydive by Felix Baumgartner on October 14, 2012.

Roswell is located in southeastern New Mexico, approximately west of the Pecos River and some east of highlands that rise to the Sierra Blanca range. U.S. Routes 70, 285 and 380 intersect in the city. US 70 leads northeast to Clovis and west to Alamogordo; US 285 leads north to Santa Fe and south to Carlsbad; and US 380 leads east to Brownfield, Texas, and west to Socorro.

According to the United States Census Bureau, Roswell has a total area of , of which is land and , or 0.19%, is covered by water.
Roswell is located in the High Plains and has four very distinct seasons, giving it a "BSk" or "BSh" semiarid climate according to the KÃ¶ppen climate classification. Winters are cold, but usually sunny, and snowfall is a common occurrence. Spring is mild and usually warm, but can still be cold on occasion. Summers are hot (as is common with the High Plains of New Mexico and Colorado) and, quite frequently, the temperature rises above 100Â Â°F, which can be unpleasant. The North American monsoon occurs during the summer, and can bring torrential downpours, severe thunderstorms (with high winds and hail) and sometimes even tornadoes. The rain can provide a cooling relief from the scorching great plains heat. Fall is mild and pleasant, but can be cold. Snow is possible in October and November.

The record low in Roswell is on January 11, 1962 and February 8, 1933. The record high is on June 27, 1994.

As of the 2000 census, 45,293 people, 17,068 households, and 11,742 families resided in the city. The population density was 1,565.2 people per square mile (604.3/kmÂ²). The 19,327 housing units averaged 667.9 per square mile (257.9/kmÂ²). The racial makeup of the city was 70.96% White, 2.47% African American, 1.28% Native American, 0.65% Asian, 21.29% from other races, and 3.31% from two or more races. Hispanics or Latinos of any race were 44.34% of the population.

Of the 17,069 households, 34.5% had children under the age of 18 living with them, 49.1% were married couples living together, 14.9% had a female householder with no husband present, and 31.2% were not families. About 27.1% of all households were made up of individuals, and 13.4% had someone living alone who was 65 years of age or older. The average household size was 2.58 and the average family size was 3.13.

In the city, the population was distributed as 28.5% under the age of 18, 9.9% from 18 to 24, 24.9% from 25 to 44, 20.6% from 45 to 64, and 16.0% who were 65 years of age or older. The median age was 35 years. For every 100 females, there were 93.1 males. For every 100 females age 18 and over, there were 88.7 males.

The median income for a household in the city was $27,252, and for a family was $31,724. Males had a median income of $26,554 versus $21,408 for females. The per capita income for the city was $14,589. About 18.7% of families and 22.6% of the population were below the poverty line, including 31.1% of those under age 18 and 13.8% of those age 65 or over.









Roswell is home to Leprino Foods, one of the world's largest mozzarella factories. It is also the location of the former Transportation Manufacturing Corporation factory, best known for producing various iterations of the RTS city bus since 1987. The factory was operated by Nova Bus from 1994 to 2003 and subsequently by Millennium Transit Services.






</doc>
<doc id="26188" url="https://en.wikipedia.org/wiki?curid=26188" title="Relativity">
Relativity

Relativity may refer to:








</doc>
<doc id="26191" url="https://en.wikipedia.org/wiki?curid=26191" title="Red Sea">
Red Sea

The Red Sea () is a seawater inlet of the Indian Ocean, lying between Africa and Asia. The connection to the ocean is in the south through the Bab el Mandeb strait and the Gulf of Aden. To the north lie the Sinai Peninsula, the Gulf of Aqaba, and the Gulf of Suez (leading to the Suez Canal). The Red Sea is a Global 200 ecoregion. The sea is underlain by the Red Sea Rift which is part of the Great Rift Valley.

The Red Sea has a surface area of roughly 438,000Â km (169,100Â mi), is about 2250Â km (1398Â mi) long and, at its widest point, 355Â km (220.6Â mi) wide. It has a maximum depth of in the central "Suakin Trough", and an average depth of 490Â m (1,608Â ft). However, there are also extensive shallow shelves, noted for their marine life and corals. The sea is the habitat of over 1,000 invertebrate species, and 200 soft and hard corals. It is the world's northernmost tropical sea.

The International Hydrographic Organization defines the limits of the Red Sea as follows:

"Red Sea" is a direct translation of the Greek "Erythra Thalassa" (), Latin "Mare Rubrum" (alternatively "Sinus Arabicus", literally "Arabian Gulf"), (alternatively Ø¨Ø­Ø± Ø§ÙÙÙØ²Ù "Baá¸¥r Al-Qulzum", literally "the Sea of Clysma"), Somali "Badda Cas" and Tigrinya "Qeyyiá¸¥ bÄá¸¥rÄ«" (áá­á á£ááª). The name of the sea may signify the seasonal blooms of the red-coloured "Trichodesmium erythraeum" near the water's surface. A theory favoured by some modern scholars is that the name "red" is referring to the direction south, just as the Black Sea's name may refer to north. The basis of this theory is that some Asiatic languages used colour words to refer to the cardinal directions. Herodotus on one occasion uses Red Sea and Southern Sea interchangeably.

The name in Hebrew "Yam Suph" () is of biblical origin.
The name in "Phiom Enhah" ("Sea of Hah") is connected to Ancient Egyptian root "á¸¥á¸¥" which refers to water and sea (for example the names of the Ogdoad gods Heh and Hauhet) - Pa-yem 'Aa en Mu-Ked, the ancient Egyptian name of the Red Sea.

Historically, it was also known to western geographers as "Mare Mecca" (Sea of Mecca), and "Sinus Arabicus" (Gulf of Arabia). Some ancient geographers called the Red Sea the Arabian Gulf or Gulf of Arabia.

The association of the Red Sea with the biblical account of the Israelites crossing the Red Sea is ancient, and was made explicit in the Septuagint translation of the Book of Exodus from Hebrew to Koine Greek in approximately the third century B.C. In that version, the "Yam Suph" () is translated as "Erythra Thalassa" (Red Sea). Although reeds do not grow in the Red Sea today (reeds do not grow in salt water), Professor Colin Humphreys explains the discrepancy on the basis that a freshwater marsh of reeds could have existed around Aqaba.

The Red Sea is one of four seas named in English after common color terms â the others being the Black Sea, the White Sea and the Yellow Sea. The direct rendition of the Greek "Erythra thalassa" in Latin as Mare Erythraeum refers to the north-western part of the Indian Ocean, and also to a region on Mars.

The earliest known exploration of the Red Sea was conducted by ancient Egyptians, as they attempted to establish commercial routes to Punt. One such expedition took place around 2500 BCE, and another around 1500 BCE (by Hatshepsut). Both involved long voyages down the Red Sea. The biblical Book of Exodus tells the account of the Israelites' crossing of a body of water, which the Hebrew text calls "Yam Suph" (). "Yam Suph" was traditionally identified as the Red Sea. Rabbi Saadia Gaon (882â942), in his Judeo-Arabic translation of the Pentateuch, identifies the crossing place of the Red Sea as "Baá¸¥ar al-Qulzum", meaning the Gulf of Suez.

In the 6th century BCE, Darius the Great of Persia sent reconnaissance missions to the Red Sea, improving and extending navigation by locating many hazardous rocks and currents. A canal was built between the Nile and the northern end of the Red Sea at Suez. In the late 4th century BCE, Alexander the Great sent Greek naval expeditions down the Red Sea to the Indian Ocean. Greek navigators continued to explore and compile data on the Red Sea. Agatharchides collected information about the sea in the 2nd century BCE. The "Periplus of the Erythraean Sea" ("Periplus of the Red Sea"), a Greek periplus written by an unknown author around the 1st century , contains a detailed description of the Red Sea's ports and sea routes. The Periplus also describes how Hippalus first discovered the direct route from the Red Sea to India.

The Red Sea was favored for Roman trade with India starting with the reign of Augustus, when the Roman Empire gained control over the Mediterranean, Egypt, and the northern Red Sea. The route had been used by previous states but grew in the volume of traffic under the Romans. From Indian ports goods from China were introduced to the Roman world. Contact between Rome and China depended on the Red Sea, but the route was broken by the Aksumite Empire around the 3rd century AD.

During the Middle Ages, the Red Sea was an important part of the spice trade route. In 1183, Raynald of ChÃ¢tillon launched a raid down the Red Sea to attack the Muslim pilgrim convoys to Mecca. The possibility that Raynald's fleet might sack the holy cities of Mecca and Medina caused fury throughout the Muslim world. However, it appears that Reynald's target were the lightly armed Muslim pilgrim convoys rather the well guarded cities of Mecca and Medina, and the belief in the Muslim world that Reynald was seeking to sack the holy cities was due to the proximity of those cities to the areas that Raynald raided. In 1513, trying to secure that channel to Portugal, Afonso de Albuquerque laid siege to Aden but was forced to retreat. They cruised the Red Sea inside the Bab al-Mandab, as the first fleet from Europe in modern times to have sailed these waters.

In 1798, France ordered General Napoleon to invade Egypt and take control of the Red Sea. Although he failed in his mission, the engineer Jean-Baptiste LepÃ¨re, who took part in it, revitalised the plan for a canal which had been envisaged during the reign of the Pharaohs. Several canals were built in ancient times from the Nile to the Red Sea along or near the line of the present Sweet Water Canal, but none lasted for long. The Suez Canal was opened in November 1869. After the Second World War, the Americans and Soviets exerted their influence whilst the volume of oil tanker traffic intensified. However, the Six-Day War culminated in the closure of the Suez Canal from 1967 to 1975. Today, in spite of patrols by the major maritime fleets in the waters of the Red Sea, the Suez Canal has never recovered its supremacy over the Cape route, which is believed to be less vulnerable to piracy.

The Red Sea is between arid land, desert and semi-desert. Reef systems are better developed along the Red Sea mainly because of its greater depths and an efficient water circulation pattern. The Red Sea water mass-exchanges its water with the Arabian Sea, Indian Ocean via the Gulf of Aden. These physical factors reduce the effect of high salinity caused by evaporation in the north and relatively hot water in the south.

The climate of the Red Sea is the result of two monsoon seasons; a northeasterly monsoon and a southwesterly monsoon. Monsoon winds occur because of differential heating between the land and the sea. Very high surface temperatures and high salinities make this one of the warmest and saltiest bodies of seawater in the world. The average surface water temperature of the Red Sea during the summer is about in the north and in the south, with only about 2Â Â°C (3.6Â Â°F) variation during the winter months. The overall average water temperature is . Temperature and visibility remain good to around 200Â m (656Â ft). The sea is known for its strong winds and unpredictable local currents.

The rainfall over the Red Sea and its coasts is extremely low, averaging per year. The rain is mostly short showers, often with thunderstorms and occasionally with dust storms. The scarcity of rainfall and no major source of fresh water to the Red Sea result in excess evaporation as high as per year and high salinity with minimal seasonal variation. A recent underwater expedition to the Red Sea offshore from Sudan and Eritrea found surface water temperatures in winter and up to in the summer, but despite that extreme heat, the coral was healthy with much fish life with very little sign of coral bleaching, with only 9% infected by "Thalassomonas loyana", the 'white plague' agent. "Favia favus" coral there harbours a virus, BA3, which kills "T. loyana".
Plans are afoot to use samples of these corals' apparently heat-adapted commensal algae to salvage bleached coral elsewhere.

The Red Sea is one of the saltiest bodies of water in the world, owing to high evaporation and low precipitation; no significant rivers or streams drain into the sea, and its southern connection to the Gulf of Aden, an arm of the Indian Ocean, is narrow. Its salinity ranges from between ~36Â â° in the southern part and 41Â â° in the northern part around the Gulf of Suez, with an average of 40Â â°. (Average salinity for the world's seawater is ~35Â â° on the Practical Salinity Scale, or PSU; that translates to 3.5% of actual dissolved salts.)

In general, tide ranges between in the north, near the mouth of the Gulf of Suez and in the south near the Gulf of Aden, but it fluctuates between and away from the nodal point. The central Red Sea (Jeddah area) is therefore almost tideless, and as such the annual water level changes are more significant. Because of the small tidal range the water during high tide inundates the coastal sabkhas as a thin sheet of water up to a few hundred metres rather than flooding the sabkhas through a network of channels. However, south of Jeddah in the Shoiaba area, the water from the lagoon may cover the adjoining sabkhas as far as , whereas north of Jeddah in the Al-Kharrar area the sabkhas are covered by a thin sheet of water as far as . The prevailing north and northeast winds influence the movement of water in the coastal inlets to the adjacent sabkhas, especially during storms. Winter mean sea level is higher than in summer. Tidal velocities passing through constrictions caused by reefs, sand bars and low islands commonly exceed 1â2Â m/s (3â6.5Â ft/s). Coral reefs in the Red Sea are near Egypt, Eritrea, Israel, Saudi Arabia, and Sudan.

Detailed information regarding current data is lacking, partially because the currents are weak and both spatially and temporally variable. The variation of temporal and spatial currents is as low as and are governed all by wind. During the summer, NW winds drive surface water south for about four months at a velocity of 15â20Â cm/s (6â8Â in/s), whereas in winter the flow is reversed resulting in the inflow of water from the Gulf of Aden into the Red Sea. The net value of the latter predominates, resulting in an overall drift to the north end of the Red Sea. Generally, the velocity of the tidal current is between 50â60Â cm/s (20â23.6Â in/s) with a maximum of at the mouth of the al-Kharrar Lagoon. However, the range of the north-northeast current along the Saudi coast is 8â29Â cm/s (3â11.4Â in/s).

The north part of the Red Sea is dominated by persistent north-west winds, with speeds ranging between and . The rest of the Red Sea and the Gulf of Aden are subjected to regular and seasonally reversible winds. The wind regime is characterized by seasonal and regional variations in speed and direction with average speed generally increasing northward.

Wind is the driving force in the Red Sea to transport material as suspension or as bedload. Wind-induced currents play an important role in the Red Sea in resuspending bottom sediments and transferring materials from sites of dumping to sites of burial in quiescent environment of deposition. Wind-generated current measurement is therefore important in order to determine the sediment dispersal pattern and its role in the erosion and accretion of the coastal rock exposure and the submerged coral beds.

The Red Sea was formed by the Arabian peninsula being split from the Horn of Africa by movement of the Red Sea Rift. This split started in the Eocene and accelerated during the Oligocene. The sea is still widening (in 2005, following a three-week period of tectonic activity it had grown by 8m), and it is considered that it will become an ocean in time (as proposed in the model of John Tuzo Wilson). In 1949, a deep water survey reported anomalously hot brines in the central portion of the Red Sea. Later work in the 1960s confirmed the presence of hot, 60Â Â°C (140Â Â°F), saline brines and associated metalliferous muds. The hot solutions were emanating from an active subseafloor rift. Lake Asal in Djibouti is eligible as an experimental site to study the evolution of the deep hot brines of the Red Sea. Indeed, by observing the strontium isotope composition of the Red Sea brines, it is easy to deduce how these salt waters found at the bottom of the Red Sea could have evolved in a similar way to Lake Asal, which ideally represents their compositional extreme. The high salinity of the waters was not hospitable to living organisms.

Sometime during the Tertiary period, the Bab el Mandeb closed and the Red Sea evaporated to an empty hot dry salt-floored sink. Effects causing this would have been:

A number of volcanic islands rise from the center of the sea. Most are dormant. However, in 2007, Jabal al-Tair island in the Bab el Mandeb strait erupted violently. Two new islands were formed in 2011 and 2013 in the Zubair Archipelago, a small chain of islands owned by Yemen. The first island, Sholan Island, emerged in an eruption in December 2011, the second island, Jadid, emerged in September 2013.

The Durwara 2 Field was discovered in 1963, while the Suakin 1 Field and the Bashayer 1A Field were discovered in 1976, on the Egyptian side of the Red Sea. The Barqan Field was discovered in 1969, and the Midyan Field in 1992, both within the Midyan Basin on the Saudi Arabian side of the Red Sea. The 20-m thick Middle Miocene Maqna Formation is an oil source rock in the basin. Oil seeps occur near the Farasan Islands, the Dahlak Archipelago, along the coast of Eritrea, and in the southeastern Red Sea along the coasts of Saudi Arabia and Yemen.

In terms of mineral resources the major constituents of the Red Sea sediments are as follows:

The Red Sea is a rich and diverse ecosystem. More than 1200 species of fish have been recorded in the Red Sea, and around 10% of these are found nowhere else. This also includes 42 species of deepwater fish. 

The rich diversity is in part due to the of coral reef extending along its coastline; these fringing reefs are 5000â7000 years old and are largely formed of stony acropora and porites corals. The reefs form platforms and sometimes lagoons along the coast and occasional other features such as cylinders (such as the Blue Hole (Red Sea) at Dahab). These coastal reefs are also visited by pelagic species of Red Sea fish, including some of the 44 species of shark.

It contains 175 species of nudibranch, many of which are only found in the Red Sea.

The Red Sea also contains many offshore reefs including several true atolls. Many of the unusual offshore reef formations defy classic (i.e., Darwinian) coral reef classification schemes, and are generally attributed to the high levels of tectonic activity that characterize the area.

The special biodiversity of the area is recognized by the Egyptian government, who set up the Ras Mohammed National Park in 1983. The rules and regulations governing this area protect local marine life, which has become a major draw for diving enthusiasts.

Divers and snorkellers should be aware that although most Red Sea species are innocuous, a few are hazardous to humans: see Red Sea species hazardous to humans.

Other marine habitats include sea grass beds, salt pans, mangroves and salt marshes.

There is extensive demand for desalinated water to meet the needs of the population and the industries along the Red Sea.

There are at least 18 desalination plants along the Red Sea coast of Saudi Arabia which discharge warm brine and treatment chemicals (chlorine and anti-scalants) that bleach and kill corals and cause diseases in the fish. This is only localized, but it may intensify with time and profoundly impact the fishing industry.

The water from the Red Sea is also used by oil refineries and cement factories for cooling.

The Red Sea is part of the sea roads between Europe, the Persian Gulf and East Asia, and as such has heavy shipping traffic. Government-related bodies with responsibility to police the Red Sea area include the Port Said Port Authority, Suez Canal Authority and Red Sea Ports Authority of Egypt, Jordan Maritime Authority, Israel Port Authority, Saudi Ports Authority and Sea Ports Corporation of Sudan.

The sea is known for its recreational diving sites, such as Ras Mohammed, SS Thistlegorm (shipwreck), Elphinstone Reef, The Brothers, Daedalus Reef, St.John's Reef, Rocky Island in Egypt and less known sites in Sudan such as Sanganeb, Abington, Angarosh and Shaab Rumi.

The Red Sea became a popular destination for diving after the expeditions of Hans Hass in the 1950s, and later by Jacques-Yves Cousteau. Popular tourist resorts include El Gouna, Hurghada, Safaga, Marsa Alam, on the west shore of the Red Sea, and Sharm-el-Sheikh, Dahab, and Taba on the Egyptian side of SinaÃ¯, as well as Aqaba in Jordan and Eilat in Israel in an area known as the Red Sea Riviera.

The popular tourist beach of Sharm el-Sheikh was closed to all swimming in December 2010 due to several serious shark attacks, including a fatality. As of December 2010, scientists are investigating the attacks and have identified, but not verified, several possible causes including over-fishing which causes large sharks to hunt closer to shore, tourist boat operators who chum offshore for shark-photo opportunities, and reports of ships throwing dead livestock overboard. The sea's narrowness, significant depth, and sharp drop-offs, all combine to form a geography where large deep-water sharks can roam in hundreds of meters of water, yet be within a hundred meters of swimming areas.
Tourism to the region has been threatened by occasional terrorist attacks, and by incidents related to food safety standards.

The Red Sea may be geographically divided into three sections: the Red Sea proper, and in the north, the Gulf of Aqaba and the Gulf of Suez. The six countries bordering the Red Sea proper are:


The Gulf of Suez is entirely bordered by Egypt. The Gulf of Aqaba borders Egypt, Israel, Jordan and Saudi Arabia.

In addition to the standard geographical definition of the six countries bordering the Red Sea cited above, areas such as Somalia are sometimes also described as Red Sea territories. This is primarily due to their proximity to and geological similarities with the nations facing the Red Sea and/or political ties with said areas.

Towns and cities on the Red Sea coast (including the coasts of the Gulfs of Aqaba and Suez) include:





</doc>
<doc id="26192" url="https://en.wikipedia.org/wiki?curid=26192" title="Josh Kirby">
Josh Kirby

Ronald William "Josh" Kirby (27 November 1928 â 23 October 2001) was a commercial artist born on the outskirts of Liverpool in the town of Waterloo, Lancashire, in the U.K. With a career spanning 60 years, he is known for being the original artist for the covers of Terry Pratchett's Discworld novels, as well as some of science fiction's most acclaimed book cover illustrations.

Born Ronald William Kirby in 1928 at 58 Argo Road, Waterloo (at that date this was in the sub-district of Crosby, County of Lancashire), Liverpool, to Charles William and Ellen (nÃ©e Marsh) Kirby. His father was a ship owner's freight clerk, and his parents ran a grocery shop. Kirby lived at this address while studying at Liverpool's School of Art. 

Kirby dreamed of his future career early on, so that at age 7, he made the trade sign that said âKIRBY â ARTISTâ. As a boy, Kirby found a magazine for young people called "The Modern World", which pictured a valley of giant insects and futuristic vehicles. Science fiction fascinated him from that point on. It was the genre in which "the realm of the possible was extended."

As a young adult he spent six years studying various art techniques at the Liverpool City School of Art (1943-1949), gaining a certificate and diploma in drawing and painting respectively. It was here that his Old Master-style portraits earned him the nickname "Josh" when colleagues likened his work to that of the painter Sir Joshua Reynolds. The nickname stuck and, from that time forward, few people ever called him by his original name.

After leaving art school, Liverpool City Council commissioned him to paint the Mayor in 1950 â an honour for a 22-year old artist starting out. Kirby ultimately decided against portraiture as a career and turned to illustration.

His professional freelance career started in the early 1950s when Kirby illustrated film posters for studios in both London and Paris. His first published cover art was for the 1955 science fiction novel "Cee-Tee Man", by Dan Morgan. His next milestone was in 1956 when he created a cover for Ian Fleming's book, "Moonraker".

Kirby began to produce artwork for book covers ranging from westerns and crime novels to non-fiction, as well as painting covers and interior art for science fiction magazines. His illustrations appear on the covers of some of the literary science fiction, fantasy and horror books of the 50s, 60s, 70s and 80s. The list of authors includes Ray Bradbury, Isaac Asimov, Alfred Hitchcock, Guy de Maupassant, Jimmy Sangster, Richard Matheson, Ursula Le Guin, Jack Kerouac, Jules Verne, Edgar Rice Burroughs, Robert Heinlein, H. G. Wells, Robert Rankin, Craig Shaw Gardner, Stephen Briggs, Ron Goulart, Brian Aldiss as well as Terry Pratchett.

In the 70s, Kirby returned to film poster art for publicity agency FEREF. Working alongside designer Eddie Paul, Kirby depicted the characters for Star Wars: "Return of the Jedi;" films "The Beastmaster" and "Krull", among many others. When the market for poster illustration dried up in the mid 80s, Kirby switched his attention to the booming role-playing game phenomena. He provided cover art for "Duelmasters", "Tunnels & Trolls" and "Wizards & Warriors." 

Kirbyâs most significant move of the 80s was teaming up with Terry Pratchett, a commission that Kirby thought would be a "one-off". He was eventually commissioned to produce the covers for the "Discworld" series, producing 26 covers before his death in 2001. Beginning with the twenty-seventh "Discworld" novel, "The Last Hero" (2001), Paul Kidby took over as cover illustrator.

Pratchett said, "I only invented the Discworld, Josh created it.â

Throughout his career, Kirby used oils, acrylics, gouache, or watercolor, often using more than one method on a single piece. Ultimately, he preferred oils as they wouldnât dry too quickly and could be manipulated and applied in layers. This allowed for them to be retouched or entirely painted over, whatever it took to achieve the result. 

Kirby worked slowly and meticulously. It would take him four to eight weeks to complete a single painting because his process included reading each novel before illustrating it. He would then draw a rough sketch in pencil to be approved by the art editor at the publisher, except in the case where Kirby would discuss the concept over the phone directly with Pratchett â unusual in the publishing world where the convention is to deal with the publisher's art director.

When asked about influences, he most often named three past artists. The oldest was Hieronymus Bosch, famous for his fantastic imagery, detailed landscapes and illustrations of religious concepts and narratives. Next was Pieter Bruegel, whose religious and mythological depictions expanded the viewerâs perspective of reality. And finally muralist Frank Brangwyn, an avante-garde artist-craftsman notable for his boldly-coloured murals.

Past collections of his work include: 

"The Voyage of the Ayeguy" (1981), a portfolio of six linked science-fantasy pictures

"The Josh Kirby Poster Book" (1989), containing 13 posters inspired by Discworld

"Faust Eric" (1990), by Terry Pratchett with 15 Kirby illustrations

"In the Garden of Unearthly Delights" (1991), a large selection of 159 Kirby paintings

"The Josh Kirby Discworld Portfolio" (1993).


Kirby died of natural causes in his sleep at home in Shelfanger near Diss in Norfolk at the age of 72.




</doc>
<doc id="26193" url="https://en.wikipedia.org/wiki?curid=26193" title="Roger Penrose">
Roger Penrose

Sir Roger Penrose (born 8 August 1931) is an English mathematical physicist, mathematician and philosopher of science. He is Emeritus Rouse Ball Professor of Mathematics in the University of Oxford, an emeritus fellow of Wadham College, Oxford and an honorary fellow of St John's College, Cambridge.

Penrose has made contributions to the mathematical physics of general relativity and cosmology. He has received several prizes and awards, including the 1988 Wolf Prize for physics, which he shared with Stephen Hawking for the PenroseâHawking singularity theorems.

Born in Colchester, Essex, Roger Penrose is a son of psychiatrist and geneticist Lionel Penrose and Margaret Leathes, and the grandson of the physiologist John Beresford Leathes and his Russian wife, Sonia Marie Natanson, who had left St. Petersburg in the late 1880s. His uncle was artist Roland Penrose, whose son with photographer Lee Miller is Antony Penrose. Penrose is the brother of physicist Oliver Penrose and of chess Grandmaster Jonathan Penrose. Penrose attended University College School and University College, London, where he graduated with a first class degree in mathematics. In 1955, while still a student, Penrose reintroduced the E. H. Moore generalised matrix inverse, also known as the MooreâPenrose inverse, after it had been reinvented by Arne Bjerhammar in 1951. Having started research under the professor of geometry and astronomy, Sir W. V. D. Hodge, Penrose finished his PhD at St John's College, Cambridge in 1958, with a thesis on "tensor methods in algebraic geometry" under algebraist and geometer John A. Todd. He devised and popularised the Penrose triangle in the 1950s, describing it as "impossibility in its purest form", and exchanged material with the artist M. C. Escher, whose earlier depictions of impossible objects partly inspired it. Escher's Waterfall, and Ascending and Descending were in turn inspired by Penrose.

As reviewer Manjit Kumar puts it:
Having become a reader at Birkbeck College, London (and having had his attention drawn from pure mathematics to astrophysics by the cosmologist Dennis Sciama, then at Cambridge) it was in 1964 that, in the words of Kip Thorne of Caltech, "Roger Penrose revolutionised the mathematical tools that we use to analyse the properties of spacetime". Until then work on the curved geometry of general relativity had been confined to configurations with sufficiently high symmetry for Einstein's equations to be soluble explicitly, and there was doubt about whether such cases were typical. One approach to this issue was by the use of perturbation theory, as developed under the leadership of John Archibald Wheeler at Princeton. The other, more radically innovative, approach initiated by Penrose was to overlook the detailed geometrical structure of spacetime and instead concentrate attention just on the topology of the space, or at most its conformal structure, since it is the latter â as determined by the lay of the lightcones â that determines the trajectories of lightlike geodesics, and hence their causal relationships. The importance of Penrose's epoch-making paper "Gravitational collapse and space-time singularities" was not only its result (roughly that if an object such as a dying star implodes beyond a certain point, then nothing can prevent the gravitational field getting so strong as to form some kind of singularity). It also showed a way to obtain similarly general conclusions in other contexts, notably that of the cosmological Big Bang, which he dealt with in collaboration with Dennis Sciama's most famous student, Stephen Hawking.
It was in the local context of gravitational collapse that the contribution of Penrose was most decisive, starting with his 1969 cosmic censorship conjecture, to the effect that any ensuing singularities would be confined within a well-behaved event horizon surrounding a hidden space-time region for which Wheeler coined the term black hole, leaving a visible exterior region with strong but finite curvature, from which some of the gravitational energy may be extractable by what is known as the Penrose process, while accretion of surrounding matter may release further energy that can account for astrophysical phenomena such as quasars.

Following up his "weak cosmic censorship hypothesis", Penrose went on, in 1979, to formulate a stronger version called the "strong censorship hypothesis". Together with the BKL conjecture and issues of nonlinear stability, settling the censorship conjectures is one of the most important outstanding problems in general relativity. Also from 1979 dates Penrose's influential Weyl curvature hypothesis on the initial conditions of the observable part of the universe and the origin of the second law of thermodynamics. Penrose and James Terrell independently realised that objects travelling near the speed of light will appear to undergo a peculiar skewing or rotation. This effect has come to be called the Terrell rotation or PenroseâTerrell rotation.
In 1967, Penrose invented the twistor theory which maps geometric objects in Minkowski space into the 4-dimensional complex space with the metric signature (2,2). 

Penrose is well known for his 1974 discovery of Penrose tilings, which are formed from two tiles that can only tile the plane nonperiodically, and are the first tilings to exhibit fivefold rotational symmetry. Penrose developed these ideas based on the article "Deux types fondamentaux de distribution statistique" (1938; an English translation "Two Basic Types of Statistical Distribution") by Czech geographer, demographer and statistician JaromÃ­r KorÄÃ¡k. In 1984, such patterns were observed in the arrangement of atoms in quasicrystals. Another noteworthy contribution is his 1971 invention of spin networks, which later came to form the geometry of spacetime in loop quantum gravity. He was influential in popularising what are commonly known as Penrose diagrams (causal diagrams).

In 1983, Penrose was invited to teach at Rice University in Houston, by the then provost Bill Gordon. He worked there from 1983 to 1987.

In 2004, Penrose released "", a 1,099-page comprehensive guide to the Laws of Physics that includes an explanation of his own theory. The Penrose Interpretation predicts the relationship between quantum mechanics and general relativity, and proposes that a quantum state remains in superposition until the difference of space-time curvature attains a significant level.

Penrose is the Francis and Helen Pentz Distinguished Visiting Professor of Physics and Mathematics at Pennsylvania State University. He is also a member of the Editorial Board of "The Astronomical Review" and of the Advisory Board of "Universe".

In 2010, Penrose reported possible evidence, based on concentric circles found in WMAP data of the CMB sky, of an earlier universe existing before the Big Bang of our own present universe. He mentions this evidence in the epilogue of his 2010 book "Cycles of Time", a book in which he presents his reasons, to do with Einstein's field equations, the Weyl curvature C, and the Weyl curvature hypothesis (WCH), that the transition at the Big Bang could have been smooth enough for a previous universe to survive it. He made several conjectures about C and the WCH, some of which were subsequently proved by others, and he also popularized his conformal cyclic cosmology (CCC) theory.

In simple terms, he believes that the singularity in Einstein's field equation at the Big Bang is only an apparent singularity, similar to the well-known apparent singularity at the event horizon of a black hole. The latter singularity can be removed by a change of coordinate system, and Penrose proposes a different change of coordinate system that will remove the singularity at the big bang. One implication of this is that the major events at the Big Bang can be understood without unifying general relativity and quantum mechanics, and therefore we are not necessarily constrained by the WheelerâDeWitt equation, which disrupts time. Alternatively, one can use the EinsteinâMaxwellâDirac equations.

Penrose has written books on the connection between fundamental physics and human (or animal) consciousness. In "The Emperor's New Mind" (1989), he argues that known laws of physics are inadequate to explain the phenomenon of consciousness. Penrose proposes the characteristics this new physics may have and specifies the requirements for a bridge between classical and quantum mechanics (what he calls "correct quantum gravity"). Penrose uses a variant of Turing's halting theorem to demonstrate that a system can be deterministic without being algorithmic. (For example, imagine a system with only two states, ON and OFF. If the system's state is ON when a given Turing machine halts and OFF when the Turing machine does not halt, then the system's state is completely determined by the machine; nevertheless, there is no algorithmic way to determine whether the Turing machine stops.)

Penrose believes that such deterministic yet non-algorithmic processes may come into play in the quantum mechanical wave function reduction, and may be harnessed by the brain. He argues that computers today are unable to have intelligence because they are algorithmically deterministic systems. He argues against the viewpoint that the rational processes of the mind are completely algorithmic and can thus be duplicated by a sufficiently complex computer. This contrasts with supporters of strong artificial intelligence, who contend that thought can be simulated algorithmically. He bases this on claims that consciousness transcends formal logic because things such as the insolubility of the halting problem and GÃ¶del's incompleteness theorem prevent an algorithmically based system of logic from reproducing such traits of human intelligence as mathematical insight. These claims were originally espoused by the philosopher John Lucas of Merton College, Oxford.

The PenroseâLucas argument about the implications of GÃ¶del's incompleteness theorem for computational theories of human intelligence has been widely criticised by mathematicians, computer scientists and philosophers, and the consensus among experts in these fields seems to be that the argument fails, though different authors may choose different aspects of the argument to attack. Marvin Minsky, a leading proponent of artificial intelligence, was particularly critical, stating that Penrose "tries to show, in chapter after chapter, that human thought cannot be based on any known scientific principle." Minsky's position is exactly the opposite â he believed that humans are, in fact, machines, whose functioning, although complex, is fully explainable by current physics. Minsky maintained that "one can carry that quest [for scientific explanation] too far by only seeking new basic principles instead of attacking the real detail. This is what I see in Penrose's quest for a new basic principle of physics that will account for consciousness."

Penrose responded to criticism of "The Emperor's New Mind" with his follow up 1994 book "Shadows of the Mind", and in 1997 with "The Large, the Small and the Human Mind". In those works, he also combined his observations with that of anesthesiologist Stuart Hameroff.

Penrose and Hameroff have argued that consciousness is the result of quantum gravity effects in microtubules, which they dubbed Orch-OR (orchestrated objective reduction). Max Tegmark, in a paper in "Physical Review E", calculated that the time scale of neuron firing and excitations in microtubules is slower than the decoherence time by a factor of at least 10,000,000,000. The reception of the paper is summed up by this statement in Tegmark's support: "Physicists outside the fray, such as IBM's John A. Smolin, say the calculations confirm what they had suspected all along. 'We're not working with a brain that's near absolute zero. It's reasonably unlikely that the brain evolved quantum behavior'". Tegmark's paper has been widely cited by critics of the PenroseâHameroff position.

In their reply to Tegmark's paper, also published in "Physical Review E", the physicists Scott Hagan, Jack TuszyÅski and Hameroff claimed that Tegmark did not address the Orch-OR model, but instead a model of his own construction. This involved superpositions of quanta separated by 24Â nm rather than the much smaller separations stipulated for Orch-OR. As a result, Hameroff's group claimed a decoherence time seven orders of magnitude greater than Tegmark's, but still well short of the 25Â ms required if the quantum processing in the theory was to be linked to the 40Â Hz gamma synchrony, as Orch-OR suggested. To bridge this gap, the group made a series of proposals.

They supposed that the interiors of neurons could alternate between liquid and gel states. In the gel state, it was further hypothesized that the water electrical dipoles are oriented in the same direction, along the outer edge of the microtubule tubulin subunits. Hameroff et al. proposed that this ordered water could screen any quantum coherence within the tubulin of the microtubules from the environment of the rest of the brain. Each tubulin also has a tail extending out from the microtubules, which is negatively charged, and therefore attracts positively charged ions. It is suggested that this could provide further screening. Further to this, there was a suggestion that the microtubules could be pumped into a coherent state by biochemical energy. Finally, he suggested that the configuration of the microtubule lattice might be suitable for quantum error correction, a means of holding together quantum coherence in the face of environmental interaction.

Hameroff, in a lecture in part of a Google Tech talks series exploring quantum biology, gave an overview of current research in the area, and responded to subsequent criticisms of the Orch-OR model. In addition to this, a 2011 paper by Roger Penrose and Stuart Hameroff published in the fringe "Journal of Cosmology" gives an updated model of their Orch-OR theory, in light of criticisms, and discusses the place of consciousness within the universe.

Phillip Tetlow, although himself supportive of Penrose's views, acknowledges that Penrose's ideas about the human thought process are at present a minority view in scientific circles, citing Minsky's criticisms and quoting science journalist Charles Seife's description of Penrose as "one of a handful of scientists" who believe that the nature of consciousness suggests a quantum process.

In January 2014 Hameroff and Penrose claimed that a discovery of quantum vibrations in microtubules by Anirban Bandyopadhyay of the National Institute for Materials Science in Japan confirms the hypothesis of Orch-OR theory. A reviewed and updated version of the theory was published along with critical commentary and debate in the March 2014 issue of "Physics of Life Reviews".

Penrose is married to Vanessa Thomas, director of Academic Development at Cokethorpe School and former head of mathematics at Abingdon School, with whom he has one son. He has three sons from a previous marriage to American Joan Isabel Penrose (nÃ©e Wedge), whom he married in 1959.

During an interview with BBC Radio 4 on 25 September 2010, Penrose states, "I'm not a believer myself. I don't believe in established religions of any kind. I would say I'm an atheist", during a discussion on the Big Bang Theory.

In the film "A Brief History of Time", he said, "I think I would say that the universe has a purpose, it's not somehow just there by chance ... some people, I think, take the view that the universe is just there and it runs along â it's a bit like it just sort of computes, and we happen somehow by accident to find ourselves in this thing. But I don't think that's a very fruitful or helpful way of looking at the universe, I think that there is something much deeper about it." He went on to explain that he believed our universe would end in a Big Crunch, a scenario cosmology has since found to be unlikely.

Penrose is a patron of Humanists UK.

Penrose has been awarded many prizes for his contributions to science. He was elected a Fellow of the Royal Society (FRS) in 1972. In 1975, Stephen Hawking and Penrose were jointly awarded the Eddington Medal of the Royal Astronomical Society. In 1985, he was awarded the Royal Society Royal Medal. Along with Stephen Hawking, he was awarded the prestigious Wolf Foundation Prize for Physics in 1988. In 1989 he was awarded the Dirac Medal and Prize of the British Institute of Physics. In 1990 Penrose was awarded the Albert Einstein Medal for outstanding work related to the work of Albert Einstein by the Albert Einstein Society. In 1991, he was awarded the Naylor Prize of the London Mathematical Society. From 1992 to 1995 he served as President of the International Society on General Relativity and Gravitation.
In 1994, Penrose was knighted for services to science. In the same year he was also awarded an Honorary Degree (Doctor of Science) by the University of Bath. In 1998, he was elected Foreign Associate of the United States National Academy of Sciences. In 2000 he was appointed to the Order of Merit. In 2004 he was awarded the De Morgan Medal for his wide and original contributions to mathematical physics. To quote the citation from the London Mathematical Society:

In 2005 Penrose was awarded an honorary doctorate by Warsaw University and Katholieke Universiteit Leuven (Belgium), and in 2006 by the University of York. In 2008 Penrose was awarded the Copley Medal. He is also a Distinguished Supporter of Humanists UK and one of the patrons of the Oxford University Scientific Society. In 2011, Penrose was awarded the Fonseca Prize by the University of Santiago de Compostela.
In 2012, Penrose was awarded the Richard R. Ernst Medal by ETH ZÃ¼rich for his contributions to science and strengthening the connection between science and society. In 2015 Penrose was awarded an honorary doctorate by CINVESTAV-IPN (Mexico).










</doc>
<doc id="26194" url="https://en.wikipedia.org/wiki?curid=26194" title="Restriction enzyme">
Restriction enzyme

A restriction enzyme, restriction endonuclease, or " restrictase " is an enzyme that cleaves DNA into fragments at or near specific recognition sites within molecules known as restriction sites. Restriction enzymes are one class of the broader endonuclease group of enzymes. Restriction enzymes are commonly classified into five types, which differ in their structure and whether they cut their DNA substrate at their recognition site, or if the recognition and cleavage sites are separate from one another. To cut DNA, all restriction enzymes make two incisions, once through each sugar-phosphate backbone (i.e. each strand) of the DNA double helix.

These enzymes are found in bacteria and archaea and provide a defence mechanism against invading viruses. Inside a prokaryote, the restriction enzymes selectively cut up "foreign" DNA in a process called "restriction digestion"; meanwhile, host DNA is protected by a modification enzyme (a methyltransferase) that modifies the prokaryotic DNA and blocks cleavage. Together, these two processes form the restriction modification system.

Over 3,000 restriction enzymes have been studied in detail, and more than 600 of these are available commercially. These enzymes are routinely used for DNA modification in laboratories, and they are a vital tool in molecular cloning.

The term restriction enzyme originated from the studies of phage Î», a virus that infects bacteria, and the phenomenon of host-controlled restriction and modification of such bacterial phage or bacteriophage. The phenomenon was first identified in work done in the laboratories of Salvador Luria, Weigle and Giuseppe Bertani in the early 1950s. It was found that, for a bacteriophage Î» that can grow well in one strain of "Escherichia coli", for example "E. coli" C, when grown in another strain, for example "E. coli" K, its yields can drop significantly, by as much as 3-5 orders of magnitude. The host cell, in this example "E. coli" K, is known as the restricting host and appears to have the ability to reduce the biological activity of the phage Î». If a phage becomes established in one strain, the ability of that phage to grow also becomes restricted in other strains. In the 1960s, it was shown in work done in the laboratories of Werner Arber and Matthew Meselson that the restriction is caused by an enzymatic cleavage of the phage DNA, and the enzyme involved was therefore termed a restriction enzyme.

The restriction enzymes studied by Arber and Meselson were type I restriction enzymes, which cleave DNA randomly away from the recognition site. In 1970, Hamilton O. Smith, Thomas Kelly and Kent Wilcox isolated and characterized the first type II restriction enzyme, "Hin"dII, from the bacterium "Haemophilus influenzae". Restriction enzymes of this type are more useful for laboratory work as they cleave DNA at the site of their recognition sequence and are the most commonly used as a molecular biology tool. Later, Daniel Nathans and Kathleen Danna showed that cleavage of simian virus 40 (SV40) DNA by restriction enzymes yields specific fragments that can be separated using polyacrylamide gel electrophoresis, thus showing that restriction enzymes can also be used for mapping DNA. For their work in the discovery and characterization of restriction enzymes, the 1978 Nobel Prize for Physiology or Medicine was awarded to Werner Arber, Daniel Nathans, and Hamilton O. Smith. The discovery of restriction enzymes allows DNA to be manipulated, leading to the development of recombinant DNA technology that has many applications, for example, allowing the large scale production of proteins such as human insulin used by diabetics.

Restriction enzymes likely evolved from a common ancestor and became widespread via horizontal gene transfer. In addition, there is mounting evidence that restriction endonucleases evolved as a selfish genetic element.

Restriction enzymes recognize a specific sequence of nucleotides and produce a double-stranded cut in the DNA. The recognition sequences can also be classified by the number of bases in its recognition site, usually between 4 and 8 bases, and the number of bases in the sequence will determine how often the site will appear by chance in any given genome, e.g., a 4-base pair sequence would theoretically occur once every 4^4 or 256bp, 6 bases, 4^6 or 4,096bp, and 8 bases would be 4^8 or 65,536bp.<ref name="http://bioweb.uwlax.edu/genweb/molecular/seq_anal/restriction_map/restriction_map.htm">Restriction Map</ref> Many of them are palindromic, meaning the base sequence reads the same backwards and forwards. In theory, there are two types of palindromic sequences that can be possible in DNA. The "mirror-like" palindrome is similar to those found in ordinary text, in which a sequence reads the same forward and backward on a single strand of DNA, as in GTAATG. The "inverted repeat" palindrome is also a sequence that reads the same forward and backward, but the forward and backward sequences are found in complementary DNA strands (i.e., of double-stranded DNA), as in GTATAC (GTATAC being complementary to CATATG). Inverted repeat palindromes are more common and have greater biological importance than mirror-like palindromes.

EcoRI digestion produces "sticky" ends,

whereas SmaI restriction enzyme cleavage produces "blunt" ends:

Recognition sequences in DNA differ for each restriction enzyme, producing differences in the length, sequence and strand orientation (5' end or 3' end) of a sticky-end "overhang" of an enzyme restriction.

Different restriction enzymes that recognize the same sequence are known as neoschizomers. These often cleave in different locales of the sequence. Different enzymes that recognize and cleave in the same location are known as isoschizomers.

Naturally occurring restriction endonucleases are categorized into four groups (Types I, II III, and IV) based on their composition and enzyme cofactor requirements, the nature of their target sequence, and the position of their DNA cleavage site relative to the target sequence. DNA sequence analyses of restriction enzymes however show great variations, indicating that there are more than four types. All types of enzymes recognize specific short DNA sequences and carry out the endonucleolytic cleavage of DNA to give specific fragments with terminal 5'-phosphates. They differ in their recognition sequence, subunit composition, cleavage position, and cofactor requirements, as summarised below:


Type I restriction enzymes were the first to be identified and were first identified in two different strains (K-12 and B) of "E. coli". These enzymes cut at a site that differs, and is a random distance (at least 1000 bp) away, from their recognition site. Cleavage at these random sites follows a process of DNA translocation, which shows that these enzymes are also molecular motors. The recognition site is asymmetrical and is composed of two specific portionsâone containing 3â4 nucleotides, and another containing 4â5 nucleotidesâseparated by a non-specific spacer of about 6â8 nucleotides. These enzymes are multifunctional and are capable of both restriction digestion and modification activities, depending upon the methylation status of the target DNA. The cofactors S-Adenosyl methionine (AdoMet), hydrolyzed adenosine triphosphate (ATP), and magnesium (Mg) ions, are required for their full activity. Type I restriction enzymes possess three subunits called HsdR, HsdM, and HsdS; HsdR is required for restriction digestion; HsdM is necessary for adding methyl groups to host DNA (methyltransferase activity), and HsdS is important for specificity of the recognition (DNA-binding) site in addition to both restriction digestion (DNA cleavage) and modification (DNA methyltransferase) activity.

Typical type II restriction enzymes differ from type I restriction enzymes in several ways. They form homodimers, with recognition sites that are usually undivided and palindromic and 4â8 nucleotides in length. They recognize and cleave DNA at the same site, and they do not use ATP or AdoMet for their activityâthey usually require only Mg as a cofactor. These enzymes cleave the phosphodiester bond of double helix DNA. It can either cleave at the center of both strands to yield a blunt end, or at a staggered position leaving overhangs called sticky ends. These are the most commonly available and used restriction enzymes. In the 1990s and early 2000s, new enzymes from this family were discovered that did not follow all the classical criteria of this enzyme class, and new subfamily nomenclature was developed to divide this large family into subcategories based on deviations from typical characteristics of type II enzymes. These subgroups are defined using a letter suffix.

Type IIB restriction enzymes (e.g., BcgI and BplI) are multimers, containing more than one subunit. They cleave DNA on both sides of their recognition to cut out the recognition site. They require both AdoMet and Mg cofactors. Type IIE restriction endonucleases (e.g., NaeI) cleave DNA following interaction with two copies of their recognition sequence. One recognition site acts as the target for cleavage, while the other acts as an allosteric effector that speeds up or improves the efficiency of enzyme cleavage. Similar to type IIE enzymes, type IIF restriction endonucleases (e.g. NgoMIV) interact with two copies of their recognition sequence but cleave both sequences at the same time. Type IIG restriction endonucleases (e.g., Eco57I) do have a single subunit, like classical Type II restriction enzymes, but require the cofactor AdoMet to be active. Type IIM restriction endonucleases, such as DpnI, are able to recognize and cut methylated DNA. Type IIS restriction endonucleases (e.g., "Fok"I) cleave DNA at a defined distance from their non-palindromic asymmetric recognition sites; this characteristic is widely used to perform in-vitro cloning techniques such as Golden Gate cloning. These enzymes may function as dimers. Similarly, Type IIT restriction enzymes (e.g., Bpu10I and BslI) are composed of two different subunits. Some recognize palindromic sequences while others have asymmetric recognition sites.

Type III restriction enzymes (e.g., EcoP15) recognize two separate non-palindromic sequences that are inversely oriented. They cut DNA about 20â30 base pairs after the recognition site. These enzymes contain more than one subunit and require AdoMet and ATP cofactors for their roles in DNA methylation and restriction digestion , respectively. They are components of prokaryotic DNA restriction-modification mechanisms that protect the organism against invading foreign DNA. Type III enzymes are hetero-oligomeric, multifunctional proteins composed of two subunits, Res () and Mod (). The Mod subunit recognises the DNA sequence specific for the system and is a modification methyltransferase; as such, it is functionally equivalent to the M and S subunits of type I restriction endonuclease. Res is required for restriction digestion, although it has no enzymatic activity on its own. Type III enzymes recognise short 5â6 bp-long asymmetric DNA sequences and cleave 25â27 bp downstream to leave short, single-stranded 5' protrusions. They require the presence of two inversely oriented unmethylated recognition sites for restriction digestion to occur. These enzymes methylate only one strand of the DNA, at the N-6 position of adenosyl residues, so newly replicated DNA will have only one strand methylated, which is sufficient to protect against restriction digestion. Type III enzymes belong to the beta-subfamily of N6 adenine methyltransferases, containing the nine motifs that characterise this family, including motif I, the AdoMet binding pocket (FXGXG), and motif IV, the catalytic region (S/D/N (PP) Y/F).

Type IV enzymes recognize modified, typically methylated DNA and are exemplified by theÂ McrBCÂ and Mrr systems ofÂ "E. coli".

Type V restriction enzymes (e.g., the cas9-gRNA complex from CRISPRs) utilize guide RNAs to target specific non-palindromic sequences found on invading organisms. They can cut DNA of variable length, provided that a suitable guide RNA is provided. The flexibility and ease of use of these enzymes make them promising for future genetic engineering applications.

Artificial restriction enzymes can be generated by fusing a natural or engineered DNA binding domain to a nuclease domain (often the cleavage domain of the type IIS restriction enzyme "Fok"I). Such artificial restriction enzymes can target large DNA sites (up to 36 bp) and can be engineered to bind to desired DNA sequences. Zinc finger nucleases are the most commonly used artificial restriction enzymes and are generally used in genetic engineering applications, but can also be used for more standard gene cloning applications. Other artificial restriction enzymes are based on the DNA binding domain of TAL effectors.

In 2013, a new technology CRISPR-Cas9, based on a prokaryotic viral defense system, was engineered for editing the genome, and it was quickly adopted in laboratories. For more detail, read CRISPR (Clustered regularly interspaced short palindromic repeats).

In 2017 a group in Illinois announced using an Argonaute protein taken from Pyrococcus furiosus (PfAgo) along with guide DNA to edit DNA as artificial restriction enzymes. The authors, however, retracted their study later that year.

Artificial ribonucleases that act as restriction enzymes for RNA are also being developed. A PNA-based system, called PNAzymes, has a Cu(II)-2,9-dimethylphenanthroline group that mimics ribonucleases for specific RNA sequence and cleaves at a non-base-paired region (RNA bulge) of the targeted RNA formed when the enzyme binds the RNA. This enzyme shows selectivity by cleaving only at one site that either does not have a mismatch or is kinetically preferred out of two possible cleavage sites.

Since their discovery in the 1970s, many restriction enzymes have been identified; for example, more than 3500 different Type II restriction enzymes have been characterized. Each enzyme is named after the bacterium from which it was isolated, using a naming system based on bacterial genus, species and strain. For example, the name of the EcoRI restriction enzyme was derived as shown in the box.

Isolated restriction enzymes are used to manipulate DNA for different scientific applications.

They are used to assist insertion of genes into plasmid vectors during gene cloning and protein production experiments. For optimal use, plasmids that are commonly used for gene cloning are modified to include a short "polylinker" sequence (called the multiple cloning site, or MCS) rich in restriction enzyme recognition sequences. This allows flexibility when inserting gene fragments into the plasmid vector; restriction sites contained naturally within genes influence the choice of endonuclease for digesting the DNA, since it is necessary to avoid restriction of wanted DNA while intentionally cutting the ends of the DNA. To clone a gene fragment into a vector, both plasmid DNA and gene insert are typically cut with the same restriction enzymes, and then glued together with the assistance of an enzyme known as a DNA ligase.

Restriction enzymes can also be used to distinguish gene alleles by specifically recognizing single base changes in DNA known as single nucleotide polymorphisms (SNPs). This is however only possible if a SNP alters the restriction site present in the allele. In this method, the restriction enzyme can be used to genotype a DNA sample without the need for expensive gene sequencing. The sample is first digested with the restriction enzyme to generate DNA fragments, and then the different sized fragments separated by gel electrophoresis. In general, alleles with correct restriction sites will generate two visible bands of DNA on the gel, and those with altered restriction sites will not be cut and will generate only a single band. A DNA map by restriction digest can also be generated that can give the relative positions of the genes. The different lengths of DNA generated by restriction digest also produce a specific pattern of bands after gel electrophoresis, and can be used for DNA fingerprinting.

In a similar manner, restriction enzymes are used to digest genomic DNA for gene analysis by Southern blot. This technique allows researchers to identify how many copies (or paralogues) of a gene are present in the genome of one individual, or how many gene mutations (polymorphisms) have occurred within a population. The latter example is called restriction fragment length polymorphism (RFLP).

Artificial restriction enzymes created by linking the "Fok"I DNA cleavage domain with an array of DNA binding proteins or zinc finger arrays, denoted zinc finger nucleases (ZFN), are a powerful tool for host genome editing due to their enhanced sequence specificity. ZFN work in pairs, their dimerization being mediated in-situ through the "Fok"I domain. Each zinc finger array (ZFA) is capable of recognizing 9â12 base pairs, making for 18â24 for the pair. A 5â7 bp spacer between the cleavage sites further enhances the specificity of ZFN, making them a safe and more precise tool that can be applied in humans. A recent Phase I clinical trial of ZFN for the targeted abolition of the CCR5 co-receptor for HIV-1 has been undertaken.

Others have proposed using the bacteria R-M system as a model for devising human anti-viral gene or genomic vaccines and therapies since the RM system serves an innate defense-role in bacteria by restricting tropism by bacteriophages. There is research on REases and ZFN that can cleave the DNA of various human viruses, including HSV-2, high-risk HPVs and HIV-1, with the ultimate goal of inducing target mutagenesis and aberrations of human-infecting viruses. The human genome already contains remnants of retroviral genomes that have been inactivated and harnessed for self-gain. Indeed, the mechanisms for silencing active L1 genomic retroelements by the three prime repair exonuclease 1 (TREX1) and excision repair cross complementing 1(ERCC) appear to mimic the action of RM-systems in bacteria, and the non-homologous end-joining (NHEJ) that follows the use of ZFN without a repair template.

Examples of restriction enzymes include:
Key:
<nowiki>*</nowiki> = blunt ends
N = C or G or T or A
W = A or T


"General Information:"
"Databases:"
"Software:"


</doc>
<doc id="26195" url="https://en.wikipedia.org/wiki?curid=26195" title="RNA virus">
RNA virus

An RNA virus is a virus that has RNA (ribonucleic acid) as its genetic material. This nucleic acid is usually single-stranded RNA (ssRNA) but may be double-stranded RNA (dsRNA). Notable human diseases caused by RNA viruses include Ebola virus disease, SARS, rabies, common cold, influenza, hepatitis C, hepatitis E, West Nile fever, polio, measles, and Coronavirus.

The International Committee on Taxonomy of Viruses (ICTV) classifies RNA viruses as those that belong to "Group III", "Group IV" or "Group V" of the Baltimore classification system of classifying viruses and does not consider viruses with DNA intermediates in their life cycle as RNA viruses. Viruses with RNA as their genetic material which also include DNA intermediates in their replication cycle are called retroviruses, and comprise "Group VI" of the Baltimore classification. Notable human retroviruses include HIV-1 and HIV-2, the cause of the disease AIDS.

Another term for RNA viruses that explicitly excludes retroviruses is ribovirus.

RNA viruses can be further classified according to the sense or polarity of their RNA into negative-sense and positive-sense, or ambisense RNA viruses. Positive-sense viral RNA is similar to mRNA and thus can be immediately translated by the host cell. Negative-sense viral RNA is complementary to mRNA and thus must be converted to positive-sense RNA by an RNA-dependent RNA polymerase before translation. As such, purified RNA of a positive-sense virus can directly cause infection though it may be less infectious than the whole virus particle. Purified RNA of a negative-sense virus is not infectious by itself as it needs to be transcribed into positive-sense RNA; each virion can be transcribed to several positive-sense RNAs. Ambisense RNA viruses resemble negative-sense RNA viruses, except they also translate genes from the negative strand.

The double-stranded (ds)RNA viruses represent a diverse group of viruses that vary widely in host range (humans, animals, plants, fungi, and bacteria), genome segment number (one to twelve), and virion organization (Triangulation number, capsid layers, spikes, turrets, etc.). Members of this group include the rotaviruses, renowned globally as the most common cause of gastroenteritis in young children, and picobirnaviruses, renowned worldwide as the most commonly occurring virus in fecal samples of both humans and animals with or without signs of diarrhea. Bluetongue virus is an economically important pathogen of cattle and sheep. In recent years, remarkable progress has been made in determining, at atomic and subnanometeric levels, the structures of a number of key viral proteins and of the virion capsids of several dsRNA viruses, highlighting the significant parallels in the structure and replicative processes of many of these viruses.

RNA viruses generally have very high mutation rates compared to DNA viruses, because viral RNA polymerases lack the proofreading ability of DNA polymerases. This is one reason why it is difficult to make effective vaccines to prevent diseases caused by RNA viruses.
Retroviruses also have a high mutation rate even though their DNA intermediate integrates into the host genome (and is thus subject to host DNA proofreading once integrated), because errors during reverse transcription are embedded into both strands of DNA before integration.
Some genes of RNA virus are important to the viral replication cycles and mutations are not tolerated. For example, the region of the hepatitis C virus genome that encodes the core protein is highly conserved, because it contains an RNA structure involved in an internal ribosome entry site.

Animal RNA viruses are classified by the ICTV. There are three distinct groups of RNA viruses depending on their genome and mode of replication:

Retroviruses (Group VI) have a single-stranded RNA genome but, in general, are not considered RNA viruses because they use DNA intermediates to replicate. Reverse transcriptase, a viral enzyme that comes from the virus itself after it is uncoated, converts the viral RNA into a complementary strand of DNA, which is copied to produce a double-stranded molecule of viral DNA. After this DNA is integrated into the host genome using the viral enzyme integrase, expression of the encoded genes may lead to the formation of new virions.

Classification of the RNA viruses has proven to be a difficult problem. This is in part due to the high mutation rates these genomes undergo. Classification is based principally on the type of genome (double-stranded, negative- or positive-single-strand) and gene number and organisation. Currently there are 5 orders and 47 families of RNA viruses recognised. There are also many unassigned species and genera.

Related to but distinct from the RNA viruses are the viroids and the RNA satellite viruses. These are not currently classified as RNA viruses and are described on their own pages.

A study of several thousand RNA viruses has shown the presence of at least five main taxa: a levivirus and relatives group; a picornavirus supergroup; an alphavirus supergroup plus a flavivirus supergroup; the dsRNA viruses; and the -ve strand viruses. The lentivirus group appears to be basal to all the remaining RNA viruses. The next major division lies between the picornasupragroup and the remaining viruses. The dsRNA viruses appear to have evolved from a +ve RNA ancestor and the -ve RNA viruses from within the dsRNA viruses. The closest relation to the -ve stranded RNA viruses are the Reoviridae.

This is the single largest group of RNA viruses with 30 families. Attempts have been made to group these families in higher orders. These proposals were based on an analysis of the RNA polymerases and are still under consideration. To date, the suggestions proposed have not been broadly accepted because of doubts over the suitability of a single gene to determine the taxonomy of the clade.

The proposed classification of positive-strand RNA viruses is based on the RNA-dependent RNA polymerase. Three groups have been recognised:


A division of the alpha-like (Sindbis-like) supergroup on the basis of a novel domain located near the N termini of the proteins involved in viral replication has been proposed. The two groups proposed are: the 'altovirus' group (alphaviruses, furoviruses, hepatitis E virus, hordeiviruses, tobamoviruses, tobraviruses, tricornaviruses and probably rubiviruses); and the 'typovirus' group (apple chlorotic leaf spot virus, carlaviruses, potexviruses and tymoviruses).

The alpha like supergroup can be further divided into three clades: the rubi-like, tobamo-like, and tymo-like viruses.

Additional work has identified five groups of positive-stranded RNA viruses containing four, three, three, three, and one order(s), respectively. These fourteen orders contain 31 virus families (including 17 families of plant viruses) and 48 genera (including 30 genera of plant viruses). This analysis suggests that alphaviruses and flaviviruses can be separated into two familiesâthe Togaviridae and Flaviridae, respectivelyâbut suggests that other taxonomic assignments, such as the pestiviruses, hepatitis C virus, rubiviruses, hepatitis E virus, and arteriviruses, may be incorrect. The coronaviruses and toroviruses appear to be distinct families in distinct orders and not distinct genera of the same family as currently classified. The luteoviruses appear to be two families rather than one, and apple chlorotic leaf spot virus appears not to be a closterovirus but a new genus of the Potexviridae.


The evolution of the picornaviruses based on an analysis of their RNA polymerases and helicases appears to date to the divergence of the eukaryotes. Their putative ancestors include the bacterial group II retroelements, the family of HtrA proteases and DNA bacteriophages.

Partitiviruses are related to and may have evolved from a totivirus ancestor.

Hypoviruses and barnaviruses appear to share an ancestry with the potyvirus and sobemovirus lineages respectively.

This analysis also suggests that the dsRNA viruses are not closely related to each other but instead belong to four additional classesâBirnaviridae, Cystoviridae, Partitiviridae, and Reoviridaeâand one additional order (Totiviridae) of one of the classes of positive ssRNA viruses in the same subphylum as the positive-strand RNA viruses.

One study has suggested that there are two large clades: One includes the Caliciviridae, Flaviviridae, and Picornaviridae families and a second that includes the Alphatetraviridae, Birnaviridae and Cystoviridae, Nodaviridae, and Permutotretraviridae families.

These viruses have multiple types of genome ranging from a single RNA molecule up to eight segments. Despite their diversity it appears that they may have originated in arthropods and to have diversified from there.

A number of satellite virusesâviruses that require the assistance of another virus to complete their life cycleâare also known. Their taxonomy has yet to be settled. The following four genera have been proposed for positive sense single stranded RNA satellite viruses that infect plantsâAlbetovirus, Aumaivirus, Papanivirus and Virtovirus. A familyâSarthroviridae which includes the genus Macronovirusâhas been proposed for the positive sense single stranded RNA satellite viruses that infect arthropods.

There are twelve families and a number of unassigned genera and species recognised in this group.

There are three orders and 34 families recognised in this group. In addition, there are a number of unclassified species and genera.

Satellite viruses

An unclassified astrovirus/hepevirus-like virus has also been described.

With the exception of the Hepatitis D virus, this group of viruses have been placed into a single phylumâNegarnaviricota. This phylum has been divided into two subphylaâHaploviricotina and Polyploviricotina. Within the subphylum Haploviricotina four classes are currently recognised: Chunqiuviricetes, Milneviricetes, Monjiviricetes and Yunchangviricetes. In the subphylum Polyploviricotina two classes are recognised: Ellioviricetes and Insthoviricetes.

Six classes, seven orders and twenty four families are currently recognised in this group. A number of unassigned species and genera are yet to be classified.

The majority of fungal viruses are double-stranded RNA viruses. A small number of positive-strand RNA viruses have been described. One report has suggested the possibility of a negative stranded virus.




</doc>
<doc id="26197" url="https://en.wikipedia.org/wiki?curid=26197" title="Radiocarbon dating">
Radiocarbon dating

Radiocarbon dating (also referred to as carbon dating or carbon-14 dating) is a method for determining the age of an object containing organic material by using the properties of radiocarbon, a radioactive isotope of carbon.

The method was developed in the late 1940s at the University of Chicago by Willard Libby, who received the Nobel Prize in Chemistry for his work in 1960. It is based on the fact that radiocarbon () is constantly being created in the atmosphere by the interaction of cosmic rays with atmospheric nitrogen. The resulting combines with atmospheric oxygen to form radioactive carbon dioxide, which is incorporated into plants by photosynthesis; animals then acquire by eating the plants. When the animal or plant dies, it stops exchanging carbon with its environment, and from that point onwards the amount of it contains begins to decrease as the undergoes radioactive decay. Measuring the amount of in a sample from a dead plant or animal such as a piece of wood or a fragment of bone provides information that can be used to calculate when the animal or plant died. The older a sample is, the less there is to be detected, and because the half-life of (the period of time after which half of a given sample will have decayed) is about 5,730 years, the oldest dates that can be reliably measured by this process date to around 50,000 years ago, although special preparation methods occasionally permit accurate analysis of older samples.

Research has been ongoing since the 1960s to determine what the proportion of in the atmosphere has been over the past fifty thousand years. The resulting data, in the form of a calibration curve, is now used to convert a given measurement of radiocarbon in a sample into an estimate of the sample's calendar age. Other corrections must be made to account for the proportion of in different types of organisms (fractionation), and the varying levels of throughout the biosphere (reservoir effects). Additional complications come from the burning of fossil fuels such as coal and oil, and from the above-ground nuclear tests done in the 1950s and 1960s. Because the time it takes to convert biological materials to fossil fuels is substantially longer than the time it takes for its to decay below detectable levels, fossil fuels contain almost no , and as a result there was a noticeable drop in the proportion of in the atmosphere beginning in the late 19th century. Conversely, nuclear testing increased the amount of in the atmosphere, which attained a maximum in about 1965 of almost twice what it had been before the testing began.

Measurement of radiocarbon was originally done by beta-counting devices, which counted the amount of beta radiation emitted by decaying atoms in a sample. More recently, accelerator mass spectrometry has become the method of choice; it counts all the atoms in the sample and not just the few that happen to decay during the measurements; it can therefore be used with much smaller samples (as small as individual plant seeds), and gives results much more quickly. The development of radiocarbon dating has had a profound impact on archaeology. In addition to permitting more accurate dating within archaeological sites than previous methods, it allows comparison of dates of events across great distances. Histories of archaeology often refer to its impact as the "radiocarbon revolution". Radiocarbon dating has allowed key transitions in prehistory to be dated, such as the end of the last ice age, and the beginning of the Neolithic and Bronze Age in different regions.

In 1939, Martin Kamen and Samuel Ruben of the Radiation Laboratory at Berkeley began experiments to determine if any of the elements common in organic matter had isotopes with half-lives long enough to be of value in biomedical research. They synthesized using the laboratory's cyclotron accelerator and soon discovered that the atom's half-life was far longer than had been previously thought. This was followed by a prediction by Serge A. Korff, then employed at the Franklin Institute in Philadelphia, that the interaction of thermal neutrons with in the upper atmosphere would create . It had previously been thought that would be more likely to be created by deuterons interacting with . At some time during World War II, Willard Libby, who was then at Berkeley, learned of Korff's research and conceived the idea that it might be possible to use radiocarbon for dating.

In 1945, Libby moved to the University of Chicago where he began his work on radiocarbon dating. He published a paper in 1946 in which he proposed that the carbon in living matter might include as well as non-radioactive carbon. Libby and several collaborators proceeded to experiment with methane collected from sewage works in Baltimore, and after isotopically enriching their samples they were able to demonstrate that they contained . By contrast, methane created from petroleum showed no radiocarbon activity because of its age. The results were summarized in a paper in "Science" in 1947, in which the authors commented that their results implied it would be possible to date materials containing carbon of organic origin.

Libby and James Arnold proceeded to test the radiocarbon dating theory by analyzing samples with known ages. For example, two samples taken from the tombs of two Egyptian kings, Zoser and Sneferu, independently dated to 2625 BC plus or minus 75 years, were dated by radiocarbon measurement to an average of 2800 BC plus or minus 250 years. These results were published in "Science" in 1949. Within 11 years of their announcement, more than 20 radiocarbon dating laboratories had been set up worldwide. In 1960, Libby was awarded the Nobel Prize in Chemistry for this work.

In nature, carbon exists as two stable, nonradioactive isotopes: carbon-12 (), and carbon-13 (), and a radioactive isotope, carbon-14 (), also known as "radiocarbon". The half-life of (the time it takes for half of a given amount of to decay) is about 5,730 years, so its concentration in the atmosphere might be expected to reduce over thousands of years, but is constantly being produced in the lower stratosphere and upper troposphere, primarily by galactic cosmic rays, and to a lesser degree by solar cosmic rays. These generate neutrons that in turn create when they strike nitrogen-14 () atoms. The following nuclear reaction is the main pathway by which is created:
where n represents a neutron and p represents a proton.

Once produced, the quickly combines with the oxygen in the atmosphere to form first carbon monoxide (), and ultimately carbon dioxide ().

Carbon dioxide produced in this way diffuses in the atmosphere, is dissolved in the ocean, and is taken up by plants via photosynthesis. Animals eat the plants, and ultimately the radiocarbon is distributed throughout the biosphere. The ratio of to is approximately 1.25 parts of to 10 parts of . In addition, about 1% of the carbon atoms are of the stable isotope .

The equation for the radioactive decay of is:
By emitting a beta particle (an electron, e) and an electron antineutrino (), one of the neutrons in the nucleus changes to a proton and the nucleus reverts to the stable (non-radioactive) isotope .

During its life, a plant or animal is in equilibrium with its surroundings by exchanging carbon either with the atmosphere, or through its diet. It will therefore have the same proportion of as the atmosphere, or in the case of marine animals or plants, with the ocean. Once it dies, it ceases to acquire , but the within its biological material at that time will continue to decay, and so the ratio of to in its remains will gradually decrease. Because decays at a known rate, the proportion of radiocarbon can be used to determine how long it has been since a given sample stopped exchanging carbonÂ â the older the sample, the less will be left.

The equation governing the decay of a radioactive isotope is:
where "N" is the number of atoms of the isotope in the original sample (at time "t" = 0, when the organism from which the sample was taken died), and "N" is the number of atoms left after time "t". "Î»" is a constant that depends on the particular isotope; for a given isotope it is equal to the reciprocal of the mean-lifeÂ â i.e. the average or expected time a given atom will survive before undergoing radioactive decay. The mean-life, denoted by "Ï", of is 8,267 years, so the equation above can be rewritten as:
The sample is assumed to have originally had the same / ratio as the ratio in the atmosphere, and since the size of the sample is known, the total number of atoms in the sample can be calculated, yielding "N", the number of atoms in the original sample. Measurement of "N", the number of atoms currently in the sample, allows the calculation of "t", the age of the sample, using the equation above.

The half-life of a radioactive isotope (usually denoted by t) is a more familiar concept than the mean-life, so although the equations above are expressed in terms of the mean-life, it is more usual to quote the value of 's half-life than its mean-life. The currently accepted value for the half-life of is 5,730 Â± 40 years. This means that after 5,730 years, only half of the initial will remain; a quarter will remain after 11,460 years; an eighth after 17,190 years; and so on.

The above calculations make several assumptions, such as that the level of in the atmosphere has remained constant over time. In fact, the level of in the atmosphere has varied significantly and as a result the values provided by the equation above have to be corrected by using data from other sources. This is done by calibration curves (discussed below), which convert a measurement of in a sample into an estimated calendar age. The calculations involve several steps and include an intermediate value called the "radiocarbon age", which is the age in "radiocarbon years" of the sample: an age quoted in radiocarbon years means that no calibration curve has been used â the calculations for radiocarbon years assume that the atmospheric / ratio has not changed over time.

Calculating radiocarbon ages also requires the value of the half-life for . In Libby's 1949 paper he used a value of 5720 Â± 47 years, based on research by Engelkemeir et al. This was remarkably close to the modern value, but shortly afterwards the accepted value was revised to 5568 Â± 30 years, and this value was in use for more than a decade. It was revised again in the early 1960s to 5,730 Â± 40 years, which meant that many calculated dates in papers published prior to this were incorrect (the error in the half-life is about 3%). For consistency with these early papers, it was agreed at the 1962 Radiocarbon Conference in Cambridge (UK) to use the âLibby half-lifeâ of 5568 years. Radiocarbon ages are still calculated using this half-life, and are known as "Conventional Radiocarbon Age". Since the calibration curve (IntCal) also reports past atmospheric concentration using this conventional age, any conventional ages calibrated against the IntCal curve will produce a correct calibrated age. When a date is quoted, the reader should be aware that if it is an uncalibrated date (a term used for dates given in radiocarbon years) it may differ substantially from the best estimate of the actual calendar date, both because it uses the wrong value for the half-life of , and because no correction (calibration) has been applied for the historical variation of in the atmosphere over time.

Carbon is distributed throughout the atmosphere, the biosphere, and the oceans; these are referred to collectively as the carbon exchange reservoir, and each component is also referred to individually as a carbon exchange reservoir. The different elements of the carbon exchange reservoir vary in how much carbon they store, and in how long it takes for the generated by cosmic rays to fully mix with them. This affects the ratio of to in the different reservoirs, and hence the radiocarbon ages of samples that originated in each reservoir. The atmosphere, which is where is generated, contains about 1.9% of the total carbon in the reservoirs, and the it contains mixes in less than seven years. The ratio of to in the atmosphere is taken as the baseline for the other reservoirs: if another reservoir has a lower ratio of to , it indicates that the carbon is older and hence that either some of the has decayed, or the reservoir is receiving carbon that is not at the atmospheric baseline. The ocean surface is an example: it contains 2.4% of the carbon in the exchange reservoir, but there is only about 95% as much as would be expected if the ratio were the same as in the atmosphere. The time it takes for carbon from the atmosphere to mix with the surface ocean is only a few years, but the surface waters also receive water from the deep ocean, which has more than 90% of the carbon in the reservoir. Water in the deep ocean takes about 1,000 years to circulate back through surface waters, and so the surface waters contain a combination of older water, with depleted , and water recently at the surface, with in equilibrium with the atmosphere.

Creatures living at the ocean surface have the same ratios as the water they live in, and as a result of the reduced / ratio, the radiocarbon age of marine life is typically about 400 years. Organisms on land are in closer equilibrium with the atmosphere and have the same / ratio as the atmosphere. These organisms contain about 1.3% of the carbon in the reservoir; sea organisms have a mass of less than 1% of those on land and are not shown on the diagram. Accumulated dead organic matter, of both plants and animals, exceeds the mass of the biosphere by a factor of nearly 3, and since this matter is no longer exchanging carbon with its environment, it has a / ratio lower than that of the biosphere.

The variation in the / ratio in different parts of the carbon exchange reservoir means that a straightforward calculation of the age of a sample based on the amount of it contains will often give an incorrect result. There are several other possible sources of error that need to be considered. The errors are of four general types:

In the early years of using the technique, it was understood that it depended on the atmospheric / ratio having remained the same over the preceding few thousand years. To verify the accuracy of the method, several artefacts that were datable by other techniques were tested; the results of the testing were in reasonable agreement with the true ages of the objects. Over time, however, discrepancies began to appear between the known chronology for the oldest Egyptian dynasties and the radiocarbon dates of Egyptian artefacts. Neither the pre-existing Egyptian chronology nor the new radiocarbon dating method could be assumed to be accurate, but a third possibility was that the / ratio had changed over time. The question was resolved by the study of tree rings: comparison of overlapping series of tree rings allowed the construction of a continuous sequence of tree-ring data that spanned 8,000 years. (Since that time the tree-ring data series has been extended to 13,900 years.) In the 1960s, Hans Suess was able to use the tree-ring sequence to show that the dates derived from radiocarbon were consistent with the dates assigned by Egyptologists. This was possible because although annual plants, such as corn, have a / ratio that reflects the atmospheric ratio at the time they were growing, trees only add material to their outermost tree ring in any given year, while the inner tree rings don't get their replenished and instead start losing through decay. Hence each ring preserves a record of the atmospheric / ratio of the year it grew in. Carbon-dating the wood from the tree rings themselves provides the check needed on the atmospheric / ratio: with a sample of known date, and a measurement of the value of "N" (the number of atoms of remaining in the sample), the carbon-dating equation allows the calculation of "N" â the number of atoms of in the sample at the time the tree ring was formed â and hence the / ratio in the atmosphere at that time. Equipped with the results of carbon-dating the tree rings, it became possible to construct calibration curves designed to correct the errors caused by the variation over time in the / ratio. These curves are described in more detail below.

Coal and oil began to be burned in large quantities during the 19th century. Both are sufficiently old that they contain little or no detectable and, as a result, the released substantially diluted the atmospheric / ratio. Dating an object from the early 20th century hence gives an apparent date older than the true date. For the same reason, concentrations in the neighbourhood of large cities are lower than the atmospheric average. This fossil fuel effect (also known as the Suess effect, after Hans Suess, who first reported it in 1955) would only amount to a reduction of 0.2% in activity if the additional carbon from fossil fuels were distributed throughout the carbon exchange reservoir, but because of the long delay in mixing with the deep ocean, the actual effect is a 3% reduction.

A much larger effect comes from above-ground nuclear testing, which released large numbers of neutrons and created . From about 1950 until 1963, when atmospheric nuclear testing was banned, it is estimated that several tonnes of were created. If all this extra had immediately been spread across the entire carbon exchange reservoir, it would have led to an increase in the / ratio of only a few per cent, but the immediate effect was to almost double the amount of in the atmosphere, with the peak level occurring in 1964 for the northern hemisphere, and in 1966 for the southern hemisphere. The level has since dropped, as this bomb pulse or "bomb carbon" (as it is sometimes called) percolates into the rest of the reservoir.

Photosynthesis is the primary process by which carbon moves from the atmosphere into living things. In photosynthetic pathways is absorbed slightly more easily than , which in turn is more easily absorbed than . The differential uptake of the three carbon isotopes leads to / and / ratios in plants that differ from the ratios in the atmosphere. This effect is known as isotopic fractionation.

To determine the degree of fractionation that takes place in a given plant, the amounts of both and isotopes are measured, and the resulting / ratio is then compared to a standard ratio known as PDB. The / ratio is used instead of / because the former is much easier to measure, and the latter can be easily derived: the depletion of relative to is proportional to the difference in the atomic masses of the two isotopes, so the depletion for is twice the depletion of . The fractionation of , known as , is calculated as follows:

where the â° sign indicates parts per thousand. Because the PDB standard contains an unusually high proportion of , most measured values are negative.

For marine organisms, the details of the photosynthesis reactions are less well understood, and the values for marine photosynthetic organisms are dependent on temperature. At higher temperatures, has poor solubility in water, which means there is less available for the photosynthetic reactions. Under these conditions, fractionation is reduced, and at temperatures above 14Â Â°C the values are correspondingly higher, while at lower temperatures, becomes more soluble and hence more available to marine organisms. The value for animals depends on their diet. An animal that eats food with high values will have a higher than one that eats food with lower values. The animal's own biochemical processes can also impact the results: for example, both bone minerals and bone collagen typically have a higher concentration of than is found in the animal's diet, though for different biochemical reasons. The enrichment of bone also implies that excreted material is depleted in relative to the diet.

Since makes up about 1% of the carbon in a sample, the / ratio can be accurately measured by mass spectrometry. Typical values of have been found by experiment for many plants, as well as for different parts of animals such as bone collagen, but when dating a given sample it is better to determine the value for that sample directly than to rely on the published values.

The carbon exchange between atmospheric and carbonate at the ocean surface is also subject to fractionation, with in the atmosphere more likely than to dissolve in the ocean. The result is an overall increase in the / ratio in the ocean of 1.5%, relative to the / ratio in the atmosphere. This increase in concentration almost exactly cancels out the decrease caused by the upwelling of water (containing old, and hence depleted, carbon) from the deep ocean, so that direct measurements of radiation are similar to measurements for the rest of the biosphere. Correcting for isotopic fractionation, as is done for all radiocarbon dates to allow comparison between results from different parts of the biosphere, gives an apparent age of about 400 years for ocean surface water.

Libby's original exchange reservoir hypothesis assumed that the / ratio in the exchange reservoir is constant all over the world, but it has since been discovered that there are several causes of variation in the ratio across the reservoir.

Marine effect

The in the atmosphere transfers to the ocean by dissolving in the surface water as carbonate and bicarbonate ions; at the same time the carbonate ions in the water are returning to the air as . This exchange process brings from the atmosphere into the surface waters of the ocean, but the thus introduced takes a long time to percolate through the entire volume of the ocean. The deepest parts of the ocean mix very slowly with the surface waters, and the mixing is uneven. The main mechanism that brings deep water to the surface is upwelling, which is more common in regions closer to the equator. Upwelling is also influenced by factors such as the topography of the local ocean bottom and coastlines, the climate, and wind patterns. Overall, the mixing of deep and surface waters takes far longer than the mixing of atmospheric with the surface waters, and as a result water from some deep ocean areas has an apparent radiocarbon age of several thousand years. Upwelling mixes this "old" water with the surface water, giving the surface water an apparent age of about several hundred years (after correcting for fractionation). This effect is not uniformÂ â the average effect is about 400 years, but there are local deviations of several hundred years for areas that are geographically close to each other. These deviations can be accounted for in calibration, and users of software such as CALIB can provide as an input the appropriate correction for the location of their samples. The effect also applies to marine organisms such as shells, and marine mammals such as whales and seals, which have radiocarbon ages that appear to be hundreds of years old.

Hemisphere effect

The northern and southern hemispheres have atmospheric circulation systems that are sufficiently independent of each other that there is a noticeable time lag in mixing between the two. The atmospheric / ratio is lower in the southern hemisphere, with an apparent additional age of about 40 years for radiocarbon results from the south as compared to the north. This is because the greater surface area of ocean in the southern hemisphere means that there is more carbon exchanged between the ocean and the atmosphere than in the north. Since the surface ocean is depleted in because of the marine effect, is removed from the southern atmosphere more quickly than in the north. The effect is strengthened by strong upwelling around Antarctica.

Other effects

If the carbon in freshwater is partly acquired from aged carbon, such as rocks, then the result will be a reduction in the / ratio in the water. For example, rivers that pass over limestone, which is mostly composed of calcium carbonate, will acquire carbonate ions. Similarly, groundwater can contain carbon derived from the rocks through which it has passed. These rocks are usually so old that they no longer contain any measurable , so this carbon lowers the / ratio of the water it enters, which can lead to apparent ages of thousands of years for both the affected water and the plants and freshwater organisms that live in it. This is known as the hard water effect because it is often associated with calcium ions, which are characteristic of hard water; other sources of carbon such as humus can produce similar results, and can also reduce the apparent age if they are of more recent origin than the sample. The effect varies greatly and there is no general offset that can be applied; additional research is usually needed to determine the size of the offset, for example by comparing the radiocarbon age of deposited freshwater shells with associated organic material.

Volcanic eruptions eject large amounts of carbon into the air. The carbon is of geological origin and has no detectable , so the / ratio in the vicinity of the volcano is depressed relative to surrounding areas. Dormant volcanoes can also emit aged carbon. Plants that photosynthesize this carbon also have lower / ratios: for example, plants in the neighbourhood of the Furnas caldera in the Azores were found to have apparent ages that ranged from 250 years to 3320 years.

Any addition of carbon to a sample of a different age will cause the measured date to be inaccurate. Contamination with modern carbon causes a sample to appear to be younger than it really is: the effect is greater for older samples. If a sample that is 17,000 years old is contaminated so that 1% of the sample is modern carbon, it will appear to be 600 years younger; for a sample that is 34,000 years old the same amount of contamination would cause an error of 4,000 years. Contamination with old carbon, with no remaining , causes an error in the other direction independent of ageÂ â a sample contaminated with 1% old carbon will appear to be about 80 years older than it truly is, regardless of the date of the sample.

Samples for dating need to be converted into a form suitable for measuring the content; this can mean conversion to gaseous, liquid, or solid form, depending on the measurement technique to be used. Before this can be done, the sample must be treated to remove any contamination and any unwanted constituents. This includes removing visible contaminants, such as rootlets that may have penetrated the sample since its burial. Alkali and acid washes can be used to remove humic acid and carbonate contamination, but care has to be taken to avoid removing the part of the sample that contains the carbon to be tested.


Particularly for older samples, it may be useful to enrich the amount of in the sample before testing. This can be done with a thermal diffusion column. The process takes about a month and requires a sample about ten times as large as would be needed otherwise, but it allows more precise measurement of the / ratio in old material and extends the maximum age that can be reliably reported.

Once contamination has been removed, samples must be converted to a form suitable for the measuring technology to be used. Where gas is required, is widely used. For samples to be used in liquid scintillation counters, the carbon must be in liquid form; the sample is typically converted to benzene. For accelerator mass spectrometry, solid graphite targets are the most common, although gaseous can also be used.

The quantity of material needed for testing depends on the sample type and the technology being used. There are two types of testing technology: detectors that record radioactivity, known as beta counters, and accelerator mass spectrometers. For beta counters, a sample weighing at least is typically required. Accelerator mass spectrometry is much more sensitive, and samples containing as little as 0.5 milligrams of carbon can be used.

For decades after Libby performed the first radiocarbon dating experiments, the only way to measure the in a sample was to detect the radioactive decay of individual carbon atoms. In this approach, what is measured is the activity, in number of decay events per unit mass per time period, of the sample. This method is also known as "beta counting", because it is the beta particles emitted by the decaying atoms that are detected. In the late 1970s an alternative approach became available: directly counting the number of and atoms in a given sample, via accelerator mass spectrometry, usually referred to as AMS. AMS counts the / ratio directly, instead of the activity of the sample, but measurements of activity and / ratio can be converted into each other exactly. For some time, beta counting methods were more accurate than AMS, but AMS is now more accurate and has become the method of choice for radiocarbon measurements. In addition to improved accuracy, AMS has two further significant advantages over beta counting: it can perform accurate testing on samples much too small for beta counting; and it is much fasterÂ â an accuracy of 1% can be achieved in minutes with AMS, which is far quicker than would be achievable with the older technology.

Libby's first detector was a Geiger counter of his own design. He converted the carbon in his sample to lamp black (soot) and coated the inner surface of a cylinder with it. This cylinder was inserted into the counter in such a way that the counting wire was inside the sample cylinder, in order that there should be no material between the sample and the wire. Any interposing material would have interfered with the detection of radioactivity, since the beta particles emitted by decaying are so weak that half are stopped by a 0.01Â mm thickness of aluminium.

Libby's method was soon superseded by gas proportional counters, which were less affected by bomb carbon (the additional created by nuclear weapons testing). These counters record bursts of ionization caused by the beta particles emitted by the decaying atoms; the bursts are proportional to the energy of the particle, so other sources of ionization, such as background radiation, can be identified and ignored. The counters are surrounded by lead or steel shielding, to eliminate background radiation and to reduce the incidence of cosmic rays. In addition, anticoincidence detectors are used; these record events outside the counter, and any event recorded simultaneously both inside and outside the counter is regarded as an extraneous event and ignored.

The other common technology used for measuring activity is liquid scintillation counting, which was invented in 1950, but which had to wait until the early 1960s, when efficient methods of benzene synthesis were developed, to become competitive with gas counting; after 1970 liquid counters became the more common technology choice for newly constructed dating laboratories. The counters work by detecting flashes of light caused by the beta particles emitted by as they interact with a fluorescing agent added to the benzene. Like gas counters, liquid scintillation counters require shielding and anticoincidence counters.

For both the gas proportional counter and liquid scintillation counter, what is measured is the number of beta particles detected in a given time period. Since the mass of the sample is known, this can be converted to a standard measure of activity in units of either counts per minute per gram of carbon (cpm/g C), or becquerels per kg (Bq/kg C, in SI units). Each measuring device is also used to measure the activity of a blank sampleÂ â a sample prepared from carbon old enough to have no activity. This provides a value for the background radiation, which must be subtracted from the measured activity of the sample being dated to get the activity attributable solely to that sample's . In addition, a sample with a standard activity is measured, to provide a baseline for comparison.

AMS counts the atoms of and in a given sample, determining the / ratio directly. The sample, often in the form of graphite, is made to emit C ions (carbon atoms with a single negative charge), which are injected into an accelerator. The ions are accelerated and passed through a stripper, which removes several electrons so that the ions emerge with a positive charge. The ions, which may have from 1 to 4 positive charges (C to C), depending on the accelerator design, are then passed through a magnet that curves their path; the heavier ions are curved less than the lighter ones, so the different isotopes emerge as separate streams of ions. A particle detector then records the number of ions detected in the stream, but since the volume of (and , needed for calibration) is too great for individual ion detection, counts are determined by measuring the electric current created in a Faraday cup. The large positive charge induced by the stripper forces molecules such as , which has a weight close enough to to interfere with the measurements, to dissociate, so they are not detected. Most AMS machines also measure the sample's , for use in calculating the sample's radiocarbon age. The use of AMS, as opposed to simpler forms of mass spectrometry, is necessary because of the need to distinguish the carbon isotopes from other atoms or molecules that are very close in mass, such as and . As with beta counting, both blank samples and standard samples are used. Two different kinds of blank may be measured: a sample of dead carbon that has undergone no chemical processing, to detect any machine background, and a sample known as a process blank made from dead carbon that is processed into target material in exactly the same way as the sample which is being dated. Any signal from the machine background blank is likely to be caused either by beams of ions that have not followed the expected path inside the detector, or by carbon hydrides such as or . A signal from the process blank measures the amount of contamination introduced during the preparation of the sample. These measurements are used in the subsequent calculation of the age of the sample.

The calculations to be performed on the measurements taken depend on the technology used, since beta counters measure the sample's radioactivity whereas AMS determines the ratio of the three different carbon isotopes in the sample.

To determine the age of a sample whose activity has been measured by beta counting, the ratio of its activity to the activity of the standard must be found. To determine this, a blank sample (of old, or dead, carbon) is measured, and a sample of known activity is measured. The additional samples allow errors such as background radiation and systematic errors in the laboratory setup to be detected and corrected for. The most common standard sample material is oxalic acid, such as the HOxII standard, 1,000Â lb of which was prepared by the National Institute of Standards and Technology (NIST) in 1977 from French beet harvests.

The results from AMS testing are in the form of ratios of , , and , which are used to calculate Fm, the "fraction modern". This is defined as the ratio between the / ratio in the sample and the / ratio in modern carbon, which is in turn defined as the / ratio that would have been measured in 1950 had there been no fossil fuel effect.

Both beta counting and AMS results have to be corrected for fractionation. This is necessary because different materials of the same age, which because of fractionation have naturally different / ratios, will appear to be of different ages because the / ratio is taken as the indicator of age. To avoid this, all radiocarbon measurements are converted to the measurement that would have been seen had the sample been made of wood, which has a known Î´ value of â25â°.

Once the corrected / ratio is known, a "radiocarbon age" is calculated using:

The calculation uses 8,033, the mean-life derived from Libby's half-life of 5,568 years, not 8,267, the mean-life derived from the more accurate modern value of 5,730 years. Libby's value for the half-life is used to maintain consistency with early radiocarbon testing results; calibration curves include a correction for this, so the accuracy of final reported calendar ages is assured.

The reliability of the results can be improved by lengthening the testing time. For example, if counting beta decays for 250 minutes is enough to give an error of Â± 80 years, with 68% confidence, then doubling the counting time to 500 minutes will allow a sample with only half as much to be measured with the same error term of 80 years.

Radiocarbon dating is generally limited to dating samples no more than 50,000 years old, as samples older than that have insufficient to be measurable. Older dates have been obtained by using special sample preparation techniques, large samples, and very long measurement times. These techniques can allow measurement of dates up to 60,000 and in some cases up to 75,000 years before the present.

Radiocarbon dates are generally presented with a range of one standard deviation (usually represented by the Greek letter sigma as 1Ï) on either side of the mean. However, a date range of 1Ï represents only 68% confidence level, so the true age of the object being measured may lie outside the range of dates quoted. This was demonstrated in 1970 by an experiment run by the British Museum radiocarbon laboratory, in which weekly measurements were taken on the same sample for six months. The results varied widely (though consistently with a normal distribution of errors in the measurements), and included multiple date ranges (of 1Ï confidence) that did not overlap with each other. The measurements included one with a range from about 4250 to about 4390 years ago, and another with a range from about 4520 to about 4690.

Errors in procedure can also lead to errors in the results. If 1% of the benzene in a modern reference sample accidentally evaporates, scintillation counting will give a radiocarbon age that is too young by about 80 years.

The calculations given above produce dates in radiocarbon years: i.e. dates that represent the age the sample would be if the / ratio had been constant historically. Although Libby had pointed out as early as 1955 the possibility that this assumption was incorrect, it was not until discrepancies began to accumulate between measured ages and known historical dates for artefacts that it became clear that a correction would need to be applied to radiocarbon ages to obtain calendar dates.

To produce a curve that can be used to relate calendar years to radiocarbon years, a sequence of securely dated samples is needed which can be tested to determine their radiocarbon age. The study of tree rings led to the first such sequence: individual pieces of wood show characteristic sequences of rings that vary in thickness because of environmental factors such as the amount of rainfall in a given year. These factors affect all trees in an area, so examining tree-ring sequences from old wood allows the identification of overlapping sequences. In this way, an uninterrupted sequence of tree rings can be extended far into the past. The first such published sequence, based on bristlecone pine tree rings, was created by Wesley Ferguson. Hans Suess used this data to publish the first calibration curve for radiocarbon dating in 1967. The curve showed two types of variation from the straight line: a long term fluctuation with a period of about 9,000 years, and a shorter term variation, often referred to as "wiggles", with a period of decades. Suess said he drew the line showing the wiggles by "cosmic "schwung"", by which he meant that the variations were caused by extraterrestrial forces. It was unclear for some time whether the wiggles were real or not, but they are now well-established. These short term fluctuations in the calibration curve are now known as de Vries effects, after Hessel de Vries.

A calibration curve is used by taking the radiocarbon date reported by a laboratory, and reading across from that date on the vertical axis of the graph. The point where this horizontal line intersects the curve will give the calendar age of the sample on the horizontal axis. This is the reverse of the way the curve is constructed: a point on the graph is derived from a sample of known age, such as a tree ring; when it is tested, the resulting radiocarbon age gives a data point for the graph.Over the next thirty years many calibration curves were published using a variety of methods and statistical approaches. These were superseded by the INTCAL series of curves, beginning with INTCAL98, published in 1998, and updated in 2004, 2009, and 2013. The improvements to these curves are based on new data gathered from tree rings, varves, coral, plant macrofossils, speleothems, and foraminifera. The INTCAL13 data includes separate curves for the northern and southern hemispheres, as they differ systematically because of the hemisphere effect. The southern curve (SHCAL13) is based on independent data where possible, and derived from the northern curve by adding the average offset for the southern hemisphere where no direct data was available. There is also a separate marine calibration curve, MARINE13. For a set of samples forming a sequence with a known separation in time, these samples form a subset of the calibration curve. The sequence can be compared to the calibration curve and the best match to the sequence established. This âwiggle-matchingâ technique can lead to more precise dating than is possible with individual radiocarbon dates. Wiggle-matching can be used in places where there is a plateau on the calibration curve, and hence can provide a much more accurate date than the intercept or probability methods are able to produce. The technique is not restricted to tree rings; for example, a stratified tephra sequence in New Zealand, believed to predate human colonization of the islands, has been dated to 1314Â AD Â± 12 years by wiggle-matching. The wiggles also mean that reading a date from a calibration curve can give more than one answer: this occurs when the curve wiggles up and down enough that the radiocarbon age intercepts the curve in more than one place, which may lead to a radiocarbon result being reported as two separate age ranges, corresponding to the two parts of the curve that the radiocarbon age intercepted.

Bayesian statistical techniques can be applied when there are several radiocarbon dates to be calibrated. For example, if a series of radiocarbon dates is taken from different levels in a stratigraphic sequence, Bayesian analysis can be used to evaluate dates which are outliers, and can calculate improved probability distributions, based on the prior information that the sequence should be ordered in time. When Bayesian analysis was introduced, its use was limited by the need to use mainframe computers to perform the calculations, but the technique has since been implemented on programs available for personal computers, such as OxCal.

Several formats for citing radiocarbon results have been used since the first samples were dated. As of 2019, the standard format required by the journal "Radiocarbon" is as follows.

Uncalibrated dates should be reported as "<laboratory>: < year> Â± <range> BP", where:

For example, the uncalibrated date "UtC-2020: 3510 Â± 60 BP" indicates that the sample was tested by the Utrecht van der Graaff Laboratorium, where it has a sample number of 2020, and that the uncalibrated age is 3510 years before present, Â± 60 years. Related forms are sometimes used: for example, "10 ka BP" means 10,000 radiocarbon years before present (i.e. 8,050 BC), and yr BP might be used to distinguish the uncalibrated date from a date derived from another dating method such as thermoluminescence.

Calibrated dates are frequently reported as cal BP, cal BC, or cal AD, again with BP referring to the year 1950 as the zero date. "Radiocarbon" gives two options for reporting calibrated dates. A common format is "cal <date-range> <confidence>", where:

For example, "cal 1220â1281 AD (1Ï)" means a calibrated date for which the true date lies between 1220 AD and 1281 AD, with the confidence level given as 1Ï, or one standard deviation. Calibrated dates can also be expressed as BP instead of using BC and AD. The curve used to calibrate the results should be the latest available INTCAL curve. Calibrated dates should also identify any programs, such as OxCal, used to perform the calibration. In addition, an article in "Radiocarbon" in 2014 about radiocarbon date reporting conventions recommends that information should be provided about sample treatment, including the sample material, pretreatment methods, and quality control measurements; that the citation to the software used for calibration should specify the version number and any options or models used; and that the calibrated date should be given with the associated probabilities for each range.

A key concept in interpreting radiocarbon dates is archaeological association: what is the true relationship between two or more objects at an archaeological site? It frequently happens that a sample for radiocarbon dating can be taken directly from the object of interest, but there are also many cases where this is not possible. Metal grave goods, for example, cannot be radiocarbon dated, but they may be found in a grave with a coffin, charcoal, or other material which can be assumed to have been deposited at the same time. In these cases a date for the coffin or charcoal is indicative of the date of deposition of the grave goods, because of the direct functional relationship between the two. There are also cases where there is no functional relationship, but the association is reasonably strong: for example, a layer of charcoal in a rubbish pit provides a date which has a relationship to the rubbish pit.

Contamination is of particular concern when dating very old material obtained from archaeological excavations and great care is needed in the specimen selection and preparation. In 2014, Thomas Higham and co-workers suggested that many of the dates published for Neanderthal artefacts are too recent because of contamination by "young carbon".

As a tree grows, only the outermost tree ring exchanges carbon with its environment, so the age measured for a wood sample depends on where the sample is taken from. This means that radiocarbon dates on wood samples can be older than the date at which the tree was felled. In addition, if a piece of wood is used for multiple purposes, there may be a significant delay between the felling of the tree and the final use in the context in which it is found. This is often referred to as the "old wood" problem. One example is the Bronze Age trackway at Withy Bed Copse, in England; the trackway was built from wood that had clearly been worked for other purposes before being re-used in the trackway. Another example is driftwood, which may be used as construction material. It is not always possible to recognize re-use. Other materials can present the same problem: for example, bitumen is known to have been used by some Neolithic communities to waterproof baskets; the bitumen's radiocarbon age will be greater than is measurable by the laboratory, regardless of the actual age of the context, so testing the basket material will give a misleading age if care is not taken. A separate issue, related to re-use, is that of lengthy use, or delayed deposition. For example, a wooden object that remains in use for a lengthy period will have an apparent age greater than the actual age of the context in which it is deposited.

Archaeology is not the only field to make use of radiocarbon dating. Radiocarbon dates can also be used in geology, sedimentology, and lake studies, for example. The ability to date minute samples using AMS has meant that palaeobotanists and palaeoclimatologists can use radiocarbon dating directly on pollen purified from sediment sequences, or on small quantities of plant material or charcoal. Dates on organic material recovered from strata of interest can be used to correlate strata in different locations that appear to be similar on geological grounds. Dating material from one location gives date information about the other location, and the dates are also used to place strata in the overall geological timeline.

Radiocarbon is also used to date carbon released from ecosystems, particularly to monitor the release of old carbon that was previously stored in soils as a result of human disturbance or climate change. Recent advances in field collection techniques also allow the radiocarbon dating of methane and carbon dioxide, which are important Greenhouse gases.

The Pleistocene is a geological epoch that began about 2.6 million years ago. The Holocene, the current geological epoch, begins about 11,700 years ago, when the Pleistocene ends. Establishing the date of this boundary â which is defined by sharp climatic warming â as accurately as possible has been a goal of geologists for much of the 20th century. At Two Creeks, in Wisconsin, a fossil forest was discovered (Two Creeks Buried Forest State Natural Area), and subsequent research determined that the destruction of the forest was caused by the Valders ice readvance, the last southward movement of ice before the end of the Pleistocene in that area. Before the advent of radiocarbon dating, the fossilized trees had been dated by correlating sequences of annually deposited layers of sediment at Two Creeks with sequences in Scandinavia. This led to estimates that the trees were between 24,000 and 19,000 years old, and hence this was taken to be the date of the last advance of the Wisconsin glaciation before its final retreat marked the end of the Pleistocene in North America. In 1952 Libby published radiocarbon dates for several samples from the Two Creeks site and two similar sites nearby; the dates were averaged to 11,404 BP with a standard error of 350 years. This result was uncalibrated, as the need for calibration of radiocarbon ages was not yet understood. Further results over the next decade supported an average date of 11,350 BP, with the results thought to be most accurate averaging 11,600 BP. There was initial resistance to these results on the part of Ernst Antevs, the palaeobotanist who had worked on the Scandinavian varve series, but his objections were eventually discounted by other geologists. In the 1990s samples were tested with AMS, yielding (uncalibrated) dates ranging from 11,640 BP to 11,800 BP, both with a standard error of 160 years. Subsequently, a sample from the fossil forest was used in an interlaboratory test, with results provided by over 70 laboratories. These tests produced a median age of 11,788 Â± 8 BP (2Ï confidence) which when calibrated gives a date range of 13,730 to 13,550 cal BP. The Two Creeks radiocarbon dates are now regarded as a key result in developing the modern understanding of North American glaciation at the end of the Pleistocene.

In 1947, scrolls were discovered in caves near the Dead Sea that proved to contain writing in Hebrew and Aramaic, most of which are thought to have been produced by the Essenes, a small Jewish sect. These scrolls are of great significance in the study of Biblical texts because many of them contain the earliest known version of books of the Hebrew bible. A sample of the linen wrapping from one of these scrolls, the Great Isaiah Scroll, was included in a 1955 analysis by Libby, with an estimated age of 1,917 Â± 200 years. Based on an analysis of the writing style, palaeographic estimates were made of the age of 21 of the scrolls, and samples from most of these, along with other scrolls which had not been palaeographically dated, were tested by two AMS laboratories in the 1990s. The results ranged in age from the early 4th century BC to the mid 4th century AD. In all but two cases the scrolls were determined to be within 100 years of the palaeographically determined age. The Isaiah scroll was included in the testing and was found to have two possible date ranges at a 2Ï confidence level, because of the shape of the calibration curve at that point: there is a 15% chance that it dates from 355â295 BC, and an 84% chance that it dates from 210â45 BC. Subsequently, these dates were criticized on the grounds that before the scrolls were tested, they had been treated with modern castor oil in order to make the writing easier to read; it was argued that failure to remove the castor oil sufficiently would have caused the dates to be too young. Multiple papers have been published both supporting and opposing the criticism.

Soon after the publication of Libby's 1949 paper in "Science", universities around the world began establishing radiocarbon-dating laboratories, and by the end of the 1950s there were more than 20 active research laboratories. It quickly became apparent that the principles of radiocarbon dating were valid, despite certain discrepancies, the causes of which then remained unknown.

The development of radiocarbon dating has had a profound impact on archaeologyoften described as the "radiocarbon revolution". In the words of anthropologist R.Â E. Taylor, " data made a "world" prehistory possible by contributing a time scale that transcends local, regional and continental boundaries". It provides more accurate dating within sites than previous methods, which usually derived either from stratigraphy or from typologies (e.g. of stone tools or pottery); it also allows comparison and synchronization of events across great distances. The advent of radiocarbon dating may even have led to better field methods in archaeology, since better data recording leads to firmer association of objects with the samples to be tested. These improved field methods were sometimes motivated by attempts to prove that a date was incorrect. Taylor also suggests that the availability of definite date information freed archaeologists from the need to focus so much of their energy on determining the dates of their finds, and led to an expansion of the questions archaeologists were willing to research. For example, from the 1970s questions about the evolution of human behaviour were much more frequently seen in archaeology.

The dating framework provided by radiocarbon led to a change in the prevailing view of how innovations spread through prehistoric Europe. Researchers had previously thought that many ideas spread by diffusion through the continent, or by invasions of peoples bringing new cultural ideas with them. As radiocarbon dates began to prove these ideas wrong in many instances, it became apparent that these innovations must sometimes have arisen locally. This has been described as a "second radiocarbon revolution", and with regard to British prehistory, archaeologist Richard Atkinson has characterized the impact of radiocarbon dating as "radicalÂ ... therapy" for the "progressive disease of invasionism". More broadly, the success of radiocarbon dating stimulated interest in analytical and statistical approaches to archaeological data. Taylor has also described the impact of AMS, and the ability to obtain accurate measurements from very small samples, as ushering in a third radiocarbon revolution.

Occasionally, radiocarbon dating techniques date an object of popular interest, for example the Shroud of Turin, a piece of linen cloth thought by some to bear an image of Jesus Christ after his crucifixion. Three separate laboratories dated samples of linen from the Shroud in 1988; the results pointed to 14th-century origins, raising doubts about the shroud's authenticity as an alleged 1st-century relic.

Researchers have studied other radioactive isotopes created by cosmic rays to determine if they could also be used to assist in dating objects of archaeological interest; such isotopes include , , , , and . With the development of AMS in the 1980s it became possible to measure these isotopes precisely enough for them to be the basis of useful dating techniques, which have been primarily applied to dating rocks. Naturally occurring radioactive isotopes can also form the basis of dating methods, as with potassiumâargon dating, argonâargon dating, and uranium series dating. Other dating techniques of interest to archaeologists include thermoluminescence, optically stimulated luminescence, electron spin resonance, and fission track dating, as well as techniques that depend on annual bands or layers, such as dendrochronology, tephrochronology, and varve chronology.





</doc>
<doc id="26199" url="https://en.wikipedia.org/wiki?curid=26199" title="Roald Amundsen">
Roald Amundsen

Roald Engelbregt Gravning Amundsen (, ; 16 July 1872Â â ) was a Norwegian explorer of polar regions and a key figure of the Heroic Age of Antarctic Exploration. He led the first expedition to traverse the Northwest Passage by sea, from 1903 to 1906, and the first expedition to the South Pole in 1911. He led the first expedition proven to have reached the North Pole in a dirigible in 1926. He disappeared while taking part in a rescue mission for the airship in 1928.

Amundsen was born to a family of Norwegian shipowners and captains in Borge, between the towns Fredrikstad and Sarpsborg. His parents were Jens Amundsen and Hanna Sahlqvist. Roald was the fourth son in the family. His mother wanted him to avoid the family maritime trade and encouraged him to become a doctor, a promise that Amundsen kept until his mother died when he was aged 21. He promptly quit university for a life at sea.

When he was fifteen years old, Amundsen was enthralled by reading Sir John Franklin's narratives of his overland Arctic expeditions. Amundsen wrote "I read them with a fervid fascination which has shaped the whole course of my life".

Amundsen joined the Belgian Antarctic Expedition as first mate. This expedition, led by Adrien de Gerlache using the ship the RV "Belgica", became the first expedition to overwinter in Antarctica. The "Belgica", whether by mistake or design, became locked in the sea ice at 70Â°30â²S off Alexander Island, west of the Antarctic Peninsula. The crew endured a winter for which they were poorly prepared.

By Amundsen's own estimation, the doctor for the expedition, the American Frederick Cook, probably saved the crew from scurvy by hunting for animals and feeding the crew fresh meat. In cases where citrus fruits are lacking, fresh meat from animals that make their own vitamin C contains enough of the vitamin to prevent scurvy, and even partly treat it. This was an important lesson for Amundsen's future expeditions.

In 1903, Amundsen led the first expedition to successfully traverse Canada's Northwest Passage between the Atlantic and Pacific oceans. He planned a small expedition of six men in a fishing vessel, , in order to have flexibility. His ship had relatively shallow draft. His technique was to use a small ship and hug the coast. Amundsen had the ship outfitted with a small 13Â horsepower single-screw paraffin engine.

They traveled via Baffin Bay, the Parry Channel and then south through Peel Sound, James Ross Strait, Simpson Strait and Rae Strait. They spent two winters at King William Island, in the harbor of what is today Gjoa Haven. During this time, Amundsen and the crew learned from the local Netsilik Inuit people about Arctic survival skills, which he found invaluable in his later expedition to the South Pole. For example, he learned to use sled dogs for transportation of goods and to wear animal skins in lieu of heavy, woolen parkas, which could not keep out the cold when wet.

Leaving Gjoa Haven, he sailed west and passed Cambridge Bay, which had been reached from the west by Richard Collinson in 1852. Continuing to the south of Victoria Island, the ship cleared the Canadian Arctic Archipelago on . It had to stop for the winter before going on to Nome on Alaska's Pacific coast. The nearest telegraph station was away in Eagle. Amundsen traveled there overland to wire a success message on 5 December, then returned to Nome in 1906. Later that year he was elected to the American Antiquarian Society.

At this time, Amundsen learned of the dissolution of the union between Norway and Sweden, and that he had a new king. The explorer sent the new king, Haakon VII, news that his traversing the Northwest Passage "was a great achievement for Norway". He said he hoped to do more and signed it "Your loyal subject, Roald Amundsen." The crew returned to Oslo in November 1906, after almost three-and-a-half years abroad. "GjÃ¸a" was returned to Norway in 1972. After a trip from San Francisco on a bulk carrier, she was placed on land outside the Fram Museum in Oslo, where she is now situated inside her own dedicated building at the museum.

Amundsen next planned to take an expedition to the North Pole and explore the Arctic Basin. Finding it difficult to raise funds, when he heard in 1909 that the Americans Frederick Cook and Robert Peary had claimed to reach the North Pole as a result of two different expeditions, he decided to reroute to Antarctica. He was not clear about his intentions, and Robert F. Scott and the Norwegian supporters felt misled. Scott was planning his own expedition to the South Pole that year. Using the ship , earlier used by Fridtjof Nansen, Amundsen left Oslo for the south on 3 June 1910. At Madeira, Amundsen alerted his men that they would be heading to Antarctica, and sent a telegram to Scott: "Beg to inform you "Fram" proceeding AntarcticâAmundsen."

Nearly six months later, the expedition arrived at the eastern edge of the Ross Ice Shelf (then known as "the Great Ice Barrier"), at a large inlet called the Bay of Whales, on 14 January 1911. Amundsen established his base camp there, calling it . Amundsen eschewed the heavy wool clothing worn on earlier Antarctic attempts in favour of adopting Inuit-style furred skins.

Using skis and dog sleds for transportation, Amundsen and his men created supply depots at 80Â°, 81Â° and 82Â°Â South on the Barrier, along a line directly south to the Pole. Amundsen also planned to kill some of his dogs on the way and use them as a source for fresh meat. A small group, including Hjalmar Johansen, Kristian Prestrud and JÃ¸rgen Stubberud, set out on 8 September, but had to abandon their trek due to extreme temperatures. The painful retreat caused a quarrel within the group, and Amundsen sent Johansen and the other two men to explore King Edward VII Land.

A second attempt, with a team of five made up of Olav Bjaaland, Helmer Hanssen, Sverre Hassel, Oscar Wisting, and Amundsen, departed base camp on 19 October. They took four sledges and 52Â dogs. Using a route along the previously unknown Axel Heiberg Glacier, they arrived at the edge of the Polar Plateau on 21 November after a four-day climb. The team and 16Â dogs arrived at the pole on 14 December, a month before Scott's group. Amundsen named their South Pole camp Polheim. Amundsen renamed the Antarctic Plateau as King Haakon VII's Plateau. They left a small tent and letter stating their accomplishment, in case they did not return safely to Framheim.

The team arrived at Framheim on 25 January 1912, with 11Â surviving dogs. They made their way off the continent and to Hobart, Australia, where Amundsen publicly announced his success on 7 March. He telegraphed news to backers.

Amundsen's expedition benefited from his careful preparation, good equipment, appropriate clothing, a simple primary task, an understanding of dogs and their handling, and the effective use of skis. In contrast to the misfortunes of Scott's team, Amundsen's trek proved relatively smooth and uneventful.

In 1918, an expedition Amundsen began with a new ship, , lasted until 1925. "Maud" was carefully navigated through the ice west to east through the Northeast Passage. With him on this expedition were Oscar Wisting and Helmer Hanssen, both of whom had been part of the team to reach the South Pole. In addition, Henrik LindstrÃ¸m was included as a cook. He suffered a stroke and was so physically reduced that he could not participate.

The goal of the expedition was to explore the unknown areas of the Arctic Ocean, strongly inspired by Fridtjof Nansen's earlier expedition with "Fram". The plan was to sail along the coast of Siberia and go into the ice farther to the north and east than Nansen had. In contrast to Amundsen's earlier expeditions, this was expected to yield more material for academic research, and he carried the geophysicist Harald Sverdrup on board.

The voyage was to the northeasterly direction over the Kara Sea. Amundsen planned to freeze the "Maud" into the polar ice cap and drift towards the North Poleâas Nansen had done with the "Fram"âand he did so off Cape Chelyuskin. But, the ice became so thick that the ship was unable to break free, although it was designed for such a journey in heavy ice. In September 1919, the crew got the ship loose from the ice, but it froze again after eleven days somewhere between the New Siberian Islands and Wrangel Island.

During this time, Amundsen suffered a broken arm and was attacked by polar bears. As a result, he participated little in the work outdoors, such as sleigh rides and hunting. He, Hanssen, and Wisting, along with two other men, embarked on an expedition by dog sled to Nome, Alaska, more than away. But they found that the ice was not frozen solid in the Bering Strait, and it could not be crossed. They sent a telegram from Anadyr to signal their location.

After two winters frozen in the ice, without having achieved the goal of drifting over the North Pole, Amundsen decided to go to Nome to repair the ship and buy provisions. Several of the crew ashore there, including Hanssen, did not return on time to the ship. Amundsen considered Hanssen to be in breach of contract, and dismissed him from the crew.

During the third winter, "Maud" was frozen in the western Bering Strait. She finally became free and the expedition sailed south, reaching Seattle, in the American Pacific Northwest in 1921 for repairs. Amundsen returned to Norway, needing to put his finances in order. He took with him two young indigenous girls, a four-year-old he adopted, Kakonita, and her companion Camilla. When Amundsen went bankrupt two years later, however, he sent the girls to be cared for by Camilla's father, who lived in eastern Russia.

In June 1922, Amundsen returned to "Maud", which had been sailed to Nome. He decided to shift from the planned naval expedition to aerial ones, and arranged to charter a plane. He divided the expedition team in two: one part, led by him, was to winter over and prepare for an attempt to fly over the pole in 1923. The second team on "Maud", under the command of Wisting, was to resume the original plan to drift over the North Pole in the ice. The ship drifted in the ice for three years east of the New Siberian Islands, never reaching the North Pole. It was finally seized by Amundsen's creditors as collateral for his mounting debt.

The 1923 attempt to fly over the Pole failed. Amundsen and Oskar Omdal, of the Royal Norwegian Navy, tried to fly from Wainwright, Alaska, to Spitsbergen across the North Pole. When their aircraft was damaged, they abandoned the journey. To raise additional funds, Amundsen traveled around the United States in 1924 on a lecture tour. Although he was unable to reach the North Pole, the scientific results of the expedition, mainly the work of Sverdrup, have proven to be of considerable value. Much of the carefully collected scientific data was lost during the ill-fated journey of Peter Tessem and Paul Knutsen, two crew members sent on a mission by Amundsen. The scientific materials were later retrieved by Russian scientist Nikolay Urvantsev from where they had been abandoned on the shores of the Kara Sea.

In 1925, accompanied by Lincoln Ellsworth, pilot Hjalmar Riiser-Larsen, and three other team members, Amundsen took two Dornier Do J flying boats, the N-24 and N-25, to 87Â°Â 44â²Â north. It was the northernmost latitude reached by plane up to that time. The aircraft landed a few miles apart without radio contact, yet the crews managed to reunite. The N-24 was damaged. Amundsen and his crew worked for more than three weeks to clean up an airstrip to take off from ice. They shovelled 600 tons of ice while consuming only one pound (400Â g) of daily food rations. In the end, the six crew members were packed into the N-25. In a remarkable feat, Riiser-Larsen took off, and they barely became airborne over the cracking ice. They returned triumphant when everyone thought they had been lost forever.

In 1926, Amundsen and 15 other men (including Ellsworth, Riiser-Larsen, Oscar Wisting, and the Italian air crew led by aeronautical engineer Umberto Nobile) made the first crossing of the Arctic in the airship "Norge," designed by Nobile. They left Spitsbergen on 11 May 1926, flew over the North Pole on 12 May, and landed in Alaska the following day. 

The three previous claims to have arrived at the North Pole: Frederick Cook in 1908; Robert Peary in 1909; and Richard E. Byrd in 1926 (just a few days before the "Norge") are disputed by some, as being either of dubious accuracy or outright fraud. If these other claims are false, the crew of the "Norge" would be the first explorers verified to have reached the North Pole, floated over it in the Norge in 1926. If the "Norge" expedition was the first to the North Pole, Amundsen and Oscar Wisting were the first men to have reached both geographical poles, by ground or by air.

Amundsen disappeared on 18 June 1928 while flying on a rescue mission in the Arctic. His team included Norwegian pilot Leif Dietrichson, French pilot RenÃ© Guilbaud, and three more Frenchmen. They were seeking missing members of Nobile's crew, whose new airship had crashed while returning from the North Pole. Amundsen's French Latham 47 flying boat
never returned.

Later, a wing-float and bottom gasoline tank from the plane, which had been adapted as a replacement wing-float, were found near the TromsÃ¸ coast. It is believed that the plane crashed in fog in the Barents Sea, and that Amundsen and his crew were killed in the wreck, or died shortly afterward. The search for Amundsen and team was called off in September 1928 by the Norwegian government, and the bodies were never found.

In 2004 and in late August 2009, the Royal Norwegian Navy used the unmanned submarine "Hugin 1000" to search for the wreckage of Amundsen's plane. The searches focused on a area of the sea floor, and were documented by the German production company ContextTV. They found nothing from the Amundsen flight.

In 1925, Amundsen was awarded the Hans Egede Medal by the Royal Danish Geographical Society.

Owing to Amundsen's numerous significant accomplishments in polar exploration, many places in both the Arctic and Antarctic are named after him. The AmundsenâScott South Pole Station, operated by the United States Antarctic Program, was jointly named in honour of Amundsen and his rival. British novelist Roald Dahl was named after Amundsen, as was Nobel Prize laureate Roald Hoffmann.

The 1969 film "The Red Tent" tells the story of the Nobile expedition and Amundsen's disappearance. Sean Connery plays the role of Amundsen.

Huntford's book was adapted into the TV serial "The Last Place on Earth". It aired in 1985 and featured Sverre Anker Ousdal as Amundsen.

On 15 February 2019, a biographic Norwegian film titled "Amundsen", directed by Espen Sandberg, was released.

At least two Inuit people in GjÃ¸a Haven with European ancestry have claimed to be descendants of Amundsen, from the period of their extended winter stay on King Williams Island from 1903 to 1905. Accounts by members of the expedition told of their relations with Inuit women, and historians have speculated that Amundsen might also have taken a partner, although he wrote a warning against this.

Specifically, half-brothers Bob Konona and Paul Ikuallaq say that their father Luke Ikuallaq told them on his deathbed that he was the son of Amundsen. Konona said that their father Ikuallaq was left out on the ice to die after his birth, as his European ancestry made him illegitimate to the Inuit, threatening their community. His Inuit grandparents saved him.

In 2012, Y-DNA analysis, with the families' permission, showed that Ikuallaq was not a match to the direct male line of Amundsen. Not all descendants claiming European ancestry have been tested for a match to Amundsen, nor has there been a comparison of Ikuallaq's DNA to that of other European members of Amundsen's crew.







</doc>
<doc id="26200" url="https://en.wikipedia.org/wiki?curid=26200" title="Richard Lovelace">
Richard Lovelace

Richard Lovelace (pronounced , homophone of "loveless") (9 December 1617 â 1657) was an English poet in the seventeenth century. He was a cavalier poet who fought on behalf of the king during the Civil War. His best known works are "To Althea, from Prison", and "To Lucasta, Going to the Warres".

Richard Lovelace was born on 9 December 1617. His exact birthplace is unknown, and may have been Woolwich, Kent, or Holland. He was the oldest son of Sir William Lovelace and Anne Barne Lovelace. He had four brothers and three sisters. His father was from a distinguished military and legal family; the Lovelace family owned a considerable amount of property in Kent.

His father, Sir William Lovelace, was a member of the Virginia Company and an incorporator in the second Virginia Company in 1609. He was a soldier and died during the war with Spain and the Dutch Republic in the Siege of Groenlo (1627) a few days before the town fell. Richard was nine years old when his father died.

Lovelace's father was the son of Sir William Lovelace and Elizabeth Aucher, who was the daughter of Mabel Wroths and Edward Aucher, who inherited, under his father's will, the manors of Bishopsbourne and Hautsborne. Elizabeth's nephew was Sir Anthony Aucher (1614 â 31 May 1692) an English politician and Cavalier during the English Civil War. He was the son of her brother Sir Anthony Aucher and his wife Hester Collett.

Lovelace's mother, Anne Barne (1587â1633), was the daughter of Sir William Barne and the granddaughter of Sir George Barne III (1532â1593), the Lord Mayor of London and a prominent merchant and public official from London during the reign of Elizabeth I and Anne Gerrard, daughter of Sir William Garrard, who was Lord Mayor of London in 1555.

Lovelace's maternal grandmother was Anne Sandys. His great-grandmother was Cicely Wilford and his great-grandfather Most Reverend Dr Edwin Sandys, an Anglican church leader who successively held the posts of Bishop of Worcester (1559â1570), Bishop of London (1570â1576), and Archbishop of York (1576â1588) and was one of the translators of the Bishops' Bible.

His mother, Anne Barne Lovelace, married as her second husband, on 20 January 1630, at Greenwich, England, the Very Rev Dr Jonathan Browne. They were the parents of one child, Anne Browne, Richard's half-sister, who married Herbert Croft and was the mother of Sir Herbert Croft, 1st Baronet see Croft baronets.

Lovelace's brother, Francis Lovelace (1621â1675), was the second governor of the New York Colony appointed by the Duke of York, later King James II of England. They were also great nephews of both George Sandys (2 March 1577 â March 1644), an English traveller, colonist and poet; and of Sir Edwin Sandys (9 December 1561 â October 1629), an English statesman and one of the founders of the London Company.

In 1629, when Lovelace was eleven, he went to Sutton's Foundation at Charterhouse School, then in London. There is no clear record that Lovelace actually attended; it is believed that he studied as a "boarder" because he did not need financial assistance like the "scholars". He spent five years at Charterhouse, three of which were spent with Richard Crashaw, who also became a poet. On 5 May 1631, Lovelace was sworn in as a Gentleman Wayter Extraordinary to King Charles I, an honorary position for which one paid a fee. He went on to Gloucester Hall, Oxford, in 1634.

Lovelace attended the University of Oxford and was praised by his contemporary Anthony Wood as "the most amiable and beautiful person that ever eye beheld; a person also of innate modesty, virtue and courtly deportment, which made him then, but especially after, when he retired to the great city, much admired and adored by the female sex".

While at college, he tried to portray himself more as a social connoisseur than as a scholar, continuing his image of being a Cavalier. Being a Cavalier poet, Lovelace wrote to praise a friend or fellow poet, to give advice in grief or love, to define a relationship, to articulate the precise amount of attention a man owes a woman, to celebrate beauty, and to persuade to love. Lovelace wrote a comedy, "The Scholars", while at Oxford. He then left for the University of Cambridge for a few months, where he met Lord Goring, who led him into political trouble.

At the age of eighteen he was granted the degree of Master of Arts at Oxford University.

Lovelace's poetry was often influenced by his experiences with politics and association with important figures of his time. At the age of nineteen he contributed a verse to a volume of elegies commemorating Princess Katharine. In 1639 Lovelace joined the regiment of Lord Goring, serving first as a senior ensign and later as a captain in the Bishops' Wars. This experience inspired "Sonnet. To Generall Goring", the poem "To Lucasta, Going to the Warres" and the tragedy "The Soldier". On his return to his home in Kent in 1640, Lovelace served as a country gentleman and a justice of the peace, encountering civil turmoil over religion and politics.

In 1641, Lovelace led a group of men to seize and destroy a petition for the abolition of Episcopal rule, which had been signed by 15,000 people. The following year he presented the House of Commons with Dering's pro-Royalist petition which was supposed to have been burned. These actions resulted in Lovelace's first imprisonment. He was shortly released on bail, with the stipulation that he avoid communication with the House of Commons without permission. This prevented Lovelace, who had done everything to prove himself during the Bishops' Wars, from participating in the first phase of the English Civil War. This first experience of imprisonment brought him to write one of his best known lyrics, "To Althea, from Prison", in which he illustrates his noble and paradoxical nature. Lovelace did everything he could to remain in the king's favor despite his inability to participate in the war.

During the political chaos of 1648 he was again imprisoned, this time for nearly a year. When he was released in April 1649, the king had been executed and Lovelace's cause seemed lost. As in his previous incarceration, this experience led to creative productionâthis time in the cause of spiritual freedom, as reflected in the release of his first volume of poetry, "Lucasta".

Lovelace died in 1657 and was buried in St Bride's Church in Fleet Street in the City of London.

From the time Richard Lovelace started writing while he was a student at Oxford he wrote almost 200 poems. His first work was a drama, "The Scholars", never published but performed at college and then in London. In 1640, he wrote a tragedy, "The Soldier" based on his military experience. When serving in the Bishops' Wars, he wrote the sonnet "To Generall Goring", a poem of Bacchanalian celebration rather than a glorification of military action. "To Lucasta, Going to the Warres", written in 1640, concerned his first political action. "To Althea, From Prison" was written during his first imprisonment in 1642. Later that year, during his travels to Holland with General Goring, he wrote "The Rose", followed by "The Scrutiny". On 14 May 1649, "Lucasta" was published. He also wrote poems on animal life: "The Ant", "The Grasse-hopper", "The Snayl", "The Falcon", "The Toad and Spyder". In 1660, after Lovelace died, "Lucasta: Postume Poems" was published; it contains "A Mock-Song", which has a darker tone than his previous works.

William Winstanley thought highly of Lovelace's work and compared him to an idol: "I can compare no Man so like this Colonel Lovelace as Sir Philip Sidney" of which it is in an Epitaph made of him;

His most quoted excerpts are from the beginning of the last stanza of "To Althea, From Prison":

and the end of "To Lucasta. Going to the Warres":




</doc>
<doc id="26201" url="https://en.wikipedia.org/wiki?curid=26201" title="Reduced instruction set computer">
Reduced instruction set computer

A reduced instruction set computer, or RISC (), is a computer instruction set that allows a computer's microprocessor to have fewer cycles per instruction (CPI) than a complex instruction set computer (CISC).

A RISC computer has a small set of simple and general instructions, rather than a large set of complex and specialized ones. The main distinguishing feature of RISC is that the instruction set is optimized for a highly regular instruction pipeline flow. Another common RISC trait is their load/store architecture, in which memory is accessed through specific instructions rather than as a part of most instructions.

Although a number of computers from the 1960s and 1970s have been identified as forerunners of RISCs, the modern concept dates to the 1980s. In particular, two projects at Stanford University and the University of California, Berkeley are most associated with the popularization of this concept. Stanford's MIPS would go on to be commercialized as the successful MIPS architecture, while Berkeley's RISC gave its name to the entire concept and was commercialized as the SPARC. Another success from this era was IBM's effort that eventually led to the IBM POWER instruction set architecture, PowerPC, and Power ISA. As these projects matured, a variety of similar designs flourished in the late 1980s and especially the early 1990s, representing a major force in the Unix workstation market as well as for embedded processors in laser printers, routers and similar products.

The many varieties of RISC designs include ARC, Alpha, Am29000, ARM, Atmel AVR, Blackfin, i860, i960, M88000, MIPS, PA-RISC, Power ISA (including PowerPC), RISC-V, SuperH, and SPARC. The use of ARM architecture processors in smartphones and tablet computers such as the iPad and Android devices provided a wide user base for RISC-based systems. RISC processors are also used in supercomputers such as Summit, which, , is the world's fastest supercomputer as ranked by the TOP500 project.

Alan Turing's 1946 Automatic Computing Engine (ACE) design had many of the characteristics of a RISC architecture. A number of systems, going back to the 1960s, have been credited as the first RISC architecture, partly based on their use of load/store approach. The term RISC was coined by David Patterson of the Berkeley RISC project, although somewhat similar concepts had appeared before.

The CDC 6600 designed by Seymour Cray in 1964 used a load/store architecture with only two addressing modes (register+register, and register+immediate constant) and 74 operation codes, with the basic clock cycle being 10 times faster than the memory access time. Partly due to the optimized load/store architecture of the CDC 6600, Jack Dongarra says that it can be considered a forerunner of modern RISC systems, although a number of other technical barriers needed to be overcome for the development of a modern RISC system.

Michael J. Flynn views the first RISC system as the IBM 801 design, begun in 1975 by John Cocke and completed in 1980. The 801 was eventually produced in a single-chip form as the IBM ROMP in 1981, which stood for 'Research OPD [Office Products Division] Micro Processor'. As the name implies, this CPU was designed for "mini" tasks, and was also used in the IBM RT PC in 1986, which turned out to be a commercial failure. But the 801 inspired several research projects, including new ones at IBM that would eventually lead to the IBM POWER instruction set architecture.

In the mid-1970s, researchers (particularly John Cocke) at IBM (and similar projects elsewhere) demonstrated that the majority of combinations of these orthogonal addressing modes and instructions were not used by most programs generated by compilers available at the time. It proved difficult in many cases to write a compiler with more than limited ability to take advantage of the features provided by conventional CPUs. It was also discovered that, on microcoded implementations of certain architectures, complex operations tended to be "slower" than a sequence of simpler operations doing the same thing. This was in part an effect of the fact that many designs were rushed, with little time to optimize or tune every instruction; only those used most often were optimized, and a sequence of those instructions could be faster than a less-tuned instruction performing an equivalent operation as that sequence. One infamous example was the VAX's codice_1 instruction. As mentioned elsewhere, core memory had long since been slower than many CPU designs. The advent of semiconductor memory reduced this difference, but it was still apparent that more registers (and later caches) would allow higher CPU operating frequencies. Additional registers would require sizeable chip or board areas which, at the time (1975), could be made available if the complexity of the CPU logic was reduced.

The most public RISC designs, however, were the results of university research programs run with funding from the DARPA VLSI Program. The VLSI Program, practically unknown today, led to a huge number of advances in chip design, fabrication, and even computer graphics. The Berkeley RISC project started in 1980 under the direction of David Patterson and Carlo H. Sequin.

Berkeley RISC was based on gaining performance through the use of pipelining and an aggressive use of a technique known as register windowing. In a traditional CPU, one has a small number of registers, and a program can use any register at any time. In a CPU with register windows, there are a huge number of registers, e.g., 128, but programs can only use a small number of them, e.g., eight, at any one time. A program that limits itself to eight registers per procedure can make very fast procedure calls: The call simply moves the window "down" by eight, to the set of eight registers used by that procedure, and the return moves the window back. The Berkeley RISC project delivered the RISC-I processor in 1982. Consisting of only 44,420 transistors (compared with averages of about 100,000 in newer CISC designs of the era) RISC-I had only 32 instructions, and yet completely outperformed any other single-chip design. They followed this up with the 40,760 transistor, 39 instruction RISC-II in 1983, which ran over three times as fast as RISC-I.

The MIPS project grew out of a graduate course by John L. Hennessy at Stanford University in 1981, resulted in a functioning system in 1983, and could run simple programs by 1984. The MIPS approach emphasized an aggressive clock cycle and the use of the pipeline, making sure it could be run as "full" as possible. The MIPS system was followed by the MIPS-X and in 1984 Hennessy and his colleagues formed MIPS Computer Systems. The commercial venture resulted in a new architecture that was also called MIPS and the R2000 microprocessor in 1985.

In the early 1980s, significant uncertainties surrounded the RISC concept, and it was uncertain if it could have a commercial future, but by the mid-1980s the concepts had matured enough to be seen as commercially viable. In 1986 Hewlett Packard started using an early implementation of their PA-RISC in some of their computers. In the meantime, the Berkeley RISC effort had become so well known that it eventually became the name for the entire concept and in 1987 Sun Microsystems began shipping systems with the SPARC processor, directly based on the Berkeley RISC-II system.

The U.S. government Committee on Innovations in Computing and Communications credits the acceptance of the viability of the RISC concept to the success of the SPARC system. The success of SPARC renewed interest within IBM, which released new RISC systems by 1990 and by 1995 RISC processors were the foundation of a $15 billion server industry.

Since 2010 a new open source instruction set architecture (ISA), RISC-V, has been under development at the University of California, Berkeley, for research purposes and as a free alternative to proprietary ISAs. As of 2014, version 2 of the user space ISA is fixed. The ISA is designed to be extensible from a barebones core sufficient for a small embedded processor to supercomputer and cloud computing use with standard and chip designer defined extensions and coprocessors. It has been tested in silicon design with the ROCKET SoC which is also available as an open-source processor generator in the CHISEL language.

A common misunderstanding of the phrase "reduced instruction set computer" is the mistaken idea that instructions are simply eliminated, resulting in a smaller set of instructions.
In fact, over the years, RISC instruction sets have grown in size, and today many of them have a larger set of instructions than many CISC CPUs. Some RISC processors such as the PowerPC have instruction sets as large as the CISC IBM System/370, for example; conversely, the DEC PDP-8âclearly a CISC CPU because many of its instructions involve multiple memory accessesâhas only 8 basic instructions and a few extended instructions.

The term "reduced" in that phrase was intended to describe the fact that the amount of work any single instruction accomplishes is reducedâat most a single data memory cycleâcompared to the "complex instructions" of CISC CPUs that may require dozens of data memory cycles in order to execute a single instruction. In particular, RISC processors typically have separate instructions for I/O and data processing.

The term load/store architecture is sometimes preferred.

Most RISC architectures have fixed-length instructions (commonly 32 bits) and a simple encoding, which simplifies fetch, decode, and issue logic considerably. One drawback of 32-bit instructions is reduced code density, which is more adverse a characteristic in embedded computing than it is in the workstation and server markets RISC architectures were originally designed to serve. To address this problem, several architectures, such as ARM, Power ISA, MIPS, RISC-V, and the Adapteva Epiphany, have an optional short, feature-reduced instruction format or instruction compression feature. The SH5 also follows this pattern, albeit having evolved in the opposite direction, having added longer media instructions to an original 16-bit encoding.

For any given level of general performance, a RISC chip will typically have far fewer transistors dedicated to the core logic which originally allowed designers to increase the size of the register set and increase internal parallelism.

Other features of RISC architectures include:


RISC designs are also more likely to feature a Harvard memory model, where the instruction stream and the data stream are conceptually separated; this means that modifying the memory where code is held might not have any effect on the instructions executed by the processor (because the CPU has a separate instruction and data cache), at least until a special synchronization instruction is issued. On the upside, this allows both caches to be accessed simultaneously, which can often improve performance.

Many early RISC designs also shared the characteristic of having a branch delay slot, an instruction space immediately following a jump or branch. The instruction in this space is executed, whether or not the branch is taken (in other words the effect of the branch is delayed). This instruction keeps the ALU of the CPU busy for the extra time normally needed to perform a branch. Nowadays the branch delay slot is considered an unfortunate side effect of a particular strategy for implementing some RISC designs, and modern RISC designs generally do away with it (such as PowerPC and more recent versions of SPARC and MIPS).

Some aspects attributed to the first RISC-"labeled" designs around 1975 include the observations that the memory-restricted compilers of the time were often unable to take advantage of features intended to facilitate "manual" assembly coding, and that complex addressing modes take many cycles to perform due to the required additional memory accesses. It was argued that such functions would be better performed by sequences of simpler instructions if this could yield implementations small enough to leave room for many registers, reducing the number of slow memory accesses. In these simple designs, most instructions are of uniform length and similar structure, arithmetic operations are restricted to CPU registers and only separate "load" and "store" instructions access memory. These properties enable a better balancing of pipeline stages than before, making RISC pipelines significantly more efficient and allowing higher clock frequencies.

Yet another impetus of both RISC and other designs came from practical measurements on real-world programs. Andrew Tanenbaum summed up many of these, demonstrating that processors often had oversized immediates. For instance, he showed that 98% of all the constants in a program would fit in 13 bits, yet many CPU designs dedicated 16 or 32 bits to store them. This suggests that, to reduce the number of memory accesses, a fixed length machine could store constants in unused bits of the instruction word itself, so that they would be immediately ready when the CPU needs them (much like immediate addressing in a conventional design). This required small opcodes in order to leave room for a reasonably sized constant in a 32-bit instruction word.

Since many real-world programs spend most of their time executing simple operations, some researchers decided to focus on making those operations as fast as possible. The clock rate of a CPU is limited by the time it takes to execute the slowest "sub-operation" of any instruction; decreasing that cycle-time often accelerates the execution of other instructions. The focus on "reduced instructions" led to the resulting machine being called a "reduced instruction set computer" (RISC). The goal was to make instructions so simple that they could "easily" be pipelined, in order to achieve a "single clock" throughput at "high frequencies".

Later, it was noted that one of the most significant characteristics of RISC processors was that external memory was only accessible by a "load" or "store" instruction. All other instructions were limited to internal registers. This simplified many aspects of processor design: allowing instructions to be fixed-length, simplifying pipelines, and isolating the logic for dealing with the delay in completing a memory access (cache miss, etc.) to only two instructions. This led to RISC designs being referred to as "load/store" architectures.

Some CPUs have been specifically designed to have a very small set of instructions â but these designs are very different from classic RISC designs, so they have been given other names such as minimal instruction set computer (MISC) or transport triggered architecture (TTA).

RISC architectures have traditionally had few successes in the desktop PC and commodity server markets, where the x86-based platforms remain the dominant processor architecture. However, this may change, as ARM-based processors are being developed for higher performance systems. Manufacturers including Cavium, AMD, and Qualcomm have released server processors based on the ARM architecture. ARM is further partnered with Cray in 2017 to produce an ARM-based supercomputer. On the desktop, Microsoft announced that it planned to support the PC version of Windows 10 on Qualcomm Snapdragon-based devices in 2017 as part of its partnership with Qualcomm. These devices will support x86-based Win32 software via an x86 processor emulator. 

Outside of the desktop arena, however, the ARM RISC architecture is in widespread use in smartphones, tablets and many forms of embedded device. It is also the case that since the Pentium Pro (P6), Intel has been using an internal RISC processor core for its processors.

While early RISC designs differed significantly from contemporary CISC designs, by 2000 the highest-performing CPUs in the RISC line were almost indistinguishable from the highest-performing CPUs in the CISC line.

RISC architectures are now used across a range of platforms, from smartphones and tablet computers to some of the world's fastest supercomputers such as Summit, the fastest on the TOP500 list .

By the beginning of the 21st century, the majority of low-end and mobile systems relied on RISC architectures. Examples include:





</doc>
<doc id="26202" url="https://en.wikipedia.org/wiki?curid=26202" title="Ralph Waldo Emerson">
Ralph Waldo Emerson

Ralph Waldo Emerson (May 25, 1803 â April 27, 1882) was an American essayist, lecturer, philosopher, and poet who led the transcendentalist movement of the mid-19th century. He was seen as a champion of individualism and a prescient critic of the countervailing pressures of society, and he disseminated his thoughts through dozens of published essays and more than 1,500 public lectures across the United States.

Emerson gradually moved away from the religious and social beliefs of his contemporaries, formulating and expressing the philosophy of transcendentalism in his 1836 essay "Nature". Following this work, he gave a speech entitled "The American Scholar" in 1837, which Oliver Wendell Holmes Sr. considered to be America's "intellectual Declaration of Independence."

Emerson wrote most of his important essays as lectures first and then revised them for print. His first two collections of essays, "" (1841) and "" (1844), represent the core of his thinking. They include the well-known essays "Self-Reliance", "The Over-Soul", "Circles", "The Poet", and "Experience." Together with "Nature", these essays made the decade from the mid-1830s to the mid-1840s Emerson's most fertile period. Emerson wrote on a number of subjects, never espousing fixed philosophical tenets, but developing certain ideas such as individuality, freedom, the ability for mankind to realize almost anything, and the relationship between the soul and the surrounding world. Emerson's "nature" was more philosophical than naturalistic: "Philosophically considered, the universe is composed of Nature and the Soul." Emerson is one of several figures who "took a more pantheist or pandeist approach by rejecting views of God as separate from the world."

He remains among the linchpins of the American romantic movement, and his work has greatly influenced the thinkers, writers and poets that followed him. "In all my lectures," he wrote, "I have taught one doctrine, namely, the infinitude of the private man." Emerson is also well known as a mentor and friend of Henry David Thoreau, a fellow transcendentalist.

Emerson was born in Boston, Massachusetts, on May 25, 1803, a son of Ruth Haskins and the Rev. William Emerson, a Unitarian minister. He was named after his mother's brother Ralph and his father's great-grandmother Rebecca Waldo. Ralph Waldo was the second of five sons who survived into adulthood; the others were William, Edward, Robert Bulkeley, and Charles. Three other childrenâPhebe, John Clarke, and Mary Carolineâdied in childhood. Emerson was entirely of English ancestry, and his family had been in New England since the early colonial period.

Emerson's father died from stomach cancer on May 12, 1811, less than two weeks before Emerson's eighth birthday. Emerson was raised by his mother, with the help of the other women in the family; his aunt Mary Moody Emerson in particular had a profound effect on him. She lived with the family off and on and maintained a constant correspondence with Emerson until her death in 1863.

Emerson's formal schooling began at the Boston Latin School in 1812, when he was nine. In October 1817, at age 14, Emerson went to Harvard College and was appointed freshman messenger for the president, requiring Emerson to fetch delinquent students and send messages to faculty. Midway through his junior year, Emerson began keeping a list of books he had read and started a journal in a series of notebooks that would be called "Wide World". He took outside jobs to cover his school expenses, including as a waiter for the Junior Commons and as an occasional teacher working with his uncle Samuel and aunt Sarah Ripley in Waltham, Massachusetts. By his senior year, Emerson decided to go by his middle name, Waldo. Emerson served as Class Poet; as was custom, he presented an original poem on Harvard's Class Day, a month before his official graduation on August 29, 1821, when he was 18. He did not stand out as a student and graduated in the exact middle of his class of 59 people.

In 1826, faced with poor health, Emerson went to seek a warmer climate. He first went to Charleston, South Carolina, but found the weather was still too cold. He then went farther south, to St. Augustine, Florida, where he took long walks on the beach and began writing poetry. While in St. Augustine he made the acquaintance of Prince Achille Murat, the nephew of Napoleon Bonaparte. Murat was two years his senior; they became good friends and enjoyed each other's company. The two engaged in enlightening discussions of religion, society, philosophy, and government. Emerson considered Murat an important figure in his intellectual education.

While in St. Augustine, Emerson had his first encounter with slavery. At one point, he attended a meeting of the Bible Society while a slave auction was taking place in the yard outside. He wrote, "One ear therefore heard the glad tidings of great joy, whilst the other was regaled with 'Going, gentlemen, going!'"

After Harvard, Emerson assisted his brother William in a school for young women established in their mother's house, after he had established his own school in Chelmsford, Massachusetts; when his brother William went to GÃ¶ttingen to study law in mid-1824, Ralph Waldo closed the school but continued to teach in Cambridge, Massachusetts, until early 1825. Emerson was accepted into the Harvard Divinity School in late 1824, and was inducted into Phi Beta Kappa in 1828. Emerson's brother Edward, two years younger than he, entered the office of the lawyer Daniel Webster, after graduating from Harvard first in his class. Edward's physical health began to deteriorate, and he soon suffered a mental collapse as well; he was taken to McLean Asylum in June 1828 at age 23. Although he recovered his mental equilibrium, he died in 1834, apparently from long-standing tuberculosis. Another of Emerson's bright and promising younger brothers, Charles, born in 1808, died in 1836, also of tuberculosis, making him the third young person in Emerson's innermost circle to die in a period of a few years.

Emerson met his first wife, Ellen Louisa Tucker, in Concord, New Hampshire, on Christmas Day, 1827, and married her when she was 18. The couple moved to Boston, with Emerson's mother, Ruth, moving with them to help take care of Ellen, who was already ill with tuberculosis. Less than two years later, on February 8, 1831, Ellen died, at the age of 20, after uttering her last words: "I have not forgotten the peace and joy". Emerson was heavily affected by her death and visited her grave in Roxbury daily. In a journal entry dated March 29, 1832, he wrote, "I visited Ellen's tomb & opened the coffin".

Boston's Second Church invited Emerson to serve as its junior pastor, and he was ordained on January 11, 1829. His initial salary was $1,200 a year, increasing to $1,400 in July, but with his church role he took on other responsibilities: he was the chaplain of the Massachusetts legislature and a member of the Boston school committee. His church activities kept him busy, though during this period, facing the imminent death of his wife, he began to doubt his own beliefs.

After his wife's death, he began to disagree with the church's methods, writing in his journal in June 1832, "I have sometimes thought that, in order to be a good minister, it was necessary to leave the ministry. The profession is antiquated. In an altered age, we worship in the dead forms of our forefathers". His disagreements with church officials over the administration of the Communion service and misgivings about public prayer eventually led to his resignation in 1832. As he wrote, "This mode of commemorating Christ is not suitable to me. That is reason enough why I should abandon it". As one Emerson scholar has pointed out, "Doffing the decent black of the pastor, he was free to choose the gown of the lecturer and teacher, of the thinker not confined within the limits of an institution or a tradition".

Emerson toured Europe in 1833 and later wrote of his travels in "English Traits" (1856). He left aboard the brig "Jasper" on Christmas Day, 1832, sailing first to Malta. During his European trip, he spent several months in Italy, visiting Rome, Florence and Venice, among other cities. When in Rome, he met with John Stuart Mill, who gave him a letter of recommendation to meet Thomas Carlyle. He went to Switzerland, and had to be dragged by fellow passengers to visit Voltaire's home in Ferney, "protesting all the way upon the unworthiness of his memory". He then went on to Paris, a "loud modern New York of a place", where he visited the Jardin des Plantes. He was greatly moved by the organization of plants according to Jussieu's system of classification, and the way all such objects were related and connected. As Robert D. Richardson says, "Emerson's moment of insight into the interconnectedness of things in the Jardin des Plantes was a moment of almost visionary intensity that pointed him away from theology and toward science".

Moving north to England, Emerson met William Wordsworth, Samuel Taylor Coleridge, and Thomas Carlyle. Carlyle in particular was a strong influence on him; Emerson would later serve as an unofficial literary agent in the United States for Carlyle, and in March 1835, he tried to persuade Carlyle to come to America to lecture. The two maintained a correspondence until Carlyle's death in 1881.
Emerson returned to the United States on October 9, 1833, and lived with his mother in Newton, Massachusetts. In October 1834, he moved to Concord, Massachusetts to live with his step-grandfather, Dr. Ezra Ripley, at what was later named The Old Manse. Seeing the budding Lyceum movement, which provided lectures on all sorts of topics, Emerson saw a possible career as a lecturer. On November 5, 1833, he made the first of what would eventually be some 1,500 lectures, "The Uses of Natural History", in Boston. This was an expanded account of his experience in Paris. In this lecture, he set out some of his important beliefs and the ideas he would later develop in his first published essay, "Nature":

On January 24, 1835, Emerson wrote a letter to Lidian Jackson proposing marriage. Her acceptance reached him by mail on the 28th. In July 1835, he bought a house on the Cambridge and Concord Turnpike in Concord, Massachusetts, which he named Bush; it is now open to the public as the Ralph Waldo Emerson House. Emerson quickly became one of the leading citizens in the town. He gave a lecture to commemorate the 200th anniversary of the town of Concord on September 12, 1835. Two days later, he married Lidian Jackson in her home town of Plymouth, Massachusetts, and moved to the new home in Concord together with Emerson's mother on September 15.

Emerson quickly changed his wife's name to Lidian, and would call her Queenie, and sometimes Asia, and she called him Mr. Emerson. Their children were Waldo, Ellen, Edith, and Edward Waldo Emerson. Edward Waldo Emerson was the father of Raymond Emerson. Ellen was named for his first wife, at Lidian's suggestion.

Emerson was poor when he was at Harvard, but was later able to support his family for much of his life. He inherited a fair amount of money after his first wife's death, though he had to file a lawsuit against the Tucker family in 1836 to get it. He received $11,600 in May 1834, and a further $11,674.49 in July 1837. In 1834, he considered that he had an income of $1,200 a year from the initial payment of the estate, equivalent to what he had earned as a pastor.

On September 8, 1836, the day before the publication of "Nature", Emerson met with Frederic Henry Hedge, George Putnam and George Ripley to plan periodic gatherings of other like-minded intellectuals. This was the beginning of the Transcendental Club, which served as a center for the movement. Its first official meeting was held on September 19, 1836. On September 1, 1837, women attended a meeting of the Transcendental Club for the first time. Emerson invited Margaret Fuller, Elizabeth Hoar and Sarah Ripley for dinner at his home before the meeting to ensure that they would be present for the evening get-together. Fuller would prove to be an important figure in transcendentalism.

Emerson anonymously published his first essay, "Nature", on September 9, 1836. A year later, on August 31, 1837, he delivered his now-famous Phi Beta Kappa address, "The American Scholar", then entitled "An Oration, Delivered before the Phi Beta Kappa Society at Cambridge"; it was renamed for a collection of essays (which included the first general publication of "Nature") in 1849. Friends urged him to publish the talk, and he did so, at his own expense, in an edition of 500 copies, which sold out in a month. In the speech, Emerson declared literary independence in the United States and urged Americans to create a writing style all their own and free from Europe. James Russell Lowell, who was a student at Harvard at the time, called it "an event without former parallel on our literary annals". Another member of the audience, Reverend John Pierce, called it "an apparently incoherent and unintelligible address".

In 1837, Emerson befriended Henry David Thoreau. Though they had likely met as early as 1835, in the fall of 1837, Emerson asked Thoreau, "Do you keep a journal?" The question went on to be a lifelong inspiration for Thoreau. Emerson's own journal was published in 16 large volumes, in the definitive Harvard University Press edition issued between 1960 and 1982. Some scholars consider the journal to be Emerson's key literary work.

In March 1837, Emerson gave a series of lectures on the philosophy of history at the Masonic Temple in Boston. This was the first time he managed a lecture series on his own, and it was the beginning of his career as a lecturer. The profits from this series of lectures were much larger than when he was paid by an organization to talk, and he continued to manage his own lectures often throughout his lifetime. He eventually gave as many as 80 lectures a year, traveling across the northern United States as far as St. Louis, Des Moines, Minneapolis, and California.

On July 15, 1838, Emerson was invited to Divinity Hall, Harvard Divinity School, to deliver the school's graduation address, which came to be known as the "Divinity School Address". Emerson discounted biblical miracles and proclaimed that, while Jesus was a great man, he was not God: historical Christianity, he said, had turned Jesus into a "demigod, as the Orientals or the Greeks would describe Osiris or Apollo". His comments outraged the establishment and the general Protestant community. He was denounced as an atheist and a poisoner of young men's minds. Despite the roar of critics, he made no reply, leaving others to put forward a defense. He was not invited back to speak at Harvard for another thirty years.

The transcendental group began to publish its flagship journal, "The Dial", in July 1840. They planned the journal as early as October 1839, but work did not begin until the first week of 1840. George Ripley was the managing editor. Margaret Fuller was the first editor, having been approached by Emerson after several others had declined the role. Fuller stayed on for about two years, when Emerson took over, utilizing the journal to promote talented young writers including Ellery Channing and Thoreau.

In 1841 Emerson published "Essays", his second book, which included the famous essay "Self-Reliance". His aunt called it a "strange medley of atheism and false independence", but it gained favorable reviews in London and Paris. This book, and its popular reception, more than any of Emerson's contributions to date laid the groundwork for his international fame.

In January 1842 Emerson's first son, Waldo, died of scarlet fever. Emerson wrote of his grief in the poem "Threnody" ("For this losing is true dying"), and the essay "Experience". In the same month, William James was born, and Emerson agreed to be his godfather.

Bronson Alcott announced his plans in November 1842 to find "a farm of a hundred acres in excellent condition with good buildings, a good orchard and grounds". Charles Lane purchased a farm in Harvard, Massachusetts, in May 1843 for what would become Fruitlands, a community based on Utopian ideals inspired in part by transcendentalism. The farm would run based on a communal effort, using no animals for labor; its participants would eat no meat and use no wool or leather. Emerson said he felt "sad at heart" for not engaging in the experiment himself. Even so, he did not feel Fruitlands would be a success. "Their whole doctrine is spiritual", he wrote, "but they always end with saying, Give us much land and money". Even Alcott admitted he was not prepared for the difficulty in operating Fruitlands. "None of us were prepared to actualize practically the ideal life of which we dreamed. So we fell apart", he wrote. After its failure, Emerson helped buy a farm for Alcott's family in Concord which Alcott named "Hillside".

"The Dial" ceased publication in April 1844; Horace Greeley reported it as an end to the "most original and thoughtful periodical ever published in this country".

In 1844, Emerson published his second collection of essays, "Essays: Second Series". This collection included "The Poet", "Experience", "Gifts", and an essay entitled "Nature", a different work from the 1836 essay of the same name.

Emerson made a living as a popular lecturer in New England and much of the rest of the country. He had begun lecturing in 1833; by the 1850s he was giving as many as 80 lectures per year. He addressed the Boston Society for the Diffusion of Useful Knowledge and the Gloucester Lyceum, among others. Emerson spoke on a wide variety of subjects, and many of his essays grew out of his lectures. He charged between $10 and $50 for each appearance, bringing him as much as $2,000 in a typical winter lecture season. This was more than his earnings from other sources. In some years, he earned as much as $900 for a series of six lectures, and in another, for a winter series of talks in Boston, he netted $1,600. He eventually gave some 1,500 lectures in his lifetime. His earnings allowed him to expand his property, buying of land by Walden Pond and a few more acres in a neighboring pine grove. He wrote that he was "landlord and waterlord of 14 acres, more or less".

Emerson was introduced to Indian philosophy through the works of the French philosopher Victor Cousin. In 1845, Emerson's journals show he was reading the "Bhagavad Gita" and Henry Thomas Colebrooke's "Essays on the Vedas". He was strongly influenced by Vedanta, and much of his writing has strong shades of nondualism. One of the clearest examples of this can be found in his essay "The Over-soul":
The central message Emerson drew from his Asian studies was that "the purpose of life was spiritual transformation and direct experience of divine power, here and now on earth."

In 1847â48, he toured the British Isles. He also visited Paris between the French Revolution of 1848 and the bloody June Days. When he arrived, he saw the stumps of trees that had been cut down to form barricades in the February riots. On May 21, he stood on the Champ de Mars in the midst of mass celebrations for concord, peace and labor. He wrote in his journal, "At the end of the year we shall take account, & see if the Revolution was worth the trees." The trip left an important imprint on Emerson's later work. His 1856 book "English Traits" is based largely on observations recorded in his travel journals and notebooks. Emerson later came to see the American Civil War as a "revolution" that shared common ground with the European revolutions of 1848.

In a speech in Concord, Massachusetts on May 3, 1851, Emerson denounced the Fugitive Slave Act:
That summer, he wrote in his diary:
In February 1852 Emerson and James Freeman Clarke and William Henry Channing edited an edition of the works and letters of Margaret Fuller, who had died in 1850. Within a week of her death, her New York editor, Horace Greeley, suggested to Emerson that a biography of Fuller, to be called "Margaret and Her Friends", be prepared quickly "before the interest excited by her sad decease has passed away". Published under the title "The Memoirs of Margaret Fuller Ossoli", Fuller's words were heavily censored or rewritten. The three editors were not concerned about accuracy; they believed public interest in Fuller was temporary and that she would not survive as a historical figure. Even so, it was the best-selling biography of the decade and went through thirteen editions before the end of the century.

Walt Whitman published the innovative poetry collection "Leaves of Grass" in 1855 and sent a copy to Emerson for his opinion. Emerson responded positively, sending Whitman a flattering five-page letter in response. Emerson's approval helped the first edition of "Leaves of Grass" stir up significant interest and convinced Whitman to issue a second edition shortly thereafter. This edition quoted a phrase from Emerson's letter, printed in gold leaf on the cover: "I Greet You at the Beginning of a Great Career". Emerson took offense that this letter was made public and later was more critical of the work.

Ralph Waldo Emerson, in the summer of 1858, would venture into the great wilderness of upstate New York.

Joining him were nine of the most illustrious intellectuals ever to camp out in the Adirondacks to connect with nature: Louis Agassiz, James Russell Lowell, John Holmes, Horatio Woodman, Ebenezer Rockwell Hoar, Jeffries Wyman, Estes Howe, Amos Binney, and William James Stillman. Invited, but unable to make the trip for diverse reasons, were: Oliver Wendell Holmes, Henry Wadsworth Longfellow and Charles Eliot Norton, all members of the Saturday Club (Boston, Massachusetts).

This social club was mostly a literary membership that met the last Saturday of the month at the Boston Parker House Hotel (Omni Parker House). William James Stillman was a painter and founding editor of an art journal called the Crayon. Stillman was born and grew up in Schenectady which was just south of the Adirondack mountains. He would later travel there to paint the wilderness landscape and to fish and hunt. He would share his experiences in this wilderness to the members of the Saturday Club, raising their interest in this unknown region.

James Russell Lowell and William Stillman would lead the effort to organize a trip to the Adirondacks. They would begin their journey on August 2, 1858, traveling by train, steam boat, stagecoach and canoe guide boats. News that these cultured men were living like "Sacs and Sioux" in the wilderness appeared in newspapers across the nation. This would become known as the ""Philosophers Camp""

This event was a landmark in the 19th-century intellectual movement, linking nature with art and literature.

Although much has been written over many years by scholars and biographers of Emerson's life, little has been written of what has become known as the "Philosophers Camp". Yet, his epic poem "Adirondac" reads like a journal of his day to day detailed description of adventures in the wilderness with his fellow members of the Saturday Club. This two week camping excursion (1858 in the Adirondacks) brought him face to face with a true wilderness, something he spoke of in his essay "Nature" published in 1836. He said, "in the wilderness I find something more dear and connate than in streets or villages".

Emerson was staunchly opposed to slavery, but he did not appreciate being in the public limelight and was hesitant about lecturing on the subject. But in the years leading up to the Civil War, he did give a number of lectures, beginning as early as November, 1837. A number of his friends and family members were more active abolitionists than he, at first, but from 1844 on, he more actively opposed slavery. He gave a number of speeches and lectures, and welcomed John Brown to his home during Brown's visits to Concord. He voted for Abraham Lincoln in 1860, but was disappointed that Lincoln was more concerned about preserving the Union than eliminating slavery outright. Once the American Civil War broke out, Emerson made it clear that he believed in immediate emancipation of the slaves.

Around this time, in 1860, Emerson published "The Conduct of Life", his seventh collection of essays. It "grappled with some of the thorniest issues of the moment," and "his experience in the abolition ranks is a telling influence in his conclusions." In these essays Emerson strongly embraced the idea of war as a means of national rebirth: "Civil war, national bankruptcy, or revolution, [are] more rich in the central tones than languid years of prosperity."

Emerson visited Washington, D.C, at the end of January 1862. He gave a public lecture at the Smithsonian on January 31, 1862, and declared:, "The South calls slavery an institution ... I call it destitution ... Emancipation is the demand of civilization". The next day, February 1, his friend Charles Sumner took him to meet Lincoln at the White House. Lincoln was familiar with Emerson's work, having previously seen him lecture. Emerson's misgivings about Lincoln began to soften after this meeting. In 1865, he spoke at a memorial service held for Lincoln in Concord: "Old as history is, and manifold as are its tragedies, I doubt if any death has caused so much pain as this has caused, or will have caused, on its announcement." Emerson also met a number of high-ranking government officials, including Salmon P. Chase, the secretary of the treasury; Edward Bates, the attorney general; Edwin M. Stanton, the secretary of war; Gideon Welles, the secretary of the navy; and William Seward, the secretary of state.

On May 6, 1862, Emerson's protÃ©gÃ© Henry David Thoreau died of tuberculosis at the age of 44. Emerson delivered his eulogy. He often referred to Thoreau as his best friend, despite a falling-out that began in 1849 after Thoreau published "A Week on the Concord and Merrimack Rivers". Another friend, Nathaniel Hawthorne, died two years after Thoreau, in 1864. Emerson served as a pallbearer when Hawthorne was buried in Concord, as Emerson wrote, "in a pomp of sunshine and verdure".

He was elected a Fellow of the American Academy of Arts and Sciences in 1864.

Starting in 1867, Emerson's health began declining; he wrote much less in his journals. Beginning as early as the summer of 1871 or in the spring of 1872, he started experiencing memory problems and suffered from aphasia. By the end of the decade, he forgot his own name at times and, when anyone asked how he felt, he responded, "Quite well; I have lost my mental faculties, but am perfectly well".

In the spring of 1871, Emerson took a trip on the transcontinental railroad, barely two years after its completion. Along the way and in California he met a number of dignitaries, including Brigham Young during a stopover in Salt Lake City. Part of his California visit included a trip to Yosemite, and while there he met a young and unknown John Muir, a signature event in Muir's career.

Emerson's Concord home caught fire on July 24, 1872. He called for help from neighbors and, giving up on putting out the flames, all tried to save as many objects as possible. The fire was put out by Ephraim Bull Jr., the one-armed son of Ephraim Wales Bull. Donations were collected by friends to help the Emersons rebuild, including $5,000 gathered by Francis Cabot Lowell, another $10,000 collected by LeBaron Russell Briggs, and a personal donation of $1,000 from George Bancroft. Support for shelter was offered as well; though the Emersons ended up staying with family at the Old Manse, invitations came from Anne Lynch Botta, James Elliot Cabot, James Thomas Fields and Annie Adams Fields. The fire marked an end to Emerson's serious lecturing career; from then on, he would lecture only on special occasions and only in front of familiar audiences.

While the house was being rebuilt, Emerson took a trip to England, continental Europe, and Egypt. He left on October 23, 1872, along with his daughter Ellen while his wife Lidian spent time at the Old Manse and with friends. Emerson and his daughter Ellen returned to the United States on the ship "Olympus" along with friend Charles Eliot Norton on April 15, 1873. Emerson's return to Concord was celebrated by the town and school was canceled that day.

In late 1874, Emerson published an anthology of poetry called "Parnassus", which included poems by Anna Laetitia Barbauld, Julia Caroline Dorr, Jean Ingelow, Lucy Larcom, Jones Very, as well as Thoreau and several others. The anthology was originally prepared as early as the fall of 1871 but was delayed when the publishers asked for revisions.

The problems with his memory had become embarrassing to Emerson and he ceased his public appearances by 1879. As Holmes wrote, "Emerson is afraid to trust himself in society much, on account of the failure of his memory and the great difficulty he finds in getting the words he wants. It is painful to witness his embarrassment at times". On April 21, 1882, Emerson was found to be suffering from pneumonia. He died six days later. Emerson is buried in Sleepy Hollow Cemetery, Concord, Massachusetts. He was placed in his coffin wearing a white robe given by the American sculptor Daniel Chester French.

Emerson's religious views were often considered radical at the time. He believed that all things are connected to God and, therefore, all things are divine. Critics believed that Emerson was removing the central God figure; as Henry Ware Jr. said, Emerson was in danger of taking away "the Father of the Universe" and leaving "but a company of children in an orphan asylum". Emerson was partly influenced by German philosophy and Biblical criticism. His views, the basis of Transcendentalism, suggested that God does not have to reveal the truth but that the truth could be intuitively experienced directly from nature. When asked his religious belief, Emerson stated, "I am more of a Quaker than anything else. I believe in the 'still, small voice,' and that voice is Christ within us."

Emerson did not become an ardent abolitionist until 1844, though his journals show he was concerned with slavery beginning in his youth, even dreaming about helping to free slaves. In June 1856, shortly after Charles Sumner, a United States Senator, was beaten for his staunch abolitionist views, Emerson lamented that he himself was not as committed to the cause. He wrote, "There are men who as soon as they are born take a bee-line to the axe of the inquisitor. ... Wonderful the way in which we are saved by this unfailing supply of the moral element". After Sumner's attack, Emerson began to speak out about slavery. "I think we must get rid of slavery, or we must get rid of freedom", he said at a meeting at Concord that summer. Emerson used slavery as an example of a human injustice, especially in his role as a minister. In early 1838, provoked by the murder of an abolitionist publisher from Alton, Illinois named Elijah Parish Lovejoy, Emerson gave his first public antislavery address. As he said, "It is but the other day that the brave Lovejoy gave his breast to the bullets of a mob, for the rights of free speech and opinion, and died when it was better not to live". John Quincy Adams said the mob-murder of Lovejoy "sent a shock as of any earthquake throughout this continent". However, Emerson maintained that reform would be achieved through moral agreement rather than by militant action. By August 1, 1844, at a lecture in Concord, he stated more clearly his support for the abolitionist movement: "We are indebted mainly to this movement, and to the continuers of it, for the popular discussion of every point of practical ethics".

Emerson is often known as one of the most liberal democratic thinkers of his time who believed that through the democratic process, slavery should be abolished. While being an avid abolitionist who was known for his criticism of the legality of slavery, Emerson struggled with the implications of race. His usual liberal leanings did not clearly translate when it came to believing that all races had equal capability or function, which was a common conception for the period in which he lived. Many critics believe that it was his views on race that inhibited him from becoming an abolitionist earlier in his life and also inhibited him from being more active in the antislavery movement. Much of his early life, he was silent on the topic of race and slavery. Not until he was well into his 30s did Emerson begin to publish writings on race and slavery, and not until he was in his late 40s and 50s did he became known as an antislavery activist.

During his early life, Emerson seems to develop a hierarchy of races based on faculty to reason or rather, whether African slaves were distinguishably equal to white men based on their ability to reason. In a journal entry written in 1822, Emerson wrote about a personal observation: "It can hardly be true that the difference lies in the attribute of reason. I saw ten, twenty, a hundred large lipped, lowbrowed black men in the streets who, except in the mere matter of language, did not exceed the sagacity of the elephant. Now is it true that these were created superior to this wise animal, and designed to control it? And in comparison with the highest orders of men, the Africans will stand so low as to make the difference which subsists between themselves & the sagacious beasts inconsiderable."

As with many supporters of slavery, during his early years, Emerson seems to have thought that the faculties of African slaves were not equal to their white owners. But this belief in racial inferiorities did not make Emerson a supporter of slavery. Emerson wrote later that year that "No ingenious sophistry can ever reconcile the unperverted mind to the pardon of Slavery; nothing but tremendous familiarity, and the bias of private interest". Emerson saw the removal of people from their homeland, the treatment of slaves, and the self-seeking benefactors of slaves as gross injustices. For Emerson, slavery was a moral issue, while superiority of the races was an issue he tried to analyze from a scientific perspective based what he believed to be inherited traits.

Emerson saw himself as a man of "Saxon descent". In a speech given in 1835 titled "Permanent Traits of the English National Genius", he said, "The inhabitants of the United States, especially of the Northern portion, are descended from the people of England and have inherited the traits of their national character". He saw direct ties between race based on national identity and the inherent nature of the human being. White Americans who were native-born in the United States and of English ancestry were categorized by him as a separate "race", which he thought had a position of being superior to other nations. His idea of race was based on a shared culture, environment, and history. He believed that native-born Americans of English descent were superior to European immigrants, including the Irish, French, and Germans, and also as being superior to English people from England, whom he considered a close second and the only really comparable group.

Later in his life, Emerson's ideas on race changed when he became more involved in the abolitionist movement while at the same time he began to more thoroughly analyze the philosophical implications of race and racial hierarchies. His beliefs shifted focus to the potential outcomes of racial conflicts. Emerson's racial views were closely related to his views on nationalism and national superiority, specifically that of the Saxons of ancient England, which was a common view in the United States of that time. Emerson used contemporary theories of race and natural science to support a theory of race development. He believed that the current political battle and the current enslavement of other races was an inevitable racial struggle, one that would result in the inevitable union of the United States. Such conflicts were necessary for the dialectic of change that would eventually allow the progress of the nation. In much of his later work, Emerson seems to allow the notion that different races will eventually mix in America. This hybridization process would lead to a superior race that would be to the advantage of the superiority of the United States.

Emerson was a supporter of the spread of community libraries in the 19th century, having this to say of them: "Consider what you have in the smallest chosen library. A company of the wisest and wittiest men that could be picked out of all civil countries, in a thousand years, have set in best order the results of their learning and wisdom."

Emerson may have had erotic thoughts about at least one man. During his early years at Harvard, he found himself attracted to a young freshman named Martin Gay about whom he wrote sexually charged poetry. He also had a number of romantic interests in various women throughout his life, such as Anna Barker and Caroline Sturgis.

As a lecturer and orator, Emersonânicknamed the Sage of Concordâbecame the leading voice of intellectual culture in the United States. James Russell Lowell, editor of the "Atlantic Monthly" and the "North American Review", commented in his book "My Study Windows" (1871), that Emerson was not only the "most steadily attractive lecturer in America," but also "one of the pioneers of the lecturing system." Herman Melville, who had met Emerson in 1849, originally thought he had "a defect in the region of the heart" and a "self-conceit so intensely intellectual that at first one hesitates to call it by its right name", though he later admitted Emerson was "a great man". Theodore Parker, a minister and transcendentalist, noted Emerson's ability to influence and inspire others: "the brilliant genius of Emerson rose in the winter nights, and hung over Boston, drawing the eyes of ingenuous young people to look up to that great new star, a beauty and a mystery, which charmed for the moment, while it gave also perennial inspiration, as it led them forward along new paths, and towards new hopes".

Emerson's work not only influenced his contemporaries, such as Walt Whitman and Henry David Thoreau, but would continue to influence thinkers and writers in the United States and around the world down to the present. Notable thinkers who recognize Emerson's influence include Nietzsche and William James, Emerson's godson. There is little disagreement that Emerson was the most influential writer of 19th-century America, though these days he is largely the concern of scholars. Walt Whitman, Henry David Thoreau and William James were all positive Emersonians, while Herman Melville, Nathaniel Hawthorne and Henry James were Emersonians in denialâwhile they set themselves in opposition to the sage, there was no escaping his influence. To T. S. Eliot, Emerson's essays were an "encumbrance". Waldo the Sage was eclipsed from 1914 until 1965, when he returned to shine, after surviving in the work of major American poets like Robert Frost, Wallace Stevens and Hart Crane.

In his book "The American Religion", Harold Bloom repeatedly refers to Emerson as "The prophet of the American Religion", which in the context of the book refers to indigenously American religions such as Mormonism and Christian Science, which arose largely in Emerson's lifetime, but also to mainline Protestant churches that Bloom says have become in the United States more gnostic than their European counterparts. In "The Western Canon", Bloom compares Emerson to Michel de Montaigne: "The only equivalent reading experience that I know is to reread endlessly in the notebooks and journals of Ralph Waldo Emerson, the American version of Montaigne." Several of Emerson's poems were included in Bloom's "The Best Poems of the English Language", although he wrote that none of the poems are as outstanding as the best of Emerson's essays, which Bloom listed as "Self-Reliance", "Circles", "Experience", and "nearly all of "Conduct of Life"". In his belief that line lengths, rhythms, and phrases are determined by breath, Emerson's poetry foreshadowed the theories of Charles Olson.


Collections

Individual essays

Poems

Letters






</doc>
<doc id="26204" url="https://en.wikipedia.org/wiki?curid=26204" title="Women in Judaism">
Women in Judaism

The role(s) of women in Judaism is determined by the Hebrew Bible, the Oral Law (the corpus of rabbinic literature), by custom, and by cultural factors. Although the Hebrew Bible and rabbinic literature mention various female role models, religious law treats women differently in various circumstances.

Gender has a bearing on familial lines: In traditional Judaism, Jewishness is passed down through the mother, although the father's name is used to describe sons and daughters in the Torah, e. g., "Dinah, daughter of Jacob".

The status of Levi is only given to a Jewish male descended patrilineally from Levi; likewise a Kohen descends from Aharon, the first Kohen. A Bat-Kohen or Bat-Levi has that status from her Jewish father with the corresponding HaKohen/HaLevi title.

Relatively few women are mentioned in the Bible by name and role, suggesting that they were rarely allowed to navigate the dominant public culture in the way their male counterparts were. There are a number of exceptions to this rule, including the Matriarchs Sarah, Rebecca, Rachel, and Leah, Miriam the prophetess, Deborah the Judge, Huldah the prophetess, Abigail, who married David, Rahab, and Esther. A common phenomenon in the bible is the pivotal role that women take in subverting man-made power structures. The result is often a more just outcome than what would have taken place under ordinary circumstances. These women did not meet with sufficient opposition to stifle their passion for the relatively public role they had. Today, many of them are considered foundational by feminists because of the insights they provide into the lives of Jewish women during those times, albeit as notable examples of women who broke the male dominance of historical documentation of the time compared to the poor documentation of most women's lives.

According to Jewish tradition, a covenant was formed between the Israelites and the God of Abraham at Mount Sinai. The Torah relates that both Israelite men and Israelite women were present at Sinai; however, the covenant was worded in such a way that it bound men to act upon its requirements, and to ensure that the members of their household (wives, children, and slaves) met these requirements as well. In this sense, the covenant bound women as well, though indirectly.

Marriage and family law in biblical times favored men over women. For example, a husband could divorce a wife if he chose to, but a wife could not divorce a husband without his consent. The practice of levirate marriage applied to widows of childless deceased husbands, not to widowers of childless deceased wives; though, if either he or she did not consent to the marriage, a different ceremony called "chalitza" is done instead, which basically involves the widow's removing her brother-in-law's shoe, spitting in front of him, and proclaiming, "This is what happens to someone who will not build his brother's house!" Laws concerning the loss of female virginity had no male equivalent. Many of these laws, such as levirate marriage, are no longer practiced in Judaism. These and other gender differences found in the Torah suggest that biblical society viewed continuity, property, and family unity as paramount; however, they also suggest that women were subordinate to men during biblical times. Men were required to perform some specific obligations for their wives, but these often reinforced the gendered roles in the culture of the time. These included the provision of clothing, food, and sexual relations to their wives.

Women also had a role in ritual life. Women (as well as men) were required to make a pilgrimage to the Temple in Jerusalem once a year (men each of the three main festivals if they could) and offer the Passover sacrifice. They would also do so on special occasions in their lives such as giving a "todah" ("thanksgiving") offering after childbirth. Hence, they participated in many of the major public religious roles that non-Levitical men could, albeit less often and on a somewhat smaller and generally more discreet scale.

According to Jewish tradition, Michal, the daughter of Saul and David's first wife, accepted the commandments of tefillin and tzitzit although these requirements applied only to men. Many of the mitzvot that applied to men applied to women as well; however, women were usually exempt from positive time-bound commandments (requirements to perform a duty at a specific time, as opposed to requirements to perform a duty at any time or requirements to abstain from an act). There are two prominent theories about why this is: pragmatism (because the role of women in household duties consumes their time) and spirituality (because according to some traditions, "women have superior inherent spiritual wisdom", known as bina, that makes them less dependent than men on the performance of timely religious practices to retain a strong spiritual connection to God).

Women depended on men economically. Women generally did not own property except in the rare case of inheriting land from a father who did not bear sons. Even "in such cases, women would be required to remarry within the tribe so as not to reduce its land holdings".

Women are required by "halacha" to do all negative "mitzvot" (i. e., commandments that prohibit action such as "Thou shalt not commit adultery"), but they are excused from doing most time-bound, positive "mitzvot" (i. e., commandments that proscribe ritual action that must be done at certain times such as hearing a shofar on Rosh Hashanah). A woman would not, however, be prohibited from doing a "mitzvah" from which she was excused. "Halacha" also provides women with material and emotional protections that most non-Jewish women did not enjoy during the first millennium of the Common Era. The penal and civil law of the time treated men and women equally.

There is evidence that, at least among the elite, women were educated in the Bible and in "halacha". The daughter of a scholar was considered a good prospect for marriage in part because of her education. There are stories in the Talmud about women whose husbands died or were exiled and yet were still able to educate their children because of their own level of learning.

Classical Jewish rabbinical literature contains quotes that may be seen as both laudatory and derogatory of women. The Talmud states that:

While few women are mentioned by name in rabbinic literature, and none are known to have authored a rabbinic work, those who are mentioned are portrayed as having a strong influence on their husbands. Occasionally they have a public persona. Examples are Bruriah, the wife of the Tanna Rabbi Meir; Rachel, wife of Rabbi Akiva; and Yalta, the wife of Rabbi Nachman. Eleazar ben Arach's wife Ima Shalom counselled her husband in assuming leadership over the Sanhedrin. When Eleazar ben Arach was asked to assume the role of "Nasi" ("Prince" or President of the Sanhedrin), he replied that he must first take counsel with his wife, which he did.

Since Jews were seen as second-class citizens in the Christian and Muslim world, it was even harder for Jewish women to establish their own status. Avraham Grossman argues in his book, "Pious and Rebellious: Jewish Women in Medieval Europe", that three factors affected how Jewish women were perceived by the society around them: "the biblical and talmudic heritage; the situation in the non-Jewish society within which the Jews lived and functioned; and the economic status of the Jews, including the woman's role in supporting the family." Grossman uses all three factors to argue that women's status overall during this period actually rose.

During the Middle Ages, there was a conflict between Judaism's lofty religious expectations of women and the reality of society in which these Jewish women lived; this is similar to the lives of Christian women in the same period. This prompted the kabbalistic work "Sefer Hakanah" to demand that women fulfill the "mitzvot" in a way that would be equal to men. There is evidence that in some communities of Ashkenaz in the 15th century, the wife of the rabbi wore "tzitzit" just like her husband.

Religious developments during the medieval period included relaxation on prohibitions against teaching women Torah, and the rise of women's prayer groups. One place that women participated in Jewish practices publicly was the synagogue. Women probably learned how to read the liturgy in Hebrew.

According to John Bowker, traditionally, Jewish "men and women pray separately. This goes back to ancient times when women could go only as far as the second court of the Temple." In most synagogues, the women were given their own section, most likely a balcony; some synagogues had a separate building.

Separation from the men was created by the Rabbis in the Mishnah and the Talmud. The reasoning behind the Halacha was that a woman and her body would distract men and give them impure thoughts during prayer. Due to this rabbinical interpretation, scholars have seen the women's role in the synagogue as limited and sometimes even non-existent. However, recent research has shown that women actually had a larger role in the synagogue and the community at large. Women usually attended synagogue, for example, on the Shabbat and the holidays.

Depending on the location of the women in the synagogue, they may have followed the same service as the men or they conducted their own services. Since the synagogues were large, there would be a designated woman who would be able to follow the cantor and repeat the prayers aloud for the women. Women had always attended services on Shabbat and holidays, but beginning in the eleventh century, women became more involved in the synagogue and its rituals. Women sitting separately from the men became a norm in synagogues around the beginning of the thirteenth century. Women, however, did much more than pray in the synagogue. One of the main jobs for women was to beautify the building. There are Torah ark curtains and Torah covers that women sewed and survive today. The synagogue was a communal place for both men and women where worship, learning and community activities occurred.

The rise and increasing popularity of Kabbalah, which emphasized the shechinah and female aspects of the divine presence and human-divine relationship, and which saw marriage as a holy covenant between partners rather than a civil contract, had great influence. Kabbalists explained the phenomenon of menstruation as expressions of the demonic or sinful character of the menstruant. These changes were accompanied by increased pietistic strictures, including greater requirements for modest dress, and greater strictures during the period of menstruation. At the same time, there was a rise in philosophical and midrashic interpretations depicting women in a negative light, emphasizing a duality between matter and spirit in which femininity was associated, negatively, with earth and matter. The gentile society was also seen as a negative influence on the Jewish community. For example, it seems that Jews would analyze the modesty of their non-Jewish neighbors before officially moving into a new community because they knew that their children would be influenced by the local gentiles.

After the expulsion of the Jews from Spain in 1492, women became virtually the only source of Jewish ritual and tradition in the Catholic world in a phenomenon known as crypto-Judaism. Crypto-Jewish women would slaughter their own animals and made sure to keep as many of the Jewish dietary laws and life cycle rituals as possible without raising suspicion. Occasionally, these women were prosecuted by Inquisition officials for suspicious behavior such as lighting candles to honor the Sabbath or refusing to eat pork when it was offered to them. The Inquisition targeted crypto-Jewish women at least as much as it targeted crypto-Jewish men because women were accused of perpetuating Jewish tradition while men were merely permitting their wives and daughters to organize the household in this manner.

Marriage, domestic violence and divorce are all topics discussed by Jewish sages of the Medieval world. Marriage is an important institution in Judaism (see Marriage in Judaism). The sages of this period discussed this topic at length.

Rabbeinu Gershom instituted a rabbinic decree (Takkanah) prohibiting polygyny among Ashkenazic Jews. At the time, Sephardic and Mizrahi Jews did not recognize the validity of the ban.

The rabbis instituted legal methods to enable women to petition a rabbinical court to compel a divorce. Maimonides ruled that a woman who found her husband "repugnant" could ask a court to compel a divorce by flogging the recalcitrant husband "because she is not like a captive, to be subjected to intercourse with one who is hateful to her". Furthermore, Maimonides ruled that a woman may "consider herself as divorced and remarry" if her husband became absent for three years or more. This was to prevent women married to traveling merchants from becoming an agunah if the husband never returned.

The rabbis also instituted and tightened prohibitions on domestic violence. Rabbi Peretz ben Elijah ruled, "The cry of the daughters of our people has been heard concerning the sons of Israel who raise their hands to strike their wives. Yet who has given a husband the authority to beat his wife?" Rabbi Meir of Rothenberg ruled that, "For it is the way of the Gentiles to behave thus, but Heaven forbid that any Jew should do so. And one who beats his wife is to be excommunicated and banned and beaten." Rabbi Meir of Rothenberg also ruled that a battered wife could petition a rabbinical court to compel a husband to grant a divorce, with a monetary fine owed to her on top of the regular ketubah money. These rulings occurred in the midst of societies where wife-beating was legally sanctioned and routine.

Jewish women had a limited education. They were taught to read, write, run a household. They were also given some education in religious law that was essential to their daily lives, such as keeping kosher. Both Christian and Jewish girls were educated in the home. Although Christian girls may have had a male or female tutor, most Jewish girls had a female tutor. Higher learning was uncommon for women. (See Female Education in the Medieval Period). There are more sources of education for Jewish women living in Muslim-controlled lands. Middle Eastern Jewry, on the other hand, had an abundance of female literates. The Cairo Geniza is filled with correspondences written (sometimes dictated) between family members and spouses. Many of these letters are pious and poetic and express a desire to be in closer or more frequent contact with a loved one that is far enough away to only be reached by written correspondence. There are also records of wills and other personal legal documents as well as written petitions to officials in cases of spouse spousal abuse or other conflicts between family members written or dictated by women.

Many women gained enough education to help their husbands out in business or even hold their own. Just like Christian women who ran their own business, Jewish women were engaged in their own occupations as well as helping their husbands. Jewish women seem to have lent money to Christian women throughout Europe. Women were also copyists, midwives, spinners, and weavers.

Bruriah is one of several women quoted as a sage in the Talmud. She was the wife of the Tanna Rabbi Meir and the daughter of Rabbi Hananiah Ben Teradion, who is listed as one of the "Ten Martyrs". She is greatly admired for her breadth of knowledge in matters pertaining to both halachah and aggadah, and is said to have learned from the rabbis 300 halachot on a single cloudy day (Tractate Pesachim 62b). Her parents were put to death by the Romans for teaching Torah, but she carried on their legacy.

Bruriah was very involved in the halachic discussions of her time, and even challenges her father on a matter of ritual purity (Tosefta Keilim Kamma 4:9). Her comments there are praised by Rabbi Judah ben Bava. In another instance, Rabbi Joshua praises her intervention in a debate between Rabbi Tarfon and the sages, saying "Bruriah has spoken correctly" (Tosefta Keilim Metzia 1:3).
She is mentioned at least four times in the Talmudic discourse regarding her law decrees first Babylonian Talmud Berakhot 10a then in Tosefta Pesahim 62b in Babylonian Talmud Eruvin 53bâ54a and Babylonian Talmud Avodah Zarah 18b. In one case, she gave an interpretation of the religious sense (to "paskin din") of "klaustra" a rare Greek word referring to a "door-bolt" in the Talmud. However, Rabbi Yehudah Hanassi did not believe women could be credited with "paskining din". Because, as the saying goes, 'do not speak too much to women' (Tannah Rabbi Jesse the Galilean), he credited the law to Rabbi Joshua, who may be considered to have been her father.

Bruriah however was actually remembered with great respect in the Talmud where she is lauded to have been reputed as such a genius as to study "three hundred Halachot from three hundred sages in just one day" (Pesachim 62b). This praise was in clear contradiction of the common injunction against women studying the Torah.

Rashi had no sons, and taught the Mishnah and Talmud to his daughters, until they knew it by heart, as Jewish tradition teaches; they then transferred their knowledge of original Mishnah commentary to the Ashkenazi men of the next generation.

When Maimonides wrote responsa concerning women, he tended to elevate their status above what was common practice in the Middle Ages. For example, Maimonides permitted women to study Torah, despite the fact that other legal opinions from his time and before did not.

The Hida, wrote (Tuv Ayin, no. 4) woman should study Mishnah only if they do want to.'We cannot force a woman to learn, like we do to boys'. However, if she wants to learn, then not only may she do so on her own, but men may teach her from the start, and she can then teach other women if they so choose. According to Hida, the prohibition of teaching women does not apply to a motivated woman or girl. Other Mizrahi Rabbis disputed this with him.

His response to detractors was that indeed, in truth, there is a prohibition against teaching Mishnah to any studentâmale or femaleâwho one knows is not properly prepared and motivated. This response referred to a "talmid she-eino hagun" (Shulhan Arukh, Yoreh De'ah 246:7). Babylonian Talmud Berakhos 28a which relates that Rabban Gam(a)liel would announce that any student who is not pure enough so that 'his outer self is like his inner self' may not enter the study hall. While this approach, requiring absolute purity, was rejected by other ancient Rabbis, for example 'he who is not for the name of God, will become for the name of God', and a middle approach was adopted by Jews as standard. If one has knowledge that a particular Mishnayot student is definitely bad then he may not be taught. Gam(a)liel claimed that 'it seems that for women there is a higher standard and she must be motivated in order to have this permission to learn' in his response to the Mizrahi tradition.

One of the most important Ashkenazic rabbanim of the past century, Yisrael Meir Kagan, known popularly as the "Chofetz Chaim", favored Torah education for girls to counteract the French "finishing schools" prevalent in his day for the daughters of the bourgeoisie.

Rabbi Yoseph Solovetchik "amended" the teachings of The Hafetz Haim. Rabbi Solovetchik taught that all religious Ashkenazi Jews with the exception of hard-line Hasidim, not merely should, or solely if they show motivation, but must teach their female children Gemarah like the boy school children. He, among others, fully institutionalized the teaching of Mishnah and Talmud to girls, from an autobiography on him by Rabbi Mayor Twersky called "A Glimpse of the Rav" in R. Menachem Genack ed., Rabbi Joseph B. Soloveitchik: Man of Halacha, Man of Faith, page 113: 

Orthodox Judaism is based on gendered understandings of Jewish practice - i. e., that there are different roles for men and women in religious life. There are different opinions among Orthodox Jews concerning these differences. Most claim that men and women have complementary, yet different, roles in religious life, resulting in different religious obligations. Others believe that some of these differences are not a reflection of religious law, but rather of cultural, social, and historical causes. In the area of education, women were historically exempted from any study beyond an understanding of the practical aspects of Torah, and the rules necessary in running a Jewish household, both of which they have an obligation to learn. Until the twentieth century, women were often discouraged from learning Talmud and other advanced Jewish texts. In the past 100 years, Orthodox Jewish education for women has advanced tremendously.

There have been many areas in which Orthodox women have been working towards change within religious life over the past 20 years: promoting advanced women's learning and scholarship, promoting women's ritual inclusion in synagogue, promoting women's communal and religious leadership, and more. Women have been advancing change, despite often vocal opposition by rabbinic leaders. Some Orthodox rabbis try to discount changes by claiming that women are motivated by sociological reasons, and not by "true" religious motivation. For example, Orthodox, Haredi, and Hasidic rabbis discourage women from wearing a kippah, tallit, or tefillin.

In most Orthodox synagogues, women do not give a "d'var Torah" (brief discourse, generally on the weekly Torah portion) after or between services. Furthermore, many Orthodox synagogues have physical barriers (known as a "mechitzot") dividing the left and right sides of the synagogue (rather than the usual division between the main floor and large balconies), with the women's section on one side, and the men's section on the other. Technically, a "mechitzah" of over four feet or so (ten handbreadths) suffices, even if the men can see the women, though it is not preferable. A typical "mechitzah" consists of wheeled wooden panels, often topped with one-way glass to allow women to view the Torah reading.

Although Judaism prescribes modesty for both men and women, the importance of modesty in dress and conduct is particularly stressed among women and girls in Orthodox society. Most Orthodox women only wear skirts, and avoid wearing trousers, and most married Orthodox women cover their hair with a scarf ("tichel"), snood, hat, beret, or wig.

In accordance with Jewish Law, Orthodox Jewish women refrain from bodily contact with their husbands while they are menstruating, and for a period of 7 clean days after menstruating, and after the birth of a child. The Israeli Rabbinate has recently approved women acting as "yoatzot", halakhic advisers on sensitive personal matters such as family purity.

Rabbi Joseph B. Soloveitchik, a leader of profound influence in modern Orthodoxy in the United States, discouraged women from serving as presidents of synagogues or any other official positions of leadership, from performing other mitzvot (commandments) traditionally performed by males exclusively, such as wearing a tallit or tefillin. (However, tefilllin are intended for men partly because the tefillin help keep them from thinking impure thoughts. Women are thought not to need help with this.) Soloveitchik wrote that while women do not lack the capability to perform such acts, there is no "mesorah" (Jewish tradition) that permits it. In making his decision, he relied upon Jewish oral law, including a mishnah in Chulin 2a and a Beit Yoseph in the Tur Yoreh Deah stating that a woman can perform a specific official communal service for her own needs, but not those of others.

Women's issues garnered more interest with the advent of feminism. Many Modern Orthodox Jewish women and Modern Orthodox rabbis sought to provide greater and more advanced Jewish education for women. Since most Modern Orthodox women attend college, and many receive advanced degrees in a variety of fields, Modern Orthodox communities promote women's secular education. A few Modern Orthodox Synagogues have women serving as clergy, including Gilah Kletenik at Congregation Kehilath Jeshurun. In 2013, Yeshivat Maharat, located in the United States, became the first Orthodox institution to consecrate female clergy. The graduates of Yeshivat Maharat did not call themselves "rabbis". The title they were given is "maharat". However, in 2015, Yaffa Epstein was ordained as Rabba by Yeshivat Maharat. Also in 2015, Lila Kagedan was ordained as Rabbi by that same organization, making her their first graduate to take the title "Rabbi".

In 2013, Malka Schaps became the first female Haredi dean at an Israeli university when she was appointed dean of Bar Ilan University's Faculty of Exact Sciences. Also in 2013, the first class of female halachic advisers trained to practice in the US graduated; they graduated from the North American branch of Nishmat's yoetzet halacha program in a ceremony at Congregation Sheartith Israel, Spanish and Portuguese Synagogue in Manhattan, and SAR High School in Riverdale, New York, began allowing girls to wrap tefillin during Shacharit-morning prayer in an all-female prayer group; it is probably the first Modern Orthodox high school in the U.S. to do so.

In 2014, the first-ever book of halachic decisions written by women who were ordained to serve as poskot (Idit Bartov and Anat Novoselsky) was published. The women were ordained by the municipal chief rabbi of Efrat, Rabbi Shlomo Riskin, after completing Midreshet Lindenbaum women's college's five-year ordination course in advanced studies in Jewish law, as well as passing examinations equivalent to the rabbinate's requirement for men.

In 2010, Sara Hurwitz became the first woman to ordained as a "Rabba", or female equivalent of a rabbi, when she started serving as an "Open Orthodox" spiritual leader at Riverdale, Bronx, New York On June 10, 2015, Dr. Meesh Hammer-Kossoy and Rahel Berkovits became the first two women to be ordained as Modern Orthodox Jewish Rabbas in Israel.

In June 2015, Lila Kagedan was ordained by Yeshivat Maharat and in keeping with newer policies, was given the freedom to choose her own title, and she chose to be addressed as "Rabbi". She officially became the first female Modern Orthodox rabbi in the United States of America when the Modern Orthodox Mount Freedom Jewish Center in Randolph, New Jersey hired her as a spiritual leader in January 2016. As of 2019, Kagedan is working as the rabbi at Walnut Street Synagogue.

In the fall of 2015, the Agudath Israel of America denounced moves to ordain women, and went even further, declaring Yeshivat Maharat, Yeshivat Chovevei Torah, Open Orthodoxy, and other affiliated entities to be similar to other dissident movements throughout Jewish history in having rejected basic tenets of Judaism.

Also in the fall of 2015, the Rabbinical Council of America passed a resolution which states, "RCA members with positions in Orthodox institutions may not ordain women into the Orthodox rabbinate, regardless of the title used; or hire or ratify the hiring of a woman into a rabbinic position at an Orthodox institution; or allow a title implying rabbinic ordination to be used by a teacher of Limudei Kodesh in an Orthodox institution."

Also in 2015, Jennie Rosenfeld became the first female Orthodox spiritual advisor in Israel. (Specifically, she became the spiritual advisor, also called manhiga ruchanit, for the community of Efrat.)

In 2016, it was announced that Ephraim Mirvis created the job of ma'ayan by which women would be advisers on Jewish law in the area of family purity and as adult educators in Orthodox synagogues. This requires a part-time training course for 18 months, which is the first such course in the United Kingdom. On August 23, 2016, Karmit Feintuch became the first woman in Jerusalem, Israel, to be hired as a Modern Orthodox "rabbanit" and serve as a spiritual leader.

In 2017, the Orthodox Union adopted a policy banning women from serving as clergy, from holding titles such as "rabbi", or from doing common clergy functions even without a title, in its congregations in the United States.

Separate Jewish women's prayer groups were a sanctioned custom among German Jews in the Middle Ages. The "Kol Bo" provides, in the laws for Tisha B'Av:

In Germany, in the 12th and 13th centuries, women's prayer groups were led by female cantors. Rabbi Eliezer of Worms, in his elegy for his wife Dulca, praised her for teaching the other women how to pray and embellishing the prayer with music. The gravestone of Urania of Worms, who died in 1275, contains the inscription "who sang "piyyutim" for the women with musical voice". In the Nurnberg Memorial Book, one Richenza was inscribed with the title "prayer leader of the women".

Orthodox women more recently began holding organized women's "tefila" (prayer) groups beginning in the 1970s. While no Orthodox legal authorities agree that women can form a "minyan" (prayer quorum) for the purpose of regular services, women in these groups read the prayers and study Torah. A number of leaders from all segments of Orthodox Judaism have commented on this issue, but it has had little, though growing, impact on Haredi and Sephardi Judaism. However, the emergence of this phenomenon has enmeshed Modern Orthodox Judaism in a debate which still continues today. There are three schools of thought on this issue:


In 2013, the Israeli Orthodox rabbinical organization Beit Hillel issued a halachic ruling which allows women, for the first time, to say the Kaddish prayer in memory of their deceased parents.

Traditionally, women are not generally permitted to serve as witnesses in an Orthodox Beit Din (rabbinical court), although they have recently been permitted to serve as "toanot" (advocates) in those courts. This limitation has exceptions which have required exploration under rabbinic law, as the role of women in society and the obligations of religious groups under external civil law have been subject to increasing recent scrutiny.

The recent case of Rabbi Mordecai Tendler, the first rabbi to be expelled from the Rabbinical Council of America following allegations of sexual harassment, illustrated the importance of clarification of Orthodox halakha in this area. Rabbi Tendler claimed that the tradition of exclusion of women's testimony should compel the RCA to disregard the allegations. He argued that since the testimony of a woman could not be admitted in Rabbinical court, there were no valid witnesses against him, and hence, the case for his expulsion had to be thrown out for lack of evidence. In a ruling of importance for Orthodox women's capacity for legal self-protection under Jewish law, Haredi Rabbi Benzion Wosner, writing on behalf of the "Shevet Levi" Beit Din (Rabbinical court) of Monsey, New York, identified sexual harassment cases as coming under a class of exceptions to the traditional exclusion, under which "even children or women" have not only a right, but an obligation, to testify, and can be relied upon by a rabbinical court as valid witnesses:

The Rabbinical Council of America, while initially relying on its own investigation, chose to rely on the Halakhic ruling of the Haredi Rabbinical body as authoritative in the situation.

Leaders of the Haredi community have been steadfast in their opposition to a change in the role of women, arguing that the religious and social constraints on women, as dictated by traditional Jewish texts, are timeless, and are not affected by contemporary social change. Many also argue that giving traditionally male roles to women will only detract from both women's and men's ability to lead truly fulfilling lives. Haredim have also sometimes perceived arguments for liberalization as in reality stemming from antagonism to Jewish law and beliefs generally, arguing that preserving faith requires resisting secular and "un-Jewish" ideas.

Modern Orthodox Judaism, particularly in its more liberal variants, has tended to look at proposed changes in the role of women on a specific, case-by-case basis, focusing on arguments regarding the religious and legal role of specific prayers, rituals and activities individually. Such arguments have tended to focus on cases where the Talmud and other traditional sources express multiple or more liberal viewpoints, particularly where the role of women in the past was arguably broader than in more recent times. Feminist advocates within Orthodoxy have tended to stay within the traditional legal process of argumentation, seeking a gradualist approach, and avoiding wholesale arguments against the religious tradition as such. Nevertheless, a growing Orthodox feminist movement seeks to address gender inequalities.

Agunot (Hebrew: "chained women") are women who wish to divorce their husbands, but whose husbands refuse to give them a Get (divorce document). The word can also refer to a woman whose husband disappeared and may or may not be dead. In Orthodox Judaism, only a man is able to give a get. In order to prevent the occurrence of the first type, many Jewish couples sign a Jewish prenuptial agreement, which is designed to force the husband to serve a get or else be reported to the Beth din (Hebrew: "Jewish court").

Although the position of Conservative Judaism toward women originally differed little from the Orthodox position, it has in recent years minimized legal and ritual differences between men and women. The Committee on Jewish Law and Standards (CJLS) of the Rabbinical Assembly has approved a number of decisions and responsa on this topic. These provide for women's active participation in areas such as:


A rabbi may or may not decide to adopt particular rulings for the congregation; thus, some Conservative congregations will be more or less egalitarian than others. However, there are other areas where legal differences remain between men and women, including:

A Conservative Jewish "ketuba" includes a clause that puts a husband and wife on more equal footing when it comes to marriage and divorce law within "halacha".

The CJLS recently reaffirmed the obligation of Conservative women to observe "niddah" (sexual abstinence during and after menstruation) and "mikvah" (ritual immersion) following menstruation, although somewhat liberalizing certain details. Such practices, while requirements of Conservative Judaism, are not widely observed among Conservative laity.

Prior to 1973, Conservative Judaism had more limited roles for women and was more similar to current Orthodoxy. However, there were some notable changes in favor of expanded roles for women in Conservative Judaism prior to 1973. In 1946, the new Silverman siddur changed the traditional words of thanking God for "not making me a woman", instead using words thanking God for "making me a free person." In 1955, the CJLS of the Rabbinical Assembly issued a decision that allowed women to have an aliyah at Torah-readings services.

In 1973, the CJLS of the Rabbinical Assembly voted, without issuing an opinion, that women could count in a minyan.

There was a special commission appointed by the Conservative movement to study the issue of ordaining women as rabbis, which met between 1977 and 1978, and consisted of eleven men and three women; the women were Marian Siner Gordon, an attorney, Rivkah Harris, an Assyriologist, and Francine Klagsbrun, a writer. In 1983, the Jewish Theological Seminary of America (JTSA) faculty voted, also without accompanying opinion, to ordain women as rabbis and as cantors. Paula Hyman, among others, took part in the vote as a member of the JTS faculty.

In 2002, the CJLS adapted a responsum by Rabbi David Fine, "Women and the Minyan", which provides an official religious-law foundation for women counting in a minyan and explains the current Conservative approach to the role of women in prayer. This responsum holds that although Jewish women do not traditionally have the same obligations as men, Conservative women have, as a collective whole, voluntarily undertaken them. Because of this collective undertaking, the Fine responsum holds that Conservative women are eligible to serve as agents and decision-makers for others. The responsum also holds that traditionally minded communities and individual women can opt out without being regarded by the Conservative movement as sinning. By adopting this responsum, the CJLS found itself in a position to provide a considered Jewish-law justification for its egalitarian practices, without having to rely on potentially unconvincing arguments, undermine the religious importance of community and clergy, ask individual women intrusive questions, repudiate the "halakhic" tradition, or label women following traditional practices as sinners.

In 2006, the CJLS adopted three responsa on the subject of niddah, which reaffirmed an obligation of Conservative women to abstain from sexual relations during and following menstruation and to immerse in a mikvah prior to resumption, while liberalizing observance requirements including shortening the length of the niddah period, lifting restrictions on non-sexual contact during niddah, and reducing the circumstances under which spotting and similar conditions would mandate abstinence.

In all cases, continuing the Orthodox approach was also upheld as an option. Individual Conservative rabbis and synagogues are not required to adopt any of these changes, and a small number have adopted none of them.

Prior to 1973, Conservative approaches to change were generally on an individual, case-by-case basis. Between 1973 and 2002, the Conservative movement adapted changes through its official organizations, but without issuing explanatory opinions. Since 2002, the Conservative movement has coalesced around a single across-the board approach to the role of women in Jewish law.

In 1973, 1983, and 1993, individual rabbis and professors issued six major opinions which influenced change in the Conservative approach, the first and second Sigal, Blumenthal, Rabinowitz, and Roth responsa, and the Hauptman article. These opinions sought to provide for a wholesale shift in women's public roles through a single, comprehensive legal justification. Most such opinions based their positions on an argument that Jewish women always were, or have become, legally obligated to perform the same "mitzvot" as men and to do so in the same manner.

The first Sigal and the Blumenthal responsa were considered by the CJLS as part of its decision on prayer roles in 1973. They argued that women have always had the same obligations as men. The first Sigal responsum used the Talmud's general prayer obligation and examples of cases in which women were traditionally obligated to say specific prayers and inferred from them a public prayer obligation identical to that of men. The Blumenthal responsum extrapolated from a minority authority that a "minyan" could be formed with nine men and one woman in an emergency. The Committee on Jewish Law and Standards (CJLS) declined to adopt either responsum. Rabbi Siegel reported to the Rabbinical Assembly membership that many on the CJLS, while agreeing with the result, found the arguments unconvincing.

The Rabinowitz, Roth, and second Sigal responsa were considered by the JTSA faculty as part of its decision to ordain women as rabbis in 1983. The Rabbinowitz responsum sidestepped the issue of obligation, arguing that there is no longer a religious need for a community representative in prayer and hence there is no need to decide whether a woman can "halakhically" serve as one. The CJLS felt that an argument potentially undermining the value of community and clergy was unconvincing: "We should not be afraid to recognize that the function of clergy is to help our people connect with the holy." The Roth and second Sigal responsa accepted that time-bound "mitzvot" were traditionally optional for women, but argued that women in modern times could change their traditional roles. The Roth responsum argued that women could individually voluntarily assume the same obligations as men, and that women who do so (e. g., pray three times a day regularly) could count in a "minyan" and serve as agents. The JTSA accordingly required female rabbinical students wishing to train as rabbis to personally obligate themselves, but synagogue rabbis, unwilling to inquire into individual religiosity, found it impractical. The second Sigal responsum called for a "takkanah", or rabbinical edict, "that would serve as a "halakhic" ERA", overruling all non-egalitarian provisions in law or, in the alternative, a new approach to "halakhic" interpretation independent of legal precedents. The CJLS, unwilling to use either an intrusive approach or a repudiation of the traditional legal process as bases for action, did not adopt either and let the JTS faculty vote stand unexplained.

In 1993, Professor Judith Hauptman of JTS issued an influential paper arguing that women had historically always been obligated in prayer, using more detailed arguments than the Blumenthal and first Sigal responsa. The paper suggested that women who followed traditional practices were failing to meet their obligations. Rabbi Roth argued that Conservative Judaism should think twice before adopting a viewpoint labeling its most traditional and often most committed members as sinners. The issue was again dropped.

In 2002, the CJLS returned to the issue of justifying its actions regarding women's status, and adopted a single authoritative approach, the Fine responsum, as the definitive Conservative halakha on role-of-women issues. This responsum holds that although Jewish women do not traditionally have the same obligations as men, Conservative women have, as a collective whole, voluntarily undertaken them. Because of this collective undertaking, the Fine responsum holds that Conservative women are eligible to serve as agents and decision-makers for others. The Responsum also holds that traditionally minded communities and individual women can opt out without being regarded by the Conservative movement as sinning. By adopting this Responsum, the CJLS found itself in a position to provide a considered Jewish-law justification for its egalitarian practices, without having to rely on potentially unconvincing arguments, undermine the religious importance of community and clergy, ask individual women intrusive questions, repudiate the "halakhic" tradition, or label women following traditional practices as sinners.

Reform Judaism believes in the equality of men and women. The Reform movement rejects the idea that halakha (Jewish law) is the sole legitimate form of Jewish decision making, and holds that Jews can and must consider their conscience and ethical principles inherent in the Jewish tradition when deciding upon a right course of action. There is widespread consensus among Reform Jews that traditional distinctions between the role of men and women are antithetical to the deeper ethical principles of Judaism. This has enabled Reform communities to allow women to perform many rituals traditionally reserved for men, such as:

Concerns about intermarriage have also influenced the Reform Jewish position on gender. In 1983, the Central Conference of American Rabbis passed a resolution waiving the need for formal conversion for anyone with at least one Jewish parent who has made affirmative acts of Jewish identity. This departed from the traditional position requiring formal conversion to Judaism for children without a Jewish mother. The 1983 resolution of the American Reform movement has had a mixed reception in Reform Jewish communities outside of the United States. Most notably, the Israel Movement for Progressive Judaism has rejected patrilineal descent and requires formal conversion for anyone without a Jewish mother. As well, a joint Orthodox, Traditional, Conservative and Reform Bet Din formed in Denver, Colorado to promote uniform standards for conversion to Judaism was dissolved in 1983, due to that Reform resolution. However, in 2015 the majority of Britain's Assembly of Reform Rabbis voted in favor of a position paper proposing "that individuals who live a Jewish life, and who are patrilineally Jewish, can be welcomed into the Jewish community and confirmed as Jewish through an individual process". Britain's Assembly of Reform Rabbis stated that rabbis "would be able to take local decisions â ratified by the Beit Din â confirming Jewish status".

Liberal prayerbooks tend increasingly to avoid male-specific words and pronouns, seeking that all references to God in translations be made in gender-neutral language. For example, the UK Liberal movement's "Siddur Lev Chadash" (1995) does so, as does the UK Reform Movement's "Forms of Prayer" (2008). In Mishkan T'filah, the American Reform Jewish prayer book released in 2007, references to God as "He" have been removed, and whenever Jewish patriarchs are named (Abraham, Isaac, and Jacob), so also are the matriarchs (Sarah, Rebecca, Rachel, and Leah.) In 2015 the Reform Jewish High Holy Days prayer book Mishkan HaNefesh was released; it is intended as a companion to Mishkan T'filah. It includes a version of the High Holy Days prayer Avinu Malkeinu that refers to God as both "Loving Father" and "Compassionate Mother". Other notable changes are replacing a line from the Reform movement's earlier prayerbook, "Gates of Repentance", that mentioned the joy of a bride and groom specifically, with the line "rejoicing with couples under the chuppah [wedding canopy]", and adding a third, non-gendered option to the way worshippers are called to the Torah, offering "mibeit", Hebrew for "from the house of", in addition to the traditional "son of" or "daughter of".

In 2008, Stacy Offner became the first female vice president of the Union for Reform Judaism, a position she held for two years. In 2015, Daryl Messinger became the first female chair of the Union.

Reform Judaism generally holds that the various differences between the roles of men and women in traditional Jewish law are not relevant to modern conditions and not applicable today. Accordingly, there has been no need to develop legal arguments analogous to those made within the Orthodox and Conservative movements.

The equality of women and men is a central tenet and hallmark of Reconstructionist Judaism. From the beginning, Reconstructionist Jewish ritual allowed men and women to pray togetherâa decision based on egalitarian philosophy. It was on this basis that Rabbi Mordecai Kaplan called for the full equality of women and men, despite the obvious difficulties reconciling this stance with norms of traditional Jewish practice. The Reconstructionist Movement ordained women rabbis from the start. In 1968, women were accepted into the Reconstructionist Rabbinical College, under the leadership of Ira Eisenstein. The first ordained female Reconstructionist rabbi, Sandy Eisenberg Sasso, served as rabbi of the Manhattan Reconstructionist Congregation in 1976, and gained a pulpit in 1977 at Beth El Zedeck congregation in Indianapolis. Sandy Eisenberg Sasso was accepted without debate or subsequent controversy. In 2005, 24 out of the movement's 106 synagogues in the US had women as senior or assistant rabbis. In 2013 Rabbi Deborah Waxman was elected as the President of the Reconstructionist Rabbinical College. As the President, she is believed to be the first woman and first lesbian to lead a Jewish congregational union, and the first female rabbi and first lesbian to lead a Jewish seminary; the Reconstructionist Rabbinical College is both a congregational union and a seminary.

The Reconstructionist Community began including women in the minyan and allowing them to come up to the Torah for aliyot. They also continued the practice of bat mitzvah. Reconstructionist Judaism also allowed women to perform other traditional male tasks, such as serving as witnesses, leading services, public Torah reading, and wearing ritual prayer garments like kippot and tallitot. Female Reconstructionist rabbis have been instrumental in the creation of rituals, stories, and music that have begun to give women's experience a voice in Judaism. Most of the focus has been on rituals for life-cycle events. New ceremonies have been created for births, weddings, divorces, conversions, weaning, and the onset of menarche and menopause. The Reconstructionist movement as a whole has been committed to creating liturgy that is in consonance with gender equality and the celebration of women's lives. Another major step: The Federation of Reconstructionist Congregations has also developed educational programs that teach the full acceptance of lesbians, as well as rituals that affirm lesbian relationships. Reconstructionist rabbis officiate at same-sex weddings. Reconstructionist Judaism also allows openly LGBT men and women to be ordained as rabbis and cantors.

Several prominent members of the Reconstructionist community have focused on issues like domestic violence. Others have devoted energy to helping women gain the right of divorce in traditional Jewish communities. Many have spoken out for the right of Jewish women to pray aloud and read from the Torah at the Western Wall in Jerusalem, particularly members of the Women of the Wall group.

When the roles of women in religion change, there may also be changed roles for men. With their acceptance of patrilineal descent in 1979, the Reconstructionist Rabbinical Association supported the principle that a man can pass Judaism on to the next generation as well as a woman.

Jewish Renewal is a recent movement in Judaism which endeavors to reinvigorate modern Judaism with Kabbalistic, Hasidic, musical and meditative practices; it describes itself as "a worldwide, transdenominational movement grounded in Judaism's prophetic and mystical traditions". The Jewish Renewal movement ordains women as well as men as rabbis and cantors. Lynn Gottlieb became the first female rabbi in Jewish Renewal in 1981, and Avitall Gerstetter, who lives in Germany, became the first female cantor in Jewish Renewal (and the first female cantor in Germany) in 2002. In 2009 and 2012 respectively, OHALAH (Association of Rabbis for Jewish Renewal) issued a board statement and a resolution supporting Women of the Wall. The Statement of Principles of OHALAH states in part, "Our local communities will embody egalitarian and inclusive values, manifested in a variety of leadership and decision-making structures, ensuring that women and men are full and equal partners in every aspect of our communal Jewish life." In 2014 OHALAH issued a board resolution stating in part, "Therefore, be it resolved that: OHALAH supports the observance of Women's History Month, International Women's Day, and Women's Equality Day; OHALAH condemns all types of sexism; OHALAH is committed to gender equality, now and in all generations to come; and OHALAH supports equal rights regardless of gender." Also in 2014, ALEPH: Alliance for Jewish Renewal issued a statement stating, "ALEPH: Alliance for Jewish Renewal supports the observance of Women's History Month, International Women's Day, and Women's Equality Day, condemns all types of sexism, is committed to gender equality, now and in all generations to come, and supports equal rights regardless of gender, in recognition and allegiance to the view that we are all equally created in the Divine Image."

Humanistic Judaism is a movement in Judaism that offers a non-theistic alternative in contemporary Jewish life. It ordains both men and women as rabbis, and its first rabbi was a woman, Tamara Kolton, who was ordained in 1999. Its first cantor was also a woman, Deborah Davis, ordained in 2001; however, Humanistic Judaism has since stopped ordaining cantors. The Society for Humanistic Judaism issued a statement in 1996 stating in part, "We affirm that a woman has the moral right and should have the continuing legal right to decide whether or not to terminate a pregnancy in accordance with her own ethical standards. Because a decision to terminate a pregnancy carries serious, irreversible consequences, it is one to be made with great care and with keen awareness of the complex psychological, emotional, and ethical implications." They also issued a statement in 2011 condemning the then-recent passage of the "No Taxpayer Funding for Abortion Act" by the U.S. House of Representatives, which they called "a direct attack on a women's right to choose". In 2012, they issued a resolution opposing conscience clauses that allow religious-affiliated institutions to be exempt from generally applicable requirements mandating reproductive healthcare services to individuals or employees. In 2013 they issued a resolution stating in part, "Therefore, be it resolved that: The Society for Humanistic Judaism wholeheartedly supports the observance of Women's Equality Day on August 26 to commemorate the anniversary of the passage of the Nineteenth Amendment to the U.S. Constitution allowing women to vote; The Society condemns gender discrimination in all its forms, including restriction of rights, limited access to education, violence, and subjugation; and The Society commits itself to maintain vigilance and speak out in the fight to bring gender equality to our generation and to the generations that follow."

A Mohelet is a female mohel. Conservative, Reform, and Reconstructionist Judaism allows female mohelot.

Soferot is the feminine plural of Soferet. A Sopher, Sopher, Sofer STaM, or Sofer ST"M (Heb: "scribe", ×¡××¤×¨ ×¡×ª×´×) is a Jewish scribe who is able and entitled to transcribe Torah scrolls, tefillin and mezuzot, and other religious writings. (ST"M, ×¡×ª×´×, is an abbreviation for Sefer Torahs, Tefillin, and Mezuzot. The masculine plural of sofer is "sofrim" ×¡××¤×¨××).

Forming the basis for the discussion of women becoming soferot, Talmud Gittin 45b states: "Sifrei Torah, tefillin, and mezuzot written by a heretic, a star-worshipper, a slave, a woman, a minor, a Cuthean, or an apostate Jew, are unfit for ritual use." The rulings on Mezuzah and Tefillin are virtually undisputed among those who hold to the Talmudic Law. While Arba'ah Turim does not include women in its list of those ineligible to write Sifrei Torah, some see this as proof that women are permitted to write a Torah scroll. However today, virtually all Orthodox (both Modern and Ultra) authorities contest the idea that a woman is permitted to write a Sefer Torah. Yet women are permitted to inscribe Ketubot (marriage contracts), STaM not intended for ritual use, and other writings of Sofrut beyond simple STaM. In 2003, Canadian Aviel Barclay became the world's first known traditionally trained female sofer. In 2007 Jen Taylor Friedman, a British woman, became the first female sofer to scribe a Sefer Torah. In 2010 the first Sefer Torah scribed by a group of women (six female sofers, who were from Brazil, Canada, Israel, and the United States) was completed; this was known as the Women's Torah Project. Also, not just any man may write a Sefer Torah; they should ideally be written by a "G-d-fearing person" who knows at least the first layer of meanings, some of them hidden, in the Torah.

From October 2010 until spring 2011, Julie Seltzer, one of the female soferot from the Women's Torah Project, scribed a Sefer Torah as part of an exhibition at the Contemporary Jewish Museum in San Francisco. This makes her the first American female sofer to scribe a Sefer Torah; Julie Seltzer was born in Philadelphia and is non-denominationally Jewish. From spring 2011 until August 2012 she scribed another Sefer Torah, this time for the Reform congregation Beth Israel in San Diego. Seltzer was taught mostly by Jen Taylor Friedman. On September 22, 2013, Congregation Beth Elohim of New York dedicated a new Torah, which members of Beth Elohim said was the first Torah in New York City to be completed by a woman. The Torah was scribed by Linda Coppleson. As of 2014, there are an estimated 50 female soferot in the world.




General

Publications


</doc>
<doc id="26207" url="https://en.wikipedia.org/wiki?curid=26207" title="Robert Herrick">
Robert Herrick

Robert Herrick may refer to:



</doc>
<doc id="26211" url="https://en.wikipedia.org/wiki?curid=26211" title="Racketeer Influenced and Corrupt Organizations Act">
Racketeer Influenced and Corrupt Organizations Act

The Racketeer Influenced and Corrupt Organizations (RICO) Act is a United States federal law that provides for extended criminal penalties and a civil cause of action for acts performed as part of an ongoing criminal organization. The RICO Act focuses specifically on racketeering and allows the "leaders" of a syndicate to be tried for the crimes they "ordered" others to do or assisted them in doing, closing a perceived loophole that allowed a person who instructed someone else to, for example, murder, to be exempt from the trial because they did not actually commit the crime personally.

RICO was enacted by section 901(a) of the Organized Crime Control Act of 1970 () and is codified at as . G. Robert Blakey, an adviser to the United States Senate Government Operations Committee, drafted the law under the close supervision of the committee's chairman, Senator John Little McClellan. It was enacted as Title IX of the Organized Crime Control Act of 1970, and signed into law by Richard M. Nixon. While its original use in the 1970s was to prosecute the Mafia as well as others who were actively engaged in organized crime, its later application has been more widespread.

Beginning in 1972, 33 states adopted state RICO laws to be able to prosecute similar conduct.

Under RICO, a person who has committed "at least two acts of racketeering activity" drawn from a list of 35 crimesâ27 federal crimes and 8 state crimesâwithin a 10-year period can be charged with racketeering if such acts are related in one of four specified ways to an "enterprise". Those found guilty of racketeering can be fined up to $25,000 and sentenced to 20 years in prison per racketeering count. In addition, the racketeer must forfeit all ill-gotten gains and interest in any business gained through a pattern of "racketeering activity." 

When the U.S. Attorney decides to indict someone under RICO, they have the option of seeking a pre-trial restraining order or injunction to temporarily seize a defendant's assets and prevent the transfer of potentially forfeitable property, as well as require the defendant to put up a performance bond. This provision was placed in the law because the owners of Mafia-related shell corporations often absconded with the assets. An injunction or performance bond ensures that there is something to seize in the event of a guilty verdict.

In many cases, the threat of a RICO indictment can force defendants to plead guilty to lesser charges, in part because the seizure of assets would make it difficult to pay a defense attorney. Despite its harsh provisions, a RICO-related charge is considered easy to prove in court since it focuses on patterns of behavior as opposed to criminal acts.

RICO also permits a private individual "damaged in his business or property" by a "racketeer" to file a civil suit. The plaintiff must prove the existence of an "enterprise". The defendant(s) are not the enterprise; in other words, the defendant(s) and the enterprise are not one and the same. There must be one of four specified relationships between the defendant(s) and the enterprise: either the defendant(s) invested the proceeds of the pattern of racketeering activity into the enterprise (18 U.S.C. Â§ 1962(a)); or the defendant(s) acquired or maintained an interest in, or control of, the enterprise through the pattern of racketeering activity (subsection (b)); or the defendant(s) conducted or participated in the affairs of the enterprise "through" the pattern of racketeering activity (subsection (c)); or the defendant(s) conspired to do one of the above (subsection (d)). In essence, the enterprise is either the 'prize,' 'instrument,' 'victim,' or 'perpetrator' of the racketeers. A civil RICO action can be filed in state or federal court.

Both the criminal and civil components allow the recovery of treble damages (damages in triple the amount of actual/compensatory damages).

Although its primary intent was to deal with organized crime, Blakey said that Congress never intended it to merely apply to the Mob. He once told "Time," "We don't want one set of rules for people whose collars are blue or whose names end in vowels, and another set for those whose collars are white and have Ivy League diplomas."

Initially, prosecutors were skeptical of using RICO, mainly because it was unproven. The RICO Act was first used by the US Attorney's Office in the Southern District of New York on September 18, 1979, in the United States v. Scotto. Scotto, who was convicted on charges of racketeering, accepting unlawful labor payments, and income tax evasion, headed the International Longshoreman's Association. During the 1980s and 1990s, federal prosecutors used the law to bring charges against several Mafia figures. The second major success was the Mafia Commission Trial, which resulted in several top leaders of New York City's Five Families getting what amounted to life sentences. By the turn of the century, RICO cases resulted in virtually all of the top leaders of the New York Mafia being sent to prison.

Beginning in 1972, 33 states, as well as Puerto Rico and the US Virgin Islands, adopted state RICO laws to cover additional state offenses under a similar scheme.

Under the law, the meaning of racketeering activity is set out at . As currently amended it includes:


Pattern of racketeering activity requires at least two acts of racketeering activity, one of which occurred after the effective date of this chapter and the last of which occurred within ten years (excluding any period of imprisonment) after the commission of a prior act of racketeering activity. The US Supreme Court has instructed federal courts to follow the continuity-plus-relationship test in order to determine whether the facts of a specific case give rise to an established pattern. The illegal acts comprising a pattern are called "predicate" offenses. Predicate acts are related if they "have the same or similar purposes, results, participants, victims, or methods of commission, or otherwise are interrelated by distinguishing characteristics and are not isolated events." Continuity is both a closed and open ended concept, referring to either a closed period of conduct, or to past conduct that by its nature projects into the future with a threat of repetition.

Although some of the RICO predicate acts are extortion and blackmail, one of the most successful applications of the RICO laws has been the ability to indict and or sanction individuals for their behavior and actions committed against witnesses and victims in alleged retaliation or retribution for cooperating with federal law enforcement or intelligence agencies.

Violations of the RICO laws can be alleged in civil lawsuit cases or for criminal charges. In these instances, charges can be brought against individuals or corporations in retaliation for said individuals or corporations working with law enforcement. Further, charges can also be brought against individuals or corporations who have sued or filed criminal charges against a defendant.

Anti-SLAPP (strategic lawsuit against public participation) laws can be applied in an attempt to curb alleged abuses of the legal system by individuals or corporations who use the courts as a weapon to retaliate against whistle blowers or victims or to silence another's speech. RICO could be alleged if it can be shown that lawyers or their clients conspired and collaborated to concoct fictitious legal complaints solely in retribution and retaliation for themselves having been brought before the courts.

Although the RICO laws may cover drug trafficking crimes in addition to other more traditional RICO predicate acts such as extortion, blackmail, and racketeering, large-scale and organized drug networks are now commonly prosecuted under the Continuing Criminal Enterprise Statute, also known as the "Kingpin Statute". The CCE laws target only traffickers who are responsible for long-term and elaborate conspiracies, whereas the RICO law covers a variety of organized criminal behaviors.

The RICO statute contains a provision that allows for the commencement of a civil action by a private party to recover damages sustained as a result of the commission of a RICO predicate offense.

In 1979, the United States Federal Government went after Sonny Barger and several members and associates of the Oakland chapter of the Hells Angels using RICO. In "United States vs. Barger", the prosecution team attempted to demonstrate a pattern of behavior to convict Barger and other members of the club of RICO offenses related to guns and illegal drugs. The jury acquitted Barger on the RICO charges with a hung jury on the predicate acts: "There was no proof it was part of club policy, and as much as they tried, the government could not come up with any incriminating minutes from any of our meetings mentioning drugs and guns."

On August 20, 2006, in Tampa, Florida, most of the state leadership members of street gang the Latin Kings were arrested in connection with RICO conspiracy charges to engage in racketeering and currently await trial. The operation, called "Broken Crown", targeted statewide leadership of the Latin Kings. The raid occurred at the Caribbean American Club. Along with Hillsborough County Sheriff's Office, Tampa Police Department, the State Attorney's Office, the FBI, Immigration and Customs Enforcement, and the federal Bureau of Alcohol, Tobacco and Firearms were involved in the operation. 

Latin Kings in Chicago have been hit in 2009, their nation leader Augustin Zambrano, who was sentenced in 2012 to 60 years on 3 counts.

Louisiana Commissioner of Agriculture and Forestry Gil Dozier, in office from 1976 to 1980, faced indictment with violations of both the Hobbs and the RICO laws. He was accused of compelling companies doing business with his department to make campaign contributions on his behalf. On September 23, 1980, the Baton Rouge-based United States District Court for the Middle District of Louisiana convicted Dozier of five counts of extortion and racketeering. The sentence of ten years imprisonment, later upgraded to eighteen when other offenses were determined, and a $25,000 fine was suspended pending appeal, and Dozier remained free on bail. He eventually served nearly four years until a presidential commutation freed him in 1986.

Around June 1984, the Key West Police Department located in Monroe County, Florida, was declared a criminal enterprise under the federal RICO statutes after a lengthy United States Department of Justice investigation. Several high-ranking officers of the department, including Deputy Police Chief Raymond Cassamayor, were arrested on federal charges of running a protection racket for illegal cocaine smugglers. At trial, a witness testified he routinely delivered bags of cocaine to the Deputy Chief's office at City Hall.

On 29 March 1989 American financier Michael Milken was indicted on 98 counts of racketeering and fraud relating to an investigation into an allegation of insider trading and other offenses. Milken was accused of using a wide-ranging network of contacts to manipulate stock and bond prices. It was one of the first occasions that a RICO indictment was brought against an individual with no ties to organized crime. Milken pleaded guilty to six lesser felonies of securities fraud and tax evasion rather than risk spending the rest of his life in prison and ended up serving 22 months in prison. Milken was also ordered banned for life from the securities industry.

On September 7, 1988, Milken's employer, Drexel Burnham Lambert, was threatened with RICO charges "respondeat superior", the legal doctrine that corporations are responsible for their employees' crimes. Drexel avoided RICO charges by entering an Alford plea to lesser felonies of stock parking and stock manipulation. In a carefully worded plea, Drexel said it was "not in a position to dispute the allegations" made by the Government. If Drexel had been indicted under RICO statutes, it would have had to post a performance bond of up to $1 billion to avoid having its assets frozen. This would have taken precedence over all of the firm's other obligationsâincluding the loans that provided 96 percent of its capital base. If the bond ever had to be paid, its shareholders would have been practically wiped out. Since banks will not extend credit to a firm indicted under RICO, an indictment would have likely put Drexel out of business. By at least one estimate, a RICO indictment would have destroyed the firm within a month. Years later, Drexel president and CEO Fred Joseph said that Drexel had no choice but to plead guilty because "a financial institution cannot survive a RICO indictment."

In 2001, Major League Baseball team owners voted to eliminate two teams, presumably the Minnesota Twins and Montreal Expos. In 2002, the former minority owners of the Expos filed charges under the RICO Act against MLB commissioner Bud Selig and former Expos owner Jeffrey Loria, claiming that Selig and Loria deliberately conspired to devalue the team for personal benefit in preparation for a move. If found liable, Major League Baseball could have been responsible for up to $300 million in punitive damages. The case lasted two years, successfully stalling the Expos' move to Washington or contraction during that time. It was eventually sent to arbitration, where the arbiters ruled in favor of Major League Baseball, permitting the move to Washington to take place.

In April 2000, federal judge William J. Rea in Los Angeles, ruling in one Rampart scandal case, said that the plaintiffs could pursue RICO claims against the LAPD, an unprecedented finding. The idea that a police organization could be characterized as a racketeering enterprise shook up City Hall and further damaged the already-tarnished image of the LAPD. However, in July 2001, US District Judge Gary A. Feess said that the plaintiffs do not have standing to sue the LAPD under RICO because they are alleging personal injuries rather than economic or property damage.

On April 26, 2006, the Supreme Court heard "Mohawk Industries, Inc. v. Williams", , which concerned what sort of corporations fell under the scope of RICO. Mohawk Industries had allegedly hired illegal aliens, in violation of RICO. The court was asked to decide whether Mohawk Industries, along with recruiting agencies, constitutes an "enterprise" that can be prosecuted under RICO, but in June of that year dismissed the case and remanded it to Court of Appeals.

Also in Tampa, on October 16, 2006, four members of the Gambino crime family (Capo Ronald Trucchio, Terry Scaglione, Steven Catallono, and Anthony Mucciarone and associate Kevin McMahon) were tried under RICO statutes, found guilty, and sentenced to life in prison.

In the mid-1990s, prosecuting attorneys Gregory O'Connell and Charles Rose used RICO charges to bring down the Lucchese family within an 18-month period. Dismantling the Lucchese family had a profound financial impact on previously Mafia held businesses such as construction, garment, and garbage hauling. Here they dominated and extorted money through taxes, dues, and fees. An example of this extortion was through the garbage business. Hauling of garbage from the World Trade Center cost the building owners $1.2 million per year to be removed when the Mafia monopolized the business, as compared to $150,000 per year when competitive bids could be sought.

In 2005, the U.S. Department of Justice's Operation Family Secrets indicted 15 Chicago Outfit (also known as the Outfit, the Chicago Mafia, the Chicago Mob, or the Organization) members and associates under RICO predicates. Five defendants were convicted of RICO violations and other crimes. Six pleaded guilty, two died before trial and one was too sick to be tried.

A federal grand jury in the Middle District of Pennsylvania handed down a 48-count indictment against former Luzerne County Court of Common Pleas Judges Michael Conahan and Mark Ciavarella. The judges were charged with RICO after allegedly committing acts of mail and wire fraud, tax evasion, money laundering, and honest services fraud. The judges were accused of taking kickbacks for housing juveniles, that the judges convicted of mostly petty crimes, at a private detention center. The incident was dubbed by many local and national newspapers as the "Kids for cash scandal". On February 18, 2011, a federal jury found Michael Ciavarella guilty of racketeering because of his involvement in accepting illegal payments from Robert Mericle, the developer of PA Child Care, and Attorney Robert Powell, a co-owner of the facility. Ciavarella is facing 38 other counts in federal court.

Scott W. Rothstein is a disbarred lawyer and the former managing shareholder, chairman, and chief executive officer of the now-defunct Rothstein Rosenfeldt Adler law firm. He was accused of funding his philanthropy, political contributions, law firm salaries, and an extravagant lifestyle with a massive 1.2 billion dollar Ponzi scheme. On December 1, 2009, Rothstein turned himself in to federal authorities and was subsequently arrested on charges related to RICO. Although his arraignment plea was not guilty, Rothstein cooperated with the government and reversed his plea to guilty of five federal crimes on January 27, 2010. Bond was denied by U.S. Magistrate Judge Robin Rosenbaum, who ruled that due to his ability to forge documents, he was considered a flight risk. On June 9, 2010, Rothstein received a 50-year prison sentence after a hearing in federal court in Fort Lauderdale.

Eleven defendants were indicted on RICO charges for allegedly assisting AccessHealthSource, a local health care provider, in obtaining and maintaining lucrative contracts with local and state government entities in the city of El Paso, Texas, "through bribery of and kickbacks to elected officials or himself and others, extortion under color of authority, fraudulent schemes and artifices, false pretenses, promises and representations and deprivation of the right of citizens to the honest services of their elected local officials" (see indictment).

Fourteen defendants affiliated with FIFA were indicted under the RICO act on 47 counts for "racketeering, wire fraud and money laundering conspiracies, among other offenses, in connection with the defendants' participation in a 24-year scheme to enrich themselves through the corruption of international soccer." The defendants include many current and former high-ranking officers of FIFA and its affiliate CONCACAF. The defendants had allegedly used the enterprise as a front to collect millions of dollars in bribes, which may have influenced Russia and Qatar's winning bids to host the 2018 and 2022 FIFA World Cups, respectively.

In 2015, the Drummond Company sued attorneys Terrence P. Collingsworth and William R. Scherer, the advocacy group International Rights Advocates (IRAdvocates), and Dutch businessman Albert van Bilderbeek, one of the owners of Llanos Oil, accusing them of violating RICO by alleging that Drummond had worked alongside Autodefensas Unidas de Colombia to murder labor union leaders within proximity of their Colombian coal mines, which Drummond denies.

In 2005, a federal jury ordered Fasano to pay $500,000 under RICO for illegally helping a client hide their assets in a bankruptcy case.

"Art Cohen vs. Donald J. Trump" was a civil RICO class action suit filed October 18, 2013, accusing Donald Trump of misrepresenting Trump University "to make tens of millions of dollars" but delivering "neither Donald Trump nor a university". The case was being heard in U.S. District Court for the Southern District of California in San Diego, No. 3:2013cv02519, by Judge Gonzalo P. Curiel. It was scheduled for argument beginning November 28, 2016. However, on November 18 and shortly after the 2016 election, this case and two others were settled for a total of $25 million and without any admission of wrongdoing by Trump.

The US RICO legislation has other equivalents in the rest of the world. In spite of Interpol having a standardized definition of RICO-like crimes, the interpretation and national implementation in legislation (and enforcement) widely varies. Most nations cooperate with the US on RICO enforcement only where their own related laws are specifically broken, but this is in line with the Interpol protocols for such matters.

By nation, alphabetically:

Without other nations enforcing similar legislation to RICO, many cross border RICO cases would not be possible. In the overall body of RICO cases that went to trial, at least 50% have had some non-US enforcement component to them. The offshoring of money away from the US finance system as part racketeering (and especially money laundering) is typically a major contributing factor to this.

However, other countries have laws that enable the government to seize property with unlawful origins. Colombia and Mexico both have specific laws that define the participation in criminal organizations as a separate crime as well as separate laws that allow the seizure of goods related to these crimes. This latter provides a specific chapter titled "International Cooperation", which instructs Mexican authorities to cooperate with foreign authorities with respect to organized crime assets within Mexico, and provides the framework by which Mexican authorities may politely request the cooperation of foreign authorities with respect to assets located outside of Mexico, in terms of any international instruments they may be party to.

Arguably, this may be construed as allowing the application of the RICO Act in Mexico, provided the relevant international agreements exist among Mexico and countries with RICO or RICO-equivalent provisions.





</doc>
<doc id="26213" url="https://en.wikipedia.org/wiki?curid=26213" title="Rhombicuboctahedron">
Rhombicuboctahedron

In geometry, the rhombicuboctahedron, or small rhombicuboctahedron, is an Archimedean solid with eight triangular and eighteen square faces. There are 24 identical vertices, with one triangle and three squares meeting at each one. (Note that six of the squares only share vertices with the triangles while the other twelve share an edge.) The polyhedron has octahedral symmetry, like the cube and octahedron. Its dual is called the deltoidal icositetrahedron or trapezoidal icositetrahedron, although its faces are not really true trapezoids.

Johannes Kepler in Harmonices Mundi (1618) named this polyhedron a "rhombicuboctahedron", being short for "truncated cuboctahedral rhombus", with "cuboctahedral rhombus" being his name for a rhombic dodecahedron. There are different truncations of a rhombic dodecahedron into a topological rhombicuboctahedron: Prominently its rectification (left), the one that creates the uniform solid (center), and the rectification of the dual cuboctahedron (right), which is the core of the dual compound.

It can also be called an "expanded" or "cantellated" cube or octahedron, from truncation operations on either uniform polyhedron.

There are distortions of the rhombicuboctahedron that, while some of the faces are not regular polygons, are still vertex-uniform. Some of these can be made by taking a cube or octahedron and cutting off the edges, then trimming the corners, so the resulting polyhedron has six square and twelve rectangular faces. These have octahedral symmetry and form a continuous series between the cube and the octahedron, analogous to the distortions of the rhombicosidodecahedron or the tetrahedral distortions of the cuboctahedron. However, the rhombicuboctahedron also has a second set of distortions with six rectangular and sixteen trapezoidal faces, which do not have octahedral symmetry but rather T symmetry, so they are invariant under the same rotations as the tetrahedron but different reflections.

The lines along which a Rubik's Cube can be turned are, projected onto a sphere, similar, topologically identical, to a rhombicuboctahedron's edges. In fact, variants using the Rubik's Cube mechanism have been produced which closely resemble the rhombicuboctahedron.

The rhombicuboctahedron is used in three uniform space-filling tessellations: the cantellated cubic honeycomb, the runcitruncated cubic honeycomb, and the runcinated alternated cubic honeycomb.

The rhombicuboctahedron can be dissected into two square cupolae and a central octagonal prism. A rotation of one cupola by 45 degrees creates the "pseudoÂ­rhombiÂ­cuboctaÂ­hedron". Both of these polyhedra have the same vertex figure: 3.4.4.4.

There are three pairs of parallel planes that each intersect the rhombicuboctahedron in a regular octagon. The rhombicuboctahedron may be divided along any of these to obtain an octagonal prism with regular faces and two additional polyhedra called square cupolae, which count among the Johnson solids; it is thus an "elongated square orthobicupola". These pieces can be reassembled to give a new solid called the elongated square gyrobicupola or "pseudorhombicuboctahedron", with the symmetry of a square antiprism. In this the vertices are all locally the same as those of a rhombicuboctahedron, with one triangle and three squares meeting at each one, but are not all identical with respect to the entire polyhedron, since some are closer to the symmetry axis than others.

The "rhombicuboctahedron" has six special orthogonal projections, centered, on a vertex, on two types of edges, and three types of faces: triangles, and two squares. The last two correspond to the B and A Coxeter planes.
The rhombicuboctahedron can also be represented as a spherical tiling, and projected onto the plane via a stereographic projection. This projection is conformal, preserving angles but not areas or lengths. Straight lines on the sphere are projected as circular arcs on the plane.
A half symmetry form of the rhombicuboctahedron, , exists with pyritohedral symmetry, [4,3], (3*2) as Coxeter diagram , SchlÃ¤fli symbol s{3,4}, and can be called a "cantic snub octahedron". This form can be visualized by alternatingly coloring the edges of the 6 squares. These squares can then be distorted into rectangles, while the 8 triangles remain equilateral. The 12 diagonal square faces will become isosceles trapezoids. In the limit, the rectangles can be reduced to edges, and the trapezoids become triangles, and an icosahedron is formed, by a "snub octahedron" construction, , s{3,4}. (The compound of two icosahedra is constructed from both alternated positions.)

Cartesian coordinates for the vertices of a rhombicuboctahedron centred at the origin, with edge length 2 units, are all the even permutations of 

If the original rhombicuboctahedron has unit edge length, its dual strombic icositetrahedron has edge lengths

The area "A" and the volume "V" of the rhombicuboctahedron of edge length "a" are:

The optimal packing fraction of rhombicuboctahedra is given by
It was noticed that this optimal value is obtained in a Bravais lattice by . Since the rhombicuboctahedron is contained in a rhombic dodecahedron whose inscribed sphere is identical to its own inscribed sphere, the value of the optimal packing fraction is a corollary of the Kepler conjecture: it can be achieved by putting a rhombicuboctahedron in each cell of the rhombic dodecahedral honeycomb, and it cannot be surpassed, since otherwise the optimal packing density of spheres could be surpassed by putting a sphere in each rhombicuboctahedron of the hypothetical packing which surpasses it.

The 1495 "Portrait of Luca Pacioli", traditionally attributed to Jacopo de' Barbari, includes a glass rhombicuboctahedron half-filled with water, which may have been painted by Leonardo da Vinci.
The first printed version of the rhombicuboctahedron was by Leonardo and appeared in Pacioli's "Divina proportione" (1509).

A spherical 180Â°Â ÃÂ 360Â° panorama can be projected onto any polyhedron; but the rhombicuboctahedron provides a good enough approximation of a sphere while being easy to build. This type of projection, called "Philosphere", is possible from some panorama assembly software. It consists of two images that are printed separately and cut with scissors while leaving some flaps for assembly with glue.

The Freescape games "Driller" and "Dark Side" both had a game map in the form of a rhombicuboctahedron.

The "Hurry-Scurry Galaxy" and "Sea Slide Galaxy" in the videogame "Super Mario Galaxy" have planets in the similar shape of a rhombicuboctahedron.

"Sonic the Hedgehog 3"'s Icecap Zone features pillars topped with rhombicuboctahedra.

During the Rubik's Cube craze of the 1980s, at least two twisty puzzles sold had the form of a rhombicuboctahedron (the mechanism was of course that of a Rubik's Cube).

The rhombicuboctahedron is one of a family of uniform polyhedra related to the cube and regular octahedron.

This polyhedron is topologically related as a part of sequence of cantellated polyhedra with vertex figure (3.4."n".4), and continues as tilings of the hyperbolic plane. These vertex-transitive figures have (*"n"32) reflectional symmetry.

It shares its vertex arrangement with three nonconvex uniform polyhedra: the stellated truncated hexahedron, the small rhombihexahedron (having the triangular faces and six square faces in common), and the small cubicuboctahedron (having twelve square faces in common).

In the mathematical field of graph theory, a rhombicuboctahedral graph is the graph of vertices and edges of the rhombicuboctahedron, one of the Archimedean solids. It has 24 vertices and 48 edges, and is a quartic graph Archimedean graph.




</doc>
<doc id="26214" url="https://en.wikipedia.org/wiki?curid=26214" title="Reverse transcriptase">
Reverse transcriptase

A reverse transcriptase (RT) is an enzyme used to generate complementary DNA (cDNA) from an RNA template, a process termed "reverse transcription". Reverse transcriptases are used by retroviruses to replicate their genomes, by retrotransposon mobile genetic elements to proliferate within the host genome, by eukaryotic cells to extend the telomeres at the ends of their linear chromosomes, and by some non-retroviruses such as the hepatitis B virus, a member of the "Hepadnaviridae", which are dsDNA-RT viruses.

Retroviral RT has three sequential biochemical activities: RNA-dependent DNA polymerase activity, ribonuclease H, and DNA-dependent DNA polymerase activity. Collectively, these activities enable the enzyme to convert single-stranded RNA into double-stranded cDNA. In retroviruses and retrotransposons, this cDNA can then integrate into the host genome, from which new RNA copies can be made via host-cell transcription. The same sequence of reactions is widely used in the laboratory to convert RNA to DNA for use in molecular cloning, RNA sequencing, polymerase chain reaction (PCR), or genome analysis.

Reverse transcriptases were discovered by Howard Temin at the University of WisconsinâMadison in Rous sarcoma virions and independently isolated by David Baltimore in 1970 at MIT from two RNA tumour viruses: murine leukemia virus and again Rous sarcoma virus. For their achievements, they shared the 1975 Nobel Prize in Physiology or Medicine (with Renato Dulbecco).

Well-studied reverse transcriptases include:

The enzymes are encoded and used by viruses that use reverse transcription as a step in the process of replication. Reverse-transcribing RNA viruses, such as retroviruses, use the enzyme to reverse-transcribe their RNA genomes into DNA, which is then integrated into the host genome and replicated along with it. Reverse-transcribing DNA viruses, such as the hepadnaviruses, can allow RNA to serve as a template in assembling and making DNA strands. HIV infects humans with the use of this enzyme. Without reverse transcriptase, the viral genome would not be able to incorporate into the host cell, resulting in failure to replicate.

Reverse transcriptase creates double-stranded DNA from an RNA template.

In virus species with reverse transcriptase lacking DNA-dependent DNA polymerase activity, creation of double-stranded DNA can possibly be done by host-encoded DNA polymerase Î´, mistaking the viral DNA-RNA for a primer and synthesizing a double-stranded DNA by similar mechanism as in primer removal, where the newly synthesized DNA displaces the original RNA template.

The process of reverse transcription is extremely error-prone, and it is during this step that mutations may occur. Such mutations may cause drug resistance.

Retroviruses, also referred to as class VI ssRNA-RT viruses, are RNA reverse-transcribing viruses with a DNA intermediate. Their genomes consist of two molecules of positive-sense single-stranded RNA with a 5' cap and 3' polyadenylated tail. Examples of retroviruses include the human immunodeficiency virus (HIV) and the human T-lymphotropic virus (HTLV). Creation of double-stranded DNA occurs in the cytosol as a series of these steps:

Creation of double-stranded DNA also involves "strand transfer", in which there is a translocation of short DNA product from initial RNA-dependent DNA synthesis to acceptor template regions at the other end of the genome, which are later reached and processed by the reverse transcriptase for its DNA-dependent DNA activity.

Retroviral RNA is arranged in 5â terminus to 3â terminus. The site where the primer is annealed to viral RNA is called the primer-binding site (PBS). The RNA 5âend to the PBS site is called U5, and the RNA 3â end to the PBS is called the leader. The tRNA primer is unwound between 14 and 22 nucleotides and forms a base-paired duplex with the viral RNA at PBS. The fact that the PBS is located near the 5â terminus of viral RNA is unusual because reverse transcriptase synthesize DNA from 3â end of the primer in the 5â to 3â direction (with respect to the newly synthesized DNA strand). Therefore, the primer and reverse transcriptase must be relocated to 3â end of viral RNA. In order to accomplish this reposition, multiple steps and various enzymes including DNA polymerase, ribonuclease H(RNase H) and polynucleotide unwinding are needed.

The HIV reverse transcriptase also has ribonuclease activity that degrades the viral RNA during the synthesis of cDNA, as well as DNA-dependent DNA polymerase activity that copies the sense cDNA strand into an "antisense" DNA to form a double-stranded viral DNA intermediate (vDNA).

Self-replicating stretches of eukaryotic genomes known as retrotransposons utilize reverse transcriptase to move from one position in the genome to another via an RNA intermediate. They are found abundantly in the genomes of plants and animals. Telomerase is another reverse transcriptase found in many eukaryotes, including humans, which carries its own RNA template; this RNA is used as a template for DNA replication.

Initial reports of reverse transcriptase in prokaryotes came as far back as 1971 (Beljanski et al., 1971a, 1972). These have since been broadly described as part of bacterial Retrons, distinct sequences that code for reverse transcriptase, and are used in the synthesis of msDNA. In order to initiate synthesis of DNA, a primer is needed. In bacteria, the primer is synthesized during replication.

Valerian Dolja of Oregon State argues that viruses, due to their diversity, have played an evolutionary role in the development of cellular life, with reverse transcriptase playing a central role.

The reverse transcriptase employs a "right hand" structure similar to that found in other viral nucleic acid polymerases. In addition to the transcription function, retroviral reverse transcriptases have a domain belonging to the RNase H family, which is vital to their replication. By degrading the RNA template, it allows the other strand of DNA to be synthesized. Some fragments from the digestion also serves as the primer for the DNA polymerase (either the same enzyme or a host protein), responsible for making the other (plus) strand.

There are three different replication systems during the life cycle of a retrovirus. First of all, the reverse transcriptase synthesizes viral DNA from viral RNA, and then from newly made complementary DNA strand. The second replication process occurs when host cellular DNA polymerase replicates the integrated viral DNA. Lastly, RNA polymerase II transcribes the proviral DNA into RNA, which will be packed into virions. Therefore, mutation can occur during one or all of these replication steps.

Reverse transcriptase has a high error rate when transcribing RNA into DNA since, unlike most other DNA polymerases, it has no proofreading ability. This high error rate allows mutations to accumulate at an accelerated rate relative to proofread forms of replication. The commercially available reverse transcriptases produced by Promega are quoted by their manuals as having error rates in the range of 1 in 17,000 bases for AMV and 1 in 30,000 bases for M-MLV.

Other than creating single-nucleotide polymorphisms, reverse transcriptases have also been shown to be involved in processes such as transcript fusions, exon shuffling and creating artificial antisense transcripts. It has been speculated that this template switching activity of reverse transcriptase, which can be demonstrated completely "in vivo", may have been one of the causes for finding several thousand unannotated transcripts in the genomes of model organisms.

As HIV uses reverse transcriptase to copy its genetic material and generate new viruses (part of a retrovirus proliferation circle), specific drugs have been designed to disrupt the process and thereby suppress its growth. Collectively, these drugs are known as reverse-transcriptase inhibitors and include the nucleoside and nucleotide analogues zidovudine (trade name Retrovir), lamivudine (Epivir) and tenofovir (Viread), as well as non-nucleoside inhibitors, such as nevirapine (Viramune).

Reverse transcriptase is commonly used in research to apply the polymerase chain reaction technique to RNA in a technique called reverse transcription polymerase chain reaction (RT-PCR). The classical PCR technique can be applied only to DNA strands, but, with the help of reverse transcriptase, RNA can be transcribed into DNA, thus making PCR analysis of RNA molecules possible. Reverse transcriptase is used also to create cDNA libraries from mRNA. The commercial availability of reverse transcriptase greatly improved knowledge in the area of molecular biology, as, along with other enzymes, it allowed scientists to clone, sequence, and characterise RNA.

Reverse transcriptase has also been employed in insulin production. By inserting eukaryotic mRNA for insulin production along with reverse transcriptase into bacteria, the mRNA could be inserted into the prokaryote's genome. Large amounts of insulin can then be created, sidestepping the need to harvest pig pancreas and other such traditional sources. Directly inserting eukaryotic DNA into bacteria would not work because it carries introns, so would not translate successfully using the bacterial ribosomes. Processing in the eukaryotic cell during mRNA production removes these introns to provide a suitable template. Reverse transcriptase converted this edited RNA back into DNA so it could be incorporated in the genome.




</doc>
<doc id="26215" url="https://en.wikipedia.org/wiki?curid=26215" title="Riemann mapping theorem">
Riemann mapping theorem

In complex analysis, the Riemann mapping theorem states that if "U" is a non-empty simply connected open subset of the complex number plane C which is not all of C, then there exists a biholomorphic mapping "f" (i.e. a bijective holomorphic mapping whose inverse is also holomorphic) from "U" onto the open unit disk 

This mapping is known as a Riemann mapping.

Intuitively, the condition that "U" be simply connected means that "U" does not contain any âholesâ. The fact that "f" is biholomorphic implies that it is a conformal map and therefore angle-preserving. Intuitively, such a map preserves the shape of any sufficiently small figure, while possibly rotating and scaling (but not reflecting) it.

Henri PoincarÃ© proved that the map "f" is essentially unique: if "z" is an element of "U" and Ï is an arbitrary angle, then there exists precisely one "f" as above such that "f"("z") = 0 and such that the argument of the derivative of "f" at the point "z" is equal to Ï. This is an easy consequence of the Schwarz lemma.

As a corollary of the theorem, any two simply connected open subsets of the Riemann sphere which both lack at least two points of the sphere can be conformally mapped into each other.

The theorem was stated (under the assumption that the boundary of "U" is piecewise smooth) by Bernhard Riemann in 1851 in his PhD thesis. Lars Ahlfors wrote once, concerning the original formulation of the theorem, that it was âultimately formulated in terms which would defy any attempt of proof, even with modern methodsâ. Riemann's flawed proof depended on the Dirichlet principle (which was named by Riemann himself), which was considered sound at the time. However, Karl Weierstrass found that this principle was not universally valid. Later, David Hilbert was able to prove that, to a large extent, the Dirichlet principle is valid under the hypothesis that Riemann was working with. However, in order to be valid, the Dirichlet principle needs certain hypotheses concerning the boundary of "U" which are not valid for simply connected domains in general. Simply connected domains with arbitrary boundaries were first treated by .

The first proof of the theorem is due to Constantin CarathÃ©odory, who published it in 1912. His proof used Riemann surfaces and it was simplified by Paul Koebe two years later in a way which did not require them.

Another proof, due to LipÃ³t FejÃ©r and to Frigyes Riesz, was published in 1922 and it was rather shorter than the previous ones. In this proof, like in Riemann's proof, the desired mapping was obtained as the solution of an extremal problem. The FejÃ©râRiesz proof was further simplified by Alexander Ostrowski and by CarathÃ©odory.

The following points detail the uniqueness and power of the Riemann mapping theorem:


Given "U" and a point "z" in "U", we want to construct a function "f" which maps "U" to the unit disk and "z" to 0. For this sketch, we will assume that "U" is bounded and its boundary is smooth, much like Riemann did. Write

where "g" = "u" + "iv" is some (to be determined) holomorphic function with real part "u" and imaginary part "v". It is then clear that "z" is the only zero of "f". We require |"f"("z")| = 1 for "z" â â"U", so we need 

on the boundary. Since "u" is the real part of a holomorphic function, we know that "u" is necessarily a harmonic function; i.e., it satisfies Laplace's equation.

The question then becomes: does a real-valued harmonic function "u" exist that is defined on all of "U" and has the given boundary condition? The positive answer is provided by the Dirichlet principle. Once the existence of "u" has been established, the CauchyâRiemann equations for the holomorphic function "g" allow us to find "v" (this argument depends on the assumption that "U" be simply connected). Once "u" and "v" have been constructed, one has to check that the resulting function "f" does indeed have all the required properties.

The Riemann mapping theorem can be generalized to the context of Riemann surfaces: If "U" is a non-empty simply-connected open subset of a Riemann surface, then "U" is biholomorphic to one of the following: the Riemann sphere, C or "D". This is known as the uniformization theorem.

In the case of a simply connected bounded domain with smooth boundary, the Riemann mapping function and all its derivatives extend by continuity to the closure of the domain. This can be proved using regularity properties of solutions of the Dirichlet boundary value problem, which follow either from the theory of Sobolev spaces for planar domains or from classical potential theory. Other methods for proving the smooth Riemann mapping theorem include the theory of kernel functions or the Beltrami equation.

Computational conformal mapping is prominently featured in problems of applied analysis and mathematical physics, as well as in engineering disciplines, such as image processing.

In the early 1980s an elementary algorithm for computing conformal maps was discovered. Given points formula_4 in the plane, the algorithm computes an explicit conformal map of the unit disk onto a region bounded by a Jordan curve formula_5 with formula_6 This algorithm converges for Jordan regions in the sense of uniformly close boundaries. There are corresponding uniform estimates on the closed region and the closed disc for the mapping functions and their inverses. Improved estimates are obtained if the data points lie on a formula_7 curve or a K-quasicircle. The algorithm was discovered as an approximate method for conformal welding; however, it can also be viewed as a discretization of the Loewner differential equation.

The following is known about numerically approximating the conformal mapping between two planar domains.

Positive results:



Negative results:






</doc>
<doc id="26219" url="https://en.wikipedia.org/wiki?curid=26219" title="Rhodesia">
Rhodesia

Rhodesia (, ) was an unrecognised state in southern Africa from 1965 to 1979, equivalent in territory to modern Zimbabwe. Rhodesia was the "de facto" successor state to the British colony of Southern Rhodesia, which had been self-governing since achieving responsible government in 1923. A landlocked nation, Rhodesia was bordered by South Africa to the south, Bechuanaland (later Botswana) to the southwest, Zambia to the northwest, and Mozambique (a Portuguese province until 1975) to the east. British historian William Hale notes that the state of Rhodesia was âsimply the most successful example of decolonisationâ.

In the late 19th century, the territory north of the Transvaal was chartered to the British South Africa Company, led by Cecil Rhodes. Rhodes and his Pioneer Column marched north in 1890, acquiring a huge block of territory that the company would rule until the early 1920s. In 1923, the company's charter was revoked, and Southern Rhodesia attained self-government and established a legislature. Between 1953 and 1963, Southern Rhodesia was joined with Northern Rhodesia and Nyasaland in the Federation of Rhodesia and Nyasaland.

The decolonisation of Africa in the early 1960s alarmed a significant proportion of Rhodesia's white population. In an effort to delay the transition to black majority rule, Rhodesia's predominantly white government issued its own Unilateral Declaration of Independence (UDI) from the United Kingdom on 11 November 1965. (The government of the United Kingdom supported Rhodesia's transition to a multiracial democracy.) The UDI administration initially sought recognition as an autonomous realm within the Commonwealth of Nations, but reconstituted itself as a republic in 1970. The Rhodesian Bush War, which pitted the government against two African nationalist organisations, ZANU and ZAPU, intensified in the 1970s, prompting Rhodesian premier Ian Smith to concede to multiracial democracy in 1978. However, a provisional government subsequently headed by Smith and his moderate colleague Abel Muzorewa failed in appeasing international critics or halting the bloodshed. By December 1979, Muzorewa had replaced Smith as Prime Minister and secured an agreement with the militant nationalists, allowing Rhodesia to briefly revert to colonial status pending elections under a universal franchise. It finally achieved internationally recognised independence in April 1980 as the Republic of Zimbabwe.

Rhodesia's largest cities were its capital, Salisbury, and Bulawayo. The white population, which grew to nearly 300,000, dominated the country's politics and economy, though they never made up more than 8% of the total population. Rhodesia developed an economy largely dependent on agriculture, manufacturing, and mining. Its largest exports were chromium, tobacco, and steel. International sanctions put increasing pressure on the country as time went on. The unicameral Legislative Assembly was predominantly white, with minority of seats reserved for blacks. Following the declaration of a republic in 1970, this was replaced by a bicameral Parliament with a House of Assembly and a Senate. The Westminster system was retained, with the President acting as ceremonial head of state, and the Prime Minister, heading the Cabinet, as head of government.

The official name of the country, according to the constitution adopted concurrently with the UDI in 1965, was Rhodesia. This was not the case under British law, however, which considered the territory's legal name to be Southern Rhodesia, the name given to the country in 1898 during the British South Africa Company's administration of the Rhodesias, and retained by the self-governing colony of Southern Rhodesia after the end of company rule in 1923.

This naming dispute dated back to October 1964, when Northern Rhodesia became independent from the UK and concurrently changed its name to Zambia. The Southern Rhodesian colonial government in Salisbury felt that in the absence of a "Northern" Rhodesia, the continued use of "Southern" was superfluous. It passed legislation to become simply Rhodesia, but the British government refused to approve this on the grounds that the country's name was defined by British legislation, so could not be altered by the colonial government. Salisbury went on using the shortened name in an official manner nevertheless, while the British government continued referring to the country as Southern Rhodesia. This situation continued throughout the UDI period. The shortened name was used by many people including the British government in the House of Commons.

Until after World War II, the landlocked British possession of Southern Rhodesia was not developed as an indigenous African territory, but rather as a unique state that reflected its multiracial character. This situation certainly made it very different from other lands that existed under colonial rule, as many Europeans had arrived to make permanent homes, populating the towns as traders or settling to farm the most productive soils. In 1922, faced with the decision to join the Union of South Africa as a fifth province or accept nearly full internal autonomy, the electorate cast its vote against South African integration.

In view of the outcome of the referendum, the territory was annexed by the United Kingdom on 12 September 1923. Shortly after annexation, on 1 October 1923, the first constitution for the new Colony of Southern Rhodesia came into force. Under this constitution, Southern Rhodesia was given the right to elect its own thirty-member legislature, premier, and cabinetâalthough the British Crown retained a formal veto over measures affecting natives and dominated foreign policy.

Over the course of the next three decades, Southern Rhodesia experienced a degree of economic expansion and industrialisation almost unrivaled in sub-Saharan Africa. Its natural abundance of mineral wealthâincluding large deposits of chromium and manganeseâcontributed to the high rate of conventional economic growth. However, most colonies in Africa, even those rich in natural resources, experienced difficulty in achieving similar rates of development due to a shortage of technical and managerial skills. Small, rotating cadres of colonial civil servants who possessed little incentive to invest their skills in the local economy were insufficient to compensate for this disadvantage. Southern Rhodesia had negated the issue by importing a skilled workforce directly from abroad in the form of its disproportionately large European immigrant and expatriate population. For example, in 1951 over 90% of white Southern Rhodesians were engaged in what the British government classified as "skilled occupations", or professional and technical trades. This resulted in the establishment of a diversified economy with a strong manufacturing sector and iron and steel industries. As the white population increased, so too did capital imports, especially in the wake of World War II. The considerable investment made by European residents in the economy financed the development of Southern Rhodesia's export industries as well as the infrastructure necessary to integrate it further with international markets.

In 1953, Southern Rhodesia merged with the two other British Central African states to form the Federation of Rhodesia and Nyasaland â a loose association that placed defence and economic direction under a central government but left many domestic affairs under the control of its constituent territories. As it began to appear that decolonisation was inevitable and indigenous black populations were pressing heavily for change, the federation was dissolved in 1963.

Although prepared to grant formal independence to Southern Rhodesia (now Rhodesia), the British government had adopted a policy of "no independence before majority rule", dictating that colonies with a substantial population of European settlers would not receive independence except under conditions of majority rule. White Rhodesians initially balked at the suggestion; some felt they had a right to absolute political control, at least for the time being, despite their relatively small numbers. The Rhodesian authorities were also disturbed by the post-independence chaos that was plaguing other African nations at the time. However, once Rhodesia had been introduced as a topic for discussion in international bodies, extension of the status quo became a matter of concern to the world community and a serious embarrassment to the United Kingdom.

After the federal break-up in 1963, then-Prime Minister Alec Douglas-Home insisted that preconditions on independence talks hinge on what he termed the "five principles" â unimpeded progress to majority rule, assurance against any future legislation decidedly detrimental to black interests, "improvement in the political status" of local Africans, moves towards ending racial discrimination, and agreement on a settlement that could be "acceptable to the whole population". Harold Wilson and his incoming Labour government took an even harder line on demanding that these points be legitimately addressed before an independence agenda could be set.

By 1964, growing dissatisfaction with the ongoing negotiations ousted Salisbury's incumbent Winston Field, replacing him with Ian Smith, deputy chairman of the conservative Rhodesian Front party. Smith, the colony's first Rhodesian-born leader, soon came to personify resistance to liberals in British government and those agitating for change at home. In September 1964, Smith visited Lisbon, where Portuguese prime minister AntÃ³nio de Oliveira Salazar promised him "maximum support" if he should declare independence. Aside from a common interest in maintaining security ties in southern Africa, Salazar expressed a great deal of anger at Britain's refusal to support Portugal when India seized Goa in 1961, admonishing Smith not to trust the British government. A Rhodesian Trade Office was opened in Lisbon in order to co-ordinate breaking the anticipated sanctions in the event of a unilateral declaration of independence later that year, which encouraged Smith not to compromise. In its turn, the Rhodesian Trade Office in Lisbon functioned as a "de facto" embassy and caused tension with London, which objected to Rhodesia conducting its own foreign policy. As land-locked Rhodesia bordered on the Portuguese colony of Mozambique, Salazar's promise of "maximum support" from Portugal in breaking the anticipated sanctions gave Smith more grounds for self-confidence in his talks with London. Smith ruled out acceptance for all five of the proposed principles as they stood, implying instead that Rhodesia was already legally entitled to independenceâa claim that was overwhelmingly endorsed by registered (i.e., white) voters in a referendum.

Emboldened by the results of this referendum and the subsequent general election, Rhodesia now threatened to assume her own sovereignty without British consent. Harold Wilson countered by warning that such an irregular procedure would be considered treasonous, although he specifically rejected using armed force against the English "kith and kin" in Africa. Wilson's refusal to consider a military option encouraged Smith to proceed with his plans. Talks quickly broke down, and final efforts in October to achieve a settlement floundered; the Rhodesian Front remained unwilling to accept what were regarded as unacceptably drastic terms and the British would settle for nothing less â it was a formula doomed to failure.

On 11 November 1965, following a brief but solemn consensus, Rhodesia's leading statesmen issued a unilateral declaration of independence (UDI). This was immediately denounced as an "act of rebellion against the Crown" in the United Kingdom, and Wilson promised that the illegal action would be short-lived. However, few seemed to initially realise that Rhodesia was no longer within the Commonwealth's direct sphere of influence and British rule was now a constitutional fiction; Salisbury remained virtually immune to credible metropolitan leverage.

On 12 October 1965, the United Nations General Assembly had noted the repeated threats of the Rhodesian authorities "to declare unilaterally the independence of Southern Rhodesia, in order to perpetuate minority rule", and called upon Wilson to use all means at his disposal (including military force) to prevent the Rhodesian Front from asserting independence. After UDI was proclaimed, UN officials branded Ian Smith's government as an "illegal racist minority regime" and called on member states to sever economic ties with Rhodesia, recommending sanctions on petroleum products and military hardware. In December 1966, these measures became mandatory, extending to bar the purchase of Rhodesian tobacco, chromium, copper, asbestos, sugar, meat, and hides.

The UK, having already adopted extensive sanctions of its own, dispatched a Royal Navy squadron to monitor oil deliveries in the port of Beira in Mozambique, from which a strategic pipeline ran to Umtali in Rhodesia. The warships were to deter "by force, if necessary, vessels reasonably believed to be carrying oil destined for (Southern) Rhodesia".

Some nations, such as Switzerland, and West Germany, which were not UN members, conducted business legally with Rhodesia â the latter remained the Smith government's largest trading partner in Western Europe until 1973, when Bonn joined the UN. Japan continued to accept more Rhodesian exports than any other nation, and Iran provided oil. The Portuguese government marketed Rhodesian products as its own, via false certificates of origin and disguised trade channels. South Africa openly refused to observe the UN sanctions. A 1971 law passed in the United States permitted American firms to go on importing Rhodesian chromium and nickel as normal.

Despite the poor showing of sanctions, Rhodesia found it nearly impossible to obtain diplomatic recognition abroad. In 1970, the US government had made it clear that the UDI would not be recognised "under [any] circumstances". Even the National Party government in South Africa and the Estado Novo government of Portugal, although sympathetic, did not recognise Rhodesia as an independent state, maintaining only an Accredited Diplomatic Representative in Salisbury. This allowed Pretoria and Lisbon to continue to recognise British sovereignty as well as to deal with the "de facto" authority of the Smith government

Initially, the state retained its pledged loyalty to Elizabeth II of the United Kingdom, recognising her as Queen of Rhodesia. When Smith and Deputy Prime Minister Clifford Dupont called on colonial Governor Sir Humphrey Gibbs to formally notify him of the UDI, Gibbs condemned the UDI as an act of treason. After Smith formally announced the UDI on the radio, Gibbs used his reserve power to dismiss Smith and his entire cabinet from office on orders from Whitehall. However, Gibbs was unable to enact any concrete actions to foster a return to legality. Government ministers simply ignored his notices, contending that UDI made his office obsolete. Even so, Gibbs continued to occupy his residence in Salisbury until 1970, when he vacated the premises and left Rhodesia following the declaration of a republic. He had effectively been superseded before then; the Smith government stated that if the Queen did not appoint a Governor-General, it would name Dupont as "Officer Administering the Government". Smith had intended to have Dupont named Governor-General, but Elizabeth would not even consider this advice. With few exceptions, the international community backed Whitehall's assertion that Gibbs was the Queen's only legitimate representative, and hence the only lawful authority in what it still maintained was "Southern" Rhodesia.

In September 1968, the Appellate Division of the Rhodesian High Court ruled that Ian Smith's administration had become the "de jure" government of the country, not merely the "de facto" one. To support his decision, Chief Justice Sir Hugh Beadle used several statements made by Hugo Grotius, who maintained that there was no way that a nation could rightly claim to be governing a particular territory â if it was waging a war against that territory. Beadle argued that due to Britain's economic war against Rhodesia, she could not (at the same point) be described as "governing" Rhodesia. Resulting court decisions held that the Smith government "could lawfully do anything its predecessors could lawfully have done".

A Salisbury commission chaired by prominent lawyer W.R. Waley was appointed to study constitutional options open to the Rhodesian authorities as of April 1968, but reaching a further settlement with the British was ruled out early on. Waley, although insistent that "Europeans must surrender any belief in permanent European domination", also testified that majority rule was not desirable immediately.

Talks aimed at easing the differences between Rhodesia and the United Kingdom were carried out aboard Royal Navy vessels once in December 1966 and again in October 1968. Both efforts failed to achieve agreement, although Harold Wilson added a sixth principle to the five he had previously enunciated: "it would be necessary to ensure that, regardless of race, there was no oppression of the majority by the minority or of [any] minority by the majority." Rhodesian resolve stiffened following a failure to reach a new settlement, with more radical elements of the Rhodesian Front calling for a republican constitution.

During a two-proposition referendum held in 1969, the proposal for severing all remaining ties to the British Crown passed by a majority of 61,130 votes to 14,327. Rhodesia declared itself a republic on 2 March 1970. Under the new constitution, a president served as ceremonial head of state, with the prime minister nominally reporting to him. Some in Rhodesian government had hoped in vain that the declaration of a republic would finally prompt other nations to grant recognition.

The years following Rhodesia's UDI saw an unfolding series of economic, military, and political pressures placed on the country that eventually brought about majority rule, a totality of these factors rather than any one the reason for introducing change. In 2005, a conference at the London School of Economics that discussed Rhodesia's independence concluded that UDI was sparked by an existing racial conflict complicated by Cold War intrigues.

Critics of UDI sought to maintain that Ian Smith intended only to safeguard the privileges of an entrenched colonial elite at the expense of the impoverished African community. According to this logic, UDI created a vacuum of oppression that was eventually filled by Robert Mugabe's dictatorship. Smith and his supporters continued to defend their actions, however, by claiming that the Rhodesian majority was too inexperienced at the time to manage what was, by contemporary African standards, a reasonably industrialised nation.

At large, the European population's emerging attitude to UDI was tense. Many white Rhodesians had seen themselves as nothing less than fully fledged members of the British Empire, carrying on the same rugged values and frontier spirit of the early Englishmen who had settled in 1890. But such confidence was rudely shaken by Whitehall's refusal to grant independence on their terms. After 1965, there were those who continued to claim that they were collectively upholders of principle and defenders of such values against the twin threats of communism, manifested through the militant black nationalists, and â ironically â the decadence of Britain herself. Often repeated appeals to the Christian heritage of their pioneer ancestors in "defending the free world" reflected these beliefs.

African parties displayed initial horror at Smith's declaration, with one ZANU official stating, "...for all those who cherish freedom and a meaningful life, UDI has set a collision course that cannot be altered. 11 November 1965 [has] marked the turning point of the struggle for freedom in that land from a constitutional and political one to primarily a military struggle." It would, however, be several years before even the most radical nationalists chose to develop a coherent strategy revolving around armed resistance, preferring instead to create opportunities for external intervention.

Because Rhodesian exports were generally competitive and had previously been entitled to preferential treatment on the British market, the former colony did not recognise the need for escalating the pace of diversification before independence. Following the UDI, however, Rhodesia began to demonstrate that it had the potential to develop a greater degree of economic self-sufficiency. After the Rhodesian Front began introducing incentives accorded to domestic production, industrial output expanded dramatically. A rigid system of countermeasures enacted to combat sanctions succeeded in blunting their impact for at least a decade. Over the next nine years Rhodesian companies, spiting the freezing of their assets and blocking of overseas accounts, also perfected cunning techniques of sanctions evasion through both local and foreign subsidiaries, which operated on a clandestine trade network.

From 1968 until 1970, there was virtually no further dialogue between Rhodesia and the UK. In a referendum in 1969, white voters approved a new constitution and the establishment of a republic, thereby severing Rhodesia's last links with the British Crown, duly declared in March 1970. This changed immediately after the election of Edward Heath, who reopened negotiations. Smith remained optimistic that Heath would do his utmost to remedy Anglo-Rhodesian relations, although disappointed that he continued to adhere publicly to the original "five principles" proposed by Alec Douglas-Home, now foreign secretary. In November 1971, Douglas-Home renewed contacts with Salisbury and announced a proposed agreement that would be satisfactory to both sides â it recognised Rhodesia's 1969 constitution as the legal frame of government, while agreeing that gradual legislative representation was an acceptable formula for unhindered advance to majority rule. Nevertheless, the new settlement, if approved, would also implement an immediate improvement in black political status, offer a means to terminate racial discrimination, and provide a solid guarantee against retrogressive constitutional amendments.

Implementation of the proposed settlement hinged on popular acceptance, but the Rhodesian government consistently refused to submit it to a universal referendum. A twenty four-member commission headed by an eminent jurist, Lord Pearce, was therefore tasked with ascertaining public opinion on the subject. In 1972, the commission began interviewing interest groups and sampling opinions â although concern was expressed over the widespread apathy encountered. According to the commission, whites were in favour of the settlement, and Rhodesians of Coloured or Asian ancestry generally pleased, while the black response to the settlement's terms was resoundingly negative. As many as thirty black Rhodesian chiefs and politicians voiced their opposition, prompting Britain to withdraw from the proposals on the grounds of the commission's report.

As early as 1960, minority rule in Southern Rhodesia was already being challenged by a rising tide of political violence led by African nationalists such as Joshua Nkomo and Ndabaningi Sithole. After their public campaigns were initially suppressed, many believed that negotiation was completely incapable of meeting their aspirations. Petrol bombings by radicals became increasingly common, with the "Zimbabwe Review" observing in 1961, "for the first time home-made petrol bombs were used by freedom fighters in Salisbury against settler establishments." It was officially noted that between January and September 1962 alone, 33 bombings were carried out, in addition to 27 acts of attempted sabotage on communications. In that same period, nationalists were implicated in arson targeting 18 schools and 10 churches. Nkomo's Zimbabwe African People's Union (ZAPU) subsequently disclosed that it had formed a military wing, the Zimbabwe People's Revolutionary Army (ZIPRA), and 'the decision to start bringing in arms and ammunition and to send young men away for sabotage training' had already been made. The Rhodesian authorities responded by banning ZAPU and driving its supporters underground. Frustrated by their repeated failures, nationalists also conducted a campaign of terror against black Africans, murdering those who had either identified with the colonial administration or had simply failed to demonstrate their allegiance to the cause. To protect civilians, emergency laws were imposed, broadening the legal definition of unlawful gatherings and giving the police greater powers to crack down on agitators or subversives. The death sentence was also introduced for terrorism involving explosives and arson.

A crisis of confidence soon resulted across ZAPU, which was already suffering from poor morale, compounded by tribal and ideological factionalism. In 1963, party dissidents rejected Joshua Nkomo's authority and formed their own organisation, the Zimbabwe African National Union (ZANU) â which worked out its own strategy for impressing international opinion, undermining white assurance, and achieving a complete breakdown of order. By August 1964, ZANU was banned by the Rhodesian government as well, which cited widespread intimidation by that party.

ZANU's agenda was inward-looking, leftist, and pan-Africanist in nature. Ndabaningi Sithole and avowed Marxist Robert Mugabe, its most prominent leaders, demanded a one-party Zimbabwean state with majority rule and a public monopoly on land. After being forced from Rhodesia, they continued to operate in exile, creating occupation groups representing urban workers, miners, and peasant farmers. ZANU also attracted professionals, students, and feminists to its ranks. While ZAPU theoretically continued to command the allegiance of most Ndebele and Shona activists, Sithole and Mugabe drew their support base from the rural peasantry in the Mashonaland countryside.

After the UDI, ZANU officials mapped an elaborate plan for the "liberation of Zimbabwe" which called for attacks on white farmers, destruction of cash crops, disrupting electricity in urban areas, and petrol bombings. They also formed an armed wing of their own, the Zimbabwe African National Liberation Army (ZANLA).

Sithole and Nkomo both insisted on the need for armed struggle, but disagreed on the means to go about it. For example, ZIPRA tended to follow Soviet thinking, placing an emphasis on sophisticated weaponry in the hopes of winning a conventional battle like the Viet Minh at Dien Bien Phu. ZANLA militants preferred to politicise populations in areas which they intended to seize. Neither force, however, had acquired basic knowledge of guerrilla warfare. Debate on political theory and insurgent tactics became the obsession of nationalists at this stage.

In April 1966, two ZANLA units, having received prior training at Nanjing Military College, crossed into Rhodesia from Zambia. They were armed with SKS carbines, hand grenades, explosives, and communist pamphlets, having been issued vague instructions to sabotage important installations before killing white persons indiscriminately. At least five guerrillas were simply arrested before getting very far. Another seven hoped to destroy a pylon carrying electricity to Sinoia in the northwest. Their faulty demolitions were uncovered by the Rhodesian Security Forces and the men easily tracked to a nearby ranch on 28 April, where they were shot resisting capture. This event is considered to have been the first engagement of what came to be known as the "Bush War" in Rhodesia and the "Second " (or "rebellion" in Shona) by supporters of the guerrillas.

The campaign proper is generally considered to have started in 1972 with the Attack on Altena Farm, despite the minor threat already represented by the nationalist movements in the 1960s.

After unsuccessful appeals to Britain and the United States for military assistance, Robert Mugabe, who was based in Mozambique after that country's independence from Portugal in 1975, led ZANU to seek support from the People's Republic of China and countries of the Soviet Bloc. Joshua Nkomo, based in Zambia and also supported by the Soviet Union, led ZAPU. ZANU and ZAPU together formed 'the Patriotic Front'. Broadly, ZANLA recruited mainly from Mashonaland and Manicaland provinces, whilst the ZIPRA recruited from Mashonaland West, Midlands and Matabeleland provinces of Zimbabwe. As Mugabe had described himself in an interview as a "Marxist-Leninist of Maoist Thought", which enraged the Kremlin, Soviet support went exclusively to ZAPU while China supported ZANU. Soviet arms went to the ZAPU via Zambia and Mozambique, and Nkomo was in regular contact with Vasili Grigoryevich Solodovnikov, the Soviet ambassador to Zambia who was also known to be associated with the KGB. Nkomo, who depended heavily on Soviet arms, had what he called an "extensive correspondence" with Yuri Andropov, the KGB chief, while officers from the Cuban DGI provided training for the ZAPU.

After the collapse of Portuguese rule in Mozambique in 1974â75, it was no longer viable for the Smith regime to sustain white minority rule indefinitely. By this time, even South Africa's Vorster had come to this view. While Vorster was unwilling to make concessions to his own country's blacks, he concluded that white minority rule was not sustainable in a country where blacks outnumbered whites 22:1. In 1978, there were 270,000 Rhodesians of European descent and more than six million Africans.

International business groups involved in the country (e.g. Lonrho) transferred their support from the Rhodesian government to black nationalist parties. Business leaders and politicians feted Nkomo on his visits to Europe. ZANU also attracted business supporters who saw the course that future events were likely to take. Funding and arms support provided by supporters, particularly from the Soviet Union and its allies in the latter 1970s, allowed both ZIPRA and the ZANLA to acquire more sophisticated weaponry, thereby increasing the military pressure that the guerrillas were able to place on Rhodesia.

Until 1972, containing the guerrillas was little more than a police action. Even as late as August 1975 when Rhodesian government and black nationalist leaders met at Victoria Falls for negotiations brokered by South Africa and Zambia, the talks never got beyond the procedural phase. Rhodesian representatives made it clear they were prepared to fight an all out war to prevent majority rule. However, the situation changed dramatically after the end of Portuguese colonial rule in Mozambique in 1975. Rhodesia now found itself almost entirely surrounded by hostile states and even South Africa, its only real ally, pressed for a settlement.

At this point, ZANU's alliance with FRELIMO (the Liberation Front of Mozambique) and the porous border between Mozambique and eastern Rhodesia enabled large-scale training and infiltration of ZANU/ZANLA fighters. The governments of Zambia and Botswana were also emboldened sufficiently to allow resistance movement bases to be set up in their territories. Guerrillas began to launch operations deep inside Rhodesia, attacking roads, railways, economic targets and isolated security force positions, in 1976.
The government adopted a strategic hamlets policy of the kind used in Malaya and Vietnam to restrict the influence of insurgents over the population of rural areas. Local people were forced to relocate to protected villages (PVs) which were strictly controlled and guarded by the government against rebel atrocities. The protected villages were compared by the guerrillas to concentration camps. Some contemporary accounts claim that this interference in the lives of local residents induced many of them who had previously been neutral to support the guerrillas.

The war degenerated into rounds of increasing brutality from all three parties involved (ZANU and ZAPU, and the Rhodesian Army). Mike Subritzky, a former NZ Army ceasefire monitor in Rhodesia, in 1980 described the war as "both bloody and brutal and brought out the very worst in the opposing combatants on all three sides."

A major problem for the Rhodesian state in fighting the Bush War was always a shortage of manpower. Of the 3,000 white men liable for conscription in 1973, only about 1,000 reported when called-up. In February 1978, the Rhodesian Army stated it needed a minimum of 1,041 men to continue combat operations, and of those called up, only 570 reported for duty while the rest chose to move to South Africa. The Rhodesian Army consistently out-fought the ZANU and ZAPU guerillas. However, white emigration caused a shortage of military manpower. White emigration increased as the state called up more and more men to fight in the war, creating a vicious circle, which gradually limited the capacity of the Rhodesian state to continue the war. In order to stop white emigration, the Smith government brought in a law in 1975 forbidding Rhodesian citizens from holding foreign currency, but the law was widely flouted. In order to encourage white emigration, the guerrillas of ZANU and ZAPU followed a strategy of attacking anything and everything that was of economic value across the country in order to force the state to call up more men, and of killing white civilians. Killing Rhodesian white citizens tended to have an "echo effect" as the ZANU and ZAPU had each estimated that for one white citizen killed, it caused about 20 to leave Rhodesia.

Rhodesia began to lose vital economic and military support from South Africa, which, while sympathetic to the white minority government, never accorded it diplomatic recognition. The South African government placed limits on the fuel and munitions they supplied to the Rhodesian military. They also withdrew the personnel and equipment that they had previously provided to aid the war effort, though covert military support continued.

In 1976, the South African government and United States governments worked together to place pressure on Smith to agree to a form of majority rule. In response to the initiative of US Secretary of State Henry Kissinger, in 1976 Ian Smith accepted the principle of black majority rule within two years. The Rhodesians now offered more concessions, but those concessions, focused on reaching an "internal settlement" with moderate black leaders, were insufficient to end the war.

At the time, some Rhodesians said the still embittered history between the British-dominated Rhodesia and the Afrikaner-dominated South Africa partly led the South African government to withdraw its aid to Rhodesia. Ian Smith said in his memoirs that even though many white South Africans supported Rhodesia, South African Prime Minister John Vorster's policy of dÃ©tente with the Black African states ended up with Rhodesia being offered as the "sacrificial lamb" to buy more time for South Africa. Other observers perceived South Africa's distancing itself from Rhodesia as being an early move in the process that led to majority rule in South Africa itself.

In the latter 1970s, the militants had successfully put the economy of Rhodesia under significant pressure while the numbers of guerrillas in the country were steadily increasing. The government abandoned its early strategy of trying to defend the borders in favour of trying to defend key economic areas and lines of communication with South Africa, while the rest of the countryside became a patchwork of "no-go areas".

By the late 1970s, Rhodesia's front-line forces contained about 25,000 regular troops and police â backed up by relatively strong army and police reserves. Its mechanised contingent consisted of light armoured cars and improvised mine-protected armoured personnel carriers, complemented by eight tanks (Polish built T-55LD tanks), delivered in the last year of the war. The Rhodesian Air Force operated an assortment of both Canberra light bombers, Hawker Hunter fighter bombers, older de Havilland Vampire jets as well as a somewhat antiquated, but still potent, helicopter arm. These forces, including highly trained special operations units, were capable of launching devastating raids on resistance movement camps outside the country, as in Operation Dingo in 1977 and other similar operations.

Nevertheless, guerrilla pressure inside the country itself was steadily increasing in the latter 1970s. By 1978â79, the war had become a contest between the guerrilla warfare placing ever increasing pressure on the Rhodesian regime and civil population, and the Rhodesian government's strategy of trying to hold off the militants until external recognition for a compromise political settlement with moderate black leaders could be secured.

By this time, the need to cut a deal was apparent to most Rhodesians, but not to all. Ian Smith had dismissed his intransigent Defence Minister, P. K. van der Byl, as early as 1976. Van der Byl was a hard-line opponent of any form of compromise with domestic opposition or the international community since before UDI.

Van der Byl eventually retired to his country estate outside Cape Town, but there were elements in Rhodesia, mainly embittered former security force personnel, who forcibly opposed majority rule up to and well beyond the establishment of majority rule. New white immigrants continued to arrive in Rhodesia right up to the eve of majority rule.

The work of journalists such as Lord Richard Cecil, son of the Marquess of Salisbury, stiffened the morale of Rhodesians and their overseas supporters. Lord Richard produced news reports for ITN which typically contrasted the incompetent insurgents with the "superbly professional" government troops. A group of ZANLA fighters killed Lord Richard on 20 April 1978 when he was accompanying a Rhodesian airborne unit employed in Fire Force Operations.

The shooting down on 3 September 1978 of the civilian Vickers Viscount airliner "Hunyani", Air Rhodesia Flight RH825, in the Kariba area by ZIPRA fighters using a surface-to-air missile, with the subsequent massacre of its survivors, is widely considered to be the event that finally destroyed the Rhodesians' will to continue the war. Although militarily insignificant, the loss of this aircraft (and a second Viscount, the "Umniati", in 1979) demonstrated the reach of resistance movements extended to Rhodesian civil society.

The Rhodesians' means to continue the war were also eroding fast. In December 1978, a ZANLA unit penetrated the outskirts of Salisbury and fired a volley of rockets and incendiary device rounds into the main oil storage depot â the most heavily defended economic asset in the country. The storage tanks burned for five days, giving off a column of smoke that could be seen away. of petroleum product (comprising Rhodesia's strategic oil reserve) were lost.

The government's defence spending increased from R$30 million, 8.5% of the national budget in 1971 to 1972, to R$400 m in 1978 to 1979, 47% of the national budget. In 1980, the post-independence government of Zimbabwe inherited a US$500 million national debt.

The Rhodesian army continued its "mobile counter-offensive" strategy of holding key positions ("vital asset ground") while carrying out raids into the no-go areas and into neighbouring countries. While often extraordinarily successful in inflicting heavy guerrilla casualties, such raids also on occasion failed to achieve their objectives. In April 1979 special forces carried out a raid on Joshua Nkomo's residence in Lusaka (Zambia) with the stated intention of assassinating him. Nkomo and his family left hastily a few hours before the raid â having clearly been warned that the raid was coming.

In 1979, some special forces units were accused of using counterinsurgent operations as cover for ivory poaching and smuggling. Colonel Reid-Daly (commander of the Selous Scouts) discovered that his phone was bugged and after challenging a superior officer on this issue was court martialled for insubordination. He received the lightest sentence possible, a caution, but he continued to fight his conviction and eventually resigned his commission and left the Army.

By 1978â79, up to 70% of the regular army was composed of black soldiers (though both the army and police reserves remained overwhelmingly white). By 1979 there were also 30 black commissioned officers in the regular army. While there was never any suggestion of disloyalty among the soldiers from predominantly black units (in particular within the Selous Scouts or the Rhodesian African Rifles â RAR), some argue that, by the time of the 1980 election, many of the RAR soldiers voted for Robert Mugabe.

As the result of an Internal Settlement signed on 3 March 1978 between the Rhodesian government and the moderate African nationalist parties, which were not in exile and not involved in the war, elections were held in April 1979. The United African National Council (UANC) party won a majority in this election, and its leader, Abel Muzorewa (a United Methodist Church bishop), became the country's first black prime minister on 1 June 1979. The country's name was changed to Zimbabwe Rhodesia. The internal settlement left control of the country's police, security forces, civil service and judiciary in white hands, for the moment. It assured whites of about one-third of the seats in parliament. It was essentially a power-sharing arrangement between whites and blacks which, in the eyes of many, particularly the insurgents, did not amount to majority rule. However, the United States Senate voted to end economic sanctions against Zimbabwe Rhodesia on 12 June.

While the 1979 election was described by the Rhodesian government as non-racial and democratic, it did not include the main nationalist parties ZANU and ZAPU. In spite of offers from Ian Smith, the latter parties declined to participate in an election in which their political position would be insecure and under a proposed constitution which they had played no part in drafting and which was perceived as retaining strong white minority privilege.

Bishop Muzorewa's government did not receive international recognition. The Bush War continued unabated and sanctions were not lifted. The international community refused to accept the validity of any agreement which did not incorporate the main nationalist parties. The British Government (then led by the recently elected Margaret Thatcher) issued invitations to all parties to attend a peace conference at Lancaster House. These negotiations took place in London in late 1979. The three-month-long conference almost failed to reach conclusion, due to disagreements on land reform, but resulted in the Lancaster House Agreement. UDI ended, and Rhodesia temporarily reverted to the status of a British colony (the 'Colony of Southern Rhodesia'). As per the agreement, Lord Soames became Governor with full legislative and executive powers.

The Lancaster House Agreement further provided for a ceasefire which was followed by an internationally supervised general election, held on February 1980. ZANU led by Robert Mugabe won this election, some alleged, by terrorising its political opposition, including supporters of ZAPU, through former insurgents that had not confined themselves to the designated guerrilla assembly points, as stipulated by the Lancaster House Agreement. The observers and Soames were accused of looking the other way, and Mugabe's victory was certified. Nevertheless, few could doubt that Mugabe's support within his majority Shona tribal group was extremely strong. The Rhodesian military seriously considered mounting a coup against a perceived stolen election ("Operation Quartz") to prevent ZANU from taking over the country. The alleged coup was to include the assassination of Mugabe and coordinated assaults on guerrilla assembly points throughout the country. The plan was eventually scuttled, as it was obvious that Mugabe enjoyed widespread support from the black majority despite voter intimidation, as well as the fact that the coup would gain no external support, and a conflagration which would engulf the country was seen as inevitable.

Mugabe (and nationalists who supported his rule) were rather less concerned by Operation Quartz than by the possibility that there might be a mass exodus of the white community of the kind that had caused chaos in Mozambique five years earlier. Such an exodus had been prepared for by the South African government. With the agreement of the British Governor of Rhodesia, South African troops had entered the country to secure the road approaches to the Beit Bridge border crossing point. Refugee camps had been prepared in the Transvaal. On the day the election results became known, most white families had prepared contingency plans for flight, including the packing of cars and suitcases.

However, after a meeting with Robert Mugabe and the central committee of ZANU (PF), Ian Smith was reassured that whites could and should stay in the new Zimbabwe. Mugabe promised that he would abide strictly by the terms of the Lancaster House Agreement and that changes in Zimbabwe would be made gradually and by a proper legal process. In a CBS news interview, Mugabe claimed that Rhodesian whites "...are still in control of the economy, the majority being commercial farmers." Mugabe, however, would reverse his commitment to these agreements some years later; the regime began confiscating white-owned farmlands. This is widely blamed for leading to the deterioration of the Zimbabwean economy, which plagues the country today.

On 18 April 1980 the country became independent within the Commonwealth of Nations as the Republic of Zimbabwe, and its capital, Salisbury, was renamed Harare two years later.

Rhodesia is equivalent in territory to modern Zimbabwe. It was a landlocked country in southern Africa, lying between latitudes 15Â° and 23Â°S, and longitudes 25Â° and 34Â°E. It was bordered by South Africa to the south, the Bechuanaland Protectorate (later Botswana) to the west and southwest, Zambia to the northwest, and Mozambique to the east and northeast. Its northwest corner was roughly from South West Africa (present-day Namibia), South Africa, nearly forming a four-nation quadripoint. Most of the country was elevated, consisting of a central plateau (high veld) stretching from the southwest northwards with altitudes between . The country's extreme east was mountainous, this area being known as the Eastern Highlands, with Mount Inyangani as the highest point at .

Rhodesia had a tropical climate with many local variations. The southern areas are known for their heat and aridity, parts of the central plateau receive frost in winter, the Zambezi valley is also known for its extreme heat and the Eastern Highlands usually experience cool temperatures and the highest rainfall in the country. The country's rainy season was from late October to March and the hot climate is moderated by increasing altitude. The country was faced with recurring droughts, and severe storms are rare.

The country was mostly savannah, although the moist and mountainous eastern highlands support areas of tropical evergreen and hardwood forests. Trees found in these Eastern Highlands included teak, mahogany, enormous specimens of strangling fig, forest newtonia, big leaf, white stinkwood, chirinda stinkwood, knobthorn and many others.

In the low-lying parts of the country fever trees, mopane, combretum and baobabs abound. Much of the country was covered by miombo woodland, dominated by brachystegia species and others. Among the numerous flowers and shrubs are hibiscus, flame lily, snake lily, spider lily, leonotus, cassia, tree wisteria and dombeya. There are around 350 species of mammals that can be found in Rhodesia. There are also many snakes and lizards, over 500 bird species, and 131 fish species.

Although Southern Rhodesia never gained full dominion status within the Commonwealth of Nations, Southern Rhodesians ruled themselves from the attainment of 'Responsible Government' in 1923. Its electoral register had property and education qualifications. Over the years various electoral arrangements made at a national and municipal level upheld these standards. For example, the franchise for the first Southern Rhodesian Legislative Council election in 1899 contained the following requirement:

voters to be British subjects, male, 21 years of age and older, able to write their address and occupation, and then to fulfil the following financial requirements: (a) ownership of a registered mining claim in Southern Rhodesia, or (b) occupying immovable property worth Â£75, or (c) receiving wages or salary of Â£50 per annum in Southern Rhodesia. Six months' continuous residence was also required for qualifications (b) and (c).

Following Cecil Rhodes's dictum of "equal rights for all civilised men", there was no overt racial component to the franchise. However, the requirement excluded a majority of native blacks from the electorate.

Up until the 1950s, Southern Rhodesia had a vibrant political life with right and left wing parties competing for power. The Rhodesian Labour Party held seats in the Assembly and in municipal councils throughout the 1920s and 1930s. From 1953 to 1958, the prime minister was Garfield Todd, a liberal who did much to promote the development of the Black community through investment in education, housing and healthcare. However, the government forced Todd from office because his proposed reforms were seen by many whites as too radical.

From 1958 onwards, white settler politics consolidated and ossified around resistance to majority rule, setting the stage for UDI. The 1961 Constitution governed Southern Rhodesia and independent Rhodesia up until 1969, using the Westminster Parliamentary System modified by a system of separate voter rolls with differing property and education qualifications, without regard to race. Whites ended up with the majority of Assembly seats.

The 1969 republican constitution established a bicameral Parliament consisting of an indirectly elected Senate and a directly elected House of Assembly, effectively reserving the majority of seats for whites. The office of President had only ceremonial significance with the Prime Minister holding executive power.

The Constitution of the short-lived Zimbabwe Rhodesia, which saw a black-led government elected for the first time, reserved 28 of the 100 parliamentary seats for whites. The independence constitution agreed at Lancaster House watered those provisions down and reserved 20 out of 100 seats for whites in the House of Assembly and 8 out of 40 seats in the Senate. The constitution prohibited Zimbabwe authorities from altering the Constitution for seven years without unanimous consent and required a three-quarters vote in Parliament for a further three years. The government amended the Constitution in 1987 to abolish the seats reserved for whites, and replace the office of Prime Minister with an executive President. In 1990, the government abolished the Senate.

Southern Rhodesia had long been distinctive among British dependencies in that it had financed and developed its own security forces and command structure. After UDI, this posed a particular dilemma for the British government, which considered and rejected various proposals aimed at ending Rhodesia's state of rebellion by force. Harold Wilson once remarked that bringing an end to Rhodesian independence "would not be a case of arresting a subversive individual. It would mean a bloody war, and probably a bloody war turning into a bloody civil war." The formidable nature of the Rhodesian security forces, as well as British fears of a direct South African intervention on behalf of the rogue colony, preempted the further consideration of military options.

For much of its history Rhodesia had a small professional standing army of 3,400 troops, about a third of whom were black volunteers. The troops were organised into light infantry battalions optimised for counter-insurgency and unconventional warfare, and they possessed little artillery or armour. The Royal Rhodesian Air Force had 1,000 personnel and six squadrons of aircraft, including forty to fifty Hawker Hunter and de Havilland Vampire strike aircraft and English Electric Canberra light bombers. It also possessed a helicopter squadron, a transport squadron, and a light reconnaissance squadron. The Rhodesian military was backed by the British South Africa Police (BSAP), a well-equipped police force whose title was derived from the law enforcement division of the British South Africa Company. The BSAP had armoured vehicles of its own and a potent paramilitary capability. Domestic and external intelligence gathering were vested in the Central Intelligence Organisation.

As a result of the escalating rural insurgency, the Rhodesian Security Forces began to depend more heavily on white conscripts and reservists of the Territorial Force and Territorial reserves. Regular units remained small throughout the Rhodesian Bush War but became increasingly specialised and were often able to have an effect utterly disproportionate to their size. The security forces included a disproportionate number of personnel who had seen action during the First Malayan Emergency as well as the Aden Emergency, and their experience gave Rhodesia's defence establishment a solid grounding in counter-insurgency warfare and small unit tactics in particular. Nevertheless, the vastness of the operational area and Rhodesia's limited manpower pool left the army, air force, and BSAP constantly overstretched. Budgetary and resource restraints, coupled with manpower shortages, meant the security forces could not expand quickly enough to match the guerrilla movements, and were almost always outnumbered. Rhodesian units compensated for their disadvantage in this regard by pursuing an aggressive preemptive and counterstrike strategy, raiding neighbouring states to destroy guerrilla forces in their external sanctuaries.

All male Rhodesian citizens aged eighteen to twenty-three, except blacks, were obligated to fulfill four and a half months (later extended to nine months) of full-time national service. This was followed by a three-year reservist obligation. By 1974 the national service intakes had been doubled, and whites over twenty-three were also conscripted. In 1978 the Rhodesian Army had about 14,000 white national servicemen, but continued manpower shortages forced it to recruit black volunteers in larger numbers and extend compulsory military service to all white males up to sixty years of age. By the end of the Rhodesian Bush War virtually all male white Rhodesians were either serving in the military or police in a full-time or part-time capacity. The size of the Rhodesian Army had swelled to about 20,000 personnel, and the BSAP to over 40,000, including reservists.

From 1975 to 1980 the Rhodesian government made several attempts to weaponise chemical and biological agents. Members of the security forces contaminated supplies before replacing them in guerrilla caches or planted them in rural stores to be stolen by the guerrillas during raids. They also poisoned water sources along known infiltration routes along the Rhodesian border, forcing their opponents to travel through more arid regions or carry more water during their treks.

The chemical agents most used in the Rhodesian chemical and biological warfare (CBW) programme were parathion (an organophosphate insecticide) and thallium (a heavy metal commonly found in rodenticide). The weapons the Rhodesians selected for use also included "Vibrio cholerae" (causative agent of cholera) and possibly "Bacillus anthracis" (causative agent of anthrax). They also looked at using "Rickettsia prowazekii" (causative agent of epidemic typhus), and "Salmonella typhi" (causative agent of typhoid fever), and toxins such as ricin and botulinum toxin.

Biological agents, namely "Vibrio cholerae" (causative agent of cholera), had some impact on the fighting capability of ZANLA. Some former officers of the Rhodesian Security Forces alleged that anthrax was used covertly during the late 1970s, but this has been disputed. Use of "anthracis", ricin, or botulinum toxin was favoured during assassination attempts of prominent guerrilla commanders.

Economically, Southern Rhodesia developed an economy that was narrowly based on the production of a few primary products, notably, chromium and tobacco. It was therefore vulnerable to the economic cycle. The deep recession of the 1930s gave way to a post-war boom. This boom prompted the immigration of about 200,000 whites between 1945 and 1970, taking the white population up to 307,000. A large number of these immigrants were of British working-class origin, with others coming from the Belgian Congo, Kenya, Tanzania, and later Angola and Mozambique. They established a relatively balanced economy, transforming what was once a primary producer dependent on backwoods farming into an industrial giant which spawned a strong manufacturing sector, iron and steel industries, and modern mining ventures. These economic successes owed little to foreign aid apart from the immigration of skilled labour.

The economy of the state of Rhodesia sustained international sanctions for a decade following the declaration of its independence, a resistance which waned as more southern African states declared independence and majority rule as well as the destruction of the Rhodesian Bush War.

A central feature of the white community in Rhodesia was its transience, as white settlers were just as likely to leave Rhodesia after a few years as permanently settle; for example, of the 700 British settlers who were the first white settlers, arriving in 1890, only 15 were still living in Rhodesia in 1924. As the white population of Rhodesia had a low birth rate (18 per 1,000 compared to the African rate of 48 per 1,000), to maintain white population growth was largely dependent upon taking in new white immigrants with immigration accounting for 60% of the growth of the white Rhodesian population between 1955â72. However, the American historian Josiah Brownell noted that the turnover rate for white residents in Rhodesia was very high, as Rhodesia took in a total of 255,692 white immigrants between 1955â79 while the same period a total of 246,583 whites emigrated. Even during the boom years of the late 1950s, when Rhodesia took in an average of 13,666 white immigrants per year, mostly from the United Kingdom and South Africa, an average of about 7,666 whites emigrated annually. Between 1961â65, Rhodesia took in an average of 8,225 white immigrants per year while also having an average white emigration of 12, 912 per year. Many prospective white immigrants in Rhodesia arrived seeking economic opportunities and departed with fluctuations in the security situation as the Bush War intensified. A substantial number were uninterested in settling there permanently and did not apply for Rhodesian citizenship, despite a much-publicised 1967 campaign urging them to do so. Brownell asserted that patriotism in the white community was "shallow" due to its essentially expatriate character. Brownell also claimed that the majority of white immigrants in the late 1960s and early 1970s were unskilled laborers who competed with the country's black African workforce and did not contribute badly needed technical or professional skills to the country. He argued that this was due to a government policy aimed at making white immigration as "unselective as possible" and guaranteeing every white immigrant a job.

The population of Rhodesia boomed during the late 1960s due to immigration and an exceptional rate of natural increase among its black citizens, the highest in sub-Saharan Africa at the time.

White Rhodesians mostly spoke English, with a minority that spoke Afrikaans and the remainder either spoke Dutch, French, German, Greek, Italian, Polish or Portuguese. Approximately 70% of black Rhodesians spoke Shona, and around 20% spoke Ndebele.

Rhodesia was a predominantly Christian country.

Throughout the period of its Unilateral Declaration of Independence (1965 to 1979), Rhodesia pursued a foreign policy of attempting to secure recognition as an independent country, and insisting that its political system would include 'gradual steps to majority rule.' Ardently anti-communist, Rhodesia tried to present itself to the West as a front-line state against communist expansion in Africa, to little avail. Rhodesia received little international recognition during its existence; recognition only occurred after elections in 1980 and a transition to majority rule.

Rhodesia wished to retain its economic prosperity and also feared communist elements in the rebel forces, and thus felt their policy of a gradual progression to black majority rule was justified. However, the international community refused to accept this rationale, believing that their policies were perpetuating racism. This attitude was part of the larger decolonisation context, during which Western powers such as the United Kingdom, France, and Belgium hastened to grant independence to their colonies in Africa.

Rhodesia was originally a British colony. Although decolonisation in Africa had begun after World War II, it began accelerating in the early 1960s, causing Britain to negotiate independence rapidly with several of its colonies. During this period, it adopted a foreign policy called NIBMAR, or No Independence Before Majority African Rule, mandating democratic reforms that placed governance in the hands of the majority black Africans. The governing white minority of Rhodesia, led by Ian Smith, opposed the policy and its implications. On 11 November 1965, Rhodesia's minority white government made a unilateral declaration of independence (UDI) from the United Kingdom, as it became apparent that negotiations would not lead to independence under the white regime.

The United Kingdom government immediately brought in legislation (Southern Rhodesia Act 1965) which formally abolished all Rhodesian government institutions. This move made life difficult for Rhodesian citizens who wished to travel internationally as passports issued by Rhodesia's UDI administration were not recognised as valid; in January 1966, the British issued a statement accepting as valid any passport issued before the declaration of independence and allowing six-month United Kingdom passports to be granted when they expired â provided that the bearer declared they did not intend to aid the UDI Rhodesian government.

Until late 1969, Rhodesia still recognised Queen Elizabeth II as head of state, even though it opposed the British government itself for hindering its goals of independence. The Queen, however, refused to accept the title "Queen of Rhodesia." Eventually, the Smith government abandoned attempts to remain loyal to the British Crown, and in 1969, a majority of the electorate voted in referendum to declare Rhodesia a republic. They hoped that this move would facilitate recognition as an independent state by the international community, but the issues of white minority control remained and hindered this effort, and like the UDI before it, the proclamation of a republic lacked international recognition.

After the declaration of independence, and indeed for the entire duration of its existence, Rhodesia did not receive official recognition from any state, although it did maintain diplomatic relations with South Africa, which was then under apartheid. South Africa did not recognise Rhodesia to preserve its fragile positions with other nations, but frequently assisted the Rhodesian state. Portugal maintained informal relations until the Carnation Revolution of 1974. The day following the declaration of independence, the United Nations Security Council passed a resolution (S/RES/216) calling upon all states not to accord Rhodesia recognition, and to refrain from any assistance. The Security Council also imposed selective mandatory economic sanctions, which were later made comprehensive.

Malawi, Israel, South Africa, Portugal and Iran did not comply with economic sanctions against Rhodesia. The US, despite voting in favour of the sanctions at the UNSC, violated them to buy chromium ore from Rhodesia. Kenneth Kaunda, president of Zambia, also accused western oil companies of violating the sanctions and selling oil to Rhodesia.

Rhodesia's Unilateral Declaration of Independence from the United Kingdom on 11 November 1965 was promptly condemned by the international community. The United Nations Security Council Resolution 216 of 12 November 1965 called "upon all States not to recognise this illegal racist minority regime in Southern Rhodesia."

Rhodesia campaigned for international acceptance and invoked the doctrine of non-intervention in internal affairs as justification for rebuking external criticism of its internal policies. However, the emerging doctrine of self-determination in colonial situations meant that most nations regarded Rhodesia's self-declared independence as illegitimate.

Zambia, formerly Northern Rhodesia, took a pragmatic approach towards Rhodesia. Kenneth Kaunda, heavily dependent on access through Rhodesia for his nation's copper ore exports, fuel, and power imports unofficially worked with the Rhodesian government. Rhodesia still allowed Zambia to export and import its goods through its territory to Mozambique ports, despite the Zambian government's official policy of hostility and non-recognition of the post-UDI Smith Administration.

The United States, like all other Western nations, refused to recognise Rhodesia, but unlike others allowed its Consulate-General to function as a communications conduit between the US government in Washington, DC and the Rhodesian government in Salisbury. When Rhodesia set up an information office in Washington, DC, OAS nations loudly protested. The US government responded by saying the Rhodesian mission and its staff had no official diplomatic status and violated no US laws.

Portugal pursued a middle path with Rhodesia. While not officially recognising Rhodesia under Ian Smith, the government of AntÃ³nio Salazar did permit Rhodesia to establish a representative mission in Lisbon, and permitted Rhodesian exports and imports through their colony of Mozambique. The Portuguese government in power at that time, authoritarian and ardently anti-communist, gave active behind-the-scenes support in Rhodesia's fight against the guerrilla groups.

South Africa, itself under international pressure as a white minority government, pursued a policy of dÃ©tente with the black African states at the time. These states wanted South Africa to pressure Ian Smith to accept a faster transition to majority rule in Rhodesia, in return for pledges of non-interference in South Africa's internal affairs. Prime Minister John Vorster, believing majority rule in Rhodesia would lead to international acceptance for South Africa, used a number of tactics to pressure Smith. The South African government held up shipments of fuel and ammunition and pulled out friendly South African forces from Rhodesia. The combined loss of Mozambique and the loss of support from South Africa dealt critical blows to the Rhodesian government.

After the UDI, Rhodesia maintained several overseas missions, including Pretoria, and until 1975, Lisbon in Portugal and LourenÃ§o Marques (now Maputo) in Mozambique.

Since 1961, Rhodesia had an "Accredited Diplomatic Representative" with South Africa, heading a "Rhodesian Diplomatic Mission" or "de facto" embassy. Before South Africa left the Commonwealth that year, the then Southern Rhodesia had exchanged High Commissioners with the then Union of South Africa, but following the change in status, the Republic now had a "South African Diplomatic Mission" in Salisbury.

During 1965, the government of Rhodesia made moves to establish a mission in Lisbon separate from the British Embassy, with its own accredited representative, having previously been able to establish its own consulate in LourenÃ§o Marques, capital of Portuguese Mozambique. This prompted protests from the British government, which was determined that the representative, Harry Reedman, should be a nominal member of the British Ambassador's staff. For their part, the Portuguese authorities sought a compromise whereby they would accept Reedman as an independent representative but deny him diplomatic status.

The Rhodesian Information Office in Washington remained open following UDI, but its director, Ken Towsey, and his staff were deprived of their diplomatic status. Previously, there had been a "Minister for Rhodesian Affairs" operating under the aegis of the British Embassy in Washington, as well representatives in Tokyo and Bonn. Following the country's independence as Zimbabwe, Towsey became chargÃ© d'affaires at the new Embassy.

The High Commission in London, known as Rhodesia House, continued to function until it was closed in 1969 following the decision by white Rhodesians in a referendum to make the country a republic, along with the "British Residual Mission" in Salisbury. Prior to its closure, the mission flew the newly adopted Flag of Rhodesia, considered illegal by the Foreign Office, prompting calls by Labour MP Willie Hamilton for its removal.
In Australia, the federal government in Canberra sought to close the Rhodesian Information Centre in Sydney, but it remained open, operating under the jurisdiction of the state of New South Wales. In 1973, the Labor government of Gough Whitlam cut post and telephone links to the Centre, but this was ruled illegal by the High Court. An office was also established in Paris, but this was closed down by the French government in 1977.

Similarly, the United States recalled its consul-general from Salisbury, and reduced consular staff, but did not move to close its consulate until the declaration of a republic in 1970. South Africa, however, retained its "Accredited Diplomatic Representative" after UDI, which allowed it to continue to recognise British sovereignty as well as to deal with the "de facto" authority of the government of Ian Smith.

The South African Diplomatic Mission in Salisbury became the only such mission remaining in the country after 1975, when Portugal downgraded its mission to consul level, having recalled its consul-general in Salisbury in May 1970. After Zimbabwe's independence, the new government closed its missions in Pretoria and Cape Town, only maintaining a trade mission in Johannesburg, while the South African Diplomatic Mission in Salisbury was also closed.

Continuing civil war and a lack of international support eventually led the Rhodesian government to submit to an agreement with the UK in 1979. This led to internationally supervised elections, won by Zimbabwe African National Union - Patriotic Front and Robert Mugabe, establishing the internationally recognised Zimbabwe.

In the ten years after independence, around 60% of the white population of Zimbabwe emigrated, most to South Africa and to other mainly white, English speaking countries where they formed expatriate communities. Politically within Zimbabwe, the consolidation of power by Robert Mugabe continued through the 1980s. Following amendments to the country's constitution in 1987, parliamentary seats reserved for whites were abolished, and an executive presidency was created, held by Mugabe. Many expatriates and some of the whites who stayed in Zimbabwe became deeply nostalgic for Rhodesia. These individuals are known as "Rhodies." Native whites who are more accepting of the new order are known as "Zimbos."

While as Rhodesia, the country was once considered the breadbasket of Africa. Today, Zimbabwe is a net importer of foodstuffs, with the European Union and United States providing emergency food relief as humanitarian aid on a regular basis. The nation has suffered profound economic and social decline in the past twenty years. Recently the agriculture sector has started to do well since the availability of expertise and machines has improved supported mainly by China.

Zimbabwe also suffered from a crippling inflation rate, as the Reserve Bank of Zimbabwe had a policy of printing money to satisfy government debt. This policy caused the inflation rate to increase from 32% in 1998 to 11,200,000% in 2007. Monetary aid by the International Monetary Fund was suspended due to the Zimbabwe government's defaulting on past loans, its inability to stabilise its own economy, its inability to stem corruption and its failure to advance human rights. In 2009, Zimbabwe abandoned its currency, relying instead on foreign currencies.

In the 2008 elections, Mugabe garnered 41%, Simba Makoni 10% and Morgan Tsvangirai 48% of the votes cast for president, forcing a runoff election called by the Zimbabwe Electoral Commission (ZEC). In the months leading to the run-off, instances of extreme violence between the two major parties (ZANU PF and MDC) led Tsvangirai to withdraw from the election. In February 2009, a power-sharing accord was reached which resulted in the Zimbabwe Government of National Unity of 2009. The accord was, essentially, to create the position of "Prime Minister" for Tsvangirai, who served in that role from 2009 to 2013. Mugabe retained the title of President.

The main newspapers were the "Rhodesia Herald" in Salisbury and "The Chronicle" in Bulawayo. Following UDI, in 1976, the state-run Rhodesian Broadcasting Corporation (RBC) took over the privately owned Rhodesian Television (RTV) service, in which it had previously acquired a 51 per cent stake.
Among the news magazines published in Rhodesia under UDI were the "Illustrated Life Rhodesia", while "The Valiant Years" by Beryl Salt told the history of Rhodesia from 1890 to 1978 entirely through the medium of facsimile reproduction of articles and headlines from Rhodesian newspapers.

Since Rhodesia was a former colony of the United Kingdom, all of the sports that were born in the United Kingdom enjoyed considerable popularity in Rhodesia; especially cricket, rugby, football, netball, golf, tennis, lawn bowls, field hockey, etc. Just like neighbouring South Africa, Rhodesia was barred from both competing against and participating with Commonwealth member countries.





</doc>
<doc id="26220" url="https://en.wikipedia.org/wiki?curid=26220" title="Relational model">
Relational model

The relational model (RM) for database management is an approach to managing data using a structure and language consistent with first-order predicate logic, first described in 1969 by English computer scientist Edgar F. Codd, where all data is represented in terms of tuples, grouped into relations. A database organized in terms of the relational model is a relational database.

The purpose of the relational model is to provide a declarative method for specifying data and queries: users directly state what information the database contains and what information they want from it, and let the database management system software take care of describing data structures for storing the data and retrieval procedures for answering queries.

Most relational databases use the SQL data definition and query language; these systems implement what can be regarded as an engineering approximation to the relational model. A "table" in an SQL database schema corresponds to a predicate variable; the contents of a table to a relation; key constraints, other constraints, and SQL queries correspond to predicates. However, SQL databases deviate from the relational model in many details, and Codd fiercely argued against deviations that compromise the original principles.

The relational model's central idea is to describe a database as a collection of predicates over a finite set of predicate variables, describing constraints on the possible values and combinations of values. The content of the database at any given time is a finite (logical) model of the database, i.e. a set of relations, one per predicate variable, such that all predicates are satisfied. A request for information from the database (a database query) is also a predicate.
Other models are the hierarchical model and network model. Some systems using these older architectures are still in use today in data centers with high data volume needs, or where existing systems are so complex and abstract that it would be cost-prohibitive to migrate to systems employing the relational model. Also of note are newer object-oriented databases.

There have been several attempts to produce a true implementation of the relational database model as originally defined by Codd and explained by Date, Darwen and others, but none have been popular successes so far. Rel is one of the more recent attempts to do this.

The relational model was the first database model to be described in formal mathematical terms. Hierarchical and network databases existed before relational databases, but their specifications were relatively informal. After the relational model was defined, there were many attempts to compare and contrast the different models, and this led to the emergence of more rigorous descriptions of the earlier models; though the procedural nature of the data manipulation interfaces for hierarchical and network databases limited the scope for formalization.

Structural database analytics employing relational modality protocols frequently employ data sequence differentials to maintain hierarchical architecture designations with incorporation of new input. These systems are functionally similar in concept to alternative relay algorithms, which form the foundation of cloud database infrastructure.

The relational model was invented by Edgar F. Codd as a general model of data, and subsequently promoted by Chris Date and Hugh Darwen among others. In The Third Manifesto (first published in 1995) Date and Darwen attempt to show how the relational model can allegedly accommodate certain "desired" object-oriented features.

Codd himself, some years after publication of his 1970 model, proposed a three-valued logic (True, False, Missing/NULL) version of it to deal with missing information, and in his "The Relational Model for Database Management Version 2" (1990) he went a step further with a four-valued logic (True, False, Missing but Applicable, Missing but Inapplicable) version. But these have never been implemented, presumably because of attending complexity. SQL's NULL construct was intended to be part of a three-valued logic system, but fell short of that due to logical errors in the standard and in its implementations.

The fundamental assumption of the relational model is that all data is represented as mathematical "n"-ary relations, an "n"-ary relation being a subset of the Cartesian product of "n" domains. In the mathematical model, reasoning about such data is done in two-valued predicate logic, meaning there are two possible evaluations for each proposition: either "true" or "false" (and in particular no third value such as "unknown", or "not applicable", either of which are often associated with the concept of NULL). Data are operated upon by means of a relational calculus or relational algebra, these being equivalent in expressive power.

The relational model of data permits the database designer to create a consistent, logical representation of information. Consistency is achieved by including declared constraints in the database design, which is usually referred to as the "logical schema". The theory includes a process of database normalization whereby a design with certain desirable properties can be selected from a set of logically equivalent alternatives. The access plans and other implementation and operation details are handled by the DBMS engine, and are not reflected in the logical model. This contrasts with common practice for SQL DBMSs in which performance tuning often requires changes to the logical model.

The basic relational building block is the domain or data type, usually abbreviated nowadays to type. A "tuple" is an ordered set of attribute values. An attribute is an ordered pair of attribute name and type name. An attribute value is a specific valid value for the type of the attribute. This can be either a scalar value or a more complex type.

A relation consists of a heading and a body. A heading is a set of attributes. A body (of an "n"-ary relation) is a set of "n"-tuples. The heading of the relation is also the heading of each of its tuples.

A relation is defined as a set of "n"-tuples. In both mathematics and the relational database model, a set is an "unordered" collection of unique, non-duplicated items, although some DBMSs impose an order to their data. In mathematics, a tuple has an order, and allows for duplication. E.F. Codd originally defined tuples using this mathematical definition. Later, it was one of E.F. Codd's great insights that using attribute names instead of an ordering would be more convenient (in general) in a computer language based on relations . This insight is still being used today. Though the concept has changed, the name "tuple" has not. An immediate and important consequence of this distinguishing feature is that in the relational model the Cartesian product becomes commutative.

A table is an accepted visual representation of a relation; a tuple is similar to the concept of a "row".

A "relvar" is a named variable of some specific relation type, to which at all times some relation of that type is assigned, though the relation may contain zero tuples.

The basic principle of the relational model is the Information Principle: all information is represented by data values in relations. In accordance with this Principle, a relational database is a set of relvars and the result of every query is presented as a relation.

The consistency of a relational database is enforced, not by rules built into the applications that use it, but rather by "constraints", declared as part of the logical schema and enforced by the DBMS for all applications. In general, constraints are expressed using relational comparison operators, of which just one, "is subset of" (â), is theoretically sufficient. In practice, several useful shorthands are expected to be available, of which the most important are candidate key (really, superkey) and foreign key constraints.

To fully appreciate the relational model of data it is essential to understand the intended "interpretation" of a relation.

The body of a relation is sometimes called its extension. This is because it is to be interpreted as a representation of the extension of some predicate, this being the set of true propositions that can be formed by replacing each free variable in that predicate by a name (a term that designates something).

There is a one-to-one correspondence between the free variables of the predicate and the attribute names of the relation heading. Each tuple of the relation body provides attribute values to instantiate the predicate by substituting each of its free variables. The result is a proposition that is deemed, on account of the appearance of the tuple in the relation body, to be true. Contrariwise, every tuple whose heading conforms to that of the relation, but which does not appear in the body is deemed to be false. This assumption is known as the closed world assumption: it is often violated in practical databases, where the absence of a tuple might mean that the truth of the corresponding proposition is unknown. For example, the absence of the tuple ('John', 'Spanish') from a table of language skills cannot necessarily be taken as evidence that John does not speak Spanish.

For a formal exposition of these ideas, see the section Set-theoretic Formulation, below.

A data type as used in a typical relational database might be the set of integers, the set of character strings, the set of dates, or the two boolean values "true" and "false", and so on. The corresponding type names for these types might be the strings "int", "char", "date", "boolean", etc. It is important to understand, though, that relational theory does not dictate what types are to be supported; indeed, nowadays provisions are expected to be available for "user-defined" types in addition to the "built-in" ones provided by the system.

Attribute is the term used in the theory for what is commonly referred to as a column. Similarly, table is commonly used in place of the theoretical term relation (though in SQL the term is by no means synonymous with relation). A table data structure is specified as a list of column definitions, each of which specifies a unique column name and the type of the values that are permitted for that column. An attribute "value" is the entry in a specific column and row, such as "John Doe" or "35".

A tuple is basically the same thing as a row, except in an SQL DBMS, where the column values in a row are ordered. (Tuples are not ordered; instead, each attribute value is identified solely by the attribute name and never by its ordinal position within the tuple.) An attribute name might be "name" or "age".

A relation is a table structure definition (a set of column definitions) along with the data appearing in that structure. The structure definition is the heading and the data appearing in it is the body, a set of rows. A database relvar (relation variable) is commonly known as a base table. The heading of its assigned value at any time is as specified in the table declaration and its body is that most recently assigned to it by invoking some update operator (typically, INSERT, UPDATE, or DELETE). The heading and body of the table resulting from evaluation of some query are determined by the definitions of the operators used in the expression of that query. (Note that in SQL the heading is not always a set of column definitions as described above, because it is possible for a column to have no name and also for two or more columns to have the same name. Also, the body is not always a set of rows because in SQL it is possible for the same row to appear more than once in the same body.)

SQL, initially pushed as the standard language for relational databases, deviates from the relational model in several places. The current ISO SQL standard doesn't mention the relational model or use relational terms or concepts. However, it is possible to create a database conforming to the relational model using SQL if one does not use certain SQL features.

The following deviations from the relational model have been noted in SQL. Note that few database servers implement the entire SQL standard and in particular do not allow some of these deviations. Whereas NULL is ubiquitous, for example, allowing duplicate column names within a table or anonymous columns is uncommon.


Users (or programs) request data from a relational database by sending it a query that is written in a special language, usually a dialect of SQL. Although SQL was originally intended for end-users, it is much more common for SQL queries to be embedded into software that provides an easier user interface. Many Web sites, such as Wikipedia, perform SQL queries when generating pages.

In response to a query, the database returns a result set, which is just a list of rows containing the answers. The simplest query is just to return all the rows from a table, but more often, the rows are filtered in some way to return just the answer wanted.

Often, data from multiple tables are combined into one, by doing a join. Conceptually, this is done by taking all possible combinations of rows (the Cartesian product), and then filtering out everything except the answer. In practice, relational database management systems rewrite ("optimize") queries to perform faster, using a variety of techniques.

There are a number of relational operations in addition to join. These include project (the process of eliminating some of the columns), restrict (the process of eliminating some of the rows), union (a way of combining two tables with similar structures), difference (that lists the rows in one table that are not found in the other), intersect (that lists the rows found in both tables), and product (mentioned above, which combines each row of one table with each row of the other). Depending on which other sources you consult, there are a number of other operatorsÂ â many of which can be defined in terms of those listed above. These include semi-join, outer operators such as outer join and outer union, and various forms of division. Then there are operators to rename columns, and summarizing or aggregating operators, and if you permit relation values as attributes (relation-valued attribute), then operators such as group and ungroup. The SELECT statement in SQL serves to handle all of these except for the group and ungroup operators.

The flexibility of relational databases allows programmers to write queries that were not anticipated by the database designers. As a result, relational databases can be used by multiple applications in ways the original designers did not foresee, which is especially important for databases that might be used for a long time (perhaps several decades). This has made the idea and implementation of relational databases very popular with businesses.

Relations are classified based upon the types of anomalies to which they're vulnerable. A database that's in the first normal form is vulnerable to all types of anomalies, while a database that's in the domain/key normal form has no modification anomalies. Normal forms are hierarchical in nature. That is, the lowest level is the first normal form, and the database cannot meet the requirements for higher level normal forms without first having met all the requirements of the lesser normal forms.

An idealized, very simple example of a description of some relvars (relation variables) and their attributes:

In this design we have six relvars: Customer, Order, Order Line, Invoice, Invoice Line and Product. The bold, underlined attributes are "candidate keys". The non-bold, underlined attributes are "foreign keys".

Usually one candidate key is chosen to be called the primary key and used in preference over the other candidate keys, which are then called alternate keys.

A "candidate key" is a unique identifier enforcing that no tuple will be duplicated; this would make the relation into something else, namely a bag, by violating the basic definition of a set. Both foreign keys and superkeys (that includes candidate keys) can be composite, that is, can be composed of several attributes. Below is a tabular depiction of a relation of our example Customer relvar; a relation can be thought of as a value that can be attributed to a relvar.

If we attempted to "insert" a new customer with the ID "1234567890", this would violate the design of the relvar since Customer ID is a "primary key" and we already have a customer "1234567890". The DBMS must reject a transaction such as this that would render the database inconsistent by a violation of an integrity constraint.

"Foreign keys" are integrity constraints enforcing that the value of the attribute set is drawn from a "candidate key" in another relation. For example, in the Order relation the attribute Customer ID is a foreign key. A "join" is the operation that draws on information from several relations at once. By joining relvars from the example above we could "query" the database for all of the Customers, Orders, and Invoices. If we only wanted the tuples for a specific customer, we would specify this using a restriction condition.

If we wanted to retrieve all of the Orders for Customer "1234567890", we could query the database to return every row in the Order table with Customer ID "1234567890" and join the Order table to the Order Line table based on Order No.

There is a flaw in our database design above. The Invoice relvar contains an Order No attribute. So, each tuple in the Invoice relvar will have one Order No, which implies that there is precisely one Order for each Invoice. But in reality an invoice can be created against many orders, or indeed for no particular order. Additionally the Order relvar contains an Invoice No attribute, implying that each Order has a corresponding Invoice. But again this is not always true in the real world. An order is sometimes paid through several invoices, and sometimes paid without an invoice. In other words, there can be many Invoices per Order and many Orders per Invoice. This is a many-to-many relationship between Order and Invoice (also called a "non-specific relationship"). To represent this relationship in the database a new relvar should be introduced whose role is to specify the correspondence between Orders and Invoices:

Now, the Order relvar has a "one-to-many relationship" to the OrderInvoice table, as does the Invoice relvar. If we want to retrieve every Invoice for a particular Order, we can query for all orders where Order No in the Order relation equals the Order No in OrderInvoice, and where Invoice No in OrderInvoice equals the Invoice No in Invoice.

Basic notions in the relational model are "relation names" and "attribute names". We will represent these as strings such as "Person" and "name" and we will usually use the variables formula_1 and formula_2 to range over them. Another basic notion is the set of "atomic values" that contains values such as numbers and strings.

Our first definition concerns the notion of "tuple", which formalizes the notion of row or record in a table:


The next definition defines "relation" that formalizes the contents of a table as it is defined in the relational model.


Such a relation closely corresponds to what is usually called the extension of a predicate in first-order logic except that here we identify the places in the predicate with attribute names. Usually in the relational model a database schema is said to consist of a set of relation names, the headers that are associated with these names and the constraints that should hold for every instance of the database schema.


One of the simplest and most important types of relation constraints is the "key constraint". It tells us that in every instance of a certain relational schema the tuples can be identified by their values for certain attributes.

A superkey is a set of column headers for which the values of those columns concatenated are unique across all rows. Formally:
A candidate key is a superkey cannot be further subdivided to form another superkey.
Functional dependency is the property that a value in a tuple may be derived from another value in that tuple.

 :INPUT: a set "S" of FDs that contain only subsets of a header "H"





</doc>
<doc id="26221" url="https://en.wikipedia.org/wiki?curid=26221" title="Rathaus SchÃ¶neberg">
Rathaus SchÃ¶neberg

Rathaus SchÃ¶neberg is the city hall for the borough of Tempelhof-SchÃ¶neberg in Berlin. From 1949 until 1990 it served as the seat of the state senate of West Berlin and from 1949 until 1991 as the seat of the Governing Mayor.

The sandstone building was constructed between 1911 and 1914, when it replaced the old town hall of SchÃ¶neberg, at that time an independent city () not yet incorporated into Greater Berlin, which took place in 1920. The Nazi authorities had a series of war murals by Franz Eichhorst added to the interior in 1938. In World War II the building was severely damaged by Allied bombing and during the final Battle of Berlin.

After the war the undestroyed "Neues Stadthaus", former head office of Berlin's municipal fire insurance "FeuersozietÃ¤t", on ParochialstraÃe in Mitte, served as intermittent city hall, replacing the ruined Rotes Rathaus (Red City Hall, also in East Berlin), the traditional seat of the Berlin government. With the division of Berlin's city government and administration in September 1948 the "Neues Stadthaus" was in the Communist "Ostsektor" (eastern sector) and became off limits to West Berlin. As a "temporary" measure the barely repaired Rathaus SchÃ¶neberg on Rudolph-Wilde-Platz became the city hall for West Berlin. In 1950 the Freedom Bell ("Freiheitsglocke"), a gift by the United States, was installed in the rebuilt tower.
During the Berlin Blockade, the Uprising of 1953, and the Hungarian Revolution of 1956, Rudolph-Wilde-Platz in front of the building became a gathering place for protest rallies. After the construction of the Berlin Wall in 1961, the steps of Rathaus SchÃ¶neberg were the location where U.S. President John F. Kennedy spoke on 26 June 1963, proclaiming "Ich bin ein Berliner". On the night of his assassination, several thousand Berliners spontaneously gathered at the square, which was officially renamed John-F.-Kennedy-Platz three days later. A large memorial plaque, mounted on a column at the entrance of the building, and the room above the entrance overlooking the square are dedicated to Kennedy and his visit.

There was a large assembly in front of the Rathaus on 10 November 1989, the day after the fall of the Berlin Wall. Prominent people attending were chancellor Helmut Kohl, former chancellor Willy Brandt, and foreign minister Hans-Dietrich Genscher.

After reunification, Rathaus SchÃ¶neberg reverted to its original purpose of being SchÃ¶neberg Borough Town Hall. Upon the 2001 Berlin administrative reform, Rathaus SchÃ¶neberg became the town hall for the newly constituted borough of Tempelhof-SchÃ¶neberg.

It was also the permanent home to an exhibition of the life of Willy Brandt (1913â1992), Mayor of West Berlin from 1957 to 1966 and Chancellor of the Federal Republic of Germany 1969â74. The exhibition was closed as from January 2010; it is planned to open again at another site in the city.

Since 2005, the exhibition called "Wir waren Nachbarn â Biografien jÃ¼discher Zeitzeugen" (English title:"We were Neighbours once â Biographies of Jews in SchÃ¶neberg and Tempelhof under the Nazi Regime") takes place in the exhibition hall of the Rathaus SchÃ¶neberg.



</doc>
<doc id="26225" url="https://en.wikipedia.org/wiki?curid=26225" title="RÃ¦dwald of East Anglia">
RÃ¦dwald of East Anglia

RÃ¦dwald ( , 'power in counsel'), also written as Raedwald or Redwald, was a king of East Anglia, an Anglo-Saxon kingdom which included the present-day English counties of Norfolk and Suffolk. He was the son of Tytila of East Anglia and a member of the Wuffingas dynasty (named after his grandfather, Wuffa), who were the first kings of the East Angles. Details about RÃ¦dwald's reign are scarce, primarily because the Viking invasions of the 9th century destroyed the monasteries in East Anglia where many documents would have been kept. RÃ¦dwald reigned from about 599 until his death around 624, initially under the overlordship of Ãthelberht of Kent. In 616, as a result of fighting the Battle of the River Idle and defeating Ãthelfrith of Northumbria, he was able to install Edwin, who was acquiescent to his authority, as the new king of Northumbria. During the battle, both Ãthelfrith and RÃ¦dwald's son RÃ¦genhere were killed.

From around 616, RÃ¦dwald was the most powerful of the English kings south of the River Humber. According to Bede he was the fourth ruler to hold "imperium" over other southern Anglo-Saxon kingdoms: he was referred to in the "Anglo-Saxon Chronicle", written centuries after his death, as a "bretwalda" (an Old English term meaning 'Britain-ruler' or 'wide-ruler'). He was the first king of the East Angles to become a Christian, converting at Ãthelberht's court some time before 605, whilst at the same time maintaining a pagan temple. In receiving the faith he helped to ensure the survival of Christianity in East Anglia during the apostasy of the Anglo-Saxon kingdoms of Essex and Kent. He is generally considered by historians to be the most favoured candidate for the occupant of the Sutton Hoo ship-burial, although other theories have been advanced.

The kingdom of East Anglia () was a small independent Anglo-Saxon kingdom that comprised what are now the English counties of Norfolk and Suffolk and perhaps the eastern part of the Cambridgeshire Fens. Few sources have survived that were written by the Anglo-Saxons in England, and East Anglia has even less documentary evidence than most of the kingdoms existing at that time. The historian Barbara Yorke has suggested that the reason for the paucity of East Anglian sources was almost certainly the Viking expansion in the 9th century as the monks and scribes of East Anglia produced as much work as those living in other parts of England. The devastation caused by the Vikings is thought to have destroyed all the books and charters that may have been kept there.

RÃ¦dwald is the first king of the East Angles of whom more than a name is known, though no details of his life before his accession are known. The earliest and most substantial source for RÃ¦dwald is the "Historia ecclesiastica gentis Anglorum" ("Ecclesiastical History of the English People"), completed in 731 by Bede, a Northumbrian monk. Bede placed RÃ¦dwald's reign between the advent of the Gregorian mission to Kent in 597 and the marriage and conversion of Edwin of Northumbria during 625â26.

Later medieval chroniclers, such as Roger of Wendover, gave some information about East Anglian events, but Yorke suggests that the annalistic format used forced these writers to guess the dates of the key events they recorded. Such later sources are therefore treated with caution. The "Anglian collection", which dates from the late 8th century, contains an East Anglian genealogical tally, but RÃ¦dwald is not included. RÃ¦dwald is however referred to in the 8th century "Vita" of St Gregory the Great, written by a member of the religious community at Whitby. The Battle of the River Idle, in which RÃ¦dwald and his forces defeated the Northumbrians, is described in the 12th century "Historia Anglorum", written by Henry of Huntingdon.

The Anglo-Saxons, who are known to have included Angles, Saxons, Jutes and Frisians, began to arrive in Britain in the 5th century. By 600, a number of kingdoms had begun to form in the conquered territories. By the beginning of the 7th century, southern England was almost entirely under their control.

During RÃ¦dwald's youth, the establishment of other ruling houses was accomplished. Sometime before 588, Ãthelberht of Kent married Bercta, the Christian daughter of the Frankish ruler Charibert. As early as 568, Ceawlin of Wessex, the most powerful ruler south of the River Humber, repulsed Ãthelberht. According to later sources, Mercia was founded by Creoda in 585, although a paucity of sources makes it difficult to know how the Mercian royal line became established.

North of the Humber, the kingdoms of Deira and Bernicia possessed rival royal dynasties. Ãlla ruled Deira until his death in 588, leaving his daughter Acha, his son Edwin, and another unknown sibling. The Bernician dynasty, allied by kinship to the kingdom of Wessex, gained ascendancy over Deira, forcing Edwin to live in exile in the court of Cadfan ap Iago of Gwynedd. In various wars, Ãthelfrith of Bernicia consolidated the Northumbrian state, and in around 604 he was able to bring Deira under his dominion.

RÃ¦dwald, which in Old English means 'power in counsel', was born around 560â580. The son of Tytila, whom he succeeded, he was the elder brother of Eni. According to Bede, he was descended from Wuffa, the founder of the Wuffingas dynasty: filius Tytili, cuius pater fuit UUffa ('the son of Tytil, whose father was Wuffa').

At some time during the 590s, RÃ¦dwald married a woman whose name is unknown, though it is known from Bede that she was pagan. By her he fathered at least two sons, RÃ¦genhere and Eorpwald. He also had an older son, Sigeberht, whose name is unlike other Wuffingas names but which is typical of the East Saxon dynasty. It has been suggested that RÃ¦dwald's queen had previously been married to a member of the Essex royal family and that Sigeberht was RÃ¦dwald's stepson, as was stated by William of Malmesbury in the 12th century. Sigeberht earned the enmity of his step-father, who drove him into exile in Gaul, possibly to protect the Wuffingas bloodline.

Events that occurred during the early years of RÃ¦dwald's reign include the arrival of Augustine of Canterbury and his mission from Rome in 597, the conversions of Ãthelberht of Kent and Saeberht of Essex, and the establishment of new bishoprics in their kingdoms. Bede, when relating the conversion of RÃ¦dwald's son Eorpwald in his "Historia ecclesiastica gentis Anglorum", mentioned that RÃ¦dwald received the Christian sacraments in Kent. This happened in perhaps 604 or later, presumably at the invitation of Ãthelberht, who may have been his baptismal sponsor. The date of his conversion is unknown, but it would have occurred after the arrival of the Gregorian mission in 597. Since it is claimed that Augustine, who died in about 605, dedicated a church near Ely, it may have followed Saebert's conversion fairly swiftly. RÃ¦dwald's marriage to a member of the royal dynasty of Essex helped form a diplomatic alliance between the neighbouring kingdoms of East Anglia and Essex. His conversion in Kent would have affiliated him with Ãthelberht, bringing him directly into the sphere of Kent.

In East Anglia, RÃ¦dwald's conversion was not universally accepted by his household or his own queen. According to the historian Steven Plunkett, she and her pagan teachers persuaded him to default in part from his commitment to the Christian faith. As a result, he kept in the temple two altars, one dedicated to pagan Gods and the other to Christ. Bede, writing decades later, described how Ealdwulf of East Anglia, a grandson of RÃ¦dwald's brother Eni, recalled seeing the temple when he was a boy. It may have been located at Rendlesham, emerging focus of the "regio" of the Wuffing dynasty, according to Plunkett. Barbara Yorke argues that RÃ¦dwald was not willing to fully embrace Christianity because conversion via Ãthelberht would have been acknowledgment of an inferior status to the Kentish king. RÃ¦dwald's lack of commitment towards Christianity earned him the enmity of Bede, who regarded him as a renouncer of the faith.

Ãthelfrith of Northumbria may have married Acha, who was the mother of his son Oswald (born in about 604), according to Bede. Ãthelfrith pursued Acha's exiled brother Edwin in an attempt to destroy him and ensure that the Bernician rulership of Northumbria would be unchallenged. Edwin found hospitality in the household of Cearl of Mercia and later married Cearl's daughter. Edwin's nephew Hereric, an exile in the British kingdom of Elmet, was slain there under treacherous circumstances. Edwin eventually sought the protection of RÃ¦dwald, where he was received willingly. RÃ¦dwald promised to protect him, and Edwin lived with the king amongst his royal companions. When news of Edwin reached Ãthelfrith in Northumbria, he sent messengers to RÃ¦dwald offering money in return for Edwin's death, but RÃ¦dwald refused to comply. Ãthelfrith sent messengers a second and a third time, offering even greater gifts of silver and promising war if these were not accepted. RÃ¦dwald then weakened and promised either to kill Edwin or to hand him over to ambassadors.

When a chance arose for him to escape to a safe country, Edwin chose to remain at RÃ¦dwald's court. He was then visited by a stranger who was aware of RÃ¦dwald's deliberations. The source for this story, written at Whitby, stated that the stranger was Paulinus of York, a member of the Canterbury mission, who offered Edwin the hope of RÃ¦dwald's support and held out the prospect that Edwin might someday attain greater royal power than any previous English king. Paulinus was assured by Edwin that he would accept his religious teaching. His vision of Paulinus was afterwards made the means of his decision to embrace Christianity, on the condition that he survived and achieved power. If, as is supposed by some, Paulinus appeared to him in the flesh, the bishop's presence at RÃ¦dwald's court would throw some light on the king's position regarding religion.

RÃ¦dwald's pagan queen admonished him for acting in a manner dishonourable for a king by betraying his trust for the sake of money and wanting to sell his imperiled friend in exchange for riches. As a result of her admonishment, once Ãthelfrith's ambassadors had gone, RÃ¦dwald resolved on war.

In 616 or 617, RÃ¦dwald assembled an army and marched north, accompanied by his son RÃ¦genhere, to confront Ãthelfrith. They met on the western boundary of the kingdom of Lindsey, on the east bank of the River Idle. The battle was fierce and was long commemorated in the saying, âThe river Idle was foul with the blood of Englishmenâ. During the fighting, Ãthelfrith and RÃ¦dwald's son RÃ¦genhere were both slain. Edwin then succeeded Ãthelfrith as the king of Northumbria, and Ãthelfrith's sons were subsequently forced into exile.

A separate account of the battle, given by Henry of Huntingdon, stated that RÃ¦dwald's army was split into three formations, led by RÃ¦dwald, RÃ¦genhere, and Edwin. With more experienced fighters, Ãthelfrith attacked in loose formation. At the sight of RÃ¦genhere, perhaps thinking he was Edwin, Ãthelfrith's men cut their way through to him and slew him. After the death of his son, RÃ¦dwald furiously breached his lines, killing Ãthelfrith amid a great slaughter of the Northumbrians.

D.P. Kirby has argued that the battle was more than a clash between two kings over the treatment of an exiled nobleman but was "part of a protracted struggle to determine the military and political leadership of the Anglian peoples" at that time.

On 24 February 616, the year of the Battle of the River Idle, Ãthelberht of Kent died and was succeeded by his pagan son Eadbald. After the death of the Christian Saebert of Essex, his three sons shared the kingdom, returning it to pagan rule, and drove out the Gregorian missionaries led by Mellitus. The Canterbury mission had removed to Gaul before Eadbald was brought back into the fold. During this period the only royal Christian altar in England belonged to RÃ¦dwald. By the time of his death, the mission in Kent had been fully re-established.

RÃ¦dwald's power became great enough for Bede to recognise him as the successor to the "imperium" of Ãthelberht. Bede also called him "Rex Anglorum", the 'King of the Angles', a term that RÃ¦dwald's contemporaries would have used for their overlord. It is unclear where his power was centred or even how he established his authority over the Angles of eastern England.

By Edwin's debt of allegiance to him, RÃ¦dwald became the first foreign king to hold direct influence in Northumbria. He would have been instrumental in Edwin's secure establishment as king of both Deira and Bernicia.

During the first quarter of the 7th century, the quayside settlement at Gipeswic (Ipswich) became an important estuarine trading centre, receiving imported goods such as pottery from other trading markets situated around the coasts of the North Sea. Steven Plunkett suggests that the founding of Gipeswic took place under Wuffingas supervision. It took another hundred years for the settlement to develop into a town, but its beginnings can be seen as a reflection of the personal importance of RÃ¦dwald during the period of his supremacy.

The excavated grave-goods of the Anglo-Saxon cemetery at Gipeswic, including those found in burials under small barrows, were not particularly wealthy or elaborate. They lacked the strong characterization of a neighbouring late 6th century cemetery at a higher crossing of the river. One exception was a furnished grave that has been suggested to be that of a visitor from the Rhineland.

RÃ¦dwald is believed to have died around 624: his death can be located only within a few years. He must have reigned for some time after Ãthelberht died, in order for him to have been noted as a "bretwalda". Barbara Yorke suggests that he died before Edwin converted to Christianity in 627 and also before Paulinus became bishop of Northumbria in 625. His death is recorded twice by Roger of Wendover, in 599 and in 624, in a history that dates from the 13th century but appears to include earlier annals of unknown origin and reliability. Plunkett notes that the earlier date of 599 is now taken as a mistaken reference to the death of RÃ¦dwaldâs father, Tytila, and the later date is commonly given for the death of RÃ¦dwald.

He was succeeded by his pagan son Eorpwald, who was later persuaded to adopt Christianity by Edwin of Northumbria.

RÃ¦dwald lived at a time when eminent individuals were buried in barrows at the cemetery at Sutton Hoo, near Woodbridge, Suffolk. There, large moundsâwhich were originally much higher and more visibleâcan still be seen, overlooking the upper estuary of the River Deben.

In 1939, a mound at Sutton Hoo, now known as Mound 1, was discovered to contain an Anglo-Saxon ship-burial of unparalleled richness. The mound enclosed a ship, long, which had seen use on the seas and had been repaired. In the centre of the ship was a chamber containing a collection of jewellery and other rich grave goods, including silver bowls, drinking vessels, clothing and weaponry. One unusual item was a large 'sceptre' in the form of a whetstone that showed no sign of previous use as a tool: it has been suggested that this was a symbol of the office of "bretwalda". The gold and garnet body-equipment found with the other goods was produced for a patron who employed a goldsmith the equal or better than any in Europe and was designed to project an image of imperial power. The Mediterranean silverware in the grave is a unique assemblage for its period in Europe.

The magnificence of the objects, both the personal possessions and those items designed to denote the authority of the dead individual, point to the death of a person connected with the royal court, according to Rupert Bruce-Mitford, who regards the burial as "very likely the monument of the High King or "bretwalda" Raedwald". Yorke suggests that the treasures buried with the ship reflect the size of the tribute paid to RÃ¦dwald by subject kings during his period as "bretwalda". Bruce-Mitford has suggested that the inclusion of bowls and spoons amongst the treasures fits with Bede's account of Raedwald's conversion: the spoons may have been a present for a convert from paganism and the bowls had Christian significance. Coins found in the burial have been dated to the approximate date of RÃ¦dwald's death. The controversy surrounding the identity of the person for whom the mound was built are reflected in the comments in the article on RÃ¦dwald in the "Oxford Dictionary of National Biography" ("It has been argued, more strongly than convincingly, that RÃ¦dwald must be the man buried in Mound 1 at Sutton Hoo") and by McClure and Collins, who note that the evidence for Raedwald is "almost non-existent".

Alternative suggestions as candidates include other East Anglian kings or a prestigious foreign visitor. There are alternative explanations: the person may have been a wealthy status-seeker, rather than a king, though Rendlesham, a known residence of the East Anglian kings, is only away.

Swedish cultural influence has been detected at Sutton Hoo: there are strong similarities in both the armour and the burial with Vendel-age finds from Sweden. Bruce-Mitford suggested that the connection is close enough to imply that the Wuffing dynasty came from that part of Scandinavia. There are also significant differences, and exact parallels with the workmanship and style of the Sutton Hoo artefacts cannot be found elsewhere; as a result the connection is generally regarded as unproven.

It is also possible that the mound is actually a cenotaph rather than a grave, the only sign of body being a chemical stain which could have had other origins; indeed, the site includes burials of both meat and companion animals. Further, there is a lack of shroud ties, and no clear evidence of items which might have adorned a body being left in the expected places in relation to the stain. The cenotaph theory may be consistent with the transition from pagan burial to Christian burial; certainly as far as RÃ¦dwald is concerned, he could have received a Christian burial, and the mound, whether completed before or after his conversion, being used as a memorial and as symbol of the status of the Kingship of East Anglia.

Primary sources

Secondary sources

 


</doc>
<doc id="26226" url="https://en.wikipedia.org/wiki?curid=26226" title="Rhyme">
Rhyme

A rhyme is a repetition of similar sounds (usually, exactly the same sound) in the final stressed syllables and any following syllables of two or more words. Most often, this kind of "perfect" rhyming is consciously used for effect in the final positions of lines of poems and songs. More broadly, a rhyme may also variously refer to other types of similar sounds near the ends of two or more words. Furthermore, the word "rhyme" has come to be sometimes used as a shorthand term for any brief poem, such as a rhyming couplet or nursery rhyme. 

The word derives from Old French "rime" or "ryme", which may be derived from Old Frankish "*rÄ«m", a Germanic term meaning "series, sequence" attested in Old English (Old English "rÄ«m" meaning "enumeration, series, numeral") and Old High German "rÄ«m", ultimately cognate to Old Irish "rÃ­m", Greek ' "arithmos" "number". Alternatively, the Old French words may derive from Latin "rhythmus", from Greek ' ("rhythmos", rhythm).

The spelling "rhyme" (from original "rime") was introduced at the beginning of the Modern English period from a learned (but perhaps etymologically incorrect) association with Latin "rhythmus". The older spelling "rime" survives in Modern English as a rare alternative spelling; cf. "The Rime of the Ancient Mariner". A distinction between the spellings is also sometimes made in the study of linguistics and phonology for which "rime/rhyme" is used to refer to the nucleus and coda of a syllable. Some prefer to spell it "rime" to separate it from the poetic rhyme covered by this article (see syllable rime).

Rhyme partly seems to be enjoyed simply as a repeating pattern that is pleasant to hear. It also serves as a powerful mnemonic device, facilitating memorization. The regular use of tail rhyme helps to mark off the ends of lines, thus clarifying the metrical structure for the listener. As with other poetic techniques, poets use it to suit their own purposes; for example William Shakespeare often used a rhyming couplet to mark off the end of a scene in a play.

The word "rhyme" can be used in a specific and a general sense. In the specific sense, two words rhyme if their final stressed vowel and all following sounds are identical; two lines of poetry rhyme if their final strong positions are filled with rhyming words. A rhyme in the strict sense is also called a perfect rhyme. Examples are "sight" and "flight", "deign" and "gain", "madness" and "sadness", "love" and "dove".

Perfect rhymes can be classified according to the number of syllables included in the rhyme, which is dictated by the location of the final stressed syllable.


In the general sense, "general rhyme" can refer to various kinds of phonetic similarity between words, and to the use of such similar-sounding words in organizing verse. Rhymes in this general sense are classified according to the degree and manner of the phonetic similarity:


Identical rhymes are considered less than perfect in English poetry; but are valued more highly in other literatures such as, for example, "rime riche" in French poetry.

Though homophones and homonyms satisfy the first condition for rhymingâthat is, that the stressed vowel sound is the sameâthey do not satisfy the second: that the preceding consonant be different. As stated above, in a perfect rhyme the last stressed vowel and all following sounds are identical in both words.

If the sound preceding the stressed vowel is also identical, the rhyme is sometimes considered to be inferior and not a perfect rhyme after all. An example of such a "super-rhyme" or "more than perfect rhyme" is the "identical rhyme", in which not only the vowels but also the onsets of the rhyming syllables are identical, as in "gun" and "begun". Punning rhymes, such as "bare" and "bear" are also identical rhymes. The rhyme may extend even farther back than the last stressed vowel. If it extends all the way to the beginning of the line, so that there are two lines that sound very similar or identical, it is called a "holorhyme" ("For I scream/For ice cream").

In poetics these would be considered "identity", rather than rhyme.

Eye rhymes or sight rhymes or spelling rhymes refer to similarity in spelling but not in sound where the final sounds are spelled identically but pronounced differently. Examples in English are "cough", "bough", and "love", "move".

Some early written poetry appears to contain these, but in many cases the words used rhymed at the time of writing, and subsequent changes in pronunciation have meant that the rhyme is now lost.

Mind rhyme is a kind of substitution rhyme similar to rhyming slang, but it is less generally codified and is âheardâ only when generated by a specific verse context. For instance, âthis sugar is neat / and tastes so sour.â If a reader or listener thinks of the word âsweetâ instead of âsour,â a mind rhyme has occurred.

Rhymes may be classified according to their position in the verse:

A rhyme scheme is the pattern of rhyming lines in a poem.

In many languages, including modern European languages and Arabic, poets use rhyme in set patterns as a structural element for specific poetic forms, such as ballads, sonnets and rhyming couplets. Some rhyming schemes have become associated with a specific language, culture or period, while other rhyming schemes have achieved use across languages, cultures or time periods. However, the use of structural rhyme is not universal even within the European tradition. Much modern poetry avoids traditional rhyme schemes.

The earliest surviving evidence of rhyming is the Chinese Shi Jing (ca. 10th century BC). Rhyme is also occasionally used in the Bible. Classical Greek and Latin poetry did not usually rhyme, but rhyme was used very occasionally. For instance, Catullus includes partial rhymes in the poem "Cui dono lepidum novum libellum". The ancient Greeks knew rhyme, and rhymes in "The Wasps" by Aristophanes are noted by a translator.

Rhyme is central to classical Arabic poetry tracing back to its 6th century pre-Islamic roots. According to some archaic sources, Irish literature introduced the rhyme to Early Medieval Europe, but that is a disputed claim. In the 7th century, the Irish had brought the art of rhyming verses to a high pitch of perfection. The leonine verse is notable for introducing rhyme into High Medieval literature in the 12th century.

Rhyme entered European poetry in the High Middle Ages, in part under the influence of the Arabic language in Al Andalus (modern Spain). Arabic language poets used rhyme extensively from the first development of literary Arabic in the sixth century, as in their long, rhyming qasidas.

Since dialects vary and languages change over time, lines that rhyme in a given register or era may not rhyme in another, and it may not be clear whether one should pronounce the words so that they rhyme. An example is this couplet from Handel's Judas Maccabaeus:

Rhyming in the Celtic Languages takes a drastically different course from most other Western rhyming schemes despite strong contact with the Romance and English patterns. Even today, despite extensive interaction with English and French culture, Celtic rhyme continues to demonstrate native characteristics. Brian Ã CuÃ­v sets out the rules of rhyme in Irish poetry of the classical period: the last stressed vowel and any subsequent long vowels must be identical in order for two words to rhyme. Consonants are grouped into six classes for the purpose of rhyme: they need not be identical, but must belong to the same class. Thus 'b' and 'd' can rhyme (both being 'voiced plosives'), as can 'bh' and 'l' (which are both 'voiced continuants') but 'l', a 'voiced continuant', cannot rhyme with 'ph', a 'voiceless continuant'. Furthermore, "for perfect rhyme a palatalized consonant may be balanced only by a palatalized consonant and a velarized consonant by a velarized one." In the post-Classical period, these rules fell into desuetude, and in popular verse simple assonance often suffices, as can be seen in an example of Irish Gaelic rhyme from the traditional song "BrÃ­d Ãg NÃ­ MhÃ¡ille":
Here the vowels are the same, but the consonants, although both palatalized, do not fall into the same class in the bardic rhyming scheme.

Besides the vowel/consonant aspect of rhyming, Chinese rhymes often include tone quality (that is, tonal contour) as an integral linguistic factor in determining rhyme.

Use of rhyme in Classical Chinese poetry typically but not always appears in the form of paired couplets, with end-rhyming in the final syllable of each couplet.

Another important aspect of rhyme in regard to Chinese language studies is the study or reconstruction of past varieties of Chinese, such as Middle Chinese.

Old English poetry is mostly alliterative verse. One of the earliest rhyming poems in English is The Rhyming Poem.

As stress is important in English, lexical stress is one of the factors that affects the similarity of sounds for the perception of rhyme. Perfect rhyme can be defined as the case when two words rhyme if their final stressed vowel and all following sounds are identical.

Some words in English, such as "orange" and "silver", are commonly regarded as having no rhyme. Although a clever writer can get around this (for example, by obliquely rhyming "orange" with combinations of words like "door hinge" or with lesser-known words like "Blorenge" â a hill in Wales â or the surname Gorringe), it is generally easier to move the word out of rhyming position or replace it with a synonym ("orange" could become "amber", while "silver" could become a combination of "bright and argent").A skilled orator might be able to tweak the pronunciation of certain words to facilitate a stronger rhyme (for example, pronouncing 'orange' as 'oringe' to rhyme with 'door hinge')

One view of rhyme in English is from John Milton's preface to "Paradise Lost":
A more tempered view is taken by W. H. Auden in The Dyer's Hand:
Forced or clumsy rhyme is often a key ingredient of doggerel.

In French poetry, unlike in English, it is common to have "identical rhymes", in which not only the vowels of the final syllables of the lines rhyme, but their onset consonants ("consonnes d'appui") as well. To the ear of someone accustomed to English verse, this often sounds like a very weak rhyme. For example, an English perfect rhyme of homophones, "flour" and "flower", would seem weak, whereas a French rhyme of homophones "doigt" ("finger") and "doit" ("must") or "point" ("point") and "point" ("not") is not only acceptable but quite common.

Rhymes are sometimes classified into the categories of "rime pauvre" ("poor rhyme"), "rime suffisante" ("sufficient rhyme"), "rime riche" ("rich rhyme") and "rime richissime" ("very rich rhyme"), according to the number of rhyming sounds in the two words or in the parts of the two verses. For example, to rhyme "tu" with "vu" would be a poor rhyme (the words have only the vowel in common), to rhyme "pas" with "bras" a sufficient rhyme (with the vowel and the silent consonant in common), and "tante" with "attente" a rich rhyme (with the vowel, the onset consonant, and the coda consonant with its mute "e" in common). Authorities disagree, however, on exactly where to place the boundaries between the categories.

"Holorime" is an extreme example of "rime richissime" spanning an entire verse. Alphonse Allais was a notable exponent of holorime. Here is an example of a holorime couplet from Marc Monnier:
Classical French rhyme not only differs from English rhyme in its different treatment of onset consonants. It also treats coda consonants in a distinctive way.

French spelling includes several final letters that are no longer pronounced, and that in many cases have never been pronounced. Such final unpronounced letters continue to affect rhyme according to the rules of Classical French versification. They are encountered in almost all of the pre-20th-century French verse texts, but these rhyming rules are almost never taken into account from the 20th century.

The most important "silent" letter is the "mute e". In spoken French today, final "e" is, in some regional accents (in Paris for example), omitted after consonants; but in Classical French prosody, it was considered an integral part of the rhyme even when following the vowel. "Joue" could rhyme with "boue", but not with "trou". Rhyming words ending with this silent "e" were said to make up a "double rhyme", while words not ending with this silent "e" made up a "single rhyme". It was a principle of stanza-formation that single and double rhymes had to alternate in the stanza. Virtually all 17th-century French plays in verse alternate masculine and feminine couplets.

The now-silent final consonants present a more complex case. They, too, were traditionally an integral part of the rhyme, such that "pont" rhymed with "vont" but not with "long"; but spelling and pronunciation did not coincide exactlyâ"pont" also rhymed with "rond". There are a few rules that govern most word-final consonants in archaic French pronunciation:

Because German phonology features a wide array of vowel sounds, certain imperfect rhymes are widely admitted in German poetry. These include rhyming "e" with "Ã¤" and "Ã¶", rhyming "i" with "Ã¼", rhyming "ei" with "eu" (spelled "Ã¤u" in some words) and rhyming a long vowel with its short counterpart.

Some examples of imperfect rhymes (all from Friedrich Schiller's "An die Freude"):

Ancient Greek poetry is strictly metrical. Rhyme is used, if at all, only as an occasional rhetorical flourish.

The first Greek to write rhyming poetry was the fourteenth-century Cretan Stephanos Sachlikis. Rhyme is now a common fixture of Greek poetry.

Ancient Hebrew rarely employed rhyme, e.g. in Exodus 29 35: ××¢×©××ª ××××¨× ×××× ×× ×Ö¸Ö¼××, ××× ××©×¨ ×¦×××ª× ×Ö¹×ªÖ¸×× (the identical part in both rhyming words being / 'axa/ ). Rhyme became a permanent - even obligatory - feature of poetry in Hebrew language, around the 4th century CE. It is found in the Jewish liturgical poetry written in the Byzantine empire era. This was realized by scholars only recently, thanks to the thousands of piyyuts that have been discovered in the Cairo Geniza. It is assumed that the principle of rhyme was transferred from Hebrew liturgical poetry to the poetry of the Syriac Christianity (written in Aramaic), and through this mediation introduced into Latin poetry and then into all other languages of Europe.

In Latin rhetoric and poetry homeoteleuton and alliteration were frequently used devices.

Tail rhyme was occasionally used, as in this piece of poetry by Cicero:
But tail rhyme was not used as a prominent structural feature of Latin poetry until it was introduced under the influence of local vernacular traditions in the early Middle Ages. This is the Latin hymn "Dies Irae":
Medieval poetry may mix Latin and vernacular languages. Mixing languages in verse or rhyming words in different languages is termed macaronic.

Portuguese classifies rhymes in the following manner:


Rhyme was introduced into Russian poetry in the 18th century. Folk poetry had generally been unrhymed, relying more on dactylic line endings for effect. Two words ending in an accented vowel are only considered to rhyme if they share a preceding consonant. Vowel pairs rhymeâeven though non-Russian speakers may not perceive them as the same sound. Consonant pairs rhyme if both are devoiced. As in French, formal poetry traditionally alternates between masculine and feminine rhymes.

Early 18th-century poetry demanded perfect rhymes that were also grammatical rhymesânamely that noun endings rhymed with noun endings, verb endings with verb endings, and so on. Such rhymes relying on morphological endings become much rarer in modern Russian poetry, and greater use is made of approximate rhymes.

Spanish mainly differentiates two types of rhymes:



Spanish rhyme is also classified by stress type since different types cannot rhyme with each other:


In Polish literature rhyme was used from the beginning. Unrhymed verse was never popular, although sometimes it was sometimes imitated form Latin. Homer's, Virgil's and even Milton's epic poems were furnished with rhymes by Polish translators. Because of paroxytonic accentuation in Polish, feminine rhymes always prevailed. Rules of Polish rhyme were established in 16th century. Then only feminine rhymes were allowed in syllabic verse system. Together with introducing syllabo-accentual metres, masculine rhymes began to occur in Polish poetry. They were most popular at the end of 19th century. The most frequent rhyme scheme in Old Polish (16th - 18th centuries) was couplet AABBCCDD..., but Polish poets, having perfect knowledge of Italian language and literature, experimented with other schemes, among others ottava rima (ABABABCC) and sonnet (ABBA ABBA CDC DCD or ABBA ABBA CDCD EE).
The metre of Mickiewicz's sonnet is the Polish alexandrine (tridecasyllable, in Polish "trzynastozgÅoskowiec"): 13(7+6) and its rhymes are feminine: [anu] and [odzi].

Rhymes were widely spread in the Arabian peninsula around the 6th century, in letters, poems and songs, as well as long, rhyming qasidas. In addition, the Quran uses a form of rhymed prose named saj'.

Patterns of rich rhyme ("prÄsa") play a role in modern Sanskrit poetry, but only to a minor extent in historical Sanskrit texts. They are classified according to their position within the "pada" (metrical foot): "ÄdiprÄsa" (first syllable), "dvitÄ«yÄká¹£ara prÄsa" (second syllable), "antyaprÄsa" (final syllable) etc.

There are some unique rhyming schemes in Dravidian languages like Tamil. Specifically, the rhyme called "etukai" (anaphora) occurs on the second consonant of each line.

The other rhyme and related patterns are called "mÅnai" (alliteration), "toá¹­ai" (epiphora) and "iraá¹­á¹­ai kiá¸·avi" (parallelism).

Some classical Tamil poetry forms, such as "veá¹pÄ", have rigid grammars for rhyme to the point that they could be expressed as a context-free grammar.

Rhymes are used in Vietnamese to produce similes. The following is an example of a Rhyming Simile:

NghÃ¨o nhÆ° con mÃ¨o
<br>/ÅÉu É²É¯ kÉn mÉu/ 
<br>"Poor as a cat"

Compare the above Vietnamese example, which is a "rhyming" simile, to the English phrase "(as) poor as a church mouse", which is only a "semantic" simile.




</doc>
<doc id="26227" url="https://en.wikipedia.org/wiki?curid=26227" title="Rhythm">
Rhythm

Rhythm (from Greek , "rhythmos", "any regular recurring motion, symmetry" ) generally means a "movement marked by the regulated succession of strong and weak elements, or of opposite or different conditions" . This general meaning of regular recurrence or pattern in time can apply to a wide variety of cyclical natural phenomena having a periodicity or frequency of anything from microseconds to several seconds (as with the riff in a rock music song); to several minutes or hours, or, at the most extreme, even over many years.

Rhythm is related to and distinguished from pulse, meter, and beats: 
In the performance arts, rhythm is the timing of events on a human scale; of musical sounds and silences that occur over time, of the steps of a dance, or the meter of spoken language and poetry. In some performing arts, such as hip hop music, the rhythmic delivery of the lyrics is one of the most important elements of the style. Rhythm may also refer to visual presentation, as "timed movement through space" and a common language of pattern unites rhythm with geometry. In recent years, rhythm and meter have become an important area of research among music scholars. Recent work in these areas includes books by Maury , Fred Lerdahl and Ray Jackendoff , Jonathan Kramer, Christopher , Godfried , William , Joel Lester , and Guerino Mazzola.

In his television series "How Music Works", Howard Goodall presents theories that human rhythm recalls the regularity with which we walk and the heartbeat . Other research suggests that it does not relate to the heartbeat directly, but rather the speed of emotional affect, which also influences heartbeat. Yet other researchers suggest that since certain features of human music are widespread, it is "reasonable to suspect that beat-based rhythmic processing has ancient evolutionary roots" . Justin London writes that musical metre "involves our initial perception as well as subsequent anticipation of a series of beats that we abstract from the rhythm surface of the music as it unfolds in time" . The "perception" and "abstraction" of rhythmic measure is the foundation of human instinctive musical participation, as when we divide a series of identical clock-ticks into "tick-tock-tick-tock" (; ).

Joseph Jordania recently suggested that the sense of rhythm was developed in the early stages of hominid evolution by the forces of natural selection . Plenty of animals walk rhythmically and hear the sounds of the heartbeat in the womb, but only humans have the ability to be engaged (entrained) in rhythmically coordinated vocalizations and other activities. According to Jordania, development of the sense of rhythm was central for the achievement of the specific neurological state of the battle trance, crucial for the development of the effective defense system of early hominids. Rhythmic war cry, rhythmic drumming by shamans, rhythmic drilling of the soldiers and contemporary professional combat forces listening to the heavy rhythmic rock music all use the ability of rhythm to unite human individuals into a shared collective identity where group members put the interests of the group above their individual interests and safety.

Some types of parrots can know rhythm . Neurologist Oliver Sacks states that chimpanzees and other animals show no similar appreciation of rhythm yet posits that human affinity for rhythm is fundamental, so that a person's sense of rhythm cannot be lost (e.g. by stroke). "There is not a single report of an animal being trained to tap, peck, or move in synchrony with an auditory beat" (, cited in , who adds, "No doubt many pet lovers will dispute this notion, and indeed many animals, from the Lippizaner horses of the Spanish Riding School of Vienna to performing circus animals appear to 'dance' to music. It is not clear whether they are doing so or are responding to subtle visual or tactile cues from the humans around them.") Human rhythmic arts are possibly to some extent rooted in courtship ritual .

The establishment of a basic beat requires the perception of a regular sequence of distinct short-duration pulses and, as a subjective perception of loudness is relative to background noise levels, a pulse must decay to silence before the next occurs if it is to be really distinct. For this reason, the fast-transient sounds of percussion instruments lend themselves to the definition of rhythm. Musical cultures that rely upon such instruments may develop multi-layered polyrhythm and simultaneous rhythms in more than one time signature, called polymeter. Such are the cross-rhythms of Sub-Saharan Africa and the interlocking "kotekan" rhythms of the "gamelan".

For information on rhythm in Indian music see Tala (music). For other Asian approaches to rhythm see Rhythm in Persian music, Rhythm in Arabic music and "Usul"âRhythm in Turkish music and Dumbek rhythms.

Most music, dance and oral poetry establishes and maintains an underlying "metric level", a basic unit of time that may be audible or implied, the pulse or "tactus" of the mensural level (; ; ), or "beat level", sometimes simply called the beat. This consists of a (repeating) series of identical yet distinct periodic short-duration stimuli perceived as points in time . The "beat" pulse is not necessarily the fastest or the slowest component of the rhythm but the one that is perceived as fundamental: it has a tempo to which listeners entrain as they tap their foot or dance to a piece of music . It is currently most often designated as a crotchet or quarter note in western notation (see time signature). Faster levels are "division levels", and slower levels are "multiple levels" . Maury Yeston clarified "Rhythms of recurrence" arise from the interaction of two levels of motion, the faster providing the pulse and the slower organizing the beats into repetitive groups . "Once a metric hierarchy has been established, we, as listeners, will maintain that organization as long as minimal evidence is present" .

A durational pattern that synchronises with a pulse or pulses on the underlying metric level may be called a "rhythmic unit". These may be classified as; "metric"âeven patterns, such as steady eighth notes or pulsesâ"intrametric"âconfirming patterns, such as dotted eighth-sixteenth note and swing patternsâ"contrametric"ânon-confirming, or syncopated patterns and "extrametric"âirregular patterns, such as tuplets.

A rhythmic gesture is any durational pattern that, in contrast to the rhythmic unit, does not occupy a period of time equivalent to a pulse or pulses on an underlying metric level. It may be described according to its beginning and ending or by the rhythmic units it contains. Rhythms that begin on a strong pulse are "thetic", those beginning on a weak pulse are "anacrustic" and those beginning after a rest or tied-over note are called "initial rest". Endings on a strong pulse are "strong", on a weak pulse, "weak" and those that end on a strong or weak upbeat are "upbeat" .

Rhythm is marked by the regulated succession of opposite elements, the dynamics of the strong and weak beat, the played beat and the inaudible but implied rest beat, the long and short note. As well as perceiving rhythm humans must be able to anticipate it. This depends on repetition of a pattern that is short enough to memorize.

The alternation of the strong and weak beat is fundamental to the ancient language of poetry, dance and music. The common poetic term "foot" refers, as in dance, to the lifting and tapping of the foot in time. In a similar way musicians speak of an upbeat and a downbeat and of the "on" and "off" beat. These contrasts naturally facilitate a dual hierarchy of rhythm and depend on repeating patterns of duration, accent and rest forming a "pulse-group" that corresponds to the poetic foot. Normally such pulse-groups are defined by taking the most accented beat as the first and counting the pulses until the next accent (; ). A rhythm that accents another beat and de-emphasises the downbeat as established or assumed from the melody or from a preceding rhythm is called syncopated rhythm.

Normally, even the most complex of meters may be broken down into a chain of duple and triple pulses (; ) either by addition or division. According to Pierre Boulez, beat structures beyond four, in western music, are "simply not natural" .

The tempo of the piece is the speed or frequency of the "tactus", a measure of how quickly the beat flows. This is often measured in 'beats per minute' (bpm): 60Â bpm means a speed of one beat per second, a frequency of 1Â Hz. A rhythmic unit is a durational pattern that has a period equivalent to a pulse or several pulses . The duration of any such unit is inversely related to its tempo.

Musical sound may be analyzed on five different time scales, which Moravscik has arranged in order of increasing duration .

Curtis Roads takes a wider view by distinguishing nine-time scales, this time in order of decreasing duration. The first two, the infinite and the supra musical, encompass natural periodicities of months, years, decades, centuries, and greater, while the last three, the sample and subsample, which take account of digital and electronic rates "too brief to be properly recorded or perceived", measured in millionths of seconds (microseconds), and finally the infinitesimal or infinitely brief, are again in the extra-musical domain. Roads' Macro level, encompassing "overall musical architecture or form" roughly corresponds to Moravcsik's "very long" division while his Meso level, the level of "divisions of form" including movements, sections, phrases taking seconds or minutes, is likewise similar to Moravcsik's "long" category. Roads' Sound object (; ): "a basic unit of musical structure" and a generalization of note (Xenakis' mini structural time scale); fraction of a second to several seconds, and his Microsound (see granular synthesis) down to the threshold of audible perception; thousands to millionths of seconds, are similarly comparable to Moravcsik's "short" and "supershort" levels of duration.

The study of rhythm, stress, and pitch in speech is called prosody (see also: prosody (music)): it is a topic in linguistics and poetics, where it means the number of lines in a verse, the number of syllables in each line and the arrangement of those syllables as long or short, accented or unaccented. Music inherited the term "meter or metre" from the terminology of poetry (; ; ).

The metric structure of music includes meter, tempo and all other rhythmic aspects that produce temporal regularity against which the foreground details or durational patterns of the music are projected (). The terminology of western music is notoriously imprecise in this area . preferred to speak of "time" and "rhythmic shape", Imogen Holst of "measured rhythm".

Dance music has instantly recognizable patterns of beats built upon a characteristic tempo and measure. The Imperial Society of Teachers of Dancing defines the tango, for example, as to be danced in time at approximately 66 beats per minute. The basic slow step forwards or backwards, lasting for one beat, is called a "slow", so that a full "rightâleft" step is equal to one measure ("See Rhythm and dance").

The general classifications of "metrical rhythm", "measured rhythm", and "free rhythm" may be distinguished . Metrical or divisive rhythm, by far the most common in Western music calculates each time value as a multiple or fraction of the beat. Normal accents re-occur regularly providing systematical grouping (measures). Measured rhythm (additive rhythm) also calculates each time value as a multiple or fraction of a specified time unit but the accents do not recur regularly within the cycle. Free rhythm is where there is neither , such as in Christian chant, which has a basic pulse but a freer rhythm, like the rhythm of prose compared to that of verse . "See Free time (music)".

Finally some music, such as some graphically scored works since the 1950s and non-European music such as Honkyoku repertoire for shakuhachi, may be considered "ametric" . "Senza misura" is an Italian musical term for "without meter", meaning to play without a beat, using time to measure how long it will take to play the bar ().

A "composite rhythm" is the durations and patterns (rhythm) produced by amalgamating all sounding parts of a musical texture. In music of the common practice period, the composite rhythm usually confirms the meter, often in metric or even-note patterns identical to the pulse on a specific metric level. White defines "composite rhythm" as, "the resultant overall rhythmic articulation among all the voices of a contrapuntal texture" . This concept was concurrently defined as âattack point rhythmâ by Maury Yeston in 1976 as âthe extreme rhythmic foreground of a composition â the absolute surface of articulated movementâ .

In the Griot tradition of Africa everything related to music has been passed on orally. Babatunde Olatunji (1927â2003) developed a simple series of spoken sounds for teaching the rhythms of the hand-drum, using six vocal sounds, "Goon, Doon, Go, Do, Pa, Ta", for three basic sounds on the drum, each played with either the left or the right hand. The debate about the appropriateness of staff notation for African music is a subject of particular interest to outsiders while African scholars from Kyagambiddwa to Kongo have, for the most part, accepted the conventions and limitations of staff notation, and produced transcriptions to inform and enable discussion and debate .

John Miller has argued that West African music is based on the tension between rhythms, polyrhythms created by the simultaneous sounding of two or more different rhythms, generally one dominant rhythm interacting with one or more independent competing rhythms. These often oppose or complement each other and the dominant rhythm. Moral values underpin a musical system based on repetition of relatively simple patterns that meet at distant cross-rhythmic intervals and on call-and-response form. Collective utterances such as proverbs or lineages appear either in phrases translated into "drum talk" or in the words of songs. People expect musicians to stimulate participation by reacting to people dancing. Appreciation of musicians is related to the effectiveness of their upholding community values .

Indian music has also been passed on orally. Tabla players would learn to speak complex rhythm patterns and phrases before attempting to play them. Sheila Chandra, an English pop singer of Indian descent, made performances based on her singing these patterns. In Indian Classical music, the Tala of a composition is the rhythmic pattern over which the whole piece is structured.

In the 20th century, composers like Igor Stravinsky, BÃ©la BartÃ³k, Philip Glass, and Steve Reich wrote more rhythmically complex music using odd meters, and techniques such as phasing and additive rhythm. At the same time, modernists such as Olivier Messiaen and his pupils used increased complexity to disrupt the sense of a regular beat, leading eventually to the widespread use of irrational rhythms in New Complexity. This use may be explained by a comment of John Cage's where he notes that regular rhythms cause sounds to be heard as a group rather than individually; the irregular rhythms highlight the rapidly changing pitch relationships that would otherwise be subsumed into irrelevant rhythmic groupings . La Monte Young also wrote music in which the sense of a regular beat is absent because the music consists only of long sustained tones (drones). In the 1930s, Henry Cowell wrote music involving multiple simultaneous periodic rhythms and collaborated with LÃ©on Theremin to invent the rhythmicon, the first electronic rhythm machine, in order to perform them. Similarly, Conlon Nancarrow wrote for the player piano.

In linguistics, rhythm or isochrony is one of the three aspects of prosody, along with stress and intonation. Languages can be categorized according to whether they are syllable-timed, mora-timed, or stress-timed. Speakers of syllable-timed languages such as Spanish and Cantonese put roughly equal time on each syllable; in contrast, speakers of stressed-timed languages such as English and Mandarin Chinese put roughly equal time lags between stressed syllables, with the timing of the unstressed syllables in between them being adjusted to accommodate the stress timing.




[[Category:Cognitive musicology]]
[[Category:Musical terminology]]
[[Category:Rhythm and meter|*]]
[[Category:Patterns]]

</doc>
<doc id="26228" url="https://en.wikipedia.org/wiki?curid=26228" title="Rondeau">
Rondeau

Rondeau may refer to:





</doc>
<doc id="26229" url="https://en.wikipedia.org/wiki?curid=26229" title="Riboflavin">
Riboflavin

Riboflavin, also known as vitamin B, is a vitamin found in food and used as a dietary supplement. Food sources include eggs, green vegetables, milk and other dairy product, meat, mushrooms, and almonds. Some countries require its addition to grains. As a supplement it is used to prevent and treat riboflavin deficiency and prevent migraines. It may be given by mouth or injection.
It is nearly always well tolerated. Normal doses are safe during pregnancy. Riboflavin is in the vitamin B group. It is required by the body for cellular respiration.
Riboflavin was discovered in 1920, isolated in 1933, and first made in 1935. It is on the World Health Organization's List of Essential Medicines, the safest and most effective medicines needed in a health system. Riboflavin is available as a generic medication and over the counter. In the United States a month of supplements was priced (in 2015) at less than 25 USD.

Corneal ectasia is a progressive thinning of the cornea; the most common form of this condition is keratoconus. Collagen cross-linking by applying riboflavin topically then shining UV light is a method to slow progression of corneal ectasia by strengthening corneal tissue.

As of 2017 a system is marketed by Terumo in Europe that is used to remove pathogens from blood; donated blood is treated with riboflavin and then with ultraviolet light.

A 2017 review found that riboflavin may be useful to prevent migraines in adults, but found that clinical trials in adolescents and children had produced mixed outcomes.

In humans, there is no evidence for riboflavin toxicity produced by excessive intakes, in part because it has lower water solubility than other B vitamins, because absorption becomes less efficient as doses increase, and because what exceeds the absorption is excreted via the kidneys into urine. Even when 400Â mg of riboflavin per day was given orally to subjects in one study for three months to investigate the efficacy of riboflavin in the prevention of migraine headache, no short-term side effects were reported. Although toxic doses can be administered by injection, any excess at nutritionally relevant doses is excreted in the urine, imparting a bright yellow color when in large quantities. The limited data available on riboflavin's adverse effects do not mean, however, that high intakes have no adverse effects, and the Food and Nutrition Board urges people to be cautious about consuming excessive amounts of riboflavin.

Flavin mononucleotide (FMN) and flavin adenine dinucleotide (FAD) function as cofactors for a variety of flavoprotein enzyme reactions:

For the molecular mechanism of action see main articles Flavin mononucleotide (FMN) and flavin adenine dinucleotide (FAD)

Other Flavin derivatives such as N(5)-ethylflavinium ion, Et-Fl+, can oxidize water and produce O2.

Food and beverages that provide riboflavin without fortification are milk, cheese, eggs, leaf vegetables, liver, kidneys, lean meats, legumes, mushrooms, and almonds.

The milling of cereals results in considerable loss (up to 60%) of vitamin B, so white flour is enriched in some countries by addition of the vitamin. The enrichment of bread and ready-to-eat breakfast cereals contributes significantly to the dietary supply of vitamin B. Polished rice is not usually enriched, because the vitamin's yellow color would make the rice visually unacceptable to the major rice-consuming populations. However, most of the flavin content of whole brown rice is retained if the rice is steamed (parboiled) prior to milling. This process drives the flavins in the germ and aleurone layers into the endosperm. Free riboflavin is naturally present in foods along with protein-bound FMN and FAD. Bovine milk contains mainly free riboflavin, with a minor contribution from FMN and FAD. In whole milk, 14% of the flavins are bound noncovalently to specific proteins. Milk and yogurt contain some of the highest riboflavin content. Egg white and egg yolk contain specialized riboflavin-binding proteins, which are required for storage of free riboflavin in the egg for use by the developing embryo.

Riboflavin is added to baby foods, breakfast cereals, pastas and vitamin-enriched meal replacement products. It is difficult to incorporate riboflavin into liquid products because it has poor solubility in water, hence the requirement for riboflavin-5'-phosphate (E101a), a more soluble form of riboflavin. Riboflavin is also used as a food coloring and as such is designated in Europe as the E number E101.

The National Academy of Medicine (then the U.S. Institute of Medicine [IOM]) updated Estimated Average Requirements (EARs) and Recommended Dietary Allowances (RDAs) for riboflavin in 1998. The current EARs for riboflavin for women and men ages 14 and up are 0.9Â mg/day and 1.1Â mg/day, respectively; the RDAs are 1.1 and 1.3Â mg/day, respectively. RDAs are higher than EARs so as to identify amounts that will cover people with higher than average requirements. RDA for pregnancy is 1.4Â mg/day. RDA for lactation is 1.6Â mg/day. For infants up to 12 months the Adequate Intake (AI) is 0.3â0.4Â mg/day. and for children ages 1â13 years the RDA increases with age from 0.5 to 0.9Â mg/day. As for safety, the IOM sets Tolerable upper intake levels (ULs) for vitamins and minerals when evidence is sufficient. In the case of riboflavin there is no UL, as there is no human data for adverse effects from high doses. Collectively the EARs, RDAs, AIs and ULs are referred to as Dietary Reference Intakes (DRIs).

The European Food Safety Authority (EFSA) refers to the collective set of information as Dietary Reference Values, with Population Reference Intake (PRI) instead of RDA, and Average Requirement instead of EAR. AI and UL defined the same as in United States. For women and men ages 15 and older the PRI is set at 1.6Â mg/day. PRI for pregnancy is 1.9Â mg/day, for lactation 2.0Â mg/day. For children ages 1â14 years the PRIs increase with age from 0.6 to 1.4Â mg/day. These PRIs are higher than the U.S. RDAs. The EFSA also reviewed the safety question and like the U.S., decided that there was not sufficient information to set an UL.

For U.S. food and dietary supplement labeling purposes the amount in a serving is expressed as a percent of Daily Value (%DV). For riboflavin labeling purposes 100% of the Daily Value was 1.7Â mg, but as of May 27, 2016 it was revised to 1.3Â mg to bring it into agreement with the RDA. A table of the old and new adult Daily Values is provided at Reference Daily Intake. The original deadline to be in compliance was July 28, 2018, but on September 29, 2017 the FDA released a proposed rule that extended the deadline to January 1, 2020 for large companies and January 1, 2021 for small companies.

Mild deficiencies can exceed 50% of the population in Third World countries and in refugee situations. Deficiency is uncommon in the United States and in other countries that have wheat flour, bread, pasta, corn meal or rice enrichment regulations. In the U.S., starting in the 1940s, flour, corn meal and rice have been fortified with B vitamins as a means of restoring some of what is lost in milling, bleaching and other processing. For adults 20 and older, average intake from food and beverages is 1.8Â mg/day for women and 2.5Â mg/day for men. An estimated 23% consume a riboflavin-containing dietary supplement that provides on average 10Â mg. The U.S. Department of Health and Human Services conducts National Health and Nutrition Examination Survey every two years and reports food results in a series of reports referred to as "What We Eat In America." From NHANES 2011â2012, estimates were that 8% of women and 3% of men consumed less than the RDA. When compared to the lower Estimated Average Requirements, fewer than 3% did not achieve the EAR level.

Riboflavin deficiency (also called ariboflavinosis) results in stomatitis including painful red tongue with sore throat, chapped and fissured lips (cheilosis), and inflammation of the corners of the mouth (angular stomatitis). There can be oily scaly skin rashes on the scrotum, vulva, philtrum of the lip, or the nasolabial folds. The eyes can become itchy, watery, bloodshot and sensitive to light. Due to interference with iron absorption, even mild to moderate riboflavin deficiency results in an anemia with normal cell size and normal hemoglobin content (i.e. normochromic normocytic anemia). This is distinct from anemia caused by deficiency of folic acid (B) or cyanocobalamin (B), which causes anemia with large blood cells (megaloblastic anemia). Deficiency of riboflavin during pregnancy can result in birth defects including congenital heart defects and limb deformities. Prolonged riboflavin insufficiency is also known to cause degeneration of the liver and nervous system.

The stomatitis symptoms are similar to those seen in pellagra, which is caused by niacin (B) deficiency. Therefore, riboflavin deficiency is sometimes called "pellagra sine pellagra" (pellagra without pellagra), because it causes stomatitis but not widespread peripheral skin lesions characteristic of niacin deficiency.

Riboflavin deficiency prolongs recovery from malaria, despite preventing growth of plasmodium (the malaria parasite).

Riboflavin is continuously excreted in the urine of healthy individuals, making deficiency relatively common when dietary intake is insufficient. Riboflavin deficiency is usually found together with other nutrient deficiencies, particularly of other water-soluble vitamins.
A deficiency of riboflavin can be primary â poor vitamin sources in one's daily diet â or secondary, which may be a result of conditions that affect absorption in the intestine, the body not being able to use the vitamin, or an increase in the excretion of the vitamin from the body.
Subclinical deficiency has also been observed in women taking oral contraceptives, in the elderly, in people with eating disorders, chronic alcoholism and in diseases such as HIV, inflammatory bowel disease, diabetes and chronic heart disease. The Celiac Disease Foundation points out that a gluten-free diet may be low in riboflavin (and other nutrients) as enriched wheat flour and wheat foods (bread, pasta, cereals, etc.) is a major dietary contribution to total riboflavin intake.
Phototherapy to treat jaundice in infants can cause increased degradation of riboflavin, leading to deficiency if not monitored closely.

Overt clinical signs are rarely seen among inhabitants of the developed countries. The assessment of riboflavin status is essential for confirming cases with unspecific symptoms where deficiency is suspected.


Treatment involves a diet which includes an adequate amount of riboflavin containing foods. Multi-vitamin and mineral dietary supplements often contain 100% of the Daily Value (1.3Â mg) for riboflavin, and can be used by persons concerned about an inadequate diet. Over-the-counter dietary supplements are available in the United States with doses as high as 100Â mg, but there is no evidence that these high doses have any additional benefit for healthy people.

In other animals, riboflavin deficiency results in lack of growth, failure to thrive, and eventual death. Experimental riboflavin deficiency in dogs results in growth failure, weakness, ataxia, and inability to stand. The animals collapse, become comatose, and die. During the deficiency state, dermatitis develops together with hair loss. Other signs include corneal opacity, lenticular cataracts, hemorrhagic adrenals, fatty degeneration of the kidney and liver, and inflammation of the mucous membrane of the gastrointestinal tract. Post-mortem studies in rhesus monkeys fed a riboflavin-deficient diet revealed about one-third the normal amount of riboflavin was present in the liver, which is the main storage organ for riboflavin in mammals. Riboflavin deficiency in birds results in low egg hatch rates.

As a chemical compound, riboflavin is a yellow-orange solid substance with poor solubility in water compared to other B vitamins. Visually, it imparts color to vitamin supplements (and bright yellow color of urine in persons taking it).

Because riboflavin is fluorescent under UV light, dilute solutions (0.015â0.025% w/w) are often used to detect leaks or to demonstrate coverage in an industrial system such a chemical blend tank or bioreactor. (See the ASME BPE section on Testing and Inspection for additional details.)

The industrial scale production of riboflavin using diverse microorganisms, including filamentous fungi such as "Ashbya gossypii", "Candida famata" and "Candida flaveri", as well as the bacteria "Corynebacterium ammoniagenes" and "Bacillus subtilis". The latter organism, genetically modified to both increase the production of riboflavin and to introduce an antibiotic (ampicillin) resistance marker, is employed at a commercial scale to produce riboflavin for feed and food fortification. The chemical company BASF has installed a plant in South Korea, which is specialized on riboflavin production using "Ashbya gossypii". The concentrations of riboflavin in their modified strain are so high that the mycelium has a reddish/brownish color and accumulates riboflavin crystals in the vacuoles, which will eventually burst the mycelium. Riboflavin is sometimes overproduced, possibly as a protective mechanism, by some bacteria in the presence of high concentrations of hydrocarbons or aromatic compounds. One such organism is "Micrococcus luteus" (American Type Culture Collection strain number ATCC 49442), which develops a yellow color due to production of riboflavin while growing on pyridine, but not when grown on other substrates, such as succinic acid.

Vitamin B was originally considered to have two components, a heat-labile vitamin B and a heat-stable vitamin B. In the 1920s, vitamin B was thought to be the factor necessary for preventing pellagra. In 1923, Paul Gyorgy in Heidelberg was investigating egg-white injury in rats; the curative factor for this condition was called vitamin H (which is now called biotin or vitamin B). Since both pellagra and vitamin H deficiency were associated with dermatitis, Gyorgy decided to test the effect of vitamin B on vitamin H deficiency in rats. He enlisted the service of Wagner-Jauregg in Kuhn's laboratory. In 1933, Kuhn, Gyorgy, and Wagner found that thiamin-free extracts of yeast, liver, or rice bran prevented the growth failure of rats fed a thiamin-supplemented diet.

Further, the researchers noted that a yellow-green fluorescence in each extract promoted rat growth, and that the intensity of fluorescence was proportional to the effect on growth. This observation enabled them to develop a rapid chemical and bioassay to isolate the factor from egg white in 1933. The same group then isolated the same preparation (a growth-promoting compound with yellow-green fluorescence) from whey using the same procedure (lactoflavin). In 1934, Kuhn's group identified the structure of so-called flavin and synthesized vitamin B, leading to evidence in 1939 that riboflavin was essential for human health.

The name "riboflavin" (often abbreviated to Rbf or RBF) comes from "ribose" (the sugar whose reduced form, ribitol, forms part of its structure) and "flavin", the ring-moiety which imparts the yellow color to the oxidized molecule (from Latin "flavus", "yellow"). The reduced form, which occurs in metabolism along with the oxidized form, is colorless.



</doc>
<doc id="26230" url="https://en.wikipedia.org/wiki?curid=26230" title="Rijksmuseum">
Rijksmuseum

The Rijksmuseum (; ) is a Dutch national museum dedicated to arts and history in Amsterdam. The museum is located at the Museum Square in the borough Amsterdam South, close to the Van Gogh Museum, the Stedelijk Museum Amsterdam, and the Concertgebouw.

The Rijksmuseum was founded in The Hague on 19 november 1798 and moved to Amsterdam in 1808, where it was first located in the Royal Palace and later in the Trippenhuis. The current main building was designed by Pierre Cuypers and first opened in 1885. On 13 April 2013, after a ten-year renovation which cost â¬ 375 million, the main building was reopened by Queen Beatrix. In 2013 and 2014, it was the most visited museum in the Netherlands with record numbers of 2.2 million and 2.47 million visitors. It is also the largest art museum in the country.

The museum has on display 8,000 objects of art and history, from their total collection of 1 million objects from the years 1200â2000, among which are some masterpieces by Rembrandt, Frans Hals, and Johannes Vermeer. The museum also has a small Asian collection, which is on display in the Asian pavilion.

In 1795, the Batavian Republic was proclaimed. The Minister of Finance Isaac Gogel argued that a national museum, following the French example of The Louvre, would serve the national interest. On 19 November 1798, the government decided to found the museum.

On 31 May 1800, the National Art Gallery (Dutch: "Nationale Kunst-Galerij"), precursor of the Rijksmuseum, opened in Huis ten Bosch in The Hague. The museum exhibited around 200 paintings and historic objects from the collections of the Dutch stadtholders.

In 1805, the National Art Gallery moved within The Hague to the Prince William V Gallery, on the Buitenhof.

In 1806, the Kingdom of Holland was established by Napoleon Bonaparte. On the orders of king Louis Bonaparte, brother of Napoleon, the museum moved to Amsterdam in 1808. The paintings owned by that city, such as "The Night Watch" by Rembrandt, became part of the collection. In 1809, the museum opened in the Royal Palace in Amsterdam.

In 1817, the museum moved to the Trippenhuis. The Trippenhuis turned out to be unsuitable as a museum. In 1820, the historical objects were moved to the Mauritshuis in The Hague and in 1838, the 19th-century paintings ""of living masters"" were moved to King Louis Bonaparte's former summer palace Paviljoen Welgelegen in Haarlem.

In 1863, there was a design contest for a new building for the Rijksmuseum, but none of the submissions was considered to be of sufficient quality. Pierre Cuypers also participated in the contest and his submission reached the second place.

In 1876, a new contest was held and this time Pierre Cuypers won. The design was a combination of gothic and renaissance elements. The construction began on 1 October 1876. On both the inside and the outside, the building was richly decorated with references to Dutch art history. Another contest was held for these decorations. The winners were B. van Hove and J.F. Vermeylen for the sculptures, G. Sturm for the tile tableaus and painting and W.F. Dixon for the stained glass. The museum was opened at its new location on 13 July 1885.

In 1890, a new building was added a short distance to the south-west of the Rijksmuseum. As the building was made out of fragments of demolished buildings, the building offers an overview of the history of Dutch architecture and has come to be known informally as the 'fragment building'. It is also known as the 'south wing' and is currently (in 2013) branded the "Philips Wing".

In 1906, the hall for the "Night Watch" was rebuilt. In the interior more changes were made between the 1920s and 1950s - most multi-coloured wall decorations were painted over. In the 1960s exposition rooms and several floors were built into the two courtyards. The building had some minor renovations and restorations in 1984, 1995â1996 and 2000.

A renovation of the south wing of the museum, also known as the 'fragment building' or 'Philips Wing', was completed in 1996, the same year that the museum held its first major photography exhibition featuring its extensive collection of 19th-century photos.

In December 2003, the main building of the museum closed for a major renovation. During this renovation, about 400 objects from the collection were on display in the 'fragment building', including Rembrandt's "The Night Watch" and other 17th-century masterpieces.

The restoration and renovation of the Rijksmuseum are based on a design by Spanish architects Antonio Cruz and Antonio Ortiz. Many of the old interior decorations were restored and the floors in the courtyards were removed. The renovation would have initially taken five years, but was delayed and eventually took almost ten years to complete. The renovation cost â¬ 375 million.

The reconstruction of the building was completed on 16 July 2012. In March 2013, the museum's main pieces of art were moved back from the 'fragment building' (Philips Wing) to the main building. "The Night Watch" returned to the Night Watch Room, at the end of the Hall of Fame. On 13 April 2013, the main building was reopened by Queen Beatrix. On 1 November 2014, the Philips Wing reopened with the exhibition .


The building of the Rijksmuseum was designed by Pierre Cuypers and opened in 1885. It consists of two squares with an atrium in each centre. In the central axis is a tunnel with the entrances at ground level and the Gallery of Honour at the first floor. The building also contains a library. The fragment building, branded Philips wing, contains building fragments that show the history of architecture in the Netherlands. The Rijksmuseum is a "rijksmonument" (national heritage site) since 1970 and was listed in the Top 100 Dutch heritage sites in 1990. The Asian pavilion was designed by Cruz y Ortiz and opened in 2013.

According to Muriel Huisman, Project Architect for the Rijksmuseum's renovation, "Cruz y Ortiz always like to look for synergy between old and new, and we try not to explain things with our architecture.â With the Rijks, âthereâs no cut between old and new; weâve tried to merge it. We did this by looking for materials that were true to the original building, resulting in a kind of silent architecture."

The collection of the Rijksmuseum consists of 1 million objects and is dedicated to arts, crafts, and history from the years 1200 to 2000. Around 8,000 objects are currently on display in the museum.

The collection contains more than 2,000 paintings from the Dutch Golden Age by notable painters such as Jacob van Ruisdael, Frans Hals, Johannes Vermeer, Jan Steen, Rembrandt, and Rembrandt's pupils.

The museum also has a small Asian collection which is on display in the Asian pavilion.

It also displays the stern of HMS "Royal Charles" which was captured in the Raid on the Medway, and the Hartog plate.

In 2012, the museum took the unusual step of making some 125,000 high-resolution images available for download via its Rijksstudio webplatform, with plans to add another 40,000 images per year until the entire collection of one million works is available, according to Taco Dibbits, director of collections.

The 20th-century visitor record of 1,412,000 was reached in the year 1975.

In the 1990s and early 2000s, the Rijksmuseum was annually visited by 0.9 to 1.3 million people. On 7 December 2003, the main building of the museum was closed for a renovation until 13 April 2013. In the preceding decade, the number of visitors had slightly decreased to 0.8 to 1.1 million people. The museum says after the renovation, the museum's capacity is 1.5 to 2.0 million visitors annually. Within eight months since the reopening in 2013, the museum was visited by 2 million people.

The museum had 2.2 million visitors in 2013 and reached an all-time record of 2.47 million visitors in 2014. The museum was the most visited museum in the Netherlands and the 19th most visited art museum in the world in 2013 and 2014.

The Rijksmuseum Research Library is part of the Rijksmuseum, and is the best and the largest public art history research library in The Netherlands.

Rijks, stylized as RIJKSÂ®, is a restaurant with 140 seats in the Philips Wing. Joris Bijdendijk has been the chef de cuisine since the opening in 2014. The restaurant was awarded a Michelin star in 2017.



</doc>
<doc id="26232" url="https://en.wikipedia.org/wiki?curid=26232" title="Ruhollah Khomeini">
Ruhollah Khomeini

Sayyid Ruhollah Musavi Khomeini ( , ; ; 24 September 1902 â 3 June 1989), also known in the Western world as Ayatollah Khomeini, was an Iranian revolutionary, politician, and cleric. He was the founder of the Islamic Republic of Iran and the leader of the 1979 Iranian Revolution, which saw the overthrow of the last shah of Iran, Mohammad Reza Pahlavi, and the end of the 2,500 year old Persian monarchy. Following the revolution, Khomeini became the country's supreme leader, a position created in the constitution of the Islamic Republic as the highest-ranking political and religious authority of the nation, which he held until his death. He was succeeded by Ali Khamenei on 4 June 1989.

Khomeini was born in 1902 in Khomeyn, in what is now Iran's Markazi Province. His father was murdered in 1903 when Khomeini was five months old. He began studying the Quran and the Persian language from a young age and was assisted in his religious studies by his relatives, including his mother's cousin and older brother.

Khomeini was a "marja" ("source of emulation") in Twelver Shia Islam, a Mujtahid or "faqih" (an expert in Sharia) and author of more than 40 books, but he is primarily known for his political activities. He spent more than 15 years in exile for his opposition to the last shah. In his writings and preachings he expanded the theory of "welayat-el faqih", the "Guardianship of the Islamic Jurist (clerical authority)", to include theocratic . This principle (though not known to the wider public before the revolution), was appended to the new Iranian constitution after being put to a referendum. According to "The New York Times", Khomeini called democracy the equivalent of prostitution. Whether Khomeini's ideas are compatible with democracy and whether he intended the Islamic Republic to be democratic is disputed. He was "Time" magazine's Man of the Year in 1979 for his international influence, and Khomeini has been described as the "virtual face of Shia Islam in Western popular culture". In 1982, he survived one military coup attempt. Khomeini was known for his support of the hostage takers during the Iran hostage crisis, his fatwa calling for the murder of British Indian novelist Salman Rushdie, and for referring to the United States as the "Great Satan" and Soviet Union as the "Lesser Satan." Khomeini has been criticized for these acts and for human rights violations of Iranians (including his ordering of execution of thousands of political prisoners, war criminals and prisoners of the IranâIraq War).

He has also been lauded as a "charismatic leader of immense popularity", a "champion of Islamic revival" by Shia scholars, who attempted to establish good relations between Sunnis and Shias, and a major innovator in political theory and religious-oriented populist political strategy. Khomeini held the title of Grand Ayatollah and is officially known as Imam Khomeini inside Iran and by his supporters internationally. He is generally referred to as Ayatollah Khomeini by others. In Iran, his gold-domed tomb in Tehran's Behesht-e ZahrÄÊ¾ cemetery has become a shrine for his adherents, and he is legally considered "inviolable", with Iranians regularly punished for insulting him.

Ruhollah Khomeini's ancestors migrated towards the end of the 18th century from their original home in Nishapur, Khorasan Province, in northeastern part of Iran, for a short stay, to the Kingdom of Awadh â a region in the modern state of Uttar Pradesh, India â whose rulers were Twelver Shia Muslims of also Nishapur origin. During their rule they extensively invited, and received, a steady stream of Persian scholars, poets, jurists, architects, and painters. The family eventually settled in the small town of Kintoor, near Lucknow, the capital of Awadh. Ayatollah Khomeini's paternal grandfather, Seyyed Ahmad Musavi Hindi, was born in Kintoor. He left Lucknow in 1830, on a pilgrimage to the tomb of Imam Ali in Najaf, Ottoman Iraq (now Iraq) and never returned. According to Moin, this migration was to escape from the spread of British power in India. In 1834 Seyyed Ahmad Musavi Hindi visited Persia, and in 1839 he settled in Khomein. Although he stayed and settled in Iran, he continued to be known as "Hindi", indicating his stay in India, and Ruhollah Khomeini even used "Hindi" as a pen name in some of his ghazals. There are also claims that Seyyed Ahmad Musavi Hindi departed from Kashmir, instead of Lucknow. Khomeini's grandfather, Mirza Ahmad Mojtahed-e Khonsari was the cleric issuing a fatwa to forbid usage of Tobacco during the Tobacco Protest.

Ruhollah Musavi Khomeini, whose first name means "spirit of Allah", was born on 24 September 1902 in Khomeyn, Markazi Province. He was raised by his mother, Hajieh Agha Khanum, and his aunt, Sahebeth, following the murder of his father, Mustapha Musavi, five months after his birth in 1903.

Ruhollah began to study the Qur'an and elementary Persian at the age of six. The following year, he began to attend a local school, where he learned religion, "noheh khani" (lamentation recital), and other traditional subjects. Throughout his childhood, he continued his religious education with the assistance of his relatives, including his mother's cousin, Ja'far, and his elder brother, Morteza Pasandideh.

After World War I arrangements were made for him to study at the Islamic seminary in Isfahan, but he was attracted instead to the seminary in Arak. He was placed under the leadership of Ayatollah Abdul Karim Haeri Yazdi. In 1920, Khomeini moved to Arak and commenced his studies. The following year, Ayatollah Haeri Yazdi transferred to the Islamic seminary in the holy city of Qom, southwest of Tehran, and invited his students to follow. Khomeini accepted the invitation, moved, and took up residence at the Dar al-Shafa school in Qom. Khomeini's studies included Islamic law ("sharia") and jurisprudence ("fiqh"), but by that time, Khomeini had also acquired an interest in poetry and philosophy ("irfan"). So, upon arriving in Qom, Khomeini sought the guidance of Mirza Ali Akbar Yazdi, a scholar of philosophy and mysticism. Yazdi died in 1924, but Khomeini continued to pursue his interest in philosophy with two other teachers, Javad Aqa Maleki Tabrizi and Rafi'i Qazvini. However, perhaps Khomeini's biggest influences were another teacher, Mirza Muhammad 'Ali Shahabadi, and a variety of historic Sufi mystics, including Mulla Sadra and Ibn Arabi.

Khomeini studied Greek philosophy and was influenced by both the philosophy of Aristotle, whom he regarded as the founder of logic, and Plato, whose views "in the field of divinity" he regarded as "grave and solid". Among Islamic philosophers, Khomeini was mainly influenced by Avicenna and Mulla Sadra.
Apart from philosophy, Khomeini was interested in literature and poetry. His poetry collection was released after his death. Beginning in his adolescent years, Khomeini composed mystic, political and social poetry. His poetry works were published in three collections: "The Confidant", "The Decanter of Love and Turning Point", and "Divan". His knowledge of poetry is further attested by the modern poet Nader Naderpour (1929â2000), who "had spent many hours exchanging poems with Khomeini in the early 1960". Naderpour remembered: "For four hours we recited poetry. Every single line I recited from any poet, he recited the next."

Ruhollah Khomeini was a lecturer at Najaf and Qom seminaries for decades before he was known on the political scene. He soon became a leading scholar of Shia Islam. He taught political philosophy, Islamic history and ethics. Several of his students â for example, Morteza Motahhari â later became leading Islamic philosophers and also "marja'". As a scholar and teacher, Khomeini produced numerous writings on Islamic philosophy, law, and ethics. He showed an exceptional interest in subjects like philosophy and mysticism that not only were usually absent from the curriculum of seminaries but were often an object of hostility and suspicion.

Inaugurating his teaching career at the age of 27 by giving private lessons on irfan and Mulla Sadra to a private circle, around the same time, in 1928, he also released his first publication, "Sharh Du'a al-Sahar" (Commentary on the Du'a al-Baha), "a detailed commentary, in Arabic, on the prayer recited before dawn during Ramadan by Imam Ja'far al-Sadiq", followed, some years later, by "Sirr al-Salat" (Secret of the Prayer), where "the symbolic dimensions and inner meaning of every part of the prayer, from the ablution that precedes it to the salam that concludes it, are expounded in a rich, complex, and eloquent language that owes much to the concepts and terminology of Ibn 'Arabi. As Sayyid Fihri, the editor and translator of "Sirr al-Salat", has remarked, the work is addressed only to the foremost among the spiritual elite (akhass-i khavass) and establishes its author as one of their number." The second book has been translated by Sayyid Amjad Hussain Shah Naqavi and released by BRILL in 2015, under the title "The Mystery of Prayer: The Ascension of the Wayfarers and the Prayer of the Gnostics".

His seminary teaching often focused on the importance of religion to practical social and political issues of the day, and he worked against secularism in the 1940s. His first political book, "Kashf al-Asrar" (Uncovering of Secrets) published in 1942, was a point-by-point refutation of "Asrar-e hezar sale" (Secrets of a Thousand Years), a tract written by a disciple of Iran's leading anti-clerical historian, Ahmad Kasravi, as well as a condemnation of innovations such as international time zones, and the banning of hijab by Reza Shah. In addition, he went from Qom to Tehran to listen to Ayatullah Hasan Mudarris, the leader of the opposition majority in Iran's parliament during the 1920s. Khomeini became a "marja"' in 1963, following the death of Grand Ayatollah Seyyed Husayn Borujerdi.

Most Iranians had a deep respect for the Shi'a clergy or Ulama, and tended to be religious, traditional, and alienated from the process of Westernization pursued by the Shah. In the late 19th century the clergy had shown themselves to be a powerful political force in Iran initiating the Tobacco Protest against a concession to a foreign (British) interest.

At the age of 61, Khomeini found the arena of leadership open following the deaths of Ayatollah Sayyed Husayn Borujerdi (1961), the leading, although quiescent, Shi'ah religious leader; and Ayatollah Abol-Ghasem Kashani (1962), an activist cleric. The clerical class had been on the defensive ever since the 1920s when the secular, anti-clerical modernizer Reza Shah Pahlavi rose to power. Reza's son Mohammad Reza Shah, instituted a "White Revolution", which was a further challenge to the Ulama.

In January 1963, the Shah announced the "White Revolution", a six-point programme of reform calling for land reform, nationalization of the forests, the sale of state-owned enterprises to private interests, electoral changes to enfranchise women and allow non-Muslims to hold office, profit-sharing in industry, and a literacy campaign in the nation's schools. Some of these initiatives were regarded as dangerous, especially by the powerful and privileged Shi'a ulama (religious scholars), and as Westernizing trends by traditionalists (Khomeini viewed them as "an attack on Islam"). Ayatollah Khomeini summoned a meeting of the other senior marjas of Qom and persuaded them to decree a boycott of the referendum on the White Revolution. On 22 January 1963 Khomeini issued a strongly worded declaration denouncing the Shah and his plans. Two days later the Shah took an armored column to Qom, and delivered a speech harshly attacking the ulama as a class.

Khomeini continued his denunciation of the Shah's programmes, issuing a manifesto that bore the signatures of eight other senior Iranian Shia religious scholars. In it he listed the various ways in which the Shah had allegedly violated the constitution, condemned the spread of moral corruption in the country, and accused the Shah of submission to the United States and Israel. He also decreed that the Nowruz celebrations for the Iranian year 1342 (which fell on 21 March 1963) be canceled as a sign of protest against government policies.
On the afternoon of 'Ashura (3 June 1963), Khomeini delivered a speech at the Feyziyeh madrasah drawing parallels between the Sunni Muslim caliph Yazid, who is perceived as a 'tyrant' by Shias, and the Shah, denouncing the Shah as a "wretched, miserable man," and warning him that if he did not change his ways the day would come when the people would offer up thanks for his departure from the country.

On 5 June 1963 (15 of Khordad) at 3:00Â am, two days after this public denunciation of the Shah Mohammad Reza Pahlavi, Khomeini was detained in Qom and transferred to Tehran. Following this action, there were three days of major riots throughout Iran and the deaths of some 400 people. That event is now referred to as the Movement of 15 Khordad. Khomeini was kept under house arrest and released in August.

On 26 October 1964, Khomeini denounced both the Shah and the United States. This time it was in response to the "capitulations" or diplomatic immunity granted by the Shah to American military personnel in Iran. The "capitulation" law (or "status-of-forces agreement") allowed members of the U.S. armed forces in Iran to be tried in their own military courts. Khomeini was arrested in November 1964 and held for half a year. Upon his release, he was brought before Prime Minister Hasan Ali Mansur, who tried to convince Khomeini that he should apologize and drop his opposition to the government. When Khomeini refused, Mansur slapped Khomeini's face in a fit of rage. Two months later, Mansur was assassinated on his way to parliament. Four members of the Fadayan-e Islam were later executed for the murder.

Khomeini spent more than 14 years in exile, mostly in the holy Iraqi city of Najaf. Initially, he was sent to Turkey on 4 November 1964 where he stayed in Bursa in the home of Colonel Ali Cetiner of the Turkish Military Intelligence. In October 1965, after less than a year, he was allowed to move to Najaf, Iraq, where he stayed until 1978, when he was expelled by then-Vice President Saddam Hussein. By this time discontent with the Shah was becoming intense and Khomeini visited Neauphle-le-ChÃ¢teau, a suburb of Paris, France on a tourist visa on 6 October 1978.

By the late 1960s, Khomeini was a marja-e taqlid (model for imitation) for "hundreds of thousands" of Shia, one of six or so models in the Shia world. While in the 1940s Khomeini accepted the idea of a limited monarchy under the Iranian Constitution of 1906â07 â as evidenced by his book "Kashf al-Asrar" â by the 1970s he had rejected the idea. In early 1970, Khomeini gave a series of lectures in Najaf on Islamic government, later published as a book titled variously "Islamic Government" or "" ("Hokumat-e Islami: Velayat-e faqih").

This was his best known and most influential work, and laid out his ideas on governance (at that time):

A modified form of this "wilayat al-faqih" system was adopted after Khomeini and his followers took power, and Khomeini was the Islamic Republic's first "Guardian" or "Supreme Leader". In the meantime, however, Khomeini was careful not to publicize his ideas for clerical rule outside of his Islamic network of opposition to the Shah which he worked to build and strengthen over the next decade. In Iran, a number of actions of the Shah including his repression of opponents began to build opposition to his regime.

Cassette copies of his lectures fiercely denouncing the Shah as (for example) "the Jewish agent, the American serpent whose head must be smashed with a stone", became common items in the markets of Iran, helping to demythologize the power and dignity of the Shah and his reign. Aware of the importance of broadening his base, Khomeini reached out to Islamic reformist and secular enemies of the Shah, despite his long-term ideological incompatibility with them.

After the 1977 death of Ali Shariati (an Islamic reformist and political revolutionary author/academic/philosopher who greatly assisted the Islamic revival among young educated Iranians), Khomeini became the most influential leader of the opposition to the Shah. Adding to his mystique was the circulation among Iranians in the 1970s of an old Shia saying attributed to the Imam Musa al-Kadhem. Prior to his death in 799, al-Kadhem was said to have prophesied that "A man will come out from Qom and he will summon people to the right path". In late 1978, a rumour swept the country that Khomeini's face could be seen in the full moon. Millions of people were said to have seen it and the event was celebrated in thousands of mosques. He was perceived by many Iranians as the spiritual as well as political leader of the revolt. Additionally, the episode with Khomeini's face in the moon showed that in late 1978 he was increasingly regarded as a messianic figure in Iran.

As protests grew, so did his profile and importance. Although several thousand kilometers away from Iran in Paris, Khomeini set the course of the revolution, urging Iranians not to compromise and ordering work stoppages against the regime. During the last few months of his exile, Khomeini received a constant stream of reporters, supporters, and notables, eager to hear the spiritual leader of the revolution.

AccordingÂ to the BBC, Khomeini's contact with the US "is part of a trove of newly declassified US government documents - diplomatic cables, policy memos, meeting records". The documents suggest that the Carter administration helped Khomeini return to Iran by preventing the Iranian army from launching a military coup, and that Khomeini told an American in France to convey a message to Washington that "There should be no fear about oil. It is not true that we wouldn't sell to the US." Guardian wrote that it "did not have access to the newly declassified documents and was not able to independently verify them".

Supreme leader Ayatollah Ali Khamenei denied the report, and described the documents as âfabricatedâ. Other Iranian politicians including Ebrahim Yazdi, Khomeini's spokesman, and adviser at the time of the revolution, have questioned the BBC's documents. Mark Toner, deputy spokesperson at the state department, when asked about contact between the Carter administration and Khomeini, responded "I apologise. Iâm not â Iâm not aware of that and I donât have any updates to offer". Zbigniew Brzezinski, who was national security adviser to Carter from 1977 to 1981, said "I do not have any special information particularly on the Ayatollah and his role in it. Probably in some fashion there was some involvement but nothing specific that I can recall."

According to the BBC, "these document show that in his long quest for power, he [Khomeini] was tactically flexible; he played the moderate even pro-American card to take control but once change had come he put in place an anti-America legacy that would last for decades."

Khomeini was not allowed to return to Iran during the Shah's reign (as he had been in exile). On 16 January 1979, the Shah left the country for medical treatment (ostensibly "on vacation"), never to return. Two weeks later, on Thursday, 1 February 1979, Khomeini returned in triumph to Iran, welcomed by a joyous crowd estimated (by the BBC) to be of up to five million people. On his chartered Air France flight back to Tehran, he was accompanied by 120 journalists, including three women. One of the journalists, Peter Jennings, asked: "Ayatollah, would you be so kind as to tell us how you feel about being back in Iran?" Khomeini answered via his aide Sadegh Ghotbzadeh: ""Hichi"" (Nothing). This statementâmuch discussed at the time and sinceâwas considered by some reflective of his mystical beliefs and non-attachment to ego. Others considered it a warning to Iranians who hoped he would be a "mainstream nationalist leader" that they were in for disappointment. To others, it was a reflection of an unfeeling leader incapable or unconcerned with understanding the thoughts, beliefs, or the needs of the Iranian populace.

Khomeini adamantly opposed the provisional government of Shapour Bakhtiar, promising "I shall kick their teeth in. I appoint the government." On 11 February (Bahman 22), Khomeini appointed his own competing interim prime minister, Mehdi Bazargan, demanding, "since I have appointed him, he must be obeyed." It was "God's government," he warned, disobedience against him or Bazargan was considered a "revolt against God."

As Khomeini's movement gained momentum, soldiers began to defect to his side and Khomeini declared ill fortune on troops who did not surrender. On 11 February, as revolt spread and armories were taken over, the military declared neutrality and the Bakhtiar regime collapsed. On 30 and 31 March 1979, a referendum to replace the monarchy with an Islamic Republic passed with 98% voting in favour of the replacement, with the question: "should the monarchy be abolished in favour of an Islamic Government?"

Although revolutionaries were now in charge and Khomeini was their leader, some opposition groups claim that several secular and religious groups were unaware of Khomeini's plan for Islamic government by "wilayat al-faqih", which involved rule by a marja' Islamic cleric. They claim that this provisional constitution for the Islamic Republic did not include the post of supreme Islamic clerical ruler. The Islamic government was clearly defined by Khomeini in his book "" (Islamic Government: Governance of the Jurist) which was published while Khomeini was in exile in 1970, smuggled into Iran, and distributed to Khomeini's supporters. This book included Khomeini's notion of "wilayat al-faqih" (Governance of the Jurist) as well as the reasoning and in his view, the necessity of it in running an Islamic state.
Khomeini and his supporters worked to suppress some former allies and rewrote the proposed constitution. Some newspapers were closed, and those protesting the closings were attacked. Opposition groups such as the National Democratic Front and Muslim People's Republican Party were attacked and finally banned. Through popular support, Khomeini supporters gained an overwhelming majority of the seats in the Assembly of Experts which revised the proposed constitution. The newly proposed constitution included an Islamic jurist Supreme Leader of the country, and a Council of Guardians to veto un-Islamic legislation and screen candidates for office, disqualifying those found un-Islamic.

In November 1979, the new constitution of the Islamic Republic was adopted by national referendum. Khomeini himself became instituted as the Supreme Leader (Guardian Jurist), and officially became known as the "Leader of the Revolution." On 4 February 1980, Abolhassan Banisadr was elected as the first president of Iran. Critics complain that Khomeini had gone back on his word to advise, rather than rule the country.

On 22 October 1979, the United States admitted the exiled and ailing Shah into the country for cancer treatment. In Iran, there was an immediate outcry, with both Khomeini and leftist groups demanding the Shah's return to Iran for trial and execution.

On 4 November, a group of Iranian college students calling themselves the Muslim Student Followers of the Imam's Line, took control of the American Embassy in Tehran, holding 52 embassy staff hostage for 444 days â an event known as the Iran hostage crisis. In the United States, the hostage-taking was seen as a flagrant violation of international law and aroused intense anger and anti-Iranian sentiments.

In Iran, the takeover was immensely popular and earned the support of Khomeini under the slogan "America can't do a damn thing against us." The seizure of the embassy of a country he called the "Great Satan" helped to advance the cause of theocratic government and outflank politicians and groups who emphasized stability and normalized relations with other countries. Khomeini is reported to have told his president: "This action has many benefits ... this has united our people. Our opponents do not dare act against us. We can put the constitution to the people's vote without difficulty, and carry out presidential and parliamentary elections." The new constitution was successfully passed by referendum a month after the hostage crisis began.

The crisis had the effect of splitting of the opposition into two groups â radicals supporting the hostage taking, and the moderates opposing it. On 23 February 1980, Khomeini proclaimed Iran's Majlis would decide the fate of the American embassy hostages, and demanded that the United States hand over the Shah for trial in Iran for crimes against the nation. Although the Shah died a few months later, during the summer, the crisis continued. In Iran, supporters of Khomeini named the embassy a "Den of Espionage", publicizing details regarding armaments, espionage equipment and many volumes of official and classified documents which they found there.

Khomeini believed in Muslim unity and solidarity and the export of his revolution throughout the world. He believed Shia and (the significantly more numerous) Sunni Muslims should be "united and stand firmly against Western and arrogant powers."
"Establishing the Islamic state world-wide belong to the great goals of the revolution." He declared the birth week of Muhammad (the week between 12th to 17th of Rabi' al-awwal) as the "Unity week". Then he declared the last Friday of Ramadan as International Day of Quds in 1981.

Shortly after assuming power, Khomeini began calling for Islamic revolutions across the Muslim world, including Iran's Arab neighbor Iraq, the one large state besides Iran with a Shia majority population. At the same time Saddam Hussein, Iraq's secular Arab nationalist Ba'athist leader, was eager to take advantage of Iran's weakened military and (what he assumed was) revolutionary chaos, and in particular to occupy Iran's adjacent oil-rich province of Khuzestan, and to undermine Iranian Islamic revolutionary attempts to incite the Shi'a majority of his country.

In September 1980, Iraq launched a full-scale invasion of Iran, beginning the IranâIraq War (September 1980 â August 1988). A combination of fierce resistance by Iranians and military incompetence by Iraqi forces soon stalled the Iraqi advance and, despite Saddam's internationally condemned use of poison gas, Iran had by early 1982 regained almost all of the territory lost to the invasion. The invasion rallied Iranians behind the new regime, enhancing Khomeini's stature and allowing him to consolidate and stabilize his leadership. After this reversal, Khomeini refused an Iraqi offer of a truce, instead demanding reparations and the toppling of Saddam Hussein from power. In 1982, there was an attempted military coup against Khomeini. The IranâIraq War ended in 1988, with 320,000â720,000 Iranian soldiers and militia killed.

Although Iran's population and economy were three times the size of Iraq's, the latter was aided by neighboring Persian Gulf Arab states, as well as the Soviet Bloc and Western countries. The Persian Gulf Arabs and the West wanted to be sure the Islamic revolution did not spread across the Persian Gulf, while the Soviet Union was concerned about the potential threat posed to its rule in central Asia to the north. However, Iran had large amounts of ammunition provided by the United States of America during the Shah's era and the United States illegally smuggled arms to Iran during the 1980s despite Khomeini's anti-Western policy (see IranâContra affair).

During war Iranians used human wave attacks (people walking to certain death including child soldiers) on Iraq, with his promise that they would automatically go to paradiseâal Jannaâ if they died in battle, and his pursuit of victory in the IranâIraq War that ultimately proved futile. By March 1984, Iran's population had dropped by well over two million. This included an estimated one and a half million that had fled Iran, victims of political executions, and the hundreds of thousands of "martyrs" from Khomeini's bloody "human wave " attacks on Iraq.

In July 1988, Khomeini, in his words, "drank the cup of poison" and accepted a truce mediated by the United Nations. Despite the high cost of the war â 450,000 to 950,000 Iranian casualties and US$300Â billion â Khomeini insisted that extending the war into Iraq in an attempt to overthrow Saddam had not been a mistake. In a "Letter to Clergy" he wrote: "... we do not repent, nor are we sorry for even a single moment for our performance during the war. Have we forgotten that we fought to fulfill our religious duty and that the result is a marginal issue?"

In an interview with Gareth Porter, Mohsen Rafighdoost, the eight-year war time minister of the Islamic Revolutionary Guard Corps, disclosed how Khomeini had opposed his proposal for beginning work on both nuclear and chemical weapons by a fatwa which had never been made public in details of when and how it was issued.

In early 1989, Khomeini issued a fatwÄ calling for the assassination of Salman Rushdie, an India-born British author. Rushdie's book, "The Satanic Verses", published in 1988, was alleged to commit blasphemy against Islam and Khomeini's juristic ruling (fatwÄ) prescribed Rushdie's assassination by any Muslim. The fatwÄ required not only Rushdie's execution, but also the execution of "all those involved in the publication" of the book.

Khomeini's fatwÄ was condemned across the Western world by governments on the grounds that it violated the universal human rights of free speech and freedom of religion. The fatwÄ has also been attacked for violating the rules of fiqh by not allowing the accused an opportunity to defend himself, and because "even the most rigorous and extreme of the classical jurist only require a Muslim to kill anyone who insults the Prophet in his hearing and in his presence."

Though Rushdie publicly regretted "the distress that publication has occasioned to sincere followers of Islam", the fatwa was not revoked.

Rushdie himself was not killed but Hitoshi Igarashi, the Japanese translator of the book "The Satanic Verses", was murdered and two other translators of the book survived murder attempts.

In a speech on 1 February 1979 delivered to a huge crowd after returning to Iran from exile, Khomeini made a variety of promises to Iranians for his coming Islamic regime: a popularly elected government that would represent the people of Iran and with which the clergy would not interfere. He promised that "no one should remain homeless in this country," and that Iranians would have free telephone, heating, electricity, bus services and free oil at their doorstep.

Under Khomeini's rule, Sharia (Islamic law) was introduced, with the Islamic dress code enforced for both men and women by Islamic Revolutionary Guards and other Islamic groups. Women were required to cover their hair, and men were not allowed to wear shorts. Alcoholic drinks, most Western movies, and the practice of men and women swimming or sunbathing together were banned. The Iranian educational curriculum was Islamized at all levels with the Islamic Cultural Revolution; the "Committee for Islamization of Universities" carried this out thoroughly. The broadcasting of any music other than martial or religious on Iranian radio and television was banned by Khomeini in July 1979. The ban lasted 10 years (approximately the rest of his life).

According to Janet Afari, "the newly established regime of Ayatollah Khomeini moved quickly to repress feminists, ethnic and religious minorities, liberals, and leftists - all in the name of Islam."

Khomeini took on extensive and proactive support of the female populace during the ouster of Shah and his subsequent homecoming, advocating for mainstreaming of women into all spheres of life and even hypothesizing about a woman head of state. However, once he returned, his stances on women's rights exhibited drastic changes. He opposed the grant of the voting franchise to women and criticized a law that allowed a Muslim women to divorce at will and remarry, which was allegedly contrary to Islamic scriptures, and hence equivalent to adultery.

A mere three weeks after assuming power, under the pretext of reversing the Shah's excessive affinity for westernization and backed by a vocal conservative section of Iranian society, he revoked the divorce law. Khomeini went on to lower the minimum age of marriage for girls to 13 and even permitted girls as young as seven years old to be married if a physician signed a certificate agreeing to their sexual maturity, in keeping with Sharia law which dictates no minimum age for marriage beyond puberty. Khomeini, in his subsequent writings, also approved of adults satisfying their sexual lusts with children provided such activities stopped short of any penetration. Laws were passed that encouraged polygamy, made it impossible for women to divorce men, and treated adultery as the highest form of criminal offense. Women were compelled to wear veils, as the images of Western women was carefully reconstructed as a symbol of impiety. Morality and modesty were perceived as fundamental womanly traits that needed state protection, and western concepts of individual gender rights were relegated to women's social rights as ordained in Islam. Fatima was widely presented as the ideal emulatable woman.

At the same times, amidst the religious orthodoxy, there was an active effort to rehabilitate women into employment. Female participation in healthcare, education and the workforce increased drastically during his regime.

Reception among women of his regime has been mixed. Whilst a section were dismayed at the increasing Islamisation and concurrent degradation of women's rights, others did notice more opportunities and mainstreaming of relatively religiously conservative women.

Shortly after his accession as supreme leader in February 1979, Khomeini imposed capital punishment on homosexuals. Between February and March, sixteen Iranians were executed due to offenses related to sexual violations. Khomeini also created the "Revolutionary Tribunals". According to historian Ervand Abrahamian, Khomeini encouraged the clerical courts to continue implementing their version of the Shariâa. As part of the campaign to "cleanse" the society, these courts executed over 100 drug addicts, prostitutes, homosexuals, rapists, and adulterers on the charge of "sowing corruption on earth." According to author Arno Schmitt, "Khomeini asserted that 'homosexuals' had to be exterminated because they were parasites and corruptors of the nation by spreading the 'stain of wickedness.'" Transsexuality was designated by Khomeini as a sickness that was able to be cured through surgery. In 1979, he had declared that the execution of homosexuals (as well as prostitutes and adulterers) was reasonable in a moral civilization in the same sense as cutting off decayed skin.

Khomeini is said to have stressed "the spiritual over the material". Six months after his first speech he expressed exasperation with complaints about the sharp drop in Iran's standard of living, saying that: "I cannot believe that the purpose of all these sacrifices was to have less expensive melons." On another occasion emphasizing the importance of martyrdom over material prosperity, he said: "Could anyone wish his child to be martyred to obtain a good house? This is not the issue. The issue is another world." He also reportedly answered a question about his economic policies by declaring that 'economics is for donkeys'. This disinterest in economic policy is said to be "one factor explaining the inchoate performance of the Iranian economy since the revolution." Other factors include the long war with Iraq, the cost of which led to government debt and inflation, eroding personal incomes, and unprecedented unemployment, ideological disagreement over the economy, and "international pressure and isolation" such as US sanctions following the hostage crisis.

Due to the IranâIraq War, poverty is said to have risen by nearly 45% during the first 6 years of Khomeini's rule. Emigration from Iran also developed, reportedly for the first time in the country's history. Since the revolution and war with Iraq, an estimated "two to four million entrepreneurs, professionals, technicians, and skilled craftspeople (and their capital)" have emigrated to other countries.

In a talk at the Fayzieah School in Qom on 30 August 1979, Khomeini warned pro-imperialist opponents: "Those who are trying to bring corruption and destruction to our country in the name of democracy will be oppressed. They are worse than Bani-Ghorizeh Jews, and they must be hanged. We will oppress them by God's order and God's call to prayer."

However, in 1983, the Central Intelligence Agency (CIA) helped him by providing a list of Soviet KGB agents and collaborators operating in Iran to Khomeini, who then executed up to 200 suspects and closed down the Communist Tudeh Party of Iran.

The Shah Mohammad Reza Pahlavi and his family left Iran and escaped harm, but hundreds of former members of the overthrown monarchy and military met their ends in firing squads, with exiled critics complaining of "secrecy, vagueness of the charges, the absence of defense lawyers or juries", or the opportunity of the accused "to defend themselves." In later years these were followed in larger numbers by the erstwhile revolutionary allies of Khomeini's movementâMarxists and socialists, mostly university studentsâwho opposed the theocratic regime. Following the 1981 Hafte Tir bombing, Khomeini declared the Mojahedin and anyone violently opposed to the government, "enemies of God" and pursued a mass campaign against members of the Mojahedin, Fadaiyan, and Tudeh parties as well as their families, close friends, and even anyone who was accused of counterrevolutionary behavior.

In the 1988 executions of Iranian political prisoners, following the People's Mujahedin of Iran unsuccessful operation Forough-e Javidan against the Islamic Republic, Khomeini issued an order to judicial officials to judge every Iranian political prisoner (mostly but not all Mujahedin) and kill those judged to be apostates from Islam ("mortad") or "waging war on God" ("moharebeh"). Almost all of those interrogated were killed, around 30,000 of them. Because of the large number, prisoners were loaded into forklift trucks in groups of six and hanged from cranes in half-hour intervals.

Zoroastrians, Jews, and Christians are officially recognized and protected by the government. Shortly after Khomeini's return from exile in 1979, he issued a fatwa ordering that Jews and other minorities (except BahÃ¡'Ã­s) be treated well. In power, Khomeini distinguished between Zionism as a secular political party that employs Jewish symbols and ideals and Judaism as the religion of Moses.

Senior government posts were reserved for Muslims. Schools set up by Jews, Christians and Zoroastrians had to be run by Muslim principals. Conversion to Islam was encouraged by entitling converts to inherit the entire share of their parents (or even uncle's) estate if their siblings (or cousins) remain non-Muslim. Iran's non-Muslim population has decreased. For example, the Jewish population in Iran dropped from 80,000 to 30,000. The Zoroastrian population has also decreased, due to suffering from renewed persecution and the revived legal contrasts between a Muslim and Zoroastrian, which mirrors the laws that Zoroastrians experienced under earlier Islamic regimes. The view that Zoroastrians are "najis" ("unclean") has also been renewed.

Four of the 270 seats in parliament were reserved for each three non-Muslim minority religions, under the Islamic constitution that Khomeini oversaw. Khomeini also called for unity between Sunni and Shi'a Muslims. Sunni Muslims make up 9% of the entire Muslim population.

One non-Muslim group treated differently were the 300,000 members of the BahÃ¡'Ã­ Faith. Starting in late 1979 the new government systematically targeted the leadership of the BahÃ¡'Ã­ community by focusing on the BahÃ¡'Ã­ National Spiritual Assembly (NSA) and Local Spiritual Assemblies (LSAs); prominent members of NSAs and LSAs were often detained and even executed. "Some 200 of whom have been executed and the rest forced to convert or subjected to the most horrendous disabilities."

Like most conservative Muslims, Khomeini believed BahÃ¡'Ã­ to be apostates. He claimed they were a political rather than a religious movement,
declaring:

After the Shah left Iran in 1979, a Kurdish delegation traveled to Qom to present the Kurds' demands to Khomeini. Their demands included language rights and the provision for a degree of political autonomy. Khomeini responded that such demands were unacceptable since it involved the division of the Iranian nation. The following months saw numerous clashes between Kurdish militia groups and the Revolutionary Guards. The referendum on the Islamic Republic was massively boycotted in Kurdistan, where it was thought 85 to 90% of voters abstained. Khomeini ordered additional attacks later on in the year, and by September most of Iranian Kurdistan was under direct martial law.

Khomeini's health declined several years prior to his death. After spending eleven days in Jamaran hospital, Ruhollah Khomeini died on 3 June 1989 after suffering five heart attacks in just ten days, at the age of 86 just before midnight. He was succeeded as Supreme Leader by Ali Khamenei. Iranians poured out into the cities and streets in enormous numbers to mourn Khomeini's death in a spontaneous outpouring of grief. In the scorching summer heat, fire trucks sprayed water on the crowds to cool them. At least 10 mourners were trampled to death, more than 400 were badly hurt and several thousand more were treated for injuries sustained in the ensuing pandemonium.

According to Iran's official estimates, 10.2 million people lined the route to Tehran's Behesht-e Zahra cemetery on 11 June 1989, for the funeral of Ayatollah Ruhollah Khomeini. Western agencies estimated that 2Â million paid their respects as the body lay in state.

Figures about Khomeini's initial funeral attendance which took place on 4 June range around 2.5â3.5Â million people. Early the following day, Khomeini's corpse was flown in by helicopter for burial at the Paradise of Zahra cemetery. Iranian officials postponed Khomeini's first funeral after a huge mob stormed the funeral procession, destroying Khomeini's wooden coffin in order to get a last glimpse of his body or touch of his coffin. In some cases, armed soldiers were compelled to fire warning shots in the air to restrain the crowds. At one point, Khomeini's body fell to the ground, as the crowd ripped off pieces of the death shroud, trying to keep them as if they were holy relics. According to journalist James Buchan:

The second funeral was held under much tighter security five hours later. This time, Khomeini's casket was made of steel, and in accordance with Islamic tradition, the casket was only to carry the body to the burial site. In 1995, his son Ahmad was buried next to him. Khomeini's grave is now housed within a larger mausoleum complex.

Grand Ayatollah Hussein-Ali Montazeri, a former student of Khomeini and a major figure of the Revolution, was chosen by Khomeini to be his successor as Supreme Leader and approved as such by the Assembly of Experts in November 1985. The principle of "velayat-e faqih" and the Islamic constitution called for the Supreme Leader to be a "marja" (a grand ayatollah), and of the dozen or so grand ayatollahs living in 1981 only Montazeri qualified as a potential Leader (this was either because only he accepted totally Khomeini's concept of rule by Islamic jurists, or, as at least one other source stated, because only Montazeri had the "political credentials" Khomeini found suitable for his successor). The execution of Mehdi Hashemi in September 1987 on charges of counterrevolutionary activities was a blow to Ayatollah Montazeri, who knew Hashemi since their childhood. In 1989 Montazeri began to call for liberalization, freedom for political parties. Following the execution of thousands of political prisoners by the Islamic government, Montazeri told Khomeini: "Your prisons are far worse than those of the Shah and his SAVAK." After a letter of his complaints was leaked to Europe and broadcast on the BBC, a furious Khomeini ousted him in March 1989 from his position as official successor. His portraits were removed from offices and mosques.

To deal with the disqualification of the only suitable "marja", Khomeini called for an 'Assembly for Revising the Constitution' to be convened. An amendment was made to Iran's constitution removing the requirement that the Supreme Leader be a Marja and this allowed Ali Khamenei, the new favoured jurist who had suitable revolutionary credentials but lacked scholarly ones and who was not a Grand Ayatollah, to be designated as successor. Ayatollah Khamenei was elected Supreme Leader by the Assembly of Experts on 4 June 1989. Grand Ayatollah Hossein Montazeri continued his criticism of the regime and in 1997 was put under house arrest for questioning what he regarded to be an unaccountable rule exercised by the supreme leader.

The anniversary of Khomeini's death is a public holiday. To commemorate Khomeini, people visit his mausoleum placed on Behesht-e Zahra to hear sermons and practice prayers on his death day.

According to at least one scholar, politics in the Islamic Republic of Iran "are largely defined by attempts to claim Khomeini's legacy" and that "staying faithful to his ideology has been the litmus test for all political activity" there. Throughout his many writings and speeches, Khomeini's views on governance evolved. Originally declaring rule by monarchs or others permissible so long as sharia law was followed Khomeini later adamantly opposed monarchy, arguing that only rule by a leading Islamic jurist (a marja') would ensure Sharia was properly followed (wilayat al-faqih), before finally insisting the ruling jurist need not be a leading one and Sharia rule could be overruled by that jurist if necessary to serve the interests of Islam and the "divine government" of the Islamic state.
Khomeini's concept of (ÙÙØ§ÛØª ÙÙÛÙ, "velayat-e faqih") as Islamic government did not win the support of the leading Iranian Shi'i clergy of the time. Towards the 1979 Revolution, many clerics gradually became disillusioned with the rule of the Shah, although none came around to supporting Khomeini's vision of a theocratic Islamic Republic.

There is much debate to as whether Khomeini's ideas are or are not compatible with democracy and whether he intended the Islamic Republic to be a democratic republic. According to the state-run "Aftab News", both ultraconservative (Mohammad Taghi Mesbah Yazdi) and reformist opponents of the regime (Akbar Ganji and Abdolkarim Soroush) believe he did not, while regime officials and supporters like Ali Khamenei, Mohammad Khatami and Mortaza Motahhari believe Khomeini intended the Islamic republic to be democratic and that it is so. Khomeini himself also made statements at different times indicating both support and opposition to democracy.
One scholar, Shaul Bakhash, explains this disagreement as coming from Khomeini's belief that the huge turnout of Iranians in anti-Shah demonstrations during the revolution constituted a 'referendum' in favor of an Islamic republic. Khomeini also wrote that since Muslims must support a government based on Islamic law, Sharia-based government will always have more popular support in Muslim countries than any government based on elected representatives.

Khomeini offered himself as a "champion of Islamic revival" and unity, emphasizing issues Muslims agreed upon â the fight against Zionism and imperialism â and downplaying Shia issues that would divide Shia from Sunni.
Khomeini strongly opposed close relations with either Eastern or Western Bloc nations, believing the Islamic world should be its own bloc, or rather converge into a single unified power. He viewed Western culture as being inherently decadent and a corrupting influence upon the youth. The Islamic Republic banned or discouraged popular Western fashions, music, cinema, and literature. In the Western world it is said "his glowering visage became the virtual face of Islam in Western popular culture" and "inculcated fear and distrust towards Islam," making the word 'Ayatollah' "a synonym for a dangerous madman ... in popular parlance." This has particularly been the case in the United States where some Iranians complained that even at universities they felt the need to hide their Iranian identity for fear of physical attack. There Khomeini and the Islamic Republic are remembered for the American embassy hostage taking and accused of sponsoring hostage-taking and terrorist attacks, and which continues to apply economic sanctions against Iran.

Before taking power Khomeini expressed support for the Universal Declaration of Human Rights. "We would like to act according to the Universal Declaration of Human Rights. We would like to be free. We would like independence." However once in power Khomeini took a firm line against dissent, warning opponents of theocracy for example: "I repeat for the last time: abstain from holding meetings, from blathering, from publishing protests. Otherwise I will break your teeth."

Many of Khomeini's political and religious ideas were considered to be progressive and reformist by leftist intellectuals and activists prior to the Revolution. However, once in power his ideas often clashed with those of modernist or secular Iranian intellectuals. This conflict came to a head during the writing of the Islamic constitution when many newspapers were closed by the government. Khomeini angrily told the intellectuals:

Yes, we are reactionaries, and you are enlightened intellectuals: You intellectuals do not want us to go back 1400 years. You, who want freedom, freedom for everything, the freedom of parties, you who want all the freedoms, you intellectuals: freedom that will corrupt our youth, freedom that will pave the way for the oppressor, freedom that will drag our nation to the bottom. 
In contrast to his alienation from Iranian intellectuals, and "in an utter departure from all other Islamist movements," Khomeini embraced international revolution and Third World solidarity, giving it "precedence over Muslim fraternity." From the time Khomeini's supporters gained control of the media until his death, the Iranian media "devoted extensive coverage to non-Muslim revolutionary movements (from the Sandinistas to the African National Congress and the Irish Republican Army) and downplayed the role of the Islamic movements considered conservative, such as the Afghan mujahidin."

Khomeini's legacy to the economy of the Islamic Republic has been expressions of concern for the "mustazafin" (a Quranic term for the oppressed or deprived), but not always results that aided them. During the 1990s the "mustazafin" and disabled war veterans rioted on several occasions, protesting the demolition of their shantytowns and rising food prices, etc. Khomeini's disdain for the science of economics ("economics is for donkeys") is said to have been "mirrored" by the populist redistribution policies of former president, Mahmoud Ahmadinejad, who allegedly wears "his contempt for economic orthodoxy as a badge of honour", and has overseen sluggish growth and rising inflation and unemployment.

In 1963, Ayatollah Ruhollah Khomeini wrote a book in which he stated that there is no religious restriction on corrective surgery for transgender individuals. At the time Khomeini was an anti-Shah revolutionary and his fatwas did not carry any weight with the Imperial government, which did not have any specific policies regarding transsexual individuals.
However, after 1979, his fatwa "formed the basis for a national policy" and perhaps in part because of a penal code that "allows for the execution of homosexuals", as of 2005 Iran "permits and partly finances seven times as many gender reassignment operation as the entire European Union".

Khomeini was described as "slim", but athletic and "heavily boned".

He was known for his punctuality:

Khomeini was also known for his aloofness and austere demeanor. He is said to have had "variously inspired admiration, awe, and fear from those around him." His practice of moving "through the halls of the madresehs never smiling at anybody or anything; his practice of ignoring his audience while he taught, contributed to his charisma."

Khomeini adhered to traditional beliefs of Islamic hygienical jurisprudence holding that things like urine, excrement, blood, wine etc. and also non-Muslims were some of eleven ritualistically "impure" things that physical contact with which while wet required ritual washing or Ghusl before prayer or salat. He is reported to have refused to eat or drink in a restaurant unless he knew for sure the waiter was a Muslim.

Khomeini was noted by many for his mystique. Before the revolution he benefited from the widespread circulation of a Hadith attributed to the Imam Musa al-Kazim who is said to have prophesied shortly before his death in 799 that:

Khomeini was the first and only Iranian cleric to be addressed as "Imam", a title hitherto reserved in Iran for the twelve infallible leaders of the early Shi'a. He was also associated with the "Mahdi" or 12th Imam of Shia belief in a number of ways. One of his titles was "Na'eb-e Imam" (Deputy to the Twelfth Imam). His enemies were often attacked as "taghut" and "Mofsed-e-filarz", religious terms used for enemies of the Twelfth Imam. Many of the officials of the overthrown Shah's government executed by Revolutionary Courts were convicted of "fighting against the Twelfth Imam". When a deputy in the majlis asked Khomeini directly if he was the 'promised Mahdi', Khomeini did not answer, "astutely" neither confirming nor denying the title.

As the revolution gained momentum, even some non-supporters exhibited awe, called him "magnificently clear-minded, single-minded and unswerving." His image was as "absolute, wise, and indispensable leader of the nation"

The Imam, it was generally believed, had shown by his uncanny sweep to power, that he knew how to act in ways which others could not begin to understand. His timing was extraordinary, and his insight into the motivation of others, those around him as well as his enemies, could not be explained as ordinary knowledge. This emergent belief in Khomeini as a divinely guided figure was carefully fostered by the clerics who supported him and spoke up for him in front of the people.

Even many secularists who firmly disapproved of his policies were said to feel the power of his "messianic" appeal. Comparing him to a father figure who retains the enduring loyalty even of children he disapproves of, journalist Afshin Molavi writes that defenses of Khomeini are "heard in the most unlikely settings":

Another journalist tells the story of listening to bitter criticism of the regime by an Iranian who tells her of his wish for his son to leave the country and who "repeatedly" makes the point "that life had been better" under the Shah. When his complaint is interrupted by news that "the Imam" â over 85 years old at the time â might be dying, the critic becomes "ashen faced" and speechless, pronouncing "this is terrible for my country."

An example of Khomeini's charisma is the effect a half-hour-long, 1982 speech on the Quran by him had on a Muslim Scholar from South Africa, Sheikh Ahmad Deedat:

In 1929, Khomeini married Khadijeh Saqafi, the 16-year-old daughter of a cleric in Tehran. Some sources claim that Khomeini married Sagafi when she was ten years old, while others claim she was fifteen years old. By all accounts their marriage was harmonious and happy. She died in 2009. They had seven children, though only five survived infancy. His daughters all married into either merchant or clerical families, and both his sons entered into religious life. Mostafa, the elder son, died in 1977 while in exile in Najaf, Iraq with his father and was rumored by supporters of his father to have been murdered by SAVAK. Ahmad Khomeini, who died in 1995 at the age of 50, was also rumoured to be a victim of foul play, but at the hands of the regime. Perhaps his "most prominent daughter", Zahra Mostafavi, is a professor at the University of Tehran, and still alive.

Khomeini's fifteen grandchildren include:

Khomeini was a prolific writer and speaker (200 of his books are online) who authored commentaries on the Qur'an, on Islamic jurisprudence, the roots of Islamic law, and Islamic traditions. He also released books about philosophy, gnosticism, poetry, literature, government and politics.

His books include:






</doc>
<doc id="26235" url="https://en.wikipedia.org/wiki?curid=26235" title="Rousseau (disambiguation)">
Rousseau (disambiguation)

Jean-Jacques Rousseau (1712â1778) was a Swiss author and philosopher.

Rousseau may also refer to:



</doc>
<doc id="26239" url="https://en.wikipedia.org/wiki?curid=26239" title="Rhineland-Palatinate">
Rhineland-Palatinate

Rhineland-Palatinate (, ) is a state of Germany.

Rhineland-Palatinate is located in western Germany covering an area of and a population of 4.05 million inhabitants, the seventh-most populous German state. Mainz is the state capital and largest city, while other major cities include Ludwigshafen am Rhein, Koblenz, Trier, Kaiserslautern, and Worms. Rhineland-Palatinate is surrounded by the states of North Rhine-Westphalia, Saarland, Baden-WÃ¼rttemberg, and Hesse. It also borders three foreign countries: France, Luxembourg, and Belgium.

Rhineland-Palatinate was established in 1946 after World War II from territory of the historically separate regions of the Free State of Prussia, People's State of Hesse, and Bavaria, by the French military administration in Allied-occupied Germany. Rhineland-Palatinate became part of the Federal Republic of Germany in 1949, and shared the country's only border with the Saar Protectorate until it was returned to German control in 1957. Rhineland-Palatinate has since developed its own identity built on its natural and cultural heritage, including the extensive Palatinate winegrowing region, its picturesque landscapes, and many castles and palaces.

The state of Rhineland-Palatinate was founded shortly after the Second World War on 30 August 1946. It was formed mainly from the southern part of the Prussian Rhine Province (the of Koblenz and Trier), from Rhenish Hesse, from the western part of Nassau and the Bavarian Rhenish Palatinate minus the county of Saarpfalz. The Joint German-Luxembourg Sovereign Region () is the only unincorporated area of the state of Rhineland-Palatinate. This condominium is formed by the rivers Moselle, Sauer, and Our, where they run along the border between Luxembourg and Rhineland-Palatinate or the Saarland.

The present state of Rhineland-Palatinate formed part of the French Zone of Occupation (1945-1949) after the Second World War. It comprised the former Bavarian Palatinate, the ("government districts") of Koblenz and Trier of the old Prussian Rhine Province, those parts of the Province of Rhenish Hesse () west of the River Rhine and belonging to the People's State of Hesse (), parts of the Prussian province of Hesse-Nassau (Montabaur), and the former Oldenburg region around Birkenfeld (Principality of Birkenfeld).

On 10 July 1945, the occupation authority on the soil of the present-day Rhineland-Palatinate transferred from the Americans to the French. To begin with, the French divided the region provisionally into two "upper presidiums" (), Rhineland-Hesse-Nassau (for the hitherto Prussian government districts and regions of Koblenz, Trier, and Montabaur) and Hesse-Palatinate (for the hitherto Bavarian Palatinate and old Hessian-Darmstadt province of Rhenish Hesse). The formation of the state was ordained on 30 August 1946, the last state in the Western Zone of Occupation to be established, by Regulation No. 57 of the French military government under General Marie-Pierre KÅnig. It was initially called Rhenish-Palatinate ( or ); the name Rhineland-Palatinate () was first confirmed in the constitution of 18 May 1947.

The provisional French government at that time wanted originally to leave the option open of annexing further areas west of the Rhine after the Saarland was turned into a protectorate. When the Americans and British, however, had led the way with the establishment of German federal states, the French came under increasing pressure and eventually followed their example by setting up the states of Baden, WÃ¼rttemberg-Hohenzollern, and Rhineland-Palatinate. However, the French military government forbade the Saarland joining Rhineland-Palatinate. Mainz was named as the state capital in the regulation; the "Mixed Commission" (), named as the highest organ of state charged with the administration of the new state and with the preparation of an advisory state assembly, started its work in Mainz. However, war damage and destruction meant that Mainz did not have enough administrative buildings, so the headquarters of the state government and parliament was provisionally established in Koblenz. On 22 November 1946, the constituent meeting of the Advisory State Assembly () took place there, and a draft constitution was drawn up. Previously, local elections had been held. Wilhelm Boden was (after a short term of office as the of Rhineland-Hesse-Nassau) nominated on 2 December as the minister president of the new state by the French military government.

Adolf SÃ¼sterhenn submitted a draft constitution to the Advisory State Assembly, which was passed after several rounds of negotiation on 25 April 1947 in a final vote with the absolute majority of the CDU voting for and the SPD and KPD voting against it. One of the reasons for this was that the draft constitution made provision for separate schools based on Christian denomination. On 18 May 1947, the Constitution for Rhineland-Palatinate was adopted by 53% of the electorate in a referendum. While the Catholic north and west of the new state adopted the constitution by a majority, it was rejected by the majority in Rhenish Hesse and the Palatinate. On the same date, the first elections took place for the state parliament, the Landtag of Rhineland-Palatinate. The inaugural assembly of parliament took place on 4 June 1947 in the large city hall at Koblenz. Wilhelm Boden was elected the first minister-president of Rhineland-Palatinate. Just one month later, Peter Altmeier succeeded him.

The constitutional bodies, the Government (), the Parliament () and the Constitutional Court (), established their provisional seat in Koblenz. In the following period, Koblenz and Mainz emphasized their suitability as the state capital in a public debate. From the beginning, Minister-President Altmeier pressed for Mainz as the capital because he knew that the south of the country, especially the Palatinate, would not accept Koblenz, which was far to the north and formerly Prussian. On 16 May 1950, the decided to relocate itself and the from Koblenz to Mainz. After the government and parliament moved to Mainz, many state authorities and courts remained in Koblenz, including the Constitutional Court and the State Archives. In addition, the German Federal Archives and Federal Office of Hydrology were established in Koblenz in 1952.

A sense of community developed only very gradually in the "land of the retort", which had been established largely without regard to the historical affiliations of its inhabitants. It was given little chance of survival, especially as it had very few large industrial centres. However, the establishment of numerous military bases, both Allied and Bundeswehr, helped to some extent to boost the economy. In 1956, under Article 29 of the Basic Law for the Federal Republic of Germany, petitions were made in the regions of Koblenz, Trier, Montabaur, Rhenish Hesse, and Palatinate for their incorporation into the respective states of North Rhine-Westphalia, Hesse, Bavaria, and Baden-WÃ¼rttemberg. All petitions for a referendum except those in the administrative district of Palatinate won the necessary majority; however, almost 20 years passed before the referenda finally took place. On 19 January 1975, none of the regions concerned returned a majority for being transferred to another state. This put an end to decades of discussion. Only the AKK conflict, a dispute over the districts of Mainz-AmÃ¶neburg, Mainz-Kastel, and Mainz-Kostheim, has continued to exercise politicians up to the present day.

Rhineland-Palatinate shares international borders with France (Grand Est), Luxembourg (Clervaux, Diekirch, Echternach, Grevenmacher, Remich, and Vianden), and Belgium (Wallonia). Within Germany, it neighbours are Baden-WÃ¼rttemberg, Hesse, Northrhine-Westphalia, and the Saarland. It is the ninth-largest state by area. Rhineland-Palatinate is part of the SaarLorLux euregion.

With 42% of its area covered by forests, it is the most forested state along with Hesse. The state's major rivers are the Rhine, including the UNESCO World Heritage Site Middle Rhine, and the Moselle. Several crater lakes of volcanic origin are in the Eifel, the biggest of which is the Laacher See.

The Rhenish Massif forms roughly the northern half of the state, including the regions Eifel, Moselle Valley, HunsrÃ¼ck, Westerwald, and parts of the Taunus. The Palatinate forms the biggest part of the southern half along with Rhenish Hesse. The Nahe Valley separates both parts.

Significant foreign resident populations

The following table shows the ten largest cities of Rhineland-Palatinate:



, 41.0% of the population of the state adhered to the Roman Catholic Church and 27.6% to the Evangelical Church in Germany; 31.4% of the population is irreligious or adheres to other religions. Muslims made up 2.5% of the total.

The league of ShUM-cities in the later Rhineland-Palatinate comprised the Jewish communities of Mainz, Speyer, and Worms, which became the center of Jewish life during medieval times. The "Takkanot Shum" (), or Enactments of ShU"M were a set of decrees formulated and agreed upon over a period of decades by their Jewish community leaders.
The official web site for the city of Mainz states: 


</doc>
<doc id="26240" url="https://en.wikipedia.org/wiki?curid=26240" title="House of Romanov">
House of Romanov

The House of Romanov (; also Romanoff; , "RomÃ¡novy", ) was the reigning royal house of Russia from 1613 to 1917.

The Romanovs achieved prominence as "boyars" of the Grand Duchy of Moscow and later the Tsardom of Russia under the reigning Rurik dynasty, which became extinct upon the death of Tsar Feodor I in 1598. The Time of Troubles was caused by the resulting succession crisis, where several pretenders and imposters (False Dmitris) fought for the crown during the PolishâMuscovite War. On 21 February 1613, Michael Romanov was elected Tsar of Russia by the Zemsky Sobor, establishing the Romanovs as Russia's second reigning dynasty. Michael's grandson Peter I established the Russian Empire in 1721, transforming the country into a great power through a series of wars and reforms. The direct male line of the Romanovs ended when Elizabeth of Russia died in 1762 leading the House of Holstein-Gottorp, a cadet branch of the German House of Oldenburg that reigned in Denmark, to ascend to the crown under Peter III. Officially known as the House of Romanov, descendants after Elizabeth are sometimes referred to as "Holstein-Gottorp-Romanov". The abdication of Tsar Nicholas II on 15 March 1917 as a result of the February Revolution ended 304 years of Romanov rule, establishing the Russian Republic under the Russian Provisional Government in the lead up to the Russian Civil War. In 1918, the Tsar and his family were executed by the Bolsheviks and the 47 survivors of the House of Romanov's 65 members went into exile abroad.

In 1924, Grand Duke Kirill Vladimirovich, the senior surviving male-line descendant of Alexander II of Russia by primogeniture, claimed the headship of the defunct Imperial House of Russia. Since 1991, the succession to the former Russian throne has been in dispute, largely due to disagreements over the validity of dynasts' marriages, especially between the lines of Grand Duchess Maria Vladimirovna of Russia and Prince Nicholas Romanovich Romanov, succeeded by Prince Andrew Romanov.

Legally, it remains unclear whether any "ukase" ever abolished the surname of Michael Romanov (or of his subsequent male-line descendants) after his accession to the Russian throne in 1613, although by tradition members of reigning dynasties seldom use surnames, being known instead by dynastic titles ("Tsarevich Ivan Alexeevich", "Grand Duke Nikolai Nikolaevich", etc.). From , the monarchs of the Russian Empire claimed the throne as relatives of Grand Duchess Anna Petrovna of Russia (1708â1728), who had married Charles Frederick, Duke of Holstein-Gottorp. Thus they were no longer Romanovs by patrilineage, belonging instead to the Holstein-Gottorp cadet branch of the German House of Oldenburg that reigned in Denmark. The 1944 edition of the "Almanach de Gotha" records the name of Russia's ruling dynasty from the time of PeterÂ III (reigned 1761â1762) as "Holstein-Gottorp-Romanov". However, the terms "Romanov" and "House of Romanov" often occurred in official references to the Russian imperial family. The coat-of-arms of the Romanov boyars was included in legislation on the imperial dynasty,
and in a 1913 jubilee, Russia officially celebrated the "300th Anniversary of the Romanovs' rule".

After the February Revolution of March 1917, a special decree of the Provisional Government of Russia granted all members of the imperial family the surname "Romanov". The only exceptions, the morganatic descendants of the Grand Duke Dmitri Pavlovich (1891â1942), took (in exile) the surname .

The Romanovs share their origin with two dozen other Russian noble families. Their earliest common ancestor is one Andrei Kobyla, attested around 1347 as a boyar in the service of Semyon I of Moscow. Later generations assigned to Kobyla an illustrious pedigree. An 18th-century genealogy claimed that he was the son of the Old Prussians prince Glanda Kambila, who came to Russia in the second half of the 13th century, fleeing the invading Germans. Indeed, one of the leaders of the Old Prussians rebellion of 1260â1274 against the Teutonic order was named Glande. This legendary version of the Romanov's origin is contested by a more plausible version of their descent from a boyar family from Novgorod.

His actual origin may have been less spectacular. Not only is "Kobyla" Russian for "mare", some of his relatives also had as nicknames the terms for horses and other domestic animals, thus suggesting descent from one of the royal equerries. One of Kobyla's sons, Feodor, a member of the boyar Duma of Dmitri Donskoi, was nicknamed Koshka ("cat"). His descendants took the surname Koshkin, then changed it to Zakharin, which family later split into two branches: Zakharin-Yakovlev and Zakharin-Yuriev. During the reign of Ivan the Terrible, the former family became known as Yakovlev (Alexander Herzen among them), whereas grandchildren of changed their name to "Romanov".

Feodor Nikitich Romanov was descended from the Rurik dynasty through the female line. His mother, Evdokiya Gorbataya-Shuyskaya, was a Rurikid princess from the Shuysky branch, daughter of Alexander Gorbatyi-Shuisky.

The family fortunes soared when Roman's daughter, Anastasia Zakharyina, married Ivan IV (the Terrible), the Rurikid Grand Prince of Moscow, on 3 (13) February 1547. Since her husband had assumed the title of tsar, which literally means "Caesar", on 16 January 1547, she was crowned the very first tsaritsa of Russia. Her mysterious death in 1560 changed Ivan's character for the worse. Suspecting the boyars of having poisoned his beloved, Tsar Ivan started a reign of terror against them. Among his children by Anastasia, the elder (Ivan) was murdered by the tsar in a quarrel; the younger Feodor, a pious but lethargic prince, inherited the throne upon his father's death in 1584.

Throughout Feodor's reign (1584â1598), the Tsar's brother-in-law, Boris Godunov, and his Romanov cousins contested the "de facto" rule of Russia. Upon the death of childless Feodor, the 700-year-old line of Rurikids came to an end. After a long struggle, the party of Boris Godunov prevailed over the Romanovs, and the "Zemsky sobor" elected Godunov as tsar in 1599. Godunov's revenge on the Romanovs was terrible: all the family and its relations were deported to remote corners of the Russian North and Urals, where most of them died of hunger or in chains. The family's leader, Feodor Nikitich Romanov, was exiled to the Antoniev Siysky Monastery and forced to take monastic vows with the name Filaret.

The Romanovs' fortunes again changed dramatically with the fall of the Godunov dynasty in June 1605. As a former leader of the anti-Godunov party and cousin of the last legitimate tsar, Filaret Romanov's recognition was sought by several impostors who attempted to claim the Rurikid legacy and throne during the Time of Troubles. False Dmitriy I made him a metropolitan, and False Dmitriy II raised him to the dignity of patriarch. Upon the expulsion of the Poles from Moscow in 1612, the "Zemsky Sobor" offered the Russian crown to several Rurikid and Gediminian princes, but all declined the honour.

On being offered the Russian crown, Filaret's 16-year-old son Mikhail Romanov, then living at the Ipatiev Monastery of Kostroma, burst into tears of fear and despair. He was finally persuaded to accept the throne by his mother Kseniya Ivanovna Shestova, who blessed him with the holy image of Our Lady of St. Theodore. Feeling how insecure his throne was, Mikhail attempted to emphasize his ties with the last Rurikid tsars and sought advice from the "Zemsky Sobor" on every important issue. This strategy proved successful. The early Romanovs were generally accepted by the population as in-laws of Ivan the Terrible and viewed as innocent martyrs of Godunov's wrath.

Mikhail was succeeded by his only son Alexei, who steered the country quietly through numerous troubles. Upon Alexei's death, there was a period of dynastic struggle between his children by his first wife Maria Ilyinichna Miloslavskaya (Feodor III, Sofia Alexeyevna, Ivan V) and his son by his second wife Nataliya Kyrillovna Naryshkina, the future Peter the Great. Peter ruled from 1682 until his death in 1725. In numerous successful wars he expanded the Tsardom into a huge empire that became a major European power. He led a cultural revolution that replaced some of the traditionalist and medieval social and political system with a modern, scientific, Europe-oriented, and rationalist system.

New dynastic struggles followed the death of Peter. His only son to survive into adulthood, Tsarevich Alexei, did not support Peter's modernization of Russia. He had previously been arrested and died in prison shortly thereafter. Near the end of his life, Peter managed to alter the succession tradition of male heirs, allowing him to choose his heir. Power then passed into the hands of his second wife, Empress Catherine, who ruled until her death in 1727. Peter II, the son of Tsarevich Alexei, took the throne but died in 1730, ending the Romanov male line. He was succeeded by Anna I, daughter of Peter the Great's half-brother and co-ruler, Ivan V. Before she died in 1740 the empress declared that her grandnephew, Ivan VI, should succeed her. This was an attempt to secure the line of her father, while excluding descendants of Peter the Great from inheriting the throne. Ivan VI was only a one-year-old infant at the time of his succession to the throne, and his parents, Grand Duchess Anna Leopoldovna and Duke Anthony Ulrich of Brunswick, the ruling regent, were detested for their German counselors and relations. As a consequence, shortly after Empress Anna's death, Elizabeth Petrovna, a legitimized daughter of Peter I, managed to gain the favor of the populace and dethroned Ivan VI in a "coup d'Ã©tat", supported by the Preobrazhensky Regiment and the ambassadors of France and Sweden. Ivan VI and his parents died in prison many years later.

The Holstein-Gottorps of Russia retained the Romanov surname, emphasizing their matrilineal descent from Peter the Great, through Anna Petrovna (Peter I's elder daughter by his second wife). In 1742, Empress Elizabeth of Russia brought Anna's son, her nephew Peter of Holstein-Gottorp, to St. Petersburg and proclaimed him her heir. In time, she married him off to a German princess, Sophia of Anhalt-Zerbst. In 1762, shortly after the death of Empress Elizabeth, Sophia, who had taken the Russian name Catherine upon her marriage, overthrew her unpopular husband, with the aid of her lover, Grigory Orlov. She reigned as Catherine the Great. Catherine's son, Paul I, who succeeded his mother in 1796, was particularly proud to be a great-grandson of Peter the Great, although his mother's memoirs arguably insinuate that Paul's natural father was, in fact, her lover Serge Saltykov, rather than her husband, Peter. Painfully aware of the hazards resulting from battles of succession, Paul decreed house laws for the Romanovs â the so-called Pauline laws, among the strictest in Europe â which established semi-Salic primogeniture as the rule of succession to the throne, requiring Orthodox faith for the monarch and dynasts, and for the consorts of the monarchs and their near heirs. Later, Alexander I, responding to the 1820 morganatic marriage of his brother and heir, added the requirement that consorts of all Russian dynasts in the male line had to be of equal birth (i.e., born to a royal or sovereign dynasty).

Paul I was murdered in his palace in Saint Petersburg in 1801. Alexander I succeeded him on the throne and later died without leaving a son. His brother, crowned Nicholas I, succeeded him on the throne. The succession was far from smooth, however, as hundreds of troops took the oath of allegiance to Nicholas's elder brother, Constantine Pavlovich who, unbeknownst to them, had renounced his claim to the throne in 1822, following his marriage. The confusion, combined with opposition to Nicholas' accession, led to the Decembrist revolt. Nicholas I fathered four sons, educating them for the prospect of ruling Russia and for military careers, from whom the last branches of the dynasty descended.

Alexander II, son of Nicholas I, became the next Russian emperor in 1855, in the midst of the Crimean War. While Alexander considered it his charge to maintain peace in Europe and Russia, he believed only a strong Russian military could keep the peace. By developing the army, giving some freedom to Finland, and freeing the serfs in 1861 he gained much popular support.

Despite his popularity, however, his family life began to unravel by the mid 1860s. In 1864, his eldest son, and heir, Tsarevich Nicholas, died suddenly. His wife, Empress Maria Alexandrovna, who suffered from tuberculosis, spent much of her time abroad. Alexander eventually turned to a mistress, Princess Catherine Dolgoruki. Immediately following the death of his wife in 1880 he contracted a morganatic marriage with Dolgoruki. His legitimization of their children, and rumors that he was contemplating crowning his new wife as empress, caused tension within the dynasty. In particular, the grand duchesses were scandalized at the prospect of deferring to a woman who had borne Alexander several children during his wife's lifetime. Before Princess Catherine could be elevated in rank, however, on 13 March 1881 Alexander was assassinated by a hand-made bomb hurled by Ignacy Hryniewiecki. Slavic patriotism, cultural revival, and Panslavist ideas grew in importance in the latter half of this century, evoking expectations of a more Russian than cosmopolitan dynasty. Several marriages were contracted with members of other reigning Slavic or Orthodox dynasties (Greece, Montenegro, Serbia). In the early 20th century two Romanov princesses were allowed to marry Russian high noblemen â whereas until the 1850s, practically all marriages had been with German princelings.

Alexander II was succeeded by his son Alexander III. This tsar, the second-to-last Romanov emperor, was responsible for conservative reforms in Russia. Not expected to inherit the throne, he was educated in matters of state only after the death of his older brother, Nicholas. Lack of diplomatic training may have influenced his politics as well as those of his son, Nicholas II. Alexander III was physically impressive, being not only tall (1.93 m or 6'4", according to some sources), but of large physique and considerable strength. His beard hearkened back to the likeness of tsars of old, contributing to an aura of brusque authority, awe-inspiring to some, alienating to others. Alexander, fearful of the fate which had befallen his father, strengthened autocratic rule in Russia. Some of the reforms the more liberal Alexander II had pushed through were reversed.

Alexander had not only inherited his dead brother's position as "Tsesarevich", but also his brother's Danish fiancÃ©e, Princess Dagmar. Taking the name Maria Fyodorovna upon her conversion to Orthodoxy, she was the daughter of King Christian IX and the sister of the future kings Frederik VIII of Denmark and George I of Greece, as well as of Britain's Queen Alexandra, consort of Edward VII. Despite contrasting natures and backgrounds the marriage was considered harmonious, producing six children and acquiring for Alexander the reputation of being the first tsar not known to take mistresses.

His eldest son, Nicholas, became emperor upon Alexander III's death due to kidney disease at age 49 in November 1894. Nicholas reputedly said, "I am not ready to be tsar..." Just a week after the funeral, Nicholas married his fiancÃ©e, Alix of Hesse-Darmstadt, a favorite grandchild of Queen Victoria of the United Kingdom. Though a kind-hearted man, he tended to leave intact his father's harsh policies. For her part the shy Alix, who took the name Alexandra Fyodorovna, became a devout convert to Orthodoxy as well as a devoted wife to Nicholas and mother to their five children, yet avoided many of the social duties traditional for Russia's tsarinas. Seen as distant and severe, unfavorable comparisons were drawn between her and her popular mother-in-law, Maria Fyodorovna. When, in September 1915, Nicholas took command of the army at the front lines during World War I, Alexandra sought to influence him toward an authoritarian approach in government affairs even more than she had done during peacetime. His well-known devotion to her injured both his and the dynasty's reputation during World War I, due both to her German origin and her unique relationship with Rasputin, whose role in the life of her only son was not widely known. Alexandra was a carrier of the gene for haemophilia, inherited from her maternal grandmother, Queen Victoria. Her son, Alexei, the long-awaited heir to the throne, inherited the disease and suffered agonizing bouts of protracted bleeding, the pain of which was sometimes partially alleviated by Rasputin's ministrations. Nicholas and Alexandra also had four daughters, the Grand Duchesses Olga, Tatiana, Maria and Anastasia.

The six crowned representatives of the Holstein-Gottorp-Romanov line were: Paul (1796â1801), Alexander I (1801â1825), Nicholas I (1825â1855), Alexander II (1855â1881), Alexander III (1881â1894), and Nicholas II (1894â1917).

Constantine Pavlovich and Michael Alexandrovich, both morganatically married, are occasionally counted among Russia's emperors by historians who observe that the Russian monarchy did not legally permit interregnums. But neither was crowned and both actively declined the throne.

The February Revolution of 1917 resulted in the abdication of Nicholas II in favor of his brother Grand Duke Michael Alexandrovich. The latter declined to accept imperial authority save to delegate it to the Provisional Government pending a future democratic referendum, effectively terminating the Romanov dynasty's rule over Russia.

After the February Revolution, Nicholas II and his family were placed under house arrest in the Alexander Palace. While several members of the imperial family managed to stay on good terms with the Provisional Government, and were eventually able to leave Russia, Nicholas II and his family were sent into exile in the Siberian town of Tobolsk by Alexander Kerensky in August 1917. In the October Revolution of 1917 the Bolsheviks ousted the Provisional government. In April 1918 the Romanovs were moved to the Russian town of Yekaterinburg, in the Urals, where they were placed in the Ipatiev House.

There have been numerous post-Revolution reports of Romanov survivors and unsubstantiated claims by individuals to be members of the deposed Tsar Nicholas II's family, the best known of whom was Anna Anderson. Proven research has, however, confirmed that all of the Romanovs held prisoners inside the Ipatiev House in Ekaterinburg were killed. Descendants of Nicholas II's two sisters, Grand Duchess Xenia Alexandrovna of Russia and Grand Duchess Olga Alexandrovna of Russia, do survive, as do descendants of previous tsars.

Grand Duke Kirill Vladimirovich, a male-line grandson of Tsar Alexander II, claimed the headship of the deposed Imperial House of Russia, and assumed, as pretender, the title "Emperor and Autocrat of all the Russias" in 1924 when the evidence appeared conclusive that all Romanovs higher in the line of succession had been killed. Kirill was followed by his only son Vladimir Kirillovich. Vladimir's only child, Maria Vladimirovna (born 1953), claims to have succeeded her father. The only son of her marriage with Prince Franz Wilhelm of Prussia, George Mikhailovich, is her heir apparent. The Romanov Family Association (RFA) formed in 1979, a private organization of most of the male-line descendants of Emperor Paul I of Russia (other than Vladimir Kirillovich, Maria Vladimirovna and her son) acknowledges the dynastic claims to the throne of no pretender, and is officially committed to support only that form of government chosen by the Russian nation. However the RFA's former president, Nicholas Romanovich, along with his brother Dimitri and some other family members, have repudiated the transfer of the dynasty's legacy to the female-line, contending that his claim is as valid as that of Maria Vladimirovna or her son. A great-grandson of Kirill's who is not a male-line Romanov, Prince Karl Emich of Leiningen, also claims to be the rightful representative of the Romanov Imperial heritage and has become the founder of Romanov Empire.

On the night of 17 July 1918, Bolshevik authorities acting on Yakov Sverdlov's orders in Moscow and led locally by Filip Goloschekin and Yakov Yurovsky, shot Nicholas II, his immediate family and four servants in the Ipatiev House's cellar.

The family was roused from sleep around 1:30Â a.m. and told that they were being moved to a newer, safer location. They dressed quickly but informally. They were then led from the house where they had been staying and taken across a courtyard and down some stairs, then through a number of corridors and small dark rooms, few of which were lit. They reached a room at the end of one particular corridor that had a single electric light burning dimly. They asked for and were brought two chairs for the youngest children to sit on. The family members were then left alone for several minutes. Suddenly, a group of armed men led by Yurovsky entered the room. Yurovsky read an announcement from the local Duma explaining that they must all be killed immediately. Nicholas was utterly perplexed, and asked Yurovsky, "What? What?" Yurovsky eventually responded by saying, "This!" and shot Nicholas in the chest.

Initially the gunmen shot at Nicholas, who immediately fell dead from multiple bullet wounds. Then the dark room filled with smoke and dust from the spray of bullets, and the gunmen shot blindly, often hitting the ceiling and walls, creating yet more dust. Alexandra was soon shot in the head by military commissar Petar Ermakov, and killed, and some of the gunmen themselves became injured. It was not until after the room had been cleared of smoke that the shooters re-entered to find the remaining Imperial family still alive and uninjured. Maria tried to escape through the doors at the rear of the room, which led to a storage area, but the doors were nailed shut. The noise as she rattled the doors attracted the attention of Ermakov. Some of the family were shot in the head, but several of the others, including the young and frail Tsarevich, would not die either from multiple close-range bullet wounds or bayonet stabs. Finally, each was shot in the head. Even so, two of the girls were still alive 10 minutes later, and had to be bludgeoned with the butt of a rifle to finally be killed. Later it was discovered that the bullets and bayonet stabs had been partially blocked by diamonds that had been sewn into the children's clothing. The bodies of the Romanovs were then hidden and moved several times before being interred in an unmarked pit where they remained until the summer of 1979 when amateur enthusiasts disinterred and re-buried some of them, and then decided to conceal the find until the fall of communism. In 1991 the grave site was excavated and the bodies were given a state funeral under the nascent democracy of post-Soviet Russia, and several years later DNA and other forensic evidence was used by Russian and international scientists to make genuine identifications.

The Ipatiev House has the same name as the Ipatiev Monastery in Kostroma, where Mikhail Romanov had been offered the Russian Crown in 1613. The large memorial church "on the blood" has been built on the spot where the Ipatiev House once stood.

Nicholas II and his family were proclaimed passion-bearers by the Russian Orthodox Church in 2000. In orthodoxy, a passion-bearer is a saint who was not killed "because" of his faith, like a martyr; but who died "in" faith at the hand of murderers.

In July 1991, the crushed bodies of Nicholas II and his wife, along with three of their five children and four of their servants, were exhumed (although some questioned the authenticity of these bones despite DNA testing). Because two bodies were not present, many people believed that two Romanov children escaped the killings. There was much debate as to which two children's bodies were missing. A Russian scientist made photographic superimpositions and determined that Maria and Alexei were not accounted for. Later, an American scientist concluded from dental, vertebral, and other remnants that it was Anastasia and Alexei who were missing. Much mystery has always surrounded Anastasia's fate. Several films have been produced suggesting that she lived on. This has since been disproved with the discovery of the final Romanov children's remains and extensive DNA testing, which connected those remains to the DNA of Nicholas II, his wife, and the other three children.

After the bodies were exhumed in June 1991, they remained in laboratories until 1998, while there was a debate as to whether they should be reburied in Yekaterinburg or St. Petersburg. A commission eventually chose St. Petersburg. The remains were transferred with full military honor guard and accompanied by members of the Romanov family from Yekaterinburg to St. Petersburg. In St. Petersburg the remains of the imperial family were moved by a formal military honor guard cortege from the airport to the Sts. Peter and Paul Fortress where they (along with several loyal servants who were killed with them) were interred in a special chapel in the Peter and Paul Cathedral near the tombs of their ancestors. President Boris Yeltsin attended the interment service on behalf of the Russian people.

In mid-2007, a Russian archaeologist announced a discovery by one of his workers. The excavation uncovered the following items in the two pits which formed a "T":
The area where the remains were found was near the old Koptyaki Road, under what appeared to be double bonfire sites about from the mass grave in Pigs Meadow near Yekaterinburg. The general directions were described in Yurovsky's memoirs, owned by his son, although no one is sure who wrote the notes on the page. The archaeologists said the bones are from a boy who was roughly between the ages of 10 and 13 years at the time of his death and of a young woman who was roughly between the ages of 18 and 23 years old. Anastasia was 17 years, 1 month old at the time of the murder, while Maria was 19 years, 1 month old. Alexei would have been 14 in two weeks' time. Alexei's elder sisters Olga and Tatiana were 22 and 21 years old at the time of the murder respectively. The bones were found using metal detectors and metal rods as probes. Also, striped material was found that appeared to have been from a blue-and-white striped cloth; Alexei commonly wore a blue-and-white striped undershirt.

On 30 April 2008, Russian forensic scientists announced that DNA testing proves that the remains belong to the Tsarevich Alexei and his sister Maria. DNA information, made public in July 2008, that has been obtained from Ekaterinburg and repeatedly subject to independent testing by laboratories such as the University of Massachusetts Medical School, US, and reveals that the final two missing Romanov remains are indeed authentic and that the entire Romanov family housed in the Ipatiev House, Yekaterinburg were executed in the early hours of 17 July 1918. In March 2009, results of the DNA testing were published, confirming that the two bodies discovered in 2007 were those of Tsarevich Alexei and Maria.

Research on mitochondrial DNA (mtDNA) was conducted in the American AFDIL and in European GMI laboratories. In comparison with the previous analyses mtDNA in the area of Alexandra Fyodorovna, positions 16519C, 524.1A and 524.2C were added. The mtDNA of Prince Philip, Duke of Edinburgh, a great-nephew of the last Tsarina, was used by forensic scientists to identify her body and those of her children.

On 18 July 1918, the day after the killing at Yekaterinburg of the tsar and his family, members of the extended Russian imperial family met a brutal death by being killed near Alapayevsk by Bolsheviks. They included: Grand Duke Sergei Mikhailovich of Russia, Prince Ioann Konstantinovich of Russia, Prince Konstantin Konstantinovich of Russia, Prince Igor Konstantinovich of Russia and Prince Vladimir Pavlovich Paley, Grand Duke Sergei's secretary Varvara Yakovleva, and Grand Duchess Elisabeth Fyodorovna, a granddaughter of Queen Victoria and elder sister of Tsarina Alexandra. Following the 1905 assassination of her husband, Grand Duke Sergei Alexandrovich, Elisabeth Fyodorovna had ceased living as a member of the Imperial family and took up life as a serving nun, but would nonetheless be arrested and slated for death with other Romanovs. They were thrown down a mine shaft into which explosives were then dropped, all being left to die there slowly.
The bodies were recovered from the mine by the White Army in 1918, who arrived too late to rescue them. Their remains were placed in coffins and moved around Russia during struggles between the White and the opposing Red Army. By 1920 the coffins were interred in a former Russian mission in Beijing, now beneath a parking area. In 1981 Grand Duchess Elisabeth was canonized by the Russian Orthodox Church Outside of Russia, and in 1992 by the Moscow Patriarchate. In 2006 representatives of the Romanov family were making plans to re-inter the remains elsewhere. The town became a place of pilgrimage to the memory of Elisabeth Fyodorovna, whose remains were eventually re-interred in Jerusalem.

On 13 June 1918, Bolshevik revolutionary authorities killed Grand Duke Michael Alexandrovich of Russia and Nicholas Johnson (Michael's secretary) in Perm.

In January 1919 revolutionary authorities killed Grand Dukes Dmitry Konstantinovich, Nikolai Mikhailovich, Paul Alexandrovich and George Mikhailovich, who had been held in the prison of the Saint Peter and Paul Fortress in Petrograd.

In 1919, Maria Fyodorovna, widow of Alexander III, and mother of Nicholas II, managed to escape Russia aboard , which her nephew, King George V of the United Kingdom, had sent, at the urging of his own mother, Queen Alexandra, Maria's elder sister, to rescue her. After a stay in England with Queen Alexandra, she returned to her native Denmark, first living at Amalienborg Palace, with her nephew, King Christian X, and later, at Villa HvidÃ¸re. Upon her death in 1928 her coffin was placed in the crypt of Roskilde Cathedral, the burial site of members of the Danish Royal Family.

In 2006, the coffin with her remains was moved to the Sts. Peter and Paul Fortress, to be buried beside that of her husband. The transfer of her remains was accompanied by an elaborate ceremony at Saint Isaac's Cathedral officiated by the Patriarch Alexis II. Descendants and relatives of the Dowager Empress attended, including her great-grandson Prince Michael Andreevich, Princess Catherine Ioannovna of Russia, the last living member of the Imperial Family born before the fall of the dynasty, and Princes Dmitri and Prince Nicholas Romanov.

Among the other exiles who managed to leave Russia, were Maria Fyodorovna's two daughters, the Grand Duchesses Xenia Alexandrovna and Olga Alexandrovna, with their husbands, Grand Duke Alexander Mikhailovich and Nikolai Kulikovsky, respectively, and their children, as well as the spouses of Xenia's elder two children and her granddaughter. Xenia remained in England, following her mother's return to Denmark, although after their mother's death Olga moved to Canada with her husband, both sisters dying in 1960. Grand Duchess Maria Pavlovna, widow of Nicholas II's uncle, Grand Duke Vladimir, and her children the Grand Dukes Kiril, Boris and Andrei, and their sister Elena, also managed to flee Russia. Grand Duke Dmitri Pavlovich, a cousin of Nicholas II, had been exiled to the Caucasus in 1916 for his part in the murder of Grigori Rasputin, and managed to escape Russia. Grand Duke Nicholas Nikolaievich, who had commanded Russian troops during World War I prior to Nicholas II taking command, along with his brother, Grand Duke Peter, and their wives, Grand Duchesses Anastasia and Militza, who were sisters, and Peter's children, son-in-law, and granddaughter also fled the country.

Elizaveta Mavrikievna, widow of Konstantin Konstantinovich, escaped with her daughter Vera Konstantinovna and her son Georgii Konstantinovich, as well as her grandson Prince Vsevolod Ivanovich and her granddaughter Princess Catherine Ivanovna to Sweden. Her other daughter, Tatiana Konstantinovna, also escaped with her children Natasha and Teymuraz, as well as her uncle's aide-de-camp Alexander Korochenzov. They fled to Romania and then Switzerland. Gavriil Konstantinovich was imprisoned before fleeing to Paris.

Ioann Konstantinovich's wife, Elena Petrovna, was imprisoned in Alapayevsk and Perm, before escaping to Sweden and Nice, France.

Since 1991, the succession to the former Russian throne has been in dispute, largely due to disagreements over the validity of dynasts' marriages.

Grand Duchess Maria Vladimirovna of Russia claims to hold the title of empress in pretense with her only child, George Mikhailovich, as heir apparent.

Others have argued in support of the rights of the late Prince Nicholas Romanovich Romanov, whose brother Prince Dimitri Romanov was the next heir male of his branch after whom it is now passed to Prince Andrew Romanov.

In 2014, a micronation calling itself the Imperial Throne, founded in 2011 by Monarchist Party leader Anton Bakov, announced Prince Karl Emich of Leiningen, a Romanov descendant, as its sovereign. In 2017, it renamed itself as "Romanov Empire".

The collection of jewels and jewelry collected by the Romanov family during their reign are commonly referred to as the "Russian Crown Jewels" and they include official state regalia as well as personal pieces of jewelry worn by Romanov rulers and their family. After the Tsar was deposed and his family murdered, their jewels and jewelry became the property of the new Soviet government. A select number of pieces from the collection were sold at auction by Christie's in London in March 1927. The remaining collection is on view today in the Kremlin Armoury in Moscow.

On 28 August 2009, a Swedish public news outlet reported that a collection of over 60 jewel-covered cigarette cases and cufflinks owned by the Romanov family, had been found in the archives of the Swedish Ministry for Foreign Affairs, and was returned to members of the Romanov family. The jewelry was allegedly turned over to the Swedish embassy in St. Petersburg in November 1918 by Duchess Marie of Mecklenburg-Schwerin to keep it safe. The value of the jewelry has been estimated at 20 million Swedish krona (about 2.6 million US dollars).

The centerpiece is the coat of arms of Moscow that contains the iconic Saint George the Dragon-slayer with a blue cape (cloak) attacking golden serpent on red field.

The wings of double-headed eagle contain coat of arms of following lands:








</doc>
<doc id="26243" url="https://en.wikipedia.org/wiki?curid=26243" title="Robert Bloch">
Robert Bloch

Robert Albert Bloch (; April 5, 1917 â September 23, 1994) was an American fiction writer, primarily of crime, horror, fantasy and science fiction, from Milwaukee, Wisconsin. He is best known as the writer of "Psycho" (1959), the basis for the film of the same name by Alfred Hitchcock. His fondness for a pun is evident in the titles of his story collections such as "Tales in a Jugular Vein", "Such Stuff as Screams Are Made Of" and "Out of the Mouths of Graves".

Bloch wrote hundreds of short stories and over 30 novels. He was one of the youngest members of the Lovecraft Circle and began his professional writing career immediately after graduation, aged 17. He was a protÃ©gÃ© of H. P. Lovecraft, who was the first to seriously encourage his talent. However, while Bloch started his career by emulating Lovecraft and his brand of "cosmic horror", he later specialized in crime and horror stories dealing with a more psychological approach.

Bloch was a contributor to pulp magazines such as "Weird Tales" in his early career, and was also a prolific screenwriter and a major contributor to science fiction fanzines and fandom in general.

He won the Hugo Award (for his story "That Hell-Bound Train"), the Bram Stoker Award, and the World Fantasy Award. He served a term as president of the Mystery Writers of America (1970) and was a member of that organization and of Science Fiction Writers of America, the Writers Guild of America, the Academy of Motion Picture Arts and Sciences and the Count Dracula Society. In 2008, The Library of America selected Bloch's essay "The Shambles of Ed Gein" (1962) for inclusion in its two-century retrospective of American true crime.

His favorites among his own novels were "The Kidnapper", "The Star Stalker", "Psycho", "Night-World," and "Strange Eons". His work has been extensively adapted into films, television productions, comics, and audiobooks.

Bloch was born in Chicago, the son of Raphael "Ray" Bloch (1884â1952), a bank cashier, and his wife Stella Loeb (1880â1944), a social worker, both of German Jewish descent. Bloch's family moved to Maywood, a Chicago suburb, when he was five; he lived there until he was ten. He attended the Methodist Church there, despite his parents' Jewish heritage, and attended Emerson Grammar School. In 1925, at eight years of age, living in Maywood, he attended (alone at night) a screening of Lon Chaney, Sr.'s film "The Phantom of the Opera" (1925). The scene of Chaney removing his mask terrified the young Bloch ("it scared the living hell out of me and I ran all the way home to enjoy the first of about two years of recurrent nightmares"). It also sparked his interest in horror. Bloch was a precocious child and found himself in fourth grade when he was eight. He also obtained a pass into the adult section of the Public Library, where he read omnivorously. Bloch considered himself a budding artist and worked in pencil sketching and watercolours, but myopia in adolescence seemed to effectively bar art as a career. He had passions for German-made lead toy soldiers and for silent cinema.

In 1929, Bloch's father Ray Bloch lost his bank job, and the family moved to Milwaukee, where Stella worked at the Milwaukee Jewish Settlement settlement house. Robert attended Washington, then Lincoln High School, where he met lifelong friend Harold Gauer. Gauer was editor of "The Quill", Lincoln's literary magazine, and accepted Bloch's first published short story, a horror story titled "The Thing" (the "thing" of the title was Death). Both Bloch and Gauer graduated from Lincoln in 1934 during the height of the Great Depression. Bloch was involved in the drama department at Lincoln and wrote and performed in school vaudeville skits.

During the 1930s, Bloch was an avid reader of the pulp magazine "Weird Tales", which he had discovered at the age of ten in 1927. In the Chicago Northwestern Railroad depot with his parents and aunt Lil, his aunt offered to buy him any magazine he wanted and he picked "Weird Tales" (Aug 1927 issue) off the newsstand over her shocked protest. He began his readings of the magazine with the first instalment of Otis Adelbert Kline's "The Bride of Osiris" which dealt with a secret Egyptian city called Karneter located beneath Bloch's birth city of Chicago. The Depression came in the early 1930s. He later recalled, in accepting the Lifetime Achievement Award at the First World Fantasy Convention (1975), how "times were very hard. "Weird Tales" cost twenty-five cents in a day when most pulp magazines cost a dime. I remember that meant a lot to me." He went on to relate how he would get up very early on the last day of the month, with twenty-five cents saved from his monthly allowance of one dollar, and would run all the way to a combination tobacco/magazine store and buy the new "Weird Tales" issue, sometimes smuggling it home under his coat if the cover was particularly risquÃ©. His parents were not impressed with Hugh Doak Rankin's sexy covers for the magazine, and when the Bloch family moved to Milwaukeee in 1928 young Bloch gradually abandoned his interest. But by the time he had entered high school, he returned to reading "Weird Tales" during convalescence from flu.

H. P. Lovecraft, a frequent contributor to "Weird Tales", became one of his favorite writers. The first of Lovecraft's stories he had read was "Pickman's Model," in "Weird Tales" for October 1927. Bloch wrote: "In school I was forced to squirm my way through the works of Oliver Wendell Holmes, James Lowell and Henry Wadsworth Longfellow. In 'Pickman's Model', the ghouls ate all three. Now that, I decided, was poetic justice." As a teenager, Bloch wrote a fan letter to Lovecraft (1933), asking where he could find copies of earlier stories of Lovecraft's that Bloch had missed. Lovecraft lent them to him. Lovecraft also gave Bloch advice on his early fiction-writing efforts. asking whether Bloch had written any weird work and, if so, whether he might see samples of it. Bloch took up Lovecraft's offer in late April 1933, sending him two short items, "The Gallows" and another work whose title is unknown.

Lovecraft also suggested Bloch write to other members of the Lovecraft Circle, including August Derleth, Robert H. Barlow, Clark Ashton Smith, Donald Wandrei, Frank Belknap Long, Henry S. Whitehead, E. Hoffman Price, Bernard Austin Dwyer and J. Vernon Shea. Bloch's first completed tales were "Lilies," "The Laughter of a Young Ghoul" and "The Black Lotus". Bloch submitted these to "Weird Tales"; editor Farnsworth Wright summarily rejected them all. However Bloch successfully placed "Lilies" in the semi-professional magazine "Marvel Tales" (Winter 1934) and "Black Lotus" in "Unusual Stories" (1935). Bloch later commented, "I figured I'd better do something different or I'd end up as a florist."

Bloch graduated from high school in June, 1934. He then wrote a story which promptly (six weeks later) sold to "Weird Tales." Bloch's first publication in "Weird Tales" was a letter criticising the Conan stories of Robert E. Howard. His first professional sales, at the age of 17 (July 1934), to "Weird Tales," were the short stories "The Feast in the Abbey" and "The Secret in the Tomb". "Feast ..." appeared first, in the January 1935 issue, which actually went on sale November 1, 1934; "The Secret in the Tomb" appeared in the May 1935 "Weird Tales".

Bloch's correspondence with Derleth led to a visit to Derleth's home in Sauk City, Wisconsin (the headquarters of Arkham House). Bloch was impressed by Derleth who "fulfilled my expectations as a writer by wearing this purple velvet smoking jacket. That impressed me even more because Derleth didn't even smoke." Following this, and continued correspondence with Lovecraft, Bloch went to Chicago and met Farnsworth Wright, the then editor of "Weird Tales". He also met the first "Weird Tales" writer outside of Derleth he had encountered - Otto Binder.

Bloch's early stories were strongly influenced by Lovecraft. Indeed, a number of his stories were set in, and extended, the world of Lovecraft's Cthulhu Mythos. These include "The Dark Demon", in which the character Gordon is a figuration of Lovecraft, and which features Nyarlathotep; "The Faceless God" (features Nyarlathotep); "The Grinning Ghoul" (written after the manner of Lovecraft) and "The Unspeakable Betrothal" (vaguely attached to the Cthulhu Mythos). It was Bloch who invented, for example, the oft-cited Mythos texts "De Vermis Mysteriis" and "Cultes des Goules". Many other stories influenced by Lovecraft were later collected in Bloch's volume "Mysteries of the Worm" (now in its third, expanded edition). In 1935, Bloch wrote the tale "Satan's Servants", on which Lovecraft lent much advice, but none of the prose was by Lovecraft; this tale did not appear in print until 1949, in "Something About Cats and Other Pieces".

The young Bloch appears, thinly disguised, as the character Robert Blake in Lovecraft's story "The Haunter of the Dark" (1936), which is dedicated to Bloch. Bloch was the only individual to whom Lovecraft ever dedicated a story. In this story, Lovecraft kills off Robert Blake, the Bloch-based character, repaying a "courtesy" Bloch earlier paid Lovecraft with his 1935 tale "The Shambler from the Stars", in which the Lovecraft-inspired figure dies; the story goes so far as to use Bloch's then-current address (620 East Knapp Street) in Milwaukee. (Bloch even had a signed certificate from Lovecraft [and some of his creations] giving Bloch permission to kill Lovecraft off in a story.) Bloch later recalled "believe me, beyond all doubt, I don't know anyone else I'd rather be killed by." Bloch later wrote a third tale, "The Shadow From the Steeple", picking up where "The Haunter of the Dark" finished ("Weird Tales" Sept 1950).

Lovecraft's death in 1937 deeply affected Bloch, who was then aged only 20. He recalled "Part of me died with him, I guess, not only because he was not a god, he was mortal, that is true, but because he had so little recognition in his own lifetime. There were no novels or collections published, no great realization, even here in Providence, of what was lost." Elsewhere he wrote, "the news of his fate came to me as a shattering blow; all the more so because the world at large ignored his passing. Only my parents and a few correspondents seemed to sense my shock, and my feeling that a part of me had died with him."

After Lovecraft's death in 1937, Bloch continued writing for "Weird Tales", where he became one of its most popular authors. He also began contributing to other pulps, such as the science fiction magazine "Amazing Stories". Bloch broadened the scope of his fiction. His horror themes included voodoo ("Mother of Serpents"), the conte cruel ("The Mandarin's Canaries"), demonic possession ("Fiddler's Fee"), and black magic ("Return to the Sabbat"). Bloch visited Henry Kuttner in California in 1937. Bloch's first science fiction story, "The Secret of the Observatory", was published in "Amazing Stories" (August 1938).

In 1935 Bloch joined a writers' group, The Milwaukee Fictioneers, members of which included Stanley Weinbaum, Ralph Milne Farley and Raymond A. Palmer. Another member of the group was Gustav Marx, who offered Bloch a job writing copy in his advertising firm, also allowing Bloch to write stories in his spare time in the office. Bloch was close friends with C.L. Moore and her husband Henry Kuttner, who visited him in Milwaukee.

During the years of the Depression, Bloch appeared regularly in dramatic productions, writing and performing in his own sketches. Around 1936 he sold some gags to radio comedians Stoopnagle and Budd, and to Roy Atwell. Also in 1936, his tale "The Grinning Ghoul" was published in "Weird Tales" (June); "The Opener of the Way" appeared in "Weird Tales" (Oct); "Mother of Serpents" appeared in the December issue. The December issue also contained Lovecraft's tale "The Haunter of the Dark" in which he killed off young author "Robert Blake".

In 1937, following Lovecraft's death, "The Mannikin" appeared in "Weird Tales" for April. "Weird Tales" published "Return to the Sabbath" in July 1938. Bloch's first science fiction story, "The Secret of the Observatory" appeared in "Amazing Stories" (Aug 1938). In a profile accompanying this tale, Bloch described himself as "tall, dark, unhandsome" with "all the charm and personality of a swamp adder". He noted that "I hate everything", but reserved particular dislike for "bean soup, red nail polish, house-cleaning, and optimists".

In 1939, Bloch was contacted by James Doolittle, who was managing the campaign for Mayor of Milwaukee of a little-known assistant city attorney named Carl Zeidler. He was asked to work on Zeidler's speechwriting, advertising, and photo ops, in collaboration with Harold Gauer. They created elaborate campaign shows; in Bloch's 1993 autobiography, "Once Around the Bloch", he gives an inside account of the campaign, and the innovations he and Gauer came up with â for instance, the original releasing-balloons-from-the-ceiling shtick. He comments bitterly on how, after Zeidler's victory, they were ignored and not even paid their promised salaries. He ends the story with a wryly philosophical point:

Also in 1939, two of Bloch's tales were published: "The Strange Flight of Richard Clayton" ("Amazing Stories," August) and "The Cloak" ("Unknown," March).

In October 1941, the tale "A Good Knight's Work" in "Unknown Worlds" first appeared. Shortly thereafter, Bloch created the Damon Runyon-esque humorous series character Lefty Feep in the story "Time Wounds All Heels" "Fantastic Adventures" (April 1942). Around the same time, he began work as an advertising copywriter at the Gustav Marx Advertising Agency, a position he held until 1953. Marx allowed Bloch to write stories in the office in quiet times. Bloch published a total of 23 Lefty Feep stories in "Fantastic Adventures", the last one published in 1950, but the bulk appeared during World War II. Feep's character name had actually been coined by Bloch's friend/collaborator Harold Gauer for their unpublished novel "In the Land of Sky-Blue Ointments", Bloch also worked for a time in local vaudeville and tried to break into writing for nationally known performers.

Bloch gradually evolved away from Lovecraftian imitations towards a unique style of his own. One of the first distinctly "Blochian" stories was "Yours Truly, Jack the Ripper", ("Weird Tales", July 1943). The story was Bloch's take on the Jack the Ripper legend, and was filled out with more genuine factual details of the case than many other fictional treatments. It cast the Ripper as an eternal being who must make human sacrifices to extend his immortality. It was adapted for both radio (in "Stay Tuned for Terror") and television (as an episode of "Thriller" in 1961 adapted by BarrÃ© Lyndon). Bloch followed up this story with a number of others in a similar vein dealing with half-historic, half-legendary figures such as the Man in the Iron Mask ("Iron Mask", 1944), the Marquis de Sade ("The Skull of the Marquis de Sade", 1945) and Lizzie Borden ("Lizzie Borden Took an Axe ...", 1946).

In 1944, Laird Cregar performed Bloch's tale "Yours Truly, Jack the Ripper" over a coast-to-coast radio network

Towards the end of World War Two, in 1945, Bloch was asked to write 39 15-minute episodes of his own radio horror show called "Stay Tuned for Terror". Many of the programs were adaptations of his own pulp stories. (None of the episodes, which were all broadcast, are extant).. The same year he published "The Skull of the Marquis de Sade" ("Weird Tales," Sept). August Derleth's Arkham House, Lovecraft's publisher, published Bloch's first collection of short stories, "The Opener of the Way", in an edition of 2,000 copies, with jacket art by Ronald Clyne. At the same time, his best-known early tale, "Yours Truly, Jack the Ripper", received considerable attention through dramatization on radio and reprinting in anthologies. This story, as noted below, involving a Ripper who has found literal immortality through his crimes, has been widely imitated (or plagiarized); Bloch himself would return to the theme (see below). Stories published in 1946 include "Enoch" ("Weird Tales", Sept) and "Lizzie Borden Took an Axe" ("Weird Tales", Nov).

Bloch's first novel was published in hardcover - the thriller "The Scarf" (The Dial Press 1947; the Fawcett Gold medal paperback of 1966 features a revised text). It tells the story of a writer, Daniel Morley, who uses real women as models for his characters. But as soon as he is done writing the story, he is compelled to murder them, and always the same way: with the maroon scarf he has had since childhood. The story begins in Minneapolis and follows him and his trail of dead bodies to Chicago, New York City, and finally Hollywood, where his hit novel is going to be turned into a movie, and where his self-control may have reached its limit.

In 1948, Bloch was the Guest of Honor at Torcon I, World Science Fiction Convention, Toronto, Canada. In 1952 he published "Lucy Comes to Stay"(Weird Tales, Jan).

Bloch published three novels in 1954 â "Spiderweb", "The Kidnapper" and "The Will to Kill" as he endeavored to support his family. That same year he was a weekly guest panellist on the TV quiz show "It's a Draw". "Shooting Star" (1958), a mainstream novel, was published in a double volume with a collection of Bloch's stories titled "Terror in the Night". "This Crowded Earth" (1958) was science fiction.

With the demise of "Weird Tales", Bloch continued to have his fiction published in "Amazing", "Fantastic", "The Magazine of Fantasy and Science Fiction", and "Fantastic Universe"; he was a particularly frequent contributor to "Imagination" and "Imaginative Tales". His output of thrillers increased and he began to appear regularly in "The Saint", "Ellery Queen" and similar mystery magazines, and to such suspense and horror-fiction magazine projects as "Shock".

Bloch continued to revisit the Jack the Ripper theme. His contribution to Harlan Ellison's 1967 science fiction anthology "Dangerous Visions" was a story, "A Toy for Juliette", which evoked both Jack the Ripper and the Marquis de Sade in a time-travel story. The same anthology had Ellison's sequel to it titled "The Prowler in the City at the Edge of the World". His earlier idea of the Ripper as an immortal being resurfaced in Bloch's contribution to the original "Star Trek" series episode "Wolf in the Fold". His 1984 novel "Night of the Ripper" is set during the reign of Queen Victoria and follows the investigation of Inspector Frederick Abberline in attempting to apprehend the Ripper, and includes some famous Victorians such as Sir Arthur Conan Doyle within the storyline.

Bloch won the Hugo Award for Best Short Story for "That Hellbound Train" in 1959, the same year that his sixth novel, "Psycho," was published. Bloch had written an earlier short story involving dissociative identity disorder, "The Real Bad Friend", which appeared in the February 1957 "Mike Shayne Mystery Magazine", that foreshadowed the 1959 novel "Psycho". However, "Psycho" also has thematic links to the story "Lucy Comes to Stay." Also in 1959, Bloch delivered a lecture titled "Imagination and Modern Social Criticism" at the University of Chicago; this was reprinted in the critical volume "The Science Fiction Novel" (Advent Publishers). His story "The Hungry Eye" appeared in "Fantastic" (May). This was also the year in which, despite having graduated from painting watercolours to oils, he gave up painting completely.

Norman Bates, the main character in "Psycho", was very loosely based on two people. First was the real-life serial killer Ed Gein, about whom Bloch later wrote a fictionalized account, "The Shambles of Ed Gein". (The story can be found in "Crimes and Punishments: The Lost Bloch, Volume 3"). Second, it has been indicated by several people, including Noel Carter (wife of Lin Carter) and Chris Steinbrunner, as well as allegedly by Bloch himself, that Norman Bates was partly based on Calvin Beck, publisher of "Castle of Frankenstein". Bloch's basing of the character of Norman Bates on Ed Gein is discussed in the documentary "Ed Gein: The Ghoul of Plainfield", which can be found on Disc 2 of the DVD release of the remake of "The Texas Chainsaw Massacre" (2003). However, Bloch also commented that it was the situation itself - a mass murderer living undetected and unsuspected in a typical small town in middle America - rather than Gein himself who sparked Bloch's storyline. He writes: "Thus the real-life murderer was not the role model for my character Norman Bates. Ed Gein didn't own or operate a motel. Ed Gein didn't kill anyone in the shower. Ed Gein wasn't into taxidermy. Ed Gein didn't stuff his mother, keep her body in the house, dress in a drag outfit, or adopt an alternative personality. These were the functions and characteristics of Norman Bates, and Norman Bates didn't exist until I made him up. Out of my own imagination, I add, which is probably the reason so few offer to take showers with me."

Though Bloch had little involvement with the film version of his novel, which was directed by Alfred Hitchcock from an adapted screenplay by Joseph Stefano, he was to become most famous as its author. Bloch was awarded a special Mystery Writers of America scroll for the novel in 1961.

The novel is one of the first examples at full length of Bloch's use of modern urban horror relying on the horrors of interior psychology rather than the supernatural. "By the mid-1940s, I had pretty well mined the vein of ordinary supernatural themes until it had become varicose," Bloch explained to Douglas E. Winter in an interview. "I realized, as a result of what went on during World War II and of reading the more widely disseminated work in psychology, that the real horror is not in the shadows, but in that twisted little world inside our own skulls." While Bloch was not the first horror writer to utilise a psychological approach (it originates in the work of Edgar Allan Poe), Bloch's psychological approach in modern times was comparatively unique.

Bloch's agent, Harry Altshuler, received a "blind bid" for the novel â the buyer's name was not mentioned â of $7,500 for screen rights to the book. The bid eventually went to $9,500, which Bloch accepted. Bloch had never sold a book to Hollywood before. His contract with Simon & Schuster included no bonus for a film sale. The publisher took 15 percent according to contract, while the agent took his 10%; Bloch wound up with about $6,750 before taxes. Despite the enormous profits generated by Hitchcock's film, Bloch received no further direct compensation.

Only Hitchcock's film was based on Bloch's novel. The later films in the "Psycho" series bear no relation to either of Bloch's sequel novels. Indeed, Bloch's proposed script for the film "Psycho II" was rejected by the studio (as were many other submissions), and it was this that he subsequently adapted for his own sequel novel.

The film "Hitchcock" (2012) tells the story of Alfred Hitchcock's making of the film version of "Psycho". Although it mentions Bloch and his novel, Bloch himself is not a character in the movie.

Following his move to Hollywood, around 1960, Bloch had multiple assignments from various television companies. However, he was not allowed to write for five months when the Writers Guild had a strike. After the strike was over, he became a frequent scriptwriter for television and film projects in the mystery, suspense, and horror genre. His first assignments were for the Macdonald Carey vehicle, "Lock-Up", (penning five episodes) as well as one for "Whispering Smith". Further TV work included an episode of "Bus Stop" ("I Kiss Your Shadow"), 10 episodes of "Thriller" (1960â62, several based on his own stories), and 10 episodes of "Alfred Hitchcock Presents" (1960â62). His short story collection "Pleasant Dreams - Nightmares" was published by Arkham House in 1960.

Bloch wrote the screenplay for "The Cabinet of Caligari" (1962), which is only very loosely related to the 1920 German silent film, and proved to be an unhappy experience. The same year, Bloch penned the story and teleplay "The Sorcerer's Apprentice" for "Alfred Hitchcock Presents". The episode was shelved when the NBC Television Network and sponsor Revlon called its ending "too gruesome" (by 1960s standards) for airing. Bloch was pleased later when the episode was included in the program's syndication package to affiliate stations, where not one complaint was registered. Today, due to public domain status, the episode is readily available in home media formats from numerous distributors and is even available on free video on demand.

His TV work did not slow Bloch's fictional output. In the early 1960s he published several novels, including "The Dead Beat" (1960), and "Firebug " (1961), for which Harlan Ellison, then an editor at Regency Books, contributed the first 1,200 words. In 1962 numerous works appeared in book form. Bloch's novel "The Couch" (1962) (the basis for the screenplay of his first movie, filmed the same year) was published. That year several Bloch short story collections- "Atoms and Evil", "More Nightmares" and "Yours Truly, Jack the Ripper" were published, as well as another novel, "Terror" (whose working titles included "Amok" and "Kill for Kali"). Editor Earl Kemp assembled a selection of Bloch's prolific output for fan magazines as "The Eight Stage of Fandom: Selections from 25 years of Fan Writing" (Advent Publishers). In this era, Stephen King later wrote, "What Bloch did with such novels as "The Deadbeat", "The Scarf", "Firebug", "Psycho", and "The Couch" was to re-discover the suspense novel and reinvent the antihero as first discovered by James Cain."

During 1963, Bloch saw into print two further collections of short stories, "Bogey men" and "Horror-7". In 1964 Bloch married Eleanor Alexander and wrote original screenplays for two films produced and directed by William Castle, "Strait-Jacket" (1964) and "The Night Walker" (also 1964), along with "The Skull" (1965).The latter film was based on his short story "The Skull of the Marquis de Sade".

Bloch's further TV writing in this period included "The Alfred Hitchcock Hour" (7 episodes, 1962â1965), "I Spy" (1 episode, 1966), "Run for Your Life" (1 episode, 1966), and "The Girl from U.N.C.L.E." (1 episode, 1967). He penned three scripts for the original "" series which were screened in 1966 and 1967: "What Are Little Girls Made Of?", "Wolf in the Fold" (another Jack the Ripper variant), and "".

In 1968, Bloch returned to London to do two episodes for the English Hammer Films series "Journey to the Unknown" for Twentieth Century Fox. One of the episodes, "The Indian Spirit Guide", was included in the American TV movie "Journey to Midnight" (1968). The other episode was "Girl of My Dreams," co-scripted with Michael J. Bird and based on the eponymous story by Richard Matheson.

Following the movie "The Skull" (1965), which was based on a Bloch story but scripted by Milton Subotsky, he wrote the screenplays for five feature films produced by Amicus Productions â "The Psychopath" (1966), "The Deadly Bees" (co-written with Anthony Marriott, 1967), "Torture Garden" (also 1967), "The House That Dripped Blood" (1971) and "Asylum" (1972). The last two films featured stories written by Bloch that were printed first in anthologies he wrote in the 1940s and early 1950s.

During the 1970s, Bloch wrote two TV movies for director Curtis Harrington â "The Cat Creature" (1973) (an "ABC Movie of the Week") and "The Dead Don't Die". "The Cat Creature" was an unhappy production experience for Bloch. Producer Doug Cramer wanted to do an update of "Cat People" (1942), the Val Lewton-produced film. Bloch commented: "Instead, I suggested a blending of the elements of several well-remembered films, and came up with a story line which dealt with the Egyptian cat-goddess (Bast), reincarnation and the first bypass operation ever performed on an artichoke heart." A detailed account of the troubled production of the film is described in Bloch's autobiography.

Bloch meanwhile (interspersed between his screenplays for Amicus Productions and other projects), penned single episodes for "Night Gallery" (1971), "Ghost Story" (1972), "The Manhunter" (1974), and "Gemini Man" (1976).

In 1965, two further collections of short stories appeared - "The Skull of the Marquis de Sade" and "Tales in a Jugular Vein". 1966 saw Bloch win the Ann Radcliffe Award for Television and publisher yet another collection of shorts - "Chamber of Horrors". Bloch returned to the site of his childhood home at 620 East Knapp St, Milwaukee (the address used by Lovecraft for the character Robert Blake in "The Haunter of the Dark") only to find the neighborhood razed and the entire neighborhood leveled and replaced by expressway approaches.

In 1967, another Bloch collection, "The Living Demons" was issued. He also published another classic story of Jack the Ripper, "A Toy for Juliette" in Harlan Ellison's "Dangerous Visions" anthology. In 1968 he published a duo of long sf novellas as "This Crowded Earth and Ladies'Day". His novel "The Star Stalker" was published, and "Dragons and Nightmares" (the first collection of Lefty Feep stories) appeared in hardcover (Mirage Press).

In 1965, two further collections of short stories appeared - "The Skull of the Marquis de Sade" and "Tales in a Jugular Vein". The following year, Bloch won the Ann Radcliffe Award for Television and publisher a collection of short stories entitled "Chamber of Horrors". Bloch returned to the site of his childhood home at 620 East Knapp St, Milwaukee (the address used by Lovecraft for Robert Blake in "The Haunter of the Dark") only to find the neighborhood razed and the entire neighbourhood levelled and replaced by expressway approaches.

In 1967, another Bloch collection, "The Living Demons" was issued. He also published another classic story of Jack the Ripper, "A Toy for Juliette" in Harlan Ellison's "Dangerous Visions" anthology. In 1968, a duo of long science fiction novellas appeared as "This Crowded Earth and Ladies'Day", as did his novel "The Star Stalker" and "Dragons and Nightmares" (the first collection of Lefty Feep stories from Mirage Press in hardback). "Ladies Day/This Crowded Earth" and "The Star Stalker" followed in 1968. The collection "Bloch and Bradbury" (a collaboration with Ray Bradbury) and the hardcover novel "The Todd Dossier", originally as by Collier Young, were published in 1969.

Bloch won a second Ann Radcliffe Award, this time for Literature, in 1969. That same year, Bloch was invited to the Second International Film Festival in Rio de Janeiro, March 23â31, along with other science fiction writers from the United States, Britain and Europe.

In 1971, Bloch served as president of the Mystery Writers of America, meanwhile publishing the novel "Sneak preview", the collection "fear Today, Gone Tomorrow," and the short novel "It's All in Your Mind". In 1972 he published another novel, "Night-World". In 1973 Bloch was the Guest of Honor at Torcon II, World Science Fiction Convention, Toronto. 1974 saw the publication of his novel "American Gothic", inspired by the true life story of serial killer H.H. Holmes.

In 1975, Bloch won the Lifetime Achievement Award at the First World Fantasy Convention held in Providence, Rhode Island. The award was a bust of H.P. Lovecraft. The occasion of this convention was the first time Bloch actually visited the city of Providence. An audio recording was made of Robert Bloch during that 1975 convention, accessible online at 

In 1976, two records of Bloch recordings of his stories were released by Alternate World recordings - "Gravely, Robert Bloch!" and "Blood! The Life and Times of jack the Ripper!"(with Harlan Ellison). In 1977, Lester del Rey edited "The Best of Robert Bloch" for Del Rey books. Two further short story collections appeared - "Cold Chills" and "The King of Terrors."

Bloch continued to published short story collections throughout this period. His "Selected Stories" (reprinted in paperback with the incorrect title "The Complete Stories") appeared in three volumes just prior to his death, although many previously uncollected tales have appeared in volumes published since 1997 (see below). Bloch also contributed the story "Heir Apparent," set in Andre Norton's Witch World, to "Tales of the Witch World" (Vol. 1), NY: Tor, 1987.

1979 saw the publication of Bloch's novel "There is a Serpent in Eden" (alsdo reissued as "The Cunning"), and two more short story collections, "Out of the Mouths of graves" and "Such Stuff as Screams Are Made Of."

His numerous novels of the 1970s demonstrate Bloch's thematic range, from science fiction - "Sneak Preview" (1971) - through horror novels such as the loving Lovecraftian tribute "Strange Eons" (Whispers Press, 1978) and the non-supernatural mystery "There is a Serpent in Eden" (1979);

Bloch's screenplay-writing career continued active through the 1980s, with teleplays for "Tales of the Unexpected" (one episode, 1980), "Darkroom" (two episodes,1981), "Alfred Hitchcock Presents" (1 episode, 1986), "Tales from the Darkside" (three episodes, 1984â87 - "Beetles", "A Case of the Stubborns" and "Everybody needs a Little Love") and "Monsters" (three episodes, 1988â1989 - "The Legacy", "Mannikins of Horror", and "Reaper"). No further screen work appeared in the last five years before his death, although an adaptation of his "collaboration" with Edgar Allan Poe, "The Lighthouse", was filmed as an episode of "The Hunger" in 1998.

"The First World Fantasy Convention: Three Authors Remember" (Necronomicon Press, 1980) features reminiscences of that important event by Bloch, T.E.D. Klein and Fritz Leiber. In 1981, Zebra Books issued the first edition of the Cthulhu Mythos-themed collection "Mysteries of the Worm". This item was reprinted some years later in an expanded edition by Chaosium.

Bloch's sequel to the original "Psycho" ("Psycho II" was published in 1982 (unrelated to the film of the same title) and in 1983 he novelised "". His novel "Night of the Ripper" (1984), was another return to one of Bloch's favourite themes, the Jack the Ripper murders of 1888.

In 1986, Scream Press published the hardcover omnibus "Unholy Trinity", collecting three by now scarce Bloch novels, "The Scarf", "The Dead Beat" and "The Couch." A second retrospective selection of Bloch's nonfiction was published by NESFA Press as "Out of My Head."

In 1987, Bloch celebrated his 70th birthday. Underwood-Miller issued the three-volume hardcover set "The Selected Stories of Robert Bloch" (individual volumes titled "Final reckonings", "Bitter Ends" and "Last Rites"). When Citadel press reissued this in paperback they incorrectly named it "The Collected Stories of Robert Bloch." The same year a collection, "Midnight Pleasures" appeared from Doubleday, and "Lost in Time and Space with Lefty Feep" (Creatures at Large Press) collected a number of the stories on the Lefty Feep series. The latter was the first of a projected series of three volumes, however the further volumes were never published. In 1988, Tor Books reissued Bloch's scarce second novel, "The Kidnapper.'

In 1989, several works were published: the collection, "Fear and Trembling", the thriller novel "Lori" (later adapted as a standalone graphic novel) and another omnibus of long out-of-print early novels, "Screams" (containing "The Will to Kill", "Firebug" and "The Star Stalker"). Randall D. Larson issued "The Robert Bloch Companion: Collected Interviews 1969-1986" (Starmont House), together with "Robert Bloch" (Starmont Reader's Guide No 37), an exhaustive study of Bloch's work, and "The Complete Robert Bloch: An Illustrated, Comprehensive Bibliography" (Fandom Unlimited Enterprises). Larson's three books were bound in hardcover and distributed by Borgo Press.

Bloch's novel, "The Jekyll Legacy" (1990), was a collaboration with Andre Norton and a sequel to Robert Louis Stevenson's "Dr. Jekyll and Mr. Hyde". The same year he returned to the Norman Bates "mythos" with "Psycho House" (Tor), the third Psycho novel. As with the second novel in the sequence, it bears no relation to the film titled "Psycho III". It would prove to be his last published novel.

In February 1991, he was given the Honor of Master of Ceremonies at the first World Horror Convention held in Nashville, Tennessee. Weird Tales issued a special Robert Bloch issue in Spring, including his screenplay for the televised version of his tale "Beetles"". A standalone chapbook of the story "Yours Truly, Jack the Ripper" was issued in both hardcover and paperback by Pulphouse, and Bloch co-edited with Martin H. Greenberg the original anthology "Psycho-Paths" (Tor). In 1991 Bloch contributed an Introduction to "In Search of Lovecraft" by J. Vernon Shea.

In 1992, Bloch celebrated his 75th birthday with a bash at a Los Angeles mystery/horror bookstore which was attended by many sf/horror notables. In 1993, he published his "unauthorized autobiography", "Once Around the Bloch" (Tor) and edited the original anthology "Monsters in Our Midst".

In early 1994, Fedogan and Bremer published a collection of 39 of his stories, "The Early Fears". Bloch began editing a new original anthology, "Robert Bloch's Psychos" but was unable to complete work on it prior to his death; Martin H. Greenberg finished the work posthumously and the book appeared several years later (1997).

On October 2, 1940, Bloch married Marion Ruth Holcombe; it was reportedly a marriage of convenience designed to keep Bloch out of the army. During their marriage, she suffered (initially undiagnosed) tuberculosis of the bone, which affected her ability to walk.

After working for 11 years for the Gustav Marx Advertising Agency in Milwaukee, Bloch left in 1953 and moved to Weyauwega, Marion's home town, so she could be close to friends and family. Although she was eventually cured of tuberculosis, she and Bloch divorced in 1963. Bloch's daughter Sally (born 1943) elected to stay with him.

On January 18, 1964, Bloch met recently widowed Eleanor ("Elly") Alexander (nÃ©e Zalisko) â who had lost her first husband, writer/producer John Alexander, to a heart attack three months earlier â and made her his second wife in a civil ceremony on the following October 16. Elly was a fashion model and cosmetician. They honeymooned in Tahiti, and in 1965 visited London, then British Columbia. They remained happily married until Bloch's death. Elly remained in the Los Angeles area for several years after selling their Laurel Canyon Home to fans of Bloch, eventually choosing to go home to Canada to be closer to her own family. She died March 7, 2007, at the Betel Home in Selkirk, Manitoba, Canada. Her ashes have been placed next to Bloch's in a similar book-shaped urn at Pierce Brothers in Westwood, California.

Bloch died on 23 September 1994 after a long battle with cancer, at the age of 77. in Los Angeles after a writing career lasting 60 years, including more than 30 years in television and film. Bloch survived by seven months the death of another member of the original "Lovecraft Circle", Frank Belknap Long, who had died in January, 1994.

Bloch was cremated and his ashes interred in the Room of Prayer columbarium at Westwood Village Memorial Park Cemetery in Los Angeles. His wife Elly is also interred there.

The Robert Bloch Award is presented at the annual Necronomicon convention. Its recipient in 2013 was editor and scholar S.T. Joshi. The award is in the shape of the Shining Trapezohedron as described in H.P. Lovecraft's tale dedicated to Bloch, The Haunter of the Dark.

A number of Bloch's works have been adapted in graphic form for comics. These include:

The comic "Aardwolf" (No 2, Feb 1995) is a special tribute issue to Bloch. It contains brief tributes to Bloch from Harlan Ellison, Ray Bradbury, Richard Matheson, Julius Schwartz and Peter Straub incorporated within a piece called "Robert Bloch: A Retrospective" compiled by Clifford Lawrence. The first part of the text of Bloch's story "The Past Master" is also reprinted in this issue.

Bloch also contributed a script as part of the DC one-shot benefit comic "Heroes Against Hunger".

A number of Bloch's works have been adapted for audio productions.

Other adaptations include:

Various recordings of Bloch speaking at fantasy and sf conventions are also extant. Many of these are available for download from Will Hart's CthulhuWho site: 



Note: The following three entries represent paperback reprints of the Underwood Miller "Selected Stories" set. "Complete Stories" is a misnomer as these three volumes do not contain anywhere near the complete oeuvre of Bloch's short fiction.




See also 42nd World Science Fiction Convention

The following is a list of films based on Bloch's work. For some of these he wrote the original screenplay; for others, he supplied the story or a novel (as in the case of "Psycho") on which the screenplay was based.

Bloch wrote a number of screenplays which remain unproduced. These include "Merry-Go-Round" for MGM (loosely based on Ray Bradbury's story "Black Ferris");, "Night-World" (from Bloch's novel, for MGM); "The Twenty-First Witch"; and "Day of the Comet" (from the H.G. Wells story), and a television adaptation of "Out of the Aeons". See also "The Todd Dossier".

Some scenes from Bloch's incomplete screenplay for the unproduced movie "Earthman's Burden", to have been based on the Hoka stories of Gordon R. Dickson and Poul Anderson appear in Richard Matheson and Ricia Mainhardt, eds, "Robert Bloch: Appreciations of the Master". NY: Tor, 1995, pp.Â 157â63.

Bloch appeared in the documentary The Fantasy Film Worlds of George Pal (1985) (Produced and directed by Arnold Leibovit).

Many of Bloch's published works, manuscripts (including those of the novels "The Star Stalker," "This Crowded Earth", and "Night World"), correspondence, books, recordings, tapes and other memorabilia are housed in the Special Collections division of the library at the University of Wyoming. The collection includes several unpublished short stories, such as "Dream Date", "The Last Clown", "A Pretty Girl is Like a Malady", "Twilight of a God", "It Only Hurts When I Laugh", "How to Pull the Wings Off a Barfly", "The Craven Image", "Afternoon in the Park", "Title Bout", and 'What Freud Can't Tell You". In addition there is even an unpublished one-act play entitled "The Birth of a Notion - A Tragedy of Hollywood." Thousands of other items from fanzines and professional periodicals to film stills, lobby cards, one-sheets and posters and press-books connected with Bloch's films, together with transcripts of several of his speeches, are also housed in the collection.





</doc>
<doc id="26244" url="https://en.wikipedia.org/wiki?curid=26244" title="Recorder (musical instrument)">
Recorder (musical instrument)

The recorder is a woodwind musical instrument in the group known as "internal duct flutes"âflutes with a whistle mouthpiece, also known as fipple flutes. A recorder can be distinguished from other duct flutes by the presence of a thumb-hole for the upper hand and seven finger-holes: three for the upper hand and four for the lower. It is the most prominent duct flute in the western classical tradition.

Recorders are made in different sizes with names and compasses roughly corresponding to different vocal ranges. The sizes most commonly in use today are the soprano (aka "descant", lowest note C), alto (aka "treble", lowest note F), tenor (lowest note C) and bass (lowest note F). Recorders are traditionally constructed from wood and ivory, while most recorders made in recent years are constructed from molded plastic. The recorders' internal and external proportions vary, but the bore is generally reverse conical (i.e. tapering towards the foot) to cylindrical, and all recorder fingering systems make extensive use of forked fingerings.

The recorder is first documented in Europe in the Middle Ages, and continued to enjoy wide popularity in the Renaissance and Baroque periods, but was little used in the Classical and Romantic periods. It was revived in the 20th century as part of the historically informed performance movement, and became a popular amateur and educational instrument. Composers who have written for the recorder include Monteverdi, Lully, Purcell, Handel, Vivaldi, Telemann, Johann Sebastian Bach, Paul Hindemith, Benjamin Britten, Leonard Bernstein, Luciano Berio, and Arvo PÃ¤rt. Today, there are many professional recorder players who demonstrate the instrument's full solo range and a large community of amateurs.

The sound of the recorder is often described as clear and sweet, and has historically been associated with birds and shepherds. It is notable for its quick response and its corresponding ability to produce a wide variety of articulations. This ability, coupled with its open finger holes, allow it to produce a wide variety of tone colors and special effects. Acoustically, its tone is relatively pure and, when the edge is positioned in the center of the
airjet, odd harmonics predominate in its sound (when the edge is decidedly off-center, an even distribution of harmonics occurs).

The instrument has been known by its modern English name at least since the 14th century. David Lasocki reports the earliest use of "recorder" in the household accounts of the Earl of Derby (later King Henry IV) in 1388, which register (one pipe called 'Recordour').

By the 15th century, the name had appeared in English literature. The earliest references are in John Lydgate's Temple of Glas (1430): "These lytylle herdegromys Floutyn al the longe day..In here smale recorderys, In floutys." (These little shepherds fluting all day long ... on these small recorders, on flutes.) and in Lydgate's Fall of Princes ( 1431â1438): "Pan, god off Kynde, with his pipes seuene, / Off recorderis fond first the melodies." (Pan, god of Nature, with his pipes seven, / of recorders found first the melodies.)

The instrument name "recorder" derives from the Latin "recordÄrÄ«" (to call to mind, remember, recollect), by way of Middle French "recorder" (before 1349; to remember, to learn by heart, repeat, relate, recite, play music) and its derivative MFr "recordeur" (1395; one who retells, a minstrel). The association between the various, seemingly disparate, meanings of "recorder" can be attributed to the role of the medieval "jongleur" in learning poems by heart and later reciting them, sometimes with musical accompaniment.

The English verb "record" (from Middle French "recorder", early 13th century) meant "to learn by heart, to commit to memory, to go over in one's mind, to recite" but it was not used in English to refer to playing music until the 16th century, when it gained the meaning "silently practicing a tune" or "sing or render in song" (both almost exclusively referring to songbirds), long after the recorder had been named. Thus, the recorder cannot have been named after the sound of birds. The name of the instrument is also uniquely English: in Middle French there is no equivalent noun sense of "recorder" referring to a musical instrument.

Partridge indicates that the use of the instrument by "jongleurs" led to its association with the verb: "recorder" the minstrel's action, a "recorder" the minstrel's tool. The reason we know this instrument as the recorder and not one of the other instruments played by the "jongleurs" is uncertain.

The introduction of the Baroque recorder to England by a group of French professionals in 1673 popularized the French name for the instrument, "flute douce", or simply "flute", a name previously reserved for the transverse instrument. Until about 1695, the names "recorder" and "flute" overlapped, but from 1673 to the late 1720s in England, the word "flute" always meant recorder. In the 1720s, as the transverse flute overtook the recorder in popularity, English adopted the convention already present in other European languages of qualifying the word "flute", calling the recorder variously the "common flute", "common English-flute", or simply "English flute" while the transverse instrument was distinguished as the "German flute" or simply "flute". Until at least 1765, some writers still used "flute" to mean recorder.

Until the mid 18th century, musical scores written in Italian refer to the instrument as , whereas the transverse instrument was called . This distinction, like the English switch from "recorder" to "flute," has caused confusion among modern editors, writers and performers.

Indeed, in most European languages, the first term for the recorder was the word for flute alone. In the present day, cognates of the word "flute," when used without qualifiers, remain ambiguous and may refer to either the recorder, the modern concert flute, or other non-western flutes. Starting in the 1530s, these languages began to add qualifiers to specify this particular flute. In the case of the recorder, these describe variously 

Since the 15th century, a variety of sizes of recorder have been documented, but a consistent terminology and notation for the different sizes was not formulated until the 20th century.

Today, recorder sizes are named after the different vocal ranges. This is not, however, a reflection of sounding pitch, and serves primarily to denote the pitch relationships between the different instruments. Groups of recorders played together are referred to as "consorts". Recorders are also often referred to by their lowest sounding note: "recorder in F" refers to a recorder with lowest note F, in any octave.

The table to the right shows the standard names of modern recorders in F and C and their respective ranges. Music composed after the modern revival of the recorder most frequently uses soprano, alto, tenor, and bass recorders, although sopranino and great bass are also fairly common. Consorts of recorders are often referred to using the terminology of organ registers: 8â² (8 foot) pitch referring to a consort sounding as written, 4â² pitch a consort sounding an octave above written, and 16â² a consort sounding an octave below written. The combination of these consorts is also possible.

As a rule of thumb, the tessitura of a baroque recorder lies approximately one octave above the tessitura of the human voice type after which it is named. For example, the tessitura of a soprano voice is roughly CâC, while the tessitura of a soprano recorder is CâC.

Modern variations include standard British terminology, due to Arnold Dolmetsch, which refers to the recorder in C (soprano) as the descant and the recorder in F (alto) as the treble. As conventions and instruments vary, especially for larger and more uncommon instruments, it is often practical to state the recorder's lowest note along with its name to avoid confusion.

Modern recorder parts are notated in the key they sound in. Parts for alto, tenor and contrabass recorders are notated at pitch, while parts for sopranino, soprano, bass, and great bass are typically notated an octave below their sounding pitch. As a result, soprano and tenor recorders are notated identically; alto and sopranino are notated identically; and bass and contrabass recorders are notated identically. Octave clefs may be used to indicate the sounding pitch, but usage is inconsistent.

Rare sizes and notations include the garklein, which may be notated two octaves below its sounding pitch, and the sub-contrabass, which may be notated an octave above its sounding pitch.

Like their historical antecedents, modern recorder players frequently also play from parts written for other instruments, reading in a variety of clefs and transpositions, and must make appropriate choices of instrumentation.

The earliest known document mentioning "a pipe called Recordour" dates from 1388.
Historically, recorders were used to play vocal music and parts written for other instruments, or for a general instrument. As a result, it was frequently the performers' responsibility to read parts not specifically intended for the instrument and to choose appropriate instruments. When such consorts consisted only of recorders, the pitch relationships between the parts were typically preserved, but when recorders were combined with other instruments, octave discrepancies were often ignored.

Recorder consorts in the 16th century were tuned in fifths and only occasionally employed tuning by octaves as seen in the modern C, F recorder consort. This means that consorts could be composed of instruments nominally in B, F, C, G, D, A and even E, although typically only three or four distinct sizes were used simultaneously. To use modern terminology, these recorders were treated as transposing instruments: consorts would be read identically to a consort made up of F, C, and G instruments. This is made possible by the fact that adjacent sizes are separated by fifths, with few exceptions. These parts would be written using "chiavi naturali", allowing the parts to roughly fit in the range of a single staff, and also in the range of the recorders of the period. (see Renaissance structure)

Transpositions ("registers"), such as CâGâD, GâDâA, or BâFâC, all read as FâCâG instruments, were possible as described by Praetorius in his "Syntagma Musicum". Three sizes of instruments could be used to play four-part music by doubling the middle size, e.g. FâCâCâG, or play six-part music by doubling the upper size and tripling the middle size, e.g. FâCâCâCâGâG. Modern nomenclature for such recorders refers to the instruments' relationship to the other members of consort, rather than their absolute pitch, which may vary. The instruments from lowest to highest are called "great bass", "bass", "basset", "tenor", "alto", and "soprano". Potential sizes include: great bass in F; bass in B or C; basset in F or G; tenor in C or D; alto in F, G or A; and soprano in C or D.

The alto in F is the standard recorder of the Baroque, although there is a small repertoire written for other sizes. In 17th-century England, smaller recorders were named for their relationship to the alto and notated as transposing instruments with respect to it: third flute (A), fifth flute (soprano; C), sixth flute (D), and octave flute (sopranino; F). The term "flute du quart", or fourth flute (B), was used by Charles Dieupart, although curiously he treated it as a transposing instrument in relation to the soprano rather than the alto. In Germanic countries, the equivalent of the same term, "QuartflÃ¶te", was applied both to the tenor in C, the interval being measured down from the alto in F, and to a recorder in C (soprano), the interval of a fourth apparently being measured up from an alto in G. Recorder parts in the Baroque were typically notated using the treble clef, although they may also be notated in French violin clef (G clef on the bottom line of the staff).

In modern usage, recorders not in C or F are alternatively referred to using the name of the closest instrument in C or F, followed by the lowest note. For example, a recorder with lowest note G may be known as a G-alto or alto in G, a recorder with lowest note D (also "sixth flute") as a D-soprano or soprano in D, and a recorder in G as a G-bass or G-basset. This usage is not totally consistent. Notably, the baroque recorder in D is not commonly referred to as a D-tenor nor a D-alto; it is most commonly referred to using the historical name "voice flute".

Recorders have historically been constructed from hardwoods and ivory, sometimes with metal keys. Since the modern revival of the recorder, plastics have been used in the mass manufacture of recorders, as well as by a few individual makers.

Today, a wide variety of hardwoods are used to make recorder bodies. Relatively fewer varieties of wood are used to make recorder blocks, which are often made of red cedar, chosen because of its rot resistance, ability to absorb water, and low expansion when wet. A recent innovation is the use of synthetic ceramics in the manufacture of recorder blocks.

Some recorders have tone holes too far apart for a player's hands to reach, or too large to cover with the pads of the fingers. In either case, more ergonomically placed keys can be used to cover the tone holes. Keys also allow the design of longer instruments with larger tone holes. Keys are most common in recorders larger than the alto. Instruments larger than the tenor need at least one key so the player can cover all eight holes. Keys are sometimes also used on smaller recorders to allow for comfortable hand stretch, and acoustically improved hole placement and size.

When playing a larger recorder, a player may not be able to simultaneously reach the keys or tone holes with the fingers and reach the windway with the mouth. In this case, a bocal may be used to allow the player to blow into the recorder while maintaining a comfortable hand position. Alternatively, some recorders have a bent bore that positions the windway closer to the keys or finger holes so the player can comfortably reach both. Instruments with a single bend are known as "knick" or bent-neck recorders.

Some newer designs of recorder are now being produced. Recorders with a square cross-section may be produced more cheaply and in larger sizes than comparable recorders manufactured by turning. Another area is the development of instrument with a greater dynamic range and more powerful bottom notes. These modern designs make it easier to be heard in concertos. Finally, recorders with a downward extension of a semitone are becoming available; such instruments can play a full three octaves in tune.

In the early 20th century, Peter Harlan developed a recorder with apparently simpler fingering, called German fingering. A recorder designed for German fingering has a hole five that is smaller than hole four, whereas baroque and neo-baroque recorders have a hole four that is smaller than hole five. The immediate difference in fingering is for F (soprano) or B (alto), which on a neo-baroque instrument must be fingered 0 123 4â67. With German fingering, this becomes a simpler 0 123 4 â â â. Unfortunately, however, this makes many other chromatic notes too out of tune to be usable. German fingering became popular in Europe, especially Germany, in the 1930s, but rapidly became obsolete in the 1950s as people began to treat the recorder more seriously, and the limitations of German fingering became more widely appreciated. Recorders with German fingering are today manufactured exclusively for educational purposes.

Modern recorders are most commonly pitched at A=442Â Hz; but among serious amateurs and professionals, other pitch standards are often found. For the performance of baroque music, A=415Â Hz is the "de facto" standard, while pre-Baroque music is often performed at A=440Â Hz or A=466Â Hz. These pitch standards are intended to reflect the broad variation in pitch standards throughout the history of the recorder. In various regions, contexts, and time periods, pitch standards have varied from A=~392Â Hz to A=~520Â Hz. The pitches A=415Â Hz and A=466Â Hz, a semitone lower and a semitone higher than A=440Â Hz respectively, were chosen because they may be used with harpsichords or chamber organs that transpose up or down a semitone from A=440. These pitch standards allow recorder players to collaborate with other instrumentalists at a pitch other than A=440Â Hz.

Some recorder makers produce instruments at pitches other than the three standard pitches above, and recorders with interchangeable bodies at different pitches.

The recorder produces sound in the manner of a whistle or an organ flue pipe. In normal play, the player blows into the "windway" (B), a narrow channel in the "head joint", which directs a stream of air across a gap called the "window", at a sharp edge called the "labium" (C). The air stream alternately travels above and below the labium, exciting standing waves in the bore of the recorder, and producing sound waves that emanate away from the window. Feedback from the resonance of the tube regulates the pitch of the sound.

In recorders, like in all woodwind instruments, the air column inside the instrument behaves like a vibrating string, to use a musical analogy, and has multiple modes of vibration. These waves produced inside the instrument are not travelling waves, like those the ear perceives as sound, but rather stationary standing waves consisting of areas of high pressure and low pressure inside the tube, called nodes. The perceived pitch is the lowest, and typically loudest, mode of vibration in the air column. The other pitches are "harmonics", or "overtones". Players typically describe recorder pitches by the number of nodes in the air column. Notes with a single node are in the "first register," notes with two nodes in the "second register," etc. As the number of nodes in the tube increases, the number of notes a player can produce in a given register decreases because of the physical constraint of the spacing of the nodes in the bore. On a Baroque recorder, the first, second, and third registers span about a major ninth, a major sixth, and a minor third respectively.

The recorder sound, for the most part, lacks high harmonics and odd harmonics predominate in its sound with the even harmonics being almost entirely absent, although the harmonic profile of the recorder sound varies from recorder to recorder, and from fingering to fingering. As a result of the lack of high harmonics, writers since Praetorius have remarked that it is difficult for the human ear to correctly perceive the sounding octave of the recorder: if the same pitch were played on a violin and on a recorder, the violin sound would have louder high harmonics.

As in organ flue pipes, the sounding pitch of duct type whistles is affected by the velocity of the air stream as it impinges upon the labium. The pitch generally increases with velocity of the airstream, up to a point.

Air speed can also be used to influence the number of pressure nodes in a process called over blowing. At higher airstream velocities, lower modes of vibration of the air column become unstable, resulting in a change of register.

The air stream is affected by the shaping of the surfaces in the head of the recorder (the "voicing"), and the way the player blows air into the windway. Recorder voicing is determined by physical parameters such as the proportions and curvature of the windway along both the longitudinal and latitudinal axes, the beveled edges ("chamfers") of the windway facing towards the labium, the length of the window, the sharpness of the labium (i.e. the steepness of the ramp) among other parameters. The player is able to control the speed and turbulence of the airstream using the diaphragm and vocal tract.

The finger holes, used in combination or partially covered, affect the sounding pitch of the instrument.

At the most basic level, the sequential uncovering of finger holes increases the sounding pitch of the instrument by decreasing the effective sounding length of the instrument, and vice versa for the sequential covering of holes. In the fingering 01234567, only the bell of the instrument is open, resulting in a low pressure node at the bell end of the instrument. The fingering 0123456 sounds at a higher pitch because the seventh hole and the bell both release air, creating a low pressure node at the seventh hole.

Besides sequential uncovering, recorders can use forked fingering to produce tones other than those produced by simple sequential lifting of fingers. In the fingering 0123, air leaks from the open holes 4,5,6, and 7. The pressure inside the bore is higher at the fourth hole than at the fifth, and decreases further at the 6th and 7th holes. Consequently, the most air leaks from the fourth hole and the least air leaks from the seventh hole. As a result, covering the fourth hole affects the pitch more than covering any of the holes below it. Thus, at the same air pressure, the fingering 01235 produces a pitch between 0123 and 01234. Forked fingerings allow recorder players to obtain fine gradations in pitch and timbre.

A recorder's pitch is also affected by the partial covering of holes. This technique is an important tool for intonation, and is related to the fixed process of tuning a recorder, which involves the adjustment of the size and shape of the finger holes through carving and the application of wax.

One essential use of partial covering is in "leaking," or partially covering, the thumb hole to destabilize low harmonics. This allows higher harmonics to sound at lower air pressures than by over-blowing alone, as on simple whistles. The player may also leak other holes to destabilize lower harmonics in place of the thumb hole (hole 0). This technique is demonstrated in the fingering tables of Ganassi's Fontegara (1535), which illustrate the simultaneous leaking of holes 0, 2, and 5 to produce some high notes. For example, Ganassi's table produces the 15th (third octave tonic) as the fourth harmonic of the tonic, leaking holes 0, 2 and 5 and produces the 16th as the third harmonic of the fifth, leaking holes 0 and 2. On some Baroque recorders, the 17th can be produced as the third harmonic of the sixth, leaking hole 0 as well as hole 1, 2 or both.

Although the design of the recorder has changed over its 700-year history, notably in fingering and bore profile (see History), the technique of playing recorders of different sizes and periods is much the same. Indeed, much of what is known about the technique of playing the recorder is derived from historical treatises and manuals dating to the 16thâ18th century. The following describes the commonalities of recorder technique across all time periods. 

In normal playing position, the recorder is held with both hands, covering the fingerholes or depressing the keys with the pads of the fingers: four fingers on the lower hand, and the index, middle and ring fingers and thumb on the upper hand. In standard modern practice, the right hand is the lower hand, while the left hand is the upper hand, although this was not standardized before the modern revival of the recorder.

The recorder is supported by the lips, which loosely seal around the beak of the instrument, the thumb of the lower hand, and, depending on the note fingered, by the other fingers and the upper thumb. A practice documented in many historical fingering charts is the use of finger seven or eight to support the recorder when playing notes for which the coverage of this hole negligibly affects the sounding pitch (e.g. notes with many holes uncovered). Larger recorders may have a thumbrest, or a neckstrap for extra support, and may use a bocal to direct air from the player's mouth to the windway.

Recorders are typically held at an angle between vertical and horizontal, the attitude depending on the size and weight of the recorder, and personal preference.

Pitches are produced on the recorder by covering the holes while blowing into the instrument. Modern terminology refers to the holes on the front of the instrument using the numbers 1 through 7, starting with the hole closest to the beak, with the thumbhole numbered hole 0. At the most basic level, the fingering technique of the recorder involves the sequential uncovering of the holes from lowest to highest (i.e. uncovering 7, then uncovering 7 and 6, then uncovering 7, 6 and 5, etc.) producing ever higher pitches. In practice, however, the uncovering of the holes is not strictly sequential, and the half covering or uncovering of holes is an essential part of recorder technique.
A forked fingering is a fingering in which an open hole has covered holes below it: fingerings for which the uncovering of the holes is not sequential. For example, the fingering 0123 is not a forked fingering, while 0123 56 is a forked fingering because the open hole 4 has holes covered below it holes 5 and 6. Forked fingerings allow for smaller adjustments in pitch than the sequential uncovering of holes alone would allow. For example, at the same air speed the fingering 0123 5 sounds higher than 01234 but lower than 0123. Many standard recorder fingerings are forked fingerings. Forked fingerings may also be used to produce microtonal variations in pitch.

Forked fingerings have a different harmonic profile from non-forked fingerings, and are generally regarded as having a weaker sound. Forked fingerings that have a different tone color or are slightly sharp or flat can provide so-called "alternate fingerings". For example, the fingering 0123 and its slightly sharper forked variant 012 4567.

Partial covering of the holes is an essential part of the playing technique of all recorders. This is variously known as "leaking," "shading," "half-holing," and in the context of the thumb hole, "pinching".

The primary function of the thumbhole is to serve as an octaving vent. When it is leaked, the first mode of vibration of the air column becomes unstable: i.e., the register changes. In most recorders, this is required for the playing of every note higher than a ninth above the lowest note. The player must adjust the position of the thumb for these notes to sound stably and in tune.

The partial opening of the thumbhole may be achieved by sliding or rolling the thumb off of the hole, or by bending the thumb at the first knuckle. To partially uncover a covered hole, the player may slide the finger off of the hole, bend or roll the finger away from the hole, gently lift the finger from the hole, or a combination of these. To partially cover an open hole, the reverse is possible.

Generally speaking, the partial opening of covered fingerholes raises the pitch of the sounding note while the partial closure of open fingerholes lowers the pitch.

On most "baroque" modeled modern recorders, the lower two fingers of the lower hand actually cover two holes each (called "double holes"). Whereas on the vast majority of baroque recorders and all earlier recorders these two fingers covered a single hole ("single holes"), double holes have become standard for baroque modeled modern recorders. By covering one or both of these two, smaller holes, a recorder player can play the notes a semitone above the lowest note and a minor third above the lowest note, notes that are only possible on single holed recorders through the partial covering of those holes, or the covering of the bell.

The open end of the bore facing away from the player (the "bell") may be covered to produce extra notes or effects. Because both hands are typically engaged in holding the recorder or covering the finger holes, the covering of the bell is normally achieved by bringing the end of the recorder in contact with the leg or knee, typically achieved through a combination of bending of the torso and/or raising of the knee. Alternatively, in rare cases instruments may be equipped with a key designed to cover the bell ("bell key"), operated by one of the fingers, typically the pinky finger of the upper hand, which is not normally used to cover a hole. Fingerings with a covered bell extend the recorder's chromatic playable range above and below the nominal fingered range.

The pitch and volume of the recorder sound are influenced by the speed of the air travelling through the windway, which may be controlled by varying the breath pressure and the shape of the vocal tract. The sound is also affected by the turbulence of the air entering the recorder. Generally speaking, faster air in the windway produces a higher pitch. Thus overblowing a note causes it to go sharp whereas underblowing the note causes it to go flat. Knowing this fact and the knowledge of a recorder's individual tonal differences over its full range will help recorders play in tune with other instruments by knowing which notes will need slightly more or less air to stay in tune.

The technique of inhalation and exhalation for the recorder differs from that of many other wind instruments in that the recorder requires very little air pressure to produce a sound, unlike reed or brasswind instruments. Thus, it is often necessary for a recorder player to produce long, controlled streams of air at a very low pressure. Recorder breathing technique focuses on the controlled release of air rather than on maintaining diaphragmatic pressure.

The use of the tongue to stop and start the air is called "articulation". In this capacity, the tongue has two basic functions: to control the start of the note (the attack) and the end, or the length of the note (legato, staccato). Articulations are roughly analogous to consonants. Practically any consonant that may produced with the tongue, mouth, and throat may be used to articulate on the recorder. Transliterations of common articulation patterns include "du du du du" (using the tip of the tongue, "single tonguing") "du gu du gu," (alternating between the tip and the back of the tongue, "double tonguing") and "du g'll du g'll" (articulation with the tip and the sides of the tongue, "double tonguing"). The attack of the note is governed by such factors as the pressure buildup behind the tongue and shape of the articulant, while the length of the note governed by the stoppage of the air by the tongue. Each articulation pattern has a different natural pattern of attack and length, and recorder technique seeks to produce a wide variety of lengths and attacks using these articulation patterns. Patterns like these have been used since at least the time of Ganassi (1535).

Mouth and throat shapes are roughly analogous to vowels. The shape of the vocal track affects the velocity and turbulence of the air entering the recorder. The shape of the mouth and vocal tract affect are closely related to the consonant used to articulate.

The player must coordinate fingers and tongue to align articulations with finger movements. In normal play, articulated attacks should align with the proper fingering, even in legato passages or in difficult finger transitions and the fingers move in the brief silence between the notes (silence d'articulation) created by the stoppage of the air by the tongue.

Both fingers and the breath can be used to control the pitch of the recorder. Coordinating the two is essential to playing the recorder in tune and with a variety of dynamics and timbres. On an elementary level, breath pressure and fingerings must accord with each other to provide an in-tune pitch. As an example of a more advanced form of coordination, a gradual increase in breath pressure combined with the shading of holes, when properly coordinated, results in an increase in volume and change in tone color without a change in pitch. The reverse is possible, decreasing breath pressure and gradually lifting fingers.

The range of a modern "baroque" model recorder is usually considered two octaves and a tone. Other notes outside this compass are less commonly used as they are normally harsher or out of tune. See the table above for "English" fingerings for the standard range. The numbers at the top correspond to the fingers and the holes on the recorder. The vast majority of recorders manufactured today are designed to play using these fingerings, with slight variations. Nonetheless, recorder fingerings vary widely between models and are mutable even for a single recorder: recorder players may use three or more fingerings for the same note along with partial covering of the holes to achieve proper intonation, in coordination with the breath or in faster passages where some fingerings are unavailable. This chart is a general guide, but by no means a definitive or complete fingering chart for the recorder, an impossible task. Rather, it is the basis for a much more complex fingering system, which is still being added to today.

Some fonts show miniature glyphs of complete recorder fingering charts in TrueType format. Because there are no Unicode values for complete recorder fingering charts, these fonts are custom encoded.

The earliest extant duct flutes date to the neolithic. They are found in almost every musical tradition around the world. Recorders are distinguished from other duct flutes primarily by the thumb hole, which is used as an octaving vent, and the presence of seven finger holes, although classification of early instruments has proved controversial. The performing practice of the recorder in its earliest history is not well documented, owing to the lack of surviving records from the time.

Our present knowledge of the structure of recorders in the Middle Ages is based on a small number of instruments preserved and artworks, or iconography, from the period.

Surviving instruments from the Middle Ages are heterogeneous.

The first medieval recorder discovered was a fruitwood instrument ("Dordrecht recorder") excavated in 1940 from the moat surrounding the castle "Huis te Merwede" ("House on the Merwede") near the town of Dordrecht in the Netherlands. The castle was only inhabited from 1335 to 1418. As the area was not disturbed until the modern excavation, the recorder has been dated to the period of occupation of the castle. The instrument has a cylindrical bore about in diameter and is about long with a vibrating air column of about . The block has survived, but the labium is damaged, making the instrument unplayable. The instrument has tenons on both ends of the instrument, suggesting the presence of now lost ferrules or turnings. Uncertainty regarding the nature of these fittings has hindered reconstruction of the instrument's original state.

A second, structurally different instrument ("GÃ¶ttingen recorder") was discovered in 1987 in an archaeological excavation of the latrine of a medieval house in GÃ¶ttingen, Germany. It has been dated to between 1246 and 1322. It is fruitwood in one piece with turnings, measuring about long. It has a cylindrical bore about at the highest measurable point, narrowing to between the first and second finger holes, to between the second and third finger holes, and contracting to at the seventh hole. The bore expands to at the bottom of the instrument, which has a bulbous foot. Unusually, the finger holes taper conically outwards, the opposite of the undercutting found in Baroque recorders. The top of the instrument is damaged: only a cut side of the windway survives, and the block has been lost. A reconstruction by Hans Reiners has a strident, penetrating sound rich in overtones and has a range of two octaves. With the thumb hole and the first three finger holes covered, the reconstruction produces a pitch ca. 450Â Hz.

In the 21st century, a number of other instruments and fragments dated to the medieval period have come to light. These include a 14th-century fragment of a headjoint excavated in Esslingen, Germany ("Esslingen fragment"); a birch instrument dated to the second half of the 14th century unearthed in Tartu, Estonia ("Tartu recorder"); and a fruitwood instrument dated to the 15th century, found in ElblÄg, Poland ("ElblÄg recorder").

Common features of the surviving instruments include: a narrow cylindrical bore (except the GÃ¶ttingen recorder); a doubled seventh hole for the little finger of the lower hand to allow for right- or left- handed playing (except the Tartu recorder); a seventh hole that produces a semitone instead of a tone; and a flat or truncated head, instead of the narrow beak found on later instruments. Additionally, the Esslingen fragment has turnings similar to the GÃ¶ttingen recorder. No complete instruments larger than have survived, although the Esslingen fragment may represent a larger recorder.

The widely spaced doubled seventh hole persisted in later instruments. According to Virdung (1511), the hole that was not used was plugged with wax. It was not until the Baroque period, when instruments with adjustable footjoints were developed, that widely spaced double holes became obsolete.

The classification of these instruments is primarily complicated by the fact that the seventh hole produces a semitone instead of a tone. As a result, chromatic fingerings are difficult, and require extensive half-holing. These instruments share similarities with the six holed flageolet, which used three fingers on each hand and had no thumb hole. Anthony Rowland-Jones has suggested that the thumb hole on these early flutes was an improvement upon the flageolet to provide a stronger fingering for the note an octave above the tonic, while the seventh finger hole provided a leading tone to the tonic. As a result, he has suggested that these flutes should be described as improved flageolets, and has proposed the condition that true recorders produce a tone (rather than a semitone) when the seventh finger is lifted.

Controversy aside, there is little question that these instruments are at least precursors to later instruments that are indisputably recorders. Because there is sparse documentary evidence from the earliest history of the instrument, such questions may never be resolved. Indeed, historically there was no need for an all inclusive definition that encompassed every form of the instrument past and present.

Recorders with a cylindrical profile are depicted in many medieval paintings, however their appearance does not easily correspond to the surviving instruments, and may be stylized. The earliest depictions of the recorder are probably in "The Mocking of Christ" from the monastery church of St George in Staro NagoriÄano near Kumanovo, Macedonia (the painting of the church began in 1315) in which a man plays a cylindrical recorder; and the center panel of the "Virgin and Child" attributed to Pedro (Pere) Serra (c. 1390), painted for the church of S. Clara, Tortosa, now in the Museu Nacional d'Art de Catalunya, Barcelona, in which a group of angels play musical instruments around the Virgin Mary, one of them playing a cylindrical recorder.

Starting in the Middle Ages, angels have frequently been depicted playing one or more recorders, often grouped around the Virgin, and in several notable paintings trios of angels play recorders. This is perhaps a sign of the trinity, although the music must have often been in three parts.

No music marked for the recorder survives from prior to 1500. Groups of recorder players or recorder playing angels, particularly trios, are depicted in paintings from the 15th century, indicating the recorder was used in these configurations, as well as with other instruments. Some of the earliest music must have been vocal repertory.

Modern recorder players have taken up the practice of playing instrumental music from the period, perhaps anachronistically, such as the monophonic estampies from the Chansonnier du Roi (13th), Add MS 29987 (14th or 15th), or the Codex Faenza (15th), and have arranged keyboard music, such as the estampies from the Robertsbridge codex (14th), or the vocal works of composers like Guillaume de Machaut and Johannes Ciconia for recorder ensembles.

In the 16th century, the structure, repertoire, and performing practice of the recorder is better documented than in prior epochs. The recorder was one of the most important wind instruments of the Renaissance, and many instruments dating to the 16th century survive, including some matched consorts. This period also produced the first extant books describing the recorder, including the treatises of Virdung (1511), Agricola (1529), Ganassi (1535), Cardano (c1546), Jambe de Fer (1556), and Praetorius (1619). Nonetheless, understanding of the instrument and its practice in this period is still developing.

In the 16th century, the recorder saw important developments in its structure. As in the recorders of the Middle Ages, the etiology of these changes remains uncertain, development was regional and multiple types of recorder existed simultaneously. Our knowledge is based on documentary sources and surviving instruments.

Far more recorders survive from the Renaissance than from the Middle Ages. Most of the surviving instruments from the period have a wide, cylindrical bore from the blockline to the uppermost fingerhole, an inverted conical portion down to around the lowest finger hole (the "choke"), then a slight flare to the bell. Externally, they have a curved shape similar to the bore, with a profile like a stretched hourglass. Their sound is warm, rich in harmonics, and somewhat introverted. Surviving consorts of this type, identified by their makers marks, include those marked "HIER Sâ¢" or "HIEâ¢S" found in Vienna, Sibiu and Verona; and those marked with variations on a rabbit's footprint, designated "!!" by Adrian Brown, which are dispersed among various museums. The pitch of these recorders is often generally grouped around AÂ =Â 466Â Hz, however little pitch standardization existed in the period. This type of recorder is described by Praetorius in "De Organographia" (1619). A surviving consort by "!!" follows the exact size configuration suggested by Praetorius: stacked fifths up from the basset in F, and down a fifth then a fourth to bass in B and great bass in F. Instruments marked "HIER Sâ¢" or "HIEâ¢S" are in stacked fifths from great bass in F to soprano in E. Many of these instruments are pitched around AÂ =Â 440Â Hz or AÂ =Â 466Â Hz, although pitch varied regionally and between consorts.

The range of this type is normally an octave plus a minor 7th, but as remarked by Praetorius (1619) and demonstrated in the fingering tables of Ganassi's "Fontegara" (1535), experienced players on particular instruments were capable of playing up to a fourth or even a seventh higher (see ). Their range is more suitable for the performance of vocal music, rather than purely instrumental music. This type is the recorder typically referred to as the "normal" Renaissance recorder, however this modern appellation does not fully capture the heterogeneity of instruments of the 16th century.

Another surviving Renaissance type has a narrow cylindrical bore and cylindrical profile like the medieval exemplars but a choke at the last hole. The earliest surviving recorders of this type were made by the Rafi family, instrument makers active in Lyons in Southern France in the early 16th century. Two recorders marked "C.RAFI" were acquired by the Accademia Filarmonica, Bologna in 1546, where they remain today. A consort of recorders or similar make, marked "P.GRE/C/E," was donated to the Accademia in 1675, expanding the pair marked "C.RAFI". Other recorders by the Rafi family survive in Northern Europe, notably a pair in Brussels. It is possible that Grece worked in the Rafi workshop, or was a member of the Rafi family. The pitch of the Rafi/Grece instruments is around AÂ =Â 440Â Hz. They have a relatively quiet sound with good pitch stability favoring dynamic expression.

In 1556, French author Philibert Jambe de Fer gave a set of fingerings for hybrid instruments like the Rafi and Grece instruments that give a range of two octaves. Here, the 15th was now produced, as on most later recorders, as a variant of the 14th instead of as the fourth harmonic of the tonic, as in Ganassi's tables.

The first two treatises of the 16th century show recorders that differ from the surviving instruments dating to the century: these are Sebastian Virdung's (b. 1465?) "Musica getutscht" (1511), and Martin Agricola's (1486â1556) similar "Musica instrumentalis deudsch" (1529), published in Basel and Saxony respectively.

"Musica Getutscht", the earliest printed treatise on western musical instruments, is an extract of an earlier, now lost, manuscript treatise by Virdung, a chaplain, singer, and itinerant musician. The printed version was written in a vernacular form of Early New High German, and was aimed at wealthy urban amateur musicians: the title translates, briefly, as "Music, translated into German ... Everything there is to know about [music] â made simple." When a topic become too complex for Virdung to discuss briefly, he refers the reader to his lost larger work, an unhelpful practice for modern readers. While the illustrations have been called "maddeningly inaccurate" and his perspectives quirky, Virdung's treatise gives us an important source on the structure and performing practice of the recorder in northern Europe in the late 15th and early 16th centuries.

The recorders described by Virdung have cylindrical profiles with flat heads, narrow windows and long ramps, ring-like turnings on the feet, and a slight external flare at the bell (above, far left and middle left). Virdung depicts four recorders together: a "baÃcontra" or "bassus" (basset) in F with an anchor shaped key and a perforated fontanelle, two tenors in C and a "discantus" (alto) in G. According to Virdung, the configurations FâCâCâG or FâCâGâG should be used for four-part music, depending on the range of the bass part. As previously mentioned, the accuracy of these woodcuts cannot be verified as no recorders fitting this description survive. Virdung also provides the first ever fingering chart for a recorder with a range of an octave and a seventh, though he says that the bass had a range of only an octave and sixth. In his fingering chart, he numbers which fingers to lift rather than those to put down and, unlike in later charts, numbers them from bottom (1) to top (8). His only other technical instruction is that the player must blow into the instrument and "learn how to coordinate the articulations ... with the fingers".

Martin Agricola's "Musica instrumentalis Deudsch" ("A German instrumental music, in which is contained how to learn to play ... all kinds of ... instruments"), written in rhyming German verse (ostensibly to improve the understanding and retention of its contents), provides a similar account and copies most of its woodcuts directly from "Getutscht". Agricola also calls the tenor "altus," mistakenly depicting it as a little smaller than the tenor in the woodcut (above, middle right). Like Virdung, Agricola takes it for granted that recorders should be played in four-part consorts. Unlike "Getutscht", which provides a single condensed fingering chart, Agricola provides separate, slightly differing, fingering charts for each instrument, leading some to suppose that Agricola experimented on three different instruments, rather than copying the fingerings from one size to the other two. Agricola adds that graces ("Mordanten"), which make the melody "subtil", must be learned from a professional ("Pfeiffer"), and that the manner of ornamentation ("Coloratur") of the organist is best of all. A substantial 1545 revision of "Musica Instrumentalis" approvingly mentions the use of vibrato ("zitterndem Wind") for woodwind instruments, and includes an account of articulation, recommending the syllables "de" for semiminims and larger, "di ri" for semiminims and smaller, and the articulation "tell ell ell ell el le", which he calls the "flutter-tongue" "(flitter zunge)" for the smallest of note values, found in "passagi (Colorirn)".

The next treatise comes from Venice: Silvestro Ganassi dal Fontego's (1492âmid-1500s) "Opera Intitulata Fontegara" (1535), which is the first work to focus specifically on the technique of playing the recorder, and perhaps the only historical treatise ever published that approaches a description of a professional or virtuoso playing technique. Ganassi was a musician employed by the Doge and at the Basilica di San Marco at the time of the work's publication, and indication of his high level of accomplishment, and later wrote two works on the playing the viol and the violone, although he does not mention being employed by the Doge after "Fontegara".

"Fontegara" can be broadly divided into two parts: the first concerns the technique of playing the recorder, the second demonstrated divisions (regole, passagi, ornaments), some of great complexity, which the player may use to ornament a melody or, literally, "divide" it into smaller notes. In all aspects, Ganassi emphasizes the importance of imitating the human voice, declaring that "the aim of the recorder player is to imitate as closely as possible all the capabilities of the human voice", maintaining that the recorder is indeed able to do this. For Ganassi, imitation of the voice has three aspects: "a certain artistic proficiency," which seems to be the ability to perceive the nature of the music, prontezza (dexterity or fluency), achieved "by varying the pressure of the breath and shading the tone by means of suitable fingering," and galanteria (elegance or grace), achieved by articulation, and by the use of ornaments, the "simplest ingredient" of them being the trill, which varies according to the expression.

Ganassi gives fingering tables for a range of an octave and a seventh, the standard range also remarked by Praetorius, then tells the reader that he has discovered, through long experimentation, more notes not known to other players due to their lack of perseverance, extending the range to two octaves and a sixth. Ganassi gives fingerings for three recorders with different makers marks, and advises the reader to experiment with different fingerings, as recorders vary in their bore. The makers mark of one of the recorders, in the form of a stylized letter "A", has been associated with the Schnitzer family of instrument makers in Germany, leading Hermann Moeck to suppose that Ganassi's recorder might have been Northern European in origin. (see also Note on "Ganassi" recorders)

Ganassi uses three basic kinds of syllables "te che", "te re", and "le re" and also varies the vowel used with the syllable, suggesting the effect of mouth shape on the sound of the recorder. He gives many combinations of these syllables and vowels, and suggests the choice of the syllables according to their smoothness, "te che" being least smooth and "le re" being most so. He does not, however, demonstrate how the syllables should be used to music.

Most of the treatise consists of tables of diminutions of intervals, small melodies and cadences, categorized by their meter. These several hundred divisions use quintuplets, septuplets, note values from whole notes to 32nd notes in modern notation, and demonstrate immense variety and complexity.

The frontispiece to "Fontegara" shows three recorder players play together with two singers. Like Agricola and Virdung, Ganassi takes for granted that recorders should be played in groups of four, and come in three sizes: F, C and G. He makes a distinction between solo playing and ensemble playing, noting that what he has said is for solo players, and that when playing with others, it is most important to match them. Unfortunately, Ganassi gives only a few ornamented examples with little context for their use. Nonetheless, Ganassi offers a tantalizing glimpse at a highly developed professional culture and technique of woodwind playing that modern players can scarcely be said to have improved upon.

Girolamo Cardano's (also Jerome Cardan, 1501â1576) "De Musica" was written around 1546, but not published until 1663 when it was published along with other works by Cardan, who was an eminent philosopher, mathematician and physician as well as a keen amateur recorder player who learned from a professional teacher, Leo Oglonus, as a child in Milan.

His account corroborates that of Ganassi, using the same three basic syllables and emphasizing the importance of breath control and ornamentation in recorder playing, but also documents several aspects of recorder technique otherwise undocumented until the 20th century. These include multiple techniques using the partial closing of the bell: to produce a tone or semitone below the tonic, and to change semitones into dieses (half semitones), which he says can also be produced by "repercussively bending back the tongue". He also adds that the position of the tongue, either extended or turned up towards the palate, can be used to improve, vary, and color notes. He is the first to differentiate between the amount of the breath (full, shallow, or moderate) and the force (relaxed or slow, intense, and the median between them) as well as the different amount of air required for each instrument, and describes a trill or vibrato called a "vox tremula" in which "a tremulous quality in the breath" is combined with a trilling of the fingers to vary the interval from anything between a major third and a diesis. He is also the first writer to mention the recorder in D ("discantus"), which he leaves unnamed.

Composer and singer Philibert Jambe de Fer ( 1515 1566) was the only French author of the 16th century to write about the recorder, in his "Epitome musical". He complains of the French name for the instrument, "fleutte Ã  neuf trouz" ("flute with nine holes") as, in practice, one of the lowermost holes must be plugged, leaving only eight open holes. He prefers "fleute d'Italien" or the Italian "flauto". His fingering chart is notable for two reasons, first for describing fingerings with the 15th produced as a variant on the 14th, and for using the third finger of the lower hand as a buttress finger, although only for three notes in the lower octave. (see also Renaissance structure)

Aurelio Virgiliano's "Il dolcimelo" ( 1600) presents ricercars intended for or playable on the recorder, a description of other musical instruments, and a fingering chart for a recorder in G similar to Jambe de Fer's.

The "Syntagma musicum" (1614â20) of Michael Praetorius (1571â1621) in three volumes (a fourth was intended but never finished) is an encyclopedic survey of music and musical instruments. Volume II, "De Organographia" (1619) is of particular interest for its description of no fewer than eight sizes of recorder ("klein FlÃ¶tlein" or "exilent" in G, "discant" in C or D, "alt" in G, "tenor" in C, "basset" in F, "bass" in B, and "grossbass" in F) as well as the four-holed "gar kleine PlockflÃ¶tlein".

Praetorius was the first author to explain that recorders can confuse the ear into believing that they sound an octave lower than pitch, which phenomenon has more recently been explained in relation to the recorder's lack of high harmonics. He also shows the different "registers" of consort possible, 2â² (discant, alt, and tenor), 4â² (alt, tenor, and basset), and 8â² (tenor, basset, and bass) (see also Nomenclature). Additionally, he proposed cutting the recorder between the beak and the first finger hole to allow for a kind of tuning slide to raise or lower its pitch, similar to the Baroque practice of adjusting a recorder's pitch by "pulling out" the top joint of the recorder.

The recorders described in Praetorius are of the "stretched hourglass" profile (see above, far right). He gives fingerings like those of Ganassi, and remarks that they normally have a range of an octave and a sixth, although exceptional players could extend that range by a fourth.

Some paintings from the 14th and 15th centuries depict musicians playing what appear to be two end-blown flutes simultaneously. In some cases, the two flutes are evidently disjoint, separate flutes of similar make, played angled away from each other, one pipe in each hand. In others, flutes of the same length have differing hand positions. In a final case, the pipes are parallel, in contact with each other, and differ in length. While the iconographic criteria for a recorder are typically a clearly recognizable labium and a double handed vertical playing technique, such criteria are not prescriptive, and it is uncertain whether any of these depictions should be considered a single instrument, or constitute a kind of recorder. The identification of the instrument depicted is further complicated by the symbolism of the aulos, a double piped instrument associated with the satyr Marsyas of Greek mythology.

An instrument consisting of two attached, parallel, end-blown flutes of differing length, dating to the 15th or 16th century, was found in poor condition near All Souls College in Oxford. The instrument has four holes finger-holes and a thumb hole for each hand. The pipes have an inverted conical "choke" bore (see Renaissance structure). Bob Marvin has estimated that the pipes played a fifth apart, at approximately C and G. The instrument is sui generis. Although the instrument's pipes have thumb holes, the lack of organological precedent makes classification of the instrument difficult. Marvin has used the terms "double recorder" and the categorization-agnostic "flauto doppio" (double flute) to describe the Oxford instrument.

Marvin has designed a "flauto doppio" based on the Oxford instrument, scaled to play at F and C. Italian recorder maker Francesco Livirghi has designed a double recorder or "flauto doppio" with connected, angled pipes of the same length but played with different hand positions, based on iconographic sources. Its pipes play at F and B. Both instruments use fingerings of the makers' design.

In the 1970s, when recorder makers began to make the first models of recorders from the 16th and 17th centuries, such models were not always representative of the playing characteristics of the original instruments. Especially notable is Fred Morgan's much copied "Ganassi" model, based loosely on an instrument in the Vienna Kunsthistorisches museum (inventory number SAM 135), was designed to use the fingerings for the highest notes in Ganassi's tables in Fontegara. As Morgan knew, these notes were not in standard use; indeed Ganassi uses them in only a few of the hundreds of diminutions contained in Fontegara. Historically, such recorders did not exist as a distinct type, and the fingerings given by Ganassi were those of a skilled player particularly familiar with his instruments. When modern music is written for 'Ganassi recorders' it means this type of recorder.

Recorders were probably first used to play vocal music, later adding purely instrumental forms like dance music to their repertoire. Much of the vocal music of the 15th, 16th and 17th centuries can be played on recorder consorts, and as illustrated in treatises from Virdung to Praetorius, the choice appropriate instruments and transpositions to play vocal music was common practice in the Renaissance. Additionally, some collections such as those of Pierre Attaingnant and Anthony Holborne, indicate that their instrumental music was suitable for recorder consorts. This section first discusses repertoire marked for the recorder, then briefly, other repertoire played on recorder.

In 1505 Giovanni Alvise, a Venetian wind player, offered Francesco Gonzaga of Mantua a motet for eight recorders, however the work has not survived.

Pierre Attaingnant's ( 1528â1549) "Vingt & sept chansons musicales a quatre parties a la fleuste dallement...et a la fleuste a neuf trous" (1533) collects 28 (not 27, as in the title) four-part instrumental motets, nine of which he says were suitable for performance on flutes ("fleustes dallement", German flutes), two on recorders ("fleuestes a neuf trous," Nine holed flutes, "recorders"), and twelve suitable for both. Of the twelve marked for both, seven use "chiavi naturali", or low-clefs typically used for recorders, while the others use the "chiavette" clefs used in the motets marked for flutes. Hence, the seven notated in "chiavi naturali" could be considered more appropriate for recorders. "Vingt et sept chansons" is the first published music marked for a recorder consort. Earlier is a part for Jacobus Barbireau's song "Een vrolic wesen", apparently for recorder, accompanying the recorder fingering chart in "Livre plaisant et tres utile..." (Antwerp, 1529), a partial French translation of Virdung's "Musica getutscht".

Jacques Moderne's "S'ensuyvent plusieurs basses dances tant communes que incommunes" published in the 1530s, depicts a four-part recorder consort like those described in Virdung, Agricola, Ganassi and others, however the dances are not marked for recorders. His "Musique de joye" (1550) contains ricercares and dances for performance on "espinetes, violons & fleustes".

In 1539â40, Henry VIII of England, also a keen amateur player (see Cultural significance), imported five brothers of the Bassano family from Venice to form a consort, expanded to six members in 1550, forming a group that maintained an exceptional focus on the recorder until at least 1630 when the recorder consort was combined with the other wind groups. Most wind bands consisted of players playing sackbutts, shawms, and other loud instruments doubling on recorder. Some music probably intended for this group survives, including dance music by Augustine and Geronimo Bassano from the third quarter of the 16th century, and the more elaborate fantasias of Jeronimo Bassano ( 1580), four in five parts and one in six parts. Additionally, the Fitzwilliam wind manuscript ("GB-Cfm" 734) contains wordless motets, madrigals and dance pieces, including some by the Bassano family, probably intended for a recorder consort in six parts.

The English members of the Bassano family, having originated in Venice, were also probably familiar with the vocal style, advanced technique, and complex improvised ornamentation described in Ganassi's "Fontegara", and they were probably among the recorder players who Ganassi reports having worked and studied with: when they were brought to England, they were regarded as some of the best wind players in Venice. While most of the music attributed to the consort uses only a range of a thirteenth, it is possible that the Bassano's were familiar with Ganassi's extended range.

Recorders were also played with other instruments, especially in England, where it was called a mixed consort or "broken consort".

Other 16th century composes whose instrumental music can be played well on recorder consorts include
Other notable composers of the Renaissance whose music may be played on the recorder include

The recorder achieved great popularity in the 16th century, and is one of the most common instruments of the Renaissance. From the 15th century onwards, paintings show upper-class men and women playing recorder, and Virdung's didactic treatise "Musica getutscht" (1511), the first of its kind, was aimed at the amateur (see also Documentary evidence). Famously, Henry VIII of England was an avid player of the recorder, and at his death in 1547 an inventory of his possessions included 76 recorders in consorts of various sizes and materials. Some Italian paintings from the 16th-century show aristocracy of both sexes playing the recorder, however many gentlemen found it unbecoming to play because it uses the mouth, preferring the lute and later the viol.

At the turn of the 17th century, playwright William Shakespeare famously referenced the recorder in his most substantial play, "The Tragedy of Hamlet, Prince of Denmark," creating an extended metaphor between manipulation and playing a musical instrument. Poet John Milton also referenced the recorder in his most famous work, the epic poem Paradise Lost published in 1667, in which the recently fallen angels in Hell "move / in perfect phalanx to the Dorian mood / of flutes and soft recorders," recalling both the affect of the Dorian mode as the mode of calling to action, and the use of flutes by the Spartans of ancient Greece, although the specification of the recorder is anachronistic in this context.

Several changes in the construction of recorders took place in the 17th century, resulting in the type of instrument generally referred to as "Baroque" recorders, as opposed to the earlier "Renaissance" recorders. These innovations allowed baroque recorders to possess a tone regarded as "sweeter" than that of the earlier instruments, at the expense of a reduction in volume, particularly in the lowest notes.

The evolution of the Renaissance recorder into the Baroque instrument is generally attributed to the Hotteterre family, in France. They developed the ideas of a more tapered bore, bringing the finger-holes of the lowermost hand closer together, allowing greater range, and enabling the construction of instruments in several jointed sections. The last innovation allowed more accurate shaping of each section and also offered the player minor tuning adjustments, by slightly pulling out one of the sections to lengthen the instrument.

The French innovations were taken to London by Pierre Bressan, a set of whose instruments survive in the Grosvenor Museum, Chester, as do other examples in various American, European and Japanese museums and private collections. Bressan's contemporary, Thomas Stanesby, was born in Derbyshire but became an instrument maker in London. He and his son (Thomas Stanesby junior) were the other important British-based recorder-makers of the early 18th century.

In continental Europe, the Denner family of Nuremberg were the most celebrated makers of this period.

The baroque recorder produces a most brilliant and projecting sound in the second octave, which is more facile and extended than that of earlier recorders, while the lowest notes in its range are relatively weak. Composers such as Bach, Telemann and Vivaldi exploit this property in their concertos for the instrument.

Measured from its lowest to its highest playable note, the baroque alto recorder has a range of at most two octaves and a fifth with many instruments having a smaller range. Even the most developed instruments of the period, however, cannot produce the augmented tonic, third and fourth of the third octave. Notably, Georg Philipp Telemann's concerto TWV 51:F1 makes use some of these notes in the third octave, posing significant technical challenges to the player, perhaps requiring the covering of the bell or other unusual techniques.

During the baroque period, the recorder was traditionally associated with pastoral scenes, miraculous events, funerals, marriages, and amorous scenes. Images of recorders can be found in literature and artwork associated with all of these. Purcell, J.Â S. Bach, Telemann, and Vivaldi used the recorder to suggest shepherds and imitate birds in their music.

Although the recorder achieved a greater level of standardization in the Baroque than in previous periods, indeed it is the first period in which there was a "standard" size of recorder, ambiguous nomenclature and uncertain organological evidence have led to controversy regarding which instruments should be used in some "flute" parts from the period.

The concertino group of Bach's fourth Brandenburg Concerto in G major, BWV 1049, consists of a "violono principale", and , with ripieno strings. His later harpsichord transcription of this concerto, BWV 1057, lowers the key by a tone, as in all of Bach's harpsichord transcriptions, and is scored for solo harpsichord, two "fiauti Ã  bec" and ripieno strings. The desired instrument for the "fiauti d'echo" parts in BWV 1049 has been a matter of perennial musicological and organological debate for two primary reasons: first, the term "fiauto d'echo" is not mentioned in dictionaries or tutors of the period; and second, the first "fiauto" part uses F#6, a note which is difficult to produce on a Baroque alto recorder in F4.

The instrumentation of BWV 1057 is uncontroversial: "fiauti Ã  bec" unambiguously specifies recorders, and both parts have been modified to fit comfortably on altos in F4, avoiding, for example, an unplayable Eb4 in the second "fiauto" that would have resulted from a simple transposition of a tone.

For the first and last movements of the concerto, two opinions predominate: first, that both recorder parts should be played on alto recorders in F4; and second, that the first part should be played on an alto recorder in G and the second part on an alto in F. Tushaar Power has argued for the alto in G4 on the basis that Bach uses the high F#6, which can be easily played on an alto in G4, but not the low F4, a note not playable on the alto in G4. He corroborates this with other alto recorder parts in Bach's cantatas. Michael Marissen reads the repertoire differently, demonstrating that in other recorder parts, Bach used both the low F4 and F#6, as well as higher notes. Marissen argues that Bach was not as consistent as Power asserts, and that Bach would have almost certainly had access to only altos in F. He corroborates this with examinations of pitch standards and notation in Bach's cantatas, in which the recorder parts are sometimes written as transposing instruments to play with organs that sounded as much as a minor third above written pitch. Marissen also reads Bach's revisions to the recorder parts in BWV 1057 as indicative of his avoidance of F#6 in BWV 1049, a sign that he only used the difficult note when necessary in designing the part for an alto recorder in F4. He posits that Bach avoided F#6 in BWV 1049, at the cost of inferior counterpoint, reinstating them as E6 in BWV 1057.

In the second movement, breaking of beaming in the "fiauto" parts, markings of "f" and "p," the fermata over the final double bar of the first movement, and the 21 bars of rest at the beginning of the third have led some musicologists to argue that Bach intended the use of "echo flutes" distinct from normal recorders in the second movement in particular. The breaking of beaming could be an indication of changes in register or tonal quality, the rests introduced to allow the players time to change instruments, and the markings of "f" and "p" further indicative of register or sound changes. Marissen has demonstrated that the "f" and "p" markings probably indicated tutti and solo sections rather than loud and soft ones.

A number of instruments other than normal recorders have been suggested for the "fiauto d'echo". One of the earliest proposed alternatives, by Thurston Dart, was the use of double flageolets, a suggestion since revealed to be founded on unsteady musicological grounds. Dart did, however, bring to light numerous newspaper references to Paisible's performance on an "echo flute" between 1713 and 1718. Another contemporary reference to the "echo flute" is in Etienne LouliÃ©'s "Elements ou principes de musique" (Amsterdan, 1696): "Les sons de deux flutes d'echo sont differents, parce que l'un est fort, & que l'autre est foible" (The sounds of two echo flutes are different, because one is strong and the other is weak). LouliÃ© is unclear on why one would need two echo flutes to play strongly and weakly, and on why it is that echo flutes differ. Perhaps the echo flute was composed in two halves: one which plays strongly, the other weakly? On this we can only speculate.

Surviving instruments which are candidates for echo flutes include an instrument in Leipzig which consists of two recorders of different tonal characteristics joined together at the head and footjoints by brass flanges. There is also evidence of double recorders tuned in thirds, but these are not candidates for the "fiauto" parts in BWV 1049.

Vivaldi wrote three concertos for the , possibly for performance by students at the Ospedale della PietÃ  in Venice, where he taught and composed in the early 18th century. They feature virtuosic solo writing, and along with his concerto RV 441 and trio sonata RV 86 are his most virtuosic recorder works. They each survive a single hastily written manuscript copy, each titled "Con.to per Flautino" (Concerto for little flute) with the additional note "Gl'istrom.ti trasportati alla 4a" (The instruments transpose by a fourth) in RV 443 and "Gl'istrom.ti alla 4ta Bassa" (The instruments lower by a fourth) in RV 445. The three concertos RV 443, 444, and 445 are notated in C major, C major and A minor respectively. Also of note is the occasional use of notes outside the normal two octave compass of the recorder: the range of the solo sections is two octaves from notated F4 to notated F6, however there is a single notated C4 in the first movement of RV 444, a notated E4 in a tutti section in the first movement of RV 443 and low E4 in multiple tutti sections of RV 445.

A number of possible "flautini" have been proposed as the instrument intended for the performance of these concertos. The first suggestion was the use of the one keyed piccolo, or another small transverse flute, however such instruments had fallen out of use in Venice by the generally accepted time of composition of these concertos in the 1720s, and this opinion is no longer considered well supported. Another suggestion, first proposed by Peter Thalheimer, is the "french" flageolet (see Flageolets below) in G5, which was notated in D4, appearing a fourth lower, possibly explaining the note in the margins of RV 443 and RV 445 ("Gl'istromti transportati alla 4a") and supported by Bismantova (1677 rev. 1694) and Bonanni (1722) which equate "flautino" to the flageolet. However this suggestion has been opposed by the presence of notated F and F which are not within the typical compass of the flageolet, although they may be produced through the covering of the bell, sometimes combined with underblowing, as attested by theorists as early as Cardano (c.Â 1546) and as late as Bellay (c.Â 1800).

Two instruments are conventionally accepted today for the performance of these concertos, the sopranino recorder, notated like an alto but sounding an octave higher, and the soprano recorder, following the instruction to transpose the parts down by a fourth. Winfried Michel was first to argue in favor of the soprano recorder in 1983, when he proposed to take Vivaldi at his word and transpose the string parts down a fourth and play the "flautino" part on a soprano recorder in C5 (also "fifth-flute") using the English practice of notating such flutes as transposing instruments using the fingerings of an alto recorder. Michel notes that this transposition allows for the use of the violins' and viola's lowest strings (in sections where they provide the accompaniment without bass) and the lowest two notes of the 'cello. He attributes the presence of notes not in the recorder's normal compass to Vivaldi's haste, noting that these notes do not appear in the solo sections. He has edited editions of RV 443 and RV 445 for soprano recorder in G major and E minor respectively. Federico Maria Sardelli concurs with Michel in supposing that the margin note was intended to allow the performance of the concertos on the soprano recorder on a specific occasion, however concludes that they were probably written for the sopranino recorder in F5, noting that small transverse flutes had fallen out of use in Italy by Vivaldi's time, the paucity of flageolets in Italy, the range of the parts, and uses of the flautino in vocal arias.

The recorder was little used in art music of the Classical and Romantic periods. Researchers have long debated why this change occurred, and to what extent the recorder remained use in the late 18th century, and later the 19th century. A significant question in this debate is which, if any, duct flutes of this period are recorders or successors to recorders.

The recorder work of the latter half of the 18th century most known today is probably a trio sonata by C.Â P.Â E. Bach, Wq.163, composed in 1755 an arrangement of a trio sonata for two violins and continuo, scored for the unusual ensemble of viola, bass recorder and continuo. This work is also notable for being perhaps the only significant surviving historical solo work for bass recorder. Also of note are the works of Johann Christoph Schultze ( 1733â1813), who wrote two concertos for the instrument, one in G major and another in B major, written around 1740. The last occurrences of the recorder in art music are apparently by Carl Maria von Weber in "Peter Schmoll und seine Nachbarn" (1801) and "Kleiner Tusch" (1806). Hector Berlioz may have intended "La fuite en Egypte" from "L'enfance du Christ" (1853) for the instrument. Donizetti owned three recorders.

Many reasons supporting the conventional view that the recorder declined have been proposed. The first significant explanation for the recorder's decline was proposed by Waitzman (1967), who proposed six reasons:
In the Baroque, the majority of professional recorder players were primarily oboists or string players. For this reason, the number of professional exponents of the recorder was smaller than that of other woodwinds.

Others attribute the decline of the recorder in part to the flute innovators of the time, such as Grenser, and Tromlitz, who extended the transverse flute's range and evened out its tonal consistency through the addition of keys, or to the supposedly greater dynamic range and volume of the flute. Similar developments occurring in many other orchestral instruments to make them louder, increase their range, and increase their tonal consistency did not simultaneously occur in the case of the recorder.

A complementary view recently advanced by Nikolaj Tarasov is that the recorder, rather than totally disappearing, evolved in similar ways to other wind instruments through the addition of keys and other devices, and remained in use throughout the 19th century, with its direct descendant's popularity overlapping with the late 19th and early 20th century recorder revival. Support for this view rests on the organological classification of some 19th century duct flutes as recorders. For more on this question, see "Other duct flutes".

Duct flutes remained popular even as the recorder waned in the 18th century. As in the instrument's earliest history, questions of the instrument's quiddity are at the forefront of modern debate. The modification and renaming of recorders in the 18th century in order to prolong their use, and the uncertainty of the extent of the recorder's use the late 18th and early 19th centuries have fueled these debates. Some recent researchers contend that some 19th century duct flutes are actually recorders. This article briefly discusses the duct flutes presented as successors to the recorder: the English flageolet and the csakan, which were popular among amateurs in the second half of the 18th century, and the whole of the 19th.

The word "flageolet" has been used since the 16th century to refer to small duct flutes, and the instrument is sometimes designated using general terms such as "flautino" and "flauto piccolo", complicating identification of its earliest form. It was first described by Mersenne in "Harmonie universelle" (1636) as having four fingers on the front, and two thumb holes on the back, with lowest note C6 and a compass of two octaves. Like the recorder, the upper thumb hole is used as an octaving vent. Flageolets were generally small flutes, however their lowest note varies. They were initially popular in France, and it is from there that the flageolet first arrived in England in the seventeenth century, becoming a popular amateur instrument, as the recorder later did. Indeed, when the recorder was introduced to England it was presented as an easy instrument for those who already played the flageolet, and the earliest English recorder tutors are notated in the flageolet tablature of the time, called "dot-way". Notably, the diarist and naval administrator Samuel Pepys (1633â1703) and his wife were both amateur players of the flageolet, and Pepys was later an amateur recorder player.

Starting in the early 1800s, a number of innovations to the flageolet were introduced, including the addition of keys to extend its range and allow it to more easily play accidentals. They also included novel solutions to the problem of condensation: most commonly, a sea sponge was placed inside the wind chamber (the conical chamber above the windway) to soak up moisture, while novel solutions like the insertion of a thin wooden wedge into the windway, the drilling of little holes in the side of the block to drain condensation and a complex system for draining condensation through a hollowed out block developed, were also developed. Around 1800 in England, the recorder ("English flute," see Name) came to be called an "English flageolet," appropriating the name of the more fashionable instrument. From at least this time to the present, the flageolet in its first form has been called the French flageolet to differentiate it from the so-called English flageolet.

From around 1803, when the London instrument maker William Bainbridge obtained a number of patents for improvements to the English flageolet, instruments were often referred as "improved" or "patent" flageolets with little reference to how they actually differed from their predecessors. In this period, the instrument had six finger holes and single thumb hole, and had as many as six keys. Tarasov reports that the English flageolets of the late 18th century had six finger holes and no thumb hole, and later regained the thumb hole seventh finger hole (see above, right). The English flageolet never reached the level of popularity that the "French" flageolet enjoyed in the 19th century, possibly because the latter instrument was louder. Both remained popular until the beginning of the 20th century.

A significant amount of music was written for the flageolet in the 19th century, like the etudes of Narcisse Bousquet although much of it was directed at amateurs.

English flageolets that may qualify as recorders are of two types: those early instruments, called "English flageolets," which were actually recorders, and 19th century instruments with seven finger holes and a thumb hole. These instruments are not typically regarded as recorders, however Tarasov has argued for their inclusion in the family.

The csakan (from Hung. "csÃ¡kÃ¡ny ""pickaxe"), also known by the recorder's old french name "flute douce", was a duct flute in the shape of a walking stick or oboe popular in Vienna from about 1800 to the 1840s. The csakan was played using the fingerings of a recorder in C, and was typically pitched in A or G and played as a transposing instrument. The first documented appearance of the csakan was at a concert in Budapest on February 18, 1807 in a performance by its billed inventor, Anton Heberle ( 1806â16). Tarasov has contested Heberle's status as the inventor of the instrument, and has argued that the csakan grew out of a Hungarian war hammer of the same name, which was converted into a recorder, perhaps for playing military music. Around 1800, it was highly fashionable for make walking sticks with additional functions (e.g., umbrellas, swords, flutes, oboes, clarinets, horns) although the csakan was the most popular of these, and the only one that became a musical instrument in its own right.

The earliest instruments were shaped like a walking stick with a mouthpiece in the handle and had no keys, although they could eventually have up to thirteen keys, along with a tuning slide and a device for narrowing the thumb hole. In the 1820s a csakan "in the pleasing shape of an oboe" was introduced in a "simple" form with a single key and a "complex" form with up to twelve keys like those found on contemporaneous flutes. Well known makers of the csakan included Johann Ziegler and Stephan Koch in Vienna, and Franz SchÃ¶llnast in Pressburg. According to accounts left by SchÃ¶llnast, the csakan was primarily an amateur instrument, purchased by those who wanted something simple and inexpensive, however there were also accomplished professionals, such as Viennese court oboist Ernst KrÃ¤hmer (1795â1837) who toured as far afield as Russia, playing the csakan with acclaimed virtuosity.

Around 400 works for the csakan were published in the first half of the 19th century, mainly for csakan solo, csakan duet or csakan with guitar or piano. The csakan's repertoire has not yet been fully explored. Notable composers for the instrument include Heberle and KrÃ¤hmer, and Tarasov notes that piano works by Beethoven were arranged for csakan and guitar (Beethoven is reported to have owned a walking-stick csakan). Modern recorder makers such as Bernhard Mollenhauer and Martin Wenner have made csakan copies.

Similarities in fingering and design make the csakan at least a close relative of the recorder. Accounts of KrÃ¤hmer's playing, which report his "diminishing and swelling the notes, up to an almost unbelievable loudness" imply a developed technique using shading and alternate fingerings, far beyond a purely amateur culture of house music. Additionally, Tarasov reports that some recorders by Baroque makers were modified, around 1800, through the addition of keys, including a J.Â C. Denner (1655â1707) basset recorder in Budapest and an alto by Nikolaus Staub (1664â1734) with added G keys, like the D key on a baroque two-key flute. Another modification is the narrowing of the thumb hole, by way of an ivory plug on the J.Â C. Denner basset and an alto by Benedikt Gahn (1674â1711), to allow it to serve purely as an octaving vent, as found on many flageolets and csakans. These changes may be archetypal to those found on csakans and flageolets, and constitute an inchoate justification for the continuous development of the Baroque recorder into its 19th-century relatives.

The concept of a recorder "revival" must be considered in the context of the decline of the recorder in the 18th and 19th centuries. The craft of recorder making was continued in some form by a number of families, such as the produced by the Oeggle family, which traces its lineage to the Walch family of recorder makers the careers of the Schlosser family of Zwota. Heinrich Oskar Schlosser (1875â1947) made instruments sold by the firm of Moeck in Celle and helped to design their Tuju series of recorders. The firm Mollenhauer, currently headed by Bernhard Mollenhauer, can trace its origins to historical instrument makers.

The recorder, if it did persist through the 19th century, did so in a manner quite unlike the success it enjoyed in previous centuries, or that it would enjoy in the century to come in. Among the earliest ensembles to begin use of recorders in the 20th century was the Bogenhauser KÃ¼nstlerkapelle (Bogenhausen Artists' Band) which from 1890 to 1939 used antique recorders and other instruments to play music of all ages, including arrangements of classical and romantic music. Nonetheless, the recorder was considered primarily an instrument of historical interest.

The eventual success of the recorder in the modern era is often attributed to Arnold Dolmetsch. While he was responsible for broadening interest in the United Kingdom beyond the small group of early music specialists, Dolmetsch was not solely responsible for the recorder's broader revival. On the continent his efforts were preceded by those of musicians at the Brussels Conservatoire (where Dolmetsch received his training), and by the German Bogenhauser KÃ¼nstlerkapelle. Also in Germany, the work of Willibald Gurlitt, Werner Danckerts and Gustav Scheck proceeded quite independently of the Dolmetsches.

Carl Dolmetsch, the son of Arnold Dolmetsch, became one of the first virtuoso recorder players in the 1920s; but more importantly he began to commission recorder works from leading composers of his day, especially for performance at the Haslemere festival which his father ran. Initially as a result of this, and later as a result of the development of a Dutch school of recorder playing led by Kees Otten, the recorder was introduced to serious musicians as a virtuoso solo instrument both in Britain and in northern Europe.

Among the influential virtuosos who figure in the revival of the recorder as a serious concert instrument in the latter part of the 20th century are Ferdinand Conrad, Kees Otten, Frans BrÃ¼ggen, Roger Cotte, Hans-Martin Linde, Bernard Krainis, and David Munrow. BrÃ¼ggen recorded most of the landmarks of the historical repertoire and commissioned a substantial number of new works for the recorder. Munrow's 1975 double album "The Art of the Recorder" remains as an important anthology of recorder music through the ages.

Among late 20th-century and early 21st-century recorder ensembles, the trio Sour Cream (led by Frans BrÃ¼ggen), Flautando KÃ¶ln, the Flanders Recorder Quartet, Amsterdam Loeki Stardust Quartet and Quartet New Generation have programmed remarkable mixtures of historical and contemporary repertoire. Soloists such as Piers Adams, Dan Laurin and Dorothee Oberlinger, Michala Petri, Maurice Steger.

In the 2012 Charlotte Barbour-Condini became the first recorder player to reach the final of the biennial BBC Young Musician of the Year competition. Recorder player Sophie Westbrooke was a finalist in the 2014 competition.

The first recorders to be played in the modern period were antique instruments from previous periods. Anecdotally, Arnold Dolmetsch was motivated to make his own recorders after losing a bag containing his antique instruments. Recorders made in the early 20th century were imitative of baroque models in their exterior form, but differed significantly in their structure. Dolmetsch introduced English fingering, the now standard fingering for "baroque" model instruments, and standardized the doubled 6th and 7th holes found on a handful of antique instruments by the English makers Stanesby and Bressan. Dolmetsch instruments generally had a large rectangular windway, unlike the curved windways of all historical instruments, and played at modern pitch.

Nearly twice as many pieces have been written for the recorder since its modern revival as were written in all previous epochs. Many of these were composed by avant-garde composers of the latter half of the 20th century who used the recorder for the variety of extended techniques which are possible using its open holes and its sensitivity to articulation.

Modern composers of great stature have written for the recorder, including Paul Hindemith, Luciano Berio, JÃ¼rg Baur, Josef Tal, John Tavener, Michael Tippett, Benjamin Britten, Leonard Bernstein, Gordon Jacob, Malcolm Arnold, Steven Stucky and Edmund Rubbra.

Owing to its ubiquity as a teaching instrument and the relative ease of sound production, the recorder has occasionally been used in popular music by groups such as The Beatles; the Rolling Stones (see, for example, "Ruby Tuesday"); Yes, for example, in the song "I've Seen All Good People"; Jefferson Airplane (see Personnel as well as Grace Slick); Led Zeppelin ("Stairway to Heaven"); Jimi Hendrix; Siouxsie and the Banshees; Judy Dyble of Fairport Convention; Dido (e.g. "Grafton Street"); and Mannheim Steamroller.

The trade of recorder making was traditionally transmitted via apprenticeship. Notable historical makers include the Rafi, Schnitzer and Bassano families in the renaissance; Stanesby (Jr. and Sr.), J.C. and J. Denner, Hotteterre, Bressan, Haka, Heitz, Rippert, Rottenburgh, Steenbergen and Terton. Most of these makers also built other wind instruments such as oboes and transverse flutes. Notably, Jacob Denner is credited with the development of the clarinet from the chalumeau.

Recorder making declined with the instrument's wane in the late 18th century, essentially severing the craft's transmission to the modern age. With few exceptions, the duct flutes manufactured in the 19th and late 18th centuries were intended for amateur or educational use, and were not constructed to the high standard of earlier epochs.

Arnold Dolmetsch, the first to achieve commercial production in the 20th century, began to build recorders in 1919. While these early recorders played at a low pitch like that of the available originals, he did not strive for exactitude in reproduction, and by the 1930s the Dolmetsch family firm, then under the direction of Arnold's son Carl Dolmetsch, was mass-producing recorders at modern pitch with wide, straight windways, and began to produce bakelite recorders shortly after the Second World War. Nonetheless, the Dolmetsch models were innovative for their time and proved influential, particularly in standardizing the English fingering system now standard for modern baroque-style instruments and doubled 6th and 7th holes, which are rare on antique instruments.

In Germany, Peter Harlan began to manufacture recorders in the 1920s, primarily for educational use in the youth movement. Following Harlan's success, numerous makers such as Adler and Mollenhauer began commercial production of recorders, fueling an explosion in the instrument's popularity in Germany. These recorders shared little in common with antiques, with large straight windways, anachronistically pitched consorts, modified fingering systems and other innovations.

In the latter half of the 20th century, historically informed performance practice was on the rise and recorder makers increasingly sought to imitate the sound and character of antiques. The German-American maker Friedrich von Huene was among the first to research recorders held in European collections and produce instruments intended to reproduce the qualities of the antiques. Von Huene and his Australian colleague Frederick Morgan sought to connect the tradition of the historical wind-makers to the modern day with the understanding that doing so creates the best instruments, and those most suited to ancient music.

Virtually all recorders manufactured today claim ascendancy to an antique model and most makers active today can trace their trade directly to one of these pioneering makers.

Today, makers maintaining individual workshops include Ammann, Blezinger, Bolton, Boudreau, Breukink, Brown, Coomber, Cranmore, de Paolis, Ehlert, Grinter (dead), Marvin (dead), Meyer, Musch, Netsch, Prescott, Rohmer, Takeyama, von Huene, and Wenner. French maker Philippe Bolton created an electroacoustic recorder and is among the last to offer mounted bell-keys and double bell-keys for both tenor and alto recorders. Those bell-keys extend easily the range of the instrument to more than three octaves. Invented by Carl Dolmetsch in 1957, he first used the bell-key system publicly in 1958.

In the mid-20th century, German composer and music educator Carl Orff popularized the recorder for use in schools as part of Orff-Schulwerk programs in German schools. Orff's five-volume opus of educational music "Music for Children" contains many pieces for recorders, usually scored for other instruments as well.

Manufacturers have made recorders out of bakelite and other more modern plastics; they are thus easy to produce, hence inexpensive. Because of this, recorders are popular in schools, as they are one of the cheapest instruments to buy in bulk. They are also relatively easy to play at a basic level because sound production needs only breath, and pitch is basically determined by fingering. It is, however, incorrect to assume that mastery is similarly easyâlike any other instrument, the recorder requires study to play well and in tune, and significant study to play at an advanced or professional level.

The recorder is a very social instrument. Many recorder players participate in large groups or in one-to-a-part chamber groups, and there is a wide variety of music for such groupings including many modern works. Groups of different sized instruments help to compensate for the limited note range of the individual instruments. Four part arrangements with a soprano, alto, tenor and bass part played on the corresponding recorders are common, although more complex arrangements with multiple parts for each instrument and parts for lower and higher instruments may also be regularly encountered.





</doc>
<doc id="26247" url="https://en.wikipedia.org/wiki?curid=26247" title="Received Pronunciation">
Received Pronunciation

Received Pronunciation (RP), commonly called BBC English and Standard British pronunciation or Southern British pronunciation, is an accent of Standard English in the United Kingdom and is defined in the "Concise Oxford English Dictionary" as "the standard accent of English as spoken in the south of England", although it can be heard from native speakers throughout England and Wales. Peter Trudgill estimated in 1974 that 3 per cent of people in Britain were RP speakers, but this rough estimate has been questioned by the phonetician J. Windsor Lewis. Clive Upton notes higher estimates of 5% (Romaine, 2000) and 10% (Wells, 1982) but refers to all these as "guesstimates" that are not based on robust research.

Formerly colloquially called "the King's English", RP enjoys high social prestige in Britain, being thought of as the accent of those with power, money, and influence, though it may be perceived negatively by some as being associated with undeserved privilege. Since the 1960s, a greater permissiveness toward regional English varieties has taken hold in education.

The study of RP is concerned exclusively with pronunciation, whereas Standard English, the Queen's English, Oxford English, and BBC English are also concerned with matters such as grammar, vocabulary, and style.

The introduction of the term "Received Pronunciation" is usually credited to the British phonetician Daniel Jones. In the first edition of the "English Pronouncing Dictionary" (1917), he named the accent "Public School Pronunciation" ("public" being what Americans would term "private"), but for the second edition in 1926, he wrote, "In what follows I call it Received Pronunciation, for want of a better term." However, the term had actually been used much earlier by P. S. Du Ponceau in 1818. A similar term, "received standard," was coined by Henry C. K. Wyld in 1927. The early phonetician Alexander John Ellis used both terms interchangeably but with a much broader definition than Daniel Jones, having said "there is no such thing as a uniform eduction pron. of English, and rp. and rs. is a variable quantity differing from individual to individual, although all its varieties are 'received', understood and mainly unnoticed".

According to "Fowler's Modern English Usage" (1965), the correct term is "'the Received Pronunciation'. The word 'received' conveys its original meaning of 'accepted' or 'approved', as in 'received wisdom'."

RP is often believed to be based on the accents of southern England, but it actually has most in common with the Early Modern English dialects of the East Midlands. This was the most populated and most prosperous area of England during the 14th and 15th centuries. By the end of the 15th century, "Standard English" was established in the City of London.

Some linguists have used the term "RP" while expressing reservations about its suitability. The Cambridge-published "English Pronouncing Dictionary" (aimed at those learning English as a foreign language) uses the phrase "BBC Pronunciation" on the basis that the name "Received Pronunciation" is "archaic" and that BBC news presenters no longer suggest high social class and privilege to their listeners. Other writers have also used the name "BBC Pronunciation".

The phonetician Jack Windsor Lewis frequently criticises the name "Received Pronunciation" in his blog: he has called it "invidious", a "ridiculously archaic, parochial and question-begging term" and noted that American scholars find the term "quite curious". He used the term "General British" (to parallel "General American") in his 1970s publication of "A Concise Pronouncing Dictionary of American and British English" and in subsequent publications. Beverley Collins and Inger Mees use the term "Non-Regional Pronunciation" for what is often otherwise called RP, and reserve the term "Received Pronunciation" for the "upper-class speech of the twentieth century". Received Pronunciation has sometimes been called "Oxford English", as it used to be the accent of most members of the University of Oxford. The "Handbook of the International Phonetic Association" uses the name "Standard Southern British". Page 4 reads:

In her book "Kipling's English History" (1974) Marghanita Laski refers to this accent as "gentry". "What the Producer and I tried to do was to have each poem spoken in the dialect that was, so far as we could tell, ringing in Kipling's ears when he wrote it. Sometimes the dialect is most appropriately, Gentry. More often, it isn't."

Faced with the difficulty of defining RP, some researchers have tried to distinguish between different sub-varieties:


Teachers often promote the modern RP accent to non-native speakers learning British English. Non-RP Britons abroad may modify their pronunciation to something closer to Received Pronunciation to allow better understanding by people unfamiliar with the diversity of British accents. They may also modify their vocabulary and grammar to approach those of Standard English for the same reason. RP serves as the standard for English in most books on general phonology and phonetics, and most dictionaries published in the United Kingdom use RP in their pronunciation schemes. Most British voices in apps like Siri and Google Assistant speak RP, and most TV and radio stations across the UK use this accent.

Most English dictionaries published in Britain (including the "Oxford English Dictionary") now give phonetically transcribed RP pronunciations for all words. Pronunciation dictionaries represent a special class of dictionary giving a wide range of possible pronunciations; British pronunciation dictionaries are all based on RP, though not necessarily using that name. Daniel Jones transcribed RP pronunciations of a large number of words and names in the "English Pronouncing Dictionary". Cambridge University Press continues to publish this title, edited by Peter Roach, the accent having been renamed "BBC Pronunciation". Two other pronunciation dictionaries are in common use: the "Longman Pronunciation Dictionary", compiled by John C. Wells (using the name "Received Pronunciation"), and the "Oxford Dictionary of Pronunciation for Current English", compiled by Clive Upton. This represents an accent named BR ("British English") â based on RP, but claimed to be representative of a wider group of speakers. An earlier pronunciation dictionary by J. Windsor Lewis gives both British and American pronunciations, using the terms General British (GB) for the former and General American (GA) for the latter.

Traditionally, Received Pronunciation was the "everyday speech in the families of Southern English persons whose men-folk [had] been educated at the great public boarding-schools" and which conveyed no information about that speaker's region of origin before attending the school.

In the 19th century, some British prime ministers still spoke with some regional features, such as William Ewart Gladstone. From the 1970s onwards, attitudes towards Received Pronunciation have been changing slowly. The BBC's use of Yorkshire-born Wilfred Pickles during the Second World War (to distinguish BBC broadcasts from German propaganda) is an earlier example of the use of non-RP accents, but even then Pickles modified his speech towards RP when reading the news.

Although admired in some circles, RP is disliked in others. It is common in parts of Britain to regard it as a south-eastern English accent rather than a non-regional one and as a symbol of the south-east's political power in Britain. A 2007 survey found that residents of Scotland and Northern Ireland tend to dislike RP. It is shunned by some with left-wing political views, who may be proud of having an accent more typical of the working classes.

Nasals and liquids (, , , , ) may be syllabic in unstressed syllables. The consonant in 'row', 'arrow' in RP is generally a postalveolar approximant, which would normally be expressed with the sign in the International Phonetic Alphabet, but the sign is nonetheless traditionally used for RP in most of the literature on the topic.

Voiceless plosives (, , , ) are aspirated at the beginning of a syllable, unless a completely unstressed vowel follows. (For example, the is aspirated in "impasse", with primary stress on "-passe", but not "compass", where "-pass" has no stress.) Aspiration does not occur when precedes in the same syllable, as in "spot" or "stop". When a sonorant , , , or follows, this aspiration is indicated by partial devoicing of the sonorant. is a fricative when devoiced.

Syllable final , , , and may be either preceded by a glottal stop (glottal reinforcement) or, in the case of , fully replaced by a glottal stop, especially before a syllabic nasal ("bitten" ). The glottal stop may be realised as creaky voice; thus, an alternative phonetic transcription of "attempt" could be .

As in other varieties of English, voiced plosives (, , , ) are partly or even fully devoiced at utterance boundaries or adjacent to voiceless consonants. The voicing distinction between voiced and voiceless sounds is reinforced by a number of other differences, with the result that the two of consonants can clearly be distinguished even in the presence of devoicing of voiced sounds:


As a result, some authors prefer to use the terms "fortis" and "lenis" in place of "voiceless" and "voiced". However, the latter are traditional and in more frequent usage.

The voiced dental fricative () is more often a weak dental plosive; the sequence is often realised as (a long dental nasal). has velarised allophone () in the syllable rhyme. becomes voiced () between voiced sounds.

Examples of short vowels: in "kit", "mirror" and "rabbit", in "foot" and "cook", in "dress" and "merry", in "strut" and "curry", in "trap" and "marry", in "lot" and orange", in ago" and "sofa".

Examples of long vowels: in "fleece", in "goose", in "bear", in "nurse" and "furry", in "north", "force" and "thought", in "father" and "start".

The long mid front vowel is transcribed with the traditional symbol in this article. The predominant realisation in contemporary RP is monophthongal.

RP's long high vowels and are slightly diphthongised, and are often narrowly transcribed in phonetic literature as diphthongs and .

The terms "long" and "short" are relative to each other when applied to the vowel phonemes of RP. Vowels may be phonologically long or short (i.e. belong to the long or the short group of vowel phonemes) but their length is influenced by their context: in particular, they are shortened if a voiceless (fortis) consonant follows in the syllable, so that, for example, the vowel in 'bat' is shorter than the vowel in 'bad' . The process is known as "pre-fortis clipping". Thus phonologically short vowels in one context can be phonetically "longer" than phonologically long vowels in another context. For example, the phonologically long vowel in 'reach' (which ends with a voiceless consonant) may be "shorter" than the phonologically short vowel in the word 'ridge' (which ends with a voiced consonant). Wiik, cited in Cruttenden (2014), published durations of English vowels with a mean value of 17.2 csec. for short vowels before voiced consonants but a mean value of 16.5 csec for long vowels preceding voiceless consonants.

In natural speech, the plosives and often have no audible release utterance-finally, and voiced consonants are partly or completely devoiced (as in ); thus the perceptual distinction between pairs of words such as 'bad' and 'bat', or 'seed' and 'seat' rests mostly on vowel length (though the presence or absence of glottal reinforcement provides an additional cue).

In addition to such length distinctions, unstressed vowels are both shorter and more centralised than stressed ones. In unstressed syllables occurring before vowels and in final position, contrasts between long and short high vowels are neutralised and short and occur (e.g. "happy" , "throughout" ). The neutralisation is common throughout many English dialects, though the phonetic realisation of e.g. rather than (a phenomenon called "happy"-tensing) is not as universal.

Unstressed vowels vary in quality:

The centring diphthongs are gradually being eliminated in RP. The vowel (as in "door", "boar") had largely merged with by the Second World War, and the vowel (as in "poor", "tour") has more recently merged with as well among most speakers, although the sound is still found in conservative speakers. See poorâpour merger. The remaining centring glide is increasingly pronounced as a monophthong , although without merging with any existing vowels.

The diphthong /ÉÊ/ is pronounced by some RP speakers in a noticeably different way when it occurs before /l/, if that consonant is syllable-final and not followed by a vowel (the context in which /l/ is pronounced as a "dark l"). The realization of /ÉÊ/ in this case begins with a more back, rounded and sometimes more open vowel quality; it may be transcribed as [ÉÊ] or [ÉÊ]. It is likely that the backness of the diphthong onset is the result of allophonic variation caused by the raising of the back of the tongue for the /l/. If the speaker has "l-vocalization" the /l/ is realized as a back rounded vowel, which again is likely to cause backing and rounding in a preceding vowel as coarticulation effects. This phenomenon has been discussed in several blogs by John C. Wells. In the recording included in this article the phrase 'fold his cloak' contains examples of the /ÉÊ/ diphthong in the two different contexts. The onset of the pre-/l/ diphthong in 'fold' is slightly more back and rounded than that in 'cloak', though the allophonic transcription does not at present indicate this.

RP also possesses the triphthongs as in "tire", as in "tower", as in "lower", as in "layer" and as in "loyal". There are different possible realisations of these items: in slow, careful speech they may be pronounced as a two-syllable triphthong with three distinct vowel qualities in succession, or as a monosyllabic triphthong. In more casual speech the middle vowel may be considerably reduced, by a process known as smoothing, and in an extreme form of this process the triphthong may even be reduced to a single vowel, though this is rare, and almost never found in the case of . In such a case the difference between , , and in "tower", "tire", and "tar" may be neutralised with all three units realised as or . This type of smoothing is known as the "tower"â"tire", "tower"â"tar" and "tire"â"tar" mergers.

There are differing opinions as to whether in the lexical set can be considered RP. The pronunciations with are invariably accepted as RP. The "English Pronouncing Dictionary" does not admit in words and the "Longman Pronunciation Dictionary" lists them with a Â§ marker of non-RP status. John Wells wrote in a blog entry on 16 March 2012 that when growing up in the north of England he used in "bath" and "glass", and considers this the only acceptable phoneme in RP. Others have argued that is too categorical in the north of England to be excluded. Clive Upton believes that in these words must be considered within RP and has called the opposing view "south-centric". Upton's "Oxford Dictionary of Pronunciation for Current English" gives both variants for words. A. F. Gupta's survey of mostly middle-class students found that was used by almost everyone who was from clearly north of the isogloss for words. She wrote, "There is no justification for the claims by Wells and Mugglestone that this is a sociolinguistic variable in the north, though it is a sociolinguistic variable on the areas on the border [the isogloss between north and south]". In a study of speech in West Yorkshire, K. M. Petyt wrote that "the amount of usage is too low to correlate meaningfully with the usual factors", having found only two speakers (both having attended boarding schools in the south) who consistently used .

Jack Windsor Lewis has noted that the Oxford Dictionary's position has changed several times on whether to include short within its prescribed pronunciation. The "BBC Pronouncing Dictionary of British Names" uses only , but its author, Graham Pointon, has stated on his blog that he finds both variants to be acceptable in place names.

Some research has concluded that many people in the North of England have a dislike of the vowel in words. A. F. Gupta wrote, "Many of the northerners were noticeably hostile to , describing it as 'comical', 'snobbish', 'pompous' or even 'for morons'." On the subject, K. M. Petyt wrote that several respondents "positively said that they did not prefer the long-vowel form or that they really detested it or even that it was incorrect". Mark Newbrook has assigned this phenomenon the name "conscious rejection", and has cited the vowel as "the main instance of conscious rejection of RP" in his research in West Wirral.

John Wells has argued that, as educated British speakers often attempt to pronounce French names in a French way, there is a case for including (as in "bon"), and and (as in "vingt-et-un"), as marginal members of the RP vowel system. He also argues against including other French vowels on the grounds that very few British speakers succeed in distinguishing the vowels in "bon" and "banc", or in "rue" and "roue".

Not all reference sources use the same system of transcription. In particular:
Most of these variants are used in the transcription devised by Clive Upton for the "Shorter Oxford English Dictionary" (1993) and now used in many other Oxford University Press dictionaries.

The linguist Geoff Lindsey has argued that the system of transcription for RP has become outdated and has proposed a new system as a replacement.

Like all accents, RP has changed with time. For example, sound recordings and films from the first half of the 20th century demonstrate that it was usual for speakers of RP to pronounce the sound, as in "land", with a vowel close to , so that "land" would sound similar to a present-day pronunciation of "lend". RP is sometimes known as the Queen's English, but recordings show that even Queen Elizabeth II has changed her pronunciation over the past 50 years, no longer using an -like vowel in words like "land". 
Some changes in RP during the 20th century include:


The change in RP may be observed in the home of "BBC English". The BBC accent of the 1950s is distinctly different from today's: a news report from the 1950s is recognisable as such, and a mock-1950s BBC voice is used for comic effect in programmes wishing to satirise 1950s social attitudes such as the Harry Enfield Show and its "Mr. Cholmondley-Warner" sketches.

More recently, in speakers born between 1981 and 1993, the vowel shifted up approaching in quality. The vowels and have undergone fronting and reduction in the amount of lip-rounding (phonetically, this can be transcribed and , respectively), while has become more open .


Conservative Received Pronunciation is a conservative standard of pronunciation of British English. Formerly the prestige model of pronunciation, it has declined in favour of other, less-conservative dialects, primarily Contemporary Received Pronunciation (Contemporary RP) also known as "Modern RP". Conservative RP is the standard adhered to in the First and Second Editions of the "Oxford English Dictionary", which, starting with the Third edition, has been modelled on Contemporary RP. Other terms for Conservative RP are "Traditional RP" and "Upper RP" (the latter in reference to the association of the standard to the upper class and aristocracy). Notable speakers of Conservative RP include Queen Elizabeth II and other older members of the British Royal Family, Sir Winston Churchill and commentators of PathÃ© News and, prior to the 1960s, the BBC.

The phonological features of Conservative RP which are distinct from Contemporary RP, include:



The "Journal of the International Phonetic Association" regularly publishes "Illustrations of the IPA" which present an outline of the phonetics of a particular language or accent. It is usual to base the description on a recording of the traditional story of the North Wind and the Sun. There is an IPA illustration of British English (Received Pronunciation).

The speaker (female) is described as having been born in 1953, and educated at Oxford University. To accompany the recording there are three transcriptions: orthographic, phonemic and allophonic.
Phonemic

Allophonic

Orthographic

The North Wind and the Sun were disputing which was the stronger, when a traveller came along wrapped in a warm cloak. They agreed that the one who first succeeded in making the traveller take his cloak off should be considered stronger than the other. Then the North Wind blew as hard as he could, but the more he blew the more closely did the traveller fold his cloak around him, and at last the North Wind gave up the attempt. Then the Sun shone out warmly, and immediately the traveller took off his cloak. And so the North Wind was obliged to confess that the Sun was the stronger of the two.
The following people have been described as RP speakers:




Sources of regular comment on RP

Audio files


</doc>
<doc id="26252" url="https://en.wikipedia.org/wiki?curid=26252" title="Ryan Lackey">
Ryan Lackey

Ryan Donald Lackey (born March 17, 1979) is an entrepreneur and computer security professional. He was a co-founder of HavenCo, the world's first data haven. He also speaks at numerous conferences and trade shows, including DEF CON, RSA Data Security Conference, on various topics in the computer security field, and has appeared on the cover of Wired Magazine, in numerous television, radio, and print articles on HavenCo and Sealand. Lackey operated BlueIraq, a VSAT communications and IT company serving the DoD and domestic markets in Iraq and Afghanistan during the US conflicts.

Lackey was born in West Chester, Pennsylvania and has also lived throughout the US and Europe, Anguilla, Sealand, Dubai, and Iraq. As a teenager, he was briefly involved with the Globewide Network Academy. Lackey attended MIT and majored in Course 18 (mathematics). While a student at MIT (he later dropped out due to financial constraints) Lackey became interested in electronic cash and distributed systems, originally for massively multiplayer online gaming. This interest led to attending several conferences (Financial Cryptography 98, various MIT presentations), participating on mailing lists such as "cypherpunks" and "dbs", and eventually implementing patented Chaumian digital cash in an underground library, HINDE, with Ian Goldberg, named after Hinde ten Berge, a Dutch cypherpunk also present at FC98. In part, he contributed to the cypherpunks movement as one of the longest Anonymous remailer operators.

In 1999 Lackey lived in the San Francisco Bay Area after a period in Anguilla before moving to the unrecognized state of Sealand off the coast of the United Kingdom and establishing HavenCo. In December 2002, he left HavenCo following a dispute with other company directors and the Sealand "Royal Family".

Eventually, BlueIraq's business model became economically unfeasible due to an escalation in anti-western violence primarily in the form of Improvised Explosive Devices and troop draw downs. BlueIraq sought venture capital to transform itself into a large general consumer cellular telephone company. However, the 2008 financial crisis and the instability of Iraq and Afghanistan made fund raising impossible.

Lackey returned to the US and located in San Francisco where he worked for a number of start-up companies before applying to Y Combinator. He was accepted into Y Combinator's Summer 2011 round. Lackey founded CryptoSeal, a VPN as a service start-up with a small group of people well known in the computer security community, and secured funding from Ron Conway and a well known venture capital fund. In June 2014, CryptoSeal was acquired by CloudFlare.


<br>


</doc>
<doc id="26253" url="https://en.wikipedia.org/wiki?curid=26253" title="Revised Julian calendar">
Revised Julian calendar

The Revised Julian calendar, also known as the MilankoviÄ calendar, or, less formally, new calendar, is a calendar proposed by the Serbian scientist Milutin MilankoviÄ in 1923, which effectively discontinued the 340 years of divergence between the naming of dates sanctioned by those Eastern Orthodox churches adopting it and the Gregorian calendar that has come to predominate worldwide. This calendar was intended to replace the ecclesiastical calendar based on the Julian calendar hitherto in use by all of the Eastern Orthodox Church. From 1 March 1600 through 28 February 2800, the Revised Julian calendar aligns its dates with the Gregorian calendar, which was proclaimed in 1582 by Pope Gregory XIII for adoption by the Christian world. The calendar has been adopted by the Orthodox churches of Constantinople, Albania, Alexandria, Antioch, Bulgaria, Cyprus, Greece, and Romania.

The Revised Julian calendar has the same months and month lengths as the Julian calendar, but, in the Revised Julian calendar, years evenly divisible by 100 are not leap years, except that years with remainders of 200 or 600 when divided by 900 remain leap years, e.g. 2000 and 2400 as in the Gregorian Calendar.

A committee composed of members of the Greek government and Greek Orthodox Church was set up to look into the question of calendar reform. It reported in January 1923. It recommended a switch (for civil purposes only) to the "political calendar" devised in 1785 and advocated by Maksim TrpkoviÄ. TrpkoviÄ advocated this calendar in preference to the Gregorian because of its greater accuracy and also because the vernal equinox would generally fall on 21 March, the date allocated to it by the church. In the Gregorian, it generally falls on 20 March. As in the Gregorian, end-century years are generally not leap years, but years that give remainder 0 or 400 on division by 900 were to be leap years. The changeover went into effect on 17 February/1 March.

After the promulgation of the royal decree, the Ecumenical Patriarch, Patriarch Meletius IV of Constantinople, issued an encyclical on 3 February recommending the calendar's adoption by Orthodox churches. The matter came up for discussion at a , which deliberated in May and June. Subsequently it was adopted by several of the autocephalous Orthodox churches. The synod was chaired by the controversial patriarch and representatives were present from the churches of Cyprus, Greece, Romania and Serbia. There were no representatives of the other members of the original Orthodox Pentarchy (the Patriarchates of Jerusalem, Antioch, and Alexandria) or from the largest Orthodox church, the Russian Orthodox Church.

Discussion was lengthy because although Serbia officially supported the political calendar, MilankoviÄ (an astronomical delegate to the synod representing the Kingdom of Serbs, Croats and Slovenes) pressed for the adoption of his own version, in which the centennial leap years would be those giving remainder 200 or 600 when divided by 900 and the equinox would generally fall on 20 March (as in the Gregorian). Under the official proposal the equinox would sometimes fall on 22 March. This might make Easter fall outside its canonical limits due to the requirement that the Easter full moon follow the equinox. Also his scheme maximised the time during which the political calendar and the Gregorian would run in tandem.

MilankoviÄ's arguments won the day. In its decision the conference noted that "the difference between the length of the political year of the new calendar and the Gregorian is so small that only after 877 years it is observed difference of dates." The same decision provided that the coming should be called , thus dropping thirteen days. It then adopted the leap year rule of MilankoviÄ. The political calendar was preferred over the Gregorian because its mean year was within two seconds of the then current length of the "mean" tropical year. The present "vernal equinox" year, however, is about 12 seconds longer, in terms of mean solar days.

The synod also proposed the adoption of an astronomical rule for Easter: Easter was to be the Sunday after the midnight-to-midnight day at the meridian of the Church of the Holy Sepulchre in Jerusalem (35Â°13â²47.2â³Â E or UT+22055 for the small dome) during which the first full moon after the vernal equinox occurs. Although the instant of the full moon must occur after the instant of the vernal equinox, it may occur on the same day. If the full moon occurs on a Sunday, Easter is the following Sunday. Churches that adopted this calendar did so on varying dates. However, all Eastern Orthodox churches continue to use the Julian calendar to determine the date of Easter (except for the Finnish Orthodox Church and the Estonian Orthodox Church, which now use the Gregorian Easter).

The following are Gregorian minus Revised Julian date differences, calculated for the beginning of March in each century year, which is where differences arise or disappear, until 10000 AD. These are exact arithmetic calculations, not depending on any astronomy. A negative difference means that the proleptic Revised Julian calendar was behind the proleptic Gregorian calendar. The Revised Julian calendar is the same as the Gregorian calendar from 1 March 1600 to 28 February 2800, but the following day would be 1 March 2800 (RJ) or 29 February 2800 (G); this difference is denoted as '+1' in the table. 2900 is a leap year in Revised Julian, but not Gregorian: 29 February 2900 (RJ) is the same as 28 February 2900 (G) and the next day will be 1 March 2900 in both calendars - hence the '0' notation.

In 900 Julian years there are = 225 leap days. The Revised Julian leap rule omits seven of nine century leap years, leaving leap days per 900-year cycle. Thus the calendar mean year is 365Â +Â  days, but this is actually a double-cycle that reduces to 365Â +Â  = 365.24 days, or exactly 365 days 5 hours 48 minutes 48 seconds, which is exactly 24 seconds shorter than the Gregorian mean year of 365.2425 days, so in the long term on "average" the Revised Julian calendar pulls ahead of the Gregorian calendar by one day in 3600 years.

The number of days per Revised Julian cycle = 900 Ã 365 + 218 = 328,718 days. Taking mod 7 leaves a remainder of 5, so like the Julian calendar, but unlike the Gregorian calendar, the Revised Julian calendar cycle does not contain a whole number of weeks. Therefore, a full repetition of the Revised Julian leap cycle with respect to the seven-day weekly cycle is seven times the cycle length = 7 Ã 900 = 6300 years.

The epoch of the Julian calendar was on the Saturday before the Monday that was the epoch of the Gregorian calendar. In other words, Gregorian = Julian . The Revised Julian reform not only changed the leap rule but also made the epoch the same as that of the Gregorian calendar. This seems to have been carried out implicitly, and even scientific articles make no mention of it. Nevertheless, it is impossible to implement calendrical calculations and calendar date conversion software without appreciating this detail and taking the 2-day shift into account. If the original Julian calendar epoch is mistakenly used in such calculations then there is no way to reproduce the currently accepted dating of the Revised Julian calendar, which yields no difference between Gregorian and Revised Julian dates from the 17th to the 28th centuries.

The following is a scatter plot of actual astronomical northward equinox moments as numerically integrated by SOLEX 11 using DE421 mode with extended (80-bit) floating point precision, high integration order (18th order), and forced solar mass loss ("forced" means taken into account at all times). SOLEX can automatically search for northern hemisphere spring equinox moments by finding when the solar declination crosses the celestial equator northward, and then it outputs that data as the Terrestrial Time day and fraction of day relative to at noon (J2000.0 epoch). The progressive tidal slowing of the Earth rotation rate was accounted for by subtracting "ÎT" as calculated by the Espenak-Meeus polynomial set recommended at the NASA Eclipses web site to obtain the J2000.0-relative Universal Time moments, which were then properly converted to Revised Julian dates and Jerusalem local apparent time, taking local apparent midnight as the beginning of each calendar day. The year range of the chart was limited to dates before the year 4400Â ADâby then "ÎT" is expected to accumulate to about six hours, with an uncertainty of less than hours.

The chart shows that the long-term equinox drift of the Revised Julian calendar is quite satisfactory, at least until 4400Â AD. The medium-term wobble spans about two days because, like the Gregorian calendar, the leap years of the Revised Julian calendar are not smoothly spread: they occur mostly at intervals of four years but there are occasional eight-year gaps (at 7 out of 9 century years). Evidently each of the authorities responsible for the Gregorian and Revised Julian calendars, respectively, accepted a modest amount of medium-term equinox wobble for the sake of traditionally perceived leap rule mental arithmetic simplicity. Therefore, the wobble is essentially a curiosity that is of no practical or ritual concern.

The new calendar has been adopted by Orthodox churches as follows:


Adopting churches are known as New calendarists. The new calendar has not been adopted by the Orthodox churches of Jerusalem, Russia, Serbia (including the uncanonical Macedonian Orthodox Church), Georgia, Ukraine (as well as the churches loyal to Moscow), Mount Athos and the Greek Old Calendarists. Although MilankoviÄ stated that the Russian Orthodox Church adopted the new calendar in 1923, the present church continues to use the Julian calendar for both its fixed festivals and for Easter. A solution to this conundrum is to hypothesize that it was accepted only by the short-lived schismatic Renovationist Church, which had seized church buildings with the support of the Soviet government while Patriarch Tikhon was under house arrest. After his release, on , he declared that all Renovationist decrees were without grace, presumably including its acceptance of the new calendar.

The basic justification for the new calendar is the known errors of the Julian calendar, which will in the course of time lead to a situation in which those following the Julian calendar will be reckoning the month of December (and the feast of Christ's Nativity) during the heat of summer, August and its feasts during the deep cold of winter, Easter during the autumn season, and the November feasts in the springtime. This would conflict with the Church's historic practice of celebrating Christ's birth on , a date chosen for a number of reasons. One of the reasons mentioned by Bennet is the time of the winter solstice, when the days begin to lengthen again as the physical sun makes its reappearance, along with the fact that Christ has traditionally been recognized by Christians as the metaphorical and spiritual sun who fulfills Malachi's prophetic words: "the sun of righteousness will shine with healing in its wings" (Malachi 4:2). The identification, based on this prophecy, of Jesus Christ as the "sun of righteousness" is found many times in writings of the early Church fathers and follows from many New Testament references linking Jesus with imagery of sun and light.

The defenders of the new calendar do not regard the Julian calendar as having any particular divine sanction (for more on this, see below); rather, they view the Julian calendar as a device of human technology, and thus subject to improvement or replacement just as many other devices of technology that were in use at the dawn of the Church have been replaced with newer forms of technology.

Supporters of the new calendar can also point to certain pastoral problems that are resolved by its adoption.

(1) Parishes observing the Julian calendar are faced with the problem that parishioners are supposed to continue fasting throughout western Christmas and New Year, seasons when their families and friends are likely to be feasting and celebrating New Year's, often with parties, use of liquor, etc. This situation presents obvious temptations, which are eliminated when the new calendar is adopted.

(2) Another pastoral problem is the tendency of some local American media to focus attention each year on the (N.S.) / (O.S.) celebration of Christmas, even in localities where most Orthodox parishes follow the new calendar. So too, in all likelihood, do certain non-Orthodox churches profit from the Orthodox remaining Old Style, since the observance of Christmas among the Orthodox tends to focus attention on ethnic identifications of the feast, rather than on its Christian, dogmatic significance; which, in turn, tends to foster the impression in the public mind that for the Orthodox, the feast of Christ's Nativity is centered on the observance of the Julian date of that feast, rather than on the commemoration of Christ's birth. Such a focus appears to the defenders of the Revised Julian calendar and to many non-Orthodox as well, as a practice that is charming and quaint, but also anachronistic, unscientific and hence ultimately unreasonable and even cultish.

(3) Some Orthodox themselves may unwittingly reinforce this impression by ignorance of their own faith and by a consequential exclusive, or excessive, focus on the calendar issue: it has been observed, anecdotally, that some Russians cannot cite "any" difference in belief or practice between their faith and the faith of western Christians, "except" for the 13-day calendar difference.

Against the new calendar, the argument is made that inasmuch as the use of the Julian calendar was implicit in the decision of the First Ecumenical Council at Nicaea (325), no authority less than an Ecumenical Council may change this decision. However, the fact is that that Council made no decision or decree at all concerning the Julian calendar. Its silence constituted an implicit acceptance not of the Julian calendar, but of the civil calendar, which happened to be, at that time, the Julian calendar (the explicit decision of Nicaea being concerned, rather, with the date of Easter). By virtue of this, defenders of the new calendar argue that no decision by an Ecumenical Council was or is necessary today in order to "revise" (not abandon) the Julian calendar; and further, that by making the revision, the Church stays with the spirit of Nicaea I by keeping with the civil calendar in all its essentialsâwhile conversely, failure to keep with the civil calendar could be seen as a departure from the spirit of Nicaea I in this respect. Lastly, it is argued that since the adoption of the new calendar evidently involves no change in or departure from the theological or the ethical teachings of Orthodox Christianity, but rather amounts to a merely disciplinary or administrative changeâa clock correction of sortsâthe authority to enact that change falls within the competency of contemporary, local episcopal authority. Implicit acceptance of this line of reasoning, or something very close to it, underlies the decision to adopt the new calendar by those Orthodox churches that have done so.

It follows that, in general, the defenders of the new calendar hold the view that in localities where the Church's episcopal authority has elected to adopt the new calendar, but where some have broken communion with those implementing this change, it is those who have broken communion who have in fact introduced the disunity, rather than the new calendar itself or those who have adopted itÂ â although most would agree that attempts at various times to mandate the use of the new calendar through compulsion, have magnified the disunity.

To the objection that the new calendar has created problems by adjusting only the fixed calendar, while leaving all of the commemorations in the moveable cycle on the original Julian calendar, the obvious answer, of course, is that the 1923 Synod, which adopted the new calendar, did in fact change the moveable calendar as well, and that calendar problems introduced as a result of the adoption of the (fixed) new calendar alone, would not have existed had the corrections to the moveable calendar also been implemented.

According to the defenders of the new calendar, the argument that the 25 December (N.S.) observance of Christmas is a purely "secular" observance and is therefore an unsuitable time for Orthodox Christians to celebrate Christ's Nativity, is plainly inaccurate, since the observances of Christ's birth among western Christians (and today, among many Orthodox Christians) obviously occur overwhelmingly in places of worship and involve hymns, prayers, scripture readings, religious dramas, liturgical concerts, and the like. Defenders of the new calendar further note that, to the extent that is a secular observance in the western world, (i.e., O.S.) appears to be becoming one as well, in Orthodox countries that continue to follow the old calendar. In Russia, for example, is no longer a spiritual holiday for Orthodox Christians alone, but has now become a national (hence secular) holiday for all Russians, including non-Orthodox Christians, people of other religions, and nonbelievers. Where this will lead in the end remains to be seen.

Among other arguments by defenders of the new calendar are those made on the basis of "truth" (notwithstanding that the detractors of that calendar make the claim that the Old Style date, , is the "true" celebration of Christ's Nativity). Arguments from truth can take two forms: (1) If a calendar is a system for reckoning time based on the motions of astronomical bodiesâspecifically the movements of Sun and Moon, in the case of the church calendarâand if precision or accuracy is understood as one aspect of truth, then a calendar that is more accurate and precise with respect to the motions of those bodies must be regarded as truer than one that is less precise. In this regard, some of those who champion the old calendar as "truth" (rather than for pastoral reasons, as seems to be the case with the national churches that adhere to it) may appear, to those following the new calendar, as the defenders of a fiction. (2) Some defenders of the new calendar argue that the celebration, in any way or form, of two feasts of Christ's Nativity within the same liturgical year is not possible, since according to the faith there is only one celebration of that feast in a given year. On this basis, they argue that those who prefer to observe a "secular" feast of the Nativity on and a "religious" one on , err in respect of the truth that there is but one feast of the Nativity each year.

While the new calendar has been adopted by many of the smaller national churches, a majority of Orthodox Christians continue to adhere to the traditional Julian calendar, and there has been much acrimony between the two parties over the decades since the change, leading sometimes even to violence, especially in Greece.

Critics see the change in calendar as an unwarranted innovation, influenced by Western society. They say that no sound theological reason has been given for changing the calendar, that the only reasons advanced are social. The proposal for change was introduced by Meletios Metaxakis, a patriarch whose canonical status has been disputed and who is alleged to have been a Freemason, which is forbidden by the Orthodox Church.

The argument is also made that since the use of the Julian calendar was implicit in the decision of the First Ecumenical Council at Nicaea (325), which standardized the calculation of the date of Easter, no authority less than an Ecumenical Council may change it. It is further argued that the adoption of the new calendar in some countries and not in others has broken the liturgical unity of the Eastern Orthodox churches, undoing the decision made by the council of bishops at Nicaea to decree that all local churches celebrate Easter on the same day. The emperor Constantine, writing to the bishops absent from the Council to notify them of the decision, argued, "Think, then, how unseemly it is, that on the same day some should be fasting whilst others are seated at a banquet".

Liturgical objections to the new calendar stem from the fact that it adjusts only those liturgical celebrations that occur on fixed calendar dates, leaving all of the commemorations on the moveable cycle on the original Julian calendar. This upsets the harmony and balance of the liturgical year. (This would not have been a problem if the recommendations of the 1923 synod to use an astronomical rule to reckon the date of Easter, as outlined above, had not been rejected.) This disruption is most noticeable during Great Lent. Certain feast days are designed to fall during Lent, such as the feast of the Forty Martyrs of Sebaste. The Feast of the Annunciation is also intended to fall either before Easter or during Bright Week. Sometimes, Annunciation will fall on the day of Easter itself, a very special concurrence known as "Kyrio-Pascha", with special liturgical practices appointed for such an occurrence. However, under the new calendar, "Kyrio-Pascha" becomes an impossibility. The Apostles' Fast displays the most difficult aspect of the new calendar. The fast begins on the moveable cycle and ends on the fixed date of 29 June; since the new calendar is 13 days ahead of the traditional Julian calendar, the Apostles' Fast is 13 days shorter for those who follow the new calendar, and some years it is completely abrogated. Furthermore, critics of the new calendar point out the advantage to celebrating Nativity separately from the secular observances of Christmas and New Year, which are associated with partying and alcohol consumption.

Critics also point out that proponents of the new calendar tend to use worldly rather than spiritual justification for changing the calendar: wanting to "party with everyone else" at Christmas; concern that the gradual shift in the Julian calendar will somehow negatively affect the celebration of feasts that are linked to the seasons of the year. However, opponents counter that the seasons are reversed in the southern hemisphere, where the liturgical celebrations are no less valid. The validity of this argument is questionable, since the feasts of the Orthodox Church were not changed no matter where they were celebrated, and Orthodox services were held in the southern hemisphere with little issue centuries before the introduction of the new calendar.

Proponents also argue that the new calendar is somehow more "scientific", but opponents argue that science is not the primary concern of the Church; rather, the Church is concerned with other-worldliness, with being "in the world, but not of it", fixing the attention of the faithful on eternity. Scientifically speaking, neither the Gregorian calendar nor the new calendar is absolutely precise. This is because the solar year cannot be evenly divided into 24-hour segments. So any public calendar is imprecise; it is simply an agreed-upon designation of days.

From a spiritual perspective, Old Calendarists also point to a number of miraculous occurrences that occur on the old calendar exclusively, such as the "descent of the cloud on the mount" on the feast of the Transfiguration. After the calendar change was instituted, the followers of the old calendar in Greece apparently witnessed the appearance of a cross in the sky, visible to thousands on the feast of the Exaltation of the Holy Cross, 1925, of which eyewitness accounts were recorded.

For such special events, if the original Julian date and year is known then the option always exists to calculate what was the proleptic Revised Julian date of that event and then observe its anniversary on that day, if that could be socially and ritually accepted.

The calendrical arithmetic discussed here is adapted from Gregorian and Julian calendar arithmetic published by Dershowitz and Reingold, although those authors explicitly ignored the Revised Julian calendar. Their book, referred to hereinafter as "CC3", should be consulted for methods to handle BC dates and the traditional omission of a year zero, both of which are ignored here. They define the MOD operator as x MOD y = x â y Ã floor(x / y), because that expression is valid for negative and floating point operands, returning the remainder from dividing x by y while discarding the quotient. Expressions like floor(x / y) return the quotient from dividing x by y while discarding the remainder.

"isLeapYear" = ("year" MOD 4 = 0)

IF "isLeapYear" THEN
END IF

Calendrical calculations are made consistent and straightforward for arithmetic operations if dates are first converted to an ordinal number of days relative to an agreed-upon epoch, in this case the Revised Julian epoch, which was the same as the Gregorian epoch. To find the difference between any two Revised Julian dates, convert both to ordinal day counts and simply subtract. To find a past or future date, convert a given date to an ordinal day count, subtract or add the desired number of days, then convert the result to a Revised Julian date.

The arithmetic given here will not "crash" if an invalid date is given. To verify that a given date is a valid Revised Julian date, convert it to an ordinal day count and then back to a Revised Julian dateâif the final date differs from the given date then the given date is invalid. This method should also be used to validate any implementation of calendrical arithmetic, by iteratively checking thousands of random and sequential dates for such errors.

To convert a Revised Julian date to any other calendar, first convert it to an ordinal day count, and then all that is needed is a function to convert the ordinal days count to that calendar.
To convert a date from any other calendar to a Revised Julian date, first convert that calendar date to an ordinal day count, then convert ordinal days to the Revised Julian date.

The following constant defined midnight at the start of Revised Julian date Monday, as the beginning of the first ordinal day. This moment was Julian day number 1721425.5.

CC3 outlines functions for Gregorian and Julian calendar conversions, as well as many other calendars, always calculating in terms of the ordinal day number, which they call the "fixed date" or "rata die" (RD), assigning the number 1 to the Gregorian calendar epoch. The arithmetic herein, by using the same ordinal day numbering epoch, is fully compatible with all CC3 functions for calendrical calculations and date inter-conversions.

One can assign a different integer to the Revised Julian epoch, for the purpose of numbering ordinal days relative to some other epoch, but if you do so then one must take the epoch difference into account when using any CC3 calendar functions and when converting an ordinal day number to a weekday number.

Optionally the ordinal day number can include a fractional component to represent the time as the elapsed fraction of a day. The ordinal day number of the J2000 moment ( noon) was 730120.5.

Convert a "year", "month", and "day" to the corresponding fixed day number:

If "month" is after February then subtract 1 day for a leap year or subtract 2 days for a common year:

Finally subtract a day for each prior century year (most of which are non-leap) and then add back in the number of prior century leap years:

Convert an ordinal day number to the corresponding Revised Julian "year", "month", and "day", starting by removing any fractional time-of-day portion:

Finally, calculate the day number within the month by subtracting the Fixed days count for the start of the month from the originally given Fixed days count, and then add one day:

Convert the ordinal number of days since the Revised Julian epoch to a weekday number (Sunday=1 through Saturday = 7):

Don't be tempted to omit subtracting the "RJepoch" just because it is offset by adding +1. As written, this expression is robust even if you assign a value other than one to the epoch.




</doc>
<doc id="26254" url="https://en.wikipedia.org/wiki?curid=26254" title="Reform of the date of Easter">
Reform of the date of Easter

A reform of the date of Easter has been proposed several times because the current system for determining the date of Easter is seen as presenting two significant problems:


There have been controversies about the "correct" date of Easter since antiquity, leading to schisms and excommunications or even executions due to heresy, but most Christian churches today agree on certain points. Easter should therefore be celebrated:


There is less agreement whether Easter also should occur:


The disagreements have been particularly about the determination of moon phases and the equinox, some still preferring astronomical observation from a certain location (usually Jerusalem, Alexandria, Rome or local), most others following nominal approximations of these in either the Hebrew, Julian or Gregorian calendar using different lookup tables and cycles in their algorithms.

It has been proposed that the first problem could be resolved by making Easter occur on a date fixed relative to the western Gregorian calendar every year, or alternatively on a Sunday within a fixed range of seven or eight dates. While tying Easter to one fixed date would serve to underline the belief that it commemorates an actual historical event, without an accompanying calendar reform that changes the pattern of the days of the week (itself a subject of religious controversy) or adopted a leap week, it would also break the tradition of Easter always being on a Sunday, established since the 2nd century and by now deeply embedded in the liturgical practice and theological understanding of almost all Christian denominations. 

The Second Ecumenical Council of the Vatican agreed in 1963 to accept a fixed Sunday in the Gregorian calendar as the date for Easter as long as other Christian churches agreed on it as well. They also agreed in principle to adopt a civil calendar reform as long as there were never any days outside the cycle of seven days per week.
The Pepuzites, a 5th-century sect, celebrated Easter on the Sunday following April 6 (in the Julian calendar). This is equivalent to the Sunday closest to April 9. The April 6 date was apparently arrived at because it was equivalent to the 14th of the month of Artemisios in an earlier calendar used in the area, hence, the 14th of the first month of spring.
The two most widespread proposals for fixing the date of Easter would set it on either the second Sunday in April (8 to 14, week 14 or 15), or the Sunday after the second Saturday in April (9 to 15). They only differ in years with dominical letter G or AG where 1 April is a Sunday. In both schemes, account has been taken of the fact thatâin spite of the many difficulties in establishing the dates of the historical events involvedâmany scholars attribute a high degree of probability to Friday 7 April 30, as the date of the crucifixion of Jesus, which would make 9 April the date of the Resurrection. Another date which is supported by many scholars is 3 April 33, making 5 April the date of the Resurrection.

In the late 1920s and 1930s, this idea gained some momentum along with other calendar reform proposals, such as the International Fixed Calendar and the World Calendar. In 1928, a law was passed in the United Kingdom authorising an Order in Council which would fix the date of Easter in that country as the Sunday after the second Saturday in April. However, this was never implemented.
The Sunday after the first Wednesday in April would always be in ISO week 14, except for leap years starting on Thursday (DC) where the week count is one higher than in otherwise equivalent common years after February. The Symmetry454 Calendar proposes a fixed date of Easter in week 14, which would agree with the aforementioned proposals in most years, but would be 1 week earlier in F/GF years (like the only deviation of the Pepuzite definition) and also in DC, D/ED and E/FE years. 

The Sunday of an ordinal ISO week "n" is also the "n"th Sunday of the year, except in A/AG, B/BA and C/CB years where it is the "n"+1st Sunday, so both major proposals put Easter on the 15th Sunday of the year except either in common years starting on Monday (G), where 8 April, i.e. the second Sunday in April, is the 14th Sunday of the year, or in leap years starting on Sunday (AG), where 15 April, i.e. the Sunday after the second Saturday in April, is the 16th Sunday of the year.

In 1977, some Eastern Orthodox representatives objected to separating the date of Easter from lunar phases.

Proposals to resolve the second problem have made greater progress, but they are yet to be adopted.

An astronomical rule for Easter was proposed by the 1923 that also proposed the Revised Julian calendar: Easter was to be the Sunday after the midnight-to-midnight day at the meridian of the Church of the Holy Sepulchre in Jerusalem (35Â°â13â²â47.2â³âE or UTâ+â2â20â55 for the small dome) during which the first full moon after the vernal equinox occurs.

Although the instant of the full moon must occur after the instant of the vernal equinox, it may occur on the same day. If the full moon occurs on a Sunday, Easter is the following Sunday. This proposed astronomical rule was rejected by all Orthodox churches and was never considered by any Western church.

The World Council of Churches (WCC) proposed a reform of the method of determining the date of Easter at a summit in Aleppo, Syria, in 1997: Easter would be defined as the first Sunday following the first astronomical full moon following the astronomical vernal equinox, as determined from the meridian of Jerusalem. The reform would have been implemented starting in 2001, since in that year the Eastern and Western dates of Easter would coincide.

This reform has not been implemented. It would have relied mainly on the co-operation of the Eastern Orthodox Church, since the date of Easter would change for them immediately; whereas for the Western churches, the new system would not differ from that currently in use until 2019. However, Eastern Orthodox support was not forthcoming, and the reform failed. The much greater impact that this reform would have had on the Eastern churches in comparison with those of the West led some Orthodox to suspect that the WCC's decision was an attempt by the West to impose its viewpoint unilaterally on the rest of the world under the guise of ecumenism. However, it could also be argued that it is fair to ask a significant change of Eastern Christians, as they would be simply making the same substantial changes the various Western Churches have already made in 1582 (when the Catholic Church first adopted the Gregorian calendar) and subsequent years so as to bring the calendar and Easter more in line with the seasons.

In 2008 and 2009, there was a new attempt to reach a consensus on a unified date on the part of Catholic, Orthodox and Protestant leaders. This effort largely relies on earlier work carried out during the 1997 Aleppo conference. It was organized by academics working at the Institute of Ecumenical Studies of Lviv University.

Part of this attempt was reportedly influenced by ecumenical efforts in Syria and Lebanon, where the Greek-Melkite Church has played an important role in improving ties with the Orthodox. There is also a series of apparition phenomena known as Our Lady of Soufanieh that has urged for a common date of Easter.

In May 2015, on the anniversary of the meeting between himself and Pope Francis, Coptic Pope Tawadros II wrote a letter to Pope Francis asking for him to consider making renewed effort at a unified date for Easter.

In response, on 12 June 2015, Catholic Pope Francis remarked to the International Catholic Charismatic Renewal Services 3rd World Retreat of Priests at the Basilica of Saint John Lateran in Rome that "we have to come to an agreement" for a common date on Easter. , an historian, writing in the Vatican daily newspaper L'Osservatore Romano, said the Pope is offering this initiative to change the date of Easter "as a gift of unity with the other Christian churches" adding that a common date for Easter would encourage "reconciliation between the Christian churches and â¦a sort of making sense out of the calendar". A week later Aphrem II, the Syriac Orthodox Patriarch of Antioch, met with Pope Francis and noted that the celebration of Easter "on two different dates is a source of great discomfort and weakens the common witness of the church in the world."

In January 2016, the Archbishop of Canterbury Justin Welby announced that he on behalf of the Anglican Communion had joined discussions with Catholic, Coptic and Orthodox representatives over a fixed date for Easter, and that he hoped it would happen within the next five to ten years. Welby has suggested that Easter be fixed on either the second or third Sunday of April relative to the Gregorian calendar. This proposal remains to be approved, especially by Eastern churches which currently determine Easter using the Julian calendar. 

According to international standards, Easter Sunday ends the week containing Good Friday and the week of the second Sunday in April has the ordinal number 14 or 15 (dominical letters D/DC, E/ED, F/FE and GF, i.e. 46.25% of years), hence the third Sunday is one respective week later. There currently is no public proposal under discussion that used a fixed week of the year for Easter and dependent feasts. The second Sunday in April is usually the 15th Sunday of the year (except for dominical letter G, 10.75%), which is almost always also the Sunday after the second Saturday in April (except for dominical letter AG, 3.75%).




</doc>
<doc id="26255" url="https://en.wikipedia.org/wiki?curid=26255" title="Robert Lowth">
Robert Lowth

Robert Lowth (; 27 November 1710 â 3 November 1787) was a Bishop of the Church of England, Oxford Professor of Poetry and the author of one of the most influential textbooks of English grammar.

Lowth was born in Hampshire, Great Britain, the son of Dr William Lowth, a clergyman and Biblical commentator. He was educated at Winchester College and became a scholar of New College, Oxford in 1729. Lowth obtained his BA in 1733 and his Master of Arts degree in 1737. In 1735, while still at Oxford, Lowth took orders in the Anglican Church and was appointed vicar of Ovington, Hampshire, a position he retained until 1741, when he was appointed Oxford Professor of Poetry.

Bishop Lowth made a translation of the book of Isaiah, first published in 1778. The Seventh-day Adventist theologian E. J. Waggoner said in 1899 that Lowth's translation of Isaiah was "without doubt, as a whole, the best English translation of the prophecy of Isaiah".

In 1750 he was appointed Archdeacon of Winchester. In 1752 he resigned the professorship at Oxford and married Mary Jackson. Shortly afterwards, in 1753, Lowth was appointed rector of East Woodhay. In 1754 he was awarded a Doctorate in Divinity by Oxford University, for his treatise on Hebrew poetry entitled "Praelectiones Academicae de Sacra Poesi Hebraeorum" ("On the Sacred Poetry of the Hebrews"). This derives from a series of lectures and was originally published in Latin. An English translation was published by George Gregory in 1787 as ""Lectures on the Sacred Poetry of the Hebrews"". This and subsequent editions include the life of Bishop Lowth as a preface. There was a further edition issued in 1815. This was republished in North America in 1829 with some additional notes. However, apart from those notes, the 1829 edition is less useful to a modern reader. This is because the editor of that edition chose to revert to citing many of the scriptural passages that Lowth uses as examples, and some of the annotations by Michaelis (Johann David Michaelis) and others, in Latin.

Lowth was appointed a fellow of the Royal Societies of London and GÃ¶ttingen in 1765. He was consecrated bishop of St David's in 1766; however, before the end of the year he was transferred to the see of Oxford. He remained Bishop of Oxford until 1777 when he was appointed Bishop of London as well as dean of the chapel royal and privy councillor. In 1783 he was offered the chance to become Archbishop of Canterbury, but declined due to failing health.

Lowth was good friends with the Scottish Enlightenment figure David Hume, as noted by the prominent Scottish bookseller Andrew Millar. Millar commented that "Hume and he are very great, tho' one orthodox and ye other Heterodox".
Lowth wrote a Latin epitaph, "Cara, Vale" ("Dear one, farewell!") on the death of his daughter Maria. Much admired in the late 18th and early 19th centuries, it was set to music by the English composer John Wall Callcott.

Lowth died in 1787, and was buried in the churchyard of All Saints Church, Fulham.

Lowth seems to have been the first modern Bible scholar to notice or draw attention to the poetic structure of the Psalms and much of the prophetic literature of the Old Testament. In Lecture 19 he sets out the classic statement of parallelism, which remains the most fundamental category for understanding Hebrew poetry. He identifies three forms of parallelism, the synonymous, antithetic and synthetic (i.e., balance only in the manner of expression without either synonymy or antithesis). This idea has been influential in Old Testament Studies to the present day.

Lowth is also remembered for his publication in 1762 of "A Short Introduction to English Grammar". Prompted by the absence of simple and pedagogical grammar textbooks in his day, Lowth set out to remedy the situation. Lowth's grammar is the source of many of the prescriptive shibboleths that are studied in schools, and established him as the first of a long line of usage commentators who judge the English language in addition to describing it. An example of both is one of his footnotes: ""Whose" is by some authors made the possessive case of "which", and applied to things as well as persons; I think, improperly."

His most famous contribution to the study of grammar may have been his tentative suggestion that sentences ending with a prepositionâsuch as "what did you ask for?"âare inappropriate in formal writing. (This is known as preposition stranding.) In what may have been intentional self-reference, Lowth used that very construction in discussing it. "This is an Idiom which our language is strongly inclined to; it prevails in common conversation, and suits very well with the familiar style in writing; but the placing of the Preposition before the Relative is more graceful, as well as more perspicuous; and agrees much better with the solemn and elevated Style." Others had previously expressed this opinion; the earliest known is John Dryden in 1672.

Lowth's method included criticising "false syntax"; his examples of false syntax were culled from Shakespeare, the King James Bible, John Donne, John Milton, Jonathan Swift, Alexander Pope, and other famous writers. His understanding of grammar, like that of all linguists of his period, was influenced by the study of Latin, though he was aware that this was problematic and condemned "forcing the English under the rules of a foreign Language". Thus Lowth condemns Addison's sentence "Who should I meet the other night, but my old friend?" on the grounds that the thing acted upon should be in the "Objective Case" (corresponding, as he says earlier, to an oblique case in Latin), rather than taking this example and others as evidence from noted writers that "who" can refer to direct objects.

Lowth's dogmatic assertions appealed to those who wished for certainty and authority in their language. Lowth's grammar was not written for children; however, within a decade after it appeared, versions of it adapted for the use of schools had appeared, and Lowth's stylistic opinions acquired the force of law in the schoolroom. The textbook remained in standard usage throughout educational institutions until the early 20th century.
Lowth has been regarded as the first imagery critic of Shakespeare's plays and highlighted the importance of the imagery in the interpretation of motives and actions of characters and dramatic movement of the plot and narrative structure.


"A Short Introduction to English Grammar", p.Â 107, condemning Richard Bentley's "corrections" of some of Milton's constructions.
"Ibid"., pp.Â 127â128.
Notes & Queries (OUP) in 1983 Vol. 30, Page 55-58 by Sailendra Kumar Sen, "Robert Lowth :the first imagery critic of Shakespeare".




</doc>
<doc id="26259" url="https://en.wikipedia.org/wiki?curid=26259" title="Robert Askin">
Robert Askin

Sir Robert William Askin, GCMG (4 April 1907 â 9 September 1981), was an Australian politician and the 32nd Premier of New South Wales from 1965 to 1975, the first representing the Liberal Party. He was born in 1907 as Robin William Askin, but always disliked his first name and changed it by deed poll in 1971. Before being knighted in 1972, however, he was generally known as Bob Askin. Born in Sydney in 1907, Askin was educated at Sydney Technical High School. After serving as a bank officer and as a Sergeant in the Second World War, Askin joined the Liberal Party and was elected to the seat of Collaroy at the 1950 election.

Askin quickly rose through party ranks, eventually becoming Deputy Leader following Walter Howarth's resignation in July 1954. When long-serving party leader Vernon Treatt announced his resignation in August 1954, Askin put his name forward to replace him. At the vote, he became deadlocked against Pat Morton and Askin asked his former commanding officer Murray Robson to take the leadership instead. Robson did not live up to expectations and was deposed in September 1955 by Morton, who then became Leader. Askin remained as Deputy until, after leading the party to a second electoral defeat in 1959, Morton was deposed and Askin was elected to succeed him. At the May 1965 election, Askin presented the Liberal Party as a viable alternative government. He won a narrow victory, ending a 24-year Labor hold on government.

Askin's time in office was marked by a significant increase in public works programs, strong opposition to an increase in Commonwealth powers, laissez-faire economic policies and wide-ranging reforms in laws and regulations such as the Law Reform Commission, the introduction of consumer laws, legal aid, breath-testing of drivers, the liberalisation of liquor laws and the restoration of Postal voting in NSW elections. More controversial changes included the 1967 abolition of Sydney City Council and increased rates of development in Sydney, often at the expense of architectural heritage and historic buildings. This culminated in the 'Green ban' movement of the 1970s led by the Union movement to conserve the heritage of Sydney.

At the end of his term, after winning another three elections, Askin was the longest-serving Premier of New South Wales; his record has since been overtaken by Neville Wran and Bob Carr. Askin remains the longest-serving Leader of the New South Wales Liberal Party. Since his death in 1981, however, Askin's legacy has been tarnished by persistent allegations that he was involved in organised crime and official corruption.

Robin William Askin was born in Sydney, New South Wales on 4 April 1907 at the Crown Street Women's Hospital, the eldest of three sons of Ellen Laura Halliday (nÃ©e Rowe) and William James Askin, an Adelaide-born sailor and worker for New South Wales Railways. His parents later married on 29 September 1916. Askin spent his early years in Stuart Town before his family moved to Glebe, a working-class inner-city suburb of Sydney. After primary education at Glebe Public School, Askin was awarded a bursary to study at Sydney Technical High School, where he sat in the same class as the future aviator Charles Kingsford Smith. At school he gained good marks, with a particular interest in Mathematics and History, and enjoyed swimming and Rugby League. He completed his Intermediate Certificate in 1921.

At the age of 15, after a short time in the electrical trade, in 1922 Askin joined the Government Savings Bank of New South Wales as a Clerk. However, when the Savings Bank closed due to the Great Depression in 1931, he joined the Rural Bank of New South Wales. Between 1925 and 1929 Askin served part-time as a Lieutenant in the 55th Battalion, Citizens Military Forces. On 5 February 1937 Askin married Mollie Isabelle Underhill, a typist at the bank, at Gilbert Park Methodist Church, Manly. They lived in Manly for the rest of their lives. He began his interest in politics by assisting in Percy Spender's successful campaign for Askin's local seat of Warringah as an Independent candidate at the 1937 Federal election. In 1940 Askin was appointed manager of the Bank service department, which focused on public relations. He served as Vice-President from 1939 to 1940 and President from 1940 to 1941 of the Rural Bank branch of the United Bank Officersâ Association.

Askin enlisted as a Private in the Second Australian Imperial Force on 30 March 1942. An instructor with the 14th Infantry Training Battalion at Dubbo, he was appointed Acting Corporal, then reverted to Private. In November 1942 he joined the 2/31st Infantry Battalion in New Guinea, where he served for two months. He was in New Guinea for another six months from July 1943. Landing at Balikpapan, Borneo, in July 1945, Askin was promoted to Sergeant under Lieutenant Colonel Murray Robson. When hostilities ceased, he unsuccessfully attempted to set up an import business in Bandjermasin. Returning to Australia in February 1946, he was demobilised on 22 March.

Upon demobilisation, Askin returned to work at the Rural Bank, managing its travel department. However, his interest in politics arose again when he assisted his former commanding officer, Lieutenant Colonel Robson, in retaining his seat of Vaucluse at the 1947 state election for the newly formed Liberal Party, which Askin then joined. Rapidly rising through the party ranks, Askin soon became President of the Liberals' Manly branch and supported Bill Wentworth's successful bid for the new seat of Mackellar at the 1949 election.

Askin gained preselection for and won the newly created seat of Collaroy, located in the Northern Beaches, at the 17 June 1950 election, gaining 63.69% of the vote. The Leader of the Liberal Party since 1946, Vernon Treatt led the Liberal/Country Coalition at the election, which resulted in a hung parliament, with Treatt's Coalition gaining 12 seats and a swing of 6.7% for a total of 46 seats. With the Labor Party also holding 46 seats, the balance of power lay with the two re-elected Independent Labor member, James Geraghty and John Seiffert, who had been expelled from the party for disloyalty during the previous parliament. Under a legalistic interpretation of the ALP rules, Seiffert was readmitted to the party and, together with the support of Geraghty, Premier James McGirr and Labor were able to stay in power. As the new local member for a constituency covering most of the Northern Beaches from North Manly to Pittwater, Askin protested against the lack of government development and services in the area, such as sewerage, education, and transport.

Labor's near-defeat weakened McGirr's position and he was replaced as premier by Joseph Cahill in April 1952. Cahill had won popular support as a vigorous and impressive minister who had resolved problems with New South Wales' electricity supply and in his first 10 months as premier had reinvigorated the party. He appeared decisive and brought order to the government's chaotic public works program. In addition, he attacked the increasingly unpopular federal Coalition government of Robert Menzies. All this contributed to Treatt's Coalition being defeated at the 14 February 1953 election, with a total loss of ten seats and a swing against them of 7.2%. Askin retained his seat with 63.35%.

With confidence in his leadership demolished, Treatt's Liberal Party descended into factional in-fighting culminating in the resignation of Deputy Leader Walter Howarth on 22 July 1954, who publicly announced it on 4 July citing that he felt that Treatt doubted his loyalty. He was replaced by now-Party Whip Askin. The resignation split the party and sparked a leadership challenge from Pat Morton. At the party meeting on 6 July, Treatt narrowly defeated Morton with 12 votes to 10. With party support eroded, Treatt did not remain long as leader afterwards. On Friday 6 August 1954, Treatt announced that he would resign as leader. At the following party meeting, after a deadlocked vote between Askin and Morton, Askin asked his friend Murray Robson to nominate and subsequently he was elected to succeed Treatt.

Like other senior members of the party, after having no conservative government since Alexander Mair in 1941, Robson had no experience in government, had little interest in policy and alienated many party members by trying to forge a closer alliance with Michael Bruxner's Country Party. Over a year after Robson assumed the leadership, at a party meeting on 20 September 1955, senior party member Ken McCaw moved that the leadership be declared vacant, citing that Robson's leadership lacked the qualities necessary for winning the next election. The motion was carried 15 votes to 5. Morton was then elected unopposed as leader, with Askin remaining as Deputy Leader.

Morton then led the party to defeat at the election on 3 March 1956. The Coalition gained six seats, reducing the government's majority from twenty to six. Askin retained Collaroy with 70.14%. Morton again led the opposition to the ballot at the 21 March 1959 election, which resulted in an overall gain of three seats but the loss of two seats to Labor. After counting was finalised the Cahill Government was left with an overall majority of four seats. Askin retained his seat with 71.09%.

Morton's refusal to give up his many business interests while as leader led many to accuse him of being a 'part-time leader' and together with his second election loss, eroded confidence in his leadership. On 14 July 1959, three Liberal MLAs called on Morton to resign, stating that the party needed a full-time leader and that Morton no longer commanded the majority support of his colleagues. Morton refused and instead called an emergency meeting on 17 July to confirm his leadership. By this time, Askin had emerged as one of the main opponents to his longtime friend and former commander. However, he and the other major challenger to Morton's leadership, Eric Willis declared that they would only take the leadership if they were given an absolute majority of 28 votes. At the party meeting, a spill motion to remove Morton as leader carried by two votes. Willis then surprised many by deciding not to put his name forward for nomination, leaving Askin to take the leadership unopposed. Willis was eventually elected as Deputy Leader. Upon election, Askin declared that "One of my main tasks will be to sell our [Liberal Party] ideas and principles to the working man."

When Premier Cahill died on 22 October 1959, he was replaced by Askin's friend and parliamentary contemporary, Robert "Bob" Heffron, which tended to calm his aggression and opposition towards the government. At the March 1962 election, Labor had been in power for 21 years and Heffron had since been Premier for 2 and a half years. Heffron was 72 at the time of the election and his age and the longevity of the government were made issues by the Askin's opposition which described it as being composed of "tired old men". The standing of Heffron's government suffered when the electors rejected its proposal to abolish the New South Wales Legislative Council at a referendum in April 1961, being the first time Labor had lost a state electoral poll in 20 years. Askin's successful opposition campaign centred on warning of a Labor-dominated single house subject to "Communist and Trades Hall influence".

Labor's policies for the election included the establishment of a Department of Industrial Development to reduce unemployment, free school travel, aid to home buyers and commencing the construction of the SydneyâNewcastle Freeway as a toll-road. By contrast, Askin put forward a wide-ranging program of reform and addressed contentious issues including the introduction of State Aid for private schools, making rent control fairer and the legalisation of off-course betting on horse races. Askin accused the state government of allowing the transport infrastructure of the state to decline and promised to build the Newcastle freeway without a toll, to construct the Eastern Suburbs Railway and to plan for a second crossing of Sydney Harbour. Askin also made promises for more resources in mental health and district hospitals.

Despite these promises, Askin and the new Country Party Leader, Charles Cutler, lost the election to Heffron, mainly due to the adverse reactions of voters towards the November 1960 "horror budget" and credit squeeze made by the federal Coalition government under Menzies. The Coalition lost five seats, despite a small swing of 0.16% and the Coalition gaining the support of prominent media businessman, Frank Packer, who helped project the image of Askin and the Liberals as a viable alternative government. Askin retained his seat with 72.53%.

The 1965 campaign against the Labor Governmentâled since April 1964 by Jack Renshawâa government widely perceived to be tired and devoid of ideas, was notable for being one of Australia's first "presidential-style" campaigns, with Askin being the major focus of campaigning and a main theme of "With Askin You'll Get Action". He received vigorous support from the newspapers and TV stations owned by Packer. At the May 1965 election, the Liberal/Country Coalition gained 49.8% of the vote to 43.3% to the ALP. While the Liberals took only two seats from Labor, Askin got the support of the two independent members, Douglas Darby (Manly) and Harold Coates (Hartley), giving him enough support to end Labor's 24-year run in power. He officially took office on 1 May, with Charles Cutler of the Country Party as Deputy Premier.

The Askin Government was sworn in by the Governor of New South Wales, Sir Eric Woodward, on 13 May at Government House. It was the first to be headed by the Liberal Party since the main non-Labor party in the state adopted the Liberal banner; being one of only three Liberals to win power from Labor. Askin, who served as his own Treasurer, heavily involved himself in the business of Government, while also maintaining a range of social agendas and regular outings to the racetrack or Rugby League games. One of the privileges of office was the access to a Ministerial car and personal driver, which became particularly important for Askin, who did not drive. On one occasion when Askin was supposed to drive a new Holden from the factory assembly line during a visit, Askin arranged for his driver, Russ Ferguson, to be hidden on the car floor working the controls while Askin held the wheel.

Askin's government was marked by strong opposition to an increase in Commonwealth powers, a tough stance on "law and order" issues, laissez-faire economic policies, and aggressive support for industrial and commercial development. At his first Cabinet meeting, Askin restored direct air services between Sydney and Dubbo, and required Joern Utzon, the Danish architect then working on the Sydney Opera House, to provide a final price and completion date for the Opera House, which had gone past the original estimates for both. His Public Works Minister Davis Hughes began to assert control over the project and demanded that costs be reined in. This brought him into direct conflict with Utzon and in February 1966, after a bitter standoff and the suspension of progress payments by Hughes, Utzon resigned, sparking a major public outcry. Two weeks after the first Government meeting, the Askin Government abolished the tow-away system for Sydney and Newcastle. In 1966 the University of New South Wales awarded him an honorary Doctor of Letters (D.Litt).

Despite a hostile Legislative Council, an extended drought and various industrial disputes, Askin and his Government passed several reforms. Among them were the removal of trading-hours restrictions on small businesses, abolishing juries for motor accident damage cases, extending the hours for liquor trading, thereby bringing an end to the "Six o'clock swill". The Government also moved into legal and local government reforms, attacking pollution and restoring the previously abolished postal voting rights in state elections. Askin also addressed the demands of the New England New State Movement by holding a referendum in 1967, which was defeated by a large margin.

Many of his governmentâs reforms were due to his Minister for Justice, John Maddison, and Attorney-General Sir Kenneth McCaw, who initiated the establishment of the Law Reform Commission of New South Wales, the introduction of consumer laws, an ombudsman, legal aid, health labels on cigarette packs, breath-testing of drivers, limits on vehicle emissions, the liberalisation of liquor laws, and compensation for victims of violent crime. There was also a new National Parks and Wildlife Service to assist environment conservation and protection. Despite these positive reforms, Askin's government maintained a brutal prison and corrective regime that was to culminate in the Bathurst Gaol riots in 1970 and 1974.

Askin, along with his Minister for Local Government, Pat Morton, oversaw the rapid escalation of building development in inner-city Sydney and the central business district, which followed in the wake of his controversial 1967 abolition of Sydney City Council and a redistribution of municipal electoral boundaries that was aimed at reducing the power of the rival Labor Party. On its abolition, Morton commented that it was "essential for Sydney's progress" and replaced the City Council with a Commission, headed by another former Liberal leader, Vernon Treatt.

The Sydney metropolitan area at the time was marked by increasing strains on state infrastructure and Askin's Government's pro-development stance was largely attributed as an attempt to alleviate these problems. Despite this, the newly established State Planning Authority were continuously criticised for not being totally accountable to the public, particularly as the pro-business Sydney Commissioners worked side-by-side with the Planning authority to increase developments in the Sydney CBD to their highest levels ever, embodied by the construction of the MLC Centre, the demolition of the Theatre Royal, Sydney and the Australia Hotel. Other controversial schemes proposed by his government were a massive freeway system that was planned to be driven through the hearts of historic inner-city suburbs including Glebe and Newtown and an equally ambitious scheme of 'slum clearance' that would have brought about the wholescale destruction of the historic areas of Woolloomooloo and The Rocks. This eventually culminated in the 1970s Green ban movement led by Unions Leader Jack Mundey, to protect the architectural heritage of Sydney.

At the 24 February 1968 election, Askin increased his previously tenuous majority, scoring a six-seat swing against Labor's Renshaw and an overall majority of 12 over the Labor Party and the two Independents. Askin retained his seat with 70.97%. It was the first time since the UAP/Country Coalition won three consecutive elections from 1932 to 1938 that a non-Labor government in New South Wales had been reelected.

In mid-1968 Askin famously became embroiled in a media controversy over the reporting of several words spoken to the United States Chamber of Commerce lunch in Sydney on 32 July 1968 (also the day Opposition Leader Renshaw resigned, to be replaced by Pat Hills), in which he spoke of the October 1966 state visit by United States President Lyndon B. Johnson. Askin had joined Prime Minister Harold Holt, President Johnson and the American Ambassador, Ed Clark, in a drive through the Sydney CBD. As Johnson's motorcade drove into Liverpool Street, several anti-Vietnam War protesters, including Graeme Dunstan, threw themselves in front of the car carrying them. As Askin later recalled, a police officer had informed him that some communists were obstructing the route. Askin claimed he had instructed the officer to drag them off. As the car moved on, he then said to Johnson "half-jocularly": "what I ought to have told him was to ride over them", to which Johnson replied "a man after my own heart". At the subsequent luncheon, Askin instead reported that he had said the remark to the police officer, which a journalist attending the event later reported it as "Run over the bastards."

As Treasurer, Askin focused on the state budget and on Commonwealth-State financial relations. His attitude towards the Commonwealth and the Federal was shaped by his first premiersâ conference in 1965 when Prime Minister Menzies negotiated with the Victorian premier Henry Bolte to achieve an extra grant of funds for Victoria at the expense of the other states and closed the conference before the other Premiers could object. At subsequent premiersâ conferences he opposed the 'centralising' tendencies of Canberra and became a strong advocate of the rights of the states.

With John Gorton becoming Prime Minister after Holt's death, Askin came into conflict with the Commonwealth Government over Gorton's determination to maintain federal command over taxation and in June 1968 declared that he could veto any form of state taxation. In late 1969, Askin, with Bolte, organised an 'emergency' premiers' conference, without Gorton, to publicise the disadvantages of the States, a move that was partly responsible for the party deposition of Gorton in 1971.

Askin had a greater dislike for Gorton's successor, William McMahon and received financial support from McMahon only when Askin threatened to release a NSW "horror budget" that could damage Federal Liberal voting intentions. However, when McMahon lost the 1972 election to Labor Leader Gough Whitlam, relations between Sydney and Canberra got even worse. Whitlam's centralising economic policies and decision to end legal appeals to the Privy Council of the United Kingdom drew criticism from Askin.

At the 13 February 1971 state election, the Coalition suffered a swing of four seats, but still managed a narrow win against Labor and new leader Pat Hills, taking 49 seatsâa bare majority of oneâin the expanded 96-seat Legislative Assembly.

Throughout his time as Premier, he was assisted by Charles Cutler as Deputy Premier and Leader of the Country Party. Cutler served as Acting Premier at times when Askin was suffering from illness, having suffered two heart attacks in 1969 and 1973. In 1972 the Eastern Orthodox Church of Antioch presented Askin with the Order of St Peter and St Paul for his services to ethnic minorities.

In 1971 Askin changed his name from "Robin" to "Robert" by a deed poll. On 1 January 1972, he was appointed a Knight Commander of the Order of St Michael and St George (KCMG). Later that year, taking advantage of unease at the increasingly erratic Labor government of Gough Whitlam and the increasing economic problems seen to be caused by it, Askin called an early election for 1973. However, a setback arose in the northern Sydney seat of Gordon, when the Liberal member and Education Minister, Harry Jago, failed to nominate his candidacy, thereby losing the seat to the Democratic Labor Party before the election took place. However, the Coalition went to a record fourth win against the ALP, led by Pat Hills, increasing the Liberal/Country majority by four seats and making Askin the only major party leader to win four consecutive terms as Premier until Neville Wran of the ALP. Askin contested the election in Pittwater, replacing his former seat of Collaroy. In 1973 he was appointed an Officer of the Lebanese National Order of the Cedar.

His last term in office was marked by tension between the NSW and Victorian Governments and a view that Askin was getting out of touch with the voters. Late in 1974, Askin announced his resignation, and his last intervention was to support his Minister for Lands, Thomas Lewis, in his bid to be Askin's successor instead of the Deputy Leader and Minister for Education, Sir Eric Willis. It was reported that Lewis had offered to upgrade Askin's knighthood from Knight Commander (KCMG) to Knight Grand Cross (GCMG) of the Order of St Michael and St George, while Willis was uncommitted. Askin retired from politics in January 1975 and was succeeded by Lewis as Premier. On 14 June 1975 he was elevated to Knight Grand Cross, for his service as Premier. His resignation began a turbulent year for the government. Lewis was ousted in a party room coup by Willis in 1976, but Willis only lasted four months before losing the 1976 election to Labor, ending the longest unbroken run for a non-Labor government since World War I.

Askin's health declined still further after 1975, and he died of heart failure on 9 September 1981 in St Vincent's Hospital, Sydney. The next day, the "Sydney Morning Herald" editorialised that he was "one of the ablest, most industrious and colourful political leaders of Australia's post-war era".

His state funeral, held on 14Â September, was attended by over 1,000 mourners including Prime Minister Malcolm Fraser, Premier Neville Wran, Mervyn Wood, Justice Lionel Murphy and former NSW Labor Premier and former Governor-General Sir William McKell.

There have been persistent allegations that Askin, allegedly assisted by then Police Commissioner Norman Allan, oversaw the creation of a lucrative network of corruption and bribery that involved politicians, public servants and police and the nascent Sydney organised crime syndicates.

When questioned about his wealth, Askin always attributed it to the salary from his high public office, his frugal lifestyle, good investments and canny punting. After his death the Australian Taxation Office audited his estate, and although it made no finding of criminality, it determined that a substantial part of it came from undisclosed income derived from sources other than shares or gambling.

With Askin's death in 1981, investigative journalists were freed from the threat of legal action under Australia's defamation laws. Stories about his reputed corruption were published almost immediately. Most notable of these was an article that appeared in the "The National Times" co-written by David Marr and David Hickie. Headlined "Askin: friend of organised crime", it was published on the day of Askin's funeral. This was followed by David Hickie's book "The Prince and The Premier", which detailed Askin's long involvement in illegal bookmaking and allegations that he had received substantial and long-running payoffs from organised crime figures.

The allegations of corruption against Askin were revived in 2008 when Alan Saffron, the son of the late Sydney crime boss Abe Saffron, published a biography of his father in which he alleged that Saffron had paid bribes to major public officials including Askin, former police commissioner Norman Allan, and other leading figures whom he claimed he could not name because they were still alive. Alan Saffron alleged that his father made payments of between A$5000 and $10,000 per week to both men over many years, that Askin and Allan both visited Saffron's office on several occasions, that Allan also visited the Saffron family home, and that Abe Saffron paid for an all-expenses overseas trip for Allan and a young female 'friend'. He also alleged that, later in Askin's premiership, Abe Saffron became the "bagman" for Sydney's illegal liquor and prostitution rackets and most illegal gambling activities, collecting payoffs that were then passed to Askin, Allan and others, in return for which his father was completely protected.


Â 


</doc>
<doc id="26262" url="https://en.wikipedia.org/wiki?curid=26262" title="Redshift">
Redshift

In physics, redshift is a phenomenon where electromagnetic radiation (such as light) from an object undergoes an increase in wavelength. Whether or not the radiation is visible, "redshift" means an increase in wavelength, equivalent to a decrease in wave frequency and photon energy, in accordance with, respectively, the wave and quantum theories of light.

Neither the emitted nor perceived light is necessarily red; instead, the term refers to the human perception of longer wavelengths as red, which is at the section of the visible spectrum with the longest wavelengths. Examples of redshifting are a gamma ray perceived as an X-ray, or initially visible light perceived as radio waves. The opposite of a redshift is a blueshift, where wavelengths shorten and energy increases. However, redshift is a more common term and sometimes blueshift is referred to as negative redshift.

There are three main causes of redshifts in astronomy and cosmology:


Knowledge of redshifts and blueshifts has been used to develop several terrestrial technologies such as Doppler radar and radar guns. Redshifts are also seen in the spectroscopic observations of astronomical objects. Its value is represented by the letter "z."

A special relativistic redshift formula (and its classical approximation) can be used to calculate the redshift of a nearby object when spacetime is flat. However, in many contexts, such as black holes and Big Bang cosmology, redshifts must be calculated using general relativity. Special relativistic, gravitational, and cosmological redshifts can be understood under the umbrella of frame transformation laws. There exist other physical processes that can lead to a shift in the frequency of electromagnetic radiation, including scattering and optical effects; however, the resulting changes are distinguishable from true redshift and are not generally referred to as such (see section on physical optics and radiative transfer).

The history of the subject began with the development in the 19th century of wave mechanics and the exploration of phenomena associated with the Doppler effect. The effect is named after Christian Doppler, who offered the first known physical explanation for the phenomenon in 1842. The hypothesis was tested and confirmed for sound waves by the Dutch scientist Christophorus Buys Ballot in 1845. Doppler correctly predicted that the phenomenon should apply to all waves, and in particular suggested that the varying colors of stars could be attributed to their motion with respect to the Earth. Before this was verified, however, it was found that stellar colors were primarily due to a star's temperature, not motion. Only later was Doppler vindicated by verified redshift observations.

The first Doppler redshift was described by French physicist Hippolyte Fizeau in 1848, who pointed to the shift in spectral lines seen in stars as being due to the Doppler effect. The effect is sometimes called the "DopplerâFizeau effect". In 1868, British astronomer William Huggins was the first to determine the velocity of a star moving away from the Earth by this method. In 1871, optical redshift was confirmed when the phenomenon was observed in Fraunhofer lines using solar rotation, about 0.1 Ã in the red.
In 1887, Vogel and Scheiner discovered the "annual Doppler effect", the yearly change in the Doppler shift of stars located near the ecliptic due to the orbital velocity of the Earth. In 1901, Aristarkh Belopolsky verified optical redshift in the laboratory using a system of rotating mirrors.

The earliest occurrence of the term "red-shift" in print (in this hyphenated form) appears to be by American astronomer Walter S. Adams in 1908, in which he mentions "Two methods of investigating that nature of the nebular red-shift". The word does not appear unhyphenated until about 1934 by Willem de Sitter, perhaps indicating that up to that point its German equivalent, "Rotverschiebung", was more commonly used.

Beginning with observations in 1912, Vesto Slipher discovered that most spiral galaxies, then mostly thought to be spiral nebulae, had considerable redshifts. Slipher first reports on his measurement in the inaugural volume of the "Lowell Observatory Bulletin". Three years later, he wrote a review in the journal "Popular Astronomy". In it he states that "the early discovery that the great Andromeda spiral had the quite exceptional velocity of â300 km(/s) showed the means then available, capable of investigating not only the spectra of the spirals but their velocities as well." Slipher reported the velocities for 15 spiral nebulae spread across the entire celestial sphere, all but three having observable "positive" (that is recessional) velocities. Subsequently, Edwin Hubble discovered an approximate relationship between the redshifts of such "nebulae" and the distances to them with the formulation of his eponymous Hubble's law. These observations corroborated Alexander Friedmann's 1922 work, in which he derived the FriedmannâLemaÃ®tre equations. They are today considered strong evidence for an expanding universe and the Big Bang theory.

The spectrum of light that comes from a single source (see idealized spectrum illustration top-right) can be measured. To determine the redshift, one searches for features in the spectrum such as absorption lines, emission lines, or other variations in light intensity. If found, these features can be compared with known features in the spectrum of various chemical compounds found in experiments where that compound is located on Earth. A very common atomic element in space is hydrogen. The spectrum of originally featureless light shone through hydrogen will show a signature spectrum specific to hydrogen that has features at regular intervals. If restricted to absorption lines it would look similar to the illustration (top right). If the same pattern of intervals is seen in an observed spectrum from a distant source but occurring at shifted wavelengths, it can be identified as hydrogen too. If the same spectral line is identified in both spectraâbut at different wavelengthsâthen the redshift can be calculated using the table below. Determining the redshift of an object in this way requires a frequency or wavelength range. In order to calculate the redshift one has to know the wavelength of the emitted light in the rest frame of the source: in other words, the wavelength that would be measured by an observer located adjacent to and comoving with the source. Since in astronomical applications this measurement cannot be done directly, because that would require travelling to the distant star of interest, the method using spectral lines described here is used instead. Redshifts cannot be calculated by looking at unidentified features whose rest-frame frequency is unknown, or with a spectrum that is featureless or white noise (random fluctuations in a spectrum).

Redshift (and blueshift) may be characterized by the relative difference between the observed and emitted wavelengths (or frequency) of an object. In astronomy, it is customary to refer to this change using a dimensionless quantity called . If represents wavelength and represents frequency (note, where is the speed of light), then is defined by the equations:

After is measured, the distinction between redshift and blueshift is simply a matter of whether is positive or negative. For example, Doppler effect blueshifts () are associated with objects approaching (moving closer to) the observer with the light shifting to greater energies. Conversely, Doppler effect redshifts () are associated with objects receding (moving away) from the observer with the light shifting to lower energies. Likewise, gravitational blueshifts are associated with light emitted from a source residing within a weaker gravitational field as observed from within a stronger gravitational field, while gravitational redshifting implies the opposite conditions.

In general relativity one can derive several important special-case formulae for redshift in certain special spacetime geometries, as summarized in the following table. In all cases the magnitude of the shift (the value of ) is independent of the wavelength.
If a source of the light is moving away from an observer, then redshift () occurs; if the source moves towards the observer, then blueshift () occurs. This is true for all electromagnetic waves and is explained by the Doppler effect. Consequently, this type of redshift is called the "Doppler redshift". If the source moves away from the observer with velocity , which is much less than the speed of light (), the redshift is given by

where is the speed of light. In the classical Doppler effect, the frequency of the source is not modified, but the recessional motion causes the illusion of a lower frequency.

A more complete treatment of the Doppler redshift requires considering relativistic effects associated with motion of sources close to the speed of light. A complete derivation of the effect can be found in the article on the relativistic Doppler effect. In brief, objects moving close to the speed of light will experience deviations from the above formula due to the time dilation of special relativity which can be corrected for by introducing the Lorentz factor into the classical Doppler formula as follows (for motion solely in the line of sight):

This phenomenon was first observed in a 1938 experiment performed by Herbert E. Ives and G.R. Stilwell, called the IvesâStilwell experiment.

Since the Lorentz factor is dependent only on the magnitude of the velocity, this causes the redshift associated with the relativistic correction to be independent of the orientation of the source movement. In contrast, the classical part of the formula is dependent on the projection of the movement of the source into the line-of-sight which yields different results for different orientations. If is the angle between the direction of relative motion and the direction of emission in the observer's frame (zero angle is directly away from the observer), the full form for the relativistic Doppler effect becomes:

and for motion solely in the line of sight (), this equation reduces to:

For the special case that the light is moving at right angle () to the direction of relative motion in the observer's frame, the relativistic redshift is known as the transverse redshift, and a redshift:

is measured, even though the object is not moving away from the observer. Even when the source is moving towards the observer, if there is a transverse component to the motion then there is some speed at which the dilation just cancels the expected blueshift and at higher speed the approaching source will be redshifted.

In the early part of the twentieth century, Slipher, Hubble and others made the first measurements of the redshifts and blueshifts of galaxies beyond the Milky Way. They initially interpreted these redshifts and blueshifts as due to random motions, but later Hubble discovered a rough correlation between the increasing redshifts and the increasing distance of galaxies. Theorists almost immediately realized that these observations could be explained by a mechanism for producing redshifts seen in certain cosmological solutions to Einstein's equations of general relativity. Hubble's law of the correlation between redshifts and distances is required by all such models that have a metric expansion of space. As a result, the wavelength of photons propagating through the expanding space is stretched, creating the cosmological redshift.

There is a distinction between a redshift in cosmological context as compared to that witnessed when nearby objects exhibit a local Doppler-effect redshift. Rather than cosmological redshifts being a consequence of the relative velocities that are subject to the laws of special relativity (and thus subject to the rule that no two locally separated objects can have relative velocities with respect to each other faster than the speed of light), the photons instead increase in wavelength and redshift because of a global feature of the spacetime metric through which they are traveling. One interpretation of this effect is the idea that space itself is expanding. Due to the expansion increasing as distances increase, the distance between two remote galaxies can increase at more than 3 m/s, but this does not imply that the galaxies move faster than the speed of light at their present location (which is forbidden by Lorentz covariance).

The observational consequences of this effect can be derived using the equations from general relativity that describe a homogeneous and isotropic universe.

To derive the redshift effect, use the geodesic equation for a light wave, which is

where

For an observer observing the crest of a light wave at a position and time , the crest of the light wave was emitted at a time in the past and a distant position . Integrating over the path in both space and time that the light wave travels yields:

In general, the wavelength of light is not the same for the two positions and times considered due to the changing properties of the metric. When the wave was emitted, it had a wavelength . The next crest of the light wave was emitted at a time

The observer sees the next crest of the observed light wave with a wavelength to arrive at a time

Since the subsequent crest is again emitted from and is observed at , the following equation can be written:

The right-hand side of the two integral equations above are identical which means

Using the following manipulation:

we find that:

For very small variations in time (over the period of one cycle of a light wave) the scale factor is essentially a constant ( today and previously). This yields

which can be rewritten as

Using the definition of redshift provided above, the equation

is obtained. In an expanding universe such as the one we inhabit, the scale factor is monotonically increasing as time passes, thus, is positive and distant galaxies appear redshifted.

Using a model of the expansion of the universe, redshift can be related to the age of an observed object, the so-called "cosmic timeâredshift relation". Denote a density ratio as :

with the critical density demarcating a universe that eventually crunches from one that simply expands. This density is about three hydrogen atoms per cubic meter of space. At large redshifts one finds:

where is the present-day Hubble constant, and is the redshift.

For cosmological redshifts of additional Doppler redshifts and blueshifts due to the peculiar motions of the galaxies relative to one another cause a wide scatter from the standard Hubble Law. The resulting situation can be illustrated by the Expanding Rubber Sheet Universe, a common cosmological analogy used to describe the expansion of space. If two objects are represented by ball bearings and spacetime by a stretching rubber sheet, the Doppler effect is caused by rolling the balls across the sheet to create peculiar motion. The cosmological redshift occurs when the ball bearings are stuck to the sheet and the sheet is stretched.

The redshifts of galaxies include both a component related to recessional velocity from expansion of the universe, and a component related to peculiar motion (Doppler shift). The redshift due to expansion of the universe depends upon the recessional velocity in a fashion determined by the cosmological model chosen to describe the expansion of the universe, which is very different from how Doppler redshift depends upon local velocity. Describing the cosmological expansion origin of redshift, cosmologist Edward Robert Harrison said, "Light leaves a galaxy, which is stationary in its local region of space, and is eventually received by observers who are stationary in their own local region of space. Between the galaxy and the observer, light travels through vast regions of expanding space. As a result, all wavelengths of the light are stretched by the expansion of space. It is as simple as that..." Steven Weinberg clarified, "The increase of wavelength from emission to absorption of light does not depend on the rate of change of [here is the RobertsonâWalker scale factor] at the times of emission or absorption, but on the increase of in the whole period from emission to absorption."

Popular literature often uses the expression "Doppler redshift" instead of "cosmological redshift" to describe the redshift of galaxies dominated by the expansion of spacetime, but the cosmological redshift is not found using the relativistic Doppler equation which is instead characterized by special relativity; thus is impossible while, in contrast, is possible for cosmological redshifts because the space which separates the objects (for example, a quasar from the Earth) can expand faster than the speed of light. More mathematically, the viewpoint that "distant galaxies are receding" and the viewpoint that "the space between galaxies is expanding" are related by changing coordinate systems. Expressing this precisely requires working with the mathematics of the FriedmannâRobertsonâWalker metric.

If the universe were contracting instead of expanding, we would see distant galaxies blueshifted by an amount proportional to their distance instead of redshifted.

In the theory of general relativity, there is time dilation within a gravitational well. This is known as the gravitational redshift or "Einstein Shift". The theoretical derivation of this effect follows from the Schwarzschild solution of the Einstein equations which yields the following formula for redshift associated with a photon traveling in the gravitational field of an uncharged, nonrotating, spherically symmetric mass:

where

This gravitational redshift result can be derived from the assumptions of special relativity and the equivalence principle; the full theory of general relativity is not required.

The effect is very small but measurable on Earth using the MÃ¶ssbauer effect and was first observed in the PoundâRebka experiment. However, it is significant near a black hole, and as an object approaches the event horizon the red shift becomes infinite. It is also the dominant cause of large angular-scale temperature fluctuations in the cosmic microwave background radiation (see SachsâWolfe effect).

The redshift observed in astronomy can be measured because the emission and absorption spectra for atoms are distinctive and well known, calibrated from spectroscopic experiments in laboratories on Earth. When the redshift of various absorption and emission lines from a single astronomical object is measured, is found to be remarkably constant. Although distant objects may be slightly blurred and lines broadened, it is by no more than can be explained by thermal or mechanical motion of the source. For these reasons and others, the consensus among astronomers is that the redshifts they observe are due to some combination of the three established forms of Doppler-like redshifts. Alternative hypotheses and explanations for redshift such as tired light are not generally considered plausible.

Spectroscopy, as a measurement, is considerably more difficult than simple photometry, which measures the brightness of astronomical objects through certain filters. When photometric data is all that is available (for example, the Hubble Deep Field and the Hubble Ultra Deep Field), astronomers rely on a technique for measuring photometric redshifts. Due to the broad wavelength ranges in photometric filters and the necessary assumptions about the nature of the spectrum at the light-source, errors for these sorts of measurements can range up to , and are much less reliable than spectroscopic determinations. However, photometry does at least allow a qualitative characterization of a redshift. For example, if a Sun-like spectrum had a redshift of , it would be brightest in the infrared rather than at the yellow-green color associated with the peak of its blackbody spectrum, and the light intensity will be reduced in the filter by a factor of four, . Both the photon count rate and the photon energy are redshifted. (See K correction for more details on the photometric consequences of redshift.)

In nearby objects (within our Milky Way galaxy) observed redshifts are almost always related to the line-of-sight velocities associated with the objects being observed. Observations of such redshifts and blueshifts have enabled astronomers to measure velocities and parametrize the masses of the orbiting stars in spectroscopic binaries, a method first employed in 1868 by British astronomer William Huggins. Similarly, small redshifts and blueshifts detected in the spectroscopic measurements of individual stars are one way astronomers have been able to diagnose and measure the presence and characteristics of planetary systems around other stars and have even made very detailed differential measurements of redshifts during planetary transits to determine precise orbital parameters. Finely detailed measurements of redshifts are used in helioseismology to determine the precise movements of the photosphere of the Sun. Redshifts have also been used to make the first measurements of the rotation rates of planets, velocities of interstellar clouds, the rotation of galaxies, and the dynamics of accretion onto neutron stars and black holes which exhibit both Doppler and gravitational redshifts. Additionally, the temperatures of various emitting and absorbing objects can be obtained by measuring Doppler broadeningâeffectively redshifts and blueshifts over a single emission or absorption line. By measuring the broadening and shifts of the 21-centimeter hydrogen line in different directions, astronomers have been able to measure the recessional velocities of interstellar gas, which in turn reveals the rotation curve of our Milky Way. Similar measurements have been performed on other galaxies, such as Andromeda. As a diagnostic tool, redshift measurements are one of the most important spectroscopic measurements made in astronomy.

The most distant objects exhibit larger redshifts corresponding to the Hubble flow of the universe. The largest-observed redshift, corresponding to the greatest distance and furthest back in time, is that of the cosmic microwave background radiation; the numerical value of its redshift is about ( corresponds to present time), and it shows the state of the universe about 13.8 billion years ago, and 379,000 years after the initial moments of the Big Bang.

The luminous point-like cores of quasars were the first "high-redshift" () objects discovered before the improvement of telescopes allowed for the discovery of other high-redshift galaxies.

For galaxies more distant than the Local Group and the nearby Virgo Cluster, but within a thousand megaparsecs or so, the redshift is approximately proportional to the galaxy's distance. This correlation was first observed by Edwin Hubble and has come to be known as Hubble's law. Vesto Slipher was the first to discover galactic redshifts, in about the year 1912, while Hubble correlated Slipher's measurements with distances he measured by other means to formulate his Law. In the widely accepted cosmological model based on general relativity, redshift is mainly a result of the expansion of space: this means that the farther away a galaxy is from us, the more the space has expanded in the time since the light left that galaxy, so the more the light has been stretched, the more redshifted the light is, and so the faster it appears to be moving away from us. Hubble's law follows in part from the Copernican principle. Because it is usually not known how luminous objects are, measuring the redshift is easier than more direct distance measurements, so redshift is sometimes in practice converted to a crude distance measurement using Hubble's law.

Gravitational interactions of galaxies with each other and clusters cause a significant scatter in the normal plot of the Hubble diagram. The peculiar velocities associated with galaxies superimpose a rough trace of the mass of virialized objects in the universe. This effect leads to such phenomena as nearby galaxies (such as the Andromeda Galaxy) exhibiting blueshifts as we fall towards a common barycenter, and redshift maps of clusters showing a fingers of god effect due to the scatter of peculiar velocities in a roughly spherical distribution. This added component gives cosmologists a chance to measure the masses of objects independent of the mass-to-light ratio (the ratio of a galaxy's mass in solar masses to its brightness in solar luminosities), an important tool for measuring dark matter.

The Hubble law's linear relationship between distance and redshift assumes that the rate of expansion of the universe is constant. However, when the universe was much younger, the expansion rate, and thus the Hubble "constant", was larger than it is today. For more distant galaxies, then, whose light has been travelling to us for much longer times, the approximation of constant expansion rate fails, and the Hubble law becomes a non-linear integral relationship and dependent on the history of the expansion rate since the emission of the light from the galaxy in question. Observations of the redshift-distance relationship can be used, then, to determine the expansion history of the universe and thus the matter and energy content.

While it was long believed that the expansion rate has been continuously decreasing since the Big Bang, recent observations of the redshift-distance relationship using Type Ia supernovae have suggested that in comparatively recent times the expansion rate of the universe has begun to accelerate.

Currently, the objects with the highest known redshifts are galaxies and the objects producing gamma ray bursts. The most reliable redshifts are from spectroscopic data, and the highest-confirmed spectroscopic redshift of a galaxy is that of GN-z11, with a redshift of , corresponding to 400 million years after the Big Bang. The previous record was held by UDFy-38135539 at a redshift of , corresponding to 600 million years after the Big Bang. Slightly less reliable are Lyman-break redshifts, the highest of which is the lensed galaxy A1689-zD1 at a redshift and the next highest being . The most distant-observed gamma-ray burst with a spectroscopic redshift measurement was GRB 090423, which had a redshift of . The most distant-known quasar, ULAS J1342+0928, is at . The highest-known redshift radio galaxy (TN J0924-2201) is at a redshift and the highest-known redshift molecular material is the detection of emission from the CO molecule from the quasar SDSS J1148+5251 at .

"Extremely red objects" (EROs) are astronomical sources of radiation that radiate energy in the red and near infrared part of the electromagnetic spectrum. These may be starburst galaxies that have a high redshift accompanied by reddening from intervening dust, or they could be highly redshifted elliptical galaxies with an older (and therefore redder) stellar population. Objects that are even redder than EROs are termed "hyper extremely red objects" (HEROs).

The cosmic microwave background has a redshift of , corresponding to an age of approximately 379,000 years after the Big Bang and a comoving distance of more than 46 billion light-years. The yet-to-be-observed first light from the oldest Population III stars, not long after atoms first formed and the CMB ceased to be absorbed almost completely, may have redshifts in the range of . Other high-redshift events predicted by physics but not presently observable are the cosmic neutrino background from about two seconds after the Big Bang (and a redshift in excess of ) and the cosmic gravitational wave background emitted directly from inflation at a redshift in excess of .

In June 2015, astronomers reported evidence for Population III stars in the Cosmos Redshift 7 galaxy at . Such stars are likely to have existed in the very early universe (i.e., at high redshift), and may have started the production of chemical elements heavier than hydrogen that are needed for the later formation of planets and life as we know it.

With advent of automated telescopes and improvements in spectroscopes, a number of collaborations have been made to map the universe in redshift space. By combining redshift with angular position data, a redshift survey maps the 3D distribution of matter within a field of the sky. These observations are used to measure properties of the large-scale structure of the universe. The Great Wall, a vast supercluster of galaxies over 500 million light-years wide, provides a dramatic example of a large-scale structure that redshift surveys can detect.

The first redshift survey was the CfA Redshift Survey, started in 1977 with the initial data collection completed in 1982. More recently, the 2dF Galaxy Redshift Survey determined the large-scale structure of one section of the universe, measuring redshifts for over 220,000 galaxies; data collection was completed in 2002, and the final data set was released 30 June 2003. The Sloan Digital Sky Survey (SDSS), is ongoing as of 2013 and aims to measure the redshifts of around 3 million objects. SDSS has recorded redshifts for galaxies as high as 0.8, and has been involved in the detection of quasars beyond . The DEEP2 Redshift Survey uses the Keck telescopes with the new "DEIMOS" spectrograph; a follow-up to the pilot program DEEP1, DEEP2 is designed to measure faint galaxies with redshifts 0.7 and above, and it is therefore planned to provide a high-redshift complement to SDSS and 2dF.

The interactions and phenomena summarized in the subjects of radiative transfer and physical optics can result in shifts in the wavelength and frequency of electromagnetic radiation. In such cases, the shifts correspond to a physical energy transfer to matter or other photons rather than being by a transformation between reference frames. Such shifts can be from such physical phenomena as coherence effects or the scattering of electromagnetic radiation whether from charged elementary particles, from particulates, or from fluctuations of the index of refraction in a dielectric medium as occurs in the radio phenomenon of radio whistlers. While such phenomena are sometimes referred to as "redshifts" and "blueshifts", in astrophysics light-matter interactions that result in energy shifts in the radiation field are generally referred to as "reddening" rather than "redshifting" which, as a term, is normally reserved for the effects discussed above.

In many circumstances scattering causes radiation to redden because entropy results in the predominance of many low-energy photons over few high-energy ones (while conserving total energy). Except possibly under carefully controlled conditions, scattering does not produce the same relative change in wavelength across the whole spectrum; that is, any calculated is generally a function of wavelength. Furthermore, scattering from random media generally occurs at many angles, and is a function of the scattering angle. If multiple scattering occurs, or the scattering particles have relative motion, then there is generally distortion of spectral lines as well.

In interstellar astronomy, visible spectra can appear redder due to scattering processes in a phenomenon referred to as interstellar reddeningâsimilarly Rayleigh scattering causes the atmospheric reddening of the Sun seen in the sunrise or sunset and causes the rest of the sky to have a blue color. This phenomenon is distinct from red"shift"ing because the spectroscopic lines are not shifted to other wavelengths in reddened objects and there is an additional dimming and distortion associated with the phenomenon due to photons being scattered in and out of the line of sight.





</doc>
<doc id="26264" url="https://en.wikipedia.org/wiki?curid=26264" title="Rob Reiner">
Rob Reiner

"This article is about the actor. For the German-American businessman, see Robert Reiner (businessman)."

Robert Reiner (born March 6, 1947) is an American actor, comedian, and filmmaker. As an actor, Reiner first came to national prominence with the role of Michael Stivic on "All in the Family" (1971â1979), a role that earned him two Emmy Awards during the 1970s. As a director, Reiner was recognized by the Directors Guild of America (DGA) with nominations for the coming of age drama film "Stand by Me" (1986), the romantic comedy "When Harry Met Sally..." (1989), and the military courtroom drama "A Few Good Men" (1992). He also directed the psychological horror-thriller "Misery" (1990), the romantic comedy fantasy adventure "The Princess Bride" (1987), and the heavy metal mockumentary "This Is Spinal Tap" (1984).

Reiner was born to a Jewish family in the Bronx, New York, and is the son of Estelle Reiner (nÃ©e Lebost; 1914â2008), an actress, and Carl Reiner (born 1922), a renowned comedian, actor, writer, producer and director. As a child, Reiner lived at 48 Bonnie Meadow Road in New Rochelle, New York; the home of the fictional Petrie family in "The Dick Van Dyke Show", created by Rob's father, was 148 Bonnie Meadow Lane. He studied at the UCLA Film School.

In the late 1960s, Reiner acted in bit roles in several television shows including "Batman", "The Andy Griffith Show", "Room 222", "Gomer Pyle, U.S.M.C." and "The Beverly Hillbillies". He began his career writing for the "Smothers Brothers Comedy Hour" in 1968 and 1969, with Steve Martin as his writing partner as the two youngest writers on the show. Two years later, Reiner became famous playing Michael Stivic, Archie Bunker's liberal son-in-law, on Norman Lear's 1970s situation comedy "All in the Family", which was the most-watched television program in the United States for five seasons (1971â1976). The character's nickname, Meathead, became closely associated with him, even after he had left the role and went on to build a career as a director. Reiner has stated, "I could win the Nobel Prize and they'd write 'Meathead wins the Nobel Prize'." For his performance, Reiner won two Emmy Awards in addition to three other nominations and five Golden Globe nominations. After an extended absence, Reiner returned to television acting with a recurring role on "New Girl" (2012â2018).

In 1972, Reiner, Phil Mishkin, and Gerry Isenberg created the situation comedy "The Super" for ABC. Starring Richard S. Castellano, the show depicted the life of the harried Italian American superintendent of a New York City apartment building and ran for 10 episodes in the summer of 1972. Reiner and Mishkin co-wrote the premiere episode.

Beginning in the 1980s, Reiner became known as a director of several successful Hollywood films that spanned many different genres. Some of his earlier films include cult classics such as the rock-band mockumentary "This Is Spinal Tap" (1984) and the comedic fantasy film "The Princess Bride" (1987), as well as his period piece coming of age tale "Stand by Me" (1986). He often collaborates with film editor Robert Leighton, whom he also shares with fellow director-actor Christopher Guest as their go-to editor.

Reiner has gone on to direct other critically and commercially successful films with his own company, Castle Rock Entertainment. These include the romantic comedy "When Harry Met Sally..." (1989), which has been critically ranked among the all-time best of its genre, the tense thriller "Misery" (1990), for which Kathy Bates won the Academy Award for Best Actress, and his most commercially successful work, the military courtroom drama "A Few Good Men" (1992), which was nominated for the Academy Award for Best Picture. Subsequent films directed by Reiner include the political romance "The American President" (1995), the courtroom drama "Ghosts of Mississippi" (1996), and the uplifting comedy "The Bucket List" (2007).

Reiner has continued to act in supporting roles in a number of movies and television shows, including "Throw Momma from the Train" (1987), "Sleepless in Seattle" (1993), "Bullets Over Broadway" (1994), "The First Wives Club" (1996), "Primary Colors" (1998), "EDtv" (1999), "New Girl" (2012â2018), and "The Wolf of Wall Street" (2013). He has also parodied himself with cameos in works such as "" (2003) and "30 Rock" (2010).

Reiner has devoted considerable time and energy to progressive activism. His lobbying as an anti-smoking advocate, in particular, prompted his likeness to be used in a satirical role in a "South Park" episode titled "Butt Out".

Reiner is a co-founder of the American Foundation for Equal Rights, which initiated the court challenge against California Proposition 8 which banned same-sex marriage in the state.
In 1998, Reiner chaired the campaign to pass Prop 10, the California Children and Families Initiative, which created First 5 California, a program of early childhood development services, funded by a tax on tobacco products. He served as the first chairman of First 5 California, from 1999 to 2006. Reiner came under criticism for campaigning for a ballot measure (Prop 82) to fund state-run preschools while still chair of the First Five Commission, causing him to resign from his position on March 29, 2006. An audit was conducted, and it concluded that the state commission did not violate state law and that it had clear legal authority to conduct its public advertising campaigns related to preschool. In the end, Prop 82 failed to win approval, garnering only 39.1% support.

Reiner is a member of the Social Responsibility Task Force, an organization advocating moderation where social issues (such as violence and tobacco use) and the entertainment industry meet. He is also active in environmental issues, and he successfully led the effort to establish California's Ahmanson Ranch as a state park and wildlife refuge rather than as a commercial real estate development. He introduced Spinal Tap at the London Live Earth concert in July 2007.

Reiner was mentioned as a possible candidate to run against California Governor Arnold Schwarzenegger in 2006 but decided not to run for personal reasons. He campaigned extensively for Democratic presidential nominee Al Gore in the 2000 presidential election, and he campaigned in Iowa for Democratic presidential candidate Howard Dean just before the 2004 Iowa caucuses. He endorsed Hillary Clinton for president for the 2008 election. In 2015, he donated US$10,000 to Correct the Record, a political action committee which supported Hillary Clinton's 2016 presidential campaign. Since the 2016 election, he has continued to campaign against Donald Trump, calling him a racist, sexist, anti-gay, and anti-Semitic, and compared him to the Nazi police at Auschwitz. Reiner said that Harvey Weinstein is a "bad guy" but Trump is "also an abuser". 

Reiner serves on the Advisory Board of the Committee to Investigate Russia.

Reiner endorsed Joe Biden for president for the 2020 election.

Rob Reiner married actress/director Penny Marshall in 1971. Marshall's daughter, actress Tracy Reiner ("A League of Their Own"), was from a previous marriage to Michael Henry. Reiner and Marshall divorced in 1981.

Reiner was introduced to his future wife, photographer Michele Singer, while directing "When Harry Met Sally". The meeting not only resulted in his deciding to change the ending of that movie, but he also married Singer in 1989. They have three children, Jake (born 1991), Nick (born 1993), and Romy (born 1998). In 1997, Reiner and Singer founded the "I Am Your Child Foundation," and in 2004, they founded the "Parents' Action for Children," a non-profit organization with a dual purpose: a) to raise awareness of the importance of a child's early years by producing and distributing celebrity-hosted educational videos for parents, and b) to advance public policy through parental education and advocacy.

Reiner has stated that his childhood home was not observantly Jewish, although he did have a Bar Mitzvah ceremony; Reiner's father Carl has acknowledged that he himself became an atheist as the Holocaust progressed. He identified himself as having no religious affiliation on the January 13, 2012, episode of "Real Time with Bill Maher" and as an atheist. Reiner later told Huffington Post contributor Debra Oliver that while he rejected organized religion, he was sympathetic to the ideas of Buddhism.

In addition to his four children, Reiner has five grandchildren, through his adopted daughter Tracy.




</doc>
<doc id="26265" url="https://en.wikipedia.org/wiki?curid=26265" title="Robin Wright">
Robin Wright

Robin Gayle Wright (born April 8, 1966) is an American actress and director. She is the recipient of eight Primetime Emmy Award nominations and has earned a Golden Globe Award and a Satellite Award for her work in television.

Wright first gained attention for her role in the NBC Daytime soap opera "Santa Barbara", as Kelly Capwell from 1984 to 1988. She then made the transition to film, starring in the romantic comedy fantasy adventure film "The Princess Bride" (1987). This role led Wright to further success in the film industry, with starring roles in films such as "Forrest Gump" (1994), the romantic drama "Message in a Bottle" (1999), the superhero drama-thriller "Unbreakable" (2000), the historical drama "The Conspirator" (2010), the biographical sports drama "Moneyball" (2011), the mystery thriller "The Girl with the Dragon Tattoo" (2011), the biographical drama "Everest" (2015), the superhero film "Wonder Woman" (2017), and the neo-noir science fiction film "Blade Runner 2049" (2017).

Wright starred as Claire Underwood in the Netflix political drama web television series "House of Cards", for which she won the Golden Globe Award for Best Actress â Television Series Drama in 2013, making her the first actress to win a Golden Globe for a web television series. Wright has also received six Primetime Emmy Award nominations in the Outstanding Lead Actress category for "House of Cards" (one for each season), and two nominations in the Outstanding Drama Series category in 2016 and 2017 as a producer on the show.

Wright is also one of the highest paid actresses in the United States, earning US$420,000 per episode for her role in "House of Cards" in 2016.

Wright was born in Dallas, Texas, to Gayle (Gaston), a cosmetics saleswoman, and Freddie Wright, a pharmaceutical company employee. Wright was raised in San Diego, California. She attended La Jolla High School in La Jolla where Gregory Peck and Raquel Welch attended and Taft High School in Woodland Hills, Los Angeles, where Lisa Kudrow and Ice Cube also attended.

Wright began her career as a model, when she was 14. At the age of 18, she played Kelly Capwell in the NBC Daytime soap opera "Santa Barbara", for which she received several Daytime Emmy Award nominations.

She transitioned into feature film work as Buttercup in the cult film "The Princess Bride" (1987). She gained critical acclaim in her role as Jenny Curran in "Forrest Gump" (1994), receiving Golden Globe Award and Screen Actors Guild nominations for Best Supporting Actress.

In 1996 she starred in the lead role of the film adaptation of Daniel Defoe's "Moll Flanders" (1996), for which she received a Satellite Award Nomination for Best Actress in a Drama. She was nominated for a Screen Actors Guild Award for Best Actress for her role in "She's So Lovely" (1997), a film in which she co-starred with her then-husband Sean Penn. Wright received her third Screen Actors Guild Award nomination for her role in the television film "Empire Falls" (2005).

Since 2013, Wright has appeared in the Netflix political drama web television series "House of Cards" in the role of Claire Underwood, the ruthless wife of political mastermind Frank Underwood. On January 12, 2014, she won a Golden Globe for the role, becoming the first actress to win the award for an online-only web television series; she was nominated for the same award the following year. She also received nominations for the Primetime Emmy Award in 2013 and 2014 for the same role. Following Season 4 in 2016, Wright stated that she felt Claire Underwood was the equal of Frank Underwood and demanded equal pay for her performance as her co-star Kevin Spacey; Netflix acquiesced. In 2017, for her performance in the fifth season, Wright was nominated for her fifth consecutive Primetime Emmy nomination for Outstanding Lead Actress â Drama. For the years 2014, 2016, and 2017, Wright received Best Actress in a Drama Series nominations for the Critics' Choice Television Awards, with her being the only nomination for the show in December 2017.

In October 2017, Wright was set as the show's new lead, following sexual misconduct allegations against Spacey, which resulted in him being fired from the sixth and final season. For her last outing as Underwood, her performance was acclaimed - described as a " commanding performance [that] is more than enough to keep [the final season] standing strong" - earning her her final nominations for the role at the Screen Actors Guild and Primetime Emmy Awards in 2019.
Wright directed 10 out of 73 episodes of House of Cards between 2014 and 2018.

In 2017, Wright played General Antiope in "Wonder Woman" (2017), alongside Gal Gadot and Chris Pine. She appears in the "Blade Runner" sequel "Blade Runner 2049" alongside Ryan Gosling, Harrison Ford, and Jared Leto.

In April 2019, it was announced that Wright would be helming her feature film directorial debut in the film "Land". Wright would also be starring as its lead, Edee Mathis, a lawyer in grief who retreats to the Shoshone National Forest in Wyoming. Sales for the film would start at Cannes the following month.

From 1986 to 1988, Wright was married to actor Dane Witherspoon, whom she met in 1984 on the set of the soap opera "Santa Barbara".

In 1989, Wright became involved with actor Sean Penn following his divorce from Madonna. Wright was offered the role of Maid Marian in the film "", but turned it down because she was pregnant. Their daughter, Dylan Frances, was born in April 1991. She backed out of the role of Abby McDeere in "The Firm" (1993) due to her pregnancy with her second child, and their son, Hopper Jack, was born in August 1993.

After breaking up and getting back together, Wright and Penn married in 1996, and she changed her name to Robin Wright Penn. Their on-and-off relationship seemingly ended in divorce plans, announced in December 2007, but the divorce petition was withdrawn four months later at the couple's request. In February 2009, Wright and Penn attended the 81st Academy Awards together, at which Penn won Best Actor. Penn filed for legal separation in April 2009, but withdrew the petition in May. On August 12, 2009, Wright filed for divorce, declaring she had no plans to reconcile. At that time, she dropped "Penn" from her professional name. The divorce was finalized on July 22, 2010.

In February 2012, Wright began dating actor Ben Foster, and their engagement was announced in January 2014. The couple called off their engagement in November 2014, but reunited in January 2015. On August 29, 2015, they announced they were ending their second engagement. In 2017, Wright began dating Clement Giraudet, a Saint Laurent executive, and they secretly wed in August 2018 in La Roche-sur-le-Buis, France.

Wright is the Honorary Spokesperson for the Dallas, Texas-based non-profit The Gordie Foundation.

In 2014, Wright co-partnered with two California-based companies; Pour Les Femmes and The SunnyLion. The SunnyLion donates a portion of its profits to the Raise Hope For Congo movement.

Wright is an activist for human rights in the Democratic Republic of the Congo. She is the narrator and executive producer of the documentary "When Elephants Fight" which highlights how multinational mining corporations and politicians in the Democratic Republic of Congo threaten human rights, and perpetuate conflict in the region. Wright is a supporter of "Stand With Congo", the human rights campaign behind the film. In 2016, she spoke publicly in support of the campaign at a film screening at the TriBeCa Film Institute in New York City, in media interviews, with journalists, and across her social media accounts.



</doc>
<doc id="26266" url="https://en.wikipedia.org/wiki?curid=26266" title="Rhea">
Rhea

Rhea may refer to:












</doc>
<doc id="26268" url="https://en.wikipedia.org/wiki?curid=26268" title="Radius (disambiguation)">
Radius (disambiguation)

A radius is a straight line or distance from the center to the edge of a curve.

Radius may also refer to:








</doc>
<doc id="26269" url="https://en.wikipedia.org/wiki?curid=26269" title="Richard Butler">
Richard Butler

Richard Butler may refer to: 






</doc>
<doc id="26270" url="https://en.wikipedia.org/wiki?curid=26270" title="List of rulers of Japan">
List of rulers of Japan

The rulers of Japan have been its Emperors, whether effectively or nominally, for its entire recorded history. These include the ancient legendary emperors, the attested but undated emperors of the Yamato period (early fifth to early 6th centuries), and the clearly dated emperors of 539 to the present. Political power was held in various eras by regents and "shÅguns", and since 1946 has been exercised exclusively by the Prime Minister as leader of a representative government. 



</doc>
<doc id="26272" url="https://en.wikipedia.org/wiki?curid=26272" title="Ryuichi Sakamoto">
Ryuichi Sakamoto

Sakamoto began his career while at university in the 1970s as a session musician, producer, and arranger. His first major success came in 1978 as co-founder of YMO. He concurrently pursued a solo career, releasing the experimental electronic fusion album "Thousand Knives" in 1978. Two years later, he released the album "B-2 Unit". It included the track "Riot in Lagos", which was significant in the development of electro and hip hop music. He went on to produce more solo records, and collaborate with many international artists, David Sylvian, Carsten Nicolai, Youssou N'Dour, and Fennesz among them. Sakamoto composed music for the opening ceremony of the 1992 Barcelona Olympics, and his composition "Energy Flow" (1999) was the first instrumental number-one single in Japan's Oricon charts history.

As a film-score composer, Sakamoto has won an Oscar, a BAFTA, a Grammy, and 2 Golden Globe Awards. "Merry Christmas, Mr. Lawrence" (1983) marked his debut as both an actor and a film-score composer; its main theme was adapted into the single "Forbidden Colours" which became an international hit. His most successful work as a film composer was "The Last Emperor" (1987), after which he continued earning accolades composing for films such as "The Sheltering Sky" (1990), "Little Buddha" (1993), and "The Revenant" (2015). On occasion, Sakamoto has also worked as a composer and a scenario writer on anime and video games. In 2009, he was awarded the Ordre des Arts et des Lettres from the Ministry of Culture of France for his contributions to music.

Sakamoto entered the Tokyo National University of Fine Arts and Music in 1970, earning a B.A. in music composition and an M.A. with special emphasis on both electronic and ethnic music. He studied ethnomusicology there with the intention of becoming a researcher in the field, due to his interest in various world music traditions, particularly the Japanese (especially Okinawan), Indian and African musical traditions. He was also trained in classical music and began experimenting with the electronic music equipment available at the university, including synthesizers such as the Buchla, Moog, and ARP. One of Sakamoto's classical influences was Claude Debussy, who he described as his "hero" and stated that âAsian music heavily influenced Debussy, and Debussy heavily influenced me. So, the music goes around the world and comes full circle.â

In 1975, Sakamoto collaborated with percussionist Tsuchitori Toshiyuki to release "Disappointment-Hateruma". After working as a session musician with Haruomi Hosono and Yukihiro Takahashi in 1977, the trio formed the internationally successful electronic music band Yellow Magic Orchestra (YMO) in 1978. Known for their seminal influence on electronic music, the group helped pioneer electronic genres such as electropop/technopop, synthpop, cyberpunk music, ambient house, and electronica. The group's work has had a lasting influence across genres, ranging from hip hop and techno to acid house and general melodic music. Sakamoto was the songwriter and composer for a number of the band's hit songsâincluding "Yellow Magic (Tong Poo)" (1978), "Technopolis" (1979), "Nice Age" (1980), "Ongaku" (1983) and "You've Got to Help Yourself" (1983)âwhile playing keyboards for many of their other songs, including international hits such as "Computer Game/Firecracker" (1978) and "Rydeen" (1979). He also sang on several songs, such as "Kimi ni Mune Kyun" (1983). Sakamoto's composition "Technopolis" (1979) was credited as a contribution to the development of techno music, while the internationally successful "Behind the Mask" (1978)âa synthpop song in which he sang vocals through a vocoderâwas later covered by a number of international artists, including Michael Jackson and Eric Clapton.

Sakamoto released his first solo album "Thousand Knives of RyÅ«ichi Sakamoto" in mid-1978 with the help of Hideki MatsutakeâHosono also contributed to the song "Thousand Knives". The album experimented with different styles, such as "Thousand Knives" and "The End of Asia"âin which electronic music was fused with traditional Japanese musicâwhile "Grasshoppers" is a more minimalistic piano song. The album was recorded from April to July 1978 with a variety of electronic musical instruments, including various synthesizers, such as the KORG PS-3100, a polyphonic synthesizer; the Oberheim Eight-Voice; the Moog III-C; the Polymoog, the Minimoog; the Micromoog; the Korg VC-10, which is a vocoder; the KORG SQ-10, which is an analog sequencer; the Syn-Drums, an electronic drum kit; and the microprocessor-based Roland MC-8 Microcomposer, which is a music sequencer that was programmed by Matsutake and played by Sakamoto. A version of the song "Thousand Knives" was released on the Yellow Magic Orchestra's 1981 album "BGM". This version was one of the earliest uses of the Roland TR-808 drum machine, for YMO's live performance of "1000 Knives" in 1980 and their "BGM" album release in 1981.

In 1980, Sakamoto released the solo album "B-2 Unit", which has been referred to as his "edgiest" record and is known for the electronic song "Riot in Lagos", which is considered an early example of electro music (electro-funk), as Sakamoto anticipated the beats and sounds of electro. Early electro and hip hop artists, such as Afrika Bambaata and Kurtis Mantronik, were influenced by the albumâespecially "Riot in Lagos"âwith Mantronik citing the work as a major influence on his electro hip hop group Mantronix. "Riot in Lagos" was later included in Playgroup's compilation album "Kings of Electro" (2007), alongside other significant electro compositions, such as Hashim's "Al-Naafyish" (1983).

According to "Dusted Magazine", Sakamoto's use of squelching bounce sounds and mechanical beats was later incorporated in early electro and hip hop music productions, such as âMessage II (Survival)â (1982), by Melle Mel and Duke Bootee; âMagicâs Wandâ (1982), by Whodini and Thomas Dolby; Twilight 22's âElectric Kingdomâ (1983); and Kurt Mantronik's "" (1985). The 1980 release of "Riot in Lagos" was listed by "The Guardian" in 2011 as one of the 50 key events in the history of dance music.

Among other tracks on "B-2 Unit", "Differencia" has, according to "Fact", "relentless tumbling beats and a stabbing bass synth that foreshadows jungle by nearly a decade". Some tracks on the album also foreshadow genres such as IDM, broken beat, and industrial techno, and the work of producers such as Actress and Oneohtrix Point Never. For several tracks on the album, Sakamoto worked with UK reggae producer Dennis Bovell, incorporating elements of afrobeat and dub music.

Also in 1980, Sakamoto released the single "War Head/Lexington Queen", an experimental synthpop and electro record, and began a long-standing collaboration with David Sylvian, when he co-wrote and performed on the Japan track "Taking Islands In Africa". In the following year, Sakamoto collaborated with Talking Heads and King Crimson guitarist Adrian Belew and Robin Scott for an album titled "Left-Handed Dream". Following Japan's dissolution, Sakamoto worked on another collaboration with Sylvian, a single entitled "Bamboo Houses/Bamboo Music" in 1982. Sakamoto's 1980 collaboration with Kiyoshiro Imawano, "Ikenai Rouge Magic", topped the Oricon singles chart.

In 1983, Sakamoto starred alongside David Bowie in director Nagisa Oshima's "Merry Christmas Mr. Lawrence". In addition to acting in the film, Sakamoto also composed the film's musical score and again collaborated with Sylvian on the film's main theme ("Forbidden Colours") â which became a minor hit. In a 2016 interview, Sakamoto reflected on his time acting in the film, claiming that he "hung out" with Bowie every evening for a month while filming on location. He remembered Bowie as "straightforward" and "nice", while also lamenting the fact that he never mustered the courage to ask for Bowie's help while scoring the film's soundtrack as he believed Bowie was too "concentrated on acting".

Sakamoto released a number of solo albums during the 1980s. While primarily focused on the piano and synthesizer, this series of albums included collaborations with artists such as Sylvian, David Byrne, Thomas Dolby, Nam June Paik and Iggy Pop. Sakamoto would alternate between exploring a variety of musical styles, ideas and genresâcaptured most notably in his 1983 album "Illustrated Musical Encyclopedia" âand focusing on a specific subject or theme, such as the Italian Futurism movement .

As his solo career began to extend outside Japan in the late 1980s, Sakamoto's explorations, influences and collaborators also developed further. "Beauty" (1989) features a track list that combines pop with traditional Japanese and Okinawan songs, as well as guest appearances by Jill Jones, Robert Wyatt, Brian Wilson and Robbie Robertson. "Heartbeat" (1991) and "Sweet Revenge" (1994) features Sakamoto's collaborations with a global range of artists such as Roddy Frame, Dee Dee Brave, Marco Prince, Arto Lindsay, Youssou N'Dour, David Sylvian and Ingrid Chavez.

In 1995 Sakamoto released "Smoochy", described by the "Sound On Sound" website as Sakamoto's "excursion into the land of easy-listening and Latin", followed by the "1996" album, which featured a number of previously released pieces arranged for solo piano, violin and cello. During December 1996 Sakamoto, composed the entirety of an hour-long orchestral work entitled "Untitled 01" and released as the album "Discord" (1998). The Sony Classical release of "Discord" was sold in a jewel case that was covered by a blue-colored slipcase made of foil, while the CD also contained a data video track. In 1998 the Ninja Tune record label released the "Prayer/Salvation Remixes", for which prominent electronica artists such as Ashley Beedle and Andrea Parker remixed sections from the "Prayer" and "Salvation" parts of "Discord". Sakamoto collaborated primarily with guitarist David Torn and DJ Spookyâartist Laurie Anderson provides spoken word on the compositionâand the recording was condensed from nine live performances of the work, recorded during a Japanese tour. "Discord" was divided into four parts: "Grief", "Anger", "Prayer" and "Salvation"; Sakamoto explained in 1998 that he was "not religious, but maybe spiritual" and "The Prayer is to anybody or anything you want to name." Sakamoto further explained:

In 1998, Italian ethnomusicologist Massimo Milano published "Ryuichi Sakamoto. Conversazioni" through the Padova, Arcana imprint. All three editions of the book were published in the Italian language. Sakamoto's next album, "BTTB" (1998)âan acronym for "Back to the Basics"âwas a fairly opaque reaction to the prior year's multilayered, lushly orchestrated "Discord". The album comprised a series of original pieces on solo piano, including "Energy Flow" (a major hit in Japan) and a frenetic, four-hand arrangement of the Yellow Magic Orchestra classic "Tong Poo". On the "BTTB" U.S. tour, he opened the show performing a brief avant-garde DJ set under the stage name DJ Lovegroove.

Sakamoto's long-awaited "opera" "LIFE" was released in 1999, with visual direction by Shiro Takatani, artistic director of Dumb Type. It premiered with seven sold-out performances in Tokyo and Osaka. This ambitious multi-genre multi-media project featured contributions by over 100 performers, including Pina Bausch, Bernardo Bertolucci, Josep Carreras, the Dalai Lama and Salman Rushdie.

Sakamoto teamed with cellist Jaques Morelenbaum (a member of his "1996" trio), and Morelenbaum's wife, Paula, on a pair of albums celebrating the work of bossa nova pioneer Antonio Carlos Jobim. They recorded their first album, "Casa" (2001), mostly in Jobim's home studio in Rio de Janeiro, with Sakamoto performing on the late Jobim's grand piano. The album was well received, having been included in the list of "The New York Times"s top albums of 2002. A live album, "Live in Tokyo", and a second album, "A Day in New York", soon followed. Sakamoto and the Morelenbaums would also collaborate on N.M.L. No More Landmine, an international effort to raise awareness for the removal of landmines. The trio would release the single "Zero Landmine", which also featured David Sylvian, Brian Eno, Kraftwerk, Cyndi Lauper, and Haruomi Hosono & Yukihiro Takahashi, the other two founding members of Yellow Magic Orchestra, amongst nearly one hundred other performers.

Sakamoto collaborated with Alva Noto (an alias of Carsten Nicolai) to release "Vrioon", an album of Sakamoto's piano clusters treated by Nicolai's unique style of digital manipulation, involving the creation of "micro-loops" and minimal percussion. The two produced this work by passing the pieces back and forth until both were satisfied with the result. This debut, released on German label Raster-Noton, was voted record of the year 2004 in the electronica category by British magazine "The Wire". They then released "Insen" (2005)âwhile produced in a similar manner to Vrioon, this album is somewhat more restrained and minimalist. They keep on collaborating and have released two more albums: "utp_" (2008) and "Summvs" (2011).

In 2005, Finnish mobile phone manufacturer Nokia hired Sakamoto to compose ring and alert tones for their high-end phone, the Nokia 8800. In 2006, Nokia offered the ringtones for free on their website. Around this time, a reunion with YMO cofounders Hosono and Takahashi caused a stir in the Japanese press. They released a single "Rescue" in 2007 and a DVD "HAS/YMO" in 2008. In July 2009, Sakamoto was honored as Officier of Ordre des Arts et des Lettres at the French embassy in Tokyo.

Throughout the latter part of the 2000s, Sakamoto collaborated on several projects with visual artist Shiro Takatani, including the installations "LIFE - fluid, invisible, inaudible..." (2007â2013), commissioned by YCAM, Yamaguchi, "collapsed" and "silence spins" at the Museum of Contemporary Art Tokyo in 2012 and 2013 Sharjah Biennial (U.A.E.), "LIFE-WELL" in 2013 and a special version for Park Hyatt Tokyo's 20th anniversary in 2014, and he did music for the joint performance "LIFE-WELL" featuring the actor Noh/Kyogen Mansai Nomura, and for Shiro Takatani's performance "ST/LL" in 2015.

In 2013, Sakamoto was a jury member at the 70th Venice International Film Festival. The jury viewed 20 films and was chaired by filmmaker Bernardo Bertolucci.

In 2014, Sakamoto became the first Guest Artistic Director of The Sapporo International Art Festival 2014 (SIAF2014).
On July 10, Sakamoto released a statement indicating that he had been diagnosed with oropharyngeal cancer in late June of the same year. He announced a break from his work while he sought treatment and recovery. On August 3, 2015, Sakamoto posted on his website that he was "in great shape ... I am thinking about returning to work" and announced that he would be providing music for Yoji Yamada's "Haha to Kuraseba" ("Living with My Mother"). In 2015, Sakamoto also composed the score for the Alejandro GonzÃ¡lez IÃ±Ã¡rritu's film, "The Revenant," for which he received a Golden Globe nomination.

In January 2017 it was announced that Sakamoto would release a solo album in April 2017 through Milan Records; the new album, titled "async", was released on March 29, 2017 to critical acclaim. In February 2018, he was selected to be on the jury for the main competition section of the 68th Berlin International Film Festival.

On June 14, 2018, a documentary about the life and work of Sakamoto, entitled "Coda", was released. The film follows Sakamoto as he recovers from cancer and resumes creating music, protests nuclear power plants following the Fukushima Daiichi Nuclear Disaster, and creates field recordings in a variety of locales. Directed by Stephen Nomura Schible, the documentary was met with critical praise.

Sakamoto's production credits represent a prolific career in this role. In 1983, he produced Mari Iijima's debut album "RosÃ©", the same year that the Yellow Magic Orchestra was disbanded. Sakamoto subsequently worked with artists such as Thomas Dolby; Aztec Camera, on the "Dreamland" (1993) album; and Imai Miki, co-producing her 1994 album "A Place In The Sun". In 1996, Sakamoto produced "Mind Circus", the first single from actress Miki Nakatani, leading to a collaboration period spanning 9 singles and 7 albums though 2001.

Roddy Frame, who worked with Sakamoto as a member of Aztec Camera, explained in a 1993 interview preceding the release of "Dreamland" that he had had to wait a lengthy period of time before he was able to work with Sakamoto, who wrote two soundtracks, a solo album and the music for the opening ceremony at the Barcelona Olympics, prior to working with Frame over four weeks in a New York studio. Frame said that he was impressed by the work of YMO and the "Merry Christmas Mr Lawrence" soundtrack, explaining: "That's where you realise that the atmosphere around his compositions is actually in the writing - it's got nothing to do with synthesisers." Frame's decision to ask Sakamoto was finalized after he saw his performance at the Japan Festival that was held in London, United Kingdom. Of his experience recording with Sakamoto, Frame said:

Sakamoto began working in films, as a composer and actor, in Nagisa Oshima's "Merry Christmas Mr. Lawrence" (1983), for which he composed the score, title theme, and the duet "Forbidden Colours" with David Sylvian. Sakamoto later composed Bernardo Bertolucci's "The Last Emperor" (1987), which earned him the Academy Award with fellow composers David Byrne and Cong Su. In that same year, he composed the score to the cult-classic anime film "". Sakamoto also went on to compose the score of the opening ceremony for the 1992 Summer Olympics in Barcelona, Spain, telecast live to an audience of over a billion viewers.

Other films scored by Sakamoto include Pedro AlmodÃ³var's "Tacones lejanos (High Heels)" (1991), Bertolucci's "The Little Buddha" (1993), Oliver Stone's "Wild Palms" (1993), John Maybury's "" (1998), Brian De Palma's "Snake Eyes" (1998) and "Femme Fatale" (2002), Oshima's "Gohatto" (1999), Jun Ichikawa's (director of the Mitsui ReHouse commercial from 1997 to 1999 starring Chizuru Ikewaki and Mao Inoue) "Tony Takitani" (2005).

Several tracks from Sakamoto's earlier solo albums have also appeared in film soundtracks. In particular, variations of "Chinsagu No Hana" (from "Beauty") and "Bibo No Aozora" (from "1996") provide the poignant closing pieces for Sue Brooks's "Japanese Story" (2003) and Alejandro GonzÃ¡lez IÃ±Ã¡rritu's "Babel" (2006), respectively. In 2015, Sakamoto teamed up with IÃ±Ã¡rritu to score his film, "The Revenant" starring Leonardo DiCaprio and Tom Hardy.

Sakamoto has also acted in several films: perhaps his most notable performance was as the conflicted Captain Yonoi in "Merry Christmas Mr Lawrence", alongside Takeshi Kitano and British rock singer David Bowie. He also played roles in "The Last Emperor" (as Masahiko Amakasu) and Madonna's "Rain" music video.

Sakamoto's first of two marriages occurred in 1972, but ended in divorce two years laterâSakamoto has a daughter from this relationship. Sakamoto then married popular Japanese pianist and singer Akiko Yano in 1982, following several musical collaborations with her, including touring work with the Yellow Magic Orchestra. Sakamoto's second marriage ended in August 2006, 14 years after a mutual decision to live separatelyâYano and Sakamoto raised one daughter, J-pop singer Miu Sakamoto. He has lived with his manager and wife Norika Sora since around 1990 and has two children with her.

Beginning in June 2014, Sakamoto took a year-long hiatus after he was diagnosed with oropharyngeal cancer. In 2015, he returned, stating: "Right now I'm good. I feel better. Much, much better. I feel energy inside, but you never know. The cancer might come back in three years, five years, maybe 10 years. Also the radiation makes your immune system really low. It means I'm very welcoming [of] another cancer in my body."

Sakamoto is a member of the anti-nuclear organization Stop Rokkasho and has demanded the closing of the Hamaoka Nuclear Power Plant. In 2012, he organized the No Nukes 2012 concert, which featured performances by 18 groups, including Yellow Magic Orchestra and Kraftwerk. Sakamoto is also known as a critic of copyright law, arguing in 2009 that it is antiquated in the information age. He argued that in "the last 100 years, only a few organizations have dominated the music world and ripped off both fans and creators" and that "with the internet we are going back to having tribal attitudes towards music."

In 2015 Sakamoto also supported opposition to the relocation of Marine Corps Air Station Futenma in the Oura bay in Henoko, with a new and Okinawan version of his 2004 single "Undercooled" whose sales partially contributed to the "Henoko Fund", aimed to stop the relocation of the base on Okinawa.

In 2006 Sakamoto, in collaboration with Japan's largest independent music company Avex Group, founded , a record label seeking to change the manner in which music is produced. Sakamoto has explained that Commmons is not his label, but is a platform for all aspiring artists to join as equal collaborators, to share the benefits of the music industry. On the initiative's "About" page, the label is described as a project that "aims to find new possibilities for music, while making meaningful contribution to culture and society." The name "Commmons" is spelt with three "m"s because the third "m" stands for music.

Sakamoto has won a number of awards for his work as a film composer, beginning with his score for "Merry Christmas, Mr. Lawrence" (1983) winning him the BAFTA Award for Best Film Music. His greatest award success was for scoring "The Last Emperor" (1987), which won him the Academy Award for Best Original Score, Golden Globe Award for Best Original Score, and Grammy Award for Best Score Soundtrack Album for a Motion Picture, Television or Other Visual Media, as well as a BAFTA nomination.

His score for "The Sheltering Sky" (1990) later won him his second Golden Globe Award, and his score for "Little Buddha" (1993) received another Grammy Award nomination. In 1997, his collaboration with Toshio Iwai, "Music Plays Images X Images Play Music", was awarded the Golden Nica, the grand prize of the Prix Ars Electronica competition. He also contributed to the Academy Award winning soundtrack for "Babel" (2006) with several pieces of music, including the "Bibo no Aozora" closing theme. In 2009, he was awarded the Ordre des Arts et des Lettres from France's Ministry of Culture for his musical contributions. His score for "The Revenant" (2015) was nominated for the Golden Globe and BAFTA, and won Best Musical Score from the DallasâFort Worth Film Critics Association.

The music video for "Risky", written and directed by Meiert Avis, also won the first ever MTV "Breakthrough Video Award". The ground breaking video explores transhumanist philosopher FM-2030's (Persian: ÙØ±ÛØ¯ÙÙ Ø§Ø³ÙÙØ¯ÛØ§Ø±Û) ideas of "Nostalgia for the Future", in the form of an imagined love affair between a robot and one of Man Ray's models in Paris in the late 1930s. Additional inspiration was drawn from Jean Baudrillard, Edvard Munch's 1894 painting "Puberty", and Roland Barthes "Death of the Author". The surrealist black and white video uses stop motion, light painting, and other retro in-camera effects techniques. Meiert Avis shot Sakamoto while at work on the score for "The Last Emperor" in London. Sakamoto also appears in the video painting words and messages to an open shutter camera. Iggy Pop, who performs the vocals on "Risky", chose not to appear in the video, allowing his performance space to be occupied by the surrealist era robot.

Sakamoto won the Golden Pine Award (Lifetime Achievement) at the 2013 International Samobor Film Music Festival, along with Clint Eastwood and Gerald Fried.








Solo studio albums



</doc>
<doc id="26273" url="https://en.wikipedia.org/wiki?curid=26273" title="Roger the Dodger">
Roger the Dodger

Roger the Dodger, whose real name is Roger Dawson, is a fictional character featured regularly in the UK comic "The Beano". His strip consists solely of Roger's basic remit to avoid doing chores and homework which usually involves him concocting complex and ultimately disastrous plans, the undoing of which results in him being punished (usually by his long-suffering father). To perform these tasks he enlists the help of his many 'dodge books'.

He first appeared in issue 561, dated 18 April 1953. His appearance is vaguely similar to that of Dennis the Menace from the same magazine; he wears a black-and-red chequered jumper, black trousers and takes better care of his hair than his equally mischievous counterpart. He also used to have a white tie, but it seems to have disappeared. Originally drawn by Ken Reid, Gordon Bell took over in 1959, but Roger dodged his way out of the Beano in 1960. He returned, drawn by Bob McGrath, in April 1961. Ken Reid was re-commissioned to draw the strip in 1962, and Robert Nixon when Reid left D. C. Thomson & Co. in 1964. When Nixon left in 1973, Tom Lavery began drawing the strip, who was then followed by Frank McDiarmid in 1976.

Ten years later, after Euan Kerr took over as Beano editor, Nixon returned, drawing in a noticeably different style from the one before. Roger's strip was given a second page in 1986. Between 1986 and 1992, a spin-off strip appeared at the end called "Roger the Dodger's Dodge Clinic". Readers would write in with problems, and Roger would try to find a dodge for it (which would usually go wrong). Winning suggestions would win a transistor radio and special scroll. Roger is often shown in other Beano characters' stories offering "help", which he took to a new level in Beano issue 2648 from April 1993. This issue marked Roger's 40th birthday, and to celebrate he made appearances in every strip in the comic.

Nixon continued drawing it until his death in October 2002, though due to the strips being drawn months in advance, his strips continued appearing in the Beano until the end of January 2003, when artist Barrie Appleby took over. He drew the strip until 2011, when he stopped to concentrate on Dennis and Gnasher, though Trevor Metcalfe drew a few strips in 2003 and 2004, and there have also been some Robert Nixon reprints during 2005 and 2006. Since Appleby stopped drawing Roger, the comic has run reprints of Robert Nixon strips from the 1980s. Along with the Nixon reprints, Roger's Dodge Diary was introduced on the second half of Roger's pages, where Beano readers can send in their own dodges. In each one, Roger says a good thing, a bad thing and the results of the dodge. When the Beano was revamped on 8 August 2012, Appleby started drawing Roger again and Roger's parents were made younger. In the 75th birthday issue released on 24 July 2013, Jamie Smart took over as artist. On 9 April 2014, Wayne Thompson replaced Jamie Smart as Roger's artist, until Barrie Appleby returned to draw the strip temporarily, before Wayne Thompson surprisingly returned. In 2017, writing duties for the strip were taken over by Danny Pearson.

Roger is currently the second longest-running character in the Beano, behind only Dennis the Menace. However, if taken into account the strip's absence in 1960 then he would be the third longest-running behind Minnie the Minx.

Roger is a crafty-looking ten-year-old boy who sports a red-and-black chequered jersey with a white shirt collar poking out. He is also usually attired in a white tie, however, the Barrie Appleby strips dropped this around 2005. Upon his debut, Roger sported the usual school boy shorts, however he began wearing trousers during the 1970s.

Roger, unlike most Beano characters, does not go out of his way to cause chaos and mayhem. Instead, he chooses to watch from the sidelines, dodging responsibilities and punishments.


18 April 1953: Roger The Dodger made his debut in issue 561, drawn by Ken Reid.
1959: Gordon Bell becomes the artist.
1960: Roger's first series ends.
April 1961: Roger returns to the Beano, drawn by Bob McGrath.
1962: Reid is artist again.
1964: Robert Nixon takes over.
1973: Tom Lavery takes over.
1976: Frank McDiarmid takes over.
1986: Nixon returns to draw Roger again, he moves to two pages and Roger The Dodger's Dodge Clinic is introduced.
1992: Roger The Dodger's Dodge Clinic ends.
April 1993: Roger's 40th anniversary is celebrated.
January 2003: Barrie Appleby takes over, after Nixon's death.
2011: Appleby stops drawing Roger to focus on Dennis and Gnasher, and Roger's Dodge Diary is introduced alongside Nixon reprints.
2012: Appleby resumes drawing Roger after Nigel Parkinson takes over Dennis and Gnasher.
July 2013: Jamie Smart takes over as artist.
April 2014: Wayne Thompson takes over as artist.
July 2014: Barrie Appleby returns as artist.





</doc>
<doc id="26275" url="https://en.wikipedia.org/wiki?curid=26275" title="Robert Nozick">
Robert Nozick

Robert Nozick (; November 16, 1938Â â January 23, 2002) was an American philosopher. He held the Joseph Pellegrino University Professorship at Harvard University, and was president of the American Philosophical Association. He is best known for his books "Philosophical Explanations" (1981), which included his counterfactual theory of knowledge, and "Anarchy, State, and Utopia" (1974), a libertarian answer to John Rawls' "A Theory of Justice" (1971), in which Nozick also presented his own theory of utopia as one in which people can freely choose the rules of the society they enter into. His other work involved ethics, decision theory, philosophy of mind, metaphysics and epistemology. His final work before his death, "Invariances" (2001), introduced his theory of evolutionary cosmology, by which he argues invariances, and hence objectivity itself, emerged through evolution across possible worlds.

Nozick was born in Brooklyn to a family of Kohenic descent. His mother was born Sophie Cohen, and his father was a Jew from the Russian shtetl who had been born with the name Cohen and who ran a small business.

Nozick attended the public schools in Brooklyn. He was then educated at Columbia University (A.B. 1959, "summa cum laude"), where he studied with Sidney Morgenbesser, and later at Princeton University (Ph.D. 1963) under Carl Hempel, and at Oxford University as a Fulbright Scholar (1963â1964). At one point he joined the youth branch of Norman Thomas's Socialist Party. In addition, at Columbia he founded the local chapter of the Student League for Industrial Democracy, which in 1962 changed its name to Students for a Democratic Society.

That same year, after receiving his bachelor of arts degree in 1959, he married Barbara Fierer. They had two children, Emily and David. The Nozicks eventually divorced and he remarried, to the poet Gjertrud Schnackenberg. Nozick died in 2002 after a prolonged struggle with stomach cancer. He was interred at Mount Auburn Cemetery in Cambridge, Massachusetts.

For "Anarchy, State, and Utopia" (1974) Nozick received a National Book Award in category Philosophy and Religion.
There, Nozick argues that only a minimal state limited to the narrow functions of protection against "force, fraud, theft, and administering courts of law" could be justified without violating people's rights. For Nozick, a distribution of goods is just if brought about by free exchange among consenting adults from a "just" starting position, even if large inequalities subsequently emerge from the process. Nozick appealed to the Kantian idea that people should be treated as ends (what he termed 'separateness of persons'), not merely as a means to some other end.

Nozick challenged the partial conclusion of John Rawls' Second Principle of Justice of his "A Theory of Justice", that "social and economic inequalities are to be arranged so that they are to be of greatest benefit to the least-advantaged members of society." "Anarchy, State, and Utopia" claims a heritage from John Locke's "Second Treatise on Government" and seeks to ground itself upon a natural law doctrine, but reaches some importantly different conclusions from Locke himself in several ways.

Most controversially, Nozick argued that a consistent upholding of the non-aggression principle would allow and regard as valid consensual or non-coercive enslavement contracts between adults. He rejected the notion of inalienable rights advanced by Locke and most contemporary capitalist-oriented libertarian academics, writing in "Anarchy, State, and Utopia" that the typical notion of a "free system" would allow adults to voluntarily enter into non-coercive slave contracts.

In "Philosophical Explanations" (1981), which received the Phi Beta Kappa Society's Ralph Waldo Emerson Award, Nozick provided novel accounts of knowledge, free will, personal identity, the nature of value, and the meaning of life. He also put forward an epistemological system which attempted to deal with both the Gettier problem and those posed by skepticism. This highly influential argument eschewed justification as a necessary requirement for knowledge.

Nozick's four conditions for S's knowing that P were:


Nozick's third and fourth conditions are counterfactuals. He called this the "tracking theory" of knowledge. Nozick believed the counterfactual conditionals bring out an important aspect of our intuitive grasp of knowledge: For any given fact, the believer's method must reliably track the truth despite varying relevant conditions. In this way, Nozick's theory is similar to reliabilism. Due to certain counterexamples that could otherwise be raised against these counterfactual conditions, Nozick specified that:

Where M stands for the method by which S came to arrive at a belief whether or not P.

A major criticism of Nozick's theory of knowledge is his rejection of the principle of deductive closure. This principle states that if S knows X and S knows that X implies Y, then S knows Y. Nozick's truth tracking conditions do not allow for the principle of deductive closure. Nozick believes that the truth tracking conditions are more fundamental to human intuition than the principle of deductive closure.

"The Examined Life" (1989), pitched to a broader public, explores love, death, faith, reality, and the meaning of life. According to Stephen Metcalf, Nozick expresses serious misgivings about capitalist libertarianism, going so far as to reject much of the foundations of the theory on the grounds that personal freedom can sometimes only be fully actualized via a collectivist politics and that wealth is at times justly redistributed via taxation to protect the freedom of the many from the potential tyranny of an overly selfish and powerful few. Nozick suggests that citizens who are opposed to wealth redistribution which fund programs they object to, should be able to opt out by supporting alternative government approved charities with an added 5% surcharge.

However, Jeff Riggenbach has noted that in an interview conducted in July 2001, he stated that he had never stopped self-identifying as a libertarian. Roderick Long reported that in his last book, "Invariances", "[Nozick] identified voluntary cooperation as the 'core principle' of ethics, maintaining that the duty not to interfere with another person's 'domain of choice' is '[a]ll that any society should (coercively) demand'; higher levels of ethics, involving positive benevolence, represent instead a 'personal ideal' that should be left to 'a person's own individual choice and development.' And that certainly sounds like an attempt to embrace libertarianism all over again. My own view is that Nozick's thinking about these matters evolved over time and that what he wrote at any given time was an accurate reflection of what he was thinking at that time." Furthermore, Julian Sanchez reported that "Nozick "always" thought of himself as a libertarian in a broad sense, right up to his final days, even as his views became somewhat less 'hardcore.'"

"The Nature of Rationality" (1993) presents a theory of practical reason that attempts to embellish notoriously spartan classical decision theory.

"Socratic Puzzles" (1997) is a collection of papers that range in topic from Ayn Rand and Austrian economics to animal rights. A thesis claims that "social ties are deeply interconnected with vital parts of Nozick's later philosophy", citing these two works as a development of "The Examined Life".

His last production, "Invariances" (2001), applies insights from physics and biology to questions of objectivity in such areas as the nature of necessity and moral value.

Nozick created the thought experiment of the "utility monster" to show that average utilitarianism could lead to a situation where the needs of the vast majority were sacrificed for one individual. He also wrote a version of what was essentially a previously-known thought experiment, the experience machine, in an attempt to show that ethical hedonism was false. Nozick asked us to imagine that "superduper neuropsychologists" have figured out a way to stimulate a person's brain to induce pleasurable experiences. We would not be able to tell that these experiences were not real. He asks us, if we were given the choice, would we choose a machine-induced experience of a wonderful life over real life? Nozick says no, then asks whether we have reasons not to plug into the machine and concludes that since it does not seem to be rational to plug in, ethical hedonism must be false.

Nozick was notable for the exploratory style of his philosophizing and for his methodological ecumenism. Often content to raise tantalizing philosophical possibilities and then leave judgment to the reader, Nozick was also notable for drawing from literature outside of philosophy (e.g., economics, physics, evolutionary biology).

In his 2001 work, "Invariances", Nozick introduces his theory of truth, in which he leans towards a deflationary theory of truth, but argues that objectivity arises through being invariant under various transformations. For instance, space-time is a significant objective fact because an interval involving both temporal and spatial separation is invariant, whereas no simpler interval involving only temporal or only spatial separation is invariant under Lorentz transformations. Nozick argues that invariances, and hence objectivity itself, emerged through a theory of evolutionary cosmology across possible worlds.





</doc>
<doc id="26276" url="https://en.wikipedia.org/wiki?curid=26276" title="Redirect examination">
Redirect examination

"

When a witness is presented for testimony in the U.S. judicial system, the order is "direct examination" testimony, then the opposing attorney does "cross examination" and then comes "redirect examination" from the attorney first offering the witness. "Recross" may be allowed, but usually the opposing attorney must ask for permission from the judge before proceeding with this additional round of questioning.

In Australia, Canada and South Africa the process is called re-examination.



</doc>
<doc id="26278" url="https://en.wikipedia.org/wiki?curid=26278" title="Robert Abbot (theologian)">
Robert Abbot (theologian)

Robert Abbot () was an English theologian who promoted puritan doctrines. With a living at Cranbrook, Kent, he wrote anti-Catholic works and cultivated a local circle among the Kent gentry.

Robert Abbot received his education at Cambridge University, and later at
Oxford University. The details of Abbot's ecclesiastical career are somewhat unclear, and can only be pieced together from fragmentary evidence, but based on something he wrote in his work "Bee Thankfull London and her Sisters", it is probable that he began his church service with a posting as "assistant to a reverend divine". A note in the margin indicates that the priest in question was "Master Haiward of Wool Church", in Dorset. In 1616 he was appointed by George Abbot to the vicarage of Cranbrook in Kent. His ministry at Cranbrook was regarded as successful, but he was noted for his lack of tolerance towards nonconformists. In 1643, Abbot left Cranbrook, becoming vicar of Southwick, Hampshire. Later, he became pastor at the "extruded" Udall of St Austin's, in London, where he apparently still served in 1657. Between 1657 and 1658, and in 1662, Abbot appears to vanish from record, and his activities are unknown.

Robert Abbot's books are conspicuous amongst the works of his time by their terseness and variety. In addition to those mentioned above he wrote "Triall of our Church-Forsakers" (1639), "Milk for Babes, or a Mother's Catechism for her Children" (1646), and "A Christian Family builded by God, or Directions for Governors of Families" (1653).

Abbot is sometimes mistakenly described as the son of the Archbishop of Canterbury of the same surname, George Abbot. The misunderstanding may stem from a passage in Robert Abbot's work "A Hand of Fellowship to Helpe Keepe out Sinne and Antichrist", in which he thanks the Archbishop for "worldly maintenance," "best earthly countenance" and "fatherly incouragements."



</doc>
