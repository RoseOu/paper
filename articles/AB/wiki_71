<doc id="20523" url="https://en.wikipedia.org/wiki?curid=20523" title="Maasai people">
Maasai people

The Maasai () are a Nilotic ethnic group inhabiting northern, central and southern Kenya and northern Tanzania. They are among the best known local populations internationally due to their residence near the many game parks of the African Great Lakes, and their distinctive customs and dress. The Maasai speak the Maa language (ɔl Maa), a member of the Nilo-Saharan family that is related to the Dinka, Kalenjin and Nuer languages. Except from some elders living in rural areas, most Maasai people speak the official languages of Kenya and Tanzania, Swahili and English. The Maasai population has been reported as numbering 841,622 in Kenya in the 2009 census, compared to 377,089 in the 1989 census.

The Tanzanian and Kenyan governments have instituted programs to encourage the Maasai to abandon their traditional semi-nomadic lifestyle, but the people have continued their age-old customs. Many Maasai tribes throughout Tanzania and Kenya welcome visits to their villages to experience their culture, traditions, and lifestyle, in return for a fee.

The Maasai inhabit the African Great Lakes region and arrived via the South Sudan. Most Nilotic speakers in the area, including the Maasai, the Turkana and the Kalenjin, are pastoralists, and are famous for their fearsome reputations as warriors and cattle-rustlers. The Maasai and other groups in East Africa have adopted customs and practices from neighboring Cushitic-speaking groups, including the age set system of social organization, circumcision, and vocabulary terms.

According to their oral history, the Maasai originated from the lower Nile valley north of Lake Turkana (Northwest Kenya) and began migrating south around the 15th century, arriving in a long trunk of land stretching from what is now northern Kenya to what is now central Tanzania between the 17th and late 18th century. Many ethnic groups that had already formed settlements in the region were forcibly displaced by the incoming Maasai, while other, mainly Southern Cushitic groups, were assimilated into Maasai society. The Nilotic ancestors of the Kalenjin likewise absorbed some early Cushitic populations.

The Maasai territory reached its largest size in the mid-19th century, and covered almost all of the Great Rift Valley and adjacent lands from Mount Marsabit in the north to Dodoma in the south. At this time the Maasai, as well as the larger Nilotic group they were part of, raised cattle as far east as the Tanga coast in Tanganyika (now mainland Tanzania). Raiders used spears and shields, but were most feared for throwing clubs (orinka) which could be accurately thrown from up to 70 paces (appx. 100 metres). In 1852, there was a report of a concentration of 800 Maasai warriors on the move in what is now Kenya. In 1857, after having depopulated the "Wakuafi wilderness" in what is now southeastern Kenya, Maasai warriors threatened Mombasa on the Kenyan coast.
Because of this migration, the Maasai are the southernmost Nilotic speakers. The period of expansion was followed by the Maasai "Emutai" of 1883–1902. This period was marked by epidemics of contagious bovine pleuropneumonia, rinderpest (see 1890s African rinderpest epizootic), and smallpox. The estimate first put forward by a German lieutenant in what was then northwest Tanganyika, was that 90% of cattle and half of wild animals perished from rinderpest. German doctors in the same area claimed that "every second" African had a pock-marked face as the result of smallpox. This period coincided with drought. Rains failed completely in 1897 and 1898.

The Austrian explorer Oscar Baumann travelled in Maasai lands between 1891 and 1893, and described the old Maasai settlement in the Ngorongoro Crater in the 1894 book "Durch Massailand zur Nilquelle" ("Through the lands of the Maasai to the source of the Nile"): "There were women wasted to skeletons from whose eyes the madness of starvation glared ... warriors scarcely able to crawl on all fours, and apathetic, languishing elders. Swarms of vultures followed them from high, awaiting their certain victims." By one estimate two-thirds of the Maasai died during this period.

Starting with a 1904 treaty, and followed by another in 1911, Maasai lands in Kenya were reduced by 60% when the British evicted them to make room for settler ranches, subsequently confining them to present-day Samburu, Laikipia, Kajiado and Narok districts. Maasai in Tanganyika (now mainland Tanzania) were displaced from the fertile lands between Mount Meru and Mount Kilimanjaro, and most of the fertile highlands near Ngorongoro in the 1940s. More land was taken to create wildlife reserves and national parks: Amboseli National Park, Nairobi National Park, Maasai Mara, Samburu National Reserve, Lake Nakuru National Park and Tsavo in Kenya; and Lake Manyara, Ngorongoro Conservation Area, Tarangire and Serengeti National Park in what is now Tanzania.

Maasai are pastoralist and have resisted the urging of the Tanzanian and Kenyan governments to adopt a more sedentary lifestyle. They have demanded grazing rights to many of the national parks in both countries.

The Maasai people stood against slavery and lived alongside most wild animals with an aversion to eating game and birds. Maasai land now has East Africa's finest game areas. Maasai society never condoned traffic of human beings, and outsiders looking for people to enslave avoided the Maasai.

Essentially there are twenty-two geographic sectors or sub tribes of the Maasai community, each one having its own customs, appearance, leadership and dialects. These subdivisions are known as 'nations' or' iloshon'in the Maa language: the Keekonyokie, Damat, Purko, Wuasinkishu, Siria, Laitayiok, Loitai, Kisonko, Matapato, Dalalekutuk, Loodokolani, Kaputiei, Moitanik, Ilkirasha, Samburu, Lchamus, Laikipia, Loitokitoki, Larusa, Salei, Sirinket and Parakuyo.

Recent advances in genetic analyses have helped shed some light on the ethnogenesis of the Maasai people. Genetic genealogy, a tool that uses the genes of modern populations to trace their ethnic and geographic origins, has also helped clarify the possible background of the modern Maasai.

The Maasai's autosomal DNA has been examined in a comprehensive study by Tishkoff et al. (2009) on the genetic affiliations of various populations in Africa. According to the study's authors, the Maasai "have maintained their culture in the face of extensive genetic introgression". Tishkoff et al. also indicate that: "Many Nilo-Saharan-speaking populations in East Africa, such as the Maasai, show multiple cluster assignments from the Nilo-Saharan [...] and Cushitic [...] AACs, in accord with linguistic evidence of repeated Nilotic assimilation of Cushites over the past 3000 years and with the high frequency of a shared East African–specific mutation associated with lactose tolerance."

A Y chromosome study by Wood et al. (2005) tested various Sub-Saharan populations, including 26 Maasai males from Kenya, for paternal lineages. The authors observed haplogroup E1b1b-M35 (not M78) in 35% of the studied Maasai. E1b1b-M35-M78 in 15%, their ancestor with the more northerly Cushitic males, who possess the haplogroup at high frequencies lived more than 13 000 years ago. The second most frequent paternal lineage among the Maasai was Haplogroup A3b2, which is commonly found in Nilotic populations, such as the Alur; it was observed in 27% of Maasai males. The third most frequently observed paternal DNA marker in the Maasai was E1b1a1-M2 (E-P1), which is very common in the Sub-Saharan region; it was found in 12% of the Maasai samples. Haplogroup B-M60 was also observed in 8% of the studied Maasai, which is also found in 30% (16/53) of Southern Sudanese Nilotes.

According to an mtDNA study by Castri et al. (2008), which tested Maasai individuals in Kenya, the maternal lineages found among the Maasai are quite diverse, but similar in overall frequency to that observed in other Nilo-Hamitic populations from the region, such as the Samburu. Most of the tested Maasai belonged to various macro-haplogroup L sub-clades, including L0, L2, L3, L4 and L5. Some maternal gene flow from North and Northeast Africa was also reported, particularly via the presence of mtDNA haplogroup M lineages in about 12.5% of the Maasai samples.

Maasai society is strongly patriarchal in nature, with elder men, sometimes joined by retired elders, deciding most major matters for each Maasai group. A full body of oral law covers many aspects of behavior. Formal capital punishment is unknown, and normally payment in cattle will settle matters. An out-of-court process is also practiced called "amitu", 'to make peace', or "arop", which involves a substantial apology.
The monotheistic Maasai worship a single deity called "Enkai" or "Engai". Engai has a dual nature: Engai Narok (Black God) is benevolent, and Engai Na-nyokie (Red God) is vengeful. There are also two pillars or totems of Maasai society: Oodo Mongi, the Red Cow and Orok Kiteng, the Black Cow with a subdivision of five clans or family trees. The Maasai also have a totemic animal, which is the lion; however, the animal can be killed. The way the Maasai kill the lion differs from trophy hunting as it is used in the rite of passage ceremony. The "Mountain of God", Ol Doinyo Lengai, is located in northernmost Tanzania and can be seen from Lake Natron in southernmost Kenya. The central human figure in the Maasai religious system is the whose roles include shamanistic healing, divination and prophecy, and ensuring success in war or adequate rainfall. Today, they have a political role as well due to the elevation of leaders. Whatever power an individual laibon had was a function of personality rather than position. Many Maasai have also adopted Christianity and Islam. The Maasai are known for their intricate jewelry and for decades, have sold these items to tourists as a business.

A once high infant mortality rate among the Maasai has led to babies not truly being recognized until they reach an age of 3 months "ilapaitin". Educating Maasai women to use clinics and hospitals during pregnancy has enabled more infants to survive. The exception is found in extremely remote areas. For Maasai living a traditional life, the end of life is virtually without ceremony, and the dead are left out for scavengers. A corpse rejected by scavengers is seen as having something wrong with it, and liable to cause social disgrace; therefore, it is not uncommon for bodies to be covered in fat and blood from a slaughtered ox. Burial has in the past been reserved for great chiefs, since it is believed to be harmful to the soil.

Traditional Maasai lifestyle centres around their cattle which constitute their primary source of food. The measure of a man's wealth is in terms of cattle and children. A herd of 50 cattle is respectable, and the more children the better. A man who has plenty of one but not the other is considered to be poor. A Maasai religious belief relates that God gave them all the cattle on earth, leading to the belief that rustling cattle from other tribes is a matter of taking back what is rightfully theirs, a practice that has become much less common.

All of the Maasai’s needs for food are met by their cattle. They eat the meat, drink the milk daily, and drink the blood on occasion. Bulls, goats, and lambs are slaughtered for meat on special occasions and for ceremonies. Though the Maasai’s entire way of life has historically depended on their cattle, more recently with their cattle dwindling, the Maasai have grown dependent on food such as sorghum, rice, potatoes and cabbage (known to the Maasai as goat leaves).

A traditional pastoral lifestyle has become increasingly difficult due to outside influences of the modern world. Garrett Hardin's article, outlining the "tragedy of the commons", as well as Melville Herskovits' "cattle complex" helped to influence ecologists and policy makers about the harm Maasai pastoralists were causing to savannah rangelands. This concept was later proven false by anthropologists but is still deeply ingrained in the minds of ecologists and Tanzanian officials. This influenced British colonial policy makers in 1951 to remove all Maasai from the Serengeti National Park and relegate them to areas in and around the Ngorongoro Conservation Area (NCA). The plan for the NCA was to put Maasai interests above all else, but this promise was never met. The spread of HIV was rampant.

Due to an increase in Maasai population, loss of cattle populations to disease, and lack of available rangelands because of new park boundaries and the incursion of settlements and farms by other tribes (this is also the chief reason for the decline in wildlife-habitat loss, with the second being poaching), the Maasai were forced to develop new ways of sustaining themselves. Many Maasai began to cultivate maize and other crops to get by, a practice that was culturally viewed negatively. Cultivation was first introduced to the Maasai by displaced WaArusha and WaMeru women who were married to Maasai men; subsequent generations practiced a mixed livelihood. To further complicate their situation, in 1975 the Ngorongoro Conservation Area banned cultivation practices. In order to survive they are forced to participate in Tanzania’s monetary economy. They have to sell their animals and traditional medicines in order to buy food. The ban on cultivation was lifted in 1992 and cultivation has again become an important part of Maasai livelihood. Park boundaries and land privatisation has continued to limit grazing area for the Maasai and have forced them to change considerably.

Over the years, many projects have begun to help Maasai tribal leaders find ways to preserve their traditions while also balancing the education needs of their children for the modern world.

The emerging forms of employment among the Maasai people include farming, business (selling of traditional medicine, running of restaurants/shops, buying and selling of minerals, selling milk and milk products by women, embroideries), and wage employment (as security guards/ watchmen, waiters, tourist guides), and others who are engaged in the public and private sectors.

Many Maasai have moved away from the nomadic life to positions in commerce and government. Yet despite the sophisticated urban lifestyle they may lead, many will happily head homewards dressed in designer clothes, only to emerge from the traditional family homestead wearing a shuka (colourful piece of cloth), cow hide sandals and carrying a wooden club (o-rinka) - at ease with themselves.

The central unit of Maasai society is the age-set. Young boys are sent out with the calves and lambs as soon as they can toddle, but childhood for boys is mostly playtime, with the exception of ritual beatings to test courage and endurance. Girls are responsible for chores such as cooking and milking, skills which they learn from their mothers at an early age. Every 15 years or so, a new and individually named generation of Morans or Il-murran (warriors) will be initiated. This involves most boys between 12 and 25, who have reached puberty and are not part of the previous age-set. One rite of passage from boyhood to the status of junior warrior is a circumcision ceremony performed without anaesthetic. In modern times, boys living close to towns with doctors may endure the ceremony in safer conditions, but still without anaesthetic because they must endure the pain that will lead them to manhood. This ritual is typically performed by the elders, who use a sharpened knife and makeshift cattle hide bandages for the procedure. The Maa word for circumcision is emorata. The boy must endure the operation in silence. Expressions of pain bring dishonor, albeit temporarily. Any exclamations can cause a mistake in the delicate and tedious process, which can result in lifelong scarring, dysfunction, and pain. The healing process will take 3–4 months, during which urination is painful and nearly impossible at times, and boys must remain in black clothes for a period of 4–8 months.

During this period, the newly circumcised young men will live in a "manyatta", a "village" built by their mothers. The manyatta has no encircling barricade for protection, emphasizing the warrior role of protecting the community. No inner kraal is built, since warriors neither own cattle nor undertake stock duties. Further rites of passage are required before achieving the status of senior warrior, culminating in the eunoto ceremony, the "coming of age".

When a new generation of warriors is initiated, the existing Il-murran will graduate to become junior elders, who are responsible for political decisions until they in turn become senior elders. This graduation from warrior to junior elder takes place at a large gathering known as Eunoto. The long hair of the former warriors is shaved off; elders must wear their hair short. Warriors are not allowed to have sexual relations with circumcised women, though they may have girlfriends who are uncircumcised girls. At Eunoto, the warriors who managed to abide by this rule are specially recognized.

The warriors spend most of their time now on walkabouts throughout Maasai lands, beyond the confines of their sectional boundaries. They are also much more involved in cattle trading than they used to be, developing and improving basic stock through trades and bartering rather than stealing as in the past.

One myth about the Maasai is that each young man is supposed to kill a lion before he is circumcised. Lion hunting was an activity of the past, but it has been banned in Southeast Africa – yet lions are still hunted when they maul Maasai livestock, and young warriors who engage in traditional lion killing do not face significant consequences. Increasing concern regarding lion populations has given rise to at least one program which promotes accepting compensation when a lion kills livestock, rather than hunting and killing the predator. Nevertheless, killing a lion gives one great value and celebrity status in the community.

Young women also undergo excision ("female circumcision", "female genital mutilation," "emorata") as part of an elaborate rite of passage ritual called "Emuratare," the ceremony that initiates young Maasai girls into adulthood through ritual circumcision and then into early arranged marriages. The Maasai believe that female circumcision is necessary and Maasai men may reject any woman who has not undergone it as either not marriageable or worthy of a much-reduced bride price. In Eastern Africa, uncircumcised women, even those highly educated members of parliament like Linah Kilimo, can be accused of not being mature enough to be taken seriously. To others the practice of female circumcision is known as female genital mutilation, and draws a great deal of criticism from both abroad and many women who have undergone it, such as Maasai activist Agnes Pareyio. It has recently been replaced in some instances by a "cutting with words" ceremony involving singing and dancing in place of the mutilation. However, the practice remains deeply ingrained and valued by the culture. The Maa word for circumcision, "emorata," is used for both female and male genital mutilation. Female genital cutting is illegal in both Kenya and Tanzania. These circumcisions are usually performed by an invited 'practitioner' who is often not Maasai, usually from a Dorobo group. The knives and blades which make the cut are fashioned by blacksmiths, il-kunono, who make their weapons for the Maasai who do not make their own:(knives, short swords (ol alem or simi or seme), spears, etc.). Similarly to the young men, women who will be circumcised wear dark clothing, paint their faces with markings, and then cover their faces on completion of the ceremony.

Married women who become pregnant are excused from all heavy work such as milking and gathering firewood. Sexual relations are also banned and there are specific rules applied to pregnant women.
The Maasai are traditionally polygynous; this is thought to be a long-standing and practical adaptation to high infant and warrior mortality rates. Polyandry is also practiced. However, today this practice is usually abandoned. A woman marries not just her husband but the entire age group. Men are expected to give up their bed to a visiting age-mate guest; however, today this practice is usually abandoned. The woman decides strictly on her own if she will join the visiting male. Any child which may result is the husband's child and his descendant in the patrilineal order of Maasai society. "Kitala", a kind of divorce or refuge, is possible in the house of a wife's father, usually for gross mistreatment of the wife. Repayment of the bride price, custody of children, etc., are mutually agreed upon.

Maasai music traditionally consists of rhythms provided by a chorus of vocalists singing harmonies while a song leader, or olaranyani, sings the melody. The olaranyani is usually the singer who can best sing that song, although several individuals may lead a song. The olaranyani begins by singing a line or title (namba) of a song. The group will respond with one unanimous call in acknowledgment, and the olaranyani will sing a verse over the group's rhythmic throat singing. Each song has its specific namba structure based on call-and-response. Common rhythms are variations of 5/4, 6/4 and 3/4 time signatures. Lyrics follow a typical theme and are often repeated verbatim over time. Neck movements accompany singing. When breathing out the head is leaned forward. The head is tilted back for an inward breath. Overall the effect is one of polyphonic syncopation. Unlike most other African tribes, Maasai widely use drone polyphony.

Women chant lullabies, humming songs, and songs praising their sons. Nambas, the call-and-response pattern, repetition of nonsensical phrases, monophonic melodies, repeated phrases following each verse being sung on a descending scale, and singers responding to their own verses are characteristic of singing by females. When many Maasai women gather together, they sing and dance among themselves.

One exception to the vocal nature of Maasai music is the use of the horn of the Greater Kudu to summon morans for the Eunoto ceremony.

Both singing and dancing sometimes occur around manyattas, and involve flirting. Young men will form a line and chant rhythmically, "Oooooh-yah", with a growl and staccato cough along with the thrust and withdrawal of their lower bodies. Girls stand in front of the men and make the same pelvis lunges while singing a high dying fall of "Oiiiyo..yo" in counterpoint to the men. Although bodies come in close proximity, they do not touch.

Eunoto, the coming of age ceremony of the warrior, can involve ten or more days of singing, dancing and ritual. The warriors of the Il-Oodokilani perform a kind of march-past as well as the adumu, or aigus, sometimes referred as "the jumping dance" by non-Maasai. (Both adumu and aigus are Maa verbs meaning "to jump" with adumu meaning "To jump up and down in a dance".) Warriors are well known for, and often photographed during, this competitive jumping. A circle is formed by the warriors, and one or two at a time will enter the center to begin jumping while maintaining a narrow posture, never letting their heels touch the ground. Members of the group may raise the pitch of their voices based on the height of the jump.
The girlfriends of the moran (intoyie) parade themselves in their most spectacular costumes as part of the eunoto. The mothers of the moran sing and dance in tribute to the courage and daring of their sons.

The piercing and stretching of earlobes is common among the Maasai as with other tribes. Various materials have been used to both pierce and stretch the lobes, including thorns for piercing, twigs, bundles of twigs, stones, the cross section of elephant tusks and empty film canisters. Fewer and fewer Maasai, particularly boys, follow this custom. Women wear various forms of beaded ornaments in both the ear lobe, and smaller piercings at the top of the ear. Amongst Maasai males, circumcision is practiced as a ritual of transition from boyhood to manhood. Women are also circumcised (as described above).

The removal of deciduous canine tooth buds in early childhood is a practice that has been documented in the Maasai of Kenya and Tanzania. There exists a strong belief among the Maasai that diarrhea, vomiting and other febrile illnesses of early childhood are caused by the gingival swelling over the canine region, which is thought to contain 'worms' or 'nylon' teeth. This belief and practice is not unique to the Maasai. In rural Kenya a group of 95 children aged between six months and two years were examined in 1991/92. 87% were found to have undergone the removal of one or more deciduous canine tooth buds. In an older age group (3–7 years of age), 72% of the 111 children examined exhibited missing mandibular or maxillary deciduous canines.

Traditionally, the Maasai diet consisted of raw meat, raw milk, and raw blood from cattle. Note that the Maasai cattle are of the Zebu variety. In the summer of 1935 Dr. Weston A. Price visited the Maasai and reported that according to Dr. Anderson from the local government hospital in Kenya most tribes were disease-free. Many had not a single tooth attacked by dental caries nor a single malformed dental arch. In particular the Maasai had a very low 0.4% of bone caries. He attributed that to their diet consisting of (in order of volume) raw milk, raw blood, raw meat and some vegetables and fruits, although in many villages they do not eat any fruit or vegetables at all. He noted that when available every growing child and every pregnant or lactating woman would receive a daily ration of raw blood. Dr. Weston A. Price also noted the government efforts back in 1935 to turn the Maasai into farmers. An ILCA study (Nestel 1989) states: "Today, the stable diet of the Maasai consists of cow's milk and maize-meal. The former is largely drunk fresh or in sweet tea and the latter is used to make a liquid or solid porridge. The solid porridge is known as ugali and is eaten with milk; unlike the liquid porridge, ugali is not prepared with milk. Animal fats or butter are used in cooking, primarily of porridge, maize, and beans. Butter is also an important infant food."

Studies by the International Livestock Centre for Africa (Bekure et al. 1991) shows a very great change in the diet of the Maasai towards non-livestock products with maize comprising 12–39 percent and sugar 8–13 percent; about one litre of milk is consumed per person daily.
Most of the milk is consumed as fermented milk or buttermilk (a by-product of butter making). Milk consumption figures are very high by any standards. The needs for protein and essential amino acids are more than adequately satisfied. However, the supply of iron, niacin, vitamin C, vitamin A, thiamine and energy are never fully met by a purely milk diet. Due to changing circumstances, especially the seasonal nature of the milk supply and frequent droughts, most pastoralists, including the Maasai, now include substantial amounts of grain in their diets.

The Maasai herd goats and sheep, including the Red Maasai sheep, as well as the more prized cattle. Electrocardiogram tests applied to 400 young adult male Maasai found no evidence whatsoever of heart disease, abnormalities or malfunction. Further study with carbon-14 tracers showed that the average cholesterol level was about 50 percent of that of an average American. These findings were ascribed to the amazing fitness of morans, which was evaluated as "Olympic standard".

Soups are probably the most important use of plants for food by Maasai. "Acacia nilotica" is the most frequently used soup plant. The root or stem bark is boiled in water and the decoction drunk alone or added to soup. The Maasai are fond of taking this as a drug, and is known to make them energetic, aggressive and fearless. Maasai eat soup laced with bitter bark and roots containing cholesterol-lowering saponins; those urban Maasai who don't have access to the bitter plants tend to develop heart disease. Although consumed as snacks, fruits constitute a major part of the food ingested by children and women looking after cattle as well as morans in the wilderness.

The mixing of cattle blood, obtained by nicking the jugular vein, and milk is done to prepare a ritual drink for special celebrations and as nourishment for the sick. However, the inclusion of blood in the traditional diet is waning due to the reduction of livestock numbers. More recently, the Maasai have grown dependent on food produced in other areas such as maize meal, rice, potatoes, cabbage (known to the Maasai as goat leaves) etc. The Maasai who live near crop farmers have engaged in cultivation as their primary mode of subsistence. In these areas, plot sizes are generally not large enough to accommodate herds of animals; thus the Maasai are forced to farm.

As a historically nomadic and then semi-nomadic people, the Maasai have traditionally relied on local, readily available materials and indigenous technology to construct their housing. The traditional Maasai house was in the first instance designed for people on the move and was thus very impermanent in nature. The houses are either somewhat rectangular shaped with extensions or circular, and are constructed by able-bodied women. The structural framework is formed of timber poles fixed directly into the ground and interwoven with a lattice of smaller branches wattle, which is then plastered with a mix of mud, sticks, grass, cow dung, human urine, and ash. The cow dung ensures that the roof is waterproof. The enkaj or engaji is small, measuring about 3 × 5 m and standing only 1.5 m high. Within this space, the family cooks, eats, sleeps, socializes, and stores food, fuel, and other household possessions. Small livestock are also often accommodated within the enkaji. Villages are enclosed in a circular fence (an enkang) built by the men, usually of thorned acacia, a native tree. At night, all cows, goats, and sheep are placed in an enclosure in the centre, safe from wild animals.

Clothing changes by age and location. Young men, for instance, wear black for several months following their circumcision. However, red is a favored colour. Blue, black, striped, and checkered cloth are also worn, as are multicolored African designs. The Maasai began to replace animal skin, calf hides and sheep skin, with commercial cotton cloth in the 1960s.

Shúkà is the Maa word for sheets traditionally worn wrapped around the body. These are typically red, though with some other colors (e.g. blue) and patterns (e.g. plaid). Pink, even with flowers, is not shunned by warriors. One piece garments known as kanga, a Swahili term, are common. Maasai near the coast may wear kikoi, a type of sarong that comes in many different colors and textiles. However, the preferred style is stripes.

Many Maasai in Tanzania wear simple sandals, which were until recently made from cowhides. They are now soled with tire strips or plastic. Both men and women wear wooden bracelets. The Maasai women regularly weave and bead jewellery. This bead work plays an essential part in the ornamentation of their body. Although there are variations in the meaning of the color of the beads, some general meanings for a few colors are: white, peace; blue, water; red, warrior/blood/bravery.

Beadworking, done by women, has a long history among the Maasai, who articulate their identity and position in society through body ornaments and body painting. Before contact with Europeans, the beads were produced mostly from local raw materials. White beads were made from clay, shells, ivory, or bone. Black and blue beads were made from iron, charcoal, seeds, clay, or horn. Red beads came from seeds, woods, gourds, bone, ivory, copper, or brass. When late in the nineteenth century, great quantities of brightly colored European glass beads arrived in Southeast Africa, beadworkers replaced the older beads with the new materials and began to use more elaborate color schemes. Currently, dense, opaque glass beads with no surface decoration and a naturally smooth finish are preferred.

Head shaving is common at many rites of passage, representing the fresh start that will be made as one passes from one to another of life's chapters. Warriors are the only members of the Maasai community to wear long hair, which they weave in thinly braided strands.

Upon reaching the age of 3 "moons", the child is named and the head is shaved clean apart from a tuft of hair, which resembles a cockade, from the nape of the neck to the forehead. The cockade symbolizes the "state of grace" accorded to infants. A woman who has miscarried in a previous pregnancy would position the hair at the front or back of the head, depending on whether she had lost a boy or a girl.

Two days before boys are circumcised, their heads are shaved. The young warriors then allow their hair to grow, and spend a great deal of time styling the hair. It is dressed with animal fat and ocher, and parted across the top of the head at ear level. Hair is then plaited: parted into small sections which are divided into two and twisted, first separately then together. Cotton or wool threads may be used to lengthen hair. The plaited hair may hang loose or be gathered together and bound with leather. When warriors go through the "Eunoto", and become elders, their long plaited hair is shaved off.

As males have their heads shaved at the passage from one stage of life to another, a bride to be will have her head shaved, and two rams will be slaughtered in honor of the occasion.





</doc>
<doc id="20524" url="https://en.wikipedia.org/wiki?curid=20524" title="Medieval fortification">
Medieval fortification

Medieval fortification refers to medieval military methods that cover the development of fortification construction and use in Europe, roughly from the fall of the Western Roman Empire to the Renaissance. During this millennium, fortifications changed warfare, and in turn were modified to suit new tactics, weapons and siege techniques.

Towers of medieval castles were usually made of stone or sometimes (but rarely) wood. Often toward the later part of the era they included battlements and arrow loops. Arrow loops were vertical slits in the wall through which archers inside shot arrows at the attackers, but made it extremely difficult for attackers to get many arrows back through at the defenders.

An exact nature of the walls of a medieval town or city would depend on the resources available for building them, the nature of the terrain, and the perceived threat. In northern Europe, early in the period, walls were likely to have been constructed of wood and proofed against small forces. Especially where stone was readily available for building, the wood will have been replaced by stone to a higher or lower standard of security. This would have been the pattern of events in the Five Boroughs of the Danelaw in England.

In many cases, the wall would have had an internal and an external "pomoerium". This was a strip of clear ground immediately adjacent the wall. The word is from the late medieval, derived from the classical Latin "post murum" ("behind the wall").

An external pomoerium, stripped of bushes and building, gave defenders a clear view of what was happening outside and an unobstructed field of shot. An internal pomoerium gave ready access to the rear of the curtain wall to facilitate movement of the garrison to a point of need. By the end of the sixteenth century, the word had developed further in common use, into "pomery".
Also by that time, the medieval walls were no longer secure against a serious threat from an army, as they were not designed to be strong enough to resist cannon fire. They were sometimes rebuilt, as at Berwick on Tweed, or retained for use against thieves and other threats of a lower order. Very elaborate and complex schemes for town defences were developed in the Netherlands and France, but these belong mainly to the post-medieval periods. By 1600, the medieval wall is likely to have been seen more as a platform for displaying hangings and the pomery as a gathering ground for spectators, or as a source of building stone and a site for its use, respectively. However, a few, such as those of Carcassonne and Dubrovnik, survived fairly well and have been restored to a nearly complete state.

Medieval walls that were no longer adequate for defending were succeeded by the star fort. After the invention of the explosive shell, star forts became obsolete as well.

Harbours or some sort of water access was often essential to the construction of medieval fortification. It was a direct route for trading and fortification. Having direct access to a body of water provided a route for resupply in times of war, an additional method of transportation in times of peace, and potential drinking water for a besieged castle or fortification. The concept of rivers or harbours coming directly up to the walls of fortifications was especially used by the English as they constructed castles throughout Wales.
There is evidence that harbours were fortified, with wooden structures in the water creating a semi-circle around the harbour, or jetties, as seen in an artists reconstruction of Hedeby, in Denmark, with an opening for ships to access the land. Usually, these wooden structures would have small bases at either end, creating a 'watch' and defense platform.

Religion was a central part of the lives of medieval soldiers, and churches, chapels, monasteries, and other buildings of religious function were often included within the walls of any fortification, be it temporary or permanent. A place to conduct religious services was usually essential to the morale of the soldiers.

Motte-and-bailey was the prevalent form of castle during 11th and 12th centuries. A courtyard (called a bailey) was protected by a ditch and a palisade (strong timber fence). Often the entrance was protected by a lifting bridge, a drawbridge or a timber gate tower. Inside the bailey were stables, workshops, and a chapel.

The motte was the final refuge in this type of castle. It was a raised earth mound, and varied considerably, with these mounds being 3 metres to 30 metres in height (10 feet to 100 feet), and from in diameter. There was a tower on top of the motte. In most cases, the tower was made of timber, though some were also made of stones. Stone towers were found in natural mounds, as artificial ones were not strong enough to support stone towers. Larger mottes had towers with many rooms, including the great hall. Smaller ones had only a watch tower.

Construction could sometimes take decades. The string of Welsh castles Edward I of England had built were an exception in that he focused much of the resources of his kingdom on their speedy construction. In addition to paid workers, forced levies of labourers put thousands of men on each site and shortened construction to a few years.

Nature could provide very effective defenses for the castle. For this reason many castles were built on larger hills, cliffs, close to rivers, lakes or even caves.

Materials that were used in the building of castles varied through history. Wood was used for most castles until 1066. They were cheap and were quick to construct. The reason wood fell into disuse as a material is that it is quite flammable. Soon stone became more popular.

Stone castles took years to construct depending on the overall size of the castle. Stone was stronger and of course much more expensive than wood. Most stone had to be quarried miles away, and then brought to the building site. But with the invention of the cannon and gunpowder, castles soon lost their power.

Costs for the walls depended on the material used. Wood would cost very little and was quick to build, but was weak. Stone was strong but very expensive and time-consuming to construct.

Manpower in the medieval era in Europe consisted mainly of serfs.

The height of walls varied widely by castle, but were often thick. They were usually topped with crenellation or parapets that offered protection to defenders. Some also featured machicolations (from the French "machicoulis", approximately "neck-crusher") which consisted of openings between a wall and a parapet, formed by corbelling out the latter, allowing defenders to throw stones, boiling water, and so forth, upon assailants below. Some castles featured additional inner walls, as additional fortifications from which to mount a defense if outer walls were breached.

Any entrance through a wall, being an opening, forms an obvious weak point. To be practical, the entryway would have to accommodate supplies being brought through, yet difficult for attackers to breach. For example, passage over ditches or moats would have to be withdrawn to deny attackers. The use of multiple walls or ditches around an entrance would also make it difficult for defenders to use the entrance practically, necessitating better methods of control. Gates came in many forms, from the simple stone buttress and timber blocks, to the massive and imposing stone archways and thick wooden doors most associated with medieval citadels.

A killing field was an area between the main wall and a secondary wall, so when the first wall was breached the attackers would run into the killing field to be confronted by another wall from which soldiers bombarded them. Soldiers would be positioned atop the second wall and armed with any variety of weapons, ranging from bows to crossbows to simple rocks.

A moat was a common addition to medieval fortifications, and the principal purpose was to simply increase the effective height of the walls and to prevent digging under the walls. In many instances, natural water paths were used as moats, and often extended through ditches to surround as much of the fortification as possible. Provided this was not so unnaturally contrived as to allow an attacker to drain the system, it served two defensive purposes. It made approaching the curtain wall of the castle more difficult and the undermining of the wall virtually impossible. To position a castle on a small island was very favorable from a defensive point of view, although it made deliveries of supplies and building materials more cumbersome and expensive.

A keep is a strong central tower which normally forms the heart of a castle. Often the keep is the most defended area of a castle, and as such may form the main habitation area for a noble or lord, or contain important stores such as the armoury or the main well.

Stairs were also constructed to contain trick or stumble steps. These were steps that had different rise height or tread depth from the rest and would cause anyone running up the stairs to stumble or fall, so slowing down the attackers' progress.

A typical exterior wooden door might be made out of two layers of oak planks. The grain of the wood would run vertically on the front layer and horizontally on the back, like a simple form of plywood. The two layers would be held together by iron studs, and the structure might be strengthened and stiffened with iron bands.

The studs themselves were pointed on the front so that attackers would damage their weapons (swords, axes, etc.) while trying to break through.

From the mid-15th century onwards, the power of cannons grew and medieval walls became obsolete as they were too thin to offer any realistic protection against prolonged bombardment. As a consequence of this, medieval walls were often upgraded with the addition of artillery platforms or bastions, and battlements were replaced by thick parapets with embrasures. In many cases, the medieval walls were dismantled and their stonework, which was still valuable as construction material, was reused in the construction of the new fortifications. The resulting space is often seen in old city centers of Europe even to this day, as broader streets often outline where the old wall once stood (evident for example in Prague and Florence, Italy).

The transition between medieval and early modern fortification can be seen in the fortifications of Rhodes in Greece and the fortifications of Famagusta in Cyprus.

Just as modern military engineers enhance field fortifications with obstacles such as barbed wire, medieval engineers used a number of obstacle types including abatis, caltrops, cheval de frise, and trou de loup.





</doc>
<doc id="20527" url="https://en.wikipedia.org/wiki?curid=20527" title="Mark Whitacre">
Mark Whitacre

Mark Edward Whitacre (born May 1, 1957) is an American business executive who came to public attention in 1995 when, as president of the Decatur, Illinois-based BioProducts Division at Archer Daniels Midland (ADM), he became the highest-level corporate executive in U.S. history to become a Federal Bureau of Investigation (FBI) whistleblower. For three years (1992–95), Whitacre acted as a cooperating witness for the FBI, which was investigating ADM for price fixing. In the late 1990s Whitacre was sentenced to 9 years in federal prison for embezzling $9.5 million from ADM at the same time he was assisting the federal price-fixing investigation.

ADM investigated Whitacre's activities and, upon discovering suspicious activity, requested the FBI investigate Whitacre for embezzlement. As a result of $9.5 million in various frauds, Whitacre lost his whistleblower's immunity, and consequently spent eight and a half years in federal prison. He was released in December 2006. Whitacre is currently the chief operating officer and President of Operations at Cypress Systems, a California biotechnology firm.

Whitacre was born on May 1, 1957 and grew up in Morrow, Ohio. He holds B.S. and M.S. degrees from Ohio State University, and earned a Ph.D. in Nutritional Biochemistry from Cornell University (1983).

Whitacre was a Ph.D. scientist at Ralston Purina after he graduated from Cornell University in early 1983. He then was Vice President at Degussa from 1984 to 1989 prior to joining ADM. In late 1989, Whitacre became the President of the BioProducts Division at ADM. In 1992, he was promoted to Corporate Vice President of ADM, as well as being President of the BioProducts Division. On August 9, 1995, Whitacre was terminated for conducting a $9.5 million fraud after ADM learned that he was an FBI informant for three years. Whitacre wore a wire for the FBI assisting in one of the largest price fixing cases in U.S. history against ADM.

After leaving ADM in August 1995, Whitacre was hired as the CEO of Future Health Technologies (FHT), which soon was renamed Biomar International. He worked at Biomar until his incarceration began during early 1998.

In December 2006, after his release from federal prison, Whitacre was hired by Cypress Systems Inc., a California biotechnology company, as the President of Technology and Business Development. In March 2008, Whitacre was promoted to the company's Chief Operating Officer (COO) and President of operations.

In 1992, during an ADM-initiated investigation of corporate espionage and sabotage, Whitacre informed an FBI agent that he and other ADM executives were involved in an illegal multinational lysine price-fixing scheme. Whitacre's wife pressured him into becoming a whistleblower after she threatened to go to the FBI herself.

Over the next three years, Whitacre worked with FBI agents to collect information and record conversations with both ADM executives and its competitors. ADM ultimately settled federal charges for more than $100 million and paid hundreds of millions of dollars more to plaintiffs and customers ($400 million alone on a high-fructose corn syrup class action case).

A few years into the price-fixing investigation, Whitacre confessed to his FBI handlers that he had been involved with corporate kickbacks and money laundering at ADM. Whitacre was later convicted of embezzling $9 million; some of this criminal activity occurred during the time he was cooperating with the FBI.

Whitacre pled guilty to tax evasion and fraud and was sent to prison on March 4, 1998. Although some officials in the FBI and the Department of Justice opposed the length of the penalty, Whitacre was sentenced to ten and a half years in Federal prison. In December 2006, he was released on good behavior after serving eight and a half years.

In his 2000 book, "The Informant", Kurt Eichenwald, a former "The New York Times" reporter, portrays Whitacre as a complex figure: while working for the FBI as one of the best and most effective undercover cooperating witnesses the U.S. government ever had, Whitacre was simultaneously committing a $9 million white-collar crime. According to Eichenwald, preceding the investigation Whitacre was scammed by a group in Nigeria in an advance fee fraud, and suggests that Whitacre's losses in the scam may have been the initial reason behind his embezzlement activity at ADM.

Eichenwald writes that Whitacre lied and became delusional in a failed attempt to save himself, making the FBI investigation much more difficult. "The Informant" details Whitacre's bizarre behavior, including Whitacre cracking under pressure, increasing his mania, telling the media that FBI agents tried to force him to destroy tapes (a story that Whitacre later recanted), and attempting suicide. Two doctors later diagnosed Whitacre as suffering from bipolar disorder. Eichenwald concludes that Whitacre's sentence was unjust because of his mental instability at the time.

Eichenwald, two prosecutors, an FBI agent, and Mark Whitacre (during his incarceration) were featured on a September 15, 2000, episode of the radio program "This American Life" about the ADM case. Eichenwald referred to Whitacre's sentence as "excessive and a law enforcement failure" because Whitacre never received credit for his substantial cooperation in assisting the government with the massive price-fixing case.

Eichenwald's account of Whitacre has been called into question by the syndicated columnist Alan Guebert, following the disclosure in August 2007 that Eichenwald paid his sources on another story.

"The Informant!" is a Warner Bros. feature film released on September 18, 2009. Produced by Jennifer Fox and directed by Steven Soderbergh, the dark comedy/drama film stars Matt Damon as Whitacre. The screenplay by Scott Z. Burns is based on Kurt Eichenwald's book, "The Informant", with most of the filming done in Central Illinois (Blue Mound, Moweaqua and Decatur). In the movie, the character of Whitacre is portrayed as exhibiting bizarre behavior, including delusions, mania, and compulsively lying. It was eventually learned that Whitacre was suffering from bipolar disorder.

In his 2000 book, "Rats In The Grain", attorney James B. Lieber focuses on ADM's price-fixing trial and presents Whitacre as an American hero overpowered by ADM's vast political clout. "Rats In The Grain" presents evidence that the U.S. Department of Justice often subjugated itself to ADM's political power and well-connected attorneys in prosecuting Whitacre. Lieber reveals that, in 1996, "ADM CEO, Mr. Dwayne Andreas, told "The Washington Post" that he had known about Whitacre's frauds for three years" and speculates that Whitacre was fired and turned over to the Federal authorities only after ADM learned he had been working as an FBI mole. If he knew about Whitacre's embezzlement for three years, Lieber asks, why didn't Andreas fire Whitacre immediately? Lieber surmises: "There were only two logical explanations for Andreas' behavior: either he did not think the funds were stolen (in other words, they were approved) or he didn't care." Based on the fact that other ADM executives committed crimes such as financial fraud by a former treasurer and technology thefts by others, Lieber concludes that fraud was well-known and widespread at ADM during the 1990s. Lieber suggests that ADM would have not turned Whitacre over to the authorities if he had not been a mole for the FBI.

Like Eichenwald, Lieber concludes that Whitacre's lengthy prison sentence was excessive and unjust when one takes into account Whitacre's cooperation in the much larger price-fixing case.

Lieber also poses this question: "Where will the government obtain the next Mark Whitacre after potential whistleblowers observe how Whitacre was treated?"

Appeals for Whitacre's full pardon or clemency to the White House were supported by several current and former justice department officials: Dean Paisley, a retired 25-year veteran and former FBI supervisor on the price-fixing case; two other FBI agents involved with the case; a former Attorney General of the United States; one of the former Asst. U.S. Attorneys who prosecuted Whitacre; two prosecutors from the Canadian Department of Justice; several Senators and Congressmen; Cornell University and Ohio State University professors; Major League Baseball Hall of Famer Harmon Killebrew; Chuck Colson; and numerous top executives of corporations.

In 2008, more than ten years after the original conviction, Paisley and two other FBI agents went public with praise for Whitacre. Paisley concluded that "Whitacre's fraud case was minuscule as compared to the ADM case Whitacre cooperated with." "Had it not been for the fraud conviction," Paisley said, "he would be a national hero. Well, he is a national hero." Paisley added, "Without him, the biggest antitrust case we've ever had would not have been." On August 4, 2010, in a Discovery Channel documentary, "Undercover: Operation Harvest King", several FBI agents stated that "Whitacre got a raw deal." In addition, official letters from the FBI in support of a Whitacre pardon were published in Floyd Perry's September 2009 book, "Mark Whitacre: Against All Odds."

A Discovery Channel TV documentary titled "Undercover: Operation Harvest King", which documents Mark Whitacre's role in the ADM price fixing case, aired several times during 2009 and 2010. Discovery Channel interviewed the three FBI agents who handled the Mark Whitacre/ADM case (i.e., Dean Paisley, Brian Shepard and Robert Herndon), along with Mark and Ginger Whitacre. The 45-minute documentary is archived.

Whitacre married his high school sweetheart, Ginger Gilbert, on June 16, 1979.

Whitacre became a Christian during his incarceration, and since his prison release during December 2006, he has been often interviewed by the Christian community-including the Christian Broadcasting Network (CBN)-about redemption, second chances, and the importance of his faith. Forbes reported that Whitacre was guest speaker at the Quantico FBI Academy during 2011 about second chances, and he was keynote speaker for the 40th Annual NAPSA (Pre Trial Services and U.S. Federal Probation) Conference in 2012 along with Robert F. Kennedy Jr.






</doc>
<doc id="20531" url="https://en.wikipedia.org/wiki?curid=20531" title="Marrakesh Agreement">
Marrakesh Agreement

The Marrakesh Agreement, manifested by the Marrakesh Declaration, was an agreement signed in Marrakesh, Morocco, by 123 nations on 15 April 1994, marking the culmination of the 8-year-long Uruguay Round and establishing the World Trade Organization, which officially came into being on 1 January 1995.

The agreement developed out of the General Agreement on Tariffs and Trade (GATT), supplemented by a number of other agreements on issues including trade in services, sanitary and phytosanitary measures, trade-related aspects of intellectual property and technical barriers to trade. It also established a new, more efficient and legally binding means of dispute resolution. The various agreements which make up the Marrakesh Agreement combine as an indivisible whole; no entity can be party to any one agreement without being party to them all.



</doc>
<doc id="20534" url="https://en.wikipedia.org/wiki?curid=20534" title="Mad">
Mad

Mad or MAD may refer to:







</doc>
<doc id="20537" url="https://en.wikipedia.org/wiki?curid=20537" title="Mainz">
Mainz

Mainz (; ; , ) is the capital and largest city of Rhineland-Palatinate, Germany. The city is located on the Rhine river at its confluence with the Main river, opposite Wiesbaden on the border with Hesse. Mainz is an independent city with a population of 206,628 (2015) and forms part of the Frankfurt Rhine-Main Metropolitan Region.

Mainz was founded by the Romans in the 1st century BC during the Classical antiquity era, serving as a military fortress on the northernmost frontier of the Roman Empire and as the provincial capital of Germania Superior. Mainz became an important city in the 8th century AD as part of the Holy Roman Empire, becoming the capital of the Electorate of Mainz and seat of the Archbishop-Elector of Mainz, the Primate of Germany. Mainz is famous as the home of Johannes Gutenberg, the inventor of the movable-type printing press, who in the early 1450s manufactured his first books in the city, including the Gutenberg Bible. Mainz was heavily damaged during World War II, with more than 30 air raids destroying about 80 percent of the city's center, including most of the historic buildings. Today, Mainz is a transport hub and a center of wine production.

Mainz is located on the 50th latitude, on the left bank of the river Rhine, opposite the confluence of the Main with the Rhine. The population in the early 2012 was 200,957, an additional 18,619 people maintain a primary residence elsewhere but have a second home in Mainz. The city is part of the Rhein Metro area comprising 5.8 million people. Mainz can easily be reached from Frankfurt International Airport in 25 minutes by commuter railway (Line S8).
Mainz is a river port city as the Rhine which connects with its main tributaries, such as the Neckar, the Main and, later, the Moselle and thereby continental Europe with the Port of Rotterdam and thus the North Sea. Mainz's history and economy are closely tied to its proximity to the Rhine historically handling much of the region's waterborne cargo. Today's huge container port hub allowing trimodal transport is located on the North Side of the town. The river also provides another positive effect, moderating Mainz's climate; making waterfront neighborhoods slightly warmer in winter and cooler in summer.

After the last ice age, sand dunes were deposited in the Rhine valley at what was to become the western edge of the city. The Mainz Sand Dunes area is now a nature reserve with a unique landscape and rare "steppe" vegetation for this area.

While the Mainz legion camp was founded in 13/12 BC on the Kästrich hill, the associated vici and canabae were erected in direction to the Rhine. Historical sources and archaeological findings both prove the importance of the military and civilian Mogontiacum as a port city on the Rhine.

Mainz experiences an oceanic climate (Köppen climate classification "Cfb").

The Roman stronghold or "castrum Mogontiacum", the precursor to Mainz, was founded by the Roman general Drusus perhaps as early as 13/12 BC. As related by Suetonius the existence of "Mogontiacum" is well established by four years later (the account of the death and funeral of Nero Claudius Drusus), though several other theories suggest the site may have been established earlier. Although the city is situated opposite the mouth of the Main, the name of Mainz is not from Main, the similarity being perhaps due to diachronic analogy. Main is from Latin "Menus", the name the Romans used for the river. Linguistic analysis of the many forms that the name "Mainz" has taken on make it clear that it is a simplification of "Mogontiacum". The name appears to be Celtic and ultimately it is. However, it had also become Roman and was selected by them with a special significance. The Roman soldiers defending Gallia had adopted the Gallic god Mogons (Mogounus, Moguns, Mogonino), for the meaning of which etymology offers two basic options: "the great one", similar to Latin magnus, which was used in aggrandizing names such as "Alexander magnus", "Alexander the Great" and "Pompeius magnus", "Pompey the great", or the god of "might" personified as it appears in young servitors of any type whether of noble or ignoble birth.

Mogontiacum was an important military town throughout Roman times, probably due to its strategic position at the confluence of the Main and the Rhine. The town of "Mogontiacum" grew up between the fort and the river. The castrum was the base of Legio XIV "Gemina" and XVI "Gallica" (AD 9–43), XXII "Primigenia", IV "Macedonica" (43–70), I "Adiutrix" (70–88), XXI "Rapax" (70–89), and XIV "Gemina" (70–92), among others. Mainz was also a base of a Roman river fleet, the Classis Germanica. Remains of Roman troop ships (navis lusoria) and a patrol boat from the late 4th century were discovered in 1982/86 and may now be viewed in the "Museum für Antike Schifffahrt". A temple dedicated to Isis Panthea and Magna Mater was discovered in 2000 and is open to the public. The city was the provincial capital of Germania Superior, and had an important funeral monument dedicated to Drusus, to which people made pilgrimages for an annual festival from as far away as Lyon. Among the famous buildings were the largest theatre north of the Alps and a bridge across the Rhine. The city was also the site of the assassination of emperor Severus Alexander in 235.

Alemanni forces under Rando sacked the city in 368. From the last day of 405 or 406, the Siling and Asding Vandals, the Suebi, the Alans, and other Germanic tribes crossed the Rhine, possibly at Mainz. Christian chronicles relate that the bishop, Aureus, was put to death by the Alemannian Crocus. The way was open to the sack of Trier and the invasion of Gaul.

Throughout the changes of time, the Roman castrum never seems to have been permanently abandoned as a military installation, which is a testimony to Roman military judgement. Different structures were built there at different times. The current citadel originated in 1660, but it replaced previous forts. It was used in World War II. One of the sights at the citadel is still the cenotaph raised by legionaries to commemorate their Drusus.

Through a series of incursions during the 4th century Alsace gradually lost its Belgic ethnic character of formerly Germanic tribes among Celts ruled by Romans and became predominantly influenced by the Alamanni. The Romans repeatedly reasserted control; however, the troops stationed at Mainz became chiefly non-Italic and the emperors had only one or two Italian ancestors in a pedigree that included chiefly peoples of the northern frontier.

The last emperor to station troops serving the western empire at Mainz was Valentinian III (reigned 425–455), who relied heavily on his "Magister militum per Gallias", Flavius Aëtius. By that time the army included large numbers of troops from the major Germanic confederacies along the Rhine, the Alamanni, the Saxons and the Franks. The Franks were an opponent that had risen to power and reputation among the Belgae of the lower Rhine during the 3rd century and repeatedly attempted to extend their influence upstream. In 358 the emperor Julian bought peace by giving them most of Germania Inferior, which they possessed anyway, and imposing service in the Roman army in exchange.

European factions in the time of master Aëtius included Celts, Goths, Franks, Saxons, Alamanni, Huns, Italians, and Alans as well as numerous other minor peoples. Aëtius played them all off against one another in a masterly effort to keep the peace under Roman sovereignty. He used Hunnic troops a number of times. At last a day of reckoning arrived between Aëtius and Attila, both commanding polyglot, multi-ethnic troops. Attila went through Alsace in 451, devastating the country and destroying Mainz and Triers with their Roman garrisons. Shortly after he was thwarted by Flavius Aëtius at the Battle of Châlons, the largest of the ancient world.

Aëtius was not to enjoy the victory long. He was assassinated in 454 by the hand of his employer, who in turn was stabbed to death by friends of Aëtius in 455. As far as the north was concerned this was the effective end of the Roman empire there. After some sanguinary but relatively brief contention a former subordinate of Aëtius, Ricimer, became commander in chief, and was named Patrician. His father was a Suebian; his mother, a princess of the Visigoths. Ricimer did not rule the north directly but set up a client province there, which functioned independently. The capital was at Soissons. Even then its status was equivocal. Many insisted it was the Kingdom of Soissons. which extended across northern France and was ruled in the name of Rome by Aegidius, an ally of emperor Majorian, 457–461, who died about 464. He was succeeded by his son, Syagrius, who was defeated by Clovis in 486.

Previously the first of the Merovingians, Clodio, had been defeated by Aëtius at about 430. His son, Merovaeus, fought on the Roman side against Attila, and his son, Childeric, served in the domain of Soissons. Meanwhile, the Franks were gradually infiltrating and assuming power in this domain from Txxandria (northern Belgium which had been given to them by the Romans to protect as allies). They also moved up the Rhine and created a domain in the region of the former Germania Superior with capital at Cologne. They became known as the Ripuarian Franks as opposed to the Salian Franks. Events moved rapidly in the late 5th century.

After the fall of the Western Roman Empire in 476, the Franks under the rule of Clovis I gained control over western Europe by the year 496. Clovis, son of Childeric, became king of the Salians in 481, ruling from Tournai. In 486 he defeated Syagrius, last governor of the Soissons domain, and took northern France. He extended his reign to Cambrai and Tongeren in 490–491, and repelled the Alamanni in 496. Also in that year he converted to Catholic from non-Arian Christianity. Clovis annexed the kingdom of Cologne in 508. Thereafter, Mainz, in its strategic position, became one of the bases of the Frankish kingdom. Mainz had sheltered a Christian community long before the conversion of Clovis. His successor Dagobert I reinforced the walls of Mainz and made it one of his seats. A solidus of Theodebert I (534–548) was minted at Mainz.

Charlemagne (768–814), through a succession of wars against other tribes, built a vast Frankian empire in Europe. Mainz from its central location became important to the empire and to Christianity. Meanwhile, language change was gradually working to divide the Franks. Mainz spoke a dialect termed Ripuarian. On the death of Charlemagne, distinctions between France and Germany began to be made. Mainz was not central any longer but was on the border, creating a question of the nationality to which it belonged, which descended into modern times as the question of Alsace-Lorraine.

In the early Middle Ages, Mainz was a centre for the Christianisation of the German and Slavic peoples. The first archbishop in Mainz, Boniface, was killed in 754 while trying to convert the Frisians to Christianity and is buried in Fulda. Boniface held a personal title of archbishop; Mainz became a regular archbishopric see in 781, when Boniface's successor Lullus was granted the pallium by Pope Adrian I. Harald Klak, king of Jutland, his family and followers, were baptized at Mainz in 826, in the abbey of St. Alban's. Other early archbishops of Mainz include Rabanus Maurus, the scholar and author, and Willigis (975–1011), who began construction on the current building of the Mainz Cathedral and founded the monastery of St. Stephan.

From the time of Willigis until the end of the Holy Roman Empire in 1806, the Archbishops of Mainz were archchancellors of the Empire and the most important of the seven Electors of the German emperor. Besides Rome, the diocese of Mainz today is the only diocese in the world with an episcopal see that is called a Holy See ("sancta sedes"). The Archbishops of Mainz traditionally were "primas germaniae", the substitutes of the Pope north of the Alps.

In 1244, Archbishop Siegfried III granted Mainz a city charter, which included the right of the citizens to establish and elect a city council. The city saw a feud between two archbishops in 1461, namely Diether von Isenburg, who was elected Archbishop by the cathedral chapter and supported by the citizens, and Adolf II von Nassau, who had been named archbishop for Mainz by the pope. In 1462, the Archbishop Adolf raided the city of Mainz, plundering and killing 400 inhabitants. At a tribunal, those who had survived lost all their property, which was then divided between those who promised to follow Adolf. Those who would not promise to follow Adolf (amongst them Johannes Gutenberg) were driven out of the town or thrown into prison. The new archbishop revoked the city charter of Mainz and put the city under his direct rule. Ironically, after the death of Adolf II his successor was again Diether von Isenburg, now legally elected by the chapter and named by the Pope.

The Jewish community of Mainz dates to the 10th century CE. It is noted for its religious education. Rabbi Gershom ben Judah (960–1040) taught there, among others. He concentrated on the study of the Talmud, creating a German Jewish tradition. Mainz is also the legendary home of the martyred Rabbi Amnon of Mainz, composer of the Unetanneh Tokef prayer. The Jews of Mainz, Speyer and Worms created a supreme council to set standards in Jewish law and education in the 12th century.

The city of Mainz responded to the Jewish population in a variety of ways, behaving, in a sense, in a bipolar fashion towards them. Sometimes they were allowed freedom and were protected; at other times, they were persecuted. The Jews were expelled in 1012, 1462 (after which they were invited to return), and in 1474. Jews were attacked in 1096 and by mobs in 1283. Outbreaks of the Black Death were usually blamed on the Jews, at which times they were massacred, such as the burning of about 6,000 Jews alive in 1349.

Nowadays the Jewish community is growing rapidly, and a new synagogue by the architect Manuel Herz was constructed in 2010 on the site of the one destroyed by the Nazis on "Kristallnacht" in 1938. The community itself has 1,034 members, according to the Central Council of Jews in Germany, and at least twice as many Jews altogether since many are unaffiliated with Judaism.

During the French Revolution, the French Revolutionary army occupied Mainz in 1792; the Archbishop of Mainz, Friedrich Karl Josef von Erthal, had already fled to Aschaffenburg by the time the French marched in. On 18 March 1793, the Jacobins of Mainz, with other German democrats from about 130 towns in the Rhenish Palatinate, proclaimed the 'Republic of Mainz'. Led by Georg Forster, representatives of the Mainz Republic in Paris requested political affiliation of the Mainz Republic with France, but too late: Prussia was not entirely happy with the idea of a democratic free state on German soil (although the French dominated Mainz was neither free nor democratic). Prussian troops had already occupied the area and besieged Mainz by the end of March 1793. After a siege of 18 weeks, the French troops in Mainz surrendered on 23 July 1793; Prussians occupied the city and ended the Republic of Mainz. It came to the Battle of Mainz in 1795 between Austria and France. Members of the Mainz Jacobin Club were mistreated or imprisoned and punished for treason.

In 1797, the French returned. The army of Napoléon Bonaparte occupied the German territory to the west of the Rhine, and the Treaty of Campo Formio awarded France this entire area. On 17 February 1800, the French "Département du Mont-Tonnerre" was founded here, with Mainz as its capital, the Rhine being the new eastern frontier of la Grande Nation. Austria and Prussia could not but approve this new border with France in 1801. However, after several defeats in Europe during the next years, the weakened Napoléon and his troops had to leave Mainz in May 1814.

In 1816, the part of the former French Département which is known today as Rhenish Hesse () was awarded to the Hesse-Darmstadt, Mainz being the capital of the new Hessian province of Rhenish Hesse. From 1816 to 1866, to the German Confederation Mainz was the most important fortress in the defence against France, and had a strong garrison of Austrian, Prussian and Bavarian troops.

In the afternoon of 18 November 1857, a huge explosion rocked Mainz when the city's powder magazine, the "Pulverturm", exploded. Approximately 150 people were killed and at least 500 injured; 57 buildings were destroyed and a similar number severely damaged in what was to be known as the "Powder Tower Explosion" or "Powder Explosion".

During the Austro-Prussian War in 1866, Mainz was declared a neutral zone. After the founding of the German Empire in 1871, Mainz no longer was as important a stronghold, because in the war of 1870/71 France had lost the territory of Alsace-Lorraine to Germany (which France had occupied piece by piece 1630/1795), and this defined the new border between the two countries.

For centuries the inhabitants of the fortress of Mainz had suffered from a severe shortage of space which led to disease and other inconveniences. In 1872 Mayor Carl Wallau and the council of Mainz persuaded the military government to sign a contract to expand the city. Beginning in 1874, the city of Mainz assimilated the "Gartenfeld", an idyllic area of meadows and fields along the banks of the Rhine to the north of the rampart. The city expansion more than doubled the urban area which allowed Mainz to participate in the industrial revolution which had previously avoided the city for decades.

Eduard Kreyßig was the man who made this happen. Having been the master builder of the city of Mainz since 1865, Kreyßig had the vision for the new part of town, the "Neustadt". He also planned the first sewer system for the old part of town since Roman times and persuaded the city government to relocate the railway line from the Rhine side to the west end of the town. The main station was built from 1882 to 1884 according to the plans of Philipp Johann Berdellé.
The Mainz master builder constructed a number of state-of-the-art public buildings, including the Mainz town hall — which was the largest of its kind in Germany at that time — as well a synagogue, the Rhine harbour and a number of public baths and school buildings. Kreyßig's last work was Christ Church ("Christuskirche"), the largest Protestant church in the city and the first building constructed solely for the use of a Protestant congregation. In 1905 the demolition of the entire circumvallation and the Rheingauwall was taken in hand, according to imperial order of Wilhelm II.

During the German Revolution of 1918 the Mainz Workers' and Soldiers' Council was formed which ran the city from 9 November until the arrival of French troops under the terms of the occupation of the Rhineland agreed in the Armistice. The French occupation was confirmed by the Treaty of Versailles which went into effect 28 June 1919. The Rhineland (in which Mainz is located) was to be a demilitarized zone until 1935 and the French garrison, representing the "Triple Entente", was to stay until reparations were paid.

In 1923 Mainz participated in the Rhineland separatist movement that proclaimed a republic in the Rhineland. It collapsed in 1924. The French withdrew on 30 June 1930. Adolf Hitler became chancellor of Germany in January 1933 and his political opponents, especially those of the Social Democratic Party, were either incarcerated or murdered. Some were able to move away from Mainz in time. One was the political organizer for the SPD, Friedrich Kellner, who went to Laubach, where as the chief justice inspector of the district court he continued his opposition against the Nazis by recording their misdeeds in a 900-page diary.

In March 1933, a detachment from the National Socialist Party in Worms brought the party to Mainz. They hoisted the swastika on all public buildings and began to denounce the Jewish population in the newspapers. In 1936, the Nazis remilitarized the Rhineland with great fanfare, the first move of Nazi Germany's meteoric expansion. The former Triple Entente took no action.

During World War II the citadel at Mainz hosted the Oflag XII-B prisoner of war camp.

The Bishop of Mainz, Albert Stohr, formed an organization to help Jews escape from Germany.

During World War II, more than 30 air raids destroyed about 80 percent of the city's center, including most of the historic buildings. Mainz was captured on 22 March 1945 against uneven German resistance (staunch in some sectors and weak in other parts of the city) by the 90th Infantry Division under William A. McNulty, a formation of the XII Corps under Third Army commanded by General George S. Patton, Jr. Patton used the ancient strategic gateway through "Germania Superior" to cross the Rhine south of Mainz, drive down the Danube towards Czechoslovakia and end the possibility of a Bavarian redoubt crossing the Alps in Austria when the war ended.

From 1945 to 1949, the city was part of the French zone of occupation. When the federal state of Rhineland-Palatinate was founded on 30 August 1946 by the commander of the French army on the French occupation zone Marie Pierre Kœnig, Mainz became capital of the new state. In 1962, the diarist, Friedrich Kellner, returned to spend his last years in Mainz. His life in Mainz, and the impact of his writings, is the subject of the Canadian documentary "".

Following the withdrawal of French forces from Mainz, the United States Army Europe occupied the military bases in Mainz. Today USAREUR only occupies McCulley Barracks in Wackernheim and the Mainz Sand Dunes for training area. Mainz is home to the headquarters of the "Bundeswehr"'s "Landeskommando" Rhineland-Palatinate and other units.

The following list shows the largest minority groups in Mainz :

The destruction caused by the bombing of Mainz during World War II led to the most intense phase of building in the history of the town. During the last war in Germany, more than 30 air raids destroyed about 80 percent of the city's center, including most of the historic buildings. The destructive attack on the afternoon of 27 February 1945 remains the most destructive of all 33 bombings that Mainz has suffered in World War II in the collective memory of most of the population living then. The air raid caused most of the dead and made an already hard-hit city largely leveled.

Nevertheless, the post-war reconstruction took place very slowly. While cities such as Frankfurt had been rebuilt fast by a central authority, only individual efforts were initially successful in rebuilding Mainz. The reason for this was that the French wanted Mainz to expand and to become a model city. Mainz lay within the French-controlled sector of Germany and it was a French architect and town-planner, Marcel Lods, who produced a Le Corbusier-style plan of an ideal architecture. But the very first interest of the inhabitants was the restoration of housing areas. Even after the failure of the model city plans it was the initiative of the French (founding of the Johannes Gutenberg University of Mainz, elevation of Mainz to the state capital of Rhineland-Palatinate, the early resumption of the Mainz carnival) driving the city in a positive development after the war. The City Plan of 1958 by Ernst May allowed a regulated reconstruction for the first time. In 1950, the seat of the government of Rhineland-Palatinate had been transferred to the new Mainz and in 1963 the seat of the new ZDF, notable architects were Adolf Bayer, Richard Jörg and Egon Hartmann. At the time of the two-thousand-years-anniversary in 1962 the city was largely reconstructed. During the 1950s and 1960s the Oberstadt had been extended, Münchfeld and Lerchenberg added as suburbs, the Altstadttangente (intersection of the old town), new neighbourhoods as Westring and Südring contributed to the extension. By 1970 there remained only a few ruins. The new town hall of Mainz had been designed by Arne Jacobsen and finished by Dissing+Weitling. The town used Jacobsens activity for the Danish Novo erecting a new office and warehouse building to contact him. The urban renewal of the old town changed the inner city. In the framework of the preparation of the cathedrals millennium, pedestrian zones were developed around the cathedral, in northern direction to the Neubrunnenplatz and in southern direction across the Leichhof to the Augustinerstraße and Kirschgarten. The 1980s brought the renewal of the façades on the Markt and a new inner-city neighbourhood on the Kästrich. During the 1990s the Kisselberg between Gonsenheim and Bretzenheim, the "Fort Malakoff Center" at the site of the old police barracks, the renewal of the Main Station and the demolition of the first post-war shopping center at the Markt followed by the erection of a new historicising building at the same place.


The city of Mainz is divided into 15 local districts according to the main statute of the city of Mainz. Each local district has a district administration of 13 members and a directly elected mayor, who is the chairman of the district administration. This local council decides on important issues affecting the local area, however, the final decision on new policies is made by the Mainz's municipal council.

In accordance with section 29 paragraph 2 Local Government Act of Rhineland-Palatinate, which refers to municipalities of more than 150,000 inhabitants, the city council has 60 members.

Districts of the town are:
Until 1945, the districts of Bischofsheim (now an independent town), Ginsheim-Gustavsburg (which together are an independent town) belonged to Mainz. The former districts Amöneburg, Kastel, and Kostheim — (in short, "AKK") are now administrated by the city of Wiesbaden (on the north bank of the river). The AKK was separated from Mainz when the Rhine was designated the boundary between the French occupation zone (the later state of Rhineland-Palatinate) and the U.S. occupation zone (Hesse) in 1945.

The coat of arms of Mainz is derived from the coat of arms of the Archbishops of Mainz and features two six-spoked silver wheels connected by a silver cross on a red background.

Mainz is home to a Carnival, the "Mainzer Fassenacht" or "Fastnacht", which has developed since the early 19th century. Carnival in Mainz has its roots in the criticism of social and political injustices under the shelter of cap and bells. Today, the uniforms of many traditional Carnival clubs still imitate and caricature the uniforms of the French and Prussian troops of the past. The height of the carnival season is on Rosenmontag ("rose Monday"), when there is a large parade in Mainz, with more than 500,000 people celebrating in the streets.

The first ever Katholikentag, a festival-like gathering of German Catholics, was held in Mainz in 1848.
Johannes Gutenberg, credited with the invention of the modern printing press with movable type, was born here and died here. Since 1968 the Mainzer Johannisnacht commemorates the person Johannes Gutenberg in his native city. The Mainz University, which was refounded in 1946, is named after Gutenberg; the earlier University of Mainz that dated back to 1477 had been closed down by Napoleon's troops in 1798.

Mainz was one of three important centers of Jewish theology and learning in Central Europe during the Middle Ages. Known collectively as "Shum", the cities of Speyer, Worms and Mainz played a key role in the preservation and propagation of Talmudic scholarship.

The city is the seat of Zweites Deutsches Fernsehen (literally, "Second German Television", ZDF), one of two federal nationwide TV broadcasters. There are also a couple of radio stations based in Mainz.

Other cultural aspects of the city include:


The local football club 1. FSV Mainz 05 has a long history in the German football leagues. Since 2004 it has competed in the Bundesliga (First German soccer league) except a break in second level in 2007–08 season. Mainz is closely associated with renowned coach Jürgen Klopp, who spent the vast majority of his playing career at the club and was also the manager for seven years, leading the club to Bundesliga football for the first time. After leaving Mainz Klopp went on to win two Bundesliga titles and reaching a Champions League final with Borussia Dortmund. In the summer 2011 the club opened its new stadium called Coface Arena. Further relevant football clubs are TSV Schott Mainz, SV Gonsenheim, Fontana Finthen, FC Fortuna Mombach and FVgg Mombach 03.

The local wrestling club ASV Mainz 1888 is currently in the top division of team wrestling in Germany, the Bundesliga. In 1973, 1977 and 2012 the ASV Mainz 1888 won the German championship.

In 2007 the Mainz Athletics won the German Men's Championship in baseball.

As a result of the 2008 invasion of Georgia by Russian troops, Mainz acted as a neutral venue for the Georgian Vs Republic of Ireland football game.

The biggest basketball club in the city is the ASC Theresianum Mainz. Its men's team is playing in the Regionalliga and its women's team is playing in the 2.DBBL.

Universitäts-Sportclub Mainz (University Sports Club Mainz) is a German sports club based in Mainz. It was founded on 9 September 1959 by Berno Wischmann primarily for students of the University of Mainz. It is considered one of the most powerful Athletics Sports clubs in Germany. 50 athletes of USC have distinguished themselves in a half-century in club history at Olympic Games, World and European Championships. In particular in the decathlon dominated USC athletes for decades: Already at the European Championships in Budapest in 1966 Mainz won three (Werner von Moltke, Jörg Mattheis and Horst Beyer) all decathlon medals. In the all-time list of the USC, there are nine athletes who have achieved more than 8,000 points – at the head of Siegfried Wentz (8762 points in 1983) and Guido Kratschmer (1980 world record with 8667 points). Most successful athlete of the association is more fighter, sprinter and long jumper Ingrid Becker (Olympic champion in 1968 in the pentathlon and Olympic champion in 1972 in the 4 × 100 Metres Relay and European champion in 1971 in the long jump). Most famous athletes of the present are the sprinter Marion Wagner (world champion in 2001 in the 4 × 100 Metres Relay) and the pole vaulters Carolin Hingst (Eighth of the 2008 Olympics in Beijing) and Anna Battke.

Three world titles adorn the balance of USC Mainz. For the discus thrower Lars Riedel attended (1991 and 1993) and the already mentioned sprinter Marion Wagner (2001). Added to 5 titles at the European Championships, a total of 65 international medals and 260 victories at the German Athletics Championships.

The players of USC's basketball section played from the season 1968/69 to the season 1974/75 in the National Basketball League (BBL) of the German Basketball Federation (DBB). As a finalist to winning the DBB Cup in 1971 USC Mainz played in the 1971–72 FIBA European Cup Winners' Cup against the Italian Cup winners of Fides Napoli.

The Baseball and Softball Club Mainz Athletics is a German baseball and softball club located in the city of Mainz in Rhineland-Palatinate. The Athletics is one of the largest clubs in the Baseball-Bundesliga Süd in terms of membership, claiming to have hundreds of active players. The club has played in the Baseball-Bundesliga for more than two decades, and has won the German Championship in 2007 and 2016.

Mainz is one of the centers of the German wine economy as a center for wine trade and the seat of the state's wine minister. Due to the importance and history of the wine industry for the federal state, Rhineland-Palatinate is the only state to have such a department.

Since 2008, the city is also member of the Great Wine Capitals Global Network (GWC), an association of well-known wineculture-cities of the world.
Many wine traders also work in the town. The sparkling wine producer Kupferberg produced in Mainz-Hechtsheim and even Henkell — now located on the other side of the river Rhine — had been founded once in Mainz. The famous Blue Nun, one of the first branded wines, had been marketed by the family Sichel.

Mainz had been a wine growing region since Roman times and the image of the wine town Mainz is fostered by the tourist center. The "Haus des Deutschen Weines" (English: House of German Wine), is located in beside the theater. The Mainzer Weinmarkt (wine market) is one of the great wine fairs in Germany.

The Schott AG, one of the world's largest glass manufactures, as well as the Werner & Mertz, a large chemical factory, are based in Mainz. Other companies such as IBM, QUINN Plastics, or Novo Nordisk have their German administration in Mainz as well.

Johann-Joseph Krug, founder of France's famous Krug champagne house in 1843, was born in Mainz in 1800.

Mainz is a major transport hub in southern Germany. It is an important component in European distribution, as it has the fifth largest inter-modal port in Germany. The Port of Mainz, now handling mainly containers, is a sizable industrial area to the north of the city, along the banks of the Rhine. In order to open up space along the city's riverfront for residential development, it was shifted further northwards in 2010.

Mainz Central Station or "Mainz Hauptbahnhof", is frequented by 80,000 travelers and visitors each day and is therefore one of the busiest 21 stations in Germany. It is a stop for the S-Bahn line S8 of the Rhein-Main-Verkehrsverbund. Additionally, the Mainbahn line to Frankfurt Hbf starts at the station. It is served by 440 daily local and regional trains (StadtExpress, RE and RB) and 78 long-distance trains (IC, EC and ICE). Intercity-Express lines connect Mainz with Frankfurt (Main), Karlsruhe Hbf, Worms Hauptbahnhof and Koblenz Hauptbahnhof. It is a terminus of the West Rhine Railway and the Mainz–Ludwigshafen railway, as well as the Alzey–Mainz Railway erected by the Hessische Ludwigsbahn in 1871. Access to the East Rhine Railway is provided by the Kaiserbrücke, a railway bridge across the Rhine at the north end of Mainz.

The station is an interchange point for the Mainz tramway network, and an important bus junction for the city and region (RNN, ORN and MVG).

Mainz offers a wide array of bicycle transportation facilities and events, including several miles of on-street bike lanes. The Rheinradweg (Rhine Cycle Route) is an international cycle route, running from the source to the mouth of the Rhine, traversing four countries at a distance of . Another cycling tour runs towards Bingen and further to the Middle Rhine, a UNESCO World Heritage Site (2002).

Mainz is served by Frankfurt Airport, the busiest airport by passenger traffic in Germany by far, the third busiest in Europe and the ninth busiest worldwide in 2009. Located about east of Mainz, it is connected to the city by an S-Bahn line.

The small Mainz Finthen Airport, located just southwest of Mainz, is used by general aviation only. Another airport, Frankfurt-Hahn Airport located about west of Mainz, is served by a few low-cost carriers.


Mainz is twinned with:

Mainz has a number of different names in other languages and dialects. In Latin it is known as ' or ' and, in the local West Middle German dialect, it is "Määnz" or "Meenz". It is known as ' in French, ' in Italian, ' in Spanish, ' in Portuguese, ' in Polish, "Magentza" () in Yiddish, and ' in Czech and Slovakian.

Before the 20th century, Mainz was commonly known in English as "Mentz" or by its French name of "Mayence". It is the namesake of two American cities named Mentz.





</doc>
<doc id="20540" url="https://en.wikipedia.org/wiki?curid=20540" title="Maria Feodorovna (Dagmar of Denmark)">
Maria Feodorovna (Dagmar of Denmark)

Maria Feodorovna (26 November 1847 – 13 October 1928), known before her marriage as Princess Dagmar of Denmark, was a Danish princess and Empress of Russia as spouse of Emperor Alexander III (reigned 1881–1894). She was the second daughter and fourth child of King Christian IX of Denmark and Louise of Hesse-Kassel; her siblings included Queen Alexandra of the United Kingdom, King Frederick VIII of Denmark and King George I of Greece. Her eldest son became the last Russian monarch, Emperor Nicholas II of Russia. She lived for ten years after he and his family were killed.

Princess Marie Sophie Frederikke Dagmar was born at the Yellow Palace in Copenhagen. Her father was Prince Christian of Schleswig-Holstein-Sonderburg-Glücksburg, a member of a relatively impoverished princely cadet line. Her mother was Princess Louise of Hesse-Kassel.

She was baptised as a Lutheran and named after her kinswoman Marie Sophie of Hesse-Kassel, Queen Dowager of Denmark as well as the medieval Danish queen, Dagmar of Bohemia. Her godmother was Queen Caroline Amalie of Denmark. Growing up, she was known by the name Dagmar. Most of her life, she was known as Maria Feodorovna, the name which she took when she converted to Orthodoxy immediately before her 1866 marriage to the future Emperor Alexander III. She was known within her family as "Minnie".

In 1852 Dagmar's father became heir-presumptive to the throne of Denmark, largely due to the succession rights of his wife Louise as niece of King Christian VIII. In 1853, he was given the title Prince of Denmark and he and his family were given an official summer residence, Bernstorff Palace. Dagmar's father became King of Denmark in 1863 upon the death of King Frederick VII.

Due to the brilliant marital alliances of his children, he became known as the "Father-in-law of Europe." Dagmar's eldest brother would succeed his father as King Frederick VIII of Denmark (one of whose sons would be elected as King of Norway). Her elder, and favourite, sister, Alexandra married Albert Edward, the Prince of Wales (the future King Edward VII) in March 1863. Alexandra, along with being queen consort of King Edward VII, was also mother of George V of the United Kingdom, which helps to explain the striking resemblance between their sons Nicholas II and George V. Within months of Alexandra's marriage, Dagmar's second older brother, Wilhelm, was elected as King George I of the Hellenes. Her younger sister was Thyra, Duchess of Cumberland. She also had another younger brother, Valdemar.

During her upbringing, Dagmar, together with her sister Alexandra, was given swimming lessons by the Swedish pioneer of swimming for women, Nancy Edberg; she would later welcome Edberg to Russia, where she came on royal scholarship to hold swimming lessons for women.

The rise of Slavophile ideology in the Russian Empire led Alexander II of Russia to search for a bride for the heir apparent, Tsarevich Nicholas Alexandrovich, in countries other than the German states that had traditionally provided consorts for the tsars. In 1864, Nicholas, or "Nixa" as he was known in his family, went to Denmark where he was betrothed to Dagmar. On 22 April 1865 he died from meningitis. His last wish was that Dagmar would marry his younger brother, the future Alexander III. Dagmar was distraught after her young fiancé's death. She was so heartbroken when she returned to her homeland that her relatives were seriously worried about her health. She had already become emotionally attached to Russia and often thought of the huge, remote country that was to have been her home. The disaster had brought her very close to "Nixa's" parents, and she received a letter from Alexander II in which the Emperor attempted to console her. He told Dagmar in very affectionate terms that he hoped she would still consider herself a member of their family. In June 1866, while on a visit to Copenhagen, the Tsarevich Alexander asked Dagmar for her hand. They had been in her room looking over photographs together.

Dagmar left Copenhagen on 1 September 1866. Hans Christian Andersen, who had occasionally been invited to tell stories to Dagmar and her siblings when they were children, was among the crowd which flocked to the quay in order to see her off. The writer remarked in his diary, "Yesterday, at the quay, while passing me by, she stopped and took me by the hand. My eyes were full of tears. What a poor child! Oh Lord, be kind and merciful to her! They say that there is a brilliant court in Saint Petersburg and the tsar's family is nice; still, she heads for an unfamiliar country, where people are different and religion is different and where she will have none of her former acquaintances by her side."

Dagmar was warmly welcomed in Kronstadt by Grand Duke Constantine Nikolaevich of Russia and escorted to St. Petersburg, where she was greeted by her future mother-in-law and sister-in-law on 24 September. On the 29th, she made her formal entry in to the Russian capital dressed in a Russian national costume in blue and gold and traveled with the Empress to the Winter Palace where she was introduced to the Russian public on a balcony. Catherine Radziwill described the occasion: ”rarely has a foreign princess been greeted with such enthusiasm… from the moment she set foot on Russian soil, succeeded in winning to herself all hearts. Her smile, the delightful way she had of bowing to the crowds…, laid immediately the foundation of …popularity” 

She converted to Orthodoxy and became Grand Duchess Maria Feodorovna of Russia. The lavish wedding took place on in the Imperial Chapel of the Winter Palace in Saint Petersburg. Financial constraints had prevented her parents from attending the wedding, and in their stead, they sent her brother, Crown Prince Frederick. Her brother-in-law, the Prince of Wales, had also travelled to Saint Petersburg for the ceremony; pregnancy had prevented the Princess of Wales from attending. After the wedding night, Alexander wrote in his diary, "I took off my slippers and my silver embroidered robe and felt the body of my beloved next to mine... How I felt then, I do not wish to describe here. Afterwards we talked for a long time." After the many wedding parties were over the newlyweds moved into the Anichkov Palace in Saint Petersburg where they were to live for the next 15 years, when they were not taking extended holidays at their summer villa Livadia in the Crimean Peninsula.

Maria Feodorovna was beautiful and well received by her Russian peers. Early on she made it a priority to learn the Russian language and to try to understand the Russian people. She rarely interfered with politics, preferring to devote her time and energies to her family, charities, and the more social side of her position. She had also seen the student protests of Kiev and St. Petersburg in the 1860's, and when police were beating students, the students cheered on Maria Feodorovna, to which she replied "They were quite loyal, they cheered me. Why do you allow the police to treat them so brutally?" Her one exception to official politics was her militant anti-German sentiment due to the annexation of Danish territories by Prussia in 1864, a sentiment also expressed by her sister, Alexandra. Prince Gorchakov remarked about this policy: “it is our belief, that Germany will not forget that both in Russia and in England [sic] a Danish Princess has her foot on the steps of the throne.” Maria Feodorovna suffered a miscarriage in 1866 in Denmark while horseback riding.
On 18 May 1868, Maria Feodorovna gave birth to her eldest son, Nicholas. Her next son, Alexander Alexandrovich, born in 1869, died from meningitis in infancy. She would bear Alexander four more children who reached adulthood: George (b. 1871), Xenia (b. 1875), Michael (b. 1878), and Olga (b. 1882). As a mother, she doted on and was quite possessive of her sons. She had a more distant relationship with her daughters.

In 1873, Maria, Alexander, and their two eldest sons made a journey to the United Kingdom. The imperial couple and their children were entertained at Marlborough House by the Prince and Princess of Wales. The royal sisters Maria and Alexandra delighted London society by dressing alike at social gatherings. The following year, Maria and Alexander welcomed the Prince and Princess of Wales to St. Petersburg; they had come for the wedding of the Prince's younger brother, Alfred, to Grand Duchess Maria Alexandrovna, daughter of Tsar Alexander II and the sister of the tsarevich.

On the morning of 13 March 1881, her father-in-law Alexander II of Russia, aged 62, was killed by a bomb on the way back to the Winter Palace from a military parade. In her diary, Maria later described how the wounded, still living Emperor was taken to the palace: "His legs were crushed terribly and ripped open to the knee; a bleeding mass, with half a boot on the right foot, and only the sole of the foot remaining on the left." Alexander II died a few hours later. Although the people were not enamoured of the new emperor, they adored Russia's new empress. As Maria's contemporaries said of her: "She is truly an empress." She was not altogether pleased with her new status. In her diary she wrote, "Our happiest and serenest times are now over. My peace and calm are gone, for now I will only ever be able to worry about Sasha." Despite being haunted by her father-in-law's gruesome death and her anxiety over the safety of her husband, at Alexander II's funeral, she was at least afforded the comfort of the presence of her brother-in-law and favourite sister, the Prince and Princess of Wales, the latter of whom, despite her husband's reluctance and Queen Victoria's objections, stayed on in Russia with Maria for several weeks after the funeral.

Alexander and Maria were crowned at the Assumption Cathedral in the Kremlin in Moscow on 27 May 1883. Just before the coronation, a major conspiracy had been uncovered, which cast a pall over the celebration. Nevertheless, over 8000 guests attended the splendid ceremony. Because of the many threats against Maria and Alexander III, the head of the security police, General Cherevin, shortly after the coronation urged the Tsar and his family to relocate to Gatchina Palace, a more secure location 50 kilometres outside St. Petersburg. The huge palace had 900 rooms and was built by Catherine the Great. The Romanovs heeded the advice. Maria and Alexander III lived at Gatchina for 13 years, and it was here that their five surviving children grew up. Under heavy guard, Alexander III and Maria made periodic trips from Gatchina to the capital to take part in official events.

Maria is described as a success in her social role as Empress, loved to dance at the balls of high society and became a popular socialite and hostess of the Imperial balls; her daughter Olga commented, “Court life had to run in splendor, and there my mother played her part without a single false step.”, and a contemporary remarked on her success: “of the long gallery of Tsarinas who have sat in state in the Kremlin or paced in the Winter Palace, Marie Feodorovna was perhaps the most brilliant”. She longed for the balls and gatherings in the Winter Palace. These also occurred at Gatchina. Alexander used to enjoy joining in with the musicians, although he would end up sending them off one by one. When that happened, Maria knew the party was over.
As tsarevna, and then as tsarina, Maria Feodorovna had something of a social rivalry with the popular Grand Duchess Marie Pavlovna, wife of her Russian brother-in-law, Grand Duke Vladimir. This rivalry had echoed the one shared by their husbands, and served to exacerbate the rift within the family. While Maria Feodorovna knew better than to publicly criticise both the Grand Duke and Duchess in public, Marie Pavlovna had earned the caustic epithet of "Empress Vladimir" from the tsarina.

Nearly each summer, Maria, Alexander and their children would make an annual trip to Denmark, where her parents, King Christian IX and Queen Louise, hosted family reunions. Maria's brother, King George I, and his wife, Queen Olga, would come up from Athens with their children, and the Princess of Wales, often without her husband, would come with some of her children from the United Kingdom. In contrast to the tight security observed in Russia, the tsar, tsarina and their children relished the relative freedom that they could enjoy at Bernstorff and Fredensborg. The annual family meetings of monarchs in Denmark was regarded as suspicious in Europe, where many assumed they secretly discussed state affairs. Bismarck nicknamed Fredensborg “Europe’s Whispering Gallery” and accused Queen Louise of plotting against him with her children. Maria also had a good relationship with the majority of her in-laws, and was often asked to act as a mediator between them and the tsar. In the words of her daughter Olga: “She proved herself extremely tactful with her in-laws, which was no easy task”.
During Alexander III's reign, the monarchy's opponents quickly disappeared underground. A group of students had been planning to assassinate Alexander III on the sixth anniversary of his father's death at the Peter and Paul Cathedral in St. Petersburg. The plotters had stuffed hollowed-out books with dynamite, which they intended to throw at the Tsar when he arrived at the cathedral. However, the Russian secret police uncovered the plot before it could be carried out. Five students were hanged in 1887; amongst them was Aleksandr Ulyanov, older brother of Vladimir Lenin.

The biggest threat to the lives of the tsar and his family, however, came not from terrorists, but from a derailment of the imperial train in the fall of 1888. Maria and her family had been at lunch in the dining car when the train jumped the tracks and slid down an embankment, causing the roof of the dining car to nearly cave in on them.

When Maria's eldest sister Alexandra visited Gatchina in July 1894, she was surprised to see how weak her brother-in-law Alexander III had become. At the time Maria had long known that he was ill and did not have long left. She now turned her attention to her eldest son, the future Nicholas II, for it was on him that both her personal future and the future of the dynasty now depended.

Nicholas had long had his heart set on marrying Princess Alix of Hesse-Darmstadt, a favourite grandchild of Queen Victoria. Despite the fact that she was their godchild, neither Alexander III nor Maria approved of the match. Nicholas summed up the situation as follows: "I wish to move in one direction, and it is clear that Mama wishes me to move in another – my dream is to one day marry Alix." Maria and Alexander found Alix shy and somewhat peculiar. They were also concerned that the young Princess was not possessed of the right character to be Empress of Russia. Nicholas's parents had known Alix as a child and formed the impression that she was hysterical and unbalanced, which may have been due to the loss of her mother and youngest sister, Marie, to diphtheria when she was just six. It was only when Alexander III's health was beginning to fail that they reluctantly gave permission for Nicholas to propose.

On 1 November 1894, Alexander III died aged just 49 at Livadia. In her diary Maria wrote, "I am utterly heartbroken and despondent, but when I saw the blissful smile and the peace in his face that came after, it gave me strength." Two days later, the Prince and Princess of Wales arrived at Livadia from London. While the Prince of Wales took it upon himself to involve himself in the preparations for the funeral, the Princess of Wales spent her time comforting grieving Maria, including praying with her and sleeping at her bedside. 
Maria Feodorovna's birthday was a week after the funeral, and as it was a day in which court mourning could be somewhat relaxed, Nicholas used the day to marry Alix of Hesse-Darmstadt, who took the name Alexandra Feodorovna.

Once the death of Alexander III had receded, Maria again took a brighter view of the future. "Everything will be all right", as she said. Maria continued to live in the Anichkov Palace in St. Petersburg and at Gatchina Palace. In May 1896, she travelled to Moscow for the coronation of Nicholas and Alexandra.

As a new Imperial Train was constructed for Nicholas II in time for his coronation, Alexander III's "Temporary Imperial Train" (composed of the cars that had survived the Borki disaster and a few converted standard passenger cars) was transferred to the Empress Dowager's personal use.

During the first years of her son's reign, Maria often acted as the political adviser to the Tsar. Uncertain of his own ability and aware of her connections and knowledge, Tsar Nicholas II often told the ministers that he would ask her advice before making decisions, and the ministers sometimes suggested this themselves. It was reportedly on her advice that Nicholas initially kept his father's ministers. Maria herself estimated that her son was of a weak character and that it was better that he was influenced by her than someone worse. Her daughter Olga remarked upon her influence: “she had never before taken the least interest … now she felt it was her duty. Her personality was magnetic and her zest of activity was incredible. She had her finger on every educational pulse in the empire. She would work her secretaries to shreds, but she did not spare herself. Even when bored in committee she never looked bored. Her manner and, above all, her tact conquered everybody”. After the death of her spouse, Maria came to be convinced that Russia needed reforms to avoid a revolution. According to courtier Paul Benckendorff there was a scene when Maria asked her son not to appoint the conservative Wahl as minister for internal affairs: “during which one [the empress dowager] almost threw herself at his [the tsar's] knees' begging him not to make this appointment and to choose someone who could make concessions. She said that if Nicholas did not agree, she would 'leave for Denmark, and then without me here let them twist your head around'". Nicholas did appoint her favored candidate, and she reportedly told her favoured candidate the liberal reformist Peter Sviatopolk-Mirsky to accept by saying: “You must fulfil my son’s wish; If you do, I will give you a kiss”. After the birth of a son to the tsar the same year, however, Nicholas II replaced his mother as his political confidant and adviser with his wife, Empress Alexandra.

Maria Feodorovna's grandson-in-law, Prince Felix Yusupov, noted that she had great influence in the Romanov family. Sergei Witte praised her tact and diplomatic skill. Nevertheless, despite her social tact, she did not get along well with her daughter-in-law, Tsarina Alexandra, holding her responsible for many of the woes that beset her son Nicholas and the Russian Empire in general. She was appalled with Alexandra's inability to win favour with public, and also that she did not give birth to an heir until almost ten years after her marriage, after bearing four daughters. The fact that Russian court custom dictated that an empress dowager took precedence over an empress consort, combined with the possessiveness that Maria had of her sons, and her jealousy of Empress Alexandra only served to exacerbate tensions between mother-in-law and daughter-in-law. Sophie Buxhoeveden remarked of this conflict: “Without actually clashing they seemed fundamentally unable … to understand one another”, and her daughter Olga commented: “they had tried to understand each other and failed. They were utterly different in character, habits and outlook”. Maria was sociable and a good dancer, with an ability to ingratiate herself with people, while Alexandra, though more intelligent and beautiful, was very shy and closed herself off from the Russian people.

By the turn of the twentieth century, Maria was spending increasing time abroad. In 1906, following the death of their father, King Christian IX, she and her sister, Alexandra, who had become queen-consort of the United Kingdom in 1901, purchased the villa of Hvidøre. The following year, a change in political circumstances allowed Maria Feodorovna to be welcomed to England by King Edward VII and Queen Alexandra, Maria's first visit to England since 1873. Following a visit in early 1908, Maria Feodorovna was present at her brother-in-law and sister's visit to Russia that summer. A little under two years later, Maria Feodorovna travelled to England yet again, this time for the funeral of her brother-in-law, King Edward VII, in May 1910. During her nearly three-month visit to England in 1910, Maria Feodorovna attempted, unsuccessfully, to get her sister, now Queen Dowager Alexandra, to claim a position of precedence over her daughter-in-law, Queen Mary.

Empress Maria Feodorovna, the mistress of Langinkoski retreat, was also otherwise a known friend of Finland. During the first russification period, she tried to have her son halt the constraining of the grand principality's autonomy and to recall the unpopular Governor-General Bobrikov from Finland to some other position in Russia itself. During the second russification period, at the start of the First World War, the Empress Dowager, travelling by her special train through Finland to Saint Petersburg, expressed her continued disapprobation for the russification of Finland by having an orchestra of a welcoming committee play the March of the Pori Regiment and the Finnish national anthem "Maamme", which at the time were under the explicit ban from Franz Albert Seyn, the Governor-General of Finland.

In 1899, Maria's second son, George, died of tuberculosis in the Caucasus. During the funeral, she kept her composure, but at the end of the service, she ran from the church clutching her son's top hat that been atop the coffin and collapsed in her carriage sobbing. Two years later, according to her daughter, Grand Duchess Olga, she arranged Olga's disastrous marriage to Peter, Duke of Oldenburg. For years Nicholas refused to grant his unhappy sister a divorce, only relenting in 1916 in the midst of the War. When Olga attempted to contract a morganatic marriage with Nikolai Kulikovsky, Maria Feodorovna and the tsar tried to dissuade her, yet, they did not protest too vehemently. Indeed, Maria Feodorovna was one of the few people who attended the wedding in November 1916. In 1912, Maria faced trouble with her youngest son, when he secretly married his mistress, much to the outrage and scandal of both Maria Feodorovna and Nicholas.

Maria Feodorovna disliked Rasputin, whom she regarded to be a dangerous charlatan, and when his activities damaged the reputation of the Tsar, she asked the Tsar and Empress to remove him from their vicinity. When the Tsar remained silent and Empress Alexandra answered and refused for both of them, Maria assumed the empress was the true regent and that she also lacked the capability for such a position: “My poor daughter-in-law does not perceive that she is ruining the dynasty and herself. She sincerely believes in the holiness of an adventurer, and we are powerless to ward of the misfortune, which is sure to come”, When the Tsar dismissed minister Vladimir Kokovtsov in February 1914 on the advice of Alexandra, Maria again reproached her son, who answered in such a way that she became even more convinced that Alexandra was the real ruler of Russia, and she called upon Kokovtsov and said to him: “My daughter-in-law does not like me; she thinks that I am jealous of her power. She does not perceive that my one aspiration is to see my son happy. Yet I see we are nearing some kind of catastrophe and the Tsar listens to no one but flatterers… Why do you not tell the Tsar everything that you think and know… if it is not already too late”.

In May 1914 Maria Feodorovna travelled to England to visit her sister. While she was in London, World War I broke out (July 1914), forcing her to hurry home to Russia. In Berlin the German authorities prevented her train from continuing toward the Russian border. Instead she had to return to Russia by way of (neutral) Denmark and Finland. Upon her return in August, she took up residence at Yelagin Palace, which was closer to St. Petersburg (renamed Petrograd in August 1914) than Gatchina. During the war she served as president of Russia's Red Cross. As she had done a decade earlier in the Russo-Japanese War of 1904-1905, she also financed a sanitary train.

During the war, there was great concern within the imperial house about the influence Empress Alexandra had upon state affairs through the Tsar, and the influence Grigori Rasputin was believed to have upon her, as it was considered to provoke the public and endanger the safety of the imperial throne and the survival of the monarchy. 
On behalf of the imperial relatives of the Tsar, both the Empress's sister Grand Duchess Elizabeth Feodorovna and her cousin Grand Duchess Victoria Feodorovna had been selected to mediate and ask Empress Alexandra to banish Rasputin from court to protect her and the throne's reputation, but without success. In parallel, several of the Grand Dukes had tried to intervene with the Tsar, but with no more success.

During this conflict of 1916-1917, Grand Duchess Maria Pavlovna reportedly planned a coup d'état to depose the Tsar with the help of four regiments of the imperial guard which were to invade the Alexander Palace, force the Tsar to abdicate and replace him with his underage son under the regency of her son Grand Duke Kirill.

There are documents that support the fact that in this critical situation, Maria Feodorovna was involved in a planned coup d'état to depose her son from the throne in order to save the monarchy. The plan was reportedly for Maria to make a final ultimatum to the Tsar to banish Rasputin unless he wished for her to leave the capital, which would be the signal to unleash the coup. Exactly how she planned to replace her son is unconfirmed, but two versions are available: first, that Grand Duke Paul Alexandrovich of Russia would take power in her name, and that she herself would thereafter become ruling empress; the other version further claims that Grand Duke Paul Alexandrovich of Russia would replace the Tsar with his son, the heir to the throne, Maria's grandson Alexey, upon which Maria and Paul Alexandrovich would share power as regents during his minority. Maria was asked to make her appeal to the Tsar after Empress Alexandra had asked the Tsar to dismiss minister Polianov. Initially, she refused to make the appeal, and her sister-in-law Grand Duchess Maria Pavlovna stated to the French Ambassador: “It’s not want of courage or inclination that keeps her back. It's better that she don’t. She’s too outspoken and imperious. The moment she starts to lecture her son, her feelings run away with her; she sometimes says the exact opposite of what she should; she annoys and humiliates him. Then he stands on his dignity and reminds his mother he is the emperor. They leave each other in a rage.” Eventually, she was however convinced to make the appeal. Reportedly, Empress Alexandra was informed about the planned coup, and when Maria Feodorovna made the ultimatum to the Tsar, the empress convinced him to order his mother to leave the capital. Consequently, the Empress Dowager left Petrograd to live in the Mariyinsky Palace in Kiev the same year. She never again returned to Russia's capital. Empress Alexandra commented about her departure: “it’s much better Motherdear stays … at Kiev, where the climate is better and she can live as she wishes and hears less gossip”.

In Kiev, Maria engaged in the Red Cross and hospital work, and in September, the 50th anniversary of her arrival in Russia was celebrated with great festivities, during which she was visited by her son, Nicholas II, who came without his wife. Empress Alexandra wrote to the Tsar: “When you see Motherdear, you must rather sharply tell her how pained you are, that she listens to slander and does not stop it, as it makes mischief and others would be delighted, I am sure, to put her against me…” Maria did ask Nicholas II to remove both Rasputin and Alexandra from all political influence, but shortly after, Nicholas and Alexandra broke all contact with the Tsar's family.
When Rasputin was murdered, part of the Imperial relatives asked Maria to return to the capital and use the moment to replace Alexandra as the Tsar's political adviser. Maria refused, but she did admit that Alexandra should be removed from influence over state affairs: “Alexandra Feodorovna must be banished. Don’t know how but it must be done. Otherwise she might go completely mad. Let her enter a convent or just disappear.” 

Revolution came to Russia in 1917, first with the February Revolution, then with Nicholas II's abdication on 15 March. After travelling from Kiev to meet with her deposed son, Nicholas II in Mogilev, Maria returned to the city, where she quickly realised how Kiev had changed and that her presence was no longer wanted. She was persuaded by her family there to travel to the Crimea by train with a group of other refugee Romanovs.

After a time living in one of the imperial residences in the Crimea, she received reports that her sons, her daughter-in-law and her grandchildren had been murdered. However, she publicly rejected the report as a rumour. On the day after the murder of the Tsar's family, Maria received a messenger from Nicky, "a touching man" who told of how difficult life was for her son's family in Yekaterinburg. "And nobody can help or liberate them - only God! My Lord save my poor, unlucky Nicky, help him in his hard ordeals!" In her diary she comforted herself: "I am sure they all got out of Russia and now the Bolsheviks are trying to hide the truth." She firmly held on to this conviction until her death. The truth was too painful for her to admit publicly. Her letters to her son and his family have since almost all been lost; but in one that survives, she wrote to Nicholas: "You know that my thoughts and prayers never leave you. I think of you day and night and sometimes feel so sick at heart that I believe I cannot bear it any longer. But God is merciful. He will give us strength for this terrible ordeal." Maria's daughter Olga Alexandrovna commented further on the matter, "Yet I am sure that deep in her heart my mother had steeled herself to accept the truth some years before her death."

Despite the overthrow of the monarchy in 1917, the former Empress Dowager Maria at first refused to leave Russia. Only in 1919, at the urging of her sister, Queen Dowager Alexandra, did she begrudgingly depart, fleeing Crimea over the Black Sea to London. King George V sent the warship HMS "Marlborough" to retrieve his aunt. The party of 17 Romanovs included her daughter the Grand Duchess Xenia and five of Xenia's sons plus six dogs and a canary.

After a brief stay in the British base in Malta, they travelled to England on the British ship the "Lord Nelson", and she stayed with her sister, Alexandra. Although Queen Alexandra never treated her sister badly and they spent time together at Marlborough House in London and at Sandringham House in Norfolk, Maria, as a deposed empress dowager, felt that she was now "number two," in contrast to her sister, a popular queen dowager, and she eventually returned to her native Denmark. After living briefly with her nephew, King Christian X, in a wing of the Amalienborg Palace, she chose her holiday villa Hvidøre near Copenhagen as her new permanent home.

There were many Russian émigrées in Copenhagen who continued to regard her as the Empress and often asked her for help. The All-Russian Monarchical Assembly held in 1921 offered her the "locum tenens" of the Russian throne but she declined with the evasive answer "Nobody saw Nicky killed" and therefore there was a chance her son was still alive. She rendered financial support to Nikolai Sokolov, who studied the circumstances of the death of the Tsar's family, but they never met. The Grand Duchess Olga sent a telegram to Paris cancelling an appointment because it would have been too difficult for the old and sick woman to hear the terrible story of her son and his family.

In November 1925, Maria's favourite sister, Queen Alexandra, died. That was the last loss that she could bear. "She was ready to meet her Creator," wrote her son-in-law, Grand Duke Alexander Mikhailovich, about Maria's last years. On 13 October 1928 at Hvidøre near Copenhagen, in a house she had once shared with her sister Queen Alexandra, Maria died at the age of 80, having outlived four of her six children. Following services in Copenhagen's Russian Orthodox Alexander Nevsky Church, the Empress was interred at Roskilde Cathedral.

In 2005, Queen Margrethe II of Denmark and President Vladimir Putin of Russia and their respective governments agreed that the Empress's remains should be returned to St. Petersburg in accordance with her wish to be interred next to her husband. A number of ceremonies took place from 23 to 28 September 2006. The funeral service, attended by high dignitaries, including the Crown Prince and Crown Princess of Denmark and Prince and Princess Michael of Kent, did not pass without some turbulence. The crowd around the coffin was so great that a young Danish diplomat fell into the grave before the coffin was interred. On 26 September 2006, a statue of Maria Feodorovna was unveiled near her favourite Cottage Palace in Peterhof. Following a service at Saint Isaac's Cathedral, she was interred next to her husband Alexander III in the Peter and Paul Cathedral on 28 September 2006, 140 years after her first arrival in Russia and almost 78 years after her death.

Tsar Alexander III and Maria Feodorovna had four sons and two daughters:



</doc>
<doc id="20541" url="https://en.wikipedia.org/wiki?curid=20541" title="Montauban">
Montauban

Montauban (, ; ) is a commune in the Tarn-et-Garonne department in the Occitanie region in southern France. It is the capital of the department and lies north of Toulouse. Montauban is the most populated town in Tarn-et-Garonne, and the sixth most populated of Occitanie behind Toulouse, Montpellier, Nîmes, Perpignan and Béziers. In 2013, there were 57,921 inhabitants, called "Montalbanais". The town has been classified "Ville d’art et d’histoire" (City of art and history) since 2015.

The town, built mainly of a reddish brick, stands on the right bank of the Tarn at its confluence with the Tescou.

Montauban is the second oldest (after Mont-de-Marsan) of the "bastides" of southern France. Its foundation dates from 1144 when Count Alphonse Jourdain of Toulouse, granted it a liberal charter. The inhabitants were drawn chiefly from Montauriol, a village which had grown up around the neighbouring monastery of St Théodard.

In the 13th century the town suffered much from the ravages of the Albigensian war and from the Inquisition, but by 1317 it had recovered sufficiently to be chosen by John XXII as the head of a diocese of which the basilica of St Théodard became the cathedral.
In 1360, under the Treaty of Brétigny, it was ceded to the English; they were expelled by the inhabitants in 1414. In 1560 the bishops and magistrates embraced Protestantism, expelled the monks, and demolished the cathedral. Ten years later it became one of the four Huguenot strongholds under the Peace of Saint-Germain, and formed a small independent republic. It was the headquarters of the Huguenot rebellion of 1621, and successfully withstood an 86-day siege by Louis XIII. It did not submit to royal authority until after the fall of La Rochelle in 1629, when its fortifications were destroyed by Cardinal Richelieu. The Protestants again suffered persecution after the revocation of the Edict of Nantes in 1685.

In the 17th century, the King of France revoked "l’Édit de Nantes". Montauban was considered as an intellectual city. Because Montauban was a Protestant town, it started to resist and hold its position against the royal power and it refused to give allegiance to the Catholic King. To scare off the King’s opponents and speed up the end of the siege, 400 cannonballs were fired, but Montauban resisted and the royal army was vanquished. Saint Jacques church is still marked by the cannonballs, and every year in September, the city celebrates "les 400 coups" (the 400 shots), which has become a common phrase in French.

During World War II, Leonardo da Vinci's Mona Lisa was briefly hidden in a secret vault behind a wine cellar at Montauban.

Montauban’s climate is temperate and subtropical (borderline "Csa"/"Csb" in the Köppen climate classification). Temperatures are rather mild in winter and hot in summer. The town experienced severe droughts in 2003, 2006, 2012 and 2015. On August 31, 2015, the Tarn-et-Garonne area was particularly struck by a wave of violent storms. These storms, accompanied by very strong winds, created a tornado, which caused considerable damage in a large part of the department. Montauban was particularly affected, with winds measured between 130 and 150 kilometers per hour (a record) in the city center.

Its fortifications have been replaced by boulevards beyond which extend numerous suburbs, while on the left bank of the Tarn is the suburb of Villebourbon, which is connected to the town by a remarkable bridge of the early 14th century. This bridge is known as "Pont Vieux" (i.e. "Old Bridge"). King Philip the Fair of France officially launched the building of the bridge in 1303 while on a tour to Toulouse. The project took 30 years to complete, and the bridge was inaugurated in 1335. The main architects were Étienne de Ferrières and Mathieu de Verdun. It is a pink brick structure over in length, but while its fortified towers have disappeared, it is otherwise in a good state of preservation. The bridge was designed to resist the violent floods of the Tarn, and indeed it successfully withstood the two terrible millennial floods of 1441 and 1930. The bridge is a straight level bridge, which is quite unusual for Medieval Europe, where lack of technological skills meant that most bridges were of the humpback type.
The "Musée Ingres", on the site of a castle of the Counts of Toulouse and once the residence of the bishops of Montauban, stands at the east end of the bridge. It belongs chiefly to the 17th century, but some portions are much older, notably an underground chamber known as the Hall of the Black Prince ("Salle du Prince Noir"). It comprises most of the work (including his "Jesus among the Teachers of the Law") of Jean Ingres, the celebrated painter, whose birth in Montauban is commemorated by an elaborate monument. It is the largest museum of Ingres paintings in the world. The museum also contains some sculptures by famous sculptor Antoine Bourdelle, another native of Montauban, as well as collections of antiquities (Greek vases) and 18th and 19th ceramics.

The "Place Nationale" is a square of the 17th century, entered at each corner by gateways giving access to a large open space surrounded by pink brick houses supported by double rows of arcades.

The "préfecture" is located in the palace built by the "intendant" of Montauban (the equivalent of a "préfet" before the French Revolution), and is a large elegant 18th century mansion, built of pink bricks and white stone, with a steep roof of blue gray slates, in a style combining northern and southern French styles of architecture.

The chief churches of Montauban are the cathedral, remarkable only for the possession of the "Vow of Louis XIII", one of the masterpieces of Ingres, and the church of St Jacques (14th and 15th centuries), dedicated to Saint James of Compostela, the façade of which is surmounted by a handsome octagonal tower, the base of which is in Romanesque style, while the upper levels, built later, are in Gothic style. Montauban:

The commercial importance of Montauban is due rather to its trade in agricultural produce, horses, game and poultry, than to its industries, which include nursery-gardening, cloth-weaving, cloth-dressing, flour-milling, wood-sawing, and the manufacture of furniture, silk-gauze and straw hats.

However, due to the proximity of Toulouse and the cheaper cost of industrial grounds, more and more mechanical products are being manufactured there.

Population:

Aire urbaine:

The town is a railway junction, and the station Gare de Montauban-Ville-Bourbon offers connections with Toulouse, Bordeaux, Paris, Brive-la-Gaillarde, Marseille and several regional destinations. Montauban communicates with the Garonne via the Canal de Montech.

Founded in 1144 by the Comte de Toulouse, the town of Montauban has some particularities: its center’s red brick streets intersect at right angles and meet at the National Square (Place Nationale) which is ranked among the most beautiful squares of France. Some buildings and architectural complexes are distinguished, such as "le Musée Ingres", "la Place Nationale", "le Pont vieux", "L’église Saint Jacques", " la Cathédrale Notre Dame", « l’Ancien Collège des Jésuites », « le Muséum ».

The town is home of the rugby union club US Montauban. The team gained promotion from the Pro D2 competition for the 2006–07 Top 14 season. The whole town supports rugby, but the athletic club is also very efficient and national results have been regular since 2007. Some athletes in Montauban’s athletic club are international athletes. Every year, since 2004, the Rene Arcuset cross country race has been organized in the city.

In the movie "Les Tontons Flingueurs" a French classic by Georges Lautner, shot and released in 1963, Lino Ventura's character is a businessman from Montauban. Called to Paris for a personal case, he is nicknamed by Bernard Blier’s character "Le gugusse de Montauban" (the guy from Montauban.) The "gugusse" will later answer: "one should never leave Montauban". Recently, a round-about in the center of the town was renamed "Tonton Flingueurs’ round-about" and placards with drawings of the actors have been displayed.

Montauban was the birthplace of:

Montauban was the deathplace of:

Montauban is the seat of a bishop and a court of assize. It has tribunals of first instance and of commerce, a chamber of commerce and a board of trade arbitration, lycées and a training college, schools of commerce and viticulture, a branch of the Bank of France, and a faculty of Protestant theology.







</doc>
<doc id="20542" url="https://en.wikipedia.org/wiki?curid=20542" title="Rail transport modelling">
Rail transport modelling

Railway modelling (UK, Australia and Ireland) or model railroading (US and Canada) is a hobby in which rail transport systems are modelled at a reduced scale.

The scale models include locomotives, rolling stock, streetcars, tracks, signalling and landscapes including: countryside, roads, bridges, buildings, vehicles, urban landscape, model figures, lights, and features such as rivers, hills, tunnels, and canyons.

The earliest model railways were the 'carpet railways' in the 1840s. Electric trains appeared around the start of the 20th century, but these were crude likenesses. Model trains today are more realistic, in addition to being much more technologically advanced. Today modellers create model railway layouts, often recreating real locations and periods throughout history. The world's oldest working model railway is a model designed to train signalmen on the Lancashire and Yorkshire Railway. It is located in the National Railway Museum, York, England and dates back to 1912. It remained in use until 1995. The model was built as a training exercise by apprentices of the company's Horwich works and supplied with rolling stock by Bassett-Lowke.

Involvement ranges from possession of a train set to spending hours and large sums of money on a large and exacting model of a railroad and the scenery through which it passes, called a "layout". Hobbyists, called "railway modellers" or "model railroaders", may maintain models large enough to ride (see "Live steam, Ridable miniature railway" and "Backyard railroad").

Modellers may collect model trains, building a landscape for the trains to pass through. They may also operate their own railroad in miniature. For some modellers, the goal of building a layout is to eventually run it as if it were a real railroad (if the layout is based on the fancy of the builder) or as the real railroad did (if the layout is based on a prototype). If modellers choose to model a prototype, they may reproduce track-by-track reproductions of the real railroad in miniature, often using prototype track diagrams and historic maps.

Layouts vary from a circle or oval of track to realistic reproductions of real places modelled to scale. Probably the largest model landscape in the UK is in the Pendon Museum in Oxfordshire, UK, where an EM gauge (same 1∶76.2 scale as 00 but with more accurate track gauge) model of the Vale of White Horse in the 1930s is under construction. The museum also houses one of the earliest scenic models – the Madder Valley layout built by John Ahern. This was built in the late 1930s to late 1950s and brought in realistic modelling, receiving coverage on both sides of the Atlantic in the magazines "Model Railway News" and "Model Railroader". Bekonscot in Buckinghamshire is the oldest model village and includes a model railway, dating from the 1930s. The world's largest model railroad in H0 scale is the "Miniatur Wunderland" in Hamburg, Germany. The largest live steam layout, with of track is 'Train Mountain' in Chiloquin, Oregon, U.S.
Operations form an important aspect of rail transport modelling with many layouts being dedicated to emulating the operational aspects of a working railway. These layouts can become extremely complex with multiple routes, movement patterns and timetabled operation. The British outline model railway of Banbury Connections is one of the world's most complicated model railways.

Model railroad clubs exist where enthusiasts meet. Clubs often display models for the public. One specialist branch concentrates on larger scales and gauges, commonly using track gauges from . Models in these scales are usually hand-built and powered by live steam, or diesel-hydraulic, and the engines are often powerful enough to haul dozens of human passengers.

The Tech Model Railroad Club (TMRC) at MIT in the 1950s pioneered automatic control of track-switching by using telephone relays.

The oldest society is 'The Model Railway Club' (established 1910), near Kings Cross, London, UK. As well as building model railways, it has 5,000 books and periodicals. Similarly, 'The Historical Model Railway Society' at Butterley, near Ripley, Derbyshire specialises in historical matters and has archives available to members and non-members.

The words "scale" and "gauge" seem at first interchangeable but their meanings are different. "Scale" is the model's measurement as a proportion to the original, while "gauge" is the measurement between the rails.

The size of engines depends on the scale and can vary from tall for the largest ridable live steam scales such as 1∶4, down to matchbox size for the smallest: Z-scale (1∶220) or T scale (1∶450). A typical HO (1∶87) engine is tall, and long. The most popular scales are: G scale, Gauge 1, O scale, S scale, HO scale (in Britain, the similar OO), TT scale, and N scale (1∶160 in the United States, but 1∶148 in the UK). HO and OO are the most popular. Popular narrow-gauge scales include Sn3, HOn3 and Nn3, which are the same in scale as S, HO and N except with a narrower spacing between the tracks (in these examples, a scale instead of the standard gauge).

The largest common scale is 1∶8, with 1∶4 sometimes used for park rides. G scale (Garden, 1∶24 scale) is most popular for backyard modelling. It is easier to fit a G scale model into a garden and keep scenery proportional to the trains. Gauge 1 and Gauge 3 are also popular for gardens. O, S, HO, and N scale are more often used indoors.

At first, model railways were not to scale. Aided by trade associations such as the National Model Railroad Association (NMRA) and "Normen Europäischer Modellbahnen" (NEM), manufacturers and hobbyists soon arrived at "de facto" standards for interchangeability, such as gauge, but trains were only a rough approximation to the real thing. Official scales for the gauges were drawn up but not at first rigidly followed and not necessarily correctly proportioned for the gauge chosen. 0 (zero) gauge trains, for instance, operate on track too widely spaced in the United States as the scale is accepted as 1∶48 whereas in Britain 0 gauge uses a ratio of 43.5∶1 or 7 mm/1 foot and the gauge is near to correct. British OO standards operate on track significantly too narrow. The 4 mm/1 foot scale on a gauge corresponds to a track gauge of , (undersized). gauge corresponds to standard gauge in H0 (half-0) 3.5 mm/1 foot or 1∶87. This arose due to British locomotives and rolling stock being smaller than those found elsewhere, leading to an increase in scale to enable H0 scale mechanisms to be used. Most commercial scales have standards that include wheel flanges that are too deep, wheel treads that are too wide, and rail tracks that are too large. In H0 scale, the rail heights are codes 100, 87, 53

Later, modellers became dissatisfied with inaccuracies and developed standards in which everything is correctly scaled. These are used by modellers but have not spread to mass-production because the inaccuracies and overscale properties of the commercial scales ensure reliable operation and allow for shortcuts necessary for cost control. The finescale standards include the UK's P4, and the even finer S4, which uses track dimensions scaled from the prototype. This 4 mm:1 ft modelling uses wheels or less wide running on track with a gauge of . Check-rail and wing-rail clearances are similarly accurate.

A compromise of P4 and OO is 'EM' which uses a gauge of with more generous tolerances than P4 for check clearances. It gives a better appearance than OO though pointwork is not as close to reality as P4. It suits many where time and improved appearance are important. There is a small following of finescale OO which uses the same 16.5mm gauge as OO, but with the finer scale wheels and smaller clearances as used with EM- it is essentially 'EM-minus-1.7mm.'

Many groups build modules, which are sections of layouts, and can be joined together to form a larger layout, for meetings or for special occasions. For each kind of module system, there is an interface standard, so that modules made by different participants may be connected, even if they have never been connected before. Many of these module types are listed in the Layout standards organizations section of this article.

In addition to different scales, there are also different types of couplers for connecting cars, which are not compatible with each other.

In HO, the Americans standardized on horn-hook, or X2F couplers. Horn hook couplers have largely given way to a design known as a working knuckle coupler which was popularized by the Kadee Quality Products Co., and which has subsequently been emulated by a number of other manufactures in recent years. Working knuckle couplers are a closer approximation to the "automatic" couplers used on the prototype there and elsewhere. Also in HO, the European manufacturers have standardized, but on a coupler mount, not a coupler: many varieties of coupler can be plugged in (and out) of the NEM coupler box. None of the popular couplers has any resemblance to the prototype three-link chains generally used on the continent.

For British modellers, whose most popular scale is OO, the normal coupler is a tension-lock coupler, which, again has no pretence of replicating the usual prototype three-link chain couplers. Bachmann and more recently Hornby have begun to offer models fitted with NEM coupler pockets. This theoretically enables modellers of British railways to substitute any other NEM362 coupler, though many Bachmann models place the coupler pocket at the wrong height. A fairly common alternative is to use representations of chain couplings as found on the prototype, though these require large radius curves to be used to avoid derailments.

Other scales have similar ranges of non-compatible couplers available. In all scales couplers can be exchanged, with varying degrees of difficulty.

Some modellers pay attention to landscaping their layout, creating a fantasy world or modelling an actual location, often historic. Landscaping is termed "scenery building" or "scenicking".

Constructing scenery involves preparing a sub-terrain using a wide variety of building materials, including (but not limited to) screen wire, a lattice of cardboard strips, or carved stacks of expanded polystyrene (styrofoam) sheets. A scenery base is applied over the sub-terrain; typical base include casting plaster, plaster of Paris, hybrid paper-pulp (papier-mâché) or a lightweight foam/fiberglass/bubblewrap composite as in Geodesic Foam Scenery.
The scenery base is covered with substitutes for ground cover, which may be Static Grass or scatter. "Scatter" or "flock" is a substance used in the building of dioramas and model railways to simulate the effect of grass, poppies, fireweed, track ballast and other scenic ground cover. Scatter used to simulate track ballast is usually fine-grained ground granite. Scatter which simulates coloured grass is usually tinted sawdust, wood chips or ground foam. Foam or natural lichen or commercial scatter materials can be used to simulate shrubbery. An alternative to scatter, for grass, is static grass which uses static electricity to make its simulated grass actually stand up.

Buildings and structures can be purchased as kits, or built from cardboard, balsa wood, basswood, other soft woods, paper, or polystyrene or other plastic. Trees can be fabricated from materials such as Western sagebrush, candytuft, and caspia, to which adhesive and model foliage are applied; or they can be bought ready-made from specialist manufacturers. Water can be simulated using polyester casting resin, polyurethane, or rippled glass. Rocks can be cast in plaster or in plastic with a foam backing. Castings can be painted with stains to give colouring and shadows.

"Weathering" refers to making a model look used and exposed to weather by simulating dirt and wear on real vehicles, structures and equipment. Most models come out of the box looking new, because unweathered finishes are easier to produce. Also, the wear a freight car or building undergoes depends not only on age but where it is used. Rail cars in cities accumulate grime from building and automobile exhaust and graffiti, while cars in deserts may be subjected to sandstorms which etch or strip paint. A model that is weathered would not fit as many layouts as a pristine model which can be weathered by its purchaser.

There are many weather techniques that include, but are not limited to, painting, sanding, breaking, and even the use of chemicals to cause corrosion. Some processes become very creative depending on the skill of the modeller. For instance several steps may be taken to create a rusting effect to ensure not only proper colouring, but also proper texture and lustre.

Weathering purchased models is common. At the least, weathering aims to reduce the plastic-like finish of scale models. The simulation of grime, rust, dirt, and wear adds realism. Some modellers simulate fuel stains on tanks, or corrosion on battery boxes. In some cases, evidence of accidents or repairs may be added, such as dents or freshly painted replacement parts, and weathered models can be nearly indistinguishable from their prototypes when photographed appropriately.

Static diorama models or 'push along' scale models are a branch of model railways for unpowered locomotives, examples are Lone Star and Airfix models. Powered model railways are now generally operated by low voltage direct current (DC) electricity supplied via the tracks, but there are exceptions, such as Märklin and Lionel Corporation, which use alternating current (AC). Modern Digital Command Control (DCC) systems use alternating current. Other locomotives, particularly large models can use steam. Steam and clockwork driven engines are still sought by collectors.

Most early models for the toy market were powered by clockwork and controlled by levers on the locomotive. Although this made control crude the models were large and robust enough that handling the controls was practical. Various manufacturers introduced slowing and stopping tracks that could trigger levers on the locomotive and allow station stops.

Early electrical models used a three-rail system with the wheels resting on a metal track with metal sleepers that conducted power and a middle rail which provided power to a skid under the locomotive. This made sense at the time as models were metal and conductive. Modern plastics were not available and insulation was a problem. In addition the notion of accurate models had yet to evolve and toy trains and track were crude tinplate. A variation on the three-rail system, Trix Twin, allowed two trains to be independently controlled on one track, before the advent of Digital Command Control.

As accuracy became important some systems adopted two-rail power in which the wheels were isolated from each other and the rails carried the positive and negative supply with the right rail carrying the positive potential.

Other systems such as Märklin instead used fine metal studs to replace the central rail, allowing existing three-rail models to use more realistic track.

Where the model is of an electric locomotive, it may be supplied by overhead lines, like the full-size locomotive. Before Digital Command Control became available, this was one way of controlling two trains separately on the same track. The electric-outline model would be supplied by the overhead wire and the other model could be supplied by one of the running rails. The other running rail would act as a common return.

Early electric trains ran on trackside batteries because few homes in the late 19th century and early 20th century had electricity. Today, inexpensive train sets running on batteries are again common but regarded as toys and seldom used by hobbyists. Batteries located in the model often power garden railway and larger scale systems because of the difficulty in obtaining reliable power supply through the outdoor rails. The high power consumption and current draw of large scale garden models is more easily and safely met with internal rechargeable batteries. Most large scale battery powered models use radio control.

Engines powered by live steam are often built in large outdoor gauges of and , are also available in Gauge 1, G scale, 16 mm scale and can be found in O and OO/HO. Hornby Railways produce live steam locomotives in OO, based on designs first arrived at by an amateur modeller. Other modellers have built live steam models in HO/OO, OO9 and N, and there is one in Z in Australia.

Occasionally gasoline-electric models, patterned after real diesel-electric locomotives, come up among hobbyists and companies like Pilgrim Locomotive Works have sold such locomotives. Large-scale petrol-mechanical and petrol-hydraulic models are available but unusual and pricier than the electrically powered versions.

Modern manufacturing techniques mean mass-produced models achieve a high degree of precision and realism. In the past this was not the case and scratch building was very common. Simple models are made using cardboard engineering techniques. More sophisticated models can be made using a combination of etched sheets of brass and low temperature castings. Parts that need machining, such as wheels and couplings are purchased.

Etched kits are still popular, still accompanied by low temperature castings. These kits produce models that are not covered by the major manufacturers or in scales that are not in mass production. Laser machining techniques have extended this ability to thicker materials for scale steam and other locomotive types. Scratch builders may also make silicone rubber moulds of the parts they create, and cast them in various plastic resins (see Resin casting), or plasters. This may be done to save duplication of effort, or to sell to others. Resin "craftsman kits" are also available for a wide range of prototypes.

The first clockwork (spring-drive) and live steam locomotives ran until out of power, with no way for the operator to stop and restart the locomotive or vary its speed. The advent of electric trains, which appeared commercially in the 1890s, allowed control of the speed by varying the current or voltage. As trains began to be powered by transformers and rectifiers more sophisticated throttles appeared, and soon trains powered by AC contained mechanisms to change direction or go into neutral gear when the operator cycled the power. Trains powered by DC can change direction by reversing polarity.

Electricity permits control by dividing the layout into isolated blocks, where trains can be slowed or stopped by lowering or cutting power to a block. Dividing a layout into blocks permits operators to run more than one train with less risk of a fast train catching and hitting a slow train. Blocks can also trigger signals or other accessories, adding realism or whimsy. Three-rail systems often insulate one of the common rails on a section of track, and use a passing train to complete the circuit and activate an accessory.

Many layout builders are choosing digital operation of their layouts rather than the more traditional DC design. The industry standard command system is Digital Command Control (DCC). The advantages to DCC are that track voltage is constant (usually in the range of 20 volts AC) and the command throttle sends a signal to small circuit cards, or decoders, hidden inside the piece of equipment which control several functions of an individual locomotive, including speed, direction of travel, lights, smoke and various sound effects. This allows more realistic operation in that the modeller can operate independently several locomotives on the same stretch of track. Less common closed proprietary systems also exist. Several manufacturers offer software that can provide computer-control of DCC layouts.

In large scales, particularly for garden railways, radio control and DCC in the garden have become popular.

Several organizations exist to set standardizations for connectability between individual layout sections (commonly called "modules"). This is so several (or hundreds, given enough space and power) people or groups can bring together their own modules, connect them together with as little trouble as possible, and operate their trains. Despite different design and operation philosophies, different organizations have similar goals; standardized ends to facilitate connection with other modules built to the same specifications, standardized electricals, equipment, curve radii.




</doc>
<doc id="20544" url="https://en.wikipedia.org/wiki?curid=20544" title="Morphophonology">
Morphophonology

Morphophonology (also morphophonemics or morphonology) is the branch of linguistics that studies the interaction between morphological and phonological or phonetic processes. Its chief focus is the sound changes that take place in morphemes (minimal meaningful units) when they combine to form words.

Morphophonological analysis often involves an attempt to give a series of formal rules that successfully predict the regular sound changes occurring in the morphemes of a given language. Such a series of rules converts a theoretical underlying representation into a surface form that is actually heard. The units of which the underlying representations of morphemes are composed are sometimes called morphophonemes. The surface form produced by the morphophonological rules may consist of phonemes (which are then subject to ordinary phonological rules to produce speech sounds or "phones"), or else the morphophonological analysis may bypass the phoneme stage and produce the phones itself.

When morphemes combine, they influence each other's sound structure (whether analyzed at a phonetic or phonemic level), resulting in different variant pronunciations for the same morpheme. Morphophonology attempts to analyze these processes. A language's morphophonological structure is generally described with a series of rules which, ideally, can predict every morphophonological alternation that takes place in the language.

An example of a morphophonological alternation in English is provided by the plural morpheme, written as "-s" or "-es". Its pronunciation alternates between , , and , as in "cats", "dogs", and "horses" respectively. A purely phonological analysis would most likely assign to these three endings the phonemic representations , , . On a morphophonological level, however, they may all be considered to be forms of the underlying object , which is a morphophoneme. The different forms it takes are dependent on the segment at the end of the morpheme to which it attaches: the dependencies are described by morphophonological rules. (The behaviour of the English past tense ending "-ed" is similar: it can be pronounced , or , as in "hoped", "bobbed" and "added".)

The plural suffix "-s" can also influence the form taken by the preceding morpheme, as in the case of the words "leaf" and "knife", which end with in the singular/but have in the plural ("leaves", "knives"). On a morphophonological level, the morphemes may be analyzed as ending in a morphophoneme , which becomes voiced when a voiced consonant (in this case the of the plural ending) is attached to it. The rule may be written symbolically as -> [αvoice] / [αvoice]. This expression is called Alpha Notation in which α can be +(positive value) or -(negative value).

Common conventions to indicate a morphophonemic rather than phonemic representation are double slashes (//  //) (as above, implying that the transcription is 'more phonemic than simply phonemic'), pipes (|  |), double pipes (‖  ‖) and curly brackets ({  }).

For instance, the English word "cats" may be transcribed phonetically as , phonemically as and morphophonemically as , if the plural is argued to be underlyingly , assimilating to after a voiceless nonsibilant. The tilde ~ may indicate morphological alternation, as in for "kneel~knelt" (the plus sign '+' indicates a morpheme boundary).

Inflected and agglutinating languages may have extremely complicated systems of morphophonemics. Examples of complex morphophonological systems include:

Until the 1950s, many phonologists assumed that neutralizing rules generally applied before allophonic rules. Thus phonological analysis was split into two parts: a morphophonological part, where neutralizing rules were developed to derive phonemes from morphophonemes; and a purely phonological part, where phones were derived from the phonemes. Since the 1960s (in particular with the work of the generative school, such as Chomsky and Halle's "The Sound Pattern of English") many linguists have moved away from making such a split, instead regarding the surface phones as being derived from the underlying morphophonemes (which may be referred to using various terminology) through a single system of (morpho)phonological rules.

The purpose of both phonemic and morphophonemic analysis is to produce simpler underlying descriptions for what appear on the surface to be complicated patterns. In purely phonemic analysis the data is just a set of words in a language, while for the purposes of morphophonemic analysis the words must be considered in grammatical paradigms to take account of the underlying morphemes. It is postulated that morphemes are recorded in the speaker's "lexicon" in an invariant (morphophonemic) form, which, in a given environment, is converted by rules into a surface form. The analyst attempts to present as completely as possible a system of underlying units (morphophonemes) and a series of rules that act on them, so as to produce surface forms consistent with the linguistic data.

The isolation form of a morpheme is the form in which that morpheme appears in isolation (when it is not subject to the effects of any other morpheme). In the case of a bound morpheme, such as the English past tense ending "-ed", it is generally not possible to identify an isolation form since such a morpheme does not occur in isolation.

It is often reasonable to assume that the isolation form of a morpheme provides its underlying representation. For example, in some varieties of American English, "plant" is pronounced , while "planting" is , where the morpheme "plant-" appears in the form . Here, the underlying form can be assumed to be , corresponding to the isolation form, since rules can be set up to derive the reduced form from this (but it would be difficult or impossible to set up rules that would derive the isolation form from an underlying ).

That is not always the case, however; the isolation form itself is sometimes subject to neutralization that does not apply to some other instances of the morpheme. For example, the French word "petit" ("small") is pronounced in isolation without the final [t] sound, but in certain derived forms (such as the feminine "petite"), the [t] is heard. If the isolation form were adopted as the underlying form, the information that there is a final "t" would be lost, and it would then be difficult to explain the appearance of the "t" in the inflected forms. Similar considerations apply to languages with final obstruent devoicing, in which the isolation form undergoes loss of voicing contrast, but other forms may not.

If the grammar of a language is assumed to have two rules, rule A and rule B, with A ordered before B, a given derivation may cause the application of rule A to create the environment for rule B to apply, which was not present before the application of rule A. Both rules then are in a "feeding relationship".

If rule A is ordered before B in the derivation in which rule A destroys the environment to which rule B applies, both rules are in a "bleeding order".

If A is ordered before B, and B creates an environment in which A could have applied, B is then said to counterfeed A, and the relationship is "counterfeeding".

If A is ordered before B, there is a "counterbleeding" relationship if B destroys the environment that A applies to and has already applied and so B has missed its chance to bleed A.

"Conjunctive ordering" is the ordering that ensures that all rules are applied in a derivation before the surface representation occurs. Rules applied in a feeding relationship are said to be "conjunctively ordered".

"Disjunctive ordering" is a rule that applies and prevents the other rule from applying in the surface representation. Such rules have a bleeding relationship and are said to be "disjunctively ordered".

The principle behind alphabetic writing systems is that the letters (graphemes) represent phonemes. However, many orthographies based on such systems have correspondences between graphemes and phonemes that are not exact, and it is sometimes the case that certain spellings better represent a word's morphophonological structure rather than the purely-phonological structure. An example is that the English plural morpheme is written "-s", regardless of whether it is pronounced or : "cats and "dogs, not "dogz".

The above example involves active morphology (inflection), and morphophonemic spellings are common in this context in many languages. Another type of spelling that can be described as morphophonemic is the kind that reflects the etymology of words. Such spellings are particularly common in English; examples include science" vs. "unconscious" , prejudice" vs. prequel" , sign signature" , nation" vs. nationalism" , and special" vs. species" .

For more detail on this topic, see Phonemic orthography, particularly the section on Morphophonemic features.



</doc>
<doc id="20545" url="https://en.wikipedia.org/wiki?curid=20545" title="Mirror">
Mirror

A mirror is an object that reflects light in such a way that, for incident light in some range of wavelengths; the reflected light preserves many or most of the detailed physical characteristics of the original light, called specular reflection. This is different from other light-reflecting objects that do not preserve much of the original wave signal other than color and diffuse reflected light, such as flat-white paint.

The most familiar type of mirror is the plane mirror, which has a flat surface. Curved mirrors are also used, to produce magnified or diminished images or focus light or simply distort the reflected image.

Mirrors are commonly used for personal grooming, viewing oneself (where they are also called looking-glasses), viewing the area behind and on the sides on motor vehicles while driving, for decoration, and architecture. They are often used by technicians, mechanics and dentists for viewing around and behind obstructions. Mirrors are also used in scientific apparatus such as telescopes and lasers, cameras, and industrial machinery. Most mirrors are designed for visible light; however, mirrors designed for other wavelengths of electromagnetic radiation are also used.

There are many types of glass mirrors, each representing a different manufacturing process and reflection type.

An aluminium glass mirror is made of a float glass manufactured using vacuum coating, i.e. aluminium powder is evaporated (or "sputtered") onto the exposed surface of the glass in a vacuum chamber and then coated with two or more layers of waterproof protective paint. 

A low aluminium glass mirror is manufactured by coating silver and two layers of protective paint on the back surface of glass. A low aluminium glass mirror is very clear, light transmissive, smooth, and reflects accurate natural colors. This type of glass is widely used for framing presentations and exhibitions in which a precise color representation of the artwork is truly essential or when the background color of the frame is predominantly white.

A safety glass mirror is made by adhering a special protective film to the back surface of a silver glass mirror, which prevents injuries in case the mirror is broken. This kind of mirror is used for furniture, doors, glass walls, commercial shelves, or public areas.

A silkscreen printed glass mirror is produced using inorganic color ink that prints patterns through a special screen onto glass. Various colors, patterns, and glass shapes are available. Such a glass mirror is durable and more moisture resistant than ordinary printed glass and can serve for over 20 years. This type of glass is widely used for decorative purposes (e.g., on mirrors, table tops, doors, windows, kitchen chop boards, etc.).

A silver glass mirror is an ordinary mirror, coated on its back surface with silver, which produces images by reflection. This kind of glass mirror is produced by coating a silver, copper film and two or more layers of waterproof paint on the back surface of float glass, which perfectly resists acid and moisture. A silver glass mirror provides clear and actual images, is quite durable, and is widely used for furniture, bathroom and other decorative purposes.

Decorative glass mirrors are usually handcrafted. A variety of shades, shapes and glass thickness are often available.

A beam of light reflects off a mirror at an angle of reflection equal to its angle of incidence (if the size of a mirror is much larger than the wavelength of light). That is, if the beam of light is shining on a mirror's surface, at a formula_1° angle vertically, then it reflects from the point of incidence at a formula_1° angle, vertically in the opposite direction. This law mathematically follows from the interference of a plane wave on a flat boundary (of much larger size than the wavelength).

Objects viewed in a (plane) mirror will appear laterally inverted (e.g., if one raises one's right hand, the image's left hand will appear to go up in the mirror), but not vertically inverted (in the image a person's head still appears above their body). However, a mirror does not usually "swap" left and right any more than it swaps top and bottom. A mirror typically reverses the forward/backward axis. To be precise, it reverses the object in the direction perpendicular to the mirror surface (the normal). Because left and right are defined relative to front-back and top-bottom, the "flipping" of front and back results in the perception of a left-right reversal in the image. (If you stand side-on to a mirror, the mirror really does reverse your left and right, because that's the direction perpendicular to the mirror.)

Looking at an image of oneself with the front-back axis flipped results in the perception of an image with its left-right axis flipped. When reflected in the mirror, your right hand remains directly opposite your real right hand, but it is perceived as the left hand of your image. When a person looks into a mirror, the image is actually front-back reversed, which is an effect similar to the hollow-mask illusion. Notice that a mirror image is fundamentally different from the object and cannot be reproduced by simply rotating the object.

For things that may be considered as two-dimensional objects (like text), front-back reversal cannot usually explain the observed reversal. In the same way that text on a piece of paper appears reversed if held up to a light and viewed from behind, text held facing a mirror will appear reversed, because the observer is behind the text. Another way to understand the reversals observed in images of objects that are effectively two-dimensional is that the inversion of left and right in a mirror is due to the way human beings turn their bodies. To turn from viewing the side of the object facing the mirror to view the reflection in the mirror requires the observer to look in the opposite direction. To look in another direction, human beings turn their heads about a vertical axis. This causes a left-right reversal in the image but not an up-down reversal. If a person instead turns by bending over and looking at the mirror image between their legs, up-down will appear reversed but not left-right. This sort of reversal is simply a change relative to the observer and not a change intrinsic to the image itself, as with a three-dimensional object.

The first mirrors used by humans were most likely pools of dark, still water, or water collected in a primitive vessel of some sort. The requirements for making a good mirror are a surface with a very high degree of flatness (preferably but not necessarily with high reflectivity), and a surface roughness smaller than the wavelength of the light. The earliest manufactured mirrors were pieces of polished stone such as obsidian, a naturally occurring volcanic glass. Examples of obsidian mirrors found in Anatolia (modern-day Turkey) have been dated to around 6000 BC. Mirrors of polished copper were crafted in Mesopotamia from 4000 BC, and in ancient Egypt from around 3000 BC. Polished stone mirrors from Central and South America date from around 2000 BC onwards. In China, bronze mirrors were manufactured from around 2000 BC, some of the earliest bronze and copper examples being produced by the Qijia culture. Mirrors made of other metal mixtures (alloys) such as copper and tin speculum metal may have also been produced in China and India. Mirrors of speculum metal or any precious metal were hard to produce and were only owned by the wealthy. These stone and metal mirrors could be made in very large sizes, but were difficult to polish and get perfectly flat; a process that became more difficult with increased size; so they often produced warped or blurred images. Stone mirrors often had poor reflectivity compared to metals, yet metals scratch or tarnish easily, so they frequently needed polishing. Depending upon the color, both often yielded reflections with poor color rendering. The poor image quality of ancient mirrors explains 1 Corinthians 13's reference to seeing "as in a mirror, darkly."

In her history of the mirror, Sabine Melchior-Bonnet draws significant attention to the relation of the mirror to Greek philosophy, specifically Socrates:If well used, however, the mirror can aid moral meditation between man and himself. Socrates, we are told by Diogenes, urged young people to look at themselves in mirrors so that, if they were beautiful, they would become worthy of their beauty, and if they were ugly, they would know how to hide their disgrace through learning. The mirror, a tool by which to "know thyself," invited man to "not" mistake himself for God, to avoid pride by knowing his limits, and to improve himself. His was thus not a passive mirror of imitation but an active mirror of transformation. (p.106)

Glass was a desirable material for mirrors. Stones and metals consist of small crystals (grains) separated by grain boundaries, so they reflect light as a mosaic of tiny, individual, closely-spaced mirrors. Because glass is non-crystalline the surface is naturally smooth and free of grain boundaries, so it produces reflections with very little blur. In addition, glass is very hard and scratch-resistant. However, glass by itself has little reflectivity, so people began coating it with metals to increase the reflectivity. Metal-coated glass mirrors are said by the Roman scholar Pliny the Elder to have been invented in Sidon (modern-day Lebanon) in the first century AD, although no archeological evidence of them date from before the third century. According to Pliny, the people of Sidon developed a technique for creating crude mirrors by coating blown glass with molten lead. Glass mirrors backed with gold leaf are mentioned by Pliny in his "Natural History", written in about 77 AD. Because there were few ways to make a smooth piece of glass with a uniform thickness, these ancient glass-mirrors were made by blowing a glass bubble, and then cutting off a small, circular section, producing mirrors that were either concave or convex. These circular mirrors were typically small, from five to eight inches (13–20 cm) in diameter. These small mirrors produced distorted images, yet were prized objects of high value. These ancient glass mirrors were very thin, thus very fragile, because the glass needed to be extremely thin to prevent cracking when coated with a hot, molten metal. Due to the poor quality, high cost, and small size of these ancient glass mirrors, solid metal-mirrors primarily of steel were usually preferred until the late nineteenth century.

Parabolic mirrors were described and studied in classical antiquity by the mathematician Diocles in his work "On Burning Mirrors". Ptolemy conducted a number of experiments with curved polished iron mirrors, and discussed plane, convex spherical, and concave spherical mirrors in his "Optics". Parabolic mirrors were also described by the physicist Ibn Sahl in the tenth century, and Ibn al-Haytham discussed concave and convex mirrors in both cylindrical and spherical geometries, carried out a number of experiments with mirrors, and solved the problem of finding the point on a convex mirror at which a ray coming from one point is reflected to another point. By the 11th century, glass mirrors were being produced in Moorish Spain.

In China, people began making mirrors by coating metallic objects with silver-mercury amalgams as early as 500 AD. This was accomplished by coating the mirror with the amalgam, and then heating it until the mercury boiled away, leaving only the silver behind.

The problems of making metal-coated, glass mirrors were due to the difficulties in making glass that was very clear, as most ancient glass was tinted green from iron or other colors from various metallic-impurities. Lack of adequate heating temperatures also produced glass that was clouded with microscopic bubbles, so most ancient glass was typically translucent rather than transparent, and used mostly as jewelry until the advent of glass blowing around the first century. These problems were overcome when people began mixing soda, limestone, potash, manganese, and fern ashes with the glass sometime around the 1600s, which lowered the melting temperature needed and augmented the natural iron-impurities, forming soda-lime glass. There was also no way for the ancients to make flat panes of glass with uniform thicknesses. The earliest methods for producing glass panes began in France, when people began blowing glass bubbles, and then spinning them rapidly to flatten them out into plates from which pieces could be cut. However, these pieces were still not uniform in thickness, so produced distorted images as well. A better method was to blow a cylinder of glass, cut off the ends, slice it down the center, and unroll it onto a flat hearth. This method produced the first mirror-quality glass panes, but it was very difficult and resulted in a lot of breakage. Even windows were primarily made of oiled paper or stained glass, until the mid-nineteenth century, due to the high cost of making clear, flat panes of glass.

The method of making flat panes of clear glass from blown cylinders began in Germany and evolved through the Middle Ages, until being perfected by the Venetians in the sixteenth century. The Venetians began using lead glass for its crystal-clarity and its easier workability. Some time during the early Renaissance, European manufacturers perfected a superior method of coating glass with a tin-mercury amalgam, producing an amorphous coating with better reflectivity than crystalline metals and causing little thermal shock to the glass. The exact date and location of the discovery is unknown, but in the sixteenth century, Venice, a city famed for its glass-making expertise, became a center of mirror production using this new technique. Glass mirrors from this period were extremely expensive luxuries. For example, in the late seventeenth century, the Countess de Fiesque was reported to have traded an entire wheat farm for a mirror, considering it a bargain. These Venetian mirrors were limited in size to a maximum area of around square, until modern glass panes began to be produced during the Industrial Revolution. The Saint-Gobain factory, founded by royal initiative in France, was an important manufacturer, and Bohemian and German glass, often rather cheaper, was also important.

The invention of the silvered-glass mirror is credited to German chemist Justus von Liebig in 1835. His process involved the deposition of a thin layer of metallic silver onto glass through the chemical reduction of silver nitrate. This silvering process was adapted for mass manufacturing and led to the greater availability of affordable mirrors. In the modern age, mirrors are often produced by the wet deposition of silver, or sometimes nickel or chromium (the latter used most often in automotive mirrors) via electroplating directly onto the glass substrate.

Vacuum deposition began with the study of the sputtering phenomenon during the 1920s and 1930s, which was a common problem in gas discharge lamps in which metal ejected from the electrodes coated the glass, blocking output. However, turning sputtering into a reliable method of coating a mirror did not occur until the invention of semiconductors in the 1970s. Evaporation coating, pioneered by Pohl and Pringsheim in 1912, resulted from a similar problem in incandescent light bulbs in which the filament would slowly sublimate when heated in a vacuum, coating the cooler glass surface. Aluminum was a desirable material for mirrors, but was too dangerous to apply with electroplating. John D. Strong used evaporation coating to make the first aluminum telescope mirrors in the 1930s. The first dielectric mirror was created in 1937 by Auwarter using evaporated rhodium, while the first metallic mirror to be enhanced with a dielectric coating of silicon dioxide was created by Hass the same year. In 1939 at the Schott Glass company, Walter Geffcken invented the first dielectric mirrors to use multilayer coatings (stacks).

Mirrors are manufactured by applying a reflective coating to a suitable substrate. The most common substrate is glass, due to its transparency, ease of fabrication, rigidity, hardness, and ability to take a smooth finish. The reflective coating is typically applied to the back surface of the glass, so that the reflecting side of the coating is protected from corrosion and accidental damage by the glass on one side and the coating itself and optional paint for further protection on the other.

In classical antiquity, mirrors were made of solid metal (bronze, later silver) and were generally too expensive for use by common people, although during the Roman Empire even maid servants used widespread silver mirrors; they were also prone to corrosion. Due to the low reflectivity of polished metal, these mirrors also gave a darker image than modern ones, making them unsuitable for indoor use with the artificial lighting of the time (candles or lanterns).

The method of making mirrors out of plate glass was invented by 13th-century Venetian glassmakers on the island of Murano, who covered the back of the glass with an amorphous coat of tin using a fire-gilding technique, obtaining near-perfect and undistorted reflection. For over one hundred years, Venetian mirrors installed in richly decorated frames served as luxury decorations for palaces throughout Europe, but the secret of the mercury process eventually arrived in London and Paris during the 17th century, due to industrial espionage. French workshops succeeded in large-scale industrialization of the process, eventually making mirrors affordable to the masses, although mercury's toxicity (a primary ingredient in gilding, which was boiled away forming noxious vapors) remained a problem.

In modern times, the mirror substrate is shaped, polished and cleaned, and is then coated. Glass mirrors are most often coated with silver or aluminium, implemented by a series of coatings:


The tin(II) chloride is applied because silver will not bond with the glass. The activator causes the tin/silver to harden. Copper is added for long-term durability. The paint protects the coating on the back of the mirror from scratches and other accidental damage.

In some applications, generally those that are cost-sensitive or that require great durability, such as for mounting in a prison cell, mirrors may be made from a single, bulk material such as polished metal. However, metals consist of small crystals (grains) separated by grain boundaries. Thus, crystalline metals do not reflect with perfect uniformity. Other methods like wet-deposition or electroplating produce a non-crystalline coating of amorphous metal (metallic glass). Lacking any grain boundaries, the amorphous coatings have higher reflectivity than crystalline metals of the same type. Electroplating must be performed by first coating the glass with carbon, to make the surface electrically conductive, thus the adhesion is often not as good as with wet-deposition. Both lack the ability to produce perfectly uniform thicknesses with high precision. When high precision or reflectivity is not a requirement, the coating may be placed on the back of the mirror so that the light passes through the glass, and the coating is the second surface it encounters. Therefore, these are called second-surface mirrors, which have the added benefit of high durability, because the glass substrate can protect the coating from damage.

For technical applications such as laser mirrors, the reflective coating is typically applied by vacuum deposition. Vacuum deposition provides an effective means of producing a very uniform coating, and controlling the thickness with high precision. In applications where great precision and low losses are required, the coated side of the mirror may be the first material encountered by the light, referred to as a first-surface mirror. This eliminates refraction and double reflections, also called "ghost reflections" (a weak reflection from the surface of the glass, and a stronger one from the reflecting metal), and reduces absorption of light by the mirror. Technical mirrors may use a silver, aluminium, or gold coating (the latter typically for infrared mirrors), and achieve reflectivities of 90–95% when new. A hard, protective, transparent overcoat may be applied to prevent oxidation of the reflective layer and scratching of the soft metal.

Applications requiring higher reflectivity or greater durability, where wide bandwidth is not essential, use dielectric coatings, which can achieve reflectivities as high as 99.997% over a limited range of wavelengths. Because they are often chemically stable and do not conduct electricity, dielectric coatings are almost always applied by methods of vacuum deposition, and most commonly by evaporation deposition. Because the coatings are usually transparent, absorption losses are negligible. Unlike with metals, the reflectivity of the individual dielectric-coatings is a function of Snell's law known as the Fresnel equations, determined by the difference in refractive index between layers. Therefore, the thickness and index of the coatings can be adjusted to be centered on any wavelength. Vacuum deposition can be achieved in a number of ways, including sputtering, evaporation deposition, arc deposition, reactive-gas deposition, and ion plating, among many others.

Mirrors can be manufactured to a wide range of engineering tolerances, including reflectivity, surface quality, surface roughness, or transmissivity, depending on the desired application. These tolerances can range from low, such as found in a normal household-mirror, to extremely high, like those used in lasers or telescopes. Increasing the tolerances allows better and more precise imaging or beam transmission over longer distances. In imaging systems this can help reduce anomalies (artifacts), distortion or blur, but at a much higher cost. Where viewing distances are relatively close or high precision is not a concern, lower tolerances can be used to make effective mirrors at affordable costs.

The reflectivity of a mirror is determined by the percentage of reflected light per the total of the incident light. The reflectivity may vary with wavelength. All or a portion of the light not reflected is absorbed by the mirror, while in some cases a portion may also transmit through. Although some small portion of the light will be absorbed by the coating, the reflectivity is usually higher for first-surface mirrors, eliminating both reflection and absorption losses from the substrate. The reflectivity is often determined by the type and thickness of the coating. When the thickness of the coating is sufficient to prevent transmission, all of the losses occur due to absorption. Aluminum is harder, less expensive, and more resistant to tarnishing than silver, and will reflect 85 to 90% of the light in the visible to near-ultraviolet range, but experiences a drop in its reflectance between 800 and 900 nm. Gold is very soft and easily scratched, costly, yet does not tarnish. Gold is greater than 96% reflective to near and far-infrared light between 800 and 12000 nm, but poorly reflects visible light with wavelengths shorter than 600 nm (yellow). Silver is expensive, soft, and quickly tarnishes, but has the highest reflectivity in the visual to near-infrared of any metal. Silver can reflect up to 98 or 99% of light to wavelengths as long as 2000 nm, but loses nearly all reflectivity at wavelengths shorter than 350 nm. Dielectric mirrors can reflect greater than 99.99% of light, but only for a narrow range of wavelengths, ranging from a bandwidth of only 10 nm to as wide as 100 nm for tunable lasers. However, dielectric coatings can also enhance the reflectivity of metallic coatings and protect them from scratching or tarnishing. Dielectric materials are typically very hard and relatively cheap, however the number of coats needed generally makes it an expensive process. In mirrors with low tolerances, the coating thickness may be reduced to save cost, and simply covered with paint to absorb transmission.

Surface quality, or surface accuracy, measures the deviations from a perfect, ideal surface shape. Increasing the surface quality reduces distortion, artifacts, and aberration in images, and helps increase coherence, collimation, and reduce unwanted divergence in beams. For plane mirrors, this is often described in terms of flatness, while other surface shapes are compared to an ideal shape. The surface quality is typically measured with items like interferometers or optical flats, and are usually measured in wavelengths of light (λ). These deviations can be much larger or much smaller than the surface roughness. A normal household-mirror made with float glass may have flatness tolerances as low as 9–14λ per inch (25.4 mm), equating to a deviation of 5600 through 8800 nanometers from perfect flatness. Precision ground and polished mirrors intended for lasers or telescopes may have tolerances as high as λ/50 (1/50 of the wavelength of the light, or around 12 nm) across the entire surface. The surface quality can be affected by factors such as temperature changes, internal stress in the substrate, or even bending effects that occur when combining materials with different coefficients of thermal expansion, similar to a bimetallic strip.

Surface roughness describes the texture of the surface, often in terms of the depth of the microscopic scratches left by the polishing operations. Surface roughness determines how much of the reflection is specular and how much diffuses, controlling how sharp or blurry the image will be.

For perfectly specular reflection, the surface roughness must be kept smaller than the wavelength of the light. Microwaves, which sometimes have a wavelength greater than an inch (~25 mm) can reflect specularly off a metal screen-door, continental ice-sheets, or desert sand, while visible light, having wavelengths of only a few hundred nanometers (a few hundred-thousandths of an inch), must meet a very smooth surface to produce specular reflection. For wavelengths that are approaching or are even shorter than the diameter of the atoms, such as X-rays, specular reflection can only be produced by surfaces that are at a grazing incidence from the rays.

Surface roughness is typically measured in microns, wavelength, or grit size, with ~80,000–100,000 grit or ~½λ–¼λ being "optical quality".

Transmissivity is determined by the percentage of light transmitted per the incident light. Transmissivity is usually the same from both first and second surfaces. The combined transmitted and reflected light, subtracted from the incident light, measures the amount absorbed by both the coating and substrate. For transmissive mirrors, such as one-way mirrors, beam splitters, or laser output couplers, the transmissivity of the mirror is an important consideration. The transmissivity of metallic coatings are often determined by their thickness. For precision beam-splitters or output couplers, the thickness of the coating must be kept at very high tolerances to transmit the proper amount of light. For dielectric mirrors, the thickness of the coat must always be kept to high tolerances, but it is often more the number of individual coats that determine the transmissivity. For the substrate, the material used must also have good transmissivity to the chosen wavelengths. Glass is a suitable substrate for most visible-light applications, but other substrates such as zinc selenide or synthetic sapphire may be used for infrared or ultraviolet wavelengths.

Wedge errors are caused by the deviation of the surfaces from perfect parallelism. An optical wedge is the angle formed between two plane-surfaces (or between the principle planes of curved surfaces) due to manufacturing errors or limitations, causing one edge of the mirror to be slightly thicker than the other. Nearly all mirrors and optics with parallel faces have some slight degree of wedge, which is usually measured in seconds or minutes of arc. For first-surface mirrors, wedges can introduce alignment deviations in mounting hardware. For second-surface or transmissive mirrors, wedges can have a prismatic effect on the light, deviating its trajectory or, to a very slight degree, its color, causing chromatic and other forms of aberration. In some instances, a slight wedge is desirable, such as in certain laser systems where stray reflections from the uncoated surface are better dispersed than reflected back through the medium.

Surface defects are small-scale, discontinuous imperfections in the surface smoothness. Surface defects are larger (in some cases much larger) than the surface roughness, but only affect small, localized portions of the entire surface. These are typically found as scratches, digs, pits (often from bubbles in the glass), sleeks (scratches from prior, larger grit polishing operations that were not fully removed by subsequent polishing grits), edge chips, or blemishes in the coating. These defects are often an unavoidable side-effect of manufacturing limitations, both in cost and machine precision. If kept low enough, in most applications these defects will rarely have any adverse effect, unless the surface is located at an image plane where they will show up directly. For applications that require extremely low scattering of light, extremely high reflectance, or low absorption due to high energy-levels that could destroy the mirror, such as lasers or Fabry-Perot interferometers, the surface defects must be kept to a minimum.

Mirrors are commonly used as aids to personal grooming. They may range from small sizes, good to carry with oneself, to full body sized; they may be handheld, mobile, fixed or adjustable. A classic example of the latter is the cheval glass, which may be tilted.




With the sun as light source, a mirror can be used to signal by variations in the orientation of the mirror. The signal can be used over long distances, possibly up to on a clear day. This technique was used by Native American tribes and numerous militaries to transmit information between distant outposts.

Mirrors can also be used for search to attract the attention of search and rescue parties. Specialized type of mirrors are available and are often included in military survival kits.

Microscopic mirrors are a core element of many of the largest high-definition televisions and video projectors. A common technology of this type is Texas Instruments' DLP. A DLP chip is a postage stamp-sized microchip whose surface is an array of millions of microscopic mirrors. The picture is created as the individual mirrors move to either reflect light toward the projection surface (pixel on), or toward a light absorbing surface (pixel off).

Other projection technologies involving mirrors include LCoS. Like a DLP chip, LCoS is a microchip of similar size, but rather than millions of individual mirrors, there is a single mirror that is actively shielded by a liquid crystal matrix with up to millions of pixels. The picture, formed as light, is either reflected toward the projection surface (pixel on), or absorbed by the activated LCD pixels (pixel off). LCoS-based televisions and projectors often use 3 chips, one for each primary color.

Large mirrors are used in rear projection televisions. Light (for example from a DLP as mentioned above) is "folded" by one or more mirrors so that the television set is compact.

Mirrors are integral parts of a solar power plant. The one shown in the adjacent picture uses concentrated solar power from an array of parabolic troughs.

Telescopes and other precision instruments use "front silvered" or first surface mirrors, where the reflecting surface is placed on the front (or first) surface of the glass (this eliminates reflection from glass surface ordinary back mirrors have). Some of them use silver, but most are aluminium, which is more reflective at short wavelengths than silver.
All of these coatings are easily damaged and require special handling.
They reflect 90% to 95% of the incident light when new.
The coatings are typically applied by vacuum deposition.
A protective overcoat is usually applied before the mirror is removed from the vacuum, because the coating otherwise begins to corrode as soon as it is exposed to oxygen and humidity in the air. "Front silvered" mirrors have to be resurfaced occasionally to keep their quality. There are optical mirrors such as mangin mirrors that are "second surface mirrors" (reflective coating on the rear surface) as part of their optical designs, usually to correct optical aberrations.

The reflectivity of the mirror coating can be measured using a reflectometer and for a particular metal it will be different for different wavelengths of light. This is exploited in some optical work to make cold mirrors and hot mirrors. A cold mirror is made by using a transparent substrate and choosing a coating material that is more reflective to visible light and more transmissive to infrared light.

A hot mirror is the opposite, the coating preferentially reflects infrared. Mirror surfaces are sometimes given thin film overcoatings both to retard degradation of the surface and to increase their reflectivity in parts of the spectrum where they will be used. For instance, aluminum mirrors are commonly coated with silicon dioxide or magnesium fluoride. The reflectivity as a function of wavelength depends on both the thickness of the coating and on how it is applied.

For scientific optical work, dielectric mirrors are often used. These are glass (or sometimes other material) substrates on which one or more layers of dielectric material are deposited, to form an optical coating. By careful choice of the type and thickness of the dielectric layers, the range of wavelengths and amount of light reflected from the mirror can be specified. The best mirrors of this type can reflect >99.999% of the light (in a narrow range of wavelengths) which is incident on the mirror. Such mirrors are often used in lasers.

In astronomy, adaptive optics is a technique to measure variable image distortions and adapt a deformable mirror accordingly on a timescale of milliseconds, to compensate for the distortions.

Although most mirrors are designed to reflect visible light, surfaces reflecting other forms of electromagnetic radiation are also called "mirrors". The mirrors for other ranges of electromagnetic waves are used in
optics and astronomy. Mirrors for radio waves (sometimes known as reflectors) are important elements of radio telescopes.

Two or more mirrors aligned exactly parallel and facing each other can give an infinite regress of reflections, called an infinity mirror effect. Some devices use this to generate multiple reflections:

It has been said that Archimedes used a large array of mirrors to burn Roman ships during an attack on Syracuse. This has never been proven or disproved. On the TV show "MythBusters", a team from MIT tried to recreate the famous "Archimedes Death Ray". They were unsuccessful at starting a fire on the ship. Previous attempts to light the boat on fire using only the bronze mirrors available in Archimedes' time were unsuccessful, and the time taken to ignite the craft would have made its use impractical, resulting in the "MythBusters" team deeming the myth "busted". It was however found that the mirrors made it very difficult for the passengers of the targeted boat to see, likely helping to cause their defeat, which may have been the origin of the myth. (See solar power tower for a practical use of this technique.)

Due to its location in a steep-sided valley, the Italian town of Viganella gets no direct sunlight for seven weeks each winter. In 2006 a €100,000 computer-controlled mirror, 8×5 m, was installed to reflect sunlight into the town's piazza. In early 2007 the similarly situated village of Bondo, Switzerland, was considering applying this solution as well. In 2013, mirrors were installed to reflect sunlight into the town square in the Norwegian town of Rjukan. Mirrors can be used to produce enhanced lighting effects in greenhouses or conservatories.

Mirrors are a popular design theme in architecture, particularly with late modern and post-modernist high-rise buildings in major cities. Early examples include the Campbell Center in Dallas, which opened in 1972, and the John Hancock Tower in Boston.

More recently, two skyscrapers designed by architect Rafael Viñoly, the Vdara in Las Vegas and 20 Fenchurch Street in London, have experienced unusual problems due to their concave curved glass exteriors acting as respectively cylindrical and spherical reflectors for sunlight. In 2010, the Las Vegas Review Journal reported that sunlight reflected off the Vdara's south-facing tower could singe swimmers in the hotel pool, as well as melting plastic cups and shopping bags; employees of the hotel referred to the phenomenon as the "Vdara death ray", aka the "fryscraper." In 2013, sunlight reflecting off 20 Fenchurch Street melted parts of a Jaguar car parked nearby and scorching or igniting the carpet of a nearby barber shop. This building had been nicknamed the "walkie-talkie" because its shape was supposedly similar to a certain model of two-way radio; but after its tendency to overheat surrounding objects became known, the nickname changed to the "walkie-scorchie."

Painters depicting someone gazing into a mirror often also show the person's reflection. This is a kind of abstraction—in most cases the angle of view is such that the person's reflection should not be visible. Similarly, in movies and still photography an actor or actress is often shown ostensibly looking at him- or herself in the mirror, and yet the reflection faces the camera. In reality, the actor or actress sees only the camera and its operator in this case, not their own reflection. In the psychology of perception, this is known as the Venus effect.

The mirror is the central device in some of the greatest of European paintings:

Mirrors have been used by artists to create works and hone their craft:

Mirrors are sometimes necessary to fully appreciate art work:

Contemporary anamorphic artist Jonty Hurwitz uses cylindrical mirrors to project distorted sculptures.

Some other contemporary artists use mirrors as the material of art:

In the Middle Ages mirrors existed in various shapes for multiple uses. Mostly they were used as an accessory for personal hygiene but also as tokens of courtly love, made from ivory in the ivory carving centers in Paris, Cologne and the Southern Netherlands. They also had their uses in religious contexts as they were integrated in a special form of pilgrims badges or pewter/lead mirror boxes since the late 14th century. Burgundian ducal inventories show us that the dukes owned a mass of mirrors or objects with mirrors, not only with religious iconography or inscriptions, but combined with reliquaries, religious paintings or other objects that were distinctively used for personal piety. Considering mirrors in paintings and book illumination as depicted artifacts and trying to draw conclusions about their functions from their depicted setting, one of these functions is to be an aid in personal prayer to achieve self-knowledge and knowledge of God, in accord with contemporary theological sources. E.g. the famous Arnolfini-Wedding by Jan van Eyck shows a constellation of objects that can be recognized as one which would allow a praying man to use them for his personal piety: the mirror surrounded by scenes of the Passion to reflect on it and on oneself, a rosary as a device in this process, the veiled and cushioned bench to use as a prie-dieu, and the abandoned shoes that point in the direction in which the praying man kneeled. The metaphorical meaning of depicted mirrors is complex and many-layered, e.g. as an attribute of Mary, the “speculum sine macula”, or as attributes of scholarly and theological wisdom and knowledge as they appear in book illuminations of different evangelists and authors of theological treatises. Depicted mirrors – orientated on the physical properties of a real mirror – can be seen as metaphors of knowledge and reflection and are thus able to remind the beholder to reflect and get to know himself. The mirror may function simultaneously as a symbol and a device of a moral appeal. That is also the case if it is shown in combination with virtues and vices, a combination which also occurs more frequently in the 15th century: The moralizing layers of mirror metaphors remind the beholder to examine himself thoroughly according to his own virtuous or vicious life. This is all the more true if the mirror is combined with iconography of death. Not only is Death as a corpse or skeleton holding the mirror for the still living personnel of paintings, illuminations and prints, but the skull appears on the convex surfaces of depicted mirrors, showing the painted and real beholder his future face.

Mirrors are frequently used in interior decoration and as ornaments:



Mirrors play a powerful role in cultural literature.

Only a few animal species have been shown to have the ability to recognize themselves in a mirror, most of them mammals. Experiments have found that the following animals can pass the mirror test:

Other types of reflecting device are also called mirrors.





</doc>
<doc id="20546" url="https://en.wikipedia.org/wiki?curid=20546" title="Mindanao">
Mindanao

Mindanao (), or still commonly known as Southern Philippines, is the second-largest island in the Philippines. Mindanao and the smaller islands surrounding it make up the island group of the same name. Located in the southern region of the archipelago, as of the 2010 census, the main island was inhabited by 20,281,545 people, while the entire Mindanao island group had an estimated total of 25,537,691 (2018) residents.

According to the 2015 Philippine Population Census, Davao City is the most populous city on the island, with a population of 1,632,991 residents, followed by Zamboanga City (pop. 861,799), Cagayan de Oro City (pop. 675,950), General Santos City (pop. 594,446), Iligan City (pop. 342,618), Butuan City (pop. 337,063) and Cotabato City (pop. 299,438). About 70% of residents identify as Christian, and 20% identify as Muslim. Mindanao is divided into six administrative regions: the Zamboanga Peninsula, Northern Mindanao, the Caraga region, the Davao region, Soccsksargen, and the Bangsamoro Autonomous Region in Muslim Mindanao (BARMM).

Native ethnic groups in Mindanao include the Lumads (namely the Subanons of the Zamboanga Peninsula; the Bukidnon, the Ata Manobos, the Mamanwas, the Matigsalugs, the Agusan Manobos, the Talaandigs, the Kamigins, and the Higaonons of Northern Mindanao and the region of Caraga; the T'bolis, the Tirurays, the B'laans, the Saranganis, and the Cotabato Manobos of the region of SOCCSKSARGEN; and the Obo, the Mandayas, the Giangans, the Tagabawas, the Kalagans, the Sangirese, and the Mansaka of the Davao region) and the Moros (namely the Maguindanaos, the Maranaos, the Tausugs, the Yakans, the Iranuns, and the Sama, mainly concentrated within Bangsamoro). Joining them are the equally indigenous Visayan groups in coastal areas like the Butuanons, Surigaonons, and Kagay-anons of Northern Mindanao and the Caraga region as well as the Zamboangueños of the eponymous peninsula, along with descendants of modern settlers from the Visayas and Luzon (chiefly from the former), among them the Cebuanos and the Hiligaynons.

Mindanao is considered the major breadbasket of the Philippines, with eight of the top 10 agri-commodities exported from the Philippines coming from the island group itself.

Mindanao is known for its moniker being "The Philippines' Land of Promise".

The name "Mindanao" is derived from the Spanish corruption of the name of the Maguindanao people, the dominant ruling ethnic group in the Sultanate of Maguindanao in southwestern Mindanao during the Spanish colonial period. The name itself means "people of the lake (Lanao)", though it is usually translated to "people of the flood plains" in modern sources.

Archaeological findings on the island point to evidence of human activity dating back to about ten thousand years ago. At around 1500 BC Austronesian people spread throughout the Philippines.

The Subanon are believed to have established themselves on Mindanao Island during the Neolithic Era, or New Stone Age, the period in the development of human technology beginning around 10,000 BC according to the ASPRO chronology (between 4,500 and 2,000 BC). The evidence of old stone tools in Zamboanga del Norte may indicate a late Neolithic presence. Ceramic burial jars, both unglazed and glazed, as well as Chinese celadons, have been found in caves, together with shell bracelets, beads, and gold ornaments. Many of the ceramic objects are from the Yuan and Ming periods. Evidently, there was a long history of trade between the Subanon and the Chinese long before the latter's contact with Islam.

In the classic epoch of Philippine history (900 AD onwards), the people of Mindanao were heavily exposed to Hindu and Buddhist influence and beliefs from Indonesia and Malaysia. Indianized abugida scripts such as Kawi and Baybayin was introduced via Sulawesi and Java, and the cultural icons of the sarong (known as malong or patadyong), the pudong turban, silk, and batik and ikat weaving and dyeing methods were introduced. Artifacts found from this era include the Golden kinnara, Golden Tara, and the Ganesh pendant. These cultural traits passed from Mindanao into the Visayas and Luzon, but were subsequently lost or heavily modified after the Spanish arrival in the 16th century.

The Hindu-Buddhist cultural revolution was strongest in the coastal areas of the island, but were incorporated into local animist beliefs and customs tribes that resided more inland. The Rajahnate of Butuan, a fully Hindu kingdom mentioned in Chinese records as a tributary state in the 10th century AD, was concentrated along the northeastern coast of the island around Butuan. The Darangen epic of the Maranao people harkens back to this era as the most complete local version of the Ramayana. The Maguindanao at this time also had strong Hindu beliefs, evidenced by the Ladya Lawana (Rajah Ravana) epic saga that survives to the modern day, albeit highly Islamized from the 17th century on wards.

The spread of Islam in the Philippines began in the 14th century, mostly by Muslim merchants from the western part of the Malay Archipelago. The first Mosque in the Philippines was built in the mid-14th century in the town of Simunul, Tawi-Tawi. Around the 16th century, the Muslim sultanates of Sulu, Lanao and Maguindanao were established from formerly Hindu-Buddhist Rajahnates. 

As Islam gained a foothold over Mindanao, the natives residing within the Sultanates were either converted into Islam or obligated to pay tribute to their new Muslim rulers. The largest of the Muslim polities in mainland Mindanao was the Sultanate of Maguindanao which controlled the southern floodplains of the Rio Grande de Mindanao and most of the coastal area of the Illana Bay and the Moro Gulf. The name Mindanao was derived from this Sultanate. However, most of Mindanao remained animist, especially the Lumad people living in the interior regions. Most of the northern, eastern, and southern coastal regions inhabited by Visayans (Surigaonon and Butuanon) and other groups were also converted to Christianity by the Spanish later on.

In 1521 Antonio Pigafetta wrote an account of reaching 'Maingdano.' He was with Magellan on the first circumnavigation of the globe and they were sailing for the king of Spain.

On 2 February 1543, Ruy Lopez de Villalobos was the first Spaniard to reach Mindanao, he called the island ""Caesarea Caroli"" after Charles V of the Holy Roman Empire (and I of Spain). Shortly after Spain's colonization of Cebu, they moved on to colonize Butuan and the surrounding Caraga region in northeast Mindanao and discovered significant Muslim presence on the island. Over time a number of tribes in Mindanao converted to Roman Catholicism and built settlements and forts throughout the coastal regions of the island. These settlements endured despite incurring attacks from neighboring Muslim Sultanates. The most heavily fortified of these settlements, apart from a short period in 1662 when Spain sent soldiers from the city to Manila after receiving a threat of invasion from the Chinese general Koxinga, was Zamboanga City.

By the late 18th century Spain had geographic dominance over the island, having established settlements and forts in most of Mindanao; including Zamboanga City (Which was then settled by Peruvian soldiers) and Misamis Occidental to the northwest, Iligan City, Misamis Oriental, Bukidnon, and Camiguin Island to the north, Butuan and the Caraga region to the east, and Davao in the island's gulf coast. Spain continued to engage in battles with Muslim Sultanates until the end of the 19th century.

In the Treaty of Paris in 1898 Spain sold the entire Philippine archipelago to the United States for $20 million. The 1900 Treaty of Washington and the 1930 Convention Between the United States and Great Britain clarified the borders between Mindanao and Borneo.

In 1939 the Philippine government encouraged citizens from Luzon and Visayas to migrate to Mindanao. Consisting mostly of Ilocanos, Cebuanos, and Illongos. Filipino settlers streaming into Soccsksargen led to the displacement of the Blaan and Tboli tribes.

In April 1942 Mindanao, along with the rest of the Philippines, officially entered World War II after Japanese soldiers invaded key cities in the islands. Many towns and cities were burned to the ground in Mindanao, most notably Davao City, Zamboanga City, Lanao, Cagayan de Oro, Iligan City, and Butuan. In the months of April and May 1942, Japanese forces defeated US troops commanded by Gen. William F. Sharp and Gen. Guy O. Fort, in a battle that started at Malabang (a town close to Gandamatu Macadar, Lanao) and ended close to the town of Ganassi, Lanao. Davao City was among the earliest to be occupied by the invading Japanese Forces. They immediately fortified the city as a bastion of the Japanese defense system.

Davao City was subjected by the returning forces of Gen. Macarthur to constant bombing, before the American Liberation Forces landed in Leyte in October 1944. Filipino soldiers and local guerrilla fighters were actively fighting Japanese forces until liberation at the conclusion of the Battle of Mindanao.

Violent conflicts in the southwestern regions of Mindanao, that began in the 1960s, led to the 1971 Manili Massacre, Pata Island Massacre, the founding of the Moro National Liberation Front (MNLF), Moro Islamic Liberation Front (MILF), and the formation of the Ilaga.

Under President Ferdinand Marcos's administration, the government was said to have encouraged Christian settlers in Mindanao, causing many locals to be displaced. The forced land seizures by Luzon and Visayan settlers have resulted in ongoing conflict as the original owners seek ancestral land reclamation.

In March 2000 President Estrada declared an "All Out War" against the Moro Islamic Liberation Front (MILF), after the militant group committed a series of terrorist attacks on government buildings, civilians, and foreigners. A number of livelihood intervention projects, from organisations such as USAID and the Emergency Livelihood Assistance Program (ELAP), aided in the reconstruction of areas affected by constant battles on the island.

In December 2009, President Gloria Macapagal Arroyo officially placed Maguindanao under a state of martial law following the Maguindanao Massacre.

Tropical storm Sendong (international name, Washi) made landfall on 15 December 2011 in Mindanao. The recorded 24-hour rainfall in Lumbia station of PAGASA reached 180.9 mm causing the overflow of the Cagayan de Oro River. The deadly storm killed 1,268 people with 49 others listed as missing. Most of the casualties were from the cities of Cagayan de Oro and Iligan. Those who survived were rendered homeless, seeking shelter in evacuation centers.

In May 2017, President Rodrigo Duterte declared martial law on the entire island group of Mindanao following the Marawi siege by the Maute terrorist group. Thousands of civilians were killed by the terrorist group during the siege, and more than 180,000 people were forced to evacuate Marawi City.

Mindanao's economy accounts for 14% of the country's gross domestic product. The region grew 4.9% in 2016 against Luzon's 5.5% and Visayas' 9.1%.

Agriculture, forestry and fishing make up more than 40% of Mindanao's market, being the country's largest supplier of major crops such as pineapples and bananas.

There are 2 defined growth corridors in the island namely Metro Davao and Metro CDO. Other regional centers are: Zamboanga City, General Santos City, Butuan City, Cotabato City, Dipolog City, Jolo, Surigao City, Pagadian City, Koronadal City, and Tagum City.

Being the top-performing economy in Mindanao, Davao Region has the 5th-biggest economy in the country and the second-fastest-growing economy next to Cordillera Autonomous Region. While the region's economy is predominantly agri-based, it is now developing into a center for agro-industrial business, trade and tourism. Its competitive advantage is in agri-industry as its products, papayas, mangoes, bananas, pineapples, fresh asparagus, flowers, and fish products are exported internationally. The region can be a vital link to markets in other parts of Mindanao, Brunei Darussalam and parts of Malaysia and Indonesia. 

There is also a growing call center sector in the region, mostly centered in Davao City.

Some 2,130 government-led infrastructure projects worth P547.9 billion have also been lined up for Mindanao until 2022.

NEDA official said that 68% of that budget will be allotted for the transportation sector, while 16% will go to water resources, and 6% to social infrastructure.

Of this amount, 18 infrastructure projects have been identified as "flagship projects," five of them have already been approved by President Rodrigo R. Duterte.

The projects include the ₱35.26 billion Tagum-Davao-Digos Segment of the Mindanao Railway, the ₱40.57 billion Davao airport, the ₱14.62 billion Laguindingan airport, the ₱4.86 billion Panguil Bay Bridge Project, and the ₱5.44 billion Malitubog-Maridagao Irrigation Project, Phase II.

Projects in the pipeline are the second and third phases of the Mindanao Railway; the Agus-Pulangi plant rehabilitation; the Davao expressway; the Zamboanga Fish Port Complex rehabilitation; the Balo-i Plains Flood Control Project; Asbang Small Reservoir Irrigation Project; the Ambal Simuay Sub-Basin of the Mindanao River Basin Flood Control and River Protection Project; as well as the Road Network Development Project in Conflict-Affected Areas in Mindanao project.

The island consists of 6 administrative regions, 22 provinces, and 30 cities (27 provinces and 33 cities if associated islands are included).

The list of largest cities and municipalities in Mindanao in terms of population is shown in the table below.
Mindanao is the second-largest island in the Philippines at 97,530 square kilometers, and is the eighth-most populous island in the world. The island of Mindanao is larger than 125 countries worldwide, including the Netherlands, South Korea, Austria, Portugal, Czechia, Hungary, and Ireland. The island is mountainous, and is home to Mount Apo, the highest mountain in the country. Mindanao is surrounded by four seas: the Sulu Sea to the west, the Philippine Sea to the east, and the Celebes Sea to the south, and the Mindanao Sea to the north. Of all the islands of the Philippines, Mindanao shows the greatest variety of physiographic development. High, rugged, faulted mountains; almost isolated volcanic peaks; high rolling plateaus; and broad, level, swampy plains are found there.

The Mindanao island group is an arbitrary grouping of islands in southern Philippines which comprises the Mindanao mainland, the Sulu Archipelago (consisting of the islands of Basilan, Sulu, and Tawi-tawi), and the outlying islands of Camiguin, Dinagat, Siargao, and Samal.
Platycerium grande is endemic to the island
The mountains of Mindanao can be grouped into ten ranges, including both complex structural mountains and volcanoes. The structural mountains on the extreme eastern and western portions of the island show broad exposures of Mesozoic rock, and Ultrabasic rocks at the surface in many places along the east coast. Other parts of the island consist mainly of Cenozoic and Quaternary volcanic or sedimentary rocks.

In the eastern portion of the island, from Bilas Point in Surigao del Norte to Cape San Agustin in Davao Oriental, is a range of complex mountains known in their northern portion as the Diwata Mountains. This range is low and rolling in its central portion. A proposed road connecting Bislig on the east coast with the Agusan River would pass through of broad saddle across the mountains at a maximum elevation of less than ; while the existing east–west road from Lianga, north of Bislig, reaches a maximum elevation of only . The Diwata Mountains, north of these low points, are considerably higher and more rugged, reaching an elevation of in Mount Hilong-Hilong, along the eastern portion of Cabadbaran City. The southern portion of this range is broader and even more rugged than the northern section. In Davao Oriental, several peaks rise above and one mountain rises to .

The east-facing coastal regions of Davao and Surigao del Sur are marked by a series of small coastal lowlands separated from each other by rugged forelands which extend to the water's edge. Offshore are numerous coral reefs and tiny islets. This remote and forbidding coast is made doubly difficult to access during the months from October to March by the heavy surf driven before the northeast trade winds. A few miles offshore is found the Philippine Deep. This ocean trench, reaching measured depths of , is the third-deepest trench, (after the Mariana Trench and Tonga Trench) on the earth's surface.

A second north–south mountain range extends from Talisayan in the north, to Tinaca Point in the southernmost point of Mindanao. This mountain range runs along the western borders of the Agusan del Norte, Agusan del Sur, and Davao provinces. This range is mainly structural in origin, but it also contains at least three active volcano peaks. The central and northern portions of this range contain several peaks between , and here the belt of mountains is about across.

West of Davao City stand two inactive volcanoes: Mount Talomo at , and Mount Apo at . Mount Apo is the highest point in the Philippines. South of Mount Apo, this central mountain belt is somewhat lower than it is to the north, with peaks averaging only .

In Western Mindanao, a range of complex structural mountains forms the long, hand-like Zamboanga Peninsula. These mountains, reaching heights of only , are not as high as the other structural belts in Mindanao. There are several places in the Zamboanga Mountains where small inter-mountain basins have been created, with some potential for future agricultural development. The northeastern end of this range is marked by the twin peaks of the now-extinct volcano, Mount Malindang, that towers over Ozamis City at a height of . Mount Dapia is the highest mountain in the Zamboanga Peninsula, reaching a height of . Batorampon Point is the highest mountain of the southernmost end of the peninsula, reaching a height of only ; it is located in the boundary of Zamboanga City.

A series of volcanic mountains is located within the vicinity of Lake Lanao forming a broad arc through the Lanao del Sur, Cotabato and Bukidnon provinces. At least six of the twenty odd peaks in this area are active and several stand in semi-isolation. The Butig Peaks, with their four crater lakes, are easily seen from Cotabato. Mount Ragang, an active volcano cone reaching , is the most isolated, while the greatest height is reached by Mount Kitanglad at .

In South Cotabato, is another range of volcanic mountains, this time paralleling the coast. These mountains have a maximum extent of from northwest to southeast and measures some across. One of the well-known mountains here is Mount Parker, whose almost circular crater lake measures a mile-and-a-quarter in diameter and lies below its summit. Mount Matutum is a protected area and is considered as one of the major landmarks in the South Cotabato province.

Another important physiographic division of Mindanao is the series of upland plateaus in the Bukidnon and Lanao del Sur provinces. These plateaus are rather extensive and almost surround several volcanoes in this area. The plateaus are made up of basaltic lava flows inter-bedded with volcanic ash and tuff. Near their edges, the plateaus are cut by deep canyons, and at several points waterfalls drop down to the narrow coastal plain. These falls hold considerable promise for development of hydroelectric energy. Indeed, one such site at Maria Cristina Falls has already become a major producer. The rolling plateaus lie at an elevation averaging 700 meters above sea level, and offer relief from the often oppressive heat of the coastal lowlands.

Lake Lanao occupies a large portion of one such plateau in Lanao del Sur. This lake is the largest lake in Mindanao and the second largest in the country; it is roughly triangular in shape with an base, having a surface at 780 meters above sea level, and is rimmed on the east, south, and west by a series of peaks reaching 2,300 meters. Marawi City, at the northern tip of the lake, is bisected by the Agus River, that feeds the Maria Cristina Falls.

Another of Mindanao's waterfall sites is located in Malabang, south of Lake Lanao. Here the Jose Abad Santos Falls present one of the nation's scenic wonders at the gateway to a 200-hectare national park development.

The Limunsudan Falls, with an approximate height of , is the highest waterfall in the Philippines; it is located in Iligan City.

Mindanao contains two large lowland areas in the valleys of the Agusan River in Agusan, and the Rio Grande de Mindanao in Cotabato City.

There is some indication that the Agusan Valley occupies a broad syncline between the central mountains and the east-coast mountains. This valley measures from south to north and varies from in width. north of the head of Davao Gulf lies the watershed between the Agusan and the tributaries of the Libuganon River, which flows to the Gulf. The elevation of this divide is well under , indicating the almost continuous nature of the lowland from the Mindanao Sea on the north to the Davao Gulf.

The Rio Grande de Mindanao and its main tributaries, the Catisan and the Pulangi, form a valley with a maximum length of and a width which varies from at the river mouth to about in central Cotabato. The southern extensions of this Cotabato Valley extend uninterrupted across a watershed from Illana Bay on the northwest to Sarangani Bay on the southeast.

Other lowlands of a coastal nature are to be found in various parts of Mindanao. Many of these are tiny isolated pockets, along the northwest coast of Zamboanga. In other areas such as the Davao Plain, these coastal lowlands are wide and several times in length.

From Dipolog City eastward along the northern coast of Mindanao approaching Butuan City extends a rolling coastal plain of varying width. In Misamis Occidental, the now dormant Mount Malindang has created a lowland averaging in width. Shallow Panquil Bay divides this province from Lanao del Norte, and is bordered by low-lying, poorly drained lowlands and extensive mangroves. In Misamis Oriental, the plain is narrower and in places whittle into rugged capes that reach the sea. East of Cagayan de Oro, a rugged peninsula extends into the Mindanao Sea.
As of 2017, Mindanao had a population of over 25 million people. This comprises 22.1 percent of the entire population of the country.

An American census conducted in the early 1900s noted that the island was inhabited by people "greatly divided in origin, temperament and religion". Evidence of the island's cultural diversity can be seen in the buildings and ruins of old Spanish settlements in the northwestern peninsula that span eastwards to the southern gulf coast, the site of the ancient Rajahnate of Butuan in the northeast region (Caraga), the Sultanates in the southwest (Sultanate of Sulu, Sultanate of Lanao, Sultanate of Maguindanao), a number of Buddhist and Taoist temples, and the numerous indigenous tribes.

Today around 25.8 percent of the household population in Mindanao classified themselves as Cebuanos. Other ethnic groups included Bisaya/Binisaya (18.4%), Hiligaynon/Ilonggo (8.2%), Maguindanaon (5.5%), and Maranao (5.4%). The remaining 36.6 percent belonged to other ethnic groups. Cebuano registered the highest proportion of ethnic group in Northern Mindanao and Davao Region with 35.59 percent and 37.76 percent, respectively. In SOCCSKSARGEN, it was Hiligaynon/Ilonggo (31.58%), Binisaya/Bisaya (33.10%) in Zamboanga Peninsula, Maranao (26.40%) in ARMM, and Surigaonon (25.67%) in Caraga.

Dozens of languages are spoken in Mindanao; among them, Cebuano, Hiligaynon, Surigaonon, Tausug, Maranao, Maguindanao, and Chavacano are most widely spoken. Of the seven aforementioned regional languages, Cebuano (often referred as Bisaya) has the highest number of speakers, being spoken throughout Northern Mindanao (except the southern parts of Lanao del Norte), the Davao region, the western half of the Caraga region (as well as the city of Bislig and the municipalities surrounding it in Surigao del Sur), the entirety of the Zamboanga Peninsula (with the exception of Zamboanga City), and southern SOCCSKSARGEN. Hiligaynon is the main language of SOCCSKSARGEN, where majority of the inhabitants are of ethnic Hiligaynon stock. Surigaonon is spoken in the eastern half of the Caraga region, mainly by the eponymous Surigaonons. Tausug is widely spoken in the western territories of the ARMM, specifically the Sulu Archipelago, which comprises the provinces of Basilan, Sulu, and Tawi-Tawi, with a sizeable community of speakers residing in Zamboanga City. Maguindanao and Maranao are the dominant languages of the eastern territories of the ARMM, respectively, with the former being spoken in Lanao del Sur as well as the southern areas of Lanao del Norte, and the latter in the eponymous province of Maguindanao and also in adjacent areas which are part of SOCCSKSARGEN. Chavacano is the native language of Zamboanga City and is also the lingua franca of Basilan; it is also spoken in the southernmost fringes of Zamboanga Sibugay. It is also spoken, albeit as a minority language, in Cotabato City and Davao City, where dialects of it, respectively, exist, namely Cotabateñ and Castellano Abakay, both of which evolved from the variant of the language spoken in Zamboanga City. English is also widely understood and spoken, being highly utilized in business and academia.

Christianity is the dominant religious affiliation in Mindanao with 65.9% of the household population, majority of which are adherents of Roman Catholicism, Islam comprised 23.39%, and other religions were Evangelical (5.34%), Aglipayan (2.16%), and Iglesia ni Cristo (2.66%).
Major tourist spots are scattered throughout Mindanao, consisting mostly of beach resorts, scuba diving resorts, surfing, museums, nature parks, mountain climbing, and river rafting. Siargao, best known for its surfing tower in Cloud 9, also has caves, pools, waterfalls, and lagoons. There are archaeological sites, historical ruins, and museums in Butuan. White Island is a popular tourist spot in Camiguin. The Duka Bay and the Matangale dive resorts in Misamis Oriental offer glass bottomed boat rides and scuba diving lessons. Cagayan de Oro has beach resorts, the Mapawa Nature Park, white water rafting and kayaking, museums, and historical landmarks. Ziplining is the main attraction at the Dahilayan Adventure Park in Bukidnon. Iligan City has The Maria Christina Falls, Tinago Falls, nature parks, beaches, and historical landmarks. There are parks, historical buildings, the Vinta Ride at Paseo del Mar, boat villages, 11 Islands (commonly called as "Onçe Islas"), 17th-century Fort Pilar Shrine & Museum and the world-renowned "Pink Sand Beach" of Sta. Cruz in Zamboanga City. There are festivals, fireworks, and the Beras Bird Sanctuary in Takurong City. Davao has Mt Apo, parks, museums, beaches, historical landmarks, and scuba diving resorts.

Many areas in Mindanao suffer rotating 12-hour blackouts due to the island's woefully inadequate power supply. The island is forecast to continue suffering from a 200-megawatt power deficit until 2015, when the private sector begins to operate new capacity. Aboitiz Equity Ventures, a publicly listed holdings company, has committed to supplying 1,200 megawatts through a coal-fired plant on the border of Davao City and Davao del Sur that is slated for operation by 2018. The Agus-Pulangui hydropower complex, which supplies more than half of Mindanao's power supply, is currently producing only 635 megawatts of its 982 megawatts capacity due to the heavy siltation of the rivers that power the complex. Zamboanga City, an urbanised center in southwest Mindanao, is expected to begin experience daily three-hour brownouts due to the National Power Corporation's decision to reduce power supply in the city by 10 megawatts.
The Manila Electric Company (Meralco), the largest power distributor in the Philippines, and Global Business Power Corp (GBPC), also a major provider, have announced plans to enter Mindanao for the first time to establish solutions for the power problems within the island.



</doc>
<doc id="20547" url="https://en.wikipedia.org/wiki?curid=20547" title="Moveable feast">
Moveable feast

A moveable feast or movable feast is an observance in a Christian liturgical calendar that occurs on a different date (relative to the dominant civil or solar calendar) in different years. 

The most important set of moveable feasts are a fixed number of days before or after Easter Sunday, which varies by 35 days since it depends partly on the phase of the moon and must be computed each year. In Eastern Christianity (including the Eastern Orthodox Church, the Oriental Orthodox Churches, the Assyrian Church of the East, and the Eastern Catholic Churches), these moveable feasts form what is called the Paschal cycle, which stands in contrast to the approach taken by Catholic and Protestant Christianity. 

Most other feast days, such as those of particular saints, are "fixed feasts", held on the same date every year. However, some observances are always held on the same day of the week, and thus occur on a range of days without depending on the date of Easter. For example, the start of Advent is the Sunday nearest November 30. In addition, the observance of some fixed feasts may move a few days in a particular year to not clash with that year's date for a more important moveable feast. There are rare examples of saints with genuinely moveable feast days, such as Saint Sarkis the Warrior in the calendar of the Armenian Church.

Moveable feasts in other faiths

Since Islamic feasts (Id ul Adha and Id ul Fitr) are lunar month based, they take place in different solar calendar dates and can, over years occur over all twelve months winter spring summer and autumn



</doc>
<doc id="20548" url="https://en.wikipedia.org/wiki?curid=20548" title="Mark McGwire">
Mark McGwire

Mark David McGwire (born October 1, 1963), nicknamed Big Mac, is an American former professional baseball first baseman. His Major League Baseball (MLB) playing career spanned from 1986 to 2001 while playing for the Oakland Athletics and the St. Louis Cardinals, winning one World Series championship each with Oakland as a player in 1989 and with St. Louis as a coach in 2011. One of the most prolific home run hitters in baseball history, McGwire holds the major league career record for at bats per home run ratio (10.6), and is the former record holder for both home runs in a single season (70 in 1998) and home runs hit by rookie (49 in 1987). 

He ranks 11th all time in home runs with 583, and led the major leagues in home runs in five different seasons, while establishing the major league record for home runs hit in a four-season period from 1996 to 1999 with 245. Further, he demonstrated exemplary patience as a batter, producing a career .394 on-base percentage (OBP) and twice leading the major leagues in bases on balls. Injuries cut short the manifestation of even greater potential as he reached 140 games played in just eight of 16 total seasons. A right-handed batter and thrower, McGwire stood tall and weighed during his playing career.

Born in Pomona, California, McGwire was selected by the Athletics with the 10th overall selection in the 1984 MLB draft, and he was a member of the silver medal-winning entry of the United States national team that same year at the Summer Olympics in Los Angeles, with Japan finishing ahead for gold medal. 

As a rookie in 1987, he quickly grabbed media attention with 33 home runs before the All-Star break, and led the major leagues in home runs that year with 49, which was a single-season rookie home run record. He appeared in six straight All-Star Games from 1987 to 1992 despite a brief career decline related to injuries. Another string of six consecutive All-Star appearances followed from 1995 to 2001. Each season from 1996 to 1999, he again led the major leagues in home runs.

A part of the 1998 Major League Baseball home run record chase of Roger Maris' 61 with the Cardinals, McGwire set the major league single-season home run record with 70, which Barry Bonds broke three years later with 73. McGwire also led the league in runs batted in, twice in bases on balls and on-base percentage, and four times in slugging percentage. Injuries significantly cut into his playing time in 2000 and 2001 before factoring into his retirement. He finished with 583 home runs, which was fifth all-time when he retired.

For his career, McGwire averaged a home run once every 10.61 at bats, the best at bats per home run ratio in baseball history (Babe Ruth is second at 11.76). He was the fastest player to hit 500 home runs, in 5,487 at-bats.

McGwire was a central figure in baseball's steroids scandal. In 2010, McGwire publicly admitted to using performance-enhancing drugs during a large portion of his career. In his first ten years of eligibility, McGwire has not been elected into the National Baseball Hall of Fame.

McGwire was born in Pomona, California. His father was a dentist. He attended Damien High School in La Verne, California, where he played baseball, golf, and basketball. He was drafted by the Montreal Expos in the 1981 amateur draft but did not sign. He played college baseball at the University of Southern California (where he was a teammate of Randy Johnson and Jack Del Rio) under coach Rod Dedeaux.

After three years at Southern California and a stint on the 1984 U.S. Olympic team, the Oakland Athletics drafted McGwire tenth overall in the 1984 Major League Baseball draft.

In a short cameo, McGwire debuted in the major leagues in August 1986, hitting three home runs and nine runs batted in in 18 games.

Retaining his rookie status in 1987, McGwire took center stage in baseball with his home runs. He hit just four in the month of April, but followed in May with 15, and another nine in June. Before the All-Star break arrived, he totaled 33 HR and earned a spot on the American League (AL) All-Star team. On August 11, he broke Al Rosen's AL rookie record of 37 home runs. Three days later, McGwire broke the major league record of 38, which Frank Robinson and Wally Berger jointly held. In September, McGwire hit nine more home runs while posting monthly personal bests of a .351 batting average, .419 on-base percentage (OBP) and 11 doubles (2B). With 49 HR and two games remaining in the regular season, he chose to sit them out with an opportunity for 50 home runs to be present for the birth of his first child. McGwire also totaled 118 runs batted in (RBI), .289 batting average, 97 runs scored, 28 doubles, a .618 slugging percentage and a .370 on-base percentage (OBP). McGwire's 49 home runs as a rookie stood as a major league record until Aaron Judge hit 52 for the New York Yankees in 2017.

Not only did he lead the AL in home runs in 1987, but he also tied for the major league lead with Chicago Cubs right fielder Andre Dawson. McGwire also led the major leagues in SLG, finished second in the AL in adjusted on-base plus slugging percentage (OPS+, 164) total bases (344), third in RBI and on-base plus slugging (OPS, .987). He was thus a unanimous choice for the AL Rookie of the Year Award and finished sixth overall in the AL Most Valuable Player Award voting.

From 1988 to 1990, McGwire followed with 32, 33, and 39 home runs, respectively, becoming the first Major Leaguer to hit 30+ home runs in each of his first four full seasons. On July 3 and 4, 1988, he hit game-winning home runs in the 16th inning of both games. Through May 2009, McGwire was tied for third all-time with Joe DiMaggio in home runs over his first two calendar years in the major leagues (71), behind Chuck Klein (83) and Ryan Braun (79).

McGwire's most famous home run with the A's was likely his game-winning solo shot in the bottom of the ninth inning of Game 3 of the 1988 World Series against the Los Angeles Dodgers and former A's closer Jay Howell. McGwire's game-winner brought the A's their only victory in the 1988 World Series, which they lost in five games; however, McGwire and his fellow Bash Brother, José Canseco, played a large part in the 1989 championship club that defeated the San Francisco Giants in the famous "Earthquake Series".

Working diligently on his defense at first base, McGwire bristled at the notion that he was a one-dimensional player. He was generally regarded as a good fielder in his early years, even winning a Gold Glove Award in 1990 – the only one that New York Yankees legend Don Mattingly would not win between 1985 and 1994. In later years, his mobility decreased and, with it, his defense; however, McGwire's batting averages after his rookie season plummeted to .260, .231, and .235 from 1988 to 1990. In 1991, he bottomed out with a .201 average and 22 homers. Manager Tony La Russa sat him out the final game of the season to avoid allowing his batting average to dip below .200. Despite the declining averages during this time of his career, his high bases on balls totals allowed him to maintain acceptable OBPs. In fact, when he hit .201, his OPS+ was 103, or just over league average.

McGwire stated in an interview with "Sports Illustrated" that 1991 was the "worst year" of his life, with his on-field performance and marriage difficulties, and that he "didn't lift a weight" that entire season. With all that behind him, McGwire re-dedicated himself to working out harder than ever and received visual therapy from a sports vision specialist.

The "new look" McGwire hit 42 homers and batted .268 in 1992, with an outstanding OPS+ of 175 (the highest of his career to that point), and put on a home run hitting show at the Home Run Derby during the 1992 All-Star break. His performance propelled the A's to the American League West Division title in 1992, their fourth in five seasons. The A's lost in the playoffs to the eventual World Series champion, the Toronto Blue Jays.

Foot injuries limited McGwire to a total of 74 games in 1993 and 1994, and just 9 home runs in each of the two seasons. He played just 104 games in 1995, but his proportional totals were much improved: 39 home runs in 317 at-bats. In 1996, McGwire belted a major league leading 52 homers in 423 at-bats. He also hit a career high .312 average, and led the league in both slugging percentage and on-base percentage.

McGwire's total of 363 home runs with the Athletics surpassed the previous franchise record. He was selected or voted to nine American League All-Star Teams while playing for the A's, including six consecutive appearances from 1987 through 1992. He was one of only four players to hit a ball over the roof in the left field of Tiger Stadium.

On July 31, having already amassed 34 home runs to this point in the 1997 season, McGwire was traded from the Oakland Athletics to the St. Louis Cardinals for T. J. Mathews, Eric Ludwick and Blake Stein. Despite playing just two-thirds of the season in the American League, he finished ninth in home runs. In 51 games with the Cardinals to finish the 1997 season, McGwire compiled a .253 batting average, 24 home runs, and 42 RBI. Overall in 1997, McGwire led the majors with 58 home runs. He also finished third in the major leagues in slugging percentage (.646), fourth in OPS (1.039), fifth in OPS+ (170), tenth in RBI (123), and ninth in walks (101). He placed 16th in the NL MVP voting.

It was the last year of his contract, so there was speculation that McGwire would play for the Cardinals only for the remainder of the season, then seek a long-term deal, possibly in Southern California, where he still lived; however, McGwire signed a contract to stay in St. Louis. It is also believed that McGwire later encouraged Jim Edmonds, another Southern California resident who was traded to St. Louis, to forgo free agency and sign a contract with the Cardinals in 2000.

As the 1998 season progressed, it became clear that McGwire, Seattle Mariners outfielder Ken Griffey Jr., and Chicago Cubs outfielder Sammy Sosa were all on track to break Roger Maris's single-season home run record. The race to break the record first attracted media attention as the home run leader changed often throughout the season. On August 19, Sosa hit his 48th home run to move ahead of McGwire; however, later that day McGwire hit his 48th and 49th home runs to regain the lead.

On September 8, 1998, McGwire hit a pitch by the Cubs' Steve Trachsel over the left field wall for his record-breaking 62nd home run, setting off massive celebrations at Busch Stadium. The fact that the game was against the Cubs meant that Sosa was able to congratulate McGwire personally on his achievement. Members of Maris's family were also present at the game. The ball was freely, albeit controversially, given to McGwire in a ceremony on the field by the stadium worker who found it.

McGwire finished the 1998 season with 70 home runs (including five in his last three games), four ahead of Sosa's 66, a record that was broken three seasons later in 2001 by Barry Bonds with 73.

McGwire was honored with the inaugural Babe Ruth Home Run Award for leading Major League Baseball in home runs. Although McGwire had the prestige of the home run record, Sammy Sosa (who had fewer HR but more RBI and stolen bases) won the 1998 NL MVP award, as his contributions helped propel the Cubs to the playoffs (the Cardinals in 1998 finished third in the NL Central). Many credited the Sosa-McGwire home run chase in 1998 with "saving baseball", by both bringing in new, younger fans and bringing back old fans soured by the 1994–95 Major League Baseball strike.

McGwire kept his high level of offensive production from 1998 going in 1999 while setting or extending several significant records. For the fourth consecutive season, he led MLB in home runs with 65. It was also his fourth consecutive season with at least 50 home runs, extending his own major league record. Sosa, who hit 63 home runs in 1999, again trailed McGwire. Thus, they became the first, and still only, players in major league history to hit 60 or more home runs in consecutive seasons. McGwire also set a record from 1998 to 1999 for home runs in a two-season period with 135. Further, he owned the highest four-season HR total, with 245 from 1996 to 1999. In 1999, he drove in an NL-leading 147 runs while only having 145 hits, the highest RBI-per-hit tally for a season in baseball history.

Statistically in 2000 and 2001, McGwire's numbers declined relative to previous years as he struggled to avoid injury (32 HR in 89 games, and 29 HR in 97 games, respectively). He retired after the 2001 season.

After his playing career ended, McGwire demonstrated coaching ability, personally assisting players such as Matt Holliday, Bobby Crosby and Skip Schumaker before accepting an official role as hitting coach with an MLB team. On October 26, 2009, Tony La Russa, then manager of the Cardinals, confirmed that McGwire would become the club's fifth hitting coach of his tenure with the Cardinals, replacing Hal McRae. McGwire received a standing ovation prior to the Cardinals home opener on April 12, 2010. In his three seasons as Cardinals hitting coach, they featured a prolific offense that led the National League in hitting and on-base percentage, and were second in runs.

In early November, 2012, McGwire rejected a contract extension to return as Cardinals hitting coach for the 2013 season. Instead, he accepted an offer for the same position with the Los Angeles Dodgers, in order to be closer to his wife and five children.

On June 11, 2013, McGwire was ejected for the first time as a coach during a bench-clearing brawl with the Arizona Diamondbacks. He was suspended for two games starting the next day.

On December 2, 2015, he was named the new bench coach for the San Diego Padres. He left the team after the 2018 season.

Known as one of the top sluggers of his era, McGwire ended his career with 583 home runs, which was fifth-most in history when he retired. When he hit his 500th career home run in 1999, he did so in 5,487 career at bats, the fewest in major league history. He led all MLB in home runs in five different seasons, including 1987 and each season from 1996 to 1999. Totaling 245 home runs from 1996−99, it was the highest four-season home run output in major league history. Further, in each of those four seasons, he exceeded 50 home runs, becoming the first player to do so. He was also the first player to hit 49 or more home runs five times, including his rookie-season record of 49 in 1987. With a career average of one home every 10.61 at-bats, he holds the MLB record for most home runs per at-bat by over a full at-bat more than second-place Babe Ruth (11.76).

As of 2015, McGwire owned three of the four lowest single-season AB/HR ratios in MLB history, which covered his 1996, 1998 and 1999 seasons. They were actually the top three seasons in MLB history until Bonds broke his single-season HR record in 2001. McGwire's 1997 season ranked 13th. Considered one of the slowest running players in the game, McGwire had the fewest career triples (six) of any player with 5,000 or more at-bats, and had just 12 stolen bases while being caught stealing eight times.

In 1999, "The Sporting News" released a list of the 100 Greatest Baseball Players, ranking McGwire at number 91. The list had been compiled during the 1998 season and included statistics through the 1997 season. That year, he was elected to the Major League Baseball All-Century Team. In 2005, "The Sporting News" published an update of their list, and McGwire had been moved up to Number 84.

McGwire first became eligible for Hall of Fame voting in 2007. For election, a player needs to be listed on 75% of ballots cast; falling under 5% removes a player from future consideration. Between 2007 and 2010 McGwire's performance held steady, receiving 128 votes (23.5%) in 2007, 128 votes (23.6%) in 2008, 118 votes (21.9%) in 2009, and 128 votes (23.7%) in 2010. The subsequent ballot in 2011 showed the first sub-20% total of 115 votes (19.8%), and McGwire's total votes continued to decline (112 votes (19.5%) in 2012, 96 votes (16.9%) in 2013, 63 votes (11.0%) in 2014, and 55 votes (10.0%) in 2015) until he was finally eliminated after receiving only 54 votes (12.3%) in 2016.

A portion of Interstate 70 in Missouri in St. Louis and near Busch Stadium was named "Mark McGwire Highway" to honor his 70 home run achievement, along with his various good works for the city. In May 2010, St. Louis politicians succeeded in passing a state bill to change the name of "Mark McGwire Highway", a 5-mile stretch of Interstate 70, to "Mark Twain Highway".

In 16 seasons playing major league baseball (1986–2001), McGwire accumulated the following career totals:

In a 1998 article by Associated Press writer Steve Wilstein, McGwire admitted to taking androstenedione, an over-the-counter muscle enhancement product that had already been banned by the World Anti-Doping Agency, the NFL, and the IOC; however, use of the substance was not prohibited by Major League Baseball at the time, and it was not federally classified as an anabolic steroid in the United States until 2004.

Jose Canseco released a book, "", in 2005. In it, he wrote positively about steroids and made various claims—among them, that McGwire had used performance-enhancing drugs since the 1980s and that Canseco had personally injected him with them.

In 2005, McGwire and Canseco were among 11 baseball players and executives subpoenaed to testify at a congressional hearing on steroids. During his testimony on March 17, 2005, McGwire declined to answer questions under oath when he appeared before the House Government Reform Committee. In a tearful opening statement, McGwire said:
On January 11, 2010, McGwire admitted to using steroids on and off for a decade and said, "I wish I had never touched steroids. It was foolish and it was a mistake. I truly apologize. Looking back, I wish I had never played during the steroid era." He admitted using them in the 1989/90 offseason and then after he was injured in 1993. He admitted using them on occasion throughout the 1990s, including during the 1998 season. McGwire said that he used steroids to recover from injuries.

McGwire's decision to admit using steroids was prompted by his decision to become hitting coach of the St. Louis Cardinals. According to McGwire, he took steroids for health reasons rather than to improve performance; however, a drug dealer who claimed to have provided steroids to McGwire asserted that his use was to improve his size and strength, rather than to just maintain his health.

McGwire's brother Dan McGwire was a quarterback for the Seattle Seahawks and Miami Dolphins of the NFL in the early 1990s, and was a first-round draft choice out of San Diego State University. He has another brother, Jay McGwire, a bodybuilder, who wrote a book in 2010 detailing their shared steroid use.

McGwire married Stephanie Slemer—a former pharmaceutical sales representative from the St. Louis area—in Las Vegas on April 20, 2002. On June 1, 2010, their triplet girls were born: Monet Rose, Marlo Rose, and Monroe Rose. They join brothers Max and Mason. They reside in a gated community in Shady Canyon Irvine, California. Together they created the Mark McGwire Foundation for Children to support agencies that help children who have been sexually and physically abused come to terms with a difficult childhood. Mark has a son, Matthew (b. 1987), from a previous marriage (1984–1990, divorced) to Kathleen Hughes.

Prior to admitting to using steroids, McGwire avoided the media and spent much of his free time playing golf. He also worked as a hitting coach for Major League players Matt Holliday, Bobby Crosby, Chris Duncan and Skip Schumaker.

McGwire appeared as himself in season 7, episode 13 of the sitcom "Mad About You".

McGwire provided his voice for an episode of "The Simpsons" titled "Brother's Little Helper", where he played himself.


</doc>
<doc id="20549" url="https://en.wikipedia.org/wiki?curid=20549" title="Manufacturing Consent">
Manufacturing Consent

Manufacturing Consent: The Political Economy of the Mass Media is a 1988 book by Edward S. Herman and Noam Chomsky, in which the authors propose that the mass communication media of the U.S. "are effective and powerful ideological institutions that carry out a system-supportive propaganda function, by reliance on market forces, internalized assumptions, and self-censorship, and without overt coercion", by means of the propaganda model of communication. The title derives from the phrase "the manufacture of consent," employed in the book "Public Opinion" (1922), by Walter Lippmann (1889–1974). The "consent" referred to is consent of the governed.

The book was revised 20 years after its first publication to take account of developments such as the fall of the Soviet Union. There has been debate about how the Internet has changed the public's access to information since 1988.

Chomsky credits the origin of the book to the impetus of Alex Carey, the Australian social psychologist, to whom Herman and he dedicated the book.

The propaganda model for the manufacture of public consent describes five editorially distorting filters, which are applied to the reporting of news in mass communications media:


According to Chomsky, "most of the book" was the work of Edward S. Herman. Herman describes a rough division of labor in preparing the book whereby he was responsible for the preface and chapters 1–4 while Chomsky was responsible for chapters 5–7. According to Herman, the propaganda model described in the book was originally his idea, tracing it back to his 1981 book "Corporate Control, Corporate Power". The main elements of the propaganda model (though not so called at the time) were discussed briefly in volume 1 chapter 2 of Herman and Chomksy's 1979 book "The Political Economy of Human Rights", where they argued, "Especially where the issues involve substantial U.S. economic and political interests and relationships with friendly or hostile states, the mass media usually function much in the manner of state propaganda agencies."


Four years after publication, "Manufacturing Consent: The Political Economy of the Mass Media" was adapted as "" (1992), a documentary film that discusses the propaganda model of communication and the politics of the mass-communications business, as well as a biography of Chomsky. The film was directed by Mark Achbar and Peter Wintonick.




</doc>
<doc id="20550" url="https://en.wikipedia.org/wiki?curid=20550" title="Maeshowe">
Maeshowe

Maeshowe (or Maes Howe; ) is a Neolithic chambered cairn and passage grave situated on Mainland Orkney, Scotland. It was probably built around . In the archaeology of Scotland, it gives its name to the Maeshowe type of chambered cairn, which is limited to Orkney. Maeshowe is a significant example of Neolithic craftsmanship and is, in the words of the archaeologist Stuart Piggott, "a superlative monument that by its originality of execution is lifted out of its class into a unique position." The monuments around Maeshowe, including Skara Brae, were designated a UNESCO World Heritage Site in 1999.

Maeshowe is one of the largest tombs in Orkney; the mound encasing the tomb is in diameter and rises to a height of . Surrounding the mound, at a distance of to is a ditch up to wide. The grass mound hides a complex of passages and chambers built of carefully crafted slabs of flagstone weighing up to 30 tons. It is aligned so that the rear wall of its central chamber held up by a bracketed wall, is illuminated on the winter solstice. A similar display occurs in Newgrange.
This entrance passage is long and leads to the central almost square chamber measuring about on each side. The current height of the chamber is , this reflects the height to which the original stonework is preserved and capped by a modern corbelled roof. The original roof may have risen to a height of or more. The entrance passage is only about high, requiring visitors to stoop or crawl into the central chamber. That chamber is constructed largely of flat slabs of stone, many of which traverse nearly the entire length of the walls. In each corner lie huge angled buttresses that rise to the vaulting. At a height of about , the wall's construction changes from the use of flat to overlapping slabs creating a beehive-shaped vault.

Estimates of the amount of effort required to build Maeshowe vary; a commonly suggested number is 39,000 man-hours, although Colin Renfrew calculated that at least 100,000 hours would be required. Dating of the construction of Maeshowe is difficult but dates derived from burials in similar tombs cluster around . Since Maeshowe is the largest and most sophisticated example of the Maeshowe "type" of tomb, archaeologists have suggested that it is the last of its class, built around . The people who built Maeshowe were users of grooved ware, a distinctive type of pottery that spread throughout the British Isles from about .

Maeshowe appears as a grassy mound rising from a flat plain near the southeast end of the Loch of Harray. The land around Maeshowe at its construction probably looked much as it does today: treeless with grasses representative of Pollen Assemblage Zone MNH-I reflecting "mixed agricultural practices, probably with a pastoral bias – there is a substantial amount of ribwort pollen, but also that of cereals."

Maeshowe is aligned with some other Neolithic sites in the vicinity, for example the entrance of "Structure 8" of the nearby Barnhouse Settlement directly faces the mound. In addition, the so-called "Barnhouse Stone" in a field around 700 metres away is perfectly aligned with the entrance to Maeshowe. This entrance corridor is so placed that it lets the direct light of the setting sun into the chamber for a few days each side of the winter solstice, illuminating the entrance to the back cell.

A Neolithic "low road" connects Maeshowe with the magnificently preserved village of Skara Brae, passing near the Standing Stones of Stenness and the Ring of Brodgar. Low roads connect Neolithic ceremonial sites throughout Britain. Some archeologists believe that Maeshowe was originally surrounded by a large stone circle. The complex including Maeshowe, the Ring of Brodgar, the Standing Stones of Stenness, Skara Brae, as well as other tombs and standing stones represents a concentration of Neolithic sites that is rivalled in Britain only by the complexes associated with Stonehenge and Avebury.

The tomb gives its name to the Maeshowe type of Scottish chambered cairn, which is limited to Orkney. Maeshowe is very similar to the famous Newgrange tomb in Ireland, suggesting a linkage between the two cultures. Chambered tombs of the Maeshowe "type" are characterized by a long, low entrance passageway leading to a square or rectangular chamber from which there is access to a number of side cells. Although there are disagreements as to the attribution of tombs to tomb types, there are only seven definitely known Maeshowe type tombs. On Mainland, there are, in addition to Maeshowe; the tombs of Cuween Hill, Wideford Hill, and Quanterness. The tomb of Quoyness is found on Sanday, while Vinquoy Hill is located on Eday. Finally, there is an unnamed tomb on the Holm of Papa Westray. Anna Ritchie reports that there are three more Maeshowe type tombs in Orkney but she doesn't name or locate them.

According to the description herein, a chambered tomb is normally characterized by grave goods, which were found at Cuween Hill and the tomb on Holm of Papa Westray (see the paragraph above) but were not found at Maeshowe. Further, the description of a passage grave states: "Not all passage graves have been found to contain evidence of human remains. One such example is Maeshowe." In addition, the Statement of Significance (cited below in the section describing the Maeshowe World Heritage designation) says, "It is an expression of genius within a group of people whose other tombs were claustrophobic chambers in smaller mounds.".

A potential explanation for the extraordinary genius of Maeshowe engineering and the lack of human remains was described by Tompkins (1971) who compared the structure at "Maes-Howe" to the Great Pyramid (p. 130-133), suggesting the site was used as an observatory, calendar, and for May Day ceremonies rather than as a tomb.

Tompkins (1971) extensively studied numerous documents related to the measurement and exploration of the Great Pyramid of Giza. He stated the central "observation chamber" (p. 130) at Maeshowe was "corbeled like the Great Pyramid's Grand Gallery", was carefully leveled, plumbed", and the jointing is of a quality that "rivals that of the Great Pyramid". Rather than chambers of a tomb, Tompkins suggested the structure contained small "retiring rooms for the observers" (p. 130). He suggested the entrance was very similar to Egyptian pyramids in that it had a "54-foot observation passage aimed like a telescope at a megalithic stone [2772 ft. away] to indicate the summer solstice" (p. 130) in addition to its "Watchstone" to the West that indicated the equinoxes. The "sighting passage" (p. 133) points to a northern star like the pyramids of Saqqara, Dashur and Medûm. Tompkins stated that "The similarity [of the pyramids] to the structure at Maes-Howe is indeed amazing" (p. 133). He cited Professor Alexander Thom, former Chair of Engineering Science at Oxford, as writing about the geometry of construction and astronomical alignment of Maeshowe in this context in 1967 (Tompkins, 1971, p. 137-138).

Tompkins (1971), citing Thom (1967) and others, described in detail how Maeshowe, Silbury Hill (Tompkins, 1971, p. 128) and other ancient mounds and Neolithic megaliths across Britain served as extremely accurate observatories, calendars, and straight-line beacons for travelers, as well as how they were used ceremonially in May Day celebrations more than 4000 years ago.

The "modern" opening of the tomb was by James Farrer, an antiquarian and the Member of Parliament for South Durham, in July 1861. Farrer, like many antiquarians of the day, was not noted for his careful excavation of sites. John Hedges describes him as possessing "a rapacious appetite for excavation matched only by his crude techniques, lack of inspiration, and general inability to publish." Farrer and his workmen broke through the roof of the entrance passage and found it filled with debris. He then turned his attention to the top of the mound, broke through and, over a period of a few days, emptied the main chamber of material that had filled it completely. He and his workmen discovered the famous runic inscriptions carved on the walls, proof that Norsemen had broken into the tomb at least six centuries earlier.

As described in the Orkneyinga Saga, Maeshowe was looted by the famous Vikings Earl Harald Maddadarson and Ragnvald, Earl of Møre in about the 12th century. The more than thirty runic inscriptions on the walls of the chamber represent the largest single collection of such carvings in the world. More recent fieldwork has demonstrated that the application of a computational photography technique, Reflectance Transformation Imaging (RTI), can shed light onto the nature of the inscriptions and their sequencing.

Excavations have revealed that the external wall surrounding the ditch was rebuilt in the 9th century. Some archaeologists see this as evidence that the tomb may have been reused by the Norse people and that they were the source of the "treasure" found by the later looters.

Fieldwork in Maeshowe has demonstrated that the application of computational photography technique, Reflectance Transformation Imaging (RTI), can shed further light onto the nature of inscriptions and contribute to interpretation of inscriptions at Maeshowe.

The origin of the name "Maeshowe" is uncertain. While the second element is certainly from the Old Norse "haugr" usually meaning a mound, there have been several different theories postulated for the first element, "maes".

These include:

As the female regent Mae/May was seen as the principal head of the famous festival held by the adult females after the Spring equinox, today's 'Easter'. Within this context the name Maes Howe seem to reflect "May's Temple".

The "Heart of Neolithic Orkney" was listed as a World Heritage site in December 1999. In addition to Maeshowe, the site includes Skara Brae, the Standing Stones of Stenness, the Ring of Brodgar and other nearby sites. It is managed by Historic Environment Scotland, whose "Statement of Significance" for the site begins:

The monuments at the heart of Neolithic Orkney and Skara Brae proclaim the triumphs of the human spirit in early ages and isolated places. They were approximately contemporary with the mastabas of the archaic period of Egypt (first and second dynasties), the brick temples of Sumeria, and the first cities of the Harappa culture in India, and a century or two earlier than the Golden Age of China. Unusually fine for their early date, and with a remarkably rich survival of evidence, these sites stand as a visible symbol of the achievements of early peoples away from the traditional centres of civilisation ... Maes Howe is a masterpiece of Neolithic engineering. It is an exceptionally early architectural accomplishment. With its almost classical strength and simplicity it is a unique survival from 5000 years ago. It is an expression of genius within a group of people whose other tombs were claustrophobic chambers in smaller mounds.




</doc>
<doc id="20551" url="https://en.wikipedia.org/wiki?curid=20551" title="Montevideo Convention">
Montevideo Convention

The Montevideo Convention on the Rights and Duties of States is a treaty signed at Montevideo, Uruguay, on December 26, 1933, during the Seventh International Conference of American States. The Convention codifies the declarative theory of statehood as accepted as part of customary international law. At the conference, United States President Franklin D. Roosevelt and Secretary of State Cordell Hull declared the "Good Neighbor Policy", which opposed U.S. armed intervention in inter-American affairs. The convention was signed by 19 states. The acceptance of three of the signatories was subject to minor reservations. Those states were Brazil, Peru and the United States.

The convention became operative on December 26, 1934. It was registered in "League of Nations Treaty Series" on January 8, 1936.

The conference is notable in U.S. history, since one of the U.S. representatives was Dr. Sophonisba Preston Breckinridge, the first U.S. female representative at an international conference.

In most cases, the only avenue open to self-determination for colonial or national ethnic minority populations was to achieve international legal personality as a nation-state. The majority of delegations at the International Conference of American States represented independent states that had emerged from former colonies. In most cases, their own existence and independence had been disputed or opposed by one or more of the European colonial empires. They agreed among themselves to criteria that made it easier for other dependent states with limited sovereignty to gain international recognition.

The convention sets out the definition, rights and duties of statehood. Most well-known is Article 1, which sets out the four criteria for statehood that have been recognized by international organizations as an accurate statement of customary international law:

Furthermore, the first sentence of Article 3 explicitly states that "The political existence of the state is independent of recognition by the other states." This is known as the declarative theory of statehood. It stands in conflict with the alternative constitutive theory of statehood: a state exists only insofar as it is recognized by other states. It should not be confused with the Estrada doctrine. "Independence" and "sovereignty" are not mentioned in article 1.

An important part of the convention was a prohibition of using military force to gain sovereignty. According to Article 11 of the Convention,

Furthermore, Article 11 reflects the contemporary Stimson Doctrine, and is now a fundamental part of international law through article 2 paragraph 4 of the Charter of the United Nations.

The 16 states that have ratified this convention are limited to the Americas.

A further four states signed the Convention on 26 December 1933, but have not ratified it.

The only state to attend the Seventh International Conference of American States, where the convention was agreed upon, which did not sign it was Bolivia. Costa Rica, which did not attend the conference, later signed the convention.

As a restatement of customary international law, the Montevideo Convention merely codified existing legal norms and its principles and therefore does not apply merely to the signatories, but to all subjects of international law as a whole.

The European Union, in the principal statement of its Badinter Committee, follows the Montevideo Convention in its definition of a state: by having a territory, a population, and a political authority. The committee also found that the existence of states was a question of fact, while the recognition by other states was purely declaratory and not a determinative factor of statehood.

Switzerland, although not a member of the European Union, adheres to the same principle, stating that "neither a political unit needs to be recognized to become a state, nor does a state have the obligation to recognize another one. At the same time, neither recognition is enough to create a state, nor does its absence abolish it."





</doc>
<doc id="20553" url="https://en.wikipedia.org/wiki?curid=20553" title="Macrolide">
Macrolide

The macrolides are a class of natural products that consist of a large macrocyclic lactone ring to which one or more deoxy sugars, usually cladinose and desosamine, may be attached. The lactone rings are usually 14-, 15-, or 16-membered. Macrolides belong to the polyketide class of natural products. Some macrolides have antibiotic or antifungal activity and are used as pharmaceutical drugs.

The first macrolide discovered was erythromycin, which was first used in 1952. Erythromycin was widely used as a substitute to penicillin in cases where patients were allergic to penicillin or had penicillin-resistant illnesses. Later macrolides developed, including azithromycin and clarithromycin, stemmed from chemically modifying erythromycin; these compounds were designed to be more easily absorbed and have fewer side-effects (erythromycin caused gastrointestinal side-effects in a significant proportion of users). 

Antibiotic macrolides are used to treat infections caused by Gram-positive bacteria (e.g., "Streptococcus pneumoniae") and limited Gram-negative bacteria (e.g., "Bordetella pertussis", "Haemophilus influenzae"), and some respiratory tract and soft-tissue infections. The antimicrobial spectrum of macrolides is slightly wider than that of penicillin, and, therefore, macrolides are a common substitute for patients with a penicillin allergy. Beta-hemolytic streptococci, pneumococci, staphylococci, and enterococci are usually susceptible to macrolides. Unlike penicillin, macrolides have been shown to be effective against Legionella pneumophila, mycoplasma, mycobacteria, some rickettsia, and chlamydia.

Macrolides are "not" to be used on non-ruminant herbivores, such as horses and rabbits. They rapidly produce a reaction causing fatal digestive disturbance. It can be used in horses less than one year old, but care must be taken that other horses (such as a foal's mother) do not come in contact with the macrolide treatment.

Macrolides can be administered in a variety of ways that include tablets, capsules, suspensions, injectings and topically.

Macrolides are protein synthesis inhibitors. The mechanism of action of macrolides is inhibition of bacterial protein biosynthesis, and they are thought to do this by preventing peptidyltransferase from adding the growing peptide attached to tRNA to the next amino acid (similarly to chloramphenicol) as well as inhibiting ribosomal translation. Another potential mechanism is premature dissociation of the peptidyl-tRNA from the ribosome.

Macrolide antibiotics do so by binding reversibly to the P site on the 50S subunit of the bacterial ribosome. This action is considered to be bacteriostatic. Macrolides are actively concentrated within leukocytes, and thus are transported into the site of infection.

The macrolide antibiotics erythromycin, clarithromycin, and roxithromycin have proven to be an effective long-term treatment for the idiopathic, Asian-prevalent lung disease diffuse panbronchiolitis (DPB). The successful results of macrolides in DPB stems from controlling symptoms through immunomodulation (adjusting the immune response), with the added benefit of low-dose requirements.

With macrolide therapy in DPB, great reduction in bronchiolar inflammation and damage is achieved through suppression of not only neutrophil granulocyte proliferation but also lymphocyte activity and obstructive secretions in airways. The antimicrobial and antibiotic effects of macrolides, however, are not believed to be involved in their beneficial effects toward treating DPB. This is evident, as the treatment dosage is much too low to fight infection, and in DPB cases with the occurrence of the macrolide-resistant bacterium "Pseudomonas aeruginosa", macrolide therapy still produces substantial anti-inflammatory results.

US FDA-approved :


Non-US FDA-approved:


Ketolides are a class of antibiotics that are structurally related to the macrolides. They are used to treat respiratory tract infections caused by macrolide-resistant bacteria. Ketolides are especially effective, as they have two ribosomal binding sites.

Ketolides include:


Fluoroketolides are a class of antibiotics that are structurally related to the ketolides. The fluoroketolides have three ribosomal interaction sites.

Fluoroketolides include:


The drugs tacrolimus, pimecrolimus, and sirolimus, which are used as immunosuppressants or immunomodulators, are also macrolides. They have similar activity to ciclosporin.

Polyene antimycotics, such as amphotericin B, nystatin etc., are a subgroup of macrolides. Cruentaren is another example of an antifungal macrolide.

A variety of toxic macrolides produced by bacteria have been isolated and characterized, such as the mycolactones.

The primary means of bacterial resistance to macrolides occurs by post-transcriptional methylation of the 23S bacterial ribosomal RNA. This acquired resistance can be either plasmid-mediated or chromosomal, i.e., through mutation, and results in cross-resistance to macrolides, lincosamides, and streptogramins (an MLS-resistant phenotype).

Two other types of acquired resistance rarely seen include the production of drug-inactivating enzymes (esterases or kinases), as well as the production of active ATP-dependent efflux proteins that transport the drug outside of the cell.

Azithromycin has been used to treat strep throat (Group A streptococcal (GAS) infection caused by "Streptococcus pyogenes") in penicillin-sensitive patients, however macrolide-resistant strains of GAS are not uncommon. Cephalosporin is another option for these patients.

A 2008 "British Medical Journal" article highlights that the combination of some macrolides and statins (used for lowering cholesterol) is not advisable and can lead to debilitating myopathy. This is because some macrolides (clarithromycin and erythromycin, not azithromycin) are potent inhibitors of the cytochrome P450 system, particularly of CYP3A4. Macrolides, mainly erythromycin and clarithromycin, also have a class effect of QT prolongation, which can lead to torsades de pointes. Macrolides exhibit enterohepatic recycling; that is, the drug is absorbed in the gut and sent to the liver, only to be excreted into the duodenum in bile from the liver. This can lead to a buildup of the product in the system, thereby causing nausea. In infants the use of erythromycin has been associated with pyloric stenosis.

Some macrolides are also known to cause cholestasis, a condition where bile cannot flow from the liver to the duodenum. A new study found an association between erythromycin use during infancy and developing IHPS in infants . However, no significant association was found between macrolides use during pregnancy or breastfeeding .

A Cochrane review showed gastrointestinal symptoms to be the most frequent adverse event reported in literature.

Macrolides should not be taken with colchicine as it may lead to colchicine toxicity. Symptoms of colchicine toxicity include gastrointestinal upset, fever, myalgia, pancytopenia, and organ failure.



</doc>
<doc id="20556" url="https://en.wikipedia.org/wiki?curid=20556" title="Meta element">
Meta element

Meta elements are tags used in HTML and XHTML documents to provide structured metadata about a Web page. 
They are part of a web page's codice_1 section. Multiple Meta elements with different attributes can be used on the same page. Meta elements can be used to specify page description, keywords and any other metadata not provided through the other codice_1 elements and attributes.

The meta element has two uses: either to emulate the use of an HTTP response header field, or to embed additional metadata within the HTML document.

With HTML up to and including HTML 4.01 and XHTML, there were four valid attributes: codice_3, codice_4, codice_5 and codice_6. Under HTML 5 there are now five valid attributes, codice_7 having been added. codice_4 is used to emulate an HTTP header, and codice_5 to embed metadata. The value of the statement, in either case, is contained in the codice_3 attribute, which is the only required attribute unless codice_7 is given. codice_7 is used to indicate the character set of the document, and is available in HTML5.

Such elements must be placed as tags in the codice_1 section of an HTML or XHTML document.

The two distinct parts of the elements are:

codice_14 elements can specify HTTP headers which should be sent before the actual content when the HTML page is served from the web server to the client. For example:

as an alternative to the response header codice_16 to indicate the media type and, more commonly needed, the UTF-8 character encoding.

Meta tags can be used to describe the contents of the page:

In this example, the codice_14 element describes the contents of a web page.

Meta elements provide information about the web page, which can be used by search engines to help categorize the page correctly.

They have been the focus of a field of marketing research known as search engine optimization (SEO), where different methods are used to provide a user's website with a higher ranking on search engines. Prior to the rise of content-analysis by search engines in the mid-1990s (most notably Google), search engines were reliant on metadata to correctly classify a Web page and webmasters quickly learned the commercial significance of having the right meta element. The search engine community is now divided as to the value of meta tags. Some claim they have no value, others that they are central, while many simply conclude there is no clear answer but, since they do no harm, they use them just in case. Google states they do support the meta tags "content", "robots", "google", "google-site-verification", "content-type", "refresh" and "google-bot".
Major search engine robots look at many factors when determining how to rank a page of which meta tags will only form a portion. Furthermore, most search engines change their ranking rules frequently. Google have stated they update their ranking rules every 48 hours. Under such circumstances, a definitive understanding of the role of meta tags in SEO is unlikely.

The codice_18 attribute was popularized by search engines such as Infoseek and AltaVista in 1995, and its popularity quickly grew until it became one of the most commonly used codice_14 elements.

No consensus exists whether or not the codice_18 attribute has any effect on ranking at any of the major search engines today. It is speculated that it does if the keywords used in the codice_14 can also be found in the page copy itself. With respect to Google, thirty-seven leaders in search engine optimization concluded in April 2007 that the relevance of having keywords in the codice_14-attribute codice_18 is little to none and in September 2009 Matt Cutts of Google announced that they were no longer taking keywords into account whatsoever. However, both these articles suggest that Yahoo! still makes use of the keywords meta tag in some of its rankings. Yahoo! itself claims support for the keywords meta tag in conjunction with other factors for improving search rankings. In October 2009 Search Engine Round Table announced that "Yahoo Drops The Meta Keywords Tag Also" but later reported that the announcement made by Yahoo!'s Senior Director of Search was incorrect. In the corrected statement Yahoo! Senior Director of Search states that "…What changed with Yahoo's ranking algorithms is that while we still index the meta keyword tag, the ranking importance given to meta keyword tags receives the lowest ranking signal in our system … it will actually have less effect than introducing those same words in the body of the document, or any other section." In Sept 2012, Google announced that they will consider Keyword Meta tag for news publishers. Google said that this may help worthy content to get noticed. The syntax of the news meta keyword has subtle difference from custom keyword meta tag; it is denoted by "news_keywords", while the custom keyword meta tag is denoted by "keywords".

According to Moz, "Title tags are the second most important on-page factor for SEO, after content". They convey to the search engines what a given page is all about. It used to be standard SEO practice to include the primary and the secondary keywords in the title for better ranking. Google has gone through various iterations of showing short or longer amounts of content from within the title tags.

Regardless, the title tags still hold importance in three different ways.

Unlike the codice_18 attribute, the codice_25 attribute is supported by most major search engines, like Yahoo! and Bing, while Google will fall back on this tag when information about the page itself is requested (e.g. using the related: query). The codice_25 attribute provides a concise explanation of a Web page's content. This allows the Web page authors to give a more meaningful description for listings than might be displayed if the search engine was unable to automatically create its own description based on the page content. The description is often, but not always, displayed on search engine results pages, so it can affect click-through rates. While clicks for a result can be a positive sign of effective codice_29 and codice_25 writing, Google does not recognize this meta element as a ranking factor, so using target keyword phrases in that element will not help a site rank better. W3C doesn't specify the size of this description meta tag, but almost all search engines recommend it to be shorter than 155 characters of plain text.

The codice_31 attribute tells search engines what natural language the website is written in (e.g. English, Spanish or French), as opposed to the coding language (e.g. HTML). It is normally an IETF language tag for the language name. It is of most use when a website is written in multiple languages and can be included on each page to tell search engines in which language a particular page is written.

The codice_33 attribute, supported by several major search engines, controls whether search engine spiders are allowed to index a page, or not, and whether they should follow links from a page, or not. The attribute can contain one or more comma-separate values. The codice_35 value prevents a page from being indexed, and codice_36 prevents links from being crawled. Other values recognized by one or more search engines can influence how the engine indexes pages, and how those pages appear on the search results. These include codice_37, which instructs a search engine not to store an archived copy of the page, and codice_38, which asks that the search engine not include a snippet from the page along with the page's listing in search results.

Meta tags are one of the best options for preventing search engines from indexing content of a website.

The search engines Google, Yahoo! and MSN use in some cases the title and abstract of the DMOZ (aka Open Directory Project) listing of a website for the title and/or description (also called snippet or abstract) in the search engine results pages (SERP). To give webmasters the option to specify that the Open Directory Project content should not be used for listings of their website, Microsoft introduced in May 2006 the new "codice_39" value for the "codice_33" element of the meta tags. Google followed in July 2006 and Yahoo! in October 2006.

The syntax is the same for all search engines who support the tag.
Webmasters can decide if they want to disallow the use of their ODP listing on a per search engine basis

Google:
Yahoo!
MSN and Live Search (via bingbot, previously msnbot): 

Yahoo! puts content from their own Yahoo! directory next to the ODP listing. In 2007 they introduced a meta tag that lets web designers opt-out of this.

Adding the codice_41 tag to a page will prevent Yahoo! from displaying Yahoo! Directory titles and abstracts.

For dynamically created web pages, Google proposes the above meta tag which causes fragment URLs (ones that look like "http://www.url.com/#xyz" ) to be rewritten and recrawled as "ugly URLs" (i.e. ones looking like "http://www.url.com/?_escaped_fragment_=xyz" ). See for more details about the rewriting process. This rewrite step is a signal to the web site to please provide a simple and full HTML web page that is the result of executing the AJAX or other scripting on the page. This allows Google and other search engines to collect and index static web pages even when a web page is dynamically created and updated by the browser.

Yahoo! also introduced in May 2007 the attribute value: codice_42. This is not a meta tag, but an attribute and value, which can be used throughout Web page tags where needed. Content of the page where this attribute is being used will be ignored by the Yahoo! crawler and not included in the search engine's index.

Examples for the use of the codice_43 tag:

Google does not use HTML keyword or meta tag elements for indexing. The Director of Research at Google, Monika Henzinger, was quoted (in 2002) as saying, "Currently we don't trust metadata because we are afraid of being manipulated." Other search engines developed techniques to penalize Web sites considered to be "cheating the system". For example, a Web site repeating the same meta keyword several times may have its ranking "decreased" by a search engine trying to eliminate this practice, though that is unlikely. It is more likely that a search engine will ignore the meta keyword element completely, and most do regardless of how many words are used in the element.

Google does, however, use meta tag elements for displaying site links. The title tags are used to create the link in search results:
The meta description often appears in Google search results to describe the link:
Additionally, enterprise search startup Swiftype considers meta tags as a mechanism for signaling relevancy for their web site search engines, even introducing their own extension called Meta Tags 2.

Meta refresh elements can be used to instruct a Web browser to automatically refresh a Web page after a given time interval. It is also possible to specify an alternative URL and use this technique in order to redirect the user to a different location.
Auto refreshing via a META element has been deprecated for more than ten years, and recognized as problematic before that.

The W3C suggests that user agents should allow users to disable it, otherwise META refresh should not be used by web pages.
For Internet Explorer's security settings, under the miscellaneous category, meta refresh can be turned off by the user, thereby disabling its redirect ability.
In Mozilla Firefox it can be disabled in the configuration file under the key name "accessibility.blockautorefresh".

Many web design tutorials also point out that client-side redirecting tends to interfere with the normal functioning of a Web browser's "back" button. After being redirected, clicking the back button will cause the user to go back to the redirect page, which redirects them again. Some modern browsers seem to overcome this problem however, including Safari, Mozilla Firefox and Opera.

Auto-redirects via markup (versus server-side redirects) are not in compliance with the W3C's - Web Content Accessibility Guidelines (WCAG) 1.0 (guideline 7.5).

Meta elements of the form codice_44 can be used as alternatives to HTTP headers. For example, codice_45 would tell the browser that the page "expires" on June 21, 2006 at 14:25:27 GMT and that it may safely cache the page until then. The HTML 4.01 specification optionally allows this tag to be parsed by HTTP servers and set as part of the HTTP response headers, but no web servers currently implement this behavior. Instead, the user agent emulates the behavior for some HTTP headers as if they had been sent in the response header itself.

Some HTML elements and attributes already handle certain pieces of meta data and may be used by authors instead of META to specify those pieces: the TITLE element, the ADDRESS element, the INS and DEL elements, the title attribute, and the cite attribute.

An alternative to codice_14 elements for enhanced subject access within a website is the use of a back-of-book-style index for the website. See the American Society of Indexers website for an example.

In 1994, ALIWEB, also used an index file to provide the type of information commonly found in meta keywords attributes.

In cases where the content attribute's value is a URL, many authors decide to use a link element with a proper value for its rel attribute as well.

For a comparison on when it is best to use HTTP-headers, meta-elements, or attributes in the case of language specification: see here.




</doc>
<doc id="20559" url="https://en.wikipedia.org/wiki?curid=20559" title="Mecha">
Mecha

The term may refer to both scientific ideas and science fiction genres that center on giant robots or machines (mechs) controlled by people. Mechas are typically depicted as humanoid mobile robots. The term was first used in Japanese ("meka") after shortening the English loanword "mekanikaru" ('mechanical'), but the meaning in Japanese is more inclusive, and "robot" ("robotto") or "giant robot" is the narrower term.

These machines vary greatly in size and shape, but are distinguished from vehicles by their humanoid or biomorphic appearance and size—bigger than a human. Different subgenres exist, with varying connotations of realism. The concept of Super Robot and Real Robot are two such examples found in Japanese anime. The term may also refer to real world piloted humanoid or non-humanoid robotic platforms, either currently in existence or still on the drawing board (i.e. at the planning or design stage). Alternatively, in the original Japanese context of the word, "mecha" may refer to mobile machinery/vehicles (including aircraft) in general, manned or otherwise.

The word is an abbreviation, first used in Japanese, of the word "mechanical". In Japanese, mecha encompasses all mechanical objects, including cars, guns, computers, and other devices, and the term or "giant robot" is used to distinguish limbed vehicles from other mechanical devices. Outside of this usage, it has become associated with large humanoid machines with limbs or other biological characteristics. Mechas differ from robots in that they are piloted from a cockpit, typically located in the chest or head of the mech.

While the distinction is often hazy, mecha typically does not refer to form-fitting powered armor such as Iron Man's suit. They are usually much larger than the wearer, like Iron Man's enemy the Iron Monger, or the mobile suits depicted in the "Gundam" series.

In most cases, mecha are depicted as fighting machines, whose appeal comes from the combination of potent weaponry with a more stylish combat technique than a mere vehicle. Often, they are the primary means of combat, with conflicts sometimes being decided through gladiatorial matches. Other works represent mecha as one component of an integrated military force, supported by and fighting alongside tanks, fighter aircraft, and infantry, functioning as a mechanical cavalry. The applications often highlight the theoretical usefulness of such a device, combining a tank's resilience and firepower with infantry's ability to cross unstable terrain and a high degree of customization. In some continuities, special scenarios are constructed to make mecha more viable than current-day status. For example, in Gundam the fictional Minovsky particle inhibits the use of radar, making long-range ballistic strikes impractical, thus favouring relatively close range warfare of Mobile Suits.

However, some stories, such as the manga/anime series "Patlabor" and the American wargame "BattleTech" universe, also encompass mecha used for civilian purposes such as heavy construction work, police functions or firefighting. Mecha also see roles as transporters, recreation, advanced hazmat suits and other R and D applications.

Mecha have been used in fantasy settings, for example in the anime series "Aura Battler Dunbine", "The Vision of Escaflowne", "Panzer World Galient" and "Maze". In those cases, the mecha designs are usually based on some alternative or "lost" science-fiction technology from ancient times. In case of anime series "Zoids", the machines resemble dinosaurs and animals, and have been shown to evolve from native metallic organisms.

A chicken walker is a fictional type of bipedal robot or mecha, distinguished by its rear-facing knee joint. This type of articulation resembles a bird's legs, hence the name. However, birds actually have forward-facing knees; they are digitigrade, and what most call the "knee" is actually the ankle.

The 1868 Edward S. Ellis novel "The Steam Man of the Prairies" featured a steam-powered, back piloted, mechanical man.
The 1880 Jules Verne novel "La Maison à vapeur (The Steam House)" featured a steam-powered, piloted, mechanical elephant. One of the first appearances of such machines in modern literature was the "tripod" or "fighting machine" of H. G. Wells' famous "The War of the Worlds" (1897). The novel does not contain a fully detailed description of the tripods' (or "fighting-machine", as they are known in the novel) mode of locomotion, however it is hinted at: "Can you imagine a milking stool tilted and bowled violently along the ground? That was the impression those instant flashes gave. But instead of a milking stool imagine it a great body of machinery on a tripod stand."

"Ōgon Bat", a kamishibai that debuted in 1931 (later adapted into an anime in 1967), featured the first piloted humanoid giant robot, , but as an enemy rather than a protagonist. The first humanoid giant robot piloted by the protagonist appeared in the manga in 1948. The manga and anime "Tetsujin 28-Go", introduced in 1956, featured a robot, Tetsujin, that was controlled externally by an operator via remote control. The manga and anime "Astro Boy", introduced in 1952, with its humanoid robot protagonist, was a key influence on the development of the giant robot genre in Japan. The first anime featuring a giant mecha being piloted by the protagonist from within a cockpit was the Super Robot show "Mazinger Z", written by Go Nagai and introduced in 1972.

An early use of mech-like machines outside Japan is found in "The Invisible Empire" a "Federal Men" comic by Jerry Siegel and Joe Shuster (serialized 1936 in New Comics #8-10). Other examples include the Brazilian comic "Audaz, the demolisher", by Álvaro "Aruom" Moura and Manoel Messias (1939), Kimball Kinnison's battle suit in E. E. "Doc" Smith's "Lensman" novel "Galactic Patrol" (1950), the french animated film "The King and the Mockingbird" (first released 1952), and the Mobile Infantry battle suits in Robert Heinlein's "Starship Troopers" (1958).

In Japan, "robot anime" (known as "mecha anime" outside Japan) is one of the oldest genres in anime. Robot anime is often tied in with toy manufacturers. Large franchises such as Zoids and Gundam have hundreds of different model kits.

The size of mecha can vary according to the story and concepts involved. Some of them may not be considerably taller than a tank ("Armored Trooper Votoms", "Megazone 23", "Code Geass"), some may be a few stories tall ("Gundam", "Escaflowne", "Bismark", "Gurren Lagann"), others can be as tall as a skyscraper ("Space Runaway Ideon", "Genesis of Aquarion", "Neon Genesis Evangelion"), some are big enough to contain an entire city ("Macross"), some the size of a planet ("Diebuster"), galaxies ("Getter Robo", "Tengen Toppa Gurren Lagann"), or even as large as universes ("Tengen Toppa Gurren Lagann: Lagann-hen", "Demonbane").

The first giant robot seen was Mitsuteru Yokoyama's 1956 manga "Tetsujin 28-go". However, it wasn't until the advent of Go Nagai's "Mazinger Z" that the genre was established. "Mazinger Z" innovated by adding the inclusion of futuristic weapons, and the concept of being able to pilot from a cockpit (rather than via remote control, in the case of Tetsujin). According to Go Nagai:

"Mazinger Z" featured giant robots which were "piloted by means of a small flying car and command center that docked inside the head." It was also a pioneer in die-cast metal toys such as the Chogokin series in Japan and the Shogun Warriors in the U.S., that were (and still are) very popular with children and collectors.

Robot/mecha anime and manga differ vastly in storytelling and animation quality from title to title, and content ranges all the way from children's shows to ones intended for an older teen or adult audience.

Some robot mecha are capable of transformation ("Macross" and "Zeta Gundam") or combining to form even bigger ones ("Beast King GoLion" and "Tengen Toppa Gurren Lagann"). Go Nagai is also often credited with inventing this in 1974 with the television series "Getter Robo".

Not all mecha need be completely mechanical. Some have biological components with which to interface with their pilots, and some are partially biological themselves, such as in "Neon Genesis Evangelion", "Eureka Seven", and "Zoids".

Mecha based on anime have seen extreme cultural reception across the world. The personification of this popularity can be seen as 1:1 size "Mazinger Z", Tetsujin, and Gundam statues built across the world.


Mecha are often featured in computer and console video games. Because of their size and fictional power, mecha are quite popular subjects for games, both tabletop and electronic. They have been featured in video games since the 1980s, particularly in vehicular combat and shooter games, including Sesame Japan's side-scrolling shooter game "Vastar" in 1983, various "Gundam" games such as "" in 1984 and "" in 1986, the run and gun shooters "Hover Attack" in 1984 and "Thexder" in 1985, and Arsys Software's 3D role-playing shooters "WiBArm" in 1986 and "Star Cruiser" in 1988. Historically mecha-based games have been more popular in Japan than in other countries.


There are a few real prototypes of mecha-like vehicles. Currently almost all of these are highly specialized or just for concept purpose, and as such may not see mass production.


In the Western world, there are few examples of mecha, however, several machines have been constructed by both companies and private figures. Timberjack, a subsidiary of John Deere, built a practical hexapod walking harvester.




</doc>
<doc id="20560" url="https://en.wikipedia.org/wiki?curid=20560" title="Macro (computer science)">
Macro (computer science)

A macro (short for "macroinstruction", from Greek 'long') in computer science is a rule or pattern that specifies how a certain input sequence (often a sequence of characters) should be mapped to a replacement output sequence (also often a sequence of characters) according to a defined procedure. The mapping process that instantiates (transforms) a macro use into a specific sequence is known as "macro expansion". A facility for writing macros may be provided as part of a software application or as a part of a programming language. In the former case, macros are used to make tasks using the application less repetitive. In the latter case, they are a tool that allows a programmer to enable code reuse or even to design domain-specific languages.

Macros are used to make a sequence of computing instructions available to the programmer as a single program statement, making the programming task less tedious and less error-prone. (Thus, they are called "macros" because a "big" block of code can be expanded from a "small" sequence of characters.) Macros often allow positional or keyword parameters that dictate what the conditional assembler program generates and have been used to create entire programs or program suites according to such variables as operating system, platform or other factors. The term derives from "macro instruction", and such expansions were originally used in generating assembly language code.

Keyboard macros and mouse macros allow short sequences of keystrokes and mouse actions to transform into other, usually more time-consuming, sequences of keystrokes and mouse actions. In this way, frequently used or repetitive sequences of keystrokes and mouse movements can be automated. Separate programs for creating these macros are called macro recorders.

During the 1980s, macro programs – originally SmartKey, then SuperKey, KeyWorks, Prokey – were very popular, first as a means to automatically format screenplays, then for a variety of user input tasks. These programs were based on the TSR (terminate and stay resident) mode of operation and applied to all keyboard input, no matter in which context it occurred. They have to some extent fallen into obsolescence following the advent of mouse-driven user interfaces and the availability of keyboard and mouse macros in applications such as word processors and spreadsheets, making it possible to create application-sensitive keyboard macros.

Keyboard macros have in more recent times come to life as a method of exploiting the economy of massively multiplayer online role-playing games (MMORPGs). By tirelessly performing a boring, repetitive, but low risk action, a player running a macro can earn a large amount of the game's currency or resources. This effect is even larger when a macro-using player operates multiple accounts simultaneously, or operates the accounts for a large amount of time each day. As this money is generated without human intervention, it can dramatically upset the economy of the game. For this reason, use of macros is a violation of the TOS or EULA of most MMORPGs, and administrators of MMORPGs fight a continual war to identify and punish macro users.

Keyboard and mouse macros that are created using an application's built-in macro features are sometimes called application macros. They are created by carrying out the sequence once and letting the application record the actions. An underlying macro programming language, most commonly a scripting language, with direct access to the features of the application may also exist.

The programmers' text editor, Emacs, (short for "editing macros") follows this idea to a conclusion. In effect, most of the editor is made of macros. Emacs was originally devised as a set of macros in the editing language TECO; it was later ported to dialects of Lisp.

Another programmers' text editor, Vim (a descendant of vi), also has full implementation of macros. It can record into a register (macro) what a person types on the keyboard and it can be replayed or edited just like VBA macros for Microsoft Office. Vim also has a scripting language called Vimscript to create macros.

Visual Basic for Applications (VBA) is a programming language included in Microsoft Office from Office 97 through Office 2019 (although it was available in some components of Office prior to Office 97). However, its function has evolved from and replaced the macro languages that were originally included in some of these applications.

VBA has access to most Microsoft Windows system calls and executes when documents are opened. This makes it relatively easy to write computer viruses in VBA, commonly known as macro viruses. In the mid-to-late 1990s, this became one of the most common types of computer virus. However, during the late 1990s and to date, Microsoft has been patching and updating their programs. In addition, current anti-virus programs immediately counteract such attacks.

A parameterized macro is a macro that is able to insert given objects into its expansion. This gives the macro some of the power of a function.

As a simple example, in the C programming language, this is a typical macro that is "not" a parameterized macro:
This causes the string "PI" to be replaced with "3.14159" wherever it occurs. It will always be replaced by this string, and the resulting string cannot be modified in any way. An example of a parameterized macro, on the other hand, is this:
What this macro expands to depends on what argument "x" is passed to it. Here are some possible expansions:
Parameterized macros are a useful source-level mechanism for performing in-line expansion, but in languages such as C where they use simple textual substitution, they have a number of severe disadvantages over other mechanisms for performing in-line expansion, such as inline functions.

The parameterized macros used in languages such as Lisp, PL/I and Scheme, on the other hand, are much more powerful, able to make decisions about what code to produce based on their arguments; thus, they can effectively be used to perform run-time code generation.

Languages such as C and some assembly languages have rudimentary macro systems, implemented as preprocessors to the compiler or assembler. C preprocessor macros work by simple textual substitution at the token, rather than the character level. However, the macro facilities of more sophisticated assemblers, e.g., IBM High Level Assembler (HLASM) can't be implemented with a preprocessor; the code for assembling instructions and data is interspersed with the code for assembling macro invocations. 
A classic use of macros is in the computer typesetting system TeX and its derivatives, where most of the functionality is based on macros.
MacroML is an experimental system that seeks to reconcile static typing and macro systems. Nemerle has typed syntax macros, and one productive way to think of these syntax macros is as a multi-stage computation.
Other examples:

Some major applications have been written as text macro invoked by other applications, e.g., by XEDIT in CMS.

Some languages, such as PHP, can be embedded in free-format text, or the source code of other languages. The mechanism by which the code fragments are recognised (for instance, being bracketed by codice_1 and codice_2) is similar to a textual macro language, but they are much more powerful, fully featured languages.

Macros in the PL/I language are written in a subset of PL/I itself: the compiler executes "preprocessor statements" at compilation time, and the output of this execution forms part of the code that is compiled. The ability to use a familiar procedural language as the macro language gives power much greater than that of text substitution macros, at the expense of a larger and slower compiler.

Frame technology's frame macros have their own command syntax but can also contain text in any language. Each frame is both a generic component in a hierarchy of nested subassemblies, and a procedure for integrating itself with its subassembly frames (a recursive process that resolves integration conflicts in favor of higher level subassemblies). The outputs are custom documents, typically compilable source modules. Frame technology can avoid the proliferation of similar but subtly different components, an issue that has plagued software development since the invention of macros and subroutines.

Most assembly languages have less powerful procedural macro facilities, for example allowing a block of code to be repeated N times for loop unrolling; but these have a completely different syntax from the actual assembly language.

Macro systems—such as the C preprocessor described earlier—that work at the level of lexical tokens cannot preserve the lexical structure reliably.
Syntactic macro systems work instead at the level of abstract syntax trees, and preserve the lexical structure of the original program. The most widely used implementations of syntactic macro systems are found in Lisp-like languages. These languages are especially suited for this style of macro due to their uniform, parenthesized syntax (known as S-expressions). In particular, uniform syntax makes it easier to determine the invocations of macros. Lisp macros transform the program structure itself, with the full language available to express such transformations. While syntactic macros are often found in Lisp-like languages, they are also available in other languages such as Prolog, Dylan, Scala, Nemerle, Rust, Elixir, Nim, Haxe, and Julia. They are also available as third-party extensions to JavaScript, C# and Python..

Before Lisp had macros, it had so-called FEXPRs, function-like operators whose inputs were not the values computed by the arguments but rather the syntactic forms of the arguments, and whose output were values to be used in the computation. In other words, FEXPRs were implemented at the same level as EVAL, and provided a window into the meta-evaluation layer. This was generally found to be a difficult model to reason about effectively.

In 1963, Timothy Hart proposed adding macros to Lisp 1.5 in AI Memo 57: MACRO Definitions for LISP.

An anaphoric macro is a type of programming macro that deliberately captures some form supplied to the macro which may be referred to by an anaphor (an expression referring to another). Anaphoric macros first appeared in Paul Graham's On Lisp and their name is a reference to linguistic anaphora—the use of words as a substitute for preceding words.

In the mid-eighties, a number of papers introduced the notion of hygienic macro expansion (codice_3), a pattern-based system where the syntactic environments of the macro definition and the macro use are distinct, allowing macro definers and users not to worry about inadvertent variable capture (cf. referential transparency). Hygienic macros have been standardized for Scheme in the R5RS, R6RS, and R7RS standards. A number of competing implementations of hygienic macros exist such as codice_4, codice_5, explicit renaming, and syntactic closures. Both codice_4 and codice_5 have been standardized in the Scheme standards.

Recently, Racket has combined the notions of hygienic macros with a "tower of evaluators", so that the syntactic expansion time of one macro system is the ordinary runtime of another block of code, and showed how to apply interleaved expansion and parsing in a non-parenthesized language.

A number of languages other than Scheme either implement hygienic macros or implement partially hygienic systems. Examples include Scala, Rust, Elixir, Julia, Dylan, and Nemerle.


Felleisen conjectures that these three categories make up the primary legitimate uses of macros in such a system. Others have proposed alternative uses of macros, such as anaphoric macros in macro systems that are unhygienic or allow selective unhygienic transformation.

The interaction of macros and other language features has been a productive area of research. For example, components and modules are useful for large-scale programming, but the interaction of macros and these other constructs must be defined for their use together. Module and component-systems that can interact with macros have been proposed for Scheme and other languages with macros. For example, the Racket language extends the notion of a macro system to a syntactic tower, where macros can be written in languages including macros, using hygiene to ensure that syntactic layers are distinct and allowing modules to export macros to other modules.

Macros are normally used to map a short string (macro invocation) to a longer sequence of instructions. Another, less common, use of macros is to do the reverse: to map a sequence of instructions to a macro string. This was the approach taken by the STAGE2 Mobile Programming System, which used a rudimentary macro compiler (called SIMCMP) to map the specific instruction set of a given computer to counterpart "machine-independent" macros. Applications (notably compilers) written in these machine-independent macros can then be run without change on any computer equipped with the rudimentary macro compiler. The first application run in such a context is a more sophisticated and powerful macro compiler, written in the machine-independent macro language. This macro compiler is applied to itself, in a bootstrap fashion, to produce a compiled and much more efficient version of itself. The advantage of this approach is that complex applications can be ported from one computer to a very different computer with very little effort (for each target machine architecture, just the writing of the rudimentary macro compiler). The advent of modern programming languages, notably C, for which compilers are available on virtually all computers, has rendered such an approach superfluous. This was, however, one of the first instances (if not the first) of compiler bootstrapping.

While "macro instructions" can be defined by a programmer for any set of native assembler program instructions, typically macros are associated with macro libraries delivered with the operating system allowing access to operating system functions such as

In older operating systems such as those used on IBM mainframes, full operating system functionality was only available to assembler language programs, not to high level language programs (unless assembly language subroutines were used, of course), as the standard macro instructions did not always have counterparts in routines available to high-level languages.

In the mid-1950s, when assembly language programming was commonly used to write programs for digital computers, the use of macro instructions was initiated for two main purposes: to reduce the amount of program coding that had to be written by generating several assembly language statements from one macro instruction and to enforce program writing standards, e.g. specifying input/output commands in standard ways. Macro instructions were effectively a middle step between assembly language programming and the high-level programming languages that followed, such as FORTRAN and COBOL. Two of the earliest programming installations to develop "macro languages" for the IBM 705 computer were at Dow Chemical Corp. in Delaware and the Air Material Command, Ballistics Missile Logistics Office in California. A macro instruction written in the format of the target assembly language would be processed by a macro compiler, which was a pre-processor to the assembler, to generate one or more assembly language instructions to be processed next by the assembler program that would translate the assembly language instructions into machine language instructions.

By the late 1950s the macro language was followed by the Macro Assemblers. This was a combination of both where one program served both functions, that of a macro pre-processor and an assembler in the same package. This allowed assembly language programmers to implement their own macro-language and allowed limited portability of code between two machines running the same CPU but different operating systems, for example, early versions of MSDOS and CPM-86. The macro library would need to be written for each target machine but not the overall assembly language program. Note that more powerful macro assemblers allowed use of conditional assembly constructs in macro instructions that could generate different code on different machines or different operating systems, reducing the need for multiple libraries.

In the 1980s and early 1990s, desktop PCs were only running at a few MHz and assembly language routines were commonly used to speed up programs written in C, Fortran, Pascal and others. These languages, at the time, used different calling conventions. Macros could be used to interface routines written in assembly language to the front end of applications written in almost any language. Again, the basic assembly language code remained the same, only the macro libraries needed to be written for each target language.

In modern operating systems such as Unix and its derivatives, operating system access is provided through subroutines, usually provided by dynamic libraries. High-level languages such as C offer comprehensive access to operating system functions, obviating the need for assembler language programs for such functionality.




</doc>
<doc id="20561" url="https://en.wikipedia.org/wiki?curid=20561" title="Malleus Maleficarum">
Malleus Maleficarum

The Malleus Maleficarum, usually translated as the Hammer of Witches, is the best known treatise on witchcraft. It was written by the discredited Catholic clergyman Heinrich Kramer (under his Latinized name "Henricus Institoris") and first published in the German city of Speyer in 1487. It endorses extermination of witches and for this purpose develops a detailed legal and theological theory. It has been described as the compendium of literature in demonology of the fifteenth century. The top theologians of the Inquisition at the Faculty of Cologne condemned the book as recommending unethical and illegal procedures, as well as being inconsistent with Catholic doctrines of demonology.

The "Malleus" elevates sorcery to the criminal status of heresy and recommends that secular courts prosecute it as such in order to eliminate witches. The recommended procedures include torture to effectively obtain confessions and the death penalty as the only sure remedy against the evils of witchcraft. At that time, it was typical to burn heretics alive at the stake and the "Malleus" encouraged the same treatment of witches. The book had a strong influence on culture for several centuries.

Jacob Sprenger's name was added as an author beginning in 1519, 33 years after the book's first publication and 24 years after Sprenger's death; but the veracity of this late addition has been questioned by many historians for various reasons.

Kramer wrote the "Malleus" following his expulsion from Innsbruck by the local bishop, due to charges of illegal behavior against Kramer himself, and because of Kramer's obsession with the sexual habits of one of the accused, Helena Scheuberin, which led the other tribunal members to suspend the trial.

It was later used by royal courts during the Renaissance, and contributed to the increasingly brutal prosecution of witchcraft during the 16th and 17th centuries.

Witchcraft had long been forbidden by the Church, whose attitude on the subject was explained in the "Canon Episcopi" written in about AD 900. It stated that witchcraft and magic were just delusions and that those who believed in such things "had been seduced by the Devil in dreams and visions". However, in the same period supernatural intervention was accepted in the form of ordeals that were later also used during witch trials. 

Possessions by the Devil are considered real even in present times by some Christians and it is a part of doctrine that demons may be cast out by appropriate sacramental exorcisms. In the "Malleus", exorcism is, for example, one of the five ways to overcome the attacks of incubi. Prayer and transubstantiation are excluded from the category of magical rites, as they emanate from God.

In 1484 clergyman Heinrich Kramer made one of the first attempts at prosecuting alleged witches in the Tyrol region. It was not a success: he was expelled from the city of Innsbruck and dismissed by the local bishop as "senile and crazy". According to Diarmaid MacCulloch, writing the book was Kramer's act of self-justification and revenge. Ankarloo and Clark claim that Kramer's purpose in writing the book was to explain his own views on witchcraft, systematically refute arguments claiming that witchcraft did not exist, discredit those who expressed skepticism about its reality, claim that those who practised witchcraft were more often women than men, and to convince magistrates to use Kramer's recommended procedures for finding and convicting witches.

Some scholars have suggested that following the failed efforts in Tyrol, Kramer requested explicit authority from the Pope to prosecute witchcraft. Kramer received a papal bull "Summis desiderantes affectibus" in 1484. It gave full papal approval for the Inquisition to prosecute what was deemed to be witchcraft in general and also gave individual authorizations to Kramer and Dominican Friar Jacob Sprenger specifically. Other scholars have disputed the idea that Sprenger was working with Kramer, arguing that the evidence shows that Sprenger was actually a persistent opponent of Kramer, even going so far as to ban him from Dominican convents within Sprenger's jurisdiction while also banning him from preaching. In the words of Wolfgang Behringer:

Sprenger had tried to suppress Kramer's activities in every possible way. He forbade the convents of his province to host him, he forbade Kramer to preach, and even tried to interfere directly in the affairs of Kramer's Séléstat convent... The same day Sprenger became successor to Jacob Strubach as provincial superior (October 19, 1487), he obtained permission from his general, Joaquino Turriani, to lash out "adversus m[agistrum] Henricum Institoris inquisitorem" ("English": against Master Heinrich Kramer, inquisitor).

The preface also includes an alleged unanimous approbation from the University of Cologne's Faculty of Theology. Nevertheless, many historians have argued that it is well established by sources outside the "Malleus" that the university's theology faculty condemned the book for unethical procedures and for contradicting Catholic theology on a number of important points: "just for good measure Institoris forged a document granting their apparently unanimous approbation." 

The book became the handbook for secular courts throughout Renaissance Europe, but was not used by the Inquisition, which "denied any authority to the "Malleus"" in the words of historian Wolfgang Behringer.

In modern times, the book has often been viewed as a typical inquisitorial manual, a perception that many historians have refuted. According to historian Jenny Gibbons:

Before 1400 it was rare for anyone to be persecuted for witchcraft, but the increasingly common persecution of heresy and failure to fully defeat these heretics paved the way for later criminal prosecution of witchcraft. By the 15th century belief in witches was widely accepted in European society. Previously, those convicted of witchcraft typically suffered penalties no more harsh than public penances such as a day in the stocks, but their persecution became more brutal following the publication of the "Malleus Maleficarum", as witchcraft became widely accepted as a real and dangerous phenomenon. The most severe persecutions took place between the years 1560 and 1630, largely ending in Europe around 1780.

Particularly in the 16th and 17th centuries an intense debate on the nature of witches preoccupied demonologists across Europe and they published many printed sermons, books and tracts. The Catholic Church played an important role in shaping of debate on demonology, but the discourse was not much affected by the Reformation. Martin Luther was also convinced about the reality and evil of witches, and facilitated development of Protestant demonology. 

Catholic and Protestant demonologies were similar in their basic beliefs about witches and most writers agreed on the severity of the crime of witchcraft. It was accepted by both Catholic and Protestant legislatures and witch-hunting was undeniably sponsored by both Protestant and Catholic governments. Witches became heretics to Christianity and witchcraft became the greatest of crimes and sins. Within continental and Roman Law witchcraft was the "crimen exceptum", a crime so foul that all normal legal procedures were superseded.

During the Age of Enlightenment, belief in the powers of witches to harm began to die out in the West. For the post-Enlightenment Christians, the disbelief was based on a belief in rationalism and empiricism.

The "Malleus Maleficarum" consists of the following parts:

In this part it is briefly explained that prevalence of sorcery which is a method of Satan's final assault motivated authors to write the "Malleus Maleficarum":
[...] [ Lucifer ] attacks through these heresies at that time in particular, when the evening of the world declines towards its setting and the evil of men swells up, since he knows in great anger, as John bears witness in the Book of Apocalypse [12:12], that he has little time remaining. Hence, he has also caused a certain unusual heretical perversity to grow up in the land of the Lord – a Heresy, I say, of Sorceresses, since it is to be designated by the particular gender over which he is known to have power. [...] In the midst of these evils, we Inquisitors, Jacobus Sprenger together with the very dear associate [Institoris] delegated by the Apostolic See for the extermination of so destructive a heresy [...] we will bring everything to the desired conclusion. [...] naming the treatise the "Hammer for Sorceresses," we are undertaking the task of compiling the work for an associate [presumably, an ecclesiastic] [...]

Copies of the "Malleus Maleficarum" contain a reproduction of a papal bull known as "Summis desiderantes affectibus" that is addressed to Heinrich Institoris and Jakob Sprenger. According to it, Pope Innocent VIII acknowledges that sorceresses are real and harmful through their involvement in the acts of Satan. As Mackay writes "It is then noted that "Institoris"'s and Sprenger's efforts to stamp these activities out had met with opposition in the form of technical objections relating to the specific offenses that were covered by their appointment as inquisitors, which the pope then overrides by reiterating and amplifying the terms of the inquisitors' appointment."

According to the date on the document, the papal bull had been issued in 1484, two years before the "Malleus Maleficarum" was finished. Therefore, it is not an endorsement of a specific final text of the "Malleus". Instead, its inclusion implicitly legitimizes the handbook by providing general confirmation of the reality of witchcraft and full authority to Sprenger and Institoris in their preachings and proceedings:

This part of the "Malleus" is titled "The Approbation of The Following Treatise and The Signatures Thereunto of The Doctors of The Illustrious University of Cologne Follows in The Form of A Public Document" and contains unanimous approval of the "Malleus Maleficarum" by all the Doctors of the Theological Faculty of the University of Cologne signed by them personally. The proceedings are attested by notary public Arnold Kolich of Euskirchen, a sworn cleric of Cologne with inclusion of confirmatory testimony by present witnesses Johannes Vorda of Mecheln a sworn beadle, Nicholas Cuper de Venrath the sworn notary of Curia of Cologne and Christian Wintzen of Euskirchen a cleric of the Diocese of Cologne.

Text of approbation mentions that during proceedings Institoris had a letter from Maximilian I, Holy Roman Emperor which is summarized in the approbation: "[... Maximilian I] takes these Inquisitors under his complete protection, ordering and commanding each and every subject of the Roman Empire to render all favor and assistance to these Inquisitors and otherwise to act in the manner that is more fully contained and included in the letter."

The approbation consists of a preamble and is followed by a resolution in two parts.

It begins with a general statement about circumstances: IN THE NAME OF Our Lord Jesus Christ. Amen. Let all those who will read, see or hear the present public document know that in the year since the Birth of Our Lord 1487, in the fifth indiction, on Saturday, the nineteenth day of May, at five in the afternoon or thereabouts, in the third year of the Pontificate of Our Lord, the Most Holy Father in Christ, Lord Innocent VIII, by Divine Providence Pope, in the presence of my notary public and of the witnesses written below who had been specifically summoned and asked for this purpose, the venerable and religious Brother Henricus Institoris, Professor of Holy Theology and member of the Order of Preachers, who was appointed as Inquisitor into Heretical Depravity by the Holy See along with his colleague, the venerable and religious Brother Jacobus Sprenger, also a Professor of Holy Theology and Prior of the Convent of Preachers in Cologne[...]

Then, signatories complain that "Some curates of souls and preachers of the Word of God feel no shame at claiming and affirming in their sermons to the congregation that sorceresses do not exist" and notice that the intention of the authors of the "Malleus Maleficarum" is not primarily to alleviate this ignorance but rather "toil to exterminate the sorceresses by explaining the appropriate methods of sentencing and punishing them in accordance with the text of the aforementioned Bull and the regulations of the Holy Canons, thereby achieving their extermination"; finally, signatories explain why they are providing their expertise: It is consonant with reason that those things that are done on behalf of the common good should also be confirmed through the common approval of the Doctors, and therefore, lest the aforementioned poorly educated curates and preachers think, in their ignorance of Holy Scripture, that the aforesaid treatise, which was composed in the manner mentioned above, is poorly supported by the determinations and pronouncements of the Doctors, they offered it for examination and comparison against Scripture to the illustrious University of Cologne or rather to certain Professors of Holy Theology, in order that if any things were found to be worthy of censure or incompatible with the Catholic Truth, they should be refuted by the judgment of those Professors, and that those things found to be compatible with the Catholic Truth should be approved. This was in fact done in the ways written below.

There are two signings, sometimes also referenced as two approbations. The difference is that four signatories of the first part testify that they have examined the treatises and endorse its text while in the second signing signatories do not assert that they have read the treatises but nonetheless express approval by explicitly restating some general propositions of the treatises and endorsing them instead.

In the first part, the opinion of a "temporary Dean of the Faculty of Holy Theology at Cologne" namely Lambertus de Monte of 's-Heerenberg is expressed and then professors Jacobus Straelen of Noetlinck, Andreas Schermer of Ochsenfurt and Thomas Lyel of Scotland testify that they agree with his opinion. The following is an excerpt from the opinion: [I proclaim] that this three part treatise, which has been examined by me and carefully compared against Scripture with regard to its first two parts, contains nothing, in my humble judgment at least, that is contrary to the pronouncements of the non-erroneous philosophers, or against the Truth of the Holy, Catholic and Apostolic Faith, or against the determinations of the Doctors approved or admitted by the Holy Church, and that the third part should certainly be upheld and approved in regard to the punishments of those heretics whom it treats, in that it does not contradict Holy Canons, and also because of the personal experiences described in this treatise, which are believed to be true because of the reputation of such great men, particularly since they are inquisitors. It should be ensured that this treatise will become known to learned and zealous men, who will then, on the basis of it, provide various healthy and appropriate advice for the extermination of sorceresses [...]

The second part is signed by those from the first signing and in addition by professors Ulrich Kridweiss of Esslingen, Konrad Vorn of Kampen, Cornelius Pays of Breda and Dietrich of Balveren (Bummel). Signatories attest that: 1) The Masters of Holy Theology written below commend the Inquisitors into Heretical Depravity appointed by the authority of the Apostolic See in conformity with the Canons, and urge that they think it right to carry out their office zealously.<br>2) The proposition that acts of sorcery can happen with God's permission through sorcerers or sorceresses when the Devil works with them is not contrary to the Catholic Faith, but consonant with the statements of Holy Scripture. Indeed, according to the pronouncements of the Holy Doctors it is necessary to admit that such acts can sometimes happen.<br>3) It is therefore erroneous to preach that acts of sorcery cannot happen, because in this way preachers impede, to the extent that they can, the pious work of the inquisitors, to the prejudice of the salvation of souls. Nonetheless, secrets that are heard at any time by inquisitors should not be revealed to everyone.<br>4) All princes and Catholics should be urged to think it right to assist such pious vows on the part of the Inquisitors in defense of the Holy Catholic Faith.

The "Malleus Maleficarum" asserts that three elements are necessary for witchcraft: the evil intentions of the witch, the help of the Devil, and the permission of God. The treatise is divided into three sections. The first section is aimed at clergy and tries to refute critics who deny the reality of witchcraft, thereby hindering its prosecution.

The second section describes the actual forms of witchcraft and its remedies. The third section is to assist judges confronting and combating witchcraft, and to aid the inquisitors by removing the burden from them. Each of the three sections has the prevailing themes of what is witchcraft and who is a witch.

Section I examines the concept of witchcraft theoretically, from the point of view of natural philosophy and theology. Specifically it addresses the question of whether witchcraft is a real phenomenon or imaginary, perhaps "deluding phantasms of the devil, or simply the fantasies of overwrought human minds". The conclusion drawn is that witchcraft must be real because the Devil is real. Witches entered into a pact with Satan to allow them the power to perform harmful magical acts, thus establishing an essential link between witches and the Devil.

Matters of practice and actual cases are discussed, and the powers of witches and their recruitment strategies. It states that it is mostly witches, as opposed to the Devil, who do the recruiting, by making something go wrong in the life of a respectable matron that makes her consult the knowledge of a witch, or by introducing young maidens to tempting young devils. It details how witches cast spells, and remedies that can be taken to prevent witchcraft, or help those who have been affected by it.

Section III is the legal part of the "Malleus Maleficarum" that describes how to prosecute a witch. The arguments are clearly laid for the lay magistrates prosecuting witches. The section offers a step-by-step guide to the conduct of a witch trial, from the method of initiating the process and assembling accusations, to the interrogation (including torture) of witnesses, and the formal charging of the accused. Women who did not cry during their trial were automatically believed to be witches.

Jakob Sprenger was an appointed inquisitor for the Rhineland, theology professor and a dean at the University of Cologne in Germany. Heinrich Kraemer (Institoris) was an appointed inquisitor of south Germany, a professor of theology at the University of Salzburg, the leading demonologist and witch-hunter in late medieval Germany. Pope Innocent VIII in Papal Bull "Summis desiderantes affectibus" refers to them both as "beloved sons" and "professors of theology"; also authorizes them to extirpate witchcraft.

The "Malleus Maleficarum" was intended to implement Exodus 22:18: "You shall not permit a sorceress to live." and explicitly argues that "Canon Episcopi" does not apply to the new, formerly unknown heresy of "modern witchcraft". Kramer and Sprenger were the first to raise harmful sorcery to the criminal status of heresy. [...] If harmful sorcery is a crime on the order of heresy, Kramer and Sprenger argue, then the secular judges who prosecute it must do so with the same vigor as would the "Inquisition" in prosecuting a heretic. The "Malleus" urges them to adopt torture, leading questions, the admission of denunciation as valid evidence, and other Inquisitorial practices to achieve swift results. Moreover, the authors insist that the death penalty for convicted witches is the only sure remedy against witchcraft. They maintain that the lesser penalty of banishment prescribed by "Canon Episcopi" for those convicted of harmful sorcery does not apply to the new breed of witches, whose unprecedented evil justifies capital punishment.

The treatise often makes references to the Bible and Aristotelian thought, and it is heavily influenced by the philosophical tenets of Neoplatonism. The first section of the book's main text is written using the scholastic methodology of Thomas Aquinas characterized by a mode of "disputed questions" most notably used in his "Summa Theologica". It was a standard mode of argumentation in scholastic discourse with a long tradition. Most of the citations in the "Malleus" come from multiple works of Aquinas, a highly influential author in theology. Aquinas is a main source for Section I but is cited in all sections; "Formicarius" by Johannes Nider is the important source for Section II, and "Directorium Inquisitorum" by Spanish inquisitor Nicholas Eymeric is a crucial source for Section III.

The ancient subjects of astronomy, philosophy, and medicine were being reintroduced to the West at this time, as well as a plethora of ancient texts being rediscovered and studied. The "Malleus" also mentions astrology and astronomy, which had recently been reintroduced to the West through the ancient works of Pythagoras. The "Malleus" is also heavily influenced by the subjects of divination, astrology, and healing rituals the Church inherited from antiquity.

Importantly, Kramer and Sprenger were convinced that God would never permit an innocent person to be convicted of witchcraft.

The "Malleus" recommended not only torture but also deception in order to obtain confessions: "And when the implements of torture have been prepared, the judge, both in person and through other good men zealous in the faith, tries to persuade the prisoner to confess the truth freely; but, if he will not confess, he bid attendants make the prisoner fast to the strappado or some other implement of torture. The attendants obey forthwith, yet with feigned agitation. Then, at the prayer of some of those present, the prisoner is loosed again and is taken aside and once more persuaded to confess, being led to believe that he will in that case not be put to death." 

All confessions acquired with the use of torture had to be confirmed: "And note that, if he confesses under the torture, he must afterward be conducted to another place, that he may confirm it and certify that it was not due alone to the force of the torture." 

However if there was no confirmation, torture could not be repeated, but it was allowed to continue at a specified day: "But, if the prisoner will not confess the truth satisfactorily, other sorts of tortures must be placed before him, with the statement that unless he will confess the truth, he must endure these also. But, if not even thus he can be brought into terror and to the truth, then the next day or the next but one is to be set for a continuation of the tortures – not a repetition, for it must not be repeated unless new evidences produced. The judge must then address to the prisoners the following sentence: We, the judge, etc., do assign to you, such and such a day for the continuation of the tortures, that from your own mouth the truth may be heard, and that the whole may be recorded by the notary."

The treatise describes how women and men become inclined to practice witchcraft. The text argues that women are more susceptible to demonic temptations through the manifold weaknesses of their gender. It was believed that they were weaker in faith and more carnal than men. Michael Bailey claims that most of the women accused as witches had strong personalities and were known to defy convention by overstepping the lines of proper female decorum. After the publication of the "Malleus", it seems as though about three quarters of those individuals prosecuted as witches were women. 

Witches were usually female. The reasons for this is the suggestion that women are "prone to believing and because the demon basically seeks to corrupt the faith, he assails them in particular." They also have a "temperament towards flux" and "loose tongues". They "are defective in all the powers of both soul and body" and are stated to be more lustful than men. 

The major reason is that at the foundation of sorcery is denial of faith and "woman, therefore, is evil as a result of nature because she doubts more quickly in the faith." Men could be witches, but were considered rarer, and the reasons were also different. The most common form of male witch mentioned in the book is the sorcerer-archer. The book is rather unclear, but the impetus behind male witches seems to come more from desire for power than from disbelief or lust, as it claims is the case for female witches.

Indeed, the very title of the "Malleus Maleficarum" is feminine, alluding to the idea that it was women who were the villains. Otherwise, it would be the "Malleus Maleficorum" (the masculine form of the Latin noun "maleficus" or "malefica," 'witch'). In Latin, the feminine "maleficarum" would only be used for women, while the masculine "maleficorum" could be used for men alone or for both sexes if together. The "Malleus Maleficarum" accuses male and female witches of infanticide, cannibalism and casting evil spells to harm their enemies as well as having the power to steal a man's penis. It goes on to give accounts of witches committing these crimes.

Arguments favoring discrimination against women are explicit in the handbook. Those arguments are not novel but constitute a selection from the long tradition of Western misogynist writings. However, according to Brauner, they are combined to produce new meanings and result in a comprehensive theory. It mixes elements borrowed from "Formicarius" (1435), "Preceptorium divinae legis" (1475) and "Lectiones super ecclesiastes" (1380).Kramer and Sprenger develop a powerful gender-specific theory of witchcraft based on a hierarchical and dualistic view of the world. Everything exists in pairs of opposites: God and Satan, Mary and Eve, and men (or virgins) and women. Each positive principle in a pair is delineated by its negative pole. Perfection is defined not as the integration or preservation of opposites, but rather as the extermination of the negative element in a polar pair. Because women are the negative counterpart to men, they corrupt male perfection through witchcraft and must be destroyed.

Although authors give many examples of male witchery in the second part of the handbook, those witchcraft trials that are independently confirmed and that were led by Kramer himself are related to persecution of women almost exclusively. They took place in Ravensburg near Constance (1484) and Innsbruck (since 1485). According to Brauner, trial records confirm that Kramer believed that women are by nature corrupt and evil. His position was in harmony with the scholastic theory at the time. 

In contrast, Sprenger never conducted a witch trial though he was consulted in a few cases. Kramer and Sprenger use a metaphor of a world turned upside down by women of which concubines are the most wicked, followed by midwives and then by wives who dominate their husbands. Authors warn of imminent arrival of the apocalypse foretold in the Bible and that men risk bewitchment that leads to impotence and sensation of castration. Brauner explains authors' prescription on how a woman can avoid becoming a witch: According to the "Malleus", the only way a woman can avoid succumbing to her passions – and becoming a witch – is to embrace a life of devout chastity in a religious retreat. But the monastic life is reserved to the spiritually gifted few. Therefore, most women are doomed to become witches, who cannot be redeemed; and the only recourse open to the authorities is to ferret out and exterminate all witches.

Strixology in the "Malleus Maleficarum" is characterized by a very specific conception of what a witch is, one that differs dramatically from earlier times. The word used, malefica, carries an explicit condemnation absent in other words referring to women with supernatural powers. The conception of witches and of magic by extension is one of evil. It differs from earlier conceptions of witchcraft that were much more generalized. 

This is the point in history where "witchcraft constituted an independent antireligion". The witch lost her powerful position vis-a-vis the deities; the ability to force the deities comply with her wishes was replaced by a total subordination to the devil. In short, "[t]he witch became Satan's puppet." This conception of witches was "part of a conception of magic that is termed by scholars as 'Satanism' or 'diabolism'". In this conception, a witch was a member of "a malevolent society presided over by Satan himself and dedicated to the infliction of malevolent acts of sorcery ("maleficia") on others."

According to Mackay, this concept of sorcery is characterized by the conviction that those guilty engage in six activities: 

In the "Malleus" demons are the ones who tempt humans to sorcery and are the main figures in the witches' vows. They interact with witches, usually sexually. The book claims that it is normal for all witches "to perform filthy carnal acts with demons." This is a major part of human-demon interaction and demons do it "not for the sake of pleasure, but for the sake of corrupting." 

It is worth noting that not all demons do such things. The book claims that "the nobility of their nature causes certain demons to balk at committing certain actions and filthy deeds." Though the work never gives a list of names or types of demons, like some demonological texts or spellbooks of the era, such as the "Liber Juratus", it does indicate different types of demons. For example, it devotes large sections to incubi and succubi and questions regarding their roles in pregnancies, the submission of witches to incubi, and protections against them.

Joseph Hansen, a historian who was appalled by the witch-craze and those who carried it out, proposed that coauthorship by Sprenger was a falsehood presented by Institoris (Kramer) and that approbation is "partially" a forgery. This had never been proposed before until Joseph Hansen in the nineteenth century.

Christopher Mackay, author of the modern academic translation of the "Malleus" into English offers rebuttals to arguments of proponents of this theory and in an interview gives an accessible summary:
The argument was made in the nineteenth century by a scholar hostile to what the Malleus stood for that the approbation was a forgery by Institoris and that Sprenger had nothing to do with the composition. The evidence for this is in my view very tenuous (and the main argument is clearly invalid). Nonetheless, once the argument was put forward, it took on a life of its own, and people continue to advance arguments in favor of the idea that Sprenger's involvement was a falsification perpetrated by Institoris, despite the fact that this argument was vitiated from the start.
In addition, Mackay points out that allegations raised in support of this theory that supposedly two of the signatories had not in fact signed the approbation are unsubstantiated.

A similar response is offered by the author of the first translation of the "Malleus" into English Montague Summers. In his introduction, he ignores completely the theory that joint authorship or approbation could be a mystification. Nonetheless, he mentions briefly that it was questioned whether Kramer or Sprenger contributed more to the work. He comments that "in the case of such a close collaboration any such inquiry seems singularly superfluous and nugatory".

Broedel, a historian who writes that it is likely that Sprenger's contribution was minimal, nonetheless says that "Sprenger certainly wrote the "Apologia auctoris" which prefaces the "Malleus" and agreed to be a coauthor.

"Encyclopædia Britannica" and "The Encyclopedia of Witches, Witchcraft and Wicca" ignore completely Hansen's theory and list Sprenger and Kramer as co-authors.

Wolfgang Behringer argues that Sprenger's name was only added as an author beginning in 1519, thirty-three years after the book was first published and decades after Sprenger's own death. One of Sprenger's friends who was still alive denounced the addition of Sprenger's name as a forgery, stating that Sprenger had nothing to do with the book. Many historians have also pointed out that Sprenger's actual views in his confirmed writings are often the opposite of the views in the "Malleus", and Sprenger was unlikely to have been a colleague of Kramer since Sprenger in fact banned Kramer from preaching and entering Dominican convents within his jurisdiction, and spoke out against him on many occasions.

The alleged approval from the theologians at Cologne, which Kramer included in the "Malleus" with a list of names of theologians who he claimed approved the book, has also been questioned by many historians, since in 1490 the clergy at Cologne condemned the book and at least two of the clergy listed by Kramer, Thomas de Scotia and Johann von Wörde, publicly denied having approved the "Malleus".

Jacob Sprenger's name was added as an author beginning in 1519, 33 years after the book's first publication and 24 years after Sprenger's death.

Jenny Gibbons, a Neo-Pagan and a historian, writes: "Actually the Inquisition immediately rejected the legal procedures Kramer recommended and censured the inquisitor himself just a few years after the "Malleus" was published. Secular courts, not inquisitorial ones, resorted to the "Malleus"".

The preface also includes an allegedly unanimous approbation from the University of Cologne's Faculty of Theology. Nevertheless, many historians have argued that it is well established by sources outside the "Malleus" that the university's theology faculty condemned the book for unethical procedures and for contradicting Catholic theology on a number of important points : "just for good measure Institoris forged a document granting their apparently unanimous approbation."

In 1484 Heinrich Kramer had made one of the first attempts at prosecuting alleged witches in the Tyrol region. It was not a success and he was asked to leave the city of Innsbruck. According to Diarmaid MacCulloch, writing the book was Kramer's act of self-justification and revenge. Ankarloo and Clark claim that Kramer's purpose in writing the book was to explain his own views on witchcraft, systematically refute arguments claiming that witchcraft does not exist, discredit those who expressed skepticism about its reality, claim that those who practiced witchcraft were more often women than men, and to convince magistrates to use Kramer's recommended procedures for finding and convicting witches.

Kramer wrote the "Malleus" following his expulsion from Innsbruck by the local bishop, due to charges of illegal behavior against Kramer himself, and because of Kramer's obsession with the sexual habits of one of the accused, Helena Scheuberin, which led the other tribunal members to suspend the trial.

Kramer received a papal bull, "Summis desiderantes affectibus", in 1484. It directed Bishop of Strasburg (then Albert of Palatinate-Mosbach) to accept the authority of Heinrich Kramer as an Inquisitor, although the motivation of the papal bull was likely political. The "Malleus Maleficarum" was finished in 1486 and the papal bull was included as part of its preface, implying papal approval for the work..

Kramer was intensely writing and preaching until his death in Bohemia in 1505. He was asked by Nuremberg council to provide expert consultation on the procedure of witch trial in 1491. His prestige was not fading. In 1495 he was summoned by the Master General of the Order, Joaquin de Torres, O.P. to Venice and gave very popular public lectures and disputations. They were worthy of presence and patronage of Patriarch of Venice.

He also wrote treatises "Several Discourses and Various Sermons upon the Most Holy Sacrament of the Eucharist" (Nuremberg, 1496); "A Tract Confuting the Errors of Master Antonio degli Roselli" (Venice, 1499); followed by "The Shield of Defence of the Holy Roman Church Against the Picards and Waldenses" which were quoted by many authors. He was appointed as papal nuncio and his assignment as inquisitor was changed to Bohemia and Moravia by Pope Alexander VI in 1500.

Sprenger continued his work as Inquisitor Extraordinary for the Provinces of Mainz, Trèves and Cologne. Later, he was elected Provincial Superior of the whole German Province (in 1488). He had enormous responsibilities. He received a letter from Pope Alexander VI praising his enthusiasm and energy in 1495.

Summers observes that 17th century "Dominican chroniclers, such as Quétif and Échard, number Kramer and Sprenger among the glories and heroes of their Order".

Gender-specific theory developed in the "Malleus Maleficarum" laid the foundations for widespread consensus in early modern Germany on the evil nature of women as witches. Later works on witchcraft have not agreed entirely with the "Malleus" but none of them challenged the view that women were more inclined to be witches than men. It was perceived as intuitive and all-accepted so that very few authors saw the need to explain why women are witches. Those who did, attributed female witchery to the weakness of body and mind (the old medieval explanation) and a few to female sexuality.

Some authors argue that the book's publication was not as influential as earlier authors believed. According to MacCulloch, the "Malleus Maleficarum" was one of several key factors contributing to the witch craze, along with popular superstition, and tensions created by the Reformation. However, according to "Encyclopædia Britannica":

Between 1487 and 1520, twenty editions of the "Malleus Maleficarum" were published, and another sixteen between 1574 and 1669. The "Malleus Maleficarum" was able to spread throughout Europe rapidly in the late 15th and at the beginning of the 16th century due to the innovation of the printing press in the middle of the 15th century by Johannes Gutenberg. The invention of printing some thirty years before the first publication of the "Malleus Maleficarum" instigated the fervor of witch hunting, and, in the words of Russell, "the swift propagation of the witch hysteria by the press was the first evidence that Gutenberg had not liberated man from original sin."

The late 15th century was also a period of religious turmoil. The "Malleus Maleficarum" and the witch craze that ensued took advantage of the increasing intolerance of the Reformation and Counter-Reformation in Europe, where the Protestant and Catholic camps respectively, pitted against one another, each zealously strove to maintain what they each deemed to be the purity of faith.
The Catholic Counter-Reformation would eventually even out this religious turmoil, but until then both the Catholics and Protestants constantly battled for what they believed was right. 
The Latin book was firstly translated by into German in 1906; an expanded edition of three volumes was published in 1923. Montague Summers was responsible for the first English translation in 1928.

General

People






</doc>
<doc id="20566" url="https://en.wikipedia.org/wiki?curid=20566" title="Mandy Patinkin">
Mandy Patinkin

Mandel Bruce Patinkin (; born November 30, 1952) is an American actor and singer.

Patinkin is well known for his portrayal of Inigo Montoya in the 1987 film "The Princess Bride." His other film credits include "Yentl" (1983), "Alien Nation" (1988), "Dick Tracy" (1990), "The Adventures of Elmo in Grouchland" (1999), and "Wish I Was Here" (2014). He has appeared in major roles in television series such as "Chicago Hope", "Dead Like Me", and "Criminal Minds", and currently plays Saul Berenson in the Showtime series "Homeland".

He is a noted interpreter of the musical works of Stephen Sondheim and is known for his work in musical theater, originating iconic roles such as Georges Seurat in "Sunday in the Park with George" and Ché in the original Broadway production of "Evita".

Mandy Bruce Patinkin was born in Chicago, Illinois, on November 30, 1952, to Doris "Doralee" (née Sinton), a homemaker, and Lester Patinkin, who operated two large Chicago-area metal factories, the People's Iron & Metal Company and the Scrap Corporation of America. His mother wrote "Grandma Doralee Patinkin's Jewish Family Cookbook". Patinkin's cousins include Mark Patinkin, an author and nationally syndicated columnist for "The Providence Journal"; Sheldon Patinkin of Columbia College Chicago's Theater Department, a founder of The Second City; and Bonnie Miller Rubin, a "Chicago Tribune" reporter.

Patinkin grew up in an upper-middle-class family, descended from Jewish immigrants (from Russia and Poland), and was raised in Conservative Judaism,
attending religious school daily "from the age of seven to 13 or 14" and singing in synagogue choirs, as well as attending the Camp Surah in Michigan.

He attended South Shore High School, Harvard St. George School, and Kenwood High School (later renamed Kenwood Academy), and graduated in 1970. He attended the University of Kansas and the Juilliard School (Drama Division "Group 5": 1972–1976). At Juilliard, he was a classmate of Kelsey Grammer. When the producers of the popular American sitcom "Cheers" were holding auditions for the role of Dr. Frasier Crane, Patinkin put Grammer's name forward.

After some television commercial and radio appearances (including the CBS Radio Mystery Theater in 1974), Patinkin had his first success in musical theater, where he played the part of Che in "Evita" on Broadway in 1979. Patinkin went on to win the 1980 Tony Award for Best Performance by a Featured Actor in a Musical. He then moved to film, playing parts in movies such as "Yentl" and "Ragtime". He returned to Broadway in 1984 to star in the Pulitzer Prize-winning musical "Sunday in the Park with George", which saw him earn another Tony Award nomination for Best Actor (Musical).

Patinkin played Inigo Montoya in Rob Reiner's 1987 "The Princess Bride", playing the role of the best swordsman in the country, short of the main character. Over the next decade, he continued to appear in movies, such as "Dick Tracy" and "Alien Nation".

On Broadway, Patinkin appeared in the musical "The Secret Garden" in 1991, and was nominated for the 1991 Drama Desk Award as Outstanding Actor in a Musical. He also released two solo albums, titled "Mandy Patinkin" (1989) and "Dress Casual" (1990).

In 1994, Patinkin took the role of Dr. Jeffrey Geiger on CBS's "Chicago Hope" for which he won an Emmy Award. However, despite the award and the ratings success of the show, Patinkin left the show during the second season because he was unhappy spending so much time away from his wife and children. He returned to the show in 1999 at the beginning of the sixth season, but it was later canceled in 2000. Since "Chicago Hope", Patinkin has appeared in a number of films. However, he has mostly performed as a singer, releasing three more albums. In 1995, he guest-starred in "The Simpsons" in the episode "Lisa's Wedding" as Hugh Parkfield, Lisa's future English groom.

"Mamaloshen", Patinkin's musical production of songs sung entirely in Yiddish, premiered in 1998. He has performed the show on Broadway and in venues around the United States. The recorded version won a "Deutscher Schallplattenpreis" award in Germany.

In 1999, Patinkin co-starred in the second "Sesame Street" film "The Adventures of Elmo in Grouchland" as Huxley, an abusive, childish, sadistic and greedy man with abnormally large eyebrows, who steals whatever he can grab and then claims it as his own. Patinkin returned to Broadway in 2000 in the New York Shakespeare Festival production of John LaChiusa's "The Wild Party", earning another Tony Award nomination for Best Actor (Musical). In 2003-2004 he appeared in the Showtime comedy–drama "Dead Like Me" as Rube Sofer. In 2004 he played a six–week engagement of his one–man concert at the Off-Broadway complex Dodger Stages.

In September 2005, Patinkin debuted in the role of Jason Gideon, an experienced profiler just coming back to work after a series of nervous breakdowns, in the CBS crime drama TV show "Criminal Minds." Patinkin was absent from a table read for "Criminal Minds" and did not return for a third season. The departure from the show was not due to contractual or salary matters, but over creative differences. He left apologetic letters for his fellow cast members explaining his reasons and wishing them luck. Many weeks before his departure, in a videotaped interview carried in the online magazine "Monaco Revue", Patinkin told journalists at the Festival de Télévision de Monte-Carlo that he loathed violence on television and was uncomfortable with certain scenes in "Criminal Minds". He later called his choice to do "Criminal Minds" his "biggest public mistake," and stated that he "thought it was something very different. I never thought they were going to kill and rape all these women every night, every day, week after week, year after year. It was very destructive to my soul and my personality, and after that, I didn't think I would get to work in television again."

He spoke of having planned to tour the world with a musical and wanting to inject more comedy into the entertainment business. In later episodes, during the 2007–08 season, Jason Gideon was written out of the series and replaced by Special Agent David Rossi (played by Joe Mantegna). Gideon was later officially killed off, ending all chances of a guest appearance by Patinkin on the show.

On October 14, 2009, it was announced that Patinkin would be a guest star on an episode of "Three Rivers", which aired on November 15, 2009. He played a patient with Lou Gehrig's disease injured in a car accident who asks the doctors at Three Rivers Hospital to take him off life support so his organs can be donated. He filmed an appearance on "The Whole Truth" that had been scheduled to air December 15, 2010, but ABC pulled the series from its schedule two weeks prior.

He starred in the new musical "Paradise Found", co-directed by Harold Prince and Susan Stroman, at the Menier Chocolate Factory, London. The musical played a limited engagement from May 2010 through June 26, 2010.

Patinkin and Patti LuPone performed their concert "An Evening with Patti LuPone and Mandy Patinkin" on Broadway for a limited 63-performance run starting November 21, 2011, at the Barrymore Theatre, and which ended on January 13, 2012. This concert marks the first time the pair has performed together on Broadway since they appeared together in "Evita".

He currently costars with Claire Danes on the Showtime series "Homeland" which initially aired in 2011. He portrays counterterrorism operative Saul Berenson, protagonist Carrie Mathison's (Danes) mentor. For his performance, Patinkin has been nominated for a Golden Globe and an Emmy Award, among other honors. Explaining what he learned from the character, he stated that "The line between good and evil runs through each one of us."

Patinkin was announced as playing the role of Pierre in the Broadway musical "Natasha, Pierre & The Great Comet of 1812" starting August 15, 2017. He would have a limited run through September 3, replacing former "Hamilton" star Okieriete Onaodowan. The role was originated by Josh Groban. Patinkin later dropped out of the role.

In 2018, Patinkin returned to recorded music with the album "Diary: January 27, 2018" which was produced by pianist Thomas Bartlett.

On June 15, 1980, Patinkin married actress and writer Kathryn Grody. They have two sons named Isaac and Gideon. Gideon joined his father onstage in "Dress Casual" in 2011. Patinkin has described himself as "Jewish with a dash of Buddhist" belief. On the Canadian radio program "Q", Patinkin describes himself as a "JewBu" because of this mix of beliefs and "spiritual but not religious."

Patinkin suffered from keratoconus, a degenerative eye condition, in the mid-1990s. This led to two corneal transplants, his right cornea in 1997 and his left in 1998. He was also diagnosed with and treated for prostate cancer in 2004. He celebrated his first year of recovery in 2005 by doing a charity bike ride with his son, Isaac – the Arava Institute Hazon Israel Ride: Cycling for Peace, Partnership & Environmental Protection.

Patinkin has been involved in a variety of Jewish causes and cultural activities. He sings in Yiddish, often in concert, and on his album "Mamaloshen". He also wrote introductions for two books on Jewish culture, "The Jewish American Family Album", by Dorothy and Thomas Hoobler, and "Grandma Doralee Patinkin's Holiday Cookbook: A Jewish Family's Celebrations", by his mother, Doralee Patinkin Rubin.

In May 2012, Patinkin delivered the opening speech at the Annual Convention of the Israeli Left, where he recounted his experiences during a visit to the West Bank with members of the Breaking the Silence organization.

Patinkin contributed to the children's book "Dewey Doo-it Helps Owlie Fly Again: A Musical Storybook", inspired by Christopher Reeve. The award-winning book, published in 2005, benefits the Christopher Reeve Foundation and includes an audio CD with Patinkin singing and reading the story as well as Dana Reeve and Bernadette Peters singing.

On December 21, 2015, Patinkin was on the "Charlie Rose" program on PBS talking about his recent trip to Greece to help refugees from war-torn Syria and his acting role on the television series "Homeland". He stated that he wanted to help "create opportunity and better systems of living and existing, to give freedom, justice and dignity, quality of life to humanity all over the world."







</doc>
<doc id="20567" url="https://en.wikipedia.org/wiki?curid=20567" title="Mel Smith">
Mel Smith

Melvin Kenneth Smith (3 December 1952 – 19 July 2013) was an English comedian and film director. Smith worked on the sketch comedy shows "Not the Nine O'Clock News" and "Alas Smith and Jones" with his comedy partner, Griff Rhys Jones. Smith and Jones founded Talkback, which grew to be one of the UK's largest producers of television comedy and light entertainment programming.

Smith's father, Kenneth, was born in Tow Law, County Durham, and worked at a coal mine during the Second World War; looking after the pit ponies. After the war ended, he moved to London and married Smith's mother, whose parents owned a greengrocers in Chiswick. When the government legalised high street betting with the Betting and Gaming Act 1960, he turned the shop into the first betting shop in Chiswick.

Smith was born and brought up in Chiswick. He was educated at Hogarth Primary School, Chiswick, and at Latymer Upper School, an independent school in Hammersmith. He went on to study Experimental Psychology at New College, Oxford.

While at Oxford University, Smith produced "The Tempest", and performed at the Edinburgh Fringe with the Oxford University Dramatic Society. One year they shared a venue with the Cambridge Footlights, directed by John Lloyd. His extra-curricular activities while at university led to his joining the Royal Court Theatre production team in London, and then Bristol Old Vic. He was also associate director of Sheffield's Crucible Theatre for two years. Later, he directed a theatre production of "Not in Front of the Audience".

John Lloyd later got the opportunity to develop the idea that became the satirical BBC television series "Not the Nine O'clock News". This was followed briefly by "Smith and Goody" (with Bob Goody) and then the comedy sketch series "Alas Smith and Jones", co-starring Griff Rhys Jones, its title being a pun on the name of the American television series "Alias Smith and Jones". In 1982, he starred as the lead role in ITV drama "Muck and Brass "where he played Tom Craig, a ruthless property developer. In 1984, he appeared in the "Minder" episode "A Star Is Gorn" playing the character Cyril Ash, a record producer. He also guest-starred on "The Goodies" episode Animals. At the end of the 1980s, he played the title role in the sitcom "Colin's Sandwich" (1988–90), playing a British Rail employee with aspirations to be a writer.

In 1981, Smith and Griff Rhys Jones founded TalkBack Productions, a company that has produced many of the most significant British comedy shows of the past two decades, including "Smack the Pony", "Da Ali G Show", "I'm Alan Partridge" and "Big Train". In 2000, the company was sold to Pearson for £62 million.

Smith co-wrote and took the lead role in the space comedy "Morons from Outer Space" (1985), but the film failed to make much impact. His next cinema effort was better received as director of "The Tall Guy" (1989), giving Emma Thompson a major screen role. Perhaps his best-known film in America is "Brain Donors", the 1992 update of the Marx Brothers film "A Night at the Opera", starring Smith as a cheeky, opportunistic cab driver turned ballet promoter. Paramount Pictures considered this film the outstanding comedy of the year, but when the producers left Paramount for another studio, Paramount withdrew its support for the film.

In 1987, Smith recorded a single with Kim Wilde for Comic Relief: a cover of the Christmas song Rockin' Around the Christmas Tree with some additional comedy lines written by Smith and Jones. The pairing of Smith and Wilde was a comic allusion to the duo Mel & Kim. The song reached number three in the UK charts. He appeared in "The Princess Bride" as the Albino.

Smith and Jones were reunited in 2005 for a review/revival of their earlier television series in "The Smith And Jones Sketchbook". Smith joked that "Obviously, Griff's got more money than me so he came to work in a Rolls Royce and I came on a bicycle. But it was great fun to do and we are firmly committed to doing something new together, because you don't chuck that sort of chemistry away. Of course, I'll have to pretend I like "Restoration".

In August 2006, Smith returned to the theatre stage after some 20 years, appearing at the Edinburgh Fringe festival in "Allegiance", Irish journalist and author Mary Kenny's play about Churchill's encounter with the Irish nationalist leader Michael Collins in 1921. The play initially caused some controversy, with Smith proposing to flout the Scottish ban on smoking in public places, but the scene was quickly adapted after gaining the required amount of publicity. The play was directed by Brian Gilbert and produced by Daniel Jewel. In 2006, he also appeared in Hustle as Benjamin Frasier, a pub landlord who was scammed by the Hustle team when his on-screen son Joey tried to launch a rap career.

In autumn 2006, Smith starred opposite Belinda Lang in a tour of a new comedy "An Hour and a Half Late" by French playwright Gérald Sibleyras, which was adapted by Smith. He then directed a West End revival of "Charley's Aunt" starring Stephen Tompkinson. From October 2007 to January 2008 he played the role of Wilbur Turnblad in the London production of "Hairspray" at the Shaftesbury Theatre.

Smith was married to Pamela (née Gay-Rees), a former model, who grew up in Easington and Durham. The couple had houses in St John's Wood (backing onto Lord's Cricket Ground), and the hamlet of Little Haseley, Oxfordshire (a Grade II-listed barn conversion, sold in 2011), as well as a property in Barbados.

Smith was hospitalised in 1999 with stomach ulcers, after an accidental overdose of more than 50 Nurofen Plus tablets a day, after previously admitting an addiction to sleeping pills. Smith said at the time that the pressures of film work were a contributing factor, along with a desperate need to ease the pain caused by gout. Partly as a result, he agreed to sell Talkback Productions. On 31 December 2008, Smith appeared on "Celebrity Mastermind" whilst suffering from severe pharyngitis.

On the morning of 19 July 2013, the London Ambulance Service was called to Smith's home in north-west London. Smith was confirmed dead by the ambulance crew, with a later post-mortem confirming death from a heart attack. Co-star Griff Rhys Jones said: "To everybody who ever met him, Mel was a force for life. He had a relish for it that seemed utterly inexhaustible". Rowan Atkinson, who starred in Smith's film "Bean" and starred with him in "Not the Nine O'Clock News", said: "He had a wonderfully generous and sympathetic presence both on and off screen". Stephen Fry noted that Smith "lived a full life, but was kind, funny and wonderful to know."







</doc>
<doc id="20568" url="https://en.wikipedia.org/wiki?curid=20568" title="Mesolithic">
Mesolithic

In Old World archaeology, Mesolithic (Greek: μέσος, "mesos" "middle"; λίθος, "lithos" "stone") is the period between the Upper Paleolithic and the Neolithic. The term Epipaleolithic is often used synonymously, especially for outside northern Europe, and for the corresponding period in the Levant and Caucasus. The Mesolithic has different time spans in different parts of Eurasia. It refers to the final period of hunter-gatherer cultures in Europe and Western Asia, between the end of the Last Glacial Maximum and the Neolithic Revolution. In Europe it spans roughly 15,000 to 5,000 BP; in Southwest Asia (the Epipalaeolithic Near East) roughly 20,000 to 8,000 BP. The term is less used of areas further east, and not at all beyond Eurasia and North Africa.

The type of culture associated with the Mesolithic varies between areas, but it is associated with a decline in the group hunting of large animals in favour of a broader hunter-gatherer way of life, and the development of more sophisticated and typically smaller lithic tools and weapons than the heavy chipped equivalents typical of the Paleolithic. Depending on the region, some use of pottery and textiles may be found in sites allocated to the Mesolithic, but generally indications of agriculture are taken as marking transition into the Neolithic. The more permanent settlements tend to be close to the sea or inland waters offering a good supply of food. Mesolithic societies are not seen as very complex, and burials are fairly simple; in contrast, grandiose burial mounds are a mark of the Neolithic.

The terms "Paleolithic" and "Neolithic" were introduced by John Lubbock in his work "Pre-historic Times" in 1865. The additional "Mesolithic" category was added as an intermediate category by Hodder Westropp in 1866. Westropp's suggestion was immediately controversial. A British school led by John Evans denied any need for an intermediate: the ages blended together like the colors of a rainbow, he said. A European school led by Louis Laurent Gabriel de Mortillet asserted that there was a gap between the earlier and later.

Edouard Piette claimed to have filled the gap with his naming of the Azilian Culture. Knut Stjerna offered an alternative in the "Epipaleolithic", suggesting a final phase of the Paleolithic rather than an intermediate age in its own right inserted between the Paleolithic and Neolithic.

By the time of Vere Gordon Childe's work, "The Dawn of Europe" (1947), which affirms the Mesolithic, sufficient data had been collected to determine that a transitional period between the Paleolithic and the Neolithic was indeed a useful concept. However, the terms "Mesolithic" and "Epipalaeolitic" remain in competition, with varying conventions of usage. In the archaeology of Northern Europe, for example for archaeological sites in Great Britain, Germany, Scandinavia, Ukraine, and Russia, the term "Mesolithic" is almost always used. In the archaeology of other areas, the term "Epipaleolithic" may be preferred by most authors, or there may be divergences between authors over which term to use or what meaning to assign to each. In the New World, neither term is used (except provisionally in the Arctic).

"Epipaleolithic" is sometimes also used alongside "Mesolithic" for the final end of the Upper Paleolithic immediately followed by the Mesolithic. As "Mesolithic" suggests an intermediate period, followed by the Neolithic, some authors prefer the term "Epipaleolithic" for hunter-gatherer cultures who are not succeeded by agricultural traditions, reserving "Mesolithic" for cultures who are clearly succeeded by the Neolithic Revolution, such as the Natufian culture. Other authors use "Mesolithic" as a generic term for hunter-gatherer cultures after the Last Glacial Maximum, whether they are transitional towards agriculture or not. In addition, terminology appears to differ between archaeological sub-disciplines, with "Mesolithic" being widely used in European archaeology, while "Epipalaeolithic" is more common in Near Eastern archaeology.

The Balkan Mesolithic begins around 15,000 years ago. In Western Europe, the Early Mesolithic, or Azilian, begins about 14,000 years ago, in the Franco-Cantabrian region of northern Spain and southern France. In other parts of Europe, the Mesolithic begins by 11,500 years ago (the beginning Holocene), and it ends with the introduction of farming, depending on the region between c. 8,500 and 5,500 years ago. Regions that experienced greater environmental effects as the last glacial period ended have a much more apparent Mesolithic era, lasting millennia. In northern Europe, for example, societies were able to live well on rich food supplies from the marshlands created by the warmer climate. Such conditions produced distinctive human behaviors that are preserved in the material record, such as the Maglemosian and Azilian cultures. Such conditions also delayed the coming of the Neolithic until some 5,500 BP in northern Europe.

The type of stone toolkit remains one of the most diagnostic features: the Mesolithic used a microlithic technology – composite devices manufactured with Mode V chipped stone tools (microliths), while the Paleolithic had utilized Modes I–IV. In some areas, however, such as Ireland, parts of Portugal, the Isle of Man and the Tyrrhenian Islands, a macrolithic technology was used in the Mesolithic. In the Neolithic, the microlithic technology was replaced by a macrolithic technology, with an increased use of polished stone tools such as stone axes.

There is some evidence for the beginning of construction at sites with a ritual or astronomical significance, including Stonehenge, with a short row of large post holes aligned east-west, and a possible "lunar calendar" at Warren Field in Scotland, with pits of post holes of varying sizes, thought to reflect the lunar phases. Both are dated to before c. 9,000 BP (the 8th millennium BC).

As the "Neolithic package" (including farming, herding, polished stone axes, timber longhouses and pottery) spread into Europe, the Mesolithic way of life was marginalized and eventually disappeared. Mesolithic adaptations such as sedentism, population size and use of plant foods are cited as evidence of the transition to agriculture. In one sample from the Blätterhöhle in Hagen, it seems that the descendants of Mesolithic people maintained a foraging lifestyle for more than 2000 years after the arrival of farming societies in the area; such societies may be called "Subneolithic". In north-Eastern Europe, the hunting and fishing lifestyle continued into the Medieval period in regions less suited to agriculture, and in Scandinavia no Mesolithic period may be accepted, with the locally preferred "Older Stone Age" moving into the "Younger Stone Age".

Compared to the preceding Upper Paleolithic and the following Neolithic, there is rather less surviving art from the Mesolithic. The Rock art of the Iberian Mediterranean Basin, which probably spreads across from the Upper Paleolithic, is a widespread phenomenon, much less well known than the cave-paintings of the Upper Paleolithic, with which it makes an interesting contrast. The sites are now mostly cliff faces in the open air, and the subjects are now mostly human rather than animal, with large groups of small figures; there are 45 figures at Roca dels Moros. Clothing is shown, and scenes of dancing, fighting, hunting and food-gathering. The figures are much smaller than the animals of Paleolithic art, and depicted much more schematically, though often in energetic poses. A few small engraved pendants with suspension holes and simple engraved designs are known, some from northern Europe in amber, and one from Star Carr in Britain in shale. The Elk's Head of Huittinen is a rare Mesolithic animal carving in soapstone from Finland.

The rock art in the Urals appears to show similar changes after the Paleolithic, and the wooden Shigir Idol is a rare survival of what may well have been a very common material for sculpture. It is a plank of larch carved with geometric motifs, but topped with a human head. Now in fragments, it would apparently have been over 5 metres tall when made. The "Ain Sakhri Lovers" from modern Israel, are a Natufian carving in calcite.

In North-Eastern Europe, Siberia, and certain southern European and North African sites, a "ceramic Mesolithic" can be distinguished between c. 9,000 to 5,850 BP. Russian archaeologists prefer to describe such pottery-making cultures as Neolithic, even though farming is absent. This pottery-making Mesolithic culture can be found peripheral to the sedentary Neolithic cultures. It created a distinctive type of pottery, with point or knob base and flared rims, manufactured by methods not used by the Neolithic farmers. Though each area of Mesolithic ceramic developed an individual style, common features suggest a single point of origin. The earliest manifestation of this type of pottery may be in the region around Lake Baikal in Siberia. It appears in the Elshan or Yelshanka or Samara culture on the Volga in Russia 9 ka, and from there spread via the Dnieper-Donets culture to the Narva culture of the Eastern Baltic. Spreading westward along the coastline it is found in the Ertebølle culture of Denmark and Ellerbek of Northern Germany, and the related Swifterbant culture of the Low Countries.

A 2012 publication in the "Science" journal, announced that the earliest pottery yet known anywhere in the world was found in Xianrendong cave in China, dating by radiocarbon to between 20,000 and 19,000 years before present, at the end of the Last Glacial Period. The carbon 14 datation was established by carefully dating surrounding sediments. Many of the pottery fragments had scorch marks, suggesting that the pottery was used for cooking. These early pottery containers were made well before the invention of agriculture (dated to 10,000 to 8,000 BC), by mobile foragers who hunted and gathered their food during the Late Glacial Maximum.

While Paleolithic and Neolithic have been found useful terms and concepts in the archaeology of China, and can be mostly regarded as happily naturalized, Mesolithic was introduced later, mostly after 1945, and does not appear to be a necessary or useful term in the context of China. Chinese sites that have been regarded as Mesolithic are better considered as "Early Neolithic".

In the archaeology of India, the Mesolithic, dated roughly between 12,000 and 8,000 BP, remains a concept in use.

In the archaeology of the Americas, an Archaic or Meso-Indian period, following the Lithic stage, somewhat equates to the Mesolithic.



</doc>
<doc id="20569" url="https://en.wikipedia.org/wiki?curid=20569" title="Metis">
Metis

Metis or Métis may refer to:






</doc>
<doc id="20571" url="https://en.wikipedia.org/wiki?curid=20571" title="Mary Robinson">
Mary Robinson

Mary Therese Winifred Robinson (; ; born 21 May 1944) is an Irish Independent politician who served as the seventh President of Ireland from December 1990 to September 1997, becoming the first woman to hold this office. She also served as United Nations High Commissioner for Human Rights from 1997 to 2002 and a Senator for the University of Dublin from 1969 to 1989. She first rose to prominence as an academic, barrister and campaigner. She defeated Fianna Fáil's Brian Lenihan and Fine Gael's Austin Currie in the 1990 presidential election, becoming the first Independent candidate nominated by the Labour Party, the Workers' Party and Independent Senators. She was the first elected President in the office's history not to have had the support of Fianna Fáil.

She is widely regarded as a transformative figure for Ireland, and for the Irish presidency, revitalising and liberalising a previously conservative, low-profile political office. She resigned the presidency two months ahead of the end of her term of office to take up her post in the United Nations. During her UN tenure she visited Tibet (1998), the first High Commissioner to do so; she criticised Ireland's immigrant policy; and criticised the use of capital punishment in the United States. She extended her intended single four-year term by a year to preside over the World Conference against Racism 2001 in Durban, South Africa; the conference proved controversial. Under continuing pressure from the United States, Robinson resigned her post in September 2002.

After leaving the United Nations in 2002, Robinson formed Realizing Rights: the Ethical Globalization Initiative, which came to a planned end at the end of 2010. Its core activities were 1) fostering equitable trade and decent work, 2) promoting the right to health and more humane migration policies, and 3) working to strengthen women's leadership and encourage corporate social responsibility. The organisation also supported capacity building and good governance in developing countries. Robinson returned to live in Ireland at the end of 2010, and has set up The Mary Robinson Foundation - Climate Justice, which aims to be 'a centre for thought leadership, education and advocacy on the struggle to secure global justice for those many victims of climate change who are usually forgotten - the poor, the disempowered and the marginalised across the world.'

Robinson is Chairman of the Institute for Human Rights and Business and served as Chancellor of the University of Dublin from 1998 until 2019. Since 2004, she has also been Professor of Practice in International Affairs at Columbia University, where she teaches international human rights. Robinson also visits other colleges and universities where she lectures on human rights. Robinson sits on the board of the Mo Ibrahim Foundation, an organisation which supports good governance and great leadership in Africa, and is a member of the Foundation's Ibrahim Prize Committee. Robinson is also a B Team Leader, alongside Richard Branson, Jochen Zeitz and a group of leaders from business and civil society as part of The B Team. Robinson is an Extraordinary Professor in the Centre for Human Rights and the Centre for Sexualities, AIDS and Gender at the University of Pretoria. Robinson served as Oxfam's honorary president from 2002 until she stepped down in 2012 and is honorary president of the European Inter-University Centre for Human Rights and Democratisation EIUC since 2005. She is Chair of the International Institute for Environment and Development (IIED) and is also a founding member and chair of the Council of Women World Leaders. Robinson was a member of the European members of the Trilateral Commission.

In 2004, she received Amnesty International's Ambassador of Conscience Award for her work in promoting human rights.

Born Mary Therese Winifred Bourke in Ballina, County Mayo, in 1944, she is the daughter of two medical doctors. Her father was Dr. Aubrey Bourke, of Ballina, while her mother was Dr. Tessa Bourke ("née" O'Donnell), of Carndonagh, Inishowen, County Donegal. The Hiberno-Norman Bourkes have lived in Mayo since the thirteenth century. Her family had links with many diverse political strands in Ireland. One ancestor was a leading activist in the Irish National Land League of Mayo and the Irish Republican Brotherhood; an uncle, Sir Paget John Bourke, was knighted by Queen Elizabeth II, after a career as a judge in the Colonial Service; while another relative was a Catholic nun. Some branches of the family were members of the Anglican Church of Ireland while others were Catholics. More distant relatives included William Liath de Burgh, Tiobóid mac Walter Ciotach Bourke, and Charles Bourke. Robinson was therefore born into a family that was a historical mix of rebels against and servants of the British Crown.

Mary Bourke attended Mount Anville Secondary School in Dublin and studied law at Trinity College Dublin (where she was elected a scholar in 1965, the same year as David Norris) graduating in 1967 with first class honours, King's Inns and Harvard Law School. She was called to the Irish Bar in 1967 and while still in her twenties, she was called to the Inner Bar as Senior Counsel, and was appointed Reid Professor of Law in the college. A subsequent holder of that title was her successor as Irish President, Mary McAleese. An outspoken critic of some Catholic church teachings, she gave an acceptance speech in 1969, for a law-review position, in which she advocated removing the prohibition of divorce in the Irish Constitution, eliminating the ban on the use of contraceptives, decriminalising homosexuality and suicide.

In 1970, she married Nicholas Robinson, with whom she had a relationship since they were fellow law students and who was then practising as a solicitor. Despite the fact that her family had close links to the Church of Ireland, her marriage to a Protestant caused a rift with her parents, who did not attend her wedding. The rift was eventually overcome in subsequent months. Together they have three children. Her son Aubrey, a photographer and film-maker who is "committed to social justice", received media attention in 2011, when he participated in Occupy Dame Street.

Robinson's early political career included election to Dublin City Council in 1979, where she served until 1983. However, she first hit national headlines as one of University of Dublin's three members of Seanad Éireann to which she was first elected, as an Independent Senator, in 1969. From this body she campaigned on a wide range of liberal issues, including the right of women to sit on juries, the then requirement that all women, upon marriage, resign from the civil service, and the right to the legal availability of contraception. This latter campaign won her many enemies. She was denounced from the pulpit of Ballina Cathedral for her campaigning for family planning rights for women in Ireland, causing distress to her parents. Condoms and other items were regularly sent in the post to the Senator by conservative critics, and a false rumour was spread that the Hayes, Conyngham & Robinson chain of pharmacies was owned by her family (and so therefore that her promotion of contraception was an attempt to benefit members of her family). So unpopular was her campaign among fellow politicians that when she introduced the first bill proposing to liberalise the law on contraception into the Seanad, although two other members 'seconded' the initiative, political leaders did not put it on the agenda for discussion. As a Senator she served on the following parliamentary committees:

For many years Robinson also worked as legal advisor for the Campaign for Homosexual Law Reform, with future Trinity College Senator David Norris. Coincidentally, just as Mary McAleese replaced Mary Robinson as Reid Professor of Law in Trinity, and would succeed her to the Irish presidency, so Robinson replaced McAleese in the Campaign for Homosexual Law Reform.

Robinson initially served in the Irish upper house as an Independent Senator, but in the mid-1970s, she joined the Labour Party. Subsequently, ran for election to Dáil Éireann (the lower house) but her efforts were unsuccessful, as were her efforts to be elected to Dublin Corporation. Robinson, along with hundreds of thousands of other Irish people, clashed with Dublin Corporation when it planned to build its new administrative headquarters on Wood Quay, one of Europe's best preserved Viking sites. Though Robinson and people who in the past might not have espoused her causes, fought a determined battle, Wood Quay was ultimately bulldozed and concreted over, to build the controversial Civic Offices.

In 1982, the Labour Party entered into a coalition government with Fine Gael. When Peter Sutherland was appointed Ireland's European Commissioner, Labour demanded the choice of the next Attorney General. Many expected Robinson to be the choice, but the party leader instead picked senior counsel John Rogers. Rogers was a very close friend of the then leader of the Labour Party, Dick Spring. Rogers and Spring had shared rooms when they had been undergraduates at Trinity College Dublin. Shortly afterward, Robinson resigned from the party in protest at the Anglo-Irish Agreement that the coalition led by Taoiseach Garret FitzGerald had signed with the British Government of Prime Minister Margaret Thatcher. Robinson argued that unionist politicians in Northern Ireland should have been consulted as part of the deal, despite their reluctance to share power.

Robinson remained in the Seanad for four more years, although at this point many of the issues she had campaigned for had been tackled. Contraception had been legalised (although heavily restricted), women were on juries, and the marriage bar on women in the civil service had been revoked. To the surprise of many, she decided not to seek re-election to the Seanad in 1989. One year later, however, Labour approached her about running for President in that year's election. She thought she was being asked her legal advice about the type of policy programme party leader Dick Spring was proposing. However, as she read the briefing notes, she began to realise that the programme was aimed at her. After some consideration, she agreed to become the first Labour nominee for the presidency and the first woman candidate in what was only the second presidential election to be contested by three candidates since 1945.

Few, even in the Labour Party, gave Robinson much chance of winning the presidency, not least because of an internal party row over her nomination. With the Labour Party the first name for a possible candidate was an elderly former Minister for Health, and a hero to the left, Noel Browne. Browne was a household name for having done more than anybody else in Ireland in tackling tuberculosis during the 1950s. However, Browne's relationship with the Labour Party had been stormy. He was critical of its ties with Fine Gael and had co-founded the short-lived Socialist Labour Party in 1977, after leaving the Labour Party. Although he was supported by left-wing members within Labour such as Michael D. Higgins, he had little or no contact with Dick Spring, and therefore had to live in hope of being nominated without the endorsement of the party leadership. The possibility that Browne might be nominated raised the possibility of an internal argument within the party. The fact that Browne was enthusiastic for the candidacy in an election which Labour had never previously contested now acted as pressure for Labour to find a candidate. Spring did not feel that he would be able to control Browne for the duration of the election, given Browne's history of defying party policy to such a degree that he had had to leave several political parties. In these circumstances, the decision to propose Robinson proved to be politically inspired. Robinson had an advantage in being the first candidate nominated for the election (and the first female), in that she could cover more meetings, public addresses and interviews. However, she refused to be drawn on specifics in case she would alienate possible support. Robinson also received the backing of "The Irish Times" newspaper, and this proved hugely advantageous.

Robinson's campaign was boosted by a lack of organisation in Fine Gael, the official opposition party. Fine Gael had previously gambled that former Taoiseach Garret FitzGerald would run as its candidate, even though he had insisted for two years that he would not run for office. When it was apparent that FitzGerald would not budge from his refusal, Fine Gael approached another senior figure, Peter Barry, who had previously been willing to run but had run out of patience and was no longer interested. The party ultimately nominated the former civil rights campaigner Austin Currie, a respected new TD and former Minister in Brian Faulkner's power-sharing executive in Northern Ireland from 1973 to 1974. Currie had little experience in the politics of the Republic and was widely seen as the party's last choice, nominated only when no-one else was available. Fianna Fáil chose Tánaiste and Minister for Defence Brian Lenihan. In three decades in politics, Lenihan had become very popular, and was widely seen as humorous and intelligent. Like Robinson he had himself delivered liberal policy reform (abolished censorship in the 1960s, for example).

When the campaign began, Lenihan was seen as a near certainty to win the presidency. The only question asked was whether Robinson would beat Currie and come second. However, as the campaign proceeded, it became apparent that Lenihan's victory was by no means a foregone conclusion, and that Robinson was a serious contender. Crucial to her appeal was the deep unpopularity of the then Taoiseach Charles Haughey and the rising popularity of the Labour Party leader Dick Spring. Notwithstanding, Fianna Fáil knew they could count on Lenihan to mount a barnstorming campaign in the last few weeks.

The head start that Robinson attained in the nomination process, and the fact that the Fine Gael candidate was from Northern Ireland, resulted in Robinson attaining second place in the polls. Given that Fine Gael normally received 25% of the election result, and were reduced to third place this was an achievement in itself. She also obtained the backing of the Workers' Party of Ireland which was strong in Dublin and Cork and was considered crucial to getting working class votes. Robinson had proved superior media skills to both alternative candidates, and only now had to compete with the Fianna Fáil party election machine.

At this point, a transfer pact was decided upon between Fine Gael and Labour, as both parties were normally preferred partners for each other in general elections. However, the Fine Gael candidate felt shortchanged by this deal as the media was more interested in the Robinson campaign, and privately he did not like Robinson. Currie later remarked that Lenihan was his personal friend, and that he felt personally sick at being asked to endorse somebody he did not like, for the sake of beating Lenihan. The possibility of transfers increased Robinson's chances if only Lenihan could be further weakened.

It emerged during the campaign that what Lenihan had told friends and insiders in private flatly contradicted his public statements on a controversial effort in 1982, by the then opposition Fianna Fáil to pressure President Hillery, into refusing a parliamentary dissolution to Garret FitzGerald, the Taoiseach at the time; Hillery had resolutely rejected the pressure.

Lenihan denied he had pressured the President but then a tape was produced of an 'on the record' interview he had given to a postgraduate student the previous May, in which he frankly discussed attempting to apply pressure. Lenihan claimed that "on mature recollection" he hadn't pressured the President and had been confused in his interview with the student. However, the issue nearly brought down the government.

Under pressure from the junior coalition partner, the Progressive Democrats, Haughey sacked the "unbeatable candidate" as Tánaiste and Minister for Defense. Lenihan's integrity for the highest office in the land was seriously questioned. Lenihan's role in the event in 1982 seemed to imply that he could be instructed by Haughey in his duties, and that electing Lenihan was in effect empowering the controversial Haughey. In a pointless effort to weaken Robinson a government minister and Haughey ally, Pádraig Flynn launched a controversial personal attack on Mary Robinson "as a wife and mother" and "having a new-found interest in her family". Flynn, even more controversially, also joked privately that Robinson would "turn the Áras into the Red Cow Inn". Flynn's tirade was itself attacked in response as "disgraceful" on live radio by Michael McDowell, a senior member of the Progressive Democrats and up to that point supporting Lenihan's campaign. When Robinson met McDowell later in a restaurant, she quipped, "with enemies like McDowell, who needs friends?" Flynn's attack was a fatal blow to Lenihan's campaign, causing many female supporters of Lenihan to vote for Robinson in a gesture of support.

Lenihan's support evaporated, and Haughey concluded that the election was as good as lost. Haughey distanced himself from Lenihan, as he did not want any share in the blame. This had unintended consequences, as disquiet with the Fianna Fáil organisation concerning Haughey's leadership increased dramatically. An episode of an RTÉ current affairs television programme featured Fianna Fáil members in Roscommon openly attacking Haughey's leadership and character. Many canvassers now restarted the campaign to get Lenihan elected. However, Lenihan's personal confidence was shattered and although he recovered somewhat in the polls towards the end of the campaign, it was insufficient. Lenihan won the first count with 44% of the first-preference votes — Robinson attaining 39%. However, transfers from Currie proved critical and the majority of these went as expected against Fianna Fáil. Lenihan became the first Fianna Fáil presidential candidate in the history of the office to lose a presidential election. Robinson now became President, the first woman to hold the office, and the first candidate to be second on first preference votes to win the presidency.

Robinson became the first Labour Party candidate, the first woman and the first non-Fianna-Fáil candidate in the history of contested presidential elections to win the presidency. Famously, RTÉ broadcast her victory speech live rather than The Angelus. Her first television interview as President-elect was on the RTÉ children's television show The Den with Ray D'Arcy, Zig and Zag and Dustin the Turkey.

Robinson was inaugurated as the seventh President of Ireland on 3 December 1990. She proved a remarkably popular President, earning the praise of Brian Lenihan himself who, before his death five years later, said that she was a better President than he ever could have been. She took an office that had a reputation as being little more than a retirement position for prominent politicians and breathed new life into the role. Robinson brought to the presidency legal knowledge, deep intellect and political experience. She reached out to the Irish diaspora (the large number of Irish emigrants and people of Irish descent). She also changed the face of Anglo-Irish relations, when she was the first serving Irish President to visit the United Kingdom and meet Queen Elizabeth II, at Buckingham Palace. She welcomed visits by senior members of the British royal family, most notably Charles, Prince of Wales, to her official residence, Áras an Uachtaráin.

Her political profile changed also. Charles Haughey, Taoiseach when she was elected (and who had had to dismiss her rival, Brian Lenihan when the Progressive Democrats, the smaller party in government, threatened to leave the government unless he was sacked) had a diffident relationship with her, at one stage preventing her from delivering the prestigious BBC Dimbleby Lecture.

In the previous 52 years, only one address to the Oireachtas (parliament) had taken place, by President Éamon de Valera in 1966, on the fiftieth anniversary of the Easter Rising. Robinson delivered two such addresses. She was also invited to chair a committee to review the workings of the United Nations, but declined when asked to by the Government of Ireland, who feared that her involvement might make it difficult for it to oppose the proposals that would result. Controversially, on one trip to Belfast, she met with Gerry Adams, the MP for Belfast West and President of Sinn Féin.

Foreign Minister Dick Spring, who was leader of the Labour Party, advised her not to meet Adams, whose party was linked with the Provisional IRA. However, the Government refused to formally advise her not to meet with him. She felt it would be wrong, in the absence of such formal advice, for her as head of state not to meet the local Member of Parliament, during her visit, and was photographed publicly shaking his hand. During her various visits to Northern Ireland, she in fact regularly met politicians of all hues, including David Trimble of the Ulster Unionist Party and John Hume of the Social Democratic and Labour Party.

To the surprise of her critics, who had seen her as embodying liberalism that the Catholic Church disapproved of, she had a close working relationship with the Church. She visited Irish nuns and priests abroad regularly, and became the first President to host an Áras reception for the Christian Brothers. When on a working trip to Rome, she requested, and was granted, an audience with Pope John Paul II. The outfit she wore was condemned by a controversial young priest, Fr. David O'Hanlon, in "The Irish Times" for supposedly breaking Vatican dress codes on her visit; the Vatican denied that she had – the Vatican dress codes had been changed early in John Paul's pontificate – an analysis echoed by Ireland's Roman Catholic Bishops who distanced themselves from Fr. O' Hanlon's comments.

In one of her roles as President, the signing into law of Bills passed by the Oireachtas, she was called upon to sign two very significant Bills that she had fought for throughout her political career: a Bill to fully liberalise the law on the availability of contraceptives; and a Bill fully decriminalising homosexuality, and which unlike legislation in much of the world at the time, provided for a fully equal age of consent, treating heterosexuals and LGBT people alike.

She invited groups not normally invited to presidential residences to visit her in Áras an Uachtaráin; from the Christian Brothers, a large religious order who ran schools throughout Ireland, but had never had its leaders invited to the Áras, to G.L.E.N., the Gay and Lesbian Equality Network. She visited Irish nuns and priests abroad, Irish famine relief charities, attended international sports events, met the Pope and, against pressure from the Taoiseach, Charles Haughey, not to do so, was the only head of state to meet the 14th Dalai Lama during his tour of Europe. She put a special symbolic light in her kitchen window in Áras an Uachtaráin which was visible to the public as it overlooked the principal public view of the building, as a sign of remembering Irish emigrants around the world (placing a light in a darkened window to guide the way of strangers was an old Irish folk custom). Robinson's symbolic light became an acclaimed symbol of an Ireland thinking about its sons and daughters around the world. She visited Rwanda where she brought world attention to the suffering in that state in the aftermath of its civil war. After her visit, she spoke at a press conference, where she became visibly emotional. As a lawyer trained to be rational, she was furious at her emotion, but it moved many who saw it. One media critic who had slated her presidential ideas in 1990, journalist and "Sunday Tribune" editor Vincent Browne, passed her a note at the end of the press conference saying simply "you were magnificent."

Browne's comments matched the attitudes of Irish people on Robinson's achievements as President, between 1990 and 1997. By halfway through her term of office her popularity rating reached an unprecedented 93 per cent.

On 24 July 1997, Robinson announced her intention to resign as President of Ireland. The Irish Government stated that her announcement "was not unexpected" and wished her "every success". She resigned by addressing a message to the Ceann Comhairle of the Dáil and her resignation took effect from 1 p.m. on Friday, 12 September 1997. She resigned in order to take up appointment as United Nations High Commissioner for Human Rights. Upon her resignation as President, the role of President of Ireland was transferred to the Presidential Commission (which comprised the Chief Justice of Ireland, the Ceann Comhairle of Dáil Éireann and the Cathaoirleach of Seanad Éireann) from 12 September to 11 November 1997, when the new President Mary McAleese was sworn in.

Robinson became the United Nations High Commissioner for Human Rights on 12 September 1997, resigning the presidency a few weeks early in order to take up the post. Media reports suggested that she had been head-hunted for the post by Secretary General of the United Nations Kofi Annan, to assume an advocacy as opposed to an administrative role, in other words to become a public campaigner outlining principles rather than the previous implementational and consensus-building model. The belief was that the post had ceased to be seen as the voice of general principles and had become largely bureaucratic. Robinson's role was to set the human rights agenda within the organisation and internationally, refocusing its appeal.

In November 1997, still new to her post, Robinson delivered the Romanes Lecture in Oxford on the topic of "Realizing Human Rights"; she spoke of the "daunting challenge" ahead of her, and how she intended to set about her task. She concluded the lecture with words from "The Golden Bough": "If fate has called you, the bough will come easily, and of its own accord. Otherwise, no matter how much strength you muster, you never will manage to quell it or cut it down with the toughest of blades."

Robinson was the first High Commissioner for Human Rights to visit Tibet, making her trip in 1998. During her tenure, she criticised the Irish system of permits for non-EU immigrants as similar to "bonded labour" and criticised the United States' use of capital punishment.

In 2001, Robinson chaired the Asia Regional Preparatory Meeting for the World Conference against Racism, Racial Discrimination, Xenophobia and related intolerances, which was held in Tehran, Iran. At this meeting, the representatives of neither the Simon Wiesenthal Centre, a Jewish group, nor the Baha'i International Community were permitted to attend. Robinson wore a headscarf at the meeting, because the Iranians enforced an edict that all women attending the conference must wear a headscarf. Women who did not wear the headscarf were criticized, and Robinson said that it "played into the hands of religious conservatives."

Though she had initially announced her intention to serve a single four-year period, she extended the term by a year following an appeal from Annan, allowing her to preside over the 2001 World Conference against Racism in Durban, South Africa, as Secretary-General. The conference drew widespread criticism, as did Robinson. Former US Congressman Tom Lantos said, "To many of us present at the events at Durban, it is clear that much of the responsibility for the debacle rests on the shoulders of UN High Commissioner for Human Rights Mary Robinson, who, in her role as secretary-general of the conference, failed to provide the leadership needed to keep the conference on track."

Robinson's period as High Commissioner ended in 2002, after sustained pressure from the United States led her to declare she was no longer able to continue her work. Robinson had criticised the US for violating human rights in its war on terrorism and the World Conference against Racism was widely condemned in the US for its perceived anti-semitism. Michael Rubin even went so far as to suggest in a tongue-in-cheek article that she be tried for war crimes for presiding over "an intellectual pogrom against Jews and Israel." On 9 November 2006, in Yogyakarta, she attended the International Conference, then she became one of 29 signators of the Yogyakarta Principles, adopted for protection of rights by International Human Rights Law.

On 18 July 2007, in Johannesburg, South Africa, Nelson Mandela, Graça Machel, and Desmond Tutu convened a group of world leaders to contribute their wisdom, independent leadership and integrity to tackle some of the world's toughest problems. Mandela announced the formation of this new group, The Elders, in a speech he delivered on the occasion of his 89th birthday.

"This group can speak freely and boldly, working both publicly and behind the scenes on whatever actions need to be taken," Mandela commented. "Together we will work to support courage where there is fear, foster agreement where there is conflict, and inspire hope where there is despair."

Mary Robinson has been active in The Elders' work, participating in a broad range of the group's initiatives. She has travelled with Elders delegations to Cote d'Ivoire, the Korean Peninsula, Ethiopia, India, South Sudan and the Middle East. In August 2014, she was joined by fellow Elder Jimmy Carter during the 2014 Israel-Gaza conflict, to pen an article in "Foreign Policy", pressing for the inclusion of recognition of Hamas as a legitimate political actor, noting the recent unity deal between Hamas and Fatah when the former agreed with the Palestinian Authority to denounce violence, recognize Israel and adhere to past agreements. Robinson and Carter called on the UN Security Council to act on what they described as the inhumane conditions in Gaza, and mandate an end to the siege.
On 16 October 2014, Mary Robinson attended the One Young World Summit in Dublin. During a session with fellow Elder Kofi Annan, Mary Robinson encouraged 1,300 young leaders from 191 countries to lead on intergenerational issues such as climate change and the need for action to take place now, not tomorrow. Mary Robinson was also the key note speaker at the One Young World Opening Ceremony where she highlighted the need to empower young people to participate in decision-making processes that shape their future.

It was announced on 1 November 2018 that Robinson had been appointed as the Chair of The Elders, succeeding Kofi Annan who had died earlier in the year.

Robinson is the twenty fourth, and first female, Chancellor of University of Dublin (i.e. Trinity College). She represented the University in the Seanad, for over twenty years and held the Reid Chair in Law.

In September 2012, Robinson's memoir "Everybody Matters" was published with Hodder & Stoughton.

In October 2016, it was revealed in the media that Robinson was planning to donate her archive to Mayo County Council, as part of the development of The Mary Robinson Centre, and had applied to have the archive designated under the Taxes Consolidation Act, 1997, potentially resulting in a personal tax credit to her worth over €2m, arising from the donation of her personal papers. The house proposed to be used for the centre was to be purchased from the brother of Mary Robinson for €665,000.

The website of the Mary Robinson Centre lists the contents of the proposed archive (valued at €2.5m) as including:
"2,000 books on law and Human Rights 3,800 periodicals; A Master File of the President's engagements from December 1990 to September 1997; The symbolic light in the window of Áras an Uachtaráin from her Presidency; Robinson's personal diaries from 1967 to 1990 and from 1998 to 2001; 325 Archive Cartons..Scrap Books, Cassette Tapes." These papers relate to Robinson's almost 50-year career, spanning her time as a senator and barrister in the 1970s and 80s, her personal papers relating to the presidency and significant papers from the post-presidential period of her career, most notably her time with the United Nations as High Commissioner for Human Rights.

The project as a whole was condemned as an "expensive vanity project" by historian Diarmuid Ferriter. A member of the fund raising committee for the Centre argued that "Ballina is the same distance to Dublin as Dublin is to Ballina." Chief Executive of Mayo County Council, Peter Hynes (who is also on the board of the Mary Robinson Centre) stated that Robinson had a "legacy as a politician" and that the centre is designed to bring significant academic, tourism, education and economic opportunities to Ballina and the West. Hynes also commented that "The west coast town (of Ballina) has considerable pride in her outstanding career and on-going global leadership and sees the proposed centre as a living institution which will focus global attention and, working in collaboration with the National University of Ireland, Galway, will continue the conversation on topics of fundamental importance."

The size of the potential tax windfall available to Robinson, was particularly controversial given her avowed socialist political stance and that she was the Presidential candidate and a member of the Labour Party, which describes itself as ".. a democratic socialist party and, through its membership of the Party of European Socialists and Socialist International, is part of the international socialist movement working for equality and to empower citizens, consumers and workers in a world increasingly dominated by big business, greed and selfishness."

Following the reporting of the potential €2m windfall, Robinson announced she would abandon the plan to "gift" the archive to Ballina and instead she said the papers would be "gifted to NUIG, with Mayo County Council having full access to any part of the collection which is required to support the mission of the centre in Ballina". In addition she stated that she would now not avail of the tax credit for the donation.


In March 2013, Robinson was chosen to oversee the implementation of a peace deal to stabilize the troubled central African country of Congo. Appointed by UN Secretary-General Ban Ki-moon, Robinson was expected to play a key role in supporting implementation of the U.N.-drafted peace deal signed by 11 African countries in late February 2013.

In July 2014, Ban Ki-moon made Robinson his special envoy for Climate Change to interact with global leaders ahead of the 2014 Climate Summit, in New York, at which the secretary-general said he hoped to forge political commitment to finalizing an agreement in 2015. In March 2015, she voiced support for fossil fuel divestment commenting "it is almost a due diligence requirement to consider ending investment in dirty energy companies".

In early 2016, Robinson was appointed by Erik Solheim, the Chairman of the Development Assistance Committee, to head a high-level panel on the future of the Development Assistance Committee.

In May 2016, Ban Ki-moon appointed Robinson and Macharia Kamau, as special envoys of the Secretary-General on El Niño and Climate, tasking them with calling attention to the people around the world affected by severe El Niño-linked drought and climate impacts, and mobilising an integrated response that takes preparedness for future climatic events into account.

In September 2016, Robinson was appointed by Ban Ki-moon to serve as member of the lead group of the Scaling Up Nutrition Movement.

In December 2018, Robinson was criticized by human rights organisations, Detained in Dubai and Guernica 37 International Justice Chambers, for her statements regarding Dubai's Sheikha Latifa's disappearance and escape attempt. After meeting Princess Latifa at a family lunch on invitation of Dubai's royal family, Robinson described Latifa to the BBC as a "troubled young woman" who regretted an earlier video in which she alleged being confined and tortured in Dubai. Detained in Dubai head Radha Stirling expressed astonishment at the former UN commissioner for repeatedly reciting a single statement from Dubai's official version of the events, "loving care of her family", and for dismissing Latifa's alleged attempt to escape from Dubai in February 2018.

Over the course of her career, Robinson has been awarded with numerous honors, including the following:


On 29 September 2010, at a ceremony in Dublin, Robinson received a damehood from the Military and Hospitaller Order of St. Lazarus of Jerusalem. As a former Head of State and in recognition of her significant contribution towards human rights she was awarded the honour of Dame Grand Cross of Merit.

In 1991 and in 2001, Robinson was awarded honorary doctorates by Brown University, University of Cambridge and Lisbon Nova University. On 22 January 2000, she received an honorary doctorate from the Faculty of Law at Uppsala University, Sweden. In 2004, she was awarded an Honorary Degree by McGill University.

In 2009, Robinson was awarded an honorary degree of Doctor of Laws from the University of Bath, at the 1100th anniversary celebration of the Diocese of Bath and Wells, where she gave a lecture entitled "Realising rights: the role of religion in human rights in the future".

In July 2009, she was awarded the Presidential Medal of Freedom, the highest civilian honour awarded by the United States. In presenting the award to Robinson, U.S. President Barack Obama said "Mary Robinson learned early on what it takes to make sure all voices are heard. As a crusader for women and those without a voice in Ireland, Mary Robinson was the first woman elected President of Ireland, before being appointed U.N. High Commissioner for Human Rights. When she traveled abroad as President, she would place a light in her window that would draw people of Irish descent to pass by below. Today, as an advocate for the hungry and the hunted, the forgotten and the ignored, Mary Robinson has not only shone a light on human suffering, but illuminated a better future for our world."

Amnesty International congratulated Mary Robinson on being named as a recipient of the Presidential Medal of Freedom. "Mary Robinson has long defended the rights of the underdog and has never shirked from speaking truth to power," said Irene Khan, Secretary General of Amnesty International. "As an outspoken, passionate and forceful advocate for human rights and human dignity in all regions of the world, Mary Robinson has helped countless individuals from Sierra Leone to Rwanda to the Balkans to Somalia and to the Middle East," she continued. Nelson Mandela and Graca Machel also congratulated Robinson on her acceptance of the award.

The award was criticised by some American and European Jewish groups, while other groups offered support for the award. Parties opposed to the award included AIPAC, the Anti-Defamation League, the European Jewish Congress, and John R. Bolton. John R. Bolton, the former US Ambassador to the United Nations, stated that those in the administration who recommended her either ignored her anti-Israel history, or missed it entirely. On the other hand, a group of Israeli human rights organizations including the Association for Civil Rights in Israel, Bimkom, B'Tselem, Gisha, Hamoked, Physicians for Human Rights and Yesh Din, stated "as leaders of a sector within Israeli civil society that monitors and often criticizes government and military policy for violating human rights, we do not see such actions as plausible reason for denying Mrs. Robinson the award." In response to the protests by some Jewish groups and commentators, Robinson said she was "surprised and dismayed" and that "this is old, recycled, untrue stuff," "I have been very critical of the Palestinian side. My conduct continues to be on the side of tackling anti-Semitism and discrimination," Robinson said. "There's a lot of bullying by certain elements of the Jewish community. They bully people who try to address the severe situation in Gaza and the West Bank. Archbishop Desmond Tutu gets the same criticism," Robinson also said. In an open letter to Robinson, Hillel Neuer, executive director of UN Watch, rejected Robinson's claim at being misunderstood or bullied by those who criticize her role in Durban. He said that she failed to confront purveyors of anti-Israel rhetoric. "You may not have been the chief culprit of the Durban debacle, but you will always be its preeminent symbol", he added. When asked about the opposition to the award by AIPAC and other Jewish groups, White House Press Secretary Robert Gibbs replied "Mary Robinson was the first female President of Ireland, and she is somebody whom we are honoring as a prominent crusader of women's rights in Ireland and throughout the world."

United States Speaker of the House Nancy Pelosi, United States Senate Assistant Majority Leader Dick Durbin, and some other legislators welcomed the presenting of the award to Robinson." Forty-five Republican Congressmen sent a letter to President Obama raised issue with the presentation citing "her failed, biased record as United Nations High Commissioner for Human Rights".

In a letter to President Obama, Nancy Rubin, a former American ambassador to the UN Human Rights Commission, welcomed the award and praised Robinson as a "dedicated crusader for human rights for all people". Oxfam confederation also expressed its strong support for Robinson. The Council of Women World Leaders, the Champalimaud Foundation, and the ImagineNations Group welcomed the presentation of the Medal of Freedom to Robinson.

The International Gay and Lesbian Human Rights Commission congratulated Robinson, saying she "helped advance recognition of the human rights of LGBT people in her capacity as President of Ireland and as United Nations High Commissioner for Human Rights. She has been unwavering in her passionate call to end torture, persecution, and discrimination against LGBT people globally."

General

Media coverage in "The Irish Times", "The Irish Independent", "The Examiner" (now renamed the "Irish Examiner"), "The Star", "The Irish Mirror", "The Irish Sun", "The Sunday Tribune", "The Sunday Independent", "The Sunday Times", "The Times", "The Daily Telegraph" and "The Guardian". Also briefing notes issued on various occasions (notably state, official or personal visits by Robinson abroad) supplied by the Irish Department of Foreign Affairs, The Foreign and Commonwealth Office, Buckingham Palace, Áras an Uachtaráin, the Holy See and the press offices of the United Nations (including the text of her Romanes Lecture in November 1997). Some background came via an interview with Robinson.

Specific



</doc>
<doc id="20572" url="https://en.wikipedia.org/wiki?curid=20572" title="Musical theatre">
Musical theatre

Musical theatre is a form of theatrical performance that combines songs, spoken dialogue, acting and dance. The story and emotional content of a musical – humor, pathos, love, anger – are communicated through words, music, movement and technical aspects of the entertainment as an integrated whole. Although musical theatre overlaps with other theatrical forms like opera and dance, it may be distinguished by the equal importance given to the music as compared with the dialogue, movement and other elements. Since the early 20th century, musical theatre stage works have generally been called, simply, musicals.

Although music has been a part of dramatic presentations since ancient times, modern Western musical theatre emerged during the 19th century, with many structural elements established by the works of Gilbert and Sullivan in Britain and those of Harrigan and Hart in America. These were followed by the numerous Edwardian musical comedies and the musical theatre works of American creators like George M. Cohan at the turn of the 20th century. The Princess Theatre musicals (1915–1918) and other smart shows like "Of Thee I Sing" (1931) were artistic steps forward beyond revues and other frothy entertainments of the early 20th century and led to such groundbreaking works as "Show Boat" (1927) and "Oklahoma!" (1943). Some of the most famous musicals through the decades that followed include
"West Side Story" (1957), "The Fantasticks" (1960), "Hair" (1967), "A Chorus Line" (1975), "Les Misérables" (1985), "The Phantom of the Opera" (1986), "Rent" (1996), "The Producers" (2001), "Wicked" (2003) and "Hamilton" (2015).

Musicals are performed around the world. They may be presented in large venues, such as big-budget Broadway or West End productions in New York City or London. Alternatively, musicals may be staged in smaller venues, such as fringe theatre, Off-Broadway, Off-Off-Broadway, regional theatre, or community theatre productions, or on tour. Musicals are often presented by amateur and school groups in churches, schools and other performance spaces. In addition to the United States and Britain, there are vibrant musical theatre scenes in continental Europe, Asia, Australasia, Canada and Latin America.

Since the 20th century, the "book musical" has been defined as a musical play where songs and dances are fully integrated into a well-made story with serious dramatic goals that is able to evoke genuine emotions other than laughter. The three main components of a book musical are its "music", "lyrics" and "book". The book or script of a musical refers to the story, character development and dramatic structure, including the spoken dialogue and stage directions, but it can also refer to the dialogue and lyrics together, which are sometimes referred to as the "libretto" (Italian for "little book"). The music and lyrics together form the "score" of a musical and include songs, incidental music and musical scenes, which are "theatrical sequence[s] set to music, often combining song with spoken dialogue." The interpretation of a musical is the responsibility of its creative team, which includes a director, a musical director, usually a choreographer and sometimes an orchestrator. A musical's production is also creatively characterized by technical aspects, such as set design, costumes, stage properties (props), lighting and sound. The creative team, designs and interpretations generally change from the original production to succeeding productions. Some production elements, however, may be retained from the original production, for example, Bob Fosse's choreography in "Chicago".

There is no fixed length for a musical. While it can range from a short one-act entertainment to several acts and several hours in length (or even a multi-evening presentation), most musicals range from one and a half to three hours. Musicals are usually presented in two acts, with one short intermission, and the first act is frequently longer than the second. The first act generally introduces nearly all of the characters and most of the music and often ends with the introduction of a dramatic conflict or plot complication while the second act may introduce a few new songs but usually contains reprises of important musical themes and resolves the conflict or complication. A book musical is usually built around four to six main theme tunes that are reprised later in the show, although it sometimes consists of a series of songs not directly musically related. Spoken dialogue is generally interspersed between musical numbers, although "sung dialogue" or recitative may be used, especially in so-called "sung-through" musicals such as "Jesus Christ Superstar", "Falsettos", "Les Misérables", "Evita" and "Hamilton". Several shorter musicals on Broadway and in the West End have been presented in one act in recent decades.

Moments of greatest dramatic intensity in a book musical are often performed in song. Proverbially, "when the emotion becomes too strong for speech, you sing; when it becomes too strong for song, you dance." In a book musical, a song is ideally crafted to suit the character (or characters) and their situation within the story; although there have been times in the history of the musical (e.g. from the 1890s to the 1920s) when this integration between music and story has been tenuous. As "The New York Times" critic Ben Brantley described the ideal of song in theatre when reviewing the 2008 revival of "Gypsy": "There is no separation at all between song and character, which is what happens in those uncommon moments when musicals reach upward to achieve their ideal reasons to be." Typically, many fewer words are sung in a five-minute song than are spoken in a five-minute block of dialogue. Therefore, there is less time to develop drama in a musical than in a straight play of equivalent length, since a musical usually devotes more time to music than to dialogue. Within the compressed nature of a musical, the writers must develop the characters and the plot.

The material presented in a musical may be original, or it may be adapted from novels ("Wicked" and "Man of La Mancha"), plays ("Hello, Dolly!" and "Carousel"), classic legends ("Camelot"), historical events ("Evita") or films ("The Producers" and "Billy Elliot"). On the other hand, many successful musical theatre works have been adapted for musical films, such as "West Side Story", "My Fair Lady", "The Sound of Music", "Oliver!" and "Chicago".

Musical theatre is closely related to the theatrical form of opera, but the two are usually distinguished by weighing a number of factors. First, musicals generally have a greater focus on spoken dialogue. Some musicals, however, are entirely accompanied and sung-through, while some operas, such as "Die Zauberflöte", and most operettas, have some unaccompanied dialogue. Second, musicals also usually include more dancing as an essential part of the storytelling, particularly by the principal performers as well as the chorus. Third, musicals often use various genres of popular music or at least popular singing and musical styles.

Finally, musicals usually avoid certain operatic conventions. In particular, a musical is almost always performed in the language of its audience. Musicals produced on Broadway or in the West End, for instance, are invariably sung in English, even if they were originally written in another language. While an opera singer is primarily a singer and only secondarily an actor (and rarely needs to dance), a musical theatre performer is often an actor first but must also be a singer and dancer. Someone who is equally accomplished at all three is referred to as a "triple threat". Composers of music for musicals often consider the vocal demands of roles with musical theatre performers in mind. Today, large theatres that stage musicals generally use microphones and amplification of the actors' singing voices in a way that would generally be disapproved of in an operatic context.

Some works (e.g. by George Gershwin, Leonard Bernstein and Stephen Sondheim) have been made into both "musical theatre" and "operatic" productions. Similarly, some older operettas or light operas (such as "The Pirates of Penzance" by Gilbert and Sullivan) have been produced in modern adaptations that treat them as musicals. For some works, production styles are almost as important as the work's musical or dramatic content in defining into which art form the piece falls. Sondheim said, "I really think that when something plays Broadway it's a musical, and when it plays in an opera house it's opera. That's it. It's the terrain, the countryside, the expectations of the audience that make it one thing or another." There remains an overlap in form between lighter operatic forms and more musically complex or ambitious musicals. In practice, it is often difficult to distinguish among the various kinds of musical theatre, including "musical play", "musical comedy", "operetta" and "light opera".

Like opera, the singing in musical theatre is generally accompanied by an instrumental ensemble called a pit orchestra, located in a lowered area in front of the stage. While opera typically uses a conventional symphony orchestra, musicals are generally orchestrated for ensembles ranging from 27 players down to only a few players. Rock musicals usually employ a small group of mostly rock instruments, and some musicals may call for only a piano or two instruments. The music in musicals uses a range of "styles and influences including operetta, classical techniques, folk music, jazz [and] local or historical styles [that] are appropriate to the setting." Musicals may begin with an overture played by the orchestra that "weav[es] together excerpts of the score's famous melodies."

There are various Eastern traditions of theatre that include music, such as Chinese opera, Taiwanese opera, Japanese Noh and Indian musical theatre, including Sanskrit drama, Indian classical dance, Parsi theatre and Yakshagana. India has, since the 20th century, produced numerous musical films, referred to as "Bollywood" musicals, and in Japan a series of 2.5D musicals based on popular anime and manga comics has developed in recent decades.

Shorter or simplified "junior" versions of many musicals are available for schools and youth groups, and very short works created or adapted for performance by children are sometimes called minimusicals.

The antecedents of musical theatre in Europe can be traced back to the theatre of ancient Greece, where music and dance were included in stage comedies and tragedies during the 5th century BCE. The music from the ancient forms is lost, however, and they had little influence on later development of musical theatre. In the 12th and 13th centuries, religious dramas taught the liturgy. Groups of actors would use outdoor Pageant wagons (stages on wheels) to tell each part of the story. Poetic forms sometimes alternated with the prose dialogues, and liturgical chants gave way to new melodies.
The European Renaissance saw older forms evolve into two antecedents of musical theatre: commedia dell'arte, where raucous clowns improvised familiar stories, and later, opera buffa. In England, Elizabethan and Jacobean plays frequently included music, and short musical plays began to be included in an evenings' dramatic entertainments. Court masques developed during the Tudor period that involved music, dancing, singing and acting, often with expensive costumes and a complex stage design. These developed into sung plays that are recognizable as English operas, the first usually being thought of as "The Siege of Rhodes" (1656). In France, meanwhile, Molière turned several of his farcical comedies into musical entertainments with songs (music provided by Jean-Baptiste Lully) and dance in the late 17th century. These influenced a brief period of English opera by composers such as John Blow and Henry Purcell.

From the 18th century, the most popular forms of musical theatre in Britain were ballad operas, like John Gay's "The Beggar's Opera", that included lyrics written to the tunes of popular songs of the day (often spoofing opera), and later pantomime, which developed from commedia dell'arte, and comic opera with mostly romantic plot lines, like Michael Balfe's "The Bohemian Girl" (1845). Meanwhile, on the continent, singspiel, comédie en vaudeville, opéra comique, zarzuela and other forms of light musical entertainment were emerging. "The Beggar's Opera" was the first recorded long-running play of any kind, running for 62 successive performances in 1728. It would take almost a century afterwards before any play broke 100 performances, but the record soon reached 150 in the late 1820s. Other musical theatre forms developed in England by the 19th century, such as music hall, melodrama and burletta, which were popularized partly because most London theatres were licensed only as music halls and not allowed to present plays without music.

Colonial America did not have a significant theatre presence until 1752, when London entrepreneur William Hallam sent a company of actors to the colonies managed by his brother Lewis. In New York in the summer of 1753, they performed ballad-operas, such as "The Beggar's Opera", and ballad-farces. By the 1840s, P. T. Barnum was operating an entertainment complex in lower Manhattan. Other early musical theatre in America consisted of British forms, such as burletta and pantomime, but what a piece was called did not necessarily define what it was. The 1852 Broadway extravaganza "The Magic Deer" advertised itself as "A Serio Comico Tragico Operatical Historical Extravaganzical Burletical Tale of Enchantment." Theatre in New York moved from downtown gradually to midtown from around 1850, and did not arrive in the Times Square area until the 1920s and 1930s. New York runs lagged far behind those in London, but Laura Keene's "musical burletta" "Seven Sisters" (1860) shattered previous New York musical theatre record, with a run of 253 performances.

Around 1850, the French composer Hervé was experimenting with a form of comic musical theatre he called opérette. The best known composers of operetta were Jacques Offenbach from the 1850s to the 1870s and Johann Strauss II in the 1870s and 1880s. Offenbach's fertile melodies, combined with his librettists' witty satire, formed a model for the musical theatre that followed. Adaptations of the French operettas (played in mostly bad, risqué translations), musical burlesques, music hall, pantomime and burletta dominated the London musical stage into the 1870s.

In America, mid-19th century musical theatre entertainments included crude variety revue, which eventually developed into vaudeville, minstrel shows, which soon crossed the Atlantic to Britain, and Victorian burlesque, first popularized in the US by British troupes. A hugely successful musical that premiered in New York in 1866, "The Black Crook", was an original musical theatre piece that conformed to many of the modern definitions of a musical, including dance and original music that helped to tell the story. The spectacular production, famous for its skimpy costumes, ran for a record-breaking 474 performances. The same year, "The Black Domino/Between You, Me and the Post" was the first show to call itself a "musical comedy." Comedians Edward Harrigan and Tony Hart produced and starred in musicals on Broadway between 1878 ("The Mulligan Guard Picnic") and 1885. These musical comedies featured characters and situations taken from the everyday life of New York's lower classes and represented a significant step forward towards a more legitimate theatrical form. They starred high quality singers (Lillian Russell, Vivienne Segal and Fay Templeton) instead of the ladies of questionable repute who had starred in earlier musical forms.

As transportation improved, poverty in London and New York diminished, and street lighting made for safer travel at night, the number of patrons for the growing number of theatres increased enormously. Plays ran longer, leading to better profits and improved production values, and men began to bring their families to the theatre. The first musical theatre piece to exceed 500 consecutive performances was the French operetta "The Chimes of Normandy" in 1878. English comic opera adopted many of the successful ideas of European operetta, none more successfully than the series of more than a dozen long-running Gilbert and Sullivan comic operas, including "H.M.S. Pinafore" (1878) and "The Mikado" (1885). These were sensations on both sides of the Atlantic and in Australia and helped to raise the standard for what was considered a successful show. These shows were designed for family audiences, a marked contrast from the risqué burlesques, bawdy music hall shows and French operettas that sometimes drew a crowd seeking less wholesome entertainment. Only a few 19th-century musical pieces exceeded the run of "The Mikado", such as "Dorothy", which opened in 1886 and set a new record with a run of 931 performances. Gilbert and Sullivan's influence on later musical theatre was profound, creating examples of how to "integrate" musicals so that the lyrics and dialogue advanced a coherent story. Their works were admired and copied by early authors and composers of musicals in Britain and America.

"A Trip to Chinatown" (1891) was Broadway's long-run champion (until "Irene" in 1919), running for 657 performances, but New York runs continued to be relatively short, with a few exceptions, compared with London runs, until the 1920s. Gilbert and Sullivan were both pirated and imitated in New York by productions such as Reginald De Koven's "Robin Hood" (1891) and John Philip Sousa's "El Capitan" (1896). "A Trip to Coontown" (1898) was the first musical comedy entirely produced and performed by African Americans on Broadway (largely inspired by the routines of the minstrel shows), followed by ragtime-tinged shows. Hundreds of musical comedies were staged on Broadway in the 1890s and early 20th century, composed of songs written in New York's Tin Pan Alley, including those by George M. Cohan, who worked to create an American style distinct from the Gilbert and Sullivan works. The most successful New York shows were often followed by extensive national tours.

Meanwhile, musicals took over the London stage in the Gay Nineties, led by producer George Edwardes, who perceived that audiences wanted a new alternative to the Savoy-style comic operas and their intellectual, political, absurdist satire. He experimented with a modern-dress, family-friendly musical theatre style, with breezy, popular songs, snappy, romantic banter, and stylish spectacle at the Gaiety and his other theatres. These drew on the traditions of comic opera and used elements of burlesque and of the Harrigan and Hart pieces. He replaced the bawdy women of burlesque with his "respectable" corps of Gaiety Girls to complete the musical and visual fun. The success of the first of these, "In Town" (1892) and "A Gaiety Girl" (1893) set the style for the next three decades. The plots were generally light, romantic "poor maiden loves aristocrat and wins him against all odds" shows, with music by Ivan Caryll, Sidney Jones and Lionel Monckton. These shows were immediately widely copied in America, and Edwardian musical comedy swept away the earlier musical forms of comic opera and operetta. "The Geisha" (1896) was one of the most successful in the 1890s, running for more than two years and achieving great international success.

"The Belle of New York" (1898) became the first American musical to run for over a year in London. The British musical comedy "Florodora" (1899) was a popular success on both sides of the Atlantic, as was "A Chinese Honeymoon" (1901), which ran for a record-setting 1,074 performances in London and 376 in New York. After the turn of the 20th century, Seymour Hicks joined forces with Edwardes and American producer Charles Frohman to create another decade of popular shows. Other enduring Edwardian musical comedy hits included "The Arcadians" (1909) and "The Quaker Girl" (1910).

Virtually eliminated from the English-speaking stage by competition from the ubiquitous Edwardian musical comedies, operettas returned to London and Broadway in 1907 with "The Merry Widow", and adaptations of continental operettas became direct competitors with musicals. Franz Lehár and Oscar Straus composed new operettas that were popular in English until World War I. In America, Victor Herbert produced a string of enduring operettas including "The Fortune Teller" (1898), "Babes in Toyland" (1903), "Mlle. Modiste" (1905), "The Red Mill" (1906) and "Naughty Marietta" (1910).

In the 1910s, the team of P. G. Wodehouse, Guy Bolton and Jerome Kern, following in the footsteps of Gilbert and Sullivan, created the "Princess Theatre shows" and paved the way for Kern's later work by showing that a musical could combine light, popular entertainment with continuity between its story and songs. Historian Gerald Bordman wrote:
The theatre-going public needed escapist entertainment during the dark times of World War I, and they flocked to the theatre. The 1919 hit musical "Irene" ran for 670 performances, a Broadway record that held until 1938. The British theatre public supported far longer runs like that of "The Maid of the Mountains" (1,352 performances) and especially "Chu Chin Chow". Its run of 2,238 performances was more than twice as long as any previous musical, setting a record that stood for nearly forty years. Revues like "The Bing Boys Are Here" in Britain, and those of Florenz Ziegfeld and his imitators in America, were also extraordinarily popular.
The musicals of the Roaring Twenties, borrowing from vaudeville, music hall and other light entertainments, tended to emphasize big dance routines and popular songs at the expense of plot. Typical of the decade were lighthearted productions like "Sally", "Lady, Be Good", "No, No, Nanette", "Oh, Kay!" and "Funny Face". Despite forgettable stories, these musicals featured stars such as Marilyn Miller and Fred Astaire and produced dozens of enduring popular songs by Kern, George and Ira Gershwin, Irving Berlin, Cole Porter and Rodgers and Hart. Popular music was dominated by musical theatre standards, such as "Fascinating Rhythm", "Tea for Two" and "Someone to Watch Over Me". Many shows were revues, series of sketches and songs with little or no connection between them. The best-known of these were the annual "Ziegfeld Follies", spectacular song-and-dance revues on Broadway featuring extravagant sets, elaborate costumes and beautiful chorus girls. These spectacles also raised production values, and mounting a musical generally became more expensive. "Shuffle Along" (1921), an all-African American show was a hit on Broadway. A new generation of composers of operettas also emerged in the 1920s, such as Rudolf Friml and Sigmund Romberg, to create a series of popular Broadway hits.

In London, writer-stars such as Ivor Novello and Noël Coward became popular, but the primacy of British musical theatre from the 19th century through 1920 was gradually replaced by American innovation, especially after World War I, as Kern and other Tin Pan Alley composers began to bring new musical styles such as ragtime and jazz to the theatres, and the Shubert Brothers took control of the Broadway theatres. Musical theatre writer Andrew Lamb notes, "The operatic and theatrical styles of nineteenth-century social structures were replaced by a musical style more aptly suited to twentieth-century society and its vernacular idiom. It was from America that the more direct style emerged, and in America that it was able to flourish in a developing society less hidebound by nineteenth-century tradition." In France, "comédie musicale" was written between in the early decades of the century for such stars as Yvonne Printemps.

Progressing far beyond the comparatively frivolous musicals and sentimental operettas of the decade, Broadway's "Show Boat" (1927), represented an even more complete integration of book and score than the Princess Theatre musicals, with dramatic themes told through the music, dialogue, setting and movement. This was accomplished by combining the lyricism of Kern's music with the skillful libretto of Oscar Hammerstein II. One historian wrote, "Here we come to a completely new genre – the musical play as distinguished from musical comedy. Now ... everything else was subservient to that play. Now ... came complete integration of song, humor and production numbers into a single and inextricable artistic entity."
As the Great Depression set in during the post-Broadway national tour of "Show Boat", the public turned back to mostly light, escapist song-and-dance entertainment. Audiences on both sides of the Atlantic had little money to spend on entertainment, and only a few stage shows anywhere exceeded a run of 500 performances during the decade. The revue "The Band Wagon" (1931) starred dancing partners Fred Astaire and his sister Adele, while Porter's "Anything Goes" (1934) confirmed Ethel Merman's position as the First Lady of musical theatre, a title she maintained for many years. Coward and Novello continued to deliver old fashioned, sentimental musicals, such as "The Dancing Years", while Rodgers and Hart returned from Hollywood to create a series of successful Broadway shows, including "On Your Toes" (1936, with Ray Bolger, the first Broadway musical to make dramatic use of classical dance), "Babes in Arms" (1937) and "The Boys from Syracuse" (1938). Porter added "DuBarry Was a Lady" (1939). The longest-running piece of musical theatre of the 1930s was "Hellzapoppin" (1938), a revue with audience participation, which played for 1,404 performances, setting a new Broadway record.

Still, a few creative teams began to build on "Show Boat"s innovations. "Of Thee I Sing" (1931), a political satire by the Gershwins, was the first musical awarded the Pulitzer Prize. "As Thousands Cheer" (1933), a revue by Irving Berlin and Moss Hart in which each song or sketch was based on a newspaper headline, marked the first Broadway show in which an African-American, Ethel Waters, starred alongside white actors. Waters' numbers included "Supper Time", a woman's lament for her husband who has been lynched. The Gershwins' "Porgy and Bess" (1935) featured an all African-American cast and blended operatic, folk and jazz idioms. "The Cradle Will Rock" (1937), directed by Orson Welles, was a highly political pro-union piece that, despite the controversy surrounding it, ran for 108 performances. Rodgers and Hart's "I'd Rather Be Right" (1937) was a political satire with George M. Cohan as President Franklin D. Roosevelt, and Kurt Weill's "Knickerbocker Holiday" depicted New York City's early history while good-naturedly satirizing Roosevelt's good intentions.

The motion picture mounted a challenge to the stage. Silent films had presented only limited competition, but by the end of the 1920s, films like "The Jazz Singer" could be presented with synchronized sound. "Talkie" films at low prices effectively killed off vaudeville by the early 1930s. Despite the economic woes of the 1930s and the competition from film, the musical survived. In fact, it continued to evolve thematically beyond the gags and showgirls musicals of the "Gay Nineties" and "Roaring Twenties" and the sentimental romance of operetta, adding technical expertise and the fast-paced staging and naturalistic dialogue style led by director George Abbott.

The 1940s would begin with more hits from Porter, Irving Berlin, Rodgers and Hart, Weill and Gershwin, some with runs over 500 performances as the economy rebounded, but artistic change was in the air.

Rodgers and Hammerstein's "Oklahoma!" (1943) completed the revolution begun by "Show Boat", by tightly integrating all the aspects of musical theatre, with a cohesive plot, songs that furthered the action of the story, and featured dream ballets and other dances that advanced the plot and developed the characters, rather than using dance as an excuse to parade scantily clad women across the stage. Rodgers and Hammerstein hired ballet choreographer Agnes de Mille, who used everyday motions to help the characters express their ideas. It defied musical conventions by raising its first act curtain not on a bevy of chorus girls, but rather on a woman churning butter, with an off-stage voice singing the opening lines of "Oh, What a Beautiful Mornin'" unaccompanied. It drew rave reviews, set off a box-office frenzy and received a Pulitzer Prize. Brooks Atkinson wrote in "The New York Times" that the show's opening number changed the history of musical theater: "After a verse like that, sung to a buoyant melody, the banalities of the old musical stage became intolerable." It was the first "blockbuster" Broadway show, running a total of 2,212 performances, and was made into a hit film. It remains one of the most frequently produced of the team's projects. William A. Everett and Paul R. Laird wrote that this was a "show, that, like "Show Boat", became a milestone, so that later historians writing about important moments in twentieth-century theatre would begin to identify eras according to their relationship to "Oklahoma!""

"After "Oklahoma!", Rodgers and Hammerstein were the most important contributors to the musical-play form... The examples they set in creating vital plays, often rich with social thought, provided the necessary encouragement for other gifted writers to create musical plays of their own". The two collaborators created an extraordinary collection of some of musical theatre's best loved and most enduring classics, including "Carousel" (1945), "South Pacific" (1949), "The King and I" (1951) and "The Sound of Music" (1959). Some of these musicals treat more serious subject matter than most earlier shows: the villain in "Oklahoma!" is a suspected murderer and psychopath with a fondness for lewd post cards; "Carousel" deals with spousal abuse, thievery, suicide and the afterlife; "South Pacific" explores miscegenation even more thoroughly than "Show Boat"; and the hero of "The King and I" dies onstage.

The show's creativity stimulated Rodgers and Hammerstein's contemporaries and ushered in the "Golden Age" of American musical theatre. Americana was displayed on Broadway during the "Golden Age", as the wartime cycle of shows began to arrive. An example of this is "On the Town" (1944), written by Betty Comden and Adolph Green, composed by Leonard Bernstein and choreographed by Jerome Robbins. The story is set during wartime and concerns three sailors who are on a 24-hour shore leave in New York City, during which each falls in love. The show also gives the impression of a country with an uncertain future, as the sailors and their women also have. Irving Berlin used sharpshooter Annie Oakley's career as a basis for his "Annie Get Your Gun" (1946, 1,147 performances); Burton Lane, E. Y. Harburg and Fred Saidy combined political satire with Irish whimsy for their fantasy "Finian's Rainbow" (1947, 725 performances); and Cole Porter found inspiration in William Shakespeare's "The Taming of the Shrew" for "Kiss Me, Kate" (1948, 1,077 performances). The American musicals overwhelmed the old-fashioned British Coward/Novello-style shows, one of the last big successes of which was Novello's "Perchance to Dream" (1945, 1,021 performances). The formula for the Golden Age musicals reflected one or more of four widely held perceptions of the "American dream": That stability and worth derives from a love relationship sanctioned and restricted by Protestant ideals of marriage; that a married couple should make a moral home with children away from the city in a suburb or small town; that the woman's function was as homemaker and mother; and that Americans incorporate an independent and pioneering spirit or that their success is self-made.

The 1950s were crucial to the development of the American musical. Damon Runyon's eclectic characters were at the core of Frank Loesser's and Abe Burrows' "Guys and Dolls", (1950, 1,200 performances); and the Gold Rush was the setting for Alan Jay Lerner and Frederick Loewe's "Paint Your Wagon" (1951). The relatively brief seven-month run of that show didn't discourage Lerner and Loewe from collaborating again, this time on "My Fair Lady" (1956), an adaptation of George Bernard Shaw's "Pygmalion" starring Rex Harrison and Julie Andrews, which at 2,717 performances held the long-run record for many years. Popular Hollywood films were made of all of these musicals. This surpassed the run of two hits by British creators: "The Boy Friend" (1954), which ran for 2,078 performances in London and marked Andrews' American debut, was very briefly the third longest-running musical in West End or Broadway history (after "Chu Chin Chow" and "Oklahoma!"), until "Salad Days" (1954) surpassed its run and became the new long-run record holder, with 2,283 performances.

Another record was set by "The Threepenny Opera", which ran for 2,707 performances, becoming the longest-running off-Broadway musical until "The Fantasticks". The production also broke ground by showing that musicals could be profitable off-Broadway in a small-scale, small orchestra format. This was confirmed in 1959 when a revival of Jerome Kern and P. G. Wodehouse's "Leave It to Jane" ran for more than two years. The 1959–1960 Off-Broadway season included a dozen musicals and revues including "Little Mary Sunshine", "The Fantasticks" and "Ernest in Love", a musical adaptation of Oscar Wilde's 1895 hit "The Importance of Being Earnest".
"West Side Story" (1957) transported "Romeo and Juliet" to modern day New York City and converted the feuding Montague and Capulet families into opposing ethnic gangs, the Jets and the Sharks. The book was adapted by Arthur Laurents, with music by Leonard Bernstein and lyrics by newcomer Stephen Sondheim. It was embraced by the critics, but failed to be a popular choice for the "blue-haired matinee ladies", who preferred the small town River City, Iowa of Meredith Willson's "The Music Man" to the alleys of Manhattan's Upper West Side. Apparently Tony Award voters were of a similar mind, since they favored the former over the latter. "West Side Story" had a respectable run of 732 performances (1,040 in the West End), while "The Music Man" ran nearly twice as long, with 1,375 performances. However, the 1961 film of "West Side Story" was extremely successful. Laurents and Sondheim teamed up again for "" (1959, 702 performances), with Jule Styne providing the music for a backstage story about the most driven stage mother of all-time, stripper Gypsy Rose Lee's mother Rose. The original production ran for 702 performances, and was given four subsequent revivals, with Angela Lansbury, Tyne Daly, Bernadette Peters and Patti LuPone later tackling the role made famous by Ethel Merman.

Although directors and choreographers have had a major influence on musical theatre style since at least the 19th century, George Abbott and his collaborators and successors took a central role in integrating movement and dance fully into musical theatre productions in the Golden Age. Abbott introduced ballet as a story-telling device in "On Your Toes" in 1936, which was followed by Agnes de Mille's ballet and choreography in "Oklahoma!". After Abbott collaborated with Jerome Robbins in "On the Town" and other shows, Robbins combined the roles of director and choreographer, emphasizing the story-telling power of dance in "West Side Story", "A Funny Thing Happened on the Way to the Forum" (1962) and "Fiddler on the Roof" (1964). Bob Fosse choreographed for Abbott in "The Pajama Game" (1956) and "Damn Yankees" (1957), injecting playful sexuality into those hits. He was later the director-choreographer for "Sweet Charity" (1968), "Pippin" (1972) and "Chicago" (1975). Other notable director-choreographers have included Gower Champion, Tommy Tune, Michael Bennett, Gillian Lynne and Susan Stroman. Prominent directors have included Hal Prince, who also got his start with Abbott, and Trevor Nunn.

During the Golden Age, automotive companies and other large corporations began to hire Broadway talent to write corporate musicals, private shows only seen by their employees or customers. The 1950s ended with Rodgers and Hammerstein's last hit, "The Sound of Music", which also became another hit for Mary Martin. It ran for 1,443 performances and shared the Tony Award for Best Musical. Together with its extremely successful 1965 film version, it has become one of the most popular musicals in history.

In 1960, "The Fantasticks" was first produced off-Broadway. This intimate allegorical show would quietly run for over 40 years at the Sullivan Street Theatre in Greenwich Village, becoming by far the longest-running musical in history. Its authors produced other innovative works in the 1960s, such as "Celebration" and "I Do! I Do!", the first two-character Broadway musical. The 1960s would see a number of blockbusters, like "Fiddler on the Roof" (1964; 3,242 performances), "Hello, Dolly!" (1964; 2,844 performances), "Funny Girl" (1964; 1,348 performances) and "Man of La Mancha" (1965; 2,328 performances), and some more risqué pieces like "Cabaret", before ending with the emergence of the rock musical. Two men had considerable impact on musical theatre history beginning in this decade: Stephen Sondheim and Jerry Herman.
The first project for which Sondheim wrote both music and lyrics was "A Funny Thing Happened on the Way to the Forum" (1962, 964 performances), with a book based on the works of Plautus by Burt Shevelove and Larry Gelbart, starring Zero Mostel. Sondheim moved the musical beyond its concentration on the romantic plots typical of earlier eras; his work tended to be darker, exploring the grittier sides of life both present and past. Other early Sondheim works include "Anyone Can Whistle" (1964, which ran only nine performances, despite having stars Lee Remick and Angela Lansbury), and the successful "Company" (1970), "Follies" (1971) and "A Little Night Music" (1973). Later, Sondheim found inspiration in unlikely sources: the opening of Japan to Western trade for "Pacific Overtures" (1976), a legendary murderous barber seeking revenge in the Industrial Age of London for "Sweeney Todd" (1979), the paintings of Georges Seurat for "Sunday in the Park with George" (1984), fairy tales for "Into the Woods" (1987), and a collection of presidential assassins in "Assassins" (1990).

While some critics have argued that some of Sondheim's musicals lack commercial appeal, others have praised their lyrical sophistication and musical complexity, as well as the interplay of lyrics and music in his shows. Some of Sondheim's notable innovations include a show presented in reverse ("Merrily We Roll Along") and the above-mentioned "Anyone Can Whistle", in which the first act ends with the cast informing the audience that they are mad.

Jerry Herman played a significant role in American musical theatre, beginning with his first Broadway production, "Milk and Honey" (1961, 563 performances), about the founding of the state of Israel, and continuing with the blockbuster hits "Hello, Dolly!" (1964, 2,844 performances), "Mame" (1966, 1,508 performances), and "La Cage aux Folles" (1983, 1,761 performances). Even his less successful shows like "Dear World" (1969) and "Mack and Mabel" (1974) have had memorable scores ("Mack and Mabel" was later reworked into a London hit). Writing both words and music, many of Herman's show tunes have become popular standards, including "Hello, Dolly!", "We Need a Little Christmas", "I Am What I Am", "Mame", "The Best of Times", "Before the Parade Passes By", "Put On Your Sunday Clothes", "It Only Takes a Moment", "Bosom Buddies" and "I Won't Send Roses", recorded by such artists as Louis Armstrong, Eydie Gormé, Barbra Streisand, Petula Clark and Bernadette Peters. Herman's songbook has been the subject of two popular musical revues, "Jerry's Girls" (Broadway, 1985) and "Showtune" (off-Broadway, 2003).
The musical started to diverge from the relatively narrow confines of the 1950s. Rock music would be used in several Broadway musicals, beginning with "Hair", which featured not only rock music but also nudity and controversial opinions about the Vietnam War, race relations and other social issues.

After "Show Boat" and "Porgy and Bess", and as the struggle in America and elsewhere for minorities' civil rights progressed, Hammerstein, Harold Arlen, Yip Harburg and others were emboldened to write more musicals and operas that aimed to normalize societal toleration of minorities and urged racial harmony. Early Golden Age works that focused on racial tolerance included "Finian's Rainbow" and "South Pacific". Towards the end of the Golden Age, several shows tackled Jewish subjects and issues, such as "Fiddler on the Roof", "Milk and Honey", "Blitz!" and later "Rags". The original concept that became "West Side Story" was set in the Lower East Side during Easter-Passover celebrations; the rival gangs were to be Jewish and Italian Catholic. The creative team later decided that the Polish (white) vs. Puerto Rican conflict was fresher.

Tolerance as an important theme in musicals has continued in recent decades. The final expression of "West Side Story" left a message of racial tolerance. By the end of the 1960s, musicals became racially integrated, with black and white cast members even covering each other's roles, as they did in "Hair". Homosexuality has also been explored in musicals, starting with "Hair", and even more overtly in "La Cage aux Folles", "Falsettos", "Rent", "Hedwig and the Angry Inch" and other shows in recent decades. "Parade" is a sensitive exploration of both anti-Semitism and historical American racism, and "Ragtime" similarly explores the experience of immigrants and minorities in America.

After the success of "Hair", rock musicals flourished in the 1970s, with "Jesus Christ Superstar", "Godspell", "The Rocky Horror Show", "Evita" and "Two Gentlemen of Verona". Some of those began as "concept albums" which were then adapted to the stage, most notably "Jesus Christ Superstar" and "Evita". Others had no dialogue or were otherwise reminiscent of opera, with dramatic, emotional themes; these sometimes started as concept albums and were referred to as rock operas. Shows like "Raisin", "Dreamgirls", "Purlie" and "The Wiz" brought a significant African-American influence to Broadway. More varied musical genres and styles were incorporated into musicals both on and especially off-Broadway. At the same time, Stephen Sondheim found success with some of his musicals, as mentioned above.

In 1975, the dance musical "A Chorus Line" emerged from recorded group therapy-style sessions Michael Bennett conducted with "gypsies" – those who sing and dance in support of the leading players – from the Broadway community. From hundreds of hours of tapes, James Kirkwood Jr. and Nick Dante fashioned a book about an audition for a musical, incorporating many real-life stories from the sessions; some who attended the sessions eventually played variations of themselves or each other in the show. With music by Marvin Hamlisch and lyrics by Edward Kleban, "A Chorus Line" first opened at Joseph Papp's Public Theater in lower Manhattan. What initially had been planned as a limited engagement eventually moved to the Shubert Theatre on Broadway for a run of 6,137 performances, becoming the longest-running production in Broadway history up to that time. The show swept the Tony Awards and won the Pulitzer Prize, and its hit song, "What I Did for Love", became a standard.

Broadway audiences welcomed musicals that varied from the golden age style and substance. John Kander and Fred Ebb explored the rise of Nazism in Germany in "Cabaret", and murder and the media in Prohibition-era "Chicago", which relied on old vaudeville techniques. "Pippin", by Stephen Schwartz, was set in the days of Charlemagne. Federico Fellini's autobiographical film "8½" became Maury Yeston's "Nine". At the end of the decade, "Evita" and "Sweeney Todd" were precursors of the darker, big budget musicals of the 1980s that depended on dramatic stories, sweeping scores and spectacular effects. At the same time, old-fashioned values were still embraced in such hits as "Annie", "42nd Street", "My One and Only", and popular revivals of "No, No, Nanette" and "Irene". Although many film versions of musicals were made in the 1970s, few were critical or box office successes, with the notable exceptions of "Fiddler on the Roof", "Cabaret" and "Grease".

The 1980s saw the influence of European "megamusicals" on Broadway, in the West End and elsewhere. These typically feature a pop-influenced score, large casts and spectacular sets and special effects – a falling chandelier (in "The Phantom of the Opera"); a helicopter landing on stage (in "Miss Saigon") – and big budgets. Some were based on novels or other works of literature. The British team of composer Andrew Lloyd Webber and producer Cameron Mackintosh started the megamusical phenomenon with their 1981 musical "Cats", based on the poems of T. S. Eliot, which overtook "A Chorus Line" to become the longest-running Broadway show. Lloyd Webber followed up with "Starlight Express" (1984), performed on roller skates; "The Phantom of the Opera" (1986; also with Mackintosh), derived from the novel of the same name; and "Sunset Boulevard" (1993), from the 1950 film of the same name. "Phantom" would surpass "Cats" to become the longest-running show in Broadway history, a record it still holds. The French team of Claude-Michel Schönberg and Alain Boublil wrote "Les Misérables", based on the novel of the same name, whose 1985 London production was produced by Mackintosh and became, and still is, the longest-running musical in West End and Broadway history. The team produced another hit with "Miss Saigon" (1989), which was inspired by the Puccini opera "Madama Butterfly".

The megamusicals' huge budgets redefined expectations for financial success on Broadway and in the West End. In earlier years, it was possible for a show to be considered a hit after a run of several hundred performances, but with multimillion-dollar production costs, a show must run for years simply to turn a profit. Megamusicals were also reproduced in productions around the world, multiplying their profit potential while expanding the global audience for musical theatre.

In the 1990s, a new generation of theatrical composers emerged, including Jason Robert Brown and Michael John LaChiusa, who began with productions Off-Broadway. The most conspicuous success of these artists was Jonathan Larson's show "Rent" (1996), a rock musical (based on the opera "La bohème") about a struggling community of artists in Manhattan. While the cost of tickets to Broadway and West End musicals was escalating beyond the budget of many theatregoers, "Rent" was marketed to increase the popularity of musicals among a younger audience. It featured a young cast and a heavily rock-influenced score; the musical became a hit. Its young fans, many of them students, calling themselves RENTheads], camped out at the Nederlander Theatre in hopes of winning the lottery for $20 front row tickets, and some saw the show dozens of times. Other shows on Broadway followed "Rent"'s lead by offering heavily discounted day-of-performance or standing-room tickets, although often the discounts are offered only to students.

The 1990s also saw the influence of large corporations on the production of musicals. The most important has been Disney Theatrical Productions, which began adapting some of Disney's animated film musicals for the stage, starting with "Beauty and the Beast" (1994), "The Lion King" (1997) and "Aida" (2000), the latter two with music by Elton John. "The Lion King" is the highest-grossing musical in Broadway history. "The Who's Tommy" (1993), a theatrical adaptation of the rock opera "Tommy", achieved a healthy run of 899 performances but was criticized for sanitizing the story and "musical theatre-izing" the rock music.

Despite the growing number of large-scale musicals in the 1980s and 1990s, a number of lower-budget, smaller-scale musicals managed to find critical and financial success, such as "Falsettoland" and "Little Shop of Horrors", "" and "Blood Brothers". The topics of these pieces vary widely, and the music ranges from rock to pop, but they often are produced off-Broadway, or for smaller London theatres, and some of these stagings have been regarded as imaginative and innovative.

In the new century, familiarity has been embraced by producers and investors anxious to guarantee that they recoup their considerable investments. Some took (usually modest-budget) chances on new and creative material, such as "Urinetown" (2001), "Avenue Q" (2003), "The Light in the Piazza" (2005), "Spring Awakening" (2006), "In the Heights" (2007), "Next to Normal" (2009), "American Idiot" (2010) and "The Book of Mormon" (2011). "Hamilton" (2015), transformed "under-dramatized American history" into an unusual hip-hop inflected hit. In 2011, Sondheim argued that of all forms of "contemporary pop music", rap was "the closest to traditional musical theatre" and was "one pathway to the future."

However, most major-market 21st-century productions have taken a safe route, with revivals of familiar fare, such as "Fiddler on the Roof", "A Chorus Line", "South Pacific", "Gypsy", "Hair", "West Side Story" and "Grease", or with adaptations of other proven material, such as literature ("The Scarlet Pimpernel", "Wicked" and "Fun Home"), hoping that the shows would have a built-in audience as a result. This trend is especially persistent with film adaptations, including ("The Producers", "Spamalot", "Hairspray", "Legally Blonde", "The Color Purple", "Xanadu", "Billy Elliot", "Shrek", "Waitress" and "Groundhog Day"). Some critics have argued that the reuse of film plots, especially those from Disney (such as "Mary Poppins" and "The Little Mermaid"), equate the Broadway and West End musical to a tourist attraction, rather than a creative outlet.
Today, it is less likely that a sole producer, such as David Merrick or Cameron Mackintosh, backs a production. Corporate sponsors dominate Broadway, and often alliances are formed to stage musicals, which require an investment of $10 million or more. In 2002, the credits for "Thoroughly Modern Millie" listed ten producers, and among those names were entities composed of several individuals. Typically, off-Broadway and regional theatres tend to produce smaller and therefore less expensive musicals, and development of new musicals has increasingly taken place outside of New York and London or in smaller venues. For example, "Spring Awakening", "Fun Home" and "Hamilton" were developed Off-Broadway before being launched on Broadway.

Several musicals returned to the spectacle format that was so successful in the 1980s, recalling extravaganzas that have been presented at times, throughout theatre history, since the ancient Romans staged mock sea battles. Examples include the musical adaptations of "Lord of the Rings" (2007), "Gone with the Wind" (2008) and "" (2011). These musicals involved songwriters with little theatrical experience, and the expensive productions generally lost money. Conversely, "The Drowsy Chaperone", "Avenue Q", "The 25th Annual Putnam County Spelling Bee", "Xanadu" and "Fun Home", among others, have been presented in smaller-scale productions, mostly uninterrupted by an intermission, with short running times, and enjoyed financial success. In 2013, "Time" magazine reported that a trend Off-Broadway has been "immersive" theatre, citing shows such as "Natasha, Pierre & The Great Comet of 1812" (2012) and "Here Lies Love" (2013) in which the staging takes place around and within the audience. The shows set a joint record, each receiving 11 nominations for Lucille Lortel Awards, and feature contemporary scores.

In 2013, Cyndi Lauper was the "first female composer to win the [Tony for] Best Score without a male collaborator" for writing the music and lyrics for "Kinky Boots". In 2015, for the first time, an all-female writing team, Lisa Kron and Jeanine Tesori, won the Tony Award for Best Original Score (and Best Book for Kron) for "Fun Home", although work by male songwriters continues to be produced more often.

Another trend has been to create a minimal plot to fit a collection of songs that have already been hits. Following the earlier success of "Buddy – The Buddy Holly Story", these have included "Movin' Out" (2002, based on the tunes of Billy Joel), "Jersey Boys" (2006, The Four Seasons), "Rock of Ages" (2009, featuring classic rock of the 1980s) and many others. This style is often referred to as the "jukebox musical". Similar but more plot-driven musicals have been built around the canon of a particular pop group including "Mamma Mia!" (1999, based on the songs of ABBA), "Our House" (2002, based on the songs of Madness) and "We Will Rock You" (2002, based on the songs of Queen).

Live-action film musicals were nearly dead in the 1980s and early 1990s, with exceptions of "Victor/Victoria", "Little Shop of Horrors" and the 1996 film of "Evita". In the new century, Baz Luhrmann began a revival of the film musical with "Moulin Rouge!" (2001). This was followed by "Chicago" (2002); "Phantom of the Opera" (2004); "Rent" (2005); "Dreamgirls" (2006); "Hairspray", "Enchanted" and "" (all in 2007); "Mamma Mia!" (2008); "Nine" (2009); "Les Misérables" and "Pitch Perfect" (both in 2012), "Into The Woods" and "The Last Five Years" (2014) and "La La Land" (2016), among others. Dr. Seuss's "How the Grinch Stole Christmas!" (2000) and "The Cat in the Hat" (2003), turned children's books into live-action film musicals. After the immense success of Disney and other houses with animated film musicals beginning with "The Little Mermaid" in 1989 and running throughout the 1990s (including some more adult-themed films, like "" (1999)), fewer animated film musicals were released in the first decade of the 21st century. The genre made a comeback beginning in 2010 with "Tangled" (2010), "Rio" (2011) and "Frozen" (2013). In Asia, India continues to produce numerous "Bollywood" film musicals, and Japan produces "Anime" and "Manga" film musicals.

Made for TV musical films were popular in the 1990s, such as "Gypsy" (1993), "Cinderella" (1997) and "Annie" (1999). Several made for TV musicals in the first decade of the 21st century were adaptations of the stage version, such as "South Pacific" (2001), "The Music Man" (2003) and "Once Upon a Mattress" (2005), and a televised version of the stage musical "Legally Blonde" in 2007. Additionally, several musicals were filmed on stage and broadcast on Public Television, for example "Contact" in 2002 and "Kiss Me, Kate" and "Oklahoma!" in 2003. The made-for-TV musical "High School Musical" (2006), and its several sequels, enjoyed particular success and were adapted for stage musicals and other media.

In 2013, NBC began a series of live television broadcasts of musicals with "The Sound of Music Live!" Although the production received mixed reviews, it was a ratings success. Further broadcasts have included "Peter Pan Live!" (NBC 2014), "The Wiz Live!" (NBC 2015), a UK broadcast, "The Sound of Music Live" (ITV 2015) "" (Fox 2016), "A Christmas Story Live!" (Fox, 2017), and "" (Fox 2019).

Some television shows have set episodes as a musical. Examples include episodes of "Ally McBeal", "" ("The Bitter Suite" and "Lyre, Lyre, Heart's On Fire"), "Psych" (""), "Buffy the Vampire Slayer" ("Once More, with Feeling"), "That's So Raven", "Daria", "Dexter's Laboratory", "The Powerpuff Girls", "The Flash", "Once Upon a Time", "Oz", "Scrubs" (one episode was written by the creators of "Avenue Q"), "" () and "That '70s Show" (the 100th episode, "That '70s Musical"). Others have included scenes where characters suddenly begin singing and dancing in a musical-theatre style during an episode, such as in several episodes of "The Simpsons", "30 Rock", "Hannah Montana", "South Park", "Bob's Burgers" and "Family Guy". The television series "Cop Rock" extensively used the musical format, as do the series "Flight of the Conchords", "Glee", "Smash" and "Crazy Ex-Girlfriend".

There have also been musicals made for the internet, including "Dr. Horrible's Sing-Along Blog," about a low-rent super-villain played by Neil Patrick Harris. It was written during the WGA writer's strike. Since 2006, reality TV shows have been used to help market musical revivals by holding a talent competition to cast (usually female) leads. Examples of these are "How Do You Solve a Problem like Maria?", "," "Any Dream Will Do," "," "I'd Do Anything" and "Over the Rainbow."

The U.S. and Britain were the most active sources of book musicals from the 19th century through much of the 20th century (although Europe produced various forms of popular light opera and operetta, for example Spanish Zarzuela, during that period and even earlier). However, the light musical stage in other countries has become more active in recent decades.

Musicals from other English-speaking countries (notably Australia and Canada) often do well locally and occasionally even reach Broadway or the West End (e.g., "The Boy from Oz" and "The Drowsy Chaperone"). South Africa has an active musical theatre scene, with revues like "African Footprint" and "Umoja" and book musicals, such as "Kat and the Kings" and "Sarafina!" touring internationally. Locally, musicals like "Vere", "Love and Green Onions", "Over the Rainbow: the all-new all-gay... extravaganza" and "Bangbroek Mountain" and "In Briefs – a queer little Musical" have been produced successfully.

Successful musicals from continental Europe include shows from (among other countries) Germany ("Elixier" and "Ludwig II"), Austria ("Tanz der Vampire", "Elisabeth", "Mozart!" and "Rebecca"), Czech Republic ("Dracula"), France ("Notre-Dame de Paris", "Les Misérables", "Roméo et Juliette" and "Mozart, l'opéra rock") and Spain ("Hoy no me puedo levantar" and "The Musical Sancho Panza").

Japan has recently seen the growth of an indigenous form of musical theatre, both animated and live action, mostly based on Anime and Manga, such as "Kiki's Delivery Service" and "Tenimyu". The popular "Sailor Moon" metaseries has had twenty-nine Sailor Moon musicals, spanning thirteen years. Beginning in 1914, a series of popular revues have been performed by the all-female Takarazuka Revue, which currently fields five performing troupes. Elsewhere in Asia, the Indian Bollywood musical, mostly in the form of motion pictures, is tremendously successful.

Beginning with a 2002 tour of "Les Misérables", various Western musicals have been imported to mainland China and staged in English. Attempts at localizing Western productions in China began in 2008 when "Fame" was produced in Mandarin with a full Chinese cast at the Central Academy of Drama in Beijing. Since then, other western productions have been staged in China in Mandarin with a Chinese cast. The first Chinese production in the style of Western musical theatre was "The Gold Sand" in 2005. In addition, Li Dun, a well-known Chinese producer, produced "Butterflies", based on a classic Chinese love tragedy, in 2007 as well as "Love U Teresa" in 2011.

Musicals are often presented by amateur and school groups in churches, schools and other performance spaces. Although amateur theatre has existed for centuries, even in the New World, François Cellier and Cunningham Bridgeman wrote, in 1914, that prior to the late 19th century, amateur actors were treated with contempt by professionals. After the formation of amateur Gilbert and Sullivan companies licensed to perform the Savoy operas, professionals recognized that the amateur societies "support the culture of music and the drama. They are now accepted as useful training schools for the legitimate stage, and from the volunteer ranks have sprung many present-day favourites." The National Operatic and Dramatic Association was founded in the UK in 1899. It reported, in 1914, that nearly 200 amateur dramatic societies were producing Gilbert and Sullivan works in Britain that year. Similarly, more than 100 community theatres were founded in the US in the early 20th century. This number has grown to an estimated 18,000 in the US. The Educational Theater Association in the US has nearly 5,000 member schools.

The Broadway League announced that in the 2007–08 season, 12.27 million tickets were purchased for Broadway shows for a gross sale amount of almost a billion dollars. The League further reported that during the 2006–07 season, approximately 65% of Broadway tickets were purchased by tourists, and that foreign tourists were 16% of attendees. The Society of London Theatre reported that 2007 set a record for attendance in London. Total attendees in the major commercial and grant-aided theatres in Central London were 13.6 million, and total ticket revenues were £469.7 million. Also, the international musicals scene has been particularly active in recent years. Stephen Sondheim commented in the year 2000:
However, noting the success in recent decades of original material, and creative re-imaginings of film, plays and literature, theatre historian John Kenrick countered:
Is the Musical dead? ... Absolutely not! Changing? Always! The musical has been changing ever since Offenbach did his first rewrite in the 1850s. And change is the clearest sign that the musical is still a living, growing genre. Will we ever return to the so-called 'golden age', with musicals at the center of popular culture? Probably not. Public taste has undergone fundamental changes, and the commercial arts can only flow where the paying public allows.






</doc>
<doc id="20575" url="https://en.wikipedia.org/wiki?curid=20575" title="Micron (disambiguation)">
Micron (disambiguation)

A micron a non-SI name for micrometre (μm).

Micron may also refer to:


</doc>
<doc id="20576" url="https://en.wikipedia.org/wiki?curid=20576" title="Magic lantern (disambiguation)">
Magic lantern (disambiguation)

A magic lantern is an early type of image projector, an ancestor of the modern slide projector.

Magic lantern may also refer to:







</doc>
<doc id="20580" url="https://en.wikipedia.org/wiki?curid=20580" title="Motion">
Motion

In physics, motion is the change in the position of an object over time. Motion is mathematically described in terms of displacement, distance, velocity, acceleration, speed, and time. The motion of a body is observed by attaching a frame of reference to an observer and measuring the change in position of the body relative to that frame.

If the position of an object is not changing relatively to a given frame of reference, the object is said to be "at rest", "motionless", "immobile", "stationary", or to have a constant or time-invariant position with reference to its surroundings. As there is no absolute frame of reference, "absolute motion" cannot be determined. Thus, everything in the universe can be considered to be in motion.

Motion applies to various physical systems: to objects, bodies, matter particles, matter fields, radiation, radiation fields, radiation particles, curvature and space-time. One can also speak of motion of images, shapes and boundaries. So, the term motion, in general, signifies a continuous change in the positions or configuration of a physical system in space. For example, one can talk about motion of a wave or about motion of a quantum particle, where the configuration consists of probabilities of occupying specific positions.

The main quantity that measures the motion of a body is momentum. An object's momentum increases with the object's mass and with its velocity. The total momentum of all objects in an isolated system (one not affected by external forces) does not change with time, as described by the law of conservation of momentum. An object's motion, and thus its momentum, cannot change unless a force acts on the object.

In physics, motion of massive bodies is described through two related sets of laws of mechanics. Motions of all large-scale and familiar objects in the universe (such as cars, projectiles, planets, cells, and humans) are described by classical mechanics, whereas the motion of very small atomic and sub-atomic objects is described by quantum mechanics. Historically, Newton and Euler formulated three laws of classical mechanics:

Classical mechanics is used for describing the motion of macroscopic objects, from projectiles to parts of machinery, as well as astronomical objects, such as spacecraft, planets, stars, and galaxies. It produces very accurate results within these domains, and is one of the oldest and largest in science, engineering, and technology.

Classical mechanics is fundamentally based on Newton's laws of motion. These laws describe the relationship between the forces acting on a body and the motion of that body. They were first compiled by Sir Isaac Newton in his work "Philosophiæ Naturalis Principia Mathematica", first published on July 5, 1687. Newton's three laws are:

Newton's three laws of motion were the first to accurately provide a mathematical model for understanding orbiting bodies in outer space. This explanation unified the motion of celestial bodies and motion of objects on earth.

Uniform Motion:

When an object moves with a constant speed at a particular direction at regular intervals of time it's known as the "uniform motion." For example: a bike moving in a straight line with a constant speed.

Equations of Uniform Motion:

If formula_1 = final and initial velocity, formula_2 = time, and formula_3 = displacement, then:

Modern kinematics developed with study of electromagnetism and refers all velocities "v" to their ratio to speed of light "c". Velocity is then interpreted as rapidity, the hyperbolic angle φ for which the hyperbolic tangent function tanh φ = "v"/"c". Acceleration, the change of velocity, then changes rapidity according to Lorentz transformations. This part of mechanics is special relativity. Efforts to incorporate gravity into relativistic mechanics were made by W. K. Clifford and Albert Einstein. The development used differential geometry to describe a curved universe with gravity; the study is called general relativity.

Quantum mechanics is a set of principles describing physical reality at the atomic level of matter (molecules and atoms) and the subatomic particles (electrons, protons, neutrons, and even smaller elementary particles such as quarks). These descriptions include the simultaneous wave-like and particle-like behavior of both matter and radiation energy as described in the wave–particle duality.

In classical mechanics, accurate measurements and predictions of the state of objects can be calculated, such as location and velocity. In the quantum mechanics, due to the Heisenberg uncertainty principle, the complete state of a subatomic particle, such as its location and velocity, cannot be simultaneously determined. 

In addition to describing the motion of atomic level phenomena, quantum mechanics is useful in understanding some large-scale phenomenon such as superfluidity, superconductivity, and biological systems, including the function of smell receptors and the structures of protein.

Third law of the Newtonian motion states that "For every action, there is an equal but opposite reaction".

Humans, like all known things in the universe, are in constant motion; however, aside from obvious movements of the various external body parts and locomotion, humans are in motion in a variety of ways which are more difficult to perceive. Many of these "imperceptible motions" are only perceivable with the help of special tools and careful observation. The larger scales of imperceptible motions are difficult for humans to perceive for two reasons: Newton's laws of motion (particularly the third) which prevents the feeling of motion on a mass to which the observer is connected, and the lack of an obvious frame of reference which would allow individuals to easily see that they are moving. The smaller scales of these motions are too small to be detected conventionally with human senses.

Spacetime (the fabric of the universe) is expanding meaning everything in the universe is stretching like a rubber band. This motion is the most obscure as it is not physical motion as such, but rather a change in the very nature of the universe. The primary source of verification of this expansion was provided by Edwin Hubble who demonstrated that all galaxies and distant astronomical objects were moving away from Earth, known as Hubble's law, predicted by a universal expansion.

The Milky Way Galaxy is moving through space and many astronomers believe the velocity of this motion to be approximately relative to the observed locations of other nearby galaxies. Another reference frame is provided by the Cosmic microwave background. This frame of reference indicates that the Milky Way is moving at around .

The Milky Way is rotating around its dense galactic center, thus the sun is moving in a circle within the galaxy's gravity. Away from the central bulge, or outer rim, the typical stellar velocity is between . All planets and their moons move with the sun. Thus, the solar system is moving.

The Earth is rotating or spinning around its axis. This is evidenced by day and night, at the equator the earth has an eastward velocity of . The Earth is also orbiting around the Sun in an orbital revolution. A complete orbit around the sun takes one year, or about 365 days; it averages a speed of about .

The Theory of Plate tectonics tells us that the continents are drifting on convection currents within the mantle causing them to move across the surface of the planet at the slow speed of approximately per year. However, the velocities of plates range widely. The fastest-moving plates are the oceanic plates, with the Cocos Plate advancing at a rate of per year and the Pacific Plate moving per year. At the other extreme, the slowest-moving plate is the Eurasian Plate, progressing at a typical rate of about per year.

The human heart is constantly contracting to move blood throughout the body. Through larger veins and arteries in the body, blood has been found to travel at approximately 0.33 m/s. Though considerable variation exists, and peak flows in the venae cavae have been found between . additionally, the smooth muscles of hollow internal organs are moving. The most familiar would be the occurrence of peristalsis which is where digested food is forced throughout the digestive tract. Though different foods travel through the body at different rates, an average speed through the human small intestine is . The human lymphatic system is also constantly causing movements of excess fluids, lipids, and immune system related products around the body. The lymph fluid has been found to move through a lymph capillary of the skin at approximately 0.0000097 m/s.

The cells of the human body have many structures which move throughout them. Cytoplasmic streaming is a way which cells move molecular substances throughout the cytoplasm, various motor proteins work as molecular motors within a cell and move along the surface of various cellular substrates such as microtubules, and motor proteins are typically powered by the hydrolysis of adenosine triphosphate (ATP), and convert chemical energy into mechanical work. Vesicles propelled by motor proteins have been found to have a velocity of approximately 0.00000152 m/s.

According to the laws of thermodynamics, all particles of matter are in constant random motion as long as the temperature is above absolute zero. Thus the molecules and atoms which make up the human body are vibrating, colliding, and moving. This motion can be detected as temperature; higher temperatures, which represent greater kinetic energy in the particles, feel warm to humans who sense the thermal energy transferring from the object being touched to their nerves. Similarly, when lower temperature objects are touched, the senses perceive the transfer of heat away from the body as feeling cold.

Within each atom, electrons exist in a region around the nucleus. This region is called the electron cloud. According to Bohr's model of the atom, electrons have a high velocity, and the larger the nucleus they are orbiting the faster they would need to move. If electrons 'move' about the electron cloud in strict paths the same way planets orbit the sun, then electrons would be required to do so at speeds which far exceed the speed of light. However, there is no reason that one must confine one's self to this strict conceptualization, that electrons move in paths the same way macroscopic objects do. Rather one can conceptualize electrons to be 'particles' that capriciously exist within the bounds of the electron cloud. Inside the atomic nucleus, the protons and neutrons are also probably moving around due to the electrical repulsion of the protons and the presence of angular momentum of both particles.

Light moves at a speed of 299,792,458 m/s, or , in a vacuum. The speed of light in vacuum (or "c") is also the speed of all massless particles and associated fields in a vacuum, and it is the upper limit on the speed at which energy, matter, information or causation can travel. The speed of light in vacuum is thus the upper limit for speed for all physical systems.

In addition, the speed of light is an invariant quantity: it has the same value, irrespective of the position or speed of the observer. This property makes the speed of light "c" a natural measurement unit for speed and fundamental constant of nature.





</doc>
<doc id="20581" url="https://en.wikipedia.org/wiki?curid=20581" title="Malpractice">
Malpractice

In the law of torts, malpractice, also known as professional negligence, is an "instance of negligence or incompetence on the part of a professional".

Professionals who may become the subject of malpractice actions include:


Professional negligence actions require a professional relationship between the professional and the person claiming to have been injured by malpractice. For example, in order to sue a lawyer for malpractice the person bringing the claim must have had an attorney-client relationship with the lawyer.

Typically, to succeed in a malpractice action the person making a malpractice claim must prove both that the professional committed an act of culpable negligence and that the person suffered injury as a result of the professional's error.

Medical malpractice is a highly complex area of law, with laws that differ significantly between jurisdictions.

In Australia, medical malpractice and the rise in incidences of claims against individual and institutional providers has led to the evolution of patient advocates.


</doc>
<doc id="20582" url="https://en.wikipedia.org/wiki?curid=20582" title="Mediation">
Mediation

Mediation is a dynamic, structured, interactive process where an impartial third party assists disputing parties in resolving conflict through the use of specialized communication and negotiation techniques. All participants in mediation are encouraged to actively participate in the process. Mediation is a "party-centered" process in that it is focused primarily upon the needs, rights, and interests of the parties. The mediator uses a wide variety of techniques to guide the process in a constructive direction and to help the parties find their optimal solution. A mediator is facilitative in that she/he manages the interaction between parties and facilitates open communication. Mediation is also evaluative in that the mediator analyzes issues and relevant norms ("reality-testing"), while refraining from providing prescriptive advice to the parties (e.g., "You should do... .").

Mediation, as used in law, is a form of alternative dispute resolution resolving disputes between two or more parties with concrete effects. Typically, a third party, the mediator, assists the parties to negotiate a settlement. Disputants may mediate disputes in a variety of domains, such as commercial, legal, diplomatic, workplace, community and family matters.

The term "mediation" broadly refers to any instance in which a third party helps others reach agreement. More specifically, mediation has a structure, timetable and dynamics that "ordinary" negotiation lacks. The process is private and confidential, possibly enforced by law. Participation is typically voluntary. The mediator acts as a neutral third party and facilitates rather than directs the process. Mediation is becoming a more peaceful and internationally accepted solution in order to end conflict. Mediation can be used to resolve disputes of any magnitude.

The term "mediation," however, due to language as well as national legal standards and regulations is not identical in content in all countries but rather has specific connotations and there are quite some differences between Anglo-Saxon definitions and other countries, especially countries with a civil, statutory law tradit.: Embedding Mediation and Dispute Resolution into Statutory Civil Law: The Example of Germany; in: Ian Macduff (ed.): Essays on Mediation – Dealing with Disputes in the 21st Century; Alphen aan den Rijn 2016, chapter 12 (pp. 177 – 192). Trenczek, T., Berning, D., Lenz, C. (2013) (in German) "Mediation und Konfliktmanagement: Handbuch", Baden-Baden, Nomos Publishing House, p. 23.

Mediators use various techniques to open, or improve, dialogue and empathy between disputants, aiming to help the parties reach an agreement. Much depends on the mediator's skill and training. As the practice gained popularity, training programs, certifications and licensing followed, producing trained, professional mediators committed to the discipline.

The history of mediation goes back to Ancient Greece, where village elders used to mediate local disputes between the villagers. The activity of mediation appeared in very ancient times. The practice developed in Ancient Greece (which knew the non-marital mediator as a "proxenetas"), then in Roman civilization. (Roman law, starting from Justinian's "Digest" of 530–533 CE) recognized mediation. The Romans called mediators by a variety of names, including "internuncius", "medium", "intercessor", "philantropus", "interpolator", "conciliator", "interlocutor", "interpres", and finally "mediator". 

Now mediation is a form a professional service, and mediators are professionally trained for mediation.

In the UK mediation has seen a rise as a service since the Children and Families Act 2014 made it compulsory for separating couples to go through a Mediation Information and Assessment Meeting (MIAM) before hearing in the Court.

There are some important statistics provided regarding the growth of the UK commercial mediation market increased by 20% from 2016 to 2018; this refers to commercial mediations rather than those relating to small claims. There was also increased scheme-related activity, this included activity from NHS Resolution and the Court of Appeal, which meant scheme related activity made up to be 37.5% of all mediation activities (HSFNotes, 2018).

The statistics in 2018 also refer to increased success rates in mediation with 74% achieving settlement on the day of the mediation session, reflecting the speedy nature of mediation once again.

The benefits of mediation include:







In addition to dispute resolution, mediation can function as a means of dispute prevention, such as facilitating the process of contract negotiation. Governments can use mediation to inform and to seek input from stakeholders in formulation or fact-seeking aspects of policy-making.

Mediation is applicable to disputes in many areas:




Within business and commercial mediation, frequently a distinction is made between business-to-business (B2B), business-to-employee (B2E) and business-to-consumer (B2C) situations.

ADR, Alternative Dispute Resolution, began in industrial relations in Australia long before the arrival of the modern ADR movement. One of the first statutes passed by the Commonwealth parliament was the Conciliation
and Arbitration Act 1904 (Cth). This allowed the Federal Government to pass laws on conciliation and arbitration for the prevention and settlement of industrial disputes extending beyond the limits of any one state. Conciliation has been the most prominently used form of ADR, and is generally far removed from modern mediation.

Significant changes in state policy took place from 1996 to 2007. The 1996 Workplace Relations Act (Cth) sought to shift the industrial system away from a collectivist approach, where unions and the Australian Industrial Relations Commission (AIRC) had strong roles, to a more decentralized system of individual bargaining between employers and employees. The Act diminished the traditional role of the AIRC by placing the responsibility of resolving disputes at the enterprise level. This allowed mediation to be used to resolve industrial relations disputes instead of traditional conciliation.

In industrial relations under the 2006 WorkChoices amendments to the Workplace Relations Act. Examples of this use of mediation can be seen in recent enterprise bargaining negotiations.
The Australian government claimed the benefits of mediation to include the following:


The implementation of human resource management (HRM) policies and practices has evolved to focus on the individual worker, and rejects all other third parties such as unions and AIRC. HRM together with the political and economic changes undertaken by Australia's Howard government created an environment where private ADR can be fostered in the workplace.

The decline of unionism and the rise of the individual encouraged the growth of mediation. This is demonstrated in the industries with the lowest unionization rates such as in the private business sector having the greatest growth of mediation.

The 2006 Work Choices Act made further legislative changes to deregulate industrial relations. A key element of the new changes was to weaken the AIRC by encouraging competition with private mediation.

A great variety of disputes occur in the workplace, including disputes between staff members, allegations of harassment, contractual disputes and workers compensation claims. At large, workplace disputes are between people who have an ongoing working relationship within a closed system, which indicate that mediation or a workplace investigation would be appropriate as dispute resolution processes. However the complexity of relationships, involving hierarchy, job security and competitiveness can complicate mediation.

Party-directed mediation (PDM) is an emerging mediation approach particularly suited for disputes between co-workers, colleagues or peers, especially deep-seated interpersonal conflict, multicultural or multiethnic disputes. The mediator listens to each party separately in a pre-caucus or pre-mediation before ever bringing them into a joint session. Part of the pre-caucus also includes coaching and role plays. The idea is that the parties learn how to converse directly with their adversary in the joint session. Some unique challenges arise when organizational disputes involve supervisors and subordinates. The negotiated performance appraisal (NPA) is a tool for improving communication between supervisors and subordinates and is particularly useful as an alternate mediation model because it preserves the hierarchical power of supervisors while encouraging dialogue and dealing with differences in opinion.

Disputes involving neighbors often have no official resolution mechanism. Community mediation centers generally focus on neighborhood conflict, with trained local volunteers serving as mediators. Such organizations often serve populations that cannot afford to utilize the courts or professional ADR-providers. Community programs typically provide mediation for disputes between landlords and tenants, members of homeowners associations and small businesses and consumers. Many community programs offer their services for free or at a nominal fee.

Experimental community mediation programs using volunteer mediators began in the early 1970s in several major U.S. cities. These proved to be so successful that hundreds of programs were founded throughout the country in the following two decades. In some jurisdictions, such as California, the parties have the option of making their agreement enforceable in court.

In Australia mediation was incorporated extensively into family law Family Law Act 1975 and the 2006 Amendments Mandatory, subject to certain exceptions, Family Dispute Resolution Mediation is required before courts will consider disputed parenting arrangements. The Family Dispute Resolution Practitioners who provide this service are accredited by the Attorney-General's Department.

A peer mediator is one who resembles the disputants, such as being of similar age, attending the same school or having similar status in a business. Purportedly, peers can better relate to the disputants than an outsider.

Peer mediation promotes social cohesion and aids development of protective factors that create positive school climates. The National Healthy School Standard (Department for Education and Skills, 2004) highlighted the significance of this approach to reducing bullying and promoting pupil achievement. Schools adopting this process recruit and train interested students to prepare them.

Peace Pals is an empirically validated peer mediation program. was studied over a 5-year period and revealed several positive outcomes including a reduction in elementary school violence and enhanced social skills, while creating a more positive, peaceful school climate.

Peer mediation helped reduce crime in schools, saved counselor and administrator time, enhanced self-esteem, improved attendance and encouraged development of leadership and problem-solving skills among students. Such conflict resolution programs increased in U.S. schools 40% between 1991 and 1999.

"Peace Pals" was studied in a diverse, suburban elementary school. Peer mediation was available to all students (N = 825). Significant and long-term reductions in school-wide violence over a five-year period occurred. The reductions included both verbal and physical conflict. Mediator knowledge made significant gains pertaining to conflict, conflict resolution and mediation, which was maintained at 3-month follow-up. Additionally, mediators and participants viewed the "Peace Pals" program as effective and valuable, and all mediation sessions resulted in successful resolution.

The commercial domain remains the most common application of mediation, as measured by number of mediators and the total exchanged value. The result of business mediation is typically a bilateral contract.

Commercial mediation includes work in finance, insurance, ship-brokering, procurement and real estate. In some areas, mediators have specialized designations and typically operate under special laws. Generally, mediators cannot themselves practice commerce in markets for goods in which they work as mediators.

Procurement mediation comprises disputes between a public body and a private body. In common law jurisdictions only regulatory stipulations on creation of supply contracts that derive from the fields of State Aids (EU Law and domestic application) or general administrative guidelines extend ordinary laws of commerce. The general law of contract applies in the UK accordingly. Procurement mediation occurs in circumstances after creation of the contract where a dispute arises in regard to the performance or payments. A Procurement mediator in the UK may choose to specialise in this type of contract or a public body may appoint an individual to a specific mediation panel.

In response to the Mabo decision, the Australian Government sought to engage the population and industry on Mabo's implications for land tenure and use by enacting the Native Title Act 1993 (Cth), which required mediation as a mechanism to determine future native title rights. The process incorporated the Federal Court and the National Native Title Tribunal (NNTT). Mediation can occur in parallel with legal challenges, such as occurred in Perth.

Some features of native title mediation that distinguish it from other forms include lengthy time frames, the number of parties (ranging on occasion into the hundreds) and that statutory and case law prescriptions constrain some aspects of the negotiations.

Mediation's effectiveness in trans-border disputes has been questioned, but an understanding of fundamental mediation principles points to the unlimited potential of mediation in such disputes. Mediators explicitly address and manage cultural and language differences in detail during the process. Voluntary referral to mediation is not required—much mediation to reach the table through binding contractual provisions, statutes, treaties, or international agreements and accords. The principle of voluntariness applies to the right of parties to self-determination once they are in the mediation—not to the mechanism for initiating the mediation process. Much mediation also results form mutual consent because they are non-binding and they encourage the exploration of interests and mutual benefits of an agreement. Because the parties, themselves, create the terms of agreement, compliance with mediated settlement agreements is relatively high. Any compliance or implementation issues can be addressed by follow-up mediation, regular compliance monitoring, and other processes.

Since the early 1980s a number of institutions in South Africa have championed mediation. The Independent Mediation Service of South Africa (IMSSA) was established in 1984. It trained mediators who then worked through Local Dispute Resolution Committees set up as part of the National Peace Accord. Initial training was undertaken by the UK's ACAS. IMSSA covers mediation within unionised environments. The more recently created Commission for Conciliation, Mediation and Arbitration (CCMA) was formed as result of the Labour Relation Act No 66 1995, and replaced the Industrial Courts in handling large areas of employment disputes.

Informal processes that engage a community in more holistic solution-finding are growing.

After 1995, the country established a legal right to take an employment dispute to conciliation/mediation. Mediation agreements are binding in law. The process has grown from generally covering collective agreements such as for wages or terms and conditions, to encompass more individual matters including dismissal.

The mediator's primary role is to act as a neutral third party who facilitates discussions between the parties. In addition, a mediator serves in an evaluative role when they analyze, assess the issues, and engage in reality-testing. A mediator is neutral and they are not the agent of any party. In their role, mediators do not offer prescriptive advice (e.g., "You should settle this case," or, "Your next offer should be X."). Mediators also manage the interaction between the parties and encourage constructive communication through the use of specialized communication techniques.

Finally, the mediator should restrict pressure, aggression and intimidation, demonstrate how to communicate through employing good speaking and listening skills, and paying attention to non-verbal messages and other signals emanating from the context of the mediation and possibly contributing expertise and experience. The mediator should direct the parties to focus on issues and stay away from personal attacks.

The role of the parties varies according to their motivations and skills, the role of legal advisers, the model of mediation, the style of mediator and the culture in which the mediation takes place. Legal requirements may also affect their roles. Party-directed mediation (PDM) is an emerging approach involving a pre-caucus between the mediator and each of the parties before going into the joint session. The idea is to help the parties improve their interpersonal negotiation skills so that in the joint session they can address each other with little mediator interference.

One of the general requirements for successful mediation is that those representing the respective parties have full authority to negotiate and settle the dispute. If this is not the case, then there is what Spencer and Brogan refer to as the "empty chair" phenomenon, that is, the person who ought to be discussing the problem is simply not present.

The parties' first role is to consent to mediation, possibly before preparatory activities commence. Parties then prepare in much the same way they would for other varieties of negotiations. Parties may provide position statements, valuation reports and risk assessment analysis. The mediator may supervise/facilitate their preparation and may require certain preparations.

Agreements to mediate, mediation rules, and court-based referral orders may have disclosure requirements. Mediators may have express or implied powers to direct parties to produce documents, reports and other material. In court-referred mediations parties usually exchange with each other all material which would be available through discovery or disclosure rules were the matter to proceed to hearing, including witness statements, valuations and statement accounts.

Mediation requires direct input from the parties. Parties must attend and participate in the mediation meeting. Some mediation rules require parties to attend in person. Participation at one stage may compensate for absence at another stage.

Choose an appropriate mediator, considering experience, skills, credibility, cost, etc. The criteria for mediator competence is under dispute. Competence certainly includes the ability to remain neutral and to move parties though various impasse-points in a dispute. The dispute is over whether expertise in the subject matter of the dispute should be considered or is actually detrimental to the mediator's objectivity.

Preparatory steps for mediation can vary according to legal and other requirements, not least gaining the willingness of the parties to participate.

In some court-connected mediation programs, courts require disputants to prepare for mediation by making a statement or summary of the subject of the dispute and then bringing the summary to the mediation. In other cases, determining the matter(s) at issue can become part of the mediation itself.

Consider having the mediator meet the disputants prior to the mediation meeting. This can reduce anxiety, improve settlement odds and increase satisfaction with the mediation process.

Ensure that all participants are ready to discuss the dispute in a reasonably objective fashion. Readiness is improved when disputants consider the viability of various outcomes.

Provide reasonable estimates of loss and/or damage.

Identify other participants. In addition to the disputants and the mediator, the process may benefit from the presence of counsel, subject-matter experts, interpreters, family, etc.

Secure a venue for each mediation session. The venue must foster the discussion, address any special needs, protect privacy and allow ample discussion time.

Ensure that supporting information such as pictures, documents, corporate records, pay-stubs, rent-rolls, receipts, medical reports, bank-statements, etc., are available.

Have parties sign a contract that addresses procedural decisions, including confidentiality, mediator payment, communication technique, etc.

The typical mediation has no formal compulsory elements, although some elements usually occur:


Individual mediators vary these steps to match specific circumstances, given that the law does not ordinarily govern mediators' methods.

Ratification and review provide safeguards for mediating parties. They also provide an opportunity for persons not privy to the mediation to undermine the result.
Some mediated agreements require ratification by an external body—such as a board, council or cabinet. In some situations the sanctions of a court or other external authority must explicitly endorse a mediation agreement. Thus if a grandparent or other non-parent is granted residence rights in a family dispute, a court counselor will be required to furnish a report to the court on merits of the proposed agreement to aid the court's ultimate disposition of the case.
In other situations it may be agreed to have agreements reviewed by lawyers, accountants or other professional advisers.

The implementation of mediated agreements must comply with the statues and regulations of the governing jurisdiction.

Parties to a private mediation may also wish to obtain court sanction for their decisions. Under the Queensland regulatory scheme on court connected mediation, mediators are required to file with a registrar a certificate about the mediation in a form prescribed in the regulations. A party may subsequently apply to a relevant court an order giving effect to the agreement reached. Where court sanction is not obtained, mediated settlements have the same status as any other agreements.

Mediators may at their discretion refer one or more parties to psychologists, accountants, social workers or others for post-mediation professional assistance.

In some situations, a post-mediation debriefing and feedback session is conducted between co-mediators or between mediators and supervisors. It involves a reflective analysis and evaluation of the process. In many community mediation services debriefing is compulsory and mediators are paid for the debriefing session.

Mediation recognised that in addition to the fact of reaching a settlement, party satisfaction and mediator competence could be measured. Surveys of mediation parties reveal strong levels of satisfaction with the process. Of course, if parties are generally satisfied post-settlement, then such measures may not be particularly explanatory.

The educational requirements for accreditation as a mediator differ between accrediting groups and from country to country. In some cases legislation mandates requirements; in others professional bodies impose accreditation standards. Many US universities offer graduate studies in mediation, such as the University of Massachusetts, Boston.

In Australia, for example, professionals wanting to practice in the area of family law must have tertiary qualifications in law or in social science, undertake 5 days training in mediation and engage in 10 hours of supervised mediation. Furthermore, they must also undertake 12 hours of education or training every 12 months.

Other institutions offer units in mediation across a number of disciplines such as law, social science, business and the humanities. Not all kinds of mediation-work require academic qualifications, as some deal more with practical skills than with theoretical knowledge. Membership organizations provide training courses. Internationally a similar approach to the training of mediators is taken by organizations such as the Centre for Effective Dispute Resolution, CEDR. Based in London, it has trained over 5000 CEDR mediators from different countries to date.

No legislated national standards on the level of education apply to all practitioners' organizations. However, organizations such as the National Alternative Dispute Resolution Advisory Council (NADRAC) advocate for a wide scope on such issues. Other systems apply in other jurisdictions such as Germany, which advocates a higher level of educational qualification for practitioners of mediation.

Common elements of codes of conduct include:


In Australia mediation codes of conduct include those developed by the Law Societies of South Australia and Western Australia and those developed by organisations such as Institute of Arbitrators & Mediators Australia (IAMA) and LEADR. The CPR/Georgetown Ethics Commission, the Mediation Forum of the Union International des Avocats, and the European Commission have promulgated codes of conduct for mediators.

In Canada codes of conduct for mediators are set by professional organizations. In Ontario three distinct professional organizations maintain codes of conduct for mediators. The Family Dispute Resolution Institute of Ontario and the Ontario Association of Family Mediators set standards for their members who mediate family matters and the Alternative Dispute Resolution Institute of Ontario who sets standards for their members.

The Alternative Dispute Resolution Institute of Ontario, a regional affiliate of the Alternative Dispute Resolution Institute of Canada, uses the code of conduct from the federal organization to regulate the conduct of its members. The Code's three objectives are to provide guiding principles for the conduct of mediators; to promote confidence in mediation as a process for resolving disputes; and to provide protection for members of the public who use mediators who are members of the institute.

In France, professional mediators have created an organization to develop a rational approach to conflict resolution. This approach is based on a "scientific" definition of a person and a conflict. These definitions help to develop a structured mediation process. Mediators have adopted a code of ethics which guarantees professionalism. 

In Germany, due to the Mediation Act of 2012, mediation as a process and the responsibilities of a mediator are legally defined. Based on the German language and the specific codification (so-called "funktionaler Mediator") one has to take into account, that all persons who "mediate" in a conflict (defined as facilitation without evaluation and proposals for solution!) are tied to the provisions of the Mediation Act even if they call their approach/process not mediation but facilitation (Prozessbegleitung), conciliation (Schlichtung), conflict counseling (Konflikt-Beratung), consulting (Organisationsberatung), conflict coaching or whatever else.
For example, according to sec. 2 and sec. 3 of the German Mediation Act, the mediator has certain information and disclosure obligations as well as limittions of practice. In particular, a person who has been in any form of (legal, social, financial, etc.) counseling role to a party in this matter is not allowed to act as a mediator in the case (sec. 3 par. 3 and 4 German Mediation ACT – so called "Vorbefassungsverbot").

A range of organizations within Australia accredit mediators. Standards vary according to the specific mediation and the level of specificity that is desired. Standards apply to particular ADR processes.

The National Mediator Accreditation System (NMAS) commenced operation on 1 January 2008. It is an industry-based scheme which relies on voluntary compliance by mediator organisations that agree to accredit mediators in accordance with the requisite standards.

Mediator organizations have varying ideals of what makes a good mediator which reflect the training and accreditation of that particular organization. Australia did not adopt a national accreditation system, which may lead to suboptimal choice of mediators.

According to sec. 6 German Mediation Act the German government on June 21, 2016 has released the German regulation about education and training of the so-called (legal term) "certified mediators" which from Sept. 1, 2017 postulates a minimum of 120 hours of initial specialized mediator training as well as case supervision and further ongoing training of 40 hours within 4 years. Beyond this basic qualification, the leading mediation associations (BAFM, BM, BMWA and DGM) have agreed on quality standards higher than the minimum standards of the national regulation to certify their mediators. To become an accredited mediator of these associations one has to complete an accredited mediation training program of a minimum of 200 hours incl. 30 hours of supervision as well as ongoing training (30–40 hours within three years)."

Mediator selection is of practical significance given varying models of mediation, mediators' discretion in structuring the process and the impact of the mediator's professional background and personal style on the result.

In community mediation programs the director generally assigns mediators. In New South Wales, for example, when the parties cannot agree on a mediator, the registrar contacts a nominating entity, such as the Bar Association which supplies the name of a qualified and experienced mediator.

As of 2006, formal mechanisms for objecting to the appointment of a particular mediator had not been established. Parties could ask the mediator to withdraw for reasons of conflict of interest. In some cases, legislation establishes criteria for mediators. In New South Wales, for example, the Family Law Act 1975 (Cth) proscribes qualifications for mediators.

The following are useful criteria for selecting a mediator:

Contracts that specify mediation may also specify a third party to suggest or impose an individual. Some third parties simply maintain a list of approved individuals, while others train mediators. Lists may be "open" (any person willing and suitably qualified can join) or a "closed" panel (invitation only).

In the UK and internationally, lists are generally open, such as The Chartered Institute of Arbitrators, the Centre for Effective Dispute Resolution. Alternatively, private panels co-exist and compete for appointments e.g., Savills Mediation.

Legal liability may stem from a mediation. For example, a mediator could be liable for misleading the parties or for even inadvertently breaching confidentiality. Despite such risks, follow-on court action is quite uncommon. Only one case reached that stage in Australia as of 2006. Damage awards are generally compensatory in nature. Proper training is mediators' best protection.

Liability can arise for the mediator from Liability in Contract; Liability in Tort; and Liability for Breach of Fiduciary Obligations.

Liability in Contract arises if a mediator breaches (written or verbal) contract with one or more parties. The two forms of breach are "failure to perform" and "anticipatory breach". Limitations on liability include the requirement to show actual causation.

Liability in Tort arises if a mediator influences a party in any way (compromising the integrity of the decision), defames a party, breaches confidentiality, or most commonly, is negligent. To be awarded damages, the party must show actual damage, and must show that the mediator's actions (and not the party's actions) were the actual cause of the damage.

Liability for Breach of Fiduciary Obligations can occur if parties misconceive their relationship with a mediator as something other than neutrality. Since such liability relies on a misconception, court action is unlikely to succeed.

As of 2008 Tapoohi v Lewenberg was the only case in Australia that set a precedent for mediators' liability.

The case involved two sisters who settled an estate via mediation. Only one sister attended the mediation in person: the other participated via telephone with her lawyers present. An agreement was executed. At the time it was orally expressed that before the final settlement, taxation advice should be sought as such a large transfer of property would trigger capital gains taxes.

Tapoohi paid Lewenberg $1.4 million in exchange for land. One year later, when Tapoohi realized that taxes were owed, she sued her sister, lawyers and the mediator based on the fact that the agreement was subject to further taxation advice.

The original agreement was verbal, without any formal agreement. Tapoohi, a lawyer herself, alleged that the mediator breached his contractual duty, given the lack of any formal agreement; and further alleged tortious breaches of his duty of care.

Although the court dismissed the summary judgment request, the case established that mediators owe a duty of care to parties and that parties can hold them liable for breaching that duty of care. Habersberger J held it "not beyond argument" that the mediator could be in breach of contractual and tortious duties. Such claims were required to be assessed at a trial court hearing.

This case emphasized the need for formal mediation agreements, including clauses that limit mediators' liability.

Within the United States, the laws governing mediation vary by state. Some states have clear expectations for certification, ethical standards and confidentiality. Some also exempt mediators from testifying in cases they've worked on. However, such laws only cover activity within the court system. Community and commercial mediators practising outside the court system may not have such legal protections. State laws regarding lawyers may differ widely from those that cover mediators. Professional mediators often consider the option of liability insurance.

Evaluative mediation is focused on providing the parties with an evaluation of their case and directing them toward settlement. During an evaluative mediation process, when the parties agree that the mediator should do so, the mediator will express a view on what might be a fair or reasonable settlement. The Evaluative mediator has somewhat of an advisory role in that s/he evaluates the strengths and weaknesses of each side's argument and makes some predictions about what would happen should they go to court. Facilitative and transformative mediators do not evaluate arguments or direct the parties to a particular settlement.

In Germany, due to national regulation "evaluative mediation" is seen as an oxymoron and not allowed by the German mediation Act. Therefore, in Germany mediation is purly facilitative. In Australia, the industry accepted definition of mediation involves a mediator adopting a non advisory and non determinative approach. However, there is also provision under the National Mediator Accreditation Standards for mediators to offer a 'blended' approach provided that participants consent to such a process in writing, the mediator is appropriately insured and has the expertise required.

Facilitative mediators typically do not evaluate a case or direct the parties to a particular settlement. Instead, the Facilitative mediator facilitates the conversation. These mediators act as guardian of the process, not the content or the outcome. During a facilitative mediation session the parties in dispute control both what will be discussed and how their issues will be resolved. Unlike the transformative mediator, the facilitative mediator is focused on helping the parties find a resolution to their dispute and to that end, the facilitative mediator provides a structure and agenda for the discussion.

Transformative mediation looks at conflict as a crisis in communication. Success is not measured by settlement but by the parties shifts toward (a) personal strength, (b) interpersonal responsiveness, (c) constructive interaction, (d) new understandings of themselves and their situation, (e) critically examining the possibilities, (f) feeling better about each other, and (g) making their own decisions. Those decisions can include settlement agreements or not. Transformative mediation practice is focused on supporting empowerment and recognition shifts, by allowing and encouraging deliberation, decision-making, and perspective-taking. A competent transformative mediator practices with a microfocus on communication, identifying opportunities for empowerment and recognition as those opportunities appear in the parties' own conversations, and responding in ways that provide an opening for parties to choose what, if anything, to do with them.

The narrative approach to mediation shares with narrative therapy an emphasis on constructing stories as a basic human activity in understanding our lives and conflict. This approach emphasizes the sociological/psychological nature of conflict-saturated narratives, and values human creativity in acting and reacting to these narratives. "The narrative metaphor draws attention to the ways in which we use stories to make sense of our lives and our relationship." Narrative mediation advocates changing the way we speak about conflicts. In objectifying the conflict narrative, participants become less attached to the problem and more creative in seeking solutions. "The person is not the problem; the problem is the problem" according to narrative mediation.

Mediation has sometimes been utilized to good effect when coupled with arbitration, particularly binding arbitration, in a process called 'mediation/arbitration'. The process begins as a standard mediation, but if mediation fails, the mediator becomes an arbiter.

This process is more appropriate in civil matters where rules of evidence or jurisdiction are not in dispute. It resembles, in some respects, criminal plea-bargaining and Confucian judicial procedure, wherein the judge also plays the role of prosecutor—rendering what, in Western European court procedures, would be considered an arbitral (even 'arbitrary') decision.

Mediation/arbitration hybrids can pose significant ethical and process problems for mediators. Many of the options and successes of mediation relate to the mediator's unique role as someone who wields no coercive power over the parties or the outcome. The parties awareness that the mediator might later act in the role of judge could distort the process. Using a different individual as the arbiter addresses this concern.

Online mediation employs online technology to provide disputants access to mediators and each other despite geographic distance, disability or other barriers to direct meeting. Online approaches also facilitate mediation when the value of the dispute does not justify the cost of face-to-face contact. Online mediation can also combine with face-to-face mediation—to allow mediation to begin sooner and/or to conduct preliminary discussions.

Neutral mediators enter into a conflict with the main intention in ending a conflict. This goal tends to hasten a mediator to reach a conclusion. Biased mediators enter into a conflict with specific biases in favor of one party or another. Biased mediators look to protect their parties interest thus leading to a better, more lasting resolution.

Mediation is one of several approaches to resolving disputes. It differs from adversarial resolution processes by virtue of its simplicity, informality, flexibility, and economy. Mediation provides the opportunity for parties to agree terms and resolve issues by themselves, without the need for legal representation or court hearings.

Not all disputes lend themselves well to mediation. Success is unlikely unless:

"Conciliation" sometimes serves as an umbrella term that covers mediation and facilitative and advisory dispute-resolution processes. Neither process determines an outcome, and both share many similarities. For example, both processes involve a neutral third-party who has no enforcing powers.

One significant difference between conciliation and mediation lies in the fact that conciliators possess expert knowledge of the domain in which they conciliate. The conciliator can make suggestions for settlement terms and can give advice on the subject-matter. Conciliators may also use their role to actively encourage the parties to come to a resolution. In certain types of dispute the conciliator has a duty to provide legal information. This helps ensure that agreements comply with relevant statutory frameworks. Therefore, conciliation may include an advisory aspect.

Mediation is purely facilitative: the mediator has no advisory role. Instead, a mediator seeks to help parties to develop a shared understanding of the conflict and to work toward building a practical and lasting resolution.

Both mediation and conciliation work to identify the disputed issues and to generate options that help disputants reach a mutually satisfactory resolution. They both offer relatively flexible processes. Any settlement reached generally must have the agreement of all parties. This contrasts with litigation, which normally settles the dispute in favour of the party with the strongest legal argument. In-between the two operates collaborative law, which uses a facilitative process where each party has counsel.

A counsellor generally uses therapeutic techniques. Some—such as a particular line of questioning—may be useful in mediation. But the role of the counsellor differs from the role of the mediator. The list below is not exhaustive but it gives an indication of important distinctions:


The technique of "early neutral evaluation" (ENE) have focus on market ineterships, and—based on that focus—offers a basis for sensible case-management or a suggested resolution of the entire case in its very early stages.

In early neutral evaluation, an evaluator acts as a neutral person to assess the strengths and weaknesses of each of the parties and to discuss the same with parties jointly or in caucuses, so that parties gain awareness (via independent evaluation) of the merits of their case.

Parties generally call on a senior counsel or on a panel with expertise and experience in the subject-matter under dispute in order to conduct ENE.

Binding Arbitration is a more direct substitute for the formal process of a court. Binding Arbitration is typically conducted in front of one or three arbitrators. The process is much like a mini trial with rules of evidence, etc. Arbitration typically proceeds faster than court and typically at a lower cost. The Arbiter makes the ultimate decision rather than the parties. Arbiters' decisions are typically final and appeals are rarely successful even if the decision appears to one party to be completely unreasonable.

In litigation, courts impose their thoughts to both parties Courts in some cases refer litigants to mediation. Mediation is typically less costly, less formal and less complex. Unlike courts, mediation does not ensure binding agreements and the mediator does not decide the outcome.

While mediation implies bringing disputing parties face-to-face with each other, the strategy of "shuttle diplomacy", where the mediator serves as a liaison between disputing parties, also sometimes occurs as an alternative.

Mediation can anticipate difficulties between parties before conflict emerges. Complaint handling and management is a conflict prevention mechanism designed to handle a complaint effectively at first contact, minimising the possibility of a dispute. One term for this role is "dispute preventer".

One of the hallmarks of mediation is that the process is strictly confidential. Two competing principles affect confidentiality. One principle encourages confidentiality to encourage people to participate, while the second principle states that all related facts should be available to courts.

The mediator must inform the parties of their responsibility for confidentiality.

Steps put in place during mediation to help ensure this privacy include:


Confidentiality is a powerful and attractive feature of mediation. It lowers the risk to participants of disclosing information and emotions and encourages realism by eliminating the benefits of posturing. In general, information discussed in mediation cannot be used as evidence in the event that the matter proceeds to court, in accord with the mediation agreement and common law.

Few mediations succeed unless the parties can communicate fully and openly without fear of compromising a potential court case. The promise of confidentiality mitigates such concerns. Organisations often see confidentiality as a reason to use mediation in lieu of litigation, particularly in sensitive areas. This contrasts with the public nature of courts and other tribunals. However mediation need not be private and confidential. In some circumstances the parties agree to open the mediation in part or whole. Laws may limit confidentiality. For example, mediators must disclose allegations of physical or other abuse to authorities. The more parties in a mediation, the less likely that perfect confidentiality will be maintained. Some parties may even be required to give an account of the mediation to outside constituents or authorities.

Most countries respect mediator confidentiality.

The without-prejudice privilege in common law denotes that in honest attempts to reach settlement, any offers or admissions cannot be used in court when the subject matter is the same. This applies to the mediation process. The rule comes with exceptions.

The without-prejudice privilege does not apply if it was excluded by either party or if the privilege was waived in proceedings. Although mediation is private and confidential, the disclosure of privileged information in the presence of a mediator does not represent a waiver of the privilege.

Parties who enter into mediation do not forfeit legal rights or remedies. If mediation does not result in settlement, each side can continue to enforce their rights through appropriate court or tribunal procedures. However, if mediation produces a settlement, legal rights and obligations are affected in differing degrees. In some situations, the parties may accept a memorandum or moral force agreement; these are often found in community mediations. In other instances, a more comprehensive deed of agreement, when registered with a court, is legally binding. It is advisable to have a lawyer draft or provide legal advice about the proposed terms.

"Court systems are eager to introduce mandatory mediation as a means to meet their needs to reduce case loads and adversarial litigation, and participants who understand the empowerment of mediation to self-determine their own agreements are equally as eager to embrace mediation as an alternative to costly and potentially harmful litigation."

Principles of mediation include non-adversarialism, responsiveness, self-determination and party autonomy.

Non-adversarialism is based on the actual process of mediation. It treats the parties as collaborating in the construction of an agreement. By contrast, litigation is explicitly adversarial in that each party attempts to subject the other to its views. Mediation is designed to conclude with an agreement rather than a winner and loser.

Responsiveness reflects the intent to allow the parties to craft a resolution outside of the strict rules of the legal system. A responsive mediation process also is informal, flexible and collaborative.

Self-determination and party autonomy allow and require parties to choose the area of agreement, rather than ceding the decision to an outside decision-maker such as a judge. This turns the responsibility for the outcome onto the parties themselves.

In the United States, mediator codes-of-conduct emphasize "client-directed" solutions rather than imposed solutions. This has become a common, definitive feature of mediation in the US and UK.

Theorists, notably Rushworth Kidder, who founded the Institute for Global Ethics in 1980, claimed that mediation is the foundation of a 'postmodern' ethics—and that it sidesteps traditional ethical issues with pre-defined limits of morality.

Mediation can also be seen as a form of harm reduction or de-escalation, especially in its large-scale application in peace and similar negotiations, or the bottom-up way it is performed in the peace movement where it is often called mindful mediation. This form derived from methods of Quakers in particular.

Society perceives conflict as something that one should resolve as quickly as possible. Mediators see conflict as a fact of life that when properly managed can benefit the parties. The benefits of conflict include the opportunity to renew relationships and make positive changes for the future.



</doc>
<doc id="20583" url="https://en.wikipedia.org/wiki?curid=20583" title="Misdemeanor">
Misdemeanor

A misdemeanor (American English, spelled misdemeanour in British English) is any "lesser" criminal act in some common law legal systems. Misdemeanors are generally punished less severely than felonies, but theoretically more so than administrative infractions (also known as minor, petty, or summary offences) and regulatory offences. Many misdemeanors are punished with monetary fines.

A misdemeanor is considered a crime of low seriousness, and a felony one of high seriousness. A principle of the rationale for the degree of punishment meted out is that the punishment should fit the crime. One standard for measurement is the degree to which a crime affects others or society. Measurements of the degree of seriousness of a crime have been developed.

In the United States, the federal government generally considers a crime punishable with incarceration for one year or less to be a misdemeanor. All other crimes are considered felonies. Many states also employ the same or a similar distinction.

The distinction between felonies and misdemeanors has been abolished by several common law jurisdictions (notably the UK and Australia). These jurisdictions have generally adopted some other classification (in the UK the substance of the original distinction remains, only slightly altered): in the Commonwealth nations of Australia, Canada, New Zealand, and the United Kingdom, the crimes are divided into summary offences and indictable offences. The Republic of Ireland, a former member of the Commonwealth, also uses these divisions.

In the United States, even if a criminal charge for the defendant's conduct is normally a misdemeanor, sometimes a repeat offender will be charged with a felony offense. For example, the first time a person commits certain crimes, such as spousal assault, it is normally a misdemeanor, but the second time it may become a felony. Other misdemeanors may be upgraded to felonies based on context. For example, in some jurisdictions the crime of indecent exposure might normally be classified as a misdemeanor, but be charged as a felony when committed in front of a minor.

In some jurisdictions, those who are convicted of a misdemeanor are known as misdemeanants (as contrasted with those convicted of a felony who are known as "felons"). Depending on the jurisdiction, examples of misdemeanors may include: petty theft, prostitution, public intoxication, simple assault, disorderly conduct, trespass, vandalism, reckless driving, discharging a firearm within city limits, possession of cannabis and in some jurisdictions first-time possession of certain other drugs, and other similar crimes.

Misdemeanors usually do not result in the loss of civil rights, but may result in loss of privileges, such as professional licenses, public offices, or public employment. Such effects are known as the collateral consequences of criminal charges. This is more common when the misdemeanor is related to the privilege in question (such as the loss of a taxi driver's license after a conviction for reckless driving), or when the misdemeanor involves moral turpitude—and in general is evaluated on a case-by-case basis.

In the United States, misdemeanors are typically crimes with a maximum punishment of 12 months of incarceration, typically in a local jail as contrasted with felons, who are typically incarcerated in a prison. Jurisdictions such as Massachusetts are a notable exception where the maximum punishment of some misdemeanors is up to 2.5 years. People who are convicted of misdemeanors are often punished with probation, community service, short jail term, or part-time incarceration such as a sentence that may be served on the weekends.

The United States Constitution provides that the President may be impeached and subsequently removed from office if found guilty by Congress for "high crimes and misdemeanors". As used in the Constitution, the term "misdemeanor" refers broadly to criminal acts as opposed to employing the felony-misdemeanor distinction used in modern criminal codes. The definition of what constitutes "high crimes and misdemeanors" for purposes of impeachment is left to the judgment of Congress.

In Singapore, misdemeanors generally are sentenced to months of jail sentence but with individual crimes suspects are sentenced to a harsher sentence. The penalty of vandalism is a fine not exceeding S$2,000 or imprisonment not exceeding three years, and also corporal punishment of not less than three strokes and not more than eight strokes of the cane.

Depending on the jurisdiction, several classes of misdemeanors may exist; the forms of punishment can vary widely between those classes. For example, the federal and some state governments in the United States divide misdemeanors into several classes, with certain classes punishable by jail time and others carrying only a fine. In New York law, a Class A Misdemeanor carries a maximum sentence of one year of imprisonment, while a Class B Misdemeanor "shall not exceed three months".

In the United States, when a statute does not specify the class of a misdemeanor, it may be referred to as an "unclassified misdemeanor". Legislators usually enact such laws when they wish to impose penalties that fall outside the framework specified by each class. For example, Virginia has four classes of misdemeanors, with Class 1 and Class 2 misdemeanors being punishable by twelve-month and six-month jail sentences, respectively, and Class 3 and Class 4 misdemeanors being non-jail offenses payable by fines. First-time cannabis possession is an unclassified misdemeanor in Virginia punishable by up to 30 days in jail rather than the normal fines and jail sentences of the four classes. New York has three classes of misdemeanor: A, B, and Unclassified.

All distinctions between felony and misdemeanour were abolished by section 1(1) of the Criminal Law Act 1967. Prior to this, a person prosecuted for misdemeanour was called a defendant.



</doc>
<doc id="20584" url="https://en.wikipedia.org/wiki?curid=20584" title="Morgan Freeman">
Morgan Freeman

Morgan Freeman (born June 1, 1937) is an American actor and film narrator. Freeman won an Academy Award in 2005 for Best Supporting Actor with "Million Dollar Baby" (2004) and has received Oscar nominations for his performances in "Street Smart" (1987), "Driving Miss Daisy" (1989), "The Shawshank Redemption" (1994) and "Invictus" (2009). He has also won a Golden Globe Award and a Screen Actors Guild Award.

Freeman has appeared in many other box office hits, including "Glory" (1989), "" (1991), "Seven" (1995), "Deep Impact" (1998), "The Sum of All Fears" (2002), "Bruce Almighty" (2003), "The Dark Knight Trilogy" (2005–2012), "Wanted" (2008), "Red" (2010), "Now You See Me" (2013), "The Lego Movie" (2014) and "Lucy" (2014). He rose to fame as part of the cast of the 1970s children's program "The Electric Company". Noted for his deep voice, Freeman has served as a narrator, commentator, and voice actor for numerous programs, series and television shows. He is ranked as the seventh-highest box office star since July 2019. He has a combined total box office gross of $4.57 billion, with an average of $71.5 million per film.

Morgan Freeman was born on June 1, 1937 in Memphis, Tennessee. He is the son of Mayme Edna (née Revere; 1912–2000), a teacher, and Morgan Porterfield Freeman (July 6, 1915 – April 27, 1961), a barber, who died of cirrhosis in 1961. He has three older siblings. According to a DNA analysis, some of his ancestors were from Niger. In 2008, a DNA test suggested that among all of his African ancestors, a little over one-quarter came from the area that stretches from present-day Senegal to Liberia and three-quarters came from the Congo-Angola region. Freeman was sent as an infant to his paternal grandmother in Charleston, Mississippi. He moved frequently during his childhood, living in Greenwood, Mississippi; Gary, Indiana; and finally Chicago, Illinois. When Freeman was 16 years old, he almost died of pneumonia.

Freeman made his acting debut at age nine, playing the lead role in a school play. He then attended Broad Street High School, a building which serves today as Threadgill Elementary School, in Greenwood, Mississippi. At age 12, he won a statewide drama competition, and while still at Broad Street High School, he performed in a radio show based in Nashville, Tennessee. In 1955, he graduated from Broad Street, but turned down a partial drama scholarship from Jackson State University, opting instead to enlist in the United States Air Force and served as an Automatic Tracking Radar Repairman, rising to the rank of Airman 1st Class.

After four years in the military, he moved to Los Angeles, California, took acting lessons at the Pasadena Playhouse and dancing lessons in San Francisco in the early 1960s, and worked as a transcript clerk at Los Angeles City College.

During the early 1960s, Freeman worked as a dancer at the 1964 World's Fair and was a member of the Opera Ring musical theater group in San Francisco. He acted in a touring company version of "The Royal Hunt of the Sun," and also appeared as an extra in the 1965 film "The Pawnbroker." Freeman made his Off-Broadway debut in 1967, opposite Viveca Lindfors in "The Nigger Lovers" (about the Freedom Riders during the American Civil Rights Movement), before debuting on Broadway in 1968's all-black version of "Hello, Dolly!" which also starred Pearl Bailey and Cab Calloway.

Although his first credited film appearance was in 1971's "Who Says I Can't Ride a Rainbow!", Freeman first became known in the American media through roles on the soap opera "Another World" and the PBS kids' show "The Electric Company" (notably as Easy Reader, Mel Mounds the DJ, and Vincent the Vegetable Vampire).

Joan Ganz Cooney claims that Freeman hated doing "The Electric Company", saying "it was a very unhappy period in his life." Freeman himself admitted in an interview that he never thinks about his tenure with the show, but he acknowledged that, contrary to Cooney's claims, he was glad to have been a part of it. Since then, Freeman has considered his "Street Smart" (1987) character Fast Black, rather than any of the characters he played in "The Electric Company", to be his breakthrough role.

Freeman continued to be involved in theater work and received the Obie Award in 1980 for the title role in "Coriolanus". In 1984, he received his second Obie Award for his role as the preacher in "The Gospel at Colonus". Freeman also won a Drama Desk Award and a Clarence Derwent Award for his role as a wino in "The Mighty Gents". He received his third Obie Award for his role as a chauffeur for a Jewish widow in "Driving Miss Daisy", which was adapted for the screen in 1989.

Beginning in the mid-1980s, Freeman began playing prominent supporting roles in feature films, earning him a reputation for depicting wise, fatherly characters. As he gained fame, he went on to bigger roles in films such as the chauffeur Hoke in "Driving Miss Daisy", and Sergeant Major Rawlins in "Glory" (both in 1989). In 1994, he portrayed Red, the redeemed convict in the acclaimed "The Shawshank Redemption". In the same year he was a member of the jury at the 44th Berlin International Film Festival.

He also starred in such films as "", "Unforgiven", "Seven", and "Deep Impact". In 1997, Freeman, together with Lori McCreary, founded the film production company Revelations Entertainment, and the two co-head its sister online film distribution company ClickStar. Freeman also hosts the channel "Our Space" on ClickStar, with specially crafted film clips in which he shares his love for the sciences, especially space exploration and aeronautics.

After three previous nominations – a Best Supporting Actor nomination for "Street Smart", and Best Actor nominations for "Driving Miss Daisy" and "The Shawshank Redemption"—he won the Academy Award for Best Supporting Actor for his performance in "Million Dollar Baby" at the 77th Academy Awards. Freeman is recognized for his distinctive voice, making him a frequent choice for narration. In 2005 alone, he provided narration for two films, "War of the Worlds" and the Academy Award-winning documentary film "March of the Penguins".

Freeman appeared as God in the hit film "Bruce Almighty" and its sequel "Evan Almighty". He appeared in Christopher Nolan's Dark Knight Trilogy – "Batman Begins" (2005) and its sequels "The Dark Knight" (2008) and "The Dark Knight Rises" (2012) – as Lucius Fox. He starred in Rob Reiner's 2007 film "The Bucket List", opposite Jack Nicholson. He teamed with Christopher Walken and William H. Macy for the comedy "The Maiden Heist", which was released direct to video due to financial problems with the distribution company. In 2008, Freeman returned to Broadway to co-star with Frances McDormand and Peter Gallagher for a limited engagement of Clifford Odets' play, "The Country Girl", directed by Mike Nichols.

Freeman wanted to do a film based on Nelson Mandela for some time. At first he tried to get Mandela's autobiography "Long Walk to Freedom" adapted into a finished script, but it was not finalized. In 2007, he purchased the film rights to a book by John Carlin, "Playing the Enemy: Nelson Mandela and the Game That Made a Nation". Clint Eastwood directed the Nelson Mandela bio-pic titled "Invictus", starring Freeman as Mandela and Matt Damon as rugby team captain Francois Pienaar.

In 2010, Freeman co-starred alongside Bruce Willis in "Red".

In 2011, Freeman was featured with John Lithgow in the Broadway debut of Dustin Lance Black's play, "8", a staged reenactment of "Perry v. Brown", the federal trial that overturned California's Proposition 8 ban on same-sex marriage. Freeman played Attorney David Boies. The production was held at the Eugene O'Neill Theatre in New York City to raise money for the American Foundation for Equal Rights.

In 2013, Freeman appeared in the action-thriller "Olympus Has Fallen", the science fiction drama "Oblivion", and the comedy "Last Vegas". In 2014, he co-starred in the action film "Lucy". In 2015, Freeman played the Chief Justice of the United States in the season two premiere of "Madam Secretary" (Freeman is also one of the series' executive producers). He also appeared in "London Has Fallen", the 2016 sequel of "Olympus Has Fallen".

Freeman made his directorial debut in 1993 with "Bopha!" for Paramount Pictures.

In July 2009, Freeman was one of the presenters at the 46664 Concert celebrating Nelson Mandela's birthday at Radio City Music Hall in New York City.

Effective January 4, 2010, Freeman replaced Walter Cronkite as the voiceover introduction to the "CBS Evening News" featuring Katie Couric as news anchor. CBS cited the need for consistency in introductions for regular news broadcasts and special reports as the basis for the change. , Freeman is the host and narrator of the Discovery Channel television show, focused on physics outreach, "Through the Wormhole". He was featured on the opening track to B.o.B's second album "Strange Clouds". The track "Bombs Away" features a prologue and epilogue (which leads into a musical outro) spoken by Freeman.

In 2015, Freeman directed "The Show Must Go On", the season two premiere of "Madam Secretary". In 2017, he hosted "The Story of Us with Morgan Freeman".

Up until May 2018, Freeman also served as the narrator of a series of Visa commercials.

From his early life, Freeman has two extramarital children; one of them is Alfonso Freeman.

Freeman was married to Jeanette Adair Bradshaw from October 22, 1967 until November 18, 1979.

Freeman married Myrna Colley-Lee on June 16, 1984. The couple separated in December 2007 and divorced on September 15, 2010. Freeman and Colley-Lee adopted Freeman's stepgranddaughter from his first marriage, E'dena Hines, and raised her together. On August 16, 2015, Hines was murdered in New York City at age 33.

In 2008, the TV series "African American Lives 2" revealed that some of Freeman's great-great-grandparents were slaves who migrated from North Carolina to Mississippi. Freeman discovered that his Caucasian maternal great-great-grandfather had lived with, and was buried beside, Freeman's African-American great-great-grandmother (in the segregated South, the two could not marry legally at the time). A DNA test on the series stated that he is descended in part from the Songhai and Tuareg peoples of Niger.

After becoming concerned with the decline of honeybees, Freeman decided to turn his 124-acre ranch into a sanctuary for them in July 2014, starting with 26 bee hives.

At age 65, Freeman earned a private pilot's license. He owns or has owned at least three private aircraft, including a Cessna Citation 501 jet and a Cessna 414 twin-engine prop. In 2007, he purchased an Emivest SJ30 long-range private jet and took delivery in December 2009. He is certified to fly all of them.

Freeman was injured in an automobile accident near Ruleville, Mississippi, on the night of August 3, 2008. The vehicle in which he was traveling, a 1997 Nissan Maxima, left the highway and flipped over several times. He and a female passenger, Demaris Meyer, were rescued from the vehicle using the "Jaws of Life". Freeman was taken via medical helicopter to The Regional Medical Center (The Med) hospital in Memphis. Police ruled out alcohol as a factor in the crash. Freeman was coherent following the crash, as he joked with a photographer about taking his picture at the scene. His left shoulder, arm, and elbow were broken in the crash, and he had surgery on August 5, 2008. Doctors operated for four hours to repair nerve damage in his shoulder and arm. On CNN's "Piers Morgan Tonight" he stated that he is left handed but cannot move the fingers of his left hand. He wears a compression glove to protect against blood pooling due to non-movement. His publicist announced he was expected to make a full recovery. Meyer, his passenger, sued him for negligence, claiming that he was drinking the night of the accident. Subsequently, the suit was settled for an undisclosed amount.

In an interview with Esquire on July 2012, Freeman revealed that he suffers from the chronic pain condition Fibromyalgia.

Freeman lives in Charleston, Mississippi, and New York City. He owns and operates Ground Zero, a blues club in Clarksdale, Mississippi. He formerly co-owned Madidi, a fine dining restaurant, also in Clarksdale.

In a 2012 interview with TheWrap, Freeman was asked if he considered himself atheist or agnostic. He replied, "It's a hard question because as I said at the start, I think we invented God. So if I believe in God, and I do, it's because I think I'm God." Freeman later said that his experience working on "The Story of God with Morgan Freeman" did not change his views on religion.

On May 24, 2018, CNN reported the results of an investigation during which eight women accused Freeman of sexually harassing them, and eight other people said they witnessed his inappropriate behavior on the set of movies, while promoting his movies, or at his production company. After the CNN story broke, Freeman issued an apology, stating "Anyone who knows me or has worked with me knows I am not someone who would intentionally offend or knowingly make anyone feel uneasy. I apologize to anyone who felt uncomfortable or disrespected—that was never my intent." CNN also made several requests to the spokesperson for Lori McCreary, Freeman's business partner, but no comment was given.

As a result of the sexual harassment allegations, the Screen Actors Guild (SAG) reviewed what action, if any, to take against Freeman, as Freeman was recognized with a lifetime achievement award by SAG. In September 2018, SAG confirmed that Freeman could retain his award.

Following the announcement of the allegations, Visa suspended its marketing campaign with Freeman and stopped airing commercials that featured his voice.

In 2004, Freeman and others formed the Grenada Relief Fund to aid people affected by Hurricane Ivan on the island of Grenada. The fund has since become PLANIT NOW, an organization that seeks to provide preparedness resources for people living in areas afflicted by hurricanes and severe storms. Freeman has worked on narrating small clips for global organizations, such as One Earth, whose goals include raising awareness of environmental issues. He has narrated the clip "Why Are We Here”, which can be viewed on One Earth's website. Freeman has donated money to the Mississippi Horse Park in Starkville, Mississippi. The park is part of Mississippi State University and Freeman has several horses that he takes there.

In 2005, Freeman criticized the celebration of Black History Month, saying, "I don't want a black history month. Black history is American history." He opined that the only way to end racism is to stop talking about it, and he noted that there is no "white history month." Freeman once said in an interview with "60 Minutes"s Mike Wallace, "I am going to stop calling you a white man and I'm going to ask you to stop calling me a black man." Freeman supported the defeated proposal to change the Mississippi state flag, which contains the Confederate battle flag. Freeman sparked controversy in 2011 when, on CNN's "Piers Morgan Tonight", he accused the Tea Party movement of racism.

In reaction to the death of Freddie Gray and the 2015 Baltimore protests, Freeman said he was "absolutely" supportive of the protesters. "That unrest [in Baltimore] has nothing to do with terrorism at all, except the terrorism we suffer from the police. [...] Because of the technology—everybody has a smartphone—now we can see what the police are doing. We can show the world, Look, this is what happened in that situation. So why are so many people dying in police custody? And why are they all black? And why are all the police killing them white? What is that? The police have always said, 'I feared for my safety.' Well, now we know. OK. You feared for your safety while a guy was running away from you, right?"

Freeman endorsed Barack Obama's candidacy for the 2008 presidential election, although he stated that he would not join Obama's campaign. He narrated for The Hall of Presidents with Obama, when he was added to the exhibit. The Hall of Presidents re-opened on July 4, 2009, at Walt Disney World Resort in Orlando, Florida. Freeman joined President Bill Clinton, USA Bid Committee Chairman Sunil Gulati, and USMNT midfielder Landon Donovan on December 1, 2010, in Zurich for the U.S. bid committee's final presentation to FIFA for the 2022 FIFA World Cup. On day four of the 2016 Democratic National Convention, Morgan Freeman provided the voiceover for the video introduction of Democratic Presidential candidate Hillary Clinton.

On September 19, 2017, Freeman featured in a video by the Committee to Investigate Russia group. In the video, Freeman declared "we are at war" with Russia. In April 2018, Freeman met with Saudi Arabia's Crown Prince Mohammad bin Salman.

Morgan Freeman has been nominated for an Academy Award "and" the Golden Globe Award five different times, each time for the same film for each award. He won the Academy Award for Best Supporting Actor on "Million Dollar Baby", and the Golden Globe for Best Actor with "Driving Miss Daisy". Likewise, he has four Screen Actors Guild Award (SAG) nominations, and one win for "Million Dollar Baby".

On October 28, 2006, Freeman was honored at the first Mississippi's Best Awards in Jackson, Mississippi, with the Lifetime Achievement Award for his works on and off the big screen. He received an honorary degree of Doctor of Arts and Letters from Delta State University during the school's commencement exercises on May 13, 2006. In 2013, Boston University presented him with an honorary degree of Doctor of Humane Letters. On November 12, 2014, he was bestowed the honor of Freedom of the City by the City of London.

In August 2017, he was named the 54th recipient of the SAG Life Achievement award for career achievement and humanitarian accomplishment.



</doc>
<doc id="20585" url="https://en.wikipedia.org/wiki?curid=20585" title="March 27">
March 27





</doc>
<doc id="20586" url="https://en.wikipedia.org/wiki?curid=20586" title="March 29">
March 29




</doc>
<doc id="20587" url="https://en.wikipedia.org/wiki?curid=20587" title="March 31">
March 31

It is the last day of the first quarter of the year.





</doc>
<doc id="20588" url="https://en.wikipedia.org/wiki?curid=20588" title="Mimas">
Mimas

Mimas may refer to:

Pronounced with a final /z/ sound, it may be:


</doc>
<doc id="20589" url="https://en.wikipedia.org/wiki?curid=20589" title="M107">
M107

The M107 is a semi automatic 50 BMG .416 Barret anti-material sniper rifle.
Its used to take down vehicles like tanks and cars, but is also used to take down buildings.





</doc>
<doc id="20590" url="https://en.wikipedia.org/wiki?curid=20590" title="Mathematical model">
Mathematical model

A mathematical model is a description of a system using mathematical concepts and language. The process of developing a mathematical model is termed mathematical modeling. Mathematical models are used in the natural sciences (such as physics, biology, earth science, chemistry) and engineering disciplines (such as computer science, electrical engineering), as well as in the social sciences (such as economics, psychology, sociology, political science).

A model may help to explain a system and to study the effects of different components, and to make predictions about behaviour.

Mathematical models can take many forms, including dynamical systems, statistical models, differential equations, or game theoretic models. These and other types of models can overlap, with a given model involving a variety of abstract structures. In general, mathematical models may include logical models. In many cases, the quality of a scientific field depends on how well the mathematical models developed on the theoretical side agree with results of repeatable experiments. Lack of agreement between theoretical mathematical models and experimental measurements often leads to important advances as better theories are developed.

In the physical sciences, a traditional mathematical model contains most of the following elements:

Mathematical models are usually composed of relationships and "variables". Relationships can be described by "operators", such as algebraic operators, functions, differential operators, etc. Variables are abstractions of system parameters of interest, that can be quantified. Several classification criteria can be used for mathematical models according to their structure:

In business and engineering, mathematical models may be used to maximize a certain output. The system under consideration will require certain inputs. The system relating inputs to outputs depends on other variables too: decision variables, state variables, exogenous variables, and random variables.

Decision variables are sometimes known as independent variables. Exogenous variables are sometimes known as parameters or constants.
The variables are not independent of each other as the state variables are dependent on the decision, input, random, and exogenous variables. Furthermore, the output variables are dependent on the state of the system (represented by the state variables).

Objectives and constraints of the system and its users can be represented as functions of the output variables or state variables. The objective functions will depend on the perspective of the model's user. Depending on the context, an objective function is also known as an "index of performance", as it is some measure of interest to the user. Although there is no limit to the number of objective functions and constraints a model can have, using or optimizing the model becomes more involved (computationally) as the number increases.

For example, economists often apply linear algebra when using input-output models. Complicated mathematical models that have many variables may be consolidated by use of vectors where one symbol represents several variables.

Mathematical modeling problems are often classified into black box or white box models, according to how much a priori information on the system is available. A black-box model is a system of which there is no a priori information available. A white-box model (also called glass box or clear box) is a system where all necessary information is available. Practically all systems are somewhere between the black-box and white-box models, so this concept is useful only as an intuitive guide for deciding which approach to take.

Usually it is preferable to use as much a priori information as possible to make the model more accurate. Therefore, the white-box models are usually considered easier, because if you have used the information correctly, then the model will behave correctly. Often the a priori information comes in forms of knowing the type of functions relating different variables. For example, if we make a model of how a medicine works in a human system, we know that usually the amount of medicine in the blood is an exponentially decaying function. But we are still left with several unknown parameters; how rapidly does the medicine amount decay, and what is the initial amount of medicine in blood? This example is therefore not a completely white-box model. These parameters have to be estimated through some means before one can use the model.

In black-box models one tries to estimate both the functional form of relations between variables and the numerical parameters in those functions. Using a priori information we could end up, for example, with a set of functions that probably could describe the system adequately. If there is no a priori information we would try to use functions as general as possible to cover all different models. An often used approach for black-box models are neural networks which usually do not make assumptions about incoming data. Alternatively the NARMAX (Nonlinear AutoRegressive Moving Average model with eXogenous inputs) algorithms which were developed as part of nonlinear system identification can be used to select the model terms, determine the model structure, and estimate the unknown parameters in the presence of correlated and nonlinear noise. The advantage of NARMAX models compared to neural networks is that NARMAX produces models that can be written down and related to the underlying process, whereas neural networks produce an approximation that is opaque.

Sometimes it is useful to incorporate subjective information into a mathematical model. This can be done based on intuition, experience, or expert opinion, or based on convenience of mathematical form. Bayesian statistics provides a theoretical framework for incorporating such subjectivity into a rigorous analysis: we specify a prior probability distribution (which can be subjective), and then update this distribution based on empirical data.

An example of when such approach would be necessary is a situation in which an experimenter bends a coin slightly and tosses it once, recording whether it comes up heads, and is then given the task of predicting the probability that the next flip comes up heads. After bending the coin, the true probability that the coin will come up heads is unknown; so the experimenter would need to make a decision (perhaps by looking at the shape of the coin) about what prior distribution to use. Incorporation of such subjective information might be important to get an accurate estimate of the probability.

In general, model complexity involves a trade-off between simplicity and accuracy of the model. Occam's razor is a principle particularly relevant to modeling, its essential idea being that among models with roughly equal predictive power, the simplest one is the most desirable. While added complexity usually improves the realism of a model, it can make the model difficult to understand and analyze, and can also pose computational problems, including numerical instability. Thomas Kuhn argues that as science progresses, explanations tend to become more complex before a paradigm shift offers radical simplification.

For example, when modeling the flight of an aircraft, we could embed each mechanical part of the aircraft into our model and would thus acquire an almost white-box model of the system. However, the computational cost of adding such a huge amount of detail would effectively inhibit the usage of such a model. Additionally, the uncertainty would increase due to an overly complex system, because each separate part induces some amount of variance into the model. It is therefore usually appropriate to make some approximations to reduce the model to a sensible size. Engineers often can accept some approximations in order to get a more robust and simple model. For example, Newton's classical mechanics is an approximated model of the real world. Still, Newton's model is quite sufficient for most ordinary-life situations, that is, as long as particle speeds are well below the speed of light, and we study macro-particles only.

Any model which is not pure white-box contains some parameters that can be used to fit the model to the system it is intended to describe. If the modeling is done by an artificial neural network or other machine learning, the optimization of parameters is called "training", while the optimization of model hyperparameters is called "tuning" and often uses cross-validation. In more conventional modeling through explicitly given mathematical functions, parameters are often determined by "curve fitting".

A crucial part of the modeling process is the evaluation of whether or not a given mathematical model describes a system accurately. This question can be difficult to answer as it involves several different types of evaluation.

Usually, the easiest part of model evaluation is checking whether a model fits experimental measurements or other empirical data. In models with parameters, a common approach to test this fit is to split the data into two disjoint subsets: training data and verification data. The training data are used to estimate the model parameters. An accurate model will closely match the verification data even though these data were not used to set the model's parameters. This practice is referred to as cross-validation in statistics.

Defining a metric to measure distances between observed and predicted data is a useful tool for assessing model fit. In statistics, decision theory, and some economic models, a loss function plays a similar role.

While it is rather straightforward to test the appropriateness of parameters, it can be more difficult to test the validity of the general mathematical form of a model. In general, more mathematical tools have been developed to test the fit of statistical models than models involving differential equations. Tools from nonparametric statistics can sometimes be used to evaluate how well the data fit a known distribution or to come up with a general model that makes only minimal assumptions about the model's mathematical form.

Assessing the scope of a model, that is, determining what situations the model is applicable to, can be less straightforward. If the model was constructed based on a set of data, one must determine for which systems or situations the known data is a "typical" set of data.

The question of whether the model describes well the properties of the system between data points is called interpolation, and the same question for events or data points outside the observed data is called extrapolation.

As an example of the typical limitations of the scope of a model, in evaluating Newtonian classical mechanics, we can note that Newton made his measurements without advanced equipment, so he could not measure properties of particles travelling at speeds close to the speed of light. Likewise, he did not measure the movements of molecules and other small particles, but macro particles only. It is then not surprising that his model does not extrapolate well into these domains, even though his model is quite sufficient for ordinary life physics.

Many types of modeling implicitly involve claims about causality. This is usually (but not always) true of models involving differential equations. As the purpose of modeling is to increase our understanding of the world, the validity of a model rests not only on its fit to empirical observations, but also on its ability to extrapolate to situations or data beyond those originally described in the model. One can think of this as the differentiation between qualitative and quantitative predictions. One can also argue that a model is worthless unless it provides some insight which goes beyond what is already known from direct investigation of the phenomenon being studied.

An example of such criticism is the argument that the mathematical models of optimal foraging theory do not offer insight that goes beyond the common-sense conclusions of evolution and other basic principles of ecology.

Mathematical models are of great importance in the natural sciences, particularly in physics. Physical theories are almost invariably expressed using mathematical models.

Throughout history, more and more accurate mathematical models have been developed. Newton's laws accurately describe many everyday phenomena, but at certain limits theory of relativity and quantum mechanics must be used. 

It is common to use idealized models in physics to simplify things. Massless ropes, point particles, ideal gases and the particle in a box are among the many simplified models used in physics. The laws of physics are represented with simple equations such as Newton's laws, Maxwell's equations and the Schrödinger equation. These laws are a basis for making mathematical models of real situations. Many real situations are very complex and thus modeled approximate on a computer, a model that is computationally feasible to compute is made from the basic laws or from approximate models made from the basic laws. For example, molecules can be modeled by molecular orbital models that are approximate solutions to the Schrödinger equation. In engineering, physics models are often made by mathematical methods such as finite element analysis.

Different mathematical models use different geometries that are not necessarily accurate descriptions of the geometry of the universe. Euclidean geometry is much used in classical physics, while special relativity and general relativity are examples of theories that use geometries which are not Euclidean.

Since prehistorical times simple models such as maps and diagrams have been used.

Often when engineers analyze a system to be controlled or optimized, they use a mathematical model. In analysis, engineers can build a descriptive model of the system as a hypothesis of how the system could work, or try to estimate how an unforeseeable event could affect the system. Similarly, in control of a system, engineers can try out different control approaches in simulations.

A mathematical model usually describes a system by a set of variables and a set of equations that establish relationships between the variables. Variables may be of many types; real or integer numbers, boolean values or strings, for example. The variables represent some properties of the system, for example, measured system outputs often in the form of signals, timing data, counters, and event occurrence (yes/no). The actual model is the set of functions that describe the relations between the different variables.

"M" = ("Q", Σ, δ, "q", "F") where

The state "S" represents that there has been an even number of 0s in the input so far, while "S" signifies an odd number. A 1 in the input does not change the state of the automaton. When the input ends, the state will show whether the input contained an even number of 0s or not. If the input did contain an even number of 0s, "M" will finish in state "S", an accepting state, so the input string will be accepted.

The language recognized by "M" is the regular language given by the regular expression 1*( 0 (1*) 0 (1*) )*, where "*" is the Kleene star, e.g., 1* denotes any non-negative number (possibly zero) of symbols "1".


that can be written also as:









</doc>
<doc id="20591" url="https://en.wikipedia.org/wiki?curid=20591" title="Fujiwara no Mototsune">
Fujiwara no Mototsune

, also known as , was a Japanese statesman, courtier and politician of the early Heian period.

He was born the third son of Fujiwara no Nagara, but was adopted by his powerful uncle Fujiwara no Yoshifusa, who had no sons. Mototsune followed in Yoshifusa's footsteps, holding power in the court in the position of regent for four successive emperors.

Mototsune invented the position of "kampaku" regent for himself in order to remain in power even after an emperor reached maturity. This innovation allowed the Fujiwara clan to tighten its grip on power right throughout an emperor's reign.

Mototsune is referred to as "Shōsen Kō" (昭宣公) (posthumous name as Daijō Daijin).


This member of the Fujiwara clan was the son of Fujiwara no Nagara, who was one of the brothers of Fujiwara no Yoshifusa. Mototsune was adopted as son and heir of Yoshifusa. In other words, Yoshifusa was Mototsune's uncle, and father through adoption.

He was married to a daughter of Imperial Prince Saneyasu (son of Emperor Ninmyō).

Their children were

He was also married to Princess "Sōshi" (操子女王), a daughter of Imperial Prince Tadara (son of Emperor Saga).

Their children were

His other children were




</doc>
<doc id="20592" url="https://en.wikipedia.org/wiki?curid=20592" title="Fujiwara no Michinaga">
Fujiwara no Michinaga

Michinaga was born in Kyōto, the son of Kaneiye. Kaneiye had become Regent in 986, holding the position until the end of his life in 990. Due to the hereditary principle of the Fujiwara Regents, Michinaga was now in line to become Regent after his brothers, Michitaka and Michikane.

Michitaka was regent from 990 until 995, when he died. Michikane then succeeded him, famously ruling as Regent for only seven days, before he too died of disease. With his two elder brothers dead, Michinaga then struggled with Fujiwara no Korechika, Michitaka's eldest son and the successor he had named. Korechika was more popular at court than Michinaga, being a favourite of Empress Teishi and well-liked by the reigning Emperor Ichijō, and held multiple prestigious positions - he had been made Naidaijin the previous year, and Sangi three years before that. However, the mother of Ichijo, Fujiwara no Senshi, disliked Korechika and aided Michinaga; for example, she coerced Ichijo into granting Michinaga the title of Nairan (内覧) in the fifth month of 995. Furthermore, Korechika's position was ruined by a scandal that took place the following year, likely arranged by Michinaga.<br>
Korechika had been seeing a mistress in one of the Fujiwara palaces. However, he was told that the retired Emperor Kazan had been visiting the same house during the night - Korechika presumed that Kazan had been seeing the same mistress. Consequently, he and his brother Takaiye ambushed the Emperor, shooting at him. An arrow struck Kazan's sleeve, a grave crime - it was considered appalling to harm a monk (for Kazan had entered religion in 986), let alone an Emperor. Michinaga and his supporters then pressed charges of lèse-majesté. Though the jurists examining the case found the servants of Kaneiye and Takaiye at fault, further charges were manufactured by Michinaga's faction: Korechika was accused of putting a curse on Senshi, for example. Their punishments were a form of cordial banishments, with Korechika made Vice-Governor of Kyushu. With Korechika removed from the capital, Michinaga had won their struggle for supremacy.
During their struggle, Michinaga had gained the position of Minister of the Right, or Udaijin (右大臣), on the 19th day of the 6th month of 995. Later in 996 Michinaga became Minister of the Left, Sadaijin (左大臣), the most senior position in government apart from that of Chancellor (Daijō-daijin).

During his lifetime, Michinaga was called the Mido Kampaku, a title referencing the name of his residence, Mido, and the fact that he was Regent in all but name.<br>
The primary method through which the Fujiwara regents maintained their power was through controlling the sovereign, usually through matrimonial links. Michinaga was particularly successful in this regard, with four of his daughters marrying an emperor. Although Ichijo already had an Empress, Teishi, Michinaga made her "Kogo" empress and had his first daughter, Shoshi, also marry him as "Chūgū" empress. This was the first time that an emperor had two empresses consort simultaneously. "Chūgū" was the more senior of the two ranks, at least unofficially. When Teishi died in childbirth in 1001, Michinaga's influence over Ichijo was absolute.<br>
Kenshi, Michinaga's second daughter, married the future Emperor Sanjō. Ichijo and Shoshi had two sons, both future emperors, and it was to these that Michinaga's third and fourth daughters were married: Ichijo's eldest son, Go-Ichijō, married the third daughter, Ishi; and Ichijo's second son, Go-Suzaku, married the fourth daughter, Kishi. <br>

Michinaga further cemented his power by making alliances with the powerful warrior clans, particularly the Minamoto (or more specifically the Seiwa Genji), as demonstrated by the fact that both of his wives were Minamoto. Minamoto no Yorimitsu and Minamoto no Yorinobu were his two principal commanders: they were loyal and effective to the extent that their enemies called them the Fujiwara's 'running dogs'. The support of these powerful warriors meant that Michinaga could threaten his enemies with violence, something that they were unable to respond to - even the imperial clan would've been unsafe if Michinaga wished to attack them, given the ornamental nature of their Guard.

It is clear that Michinaga controlled or influenced all important imperial figures of his time. It was for this reason that Michinaga never formally took the title of Kampaku - he already possessed the power that the title carried.
The supremacy of Michinaga during his lifetime is demonstrated by the fact that in 1011 he was granted the exceptional privilege of travelling to and from the court by ox-drawn cart. In the same year, Ichijo's second son, Atsunari, was proclaimed Crown Prince. Sanjō's eldest son, Atsuakira, had been the previous heir, but Michinaga leveraged his powerful position to make the Crown Prince resign. In order to prevent Atsuakira from being an enemy to him, Michinaga married his fifth daughter, Kanshi, to him.

During Sanjō's reign as Emperor, he and Michinaga often came into conflict. Resultantly, Michinaga attempted to pressure Sanjō into retirement. In 1016 he was finally successful. The youth of Go-Ichijō meant that Michinaga ruled as Sesshō, the Regency assumed when the emperor is yet to come of age. He briefly became Chancellor in the final month of 1017, before resigning in the second month of the following year. A month after his resignation, he also resigned from the position of Sesshō in favour of Yorimichi, his eldest son. In 1019 he took the tonsure, becoming a monk at the Hōjō-ji, which he had built. He took the Dharma name Gyōkan (行観), which was later changed to Gyōkaku (行覚).

On January 3rd 1028, Michinaga died at the age of sixty-two. He is said to have called out to Amida on his deathbed, asking for entry to Paradise. He left a diary, the Midō Kanpakuki; it is an important source of information about the Heian court at the height of Fujiwara power, though somewhat overshadowed by Murasaki's Tale of Genji and Sei's Pillow Book. In the Tale of Genji, the eponymous Genji is believed to be in part based on Michinaga, as well as Korechika.

Michinaga was reputed to be a skilled horseman and archer, and was perceived as courageous. His friends praised his poetry and he was reputed to have strong self-control. He clearly had a remarkable understanding of people and the human heart, given the success of his machinations - the Fujiwara were strongest under his control, despite a broader trend of the power of the sovereigns weakening and that of the provincial warrior clans growing.<br>
He had a taste for opulence and luxury, holding extravagant parties and entertainments, though it was nonetheless governed by the tasteful modesty that characterises the Heian period. His extravagance had a purpose, however - it openly demonstrated the wealth and power of the Fujiwara clan, impressing allies and intimidating rivals.<br>
Michinaga may have been pious, given his vast expenditure on shrines and temples, though this may have been another manifestation of the aforementioned excess. On the other hand, he was known to sternly rebuke courtiers who neglected Shinto ceremonies. He was a devoted follower of the Lotus Sutra; his copy had the words embellished in gold. When Amidist Pure Land Buddhism began to grow and develop during his rule, Michinaga supported and adopted its teachings.<br>
Michinaga was very proud of his achievements, as demonstrated by his poem, "Mochizuki no Uta" (望月の歌) (Full Moon Poem), which he composed in 1018 at a party to celebrate Ishi becoming Chūgū to Go-Ichijō: ""This world, I think/ Is indeed my world./ Like the full moon I shine,/ Uncovered by any cloud""

He was married to Minamoto no Rinshi, otherwise known as Michiko (源倫子), daughter of Sadaijin Minamoto no Masanobu. They had six children.

He was also married to Minamoto no Meishi (源明子), daughter of Sadaijin Minamoto no Takaakira. They had six children.

Michinaga had one daughter from an unknown woman.




</doc>
<doc id="20593" url="https://en.wikipedia.org/wiki?curid=20593" title="Lesser Poland Voivodeship">
Lesser Poland Voivodeship

Lesser Poland Voivodeship or Lesser Poland Province (in ; ), also known as "Małopolska Voivodeship" or "Małopolska Province", is a voivodeship (province), in southern Poland. It has an area of , and a population of 3,267,731 (2006).

It was created on 1 January 1999 out of the former Kraków, Tarnów, Nowy Sącz and parts of Bielsko-Biała, Katowice, Kielce and Krosno Voivodeships, pursuant to the Polish local government reforms adopted in 1998. The province's name recalls the traditional name of a historic Polish region, Lesser Poland, or in Polish: Małopolska. Current Lesser Poland Voivodeship, however, covers only a small part of the broader ancient Małopolska region which, together with Greater Poland ("Wielkopolska") and Silesia ("Śląsk"), formed the early medieval Polish state. Historic Lesser Poland is much larger than the current province. It stretches far north, to Radom, and Siedlce, also including such cities, as Stalowa Wola, Lublin, Kielce, Częstochowa, and Sosnowiec.

The province is bounded on the north by the Świętokrzyskie Mountains ("Góry Świętokrzyskie"), on the west by "Jura Krakowsko-Częstochowska" (a broad range of hills stretching from Kraków to Częstochowa), and on the south by the Tatra,
Pieniny and Beskidy Mountains. Politically it is bordered by Silesian Voivodeship to the west, Świętokrzyskie Voivodeship to the north, Subcarpathian Voivodeship to the east, and Slovakia (Prešov Region and Žilina Regions) to the south.

Almost all of Lesser Poland lies in the Vistula River catchment area. The city of Kraków was one of the European Cities of Culture in 2000. Kraków has railway and road connections with Katowice (expressway), Warsaw, Wrocław and Rzeszów. It lies at the crossroads of major international routes linking Dresden with Kiev, and Gdańsk with Budapest. Located here is the second largest international airport in Poland (after Warsaw's), the John Paul II International Airport.

The region's economy includes high technology, banking, chemical and metallurgical industries, coal, ore, food processing, and spirit and tobacco industries. The most industrialized city of the voivodeship is Kraków. The largest regional enterprise operates here, the Tadeusz Sendzimir Steelworks in Nowa Huta, employing 17,500 people. Another major industrial center is located in the west, in the neighborhood of Chrzanów (chiefly the production of railway engines) and Oświęcim (chemical works). Kraków Park Technologiczny, a Special Economic Zone, has been established within the voivodeship. There are almost 210,000 registered economic entities operating in the voivodeship, mostly small and medium-sized, of which 234 belong to the state-owned sector. Foreign investment, growing in the region, reached approximately US$18.3 billion by the end of 2006.

130,000 students attend fifteen Kraków institutions of higher learning. The Jagiellonian University, the largest university in the city (44,200 students), was founded in 1364 as Cracow Academy. Nicolaus Copernicus and Karol Wojtyła (Pope John Paul II) graduated from it. The AGH University of Science and Technology (29,800 students) is considered to be the best technical university in Poland. The Academy of Economics, the Pedagogical University, the Kraków University of Technology and the Agricultural Academy are also very highly regarded. There are also the Fine Arts Academy, the State Theatre University and the Musical Academy. Nowy Sącz has become a major educational center in the region thanks to its Higher School of Business and Administration, with an American curriculum, founded in 1992. The school has 4,500 students. There are also two private higher schools in Tarnów.

Located in Southern Poland, Lesser Poland is the warmest place in Poland with average summer temperatures between and during the day, often reaching to in July and August, the two warmest months of the year. The city of Tarnów, which is located in Lesser Poland, is the hottest place in Poland all year round, average temperatures being around during the day in the three summer months and during the day in the three winter months. In the winter the weather patterns alter each year; usually winters are mildly cold with temperatures ranging from to , but the winter season changes often to a more humid and warmer winter, or more continental and cold, depending on the many various wind patterns that affect Poland from different regions of the world. Błędów Desert, the only desert in Poland, is located in Lesser Poland, where temperatures can often reach in the summer.

Four national parks and numerous reserves have been established in the voivodeship to protect the environment of Lesser Poland. The region has areas for tourism and recreation, including Zakopane (Poland's most popular winter resort) and the Tatra, Pieniny and Beskidy Mountains. The natural landscape features many historic sites. The salt mine at Wieliczka, the pilgrimage town of Kalwaria Zebrzydowska, and Kraków's Old Town are ranked by UNESCO among the most precious sites of world heritage. At Wadowice, birthplace of John Paul II (50 kilometers southwest of Kraków) is a museum dedicated to the late Pope's childhood. The area of Oświęcim, with the former Nazi concentration camps Auschwitz-I and Auschwitz-II-Birkenau, is visited annually by a million people. Another tourist destination is the town of Bochnia with its salt mine, Europe's oldest.

The voivodeship contains 61 cities and towns. These are listed below in descending order of population (according to official figures for 2006 ):
Smaller Poland Voivodeship is divided into 22 counties (powiats): 3 city counties and 19 land counties. These are further divided into 182 gminas.

The counties are listed in the following table (ordering within categories is by decreasing population).

Protected areas in Lesser Poland Voivodeship include six National Parks and 11 Landscape Parks. These are listed below.

Smaller Poland Voivodeship's symbols can be blazoned as follows:

Coat of arms: 
"A traditional Iberian shield gules, an eagle argent displayed armed, legged, beaked, langued and crowned Or."

Flag:
"Per fess argent and gules, a narrow fess Or."





</doc>
<doc id="20595" url="https://en.wikipedia.org/wiki?curid=20595" title="Man'yōshū">
Man'yōshū

The is the oldest extant collection of Japanese "waka" (poetry in Classical Japanese), compiled sometime after AD 759 during the Nara period. The anthology is one of the most revered of Japan's poetic compilations. The compiler, or the last in a series of compilers, is today widely believed to be Ōtomo no Yakamochi, although numerous other theories have been proposed. The chronologically last datable poem in the collection is from AD 759 ( 4516). It contains many poems from much earlier, many of them anonymous or misattributed (usually to well-known poets), but the bulk of the collection represents the period between AD 600 and 759. The precise significance of the title is not known with certainty.

The collection is divided into twenty parts or books; this number was followed in most later collections. The collection contains 265 "chōka" (long poems), 4,207 "tanka" (short poems), one "tan-renga" (short connecting poem), one "bussokusekika" (a poem in the form 5-7-5-7-7-7; named for the poems inscribed on the Buddha's footprints at Yakushi-ji in Nara), four "kanshi" (Chinese poems), and 22 Chinese prose passages. Unlike later collections, such as the "Kokin Wakashū", there is no preface.

The "Man'yōshū" is widely regarded as being a particularly unique Japanese work. This does not mean that the poems and passages of the collection differed starkly from the scholarly standard (in Yakamochi's time) of Chinese literature and poetics. Certainly many entries of the "Man'yōshū" have a continental tone, earlier poems having Confucian or Taoist themes and later poems reflecting on Buddhist teachings. Yet, the "Man'yōshū" is singular, even in comparison with later works, in choosing primarily Ancient Japanese themes, extolling "Shintō" virtues of and virility "(masuraoburi)". In addition, the language of many entries of the "Man'yōshū" exerts a powerful sentimental appeal to readers:
<nowiki>[T]his</nowiki> early collection has something of the freshness of dawn. <nowiki>[...]</nowiki> There are irregularities not tolerated later, such as hypometric lines; there are evocative place names and "makurakotoba"; and there are evocative exclamations such as "kamo", whose appeal is genuine even if incommunicable. In other words, the collection contains the appeal of an art at its pristine source with a romantic sense of venerable age and therefore of an ideal order since lost.

The literal translation of the kanji that make up the title "Man'yōshū" (万 — 葉 — 集) is "ten thousand — leaves — collection".

The principal interpretations, according to the twentieth-century scholar , are (i) a book that collects a great many poems, (ii) a book for all generations, and (iii) a poetry collection that uses a large volume of paper.

Of these, supporters of (i) can be further divided into (a) those who interpret the middle character as "words" ("koto no ha", lit. "leaves of speech"), thus giving "ten thousand words", i.e. "many "waka"", including Sengaku, , Kada no Azumamaro and Kamo no Mabuchi, and (b) those who interpret the middle character as literally referring to leaves of a tree, but as a metaphor for poems, including Ueda Akinari, , Masayuki Okada (岡田正之), , and Susumu Nakanishi.

Furthermore, (ii) can be divided into: (a) it was meant to express the intention that the work should last for all time (proposed by Keichū, and supported by , , Yoshio Yamada, and ); (b) it was meant to wish for long life for the emperor and empress (Shinobu Origuchi); and (c) it was meant to indicate that the collection included poems from all ages (proposed by Yamada).

(iii) was proposed by Yūkichi Takeda in his "Man'yōshū Shinkai jō" (萬葉集新解上), but Takeda also accepted (ii); his theory that the title refers to the large volume of paper used in the collection has also not gained much traction among other scholars.

The collection is customarily divided into four periods. The earliest dates to prehistoric or legendary pasts, from the time of Emperor Yūryaku (  – ) to those of the little documented Emperor Yōmei (r. 585–587), Saimei (r. 594–661), and finally Tenji (r. 668–671) during the Taika Reforms and the time of Fujiwara no Kamatari (614–669). The second period covers the end of the seventh century, coinciding with the popularity of Kakinomoto no Hitomaro, one of Japan's greatest poets. The third period spans 700 – and covers the works of such poets as Yamabe no Akahito, Ōtomo no Tabito and Yamanoue no Okura. The fourth period spans 730–760 and includes the work of the last great poet of this collection, the compiler Ōtomo no Yakamochi himself, who not only wrote many original poems but also edited, updated and refashioned an unknown number of ancient poems.

The vast majority of the poems of the "Man'yōshū" were composed over a period of roughly a century, with scholars assigning the major poets of the collection to one or another of the four "periods" discussed above. Princess Nukata's poetry is included in that of the first period (645–672), while the second period (673–701) is represented by the poetry of Kakinomoto no Hitomaro, generally regarded as the greatest of "Man'yōshū" poets and one of the most important poets in Japanese history. The third period (702–729) includes the poems of Takechi no Kurohito, whom Donald Keene called "[t]he only new poet of importance" of the early part of this period, when Fujiwara no Fuhito promoted the composition of "kanshi" (poetry in classical Chinese). Other "third period" poets include: Yamabe no Akahito, a poet who was once paired with Hitomaro but whose reputation has suffered in modern times; Takahashi no Mushimaro, one of the last great "chōka" poets, who recorded a number of Japanese legends such as that of Ura no Shimako; and Kasa no Kanamura, a high-ranking courtier who also composed "chōka" but not as well as Hitomaro or Mushimaro. But the most prominent and important poets of the third period were Ōtomo no Tabito, Yakamochi's father and the head of a poetic circle in the Dazaifu, and Tabito's friend Yamanoue no Okura, possibly an immigrant from the Korean kingdom of Paekche, whose poetry is highly idiosyncratic in both its language and subject matter and has been highly praised in modern times. Yakamochi himself was a poet of the fourth period (730–759), and according to Keene he "dominated" this period. He composed the last dated poem of the anthology in 759.

In addition to its artistic merits the "Man'yōshū" is important for using one of the earliest Japanese writing systems, the cumbersome "man'yōgana". Though it was not the first use of this writing system, which was also used in the earlier "Kojiki" (712), it was influential enough to give the writing system its name: "the kana of the "Man'yōshū"". This system uses Chinese characters in a variety of functions: their usual logographic sense; to represent Japanese syllables phonetically; and sometimes in a combination of these functions. The use of Chinese characters to represent Japanese syllables was in fact the genesis of the modern syllabic kana writing systems, being simplified forms ("hiragana") or fragments ("katakana") of the "man'yōgana".

The collection, particularly volumes 14 and 20, is also highly valued by historical linguists for the information it provides on early Old Japanese dialects.

Julius Klaproth produced some early, severely flawed translations of "Man'yōshū" poetry. Donald Keene explained in a preface to the Nihon Gakujutsu Shinkō Kai edition of the "Man'yōshū:"
In 1940, Columbia University Press published a translation created by a committee of Japanese scholars and revised by the English poet, Ralph Hodgson. This translation was accepted in the Japanese Translation Series of the United Nations Educational, Scientific and Cultural Organization (UNESCO).

In premodern Japan, officials used wooden slips or tablets of various sizes, known as "mokkan", for recording memoranda, simple correspondence, and official dispatches. Three "mokkan" that have been excavated contain text from the "Man'yōshū". A "mokkan" excavated from an archaeological site in Kizugawa, Kyoto, contains the first 11 characters of poem 2205 in volume 10, written in Man'yōgana. It is dated between 750 and 780, and its size is . Inspection with an infrared camera revealed other characters, suggesting that the "mokkan" was used for writing practice. Another "mokkan", excavated in 1997 from the Miyamachi archaeological site in Kōka, Shiga, contains poem 3807 in volume 16. It is dated to the middle of the 8th century, and is 2 cm wide by 1 mm thick. Lastly, a "mokkan" excavated at the Ishigami archaeological site in Asuka, Nara, contains the first 14 characters of poem 1391, in volume 7, written in "Man'yōgana". Its size is , and it is dated to the late 7th century, making it the oldest of the three.

More than 150 species of grasses and trees are mentioned in approximately 1,500 entries of the "Man'yōshū". A is a botanical garden that attempts to contain every species and variety of plant mentioned in the anthology. There are dozens of these gardens around Japan. The first "Man'yō shokubutsu-en" opened in Kasuga Shrine in 1932.






</doc>
<doc id="20596" url="https://en.wikipedia.org/wiki?curid=20596" title="Mieszko II Lambert">
Mieszko II Lambert

Mieszko II Lambert (; c. 990 – 10/11 May 1034) was King of Poland from 1025–1031, and Duke from 1032 until his death.

He was the second son of Bolesław I the Brave but the eldest born from his third wife Emnilda of Lusatia. He was probably named after his paternal grandfather, Mieszko I. His second name, Lambert, sometimes erroneously considered to be a nickname, was given to him as a reference to Saint Lambert. Also, it is probable that this name Lambert was chosen after Bolesław's half-brother Lambert. It is thought that the choice of this name for his son was an expression of warming relations between Bolesław I and his stepmother Oda.

He organized two devastating invasions to Saxony in 1028 and 1030. Then Mieszko II ran a defensive war against Germany, Bohemia and the Kievan princes. Mieszko II was forced to escape from the country in 1031 after an attack of Yaroslav I the Wise, who installed Mieszko's older half-brother Bezprym onto the Polish throne. Mieszko took refuge in Bohemia, where he was imprisoned by the Duke Oldrich. In 1032 he regained power in one of the three districts, then united the country, making good use of the remaining power structures. At this time, several Polish territorial acquisitions of his father were lost: Upper Lusatia (also known as "Milsko"), part of Lower Lusatia, Red Ruthenia, western and central part of Upper Hungary (now Slovakia) and probably Moravia.

Mieszko II was very well educated for the period. He was able to read and write, and knew both Greek and Latin. He is unjustly known as Mieszko II "Gnuśny" (the "Lazy," "Stagnant" or "Slothful"). He received that epithet due to the unfortunate way his reign ended; but at the beginning he acted as a skillful and talented ruler.

Since Mieszko II was politically active before his father's death, Bolesław I appointed him as his successor. He participated mainly in German politics, both as a representative of his father and the commander of the Polish troops.

In 1013 Mieszko II went to Magdeburg, where he paid homage to the Emperor Henry II. A few months later Bolesław I paid homage in person. The real purpose of Mieszko's visit is unclear, especially since soon after his father paid homage to the Holy Roman Empire. Presumably, the young prince paid homage for Milsko or Moravia and Lusatia. The relevant treaty stipulated that it was only a personal tribute, not entailing any legal obligations. Another hypothesis assumes that the territories were transferred by Bolesław to him, and as a result made Mieszko a vassal of the Empire.

The position of the young prince, at the both Polish and Imperial courts, became stronger in 1013 when he married Richeza daughter of Count Palatine Ezzo of Lotharingia and niece of Emperor Otto III. Ezzo was a prince of a considerable influence as a great leader of the opposition against Henry II. Through the marriage with his daughter Mieszko, he entered into the circle of the Imperial family and became a person equal to, if not higher than the Emperor himself. Probably after the wedding, and in accordance with prevailing custom, Bolesław I the Brave gave a separate district to Mieszko II to rule: Kraków. One of his towns, Wawel (now part of the city), was chosen by the prince as his residence.

In the year 1014 Mieszko II was sent by his father to Bohemia as an emissary. He had to persuade Duke Oldřich to make an alliance against the Emperor Henry II. The mission failed as Oldřich imprisoned Mieszko. He was released only after the intervention of the Emperor, who, despite the planned betrayal of Bolesław I, loyally acted on behalf of his vassal. As a result, Mieszko was sent to the Imperial court in Merseburg as a hostage. Henry II probably wanted to force the presence of Bolesław I in Merseburg and make him explain his actions. The plan failed however, because, under pressure from his relatives, the Emperor soon agreed to release Mieszko.

A year later, Mieszko II stood at the head of Polish troops in the next war against the Emperor. The campaign wasn't favorable to Henry. His army needed over a month to reach the line of the Oder River, and once there, his troops encountered strong resistance led by Mieszko and his father. Henry II sent a delegation to the Polish rulers, in an effort to induce them to conclude a peace settlement. Mieszko II refused, and after the Emperor's failure to defeat his troops in battle, Henry decided to begin retreating to Dziadoszyce. The Polish prince went on pursuit, and inflicted heavy losses on the German army. When the Polish army advanced to Meissen, Mieszko II unsuccessfully tried to besiege the castle of his brother-in-law, Margrave Herman I (husband of his sister Regelinda). The fighting stopped in autumn and was resumed only in 1017 after the failure of peace talks. Imperial forces bypassed the main defensive site near Krosno Odrzańskie and besieged Niemcza. At the same time, at the head of ten legions, Mieszko went to Moravia and planned an allied attack together with Bohemia against the Emperor. This action forced the Emperor to give up on a plan of any frontal attack. A year later, the Peace of Bautzen (30 January 1018) was concluded, with terms extremely favorable to the Polish side.

Beginning in 1028, he successfully waged war against the Holy Roman Empire. He was able to repel its invading army, and later even invaded Saxony. He allied Poland with Hungary, resulting in a temporary Hungarian occupation of Vienna. This war was probably prompted by family connections of Mieszko's in Germany who opposed Emperor Conrad II. 

Due to the death of Thietmar of Merseburg, the principal chronicler of that period, there is little information about Mieszko II's life from 1018 until 1025, when he finally took over the government of Poland. Only Gallus Anonymus mentions the then Prince on occasion of the description of his father's trip to Rus in 1018: ""due to the fact that his son (...) Mieszko wasn't considered yet capable of taking the government by himself, he established a regent among his family during his trip to Rus"". This statement was probably the result of the complete ignorance of the chronicler, since 1018 Mieszko II was 28 years old and was already fully able to exercise the power by himself.

King Bolesław died on 17 June 1025. Six months later, on Christmas Day, Mieszko II Lambert was crowned King of Poland by the Archbishop of Gniezno, Hipolit, in the Gniezno Cathedral. Contemporary German chroniclers considered this to be an abuse of power on the part of the Archbishop, which was made necessary by the existing political situation. After his father's death, Mieszko inherited a vast territory, which in addition to Greater Poland, Lesser Poland, Silesia and Gdansk Pomerania also included Western Pomerania, as well as Lusatia, Red Ruthenia and territory of present-day Slovakia. Whether Moravia was still under his reign or was lost earlier is disputed. Once his solo reign had begun, as an important Central European ruler, he was now very important to the Holy Roman Empire.

Later developments during his reign had their source in dynastic and familial issues. His older half-brother Bezprym was the son of the Hungarian princess Judith, Bolesław's second wife. Mieszko also had a younger full-brother, Otto. According to Slavonic custom, a father was expected to divide his legacy among all his sons. However, since Bolesław I did not wish to break up the kingdom, Mieszko's brothers received nothing from their father's legacy. 

As Bezprym was the oldest son, there were some who felt that he should have succeeded his father as king. Bezprym had, however, always been disliked by his father, as indicated by his name (the Piasts tended to give names such as "Bolesław", "Mieszko" and later "Kazimierz", "Władysław" and emperors' names, such as "Otto", "Konrad" (Conrad), and "Henryk" (Heinrich). "Bezprym" was rather a commoner's name, which implied that Bolesław did not wish Bezprym to succeed him). For that reason, Bezprym was sent to a monastery.

According to some chroniclers, Mieszko II expelled his two brothers from the country. Otto took refuge in Germany and Bezprym escaped to the Kievan Rus.

In 1026 the German King Conrad II, went to Italy for his Imperial coronation. His absence increased the activity of the opposition centered around the Dukes Ernest II of Swabia and Frederick II of Upper Lorraine. Conrad II's opponents conspired to acquire the favor of the King of Poland. Historical evidence of these efforts is in the Prayer Book sent to Mieszko II by the Duchess Matilda of Swabia around 1027. The volume is entitled: '. In it, a miniature showed the Duchess presenting the Book to Mieszko II while sitting on a throne. The gift was accompanied by a letter, wherein Matilda named him a distinguished King and a father of the model for the spread of Christianity. Also written was praise of the merits of Mieszko II in the building of new churches, as well his knowledge of Latin, very unusual in those times when Greek was more widely used. In this book were found the earliest records of the Kingdom of Poland: neume at the margins of the sequence "Ad célèbres rex celica". The gift caused the expected effect, and Mieszko II promised to take military action. The preparations for the war began in the autumn of 1027. In the middle of that year, Conrad II returned to the Germany and began to fight the rebels. Soon he defeated Duke Ernest II, depriving him of his lands. Only when the rebel fight was nearly lost did Mieszko II arrive to their aid. In 1028 Polish troops invaded Saxony and took a number of prisoners. The devastation was so great that, according to Saxon sources "where Mieszko II's troops put their feet grass never thence grew". The Emperor accused the Polish ruler of an illegal coronation as King and declared him a usurper. This invasion involved the lands of the Lutici tribe. In October 1028, the Emperor's opportunity came as the Lutici district of Pöhlde asked the Emperor to defend against the attacks of Mieszko II, promising support in the fight against the Polish ruler.

Despite the treaty which secured peace between Poland and Germany, the Emperor soon armed a retaliatory expedition against Mieszko II. Conrad II's army arrived to Lusatia in the autumn of 1029 and began the siege of Bautzen; but the German troops did not receive the promised support of the Lutici tribe and the expedition failed. Threatened by the Hungarians, the Emperor was forced to retreat.

Probably in this same year the son of Oldřich, Bretislaus I, attacked and took Moravia. 

In 1030 Mieszko II secured an alliance with Hungary and once again invaded Saxony. In the meanwhile, his southern ally attacked Bavaria and temporarily occupied Vienna.

In response, the Emperor organized another expedition against the Polish King, this time by organizing a coalition against Mieszko II. Already in 1030 Yaroslav I the Wise began the offensive and conquered Red Ruthenia and some Bełz castles.

The Emperor in 1031 concluded a peace with the Kingdom of Hungary. Probably in exchange for his support, Conrad II give to the King Stephen I the territories between the Leitha and Fischa Rivers, ceding them to Hungary. Now that the Emperor was less concerned about an attack from the south, in the autumn of 1031 he went on the offensive against Poland and besieged Milsko. The offensive ended with a complete success, and Mieszko II was forced to surrender some lands. As a result, the Polish King lost portions of the lands taken by his father, who warred often against the Emperor Henry II.

Historians estimate that the reason for the rapid capitulation of Mieszko II was the bad internal situation in the country. Bolesław left to his son an unstable Kingdom, who had to defend his autonomy and position amongst neighboring rulers. Also, the cost of Mieszko II's extensive war against Emperor Conrad II caused his popularity to decline among his subjects, despite the fact that on the invasion of Saxony the King only defended their territory. Furthermore, the final loss of the war against the Holy Roman Empire weakened the position of the King, who had to face several rebellions among the opposition, who claimed that the previous war didn't produce the expected benefits. An additional problem was a dynastic crisis: Mieszko II's brothers continued their attempts to regain power with the help of foreign forces.

Probably the brother who caused the first problems to Mieszko II was Bezprym, who allegedly with the support of Otto won the alliance of Kiev in order to take power. When Mieszko II was busy defending Lusatia from the troops of Conrad II, the Kievan expedition started from the east with Yaroslav I the Wise as the leader. In 1031 Poland was invaded and then Bezprym was settled on the throne. Mieszko II and his family were forced to flee the country. Queen Richeza and her children found refuge in Germany. The King couldn't escape to Hungary because during his travel he was stopped by Rus' troops. King Stephen I of Hungary wasn't favorable to accepting him in his country. Without alternatives, Mieszko II went to Bohemia. Duke Oldřich once again imprisoned him. This time the King wasn't counting with the Imperial support. Mieszko II was not only imprisoned but also castrated, which was to be a punishment to Bolesław I the Brave, who blinded Duke Boleslaus III the Red (Oldřich's brother) thirty years before. Mieszko II and his wife never reunited again; according to some sources they were either officially divorced or only separated.

The new Duke Bezprym probably made bloody persecutions against the followers of Mieszko II. At the time the power was exercised to the mutiny and the people known as the "Pagan Reaction". Have degraded the structure of power, the Duke's authority collapsed, and he was forced to send the Royal crown and regalia to the Emperor. After only one year of reign, Bezprym was murdered (1032), probably thanks to the instigations of his brothers. 

After the death of Bezprym, the Polish throne remained vacant. Mieszko II was still imprisoned in Bohemia and Otto probably in Germany. German sources report that the Emperor has organized an expedition in order to invade Poland. It is unknown what happened after this, but certainly Mieszko II was released by Duke Oldřich and he could return to the country. After his recent opponent could regain the power, the Emperor immediately reacted and began the preparations for the expedition against Poland. Mieszko II wasn't prepared for the confrontation, so he used his influence in the German court in order to resolve the conflict. 

On 7 July 1032, in Merseburg a meeting took place between Conrad II and the surviving heirs of the Piast dynasty. Without alternatives, Mieszko II was forced to surrender the Royal crown and agreed to the division of Poland between him and the other two competitors: his brother Otto and certain Dytryk () —cousin, grandson of Duke Mieszko I and his third wife Oda—. 

Mieszko II probably received Lesser Poland and Masovia, Otto obtained Silesia, and Dytryk took Greater Poland. Another proposal involves that Mieszko II received Greater Poland, and other neighborhoods were given to Otto and Dytryk. 

Although the distribution was uncertain, this division was short-lived: in 1033 Otto was killed by one of his own men, and Mieszko II took his domains. Shortly after, he could have expelled Dytryk and thus was able to reunite the whole country in his hands. 

Mieszko II regained the full power, but he still had to fight against the nobility and his own subjects. In Poland his renunciation to the Royal crown wasn't counted, and after 1032, in the chronicles, he was still called King.

Mieszko II died suddenly between 10 and 11 May 1034, probably in Poznań. The Polish chronicles clearly stated that he died of natural causes; the information that he was murdered by the sword-bearer (Miecznik), given by the chronicles of Gottfried of Viterbo, refers to Bezprym. However, the historians now think that he was killed in a plot hatched by the aristocracy.
He was buried in the Cathedral of St. Peter and St. Paul.

After Mieszko II's death, Poland's peasants revolted in a "pagan reaction." The exact reasons and date are unknown. Mieszko II's only son and heir, Casimir I, was either expelled by this insurrection, or the insurrection was caused by the aristocracy's expulsion of him. 

Some modern historians argue that the insurrection was caused more by economic than by religious issues, such as new taxes for the Church and the militarization of the early Polish polity. Priests, monks and knights were killed; cities, churches and monasteries were burned. 

The chaos became still greater when unexpectedly the Czechs invaded Silesia and Greater Poland from the south (1039). The land became divided among local rulers, one of whom is known by name: Miecław, ruler of Masovia. Greater Poland was so devastated that it ceased to be the core of Polish Kingdom. The capital was moved to Kraków in Lesser Poland.

In Merseburg ca. 1013, Mieszko II married with Richeza (b. bef. 1000 – d. Saalfeld, 21 March 1063), daughter of Count Palatine Ezzo of Lotharingia. They had at least three children, and possibly four:


 


</doc>
<doc id="20597" url="https://en.wikipedia.org/wiki?curid=20597" title="Mieszko I of Poland">
Mieszko I of Poland

Mieszko I (; – 25 May 992) was the ruler of Poland from about 960 until his death. A member of the Piast dynasty, he was a son of Siemomysł, and a grandson of Lestek. He was the father of Bolesław I the Brave (the first crowned king of Poland) and of Gunhild of Wenden. Most sources make Mieszko I the father of Sigrid the Haughty, a Scandinavian queen, though one source identifies her father as Skoglar Toste, and the grandfather of Canute the Great (Gundhild's son), and the great-grandfather of Gunhilda of Denmark, Canute the Great's daughter and wife of Henry III, Holy Roman Emperor.

While he was the first Christian ruler of Poland, he continued the policies of both his father and grandfather, who initiated the process of creation of the Polish state. Through both alliances and the use of military force, Mieszko extended ongoing Polish conquests and early in his reign subjugated Kuyavia and probably Gdańsk Pomerania and Masovia. For most of his reign, Mieszko I was involved in warfare for the control of Western Pomerania, eventually conquering it up to the vicinity of the lower Oder river. During the last years of his life, he fought the Bohemian state, winning Silesia and probably Lesser Poland.

Mieszko I's alliance with the Czech prince, Boleslaus I the Cruel, strengthened by his marriage in 965 to the Czech Přemyslid princess Dobrawa, and his baptism in 966 put him and his country in the cultural sphere of Western Christianity. Apart from the great conquests accomplished during his reign (which proved to be fundamental for the future of Poland) Mieszko I was renowned for his internal reforms, aimed at expanding and improving the so-called war monarchy system.

According to existing sources, Mieszko I was a wise politician, a talented military leader, and a charismatic ruler. He successfully used diplomacy, concluding alliances, first with Bohemia, then Sweden, and the Holy Roman Empire. In foreign policy, he placed the interests of his country foremost, even entering into agreements with his former enemies. On his death, he left to his sons a country with greatly expanded territories, and a well-established position in Europe.

Mieszko I also enigmatically appeared as "Dagome" in a papal document dating to about 1085, called "Dagome iudex", which mentions a gift or dedication of Mieszko's land to the Pope (the act took place almost a hundred years earlier).

It is roughly his borders that Poland was returned to in 1945.

There is no certain information on Mieszko I's life before he took control over his lands. Only the "Lesser Poland Chronicle" gives the date of his birth as somewhere between the years 920–931 (depending on the version of the manuscript), however, modern researchers don't recognize the Chronicle as a reliable source. Several historians on the basis of their investigations postulated the date of Mieszko I's birth to have been between 922–945; the activity of the Duke in his final years of life puts the date of his birth closer to the latter year.

There are three major theories concerning the origin and meaning of Mieszko I's name. The most popular theory, proposed by Jan Długosz, explains that Mieszko is a diminutive of "Mieczysław", a combination of two elements or lexemes: "Miecz" meaning sword and "Sław" meaning famous. Today, this theory is rejected by the majority of Polish historians, who consider the name Mieczysław to have been invented by Długosz to explain the origin of the name Mieszko. Today, we know that ancient Slavs never formed their names using either animal names or weapon names. Ancient Slavic names were abstract in nature. The same explanation rules out another theory about the origin of the name Mieszko, which links the name with the Polish word miś/miśko meaning bear, as no animal names were used to form honorable Polish names among Polish nobility.

The second most popular theory about the origin and sense of Mieszko's name can be traced to the very old legend, firstly described by Gallus Anonymus, according to which Mesco (the Latinized form used by the earliest sources) was blind during his first seven years of life. The chronicler related this story (a typical medieval allegory) as follows:

This interpretation was a clear reference to the later baptism of the Duke:

In addition, it is known that the Slavic word ""mzec"" can be interpreted as "having his eyes closed" or "be blind". Yet again, today it is almost certain that this legend was used as a metaphor, in allusion to the old Slavic pagan ceremony known as the "postrzyżyny": During that ceremony hair cutting was performed to every boy at the age of seven. In that symbolic rite a child became a man. That explains that Mieszko wasn't blind in fact. He was blind only metaphorically. Besides his son's name was also Mieszko and it is hard to believe that he was also blind. In addition, as we know today ancient Slavs used only abstract names among nobility.

The third theory links the name of Mieszko with his other name, Dagome, as it appeared in the document called "Dagome iudex". We know this document only from a copy prepared by an anonymous monk who was not familiar with Polish language or Polish names. It is possible that while copying the document he made a mistake and wrote down Dagome instead of Dagomer or even Dagomir. The name Dagomir is used to this day and its construction is similar to other Polish names like for example: Władimir/Włodzimierz or Casimir/Kazimierz. The evolution of the "-mir" element to "-mierz" is due to two separate developments: first, the regular change of the vowel "i" to "(i)e" before "r", and second, the modification of the nominative case by the vocative for certain names (hence, Kazimierz replaced Kazimier based on the vocative Kazimierze). It is debatable whether the name Mieszko is a nickname formed from the second part of the name *Dago-mierz, since the merger in pronunciation of "sz" with the devoiced "rz" which would appear in this position is quite recent. However, some historians believe that the word "Dagome" is a melding of two names: the Roman Catholic "Dago," for "Dagobert" (Mieszko's hypothetical baptismal name), and the Slavic "Me," for "Mieszko." The Latin word "iudex" ("judge") would be used in the meaning of "prince." Another interpretation is that "Dagome iudex" is a corruption of "Ego Mesco dux" ("I, Prince Mieszko").

Mieszko I took over the tribal rule after his father's death ca. 950–960, probably closer to the latter date. Due to the lack of sources it is not possible to determine exactly which lands he inherited. Certainly among them were the areas inhabited by the Polans and Goplans, as well as the Sieradz-Łęczyca lands and Kuyavia. It is possible that this state included also Masovia and Gdańsk Pomerania. Soon the new ruler had faced the task of integrating the relatively large, ethnically and culturally heterogeneous territory. Although the residents of areas controlled by Mieszko spoke mostly one language, had similar beliefs and reached a similar level of economic and general development, they were socially connected primarily by tribal structures. It appears that the elders cooperating with the Duke first felt the need for super-tribal unity, as expansion allowed them to broaden their influence.

Mieszko and his people were described around 966 by Abraham ben Jacob, a Sephardi Jewish traveller, who at that time visited the Prague court of Duke Boleslav I the Cruel. Abraham presented Mieszko I as one of the four Slavic "kings", reigning over a vast "northern" area, with a highly regarded and substantial military force at his disposal. More precise contemporary records regarding Mieszko were compiled by Widukind of Corvey, and half a century later, by Bishop Thietmar of Merseburg.

By the time Mieszko I took over from his father, the Polans' tribal federation of Greater Poland had for some time been actively expanding. Continuing this process, perhaps in the first years of Mieszko's reign, if it had not been done already by his father, Mieszko I conquered Masovia. Likely also during that period or earlier, at least partially Gdańsk Pomerania was obtained. Mieszko's interests were then concentrated mainly on areas occupied by the eastern (near the Oder River) branches of the Polabian Slavs; some of them became soon subordinated by him. As Widukind of Corvey wrote, Mieszko ruled over the tribe called the "Licicaviki", now commonly identified with the Polabian Lubusz Land. Having the control over those more western (in respect to the original homeland of the Polans) tribes, Mieszko had entered the German sphere of influence.

In 963 the German Margrave Gero conquered territories occupied by the Polabian Lusatian and Słupian tribes, and as a result came into direct contact with the Polish state. At the same time (about 960) Mieszko I began his expansion against the Velunzani and Lutici tribes. The war was recorded by the chronicler Abraham ben Jacob. According to him, Mieszko I had fought against the Weltaba tribe, commonly identified with the Veleti. Wichmann the Younger, a Saxon nobleman who was then a leader of a band of Polabian Slavs, defeated Mieszko twice, and around 963 a brother of Mieszko, whose name is unknown, was killed in the fighting. The frontiers at the mouth of the Oder River were also desired by the German margraves. In addition, the Veleti Bohemia, which at that time possessed Silesia and Lesser Poland regions, constituted a danger for the young state of the Polans.

The chronicle of Thietmar poses some problems of interpretation of the information regarding the attack of Margrave Gero on the Slavic tribes, as a result of which he purportedly "subordinated to the authority of the Emperor Lusatia and the Selpuli" (meaning the Słupian tribes) "and also Mieszko with his subjects". According to the majority of modern historians, Thietmar made an error summarizing the chronicle of Widukind, placing the Gero raid there instead of the fighting that Mieszko conducted at that time against Wichmann the Younger. Other sources make no mention of such conquest and of putting the Polans state on the same footing with the Polabian Slavs. On the other hand, the supporters of the Gero's invasion theory believe that the Margrave did actually carry out a successful invasion, as a result of which Mieszko I was forced to pay tribute to the Emperor and also was compelled to adopt Catholicism through the German Church. The thesis that proposes the introduction of Catholicism as a result of this war finds no confirmation in German sources.

The homage is then a separate issue, since, according to the chronicle of Thietmar, Mieszko actually paid tribute to the Emperor from the lands "usque in Vurta fluvium" (up to the Warta River). In all probability Mieszko decided to pay tribute in order to avoid an invasion similar to the one that Lusatia had suffered. This homage would take place in 965, or in 966 at the latest. Very likely the tribute applied only to the Lubusz land, which was in the German sphere of influence. This understanding of the tribute issue explains why already in 967 Mieszko I was described in the Saxon chronicles as the Emperor's friend (or ally, supporter, Latin: "amicus imperatoris").

Probably in 964 Mieszko began negotiations with the Bohemian ruler Boleslav I the Cruel. As a result, in 965 Mieszko I married his daughter Dobrawa (also named "Dobrava", "Doubravka" or "Dąbrówka"). This political Polish-Bohemian alliance is likely to have been initiated by the Polish ruler. It is probable that the marriage was officially arranged in February 965.

The next step was the baptism of Mieszko. There are different hypotheses concerning this event. Most often it is assumed that it was a political decision, intended to bring Mieszko's state closer to the Czechs and to facilitate his activities in the Polabian Slavs area. At the same time, the baptism decreased the likelihood of future attacks by German margraves and deprived them of the opportunity to attempt Roman Catholicization of Mieszko's lands by force. An additional reason could be Mieszko's desire to remove from power the influential pagan priest class, who may have been blocking his efforts to establish a more centralized rule.

A different hypothesis is linked with the above-mentioned acceptance of the veracity of Gero's invasion of Poland. According to it, it was the attack of the Margrave that forced the Catholicization, which was to be an act of subordination to the Emperor, done without the mediation of the Pope.

Still other motives were responsible according to Gallus Anonymus, who claimed that it was the Bohemian Princess Dobrawa who convinced her husband to change his religion. Likewise chronicler Thietmar attributes Mieszko's conversion to Dobrawa's influence. There are no reasons to negate Dobrawa's role in Mieszko's acceptance of Roman Catholicism; however crediting rulers' wives with positive influence over their husbands' actions was a common convention at that time.

It is generally recognized that the baptism of Mieszko I took place in 966. The place is unknown; it could have had happened in any of the cities of the Empire (possibly Regensburg), but also in one of the Polish towns like Gniezno or Ostrów Lednicki. The belief that the baptism was accomplished through the Czechs in order to avoid the dependence on Germany and the German Church is incorrect, because Bohemia would not have its own church organization until 973. At the time of the baptism of Mieszko the existing Bohemian church establishment was a part of the Regensburg diocese. Thus, if the Polish ruler accepted the baptism through Prague's mediation, it had to be sanctioned in Regensburg. However, the religious vocabulary (words like baptism, sermon, prayer, church, apostle, bishop or confirmation) were adopted from the Czech language and had to come from Dobrawa's entourage and the church elements that arrived with her. Perhaps with her also came the first Polish bishop, Jordan. It could be that the reason for the Czech preference of Mieszko was the existence in Bohemia of a mission which followed the precepts of the Byzantine Greek brothers and later saints Cyril and Methodius, who developed and performed the liturgy in the Slavic rite, more readily understood by Mieszko and his subjects. The Slavic rite church branch had survived in Bohemia for another hundred years after Mieszko's baptism.

After the normalization of relations with the Holy Roman Empire and Bohemia, Mieszko I returned to his plans of conquest of the more western part of Pomerania. On 21 September 967 the Polish-Bohemian troops prevailed in the decisive battle against the Wolinians led by Wichmann the Younger, which gave Mieszko the control over the mouth of the Odra River. The German margraves had not opposed Mieszko's activities in Pomerania, perhaps even supported them; the death of the rebellious Wichmann, who succumbed to his wounds soon after the battle, may have been in line with their interests. A telling incident took place after the battle, a testimony to Mieszko's high standing among the Empire's dignitaries, just one year after his baptism: Widukind of Corvey reported that the dying Wichmann asked Mieszko to hand over Wichmann's weapons to Emperor Otto I, to whom Wichmann was related. For Mieszko the victory had to be a satisfying experience, especially in light of his past defeats inflicted by Wichmann.

The exact result of Mieszko's fighting in Western Pomerania is not known. Subsequent loss of the region by Mieszko's son Bolesław Chrobry suggests that the conquest was difficult and the hold over that territory rather tenuous. In one version of the legend of St. Wojciech it is written that Mieszko I had his daughter married to a Pomeranian prince, who previously voluntarily "was washed with the holy water of the baptism" in Poland. The above information, as well as the fact that Bolesław lost Western Pomerania, suggest that the region was not truly incorporated into the Polish state, but only became a fief. This conjecture seems to be confirmed in the introduction of the first volume of the chronicles of Gallus Anonymus concerning the Pomeranians: "Although often the leaders of the forces defeated by the Polish duke sought salvation in baptism, as soon as they regained their strength, they repudiated the 'Christian' (that is, Roman Catholic) faith and started the war against Christian anew".

In 972 Poland suffered the attack of Odo I, Margrave of the Saxon Ostmark. According to the chronicles of Thietmar, this attack was an arbitrary action, without the consent of the Emperor:

There are different hypotheses concerning the reasons for this invasion. Possibly Margrave Odo wanted to stop the growing power of the Polish state. Very likely Odo wanted to protect the Wolinian state, which he considered his zone of influence, from the Polish take-over. Possibly the Wolinians themselves called the Margrave and asked his help. In any event, Odo's forces moved in and on 24 June 972 twice engaged Mieszko's army at the village of "Cidini", commonly identified with Cedynia. At first, the Margrave defeated Mieszko's forces; subsequently the Duke's brother Czcibor defeated the Germans in the decisive stage, inflicting great losses among their troops. It may be that Mieszko intentionally staged the retreat, which was followed by a surprise attack on the flank of the German pursuing troops. After this battle, Mieszko and Odo were called to the Imperial Diet in Quedlinburg in 973 to explain and justify their conduct. The exact judgment of the Emperor is unknown, but it's certain that the sentence wasn't carried out because he died a few weeks after the Diet. It is commonly assumed that the sentence was unfavorable to the Polish ruler. The "Annals of Altaich" indicates that Mieszko was not present in Quedlinburg during the gathering; instead, he had to send his son Bolesław as a hostage.

Mieszko's conflict with Odo I was a surprising event because, according to Thietmar, Mieszko respected the Margrave highly. Thietmar wrote the following:

It is believed that in practical terms the victory at Cedynia sealed Western Pomerania's fate as Mieszko' dependency.

According to archaeological research, during the 970s the Sandomierz region and the Przemyśl area inhabited by the Lendians became incorporated into the Polish state. None of it is certain for the lack of written sources. It is possible that especially the Przemyśl area, inhabited by the Lendians and the White Croats, belonged at that time to Bohemia, which supposedly extended up to the Bug River and Styr River. The Primary Chronicle states that in 981 Vladimir of the Rurik Dynasty "went towards the Lachy and took their towns: Przemyśl, Czerwień and other strongholds (...)". The exact interpretation of this passage is uncertain, because the Ruthenian word "Lachy" meant both the Poles in general and the southeastern Lendians tribe. Mieszko's conquest of Sandomierz could also have taken place later, together with the take-over of the Vistulans (western and central Lesser Poland).

Some historians suggest that the regions of Sandomierz, Lublin and Czerwień (western Red Ruthenia) were indeed annexed by Mieszko's state in the 970s, as lands valuable for trade reasons and as a starting point for a future attack against what was to become Lesser Poland, then in the hands of Bohemia. Sandomierz under this scenario was the central hub of the area, with Czerwień, Przemyśl and Chełm assuming the function of defensive borderland strongholds.

After the death of Emperor Otto I in 973 Mieszko, like his brother-in-law, Duke Boleslav II of Bohemia, joined the German opposition in support of the attempted imperial succession of Henry II, Duke of Bavaria. Mieszko may have been motivated by revenge because of the (presumably) negative verdict of the Quedlinburg summit, but, more importantly, he may have wanted more favorable terms for his cooperation with Germany. The participation of Mieszko in the conspiracy against Otto II was documented in only one source, the chronicles of the monastery in Altaich in its entry for the year 974. The Duke of Bavaria was defeated, and Emperor Otto II regained full power. Shortly afterwards, the young emperor waged a retaliatory expedition against Bohemia, in 978 forcing Duke Boleslav into submission.

In 977 Mieszko's wife, Dobrawa, died. At first there were no apparent repercussions, as the Polish ruler had maintained his alliance with Bohemia.

In 979 Otto II supposedly attacked Poland. Mention of this event can be found in the "Chronicle of the Bishops of Cambrai" from the 11th century. The effects of this expedition are unknown, but it is suspected that the Emperor did not succeed. Due to bad weather, the Emperor was back at the border of Thuringia and Saxony in December of that year. It is uncertain whether the invasion actually took place. The chronicle only stated that it was an expedition "against the Slavs". Archaeological discoveries appear to support the thesis of Otto II's invasion. In the last quarter of the 10th century there had been a radical expansion of the fortifications at Gniezno and Ostrów Lednicki, which may be associated with the Polish-German war, or the expectation of such. The duration of the expedition suggests that it may have reached as far east as the vicinity of Poznań.
The Polish-German agreement was concluded in the spring or possibly summer of 980, because in November of that year Otto II left his country and went to Italy. It appears that during this time Mieszko I married Oda, daughter of Dietrich of Haldensleben, Margrave of the Northern March, after abducting her from the monastery of Kalbe. Chronicler Thietmar described the event as follows:

Although Thietmar made no mention of warfare that possibly took place on this occasion, the information on the return of the accord, acting for the good of the country and release of prisoners indicate that a conflict actually did occur.

The marriage with Oda considerably affected the position and prestige of Mieszko, who entered the world of Saxon aristocracy. As a son-in-law of Margrave Dietrich, he gained an ally in one of the most influential politicians of the Holy Roman Empire. As the Margrave was a distant relative of the Emperor, Mieszko became a member of the circle connected to the imperial ruling house.

Probably in the early 980s Mieszko allied his country with Sweden against Denmark. The alliance was sealed with the marriage of Mieszko's daughter Świętosława with the Swedish king Erik. The content of the treaty is known from the not entirely reliable, but originating directly from the Danish court tradition account given by Adam of Bremen. In this text, probably as a result of confusion, he gives instead of Mieszko's name the name of his son Bolesław:

Mieszko decided on the alliance with Sweden probably in order to help protect his possessions in Pomerania from the Danish King Harald Bluetooth and his son Sweyn. They may have acted in cooperation with the Wolinian autonomous entity. The Danish were defeated ca. 991 and their ruler was expelled. The dynastic alliance with Sweden had probably affected the equipment and composition of Mieszko's troops. Perhaps at that time the Varangian warriors were recruited; their presence is indicated by archaeological excavations in the vicinity of Poznań.

In 982 Emperor Otto II suffered a disastrous defeat against the Emirate of Sicily. The resulting weakness of the imperial power was exploited by the Lutici, who initiated a great uprising of the Polabian Slavs in 983. The German authority in the area ceased to exist and the Polabian tribes began to threaten the Empire. The death of Otto II at the end of that year contributed further to the unrest. Ultimately the Lutici and the Obotrites were able to liberate themselves from the German rule for the next two centuries.

The Emperor left a minor successor, Otto III. The right to care for him and the regency powers were claimed by Henry II of Bavaria. Like in 973, Mieszko and the Czech duke Boleslav II took the side of the Bavarian duke. This fact is confirmed in the chronicle of Thietmar:

In 984 the Czechs took over Meissen, but in the same year Henry II gave up his pretension to the German throne.

The role played by Mieszko I in the subsequent struggles is unclear because the contemporary sources are scarce and not in agreement. Probably in 985 the Polish ruler ended his support for the Bavarian duke and moved to the side of the Emperor. It is believed that Mieszko's motivation was the threat posed to his interests by the Polabian Slavs uprising. The upheaval was a problem for both Poland and Germany, but not for Bohemia. In the "Chronicle of Hildesheim", in the entry for the year 985 it is noted that Mieszko came to help the Saxons in their fight against some Slavic forces, presumably the Polabians.

One year later, the Polish ruler had a personal meeting with the Emperor, an event mentioned in the "Annals of Hersfeld":

According to Thietmar and other contemporary chronicles the gift given by Mieszko to the Emperor was a camel. The meeting consolidated the Polish-German alliance, with Mieszko joining Otto's expedition against a Slavic land, which "together they wholly devastated (...) with fire and tremendous depopulation". It is not clear which Slavic territory was invaded. Perhaps another raid against the Polabians took place. But there are indications that it was an expedition against the Czechs, Mieszko's first against his southern neighbors. Possibly on this occasion the Duke of the Polans accomplished the most significant expansion of his state, the take-over of Lesser Poland.

Thietmar's narrative, however, raises doubts as to whether the joined military operation actually happened. The chronicler claims that a settlement was then concluded between the Emperor and the Bohemian ruler Boleslav II the Pious, which is not mentioned in any other source and is contrary to the realities of the political situation at that time.

Another debatable point is Thietmar's claim that Mieszko "subordinated himself to the King". Most historians believe that it was only a matter of recognition of Otto's royal authority. Some suggest that a fealty relationship could in fact be involved.

Whether or not the German-Polish invasion of Bohemia actually happened, the friendly relations between the Czechs and the Poles came to an end. Bohemia resumed its earlier alliance with the Lutici, which caused in 990 a war with Mieszko, who was supported by Empress Theophanu. Duke Boleslav II was probably the first one to attack. As a result of the conflict Silesia was taken over by Poland. However, the annexation of Silesia possibly took place around 985, because during this year the major Piast strongholds in Wrocław, Opole and Głogów were already being built.

The issue of the incorporation of Lesser Poland is also not completely resolved. Possibly Mieszko took the region before 990, which is indicated by the vague remark of Thietmar, who wrote of a country taken by Mieszko from Boleslav. In light of this theory, the conquest of Lesser Poland could be a reason for the war, or its first stage. Many historians suggested that the Czech rule over Lesser Poland was only nominal and likely limited to the indirect control of Kraków and perhaps a few other important centers. This theory is based on the lack of archaeological discoveries, which would indicate major building investments undertaken by the Bohemian state.

Lesser Poland supposedly after its incorporation had become the partition of the country assigned to Mieszko's oldest son, Bolesław, which is indirectly indicated in the chronicle of Thietmar.

Some historians, on the basis of the chronicle of Cosmas of Prague, believe that the conquest of the lands around the lower Vistula River took place after Mieszko's death, specifically in 999. There is also a theory according to which during this transition period Lesser Poland was governed by Bolesław Chrobry, whose authority was granted to him by the Bohemian duke.

At the end of his life (ca. 991-92), Mieszko I, together with his wife Oda and their sons, issued a document called "Dagome iudex", where the Polish ruler placed his lands under the protection of the Pope and described their borders. Only a later imprecise summary of the document has been preserved.

There are two main theories concerning reasons behind the issuing of "Dagome iudex":


"Dagome iudex" is of capital importance for Polish history because it gives a general description of the Polish state's geographical location at the end of Mieszko's reign.

During his last years of life Mieszko remained loyal to the alliance with the Holy Roman Empire. In 991 he arrived at a gathering in Quedlinburg, where he participated in the customary exchange of gifts with Otto III and Empress Theophanu. In the same year he took part in a joint expedition with the young king to Brandenburg.

Mieszko died on 25 May 992. Sources give no reasons to believe that his death occurred from causes other than natural. According to Thietmar the Polish ruler died "in an old age, overcame with fever". Probably he was buried in the Poznań Cathedral. The remains of the first historical ruler of Poland have never been found and the place of his burial is not known with certainty. In 1836–1837 a cenotaph was built for Mieszko I and his successor Bolesław I the Brave in the Golden Chapel () at the Poznań Cathedral, where the damaged remains found in the 14th century tomb of Bolesław were placed.

According to Thietmar Mieszko I divided his state before his death among a number of princes. They were probably his sons: Bolesław I the Brave, Mieszko and Lambert.

In 1999 the archeologist Hanna Kóčka-Krenz located what's left of Mieszko's palace-chapel complex in Poznań.

The basic structure of the early Polish state was Mieszko's military force. The ruler managed to create an army composed of about 3,000 mounted warriors. This increasingly powerful force allowed the Polans to attack weaker neighboring tribes and conquer their lands. A key factor promoting cohesion of the growing state was fear of the invaders impressed by them among local populations. The first Piasts reinforced their rule by burning local strongholds and replacing them with new larger fortresses, located in strategic positions. Archaeological studies show that this practice was abandoned only at the end of Mieszko's reign, when his position was already well-established.

The largest social group in Mieszko's state were free peasants ("kmiecie"), who cultivated their own land. They had to support the state by levies collected from them and by supporting the duke and his attendants as he traveled around the country. There were also service villages, specializing in production of certain types of items.

Many trade routes went through the Polish lands, which facilitated the development of trade. Amber, fur and salt (extracted in Kuyavia and around Kołobrzeg) were exported to other countries, while cloth, crafts, tools and ornaments were imported.


According to Gallus Anonymus, before becoming a Roman Catholic Mieszko had seven pagan wives, whom he was required to relinquish, leaving Dobrawa as his only spouse. Nothing is known of the fates of any possible children from these relationships. In 965, before his baptism, Mieszko married Dobrawa (b. 940/45 – d. 977), daughter of Boleslav I the Cruel, Duke of Bohemia. They had two children:


According to one hypothesis there was another daughter of Mieszko, married to a Pomeranian Slavic Prince; she could be a daughter of Dobrawa or of one of the previous pagan wives. Also, a theory exists (apparently based on Thietmar and supported by Oswald Balzer in 1895) that Vladivoj, who ruled as Duke of Bohemia in 1002–1003, was a son of Mieszko and Dobrawa. Although most modern historians reject this claim, Bohemian historiography supported the Piast parentage of Vladivoj.

In 978/79, Mieszko married Oda of Haldensleben (b. 955/60 – d. 1023), daughter of Dietrich of Haldensleben, Margrave of the Northern March. She was abducted by her future husband from the monastery of Kalbe. They had three sons:

After a struggle for power between Bolesław I and Oda with her minor sons (Bolesław's half-brothers), the eldest son of Mieszko I took control over all of his father's state and expelled his stepmother and her sons from Poland.




</doc>
<doc id="20601" url="https://en.wikipedia.org/wiki?curid=20601" title="Maggieknockater">
Maggieknockater

Maggieknockater ("Magh an Fhucadair" in Scottish Gaelic) is a hamlet on the A95 road between Craigellachie and Mulben in Scotland in the Moray council area, in the former county of Banffshire.

Until the early 1970s there was large apiary which was well known in the region and has lived on in the Scottish country dance "The Bees of Maggieknockater". The meaning of Maggieknockater is "field of the fuller" or "plain of the hilly ridge" and has nothing to do with a woman called Maggie. At nearby Gauldwell Castle (now only with one partial wall left standing) Mary, Queen of Scots, is reputed to have spent the night. The school was closed in the 1960s and the chapel was turned into a home in the early 1970s. What was once a smithy is now a garage still in the hands of the Maclean family. Maggieknockater formerly had a post office; it opened in June 1876 and closed in 1940. 

Maggieknockater is situated in the heart of Scotland's Malt Whisky Trail, situated less than 4 miles from Dufftown, home of the world-famous Glenfiddich Distillery.

Less than two miles heading east along the A95 from Maggieknockater is the site for Moray's most demanding Mountain Biking trails, "The Moray Monster Trails". The trails were regenerated and improved during 2005 and 2006.


</doc>
<doc id="20603" url="https://en.wikipedia.org/wiki?curid=20603" title="Mary, Queen of Scots">
Mary, Queen of Scots

Mary, Queen of Scots (8 December 1542 – 8 February 1587), also known as Mary Stuart or Mary I of Scotland, reigned over Scotland from 14 December 1542 to 24 July 1567.

Mary, the only surviving legitimate child of King James V of Scotland, was six days old when her father died and she acceded to the throne. She spent most of her childhood in France while Scotland was ruled by regents, and in 1558, she married the Dauphin of France, Francis. Mary was queen consort of France from his accession in 1559 until his death in December 1560. Widowed, Mary returned to Scotland, arriving in Leith on 19 August 1561. Four years later, she married her half-cousin, Henry Stuart, Lord Darnley, and in June 1566 they had a son, James.

In February 1567, Darnley's residence was destroyed by an explosion, and he was found murdered in the garden. James Hepburn, 4th Earl of Bothwell, was generally believed to have orchestrated Darnley's death, but he was acquitted of the charge in April 1567, and the following month he married Mary. Following an uprising against the couple, Mary was imprisoned in Loch Leven Castle. On 24 July 1567, she was forced to abdicate in favour of her one-year-old son. After an unsuccessful attempt to regain the throne, she fled southward seeking the protection of her first cousin once removed, Queen Elizabeth I of England. Mary had once claimed Elizabeth's throne as her own and was considered the legitimate sovereign of England by many English Catholics, including participants in a rebellion known as the Rising of the North. Perceiving Mary as a threat, Elizabeth had her confined in various castles and manor houses in the interior of England. After eighteen and a half years in custody, Mary was found guilty of plotting to assassinate Elizabeth in 1586, and was beheaded the following year at Fotheringhay Castle.

Mary was born on 8 December 1542 at Linlithgow Palace, Scotland, to King James V and his French second wife, Mary of Guise. She was said to have been born prematurely and was the only legitimate child of James' to survive him. She was the great-niece of King Henry VIII of England, as her paternal grandmother, Margaret Tudor, was Henry VIII's sister. On 14 December, six days after her birth, she became Queen of Scotland when her father died, perhaps from the effects of a nervous collapse following the Battle of Solway Moss or from drinking contaminated water while on campaign.

A popular tale, first recorded by John Knox, states that James, upon hearing on his deathbed that his wife had given birth to a daughter, ruefully exclaimed, "It cam wi' a lass and it will gang wi' a lass!" His House of Stuart had gained the throne of Scotland in the 14th century via the marriage of Marjorie Bruce, daughter of Robert the Bruce, to Walter Stewart, 6th High Steward of Scotland. The crown had come to his family through a woman, and would be lost from his family through a woman. This legendary statement came true much later—not through Mary, but through her descendant Anne, Queen of Great Britain.

Mary was christened at the nearby Church of St Michael shortly after she was born. Rumours spread that she was weak and frail, but an English diplomat, Ralph Sadler, saw the infant at Linlithgow Palace in March 1543, unwrapped by her nurse, and wrote, "it is as goodly a child as I have seen of her age, and as like to live."

As Mary was an infant when she inherited the throne, Scotland was ruled by regents until she became an adult. From the outset, there were two claims to the regency: one from the Catholic Cardinal Beaton, and the other from the Protestant Earl of Arran, who was next in line to the throne. Beaton's claim was based on a version of the king's will that his opponents dismissed as a forgery. Arran, with the support of his friends and relations, became the regent until 1554 when Mary's mother managed to remove and succeed him.

King Henry VIII of England took the opportunity of the regency to propose marriage between Mary and his own son and heir, Edward, hoping for a union of Scotland and England. On 1 July 1543, when Mary was six months old, the Treaty of Greenwich was signed, which promised that, at the age of ten, Mary would marry Edward and move to England, where Henry could oversee her upbringing. The treaty provided that the two countries would remain legally separate and, if the couple should fail to have children, the temporary union would dissolve. Cardinal Beaton rose to power again and began to push a pro-Catholic pro-French agenda, angering Henry, who wanted to break the Scottish alliance with France. Beaton wanted to move Mary away from the coast to the safety of Stirling Castle. Regent Arran resisted the move, but backed down when Beaton's armed supporters gathered at Linlithgow. The Earl of Lennox escorted Mary and her mother to Stirling on 27 July 1543 with 3,500 armed men. Mary was crowned in the castle chapel on 9 September 1543, with "such solemnity as they do use in this country, which is not very costly", according to the report of Ralph Sadler and Henry Ray.

Shortly before Mary's coronation, Henry arrested Scottish merchants headed for France and impounded their goods. The arrests caused anger in Scotland, and Arran joined Beaton and became a Catholic. The Treaty of Greenwich was rejected by the Parliament of Scotland in December. The rejection of the marriage treaty and the renewal of the alliance between France and Scotland prompted Henry's "Rough Wooing", a military campaign designed to impose the marriage of Mary to his son. English forces mounted a series of raids on Scottish and French territory. In May 1544, the English Earl of Hertford (later Duke of Somerset) raided Edinburgh, and the Scots took Mary to Dunkeld for safety.

In May 1546, Beaton was murdered by Protestant lairds, and on 10 September 1547, nine months after the death of Henry VIII, the Scots suffered a heavy defeat at the Battle of Pinkie Cleugh. Mary's guardians, fearful for her safety, sent her to Inchmahome Priory for no more than three weeks, and turned to the French for help.

King Henry II of France proposed to unite France and Scotland by marrying the young queen to his three-year-old son, the Dauphin Francis. On the promise of French military help and a French dukedom for himself, Arran agreed to the marriage. In February 1548, Mary was moved, again for her safety, to Dumbarton Castle. The English left a trail of devastation behind them once more and seized the strategic town of Haddington. In June, the much awaited French help arrived at Leith to besiege and ultimately take Haddington. On 7 July 1548, a Scottish Parliament held at a nunnery near the town agreed to the French marriage treaty.

With her marriage agreement in place, five-year-old Mary was sent to France to spend the next thirteen years at the French court. The French fleet sent by Henry II, commanded by Nicolas de Villegagnon, sailed with Mary from Dumbarton on 7 August 1548 and arrived a week or more later at Roscoff or Saint-Pol-de-Léon in Brittany.

Mary was accompanied by her own court including two illegitimate half-brothers, and the "four Marys" (four girls her own age, all named Mary), who were the daughters of some of the noblest families in Scotland: Beaton, Seton, Fleming, and Livingston. Janet, Lady Fleming, who was Mary Fleming's mother and James V's half-sister, was appointed governess. When Lady Fleming left France in 1551, she was succeeded by a French governess, Françoise de Paroy.
Vivacious, beautiful, and clever (according to contemporary accounts), Mary had a promising childhood. At the French court, she was a favourite with everyone, except Henry II's wife Catherine de' Medici. Mary learned to play lute and virginals, was competent in prose, poetry, horsemanship, falconry, and needlework, and was taught French, Italian, Latin, Spanish, and Greek, in addition to speaking her native Scots. Her future sister-in-law, Elisabeth of Valois, became a close friend of whom Mary "retained nostalgic memories in later life". Mary's maternal grandmother, Antoinette de Bourbon, was another strong influence on her childhood and acted as one of her principal advisors.

Portraits of Mary show that she had a small, oval-shaped head, a long, graceful neck, bright auburn hair, hazel-brown eyes, under heavy lowered eyelids and finely arched brows, smooth pale skin, a high forehead, and regular, firm features. She was considered a pretty child and later, as a woman, strikingly attractive. At some point in her infancy or childhood, she caught smallpox, but it did not mark her features.

Mary was eloquent and especially tall, even by modern standards (she attained an adult height of ,) while Henry II's son and heir, Francis, stuttered and was unusually short. Henry commented: "from the very first day they met, my son and she got on as well together as if they had known each other for a long time". On 4 April 1558, Mary signed a secret agreement bequeathing Scotland and her claim to England to the French crown if she died without issue. Twenty days later, she married the Dauphin at Notre Dame de Paris, and he became king consort of Scotland.

In November 1558, Henry VIII's elder daughter, Mary I of England, was succeeded by her only surviving sibling, Elizabeth I. Under the Third Succession Act, passed in 1543 by the Parliament of England, Elizabeth was recognised as her sister's heir, and Henry VIII's last will and testament had excluded the Stuarts from succeeding to the English throne. Yet, in the eyes of many Catholics, Elizabeth was illegitimate, thereby rendering Mary Stuart the rightful queen of England as the senior surviving legitimate descendant of Henry VII through her grandmother, Margaret Tudor. Henry II of France proclaimed his eldest son and daughter-in-law king and queen of England, and in France the royal arms of England were quartered with those of Francis and Mary. Mary's claim to the English throne was a perennial sticking point between herself and Elizabeth.

When Henry II died on 10 July 1559, from injuries sustained in a joust, fifteen-year-old Francis and sixteen-year-old Mary became king and queen of France. Two of the Queen's uncles, the Duke of Guise and the Cardinal of Lorraine, were now dominant in French politics, enjoying an ascendancy called by some historians "la tyrannie Guisienne".

In Scotland, the power of the Protestant Lords of the Congregation was rising at the expense of Mary's mother, who maintained effective control only through the use of French troops. The Protestant Lords invited English troops into Scotland in an attempt to secure Protestantism, and a Huguenot uprising in France, called the Tumult of Amboise, in March 1560 made it impossible for the French to send further support. Instead, the Guise brothers sent ambassadors to negotiate a settlement. On 11 June 1560, their sister (Mary's mother) died, and so the question of future Franco-Scots relations was a pressing one. Under the terms of the Treaty of Edinburgh, signed by Mary's representatives on 6 July 1560, France and England undertook to withdraw troops from Scotland, and France recognised Elizabeth's right to rule England. But the seventeen-year-old Mary, still in France and grieving for her mother, refused to ratify the treaty.

King Francis II died on 5 December 1560, of a middle ear infection that led to an abscess in his brain. Mary was grief-stricken. Her mother-in-law, Catherine de' Medici, became regent for the late king's ten-year-old brother Charles IX, who inherited the French throne. Mary returned to Scotland nine months later, arriving in Leith on 19 August 1561. Having lived in France since the age of five, Mary had little direct experience of the dangerous and complex political situation in Scotland. As a devout Catholic, she was regarded with suspicion by many of her subjects, as well as by the Queen of England. Scotland was torn between Catholic and Protestant factions, and Mary's illegitimate half-brother, the Earl of Moray, was a leader of the Protestants. The Protestant reformer John Knox preached against Mary, condemning her for hearing Mass, dancing, and dressing too elaborately. She summoned him to her presence to remonstrate with him unsuccessfully, and later charged him with treason, but he was acquitted and released.

To the disappointment of the Catholic party, and against their expectations, Mary tolerated the newly established Protestant ascendancy, and kept her half-brother Lord Moray as her chief advisor. Her privy council of 16 men, appointed on 6 September 1561, retained those who already held the offices of state and was dominated by the Protestant leaders from the reformation crisis of 1559–1560: the Earls of Argyll, Glencairn, and Moray. Only four of the councillors were Catholic: the Earls of Atholl, Erroll, Montrose, and Huntly, who was Lord Chancellor. Modern historian Jenny Wormald found this remarkable, suggesting that Mary's failure to appoint a council sympathetic to Catholic and French interests was an indication of her focus on the goal of the English throne over the internal problems of Scotland. Even the one significant later addition to the council, Lord Ruthven in December 1563, was another Protestant whom Mary personally disliked. In this, she was acknowledging her lack of effective military power in the face of the Protestant lords, while also following a policy that strengthened her links with England. She joined with Lord Moray in the destruction of Scotland's leading Catholic magnate, Lord Huntly, in 1562 after he led a rebellion in the Highlands against her.

Mary sent William Maitland of Lethington as an ambassador to the English court to put the case for Mary as the heir presumptive to the English throne. Elizabeth refused to name a potential heir, fearing that to do so would invite conspiracy to displace her with the nominated successor, but she assured Maitland that she knew no one with a better claim than Mary. In late 1561 and early 1562, arrangements were made for the two queens to meet in England at York or Nottingham in August or September 1562, but Elizabeth sent Sir Henry Sidney to cancel in July because of the civil war in France.

Mary turned her attention to finding a new husband from the royalty of Europe. But when her uncle, the Cardinal of Lorraine, began negotiations with Archduke Charles of Austria without her consent, she angrily objected and the negotiations foundered. Her own attempt to negotiate a marriage to Don Carlos, the mentally unstable heir apparent of King Philip II of Spain, was rebuffed by Philip. Elizabeth attempted to neutralise Mary by suggesting that she marry English Protestant Robert Dudley, 1st Earl of Leicester (Sir Henry Sidney's brother-in-law and the English queen's own favourite), whom Elizabeth trusted and thought she could control. She sent an ambassador, Thomas Randolph, to tell Mary that if she married an English nobleman, Elizabeth would "proceed to the inquisition of her right and title to be our next cousin and heir". The proposal came to nothing, not least because the intended bridegroom was unwilling.

In contrast, a French poet at Mary's court, Pierre de Boscosel de Chastelard, was apparently besotted with Mary. In early 1563, he was discovered during a security search hidden underneath her bed, apparently planning to surprise her when she was alone and declare his love for her. Mary was horrified and banished him from Scotland. He ignored the edict, and two days later he forced his way into her chamber as she was about to disrobe. She reacted with fury and fear, and when Moray rushed into the room, in reaction to her cries for help, she shouted, "Thrust your dagger into the villain!", which Moray refused to do, as Chastelard was already under restraint. Chastelard was tried for treason, and beheaded. Maitland claimed that Chastelard's ardour was feigned, and that he was part of a Huguenot plot to discredit Mary by tarnishing her reputation.

Mary had briefly met her English-born half-cousin Henry Stuart, Lord Darnley, in February 1561 when she was in mourning for Francis. Darnley's parents, the Earl and Countess of Lennox, who were Scottish aristocrats as well as English landowners, had sent him to France ostensibly to extend their condolences while hoping for a potential match between their son and Mary. Both Mary and Darnley were grandchildren of Margaret Tudor, sister of Henry VIII of England, and patrilineal descendants of the High Stewards of Scotland. Darnley shared a more recent Stewart lineage with the Hamilton family as a descendant of Mary Stewart, Countess of Arran, a daughter of James II of Scotland. They next met on Saturday 17 February 1565 at Wemyss Castle in Scotland, after which Mary fell in love with the "long lad" (as Queen Elizabeth called him—he was over six feet tall). They married at Holyrood Palace on 29 July 1565, even though both were Catholic and a papal dispensation for the marriage of first cousins had not been obtained.

English statesmen William Cecil and the Earl of Leicester had worked to obtain Darnley's licence to travel to Scotland from his home in England. Although her advisors had thus brought the couple together, Elizabeth felt threatened by the marriage, because as descendants of her aunt, both Mary and Darnley were claimants to the English throne and their children, if any, would inherit an even stronger, combined claim. Mary's insistence on the marriage seems to have stemmed from passion rather than calculation; the English ambassador Nicholas Throckmorton stated "the saying is that surely she [Queen Mary] is bewitched", adding that the marriage could only be averted "by violence". The union infuriated Elizabeth, who felt the marriage should not have gone ahead without her permission, as Darnley was both her cousin and an English subject.

Mary's marriage to a leading Catholic precipitated Mary's half-brother, the Earl of Moray, to join with other Protestant lords, including Lords Argyll and Glencairn, in open rebellion. Mary set out from Edinburgh on 26 August 1565 to confront them, and on the 30th Moray entered Edinburgh, but left soon afterward having failed to take the castle. Mary returned to Edinburgh the following month to raise more troops. In what became known as the Chaseabout Raid, Mary and her forces and Moray and the rebellious lords roamed around Scotland without ever engaging in direct combat. Mary's numbers were boosted by the release and restoration to favour of Lord Huntly's son, and the return of James Hepburn, 4th Earl of Bothwell, from exile in France. Unable to muster sufficient support, Moray left Scotland in October for asylum in England. Mary broadened her privy council, bringing in both Catholics (Bishop of Ross John Lesley and provost of Edinburgh Simon Preston of Craigmillar) and Protestants (the new Lord Huntly, Bishop of Galloway Alexander Gordon, John Maxwell of Terregles and Sir James Balfour).

Before long, Darnley grew arrogant. Not content with his position as king consort, he demanded the Crown Matrimonial, which would have made him a co-sovereign of Scotland with the right to keep the Scottish throne for himself if he outlived his wife. Mary refused his request, and their marriage grew strained even though they conceived by October 1565. He was jealous of her friendship with her Catholic private secretary, David Rizzio, who was rumoured to be the father of her child. By March 1566, Darnley had entered into a secret conspiracy with Protestant lords, including the nobles who had rebelled against Mary in the Chaseabout Raid. On 9 March, a group of the conspirators, accompanied by Darnley, murdered Rizzio in front of the pregnant Mary at a dinner party in Holyrood Palace. Over the next two days, a disillusioned Darnley switched sides, and Mary received Moray at Holyrood. On the night of 11–12 March, Darnley and Mary escaped from the palace and took temporary refuge in Dunbar Castle before returning to Edinburgh on 18 March. The former rebels Lords Moray, Argyll and Glencairn were restored to the council.

Mary's son by Darnley, James, was born on 19 June 1566 in Edinburgh Castle, but the murder of Rizzio led inevitably to the breakdown of her marriage. In October 1566, while staying at Jedburgh in the Scottish Borders, Mary made a journey on horseback of at least four hours each way to visit the Earl of Bothwell at Hermitage Castle, where he lay ill from wounds sustained in a skirmish with border reivers. The ride was later used as evidence by Mary's enemies that the two were lovers, though no suspicions were voiced at the time and Mary had been accompanied by her councillors and guards. Immediately after her return to Jedburgh, she suffered a serious illness that included frequent vomiting, loss of sight, loss of speech, convulsions and periods of unconsciousness. She was thought to be near death or dying. Her recovery from 25 October onwards was credited to the skill of her French physicians. The cause of her illness is unknown; diagnoses include physical exhaustion and mental stress, haemorrhage of a gastric ulcer, and porphyria.

At Craigmillar Castle, near Edinburgh, at the end of November 1566, Mary and leading nobles held a meeting to discuss the "problem of Darnley". Divorce was discussed, but a bond was probably sworn between the lords present to remove Darnley by other means: "It was thought expedient and most profitable for the common wealth ... that such a young fool and proud tyrant should not reign or bear rule over them; ... that he should be put off by one way or another; and whosoever should take the deed in hand or do it, they should defend." Darnley feared for his safety, and after the baptism of his son at Stirling shortly before Christmas he went to Glasgow to stay on his father's estates. At the start of the journey, he was afflicted by a fever, possibly smallpox, syphilis, or the result of poison, and he remained ill for some weeks.

In late January 1567, Mary prompted her husband to return to Edinburgh. He recuperated from his illness in a house belonging to the brother of Sir James Balfour at the former abbey of Kirk o' Field, just within the city wall. Mary visited him daily, so that it appeared a reconciliation was in progress. On the night of 9–10 February 1567, Mary visited her husband in the early evening and then attended the wedding celebrations of a member of her household, Bastian Pagez. In the early hours of the morning, an explosion devastated Kirk o' Field, and Darnley was found dead in the garden, apparently smothered. There were no visible marks of strangulation or violence on the body. Bothwell, Moray, Secretary Maitland, the Earl of Morton and Mary herself were among those who came under suspicion. Elizabeth wrote to Mary of the rumours, "I should ill fulfil the office of a faithful cousin or an affectionate friend if I did not ... tell you what all the world is thinking. Men say that, instead of seizing the murderers, you are looking through your fingers while they escape; that you will not seek revenge on those who have done you so much pleasure, as though the deed would never have taken place had not the doers of it been assured of impunity. For myself, I beg you to believe that I would not harbour such a thought."

By the end of February, Bothwell was generally believed to be guilty of Darnley's assassination. Lennox, Darnley's father, demanded that Bothwell be tried before the Estates of Parliament, to which Mary agreed, but Lennox's request for a delay to gather evidence was denied. In the absence of Lennox, and with no evidence presented, Bothwell was acquitted after a seven-hour trial on 12 April. A week later, Bothwell managed to convince more than two dozen lords and bishops to sign the Ainslie Tavern Bond, in which they agreed to support his aim to marry the queen.

Between 21 and 23 April 1567, Mary visited her son at Stirling for the last time. On her way back to Edinburgh on 24 April, Mary was abducted, willingly or not, by Lord Bothwell and his men and taken to Dunbar Castle, where he may have raped her. On 6 May, Mary and Bothwell returned to Edinburgh and on 15 May, at either Holyrood Palace or Holyrood Abbey, they were married according to Protestant rites. Bothwell and his first wife, Jean Gordon, who was the sister of Lord Huntly, had divorced twelve days previously.

Originally Mary believed that many nobles supported her marriage, but relations quickly soured between the newly elevated Bothwell (created Duke of Orkney) and his former peers, and the marriage proved to be deeply unpopular. Catholics considered the marriage unlawful, since they did not recognise Bothwell's divorce or the validity of the Protestant service. Both Protestants and Catholics were shocked that Mary should marry the man accused of murdering her husband. The marriage was tempestuous, and Mary became despondent. Twenty-six Scottish peers, known as the confederate lords, turned against Mary and Bothwell, raising an army against them. Mary and Bothwell confronted the lords at Carberry Hill on 15 June, but there was no battle as Mary's forces dwindled away through desertion during negotiations. Bothwell was given safe passage from the field, and the lords took Mary to Edinburgh, where crowds of spectators denounced her as an adulteress and murderer. The following night, she was imprisoned in Loch Leven Castle, on an island in the middle of Loch Leven. Between 20 and 23 July, Mary miscarried twins. On 24 July, she was forced to abdicate in favour of her one-year-old son James. Moray was made regent, while Bothwell was driven into exile. He was imprisoned in Denmark, became insane and died in 1578.

On 2 May 1568, Mary escaped from Loch Leven Castle with the aid of George Douglas, brother of Sir William Douglas, the castle's owner. Managing to raise an army of 6,000 men, she met Moray's smaller forces at the Battle of Langside on 13 May. Defeated, she fled south; after spending the night at Dundrennan Abbey, she crossed the Solway Firth into England by fishing boat on 16 May. She landed at Workington in Cumberland in the north of England and stayed overnight at Workington Hall. On 18 May, local officials took her into protective custody at Carlisle Castle.

Mary apparently expected Elizabeth to help her regain her throne. Elizabeth was cautious, ordering an inquiry into the conduct of the confederate lords and the question of whether Mary was guilty of Darnley's murder. In mid-July 1568, English authorities moved Mary to Bolton Castle, because it was further from the Scottish border but not too close to London. A commission of inquiry, or conference as it was known, was held in York and later Westminster between October 1568 and January 1569. In Scotland, her supporters fought a civil war against Regent Moray and his successors.

As an anointed queen, Mary refused to acknowledge the power of any court to try her and refused to attend the inquiry at York personally (she sent representatives), but Elizabeth forbade her attendance anyway. As evidence against Mary, Moray presented the so-called casket letters—eight unsigned letters purportedly from Mary to Bothwell, two marriage contracts, and a love sonnet or sonnets said to have been found in a silver-gilt casket just less than one foot (30 cm) long, decorated with the monogram of King Francis II. Mary denied writing them, arguing that her handwriting was not difficult to imitate, and insisted they were forgeries. They are widely believed to be crucial as to whether Mary shares the guilt for Darnley's murder. The chair of the commission of inquiry, the Duke of Norfolk, described them as horrible letters and diverse fond ballads, and sent copies to Elizabeth, saying that if they were genuine they might prove Mary's guilt.

The authenticity of the casket letters has been the source of much controversy among historians. It is impossible now to prove either way. The originals, written in French, were probably destroyed in 1584 by Mary's son. The surviving copies, in French or translated into English, do not form a complete set. There are incomplete printed transcriptions in English, Scots, French, and Latin from the 1570s. Other documents scrutinised included Bothwell's divorce from Jean Gordon. Moray had sent a messenger in September to Dunbar to get a copy of the proceedings from the town's registers.

Mary's biographers, such as Antonia Fraser, Alison Weir, and John Guy, have come to the conclusion that either the documents were complete forgeries, or incriminating passages were inserted into genuine letters, or that the letters were written to Bothwell by some other person or by Mary to some other person. Guy points out that the letters are disjointed, and that the French language and grammar employed in the sonnets are too poor for a writer with Mary's education. But certain phrases of the letters (including verses in the style of Ronsard) and some characteristics of style are compatible with known writings by Mary.
The casket letters did not appear publicly until the Conference of 1568, although the Scottish privy council had seen them by December 1567. Mary had been forced to abdicate and held captive for the best part of a year in Scotland. The letters were never made public to support her imprisonment and forced abdication. Historian Jenny Wormald believes this reluctance on the part of the Scots to produce the letters, and their destruction in 1584, whatever their content, constitute proof that they contained real evidence against Mary, whereas Weir thinks it demonstrates the lords required time to fabricate them. At least some of Mary's contemporaries who saw the letters had no doubt that they were genuine. Among them was the Duke of Norfolk, who secretly conspired to marry Mary in the course of the commission, although he denied it when Elizabeth alluded to his marriage plans, saying "he meant never to marry with a person, where he could not be sure of his pillow".

The majority of the commissioners accepted the casket letters as genuine after a study of their contents and comparison of the penmanship with examples of Mary's handwriting. Elizabeth, as she had wished, concluded the inquiry with a verdict that nothing was proven, either against the confederate lords or Mary. For overriding political reasons, Elizabeth wished neither to convict nor acquit Mary of murder, and there was never any intention to proceed judicially; the conference was intended as a political exercise. In the end, Moray returned to Scotland as its regent, and Mary remained in custody in England. Elizabeth had succeeded in maintaining a Protestant government in Scotland, without either condemning or releasing her fellow sovereign. In Fraser's opinion, it was one of the strangest "trials" in legal history, ending with no finding of guilt against either party, one of whom was allowed to return home to Scotland while the other remained in custody.

On 26 January 1569, Mary was moved to Tutbury Castle and placed in the custody of the Earl of Shrewsbury and his formidable wife Bess of Hardwick. Elizabeth considered Mary's designs on the English throne to be a serious threat and so confined her to Shrewsbury's properties, including Tutbury, Sheffield Castle, Sheffield Manor Lodge, Wingfield Manor and Chatsworth House, all located in the interior of England halfway between Scotland and London, and distant from the sea. Mary was permitted her own domestic staff, which never numbered fewer than sixteen, and needed 30 carts to transport her belongings from house to house. Her chambers were decorated with fine tapestries and carpets, as well as her cloth of state on which she had the French phrase, "En ma fin est mon commencement" ("In my end lies my beginning"), embroidered. Her bedlinen was changed daily, and her own chefs prepared meals with a choice of 32 dishes served on silver plates. She was occasionally allowed outside under strict supervision, spent seven summers at the spa town of Buxton, and spent much of her time doing embroidery. Her health declined, perhaps through porphyria or lack of exercise, and by the 1580s she had severe rheumatism in her limbs, rendering her lame.

In May 1569, Elizabeth attempted to mediate the restoration of Mary in return for guarantees of the Protestant religion, but a convention held at Perth rejected the deal overwhelmingly. Norfolk continued to scheme for a marriage with Mary, and Elizabeth imprisoned him in the Tower of London between October 1569 and August 1570. Early the following year, Moray was assassinated. His death coincided with a rebellion in the North of England, led by Catholic earls, which persuaded Elizabeth that Mary was a threat. English troops intervened in the Scottish civil war, consolidating the power of the anti-Marian forces. Elizabeth's principal secretaries, Sir Francis Walsingham and William Cecil, Lord Burghley, watched Mary carefully with the aid of spies placed in her household.
In 1571, Cecil and Walsingham uncovered the Ridolfi Plot, which was a plan to replace Elizabeth with Mary with the help of Spanish troops and the Duke of Norfolk. Norfolk was executed, and the English Parliament introduced a bill barring Mary from the throne, to which Elizabeth refused to give royal assent. To discredit Mary, the casket letters were published in London. Plots centred on Mary continued. Pope Gregory XIII endorsed one plan in the latter half of the 1570s to marry her to the governor of the Low Countries and illegitimate half-brother of Philip II of Spain, John of Austria, who was supposed to organise the invasion of England from the Spanish Netherlands. After the Throckmorton Plot of 1583, Walsingham introduced the Bond of Association and the Act for the Queen's Safety, which sanctioned the killing of anyone who plotted against Elizabeth and aimed to prevent a putative successor from profiting from her murder.

In 1584, Mary proposed an "association" with her son, James. She announced that she was ready to stay in England, to renounce the Pope's bull of excommunication, and to retire, abandoning her pretensions to the English Crown. She also offered to join an offensive league against France. For Scotland, she proposed a general amnesty, agreed that James should marry with Elizabeth's knowledge, and agreed that there should be no change in religion. Her only condition was the immediate alleviation of the conditions of her captivity. James went along with the idea for a while but then rejected it and signed an alliance treaty with Elizabeth, abandoning his mother. Elizabeth also rejected the association, because she did not trust Mary to cease plotting against her during the negotiations.

In February 1585, William Parry was convicted of plotting to assassinate Elizabeth, without Mary's knowledge, although her agent Thomas Morgan was implicated. In April, Mary was placed in the stricter custody of Sir Amias Paulet, and at Christmas she was moved to a moated manor house at Chartley.

On 11 August 1586, after being implicated in the Babington Plot, Mary was arrested while out riding and taken to Tixall. In a successful attempt to entrap her, Walsingham had deliberately arranged for Mary's letters to be smuggled out of Chartley. Mary was misled into thinking her letters were secure, while in reality they were deciphered and read by Walsingham. From these letters it was clear that Mary had sanctioned the attempted assassination of Elizabeth. She was moved to Fotheringhay Castle in a four-day journey ending on 25 September, and in October was put on trial for treason under the Act for the Queen's Safety before a court of 36 noblemen, including Cecil, Shrewsbury, and Walsingham. Spirited in her defence, Mary denied the charges. She told her triers, "Look to your consciences and remember that the theatre of the whole world is wider than the kingdom of England". She protested that she had been denied the opportunity to review the evidence, that her papers had been removed from her, that she was denied access to legal counsel and that as a foreign anointed queen she had never been an English subject and thus could not be convicted of treason.

Mary was convicted on 25 October and sentenced to death with only one commissioner, Lord Zouche, expressing any form of dissent. Nevertheless, Elizabeth hesitated to order her execution, even in the face of pressure from the English Parliament to carry out the sentence. She was concerned that the killing of a queen set a discreditable precedent and was fearful of the consequences especially if, in retaliation, Mary's son, James, formed an alliance with the Catholic powers and invaded England. Elizabeth asked Paulet, Mary's final custodian, if he would contrive a clandestine way to "shorten the life" of Mary, which he refused to do on the grounds that he would not make "a shipwreck of my conscience, or leave so great a blot on my poor posterity". On 1 February 1587, Elizabeth signed the death warrant, and entrusted it to William Davison, a privy councillor. On 3 February, ten members of the Privy Council of England, having been summoned by Cecil without Elizabeth's knowledge, decided to carry out the sentence at once.

At Fotheringhay, on the evening of 7 February 1587, Mary was told she was to be executed the next morning. She spent the last hours of her life in prayer, distributing her belongings to her household, and writing her will and a letter to the King of France. The scaffold that was erected in the Great Hall was draped in black cloth. It was reached by two or three steps, and furnished with the block, a cushion for her to kneel on, and three stools, for her and the earls of Shrewsbury and Kent, who were there to witness the execution. The executioners (Bull and his assistant) knelt before her and asked forgiveness, as it was typical for the executioner to request the pardon of the one being put to death. Mary replied, "I forgive you with all my heart, for now, I hope, you shall make an end of all my troubles." Her servants, Jane Kennedy and Elizabeth Curle, and the executioners helped Mary remove her outer garments, revealing a velvet petticoat and a pair of sleeves in crimson brown, the liturgical colour of martyrdom in the Catholic Church, with a black satin bodice and black trimmings. As she disrobed Mary smiled and said she "never had such grooms before ... nor ever put off her clothes before such a company". She was blindfolded by Kennedy with a white veil embroidered in gold, knelt down on the cushion in front of the block, on which she positioned her head, and stretched out her arms. Her last words were, "In manus tuas, Domine, commendo spiritum meum" ("Into thy hands, O Lord, I commend my spirit").

Mary was not beheaded with a single strike. The first blow missed her neck and struck the back of her head. The second blow severed the neck, except for a small bit of sinew, which the executioner cut through using the axe. Afterwards, he held her head aloft and declared, "God save the Queen." At that moment, the auburn tresses in his hand turned out to be a wig and the head fell to the ground, revealing that Mary had very short, grey hair. Cecil's nephew, who was present at the execution, reported to his uncle that after her death "Her lips stirred up and down a quarter of an hour after her head was cut off" and that a small dog owned by the queen emerged from hiding among her skirts—though eye-witness Emanuel Tomascon does not include those details in his "exhaustive report". Items supposedly worn or carried by Mary at her execution are of doubtful provenance; contemporary accounts state that all her clothing, the block, and everything touched by her blood was burnt in the fireplace of the Great Hall to obstruct relic hunters.
When the news of the execution reached Elizabeth, she became indignant and asserted that Davison had disobeyed her instructions not to part with the warrant and that the Privy Council had acted without her authority. Elizabeth's vacillation and deliberately vague instructions gave her plausible deniability to attempt to avoid the direct stain of Mary's blood. Davison was arrested, thrown into the Tower of London, and found guilty of misprision. He was released nineteen months later after Cecil and Walsingham interceded on his behalf.

Mary's request to be buried in France was refused by Elizabeth. Her body was embalmed and left in a secure lead coffin until her burial, in a Protestant service, at Peterborough Cathedral in late July 1587. Her entrails, removed as part of the embalming process, were buried secretly within Fotheringhay Castle. Her body was exhumed in 1612, when her son, King James VI and I, ordered that she be reinterred in Westminster Abbey in a chapel opposite the tomb of Elizabeth. In 1867, her tomb was opened in an attempt to ascertain the resting place of James I; he was ultimately found with Henry VII, but many of her other descendants, including Elizabeth of Bohemia, Prince Rupert of the Rhine and the children of Anne, Queen of Great Britain, were interred in her vault.
Assessments of Mary in the sixteenth century divided between Protestant reformers such as George Buchanan and John Knox, who vilified her mercilessly, and Catholic apologists such as Adam Blackwood, who praised, defended and eulogised her. After the accession of James I in England, historian William Camden wrote an officially sanctioned biography that drew from original documents. It condemned Buchanan's work as an invention, and "emphasized Mary's evil fortunes rather than her evil character". Differing interpretations persisted into the eighteenth century: William Robertson and David Hume argued that the casket letters were genuine and that Mary was guilty of adultery and murder, while William Tytler argued the reverse. In the latter half of the twentieth century, the work of Antonia Fraser was acclaimed as "more objective ... free from the excesses of adulation or attack" that had characterised older biographies, and her contemporaries Gordon Donaldson and Ian B. Cowan also produced more balanced works. Historian Jenny Wormald concluded that Mary was a tragic failure, who was unable to cope with the demands placed on her, but hers was a rare dissenting view in a post-Fraser tradition that Mary was a pawn in the hands of scheming noblemen. There is no concrete proof of her complicity in Darnley's murder or of a conspiracy with Bothwell. Such accusations rest on assumptions, and Buchanan's biography is today discredited as "almost complete fantasy". Mary's courage at her execution helped establish her popular image as the heroic victim in a dramatic tragedy.





</doc>
<doc id="20604" url="https://en.wikipedia.org/wiki?curid=20604" title="Macbeth, King of Scotland">
Macbeth, King of Scotland

Macbeth (Medieval Gaelic: "Mac Bethad mac Findlaích"; Modern Gaelic: "MacBheatha mac Fhionnlaigh"; nicknamed "", "the Red King"; – 15 August 1057) was King of Scots from 1040 until his death. He ruled over only a portion of present-day Scotland.

Little is known about Macbeth's early life, although he was the son of Findláech of Moray and may have been a grandson of Malcolm II. He became Mormaer of Moray – a semi-autonomous lordship – in 1032, and was probably responsible for the death of the previous mormaer, Gille Coemgáin. He subsequently married Gille Coemgáin's widow, Gruoch, although they had no children together.

In 1040, Duncan I launched an attack into Moray and was killed in action by Macbeth's troops. Macbeth succeeded him as King of Alba, apparently with little opposition. His 17-year reign was mostly peaceful, although in 1054 he was faced with an English invasion, led by Siward, Earl of Northumbria, on behalf of Edward the Confessor. Macbeth was killed at the Battle of Lumphanan in 1057 by forces loyal to the future Malcolm III. He was buried on Iona, the traditional resting place of Scottish kings.

Macbeth was initially succeeded by his stepson Lulach, but Lulach ruled for only a few months before also being killed by Malcolm III, whose descendants would rule Scotland until the late 13th century. Macbeth is today best known as the main character of William Shakespeare's tragedy "Macbeth" and the many works it has inspired. However, Shakespeare's Macbeth is based on "Holinshed's Chronicles" (published in 1577) and is not historically accurate.

Macbeth's full name in Medieval Gaelic was '. This is realised as ' in Modern Gaelic, and anglicised as Macbeth MacFinlay (also spelled Findlay, Findley, or Finley). The name "Mac Bethad", from which the anglicised "MacBeth" is derived, means "son of life". Although it has the appearance of a Gaelic patronymic it does not have any meaning of filiation but instead carries an implication of "righteous man" or "religious man". An alternative proposed derivation is that it is a corruption of "macc-bethad" meaning "one of the elect".

Some sources make Macbeth a grandson of King Malcolm II and thus a cousin to Duncan I, whom he succeeded. He was possibly also a cousin to Thorfinn the Mighty, Earl of Orkney and Caithness. Nigel Tranter, in his novel "Macbeth the King", went so far as to portray Macbeth as Thorfinn's half-brother. However, this is speculation arising from the lack of historical certainty regarding the number of daughters Malcolm had.

When Cnut the Great came north in 1031 to accept the submission of King Malcolm II, Macbeth too submitted to him:
Malcolm II's grandson Duncan (Donnchad mac Crínáin), later King Duncan I, was acclaimed as king of Alba on 30 November 1034, apparently without opposition. Duncan appears to have been "tánaise ríg", the king in waiting, so that far from being an abandonment of tanistry, as has sometimes been argued, his kingship was a vindication of the practice. Previous successions had involved strife between various "rígdomna" men of royal blood. Far from being the aged King Duncan of Shakespeare's play, the real King Duncan was a young man in 1034, and even at his death in 1040 his youthfulness is remarked upon.

Duncan's early reign was apparently uneventful. His later reign, in line with his description as "the man of many sorrows" in the "Prophecy of Berchán", was not successful. In 1039, Strathclyde was attacked by the Northumbrians, and a retaliatory raid led by Duncan against Durham turned into a disaster. Duncan survived the defeat, but the following year he led an army north into Moray, Macbeth's domain, apparently on a punitive expedition against Moray. There he was killed in action, at Bothnagowan, now Pitgaveny, near Elgin, by the men of Moray led by Macbeth, probably on 14 August 1040.

On Duncan's death, Macbeth became king. No resistance is known at that time, but it would have been entirely normal if his reign were not universally accepted. In 1045, Duncan's father Crínán of Dunkeld (a scion of the Scottish branch of the Cenél Conaill and Hereditary Abbot of Iona) was killed in a battle between two Scottish armies.

John of Fordun wrote that Duncan's wife fled Scotland, taking her children, including the future kings Malcolm III (Máel Coluim mac Donnchada) and Donald III (Domnall Bán mac Donnchada, or Donalbane) with her. On the basis of the author's beliefs as to whom Duncan married, various places of exile, Northumbria and Orkney among them, have been proposed. However, E. William Robertson proposes the safest place for Duncan's widow and her children would be with her or Duncan's kin and supporters in Atholl.

After the defeat of Crínán, Macbeth was evidently unchallenged. Marianus Scotus tells how the king made a pilgrimage to Rome in 1050, where, Marianus says, he gave money to the poor as if it were seed.

The "Orkneyinga Saga" says that a dispute between Thorfinn Sigurdsson, Earl of Orkney, and Karl Hundason began when Karl Hundason became "King of Scots" and claimed Caithness. The identity of Karl Hundason, unknown to Scots and Irish sources, has long been a matter of dispute, and it is far from clear that the matter is settled. The most common assumption is that Karl Hundason was an insulting byname (Old Norse for "Churl, son of a Dog") given to Macbeth by his enemies. William Forbes Skene's suggestion that he was Duncan I of Scotland has been revived in recent years. Lastly, the idea that the whole affair is a poetic invention has been raised.

According to the "Orkneyinga Saga", in the war which followed, Thorfinn defeated Karl in a sea-battle off Deerness at the east end of the Orkney Mainland. Then Karl's nephew Mutatan or Muddan, appointed to rule Caithness for him, was killed at Thurso by Thorkel the Fosterer. Finally, a great battle at Tarbat Ness on the south side of the Dornoch Firth ended with Karl defeated and fugitive or dead. Thorfinn, the saga says, then marched south through Scotland as far as Fife, burning and plundering as he passed. A later note in the saga claims that Thorfinn won nine Scottish earldoms.

Whoever Karl Hundason may have been, it appears that the saga is reporting a local conflict with a Scots ruler of Moray or Ross:
In 1052, Macbeth was involved indirectly in the strife in the Kingdom of England between Godwin, Earl of Wessex and Edward the Confessor when he received a number of Norman exiles from England in his court, perhaps becoming the first king of Scots to introduce feudalism to Scotland. In 1054, Edward's Earl of Northumbria, Siward, led a very large invasion of Scotland (Duncan's widow and Malcolm's mother, Suthed, was Northumbrian-born; it is probable but not proven that there was a family tie between Siward and Malcolm). The campaign led to a bloody battle in which the "Annals of Ulster" reported 3,000 Scots and 1,500 English dead, which can be taken as meaning very many on both sides, and one of Siward's sons and a son-in-law were among the dead. The result of the invasion was that one Máel Coluim, "son of the king of the Cumbrians" (not to be confused with Máel Coluim mac Donnchada, the future Malcolm III of Scotland) was restored to his throne, i.e., as ruler of the kingdom of Strathclyde. It may be that the events of 1054 are responsible for the idea, which appears in Shakespeare's play, that Malcolm III was put in power by the English.

Macbeth did not survive the English invasion for long, for he was defeated and mortally wounded or killed by the future Malcolm III ("King Malcolm "Ceann-mor"", son of Duncan I) on the north side of the Mounth in 1057, after retreating with his men over the Cairnamounth Pass to take his last stand at the battle at Lumphanan. "The Prophecy of Berchán" has it that he was wounded and died at Scone, sixty miles to the south, some days later. Macbeth's stepson Lulach was installed as king soon after.

Unlike later writers, no near contemporary source remarks on Macbeth as a tyrant. The "Duan Albanach," which survives in a form dating to the reign of Malcolm III, calls him "Mac Bethad the renowned". "The Prophecy of Berchán", a verse history which purports to be a prophecy, describes him as "the generous king of Fortriu", and says:

Macbeth's life, like that of King Duncan I, had progressed far towards legend by the end of the 14th century, when John of Fordun and Andrew of Wyntoun wrote their histories. Hector Boece, Walter Bower, and George Buchanan all contributed to the legend.

In Shakespeare's play, which is based mainly upon Raphael Holinshed's account, Macbeth is initially a valorous and loyal general to the elderly King Duncan. After being flattered by Three Witches and his own wife, Macbeth rationalizes that murdering his king and usurping the throne is the right thing to do. Ultimately, however, the prophecies of the witches prove misleading, and Macbeth alienates the nobility of Scotland and is defeated in battle by Prince Malcolm. As the King's armies disintegrate he encounters Macduff, a refugee nobleman whose wife and children had earlier been murdered by Macbeth's death squads. Upon realizing that he will die if he duels Macduff, Macbeth at first refuses to do so. But when Macduff explains that if Macbeth surrenders he will be subjected to ridicule by his former subjects, Macbeth vows, "I will not yield to kiss the ground before young Malcolm's feet, to be baited by a rabble's curse." He chooses instead to fight Macduff to the death. Macbeth is then slain and beheaded and the play ends with Prince Malcolm planning his coronation at Scone.

The likely reason for Shakespeare's unflattering depiction of Macbeth is that King James VI and I was descended from Malcolm III via the House of Bruce and his own House of Stewart, whereas Macbeth's line died out with the death of Lulach six months after his step-father. King James was also thought to be a descendant of Banquo through Walter Stewart, 6th High Steward of Scotland.
In a 1959 essay, Boris Pasternak compared Shakespeare's "Macbeth" to Raskolnikov, the protagonist of "Crime and Punishment" by Fyodor Dostoevsky. Pasternak explained that neither character begins as a murderer, but becomes one by a set of faulty rationalizations and a belief that he is above the law.

Lady Macbeth has gained fame along the way. In his 1865 novel "Lady Macbeth of the Mtsensk District", Nikolai Leskov updated "The Tragedy of Macbeth" so that it takes place among the Imperial Russian merchant class. In an ironic twist, however, Leskov reverses the gender roles – the woman is the murderer and the man is the instigator. Leskov's novel was the basis for Dmitri Shostakovich's 1936 opera of the same name.

In modern times, Dorothy Dunnett's novel "King Hereafter" aims to portray a historical Macbeth, but proposes that Macbeth and his rival and sometime ally Thorfinn of Orkney are one and the same (Thorfinn is his birth name and Macbeth his baptismal name). John Cargill Thompson's play "Macbeth Speaks 1997", a reworking of his earlier "Macbeth Speaks", is a monologue delivered by the historical Macbeth, aware of what Shakespeare and posterity have done to him. Scottish author Nigel Tranter based one of his historical novels, "MacBeth the King", on the historical figure. David Greig's 2010 play "Dunsinane" takes Macbeth's downfall at Dunsinane as its starting point, with his just-ended reign portrayed as long and stable in contrast to Malcolm's. British Touring Shakespeare also produced in 2010 "A Season Before the Tragedy of Macbeth" by dramatist Gloria Carreño describing events from the murder of "Lord Gillecomgain", Gruoch Macbeth's first husband, to the fateful letter in the first act of Shakespeare's tragedy

Macbeth appears as a character in the television series "Gargoyles" with the Gargoyle Demona playing a crucial role in both his rise and fall as King of Scotland. He was voiced by John Rhys-Davies.



</doc>
<doc id="20606" url="https://en.wikipedia.org/wiki?curid=20606" title="Millbridge, Plymouth">
Millbridge, Plymouth

Millbridge is a small neighbourhood of Plymouth, on the boundary of what used to be the towns of Plymouth and Devonport, in the English county of Devon.

What was originally a self-standing village (which has now been subsumed within the city) lies to the north of the toll bridge, originally built by Sir Piers Edgcumbe in 1525, that crossed what used to be the Deadlake or Stonehouse Creek, to the west of Pennycomequick, the south of Stoke village and to the east of Stoke Church. It derives its name from the old toll bridge (adjacent to a naval saw mill) across the creek between Eldad Hill and Molesworth Road, at one time the principal link between Plymouth and Devonport. The creek to the east of the bridge was filled in with material from the quarries at Cattedown and Oreston during the late 1890s and the ground created became a municipal park, Victoria Park, which was officially opened in 1903. The remainder of the creek to the west of Millbridge, up to Stonehouse Bridge and Pool, was filled in and by 1972 the whole area had been developed as rugby pitches. These pitches are often used by Devonport High School for Boys and the Old Boys RFC.


</doc>
<doc id="20607" url="https://en.wikipedia.org/wiki?curid=20607" title="ML (programming language)">
ML (programming language)

ML ("Meta Language") is a general-purpose functional programming language. It has roots in Lisp, and has been characterized as "Lisp with types". ML is a statically-scoped functional programming language like Scheme. It is known for its use of the polymorphic Hindley–Milner type system, which automatically assigns the types of most expressions without requiring explicit type annotations, and ensures type safetythere is a formal proof that a well-typed ML program does not cause runtime type errors. ML provides pattern matching for function arguments, garbage collection, imperative programming, call-by-value and currying. It is used heavily in programming language research and is one of the few languages to be completely specified and verified using formal semantics. Its types and pattern matching make it well-suited and commonly used to operate on other formal languages, such as in compiler writing, automated theorem proving, and formal verification.

Features of ML include a call-by-value evaluation strategy, first-class functions, automatic memory management through garbage collection, parametric polymorphism, static typing, type inference, algebraic data types, pattern matching, and exception handling. ML uses static scoping rules.

ML can be referred to as an "impure" functional language, because although it encourages functional programming, it does allow side-effects (like languages such as Lisp, but unlike a purely functional language such as Haskell). Like most programming languages, ML uses eager evaluation, meaning that all subexpressions are always evaluated, though lazy evaluation can be achieved through the use of closures. Thus one can create and use infinite streams as in Haskell, but their expression is indirect.

ML's strengths are mostly applied in language design and manipulation (compilers, analyzers, theorem provers), but it is a general-purpose language also used in bioinformatics, and financial systems.

ML was developed by Robin Milner and others in the early 1970s at the University of Edinburgh, whose syntax is inspired by ISWIM. Historically, ML was conceived to develop proof tactics in the LCF theorem prover (whose language, "pplambda", a combination of the first-order predicate calculus and the simply-typed polymorphic lambda calculus, had ML as its metalanguage).

Today there are several languages in the ML family; the three most prominent are Standard ML (SML), OCaml and F#. Ideas from ML have influenced numerous other languages, like Haskell, Cyclone, Nemerle, ATS, and Elm.

The following examples use the syntax of Standard ML. Other ML dialects such as OCaml and F# differ in small ways.

The factorial function expressed as pure ML:

This describes the factorial as a recursive function, with a single terminating base case. It is similar to the descriptions of factorials found in mathematics textbooks. Much of ML code is similar to mathematics in facility and syntax.

Part of the definition shown is optional, and describes the "types" of this function. The notation E : t can be read as "expression E has type t". For instance, the argument n is assigned type "integer" (int), and fac (n : int), the result of applying fac to the integer n, also has type integer. The function fac as a whole then has type "function from integer to integer" (int -> int), that is, fac accepts an integer as an argument and returns an integer result. Thanks to type inference, the type annotations can be omitted and will be derived by the compiler. Rewritten without the type annotations, the example looks like:

The function also relies on pattern matching, an important part of ML programming. Note that parameters of a function are not necessarily in parentheses but separated by spaces. When the function's argument is 0 (zero) it will return the integer 1 (one). For all other cases the second line is tried. This is the recursion, and executes the function again until the base case is reached.

This implementation of the factorial function is not guaranteed to terminate, since a negative argument causes an infinite descending chain of recursive calls. A more robust implementation would check for a nonnegative argument before recursing, as follows:

The problematic case (when n is negative) demonstrates a use of ML's exception system.

The function can be improved further by writing its inner loop in a tail-recursive style, such that the call stack need not grow in proportion to the number of function calls. This is achieved by adding an extra, "accumulator", parameter to the inner function. At last, we arrive at

The following function "reverses" the elements in a list. More precisely, it returns a new list whose elements are in reverse order compared to the given list.

This implementation of reverse, while correct and clear, is inefficient, requiring quadratic time for execution. The function can be rewritten to execute in linear time in the following more efficient, though less easy-to-read, style:

Notably, this function is an example of parametric polymorphism. That is, it can consume lists whose elements have any type, and return lists of the same type.

Modules are ML's system for structuring large projects and libraries. A module consists of a signature file and one or more structure files. The signature file specifies the API to be implemented (like a C header file, or Java interface file). The structure implements the signature (like a C source file or Java class file). For example, the following define an Arithmetic signature and an implementation of it using Rational numbers:

These are imported into the interpreter by the 'use' command. Interaction with the implementation is only allowed via the signature functions, for example it is not possible to create a 'Rat' data object directly via this code. The 'structure' block hides all the implementation detail from outside.

ML's standard libraries are implemented as modules in this way.





</doc>
<doc id="20608" url="https://en.wikipedia.org/wiki?curid=20608" title="Messier object">
Messier object

The Messier objects are a set of 110 astronomical objects catalogued by the French astronomer Charles Messier in his "Catalogue des Nébuleuses et des Amas d'Étoiles" ("Catalogue of Nebulae and Star Clusters"). 
Because Messier was only interested in finding comets, he created a list of non-comet objects that frustrated his hunt for them. The compilation of this list, in collaboration with his assistant Pierre Méchain, is known as "the Messier catalogue." This catalogue of objects is one of the most famous lists of astronomical objects, and many Messier objects are still referenced by their Messier number. 
The catalogue includes some astronomical objects that can be observed from Earth's Northern Hemisphere such as deep-sky objects, a characteristic which makes the Messier objects extremely popular targets for amateur astronomers.

A preliminary version first appeared in the "Memoirs" of the French Academy of Sciences in 1771.
The first version of Messier's catalogue contained 45 objects and was published in 1774 in the journal of the French Academy of Sciences in Paris. Eighteen of the objects were discovered by Messier, the rest being previously observed by other astronomers.
By 1780 the catalogue had increased to 80 objects. The final version of the catalogue containing 103 objects was published in 1781 in the "Connaissance des Temps" for the year 1784.
However, due to what was thought for a long time to be the incorrect addition of Messier 102, the total number remained 102. Other astronomers, using side notes in Messier's texts, eventually filled out the list up to 110 objects.

The catalogue consists of a diverse range of astronomical objects, from star clusters and nebulae to galaxies. For example, Messier 1 is a supernova remnant, known as the Crab Nebula, and the great spiral Andromeda Galaxy is M31. Many further inclusions followed in the next century when the first addition came from Nicolas Camille Flammarion in 1921, who added Messier 104 after finding Messier's side note in his 1781 edition exemplar of the catalogue. M105 to M107 were added by Helen Sawyer Hogg in 1947, M108 and M109 by Owen Gingerich in 1960, and M110 by Kenneth Glyn Jones in 1967.

The first edition of 1771 covered 45 objects numbered M1 to M45. The total list published by Messier in 1781 contained 103 objects, but the list was expanded through successive additions by other astronomers, motivated by notes in Messier's and Méchain's texts indicating that at least one of them knew of the additional objects. The first such addition came from Nicolas Camille Flammarion in 1921, who added Messier 104 after finding a note Messier made in a copy of the 1781 edition of the catalogue. M105 to M107 were added by Helen Sawyer Hogg in 1947, M108 and M109 by Owen Gingerich in 1960, and M110 by Kenneth Glyn Jones in 1967. M102 was observed by Méchain, who communicated his notes to Messier. Méchain later concluded that this object was simply a re-observation of M101, though some sources suggest that the object Méchain observed was the galaxy NGC 5866 and identify that as M102.

Messier's final catalogue was included in the "Connaissance des Temps pour l'Année 1784" ("Knowledge of Time"; published in 1781), the French official yearly publication of astronomical ephemerides.

Messier lived and did his astronomical work at the Hôtel de Cluny (now the Musée national du Moyen Âge), in Paris, France. The list he compiled contains only objects found in the sky area he could observe: from the north celestial pole to a celestial latitude of about −35.7°. He did not observe or list objects visible only from farther south, such as the Large and Small Magellanic Clouds.

The Messier catalogue comprises nearly all the most spectacular examples of the five types of deep-sky object – diffuse nebulae, planetary nebulae, open clusters, globular clusters, and galaxies – visible from European latitudes. Furthermore, almost all of the Messier objects are among the closest to Earth in their respective classes, which makes them heavily studied with professional class instruments that today can resolve very small and visually spectacular details in them. A summary of the astrophysics of each Messier object can be found in the "Concise Catalog of Deep-sky Objects."

Since these objects could be observed visually with the relatively small-aperture refracting telescope (approximately 100 mm, or 4 inches) used by Messier to study the sky, they are among the brightest and thus most attractive astronomical objects (popularly called deep-sky objects) observable from Earth, and are popular targets for visual study and astrophotography available to modern amateur astronomers using larger aperture equipment. In early spring, astronomers sometimes gather for "Messier marathons", when all of the objects can be viewed over a single night.



</doc>
<doc id="20609" url="https://en.wikipedia.org/wiki?curid=20609" title="Mambo (music)">
Mambo (music)

Mambo is a genre of Cuban dance music pioneered by the charanga Arcaño y sus Maravillas in the late 1930s and later popularized in the big band style by Pérez Prado. It originated as a syncopated form of the danzón, known as danzón-mambo, with a final, improvised section, which incorporated the "guajeos" typical of son cubano (also known as "montunos"). These "guajeos" became the essence of the genre when it was played by big bands, which did not perform the traditional sections of the danzón and instead leaned towards swing and jazz. By the late 1940s and early 1950s, mambo had become a "dance craze" in the United States as its associated dance took over the East Coast thanks to Pérez Prado, Tito Puente, Tito Rodríguez and others. In the mid-1950s, a slower ballroom style, also derived from the danzón, cha-cha-cha, replaced mambo as the most popular dance genre in North America. Nonetheless, mambo continued to enjoy some degree of popularity into the 1960s and new derivative styles appeared, such as dengue; by the 1970s it had been largely incorporated into salsa.

The earliest roots of mambo can be traced to the "danzón de nuevo ritmo" (danzón with a new rhythm), later known as danzón-mambo, made popular by the orchestra Arcaño y sus Maravillas conducted by flautist Antonio Arcaño. 

Orestes López and his brother Israel López "Cachao", main composers of the Maravillas, were the first to denominate a final upbeat, improvised section of the popular Cuban danzón as a "mambo". This innovation a key step in the process of evolution of the danzón, which over the years had progressively lost its structural rigidity to the benefit of musicians and dancers alike. Prior to the "danzón de nuevo ritmo", in 1910, José Urfé had first added a montuno (typical son improvised closing section) as a final part of his composition "El bombín de Barreto". This was a swinging section consisting of a repeated musical phrase, which introduced some elements of the son into the danzón. During the mid-to-late 1930s, some members of the Arcaño group were saying "vamos a mambear" ("let's mambo") when referring to the montuno or final improvisation of the danzón. It was Arcaño's cellist, Orestes López, who created the first danzón called "Mambo" (1938). In this piece, some syncopated motives taken from the son style were combined with improvised flute passages.

Antonio Arcaño described the mambo as follows: "Mambo is a type of syncopated "montuno" that possesses the rhythmic charm, informality and eloquence of the Cuban people. The pianist attacks the mambo, the flute picks it up and improvises, the violin executes rhythmic chords in double stops, the double bass inserts a "tumbao", the "timbalero" plays the cowbell, the "güiro" scrapes and plays the "maracas" rhythm, the indispensable "tumba" (conga drum) reaffirms the bass "tumbao" and strengthens the "timbal"."

Dámaso Pérez Prado, a pianist and arranger from Matanzas, Cuba, established his residence in Havana at the beginning of the 1940s and began to work at night clubs and orchestras, such as Paulina Alvarez's and Casino de La Playa. In 1949 he traveled to Mexico looking for job opportunities and achieved great success with a new style, to which he assigned a name that had been already used by Antonio Arcaño, the "mambo".

Perez Prado's style differed from the previous mambo concept. The new style possessed a greater influence from North-American jazz, and an expanded instrumentation consisting of four to five trumpets, four to five saxophones, double bass, drums, maracas, cowbell, congas and bongoes. This new mambo included a catchy counterpoint between the trumpets and the saxophones that induced the body to move along with the rhythm, stimulated at the end of each musical phrase by a characteristic deep throat sound expression.

Because his music was aimed at an audience that lived primarily outside Cuba, Pérez Prado used a large number of international influences, especially North-American, in his arrangements. This is evident in his arrangements of songs such as "Mambo Rock", "Patricia" and "Tequila", where he uses a triple meter U.S. "swing" rhythm fused with elements from Cuban rumba and son. Pérez Prado's repertoire included numerous international pieces such as "Cerezo Rosa", "María Bonita", "Tea For Two", "La Bikina", "Cuando Calienta El Sol", "Malagueña" and "En Un Pueblito Español", among many others.

Famous Cuban singer Beny Moré also lived in Mexico between 1945 and 1952. He composed and recorded some mambos there with Mexican orchestras, especially the one led by Rafael de Paz; they recorded "Yiri Yiri Bon", "La Culebra", "Mata Siguaraya", "Solamente Una Vez" and "Bonito Y Sabroso". Benny and Perez Prado recorded 28 mambo songs including "La Múcura", "Rabo Y Oreja", and "Pachito E'ché". At this time Benny also recorded with the orchestra of Jesús "Chucho" Rodríguez. 

Prado's recordings were meant for the Latin American and U.S. "latino" markets, but some of his most celebrated mambos, such as "Mambo No. 5" and "Que Rico El Mambo", quickly crossed over to a wider U.S. audience.

Mambo arrived in 1947 and mambo music and dance became popular soon. Recording companies began to use "mambo" to label their records and advertisements for mambo dance lessons were in local newspapers. New York City had made mambo a transnational popular cultural phenomenon. In New York the mambo was played in a high-strung, sophisticated way that had the Palladium Ballroom, the famous Broadway dance-hall, jumping. The Ballroom soon proclaimed itself the "temple of mambo", for the city's best dancers—the Mambo Aces, "Killer Joe" Piro, Augie and Margo Rodriguez. Augie and Margo were still dancing 50 years later (2006) in Las Vegas.

Some of New York's biggest mambo dancers and bands of the 1950s included: Augie & Margo, Michael Terrace & Elita, Carmen Cruz & Gene Ortiz, Larry Selon & Vera Rodríguez, Mambo Aces(Anibal Vasquez and Samson Batalla), Killer Joe Piro, Paulito and Lilon, Louie Maquina, Pedro Aguilar ("Cuban Pete"), Machito, Tito Rodríguez, Jose Curbelo, Akohh, and Noro Morales.





</doc>
<doc id="20610" url="https://en.wikipedia.org/wiki?curid=20610" title="Montoneros">
Montoneros

Montoneros () was an Argentine leftist urban guerrilla group, active during the 1960s and 1970s. The name is an allusion to the 19th-century cavalry militias called Montoneras, who fought for the Partido Federal during the Argentine Civil Wars.

After Juan Perón's return from 18 years of exile and the 1973 Ezeiza massacre, which marked the definitive split between left and right-wing Peronism, the president expelled the Montoneros from the Justicialist party in May 1974. The group was completely destroyed during the Dirty War.

In Argentina, left-wing guerrillas arose in response to state terror. Some engaged in kidnapping and violence in their opposition to right-wing dictatorships in Latin America during the 1970s. The Montañeros began as a self-described Christian, nationalist, and socialist group; but as time passed the socialist element eclipsed the Christian. Giussani claims that the Montoneros maintained that democracies were a complex masquerade that concealed fascist governments and delayed class struggle. Their attacks sought to force the governments to give up such pretensions and operate openly as fascist governments, expecting that in such a scenario the people would then support the guerrillas. This doctrine did not work as intended: people despised the military dictatorships, but some did not see the guerrillas as the enemies of the dictatorships, but rather as a contributing cause to the government's repression. The projected class struggle never took place, chiefly because of the U.S.-backed military dictatorship's repression of all dissent.

Although Juan Perón encouraged the actions of José López Rega, supported the right-wing unionists and denied preferential promotions to the Montoneros, they thought that his actions were simply a strategic masquerade. Some believed that Perón supported the Montoneros' projects. Perón expelled the group from Plaza de Mayo and outlined the government's counter-insurgency that decimated the guerrillas. Some surviving Montoneros still acknowledge Perón as their leader. Shortly after his return to Argentina, however, Peron moved to the Right and insulted all leftists, prompting the Montoneros to go underground.

The Montoneros formed around 1970 out of a confluence of Roman Catholic groups, university students in social sciences, and leftist supporters of Juan Domingo Perón. "The Montoneros took their name from the pejorative term used by the 19th-century elite to discredit the mounted followers of the popular caudillos." Montonera referred to the raiding parties composed by Native Americans in Argentina, and the spear in the Montoneros seal refers to this inspiration.

The Montoneros initiated a campaign to destabilise by force the regime supported by the U.S., which had trained Argentinian and other Latin American dictators via the School of the Americas.

In 1970, as retribution for the June 1956 León Suárez massacre and Juan José Valle's execution, the Montoneros kidnapped and executed former dictator Pedro Eugenio Aramburu (1955–1958) and other collaborators. In November 1971, in solidarity with militant car workers, Montoneros took over a car manufacturing plant in Caseros, sprayed 38 Fiats with petrol, and set them afire.
On 26 July 1972, they set off explosives in the Plaza de San Isidro in Buenos Aires, which injured three policemen and killed one fireman (Carlos Adrián Ayala), who died of wounds two days later.
That same day, a policeman (Agent Ramón González) is shot dead after intercepting a vehicle when the two male and two female MPM guerrillas inside draw their guns and open fire on the police vehicle. 

In April 1973, Colonel Héctor Irabarren, head of the 3rd Army Corps' Intelligence Service, was killed when resisting a kidnap attempt by the Mariano Pojadas and Susana Lesgart platoons of the Montoneros.

On 17 October 1972, a powerful bomb detonated inside the Sheraton Hotel in Buenos Aires, to the horror of nearly 700 guests, killing a Canadian woman (Lois Crozier, travel agent from West Vancouver) and gravely wounding her husband Gerry as he slept. The Montoneros and the Revolutionary Armed Forces later claimed responsibility for the attack.

On 11 March 1973, Argentina held general elections for the first time in ten years. Perón loyalist Héctor Cámpora became president and Perón returned from Spain. In a controversial move, he released all left-wing guerrillas held captive at the time in Argentina.

On 21 February 1974, the Montoneros killed Teodoro Ponce, a right-wing Peronist labour leader in Rosario. He had sought refuge in a local business after being shot at while driving by a carload of masked gunmen. One of the gunmen who got out of the car shot him dead while he lay on the floor and also shot a woman, who screamed out, "Murderer."

In May 1974, Perón expelled the Montoneros from the Justicialist movement. The Montoneros waited until after the death of Perón in July 1974 to react. They claimed to have the "social revolutionary vision of authentic Peronism" and started guerrilla operations against the government. The more radically right-wing factions quickly took control of the government; Isabel Perón, president since Juan Perón's death, was essentially a figurehead under the influence of Rega.

On 15 July 1974, Montoneros assassinated Arturo Mor Roig, a former foreign minister. On 17 July, they murdered David Kraiselburd, journalist and editor-in-chief of "El Día" newspaper, in the Manuel B. Gonnet suburb of Buenos Aires after an exchange of fire with police.

In September, in order to finance their operations, they kidnapped the two brothers of the Bunge and Born family business. Some 20 urban guerrillas dressed as policemen shot dead a bodyguard and chauffeur and diverted traffic in this well-orchestrated ambush. Some 30 militants and sympathisers among the civilian population provided safe houses to the guerrillas and a means to escape. They demanded and received a ransom of $60 million in cash, as well as $1.2 million worth of food and clothing to be given to the poor.

Under López Rega's orders, the Triple A began kidnapping, and killing members of Montoneros and the People's Revolutionary Army (ERP), as well as other leftist militant groups. They expanded their attacks to anyone considered a leftist subversive or sympathiser, such as these groups' deputies or lawyers.

The Montoneros and the ERP in turn attacked business and political figures throughout Argentina, and raided military bases for weapons and explosives. The Montoneros killed executives from General Motors, Ford and Chrysler. On 16 September 1974, about 40 Montoneros bombs exploded throughout Argentina. They targeted both foreign companies and commemorative ceremonies of the Revolucion Libertadora, the military revolt that had ended Juan Perón's first term as president on 16 September 1955. Targets included three Ford showrooms; Peugeot and IKA-Renault showrooms; Goodyear and Firestone tyre distributors, the pharmaceutical manufacturers Riker and Eli Lilly, the Union Carbide Battery Company, the Bank of Boston, Chase Manhattan Bank, the Xerox Corporation, and the soft drink companies, Coca-Cola and Pepsi-Cola. The Peronist guerrillas also held up at gunpoint two trains in a Buenos Aires suburb on 16 September. The Montoneros discouraged foreign investment more directly by blowing up the homes of their executives. For example, in 1975 the homes of five executives of Lazar Laboratories were bombed in the suburb of La Plata in Buenos Aires. The violence was widespread.

On 7 February, four carloads of Montoneros intercepted the car driven by Antonio Muscat, a manager of the Bunge y Born firm, and shot him dead in the presence of his daughter. On 14 February 1975, Montoneros killed Hipólito Acuña, a politician, as he parked his car outside his home in the city of Santa Fe.
On 18 February, Montoneros gunmen killed Félix Villafañe of the FITAM S.A. workers union, in the presence of his wife in the suburb of San Isidro in Buenos Aires. On 22 February 1975, in an ambush in the Lomas de Zamora suburb of Buenos Aires, three policemen (First Sergeant Nicolás Cardozo, Corporal Roberto Roque Fredes and Constables Eugenio Rodriguez and Abel Pascuzzi) were killed after their patrol car came under fire from Montoneros guerrillas. On 26 February 1975, the Montoneros kidnapped 62-year-old John Patrick Egan, a U.S. consular agent in the city of Córdoba, executing him two days later. That same day, they killed three policemen in another ambush by urban guerrillas in Buenos Aires, and an army conscript in Tucumán province was reported to have been killed in action. On 5 March 1975, a Montoneros bomb detonated in the underground parking at Plaza Colón of the Argentine Army High Command; a garbage truck driver (Alberto Blas García) was killed and 28 others were wounded, including four colonels and 18 other ranks. In early June 1975, Montoneros guerrillas murdered executives David Bargut and Raul Amelong of the Acindar steel firm in Rosario, in reprisal for alleged repression against striking employees. On 10 June 1975, guerrillas in Santa Fe shot and killed Juan Enrique Pelayes, a trade union leader. On 12 June 1975, in an ambush in the capital of the Córdoba province, three policemen (Pedro Ramón Enrico, Carlos Alberto Galíndez and corporal Luis Francisco Rodríguez) were killed by guerrillas. On 25 July 1975 four policemen were wounded in guerrilla attacks using bazookas and firebombs. On 26 August 1975, 26-year-old Fernando Haymal was killed by fellow Montoneros for allegedly cooperating with government forces.

The Montoneros' leadership was keen to learn from the ERP's "Compañía de Monte Ramón Rosa Jiménez" operating in the Andean province of Tucumán. In 1975 they sent "observers" to spend a few months with the ERP platoons operating against the 5th Infantry Brigade, then consisting of the 19th, 20th and 29th Mountain Infantry Regiments. On 28 August 1975 the Montoneros planted a bomb in a culvert at the Tucumán air base airstrip. The blast destroyed an air force C-130 transport carrying 116 anti-guerrilla commandos of the Gendarmerie, killing five and wounding 40, one of whom later died of his injuries.

The network of Montoneros militants had been largely uprooted by the government in the capital of Tucumán province. In August 1975, several hundred Montoneros militants took to the streets in Córdoba, to divert attention from the military operations being waged in the mountains of Tucumán. They shot and killed five policemen (Sergeant Juan Carlos Román, Corporal Rosario del Carmen Moyano and Agents Luis Rodolfo López, Jorge Natividad Luna and Juan Antonio Diaz) after attacking their headquarters and bombed the police radio communications centre. As a result, the elite 4th Airborne Infantry Brigade, which had been ordered to assist operations in Tucumán province, was kept in Córdoba for the rest of the year.

On 5 October 1975, the Montoneros carried out a complex operation against a regiment of the 5th Brigade. During this attack named "Operation Primicia" ("Operation Scoop") a Montoneros force numbering an estimated several hundred guerrillas and underground supporters, set in motion an assault on an army barracks in Formosa province. On 5 October 1975, Montoneros members hijacked a civilian airliner bound for Corrientes from Buenos Aires. The guerrillas redirected the plane to Formosa, and took over the provincial airport, killing policeman Neri Argentino Alegre in the process. With tactical support from a local militant group, the invaders attacked the barracks of the 29th Infantry Regiment with gunfire and hand grenades. They shot several soldiers who had been resting in their quarters.

After the soldiers and NCOs got over their initial surprise, they mounted stiff resistance to the attacking Montoneros. In total, a second lieutenant (Ricardo Massaferro), sergeant (Víctor Sanabria) and ten conscripts (Antonio Arrieta, Heriberto Avalos, José Coronel, Dante Salvatierra, Ismael Sánchez, Tomás Sánchez, Edmundo Roberto Sosa, Marcelino Torales, Alberto Villalba and Hermindo Luna) were killed and several wounded. The Montoneros lost 16 killed in total. Two policemen later died of their wounds. The Montoneros escaped by air into a remote area in adjoining Santa Fe province. The aircraft, a Boeing 737, landed in a crop field not far from the city of Rafaela. The Peronist guerrillas fled to waiting cars on a highway nearby.

The sophistication of the operation, and the getaway cars and hideouts they used to escape the military crackdown, suggest the involvement of several hundred guerrillas and civilian sympathisers in Montoneros' organisation. In a controversial move under the presidency of Nestor Kirchner, the families of all the Montoneros killed in the attack were each later compensated with the payment of around US$200,000.

On 26 October 1975, a Catholic youth leader, Juan Ignacio Isla Casares, with the help of the Montoneros commander Eduardo Pereira Rossi (nom de guerre "El Carlón") was the mastermind behind the ambush and killing of five policemen (Pedro Dettle, Juan Ramón Costa, Carlos Livio Cejas, Cleofás Galeano and Juan Fernández) near near San Isidro Cathedral.

During February 1976, the Montoneros sent assistance to the hard-pressed "Compañía de Monte Ramón Rosa Jiménez" fighting in Tucumán province, in the form of a company of their elite "Jungle Troops", while the ERP backed them up with a company of their guerrillas from Cordoba. The "Baltimore Sun" reported at the time, ""In the jungle-covered mountains of Tucuman, long known as "Argentina's garden," Argentines are fighting Argentines in a Vietnam-style civil war. So far, the outcome is in doubt. But there is no doubt about the seriousness of the combat, which involves 2,000 or so leftist guerrillas and perhaps as many as 10,000 soldiers.""

While the ERP fought the army in Tucumán, the Montoneros were active in Buenos Aires. Montoneros' leadership dismissed the tactics of the ERP in Tucumán as "old fashioned" and "inappropriate" but still sent reinforcements. On 26 October 1975 five policemen (Pedro Dettle, Juan Ramón Costa, Carlos Livio Cejas, Cleofás Galeano and Juan Fernández) were killed in Buenos Aires when Montoneros guerrillas ambushed their patrol cars near the San Isidro Cathedral. Two of the captured policemen were reported to have been executed in this operation under the orders of the Montoneros commander Eduardo Pereyra Rossi (nom de guerre Carlon).

In December 1975, Montoneros raided an armaments factory in the capital's Munro neighbourhood, fleeing with 250 assault rifles and sub-machine guns. That same month, a Montoneros bomb exploded at the headquarters of the Argentine army in Buenos Aires, injuring at least six soldiers. By the end of 1975, a total of 137 army officers, NCOs and conscripts and policemen had been killed that year and approximately 3,000 wounded by left wing terrorism. U.S. journalist Paul Hoeffel in an article written for the Boston Globe concluded that, "Although there is widespread reluctance to use the term, it is now impossible to ignore the fact that civil war has broken out in Argentina."

Montoneros were inspired by the British and Italian wartime commando raids on warships, and on 1 November 1974 Montoneros successfully blew up General Commissioner Alberto Villar, the chief of the Argentine federal police in his yacht. His wife was also killed on the spot. On 24 August 1975 their frogmen planted a mine on the river's bed below the hull of a navy destroyer, the ARA "Santísima Trinidad", as she remained docked at Rio Santiago before her commissioning. The explosion caused considerable damage to the ship's computer and electronic equipment. On 14 December 1975, using the same techniques, Montoneros frogmen placed explosives on the yacht "Itati" in an attempt to kill the Commander-in-Chief of the Argentine navy, Admiral Emilio Massera. While Massera was not injured, the yacht was badly damaged by the explosives.

In January 1976, the son of retired Lieutenant-General Julio Alsogoray, Juan Alsogaray (El Hippie), copied from his father's safe a draft of "Battle Order 24 March" and passed it to the head of the Montoneros intelligence, Rodolfo Walsh, who informed the guerrilla leadership of the planned military coup. Private Sergio Tarnopolsky, serving in the Argentine Marine Corps in 1976, also passed on valuable information to Walsh regarding the tortures and killings of left-wing guerrillas taking place in ESMA. He was later that year made to disappear along with his father Hugo and mother Blanca and sister Betina in revenge for a bomb that he planted in the detention centre which failed to explode. The only survivor was his brother Daniel, who was not at home the day of the raid. On 26 January, ERP guerrillas supporting Montoneros operations in the suburb of Barracas in Buenos Aires, kill a female police traffic officer (Silvia Ester Rosboch de Campana). On 29 January, during a raid on the Bendix factory in the suburb of Munro in Buenos Aires, Montoneros shoot and kill Alberto Olabarrieta and Jorge Sarlenga of the factory's management, and an off-duty policeman, Juan Carlos Garavaglio, who had tried to intervene.

On 2 February 1976 about fifty Montoneros attacked the Juan Vucetich Police Academy in the suburb of La Plata but were repelled when the police cadets fought back and reinforcements arrived. On 13 February 1976, the Argentine army scored a major success when the 14th Airborne Infantry Regiment of the 4th Airborne Infantry Brigade ambushed the 65-strong Montoneros Jungle Company, in an action near the town of Cadillal in Tucumán province. The 2nd Airborne Infantry Regiment of the same brigade, was also released from garrison duties in the city of Córdoba after the ERP armed uprising that killed 5 policemen there in August 1975 and would achieve similar success against the ERP's "Decididos de Córdoba" company sent to rekindle the insurgency in Tucumán province. In the week preceding the military coup, the Montoneros killed 13 policemen as part of their "Third National Military Campaign" and vowed to kill at least 3,000 policemen by decade's end.

The ERP guerrillas and their supporting network of militants came under heavy attack in April 1976, and the Montoneros were forced to come to their assistance with money, weapons and safe houses. On 21 June 1976, the labour relations manager of Swift (an American food processing company), Osvaldo Raúl Trinidad was shot and killed outside his home in the La Plata suburb of Buenos Aires after coming under fire from a carload of masked Peronist guerrillas. On 1 July 1976, a carload of Montoneros shoot and kill Army Sergeant Raul Godofredo Favale in the Ramos Mejía suburb of Buenos Aires. On 2 July 1976 the Montoneros detonated a powerful bomb in the Argentine Federal Police in Buenos Aires, killing 24 and injuring 66 people. On 10 July 1976, policemen surrounded and entered a printing house in the San Andrés suburb of Buenos Aires in an effort to free Vicecomodore Roberto Echegoyen from the Argentine air force, but the alerted guerrillas shot their hostage in the head. On 19 July, Montoneros killed Brigadier-General Carlos Omar Actis (tasked with overseeing the World Cup soccer championships in Argentina in 1978) in the suburb of Wilde in Buenos Aires. On 26 July Montoneros guerrillas operating in the San Justo suburb of Buenos Aires shot and killed an off-duty policeman, Ramón Emilio Reno in the presence of his 13-year-old brother. An Argentine army 1976 report entitled "Informe Especial: Actividades OPM "Montoneros" año 1976", gave the following surviving Montoneros totals for September 1976: 9,191 members with 991 guerrillas (391 officers and 600 other ranks), 2,700 armed militants and 5,500 sympathisers and active collaborators.

On 19 August 1976, Carlos Bergometti of the senior management of Fiat in Córdoba, is intercepted on his way to work and killed by Montoneros armed with shotguns in a car. On 2 September 1976, the urban guerrillas kill Lieutenant-Colonel Carlos Heriberto Astudillo in the suburb of Escobar in Buenos Aires. On 7 September 1976, Daniel Andrés Cash of the "Banco de la Nación Argentina" is killed on his way to work by a Montoneros guerrilla armed with a shotgun. On 12 September 1976 a Montoneros car bomb destroyed a bus carrying police officers in Rosario, killing nine policemen and a married couple: 56-year-old Oscar Walter Ledesma and 42-year-old Irene Ángela Dib. There were at least 50 wounded. On 17 October a Montoneros bomb blast in an Army Club cinema in downtown Buenos Aires killed 11 and wounded about 50 officers and their families. On 9 November, eleven police officers were wounded when a Montoneros bomb exploded at the police headquarters of La Plata during a meeting of the Buenos Aires police chiefs.

On 16 November, about 40 Montoneros guerrillas stormed the police station at Arana, 30 miles south of Buenos Aires. Five policemen and one army captain were wounded in the battle. On 15 December, another Montoneros bomb planted in a Defence Ministry movie hall killed at least 14 and injured 30 officers and their families. On 29 December, Montoneros shot and killed Colonel Francisco Castellanos and wounded his driver, Private Alberto Gutiérrez, just a few blocks from the army officer's home in the suburb of Florida in Buenos Aires. The worst year of the insurgency, 1976, saw 156 army officers, NCOs and conscripts and police killed.

By the time Videla's military junta took power in March 1976, approximately five thousand prisoners were being held in various prisons around Argentina, some with connections and some just guilty by association. In all, 12,000 Argentines were detained during the military dictatorship and became known as the "detenidos-desaparecidos", but survived after international pressure forced the military authorities to release them. These prisoners were held throughout the years of the dictatorship, many of them never receiving trials, in prisons such as La Plata, Devoto, Rawson, and Caseros. Justice Minister Ricardo Gil Lavedra, who formed part of the 1985 tribunal judging the military crimes committed during the Dirty War would later go on record saying that ""I sincerely believe that the majority of the victims of the illegal repression were guerrilla militants"".
Terence Roehrig, who has written "The prosecution of former military leaders in newly democratic nations: the cases of Argentina, Greece, and South Korea " (Pg 42, McFarland & Company, 2001) estimates that of the disappeared in Argentina ""at least 10,000 were involved in various ways with the guerrillas"". The Montoneros later admitted losing 5,000 guerrillas killed, and the People's Revolutionary Army (Ejército Revolucionario del Pueblo or ERP) admitted the loss of another 5,000 of their own combatants killed. Some 11,000 Argentines have applied for and received up to US $200,000 each as monetary compensation for the loss of loved ones during the military dictatorship. In late November 2012, it was reported that the government of Cristina Fernández de Kirchner would approve monetary compensation for the families that lost loved ones in the Montoneros attack on the 29th Regiment barracks on 5 October 1975, the first of its kind for military families in Argentina.

On 24 March 1976 Isabel Perón was ousted and a military junta installed, led by General Jorge Rafael Videla. On 4 April 1976, Montoneros assassinated a naval commander (Jose Guillermo Burgos) and a Chrysler executive (Jorge Ricardo Kenny) and ambushed and killed three policemen in a patrol car. On 26 April 1976, Montoneros guerrillas killed Colonel Abel Héctor Elías Cavagnaro outside his home in Tucumán province. On 27 June 1976, Montoneros guerrillas operating in the city of Rosario ambushed and destroyed two police cars, killing three police officers During the first few months of the military government, more than 70 policemen were killed in leftist guerrilla attacks. On 11 August 1976, urban guerrillas dressed like police officers intercepted and killed army corporal Jorge Antonio Bulacio, with two shots to the head and set fire to his military lorry belonging to the 141st Headquarters Communications Battalion with a Molotov cocktail bomb.

On 4 January 1977, a female guerrilla (Ana María González) from the Montoneros movement shot and killed Private Guillermo Félix Dimitri of the 10th Mechanized Infantry Brigade while he was on roadblock duty outside the Chrysler factory in the San Justo suburb of Buenos Aires.
On 27 January, a Montoneros bomb explodes outside a police station in the city of Rosario in Santa Fe Province, killing a policeman (Miguel Angel Bracamonte) and a 15-year-old girl (María Leonor Berardi), an innocent bystander.On 28 January, a female Montoneros guerrilla (22-year-old Juana Silvia Charura) placed a bomb inside the 2nd Police Station in the suburb of Cuidadela, destroying the building and killing three policemen: Commissioner Carlos A. Benítez, Sub-Commissioner Lorenzo Bonnani and Agent César Landeria. 

On 10 February, two police officers (Roque Alipio Farías and Ernesto Olivera) with an anti-explosives unit were fatally wounded trying to deactivate a bomb rigged to a motorbike in Rosario. On 15 February 1977, army corporal Osvaldo Ramón Ríos was killed after his patrol came under fire from a group of Montoneros that had barricaded themselves inside a house in the Ezpeleta suburb of Buenos Aires. That same month, Ireneo Garnica and Alejandro Díaz, both railway workers who had refused to participate in a strike, were killed when Montoneros threw a bomb at them in the suburb of Quilmes in Buenos Aires. On 19 March 1977, 45-year-old Sergeant Martín A. Novau from the Federal Police was shot and killed while he was repairing a police car in a work shop in Buenos Aires. 

On 23 May 1977, the leftist guerrillas in Buenos Aires killed two police officers and a retired inspector as he entered his home.

The junta redoubled the Dirty War anti-guerrilla campaign. During 1977, in just Buenos Aires alone, 36 police were reported killed in actions involving the remaining urban guerrillas

On 1 August 1978, a powerful bomb meant to kill Rear Admiral Armando Lambruschini (chairman of the Joint Chiefs) ripped through a nine-story apartment building, killing three civilians and trapping scores beneath the debris.

On 14 August 1977 Susana Leonor Siver and her partner Marcelo Carlos Reinhold, both Montoneros fighters, were kidnapped from Reinold's mother's home along with a friend by a fifteen-strong naval intelligence team and taken to the ESMA naval detention camp. After a brutal torture session in front of his wife, Marcelo was supposedly "transferred" to another camp but nothing was heard of him since. In February 1978, Susana was disappeared by the military authorities soon after giving birth to a blonde girl.

Adriana and Gaspar Tasca, both identified as Montoneros, were taken into custody between 7 and 10 December 1977 and remain unaccounted for. On 6 October 1978, José Pérez Rojo and Patricia Roisinblit, both Montoneros members, were made to disappear. According to different sources, 8,000 to 30,000 people are estimated to have disappeared and died during the military dictatorship that ruled Argentina from 1976 to 1983. Some 12,000 of the missing known as the "detenidos-desaparecidos", survived detention and were later compensated for their ordeal. On the other hand, according to an NGO dedicated to defending "victims of terrorism", 1,355 people, including members of the police and military, were killed by Montoneros and other left-wing armed movements.

The commander of the Montoneros, Mario Firmenich, in a radio interview in late 2000 from Spain later stated that ""In a country that has experienced a civil war, everybody has blood on their hands."" The junta relied on mass illegal arrests, torture, and executions without trial to stifle any political opposition. Some victims were thrown from transport planes into the Atlantic Ocean on what have become infamously known as death flights. Others had their corpses left on streets as intimidation of others. The Montoneros admit 5,000 of their guerrillas were killed.

The Montoneros were effectively finished off by 1977, although their "Special Forces" did fight on until 1981. The Montoneros tried to disrupt the World Cup Football Tournament being hosted in Argentina in 1978 by launching a number of bomb attacks. In late 1979, the Montoneros launched a "strategic counteroffensive" in Argentina, and the security forces killed more than one hundred of the exiled Montoneros, who had been sent back to Argentina after receiving special forces training in camps in the Middle East. On 14 June 1980, eight Argentine army officers (in cooperation with Peruvian military authorities), kidnapped Noemí Esther Giannetti de Molfino (an active Montoneros collaborator) along with eight Argentine nationals in the Peruvian capital and had them forcefully disappear. In October 2014, the presidency of Cristina Fernández de Kirchner would rename a street in the city of Resistencia, Chaco Province in her memory. Her daughter Marcela along with her partner, Guillermo Amarilla, had both disappeared in 1979 while re-entering Argentina as part of the Montoneros "strategic counteroffensive".

Among the Montoneros killed in this operation were Luis Francisco Goya and María Lourdes Martínez Aranda who after crossing the Chilean border into Argentina were abducted in the city of Mendoza in 1980 and never seen again, with their son Jorge Guillermo being adopted and raised by an army NCO, Luis Alberto Tejada and his wife Raquel Quinteros. During the 1980s a captured Sandinista commando revealed that Montoneros "Special Forces" were training Sandinista frogmen and conducting gun runs across the Gulf of Fonseca to the Sandinista allies in El Salvador, FMLN guerrillas.

During the Falklands War against Great Britain, the Argentine military conceived the aborted Operation Algeciras, a covert plan to support and convince some Commando-trained Montoneros, by appealing to their patriotism, to sabotage British military facilities in Gibraltar. Argentina's defeat led to the fall of the junta, and Raúl Alfonsín became president in December 1983, thus initiating the democratic transition.




</doc>
<doc id="20611" url="https://en.wikipedia.org/wiki?curid=20611" title="Monophyly">
Monophyly

In cladistics, a monophyletic group, or clade, is a group of organisms that consists of all the descendants of a common ancestor (or more precisely ancestral population). Monophyletic groups are typically characterised by shared derived characteristics (synapomorphies), which distinguish organisms in the clade from other organisms. The arrangement of the members of a monophyletic group is called a monophyly.

Monophyly is contrasted with paraphyly and polyphyly as shown in the second diagram. A "paraphyletic group" consists of all of the descendants of a common ancestor minus one or more monophyletic groups. A "polyphyletic group" is characterized by convergent features or habits of scientific interest (for example, night-active primates, fruit trees, aquatic insects). The features by which a polyphyletic group is differentiated from others are not inherited from a common ancestor.

These definitions have taken some time to be accepted. When the cladistics school of thought became mainstream in the 1960s, several alternative definitions were in use. Indeed, taxonomists sometimes used terms without defining them, leading to confusion in the early literature, a confusion which persists.

The first diagram shows a phylogenetic tree with two monophyletic groups. The several groups and subgroups are particularly situated as branches of the tree to indicate ordered lineal relationships between all the organisms shown. Further, any group may (or may not) be considered a taxon by modern systematics, depending upon the selection of its members in relation to their common ancestor(s); see second and third diagrams.

The term "monophyly", or "monophyletic", derives from the two Ancient Greek words (), meaning "alone, only, unique", and (), meaning "genus, species", and refers to the fact that a monophyletic group includes organisms (e.g., genera, species) consisting of all the descendants of a "unique" common ancestor.

Conversely, the term "polyphyly", or "polyphyletic", builds on the ancient greek prefix (), meaning "many, a lot of", and refers to the fact that a polyphyletic group includes organisms arising from "multiple" ancestral sources.

By comparison, the term "paraphyly", or "paraphyletic", uses the ancient greek prefix (), meaning "beside, near", and refers to the situation in which one or several monophyletic subgroups are "left apart" from all other descendants of a unique common ancestor. That is, a paraphyletic group is "nearly" monophyletic, hence the prefix "".

On the broadest scale, definitions fall into two groups.






</doc>
<doc id="20613" url="https://en.wikipedia.org/wiki?curid=20613" title="Morphine">
Morphine

Morphine is a pain medication of the opiate family which is found naturally in a number of plants and animals. It acts directly on the central nervous system (CNS) to decrease the feeling of pain. It can be taken for both acute pain and chronic pain. It is frequently used for pain from myocardial infarction and during labor. It can be given by mouth, by injection into a muscle, by injection under the skin, intravenously, injection into the space around the spinal cord, or rectally. Maximum effect is reached after about 20 minutes when given intravenously and after 60 minutes when given by mouth, while duration of effect is 3–7 hours. Long-acting formulations also exist.
Potentially serious side effects include decreased respiratory effort and low blood pressure. Morphine is addictive and prone to abuse. If the dose is reduced after long-term use, opioid withdrawal symptoms may occur. Common side effects include drowsiness, vomiting, and constipation. Caution is advised when used during pregnancy or breast feeding, as morphine may affect the baby.
Morphine was first isolated between 1803 and 1805 by Friedrich Sertürner. This is generally believed to be the first isolation of an active ingredient from a plant. Merck began marketing it commercially in 1827. Morphine was more widely used after the invention of the hypodermic syringe in 18531855. Sertürner originally named the substance "morphium" after the Greek god of dreams, Morpheus, as it has a tendency to cause sleep.
The primary source of morphine is isolation from poppy straw of the opium poppy. In 2013, approximately 523 tons of morphine were produced. Approximately 45 tons were used directly for pain, a four-fold increase over the last twenty years. Most use for this purpose was in the developed world. About 70 percent of morphine is used to make other opioids such as hydromorphone, oxymorphone, and heroin. It is a Schedule II drug in the United States, Class A in the United Kingdom, and Schedule I in Canada. It is on the World Health Organization's List of Essential Medicines, the safest and most effective medicines needed in a health system. Morphine is sold under many trade names. In 2016, it was the 158th most prescribed medication in the United States, with more than 3 million prescriptions.
Morphine is used primarily to treat both acute and chronic severe pain. Its duration of analgesia is about three to seven hours. Side-effects of nausea and constipation are rarely severe enough to warrant stopping treatment.

It is used for pain due to myocardial infarction and for labor pains. However, concerns exist that morphine may increase mortality in the event of non ST elevation myocardial infarction. Morphine has also traditionally been used in the treatment of acute pulmonary edema. A 2006 review, though, found little evidence to support this practice. A 2016 Cochrane review concluded that morphine is effective in relieving cancer pain.

Morphine is beneficial in reducing the symptom of shortness of breath due to both cancer and noncancer causes. In the setting of breathlessness at rest or on minimal exertion from conditions such as advanced cancer or end-stage cardiorespiratory diseases, regular, low-dose sustained-release morphine significantly reduces breathlessness safely, with its benefits maintained over time.

Morphine is also available as a slow-release formulation for opiate substitution therapy (OST) in Austria, Germany, Bulgaria, Slovenia, and Canada for addicts who cannot tolerate either methadone or buprenorphine.

Relative contraindications to morphine include:

Like loperamide and other opioids, morphine acts on the myenteric plexus in the intestinal tract, reducing gut motility, causing constipation. The gastrointestinal effects of morphine are mediated primarily by μ-opioid receptors in the bowel. By inhibiting gastric emptying and reducing propulsive peristalsis of the intestine, morphine decreases the rate of intestinal transit. Reduction in gut secretion and increased intestinal fluid absorption also contribute to the constipating effect. Opioids also may act on the gut indirectly through tonic gut spasms after inhibition of nitric oxide generation. This effect was shown in animals when a nitric oxide precursor, L-arginine, reversed morphine-induced changes in gut motility.

Clinical studies consistently conclude that morphine, like other opioids, often causes hypogonadism and hormone imbalances in chronic users of both sexes. This side effect is dose-dependent and occurs in both therapeutic and recreational users. Morphine can interfere with menstruation in women by suppressing levels of luteinizing hormone. Many studies suggest the majority (perhaps as many as 90%) of chronic opioid users have opioid-induced hypogonadism. This effect may cause the increased likelihood of osteoporosis and bone fracture observed in chronic morphine users. Studies suggest the effect is temporary. , the effect of low-dose or acute use of morphine on the endocrine system is unclear.

Most reviews conclude that opioids produce minimal impairment of human performance on tests of sensory, motor, or attentional abilities. However, recent studies have been able to show some impairments caused by morphine, which is not surprising, given that morphine is a central nervous system depressant. Morphine has resulted in impaired functioning on critical flicker frequency (a measure of overall CNS arousal) and impaired performance on the Maddox wing test (a measure of the deviation of the visual axes of the eyes). Few studies have investigated the effects of morphine on motor abilities; a high dose of morphine can impair finger tapping and the ability to maintain a low constant level of isometric force (i.e. fine motor control is impaired), though no studies have shown a correlation between morphine and gross motor abilities.

In terms of cognitive abilities, one study has shown that morphine may have a negative impact on anterograde and retrograde memory, but these effects are minimal and transient. Overall, it seems that acute doses of opioids in non-tolerant subjects produce minor effects in some sensory and motor abilities, and perhaps also in attention and cognition. It is likely that the effects of morphine will be more pronounced in opioid-naive subjects than chronic opioid users.

In chronic opioid users, such as those on Chronic Opioid Analgesic Therapy (COAT) for managing severe, chronic pain, behavioural testing has shown normal functioning on perception, cognition, coordination and behaviour in most cases. One 2000 study analysed COAT patients to determine whether they were able to safely operate a motor vehicle. The findings from this study suggest that stable opioid use does not significantly impair abilities inherent in driving (this includes physical, cognitive and perceptual skills). COAT patients showed rapid completion of tasks that require the speed of responding for successful performance (e.g., Rey Complex Figure Test) but made more errors than controls. COAT patients showed no deficits in visual-spatial perception and organization (as shown in the WAIS-R Block Design Test) but did show impaired immediate and short-term visual memory (as shown on the Rey Complex Figure Test – Recall). These patients showed no impairments in higher-order cognitive abilities (i.e., planning). COAT patients appeared to have difficulty following instructions and showed a propensity toward impulsive behaviour, yet this did not reach statistical significance. It is important to note that this study reveals that COAT patients have no domain-specific deficits, which supports the notion that chronic opioid use has minor effects on psychomotor, cognitive, or neuropsychological functioning.

Morphine is a highly addictive substance. In controlled studies comparing the physiological and subjective effects of heroin and morphine in individuals formerly addicted to opiates, subjects showed no preference for one drug over the other. Equipotent, injected doses had comparable action courses, with no difference in subjects' self-rated feelings of euphoria, ambition, nervousness, relaxation, drowsiness, or sleepiness. Short-term addiction studies by the same researchers demonstrated that tolerance developed at a similar rate to both heroin and morphine. When compared to the opioids hydromorphone, fentanyl, oxycodone, and pethidine/meperidine, former addicts showed a strong preference for heroin and morphine, suggesting that heroin and morphine are particularly susceptible to abuse and addiction. Morphine and heroin were also much more likely to produce euphoria and other positive subjective effects when compared to these other opioids. The choice of heroin and morphine over other opioids by former drug addicts may also be because heroin (also known as morphine diacetate, diamorphine, or diacetyl morphine) is an ester of morphine and a morphine prodrug, essentially meaning they are identical drugs "in vivo". Heroin is converted to morphine before binding to the opioid receptors in the brain and spinal cord, where morphine causes the subjective effects, which is what the addicted individuals are seeking.

Several hypotheses are given about how tolerance develops, including opioid receptor phosphorylation (which would change the receptor conformation), functional decoupling of receptors from G-proteins (leading to receptor desensitization), μ-opioid receptor internalization or receptor down-regulation (reducing the number of available receptors for morphine to act on), and upregulation of the cAMP pathway (a counterregulatory mechanism to opioid effects) (For a review of these processes, see Koch and Hollt.) CCK might mediate some counter-regulatory pathways responsible for opioid tolerance. CCK-antagonist drugs, specifically proglumide, have been shown to slow the development of tolerance to morphine.

Cessation of dosing with morphine creates the prototypical opioid withdrawal syndrome, which, unlike that of barbiturates, benzodiazepines, alcohol, or sedative-hypnotics, is not fatal by itself in otherwise healthy people.

Acute morphine withdrawal, along with that of any other opioid, proceeds through a number of stages. Other opioids differ in the intensity and length of each, and weak opioids and mixed agonist-antagonists may have acute withdrawal syndromes that do not reach the highest level. As commonly cited, they are:

In advanced stages of withdrawal, ultrasonographic evidence of pancreatitis has been demonstrated in some patients and is presumably attributed to spasm of the pancreatic sphincter of Oddi.

The withdrawal symptoms associated with morphine addiction are usually experienced shortly before the time of the next scheduled dose, sometimes within as early as a few hours (usually 6 h to 12 h) after the last administration. Early symptoms include watery eyes, insomnia, diarrhea, runny nose, yawning, dysphoria, sweating, and in some cases a strong drug craving. Severe headache, restlessness, irritability, loss of appetite, body aches, severe abdominal pain, nausea and vomiting, tremors, and even stronger and more intense drug craving appear as the syndrome progresses. Severe depression and vomiting are very common. During the acute withdrawal period, systolic and diastolic blood pressures increase, usually beyond premorphine levels, and heart rate increases, which have potential to cause a heart attack, blood clot, or stroke.

Chills or cold flashes with goose bumps ("cold turkey") alternating with flushing (hot flashes), kicking movements of the legs ("kicking the habit") and excessive sweating are also characteristic symptoms. Severe pains in the bones and muscles of the back and extremities occur, as do muscle spasms. At any point during this process, a suitable narcotic can be administered that will dramatically reverse the withdrawal symptoms. Major withdrawal symptoms peak between 48 h and 96 h after the last dose and subside after about 8 to 12 days. Sudden withdrawal by heavily dependent users who are in poor health is very rarely fatal. Morphine withdrawal is considered less dangerous than alcohol, barbiturate, or benzodiazepine withdrawal.

The psychological dependence associated with morphine addiction is complex and protracted. Long after the physical need for morphine has passed, the addict will usually continue to think and talk about the use of morphine (or other drugs) and feel strange or overwhelmed coping with daily activities without being under the influence of morphine. Psychological withdrawal from morphine is usually a very long and painful process. Addicts often suffer severe depression, anxiety, insomnia, mood swings, amnesia (forgetfulness), low self-esteem, confusion, paranoia, and other psychological disorders. Without intervention, the syndrome will run its course, and most of the overt physical symptoms will disappear within 7 to 10 days including psychological dependence. A high probability of relapse exists after morphine withdrawal when neither the physical environment nor the behavioral motivators that contributed to the abuse have been altered. Testimony to morphine's addictive and reinforcing nature is its relapse rate. Abusers of morphine (and heroin) have one of the highest relapse rates among all drug users, ranging up to 98% in the estimation of some medical experts.

A large overdose can cause asphyxia and death by respiratory depression if the person does not receive medical attention immediately. Overdose treatment includes the administration of naloxone. The latter completely reverses morphine's effects, but may result in immediate onset of withdrawal in opiate-addicted subjects. Multiple doses may be needed.

The LD for humans of morphine sulphate and other preparations is not known with certainty. One poor quality study on morphine overdoses among soldiers reported that the fatal dose was 0.78mcg/ml in males (~71mg for an average 90Kg adult man) and 0.98mcg/ml in females (~73.5mg for an average 75Kg female). It was not specified whether the dose was oral, parenteral or IV. Laboratory animal studies are usually cited in the literature. In serious drug dependency (high tolerance), 2000–3000 mg per day can be tolerated.

Morphine has classically been divided in two classes, where class I (also known as "Morphine base") is a brown non-water-soluble powder made of concentrated opium and class II, after a chemical process, becomes a white water-soluble powder. (Some custom services around the world also defined brown Heroin as Morphine class III and the white water-soluble Heroin as Morphine class IV. As a legally permitted medicine only of the old Morphine class II is in use.

Morphine is the prototypical opioid and is the standard against which other opioids are tested. It interacts predominantly with the μ–δ-opioid (Mu-Delta) receptor heteromer. The μ-binding sites are discretely distributed in the human brain, with high densities in the posterior amygdala, hypothalamus, thalamus, nucleus caudatus, putamen, and certain cortical areas. They are also found on the terminal axons of primary afferents within laminae I and II (substantia gelatinosa) of the spinal cord and in the spinal nucleus of the trigeminal nerve.

Morphine is a phenanthrene opioid receptor agonist – its main effect is binding to and activating the μ-opioid receptor (MOR) in the central nervous system. Its intrinsic activity at the MOR is heavily dependent on the assay and tissue being tested; in some situations it is a full agonist while in others it can be a partial agonist or even antagonist. In clinical settings, morphine exerts its principal pharmacological effect on the central nervous system and gastrointestinal tract. Its primary actions of therapeutic value are analgesia and sedation. Activation of the MOR is associated with analgesia, sedation, euphoria, physical dependence, and respiratory depression. Morphine is also a κ-opioid receptor (KOR) and δ-opioid receptor (DOR) agonist. Activation of the KOR is associated with spinal analgesia, miosis (pinpoint pupils), and psychotomimetic effects. The DOR is thought to play a role in analgesia. Although morphine does not bind to the σ receptor, it has been shown that σ receptor agonists, such as (+)-pentazocine, inhibit morphine analgesia, and σ receptor antagonists enhance morphine analgesia, suggesting downstream involvement of the σ receptor in the actions of morphine.

The effects of morphine can be countered with opioid receptor antagonists such as naloxone and naltrexone; the development of tolerance to morphine may be inhibited by NMDA receptor antagonists such as ketamine or dextromethorphan. The rotation of morphine with chemically dissimilar opioids in the long-term treatment of pain will slow down the growth of tolerance in the longer run, particularly agents known to have significantly incomplete cross-tolerance with morphine such as levorphanol, ketobemidone, piritramide, and methadone and its derivatives; all of these drugs also have NMDA antagonist properties. It is believed that the strong opioid with the most incomplete cross-tolerance with morphine is either methadone or dextromoramide.

Studies have shown that morphine can alter the expression of a number of genes. A single injection of morphine has been shown to alter the expression of two major groups of genes, for proteins involved in mitochondrial respiration and for cytoskeleton-related proteins.

Morphine has long been known to act on receptors expressed on cells of the central nervous system resulting in pain relief and analgesia. In the 1970s and '80s, evidence suggesting that opioid drug addicts show increased risk of infection (such as increased pneumonia, tuberculosis, and HIV/AIDS) led scientists to believe that morphine may also affect the immune system. This possibility increased interest in the effect of chronic morphine use on the immune system.

The first step of determining that morphine may affect the immune system was to establish that the opiate receptors known to be expressed on cells of the central nervous system are also expressed on cells of the immune system. One study successfully showed that dendritic cells, part of the innate immune system, display opiate receptors. Dendritic cells are responsible for producing cytokines, which are the tools for communication in the immune system. This same study showed that dendritic cells chronically treated with morphine during their differentiation produce more interleukin-12 (IL-12), a cytokine responsible for promoting the proliferation, growth, and differentiation of T-cells (another cell of the adaptive immune system) and less interleukin-10 (IL-10), a cytokine responsible for promoting a B-cell immune response (B cells produce antibodies to fight off infection).

This regulation of cytokines appear to occur via the p38 MAPKs (mitogen-activated protein kinase)-dependent pathway. Usually, the p38 within the dendritic cell expresses TLR 4 (toll-like receptor 4), which is activated through the ligand LPS (lipopolysaccharide). This causes the p38 MAPK to be phosphorylated. This phosphorylation activates the p38 MAPK to begin producing IL-10 and IL-12. When the dendritic cells are chronically exposed to morphine during their differentiation process then treated with LPS, the production of cytokines is different. Once treated with morphine, the p38 MAPK does not produce IL-10, instead favoring production of IL-12. The exact mechanism through which the production of one cytokine is increased in favor over another is not known. Most likely, the morphine causes increased phosphorylation of the p38 MAPK. Transcriptional level interactions between IL-10 and IL-12 may further increase the production of IL-12 once IL-10 is not being produced. This increased production of IL-12 causes increased T-cell immune response.

Further studies on the effects of morphine on the immune system have shown that morphine influences the production of neutrophils and other cytokines. Since cytokines are produced as part of the immediate immunological response (inflammation), it has been suggested that they may also influence pain. In this way, cytokines may be a logical target for analgesic development. Recently, one study has used an animal model (hind-paw incision) to observe the effects of morphine administration on the acute immunological response. Following hind-paw incision, pain thresholds and cytokine production were measured. Normally, cytokine production in and around the wounded area increases in order to fight infection and control healing (and, possibly, to control pain), but pre-incisional morphine administration (0.1 mg/kg to 10.0 mg/kg) reduced the number of cytokines found around the wound in a dose-dependent manner. The authors suggest that morphine administration in the acute post-injury period may reduce resistance to infection and may impair the healing of the wound.

Morphine can be taken orally, sublingually, bucally, rectally, subcutaneously, intranasally, intravenously, intrathecally or epidurally and inhaled via a nebulizer. As a recreational drug, it is becoming more common to inhale ("Chasing the Dragon"), but, for medical purposes, intravenous (IV) injection is the most common method of administration. Morphine is subject to extensive first-pass metabolism (a large proportion is broken down in the liver), so, if taken orally, only 40% to 50% of the dose reaches the central nervous system. Resultant plasma levels after subcutaneous (SC), intramuscular (IM), and IV injection are all comparable. After IM or SC injections, morphine plasma levels peak in approximately 20 min, and, after oral administration, levels peak in approximately 30 min. Morphine is metabolised primarily in the liver and approximately 87% of a dose of morphine is excreted in the urine within 72 h of administration. Morphine is metabolized primarily into morphine-3-glucuronide (M3G) and morphine-6-glucuronide (M6G) via glucuronidation by phase II metabolism enzyme UDP-glucuronosyl transferase-2B7 (UGT2B7). About 60% of morphine is converted to M3G, and 6% to 10% is converted to M6G. Not only does the metabolism occur in the liver but it may also take place in the brain and the kidneys. M3G does not undergo opioid receptor binding and has no analgesic effect. M6G binds to μ-receptors and is half as potent an analgesic as morphine in humans. Morphine may also be metabolized into small amounts of normorphine, codeine, and hydromorphone. Metabolism rate is determined by gender, age, diet, genetic makeup, disease state (if any), and use of other medications. The elimination half-life of morphine is approximately 120 min, though there may be slight differences between men and women. Morphine can be stored in fat, and, thus, can be detectable even after death. Morphine can cross the blood–brain barrier, but, because of poor lipid solubility, protein binding, rapid conjugation with glucuronic acid and ionization, it does not cross easily. Heroin, which is derived from morphine, crosses the blood–brain barrier more easily, making it more potent.

There are extended-release formulations of orally administered morphine whose effect last longer, which can be given once per day. Brand names for this formulation of morphine include Avinza, Kadian, MS Contin and Dolcontin. For constant pain, the relieving effect of extended-release morphine given once (for Kadian) or twice (for MS Contin) every 24 hours is roughly the same as multiple administrations of "immediate release" (or "regular") morphine. Extended-release morphine can be administered together with "rescue doses" of immediate-release morphine as needed in case of breakthrough pain, each generally consisting of 5% to 15% of the 24-hour extended-release dosage.

Morphine and its major metabolites, morphine-3-glucuronide and morphine-6-glucuronide, can be detected in blood, plasma, hair, and urine using an immunoassay. Chromatography can be used to test for each of these substances individually. Some testing procedures hydrolyze metabolic products into morphine before the immunoassay, which must be considered when comparing morphine levels in separately published results. Morphine can also be isolated from whole blood samples by solid phase extraction (SPE) and detected using liquid chromatography-mass spectrometry (LC-MS).

Ingestion of codeine or food containing poppy seeds can cause false positives.

A 1999 review estimated that relatively low doses of heroin (which metabolizes immediately into morphine) are detectable by standard urine tests for 1-1.5 days after use. A 2009 review determined that, when the analyte is morphine and the limit of detection is 1ng/ml, a 20mg intravenous (IV) dose of morphine is detectable for 12–24 hours. A limit of detection of 0.6ng/ml had similar results.

Morphine is the most abundant opiate found in opium, the dried latex extracted by shallowly scoring the unripe seedpods of the "Papaver somniferum" poppy. Morphine is generally 8–14% of the dry weight of opium, although specially bred cultivars reach 26% or produce little morphine at all (under 1%, perhaps down to 0.04%). The latter varieties, including the 'Przemko' and 'Norman' cultivars of the opium poppy, are used to produce two other alkaloids, thebaine and oripavine, which are used in the manufacture of semi-synthetic and synthetic opioids like oxycodone and etorphine and some other types of drugs. "P. bracteatum" does not contain morphine or codeine, or other narcotic phenanthrene-type, alkaloids. This species is rather a source of thebaine. Occurrence of morphine in other Papaverales and Papaveraceae, as well as in some species of hops and mulberry trees has not been confirmed. Morphine is produced most predominantly early in the life cycle of the plant. Past the optimum point for extraction, various processes in the plant produce codeine, thebaine, and in some cases negligible amounts of hydromorphone, dihydromorphine, dihydrocodeine, tetrahydro-thebaine, and hydrocodone (these compounds are rather synthesized from thebaine and oripavine).

In the brain of mammals, morphine is detectable in trace steady-state concentrations. The human body also produces endorphins, which are chemically related endogenous opioid peptides that function as neuropeptides and have similar effects to morphine.

Morphine is an endogenous opioid in humans that can be synthesized by and released from various human cells, including white blood cells. CYP2D6, a cytochrome P450 isoenzyme, catalyzes the biosynthesis of morphine from codeine and dopamine from tyramine along the biosynthetic pathway of morphine in humans. The morphine biosynthetic pathway in humans occurs as follows:
L-tyrosine → "para"-tyramine or L-DOPA → dopamine → ("S")-norlaudanosoline → ("S")-reticuline → 1,2-dehydroretinulinium → ("R")-reticuline → salutaridine → salutaridinol → thebaine → neopinone → codeinone → codeine → morphine ("S")-Norlaudanosoline (also known as tetrahydropapaveroline) can also be synthesized from 3,4-dihydroxyphenylacetaldehyde (DOPAL), a metabolite of L-DOPA and dopamine. Urinary concentrations of endogenous codeine and morphine have been found to significantly increase in individuals taking L-DOPA for the treatment of Parkinson's disease.

Morphine is biosynthesized in the opium poppy from the tetrahydroisoquinoline reticuline. It is converted into salutaridine, thebaine, and oripavine. The enzymes involved in this process are the salutaridine synthase, salutaridine:NADPH 7-oxidoreductase and the codeinone reductase. Researchers are attempting to reproduce the biosynthetic pathway that produces morphine in genetically engineered yeast. In June 2015 the "S"-reticuline could be produced from sugar and "R"-reticuline could be converted to morphine, but the intermediate reaction could not be performed. In August 2015 the first complete synthesis of thebaine and hydrocodone in yeast were reported, but the process would need to be 100,000 times more productive to be suitable for commercial use.

Morphine is a benzylisoquinoline alkaloid with two additional ring closures. It has:

Most of the licit morphine produced is used to make codeine by methylation. It is also a precursor for many drugs including heroin (3,6-diacetylmorphine), hydromorphone (dihydromorphinone), and oxymorphone (14-hydroxydihydromorphinone); many morphine derivatives can also be manufactured using thebaine or codeine as a starting material. Replacement of the "N"-methyl group of morphine with an "N"-phenylethyl group results in a product that is 18 times more powerful than morphine in its opiate agonist potency. Combining this modification with the replacement of the 6-hydroxyl with a 6-methylene group produces a compound some 1,443 times more potent than morphine, stronger than the Bentley compounds such as etorphine (M99, the Immobilon tranquilliser dart) by some measures.

The structure-activity relationship of morphine has been extensively studied. As a result of the extensive study and use of this molecule, more than 250 morphine derivatives (also counting codeine and related drugs) have been developed since the last quarter of the 19th century. These drugs range from 25% the analgesic strength of codeine (or slightly more than 2% of the strength of morphine) to several thousand times the strength of morphine, to powerful opioid antagonists, including naloxone (Narcan), naltrexone (Trexan), diprenorphine (M5050, the reversing agent for the Immobilon dart) and nalorphine (Nalline). Some opioid agonist-antagonists, partial agonists, and inverse agonists are also derived from morphine. The receptor-activation profile of the semi-synthetic morphine derivatives varies widely and some, like apomorphine are devoid of narcotic effects.

Morphine and most of its derivatives do not exhibit optical isomerism, although some more distant relatives like the morphinan series (levorphanol, dextorphan and the racemic parent chemical dromoran) do, and as noted above stereoselectivity in vivo is an important issue.

Morphine-derived agonist–antagonist drugs have also been developed. Elements of the morphine structure have been used to create completely synthetic drugs such as the morphinan family (levorphanol, dextromethorphan and others) and other groups that have many members with morphine-like qualities. The modification of morphine and the aforementioned synthetics has also given rise to non-narcotic drugs with other uses such as emetics, stimulants, antitussives, anticholinergics, muscle relaxants, local anaesthetics, general anaesthetics, and others.

Most semi-synthetic opioids, both of the morphine and codeine subgroups, are created by modifying one or more of the following:

Both morphine and its hydrated form, CHNOHO, are sparingly soluble in water. In five liters of water, only one gram of the hydrate will dissolve. For this reason, pharmaceutical companies produce sulfate and hydrochloride salts of the drug, both of which are over 300 times more water-soluble than their parent molecule. Whereas the pH of a saturated morphine hydrate solution is 8.5, the salts are acidic. Since they derive from a strong acid but weak base, they are both at about pH = 5; as a consequence, the morphine salts are mixed with small amounts of NaOH to make them suitable for injection.

A number of salts of morphine are used, with the most common in current clinical use being the hydrochloride, sulfate, tartrate, and citrate; less commonly methobromide, hydrobromide, hydroiodide, lactate, chloride, and bitartrate and the others listed below. Morphine diacetate, which is another name for heroin, is a Schedule I controlled substance, so it is not used clinically in the United States; it is a sanctioned medication in the United Kingdom and in Canada and some countries in Continental Europe, its use being particularly common (nearly to the degree of the hydrochloride salt) in the United Kingdom. Morphine meconate is a major form of the alkaloid in the poppy, as is morphine pectinate, nitrate, sulfate, and some others. Like codeine, dihydrocodeine and other (especially older) opiates, morphine has been used as the salicylate salt by some suppliers and can be easily compounded, imparting the therapeutic advantage of both the opioid and the NSAID; multiple barbiturate salts of morphine were also used in the past, as was/is morphine valerate, the salt of the acid being the active principle of valerian. Calcium morphenate is the intermediate in various latex and poppy-straw methods of morphine production, more rarely sodium morphenate takes its place. Morphine ascorbate and other salts such as the tannate, citrate, and acetate, phosphate, valerate and others may be present in poppy tea depending on the method of preparation. Morphine valerate produced industrially was one ingredient of a medication available for both oral and parenteral administration popular many years ago in Europe and elsewhere called Trivalin (not to be confused with the current, unrelated herbal preparation of the same name), which also included the valerates of caffeine and cocaine, with a version containing codeine valerate as a fourth ingredient being distributed under the name Tetravalin.

Closely related to morphine are the opioids morphine-"N"-oxide (genomorphine), which is a pharmaceutical that is no longer in common use; and pseudomorphine, an alkaloid that exists in opium, form as degradation products of morphine.

The salts listed by the United States Drug Enforcement Administration for reporting purposes, in addition to a few others, are as follows:

The first morphine total synthesis, devised by Marshall D. Gates, Jr. in 1952, remains a widely used example of total synthesis. Several other syntheses were reported, notably by the research groups of Rice, Evans, Fuchs, Parker, Overman, Mulzer-Trauner, White, Taber, Trost, Fukuyama, Guillou, and Stork. It is "highly unlikely" that a chemical synthesis will ever be able to compete with the cost of producing morphine from the opium poppy.

In the opium poppy, the alkaloids are bound to meconic acid. The method is to extract from the crushed plant with diluted sulfuric acid, which is a stronger acid than meconic acid, but not so strong to react with alkaloid molecules. The extraction is performed in many steps (one amount of crushed plant is extracted at least six to ten times, so practically every alkaloid goes into the solution). From the solution obtained at the last extraction step, the alkaloids are precipitated by either ammonium hydroxide or sodium carbonate. The last step is purifying and separating morphine from other opium alkaloids. The somewhat similar Gregory process was developed in the United Kingdom during the Second World War, which begins with stewing the entire plant, in most cases save the roots and leaves, in plain or mildly acidified water, then proceeding through steps of concentration, extraction, and purification of alkaloids. Other methods of processing "poppy straw" (i.e., dried pods and stalks) use steam, one or more of several types of alcohol, or other organic solvents.

The poppy straw methods predominate in Continental Europe and the British Commonwealth, with the latex method in most common use in India. The latex method can involve either vertical or horizontal slicing of the unripe pods with a two-to five-bladed knife with a guard developed specifically for this purpose to the depth of a fraction of a millimetre and scoring of the pods can be done up to five times. An alternative latex method sometimes used in China in the past is to cut off the poppy heads, run a large needle through them, and collect the dried latex 24 to 48 hours later.

In India, opium harvested by licensed poppy farmers is dehydrated to uniform levels of hydration at government processing centers, and then sold to pharmaceutical companies that extract morphine from the opium. However, in Turkey and Tasmania, morphine is obtained by harvesting and processing the fully mature dry seed pods with attached stalks, called "poppy straw". In Turkey, a water extraction process is used, while in Tasmania, a solvent extraction process is used.

Opium poppy contains at least 50 different alkaloids, but most of them are of very low concentration. Morphine is the principal alkaloid in raw opium and constitutes roughly 8–19% of opium by dry weight (depending on growing conditions). Some purpose-developed strains of poppy now produce opium that is up to 26% morphine by weight. A rough rule of thumb to determine the morphine content of pulverised dried poppy straw is to divide the percentage expected for the strain or crop via the latex method by eight or an empirically determined factor, which is often in the range of 5 to 15. The Norman strain of "P. Somniferum", also developed in Tasmania, produces down to 0.04% morphine but with much higher amounts of thebaine and oripavine, which can be used to synthesise semi-synthetic opioids as well as other drugs like stimulants, emetics, opioid antagonists, anticholinergics, and smooth-muscle agents.

In the 1950s and 1960s, Hungary supplied nearly 60% of Europe's total medication-purpose morphine production. To this day, poppy farming is legal in Hungary, but poppy farms are limited by law to . It is also legal to sell dried poppy in flower shops for use in floral arrangements.

It was announced in 1973 that a team at the National Institutes of Health in the United States had developed a method for total synthesis of morphine, codeine, and thebaine using coal tar as a starting material. A shortage in codeine-hydrocodone class cough suppressants (all of which can be made from morphine in one or more steps, as well as from codeine or thebaine) was the initial reason for the research.

Most morphine produced for pharmaceutical use around the world is actually converted into codeine as the concentration of the latter in both raw opium and poppy straw is much lower than that of morphine; in most countries, the usage of codeine (both as end-product and precursor) is at least equal or greater than that of morphine on a weight basis.

Morphine is a precursor in the manufacture in a large number of opioids such as dihydromorphine, hydromorphone, hydrocodone, and oxycodone as well as codeine, which itself has a large family of semi-synthetic derivatives. Morphine is commonly treated with acetic anhydride and ignited to yield heroin.
Throughout Europe there is growing acceptance within the medical community of the use of slow release oral morphine as a substitution treatment alternative to methadone and buprenorphine for patients not able to tolerate the side-effects of buprenorphine and methadone. Slow-release oral morphine has been in widespread use for opiate maintenance therapy in Austria, Bulgaria, and Slovakia for many years and it is available on a small scale in many other countries including the UK. The long-acting nature of slow-release morphine mimics that of buprenorphine because the sustained blood levels are relatively flat so there is no "high" per se that a patient would feel but rather a sustained feeling of wellness and avoidance of withdrawal symptoms. For patients sensitive to the side-effects that in part may be a result of the unnatural pharmacological actions of buprenorphine and methadone, slow-release oral morphine formulations offer a promising future for use managing opiate addiction.
The pharmacology of heroin and morphine is identical except the two acetyl groups increase the lipid solubility of the heroin molecule, causing heroin to cross the blood–brain barrier and enter the brain more rapidly in injection. Once in the brain, these acetyl groups are removed to yield morphine, which causes the subjective effects of heroin. Thus, heroin may be thought of as a more rapidly acting form of morphine.

Illicit morphine is rarely produced from codeine found in over-the-counter cough and pain medicines. This demethylation reaction is often performed using pyridine and hydrochloric acid.

Another source of illicit morphine comes from the extraction of morphine from extended-release morphine products, such as MS-Contin. Morphine can be extracted from these products with simple extraction techniques to yield a morphine solution that can be injected. As an alternative, the tablets can be crushed and snorted, injected or swallowed, although this provides much less euphoria but retains some of the extended-release effect, and the extended-release property is why MS-Contin is used in some countries alongside methadone, dihydrocodeine, buprenorphine, dihydroetorphine, piritramide, levo-alpha-acetylmethadol (LAAM), and special 24-hour formulations of hydromorphone for maintenance and detoxification of those physically dependent on opioids.

Another means of using or misusing morphine is to use chemical reactions to turn it into heroin or another stronger opioid. Morphine can, using a technique reported in New Zealand (where the initial precursor is codeine) and elsewhere known as home-bake, be turned into what is usually a mixture of morphine, heroin, 3-monoacetylmorphine, 6-monoacetylmorphine, and codeine derivatives like acetylcodeine if the process is using morphine made from demethylating codeine.

Since heroin is one of a series of 3,6 diesters of morphine, it is possible to convert morphine to nicomorphine (Vilan) using nicotinic anhydride, dipropanoylmorphine with propionic anhydride, dibutanoylmorphine and disalicyloylmorphine with the respective acid anhydrides. Glacial acetic acid can be used to obtain a mixture high in 6-monoacetylmorphine, niacin (vitamin B) in some form would be precursor to 6-nicotinylmorphine, salicylic acid may yield the salicyoyl analogue of 6-MAM, and so on.

The clandestine conversion of morphine to ketones of the hydromorphone class or other derivatives like dihydromorphine (Paramorfan), desomorphine (Permonid), metopon, etc. and codeine to hydrocodone (Dicodid), dihydrocodeine (Paracodin), etc. is more involved, time-consuming, requires lab equipment of various types, and usually requires expensive catalysts and large amounts of morphine at the outset and is less common but still has been discovered by authorities in various ways during the last 20 years or so. Dihydromorphine can be acetylated into another 3,6 morphine diester, namely diacetyldihydromorphine (Paralaudin), and hydrocodone into thebacon.

An opium-based elixir has been ascribed to alchemists of Byzantine times, but the specific formula was lost during the Ottoman conquest of Constantinople (Istanbul). Around 1522, Paracelsus made reference to an opium-based elixir that he called "laudanum" from the Latin word "laudare", meaning "to praise" He described it as a potent painkiller, but recommended that it be used sparingly. In the late eighteenth century, when the East India Company gained a direct interest in the opium trade through India, another opiate recipe called laudanum became very popular among physicians and their patients.

Morphine was discovered as the first active alkaloid extracted from the opium poppy plant in December 1804 in Paderborn, Germany, by Friedrich Sertürner. In 1817 Sertürner reported experiments in which he administered morphine to himself, three young boys, three dogs, and a mouse; all four people almost died. Sertürner originally named the substance "morphium" after the Greek god of dreams, Morpheus, as it has a tendency to cause sleep. Sertürner's morphium was six times stronger than opium. He hypothesized that, because lower doses of the drug were needed, it would be less addictive. However Sertürner became addicted to the drug, warning that "I consider it my duty to attract attention to the terrible effects of this new substance I called morphium in order that calamity may be averted."

The drug was first marketed to the general public by Sertürner and Company in 1817 as a pain medication, and also as a treatment for opium and alcohol addiction. It was first used as a poison in 1822 when Dr. Edme Castaing of France was convicted of murdering a patient. Commercial production began in Darmstadt, Germany in 1827 by the pharmacy that became the pharmaceutical company Merck, with morphine sales being a large part of their early growth. In the 1850s, Alexander Wood reported that he had injected morphine into his wife Rebecca as an experiment; the myth goes that this killed her because of respiratory depression, but she outlived her husband by ten years.

Later it was found that morphine was more addictive than either alcohol or opium, and its extensive use during the American Civil War allegedly resulted in over 400,000 sufferers from the "soldier's disease" of morphine addiction. This idea has been a subject of controversy, as there have been suggestions that such a disease was in fact a fabrication; the first documented use of the phrase "soldier's disease" was in 1915.

Diacetylmorphine (better known as heroin) was synthesized from morphine in 1874 and brought to market by Bayer in 1898. Heroin is approximately 1.5 to 2 times more potent than morphine weight for weight. Due to the lipid solubility of diacetylmorphine, it can cross the blood–brain barrier faster than morphine, subsequently increasing the reinforcing component of addiction. Using a variety of subjective and objective measures, one study estimated the relative potency of heroin to morphine administered intravenously to post-addicts to be 1.80–2.66 mg of morphine sulfate to 1 mg of diamorphine hydrochloride (heroin).

Morphine became a controlled substance in the US under the Harrison Narcotics Tax Act of 1914, and possession without a prescription in the US is a criminal offense.
Morphine was the most commonly abused narcotic analgesic in the world until heroin was synthesized and came into use. In general, until the synthesis of dihydromorphine (ca. 1900), the dihydromorphinone class of opioids (1920s), and oxycodone (1916) and similar drugs, there were no other drugs in the same efficacy range as opium, morphine, and heroin, with synthetics still several years away (pethidine was invented in Germany in 1937) and opioid agonists among the semi-synthetics were analogues and derivatives of codeine such as dihydrocodeine (Paracodin), ethylmorphine (Dionine), and benzylmorphine (Peronine). Even today, morphine is the most sought after prescription narcotic by heroin addicts when heroin is scarce, all other things being equal; local conditions and user preference may cause hydromorphone, oxymorphone, high-dose oxycodone, or methadone as well as dextromoramide in specific instances such as 1970s Australia, to top that particular list. The stop-gap drugs used by the largest absolute number of heroin addicts is probably codeine, with significant use also of dihydrocodeine, poppy straw derivatives like poppy pod and poppy seed tea, propoxyphene, and tramadol.

The structural formula of morphine was determined by 1925 by Robert Robinson. At least three methods of total synthesis of morphine from starting materials such as coal tar and petroleum distillates have been patented, the first of which was announced in 1952, by Dr. Marshall D. Gates, Jr. at the University of Rochester. Still, the vast majority of morphine is derived from the opium poppy by either the traditional method of gathering latex from the scored, unripe pods of the poppy, or processes using poppy straw, the dried pods and stems of the plant, the most widespread of which was invented in Hungary in 1925 and announced in 1930 by Hungarian pharmacologist János Kabay.

In 2003, there was discovery of endogenous morphine occurring naturally in the human body. Thirty years of speculation were made on this subject because there was a receptor that, it appeared, reacted only to morphine: the μ-opioid receptor in human tissue. Human cells that form in reaction to cancerous neuroblastoma cells have been found to contain trace amounts of endogenous morphine.


The euphoria, comprehensive alleviation of distress and therefore all aspects of suffering, promotion of sociability and empathy, "body high", and anxiolysis provided by narcotic drugs including the opioids can cause the use of high doses in the absence of pain for a protracted period, which can impart a morbid craving for the drug in the user. Being the prototype of the entire opioid class of drugs means that morphine has properties that may lend it to misuse. Morphine addiction is the model upon which the current perception of addiction is based.

Animal and human studies and clinical experience back up the contention that morphine is one of the most euphoric drugs known, and via all but the IV route heroin and morphine cannot be distinguished according to studies because heroin is a prodrug for the delivery of systemic morphine. Chemical changes to the morphine molecule yield other euphorigenics such as dihydromorphine, hydromorphone (Dilaudid, Hydal), and oxymorphone (Numorphan, Opana), as well as the latter three's methylated equivalents dihydrocodeine, hydrocodone, and oxycodone, respectively; in addition to heroin, there are dipropanoylmorphine, diacetyldihydromorphine, and other members of the 3,6 morphine diester category like nicomorphine and other similar semi-synthetic opiates like desomorphine, hydromorphinol, etc. used clinically in many countries of the world but in many cases also produced illicitly in rare instances.

In general, non-medical use of morphine entails taking more than prescribed or outside of medical supervision, injecting oral formulations, mixing it with unapproved potentiators such as alcohol, cocaine, and the like, or defeating the extended-release mechanism by chewing the tablets or turning into a powder for snorting or preparing injectables. The latter method can be as time-consuming and involved as traditional methods of smoking opium. This and the fact that the liver destroys a large percentage of the drug on the first pass impacts the demand side of the equation for clandestine re-sellers, as many customers are not needle users and may have been disappointed with ingesting the drug orally. As morphine is generally as hard or harder to divert than oxycodone in a lot of cases, morphine in any form is uncommon on the street, although ampoules and phials of morphine injection, pure pharmaceutical morphine powder, and soluble multi-purpose tablets are very popular where available.

Morphine is also available in a paste that is used in the production of heroin, which can be smoked by itself or turned to a soluble salt and injected; the same goes for the penultimate products of the Kompot (Polish Heroin) and black tar processes. Poppy straw as well as opium can yield morphine of purity levels ranging from poppy tea to near-pharmaceutical-grade morphine by itself or with all of the more than 50 other alkaloids. It also is the active narcotic ingredient in opium and all of its forms, derivatives, and analogues as well as forming from breakdown of heroin and otherwise present in many batches of illicit heroin as the result of incomplete acetylation.

Morphine is marketed under many different brand names in various parts of the world. It was formerly called Morphia in British English.

Informal names for morphine include: Cube Juice, Dope, Dreamer, Emsel, First Line, God's Drug, Hard Stuff, Hocus, Hows, Lydia, Lydic, M, Miss Emma, Mister Blue, Monkey, Morf, Morph, Morphide, Morphie, Morpho, Mother, MS, Ms. Emma, Mud, New Jack Swing (if mixed with heroin), Sister, Tab, Unkie, Unkie White, and Stuff.

MS Contin tablets are known as misties, and the 100 mg extended-release tablets as greys and blockbusters. The "speedball" can use morphine as the opioid component, which is combined with cocaine, amphetamines, methylphenidate, or similar drugs. "Blue Velvet" is a combination of morphine with the antihistamine tripelennamine (Pyrabenzamine, PBZ, Pelamine) taken by injection, or less commonly the mixture when swallowed or used as a retention enema; the name is also known to refer to a combination of tripelennamine and dihydrocodeine or codeine tablets or syrups taken by mouth. "Morphia" is an older official term for morphine also used as a slang term. "Driving Miss Emma" is intravenous administration of morphine. Multi-purpose tablets (readily soluble hypodermic tablets that can also be swallowed or dissolved under the tongue or betwixt the cheek and jaw) are known, as are some brands of hydromorphone, as Shake & Bake or Shake & Shoot.

Morphine can be smoked, especially diacetylmorphine (heroin), the most common method being the "Chasing The Dragon" method. To perform a relatively crude acetylation to turn the morphine into heroin and related drugs immediately prior to use is known as AAing (for Acetic Anhydride) or home-bake, and the output of the procedure also known as home-bake or, Blue Heroin (not to be confused with Blue Magic heroin, or the linctus known as Blue Morphine or Blue Morphone, or the Blue Velvet mixture described above).

Although morphine is cheap, people in poorer countries often do not have access to it. According to a 2005 estimate by the International Narcotics Control Board, six countries (Australia, Canada, France, Germany, the United Kingdom, and the United States) consume 79% of the world's morphine. The less affluent countries, accounting for 80% of the world's population, consumed only about 6% of the global morphine supply. Some countries import virtually no morphine, and in others the drug is rarely available even for relieving severe pain while dying.

Experts in pain management attribute the under-distribution of morphine to an unwarranted fear of the drug's potential for addiction and abuse. While morphine is clearly addictive, Western doctors believe it is worthwhile to use the drug and then wean the patient off when the treatment is over.



</doc>
<doc id="20616" url="https://en.wikipedia.org/wiki?curid=20616" title="Mechanical advantage">
Mechanical advantage

Mechanical advantage is a measure of the force amplification achieved by using a tool, mechanical device or machine system. The device preserves the input power and simply trades off forces against movement to obtain a desired amplification in the output force. The model for this is the "law of the lever." Machine components designed to manage forces and movement in this way are called mechanisms. 
An ideal mechanism transmits power without adding to or subtracting from it. This means the ideal mechanism does not include a power source, is frictionless, and is constructed from rigid bodies that do not deflect or wear. The performance of a real system relative to this ideal is expressed in terms of efficiency factors that take into account departures from the ideal.

The lever is a movable bar that pivots on a fulcrum attached to or positioned on or across a fixed point. The lever operates by applying forces at different distances from the fulcrum, or pivot. The location of the fulcrum determines a lever's class. Where a lever rotates, continuously, it functions as a rotary 2nd-class lever. The motion of the lever's end-point describes a fixed orbit, where mechanical energy can be exchanged. (see a hand-crank as an example.)

In modern times, this kind of rotary leverage is widely used; see a (rotary) 2nd-class lever; see gears, pulleys or friction drive, used in a mechanical power transmission scheme. It is common for mechanical advantage to be manipulated in a 'collapsed' form, via the use of more than one gear (a gearset). In such a gearset, gears having smaller radii and less inherent mechanical advantage are used. In order to make use of non-collapsed mechanical advantage, it is necessary to use a 'true length' rotary lever. See, also, the incorporation of mechanical advantage into the design of certain types of electric motors; one design is an 'outrunner'. 
As the lever pivots on the fulcrum, points farther from this pivot move faster than points closer to the pivot. The power into and out of the lever is the same, so must come out the same when calculations are being done. Power is the product of force and velocity, so forces applied to points farther from the pivot must be less than when applied to points closer in.

If "a" and "b" are distances from the fulcrum to points "A" and "B" and if force "F" applied to "A" is the input force and "F" exerted at "B" is the output, the ratio of the velocities of points "A" and "B" is given by "a"/"b" so the ratio of the output force to the input force, or mechanical advantage, is given by

This is the "law of the lever", which was proven by Archimedes using geometric reasoning. It shows that if the distance "a" from the fulcrum to where the input force is applied (point "A") is greater than the distance "b" from fulcrum to where the output force is applied (point "B"), then the lever amplifies the input force. If the distance from the fulcrum to the input force is less than from the fulcrum to the output force, then the lever reduces the input force. Recognizing the profound implications and practicalities of the law of the lever, Archimedes has been famously attributed the quotation "Give me a place to stand and with a lever I will move the whole world."

The use of velocity in the static analysis of a lever is an application of the principle of virtual work.

The requirement for power input to an ideal mechanism to equal power output provides a simple way to compute mechanical advantage from the input-output speed ratio of the system.

The power input to a gear train with a torque "T" applied to the drive pulley which rotates at an angular velocity of "ω" is "P=Tω".

Because the power flow is constant, the torque "T" and angular velocity "ω" of the output gear must satisfy the relation
which yields
This shows that for an ideal mechanism the input-output speed ratio equals the mechanical advantage of the system. This applies to all mechanical systems ranging from robots to linkages.

Gear teeth are designed so that the number of teeth on a gear is proportional to the radius of its pitch circle, and so that the pitch circles of meshing gears roll on each other without slipping. The speed ratio for a pair of meshing gears can be computed from ratio of the radii of the pitch circles and the ratio of the number of teeth on each gear, its gear ratio.
The velocity "v" of the point of contact on the pitch circles is the same on both gears, and is given by 
where input gear "A" has radius "r" and meshes with output gear "B" of radius "r,
therefore,
where "N" is the number of teeth on the input gear and "N" is the number of teeth on the output gear.

The mechanical advantage of a pair of meshing gears for which the input gear has "N" teeth and the output gear has "N" teeth is given by

This shows that if the output gear "G" has more teeth than the input gear "G", then the gear train "amplifies" the input torque. And, if the output gear has fewer teeth than the input gear, then the gear train "reduces" the input torque.

If the output gear of a gear train rotates more slowly than the input gear, then the gear train is called a "speed reducer" (Force multiplier). In this case, because the output gear must have more teeth than the input gear, the speed reducer will amplify the input torque.

Mechanisms consisting of two sprockets connected by a chain, or two pulleys connected by a belt are designed to provide a specific mechanical advantage in power transmission systems.

The velocity "v" of the chain or belt is the same when in contact with the two sprockets or pulleys:
where the input sprocket or pulley "A" meshes with the chain or belt along the pitch radius "r" and the output sprocket or pulley "B" meshes with this chain or belt along the pitch radius "r",

therefore
where "N" is the number of teeth on the input sprocket and "N" is the number of teeth on the output sprocket. For a toothed belt drive, the number of teeth on the sprocket can be used. For friction belt drives the pitch radius of the input and output pulleys must be used.

The mechanical advantage of a pair of a chain drive or toothed belt drive with an input sprocket with "N" teeth and the output sprocket has "N" teeth is given by

The mechanical advantage for friction belt drives is given by

Chains and belts dissipate power through friction, stretch and wear, which means the power output is actually less than the power input, which means the mechanical advantage of the real system will be less than that calculated for an ideal mechanism. A chain or belt drive can lose as much as 5% of the power through the system in friction heat, deformation and wear, in which case the efficiency of the drive is 95%.

Consider the 18-speed bicycle with 7 in (radius) cranks and 26 in (diameter) wheels. If the sprockets at the crank and at the rear drive wheel are the same size, then the ratio of the output force on the tire to the input force on the pedal can be calculated from the law of the lever to be

Now, assume that the front sprockets have a choice of 28 and 52 teeth, and that the rear sprockets have a choice of 16 and 32 teeth. Using different combinations, we can compute the following speed ratios between the front and rear sprockets

The ratio of the force driving the bicycle to the force on the pedal, which is the total mechanical advantage of the bicycle, is the product of the speed ratio (or teeth ratio of output sproket/input sproket) and the crank-wheel lever ratio.

Notice that in every case the force on the pedals is greater than the force driving the bicycle forward (in the illustration above, the corresponding backward-directed reaction force on the ground is indicated). This low mechanical advantage keeps the pedal crank speed low relative to the speed of the drive wheel, even in low gears.

A block and tackle is an assembly of a rope and pulleys that is used to lift loads. A number of pulleys are assembled together to form the blocks, one that is fixed and one that moves with the load. The rope is threaded through the pulleys to provide mechanical advantage that amplifies that force applied to the rope.

In order to determine the mechanical advantage of a block and tackle system consider the simple case of a gun tackle, which has a single mounted, or fixed, pulley and a single movable pulley. The rope is threaded around the fixed block and falls down to the moving block where it is threaded around the pulley and brought back up to be knotted to the fixed block.
Let "S" be the distance from the axle of the fixed block to the end of the rope, which is "A" where the input force is applied. Let "R" be the distance from the axle of the fixed block to the axle of the moving block, which is "B" where the load is applied.

The total length of the rope "L" can be written as
where "K" is the constant length of rope that passes over the pulleys and does not change as the block and tackle moves.

The velocities "V" and "V" of the points "A" and "B" are related by the constant length of the rope, that is
or
The negative sign shows that the velocity of the load is opposite to the velocity of the applied force, which means as we pull down on the rope the load moves up.

Let "V" be positive downwards and "V" be positive upwards, so this relationship can be written as the speed ratio
where 2 is the number of rope sections supporting the moving block.

Let "F" be the input force applied at "A" the end of the rope, and let "F" be the force at "B" on the moving block. Like the velocities "F" is directed downwards and "F" is directed upwards.

For an ideal block and tackle system there is no friction in the pulleys and no deflection or wear in the rope, which means the power input by the applied force "F""V" must equal the power out acting on the load "F""V", that is

The ratio of the output force to the input force is the mechanical advantage of an ideal gun tackle system,

This analysis generalizes to an ideal block and tackle with a moving block supported by "n" rope sections,

This shows that the force exerted by an ideal block and tackle is "n" times the input force, where "n" is the number of sections of rope that support the moving block.

Mechanical advantage that is computed using the assumption that no power is lost through deflection, friction and wear of a machine is the maximum performance that can be achieved. For this reason, it is often called the "ideal mechanical advantage" (IMA). In operation, deflection, friction and wear will reduce the mechanical advantage. The amount of this reduction from the ideal to the "actual mechanical advantage" (AMA) is defined by a factor called "efficiency", a quantity which is determined by experimentation.

As an ideal example, using a block and tackle with six ropes and a 600 pound load, the operator would be required to pull the rope six feet and exert 100 pounds of force to lift the load one foot. Both the ratios "F" / "F" and "V" / "V" from below show that the IMA is six. For the first ratio, 100 pounds of force in results in 600 pounds of force out; in the real world, the force out would be less than 600 pounds. The second ratio also yields a MA of 6 in the ideal case but fails in real world calculations; it does not properly account for energy losses. Subtracting those losses from the IMA or using the first ratio yields the AMA. The ratio of AMA to IMA is the mechanical efficiency of the system.

The "ideal mechanical advantage" (IMA), or "theoretical mechanical advantage", is the mechanical advantage of a device with the assumption that its components do not flex, there is no friction, and there is no wear. It is calculated using the physical dimensions of the device and defines the maximum performance the device can achieve.

The assumptions of an ideal machine are equivalent to the requirement that the machine does not store or dissipate energy; the power into the machine thus equals the power out. Therefore, the power P is constant through the machine and force times velocity into the machine equals the force times velocity out--that is,

The ideal mechanical advantage is the ratio of the force out of the machine (load) to the force into the machine (effort), or
Applying the constant power relationship yields a formula for this ideal mechanical advantage in terms of the speed ratio:

The speed ratio of a machine can be calculated from its physical dimensions. The assumption of constant power thus allows use of the speed ratio to determine the maximum value for the mechanical advantage.

The "actual mechanical advantage" (AMA) is the mechanical advantage determined by physical measurement of the input and output forces. Actual mechanical advantage takes into account energy loss due to deflection, friction, and wear.

The AMA of a machine is calculated as the ratio of the measured force output to the measured force input,
where the input and output forces are determined experimentally.

The ratio of the experimentally determined mechanical advantage to the ideal mechanical advantage is the efficiency η of the machine,





</doc>
<doc id="20617" url="https://en.wikipedia.org/wiki?curid=20617" title="Marathi language">
Marathi language

Marathi (; ; ) is an Indo-Aryan language spoken predominantly by around 83.1 million Marathi people of Maharashtra, India. It is the official language and co-official language in the Maharashtra and Goa states of Western India, respectively, and is one of the 22 scheduled languages of India. At 83.1 million speakers in 2019, Marathi ranks 10th in the list of most spoken languages in the world. Marathi has the third largest number of native speakers in India, after Hindi and Bengali. The language has some of the oldest literature of all modern Indian languages, dating back to around 600 AD. The major dialects of Marathi are Standard Marathi and the Varhadi dialect. Koli and Malvani Konkani have been heavily influenced by Marathi varieties.

Marathi distinguishes inclusive and exclusive forms of 'we' and possesses a three-way gender system that features the neuter in addition to the masculine and the feminine. In its phonology, it contrasts apico-alveolar with alveopalatal affricates and alveolar with retroflex laterals ( and (Marathi letters and respectively).

Marathi is primarily spoken in Maharashtra (India), and parts of neighbouring states of Gujarat, Madhya Pradesh, Goa, Karnataka (particularly the bordering districts of Belgaum, Bidar, Gulbarga and Uttara Kannada), Telangana, union-territories of Daman and Diu and Dadra and Nagar Haveli. The former Maratha ruled cities of Baroda, Indore, Gwalior, Jabalpur and Tanjore have had sizable Marathi speaking populations for centuries. Marathi is also spoken by Maharashtrian migrants to other parts of India and overseas. For instance, the people from western India, that emigrated to Mauritius in the early 19th century also speak Marathi. 

There were 83 million native Marathi speakers in India, according to the 2011 census, making it the third most spoken native language after Hindi and Bengali. Native Marathi speakers form 6.86% of India's population. Native speakers of Marathi formed 68.93% of the population in Maharashtra, 10.89% in Goa, 7.01% in Dadra and Nagar Haveli, 4.53% in Daman and Diu, 3.38% in Karnataka, 1.7% in Madhya Pradesh and 1.52% in Gujarat.

Marathi is the official language of Maharashtra and co-official language in the union territories of Daman and Diu and Dadra and Nagar Haveli. In Goa, Konkani is the sole official language; however, Marathi may also be used for some official purposes in some cases. Marathi is included among the languages which stand a part of the Eighth Schedule of the Constitution of India, thus granting it the status of a "scheduled language". The Government of Maharashtra has submitted an application to the Ministry of Culture to grant "classical language" status to Marathi.

The contemporary grammatical rules described by Maharashtra Sahitya Parishad and endorsed by the Government of Maharashtra are supposed to take precedence in standard written Marathi. Traditions of Marathi Linguistics and the above-mentioned rules give special status to tatsamas, words adapted from Sanskrit. This special status expects the rules for tatsamas to be followed as in Sanskrit. This practice provides Marathi with a large corpus of Sanskrit words to cope with demands of new technical words whenever needed.

In addition to all universities in Maharashtra, Maharaja Sayajirao University of Baroda in Vadodara, Osmania University in Hyderabad, Karnataka University in Dharwad, Gulbarga University in Kalaburagi, Devi Ahilya University in Indore and Goa University in Goa have special departments for higher studies in Marathi linguistics. Jawaharlal Nehru University (New Delhi) has announced plans to establish a special department for Marathi.

Marathi Day is celebrated on 27 February, the birthday of the poet Kusumagraj (Vishnu Vaman Shirwadkar).

Indian languages, including Marathi, that belong to the Indo-Aryan language family are derived from early forms of Prakrit. Marathi is one of several languages that further descend from Maharashtri Prakrit. Further change led to the Apabhraṃśa languages like Old Marathi, however, this is challenged by Bloch (1970), who states that Apabhraṃśa was formed after Marathi had already separated from the Middle Indian dialect.

The earliest example of Maharashtri as a separate language dates to approximately 3rd century BCE: a stone inscription found in a cave at Naneghat, Junnar in Pune district had been written in Maharashtri using Brahmi script. A committee appointed by the Maharashtra State Government to get the Classical status for Marathi has claimed that Marathi existed at least 2300 years ago alongside Sanskrit as a sister language. Marathi, a derivative of Maharashtri, is probably first attested in a 739 CE copper-plate inscription found in Satara. Several inscriptions dated to the second half of the 11th century feature Marathi, which is usually appended to Sanskrit or Kannada in these inscriptions. The earliest Marathi-only inscriptions are the ones issued during the Shilahara rule, including a c. 1012 CE stone inscription from Akshi taluka of Raigad district, and a 1060 or 1086 CE copper-plate inscription from Dive that records a land grant ("agrahara") to a Brahmin. A 2-line 1118 CE Marathi inscription at Shravanabelagola records a grant by the Hoysalas. These inscriptions suggest that Marathi was a standard written language by the 12th century. However, there is no record of any literature produced in Marathi until the late 13th century.

After 1187 CE, the use of Marathi grew substantially in the inscriptions of the Seuna (Yadava) kings, who earlier used Kannada and Sanskrit in their inscriptions. Marathi became the dominant language of epigraphy during the last half century of the dynasty's rule (14th century), and may have been a result of the Yadava attempts to connect with their Marathi-speaking subjects and to distinguish themselves from the Kannada-speaking Hoysalas.

Further growth and usage of the language was because of two religious sects – the Mahanubhava and Varkari "panthan"s – who adopted Marathi as the medium for preaching their doctrines of devotion. Marathi was used in court life by the time of the Seuna kings. During the reign of the last three Seuna kings, a great deal of literature in verse and prose, on astrology, medicine, Puranas, Vedanta, kings and courtiers were created. "Nalopakhyan", "Rukmini swayamvar" and Shripati's "Jyotishratnamala" (1039) are a few examples.

The oldest book in prose form in Marathi, "Vivēkasindhu" (), was written by Mukundaraja, a Nath yogi and arch-poet of Marathi. Mukundaraja bases his exposition of the basic tenets of the Hindu philosophy and the yoga marga on the utterances or teachings of Shankaracharya. Mukundaraja's other work, "Paramamrta," is considered the first systematic attempt to explain the Vedanta in the Marathi language

Notable examples of Marathi prose are "" (), events and anecdotes from the miracle-filled the life of Chakradhar Swami of the Mahanubhava sect compiled by his close disciple, Mahimbhatta, in 1238. The "Līḷācarītra" is thought to be the first biography written in the Marathi language. Mahimbhatta's second important literary work is the "Shri Govindaprabhucharitra" or "Rudhipurcharitra", a biography of Shri Chakradhar Swami's guru, Shri Govind Prabhu. This was probably written in 1288. The Mahanubhava sect made Marathi a vehicle for the propagation of religion and culture. Mahanubhava literature generally comprises works that describe the incarnations of gods, the history of the sect, commentaries on the "Bhagavad Gita", poetical works narrating the stories of the life of Krishna and grammatical and etymological works that are deemed useful to explain the philosophy of sect.

The 13th-century varkari saint Dnyaneshwar (1275–1296) wrote a treatise in Marathi on Bhagawat Gita popularly called "Dnyaneshwari" and "Amritanubhava". His contemporary, Namdev, composed verses or abhang in Marathi as well as Hindi.

Mukund Raj was a poet who lived in the 13th century and is said to be the first poet who composed in Marathi. He is known for the "Viveka-Siddhi" and "Parammrita" which are metaphysical, pantheistic works connected with orthodox Vedantism.

The 16th century saint-poet Eknath (1528–1599) is well known for composing the Eknāthī Bhāgavat, a commentary on Bhagavat Purana and the devotional songs called Bharud. Mukteshwar translated the "Mahabharata" into Marathi; Tukaram (1608–49) transformed Marathi into a rich literary language. His poetry contained his inspirations. Tukaram wrote over 3000 abhangs or devotional songs.

Marathi was widely used during the Sultanate period. Although the rulers were Muslims, the local feudal landlords and the revenue collectors were Hindus and so was the majority of the population. To simplify administration and revenue collection, the sultans promoted use of Marathi in official documents. However, the Marathi language from the era is heavily persianised in its vocabulary. The Persian influence continues to this day with many Persian derived words used in every day speech such as bāg (Garden), kārkhānā (factory), shahar (city), bāzār (market), dukān (shop), hushār (clever), kāḡaḏ (paper), khurchi (chair), jamin (land), jāhirāt (advertisement), and hazār (thousand) Marathi also became language of administration during the Ahmadnagar Sultanate. Adilshahi of Bijapur also used Marathi for administration and record keeping.

Marathi gained prominence with the rise of the Maratha Empire beginning with the reign of Chhatrapati Shivaji Maharaj (ruled 1674–1680). Under Shivaji, the language used in administrative documents became less persianised. Whereas in 1630, 80% of the vocabulary was Persian, it dropped to 37% by 1677 Samarth Ramdas was a contemporary of Shivaji. He advocated the unity of Marathas to propagate Maharashtra dharma. Unlike varkari saints, his writing has a strong militant expression to it. Subsequent Maratha rulers extended the empire northwards to Attock, eastwards to Odisha, and southwards to Thanjavur in Tamil Nadu. These excursions by the Marathas helped to spread Marathi over broader geographical regions. This period also saw the use of Marathi in transactions involving land and other business. Documents from this period, therefore, give a better picture of the life of common people. There are a lot of Bakharis written in Marathi and Modi script from this period. But by the late 18th century, the Maratha Empire's influence over a large part of the country was on the decline.

In the 18th century during Peshwa rule, some well-known works such as Yatharthadeepika by Vaman Pandit, Naladamayanti Swayamvara by Raghunath Pandit, Pandava Pratap, Harivijay, Ramvijay by Shridhar Pandit and Mahabharata by Moropant were produced. Krishnadayarnava and Sridhar were poets during the Peshwa period. New literary forms were successfully experimented with during the period and classical styles were revived, especially the Mahakavya and Prabandha forms. The most important hagiographies of Varkari Bhakti saints was written by Mahipati in the 18th Century.
Other well known literary scholars of the 17th century were Mukteshwar and Shridhar. Mukteshwar was the grandson of Eknath and is the most distinguished poet in the "Ovi" meter. He is most known for translating the Mahabharata and the Ramayana in Marathi but only a part of the Mahabharata translation is available and the entire Ramayana translation is lost. Shridhar Kulkarni came from the Pandharpur area and his works are said to have superseded the Sanskrit epics to a certain extent. This period also saw the development of Powada (ballads sung in honor of warriors), and Lavani (romantic songs presented with dance and instruments like tabla). Major poet composers of Powada and Lavani songs of the 17th and the 18th century were Anant Phandi, Ram Joshi and Honaji Bala.

The British colonial period starting in early 1800s saw standardisation of Marathi grammar through the efforts of the Christian missionary William Carey. Carey's dictionary had fewer entries and Marathi words were in Devanagari. Translations of the Bible were first books to be printed in Marathi.These translations by William Carey, the American Marathi mission and the Scottish missionaries led to the development of a peculiar pidginized Marathi called the "Missionary Marathi in early 1800s The most comprehensive Marathi-English dictionary was compiled by Captain James Thomas Molesworth and Major Thomas Candy in 1831. The book is still in print nearly two centuries after its publication.
The colonial authorities also worked on standardizing Marathi under the leadership of James Thomas Molesworth and Candy. They used Brahmins of Pune for this task and adopted the Sanskrit dominated dialect spoken by the elite in the city as the standard dialect for Marathi.

The first Marathi translation of the New Testament was published in 1811 by the Serampore press of William Carey. The first Marathi newspaper called Durpan was started by Balshastri Jambhekar in 1832. Newspapers provided a platform for sharing literary views, and many books on social reforms were written. First Marathi periodical "Dirghadarshan" was started in 1840. 
The Marathi language flourished, as Marathi drama gained popularity. Musicals known as "Sangeet Natak" also evolved . Keshavasut, the father of modern Marathi poetry published his first poem in 1885. 
The late-19th century in Maharashtra saw the rise of essayist Vishnushastri Chiplunkar with his periodical, Nibandhmala that had essays that criticized social reformers like Phule and Gopal Hari Deshmukh. He also founded the popular Marathi periodical of that era called Kesari in 1881. Later under the editorship of Lokmanya Tilak, the newspaper was instrumental in spreading Tilak's nationalist and social views. Tilak was also opposed to intercaste marriage, particularly the match where an upper caste woman married a lower caste man. Phule and Deshmukh also started their own periodicals, "Deenbandhu" and "Prabhakar", that criticised the prevailing Hindu culture of the day. The 19th century and early 20th century saw several books published on Marathi grammar. Notable grammarians of this period were Tarkhadkar, A.K.Kher, Moro Keshav Damle, and R.Joshi

The first half of the 20th century was marked by new enthusiasm in literary pursuits, and socio-political activism helped achieve major milestones in Marathi literature, drama, music and film.. Modern Marathi prose flourished: for example, N.C.Kelkar's biographical writings, novels of Hari Narayan Apte, Narayan Sitaram Phadke and V. S. Khandekar, Vinayak Damodar Savarkar's nationalist literature and plays of Mama Varerkar and Kirloskar.

After Indian independence, Marathi was accorded the status of a scheduled language on the national level. In 1956, the then Bombay state was reorganized which brought most Marathi and Gujarati speaking areas under one state. Further re-organization of the Bombay state on 1 May 1960, created the Marathi speaking Maharashtra and Gujarati speaking Gujarat state respectively. With state and cultural protection, Marathi made great strides by the 1990s.
A literary event called "Akhil Bharatiya Marathi Sahitya Sammelan" (All-India Marathi Literature Meet) is held every year. In addition, the "Akhil Bharatiya Marathi Natya Sammelan" (All-India Marathi Theatre Convention) is also held annually. Both events are very popular among Marathi speakers.

Notable works in Marathi in the latter half of 20th century include Khandekar's Yayati, which won him the Jnanpith Award. Also Vijay Tendulkar's plays in Marathi have earned him a reputation beyond Maharashtra. P.L.Deshpande(PuLa), Vishnu Vaman Shirwadkar,
P.K.Atre & Prabodhankar Thackeray, were also known for their writings in Marathi in the field of drama, comedy and social commentary

In 1958 the term "Dalit literature" was used for the first time, when the first conference of "Maharashtra Dalit Sahitya Sangha" (Maharashtra Dalit Literature Society) was held at Mumbai, a movement inspired by 19th century social reformer, Jyotiba Phule and eminent dalit leader, Dr. Bhimrao Ambedkar.
Baburao Bagul (1930–2008) was a pioneer of Dalit writings in Marathi. His first collection of stories, "Jevha Mi Jat Chorali" (When I Concealed My Caste), published in 1963, created a stir in Marathi literature with its passionate depiction of a cruel society and thus brought in new momentum to Dalit literature in Marathi. Gradually with other writers like, Namdeo Dhasal (who founded Dalit Panther), these Dalit writings paved way for the strengthening of Dalit movement. Notable Dalit authors writing in Marathi include Arun Kamble, Shantabai Kamble, Raja Dhale, Namdev Dhasal, Daya Pawar, Annabhau Sathe, Laxman Mane, Laxman Gaikwad, Sharankumar Limbale, Bhau Panchbhai, Kishor Shantabai Kale, Narendra Jadhav, Keshav Meshram, Urmila Pawar, Vinay Dharwadkar, Gangadhar Pantawane, Kumud Pawde and Jyoti Lanjewar.

In recent decades there has been a trend among Marathi speaking parents of all social classes in major urban areas of sending their children to English medium schools. There is some concern, though without foundation, that this may lead to the marginalization of the language.

Standard Marathi is based on dialects used by academics and the print media.

Indic scholars distinguish 42 dialects of spoken Marathi. Dialects bordering other major language areas have many properties in common with those languages, further differentiating them from standard spoken Marathi. The bulk of the variation within these dialects is primarily lexical and phonological (e.g. accent placement and pronunciation). Although the number of dialects is considerable, the degree of intelligibility within these dialects is relatively high.

Zadi Boli or Zhadiboli (झाडीबोली) is spoken in Zadipranta (a forest rich region) of far eastern Maharashtra or eastern Vidarbha or western-central Gondwana comprising Gondia, Bhandara, Chandrapur, Gadchiroli and some parts of Nagpur of Maharashtra.

Zadi Boli Sahitya Mandal and many literary figures are working for the conservation of this important and distinct dialect of Marathi.

Thanjavur Marathi, Namadeva Shimpi Marathi, Arey Marathi and Bhavsar Marathi are some of the dialects of Marathi spoken by many descendants of Maharashtrians who migrated to the Southern India.

These dialects retain the 17th-century basic form of Marathi and have been considerably influenced by the Dravidian languages after the migration. These dialects have speakers in various parts of Tamil Nadu, Andhra Pradesh and Karnataka.

"Varhadi" (Varhādi) (वऱ्हाडी) or "Vaidarbhi" (वैदर्भी) is spoken in the Western Vidarbha region of Maharashtra.
In Marathi, the retroflex lateral approximant "ḷ" is common, while in the Varhadii dialect, it corresponds to the palatal approximant "y" (IPA: [j]), making this dialect quite distinct. Such phonetic shifts are common in spoken Marathi and, as such, the spoken dialects vary from one region of Maharashtra to another.

Other languages and dialects spoken in Maharashtra include Maharashtrian Konkani, Koli, Malvani, Agri, Andh, Warli, Dangi, Khandeshi, Ahirani, Kokna, Vadvali, Samavedi, Marathwadi and Deshi.

The phoneme inventory of Marathi is similar to that of many other Indo-Aryan languages. An chart of all contrastive sounds in Marathi is provided below.

Older aspirated have lost their onset, with merging with and being typically realised as an aspirated fricative, . This series is not distinguished in writing from .

There are two more vowels in Marathi to denote the pronunciations of English words such as of "a" in "act" and "a" in "all". These are written as and . The IPA signs for these are and , respectively.
Maharashtri Prakrit, the ancestor of modern Marathi, is a particularly interesting case. Maharashtri was often used for poetry and as such, diverged from proper Sanskrit grammar mainly to fit the language to the meter of different styles of poetry. The new grammar stuck, which led to the unique flexibility of vowels lengths – amongst other anomalies – in Marathi. Marathi retains the original Sanskrit pronunciation of certain letters such as the "anusvāra" (for instance, "saṃhar," compared to "sanhar" in Hindi). Moreover, Marathi preserves certain Sanskrit patterns of pronunciation, as in the words "purṇa" and "rāma" compared to "purṇ" and "rām" in Hindi.

Kadamba alphabet and its variants has been historically used to write Marathi in the form of inscriptions on stones and copper plates. The Marathi version of Devanagari, called "Balbodh", is similar to the Hindi Devanagari alphabet except for its use as words in Marathi traditionally pronounce schwa making its written form differ even from other Marathi words. For example, the word 'रंग' (colour) is pronounced as 'ranga' in Marathi & 'rang' in other languages using Devanagari despite same spelling, 'खरं' (true) despite the anuswara is pronounced as 'Khara' as the Anusara in this case is used to avoid schwa deletion in pronunciation since most other languages using Devanagari show schwa deletion in pronunciation despite the presence of schwa in the written spelling. From the 13th century until the beginning of British rule in 19th century, Marathi was written in the Modi script for administrative purposes but in Devnagari for literature. Since 1950 it has been written in the Balbodh style of Devanagari.Except for Father Stephen's Krista Purana in the Latin script in the 1600s, Marathi has mainly been printed in Devanagari because William Carey, the pioneer of printing in Indian languages, was only able to print in Devanagari. He later tried printing in Modi but by that time, Balbodh Devanagari had been accepted for printing.

Marathi is usually written in the "Balbodh" version of Devanagari script, an abugida consisting of 36 consonant letters and 16 initial-vowel letters. It is written from left to right. The Devanagari alphabet used to write Marathi is slightly different from the Devanagari alphabets of Hindi and other languages: there are a couple of additional letters in the Marathi alphabet, and Western punctuation is used.

As with a large part of India, a traditional duality existed in script usage between Devanagari by religiously educated people (most notably Brahmins) and Modi for common usage among administrators, businesspeople, and others. As observed in 1807, 

Vowels

Vowel ligatures with Consonant क/ka

consonants

क ख ग घ ङ 
च छ ज झ ञ 
ट ठ ड ढ ण 
त थ द ध न 
प फ ब भ म 
य र ल व 
श ष स 
ह ळ 
क्ष ज्ञ

"ka kha ga gha ṅa"

"ca cha ja jha ña"

"ṭa ṭha ḍa ḍha ṇa"

"ta tha da dha na"

"pa pha ba bha ma"

"ya ra la va"

"śa ṣa sa"

"ha ḷa"

"kṣa dña/jña"

It is written from left to right. Devanagari used to write Marathi is slightly different than that of Hindi or other languages. It uses additional vowels and consonants that are not found in other languages that also use Devanagari.

From the thirteenth century until 1950, Marathi, especially for business use, was written in the Modi alphabet, a cursive script designed for minimising the lifting of pen from paper while writing.

In Devanagari, consonant letters by default come with an inherent schwa. Therefore, will be <nowiki>'təyāche'</nowiki>, not <nowiki>'tyāche'</nowiki>. To form <nowiki>'tyāche'</nowiki>, you will have to write it as + , giving .

When two or more consecutive consonants are followed by a vowel then a "jodakshar" (consonant cluster) is formed. Some examples of consonant clusters are shown below:

In writing, Marathi has a few digraphs that are rarely seen in the world's languages, including those denoting the so-called "nasal aspirates" (ṇh, nh, and mh) and liquid aspirates (rh, ṟh, lh, and vh). Some examples are given below.


Marathi grammar shares similarities with other modern Indo-Aryan languages. The first modern book exclusively concerning Marathi grammar was printed in 1805 by William Carey.

Marathi employs agglutinative, inflectional and analytical forms. Unlike most other Indo-Aryan languages, Marathi preserves all three grammatical genders from Sanskrit: masculine, feminine and neuter. The primary word order of Marathi is subject–object–verb Marathi follows a split-ergative pattern of verb agreement and case marking: it is ergative in constructions with either perfective transitive verbs or with the obligative ("should", "have to") and it is nominative elsewhere. An unusual feature of Marathi, as compared to other Indo-European languages, is that it displays inclusive and exclusive we also found in Rajasthani and Gujarati and common to the Austronesian and Dravidian languages. Other similarities to Dravidian include the extensive use of participial constructions and also to a certain extent the use of the two anaphoric pronouns and . Numerous scholars have noted the existence of Dravidian linguistic patterns in the Marathi language.

Over a period of many centuries, the Marathi language and people came into contact with many other languages and dialects. The primary influence of Prakrit, Maharashtri, Apabhraṃśa and Sanskrit is understandable. Marathi borrows a lot of its vocabulary from Sanskrit.

Marathi has also shared directions, vocabulary, and grammar with languages such as Indian Dravidian languages, and foreign languages such as Persian, Arabic, English and a little from Portuguese.

Vinayak Damodar Savarkar, a noted Hindutva ideologue, writer, and poet, contributed to the Marathi language by coining new Marathi equivalents for words from other languages, mostly English. Prior to these Marathi equivalents, words from other languages were widely used, which was unacceptable to Savarkar. He opined that foreign words polluted the Marathi language and also made original Marathi words with the same meanings obsolete. The following are some of the words coined and popularized by him:



Spoken Marathi contains a high number of Sanskrit-derived ("tatsama") words. Such words are for example "nantar" (from "nantara" or after), ' (' or complete, full, or full measure of something), "ola" ("ola" or damp), ' (' or cause), "puṣkaḷ" ("puṣkala" or much, many), "satat" ("satata" or always), "vichitra" ("vichitra" or strange), "svatah" ("svatah" or himself/herself), "prayatna" ("prayatna" or effort, attempt), "bhīti" (from "bhīti", or fear) and "bhāṇḍa" ("bhāṇḍa" or vessel for cooking or storing food). Other words ("tadbhavas") have undergone phonological changes from their Sanskrit roots, for example "dār" ("dwāra" or door), "ghar" ("gṛha" or house), "vāgh" ("vyāghra" or tiger), "paḷaṇe" ("palāyate" or to run away), "kiti" ("kati" or how many) have undergone more modification.
Examples of words borrowed from other Indian and foreign languages include:

A lot of English words are commonly used in conversation and are considered to be assimilated into the Marathi vocabulary. These include "pen" (native Marathi "lekhaṇii") and "shirt" ("sadaraa").

Marathi uses many morphological processes to join words together, forming compounds. For example, "ati" + "uttam" gives the word "atyuttam", "miith-bhaakar" ("salt-bread"), "udyog-patii" ("businessman"), "ashṭa-bhujaa" ("eight-hands", name of a Hindu goddess).

Like many other languages, Marathi uses distinct names for the numbers 1 to 20 and each multiple of 10, and composite ones for those greater than 20.

As with other Indic languages, there are distinct names for the fractions , , and . They are "paava", "ardhaa", and "pauṇa", respectively. For most fractions greater than 1, the prefixes "savvaa-", "saaḍe-", "paavaṇe-" are used. There are special names for ("diiḍ") , ("aḍich"), and ("aut").

Powers of ten are denoted by separate specific words as depicted in below table.

A positive integer is read by breaking it up from the tens digit leftwards, into parts each containing two digits, the only exception being the hundreds place containing only one digit instead of two. For example, 1,234,567 is written as 12,34,567 and read as "12 lakh 34 Hazara 5 she 67".

Every two-digit number after 18 (11 to 18 are predefined) is read backward. For example, 21 is read एक-वीस (1-twenty). Also, a two digit number that ends with a 9 is considered to be the next tens place minus one. For example, 29 is एकुणतीस/एकोणतीस (एक-उणे-तीस) (thirty minus one). Two digit numbers used before "Hazara", etc. are written in the same way.

Shrilipee, Shivaji, kothare 2,4,6, Kiran fonts KF-Kiran and many more (about 48) are clip fonts that were used prior to the introduction of Unicode standard for Devanagari script. Clip fonts are in vogue on PCs even today since most of the computers in use are working with English Keyboard. Even today a large number of printed publications of books, newspapers and magazines are prepared using these ASCII based fonts. However, clip fonts cannot be used on internet since those did not have unicode compatibility.

Earlier Marathi suffered from weak support by computer operating systems and Internet services, as have other Indian languages. But recently, with the introduction of language localization projects and new technologies, various software and Internet applications have been introduced. Various Marathi typing software is widely used and display interface packages are now available on Windows, Linux and macOS. Many Marathi websites, including Marathi newspapers, have become popular especially with Maharashtrians outside India. Online projects such as the Marathi language Wikipedia, with 36,000+ articles, the Marathi blogroll, and Marathi blogs have gained immense popularity.

Marathi Language Day (मराठी दिन/मराठी दिवस () is celebrated on 27 February every year across the Indian states of Maharashtra and Goa. This day is regulated by the State Government. It is celebrated on the Birthday of eminent Marathi Poet Vi. Va. Shirwadkar, popularly known as Kusumagraj.

Essay competitions and seminars are arranged in Schools and Colleges. Government officials are asked to conduct various events.

Many government and semi-government organizations exist which work for the regulation, promotion, and enrichment of the Marathi language. These are either initiated or funded by the government of Maharashtra. A few Marathi organizations are given below:






</doc>
<doc id="20618" url="https://en.wikipedia.org/wiki?curid=20618" title="Martin Bormann">
Martin Bormann

Martin Ludwig Bormann (17 June 1900 – 2 May 1945) was a German Nazi Party official and head of the Nazi Party Chancellery. He gained immense power by using his position as Adolf Hitler's private secretary to control the flow of information and access to Hitler. After Hitler's suicide on 30 April 1945, he was Party Minister of the National Socialist German Workers' Party.

Bormann joined a paramilitary "Freikorps" organisation in 1922 while working as manager of a large estate. He served nearly a year in prison as an accomplice to his friend Rudolf Höss (later commandant of Auschwitz concentration camp) in the murder of Walther Kadow. Bormann joined the Nazi Party in 1927 and the "Schutzstaffel" (SS) in 1937. He initially worked in the party's insurance service, and transferred in July 1933 to the office of Deputy Führer Rudolf Hess, where he served as chief of staff.

Bormann used his position to create an extensive bureaucracy and involve himself as much as possible in the decision making. He gained acceptance into Hitler's inner circle, and accompanied him everywhere, providing briefings and summaries of events and requests. He began acting as Hitler's personal secretary on 12 August 1935. Bormann assumed Hess' former duties, with the title of Head of the "Parteikanzlei" (Party Chancellery), after Hess' solo flight to Britain on 10 May 1941 to seek peace negotiations with the British government. He had final approval over civil service appointments, reviewed and approved legislation, and by 1943 had "de facto" control over all domestic matters. Bormann was one of the leading proponents of the ongoing persecution of the Christian churches and favoured harsh treatment of Jews and Slavs in the areas conquered by Germany during World War II.

Bormann returned with Hitler to the "Führerbunker" in Berlin on 16 January 1945 as the Red Army approached the city. After Hitler committed suicide, Bormann and others attempted to flee Berlin on 2 May to avoid capture by the Soviets. Bormann probably committed suicide on a bridge near Lehrter station. His body was buried nearby on 8 May 1945, but was not found and confirmed as Bormann's until 1973; the identification was reaffirmed in 1998 by DNA tests. The missing Bormann was tried "in absentia" by the International Military Tribunal in the Nuremberg trials of 1945 and 1946. He was convicted of war crimes and crimes against humanity and sentenced to death by hanging.

Born in Wegeleben (now in Saxony-Anhalt) in the Kingdom of Prussia in the German Empire, Bormann was the son of Theodor Bormann (1862–1903), a post office employee, and his second wife, Antonie Bernhardine Mennong. The family was Lutheran. He had two half-siblings (Else and Walter Bormann) from his father's earlier marriage to Louise Grobler, who died in 1898. Antonie Bormann gave birth to three sons, one of whom died in infancy. Martin and Albert (1902–89) survived to adulthood. Theodor died when Bormann was three, and his mother soon remarried.

Bormann's studies at an agricultural trade high school were interrupted when he joined the 55th Field Artillery Regiment as a gunner in June 1918, in the last days of World War I. He never saw action, but served garrison duty until February 1919. After working a short time in a cattle feed mill, Bormann became estate manager of a large farm in Mecklenburg. Shortly after starting work at the estate, Bormann joined an antisemitic landowners association. While hyperinflation in the Weimar Republic meant that money was worthless, foodstuffs stored on farms and estates became ever more valuable. Many estates, including Bormann's, had "Freikorps" units stationed on site to guard the crops from pillaging. Bormann joined the "Freikorps" organisation headed by Gerhard Roßbach in 1922, acting as section leader and treasurer.

On 17 March 1924 Bormann was sentenced to a year in Elisabethstrasse Prison as an accomplice to his friend Rudolf Höss in the murder of Walther Kadow. The perpetrators believed Kadow had tipped off the French occupation authorities in the Ruhr District that fellow "Freikorps" member Albert Leo Schlageter was carrying out sabotage operations against French industries. Schlageter was arrested and was executed on 23 May 1923. On the night of 31 May, Höss, Bormann and several others took Kadow into a meadow out of town, where he was beaten and his throat cut. After one of the perpetrators confessed, police dug up the body and laid charges in July. Bormann was released from prison in February 1925. He joined the "Frontbann", a short-lived Nazi Party paramilitary organisation created to replace the "Sturmabteilung" (SA; storm detachment or assault division), which had been banned in the aftermath of the failed Munich Putsch. Bormann returned to his job at Mecklenburg and remained there until May 1926, when he moved in with his mother in Oberweimar.

In 1927, Bormann joined the National Socialist German Workers Party (Nazi Party; NSDAP). His membership number was 60,508. He joined the "Schutzstaffel" (SS) on 1 January 1937 with number 278,267. By special order of Heinrich Himmler in 1938, Bormann was granted SS number 555 to reflect his "Alter Kämpfer" (Old Fighter) status.

Bormann took a job with "Der Nationalsozialist", a weekly paper edited by NSDAP member Hans Severus Ziegler, who was deputy "Gauleiter" (party leader) for Thuringia. After joining the NSDAP in 1927, Bormann began duties as regional press officer, but his lack of public-speaking skills made him ill-suited to this position. He soon put his organisational skills to use as business manager for the "Gau" (region). He moved to Munich in October 1928, where he worked in the SA insurance office. Initially the NSDAP provided coverage through insurance companies for members who were hurt or killed in the frequent violent skirmishes with members of other political parties. As insurance companies were unwilling to pay out claims for such activities, in 1930 Bormann set up the "Hilfskasse der NSDAP" (NSDAP Auxiliary Fund), a benefits and relief fund directly administered by the party. Each party member was required to pay premiums and might receive compensation for injuries sustained while conducting party business. Payments out of the fund were made solely at Bormann's discretion. He began to gain a reputation as a financial expert, and many party members felt personally indebted to him after receiving benefits from the fund. In addition to its stated purpose, the fund was used as a last-resort source of funding for the NSDAP, which was chronically short of money at the time. After the NSDAP's success in the 1930 general election, where they won 107 seats, party membership grew dramatically. By 1932 the fund was collecting 3 million Reichsmarks per year.

Bormann also worked on the staff of the SA from 1928 to 1930, and while there he founded the National Socialist Automobile Corps, precursor to the National Socialist Motor Corps. The organisation was responsible for co-ordinating the donated use of motor vehicles belonging to party members, and later expanded to training members in automotive skills.

After the "Machtergreifung" (NSDAP seizure of power) in January 1933, the relief fund was repurposed to provide general accident and property insurance, so Bormann resigned from its administration. He applied for a transfer and was accepted as chief of staff in the office of Rudolf Hess, the Deputy Führer, on 1 July 1933. Bormann also served as personal secretary to Hess from 4 July 1933 until May 1941. Hess' department was responsible for settling disputes within the party and acted as an intermediary between the party and the state regarding policy decisions and legislation. Bormann used his position to create an extensive bureaucracy and involve himself in as much of the decision-making as possible. On 10 October 1933 Hitler named Bormann "Reichsleiter" (national leader – the highest party rank) of the NSDAP, and in November he was named "Reichstag" deputy. By June 1934, Bormann was gaining acceptance into Hitler's inner circle and accompanied him everywhere, providing briefings and summaries of events and requests.
In 1935, Bormann was appointed as overseer of renovations at the Berghof, Hitler's property at Obersalzberg. In the early 1930s, Hitler bought the property, which he had been renting since 1925 as a vacation retreat. After he became chancellor, Hitler drew up plans for expansion and remodelling of the main house and put Bormann in charge of construction. Bormann commissioned the construction of barracks for the SS guards, roads and footpaths, garages for motor vehicles, a guesthouse, accommodation for staff, and other amenities. Retaining title in his own name, Bormann bought up adjacent farms until the entire complex covered . Members of the inner circle built houses within the perimeter, beginning with Hermann Göring, Albert Speer, and Bormann himself. Bormann commissioned the building of the "Kehlsteinhaus" (Eagle's Nest), a tea house high above the Berghof, as a gift to Hitler on his fiftieth birthday (20 April 1939). Hitler seldom used the building, but Bormann liked to impress guests by taking them there.

While Hitler was in residence at the Berghof, Bormann was constantly in attendance and acted as Hitler's personal secretary. In this capacity, he began to control the flow of information and access to Hitler. During this period, Hitler gave Bormann control of his personal finances. In addition to salaries as chancellor and president, Hitler's income included money raised through royalties collected on his book "Mein Kampf" and the use of his image on postage stamps. Bormann set up the Adolf Hitler Fund of German Trade and Industry, which collected money from German industrialists on Hitler's behalf. Some of the funds received through this programme were disbursed to various party leaders, but Bormann retained most of it for Hitler's personal use. Bormann and others took notes of Hitler's thoughts expressed over dinner and in monologues late into the night and preserved them. The material was published after the war as "Hitler's Table Talk".

The office of the Deputy Führer had final approval over civil service appointments, and Bormann reviewed the personnel files and made the decisions regarding appointments. This power impinged on the purview of Minister of the Interior Wilhelm Frick, and was an example of the overlapping responsibilities typical of the Nazi regime. Bormann travelled everywhere with Hitler, including trips to Austria in 1938 after the "Anschluss" (the annexation of Austria into Nazi Germany), and to the Sudetenland after the signing of the Munich Agreement later that year. Bormann was placed in charge of organising the 1938 Nuremberg Rally, a major annual party event.
Hitler intentionally played top party members against one another and the NSDAP against the civil service. In this way, he fostered distrust, competition, and infighting among his subordinates to consolidate and maximise his own power. He typically did not give written orders; instead he communicated them verbally or had them conveyed through Bormann. Falling out of favour with Bormann meant that access to Hitler was cut off. Bormann proved to be a master of intricate political infighting. Along with his ability to control access to Hitler, this enabled him to curtail the power of Joseph Goebbels, Göring, Himmler, Alfred Rosenberg, Robert Ley, Hans Frank, Speer, and other high-ranking officials, many of whom became his enemies. This ruthless and continuous intriguing for power, influence, and Hitler's favour came to characterise the inner workings of the Third Reich.

As World War II progressed, Hitler's attention became focused on foreign affairs and the conduct of the war to the exclusion of all else. Hess, not directly engaged in either of these endeavours, became increasingly sidelined from the affairs of the nation and from Hitler's attention; Bormann had successfully supplanted Hess in many of his duties and usurped his position at Hitler's side. Hess was concerned that Germany would face a war on two fronts as plans progressed for Operation Barbarossa, the invasion of the Soviet Union scheduled to take place later that year. He flew solo to Britain on 10 May 1941 to seek peace negotiations with the British government. He was arrested on arrival and spent the rest of the war as a British prisoner, eventually receiving a life sentence for war crimes at the Nuremberg trials in 1946. Speer later said Hitler described Hess' departure as one of the worst blows of his life, as he considered it a personal betrayal. Hitler ordered Hess to be shot should he return to Germany and abolished the post of Deputy Führer on 12 May 1941, assigning Hess' former duties to Bormann, with the title of Head of the "Parteikanzlei" (Party Chancellery). In this position he was responsible for all NSDAP appointments, and was answerable only to Hitler. Associates began to refer to him as the "Brown Eminence", although never to his face.

Bormann's power and effective reach broadened considerably during the war. By early 1943, the war produced a labour crisis for the regime. Hitler created a three-man committee with representatives of the State, the army, and the Party in an attempt to centralise control of the war economy. The committee members were Hans Lammers (head of the Reich Chancellery), Field Marshal Wilhelm Keitel, chief of the "Oberkommando der Wehrmacht" (Armed Forces High Command; OKW), and Bormann, who controlled the Party. The committee was intended to independently propose measures regardless of the wishes of various ministries, with Hitler reserving most final decisions to himself. The committee, soon known as the "Dreierausschuß" (Committee of Three), met eleven times between January and August 1943. However, they ran up against resistance from Hitler's cabinet ministers, who headed deeply entrenched spheres of influence and were excluded from the committee. Seeing it as a threat to their power, Goebbels, Göring, and Speer worked together to bring it down. The result was that nothing changed, and the Committee of Three declined into irrelevance.

While Article 24 of the National Socialist Program called for conditional toleration of Christian denominations and a "Reichskonkordat" (Reich Concordat) treaty with the Vatican was signed in 1933, purporting to guarantee religious freedom for Catholics, Hitler believed that religion was fundamentally incompatible with National Socialism. Bormann, who was strongly anti-Christian, agreed; he stated publicly in 1941 that "National Socialism and Christianity are irreconcilable." Out of political expediency, Hitler intended to postpone the elimination of the Christian churches until after the war. However, his repeated hostile statements against the church indicated to his subordinates that a continuation of the "Kirchenkampf" (church struggle) would be tolerated and even encouraged.

Bormann was one of the leading proponents of the ongoing persecution of the Christian churches. In February 1937, he decreed that members of the clergy should not be admitted to the NSDAP. The following year he ruled that any members of the clergy who were holding party offices should be dismissed, and that any party member who was considering entering the clergy had to give up his party membership. While Bormann's push to force the closure of theological departments at Reich universities was unsuccessful, he was able to reduce the amount of religious instruction provided in public schools to two hours per week and mandated the removal of crucifixes from classrooms. Speer notes in his memoirs that while drafting plans for "Welthauptstadt Germania", the planned rebuilding of Berlin, he was told by Bormann that churches were not to be allocated any building sites.

As part of the campaign against the Catholic Church, hundreds of monasteries in Germany and Austria were confiscated by the Gestapo and their occupants were expelled. In 1941 the Catholic Bishop of Münster, Clemens August Graf von Galen, publicly protested against this persecution and against Action T4, the Nazi involuntary euthanasia programme under which the mentally ill, physically deformed, and incurably sick were to be killed. In a series of sermons that received international attention, he criticised the programme as illegal and immoral. His sermons led to a widespread protest movement among church leaders, the strongest protest against a Nazi policy up until that point. Bormann and others called for Galen to be hanged, but Hitler and Goebbels concluded that Galen's death would only be viewed as a martyrdom and lead to further unrest. Hitler decided to deal with the issue when the war was over.

George Mosse wrote of Bormann's beliefs:
However, Richard Overy describes Bormann as an atheist.

Preoccupied with military matters and spending most of his time at his military headquarters on the eastern front, Hitler came to rely more and more on Bormann to handle the domestic policies of the country. On 12 April 1943, Hitler officially appointed Bormann as Personal Secretary to the Führer. By this time Bormann had "de facto" control over all domestic matters, and this new appointment gave him the power to act in an official capacity in any matter.

Bormann was invariably the advocate of extremely harsh, radical measures when it came to the treatment of Jews, the conquered eastern peoples, and prisoners of war. He signed the decree of 31 May 1941 extending the 1935 Nuremberg Laws to the annexed territories of the East. Thereafter, he signed the decree of 9 October 1942 prescribing that the permanent Final Solution in Greater Germany could no longer be solved by emigration, but only by the use of "ruthless force in the special camps of the East", that is, extermination in Nazi death camps. A further decree, signed by Bormann on 1 July 1943, gave Adolf Eichmann absolute powers over Jews, who now came under the exclusive jurisdiction of the Gestapo. Historian Richard J. Evans estimates that 5.5 to 6 million Jews, representing two-thirds of the Jewish population of Europe, were exterminated by the Nazi regime in the course of The Holocaust.

Knowing Hitler viewed Slavic people as inferior, Bormann opposed the introduction of German criminal law into the conquered eastern territories. He lobbied for and eventually achieved a strict separate penal code that implemented martial law for the Polish and Jewish inhabitants of these areas. The "Edict on Criminal Law Practices against Poles and Jews in the Incorporated Eastern Territories", promulgated 4 December 1941, permitted corporal punishment and death sentences for even the most trivial of offences.

Bormann supported the hard-line approach of Erich Koch, "Reichskommissar" in Reichskommissariat Ukraine, in his brutal treatment of Slavic people. Alfred Rosenberg, serving as head of the Reich Ministry for the Occupied Eastern Territories, favoured a more moderate policy. After touring collective farms around Vinnytsia, Ukraine, Bormann was concerned about the health and good physical constitution of the population, as he was concerned that they could constitute a danger to the regime. After discussion with Hitler, he issued a policy directive to Rosenberg that read in part:

Bormann and Himmler shared responsibility for the "Volkssturm" (people's militia), which drafted all remaining able-bodied men aged 16 to 60 into a last-ditch militia founded on 18 October 1944. Poorly equipped and trained, the men were sent to fight on the eastern front, where nearly 175,000 of them were killed without having any discernible impact on the Soviet advance.

Hitler transferred his headquarters to the "Führerbunker" ("Leader's bunker") in Berlin on 16 January 1945, where he (along with Bormann, his secretary Else Krüger, and others) remained until the end of April. The "Führerbunker" was located under the Reich Chancellery garden in the government district of the city centre. The Battle of Berlin, the final major Soviet offensive of the war, began on 16 April 1945. By 19 April the Red Army started to encircle the city. On 20 April, his 56th birthday, Hitler made his last trip to the surface. In the ruined garden of the Reich Chancellery, he awarded Iron Crosses to boy soldiers of the Hitler Youth. That afternoon, Berlin was bombarded by Soviet artillery for the first time. On 23 April, Albert Bormann left the bunker complex and flew to the Obersalzberg. He and several others had been ordered by Hitler to leave Berlin.

In the early morning hours of 29 April 1945, Wilhelm Burgdorf, Goebbels, Hans Krebs, and Bormann witnessed and signed Hitler's last will and testament. Bormann was named executor of the estate. That same night, Hitler married Eva Braun in a civil ceremony.

As Soviet forces continued to fight their way into the centre of Berlin, Hitler and Braun committed suicide on the afternoon of 30 April. Braun took cyanide and Hitler shot himself. Pursuant to Hitler's instructions, their bodies were carried up to the Reich Chancellery garden and burned. In accordance with Hitler's last wishes, Bormann was named as Party Minister, thus officially confirming his top position in the Party. Grand Admiral Karl Dönitz was appointed as the new "Reichspräsident" (President of Germany) and Goebbels became head of government and Chancellor of Germany. Goebbels and his wife Magda committed suicide later that day.

On 2 May, the Battle in Berlin ended when General der Artillerie Helmuth Weidling, the commander of the Berlin Defence Area, unconditionally surrendered the city to General Vasily Chuikov, the commander of the Soviet 8th Guards Army.

At around 11:00 pm on 1 May, Bormann left the "Führerbunker" with SS doctor Ludwig Stumpfegger, Hitler Youth leader Artur Axmann, and Hitler's pilot Hans Baur as members of one of the groups attempting to break out of the Soviet encirclement. Bormann carried with him a copy of Hitler's last will and testament. The group left the "Führerbunker" and travelled on foot via a U-Bahn subway tunnel to the Friedrichstraße station, where they surfaced. Several members of the party attempted to cross the Spree River at the Weidendammer Bridge while crouching behind a Tiger tank. The tank was hit by Soviet artillery and destroyed, and Bormann and Stumpfegger were knocked to the ground. Bormann, Stumpfegger, and several others eventually crossed the river on their third attempt. Bormann, Stumpfegger, and Axmann walked along the railway tracks to Lehrter station, where Axmann decided to leave the others and go in the opposite direction. When he encountered a Red Army patrol, Axmann doubled back. He saw two bodies, which he later identified as Bormann and Stumpfegger, on a bridge near the railway switching yard. He did not have time to check thoroughly, so he did not know how they died. Since the Soviets never admitted to finding Bormann's body, his fate remained in doubt for many years.

During the chaotic days after the war, contradictory reports arose as to Bormann's whereabouts. Sightings were reported in Argentina, Spain, and elsewhere. Bormann's wife was placed under surveillance in case he tried to contact her. Jakob Glas, Bormann's long-time chauffeur, insisted that he saw Bormann in Munich in July 1946. In case Bormann was still alive, multiple public notices about the upcoming Nuremberg trials were placed in newspapers and on the radio in October and November 1945 to notify him of the proceedings against him.

The trial got underway on 20 November 1945. Lacking evidence confirming Bormann's death, the International Military Tribunal tried him "in absentia", as permitted under article 12 of their charter. He was charged with three counts: conspiracy to wage a war of aggression, war crimes, and crimes against humanity. His prosecution was assigned to Lieutenant Thomas F. Lambert Jr. and his defence to Friedrich Bergold. The prosecution stated that Bormann participated in planning and co-signed virtually all of the antisemitic legislation put forward by the regime. Bergold unsuccessfully proposed that the court could not convict Bormann because he was already dead. Due to the shadowy nature of Bormann's activities, Bergold was unable to refute the prosecution's assertions as to the extent of his involvement in decision making. Bormann was convicted of war crimes and crimes against humanity and acquitted of conspiracy to wage a war of aggression. On 15 October 1946 he was sentenced to death by hanging, with the provision that if he were later found alive, any new facts brought to light at that time could be taken into consideration to reduce the sentence or overturn it.

Over the coming years, several organisations, including the CIA and the West German Government, attempted to locate Bormann without success. In 1964, the West German government offered a reward of 100,000 Deutsche Marks for information leading to Bormann's capture. Sightings were reported at points all over the world, including Australia, Denmark, Italy, and South America. In his autobiography, Nazi intelligence officer Reinhard Gehlen claimed that Bormann had been a Soviet spy, and that he had escaped to Moscow. Nazi hunter Simon Wiesenthal believed that Bormann was living in South America. The West German government declared that its hunt for Bormann was over in 1971.

In 1963, a retired postal worker named Albert Krumnow told police that around 8 May 1945 the Soviets had ordered him and his colleagues to bury two bodies found near the railway bridge near Lehrter station. One was dressed in a "Wehrmacht" uniform and the other was clad only in his underwear. Krumnow's colleague Wagenpfohl found an SS doctor's paybook on the second body identifying him as Ludwig Stumpfegger. He gave the paybook to his boss, postal chief Berndt, who turned it over to the Soviets. They in turn destroyed it. He wrote to Stumpfegger's wife on 14 August 1945 and told her that her husband's body was "interred with the bodies of several other dead soldiers in the grounds of the Alpendorf in Berlin NW 40, Invalidenstrasse 63."

Excavations on 20–21 July 1965 at the site specified by Axmann and Krumnow failed to locate the bodies. However, on 7 December 1972, construction workers uncovered human remains near Lehrter station in West Berlin just from the spot where Krumnow claimed he had buried them. Upon autopsy, fragments of glass were found in the jaws of both skeletons, suggesting that the men had committed suicide by biting cyanide capsules to avoid capture. Dental records reconstructed from memory in 1945 by Hugo Blaschke identified one skeleton as Bormann's, and damage to the collarbone was consistent with injuries that Bormann's sons reported he had sustained in a riding accident in 1939. Forensic examiners determined that the size of the skeleton and the shape of the skull were identical to Bormann's. Likewise, the second skeleton was deemed to be Stumpfegger's, since it was of similar height to his last known proportions. Composite photographs, where images of the skulls were overlaid on photographs of the men's faces, were completely congruent. Facial reconstruction was undertaken in early 1973 on both skulls to confirm the identities of the bodies. Soon afterward, the West German government declared Bormann dead. The family was not permitted to cremate the body, in case further forensic examination later proved necessary.

The remains were conclusively identified as Bormann's in 1998 when German authorities ordered genetic testing on fragments of the skull. The testing was led by Wolfgang Eisenmenger, Professor of Forensic Science at Ludwig Maximilian University of Munich. Tests using DNA from one of his relatives identified the skull as that of Bormann. Bormann's remains were cremated and his ashes were scattered in the Baltic Sea on 16 August 1999.

On 2 September 1929, Bormann married 19-year-old Gerda Buch (23 October 1909 – 23 March 1946), whose father, Major Walter Buch, served as a chairman of the "Untersuchung und Schlichtungs-Ausschuss" (USCHLA; Investigation and Settlement Committee), which was responsible for settling disputes within the party. Hitler was a frequent visitor to the Buch house, and it was here that Bormann met him. Hess and Hitler served as witnesses at the wedding. Bormann also had a series of mistresses, including Manja Behrens, an actress.

Martin and Gerda Bormann had ten children:

Gerda Bormann and the children fled Obersalzberg for Italy on 25 April 1945 after an Allied air attack. She died of cancer on 23 March 1946, in Merano, Italy. Bormann's children survived the war, and were cared for in foster homes. His eldest son, Martin, was ordained a Roman Catholic priest and worked in Africa as a missionary. He later left the priesthood and married.






</doc>
<doc id="20619" url="https://en.wikipedia.org/wiki?curid=20619" title="Madeline Amy Sweeney">
Madeline Amy Sweeney

Madeline Amy Sweeney (December 14, 1965 – September 11, 2001), known as Amy Sweeney, was an American flight attendant killed on board American Airlines Flight 11 during the September 11 attacks.

On September 11, 2001, Sweeney was asked by American Airlines to take an extra shift because the other crew member, who was assigned to the position, was ill. Normally, she would only work part-time on weekends.

On September 11, at approximately 7:15 am, before the plane had taken off, Sweeney made a cellular telephone call to her husband Michael, from the plane (which he deemed to be 'highly unusual'). 
She was feeling low about being at work and missing out on a chance to see their daughter, a kindergartner, off to school. At 8:46 am, Sweeney was on the phone with manager Michael Woodward when the plane crashed into the North Tower. Her last words are reproduced in the box below.

At the time of her death, Sweeney had been a flight attendant for twelve years, and was survived by her husband Michael and two children, Jack and Anna. She lived in Acton, Massachusetts.

On February 11, 2002, Sweeney was commemorated in a series of new annual bravery awards initiated by the Government of Massachusetts. The annual Madeline Amy Sweeney Award for Civilian Bravery is awarded every September 11 to at least one Massachusetts resident who displayed extraordinary courage in defending or saving the lives of others.

The first recipients were Sweeney and her colleague Betty Ong, who had also relayed information about the hijacking to personnel on the ground. Pilot John Ogonowski also received a posthumous award for having thought to activate the cockpit radio, which allowed ground control to listen to remarks being made by the hijackers. They were all residents of Massachusetts. Relatives of all three accepted the awards on their behalf.

At the National 9/11 Memorial, Sweeney is memorialized at the North Pool, on Panel N-74.


</doc>
<doc id="20621" url="https://en.wikipedia.org/wiki?curid=20621" title="Microtubule">
Microtubule

Microtubules are polymers of tubulin that form part of the cytoskeleton and provide structure and shape to eukaryotic cells. Microtubules can grow as long as 50 micrometres and are highly dynamic. The outer diameter of a microtubule is between 23 and 27 nm while the inner diameter is between 11 and 15 nm. They are formed by the polymerization of a dimer of two globular proteins, alpha and beta tubulin into protofilaments that can then associate laterally to form a hollow tube, the microtubule. The most common form of a microtubule consists of 13 protofilaments in the tubular arrangement.

Microtubules are very important in a number of cellular processes. They are involved in maintaining the structure of the cell and, together with microfilaments and intermediate filaments, they form the cytoskeleton. They also make up the internal structure of cilia and flagella. They provide platforms for intracellular transport and are involved in a variety of cellular processes, including the movement of secretory vesicles, organelles, and intracellular macromolecular assemblies (see entries for dynein and kinesin). They are also involved in cell division (by mitosis and meiosis) and are the major constituents of mitotic spindles, which are used to pull eukaryotic chromosomes apart.

Microtubules are nucleated and organized by microtubule organizing centers (MTOCs), such as the centrosome found in the center of many animal cells or the basal bodies found in cilia and flagella, or the spindle pole bodies found in most fungi.

There are many proteins that bind to microtubules, including the motor proteins kinesin and dynein, microtubule-severing proteins like katanin, and other proteins important for regulating microtubule dynamics. Recently an actin-like protein has been found in a gram-positive bacterium "Bacillus thuringiensis", which forms a microtubule-like structure called a nanotubule, involved in plasmid segregation. Other bacterial microtubules have a ring of five protofilaments.

Tubulin and microtubule-mediated processes, like cell locomotion, were seen by early microscopists, like Leeuwenhoek (1677). However, the fibrous nature of flagella and other structures were discovered two centuries later, with improved light microscopes, and confirmed in the 20th century with the electron microscope and biochemical studies.

Microtubule in vitro assays for motor proteins such as dynein and kinesin are researched by fluorescently tagging a microtubule and fixing either the microtubule or motor proteins to a microscope slide then visualizing the slide with video-enhanced microscopy to record the travel of the microtubule motor proteins. This allows the movement of the motor proteins along the microtubule or the microtubule moving across the motor proteins. Consequently, some microtubule processes can be determined by kymograph.

In eukaryotes, microtubules are long, hollow cylinders made up of polymerised α- and β-tubulin dimers. The inner space of the hollow microtubule cylinders is referred to as the lumen. The α and β-tubulin subunits are approximately 50% identical at the amino acid level, and each have a molecular weight of approximately 50 kDa.

These α/β-tubulin dimers polymerize end-to-end into linear protofilaments that associate laterally to form a single microtubule, which can then be extended by the addition of more α/β-tubulin dimers. Typically, microtubules are formed by the parallel association of thirteen protofilaments, although microtubules composed of fewer or more protofilaments have been observed in various species  as well as "in vitro".

Microtubules have a distinct polarity that is critical for their biological function. Tubulin polymerizes end to end, with the β-subunits of one tubulin dimer contacting the α-subunits of the next dimer. Therefore, in a protofilament, one end will have the α-subunits exposed while the other end will have the β-subunits exposed. These ends are designated the (−) and (+) ends, respectively. The protofilaments bundle parallel to one another with the same polarity, so, in a microtubule, there is one end, the (+) end, with only β-subunits exposed, while the other end, the (−) end, has only α-subunits exposed. While microtubule elongation can occur at both the (+) and (−) ends, it is significantly more rapid at the (+) end.

The lateral association of the protofilaments generates a pseudo-helical structure, with one turn of the helix containing 13 tubulin dimers, each from a different protofilament. In the most common "13-3" architecture, the 13th tubulin dimer interacts with the next tubulin dimer with a vertical offset of 3 tubulin monomers due to the helicity of the turn. There are other alternative architectures, such as 11-3, 12-3, 14-3, 15-4, or 16-4, that have been detected at a much lower occurrence. Microtubules can also morph into other forms such as helical filaments, which are observed in protist organisms like foraminifera. There are two distinct types of interactions that can occur between the subunits of lateral protofilaments within the microtubule called the A-type and B-type lattices. In the A-type lattice, the lateral associations of protofilaments occur between adjacent α and β-tubulin subunits (i.e. an α-tubulin subunit from one protofilament interacts with a β-tubulin subunit from an adjacent protofilament). In the B-type lattice, the α and β-tubulin subunits from one protofilament interact with the α and β-tubulin subunits from an adjacent protofilament, respectively. Experimental studies have shown that the B-type lattice is the primary arrangement within microtubules. However, in most microtubules there is a seam in which tubulin subunits interact α-β.

Some species of "Prosthecobacter" also contain microtubules. The structure of these bacterial microtubules is similar to that of eukaryotic microtubules, consisting of a hollow tube of protofilaments assembled from heterodimers of bacterial tubulin A (BtubA) and bacterial tubulin B (BtubB). Both BtubA and BtubB share features of both α- and β-tubulin. Unlike eukaryotic microtubules, bacterial microtubules do not require chaperones to fold. In contrast to the 13 protofilaments of eukaryotic microtubules, bacterial microtubules comprise only five.

Microtubules are part of the cytoskeleton, a structural network within the cell's cytoplasm. The roles of the microtubule cytoskeleton include mechanical support, organization of the cytoplasm, transport, motility and chromosome segregation. In developing neurons microtubules are known as neurotubules, and they can modulate the dynamics of actin, another component of the cytoskeleton. A microtubule is capable of growing and shrinking in order to generate force, and there are motor proteins that allow organelles and other cellular components to be carried along a microtubule. This combination of roles makes microtubules important for organizing and moving intracellular constituents.

The organization of microtubules in the cell is cell-type specific. In epithelia, the minus-ends of the microtubule polymer are anchored near the site of cell-cell contact and organized along the apical-basal axis. After nucleation, the minus-ends are released and then re-anchored in the periphery by factors such as ninein and PLEKHA7. In this manner, they can facilitate the transport of proteins, vesicles and organelles along the apical-basal axis of the cell. In fibroblasts and other mesenchymal cell-types, microtubules are anchored at the centrosome and radiate with their plus-ends outwards towards the cell periphery (as shown in the first figure). In these cells, the microtubules play important roles in cell migration. Moreover, the polarity of microtubules is acted upon by motor proteins, which organize many components of the cell, including the endoplasmic reticulum and the Golgi apparatus.

Nucleation is the event that initiates the formation of microtubules from the tubulin dimer. Microtubules are typically nucleated and organized by organelles called microtubule-organizing centres (MTOCs). Contained within the MTOC is another type of tubulin, γ-tubulin, which is distinct from the α- and β-subunits of the microtubules themselves. The γ-tubulin combines with several other associated proteins to form a lock washer-like structure known as the "γ-tubulin ring complex" (γ-TuRC). This complex acts as a template for α/β-tubulin dimers to begin polymerization; it acts as a cap of the (−) end while microtubule growth continues away from the MTOC in the (+) direction.

The centrosome is the primary MTOC of most cell types. However, microtubules can be nucleated from other sites as well. For example, cilia and flagella have MTOCs at their base termed basal bodies. In addition, work from the Kaverina group at Vanderbilt, as well as others, suggests that the Golgi apparatus can serve as an important platform for the nucleation of microtubules. Because nucleation from the centrosome is inherently symmetrical, Golgi-associated microtubule nucleation may allow the cell to establish asymmetry in the microtubule network. In recent studies, the Vale group at UCSF identified the protein complex augmin as a critical factor for centrosome-dependent, spindle-based microtubule generation. It that has been shown to interact with γ-TuRC and increase microtubule density around the mitotic spindle origin.

Some cell types, such as plant cells, do not contain well defined MTOCs. In these cells, microtubules are nucleated from discrete sites in the cytoplasm. Other cell types, such as trypanosomatid parasites, have a MTOC but it is permanently found at the base of a flagellum. Here, nucleation of microtubules for structural roles and for generation of the mitotic spindle is not from a canonical centriole-like MTOC.

Following the initial nucleation event, tubulin monomers must be added to the growing polymer. The process of adding or removing monomers depends on the concentration of αβ-tubulin dimers in solution in relation to the critical concentration, which is the steady state concentration of dimers at which there is no longer any net assembly or disassembly at the end of the microtubule. If the dimer concentration is greater than the critical concentration, the microtubule will polymerize and grow. If the concentration is less than the critical concentration, the length of the microtubule will decrease.

Dynamic instability refers to the coexistence of assembly and disassembly at the ends of a microtubule. The microtubule can dynamically switch between growing and shrinking phases in this region. Tubulin dimers can bind two molecules of GTP, one of which can be hydrolyzed subsequent to assembly. During polymerization, the tubulin dimers are in the GTP-bound state. The GTP bound to α-tubulin is stable and it plays a structural function in this bound state. However, the GTP bound to β-tubulin may be hydrolyzed to GDP shortly after assembly. The assembly properties of GDP-tubulin are different from those of GTP-tubulin, as GDP-tubulin is more prone to depolymerization. A GDP-bound tubulin subunit at the tip of a microtubule will tend to fall off, although a GDP-bound tubulin in the middle of a microtubule cannot spontaneously pop out of the polymer. Since tubulin adds onto the end of the microtubule in the GTP-bound state, a cap of GTP-bound tubulin is proposed to exist at the tip of the microtubule, protecting it from disassembly. When hydrolysis catches up to the tip of the microtubule, it begins a rapid depolymerization and shrinkage. This switch from growth to shrinking is called a catastrophe. GTP-bound tubulin can begin adding to the tip of the microtubule again, providing a new cap and protecting the microtubule from shrinking. This is referred to as "rescue".

In 1986, Marc Kirschner and Tim Mitchison proposed that microtubules use their dynamic properties of growth and shrinkage at their plus ends to probe the three dimensional space of the cell. Plus ends that encounter kinetochores or sites of polarity become captured and no longer display growth or shrinkage. In contrast to normal dynamic microtubules, which have a half-life of 5–10 minutes, the captured microtubules can last for hours. This idea is commonly known as the "search and capture" model. Indeed, work since then has largely validated this idea. At the kinetochore, a variety of complexes have been shown to capture microtubule (+)-ends. Moreover, a (+)-end capping activity for interphase microtubules has also been described. This later activity is mediated by formins, the adenomatous polyposis coli protein, and EB1, a protein that tracks along the growing plus ends of microtubules.

Although most microtubules have a half-life of 5–10 minutes, certain microtubules can remain stable for hours. These stabilized microtubules accumulate post-translational modifications on their tubulin subunits by the action of microtubule-bound enzymes. However, once the microtubule depolymerizes, most of these modifications are rapidly reversed by soluble enzymes. Since most modification reactions are slow while their reverse reactions are rapid, modified tubulin is only detected on long-lived stable microtubules. Most of these modifications occur on the C-terminal region of alpha-tubulin. This region, which is rich in negatively charged glutamate, forms relatively unstructured tails that project out from the microtubule and form contacts with motors. Thus, it is believed that tubulin modifications regulate the interaction of motors with the microtubule. Since these stable modified microtubules are typically oriented towards the site of cell polarity in interphase cells, this subset of modified microtubules provide a specialized route that helps deliver vesicles to these polarized zones. These modifications include:
Tubulin is also known to be phosphorylated, ubiquitinated, sumoylated, and palmitoylated.

A wide variety of drugs are able to bind to tubulin and modify its assembly properties. These drugs can have an effect at intracellular concentrations much lower than that of tubulin. This interference with microtubule dynamics can have the effect of stopping a cell's cell cycle and can lead to programmed cell death or apoptosis. However, there are data to suggest that interference of microtubule dynamics is insufficient to block the cells undergoing mitosis. These studies have demonstrated that suppression of dynamics occurs at concentrations lower than those needed to block mitosis. Suppression of microtubule dynamics by tubulin mutations or by drug treatment have been shown to inhibit cell migration. Both microtubule stabilizers and destabilizers can suppress microtubule dynamics.

The drugs that can alter microtubule dynamics include:

Taxanes (alone or in combination with platinum derivatives (carboplatine) or gemcitabine) are used against breast and gynecological malignancies, squamous-cell carcinomas (head-and-neck cancers, some lung cancers), etc.

Expression of β3-tubulin has been reported to alter cellular responses to drug-induced suppression of microtubule dynamics. In general the dynamics are normally suppressed by low, subtoxic concentrations of microtubule drugs that also inhibit cell migration. However, incorporating β3-tubulin into microtubules increases the concentration of drug that is needed to suppress dynamics and inhibit cell migration. Thus, tumors that express β3-tubulin are not only resistant to the cytotoxic effects of microtubule targeted drugs, but also to their ability to suppress tumor metastasis. Moreover, expression of β3-tubulin also counteracts the ability of these drugs to inhibit angiogenesis which is normally another important facet of their action.

Microtubule polymers are extremely sensitive to various environmental effects. Very low levels of free calcium can destabilize microtubules and this prevented early researchers from studying the polymer in vitro. Cold temperatures also cause rapid depolymerization of microtubules. In contrast, heavy water promotes microtubule polymer stability.

MAPs have been shown to play a crucial role in the regulation of microtubule dynamics "in-vivo". The rates of microtubule polymerization, depolymerization, and catastrophe vary depending on which microtubule-associated proteins (MAPs) are present. The originally identified MAPs from brain tissue can be classified into two groups based on their molecular weight. This first class comprises MAPs with a molecular weight below 55-62 kDa, and are called τ (tau) proteins. "In-vitro", tau proteins have been shown to directly bind microtubules, promote nucleation and prevent disassembly, and to induce the formation of parallel arrays. Additionally, tau proteins have also been shown to stabilize microtubules in axons and have been implicated in Alzheimer's disease. The second class is composed of MAPs with a molecular weight of 200-1000 kDa, of which there are four known types: MAP-1, MAP-2, MAP-3 and MAP-4. MAP-1 proteins consists of a set of three different proteins: A, B and C. The C protein plays an important role in the retrograde transport of vesicles and is also known as cytoplasmic dynein. MAP-2 proteins are located in the dendrites and in the body of neurons, where they bind with other cytoskeletal filaments. The MAP-4 proteins are found in the majority of cells and stabilize microtubules. In addition to MAPs that have a stabilizing effect on microtubule structure, other MAPs can have a destabilizing effect either by cleaving or by inducing depolymerization of microtubules. Three proteins called katanin, spastin, and fidgetin have been observed to regulate the number and length of microtubules via their destabilizing activities. Furthermore, KIAA1211L is predicted to be localized to the microtubules.

Plus end tracking proteins are MAP proteins which bind to the tips of growing microtubules and play an important role in regulating microtubule dynamics. For example, +TIPs have been observed to participate in the interactions of microtubules with chromosomes during mitosis. The first MAP to be identified as a +TIP was CLIP170 (cytoplasmic linker protein), which has been shown to play a role in microtubule depolymerization rescue events. Additional examples of +TIPs include EB1, EB2, EB3, p150Glued, Dynamitin, Lis1, CLIP115, CLASP1, and CLASP2.

Microtubules can act as substrates for motor proteins that are involved in important cellular functions such as vesicle trafficking and cell division. Unlike other microtubule-associated proteins, motor proteins utilize the energy from ATP hydrolysis to generate mechanical work that moves the protein along the substrate. The major motor proteins that interact with microtubules are kinesin, which usually moves toward the (+) end of the microtubule, and dynein, which moves toward the (−) end.


Some viruses (including retroviruses, herpesviruses, parvoviruses, and adenoviruses) that require access to the nucleus to replicate their genomes attach to motor proteins.

The centrosome is the main MTOC (microtubule organizing center) of the cell during mitosis. Each centrosome is made up of two cylinders called centrioles, oriented at right angles to each other. The centriole is formed from 9 main microtubules, each having two partial microtubules attached to it. Each centriole is approximately 400 nm long and around 200 nm in circumference.

The centrosome is critical to mitosis as most microtubules involved in the process originate from the centrosome. The minus ends of each microtubule begin at the centrosome, while the plus ends radiate out in all directions. Thus the centrosome is also important in maintaining the polarity of microtubules during mitosis.

Most cells only have one centrosome for most of their cell cycle, however, right before mitosis, the centrosome duplicates, and the cell contains two centrosomes. Some of the microtubules that radiate from the centrosome grow directly away from the sister centrosome. These microtubules are called astral microtubules. With the help of these astral microtubules the centrosomes move away from each other towards opposite sides of the cell. Once there, other types of microtubules necessary for mitosis, including interpolar microtubules and K-fibers can begin to form.

A final important note about the centrosomes and microtubules during mitosis is that while the centrosome is the MTOC for the microtubules necessary for mitosis, research has shown that once the microtubules themselves are formed and in the correct place the centrosomes themselves are not needed for mitosis to occur.

Astral microtubules are a subclass of microtubules which only exist during and around mitosis. They originate from the centrosome, but do not interact with the chromosomes, kinetochores, or with the microtubules originating from the other centrosome. Instead their microtubules radiate towards the cell membrane. Once there they interact with specific motor proteins which create force that pull the microtubules, and thus the entire centrosome towards the cell membrane. As stated above, this helps the centrosomes orient themselves away from each other in the cell. However these astral microtubules do not interact with the mitotic spindle itself. Experiments have shown that without these astral microtubules, the mitotic spindle can form, however its orientation in the cell is not always correct and thus mitosis does not occur as effectively. Another key function of the astral microtubules is to aid in cytokinesis. Astral microtubules interact with motor proteins at the cell membrane to pull the spindle and the entire cell apart once the chromosomes have been replicated.

Interpolar/Polar microtubules are a class of microtubules which also radiate out from the centrosome during mitosis. These microtubules radiate towards the mitotic spindle, unlike astral microtubules. Interpolar microtubules are both the most abundant and dynamic subclass of microtubules during mitosis. Around 95 percent of microtubules in the mitotic spindle can be characterized as interpolar. Furthermore, the half life of these microtubules is extremely short as it is less than one minute. Interpolar microtubules that do not attach to the kinetochores can aid in chromosome congregation through lateral interaction with the kinetochores.

K fibers/Kinetochore microtubules are the third important subclass of mitotic microtubules. These microtubules form direct connections with the kinetochores in the mitotic spindle. Each K fiber is composed of 20–40 parallel microtubules, forming a strong tube which is attached at one end to the centrosome and on the other to the kinetochore, located in the center of each chromosome. Since each centrosome has a K fiber connecting to each pair of chromosomes, the chromosomes become tethered in the middle of the mitotic spindle by the K fibers. K fibers have a much longer half life than interpolar microtubules, at between 4 and 8 minutes. During the end of mitoses, the microtubules forming each K fiber begin to disassociate, thus shorting the K fibers. As the K fibers shorten the pair chromosomes are pulled apart right before cytokinesis. Previously, some researchers believed that K fibers form at there minus end originating from the centrosome just like other microtubules, however, new research has pointed to a different mechanism. In this new mechanism, the K fibers are initially stabilized at their plus end by the kinetochores and grow out from there. The minus end of these K fibers eventually connect to an existing Interpolar microtubule and are eventually connected to the centrosome in this way.

Most of the microtubules that form the mitotic spindle originate from the centrosome. Originally it was thought that all of these microtubules originated from the centrosome via a method called search and capture, described in more detail in a section above, however new research has shown that there are addition means of microtubule nucleation during mitosis. One of the most important of these additional means of microtubule nucleation is the RAN-GTP pathway. RAN-GTP associates with chromatin during mitosis to create a gradient that allows for local nucleation of microtubules near the chromosomes. Furthermore, a second pathway known as the augmin/HAUS complex (some organisms use the more studied augmin complex, while others such as humans use an analogous complex called HAUS) acts an additional means of microtubule nucleation in the mitotic spindle.

Microtubule plus ends are often localized to particular structures. In polarized interphase cells, microtubules are disproportionately oriented from the MTOC toward the site of polarity, such as the leading edge of migrating fibroblasts. This configuration is thought to help deliver microtubule-bound vesicles from the Golgi to the site of polarity.

Dynamic instability of microtubules is also required for the migration of most mammalian cells that crawl. Dynamic microtubules regulate the levels of key G-proteins such as RhoA and Rac1, which regulate cell contractility and cell spreading. Dynamic microtubules are also required to trigger focal adhesion disassembly, which is necessary for migration. It has been found that microtubules act as “struts” that counteract the contractile forces that are needed for trailing edge retraction during cell movement. When microtubules in the trailing edge of cell are dynamic, they are able to remodel to allow retraction. When dynamics are suppressed, microtubules cannot remodel and, therefore, oppose the contractile forces. The morphology of cells with suppressed microtubule dynamics indicate that cells can extend the front edge (polarized in the direction of movement), but have difficulty retracting their trailing edge. On the other hand, high drug concentrations, or microtubule mutations that depolymerize the microtubules, can restore cell migration but there is a loss of directionality. It can be concluded that microtubules act both to restrain cell movement and to establish directionality

Microtubules have a major structural role in eukaryotic cilia and flagella. Cilia and flagella always extend directly from a MTOC, in this case termed the basal body. The action of the dynein motor proteins on the various microtubule strands that run along a cilium or flagellum allows the organelle to bend and generate force for swimming, moving extracellular material, and other roles. Prokaryotes possess tubulin-like proteins including FtsZ. However, prokaryotic flagella are entirely different in structure from eukaryotic flagella and do not contain microtubule-based structures.

The cytoskeleton formed by microtubules is essential to the morphogenetic process of an organism's development. For example, a network of polarized microtubules is required within the oocyte of "Drosophila melanogaster" during its embryogenesis in order to establish the axis of the egg. Signals sent between the follicular cells and the oocyte (such as factors similar to epidermal growth factor) cause the reorganization of the microtubules so that their (-) ends are located in the lower part of the oocyte, polarizing the structure and leading to the appearance of an anterior-posterior axis. This involvement in the body's architecture is also seen in mammals.

Another area where microtubules are essential is the development of the nervous system in higher vertebrates, where tubulin's dynamics and those of the associated proteins (such as the microtubule-associated proteins) is finely controlled during the development of the nervous system.

The cellular cytoskeleton is a dynamic system that functions on many different levels: In addition to giving the cell a particular form and supporting the transport of vesicles and organelles, it can also influence gene expression. The signal transduction mechanisms involved in this communication are little understood. However, the relationship between the drug-mediated depolymerization of microtubules, and the specific expression of transcription factors has been described, which has provided information on the differential expression of the genes depending on the presence of these factors. This communication between the cytoskeleton and the regulation of the cellular response is also related to the action of growth factors: for example, this relation exists for connective tissue growth factor.




</doc>
<doc id="20622" url="https://en.wikipedia.org/wiki?curid=20622" title="Militia">
Militia

A militia () is generally an army or some other fighting organization of non-professional soldiers, citizens of a nation, or subjects of a state, who can be called upon for military service during a time of need, as opposed to a professional force of regular, full-time military personnel, or historically, members of a warrior nobility class (e.g., knights or samurai). Generally unable to hold ground against regular forces, it is common for militias to be used for aiding regular troops by skirmishing, holding fortifications, or irregular warfare, instead of being used in offensive campaigns by themselves. Militia are often limited by local civilian laws to serve only in their home region, and to serve only for a limited time; this further reduces their use in long military campaigns.

With the emergence of professional forces (in the form of mercenaries whose livelihood was military service) during the Renaissance, Western European militias wilted; later however, they would be revived as part of Florentine civic humanism, which held that professional militaries were a result of corruption, and admired the Roman model. The civic humanist ideal of the militia was spread through Europe by the writings of Niccolò Machiavelli (According to Hörnqvist, "The Prince", ch. 12 and 13, "Discourses on Livy", and "The Art of War".)

Beginning in the late 20th century, some militias (in particular officially recognized and sanctioned militias of a government) act as professional forces, while still being "part-time" or "on-call" organizations. For instance, the members of U.S. Army National Guard units are considered professional soldiers, as they are trained to maintain the same standards as their "full-time" (active duty) counterparts.

Militias thus can be military or paramilitary, depending on the instance. Some of the contexts in which the term "militia" is used include:

"Militia" derives from Latin roots:

The word "militia" dates back to ancient Rome, and more recently to at least 1590 when it was recorded in a book by Sir John Smythe, "Certain Discourses Military" with the meanings: a military force; a body of soldiers and military affairs; a body of military discipline
The word Militia comes from ancient Latin, in which it meant defense service, as distinguished from a body of (armed) defenders which would be "volgus militum". The term is used by several countries with the meaning of "defense activity" indicating it is taken directly from Latin.

In the early 1800s Buenos Aires, which was by then the capital of the Viceroyalty of the Río de la Plata, was attacked during the British invasions of the Río de la Plata. As regular military forces were insufficient to counter the British attackers, Santiago de Liniers drafted all males in the city capable of bearing arms into the military. These recruits included the criollo peoples, who ranked low down in the social hierarchy, as well as some slaves. With these reinforcements, the British armies were twice defeated. The militias became a strong factor in the politics of the city afterwards, as a springboard from which the "criollos" could manifest their political ambitions. They were a key element in the success of the May Revolution, which deposed the Spanish viceroy and began the Argentine War of Independence. A decree by Mariano Moreno derogated the system of promotions involving "criollos", allowing instead their promotion on military merit.

The Argentine Civil War was waged by militias again, as both federalists and unitarians drafted common people into their ranks as part of ongoing conflicts. These irregular armies were organized at a provincial level, and assembled as leagues depending on political pacts. This system had declined by the 1870s, mainly due to the establishment of the modern Argentine Army, drafted for the Paraguayan War by President Bartolome Mitre. Provincial militias were outlawed and decimated by the new army throughout the presidential terms of Mitre, Sarmiento, Avellaneda and Roca.

Armenian militia, or "fedayi" played a major role in the independence of various Armenian states, including Western Armenia, the First Republic of Armenia, and the currently de facto independent Republic of Artsakh. Armenian militia also played a role in the Georgia-Abkhazia War of 1992–1993.

In the Colony of New South Wales, Governor Lachlan Macquarie proposed a colonial militia but the idea was rejected. Governor Ralph Darling felt a mounted police force was more efficient than a militia. A military volunteer movement attracted wide interest during the Crimean War. Following Federation, the various military reserve forces of the Commonwealth of Australia became the Citizen Military Force (CMF).

A citizens' militia modeled on the British Home Guard called the Volunteer Defence Corps (VDC) was founded by the Returned and Services League of Australia (RSL) in 1940 in response to the possibility of a Japanese invasion of Australia. In the beginning, members didn't have uniforms and often paraded in business attire. They were given instruction on guerrilla warfare, and later the private organization was taken over by the Australian Government and became part of the Australian Military Forces (AMF). The government supported the organization and equipped them with anti-aircraft artillery; however, they were disbanded by the end of World War II due to the fact that there was no longer a significant threat to national security.

During the Revolutions of 1848 in the Austrian Empire, a National Guard was established in Vienna. A separate but related Academic Legion was composed mainly of students in the capital city.

After World War I, multiple militias formed as soldiers returned home to their villages, only to find many of them occupied by Slovene and Yugoslav forces. Especially in the southern province of Carinthia the Volkswehr (Peoples Defense Force) was formed, to fight the occupant forces.

During the First Republic, similar to the development in Germany, increasing radicalization of politics led to certain paramilitary militias associating with certain political parties. The Heimwehr (German: "Home Defense") became affiliated with the Christian Social Party and the Republikanischer Schutzbund (German: "Republican Defense League") became affiliated with the Social Democratic Workers' Party of Austria. Violence increasingly escalated, breaking out during the July Revolt of 1927 and finally the Austrian Civil War, when the Schutzbund was defeated by the Heimwehr, police, Gendarmerie and Austrian Armed Forces.

After World War II the Austrian Armed Forces (Bundesheer) were reestablished as a conscript military force. A basic part of it is the militia, which is a regular reservists force of the Bundesheer, comparable to the national guard units of the United States. The conscript soldiers of the militia have to store their military equipment at home, to be mobilized quite fast within a few days in case of emergency. The system was established during the Cold War and still exists, but the members of the militia now are volunteers only.

"See also: Republikanischer Schutzbund, Heimwehr"

In Bahrain, emergence of a small militia group Katibat al Haydariyah was first seen in 2015. During the year, total four attacks were claimed by the attack, including on August 22 and 24, 2015, in Muharraq, on September 10, 2015, in Al Khamis, and on October 9, 2015, on Bahraini forces in the Al Juffair region. Katibat al Haydariyah is its own distinct organization that decries the Bahraini government, but Canada and the United Kingdom listed it as an alias for the larger Al-Ashtar Brigades (or the Saraya al Ashtar). After four years, the militia group reemerged on social media in October 2019, to threaten new attacks on the island. It stated that they “will not retreat from our goals of the downfall of the Al Khalifa entity,” and that the “soon, guns will open their mouths and they will hear the whiz of bullets”.

In Canada the title "Militia" historically referred to the land component of the armed forces, both regular (full-time) and reserve. The earliest Canadian militias date from the beginning of the French colonial period. In New France, King Louis XIV created a compulsory militia of settlers in every parish that supported French authorities in the defence and expansion of the colony.

Following the British conquest of New France in 1760, local militia units supported British Army regiments stationed in British North America. In addition to the Canadian militia, British regiments were also supported by locally raised regulars (including the 40th Regiment of Foot, and the 100th (Prince of Wales's Royal Canadian) Regiment of Foot) and Fencibles regiments. These regiments were raised through ordinary modes of recruiting, as opposed to being raised by ballot like the militia. Most militia units were only activated in time of war, but remained inactive in between. The battle honours awarded to these colonial militia regiments are perpetuated by modern regiments within the Canadian Army.

Defence of the Canadas long relied on a contingent of British soldiers, as well as support from the Royal Navy. However, the Crimean War saw the diversion of a significant number of British soldiers from British North America. Fearing possible incursions from the United States, the Parliament of the Province of Canada passed the "Militia Act of 1855", creating the Active Militia. The Active Militia, later splitting into the Permanent Active Militia (PAM), a full-time professional army component (although it continued to use the label militia), and Non-Permanent Active Militia (NPAM), a military reserve force for the Canadian militia. Following 1855, the traditional sedentary militia was reorganized into the Reserve Militia, with its last enrolment taking place in 1873, and was formally abolished in 1950.

Prior to Canadian Confederation, the colonies that made up the Maritimes, and Newfoundland maintained their own militias independent of the Canadian Militia. From 1853 to 1871, the Colony of Vancouver Island (and the succeeding Colony of British Columbia) periodically raised and disbanded militia units. These units were raised for specific purposes, or in response to a specific threat, real or perceived.

After the Treaty of Washington was signed between the Americans and British, nearly all remaining British soldiers were withdrawn from Canada in November 1871. The departure of the majority of British forces in Canada made the Canadian militia the only major land forces available in Canada. In 1940, both components of the militia, PAM and NPAM were reorganized, the former into Canadian Army (Active), the latter into the Canadian Army (Reserve)

In addition to the various colonial militia units, and the regiments of the Canadian militia, in 1942, the Army's Pacific Command created the Pacific Coast Militia Rangers. Intended to function similarly to the United Kingdom's Home Guard, the Rangers were a secondary defence force, defending the coast of British Columbia and Yukon from potential Japanese attack. The Rangers were disbanded in September 1945, shortly after the conclusion of World War II. The legacy of the Pacific Coast Militia Rangers is perpetuated by the Canadian Rangers, a component of the Primary Reserve that provides a military presence in areas where it would not be economically or practically viable to have conventional Army units - most notably northern Canada.

The Canadian Army Reserve continued to use the term "militia" in reference to itself until the unification of the Canadian Armed Forces in 1968. Since unification, no Canadian military force has formally used "militia" in its name. However, the Canadian Army Reserve is still colloquially referred to as the "militia". Members of the Canadian Army Reserve troops typically train one night a week and every other weekend of the month, except in the summer. Summertime training may consist of courses, individual call-outs, or concentrations (unit and formation training of one to two weeks' duration). Most Canadian cities and counties have one or more militia units. Primary Reserve members may volunteer for overseas service, to augment their regular force counterparts—usually during NATO or United Nations missions.

China's current militia falls under the leadership of the Communist Party of China (CPC), and forms part of the Chinese armed forces. Under the command of the military organs, it undertakes such jobs as war preparation services, security and defense operational tasks and assistance in maintaining social order and public security.

Historically, militias of varying levels of ability have existed in China, organized on a village and clan level, especially during periods of instability and in areas subject to pirate and bandit attack. When the British attempted to take control of the New Territories in 1898, they were resisted by the local militias which had been formed for mutual defence against pirate raids. Although ultimately defeated, the militias' dogged resistance convinced the British to make concessions to the indigenous inhabitants allowing them to preserve inheritance, property and marriage rights and customs throughout most of the period of the British rule.

Cuba has three militia organizations: The Territorial Troops Militia ("Milicias de Tropas Territoriales") of about one million people (half women), the Youth Labor Army ("Ejército Juvenil del Trabajo") devoted to agricultural production, and a naval militia. Formerly, there existed the National Revolutionary Militias ("Milicias Nacionales Revolucionarias"), which was formed after the Cuban Revolution and initially consisted of 200,000 men who helped the 25,000 strong standing army defeat counter-revolutionary guerillas.

The Danish Home Guard () (HJV) is the fourth service of the Danish military. It was formerly concerned only with the defence of Danish territory but, since 2008, it has also supported Danish international military efforts in Afghanistan, Iraq and Kosovo. There are five branches: Army Home Guard, Naval Home Guard, Air Force Home Guard, Police Home Guard, and Infrastructure Home Guard.

The Danish Militia played a major role in repelling the Swedish attackers during the assault on Copenhagen in 1659.

The Danish Home guard are the most highly trained militia men in the world as of 2012 as the receive about 90 hours of training a year in many yearly exercises. These include many exercises such as repelling assaults and RPG fire from afghan irregulares.

These yearly exercises include marksman training, and desert training for future possible deployment in afghan, as well as CQB training with the Danish special forces frogmen(frømen).

The Omakaitse (Home Guard) was an organisation formed by the local population of Estonia on the basis of the Estonian Defence League and the forest brothers resistance movement active on the Eastern Front between 3July 1941 and 17September 1944. This arrangement was unique in the context of the war as in Latvia, which otherwise shared a common fate with Estonia, there was no organisation of this kind.

While Finland employs conscription, they do not have separate militia units: all units are organized by and under the command of the Finnish Defence Forces. All men belong to the reserve until age 50 or 60 depending on rank, and may be called up in case of mobilization. Each reservist is assigned a position in a unit to be activated. However, since 2004, the FDF does have territorial forces, organized along the lines of regular infantry formations, which are composed of volunteers. Furthermore, long-range patrol units (sissi troops, a type of special forces) are assigned to local troops.

In history, before Finland became independent, two types of local militias existed: the White Guards and Red Guards, which were non-socialists and socialists, respectively. In the Finnish Civil War (1918) the White Guards founded the White Army, which was victorious over the Red Guards. White Guards continued their existence as a volunteer militia until the Second World War. In some cases their activity found overt political expression as in the Mäntsälä rebellion. However, in 1934 separate wartime White Guard units were dissolved and in the Second World War they served at the front, dispersed in regular units. They were dissolved as a condition of peace after the Continuation War.

The first notable militia in French history was the resistance of the Gauls to invasion by the Romans until they were defeated by Julius Caesar. Centuries later, Joan of Arc organized and led a militia until her capture and execution in 1431. This settled the succession to the French crown and laid the basis for the formation of the modern nation of France.

During the French Revolution the National Guard was a political home defense militia. The levée en masse was a conscription army used during the Revolutionary and Napoleonic Wars.

At the time of the Franco-Prussian War, the Parisian National Guard engaged the Prussian Army and later rebelled against the Versailles Army under Marshal McMahon.

Under German occupation during World War II, a militia usually called the French Resistance emerged to conduct a guerrilla war of attrition against German forces and prepare the way for the D-Day Allied Invasion of France. The Resistance militia were opposed by the collaborationist French Militia—the paramilitary police force of the German puppet state of Vichy.

Although defunct from 1871 until 2016, the French National Guard has now been reestablished for homeland security purposes.

The earliest reports of Germanic militias was the system of hundreds described in 98 AD by the Roman historian Tacitus as the "centeni." They were similar in nature to the Anglo-Saxon "fyrd".

Freikorps (German for "Free Corps") was originally applied to voluntary armies. The first "Freikorps" were recruited by Frederick II of Prussia during the Seven Years' War. These troops were regarded as unreliable by regular armies, so they were mainly used as sentries and for minor duties. During the Napoleonic occupation, organizations such as the Lutzow Free Corps fought against the occupiers and later joined the allied forces as regular soldiers.

However, after 1918, the term was used for nationalist paramilitary organizations that sprang up around Germany as soldiers returned in defeat from World War I. They were one of the many Weimar paramilitary groups active during that time. They received considerable support from Gustav Noske, the German Defence Minister who used them to crush the Spartakist League with enormous violence, including the murders of Karl Liebknecht and Rosa Luxemburg on January15, 1919. Militia were also used to put down the Bavarian Soviet Republic in 1919. They were officially "disbanded" in 1920, resulting in the ill-fated Kapp Putsch in March 1920. The "Einwohnerwehr", active in Germany from 1919 to 1921 was a paramilitary citizens' militia consisting of hundreds of thousands of mostly former servicemen. Formed by the Prussian Ministry of the Interior on April15, 1919, to allow citizens to protect themselves from looters, armed gangs, and revolutionaries, the "Einwohnerwehr" was under the command of the local "Reichswehr" regiments, which supplied its guns. In 1921, the Berlin government dissolved the "Einwohnerwehr". Many of its members went on to join the Nazi Party.

In 1921 the Nazi Party created the "Sturmabteilung" (SA; Storm Detachment; Brownshirts), which was the first paramilitary wing of the Nazi Party and served as a Nazi militia whose initial assignment was to protect Nazi leaders at rallies and assemblies. The SA also took part in street battles against the forces of rival political parties and violent actions against Jews. From the SA sprung the Schutzstaffel (SS; Protective Squadron) which grew to become one of the largest and most powerful groups in Nazi Germany, which Reichsführer-SS Heinrich Himmler (the leader of the SS from 1929) envisioned as an elite group of guards. The Waffen-SS, the military branch of the SS, became a de facto fourth branch of the Wehrmacht.

In 1944–1945, as World War II came to a close in Europe, the German high command deployed increasing numbers of Volkssturm units to combat duties. These regiments were composed of men, women and children too old, young or otherwise unfit for service in the Wehrmacht (German Regular Army). Their primary role was assisting the army with fortification duties and digging anti-tank ditches. As the shortage of manpower became severe, they were used as front line infantry, most often in urban settings. Due to the physical state of members, almost non-existent training and shortage of weapons, there was not much the "Volkssturm" could do except act like shields for regular army units. However, armed with Panzerfausts and deeply entrenched, a unit of Volkssturm could cause serious trouble for Soviet armor.

Salwa Judum (meaning "Peace March" or "Purification Hunt" in Gondi language) is a militia active in the Chhattisgarh state of India.

The Basij militia founded by Ayatollah Ruhollah Khomeini in November 1980 is composed of 10,000 regular soldiers. It ultimately draws from about 11 million members, and is subordinate to the Islamic Revolutionary Guard Corps in Iran.

Several armed militia groups are presently active in Iraq. The Mehdi Army is a sectarian armed force created by the Iraqi Shi'a cleric Muqtada al-Sadr in June 2003. The Badr Organization is based in and around Karbala. The Anbar Salvation Council is a Sunni armed group in Iraq formed by members of baathist and nationalist elements to fight Al-Qaeda in Iraq.

The Awakening Councils or "concerned citizens" are emerging to defend their neighborhoods against insurgents of every kind, functioning as a form of vigilante "militia" similar to the model of militia in the US.

In modern times, the Israel Defense Forces (IDF) is often described as a heavily armed militia, not a full-fledged army, since it is legally and publicly viewed as a defensive force only, and since it relies heavily on the reserve duty of Israeli citizens who are annually called to service for set periods of time, rather than on professional, full-time soldiers. Israeli settlements in the Israeli-occupied territories rely on armed militia teams for their security. National service conscripts can also serve in the Israel Border Police (commonly known by its Hebrew abbreviation Magav which means border guard in Hebrew), which is a paramilitary branch of the Israel Police rather than the IDF.

Since the fall of Gaddafi's rule of Libya in the aftermath of the Libyan Civil War, rebel groups that have contributed to the revolution splintered into self-organized militia movements and have been involved in a feud for control of each city. Since the revolution, reports of clashes and violence by militia groups have been increasing.

Mexico has a history of various activities and insurrection by militia and paramilitary groups dating back several hundred years that include the exploits of historical figures such as Captain Manuel Pineda Munoz and Francisco "Pancho" Villa. This also includes groups such as the Free-Colored Militia (the interracial militias of New Spain, Colonial Mexico), the Camisas Doradas, and the contemporary Self Defense Council of Michoacan.

Free-colored militias were an important and at times critical organization in Colonial Mexico. Prior to the eighteenth century, Spain's territories in the Americas were mainly defended through a series of Spanish military units being based in strategic coastal port cities and important economic centers. But as European rivals began to challenge the Spanish crown and their dominance in the new world, the Bourbon dynasty initiated a series of reforms, allowing people from their colonies to serve in the regular armies, as well as permitting local militias in their territories.

While these groups began to integrate themselves into the official Spanish colonial militaries, free-colored militias have been reluctantly used since the-mid sixteenth century. "Palenques," or run away slave communities, would often initiate slavery uprising in various cities and towns in New Spain, which made the colonial Spanish authorities uneasy about arming any free colored individuals. Free colored rebellions and violence in Mexico City impacted regional policy of New Spain towards blacks. Given this social context, the racial climate in which these free-colored militias first appeared was a hostile one, and the first militias often had conflicts within them between their free-colored and white commanders. The first large scale recruitment of fee-colored militias was in response to the attack on Veracruz port in 1683 by Dutch pirateer Lorenzo de Graff, with free-colored soldiers being called in from Mexico City, Puebla, Orizaba and other large colonial cities. Militias increasingly began to take shape and develop over the course of the 17th and 18th centuries, but it's critical to understand that their development was not a linear progressive one. The experiences of militias in urban areas was vastly different than those in rural communities, and the role, influence, and duties of militias in the early 17th century were not the same as those of a century later. The critical stage for militia growth was during 1670-1762, where there was an increase of the militias responsibilities and they gained a considerable amount of autonomy over their own affairs. The social impact of these free-colored militias added complexity to the race based caste system that dominated the social landscape.

Free-colored militias were structured to follow the "tercio" organizational model that was used by Spanish Habsburg and Bourbon dynasties. "Tercios" compromised 2,500 soldiers distributed among ten companies, each under the leadership of a captain. Free-colored militias under the tercio system were headed by a "sargento mayor" (major) who became the senior operating officer in militias. Under the "sargento mayor" were the junior officers, which included one captain and alferez (lieutenant) per company, who were also aided by an "ayudante" (adjutant) and "subteniente" (second lieutenant) after they were incorporated into the system after 1767. The captain had supreme authority within their company, only reporting to the "sargento" mayor when they he could not control matters of the company. The "alferez" coordinated affairs with his captain and was next in line in command in his absence. Below the junior officers were ranking NCO's and up to four sergeants served per company. A "cabo" (corporal) was assigned to lead each squad of 25 soldiers. These NCO's were responsible for discipline of the soldiers and maintaining a limited record of individuals. Officers and first sergeants were the only soldiers in the free-colored militias to receive a monthly salary with lower ranked soldiers only receiving pay when on campaigns. Their salaries came from the royal treasuries, alongside occasional supplementation by private contributions of prominent individuals.

Who exactly constitutes as a “free-colored person” is subject to much debate and discussion. While the terms "pardos, mulatos, negros" and "morenos" were commonly used under the caste system that was in place during this era, their use in this context is much more complex and who exactly qualified as who was a very fluid process, dependent on the social context of the time and place. Despite the lack of universal understanding of racial identification across New Spain, when they were faced with external threats to their organizations, free-colored militias showed great racial unity in these times, such as in the case of Huajolotitlan, a small town of Oaxaca in southern Mexico. After a decree was passed in 1784 calling for the retirement of every free-colored officer and the disbandment of their militia, the tows free-coloreds fiercely resisted. Free-colored soldiers refused to leave their posts and they dispatched to the capital in protests to defend their racially integrated organizations. This later inspired the communities other free-colored people to protests what they saw as other aggressions by the government, such as increasing tribute burdens.

While some of the previous examples are historical, the current official view on the existence of such militias in Mexico, when they are not backed by the government, has been to always label them as illegal and to combat them in a military and a political way.

Modern examples on the Mexican view on militias are the Chiapas conflict against the EZLN and against the EPR in Guerrero, where the government forces combated the upraised militias. And in a more recent case when civilian self-defence militias appeared during the Mexican war on drugs, the government regulated them and transformed the militias in to Rural federal forces, and those who resisted were combated and imprisoned.

From the Treaty of Waitangi in 1840 until 1844 small detachments of British Imperial troops based in New Zealand were the only military. This changed as a result of the Flagstaff War, with the colonial government passing a Militia Act on 25 March 1845. Militia units were formed in Auckland, Wellington, New Plymouth, and Nelson. Service in the militia was compulsory.

Many localized militia saw service, together with British Imperial troops, during the New Zealand Wars. In the late nineteenth century a system of local Volunteer militias evolved throughout the country. These were semi-trained but uniformed and administered by a small number of regular "Imperial" officers.
The militia units were disbanded and reformed as the Territorial Army in 1911.

The Worker-Peasant Red Guards is a North Korean paramilitary organization organized on a provincial/town/city/village level.

Militias have played an important role supporting Pakistan's Military since the Indo-Pakistani War of 1947 when Pakistan, with the support of militias, was able to gain control of the region which is now known as Azad Kashmir. Pakistan found the militias volunteering to participate in the Indo-Pakistani war of 1965 and the Indo-Pakistani war of 1971 quite useful as well.

Currently Pakistani citizens forming militias from the Khyber Pakhtunkhwa province are participating in the 'war on terror'.

Article XVI, Section 4 of the Philippines Constitution states: "The Armed Forces of the Philippines shall be composed of a citizen armed force which shall undergo military training and serve as may be provided by law."

Portugal had a long tradition in the use of militias for national defense. Between the 12th and 16th centuries, the municipal militias – composed of spearmen, pikemen, horsemen, slingers, javelineers, archers, crossbowmen and later arquebusiers – constituted the main component of the Portuguese Royal Army, together with smaller military forces from the King, the military orders and the feudal lords.

After some failed previous attempts, in 1570 King Sebastian of Portugal created the "Ordenanças", a centrally managed military territorial organization that would replace the municipal militias and became the basis of a national army. After 60 years of foreign domination (1580–1640), the "Ordenanças" were reorganized for the Portuguese Restoration War. The Portuguese Army was then organized in three lines, with the 2nd and 3rd being militia forces. The "Ordenanças" became the 3rd line and acted both as a territorial draft organization for the 1st and 2nd line troops and as a kind of home guard for local defense. The 2nd line was made of the auxiliary troops, also militia units with the role of regional defense. In the end of the 18th century, the auxiliary troops were renamed "Militias".

In the Peninsular War, the Militia regiments and the Ordenanças units had an important role in the defense of the country against the Napoleonic invader army. Still in the 19th century, the Militia units also had an important role in the Liberal Wars, with the majority of those troops fighting on the side of King Miguel. Besides the regular militias, a number of volunteer militia units were formed to fight on both sides of the war.

With the establishment of the constitutional regime, the old Militias and "Ordenanças" were replaced by a single national militia force, the National Guard. However, the National Guard revealed itself an ineffective and undisciplined force. Their units became highly politicized, being involved in a number of conspiracies and coups. The National Guard having less and less confidence from the authorities, became extinct in 1847, terminating a long tradition of national militias in Portugal.

During the 20th century, some experiments with militia type forces were made. From 1911 to 1926, the Portuguese Army was organized as a militia army. Also, in 1936, the "Estado Novo" regime created the Portuguese Legion as a political volunteer militia, dedicated to the fight against the enemies of country and of the social order. From World War II, the Portuguese Legion assumed the responsibility for civil defense, this becoming its main role during the Cold War, until its extinction in 1974.

Neither the Russian Empire, nor the Soviet Union ever had an organised force that could be equated to a militia. Instead a form of organisation that predated the Russian state was used during national emergencies called Narodnoe Opolcheniye (People's Regimentation). More comparable to the English Fyrd, it was a popular voluntary joining of the local полк polk, or a regiment, though it had no regular established strength or officers, these usually elected from prominent local citizens. Although these spontaneously created popular forces had participated in several major wars of the Russian Empire, including in combat, they were not obligated to serve for more than one year, and notably departed for home during the 1813 campaign in Germany. On only one occasion, during the military history of the Soviet Union, the Narodnoe Opolcheniye was incorporated into the regular forces of the Red Army, notably in Leningrad and Moscow.

The term Militsiya in Russia and former Communist Bloc nations was specifically used to refer to the civilian police force, and should not be confused with the conventional western definition of militia. The term, as used in this context, dated from post-revolutionary Russia in late 1917 and was intended to draw a distinction between the new Soviet law enforcement agencies and the disbanded Tsarist police. In some of these states militia was renamed back to police such as Ukraine while in the other states it remains such as Belarus. In Russia it was renamed to Police (in , "Politsiya") in March 2011.

The first militias formed in Sri Lanka were by Lankan Kings, who raised militia armies for their military campaigns both within and outside the island. This was due to the reason that the Kings never maintained a standing army instead had a Royal Guard during peacetime and formed a militia in wartime.

When the Portuguese who were the first colonial power to dominate the island raised local militias under the command of local leaders known as Mudaliyars. These militias took part in the many Portuguese campaigns against the Lankan Kings. The Dutch continued to employ these militias but due to their unreliability tended to favor employing Swiss and Malay mercenaries in their campaigns in the island.

The British Empire then ousted the Dutch from the coastal areas of the country, and sought to conquer the independent Kandyan Kingdom. In 1802, the British became the first foreign power to raise a regular unit of Sinhalese with British officers, which was named the 2nd Ceylon Regiment, also known as the Sepoy Corps. It fought alongside British troops in the Kandyan wars. After the Matale Rebellion led by Puran Appu in 1848, in which a number of Sinhalese recruits defected to the side of the rebels, the recruitment of Sinhalese to the British forces was temporarily halted and the Ceylon Regiments disbanded.

In 1861, the Ceylon Light Infantry Volunteers were raised as a militia, but soon became a military reserve force. This became the Ceylon Defence Force in 1910 and consisted of militia units. These were the Colombo Town Guard and the Town Guard Artillery formed during the two world wars.

With the escalation of the Sri Lankan Civil War, local villagers under threat of attack were formed into localized militia to protect their families and homes. According to the Sri Lankan Military these militias were formed after "massacres done by the LTTE" and in the early 1990s they were reformed as the Sri Lankan Home Guard. In 2007 the Home Guard became the Sri Lanka Civil Security Force. In 2008, the government called for the formation of nearly 15,000 civil defence committees at the village level for additional protection.

In 2004, the Liberation Tigers of Tamil Eelam claimed have establish a voluntary "Tamil Eelam auxiliary force". According to the LTTE's then head of police, the force was to be assigned to tasks such as rehabilitation, construction, forest conservation and agriculture, but would also be used to battle the Sri Lankan military if the need arose. In early 2009 it ceased to exist with the military defeat of the LTTE at the hands of the Sri Lanka Armed Forces.

The Janjaweed militia consists of armed Arab Muslims fighting for the government in Khartoum against non-Arab Muslim "rebels". They are active in the Darfur region of western Sudan and also in eastern Chad. According to Human Rights Watch these partisans are responsible for abuses including war crimes, crimes against humanity and ethnic cleansing.

As of 2012, the Swedish Home Guard consists of 22,000 organized into 40 light infantry battalions of 300–700 Guardsmen. These battalions are then organised into companies, usually one for every municipality. The main task of the battalions is to guard vital military and civilian installations throughout the country.

In 2001, the Rapid Response units numbered around 5,000 soldiers of the total of 42,000. As of 2014, the majority of the force, 17,000 out of 22,000 soldiers will be in Rapid Response units. The decrease in number of troops comes with an equal increase in quality and modern equipment. These units are motorized and are ready to be mobilized more often, than other Home Guard units. Rapid response units have more combat tasks compared to the rest of the Home Guard, including escort duties. Some battalions located near the coast also have marine companies equipped with Combat Boat 90. A few battalions have recently set up 'specialized' companies to evaluate the possibility to add new abilities to the Home Guard. These are at the time of writing eight reconnaissance/intelligence companies, four CBRN-platoons, a movcon platoon, an engineer platoon, and a military police unit.

One of the best known and ancient militias is the Swiss Armed Forces. Switzerland has long maintained, proportionally, the second largest military force in the world, with about half the proportional amount of reserve forces of the Israeli Defense Forces, a militia of some 33% of the total population. The "militia principle" of public duties is central to Swiss political culture and not limited to military issues. For example, in most municipalities it is common to serve as a conscript fire fighter in the Compulsory Fire Department.

Article 58.1 of the April18, 1999, Federal Constitution of the Swiss Confederation (official, French version) provides that "Switzerland has an army. It is primarily organised according to the principle of a militia." However, under the country's militia system, professional soldiers constitute about 5 percent of military personnel. In 1995, the number of soldiers was reduced to 400,000 (including reservists, amounting to some 5.6% of the population) and again in 2004, to 200,000 (including 80,000 reservists, or 2.5% of the population). However, the Swiss Militia continues to consist of most of the adult male population (with voluntary participation by women) who are required to keep an assault rifle at home and to periodically engage in combat and marksmanship training. The militia clauses of the Swiss Federal Constitution are contained in Art. 59, where it is referred to as "military service" (; ; ; ).

The Syrian National Defense Force was formed out of pro-government militias. They receive their salaries and their military equipment from the government and as of 2013 numbers around 100,000. The force acts in an infantry role, directly fighting against rebels on the ground and running counter-insurgency operations in coordination with the army which provides them with logistical and artillery support. Unlike the Syrian Army, NDF soldiers are allowed to take loot from battlefields, which can then be sold on for extra money.

The obligation to serve in the militia in England derives from a common law tradition, and dates back to Anglo-Saxon times. The tradition was that all able-bodied males were liable to be called out to serve in one of two organisations. These were the posse comitatus, an "ad hoc" assembly called together by a law officer to apprehend lawbreakers, and the fyrd, a military body intended to preserve internal order or defend the locality against an invader. The latter developed into the militia, and was usually embodied by a royal warrant. Service in each organisation involved different levels of preparedness.

With the decay of the feudal system and the military revolution of the 16th century, the militia began to become an important institution in English life. It was organised on the basis of the shire county, and was one of the responsibilities of the Lord Lieutenant, a royal official (usually a trusted nobleman). Each of the county hundreds was likewise the responsibility of a Deputy Lieutenant, who relayed orders to the justices of the peace or magistrates. Every parish furnished a quota of eligible men, whose names were recorded on muster rolls. Likewise, each household was assessed for the purpose of finding weapons, armour, horses, or their financial equivalent, according to their status. The militia was supposed to be mustered for training purposes from time to time, but this was rarely done. The militia regiments were consequently ill-prepared for an emergency, and could not be relied upon to serve outside their own counties. This state of affairs concerned many people. Consequently, an elite force was created, composed of members of the militia who were prepared to meet regularly for military training and exercise. These were formed into trained band regiments, particularly in the City of London, where the Artillery Ground was used for training. The trained bands performed an important role in the English Civil War on the side of parliament, in marching to raise the siege of Gloucester (5 September 1643). Except for the London trained bands, both sides in the Civil War made little use of the militia, preferring to recruit their armies by other means.

As successful English settlement of North America began to take place in 1607 in the face of the hostile intentions of the powerful Spanish, and of the native populations, it became immediately necessary to raise militia amongst the settlers. The militia in Jamestown saw constant action against the Powhatan Federation and other native polities. In the Virginia Company's other outpost, Bermuda, fortification began immediately in 1612. A Spanish attack in 1614 was repulsed by two shots fired from the incomplete Castle Islands Fortifications manned by Bermudian Militiamen. In the Nineteenth century, "Fortress Bermuda" would become Britain's "Gibraltar of the West", heavily fortified by a Regular Army garrison to protect the Royal Navy's headquarters and dockyard in the Western Atlantic.

In the 17th Century, however, Bermuda's defence was left entirely in the hands of the Militia. In addition to requiring all male civilians to train and serve in the militia of their Parish, the Bermudian Militia included a standing body of trained artillerymen to garrison the numerous fortifications which ringed "New London" (St. George's). This standing body was created by recruiting volunteers, and by sentencing criminals to serve as punishment. The Bermudian militiamen were called out on numerous occasions of war, and, on one notable occasion, to quell rioting privateers. The 1707 Acts of Union made Bermudian and other English militiamen "British". The Militia in Bermuda came to include a Troop of Horse (mounted infantry) and served alongside volunteers and (from 1701) a small body of regulars. The Militia faded away after the American War of 1812 when the Parliament of Bermuda declined to renew the Militia Act. This resulted from the build-up of the regular army Bermuda Garrison along with Bermuda's development as the headquarters and dockyard of the North America and West Indies Station of the Royal Navy, which made the militia seem excess to need. Vast sums of the Imperial defence expenditure were lavished on fortifying Bermuda during the Nineteenth Century and the British Government cajoled, implored, begged, and threatened the colonial legislature for 80 years before it raised a militia and volunteer units (in 1894 and 1894 respectively). Although the militia had historically been an infantry force, many units in Britain had been re-tasked as militia artillery from the 1850s onward due to the increased importance of the coastal artillery defences and the new militia unit in Bermuda followed suit. Titled the "Bermuda Militia Artillery", it was badged and uniformed as part of the Royal Artillery, and tasked with the garrison artillery role, manning coastal batteries. As in Britain, recruitment was of volunteers who engaged for terms of service, whereas the Bermuda Volunteer Rifle Corps was organised on the same lines as volunteer rifle corps in Britain. Recruitment to the BVRC was restricted to whites, but the BMA recruited primarily coloured (those who were not entirely of European heritage) other ranks, though its officers were all white until 1953. Neither unit was reorganised in 1908 when the Militia, Volunteer Force and Yeomanry in Britain merged into the Territorial Force, but the BVRC was re-organised as a territorial in 1921 and the BMA in 1926. The BVRC name was not modified to Bermuda Rifles until 1951, however, and the Bermuda Militia Artillery (and from 1939 the Bermuda Militia Infantry) continued to be titled as militia until amalgamated with the Bermuda Rifles in 1965 to form the Bermuda Regiment.

In British India, a special class of militia was established in 1907. This took the form of the Frontier Corps, which consisted of locally recruited full-time auxiliaries under British officers. Their role combined the functions of tribal police and border guards deployed along the North-West Frontier. Regional units included the Zhob Militia, the Kurram Militia, and the Chagai Militia. After 1946 the Frontier Corps became part of the modern Pakistan Army.

Until the Glorious Revolution in 1688 the Crown and Parliament were in strong disagreement. The English Civil War left a rather unusual military legacy. Both Whigs and Tories distrusted the creation of a large standing army not under civilian control. The former feared that it would be used as an instrument of royal tyranny. The latter had memories of the New Model Army and the anti-monarchical social and political revolution that it brought about. Both preferred a small standing army under civilian control for defensive deterrence and to prosecute foreign wars, a large navy as the first line of national defence, and a militia composed of their neighbours as additional defence and to preserve domestic order.

Consequently, the English Bill of Rights (1689) declared, amongst other things: "that the raising or keeping a standing army within the kingdom in time of peace, unless it be with consent of Parliament, is against law..." and "that the subjects which are Protestants may have arms for their defence suitable to their conditions and as allowed by law." This implies that they are fitted to serve in the militia, which was intended to serve as a counterweight to the standing army and preserve civil liberties against the use of the army by a tyrannical monarch or government.

The Crown still (in the British constitution) controls the use of the army. This ensures that officers and enlisted men swear an oath to a politically neutral head of state, and not to a politician. While the funding of the standing army subsists on annual financial votes by parliament, the Mutiny Act, superseded by the Army Act, and now the Armed Forces Act is also renewed on an annual basis by Parliament. If it lapses, the legal basis for enforcing discipline disappears, and soldiers lose their legal indemnity for acts committed under orders.

With the creation of the British Empire, militias were also raised in the colonies, where little support could be provided by regular forces. Overseas militias were first raised in Jamestown, Virginia, and in Bermuda, where the Bermuda Militia followed over the next two centuries a similar trajectory to that in Britain.

In 1707 the Acts of Union united the Kingdom of England with the Kingdom of Scotland. The Scottish navy was incorporated into the Royal Navy. The Scottish military (as opposed to naval) forces merged with the English, with pre-existing regular Scottish regiments maintaining their identities, though command of the new British Army was from England. How this affected militias either side of the border is unclear.

The Militia Act of 1757 created a more professional force. Better records were kept, and the men were selected by ballot to serve for longer periods; specific provision was made for members of the Religious Society of Friends, Quakers, to be exempted, as conscientious objectors, from compulsory enlistment in the militia. Proper uniforms and better weapons were provided, and the force was 'embodied' from time to time for training sessions.

The militia was widely embodied at various times during the French and Napoleonic Wars. It served at several vulnerable locations, and was particularly stationed on the South Coast and in Ireland. A number of camps were held at Brighton, where the militia regiments were reviewed by the Prince Regent. (This is the origin of the song "Brighton Camp".) The militia could not be compelled to serve overseas, but it was seen as a training reserve for the army, as bounties were offered to men who opted to 'exchange' from the militia to the regular army.

The Parliament of Ireland passed an act in 1715 raising regiments of militia in each county and county corporate. Membership was restricted to Protestants between the ages of 16 and 60. In 1793, during the Napoleonic Wars, the Irish militia were reorganised to form thirty-seven county and city regiments. While officers of the reorganised force were Protestant, membership of the other ranks was now made available to members of all denominations.

In the late 17th century came calls for the resurrection of militia in Scotland that had the understated aim of protecting the rights of Scots from English oppression. The 1757 Militia Act did not apply in Scotland. The old traditional system continued, so that militia regiments only existed in some places. This was resented by some and the Militia Club, soon to become the Poker Club, was formed to promote the raising of a Scottish militia. This and several other Edinburgh clubs became the crucible of the Scottish Enlightenment. The Militia Act 1797 empowered Scottish Lord Lieutenants to raise and command militia regiments in each of the "Counties, Stewartries, Cities, and Places" under their jurisdiction.

Although muster rolls were prepared as late as 1820, the element of compulsion was abandoned, and the militia transformed into a volunteer force, revived by the Militia Act of 1852. It was intended to be seen as an alternative to the army. Men would volunteer and undertake basic training for several months at an army depot. Thereafter, they would return to civilian life, but report for regular periods of military training (usually on the weapons ranges) and an annual two-week training camp. In return, they would receive military pay and a financial retainer, a useful addition to their civilian wage. Of course, many saw the annual camp as the equivalent of a paid holiday. The militia thus appealed to agricultural labourers, colliers and the like, men in casual occupations, who could leave their civilian job and pick it up again. Until 1852 the militia were an entirely infantry force, but from that year a number of county infantry regiments were converted to artillery and new ones raised. In 1877 the militia of Anglesey and Monmouthshire were converted to engineers. Under the reforms, introduced by Secretary of State for War Hugh Childers in 1881, the remaining militia infantry regiments were redesignated as numbered battalions of regiments of the line, ranking after the two regular battalions. Typically, an English, Welsh or Scottish regiment would have two militia battalions (the 3rd and 4th) and Irish regiments three (numbered 3rd–5th).

The militia must not be confused with the volunteer units created in a wave of enthusiasm in the second half of the nineteenth century. In contrast with the Volunteer Force, and the similar Yeomanry Cavalry, they were considered rather plebeian.

The militia was transformed into the Special Reserve by the military reforms of Haldane in the reforming post 1906 Liberal government. In 1908 the militia infantry battalions were redesignated as "reserve" and a number were amalgamated or disbanded. Numbered Territorial Force battalions, ranking after the Special Reserve, were formed from the volunteer units at the same time. Altogether, 101 infantry battalions, 33 artillery regiments and two engineer regiments of special reservists were formed. Upon mobilisation, the special reserve units would be formed at the depot and continue training while guarding vulnerable points in Britain. The special reserve units remained in Britain throughout the First World War, but their rank and file did not, since the object of the special reserve was to supply drafts of replacements for the overseas units of the regiment. The original militiamen soon disappeared, and the battalions simply became training units. The Special Reserve reverted to its militia designation in 1921, then to Supplementary Reserve in 1924, though the units were effectively placed in "suspended animation" until disbanded in 1953.

The name was briefly revived in the Military Training Act 1939, in the aftermath of the Munich Crisis. Leslie Hore-Belisha, Secretary of State for War, wished to introduce a limited form of conscription, not known in peacetime Britain since the militia of the early 19th century and previously. It was thought that calling the conscripts 'militiamen' would make this more acceptable, as it would render them distinct from the rest of the army. Only single men aged 20 up to the day before their 22nd birthday were to be conscripted, for six months full-time training before discharge into the reserve (with a free suit of civilian clothing). Although the first intake was called up in late July 1939, the declaration of war on 3 September entailed implementation of full-time conscription for all men aged 18–41, superseding the militia, never to be revived.

Three units still maintain their militia designation in the British Army. These are the Royal Monmouthshire Royal Engineers (formed in 1539), the Jersey Field Squadron (The Royal Militia Island of Jersey) (formed in 1337), and the Royal Alderney Militia (created in the 13th century and reformed in 1984). Additionally, the Atholl Highlanders are a ceremonial infantry militia maintained by the Duke of Atholl—they are the only legal private army in Europe.

Various other part-time, home defence organisations have been raised during times of crisis or perceived threat, although without the word "militia" in their title. These have included:

The various non-state paramilitary groups involved in the 20th-century conflicts in Northern Ireland and the island of Ireland, such as the various Irish Republican Army groups and loyalist paramilitaries, could also be described as militias and are occasionally referred to as such.

The Ulster Defence Regiment (UDR) was a locally raised professional militia instituted by an Act of Parliament in December 1969, becoming operational on 1 April 1970. Created as a non-partisan force to defend Northern Ireland "against armed attack or sabotage", it eventually peaked at 11 battalions with 7,559 men and women. 197 soldiers of the UDR, including four women, were killed as active servicemen, with a further 61 killed after leaving the regiment, mostly by the Provisional Irish Republican Army. As a result of defence cuts it was eventually reduced to 7 battalions before being amalgamated with the Royal Irish Rangers in 1992 to form the "Home Service Battalions" of the Royal Irish Regiment.

The history of militia in the United States dates from the colonial era, such as in the American Revolutionary War. Based on the English system, colonial militias were drawn from the body of adult male citizens of a community, town, or local region. Because there was no standing English Army before the English Civil War, and subsequently the English Army and later the British Army had few regulars garrisoning North America, colonial militia served a vital role in local conflicts, particularly in the French and Indian Wars. Before shooting began in the American War of Independence, American revolutionaries took control of the militia system, reinvigorating training and excluding men with Loyalist inclinations. Regulation of the militia was codified by the Second Continental Congress with the Articles of Confederation. The revolutionaries also created a full-time regular army—the Continental Army—but because of manpower shortages the militia provided short-term support to the regulars in the field throughout the war.

In colonial era Anglo-American usage, militia service was distinguished from military service in that the latter was normally a commitment for a fixed period of time of at least a year, for a salary, whereas militia was only to meet a threat, or prepare to meet a threat, for periods of time expected to be short. Militia persons were normally expected to provide their own weapons, equipment, or supplies, although they may later be compensated for losses or expenditures. A related concept is the jury, which can be regarded as a specialized form of militia convened to render a verdict in a court proceeding (known as a petit jury or trial jury) or to investigate a public matter and render a presentment or indictment (grand jury).

With the Constitutional Convention of 1787 and Article 1 Section 8 of the United States Constitution, control of the army and the power to direct the militia of the states was concurrently delegated to the federal Congress. The Militia Clauses gave Congress authority for "organizing, arming, and disciplining" the militia, and "governing such Part of them as may be employed in the Service of the United States", with the States retaining authority to appoint officers and to impose the training specified by Congress. Proponents describe a key element in the concept of "militia" was that to be "genuine" it not be a "select militia", composed of an unrepresentative subset of the population. This was an argument presented in the ratification debates.

The first legislation on the subject was the Militia Act of 1792 which provided, in part:
That each and every free able-bodied white male citizen of the respective States, resident therein, who is or shall be of age of eighteen years, and under the age of forty-five years (except as is herein after excepted) shall severally and respectively be enrolled in the militia... every citizen, so enrolled and notified, shall, within six months thereafter, provide himself with a good musket or firelock.

Prior to the War of Independence the officers of militia units were commissioned by the royal governors. During the war they were commissioned either by the legislature or the chief executive of the state. After the war, commissions were typically granted by the state's chief executive. Militias did not operate independently of the state governments, but were under the command of the civil government just like the regular military forces. Twenty-four of the current US states maintain state defense forces in the form of a constitutional militia in addition to the National Guard which is shared with the US government. These states include Alabama, Alaska, California, Connecticut, Georgia, Illinois, Indiana, Louisiana, Maryland, Massachusetts, Michigan, Missouri, New Jersey, New Mexico, New York, Ohio, Oklahoma, Oregon, South Carolina, Tennessee, Texas, Washington, Vermont, and Virginia. In addition, the Territory of Puerto Rico has a defense force. Legally, any professed militia that is not under the control of a civil government and whose officers are commissioned by the state is more similar to a street gang than a constitutional militia.

During the nineteenth century, each of the states maintained its militia differently, some more than others. American militia saw action in the various Indian Wars, the War of 1812, the American Civil War, and the Spanish–American War. Sometimes militia units were found to be unprepared, ill-supplied, and unwilling. Prior to the Civil War, militia units were sometimes used by southern states for slave control. Formed in 1860, Republican Party-affiliated Wide Awakes clubs were quick to take action to defend persons against southern slave-hunters. In California, the militia carried out campaigns against bandits and against the Indians at the direction of its Governor between 1850 and 1866. During Reconstruction after the Civil War, Republican state governments had militias composed almost entirely of freed slaves and populist whites. Their deployment to maintain order in the former Confederate states caused increased resentment among many Southern whites.

After the American Civil War, secret groups like the Ku Klux Klan and Knights of the White Camellia arose quickly across the South, reaching a peak in the late 1860s. Even more significant in terms of effect were private militias: paramilitary organizations that formed starting in 1874, including the White League in Louisiana, which quickly formed chapters in other states; the Red Shirts in Mississippi in 1875, and with South Carolina and North Carolina; and other "white line" militias and rifle clubs.

In contrast to the KKK, these paramilitary organizations were open; members were often well known in their communities. Nevertheless, they used force, intimidation, and violence, including murder, to push out Republican officeholders, break up organizing, and suppress freedmen's voting and civil rights. The paramilitary groups were described as "the military arm of the Democratic Party" and were instrumental in helping secure Democratic victories in the South in the elections of 1876.

The Militia Act of 1903 divided what had been the militia into what it termed the "organized" militia, created from portions of the former state guards to become state National Guard units, and the "unorganized" militia consisting of all males from ages 17 to 45, with the exception of certain officials and others, which is codified in . Some states, such as Texas, California, and Ohio, created separate state defense forces for assistance in local emergencies. Congress later established a system of "dual enlistment" for the National Guard, so that anyone who enlisted in the National Guard also enlisted in the U.S. Army. When the U.S. Air Force was established as an independent service in 1947, the National Guard was further divided into the Army National Guard and the Air National Guard. Under this construct, the 1933 defense act's "dual enlistment" facet was further amended so that enlisted soldiers and commissioned officers in the Army National Guard were also enlisted or commissioned in the Reserve Component of the U.S. Army. Enlisted airmen and commissioned officers in the Air National Guard were also enlisted or commissioned in the Air Reserve Component (ARC) of the U.S. Air Force.

Privately organized citizen militia-related groups blossomed in the mid-1990s, which collectively became known as the constitutional militia movement. The supporters have not been affiliated with any government organization, although many have been military and law enforcement veterans.

In its original sense, "militia" meant "the state, quality, condition, or activity of being a fighter or warrior." It can be thought of as "combatant activity", "the fighter frame of mind", "the militant mode", "the soldierly status", or "the warrior way". In this latter usage, a militia is a body of private persons who respond to an emergency threat to public safety, usually one that requires an armed response, but which can also include ordinary law enforcement or disaster responses. The act of bringing to bear arms contextually changes the status of the person, from peaceful citizen, to warrior citizen. The militia is the sum total of persons undergoing this change of state. Persons have been said to engage in militia in response to a "call up" by any person aware of the emergent threat requiring the response, and thence to be in "called up" status until the emergency is past. There is no minimum size to militia, and a solitary act of defense, including self-defense, can be thought of as one person calling up himself to defend the community, represented by himself or others, and to enforce the law. See citizen's arrest and hue and cry.

In the 2008 decision of the Supreme Court, in District of Columbia v. Heller, the "de jure" definition of "militia" as used in United States jurisprudence was discussed. The Court's opinion made explicit, in its "obiter dicta", that the term "militia," as used in colonial times in this originalist decision, included both the federally organized militia and the citizen-organized militias of the several States: "... the 'militia' in colonial America consisted of a subset of 'the people'—those who were male, able-bodied, and within a certain age range" (7)... Although the militia consists of all able-bodied men, the federally-organized militia may consist of a subset of them"(23).


The most important previous activity of the Texas Militia was the Texas Revolution in 1836. Texans declared independence from Mexico while they were defeated during the Battle of the Alamo, in March 1836. On April 21, 1836, led by Sam Houston, the Militia attacked the Mexican Army at their camp, in the Battle of San Jacinto near the present city of Houston. Following the war, some militia units reorganized into what was later to be known as the Texas Rangers, which was a private, volunteer effort for several years before becoming an official organization. After Texas joined the Union of the United States in 1845, Texas militia units participated in the Mexican–American War.

In 1861 Texas joined the other Confederate States in seceding from the Union, and Texas militias played a role in the American Civil War, until it ended in 1865. Texas militiamen joined Theodore Roosevelt's Rough Riders, a volunteer militia, and fought with him during the Spanish–American War in 1898. Some of the training of the Rough Riders took place in San Pedro Park, in the north central part of San Antonio near the present site of San Antonio College. When a muster of the Militia proposed to train there on April 19, 1994, they were threatened with arrest, even though the charter of San Pedro Park forbids exclusion of activities of that kind. This threat led to a change of the meeting site. Like many other American states, Texas maintains a recognized State Militia, the Texas State Guard.

The Vietnam Militia ("Dân quân Tự vệ") is a part of Vietnam People's Armed Forces. The militia organized in communes, wards and townships and are put under commune-level military commands.

Vietnam Militia has two branches: Special Militia (nòng cốt) and General Militia (rộng rãi). The term of service in the core militia is 4 years.

Beside the federal Yugoslav People's Army, each constituent republic of the former SFR Yugoslavia had its own "Territorial Defense Forces". The Non-Aligned Yugoslavia was concerned about an eventual aggression from any of the superpowers, especially by the Warsaw Pact after the Prague Spring, so the "Territorial Defense Forces" were formed as an integral part of the total war military doctrine called "Total National Defense". Those forces corresponded to military reserve forces, paramilitary or militia, the latter, in the military meaning of the term (like military formation). It should not be confused with the Yugoslav Militia- "Milicija" which was a term for a police.




</doc>
<doc id="20623" url="https://en.wikipedia.org/wiki?curid=20623" title="Multiprotocol Label Switching">
Multiprotocol Label Switching

Multiprotocol Label Switching (MPLS) is a routing technique in telecommunications networks that directs data from one node to the next based on short path labels rather than long network addresses, thus avoiding complex lookups in a routing table and speeding traffic flows. The labels identify virtual links ("paths") between distant nodes rather than endpoints. MPLS can encapsulate packets of various network protocols, hence the "multiprotocol" reference on its name. MPLS supports a range of access technologies, including T1/E1, ATM, Frame Relay, and DSL.

MPLS is scalable and protocol-independent. In an MPLS network, data packets are assigned labels. Packet-forwarding decisions are made solely on the contents of this label, without the need to examine the packet itself. This allows one to create end-to-end circuits across any type of transport medium, using any protocol. The primary benefit is to eliminate dependence on a particular OSI model data link layer (layer 2) technology, such as Asynchronous Transfer Mode (ATM), Frame Relay, Synchronous Optical Networking (SONET) or Ethernet, and eliminate the need for multiple layer-2 networks to satisfy different types of traffic. Multiprotocol label switching belongs to the family of packet-switched networks.

MPLS operates at a layer that is generally considered to lie between traditional definitions of OSI Layer 2 (data link layer) and Layer 3 (network layer), and thus is often referred to as a "layer 2.5" protocol. It was designed to provide a unified data-carrying service for both circuit-based clients and packet-switching clients which provide a datagram service model. It can be used to carry many different kinds of traffic, including IP packets, as well as native ATM, SONET, and Ethernet frames.

A number of different technologies were previously deployed with essentially identical goals, such as Frame Relay and ATM. Frame Relay and ATM use "labels" to move frames or cells throughout a network. The header of the Frame Relay frame and the ATM cell refers to the virtual circuit that the frame or cell resides on. The similarity between Frame Relay, ATM, and MPLS is that at each hop throughout the network, the “label” value in the header is changed. This is different from the forwarding of IP packets. MPLS technologies have evolved with the strengths and weaknesses of ATM in mind. MPLS is designed to have lower overhead than ATM while providing connection-oriented services for variable-length frames, and has replaced much use of ATM in the market.

In particular, MPLS dispenses with the cell-switching and signaling-protocol baggage of ATM. MPLS recognizes that small ATM cells are not needed in the core of modern networks, since modern optical networks are so fast (, at 200 Gbit/s and beyond) that even full-length 1500 byte packets do not incur significant real-time queuing delays (the need to reduce such delays — "e.g.", to support voice traffic — was the motivation for the cell nature of ATM).

At the same time, MPLS attempts to preserve the traffic engineering (TE) and out-of-band control that made Frame Relay and ATM attractive for deploying large-scale networks.


In 1996 a group from Ipsilon Networks proposed a "flow management protocol".
Their "IP Switching" technology, which was defined only to work over ATM, did not achieve market dominance. Cisco Systems introduced a related proposal, not restricted to ATM transmission, called "Tag Switching" (with its Tag Distribution Protocol TDP). It was a Cisco proprietary proposal, and was renamed "Label Switching". It was handed over to the Internet Engineering Task Force (IETF) for open standardization. The IETF work involved proposals from other vendors, and development of a consensus protocol that combined features from several vendors' work.

One original motivation was to allow the creation of simple high-speed switches since for a significant length of time it was impossible to forward IP packets entirely in hardware. However, advances in VLSI have made such devices possible. Therefore, the advantages of MPLS primarily revolve around the ability to support multiple service models and perform traffic management. MPLS also offers a robust recovery framework that goes beyond the simple protection rings of synchronous optical networking (SONET/SDH).

MPLS works by prefixing packets with an MPLS header, containing one or more labels. This is called a label stack.
Each entry in the label stack contains four fields:

These MPLS-labeled packets are switched after a label lookup/switch instead of a lookup into the IP table. As mentioned above, when MPLS was conceived, label lookup and label switching were faster than a routing table or RIB (Routing Information Base) lookup because they could take place directly within the switched fabric and avoid having to use the OS.

The presence of such a label, however, has to be indicated to the router/switch. In the case of Ethernet frames this is done through the use of EtherType values 0x8847 and 0x8848, for unicast and multicast connections respectively.

An MPLS router that performs routing based only on the label is called a label switch router (LSR) or transit router. This is a type of router located in the middle of an MPLS network. It is responsible for switching the labels used to route packets.

When an LSR receives a packet, it uses the label included in the packet header as an index to determine the next hop on the label-switched path (LSP) and a corresponding label for the packet from a lookup table. The old label is then removed from the header and replaced with the new label before the packet is routed forward.

A label edge router (LER, also known as edge LSR) is a router that operates at the edge of an MPLS network and acts as the entry and exit points for the network. LERs "push" an MPLS label onto an incoming packet and "pop" it off an outgoing packet. Alternatively, under penultimate hop popping this function may instead be performed by the LSR directly connected to the LER.

When forwarding an IP datagram into the MPLS domain, a LER uses routing information to determine the appropriate label to be affixed, labels the packet accordingly, and then forwards the labeled packet into the MPLS domain. Likewise, upon receiving a labeled packet which is destined to exit the MPLS domain, the LER strips off the label and forwards the resulting IP packet using normal IP forwarding rules.

In the specific context of an MPLS-based virtual private network (VPN), LERs that function as ingress and/or egress routers to the VPN are often called PE (Provider Edge) routers. Devices that function only as transit routers are similarly called P (Provider) routers. The job of a P router is significantly easier than that of a PE router, so they can be less complex and may be more dependable because of this.

Labels are distributed between LERs and LSRs using the Label Distribution Protocol (LDP). LSRs in an MPLS network regularly exchange label and reachability information with each other using standardized procedures in order to build a complete picture of the network so they can then use to forward packets.

Label-switched paths (LSPs) are established by the network operator for a variety of purposes, such as to create network-based IP virtual private networks or to route traffic along specified paths through the network. In many respects, LSPs are not different from permanent virtual circuits (PVCs) in ATM or Frame Relay networks, except that they are not dependent on a particular layer-2 technology.

When an unlabeled packet enters the ingress router and needs to be passed on to an MPLS tunnel, the router first determines the forwarding equivalence class (FEC) for the packet and then inserts one or more labels in the packet's newly created MPLS header. The packet is then passed on to the next hop router for this tunnel.

The MPLS Header is added between the network layer header and link layer header of the OSI model.

When a labeled packet is received by an MPLS router, the topmost label is examined. Based on the contents of the label a "swap", "push" ("impose") or "pop" ("dispose") operation is performed on the packet's label stack. Routers can have prebuilt lookup tables that tell them which kind of operation to do based on the topmost label of the incoming packet so they can process the packet very quickly.

During these operations, the contents of the packet below the MPLS Label stack are not examined. Indeed, transit routers typically need only to examine the topmost label on the stack. The forwarding of the packet is done based on the contents of the labels, which allows "protocol-independent packet forwarding" that does not need to look at a protocol-dependent routing table and avoids the expensive IP longest prefix match at each hop.

At the egress router, when the last label has been popped, only the payload remains. This can be an IP packet or any of a number of other kinds of payload packet. The egress router must, therefore, have routing information for the packet's payload since it must forward it without the help of label lookup tables. An MPLS transit router has no such requirement.

Usually (by default with only one label in the stack, accordingly to the MPLS specification), the last label is popped off at the penultimate hop (the hop before the egress router). This is called penultimate hop popping (PHP). This may be interesting in cases where the egress router has lots of packets leaving MPLS tunnels, and thus spends inordinate amounts of CPU time on this. By using PHP, transit routers connected directly to this egress router effectively offload it, by popping the last label themselves. In the label distribution protocols, this PHP label pop action is advertised as label value 3 « implicit-null» (which is never found in a label, since it means that the label is to be popped).

This optimisation is no longer that useful (like for initial rationales for MPLS – easier operations for the routers). Several MPLS services (including end-to-end QoS management, and 6PE) imply to keep a label even between the penultimate and the last MPLS router, with a label disposition always done on the last MPLS router: the «Ultimate Hop Popping» (UHP). Some specific label values have been notably reserved for this use: 

A label-switched path (LSP) is a path through an MPLS network, set up by the NMS or by a signaling protocol such as LDP, RSVP-TE, BGP (or the now deprecated CR-LDP). The path is set up based on criteria in the FEC.

The path begins at a label edge router (LER), which makes a decision on which label to prefix to a packet, based on the appropriate FEC. It then forwards the packet along to the next router in the path, which swaps the packet's outer label for another label, and forwards it to the next router. The last router in the path removes the label from the packet and forwards the packet based on the header of its next layer, for example IPv4. Due to the forwarding of packets through an LSP being opaque to higher network layers, an LSP is also sometimes referred to as an MPLS tunnel.

The router which first prefixes the MPLS header to a packet is called an ingress router. The last router in an LSP, which pops the label from the packet, is called an egress router. Routers in between, which need only swap labels, are called transit routers or label switch routers (LSRs).

Note that LSPs are unidirectional; they enable a packet to be label switched through the MPLS network from one endpoint to another. Since bidirectional communication is typically desired, the aforementioned dynamic signaling protocols can set up an LSP in the other direction to compensate for this.

When protection is considered, LSPs could be categorized as primary (working), secondary (backup) and tertiary (LSP of last resort). As described above, LSPs are normally P2P (point to point). A new concept of LSPs, which are known as P2MP (point to multi-point), was introduced recently. These are mainly used for multicasting purposes.

There are two standardized protocols for managing MPLS paths: the Label Distribution Protocol (LDP) and RSVP-TE, an extension of the Resource Reservation Protocol (RSVP) for traffic engineering. Furthermore, there exist extensions of the Border Gateway Protocol (BGP) that can be used to manage an MPLS path.

An MPLS header does not identify the type of data carried inside the MPLS path. If one wants to carry two different types of traffic between the same two routers, with different treatment by the core routers for each type, one has to establish a separate MPLS path for each type of traffic.

Multicast was, for the most part, an after-thought in MPLS design. It was introduced by point-to-multipoint RSVP-TE. It was driven by service provider requirements to transport broadband video over MPLS. Since the inception of there has been a tremendous surge in interest and deployment of MPLS multicast and this has led to several new developments both in the IETF and in shipping products.

The hub&spoke multipoint LSP is also introduced by IETF, short as HSMP LSP. HSMP LSP is mainly used for multicast, time synchronization, and other purposes.

MPLS works in conjunction with the Internet Protocol (IP) and its routing protocols, such as the Interior Gateway Protocol (IGP). MPLS LSPs provide dynamic, transparent virtual networks with support for traffic engineering, the ability to transport layer-3 (IP) VPNs with overlapping address spaces, and support for layer-2 pseudowires using Pseudowire Emulation Edge-to-Edge (PWE3) that are capable of transporting a variety of transport payloads (IPv4, IPv6, ATM, Frame Relay, etc.). MPLS-capable devices are referred to as LSRs. The paths an LSR knows can be defined using explicit hop-by-hop configuration, or are dynamically routed by the constrained shortest path first (CSPF) algorithm, or are configured as a loose route that avoids a particular IP address or that is partly explicit and partly dynamic.

In a pure IP network, the shortest path to a destination is chosen even when the path becomes congested. Meanwhile, in an IP network with MPLS Traffic Engineering CSPF routing, constraints such as the RSVP bandwidth of the traversed links can also be considered, such that the shortest path with available bandwidth will be chosen. MPLS Traffic Engineering relies upon the use of TE extensions to Open Shortest Path First (OSPF) or Intermediate System To Intermediate System (IS-IS) and RSVP. In addition to the constraint of RSVP bandwidth, users can also define their own constraints by specifying link attributes and special requirements for tunnels to route (or not to route) over links with certain attributes.

For end-users the use of MPLS is not visible directly, but can be assumed when doing a traceroute: only nodes that do "full" IP routing are shown as hops in the path, thus not the MPLS nodes used in between, therefore when you see that a packet "hops" between two very distant nodes and hardly any other 'hop' is seen in that provider's network (or AS) it is very likely that network uses MPLS.

In the event of a network element failure when recovery mechanisms are employed at the IP layer, restoration may take several seconds which may be unacceptable for real-time applications such as VoIP. In contrast, MPLS local protection meets the requirements of real-time applications with recovery times comparable to those of shortest path bridging networks or SONET rings of less than 50 ms.

MPLS can make use of existing ATM network or Frame Relay infrastructure, as its labeled flows can be mapped to ATM or Frame Relay virtual-circuit identifiers, and vice versa.

Frame Relay aimed to make more efficient use of existing physical resources, which allow for the underprovisioning of data services by telecommunications companies (telcos) to their customers, as clients were unlikely to be utilizing a data service 100 percent of the time. In more recent years, Frame Relay has acquired a bad reputation in some markets because of excessive bandwidth overbooking by these telcos.

Telcos often sell Frame Relay to businesses looking for a cheaper alternative to dedicated lines; its use in different geographic areas depended greatly on governmental and telecommunication companies' policies.

Many customers are likely to migrate from Frame Relay to MPLS over IP or Ethernet within the next two years, which in many cases will reduce costs and improve manageability and performance of their wide area networks.

While the underlying protocols and technologies are different, both MPLS and ATM provide a connection-oriented service for transporting data across computer networks. In both technologies, connections are signaled between endpoints, the connection state is maintained at each node in the path, and encapsulation techniques are used to carry data across the connection. Excluding differences in the signaling protocols (RSVP/LDP for MPLS and PNNI:Private Network-to-Network Interface for ATM) there still remain significant differences in the behavior of the technologies.

The most significant difference is in the transport and encapsulation methods. MPLS is able to work with variable length packets while ATM transports fixed-length (53 bytes) cells. Packets must be segmented, transported and re-assembled over an ATM network using an adaptation layer, which adds significant complexity and overhead to the data stream. MPLS, on the other hand, simply adds a label to the head of each packet and transmits it on the network.

Differences exist, as well, in the nature of the connections. An MPLS connection (LSP) is unidirectional—allowing data to flow in only one direction between two endpoints. Establishing two-way communications between endpoints requires a pair of LSPs to be established. Because 2 LSPs are required for connectivity, data flowing in the forward direction may use a different path from data flowing in the reverse direction. ATM point-to-point connections (virtual circuits), on the other hand, are bidirectional, allowing data to flow in both directions over the same path (Both SVC and PVC ATM connections are bidirectional. Check ITU-T I.150 3.1.3.1).

Both ATM and MPLS support tunneling of connections inside connections. MPLS uses label stacking to accomplish this while ATM uses "virtual paths". MPLS can stack multiple labels to form tunnels within tunnels. The ATM virtual path indicator (VPI) and virtual circuit indicator (VCI) are both carried together in the cell header, limiting ATM to a single level of tunneling.

The biggest advantage that MPLS has over ATM is that it was designed from the start to be complementary to IP. Modern routers are able to support both MPLS and IP natively across a common interface allowing network operators great flexibility in network design and operation. ATM's incompatibilities with IP require complex adaptation, making it comparatively less suitable for today's predominantly IP networks.

MPLS is currently (as of March 2012) in use in IP-only networks and is standardized by the IETF in . It is deployed to connect as few as two facilities to very large deployments.

In practice, MPLS is mainly used to forward IP protocol data units (PDUs) and Virtual Private LAN Service (VPLS) Ethernet traffic. Major applications of MPLS are telecommunications traffic engineering, and MPLS VPN.

MPLS has been originally proposed to allow high-performance traffic forwarding and traffic engineering in IP networks. However it evolved in Generalized MPLS (GMPLS) to allow the creation of label-switched paths (LSPs) also in non-native IP networks, such as SONET/SDH networks and wavelength switched optical networks.

MPLS can exist in both an IPv4 and an IPv6 environment, using appropriate routing protocols. The major goal of MPLS development was the increase of routing speed. This goal is no longer relevant because of the usage of newer switching methods (able to forward plain IPv4 as fast as MPLS labelled packets), such as ASIC, TCAM and CAM-based switching. Now, therefore, the main application of MPLS is to implement limited traffic engineering and layer 3 / layer 2 “service provider type” VPNs over IPv4 networks.

Besides GMPLS, the main competitors to MPLS are Shortest Path Bridging (SPB), Provider Backbone Bridges (PBB), and MPLS-TP. These also provide services such as service provider layer 2 and layer 3 VPNs. 

As an example of NPLC, consider two cities. An organization has an office in each city. The organization requires connectivity between these two offices. The ISP will have access to a PoP in each city and therefore has a link between the PoPs. To connect the offices to the PoPs, a connection via the local loop will be commissioned for each office. In this way, an NPLC is delivered.





</doc>
<doc id="20624" url="https://en.wikipedia.org/wiki?curid=20624" title="Message transfer agent">
Message transfer agent

Within the Internet email system, a message transfer agent or mail transfer agent (MTA) or mail relay is software that transfers electronic mail messages from one computer to another using SMTP. The terms mail server, mail exchanger, and MX host are also used in some contexts.

Messages exchanged across networks are passed between mail servers, including any attached data files (such as images, multimedia or documents). These servers also often keep mailboxes for email. Access to this email by end users is typically either via webmail or an email client. 

A message transfer agent receives mail from either another MTA, a mail submission agent (MSA), or a mail user agent (MUA). The transmission details are specified by the Simple Mail Transfer Protocol (SMTP). When a recipient mailbox of a message is not hosted locally, the message is relayed, that is, forwarded to another MTA. Every time an MTA receives an email message, it adds a Received trace header field to the top of the header of the message, thereby building a sequential record of MTAs handling the message. The process of choosing a target MTA for the next hop is also described in SMTP, but can usually be overridden by configuring the MTA software with specific routes.

An MTA works in the background, while the user usually interacts directly with a mail user agent. One may distinguish initial submission as first passing through an MSA – port 587 is used for communication between an MUA and an MSA, while port 25 is used for communication between MTAs, or from an MSA to an MTA; this distinction is first made in RFC 2476.

For recipients hosted locally, the final delivery of email to a recipient mailbox is the task of a message delivery agent (MDA). For this purpose the MTA transfers the message to the message handling service component of the message delivery agent (MDA). Upon final delivery, the Return-Path field is added to the envelope to record the return path.

A relay or filtering server will typically store email only briefly, but other systems keep full mailboxes for email - in which case they usually support some means for end users to access their email via a Mail User Agent (MUA), or email client.

Common protocols for this are:

Submission of new email from a mail client is via SMTP, typically on port 587 or 465, and is now generally restricted to servers the user has an account with-such as their ISP. This is for policy, not technical, reasons so that providers have some means of holding their users accountable for the generation of spam and other forms of email abuse.



</doc>
<doc id="20625" url="https://en.wikipedia.org/wiki?curid=20625" title="Makran">
Makran

Makran (, ) is a semi-desert coastal strip in Balochistan, in Pakistan and Iran, along the coast of the Gulf of Oman.

The southern part of Balochistan is called "Kech Makran" on Pakistani side and Makran on the Iranian side which is also the name of a former Iranian province. The location corresponds to that of the Maka satrapy In Achaemenid times. The Sumerian trading partners of Magan are identified with Makran. In Varahamihira's Brihat Samhita, there is a mention of a tribe called "Makara" inhabiting the lands west of India. Arrian used the term "Ichthyophagi" (Ancient Greek for "fish eaters") for inhabitants of coastal areas, which has led to a suggestion to derive "Makran" from the Modern Persian term "māhī khorān", meaning "fish eaters", but this derivation is considered "erroneous".

Abū Rayḥān Muḥammad ibn Aḥmad Al-Bīrūnī, states in his book "India" that the coast of India begins with Tiz, the capital of Makran.

According to historian Andre Wink:
Wink has recorded Hiuen Tsang's notings on the language and script in use in easternmost Makran (eastern parts of Pakistani Balochistan and Sindh):

The first Islamic conquest of Makran took place during the Rashidun Caliphate in the year 643 A.D. Caliph Umar’s governor of Bahrain, Usman ibn Abu al-Aas, who was on a campaign to conquer the southern coastal areas beyond Sassanid, sent his brother Hakam ibn Abu al-Aas to raid and reconnoitre the Makran region.

In late 644 AD Caliph Umar dispatched an army under the command of Hakam ibn Amr for the wholesale invasion of Makkuran. He was joined by reinforcements from Kufa under the command of Shahab ibn Makharaq, and by Abdullah ibn Utban, the commander of a campaign in Kerman. They encountered no strong resistance in Makran until the army of the King of Rai, along with contingents from Makran and Sind, stopped them near the Indus River. In mid-644 the Battle of Rasil was fought between the forces of the Rashidun Caliphate and the Rai Kingdom; the Raja's forces were defeated and forced to retreat to the eastern bank of the Indus. The Raja’s army had included war elephants, but these had posed little problem for the Muslim invaders, who had dealt with them during the conquest of Persia. In accordance with the orders of Caliph Umar, the captured war elephants were sold in Islamic Persia, with the proceeds distributed among the soldiers as share in booty. In response to Caliph Umar’s questions about the Makran region, the messenger from Makkuran who brought the news of the victory told him:

Umar looked at the messenger and said: 
"Are you a messenger or a poet?" He replied, "Messenger". 
Thereupon Caliph Umar instructed Hakim bin Amr al Taghlabi that for the time being Makkuran should be the easternmost frontier of the Islamic empire, and that no further attempt should be made to extend the conquests.

Makran remained part of the Umayyad and Abbasid Caliphate, and was also ruled by Muslim Turks, Persian. It was conquered by Mongols in the 13th century AD but failed later, and in the 18th century the Baluch Nawab had agreed for governing the Makran region with mutual interest between both sides, as the British failed to conquer the area by force.

Baloch raiders plundered Mahmud of Ghazni's ambassador between Tabbas and Khabis. In revenge, his son Masud defeated them at the latter place, which lies at the foot of the Karman Mountains on the edge of the desert.

From the 15th century onward, the area was ruled by the Rind tribe which was headed by Mir Chakar Rind later by Hooth Dynasty In Makran Which led by Hooths and Khosags, Buledis, Noesherwani, Ghichkis and in small particular part govern by Gorgeig and Sardarzahi. In the late 18th century, the Khan of Kalat is said to have granted sanctuary at Gwadar to one of the claimants for the throne of Muscat. When that claimant became Sultan, he kept hold of Gwadar, installing a governor, who eventually led an army to conquer the city of Chabahar some 200 kilometres to the west.

The sultanate held onto the Makran coast throughout the period of British colonial rule, but eventually only Gwadar was left in the hands of the sultan. On the independence of Pakistan, Makran became a district within the province of Balochistan, minus an area of 800 km around Gwadar. The enclave was finally transferred in 1958 to Pakistani control as part of the district of Makran. The entire region has been subdivided into new smaller districts over the years.

The narrow coastal plain rises rapidly into several mountain ranges. Of the coastline, around is in Pakistan. The climate is dry with little rainfall. Makran is very sparsely inhabited, with much of the population concentrated in a string of small ports including Chabahar, Gwatar, Jiwani, Jask, Sirik, Gwadar (not to be confused with Gwatar), Pasni, Ormara and many smaller fishing villages.

There is only one island off the coast of Makran, Astola Island, near Pasni although there are several small islets. The coastline can be divided into an eastern lagoon coastline and a western embayed coastline. The main lagoons are Miani Hor and Kalamat Hor. The main bays of the embayed coast are Gwadar Bay and Gwatar Bay. This latter bay shelters a large mangrove forest and the nesting grounds of endangered turtle species. The Mirani Dam provides irrigation, flood prevention and water supply to Gwadar city.





</doc>
<doc id="20627" url="https://en.wikipedia.org/wiki?curid=20627" title="Micrometre">
Micrometre

The micrometre (international spelling as used by the International Bureau of Weights and Measures; SI symbol: μm) or micrometer (American spelling), also commonly known by the previous name micron, is an SI derived unit of length equalling (SI standard prefix "micro-" = 10); that is, one millionth of a metre (or one thousandth of a millimetre, 0.001 mm, or about 0.000039 inch).

The micrometre is a common unit of measurement for wavelengths of infrared radiation as well as sizes of biological cells and bacteria, and for grading wool by the diameter of the fibres. The width of a single human hair ranges from approximately 20 to 200 μm. The longest human chromosome is approximately 10 μm in length.

Between 1 μm and 10 μm:

Between 10 μm and 100 μm:
The term "micron" and the symbol μ were officially accepted for use in isolation to denote the micrometre in 1879, but officially revoked by the International System of Units (SI) in 1967. This became necessary because the older usage was incompatible with the official adoption of the unit prefix "micro-", denoted μ, during the creation of the SI in 1960. 

In the SI, the systematic name "micrometre" became the official name of the unit, and μm became the official unit symbol.

academic science (including geology, biology, physics, and astronomy) and in applied science and industry (including machining, the semiconductor industry, and plastics manufacturing). Additionally, in American English, the use of "micron" helps differentiate the unit from the micrometer, a measuring device, because the unit's name in mainstream American spelling is a homograph of the device's name. In spoken English, they may be distinguished by pronunciation, as the name of the measuring device is invariably stressed on the second syllable, whereas the systematic pronunciation of the unit name, in accordance with the convention for pronouncing SI units in English, places the stress on the first syllable.

The plural of "micron" is normally "microns", though "micra" was occasionally used before 1950.

The official symbol for the SI prefix "micro-" is a Greek lowercase mu (μ). In Unicode, there is also a micro sign with the code point U+00B5 (µ), distinct from the code point U+03BC (μ) of the Greek letter lowercase mu. According to the Unicode Consortium, the Greek letter character is preferred, but implementations must recognize the micro sign as well. Most fonts use the same glyph for the two characters.



</doc>
