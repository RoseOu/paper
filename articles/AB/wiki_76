<doc id="21148" url="https://en.wikipedia.org/wiki?curid=21148" title="Netherlands">
Netherlands

The Netherlands (, ), informally Holland, is a country in Northwestern Europe with some overseas territories in the Caribbean. In Europe, it consists of 12 provinces that border Germany to the east, Belgium to the south, and the North Sea to the northwest, with maritime borders in the North Sea with those countries and the United Kingdom. Together with the Caribbean Netherlands —Bonaire, Sint Eustatius and Saba—it forms a constituent country of the Kingdom of the Netherlands. The official language is Dutch and a secondary official language in the province of Friesland is West Frisian. In the north and east of the country, Low Saxon is also spoken, and in the southeast, Limburgish. In the Caribbean Netherlands English and Papiamento are recognised languages.

The four largest cities in the Netherlands are Amsterdam, Rotterdam, The Hague and Utrecht. Amsterdam is the country's most populous city and nominal capital, while The Hague holds the seat of the States General, Cabinet and Supreme Court. The Port of Rotterdam is the busiest seaport in Europe, and the busiest in any country outside Asia. Amsterdam Airport Schiphol is the busiest airport in the Netherlands, and the third busiest in Europe. The country is a founding member of the EU, Eurozone, G10, NATO, OECD and WTO, as well as a part of the Schengen Area and the trilateral Benelux Union. It hosts several intergovernmental organisations and international courts, many of which are centered in The Hague, which is consequently dubbed 'the world's legal capital'.

"Netherlands" literally means 'lower countries' in reference to its low elevation and flat topography, with only about 50% of its land exceeding above sea level, and nearly 17% falling below sea level. Most of the areas below sea level, known as "polders", are the result of land reclamation that began in the 16th century. With a population of 17.4 million people, all living within a total area of roughly —of which the land area is —the Netherlands is the 12th most densely populated country in the world and the 5th most densely populated country in Europe, with a density of . Nevertheless, it is the world's second-largest exporter of food and agricultural products (after the United States), owing to its fertile soil, mild climate, intensive agriculture and inventiveness.

The Netherlands has been a parliamentary constitutional monarchy with a unitary structure since 1848. The country has a tradition of pillarisation and a long record of social tolerance, having legalised abortion, prostitution and human euthanasia, along with maintaining a liberal drug policy. The Netherlands abolished the death penalty in 1870, allowed women's suffrage in 1917, before becoming the world's first country to legalise same-sex marriage in 2001. Its mixed-market advanced economy had the thirteenth-highest per capita income globally. The Netherlands ranks among the highest in international indexes of press freedom, economic freedom, human development and quality of life, as well as happiness.

The Netherlands' turbulent history and shifts of power resulted in exceptionally many and widely varying names in different languages. There is diversity even within languages. In English, the Netherlands is also called Holland or (part of) the Low Countries, whereas the term ""Dutch"" is used as the demonym and adjectival form. 

The region called the Low Countries (comprising Belgium, the Netherlands and Luxembourg) and the Country of the Netherlands, have the same toponymy. Place names with "Neder" (or "lage"), "Nieder", "Nether" (or "low") and "Nedre" (in Germanic languages) and "Bas" or "Inferior" (in Romance languages) are in use in places all over Europe. They are sometimes used in a deictic relation to a higher ground that consecutively is indicated as "Upper", "Boven", "Oben", "Superior" or "Haut". In the case of the Low Countries / Netherlands the geographical location of the "lower" region has been more or less downstream and near the sea. The geographical location of the upper region, however, changed tremendously over time, depending on the location of the economic and military power governing the Low Countries area. The Romans made a distinction between the Roman provinces of downstream Germania Inferior (nowadays part of Belgium and the Netherlands) and upstream Germania Superior (nowadays part of Germany). The designation 'Low' to refer to the region returns again in the 10th century Duchy of Lower Lorraine, that covered much of the Low Countries. But this time the corresponding "Upper" region is Upper Lorraine, in nowadays Northern France.

The Dukes of Burgundy, who ruled the Low Countries in the 15th century, used the term "les pays de par deçà" ("the lands over here") for the Low Countries as opposed to "les pays de par delà" ("the lands over there") for their original homeland: Burgundy in present-day east-central France. Under Habsburg rule, "Les pays de par deçà" developed in "pays d'embas" ("lands down-here"), a deictic expression in relation to other Habsburg possessions like Hungary and Austria. This was translated as "Neder-landen" in contemporary Dutch official documents. From a regional point of view, "Niderlant" was also the area between the Meuse and the lower Rhine in the late Middle Ages. The area known as "Oberland" (High country) was in this deictic context considered to begin approximately at the nearby higher located Cologne.

From the mid-sixteenth century on, the "Low Countries" and the "Netherlands" lost their original deictic meaning. They were probably the most commonly used names, besides Flanders, a "pars pro toto" for the Low Countries, especially in Romance language speaking Europe. The Eighty Years' War (1568–1648) divided the Low Countries into an independent northern Dutch Republic (or Latinised "Belgica Foederata", "Federated Netherlands", the precursor state of the Netherlands) and a Spanish controlled Southern Netherlands (Latinised "Belgica Regia", "Royal Netherlands", the precursor state of Belgium). The Low Countries today is a designation that includes the countries of the Netherlands, Belgium and Luxembourg, although in most Romance languages, the term "Low Countries" is used as the name for the Netherlands specifically. It is used synonymous with the more neutral and geopolitical term Benelux.

The Netherlands is also referred to as Holland in various languages, including English. The region of Holland proper consists of North and South Holland, two of the nation's twelve provinces, formerly a single province, and earlier still, the County of Holland, a remnant of the dissolved Frisian Kingdom. Following the decline of the Duchy of Brabant and the County of Flanders, Holland became the most economically and politically important county in the Low Countries region. The emphasis on Holland during the formation of the Dutch Republic, the Eighty Years' War, and the Anglo-Dutch Wars in the 16th, 17th, and 18th century, made Holland serve as a "pars pro toto" for the entire country, which is now considered informal or incorrect. The use of the term Holland when referring to the whole of the Netherlands is disliked by many Dutch people. Nonetheless, the name "Holland" is still widely used for the Netherlands national football team, including in the Netherlands, and the Dutch government's international websites for tourism and trade are "holland.com" and "hollandtradeandinvest.com". Recently, however, the Dutch government has announced that it will only communicate and advertise under the name "the Netherlands" in the future.

The term Dutch is used as the demonymic and adjectival form of the Netherlands in the English language. The origins of the word go back to Proto-Germanic "*þiudiskaz", meaning "popular" or "of the people"; akin to Old Dutch "dietsc", Old High German "diutsch", and Old English "þeodisc", all meaning "(of) the common (Germanic) people". At first, the English language used (the contemporary form of) Dutch to refer to any or all speakers of West Germanic languages (e.g. the Dutch, the Frisians, and the Germans). Gradually its meaning shifted to the West Germanic people they had most contact with, because of their geographical proximity and for the rivalry in trade and overseas territories. The derivative of the Proto-Germanic word "*þiudiskaz" in modern Dutch, "Diets", can be found in Dutch literature as a poetic name for the Dutch people or language, but is considered very archaic. It is still used in the expression "diets maken" - to put it straight to him/her (as in a threat) or, more neutral, to make it clear, understandable, explain, say in the people's language (cf. the Vulgate (Bible not in Greek or Hebrew, but Latin; the folks' language) in meaning vulgar, though not in a pejorative sense)

The prehistory of the area that is now the Netherlands was largely shaped by the sea and the rivers that constantly shifted the low-lying geography. The oldest human (Neanderthal) traces were found in higher soils, near Maastricht, from what is believed to be about 250,000 years ago. At the end of the Ice Age, the nomadic late Upper Paleolithic Hamburg culture (c. 13.000–10.000 BC) hunted reindeer in the area, using spears, but the later Ahrensburg culture (c. 11.200–9500 BC) used bow and arrow. From Mesolithic Maglemosian-like tribes (c. 8000 BC) the oldest canoe in the world was found in Drenthe.

Indigenous late Mesolithic hunter-gatherers from the Swifterbant culture (c. 5600 BC) were related to the southern Scandinavian Ertebølle culture and were strongly linked to rivers and open water. Between 4800 and 4500 BC, the Swifterbant people started to copy from the neighbouring Linear Pottery culture the practise of animal husbandry, and between 4300 and 4000 BC the practice of agriculture. To Swifterbant the related Funnelbeaker culture (c. 4300–2800 BC) erected the dolmens, large stone grave monuments found in Drenthe. There was a quick and smooth transition from the Funnelbeaker farming culture to the pan-European Corded Ware pastoralist culture (c. 2950 BC). In the southwest, the Seine-Oise-Marne culture — which was related to the Vlaardingen culture (c. 2600 BC), an apparently more primitive culture of hunter-gatherers — survived well into the Neolithic period, until it too was succeeded by the Corded Ware culture.
Of the subsequent Bell Beaker culture (2700–2100 BC) several regions of origin have been postulated, notably the Iberian peninsula, the Netherlands and Central Europe. They introduced metalwork in copper, gold and later bronze and opened international trade routes not seen before, reflected in the discoveries of copper artifacts, as the metal is not normally found in Dutch soil. The many finds in Drenthe of rare bronze objects, suggest that it was even a trading centre in the Bronze Age (2000–800 BC). The Bell Beaker culture developed locally into the Barbed-Wire Beaker culture (2100–1800 BC) and later the Elp culture (c. 1800–800 BC), a Middle Bronze Age archaeological culture having earthenware pottery of low quality as a marker. The initial phase of the Elp culture was characterised by tumuli (1800–1200 BC) that were strongly tied to contemporary tumuli in northern Germany and Scandinavia, and were apparently related to the Tumulus culture in central Europe. The subsequent phase was that of cremating the dead and placing their ashes in urns which were then buried in fields, following the customs of the Urnfield culture (1200–800 BC). The southern region became dominated by the related Hilversum culture (1800–800 BC), which apparently inherited cultural ties with Britain of the previous Barbed-Wire Beaker culture.

From 800 BC onwards, the Iron Age Celtic Hallstatt culture became influential, replacing the Hilversum culture. Iron ore brought a measure of prosperity, and was available throughout the country, including bog iron. Smiths travelled from settlement to settlement with bronze and iron, fabricating tools on demand. The King's grave of Oss (700 BC) was found in a burial mound, the largest of its kind in western Europe and containing an iron sword with an inlay of gold and coral.

The deteriorating climate in Scandinavia around 850 BC further deteriorated around 650 BC and might have triggered migration of Germanic tribes from the North. By the time this migration was complete, around 250 BC, a few general cultural and linguistic groups had emerged. The North Sea Germanic Ingvaeones inhabited the northern part of the Low Countries. They would later develop into the Frisii and the early Saxons. A second grouping, the Weser-Rhine Germanic (or Istvaeones), extended along the middle Rhine and Weser and inhabited the Low Countries south of the great rivers. This group consisted of tribes that would eventually develop into the Salian Franks. Also the Celtic La Tène culture (c. 450 BC up to the Roman conquest) had expanded over a wide range, including the southern area of the Low Countries. Some scholars have speculated that even a third ethnic identity and language, neither Germanic nor Celtic, survived in the Netherlands until the Roman period, the Iron Age Nordwestblock culture, that eventually was being absorbed by the Celts to the south and the Germanic peoples from the east.
The first author to describe the coast of Holland and Flanders was the Greek geographer Pytheas, who noted in c.325 BC that in these regions, more people died in the struggle against water than in the struggle against men. During the Gallic Wars, the area south and west of the Rhine was conquered by Roman forces under Julius Caesar from 57 BC to 53 BC. Caesar describes two main Celtic tribes living in what is now the southern Netherlands: the Menapii and the Eburones. The Rhine became fixed as Rome's northern frontier around 12 AD. Notable towns would arise along the Limes Germanicus: Nijmegen and Voorburg. At first part of Gallia Belgica, the area south of the Limes became part of the Roman province of Germania Inferior. The area to the north of the Rhine, inhabited by the Frisii, remained outside Roman rule (but not its presence and control), while the Germanic border tribes of the Batavi and Cananefates served in the Roman cavalry. The Batavi rose against the Romans in the Batavian rebellion of 69 AD, but were eventually defeated. The Batavi later merged with other tribes into the confederation of the Salian Franks, whose identity emerged at the first half of the third century. Salian Franks appear in Roman texts as both allies and enemies. They were forced by the confederation of the Saxons from the east to move over the Rhine into Roman territory in the fourth century. From their new base in West Flanders and the Southwest Netherlands, they were raiding the English Channel. Roman forces pacified the region, but did not expel the Franks, who continued to be feared at least until the time of Julian the Apostate (358), when Salian Franks were allowed to settle as "foederati" in Toxandria. It has been postulated that after deteriorating climate conditions and the Romans' withdrawal, the Frisii disappeared as "laeti" in c. 296, leaving the coastal lands largely unpopulated for the next two centuries. However, recent excavations in Kennemerland show clear indication of a permanent habitation.

After Roman government in the area collapsed, the Franks expanded their territories in numerous kingdoms. By the 490s, Clovis I had conquered and united all these territories in the southern Netherlands in one Frankish kingdom, and from there continued his conquests into Gaul. During this expansion, Franks migrating to the south eventually adopted the Vulgar Latin of the local population. A widening cultural divide grew with the Franks remaining in their original homeland in the north (i.e. southern Netherlands and Flanders), who kept on speaking Old Frankish, which by the ninth century had evolved into Old Low Franconian or Old Dutch. A Dutch-French language boundary came into existence.
To the north of the Franks, climatic conditions improved, and during the Migration Period Saxons the closely related Angles, Jutes and Frisii settled the coastal land. Many moved on to England and came to be known as Anglo-Saxons, but those who stayed would be referred to as Frisians and their language as Frisian, named after the land that was once inhabited by Frisii. Frisian was spoken along the entire southern North Sea coast, and it is still the language most closely related to English among the living languages of continental Europe. By the seventh century a Frisian Kingdom (650–734) under King Aldegisel and King Redbad emerged with Utrecht as its centre of power, while Dorestad was a flourishing trading place. Between 600 and around 719 the cities were often fought over between the Frisians and the Franks. In 734, at the Battle of the Boarn, the Frisians were defeated after a series of wars. With the approval of the Franks, the Anglo-Saxon missionary Willibrord converted the Frisian people to Christianity. He established the Archdiocese of Utrecht and became bishop of the Frisians. However, his successor Boniface was murdered by the Frisians in Dokkum, in 754.

The Frankish Carolingian empire modeled itself after the Roman Empire and controlled much of Western Europe. However, as of 843, it was divided into three parts—East, Middle, and West Francia. Most of present-day Netherlands became part of Middle Francia, which was a weak kingdom and subject of numerous partitions and annexation attempts by its stronger neighbours. It comprised territories from Frisia in the north to the Kingdom of Italy in the south. Around 850, Lothair I of Middle Francia acknowledged the Viking Rorik of Dorestad as ruler of most of Frisia. When the kingdom of Middle Francia was partitioned in 855, the lands north of the Alps passed to Lothair II and subsequently were named Lotharingia. After he died in 869, Lotharingia was partitioned, into Upper and Lower Lotharingia, the latter part comprising the Low Countries that technically became part of East Francia in 870, although it was effectively under the control of Vikings, who raided the largely defenceless Frisian and Frankish towns lying on the Frisian coast and along the rivers. Around 879, another Viking raided the Frisian lands, Godfrid, Duke of Frisia. The Viking raids made the sway of French and German lords in the area weak. Resistance to the Vikings, if any, came from local nobles, who gained in stature as a result, and that laid the basis for the disintegration of Lower Lotharingia into semi-independent states. One of these local nobles was Gerolf of Holland, who assumed lordship in Frisia after he helped to assassinate Godfrid, and Viking rule came to an end.

The Holy Roman Empire (the successor state of East Francia and then Lotharingia) ruled much of the Low Countries in the 10th and 11th century, but was not able to maintain political unity. Powerful local nobles turned their cities, counties and duchies into private kingdoms that felt little sense of obligation to the emperor. Holland, Hainaut, Flanders, Gelre, Brabant, and Utrecht were in a state of almost continual war or in paradoxically formed personal unions. The language and culture of most of the people who lived in the County of Holland were originally Frisian. As Frankish settlement progressed from Flanders and Brabant, the area quickly became Old Low Franconian (or Old Dutch). The rest of Frisia in the north (now Friesland and Groningen) continued to maintain its independence and had its own institutions (collectively called the "Frisian freedom"), which resented the imposition of the feudal system.

Around 1000 AD, due to several agricultural developments, the economy started to develop at a fast pace, and the higher productivity allowed workers to farm more land or to become tradesmen. Towns grew around monasteries and castles, and a mercantile middle class began to develop in these urban areas, especially in Flanders and later also Brabant. Wealthy cities started to buy certain privileges for themselves from the sovereign. In practice, this meant that Brugge and Antwerp became quasi-independent republics in their own right and would later develop into some of the most important cities and ports in Europe.

Around 1100 AD, farmers from Flanders and Utrecht began draining and cultivating uninhabited swampy land in the western Netherlands, making the emergence of the County of Holland as the centre of power possible. The title of Count of Holland was fought over in the Hook and Cod Wars () between 1350 and 1490. The Cod faction consisted of the more progressive cities, while the Hook faction consisted of the conservative noblemen. These noblemen invited the Duke Philip the Good of Burgundy — who was also Count of Flanders — to conquer Holland.

Most of the Imperial and French fiefs in what is now the Netherlands and Belgium were united in a personal union by Philip the Good, Duke of Burgundy in 1433. The House of Valois-Burgundy and their Habsburg heirs would rule the Low Countries in the period from 1384 to 1581. Before the Burgundian union, the Dutch identified themselves by the town they lived in or their local duchy or county. The Burgundian period is when the road to nationhood began. The new rulers defended Dutch trading interests, which then developed rapidly. The fleets of the County of Holland defeated the fleets of the Hanseatic League several times. Amsterdam grew and in the 15th century became the primary trading port in Europe for grain from the Baltic region. Amsterdam distributed grain to the major cities of Belgium, Northern France and England. This trade was vital, because Holland could no longer produce enough grain to feed itself. Land drainage had caused the peat of the former wetlands to reduce to a level that was too low for drainage to be maintained.

Under Habsburg Charles V, ruler of the Holy Roman Empire and King of Spain, all fiefs in the current Netherlands region were united into the Seventeen Provinces, which also included most of present-day Belgium, Luxembourg, and some adjacent land in what is now France and Germany. In 1568, the Eighty Years' War between the Provinces and their Spanish ruler began. The level of ferocity exhibited by both sides can be gleaned from a Dutch chronicler's report:

The Duke of Alba ruthlessly attempted to suppress the Protestant movement in the Netherlands. Netherlanders were “burned, strangled, beheaded, or buried alive” by his “Blood Council” and his Spanish soldiers. Severed heads and decapitated corpses were displayed along streets and roads to terrorize the population into submission. Alba boasted of having executed 18,600, but this figure does not include those who perished by war and famine.

The first great siege was Alba's effort to capture Haarlem and thereby cut Holland in half. It dragged on from December 1572 to the next summer, when Haarlemers finally surrendered on 13 July upon promise that the city would be spared from being sacked. It was a stipulation Don Fadrique was unable to honor, when his soldiers mutinied, angered over pay owed and the miserable conditions they endured during the long, cold months of the campaign. On 4 November 1576, Spanish tercios seized Antwerp and subjected it to the worst pillage in the Netherlands' history. The citizens resisted, but were overcome; seven thousand of them were mowed down; a thousand buildings were torched; men, women, and children were slaughtered in a delirium of blood by soldiers crying, "Santiago! España! A sangre, a carne, a fuego, a sacco!" (Saint James! Spain! To blood, to the flesh, to fire, to sack!)

Following the sack of Antwerp, delegates from Catholic Brabant, Protestant Holland and Zeeland agreed, at Ghent, to join Utrecht and William the Silent in driving out all Spanish troops and forming a new government for the Netherlands. Don Juan of Austria, the new Spanish governor, was forced to concede initially, but within months returned to active hostilities. As the fighting restarted, the Dutch began to look for help from the Queen of England, but she initially stood by her commitments to the Spanish in the Treaty of Bristol of 1574. The result was that when the next large-scale battle did occur at Gembloux in 1578, the Spanish forces easily won the day, killing at least 10,000 rebels, with the Spanish suffering few losses. In light of the defeat at Gembloux, the southern states of the Seventeen Provinces (today in northern France and Belgium) distanced themselves from the rebels in the north with the 1579 Union of Arras, which expressed their loyalty to Philip II of Spain. Opposing them, the northern half of the Seventeen Provinces forged the Union of Utrecht (also of 1579) in which they committed to support each other in their defence against the Spanish army. The Union of Utrecht is seen as the foundation of the modern Netherlands.

Spanish troops sacked Maastricht in 1579, killing over 10,000 civilians and thereby ensuring the rebellion continued. In 1581, the northern provinces adopted the Act of Abjuration, the declaration of independence in which the provinces officially deposed Philip II as reigning monarch in the northern provinces. Against the rebels Philip could draw on the resources of Spain, Spanish America, Spanish Italy and the Spanish Netherlands. The Protestant Queen Elizabeth I of England sympathised with the Dutch struggle against the Spanish, and sent an army of 7,600 soldiers to aid the Dutch in their war with the Catholic Spanish. English forces under the Earl of Leicester and then Lord Willoughby faced the Spanish in the Netherlands under the Duke of Parma in a series of largely indecisive actions that tied down significant numbers of Spanish troops and bought time for the Dutch to reorganise their defenses. The war continued until 1648, when Spain under King Philip IV finally recognised the independence of the seven north-western provinces in the Peace of Münster. Parts of the southern provinces became "de facto" colonies of the new republican-mercantile empire.

After declaring their independence, the provinces of Holland, Zeeland, Groningen, Friesland, Utrecht, Overijssel, and Gelderland formed a confederation. All these duchies, lordships and counties were autonomous and had their own government, the States-Provincial. The States General, the confederal government, were seated in The Hague and consisted of representatives from each of the seven provinces. The sparsely populated region of Drenthe was part of the republic too, although it was not considered one of the provinces. Moreover, the Republic had come to occupy during the Eighty Years' War a number of so-called Generality Lands in Flanders, Brabant and Limburg. Their population was mainly Roman Catholic, and these areas did not have a governmental structure of their own, and were used as a buffer zone between the Republic and the Spanish-controlled Southern Netherlands.

In the Dutch Golden Age, spanning much of the 17th century, the Dutch Empire grew to become one of the major seafaring and economic powers, alongside Portugal, Spain, France and England. Science, military, and art (especially painting) were among the most acclaimed in the world. By 1650, the Dutch owned 16,000 merchant ships. The Dutch East India Company and the Dutch West India Company established colonies and trading posts all over the world, including ruling the northern parts of Taiwan between 1624–1662 and 1664–1667. The Dutch settlement in North America began with the founding of New Amsterdam on the southern part of Manhattan in 1614. In South Africa, the Dutch settled the Cape Colony in 1652. Dutch colonies in South America were established along the many rivers in the fertile Guyana plains, among them Colony of Surinam (now Suriname). In Asia, the Dutch established the Dutch East Indies (now Indonesia), and the only western trading post in Japan, Dejima.

During the period of Proto-industrialization, the empire received 50% of textiles and 80% of silks import from the India's Mughal Empire, chiefly from its most developed region known as Bengal Subah.

Many economic historians regard the Netherlands as the first thoroughly capitalist country in the world. In early modern Europe it had the wealthiest trading city (Amsterdam) and the first full-time stock exchange. The inventiveness of the traders led to insurance and retirement funds as well as phenomena such as the boom-bust cycle, the world's first asset-inflation bubble, the tulip mania of 1636–1637, and the world's first bear raider, Isaac le Maire, who forced prices down by dumping stock and then buying it back at a discount. In 1672 – known in Dutch history as the Rampjaar (Disaster Year) – the Dutch Republic was at war with France, England and three German Bishoprics simultaneously. At sea it could successfully prevent the English and French navy entering the western shores. On land, however, it was almost taken over internally by the advancing French and German armies coming from the east. It managed to turn the tide by inundating parts of Holland but could never recover to its former glory again and went into a state of general decline in the 18th century, with economic competition from England and long-standing rivalries between the two main factions in Dutch society, the republican "Staatsgezinden" and the supporters of the stadtholder the "Prinsgezinden" as main political factions.

With the armed support of revolutionary France, Dutch republicans proclaimed the Batavian Republic, modelled after the French Republic and rendering the Netherlands a unitary state on 19 January 1795. The stadtholder William V of Orange had fled to England. But from 1806 to 1810, the Kingdom of Holland was set up by Napoleon Bonaparte as a puppet kingdom governed by his brother Louis Bonaparte to control the Netherlands more effectively. However, King Louis Bonaparte tried to serve Dutch interests instead of his brother's, and he was forced to abdicate on 1 July 1810. The Emperor sent in an army and the Netherlands became part of the French Empire until the autumn of 1813, when Napoleon was defeated in the Battle of Leipzig.
William Frederick, son of the last stadtholder, returned to the Netherlands in 1813 and proclaimed himself Sovereign Prince of the Netherlands. Two years later, the Congress of Vienna added the southern Netherlands to the north to create a strong country on the northern border of France. William Frederick raised this United Netherlands to the status of a kingdom and proclaimed himself as King William I in 1815. In addition, William became hereditary Grand Duke of Luxembourg in exchange for his German possessions. However, the Southern Netherlands had been culturally separate from the north since 1581, and rebelled. The south gained independence in 1830 as Belgium (recognised by the Northern Netherlands in 1839 as the Kingdom of the Netherlands was created by decree), while the personal union between Luxembourg and the Netherlands was severed in 1890, when William III died with no surviving male heirs. Ascendancy laws prevented his daughter Queen Wilhelmina from becoming the next Grand Duchess.
The Belgian Revolution at home and the Java War in the Dutch East Indies brought the Netherlands to the brink of bankruptcy. However, the Cultivation System was introduced in 1830; in the Dutch East Indies, 20% of village land had to be devoted to government crops for export. The policy brought the Dutch enormous wealth and made the colony self-sufficient.

The Netherlands abolished slavery in its colonies in 1863. Slaves in Suriname would be fully free only in 1873, since the law stipulated that there was to be a mandatory 10-year transition.

The Dutch were also one of the last European countries to industrialise, in the second half of the 19th century.

The Netherlands were able to remain neutral during World War I, in part because the import of goods through the Netherlands proved essential to German survival, until the blockade by the British Royal Navy in 1916. That changed in World War II, when Nazi Germany invaded the Netherlands on 10 May 1940. The Rotterdam Blitz forced the main element of the Dutch army to surrender four days later. During the occupation, over 100,000 Dutch Jews were rounded up and transported to Nazi extermination camps; only a few of them survived. Dutch workers were conscripted for forced labour in Germany, civilians who resisted were killed in reprisal for attacks on German soldiers, and the countryside was plundered for food. Although there were thousands of Dutch who risked their lives by hiding Jews from the Germans, over 20,000 Dutch fascists joined the Waffen SS, fighting on the Eastern Front. Political collaborators were members of the fascist NSB, the only legal political party in the occupied Netherlands. On 8 December 1941, the Dutch government-in-exile in London declared war on Japan, but could not prevent the Japanese occupation of the Dutch East Indies (Indonesia). In 1944–45, the First Canadian Army, which included Canadian, British and Polish troops, was responsible for liberating much of the Netherlands. Soon after VE Day, the Dutch fought a colonial war against the new Republic of Indonesia.
In 1954, the Charter for the Kingdom of the Netherlands reformed the political structure of the Netherlands, which was a result of international pressure to carry out decolonisation. The Dutch colonies of Surinam and Curaçao and Dependencies and the European country all became countries within the Kingdom, on a basis of equality. Indonesia had declared its independence in August 1945 (recognised in 1949), and thus was never part of the reformed Kingdom. Suriname followed in 1975. After the war the Netherlands left behind an era of neutrality and gained closer ties with neighboring states. The Netherlands was one of the founding members of the Benelux, the NATO, Euratom and the European Coal and Steel Community, which would evolve into the EEC (Common Market) and later the European Union.

Government-encouraged emigration efforts to reduce population density prompted some 500,000 Dutch people to leave the country after the war. The 1960s and 1970s were a time of great social and cultural change, such as rapid de-pillarisation characterized by the decay of the old divisions along political and religious lines. Youths, and students in particular, rejected traditional mores and pushed for change in matters such as women's rights, sexuality, disarmament and environmental issues. In 2002, the euro was introduced as fiat money and in 2010, the Netherlands Antilles was dissolved. Referendums were held on each island to determine their future status. As a result, the islands of Bonaire, Sint Eustatius and Saba (the BES islands) were to obtain closer ties with the Netherlands. This led to the incorporation of these three islands into the country of the Netherlands as "special municipalities" upon the dissolution of the Netherlands Antilles. The special municipalities are collectively known as the Caribbean Netherlands.

According to the Central Bureau of Statistics, the European Netherlands has a total area of , including water bodies; and a land area of . The Caribbean Netherlands has a total area of It lies between latitudes 50° and 54° N, and longitudes 3° and 8° E.

The Netherlands is geographically very low relative to sea level and is considered a flat country, with about 26% of its area and 21% of its population located below sea level, and only about 50% of its land exceed one metre above sea level. The European part of the country is for the most part flat, with the exception of foothills in the far southeast, up to a height of no more than 321 metres, and some low hill ranges in the central parts. Most of the areas below sea level are man-made, caused by peat extraction or achieved through land reclamation. Since the late 16th century, large polder areas are preserved through elaborate drainage systems that include dikes, canals and pumping stations. Nearly 17% of the country's land area is reclaimed from the sea and from lakes.

Much of the country was originally formed by the estuaries of three large European rivers: the Rhine ("Rijn"), the Meuse ("Maas") and the Scheldt ("Schelde"), as well as their tributaries. The south-western part of the Netherlands is to this day a river delta of these three rivers, the Rhine-Meuse-Scheldt delta.

The European Netherlands is divided into north and south parts by the Rhine, the Waal, its main tributary branch, and the Meuse. In the past these rivers functioned as a natural barrier between fiefdoms and hence historically created a cultural divide, as is evident in some phonetic traits that are recognisable on either side of what the Dutch call their "Great Rivers" ("de Grote Rivieren"). Another significant branch of the Rhine, the IJssel river, discharges into Lake IJssel, the former Zuiderzee ('southern sea'). Just like the previous, this river forms a linguistic divide: people to the northeast of this river speak Dutch Low Saxon dialects (except for the province of Friesland, which has its own language).

Over the centuries, the Dutch coastline has changed considerably as a result of natural disasters and human intervention.

On 14 December 1287, St. Lucia's flood affected the Netherlands and Germany, killing more than 50,000 people in one of the most destructive floods in recorded history. The St. Elizabeth flood of 1421 and the mismanagement in its aftermath destroyed a newly reclaimed polder, replacing it with the "Biesbosch" tidal floodplains in the south-centre. The huge North Sea flood of early February 1953 caused the collapse of several dikes in the south-west of the Netherlands; more than 1,800 people drowned in the flood. The Dutch government subsequently instituted a large-scale programme, the "Delta Works", to protect the country against future flooding, which was completed over a period of more than thirty years.
The impact of disasters was, to an extent, increased through human activity. Relatively high-lying swampland was drained to be used as farmland. The drainage caused the fertile peat to contract and ground levels to drop, upon which groundwater levels were lowered to compensate for the drop in ground level, causing the underlying peat to contract further. Additionally, until the 19th century peat was mined, dried, and used for fuel, further exacerbating the problem. Centuries of extensive and poorly controlled peat extraction lowered an already low land surface by several metres. Even in flooded areas, peat extraction continued through turf dredging.

Because of the flooding, farming was difficult, which encouraged foreign trade, the result of which was that the Dutch were involved in world affairs since the early 14th/15th century.
To guard against floods, a series of defences against the water were contrived. In the first millennium AD, villages and farmhouses were built on man-made hills called "terps". Later, these terps were connected by dikes. In the 12th century, local government agencies called ""waterschappen"" ("water boards") or ""hoogheemraadschappen"" ("high home councils") started to appear, whose job it was to maintain the water level and to protect a region from floods; these agencies continue to exist. As the ground level dropped, the dikes by necessity grew and merged into an integrated system. By the 13th century windmills had come into use to pump water out of areas below sea level. The windmills were later used to drain lakes, creating the famous polders.

In 1932 the "Afsluitdijk" ("Closure Dike") was completed, blocking the former "Zuiderzee" (Southern Sea) from the North Sea and thus creating the IJsselmeer (IJssel Lake). It became part of the larger Zuiderzee Works in which four polders totalling were reclaimed from the sea.

The Netherlands is one of the countries that may suffer most from climate change. Not only is the rising sea a problem, but erratic weather patterns may cause the rivers to overflow.

After the 1953 disaster, the Delta Works was constructed, which is a comprehensive set of civil works throughout the Dutch coast. The project started in 1958 and was largely completed in 1997 with the completion of the Maeslantkering. Since then, new projects have been periodically started to renovate and renew the Delta Works. A main goal of the Delta project was to reduce the risk of flooding in South Holland and Zeeland to once per 10,000 years (compared to 1 per 4000 years for the rest of the country). This was achieved by raising of outer sea-dikes and of inner, canal, and river dikes, and by closing off the sea estuaries of the Zeeland province. New risk assessments occasionally show problems requiring additional Delta project dike reinforcements. The Delta project is considered by the American Society of Civil Engineers as one of the seven wonders of the modern world.
It is anticipated that global warming in the 21st century will result in a rise in sea level. The Netherlands is actively preparing for a sea level rise. A politically neutral Delta Commission has formulated an action plan to cope with a sea level rise of and a simultaneous land height decline of . The plan encompasses the reinforcement of the existing coastal defences like dikes and dunes with of additional flood protection. Climate change will not only threaten the Netherlands from the sea side, but could also alter rainfall patterns and river run-off. To protect the country from river flooding, another program is already being executed. The Room for the River plan grants more flow space to rivers, protects the major populated areas and allows for periodic flooding of indefensible lands. The few residents who lived in these so-called "overflow areas" have been moved to higher ground, with some of that ground having been raised above anticipated flood levels.

The predominant wind direction in the European Netherlands is southwest, which causes a mild maritime climate, with moderately warm summers and cool winters, and typically high humidity. This is especially true close to the Dutch coastline, where the difference in temperature between summer and winter, as well as between day and night is noticeably smaller than it is in the southeast of the country.
Ice days—maximum temperature below —usually occur from December until February, with the occasional rare ice day prior to or after that period. Freezing days—minimum temperature below —occur much more often, usually ranging from mid-November to late March, but not rarely measured as early as mid-October and as late as mid-May. If one chooses the height of measurement to be above ground instead of , one may even find such temperatures in the middle of the summer. On average, snow can occur from November to April, but sometimes occurs in May or October too.

Warm days—maximum temperature above —are usually found in April to October, but in some parts of the country these warm days can also occur in March, or even sometimes in November or February (usually not in , however). Summer days—maximum temperature above —are usually measured in from May until September, tropical days—maximum temperature above —are rare and usually occur only in June to August.

Precipitation throughout the year is distributed relatively equally each month. Summer and autumn months tend to gather a little more precipitation than the other months, mainly because of the intensity of the rainfall rather than the frequency of rain days (this is especially the case in summer, when lightning is also much more frequent).

The number of sunshine hours is affected by the fact that because of the geographical latitude, the length of the days varies between barely eight hours in December and nearly 17 hours in June.

The following tables are based on mean measurements by the KNMI weather station in De Bilt between 1981 and 2010. The highest recorded temperature was an established on 25 July 2019.

The Netherlands has 20 national parks and hundreds of other nature reserves, that include lakes, heathland, woods, dunes and other habitats. Most of these are owned by Staatsbosbeheer, the national department for forestry and nature conservation and Natuurmonumenten (literally 'Natures monuments'), a private organisation that buys, protects and manages nature reserves. The Dutch part of the Wadden Sea in the north, with its tidal flats and wetlands, is rich in biological diversity, and was declared a UNESCO World Heritage Nature Site in 2009.
The Oosterschelde, formerly the northeast estuary of the river Scheldt was designated a national park in 2002, thereby making it the largest national park in the Netherlands at an area of . It consists primarily of the salt waters of the Oosterschelde, but also includes mud flats, meadows, and shoals. Because of the large variety of sea life, including unique regional species, the park is popular with Scuba divers. Other activities include sailing, fishing, cycling, and bird watching.

Phytogeographically, the European Netherlands is shared between the Atlantic European and Central European provinces of the Circumboreal Region within the Boreal Kingdom. According to the World Wide Fund for Nature, the European territory of the Netherlands belongs to the ecoregion of Atlantic mixed forests. In 1871, the last old original natural woods were cut down, and most woods today are planted monocultures of trees like Scots pine and trees that are not native to the Netherlands. These woods were planted on anthropogenic heaths and sand-drifts (overgrazed heaths) (Veluwe).

While Curaçao, Aruba and Sint Maarten have a constituent country status, the Caribbean Netherlands are three islands designated as special municipalities of the Netherlands. The islands are part of the Lesser Antilles and have land and maritime borders with France (Saint Martin), maritime borders with France (Saint Barthélemy), the United Kingdom (Anguilla), Venezuela, Saint Kitts and Nevis and the United States (U.S. Virgin Islands).
Within this island group:

The islands of the Caribbean Netherlands enjoy a tropical climate with warm weather all year round. The Leeward Antilles are warmer and drier than the Windward islands. In summer, the Windward Islands can be subject to hurricanes.

The Netherlands has been a constitutional monarchy since 1815, and due to the efforts of Johan Rudolph Thorbecke, became a parliamentary democracy since 1848. The Netherlands is described as a consociational state. Dutch politics and governance are characterised by an effort to achieve broad consensus on important issues, within both the political community and society as a whole. In 2017, "The Economist" ranked the Netherlands as the 11th most democratic country in the world.

The monarch is the head of state, at present King Willem-Alexander of the Netherlands. Constitutionally, the position is equipped with limited powers. By law, the King has the right to be periodically briefed and consulted on government affairs. Depending on the personalities and relationships of the King and the ministers, the monarch might have influence beyond the power granted by the Constitution of the Netherlands.
The executive power is formed by the Council of Ministers, the deliberative organ of the Dutch cabinet. The cabinet usually consists of 13 to 16 ministers and a varying number of state secretaries. One to three ministers are ministers without portfolio. The head of government is the Prime Minister of the Netherlands, who often is the leader of the largest party of the coalition. The Prime Minister is a "primus inter pares", with no explicit powers beyond those of the other ministers. Mark Rutte has been Prime Minister since October 2010; the Prime Minister had been the leader of the largest party continuously since 1973.

The cabinet is responsible to the bicameral parliament, the States General, which also has legislative powers. The 150 members of the House of Representatives, the lower house, are elected in direct elections on the basis of party-list proportional representation. These are held every four years, or sooner in case the cabinet falls (for example: when one of the chambers carries a motion of no confidence, the cabinet offers its resignation to the monarch). The States-Provincial are directly elected every four years as well. The members of the provincial assemblies elect the 75 members of the Senate, the upper house, which has the power to reject laws, but not propose or amend them. Both houses send members to the Benelux Parliament, a consultative council.

Both trade unions and employers organisations are consulted beforehand in policymaking in the financial, economic and social areas. They meet regularly with the government in the Social-Economic Council. This body advises government and its advice cannot be put aside easily.

The Netherlands has a long tradition of social tolerance. In the 18th century, while the Dutch Reformed Church was the state religion, Catholicism, other forms of Protestantism, such as Baptists and Lutherans, as well as Judaism were tolerated but discriminated against.
In the late 19th century this Dutch tradition of religious tolerance transformed into a system of pillarisation, in which religious groups coexisted separately and only interacted at the level of government. This tradition of tolerance influences Dutch criminal justice policies on recreational drugs, prostitution, LGBT rights, euthanasia, and abortion, which are among the most liberal in the world.

Because of the multi-party system, no single party has held a majority in parliament since the 19th century, as a result, coalition cabinets had to be formed. Since suffrage became universal in 1917, the Dutch political system has been dominated by three families of political parties: the strongest of which were the Christian Democrats, currently represented by the Christian Democratic Appeal (CDA); second were the Social Democrats, represented by the Labour Party (PvdA); and third were the Liberals, of which the right-wing People's Party for Freedom and Democracy (VVD) is the main representative.

These parties co-operated in coalition cabinets in which the Christian Democrats had always been a partner: so either a centre-left coalition of the Christian Democrats and Social Democrats was ruling or a centre-right coalition of Christian Democrats and Liberals. In the 1970s, the party system became more volatile: the Christian Democratic parties lost seats, while new parties became successful, such as the radical democrat and progressive liberal Democrats 66 (D66) or the ecologist party GroenLinks (GL).

In the 1994 election, the CDA lost its dominant position. A "purple" cabinet was formed by the VVD, D66, and PvdA. In the 2002 elections, this cabinet lost its majority, because of an increased support for the CDA and the rise of the right LPF, a new political party, around Pim Fortuyn, who was assassinated a week before the elections. A short-lived cabinet was formed by CDA, VVD, and LPF, which was led by the CDA Leader Jan Peter Balkenende. After the 2003 elections, in which the LPF lost most of its seats, a cabinet was formed by the CDA, VVD, and D66. The cabinet initiated an ambitious programme of reforming the welfare state, the healthcare system, and immigration policy.

In June 2006, the cabinet fell after D66 voted in favour of a motion of no confidence against the Minister of Immigration and Integration, Rita Verdonk, who had instigated an investigation of the asylum procedure of Ayaan Hirsi Ali, a VVD MP. A caretaker cabinet was formed by the CDA and VVD, and general elections were held on 22 November 2006. In these elections, the CDA remained the largest party and the Socialist Party made the largest gains. The formation of a new cabinet took three months, resulting in a coalition of CDA, PvdA, and Christian Union.

On 20 February 2010, the cabinet fell when the PvdA refused to prolong the involvement of the Dutch Army in Uruzgan, Afghanistan. Snap elections were held on 9 June 2010, with devastating results for the previously largest party, the CDA, which lost about half of its seats, resulting in 21 seats. The VVD became the largest party with 31 seats, closely followed by the PvdA with 30 seats. The big winner of the 2010 elections was Geert Wilders, whose right wing PVV, the ideological successor to the LPF, more than doubled its number of seats. Negotiation talks for a new government resulted in a minority government, led by VVD (a first) in coalition with CDA, which was sworn in on 14 October 2010. This unprecedented minority government was supported by PVV, but proved ultimately to be unstable, when on 21 April 2012, Wilders, leader of PVV, unexpectedly 'torpedoed seven weeks of austerity talks' on new austerity measures, paving the way for early elections.

VVD and PvdA won a majority in the House of Representatives during the 2012 general election. On 5 November 2012 they formed the second Rutte cabinet.

After the 2017 general election, VVD, Christian Democratic Appeal, Democrats 66 and ChristenUnie formed the third Rutte cabinet.

The Netherlands is divided into twelve provinces, each under a King's Commissioner ("Commissaris van de Koning"). Informally in Limburg province this position is named Governor ("Gouverneur"). All provinces are divided into municipalities ("gemeenten"), of which there are 380 (2018).

The country is also subdivided into 21 water districts (as of 2018), governed by a water board ("waterschap" or "hoogheemraadschap"), each having authority in matters concerning water management. The creation of water boards actually pre-dates that of the nation itself, the first appearing in 1196. The Dutch water boards are among the oldest democratic entities in the world still in existence. Direct elections of the water boards take place every 4 years.

The administrative structure on the 3 BES islands, collectively known as the Caribbean Netherlands, is outside the twelve provinces. These islands have the status of "openbare lichamen (public bodies)". In the Netherlands these administrative units are often referred to as "special municipalities".

The Netherlands has several Belgian exclaves and within those even several enclaves which are part of the province of North Brabant. Because the Netherlands and Belgium are both in the Benelux, and more recently in the Schengen Area, citizens of respective countries can travel through these enclaves without controls.

The history of Dutch foreign policy has been characterised by its neutrality. Since World War II, the Netherlands has become a member of a large number of international organisations, most prominently the UN, NATO and the EU. The Dutch economy is very open and relies strongly on international trade.

The foreign policy of the Netherlands is based on four basic commitments: to Atlantic co-operation, to European integration, to international development and to international law. One of the more controversial international issues surrounding the Netherlands is its liberal policy towards soft drugs.

During and after the Dutch Golden Age, the Dutch people built up a commercial and colonial empire. The most important colonies were present-day Suriname and Indonesia. Indonesia became independent after the Indonesian National Revolution in the 1940s following a war of independence, international pressure and several United Nations Security Council resolutions. Suriname became independent in 1975. The historical ties inherited from its colonial past still influence the foreign relations of the Netherlands. In addition, many people from these countries are living permanently in the Netherlands.

The Netherlands has one of the oldest standing armies in Europe; it was first established as such by Maurice of Nassau in the late 1500s. The Dutch army was used throughout the Dutch Empire. After the defeat of Napoleon, the Dutch army was transformed into a conscription army. The army was unsuccessfully deployed during the Belgian Revolution in 1830. After 1830, it was deployed mainly in the Dutch colonies, as the Netherlands remained neutral in European wars (including the First World War), until the Netherlands was invaded in World War II and defeated by the Wehrmacht in May 1940.
The Netherlands abandoned its neutrality in 1948 when it signed the Treaty of Brussels, and became a founding member of NATO in 1949. The Dutch military was therefore part of the NATO strength in Cold War Europe, deploying its army to several bases in Germany. More than 3,000 Dutch soldiers were assigned to the 2nd Infantry Division of the United States Army during the Korean War. In 1996 conscription was suspended, and the Dutch army was once again transformed into a professional army. Since the 1990s the Dutch army has been involved in the Bosnian War and the Kosovo War, it held a province in Iraq after the defeat of Saddam Hussein, and it was engaged in Afghanistan.

The military is composed of four branches, all of which carry the prefix "Koninklijke" (Royal):


The submarine service is open to women as of 1 January 2017. The Korps Commandotroepen, the Special Operations Force of the Netherlands Army, is open to women, but because of the extremely high physical demands for initial training, it is almost impossible for a woman to become a commando. The Dutch Ministry of Defence employs more than 70,000 personnel, including over 20,000 civilians and over 50,000 military personnel. In April 2011 the government announced a major reduction in its military because of a cut in government expenditure, including a decrease in the number of tanks, fighter aircraft, naval ships and senior officials. The Netherlands decided not to sign the UN treaty on the Prohibition of Nuclear Weapons.

The Netherlands has a developed economy and has been playing a special role in the European economy for many centuries. Since the 16th century, shipping, fishing, agriculture, trade, and banking have been leading sectors of the Dutch economy. The Netherlands has a high level of economic freedom. The Netherlands is one of the top countries in the Global Enabling Trade Report (2nd in 2016), and was ranked the fifth most competitive economy in the world by the Swiss International Institute for Management Development in 2017. In addition, the country was ranked the second most innovative nation in the world in the 2018 Global Innovation Index.

, the key trading partners of the Netherlands were Germany, Belgium, the United Kingdom, the United States, France, Italy, China and Russia. The Netherlands is one of the world's 10 leading exporting countries. Foodstuffs form the largest industrial sector. Other major industries include chemicals, metallurgy, machinery, electrical goods, trade, services and tourism. Examples of international Dutch companies operating in Netherlands include Randstad, Unilever, Heineken, KLM, financial services (ING, ABN AMRO, Rabobank), chemicals (DSM, AKZO), petroleum refining (Royal Dutch Shell), electronical machinery (Philips, ASML), and satellite navigation (TomTom).

The Netherlands has the 17th-largest economy in the world, and ranks 10th in GDP (nominal) per capita. Between 1997 and 2000 annual economic growth (GDP) averaged nearly 4%, well above the European average. Growth slowed considerably from 2001 to 2005 with the global economic slowdown, but accelerated to 4.1% in the third quarter of 2007. In May 2013, inflation was at 2.8% per year. In April 2013, unemployment was at 8.2% (or 6.7% following the ILO definition) of the labour force. In February 2019, this was reduced to 3.4%.

In Q3 and Q4 2011, the Dutch economy contracted by 0.4% and 0.7%, respectively, because of European Debt Crisis, while in Q4 the Eurozone economy shrunk by 0.3%. The Netherlands also has a relatively low GINI coefficient of 0.326. Despite ranking 7th in GDP per capita, UNICEF ranked the Netherlands 1st in child well-being in rich countries, both in 2007 and in 2013. On the Index of Economic Freedom Netherlands is the 13th most free market capitalist economy out of 157 surveyed countries.

Amsterdam is the financial and business capital of the Netherlands. The Amsterdam Stock Exchange (AEX), part of Euronext, is the world's oldest stock exchange and is one of Europe's largest bourses. It is situated near Dam Square in the city's centre. As a founding member of the euro, the Netherlands replaced (for accounting purposes) its former currency, the "gulden" (guilder), on 1 January 1999, along with 15 other adopters of the euro. Actual euro coins and banknotes followed on 1 January 2002. One euro was equivalent to 2.20371 Dutch guilders. In the Caribbean Netherlands, the United States dollar is used instead of the euro.
The Dutch location gives it prime access to markets in the UK and Germany, with the Port of Rotterdam being the largest port in Europe. Other important parts of the economy are international trade (Dutch colonialism started with co-operative private enterprises such as the Dutch East India Company), banking and transport. The Netherlands successfully addressed the issue of public finances and stagnating job growth long before its European partners. Amsterdam is the 5th-busiest tourist destination in Europe with more than 4.2 million international visitors. Since the enlargement of the EU large numbers of migrant workers have arrived in the Netherlands from Central and Eastern Europe.

The Netherlands continues to be one of the leading European nations for attracting foreign direct investment and is one of the five largest investors in the United States. The economy experienced a slowdown in 2005, but in 2006 recovered to the fastest pace in six years on the back of increased exports and strong investment. The pace of job growth reached 10-year highs in 2007. The Netherlands is the fourth-most competitive economy in the world, according to the World Economic Forum's Global Competitiveness Report.

Beginning in the 1950s, the Netherlands discovered huge natural gas resources. The sale of natural gas generated enormous revenues for the Netherlands for decades, adding hundreds of billions of euros to the government's budget. However, the unforeseen consequences of the country's huge energy wealth impacted the competitiveness of other sectors of the economy, leading to the theory of Dutch disease.
Apart from coal and gas, the country has no mining resources. The last coal mine was closed in 1974. The Groningen gas field, one of the largest natural gas fields in the world, is situated near Slochteren. Exploitation of this field has resulted in €159 billion in revenue since the mid-1970s. The field is operated by government-owned Gasunie and output is jointly exploited by the government, Royal Dutch Shell, and Exxon Mobil through NAM (Nederlandse Aardolie Maatschappij). "Gas extraction has resulted in increasingly strong earth tremors, some measuring as much as 3.6 on the Richter magnitude scale. The cost of damage repairs, structural improvements to buildings, and compensation for home value decreases has been estimated at 6.5 billion euros. Around 35,000 homes are said to be affected." The Netherlands have an estimated 25% of natural gas reserves in the EU. The energy sector accounted for almost 11% of the GDP in 2014. Netherlands's economy, mainly due to the large shares of natural gas reserves, is considered to have "very high" energy intensity rating.

Netherlands is faced with future challenges as the energy supply is forecasted to fall short of the demand by the year 2025 in the gas sector. This is attributed to the depletion of Netherlands's major gas field, Groningen, and the earthquakes that have hit the Groningen region. In addition, there is ambiguity surrounding the feasibility of producing unconventional gas. Netherlands relies heavily on natural gas to provide energy. Gas is the main source of heating for households in Netherlands and represented 35% of the energy mix in 2014. Furthermore, The European Union 2020 package (20% reduction in GHG emissions, 20% renewables in the energy mix and 20% improvement in energy efficiency) enacted in 2009 has influenced the domestic energy politics of Netherlands and pressured non-state actors to give consent to more aggressive energy reforms that would reduce reliance on natural resources as a source of income to the economy. Therefore, a transition towards renewable energy has been a key objective by Netherlands in order to safeguard the energy security of the country from natural resources depletion, mainly gas. Netherlands has set a 14% renewable energy target of the total energy mix by the year 2020. However, the continuation of providing tax breaks to electricity generated by coal and gas, and to the exploration and extraction of gas from fields that are “insufficiently” profitable, renders a successful transition towards renewable energy more difficult to achieve due to inconsistencies in the policy mix. In 2011, it was estimated that the renewable energy sector received 31% (EUR 743MM), while the conventional energy sector received 69% (EUR 1.6B), of the total energy subsidies by the government. Furthermore, the energy market in Netherlands remains to be dominated by few major corporations Nuon, RWE, E.ON, Eneco and Delta that have significant influence over the energy policy. Renewable energy share in the energy mix is estimated to reach 12.4% by the year 2020, falling 1.6% short of the 14% target.

From a biological resource perspective, The Netherlands has a low endowment: The Netherlands’ biocapacity adds up to only 0.8 global hectares in 2016, 0.2 of which are dedicated to agriculture. The Dutch biocapacity per person is just about half of the 1.6 global hectares of biocapacity per person available worldwide. In contrast, in 2016, the Dutch used on average 4.8 global hectares of biocapacity - their ecological footprint of consumption. This means the Dutch required nearly six times as much biocapacity as The Netherlands contains. As a result, The Netherlands was running a biocapacity deficit of 4.0 global hectares per person in 2016.

The Dutch agricultural sector is highly mechanised, and has a strong focus on international exports. It employs about 4% of the Dutch labour force but produces large surpluses in the food-processing industry and accounts for 21 percent of the Dutch total export value. The Dutch rank first in the European Union and second worldwide in value of agricultural exports, behind only the United States, with agricultural exports earning €80.7 billion in 2014, up from €75.4 billion in 2012.

The Netherlands has, at some time in recent history, supplied one quarter of all of the world's exported tomatoes, and trade of one-third of the world's exports of chilis, tomatoes and cucumbers goes through the country. The Netherlands also exports one-fifteenth of the world's apples.

Aside from that, a significant portion of Dutch agricultural exports consists of fresh-cut plants, flowers, and flower bulbs, with the Netherlands exporting two-thirds of the world's total.

Mobility on Dutch roads has grown continuously since the 1950s and now exceeds 200 billion km travelled per year, three quarters of which are done by car. Around half of all trips in the Netherlands are made by car, 25% by bicycle, 20% walking, and 5% by public transport. With a total road network of 139,295 km, which includes 2,758 km of expressways, the Netherlands has one of the densest road networks in the world—much denser than Germany and France, but still not as dense as Belgium.
About 13% of all distance is travelled by public transport, the majority of which by train. Like in many other European countries, the Dutch rail network of 3,013 route km is also rather dense. The network is mostly focused on passenger rail services and connects all major towns and cities, with over 400 stations. Trains are frequent, with two trains per hour on lesser lines, two to four trains per hour on average, and up to eight trains an hour on the busiest lines. The Dutch national train network, which is free of charge for students, also includes the HSL-Zuid, a high-speed line between the Amsterdam metropolitan area and the Belgian border for trains running from Paris and London to the Netherlands.

Cycling is a ubiquitous mode of transport in the Netherlands. Almost as many kilometres are covered by bicycle as by train. The Dutch are estimated to have at least 18 million bicycles, which makes more than one per capita, and twice as many as the circa 9 million motor vehicles on the road. In 2013, the European Cyclists' Federation ranked both the Netherlands and Denmark as the most bike-friendly countries in Europe, but more of the Dutch (36%) than of the Danes (23%) list the bike as their most frequent mode of transport on a typical day. Cycling infrastructure is comprehensive. Busy roads have received some 35,000 km of dedicated cycle tracks, physically segregated from motorised traffic. Busy junctions are often equipped with bicycle-specific traffic lights. There are large bicycle parking facilities, particularly in city centres and at train stations.

The Port of Rotterdam is the largest port in Europe, with the rivers Meuse and Rhine providing excellent access to the hinterland upstream reaching to Basel, Switzerland, and into Germany and France. , Rotterdam was the world's eighth largest container port handling 440.5 million metric tonnes of cargo annually. The port's main activities are petrochemical industries and general cargo handling and transshipment. The harbour functions as an important transit point for bulk materials and between the European continent and overseas. From Rotterdam goods are transported by ship, river barge, train or road. In 2007, the Betuweroute, a new fast freight railway from Rotterdam to Germany, was completed.

Schiphol Airport, just southwest of Amsterdam, is the main international airport in the Netherlands, and the third busiest airport in Europe in terms of passengers. In 2016, the Royal Schiphol Group airports handled 70 million passengers.

As part of its commitment to environmental sustainability, the Government of the Netherlands initiated a plan to establish over 200 recharging stations for electric vehicles across the country. The rollout will be undertaken by Switzerland-based power and automation company ABB and Dutch startup , and will aim to provide at least one station within a 50-kilometre radius (30 miles) from every home in the Netherlands.

The Netherlands had an estimated population of 17,424,978 as of 1 November 2019. It is the 5th most densely populated country in Europe, and except for the very small city-states like Monaco, Vatican City and San Marino it is the most densely populated country in Europe. And it is the 12th most densely populated country in the world with a density of . It is the 64th most populous country in the world. Between 1900 and 1950, the country's population almost doubled from 5.1 to 10 million. From 1950 to 2000, the population further increased, to 15.9 million, though this represented a lower rate of population growth. The estimated growth rate is 0.44%.
The fertility rate in the Netherlands is 1.78 children per woman (2018 estimate), which is high compared with many other European countries, but below the rate of 2.1 children per woman required for natural population replacement, it remains considerably below the high of 5.39 children born per woman in 1879. Netherlands subsequently has one of the oldest populations in the world, with the average age of 42.7 years. Life expectancy is high in the Netherlands: 83.2 years for newborn girls and 78.9 for boys (2013 estimate). The country has a migration rate of 2.0 migrants per 1,000 inhabitants per year. The majority of the population of the Netherlands is ethnically Dutch. According to a 2005 estimate, the population was 80.9% Dutch, 2.4% Indonesian, 2.4% German, 2.2% Turkish, 2.0% Surinamese, 1.9% Moroccan, 0.8% Antillean and Aruban, and 7.4% others. Some 150,000 to 200,000 people living in the Netherlands are expatriates, mostly concentrated in and around Amsterdam and The Hague, now constituting almost 10% of the population of these cities.

The Dutch are the tallest people in the world, by nationality, with an average height of for adult males and for adult females in 2009. People in the south are on average about shorter than those in the north.
According to Eurostat, in 2010 there were 1.8 million foreign-born residents in the Netherlands, corresponding to 11.1% of the total population. Of these, 1.4 million (8.5%) were born outside the EU and 0.43 million (2.6%) were born in another EU Member State. On 21 November 2016, there were 3.8 million residents in the Netherlands with at least one foreign-born parent ("migration background"). Over half the young people in Amsterdam and Rotterdam have a non-western background. Dutch people, or descendants of Dutch people, are also found in migrant communities worldwide, notably in Canada, Australia, South Africa and the United States. According to the United States Census Bureau (2006), more than 5 million Americans claim total or partial Dutch ancestry. There are close to 3 million Dutch-descended Afrikaners living in South Africa. In 1940, there were 290,000 Europeans and Eurasians in Indonesia, but most have since left the country.

The Netherlands is the 12th most densely populated country in the world with a density of . The Randstad is the country's largest conurbation located in the west of the country and contains the four largest cities: Amsterdam in the province North Holland, Rotterdam and The Hague in the province South Holland, and Utrecht in the province Utrecht. The Randstad has a population of about 8,2 million inhabitants and is the 5th largest metropolitan area in Europe. According to Dutch Central Statistics Bureau, in 2015, 28 percent of the Dutch population had a spendable income above 45,000 euros (which does not include spending on health care or education).

The official language is Dutch, which is spoken by the vast majority of the inhabitants. Besides Dutch, West Frisian is recognised as a second official language in the northern province of Friesland ("Fryslân" in West Frisian). West Frisian has a formal status for government correspondence in that province. In the European part of the kingdom two other regional languages are recognised under the European Charter for Regional or Minority Languages.

The first of these recognised regional languages is Low Saxon ("Nedersaksisch" in Dutch). Low Saxon consists of several dialects spoken in the north and east, like Twents in the region of Twente, and Drents in the province of Drenthe. Secondly, Limburgish is also recognised as a regional language. It consists of Dutch varieties of Meuse-Rhenish Franconian languages and is spoken in the south-eastern province of Limburg. The dialects most spoken in the Netherlands are the Brabantian-Hollandic dialects.

Ripuarian language, which is spoken in Kerkrade and Vaals in the form of, respectively, the Kerkrade dialect and the Vaals dialect is not recognised as a regional language of the Netherlands. These dialects are however sometimes considered to be a part of or related to Limburgish.

English has a formal status in the special municipalities of Saba and Sint Eustatius. It is widely spoken on these islands. Papiamento has a formal status in the special municipality of Bonaire. Yiddish and the Romani language were recognised in 1996 as non-territorial languages. The Netherlands has a tradition of learning foreign languages, formalised in Dutch education laws. Some 90% of the total population indicate they are able to converse in English, 70% in German, and 29% in French. English is a mandatory course in all secondary schools. In most lower level secondary school educations ("vmbo"), one additional modern foreign language is mandatory during the first two years.

In higher level secondary schools (HAVO and VWO), the acquisition of two additional modern foreign language skills is mandatory during the first three years. Only during the last three years in VWO one foreign language is mandatory. Besides English, the standard modern languages are French and German, although schools can replace one of these modern languages with Chinese, Spanish, Russian, Italian, Turkish or Arabic. Additionally, schools in Friesland teach and have exams in West Frisian, and schools across the country teach and have exams in Ancient Greek and Latin for secondary school (called Gymnasium or VWO+).

The Dutch are one of the least religious people in the world. Religion in the Netherlands was predominantly Christianity until late into the 20th century. Although religious diversity remains, there has been a decline of religious adherence.

In 2015, Statistics Netherlands, the Dutch governmental institution that gathers statistical information about the Netherlands, found that 50.1% of the total population declared to be non-religious. Groups that represent the non-religious in the Netherlands include Humanistisch Verbond. Christians comprised the 43.8% of the total population and were divided in Catholics with 23.7%, Protestants with a membership in the Protestant Church in the Netherlands with 15.5% and other Christians (including Protestants without a membership in the Protestant Church in the Netherlands) with 4.6%. Islam comprised the 4.9% of the total population and other religions (like Judaism, Buddhism and Hinduism) comprised the remaining 1.1%.

According to an independent in-depth interviewing by Radboud University and Vrije Universiteit Amsterdam in 2006, 34% of the Dutch population identified as Christians, decreasing till in 2015 almost 25% of the population adhered to one of the Christian faiths (11.7% Roman Catholic, 8.6% PKN, 4.2% other small Christian denominations), 5 percent is Muslim and 2 percent adheres to Hinduism or Buddhism, approximately 67.8% of the population in 2015 has no religious affiliation, up from 61% in 2006, 53% in 1996, 43% 1979 and 33% in 1966. The Sociaal en Cultureel Planbureau (Social and Cultural Planning Agency, SCP) expects the number of non-affiliated Dutch to be at 72% in 2020.

The Constitution of the Netherlands guarantees freedom of education, which means that all schools that adhere to general quality criteria receive the same government funding. This includes schools based on religious principles by religious groups (especially Roman Catholic and various Protestant). Three political parties in the Dutch parliament, (CDA, and two small parties, ChristianUnion and SGP) are based upon the Christian belief. Several Christian religious holidays are national holidays (Christmas, Easter, Pentecost and the Ascension of Jesus). In the late 19th century atheism began to rise as secularism, liberalism and socialism grew. By 1960, Protestantism shrunk demographically to equal Roman Catholicism, and going onwards, both Christian branches began to decline. There is one major exception: Islam which grew considerably as the result of immigration. Since the year 2000 there has been raised awareness of religion, mainly due to Muslim extremism.

The Dutch royal family has been traditionally associated with Calvinism, specifically the 1795 disestablished and now non-existent Dutch Reformed Church (which merged into the Protestant Church in the Netherlands). The Dutch Reformed Church has been the only major Protestant church in the Netherlands from the Protestant Reformation up until the 19th century. It encompassed the vast majority of Protestants in the Reformed tradition until a series of splits in 1834 and in 1886 diversified Dutch Calvinism. In 2013, a Roman Catholic became Queen consort.

From a December 2014 survey by the VU University Amsterdam it was concluded that for the first time there are more atheists (25%) than theists (17%) in the Netherlands. The majority of the population being agnostic (31%) or ietsistic (27%). In 2015, a vast majority of the inhabitants of the Netherlands (82%) said they had never or almost never visited a church, and 59% stated that they had never been to a church of any kind. Of all the people questioned, 24% saw themselves as atheist, an increase of 11% compared to the previous study done in 2006. The expected rise of spirituality (ietsism) has come to a halt according to research in 2015. In 2006, 40% of respondents considered themselves spiritual, in 2015 this has dropped to 31%. The number who believed in the existence of a higher power fell from 36% to 28% over the same period.

Christianity is currently the largest religion in the Netherlands. The provinces of North Brabant and Limburg have historically been strongly Roman Catholic, and some of their people might still consider the Catholic Church as a base for their cultural identity. Protestantism in the Netherlands consists of a number of churches within various traditions. The largest of these is the Protestant Church in the Netherlands (PKN), a United church which is Reformed and Lutheran in orientation. It was formed in 2004 as a merger of the Dutch Reformed Church, the Reformed Churches in the Netherlands and a smaller Lutheran Church. Several orthodox Reformed and liberal churches did not merge into the PKN. Although in the Netherlands as a whole Christianity has become a minority, the Netherlands contains a Bible Belt from Zeeland to the northern parts of the province Overijssel, in which Protestant (particularly Reformed) beliefs remain strong, and even has majorities in municipal councils.

Islam is the second largest religion in the state. In 2012, there were about 825,000 Muslims in the Netherlands (5% of the population). The Muslim population increased from the 1960 as a result of large numbers of migrant workers. This included migrant workers from Turkey and Morocco, as well as migrants from former Dutch colonies, such as Surinam and Indonesia. During the 1990s, Muslim refugees arrived from countries like Bosnia and Herzegovina, Iran, Iraq, Somalia, and Afghanistan.

Other religions account for some 6% of the Dutch people. Hinduism is a minority religion in the Netherlands, with around 215,000 adherents (slightly over 1% of the population). Most of these are Indo-Surinamese. There are also sizable populations of Hindu immigrants from India and Sri Lanka, and some Western adherents of Hinduism-oriented new religious movements such as Hare Krishnas. The Netherlands has an estimated 250,000 Buddhists or people strongly attracted to this religion, mainly ethnic Dutch people. There are about 45,000 Jews in the Netherlands.

Education in the Netherlands is compulsory between the ages of 5 and 16. If a child does not have a "startqualification" (HAVO, VWO or MBO 2+ degree) they are still forced to attend classes until they achieve such a qualification.

All children in the Netherlands usually attend elementary school from (on average) ages 4 to 12. It comprises eight grades, the first of which is facultative. Based on an aptitude test, the eighth grade teacher's recommendation and the opinion of the pupil's parents or caretakers, a choice is made for one of the three main streams of secondary education. After completing a particular stream, a pupil may still continue in the penultimate year of the next stream.

The VMBO has 4 grades and is subdivided over several levels. Successfully completing the vmbo results in a low-level vocational degree that grants access to the MBO. The MBO (middle-level applied education) is a form of education primarily focuses on teaching a practical trade, or a vocational degree. With the MBO certification, a student can apply for the HBO. The HAVO has 5 grades and allows for admission to the HBO. The HBO (higher professional education) are universities of professional education (applied sciences) that award professional bachelor's degrees; similar to polytechnic degrees. A HBO degree gives access to the university system. The VWO (comprising atheneum and gymnasium) has 6 grades and prepares for studying at a research university. Universities offer of a three-year bachelor's degree, followed by a one or two year master's degree, which in turn can be followed by a four or five-year doctoral degree program.

Doctoral candidates in the Netherlands are generally non-tenured employees of a university. All Dutch schools and universities are publicly funded and managed with the exception of religious schools that are publicly funded but not managed by the state even though requirements are necessary for the funding to be authorised. Dutch universities have a tuition fee of about 2,000 euros a year for students from the Netherlands and the European Union. The amount is about 10,000 euros for non-EU students.

In 2016, the Netherlands has maintained its number one position at the top of the annual Euro health consumer index (EHCI), which compares healthcare systems in Europe, scoring 916 of a maximum 1,000 points. The Netherlands has been among the top three countries in each report published since 2005. On 48 indicators such as patient rights and information, accessibility, prevention and outcomes, the Netherlands secured its top position among 37 European countries for six years in a row.
The Netherlands was ranked first in a study in 2009 comparing the health care systems of the United States, Australia, Canada, Germany and New Zealand.

Ever since a major reform of the health care system in 2006, the Dutch system received more points in the Index each year. According to the HCP (Health Consumer Powerhouse), the Netherlands has 'a chaos system', meaning patients have a great degree of freedom from where to buy their health insurance, to where they get their healthcare service. The difference between the Netherlands and other countries is that the chaos is managed. Healthcare decisions are being made in a dialogue between the patients and healthcare professionals.

Health insurance in the Netherlands is mandatory. Healthcare in the Netherlands is covered by two statutory forms of insurance:

While Dutch residents are automatically insured by the government for AWBZ, everyone has to take out their own basic healthcare insurance (basisverzekering), except those under 18 who are automatically covered under their parents' premium. If a person decides not to carry out an insurance coverage, the person may be fined. Insurers have to offer a universal package for everyone over the age of 18 years, regardless of age or state of health – it's illegal to refuse an application or impose special conditions. In contrast to many other European systems, the Dutch government is responsible for the accessibility and quality of the healthcare system in the Netherlands, but not in charge of its management.

Healthcare in the Netherlands can be divided in several ways: three echelons, in somatic and mental health care and in 'cure' (short term) and 'care' (long term). Home doctors ("huisartsen", comparable to general practitioners) form the largest part of the first echelon. Being referenced by a member of the first echelon is mandatory for access to the second and third echelon. The health care system is in comparison to other Western countries quite effective but not the most cost-effective.

Healthcare in the Netherlands is financed by a dual system that came into effect in January 2006. Long-term treatments, especially those that involve semi-permanent hospitalisation, and also disability costs such as wheelchairs, are covered by a state-controlled mandatory insurance. This is laid down in the "Algemene Wet Bijzondere Ziektekosten" ("General Law on Exceptional Healthcare Costs") which first came into effect in 1968. In 2009 this insurance covered 27% of all health care expenses.

For all regular (short-term) medical treatment, there is a system of obligatory health insurance, with private health insurance companies. These insurance companies are obliged to provide a package with a defined set of insured treatments. This insurance covers 41% of all health care expenses.

Other sources of health care payment are taxes (14%), out of pocket payments (9%), additional optional health insurance packages (4%) and a range of other sources (4%). Affordability is guaranteed through a system of income-related allowances and individual and employer-paid income-related premiums.

A key feature of the Dutch system is that premiums may not be related to health status or age. Risk variances between private health insurance companies due to the different risks presented by individual policy holders are compensated through risk equalisation and a common risk pool. The funding burden for all short-term health care coverage is carried 50% by employers, 45% by the insured person and 5% by the government. Children under 18 are covered for free. Those on low incomes receive compensation to help them pay their insurance. Premiums paid by the insured are about €100 per month (about US$127 in August 2010 and €150 or US$196 in 2012), with variation of about 5% between the various competing insurers, and a yearly deductible of €220 (US$288).

The Netherlands has had many well-known painters. The 17th century, in which the Dutch Republic was prosperous, was the age of the "Dutch Masters", such as Rembrandt van Rijn, Johannes Vermeer, Jan Steen, Jacob van Ruisdael and many others. Famous Dutch painters of the 19th and 20th century were Vincent van Gogh and Piet Mondriaan. M. C. Escher is a well-known graphics artist. Willem de Kooning was born and trained in Rotterdam, although he is considered to have reached acclaim as an American artist.

The Netherlands is the country of philosophers Erasmus of Rotterdam and Spinoza. All of Descartes' major work was done in the Netherlands since he studied at Leiden University — as did throughout the centuries geologist James Hutton, British Prime Minister John Stuart, U.S. President John Quincy Adams, Physics Nobel Prize laureate Hendrik Lorentz and Islam critic Ayaan Hirsi Ali. The Dutch scientist Christiaan Huygens (1629–1695) discovered Saturn's moon Titan, argued that light travelled as waves, invented the pendulum clock and was the first physicist to use mathematical formulae. Antonie van Leeuwenhoek was the first to observe and describe single-celled organisms with a microscope.

In the Dutch Golden Age, literature flourished as well, with Joost van den Vondel and P. C. Hooft as the two most famous writers. In the 19th century, Multatuli wrote about the poor treatment of the natives in the Dutch colony, the current Indonesia. Important 20th century authors include Godfried Bomans, Harry Mulisch, Jan Wolkers, Simon Vestdijk, Hella S. Haasse, Cees Nooteboom, Gerard Reve and Willem Frederik Hermans. Anne Frank's "Diary of a Young Girl" was published after she was murdered in the Holocaust and translated from Dutch to all major languages.

The traditional Dutch architecture is especially valued in Amsterdam, Delft and Leiden, with 17 and 18th century buildings along the canals. Smaller village architecture with wooden houses is found in Zaandam and Marken. Replicas of Dutch buildings can be found in Huis Ten Bosch, Nagasaki, Japan. A similar Holland Village is being built in Shenyang, China. Windmills, tulips, wooden shoes, cheese, Delftware pottery, and cannabis are among the items associated with the Netherlands by tourists.

The Netherlands has a long history of social tolerance and today is regarded as a liberal country, considering its drug policy and its legalisation of euthanasia. On 1 April 2001, the Netherlands became the first nation to legalise same-sex marriage.

Dutch society is egalitarian and modern. The Dutch have an aversion to the non-essential. Ostentatious behaviour is to be avoided. The Dutch are proud of their cultural heritage, rich history in art and involvement in international affairs.
Dutch manners are open and direct with a no-nonsense attitude; informality combined with adherence to basic behaviour. According to a humorous source on Dutch culture, "Their directness gives many the impression that they are rude and crude — attributes they prefer to call openness." A well known more serious source on Dutch etiquette is "Dealing with the Dutch" from Jacob Vossestein: "Dutch egalitarianism is the idea that people are equal, especially from a moral point of view, and accordingly, causes the somewhat ambiguous stance the Dutch have towards hierarchy and status." As always, manners differ between groups. Asking about basic rules will not be considered impolite. "What may strike you as being blatantly blunt topics and comments are no more embarrassing or unusual to the Dutch than discussing the weather."

The Netherlands is one of the most secular countries of Europe, and religion is in the Netherlands generally considered as a personal matter which is not supposed to be propagated in public, although it often remains a discussion subject. For only 17% of the population religion is important and 14% goes to church weekly.

As a whole, and as of 2018, the Netherlands has one of the highest rates of CO2 emission per capita in the EU, above Germany, France or Belgium. The Netherlands has nonetheless the reputation of the leader country in environmental and population management. In 2015, Amsterdam and Rotterdam were, respectively, at the 4th and the 5th position on the Arcadis Sustainable Cities Index.

Sustainability is a concept important for the Dutch. The goal of the Dutch Government is to have a sustainable, reliable and affordable energy system, by 2050, in which emissions have been halved and 40 percent of electricity is derived from sustainable sources.

The government is investing billions of euros in energy efficiency, sustainable energy and reduction. The Kingdom also encourage Dutch companies to build sustainable business/projects/facilities, with financial aids from the state to the companies or individuals who are active in making the country more sustainable.

The Netherlands has multiple music traditions. Traditional Dutch music is a genre known as "Levenslied", meaning "Song of life", to an extent comparable to a French Chanson or a German Schlager. These songs typically have a simple melody and rhythm, and a straightforward structure of couplets and choruses. Themes can be light, but are often sentimental and include love, death and loneliness. Traditional musical instruments such as the accordion and the barrel organ are a staple of levenslied music, though in recent years many artists also use synthesisers and guitars. Artists in this genre include Jan Smit, Frans Bauer and André Hazes.

Contemporary Dutch rock and pop music (Nederpop) originated in the 1960s, heavily influenced by popular music from the United States and Britain. In the 1960s and 1970s the lyrics were mostly in English, and some tracks were instrumental. Bands such as Shocking Blue, Golden Earring, Tee Set, George Baker Selection and Focus enjoyed international success. As of the 1980s, more and more pop musicians started working in the Dutch language, partly inspired by the huge success of the band Doe Maar. Today Dutch rock and pop music thrives in both languages, with some artists recording in both.

Current symphonic metal bands Epica, Delain, ReVamp, The Gathering, Asrai, Autumn, Ayreon and Within Temptation as well as jazz and pop singer Caro Emerald are having international success. Also, metal bands like Hail of Bullets, God Dethroned, Izegrim, Asphyx, Textures, Present Danger, Heidevolk and Slechtvalk are popular guests at the biggest metal festivals in Europe. Contemporary local stars include pop singer Anouk, country pop singer Ilse DeLange, South Guelderish and Limburgish dialect singing folk band Rowwen Hèze, rock band BLØF and duo Nick & Simon. Trijntje Oosterhuis, one of the country's most well known and versatile singers, has made multiple albums with famous American composers Vince Mendoza and Burt Bacharach.

Early 1990s Dutch and Belgian house music came together in Eurodance project 2 Unlimited. Selling 18 million records, the two singers in the band are the most successful Dutch music artists to this day. Tracks like "Get Ready for This" are still popular themes of U.S. sports events, like the NHL. In the mid 1990s Dutch language rap and hip hop ("Nederhop") also came to fruition and has become popular in the Netherlands and Belgium. Artists with North African, Caribbean or Middle Eastern origins have strongly influenced this genre.

Since the 1990s, Dutch electronic dance music (EDM) gained widespread popularity in the world in many forms, from trance, techno and gabber to hardstyle. Some of the world's best known dance music DJs hail from the Netherlands, including Armin van Buuren, Tiësto, Hardwell, Martin Garrix, Dash Berlin, Julian Jordan, Nicky Romero, W&W, Don Diablo and Afrojack; the first four of which have been ranked as best in the world by DJ Mag Top 100 DJs. The Amsterdam Dance Event (ADE) is the world's leading electronic music conference and the biggest club festival for the many electronic subgenres on the planet. These DJs also contribute to the world's mainstream pop music, as they frequently collaborate and produce for high-profile international artists.

The Netherlands have participated in the Eurovision Song Contest since its first edition in 1956, and have won five times. Their most recent win was in 2019.

In classical music, Jan Sweelinck ranks as the Dutch most famous composer, with Louis Andriessen amongst the best known living Dutch classical composers. Ton Koopman is a Dutch conductor, organist and harpsichordist. He is also professor at the Royal Conservatory of The Hague. Notable violinists are Janine Jansen and André Rieu. The latter, together with his Johann Strauss Orchestra, has taken classical and waltz music on worldwide concert tours, the size and revenue of which are otherwise only seen from the world's biggest rock and pop music acts. The most famous Dutch classical composition is "Canto Ostinato" by Simeon ten Holt, a minimalistic composition for multiple instruments. Acclaimed harpist Lavinia Meijer in 2012 released an album with works from Philip Glass that she transcribed for harp, with approval of Glass himself. The Concertgebouw (completed in 1888) in Amsterdam is home to the Royal Concertgebouw Orchestra, considered one of the world's finest orchestras.

Some Dutch films – mainly by director Paul Verhoeven – have received international distribution and recognition, such as "Turkish Delight" (""Turks Fruit"", 1973), "Soldier of Orange" (""Soldaat van Oranje"", 1977), "Spetters" (1980) and "The Fourth Man" (""De Vierde Man"", 1983). Verhoeven then went on to direct big Hollywood movies like "RoboCop" (1987), "Total Recall" (1990) and "Basic Instinct" (1992), and returned with Dutch film "Black Book" (""Zwartboek"", 2006).

Other well-known Dutch film directors are Jan de Bont ("Speed"), Anton Corbijn ("A Most wanted Man"), Dick Maas ("De Lift"), Fons Rademakers ("The Assault"), and documentary makers Bert Haanstra and Joris Ivens. Film director Theo van Gogh achieved international notoriety in 2004 when he was murdered by Mohammed Bouyeri in the streets of Amsterdam after directing the short film "Submission".

Internationally, successful directors of photography from the Netherlands are Hoyte van Hoytema ("Interstellar", "Spectre", "Dunkirk") and Theo van de Sande ("Wayne's World" and "Blade"). Van Hoytema went to the National Film School in Łódź (Poland) and Van de Sande went to the Netherlands Film Academy. Internationally successful Dutch actors include Famke Janssen ("X-Men"), Carice van Houten ("Game of Thrones"), Michiel Huisman ("Game of Thrones"), Rutger Hauer ("Blade Runner"), Jeroen Krabbé ("The Living Daylights") and Derek de Lint ("Three Men and a Baby").

The Netherlands has a well developed television market, with both multiple commercial and public broadcasters. Imported TV programmes, as well as interviews with responses in a foreign language, are virtually always shown with the original sound and subtitled. Only foreign shows for children are dubbed.

TV exports from the Netherlands mostly take the form of specific formats and franchises, most notably through internationally active TV production conglomerate Endemol, founded by Dutch media tycoons John de Mol and Joop van den Ende. Headquartered in Amsterdam, Endemol has around 90 companies in over 30 countries. Endemol and its subsidiaries create and run reality, talent, and game show franchises worldwide, including "Big Brother" and "Deal or No Deal". John de Mol later started his own company Talpa which created show franchises like "The Voice" and "Utopia".

Approximately 4.5 million of the 16.8 million people in the Netherlands are registered to one of the 35,000 sports clubs in the country. About two-thirds of the population between 15 and 75 participates in sports weekly. Football is the most popular participant sport in the Netherlands, before field hockey and volleyball as the second and third most popular team sports. Tennis, gymnastics and golf are the three most widely engaged in individual sports.

Organisation of sports began at the end of the 19th century and the beginning of the 20th century. Federations for sports were established (such as the speed skating federation in 1882), rules were unified and sports clubs came into existence. A Dutch National Olympic Committee was established in 1912. Thus far, the nation has won 266 medals at the Summer Olympic Games and another 110 medals at the Winter Olympic Games. In international competition, Dutch national teams and athletes are dominant in several fields of sport. The Netherlands women's field hockey team is the most successful team in World Cup history. The Netherlands baseball team have won the European championship 20 times out of 32 events. Dutch K-1 kickboxers have won the K-1 World Grand Prix 15 times out of 19 tournaments.

The Dutch speed skaters' performance at the 2014 Winter Olympics, where they won 8 out of 12 events, 23 out of 36 medals, including 4 clean sweeps, is the most dominant performance in a single sport in Olympic history. Motorcycle racing at the TT Circuit Assen has a long history. Assen is the only venue to have held a round of the Motorcycle World Championship every year since its creation in 1949. The circuit was purpose-built for the Dutch TT in 1954, with previous events having been held on public roads.

The Dutch have also had success in all three of cyclings Grand Tours with Jan Janssen winning the 1968 Tour de France, more recently with Tom Dumoulin winning the 2017 Giro d'Italia and legendary rider Joop Zoetemelk was the 1985 UCI World Champion, the winner of the 1979 Vuelta a Espana, the 1980 Tour de France and still holds or shares numerous Tour de France records including most Tours finished and most kilometers ridden.

Limburger Max Verstappen currently races in Formula One, and was the first Dutchman to win a Grand Prix. The coastal resort of Zandvoort hosted the Dutch Grand Prix from 1958 to 1985, and has been announced to return in 2020. The volleyball national men's team has also been successful, winning the silver medal at the 1992 Summer Olympics and the gold medal four years later in Atlanta. The biggest success of the women's national team was winning the European Championship in 1995 and the World Grand Prix in 2007.

Originally, the country's cuisine was shaped by the practices of fishing and farming, including the cultivation of the soil for growing crops and raising domesticated animals. Dutch cuisine is simple and straightforward, and contains many dairy products. Breakfast and lunch are typically bread with toppings, with cereal for breakfast as an alternative. Traditionally, dinner consists of potatoes, a portion of meat, and (seasonal) vegetables. The Dutch diet was relatively high in carbohydrates and fat, reflecting the dietary needs of the labourers whose culture moulded the country. Without many refinements, it is best described as rustic, though many holidays are still celebrated with special foods. In the course of the twentieth century this diet changed and became much more cosmopolitan, with most global cuisines being represented in the major cities.

Modern culinary writers distinguish between three general regional forms of Dutch cuisine. The regions in the northeast of the Netherlands, roughly the provinces of Groningen, Friesland, Drenthe, Overijssel and Gelderland north of the great rivers are the least populated areas of the Netherlands. The late (18th century) introduction of large scale agriculture means that the cuisine is generally known for its many kinds of meats. The relative lack of farms allowed for an abundance of game and husbandry, though dishes near the coastal regions of Friesland, Groningen and the parts of Overijssel bordering the IJsselmeer also include a large amount of fish. The various dried sausages, belonging to the metworst-family of Dutch sausages are found throughout this region and are highly prized for their often very strong taste. Also smoked sausages are common, of which ("Gelderse") "rookworst" is the most renowned. The sausage contains a lot of fat and is very juicy. Larger sausages are often eaten alongside "stamppot", "hutspot" or "zuurkool" (sauerkraut); whereas smaller ones are often eaten as a street food. The provinces are also home to hard textured rye bread, pastries and cookies, the latter heavily spiced with ginger or succade or contain small bits of meat. Various kinds of "Kruidkoek" (such as ), "" and "" (small savory pancakes cooked in a waffle iron) are considered typical. Notable characteristics of "Fries roggebrood" (Frisian rye bread) is its long baking time (up to 20 hours), resulting in a sweet taste and a deep dark colour. In terms of alcoholic beverages, the region is renowned for its many bitters (such as "Beerenburg") and other high-proof liquors rather than beer, which is, apart from "Jenever", typical for the rest of the country. As a coastal region, Friesland is home to low-lying grasslands, and thus has a cheese production in common with the Western cuisine. "Friese Nagelkaas" (Friesian Clove) is a notable example.

The provinces of North Holland, South Holland, Zeeland, and Utrecht and the Gelderlandic area of Betuwe make up the region in which western Dutch cuisine is found. Because of the abundance of water and flat grasslands that are found here, the area is known for its many dairy products, which include prominent cheeses such as Gouda, Leyden (spiced cheese with cumin), and Edam (traditionally in small spheres) as well as Leerdammer and Beemster, while the adjacent Zaanstreek in North Holland has since the 16th century beem known for its mayonnaise, typical whole-grain mustards, and chocolate industry. Zeeland and South Holland produce a lot of butter, which contains a larger amount of milkfat than most other European butter varieties. A by-product of the butter-making process, "karnemelk" (buttermilk), is also considered typical for this region. Seafood such as soused herring, mussels (called "Zeeuwse Mossels", since all Dutch mussels for consumption are cleaned in Zeeland's Oosterschelde), eels, oysters and shrimps are widely available and typical for the region. "", once a local delicacy consisting of small chunks of battered white fish, has become a national fast food, just as . Pastries in this area tend to be quite doughy, and often contain large amounts of sugar; either caramelised, powdered or crystallised. The "oliebol" (in its modern form) and "Zeeuwse bolus" are good examples. Cookies are also produced in great number and tend to contain a lot of butter and sugar, like "stroopwafel", as well as a filling of some kind, mostly almond, like "". The traditional alcoholic beverages of this region are beer (strong pale lager) and "Jenever", a high proof juniper-flavored spirit, that came to be known in England as gin. A noted exception within the traditional Dutch alcoholic landscape, "Advocaat", a rich and creamy liqueur made from eggs, sugar and brandy, is also native to this region.

The Southern Dutch cuisine consists of the cuisines of the Dutch provinces of North Brabant and Limburg and the Flemish Region in Belgium. It is renowned for its many rich pastries, soups, stews and vegetable dishes and is often called Burgundian which is a Dutch idiom invoking the rich Burgundian court which ruled the Low Countries in the Middle Ages, renowned for its splendor and great feasts. It is the only Dutch culinary region that developed an haute cuisine. Pastries are abundant, often with rich fillings of cream, custard or fruits. Cakes, such as the "Vlaai" from Limburg and the "Moorkop" and "Bossche Bol" from Brabant, are typical pastries. Savoury pastries also occur, with the (a roll with a sausage of ground beef, literally translates into sausage bread) being the most popular. The traditional alcoholic beverage of the region is beer. There are many local brands, ranging from "Trappist" to "Kriek". 5 of the 10 "International Trappist Association" recognised breweries in the world, are located in the Southern Dutch cultural area. Beer, like wine in French cuisine, is also used in cooking; often in stews.

In early 2014, Oxfam ranked the Netherlands as the country with the most nutritious, plentiful and healthy food, in a comparison of 125 countries.

From the exploitations in the Mughal Empire in the 17th century, to the colonisations in the 19th century, Dutch imperial possessions continued to expand, reaching their greatest extent by establishing a hegemony of the Dutch East Indies in the early 20th century. The Dutch East Indies, which later formed modern-day Indonesia, was one of the most valuable European colonies in the world and the most important one for the Netherlands. Over 350 years of mutual heritage has left a significant cultural mark on the Netherlands.

In the Dutch Golden Age of the 17th century, the Netherlands urbanised considerably, mostly financed by corporate revenue from the Asian trade monopolies. Social status was based on merchants' income, which reduced feudalism and considerably changed the dynamics of Dutch society. When the Dutch royal family was established in 1815, much of its wealth came from Colonial trade.
By the 17th century, the Dutch East India Company established their base in parts of Ceylon (modern-day Sri Lanka). Afterward, they established ports in Dutch occupied Malabar, leading to Dutch settlements and trading posts in India. However, their expansion into India was halted, after their defeat in the Battle of Colachel by the Kingdom of Travancore, during the Travancore-Dutch War. The Dutch never recovered from the defeat and no longer posed a large colonial threat to Bengal Subah.

Universities such as the Leiden University, founded in the 16th century, have developed into leading knowledge centres for Southeast Asian and Indonesian studies. Leiden University has produced leading academics such as Christiaan Snouck Hurgronje, and still has academics who specialise in Indonesian languages and cultures. Leiden University and in particular KITLV are educational and scientific institutions that to this day share both an intellectual and historical interest in Indonesian studies. Other scientific institutions in the Netherlands include the Amsterdam Tropenmuseum, an anthropological museum with massive collections of Indonesian art, culture, ethnography and anthropology.
The traditions of the Royal Dutch East Indies Army (KNIL) are maintained by the Regiment Van Heutsz of the modern Royal Netherlands Army. A dedicated "Bronbeek Museum", a former home for retired KNIL soldiers, exists in Arnhem to this day.

A specific segment of Dutch literature called Dutch Indies literature still exists and includes established authors, such as Louis Couperus, the writer of "The Hidden Force", taking the colonial era as an important source of inspiration. One of the great masterpieces of Dutch literature is the book "Max Havelaar", written by Multatuli in 1860.

The majority of Dutchmen that repatriated to the Netherlands after and during the Indonesian revolution are Indo (Eurasian), native to the islands of the Dutch East Indies. This relatively large Eurasian population had developed over a period of 400 years and were classified by colonial law as belonging to the European legal community. In Dutch they are referred to as "Indische Nederlanders" or as Indo (short for Indo-European).

Including their second generation descendants, Indos are currently the largest foreign-born group in the Netherlands. In 2008, the Dutch Central Bureau for Statistics (CBS) registered 387,000 first- and second-generation Indos living in the Netherlands. Although considered fully assimilated into Dutch society, as the main ethnic minority in the Netherlands, these 'repatriants' have played a pivotal role in introducing elements of Indonesian culture into Dutch mainstream culture.

Many Indonesian dishes and foodstuffs have become commonplace in the Netherlands. Rijsttafel, a colonial culinary concept, and dishes such as Nasi goreng and satay are very popular in the country. Practically any town of any size in the Netherlands has a "toko" (a Dutch Indonesian Shop) or a Chinese-Indonesian restaurant, and many 'Pasar Malam' (Night market in Malay/Indonesian) fairs are organised throughout the year. 













</doc>
<doc id="21149" url="https://en.wikipedia.org/wiki?curid=21149" title="N.W.A">
N.W.A

N.W.A (an abbreviation for Niggaz wit Attitudes) was an American hip hop group from Compton, California. They were among the earliest and most significant popularizers and controversial figures of the gangsta rap subgenre, and are widely considered one of the greatest and most influential groups in the history of hip hop music.

Active from 1987 to 1991, the rap group endured controversy owing to their music's explicit lyrics which many viewed as being misogynist, as well as to its glorification of drugs and crime. The group was subsequently banned from many mainstream American radio stations. In spite of this, the group has sold over 10 million units in the United States alone. Drawing on their own experiences of racism and excessive policing, the group made inherently political music. They were known for their deep hatred of the police system, which has sparked much controversy over the years.

The original lineup, formed in early 1987, consisted of Arabian Prince, Dr. Dre, Eazy-E, and Ice Cube. DJ Yella and MC Ren joined later that year. They released their first compilation album as a group in 1987 called N.W.A. and the Posse which peaked at #39 on Billboard magazine's Top R&B/Hip-Hop Albums chart. Arabian Prince left shortly after the release of their debut studio album, "Straight Outta Compton", in 1988, with Ice Cube following suit in December of the following year. Eazy-E, Ice Cube, MC Ren and Dr. Dre would later become platinum-selling solo artists in their own right in the 1990s. Their debut album marked the beginning of the new gangsta rap era as the production and social commentary in their lyrics were revolutionary within the genre. N.W.A's second studio album, "Niggaz4Life", was the first hardcore rap album to debut at number one on the "Billboard" 200 sales charts.

"Rolling Stone" ranked N.W.A number 83 on their list of the "100 Greatest Artists of All Time". In 2016, the group was inducted into the Rock and Roll Hall of Fame, following three previous nominations.

N.W.A was assembled by Compton-based Eazy-E, who co-founded Ruthless Records with Jerry Heller. Eazy-E sought an introduction to Steve Yano. Although initially rebuffed, Yano was impressed by Eazy-E's persistence and arranged a meeting with Dr. Dre. Initially, N.W.A consisted of Eazy-E and Dr. Dre. Together with fellow producer Arabian Prince, Ice Cube was added to the roster after he had started out as a rapper for the group C.I.A. Dre would later bring DJ Yella on board as well. Dre and Yella were both formerly members of the World Class Wreckin' Cru as DJs and producers. Ruthless released the single "Panic Zone" in 1987 with Macola Records, which was later included on the compilation album "N.W.A. and the Posse". N.W.A was still in its developing stages, and is only credited on three of the eleven tracks, notably the uncharacteristic record "Panic Zone", "8-Ball", and "Dopeman", which marked the first collaboration of Arabian Prince, DJ Yella, Dr. Dre, and Ice Cube. Mexican rapper Krazy-Dee co-wrote "Panic Zone", which was originally called "Hispanic Zone", but the title was later changed when Dr. Dre advised Krazy-Dee that the word "hispanic" would hinder sales. Also included was Eazy-E's solo track "Boyz-n-the-Hood".

N.W.A released their debut studio album, "Straight Outta Compton", in 1988. With its famous opening salvo of three tracks, the group reflected the rising anger of the urban youth. The opening song "Straight Outta Compton" introduced the group, "Fuck tha Police" protested police brutality and racial profiling, and "Gangsta Gangsta" painted the worldview of the inner-city youth. While the group was later credited with pioneering the burgeoning subgenre of gangsta rap, N.W.A referred to their music as "reality rap". Twenty-seven years later, member and co-producer of the "Straight Outta Compton" film, Ice Cube, commented "they were talking about what really led into the style that we ended up doing, which is now called hardcore gangster rap." Dr. Dre and DJ Yella, as HighPowered Productions, composed the beats for each song, with Dre making occasional rapping appearances. The D.O.C., Ice Cube, and MC Ren wrote most of the group's lyrics, including "Fuck tha Police", perhaps the group's most notorious song, which brought them into conflict with various law enforcement agencies. Under pressure from Focus on the Family, Milt Ahlerich, an assistant director of the FBI sent a letter to Ruthless and its distributing company Priority Records, advising the rappers that "advocating violence and assault is wrong and we in the law enforcement community take exception to such action." This letter can still be seen at the Rock and Roll Hall of Fame in Cleveland, Ohio. Policemen refused to provide security for the group's concerts, hurting their plans to tour. Nonetheless, the FBI's letter only served to draw more publicity to the group.

"Straight Outta Compton" was also one of the first albums to adhere to the new Parental Advisory label scheme, then still in its early stages: the label at the time consisted of "WARNING: Moderate impact coarse language and/or themes" only. However, the taboo nature of N.W.A's music was the most important factor of its mass appeal. Media coverage compensated for N.W.A's lack of airplay and their album eventually went double platinum. One month after "Straight Outta Compton", Eazy-E's solo debut "Eazy-Duz-It" was released. The album was dominated by Eazy's persona (MC Ren was the only guest rapper) but behind the scenes it was a group effort. Music was handled by Dr. Dre and DJ Yella; the lyrics were largely written by MC Ren, with contributions from Ice Cube and The D.O.C. The album was another double platinum success for Ruthless (in addition to girl group J.J. Fad in 1988 and singer Michel'le in 1989). 1989 saw the re-issue of "N.W.A and the Posse" and "Straight Outta Compton" on CD, and the release of The D.O.C.'s "No One Can Do It Better". His album was essentially a collaboration with Dr. Dre and notably free of "gangsta rap" content, including the N.W.A posse cut "The Grand Finalé". It would become another #1 album for the record label.

Ice Cube left the group in December 1989 over royalty disputes; having written almost half of the lyrics on "Straight Outta Compton" himself, he felt he was not getting a fair share of the profits. A lawsuit brought by Ice Cube against band manager Jerry Heller was settled out of court. He wasted little time putting together his solo debut, 1990's "AmeriKKKa's Most Wanted", but he avoided mentioning his former label mates. N.W.A's title track from their 1990 EP "100 Miles and Runnin'", however, included a diss of Ice Cube:
""We started with five, but yo / One couldn't take it—So now it's four / Cuz the fifth couldn't make it."" The video for the song depicted the remaining members of N.W.A together in a jail cell, while an Ice Cube look-alike is released. Also heard on the EP (which found its way on the "Efil4zaggin" album) was "Real Niggaz", a full-blown diss on Ice Cube where the remaining members accuse him of cowardice, and question his authenticity, longevity and originality: ""How the fuck you think a rapper lasts / With your ass sayin' shit that was said in the past / Yo, be original, your shit is sloppy / Get off the dick, you motherfuckin' carbon-copy"", and ""We started out with too much cargo / So I'm glad we got rid of Benedict Arnold, yo."" The song "100 Miles and Runnin'" was Dr. Dre's final uptempo recording, which had been a common feature of late 1980s hip hop. After this, he focused on a midtempo, synthesizer based sound which would become known as G-funk, starting with "Alwayz Into Somethin'" from "Efil4zaggin" in 1991. The G-funk style dominated both the West and East Coast hip hop music scene for several years to come. N.W.A is referenced on Ice Cube's 1990 EP, "Kill at Will", where he name-checks his former group (likely in a mocking manner) on the song "Jackin' For Beats". On "I Gotta Say What Up!!!", Ice Cube gives shout-outs to his rap peers at the time, among them Public Enemy, Geto Boys, and Sir Jinx. At the end of the track, in what appears to be an on-the-phone interview, Ice Cube is asked, "Since you went solo, what's up with the rest of the crew?" and the phone is abruptly hung up on the interviewer.

The group's second full-length release, 1991's "Efil4zaggin" ("Niggaz4Life" spelled backwards), re-established the band in the face of Ice Cube's continued solo success. The album is considered by many Dr. Dre's finest production work, and it heralded the beginning of the G-Funk era. It also showed a clear animosity towards their former member, and derogatory references to Ice Cube are found in several songs. The interlude "A Message to B.A." echoes the beginning of his song "Turn Off the Radio" from "AmeriKKKa's Most Wanted": Ice Cube is first addressed by the name Benedict Arnold (after the infamous traitor of the American Revolution) but then named outright in a torrent of abuse from both the group and its fans: ""When we see yo' ass, we gon' cut yo' hair off and fuck you with a broomstick"" spoken by MC Ren. The N.W.A–Ice Cube feud eventually escalated, both on record and in real life. "AmeriKKKa's Most Wanted" had avoided direct attacks on N.W.A, but on "Death Certificate", Ice Cube's second full-length release, he retaliated. He sampled and mocked the "Message to B.A." skit before embarking on a full-blown tirade, the infamous "No Vaseline". In a series of verses, Ice Cube verbally assaulted the group: ""You lookin' like straight bozos / I saw it comin' that's why I went solo / Kept on stompin' / When y'all Muthafuckas moved Straight outta Compton / You got jealous when I got my own company / But I'm a man, and ain't nobody humpin' me."" He also responded to members MC Ren, Dr. Dre, and Eazy-E individually to "100 Miles and Runnin'", claiming ""I started off with too much cargo / Dropped four niggaz and now I'm makin' all the dough"", using homophobic metaphors to describe their unequal business relationship with Jerry Heller, who became the target of harsh insults:
""Get rid of that devil real simple / Put a bullet in his temple / Cuz you can't be the 'Niggaz 4 Life' crew / With a white Jew tellin' you what to do."" The song attracted controversy for its antisemitism (the beginning of such accusations against Ice Cube during his affiliation with the Nation of Islam), based on the bashing of Heller's religion. The track was omitted from the UK release, and later pressings included a censored version of the song. In September 1990, members of hip hop act Above the Law clashed with Ice Cube and his posse Da Lench Mob during the annual New Music Seminar conference, forcing the latter to flee the premises of Times Square's Marriott Marquis, the venue of the event. On January 27, 1991, Dr. Dre assaulted Dee Barnes, host of the hip hop show "Pump It Up", after its coverage of the N.W.A/Ice Cube beef. According to "Rolling Stone" reporter Alan Light:
In response, Dre commented: "People talk all this shit, but you know, if somebody fucks with me, I'm gonna fuck with them. I just did it, you know. Ain't nothing you can do now by talking about it. Besides, it ain't no big thing—I just threw her through a door."

1991's "Niggaz4Life" would be the group's final album. After Dr. Dre, The D.O.C. and Michel'le departed from Ruthless to join Death Row Records and allegations over Eazy-E being coerced into signing away their contracts (while however retaining a portion of their publishing rights), a bitter rivalry ensued. Dr. Dre began the exchange with Death Row's first release, 1992's "Fuck Wit Dre Day (And Everybody's Celebratin')", and its accompanying video featured a character named "Sleazy-E" who ran around desperately trying to get money. The insults continued on "The Chronic" with "Bitches Ain't Shit". Eazy-E responded in 1993 with the EP "It's On (Dr. Dre) 187um Killa" on the tracks "Real Muthaphuckkin G's" and "It's On". Eazy-E accused Dr. Dre of being a homosexual, calling him a "she thang", and criticizing Dre's new image by calling him and Snoop "studio gangsters". The music video for "Real Muthaphuckkin G's" showed a still of Dre wearing make-up and a sequined jumpsuit. The photos dated back to Dr. Dre's World Class Wreckin' Cru days, when such fashion was common among West Coast electro hop artists, prior to N.W.A's popularization of gangsta rap. Eazy-E kept dissing Dre and Death Row on most of his songs until his AIDS-related death on March 26, 1995.

Even Eazy-E's longtime friend MC Ren voiced his dislike for Eazy-E in 1994, calling Eazy-E a "big-head" and "wannabe mega-star", and even suggesting that N.W.A should reunite without Eazy-E. MC Ren later said that the only relationship he had with Eazy-E was through Ruthless Records, where he released several gold and platinum selling albums, including "Kizz My Black Azz" and "Shock of the Hour". Eazy-E and MC Ren would squash their beef shortly before Eazy-E's death in their 1995 duet '"Tha Muthaphukkin' Real" after two years of not talking to each other. All bad blood finally ceased within the rest of the group. Dr. Dre, MC Ren and Ice Cube would later express their re-evaluated feelings to their old friend on 1998's "Ruthless for Life", 1999's "What's the Difference" and "Chin Check", 2000's "Hello", 2006's "Growin' Up", and in the 2011 music video "I Need a Doctor".

Having both parted with Ruthless Records on bad terms, tensions between Ice Cube and Dr. Dre eventually eased on their own. After Ice Cube made a cameo appearance in Dr. Dre's "Let Me Ride" video in 1993, the two recorded the hit song "Natural Born Killaz" for Snoop Doggy Dogg's 1994 short film and soundtrack "Murder Was the Case". Ice Cube also later appeared on MC Ren's album "Ruthless for Life" on the track "Comin' After You". MC Ren appeared on Dre's 1999 album "2001", and the three remaining N.W.A emcees would reunite for "Hello" on Ice Cube's 2000 album "War & Peace Vol. 2 (The Peace Disc)", and the song "Chin Check" in 1999 for the "Next Friday" soundtrack, a movie starring Ice Cube.

The West Coast and "gangsta" music scene had however fallen out of the spotlight since the death of Tupac Shakur in 1996, and it was only after Dr. Dre's successful patronage of Eminem and Dre's ensuing comeback album "2001" that the genre and its artists would regain the national spotlight. 2000's all-star Up In Smoke Tour would reunite much of the N.W.A and Death Row families, and during time spent on the road, Dre, Ice Cube, MC Ren, guest star Snoop Dogg and Eminem began recording in a mobile studio. A comeback album entitled "Not These Niggaz Again" was planned (and would include DJ Yella, who had not been present on the tour).

However, due to busy and conflicting schedules as well as the obstacles of coordinating three different record labels (Priority, No Limit and Interscope), obtaining the rights to the name N.W.A and endorsing the whole project to gain exclusive rights, the album never materialized. Only two tracks from these sessions would be released: the aforementioned "Chin Check" (with Snoop Dogg as a member of N.W.A) from 2000's "Next Friday" soundtrack and "Hello" from Ice Cube's 2000 album "War & Peace Vol. 2 (The Peace Disc)". Both songs would also appear on N.W.A's remastered "Greatest Hits". There would also be partial reunions on other projects, notably "Set It Off", from Snoop Dogg's "Tha Last Meal" (2000), which featured MC Ren and Ice Cube, and The D.O.C.'s "The Shit", from his 2003 album "Deuce", featuring MC Ren, Ice Cube, Snoop Dogg and Six-Two. Dr. Dre and DJ Yella were present in the studio for the latter song.

In addition to the "Greatest Hits" initially released by Priority in 1996, Capitol and Ruthless Records jointly released "" in 1999, a compilation that contained songs by other rap artists and only three songs from the actual group but various solo tracks from the five members. The success of the album prompted a second volume, "The N.W.A Legacy, Vol. 2", three years later. It emulated the format of its predecessor, containing only three genuine N.W.A tracks and many solo efforts by the crew members. In 2007, a new greatest hits package was released, entitled "".

In 2014, Ice Cube appeared on MC Ren's remix for "Rebel Music". This was the first time the duo had worked together since the N.W.A reunion in 2000.

On June 27, 2015, MC Ren and DJ Yella joined Ice Cube during his solo set as part of the BET Experience show at the Staples Center in Los Angeles, California. This marked the first reunion performance of the group (minus Dr. Dre) in 15 years. Following a 27-year hiatus, the group reunited with surviving members Ice Cube, MC Ren, Dr. Dre and DJ Yella taking the stage during the second weekend of the Coachella Valley Music and Arts Festival in April 2016, just days following the group's Rock N' Roll Hall of Fame induction.

New Line Cinema representatives announced to "Entertainment Weekly's" "Hollywood Insider Blog" that N.W.A's story was in development to become a feature film for theatrical release in 2012. However, it was delayed to sometime in 2014. The script was researched and written by filmmaker S. Leigh Savidge and radio veteran Alan Wenkus, who worked closely with Eazy-E's widow, Tomica Woods-Wright. Ice Cube and Dr. Dre act as producers of the film. In September 2011, John Singleton was selected as director. Ice Cube and Singleton previously collaborated on "Boyz n the Hood", a movie that was nominated for an Academy Award, and Ice Cube also played the part of the character "Fudge" in Singleton's "Higher Learning". Casting calls began in the summer of 2010. There were rumors of Lil Eazy-E playing his late father Eazy-E, and Ice Cube's son and fellow rapper O'Shea Jackson Jr. playing his father as well. Ice Cube stated of the movie, "We're taking it to the nooks and crannies, I think deeper than any other article or documentary on the group," he said. "These are the intimate conversations that helped forge N.W.A. To me, I think it's interesting to anybody who loves that era and I don't know any other movie where you can mix Gangster Rap, the F.B.I., L.A. riots, HIV, and fucking feuding with each other. This movie has everything from Darryl Gates and the battering ram."

In August 2012, F. Gary Gray was selected as director rather than Singleton. The film, named "Straight Outta Compton", had been picked up by Universal Pictures who hired Jonathan Herman in December 2013 to draft a new script and brought in Will Packer to executive produce. On February 21, 2014, director F. Gary Gray announced a March 9, 2014 open casting call for the film via his Twitter account. There were also open casting calls in Atlanta and Chicago. Rapper YG auditioned to play MC Ren in the film. The project was scheduled to start filming in April 2014 but was pushed backed due to casting delays.

On June 18, 2014, Universal officially announced that the N.W.A biopic "Straight Outta Compton" would be released August 14, 2015. It was also confirmed that Ice Cube's son, O'Shea Jackson Jr., would play a younger version of his father in the movie. O'Shea Jr. joined Jason Mitchell and Corey Hawkins who will portray group members Eazy-E and Dr. Dre, respectively, in the film. To round out the cast of N.W.A, Aldis Hodge plays MC Ren and Neil Brown Jr. portrays DJ Yella. In early July 2014, casting directors for the N.W.A biopic issued a casting call for extras and vintage cars in the Los Angeles area for scenes in the movie. According to the casting call release, the film began filming in August 2014 and was released a year later on August 14, 2015. The film received positive reviews and grossed over $200 million worldwide.

Although the group disbanded in 1991, they remain one of the greatest and most influential hip-hop groups, leaving a lasting legacy on hip hop music in the following decades. Their influence, from their funky, bass-driven beats to their exaggerated lyrics, was evident throughout the 1990s and even into the present, and is often credited as bridging the white/black American musical lines with their appeal to white Americans in the late 1980s. In Dr. Dre's 1999 single "Forgot About Dre", Eminem pays homage to the group, rapping "So what do you say to somebody you hate or anyone tryna bring trouble your way, Wanna resolve things in a bloodier way, Then just study a tape of N.W.A" referring to the negative reception of N.W.A's works by the mainstream radio, which considered their songs to be violent. A scene in the music video for the 2005 single "Hate It or Love It" by The Game featuring 50 Cent shows Tequan Richmond and Zachary Williams (portraying a youthful Game & 50 Cent respectively) being caught spraypainting "N.W.A" on a wall, resulting in their subsequent arrest by two policemen. The Game also has a tattoo that says "N.W.A" on the right side of his chest.





</doc>
<doc id="21150" url="https://en.wikipedia.org/wiki?curid=21150" title="Nibble">
Nibble

In computing, a nibble (occasionally nybble or nyble to match the spelling of byte) is a four-bit aggregation, or half an octet. It is also known as half-byte or tetrade. In a networking or telecommunication context, the nibble is often called a semi-octet, quadbit, or quartet. A nibble has sixteen (2) possible values. A nibble can be represented by a single hexadecimal digit and called a hex digit.

A full byte (octet) is represented by two hexadecimal digits; therefore, it is common to display a byte of information as two nibbles. Sometimes the set of all 256 byte values is represented as a 16×16 table, which gives easily readable hexadecimal codes for each value.

Four-bit computer architectures use groups of four bits as their fundamental unit. Such architectures were used in early microprocessors, pocket calculators and pocket computers. They continue to be used in some microcontrollers.

The term 'nibble' originates from its representing 'half a byte', with 'byte' a homophone of the English word 'bite'. In 2014, David B. Benson, a professor emeritus at Washington State University, remembered that he playfully used (and may have possibly coined) the term nibble as "half a byte" and unit of storage required to hold a binary-coded decimal (BCD) decimal digit around 1958, when talking to a programmer of Los Alamos Scientific Laboratory. The alternative spelling 'nybble' reflects the spelling of 'byte', as noted in editorials of "Kilobaud" and "Byte" in the early 1980s. Another early recorded use of the term 'nybble' was in 1977 within the consumer-banking technology group at Citibank. It created a pre-ISO 8583 standard for transactional messages between cash machines and Citibank's data centers that used the basic informational unit 'NABBLE'.

The nibble is used to describe the amount of memory used to store a digit of a number stored in packed decimal format (BCD) within an IBM mainframe. This technique is used to make computations faster and debugging easier. An 8-bit byte is split in half and each nibble is used to store one decimal digit. The last (rightmost) nibble of the variable is reserved for the sign. Thus a variable which can store up to nine digits would be "packed" into 5 bytes. Ease of debugging resulted from the numbers being readable in a hex dump where two hex numbers are used to represent the value of a byte, as 16×16 = 2. For example, a five-byte BCD value of      represents a decimal value of .

Historically, there are cases where nybble was used for a group of bits greater than 4. In the Apple II microcomputer line, much of the disk drive control and group-coded recording was implemented in software. Writing data to a disk was done by converting 256-byte pages into sets of 5-bit (later, 6-bit) nibbles and loading disk data required the reverse. Moreover, 1982 documentation for the Integrated Woz Machine refers consistently to an "8 bit nibble". The term "byte" once had the same ambiguity and meant a set of bits but not necessarily 8, hence the distinction of "bytes" and "octets" or of "nibbles" and "quartets" (or "quadbits"). Today, the terms 'byte' and 'nibble' almost always refer to 8-bit and 4-bit collections respectively and are very rarely used to express any other sizes.

The sixteen nibbles and their equivalents in other numeral systems:

The terms "low nibble" and "high nibble" are used to denote the nibbles containing, respectively, the less significant bits and the more significant bits within a byte. In graphical representations of bits within a byte, the leftmost bit could represent the most significant bit (MSB), corresponding to ordinary decimal notation in which the digit at the left of a number is the most significant. In such illustrations the four bits on the left end of the byte form the high nibble, and the remaining four bits form the low nibble. For example,

ninety-seven = 97 = (0110 0001)

the high nibble is 0110 (6), and the low nibble is 0001 (1). The total value is high-nibble × 16 + low-nibble (6×16+1=97).

In C:

where codice_1 must be a variable or constant of an integral data type, and only the least-significant byte of codice_1 is used.

For example, codice_3 and codice_4.

In Common Lisp:



</doc>
<doc id="21151" url="https://en.wikipedia.org/wiki?curid=21151" title="New wave music">
New wave music

New wave is a genre encompassing numerous pop-oriented music styles popular in the late 1970s and the 1980s. It is rooted in mid-1970s punk rock. New wave moved away from traditional blues and rock and roll sounds to create pop and rock music that incorporated disco, mod and electronic music. It engendered subgenres and fusions, including synth-pop.

New wave differs from other movements with ties to first-wave punk, as it displays characteristics common to pop music rather than the more "artsy" post-punk. Although it incorporates much of the original punk rock sound and ethos, new wave exhibits greater complexity in both music and lyrics. Common characteristics of new wave music include the use of synthesizers and electronic productions, and a distinctive visual style featured in music videos and fashion.

New wave was promoted heavily by MTV (the Buggles' "Video Killed the Radio Star" was broadcast as the first music video to promote the channel's launch). The popularity of several new wave artists is often attributed to their exposure on the channel. In the mid-1980s, differences between new wave and other music genres began to blur. New wave has enjoyed resurgences since the 1990s after a rising nostalgia for several new wave-influenced artists. During the 2000s, a number of acts explored new wave and post-punk influences and were sometimes labeled "new wave of new wave".

The catch-all nature of new wave music has been a source of much confusion and controversy. The 1985 discography "Who's New Wave in Music" listed artists in over 130 separate categories. The "New Rolling Stone Encyclopedia of Rock" calls the term "virtually meaningless".

New wave first emerged as a rock genre in the early 1970s, used by critics including Nick Kent and Dave Marsh to classify such New York-based groups as the Velvet Underground and New York Dolls. It gained currency beginning in 1976 when it appeared in U.K. punk fanzines such as "Sniffin' Glue" and newsagent music weeklies such as "Melody Maker" and "New Musical Express". In November 1976, Caroline Coon used Malcolm McLaren's term "new wave" to designate music by bands not exactly punk, but related to the same musical scene. The term was also used in that sense by music journalist Charles Shaar Murray in his comments about the Boomtown Rats. For a period of time in 1976 and 1977, the terms "new wave" and "punk" were somewhat interchangeable. By the end of 1977, "new wave" had replaced "punk" as the definition for new underground music in the U.K.

In the United States, Sire Records chairman Seymour Stein, believing that the term "punk" would mean poor sales for Sire's acts who had frequently played the New York club CBGB, launched a "Don't Call It Punk" campaign designed to replace the term with "new wave". As radio consultants in the United States had advised their clients that punk rock was a fad, they settled on the new term. Like the filmmakers of the French new wave movement (after whom the genre was named), new wave artists were anti-corporate and experimental (e.g. Ramones and Talking Heads). At first, most U.S. writers used the term "new wave" exclusively in reference to British punk acts. Starting in December 1976, "The New York Rocker", which was suspicious of the term "punk", became the first American journal to enthusiastically use the term, starting with British acts and later appropriating it to acts associated with the CBGB scene. Part of what attracted Stein and others to new wave was the music's stripped-back style and upbeat tempos, which they viewed as a much-needed return to the energetic rush of rock and roll and 1960s rock that had dwindled in the 1970s with the ascendance of overblown progressive rock and stadium spectacles.

Music historian Vernon Joynson claimed that new wave emerged in the U.K. in late 1976, when many bands began disassociating themselves from punk. Music that followed the anarchic garage band ethos of the Sex Pistols was distinguished as "punk", while music that tended toward experimentation, lyrical complexity or more polished production came to be categorized as "new wave". 

In the U.S., many of the first New Wave groups were the not-so-punk acts associated with CBGB (e.g. Talking Heads, Mink DeVille and Blondie), as well as the proto-punk scene in Ohio, which included Devo, the electric eels, Rocket from the Tombs and Pere Ubu. Some important bands, such as Suicide and the Modern Lovers, debuted even earlier.

CBGB owner Hilly Kristal, referring to the first show of the band Television at his club in March 1974, said, "I think of that as the beginning of new wave." Furthermore, many artists who would have originally been classified as punk were also termed new wave. A 1977 Phonogram Records compilation album of the same name ("New Wave") features American artists including the Dead Boys, Ramones, Talking Heads and the Runaways.

New wave is much more closely tied to punk, and came and went more quickly in the United Kingdom (and in the rest of Western Europe) than in the United States. At the time punk began, it was a major phenomenon in the United Kingdom and a minor one in the United States. Thus when new wave acts started getting noticed in America, punk meant little to the mainstream audience and it was common for rock clubs and discos to play British dance mixes and videos between live sets by American guitar acts.

Post-punk music developments in the UK became mainstream and were considered unique cultural events. By the early 1980s, British journalists largely had abandoned the term "new wave" in favor of subgenre terms such as "synthpop". By 1983, the term of choice for the U.S. music industry had become "new music", while to the majority of American fans it was still a "new wave" reacting to album-based rock.

New wave died out in the mid-1980s, knocked out by guitar-driven rock reacting against new wave.

In the 21st-century United States, "new wave" was used to describe artists such as Morrissey, Duran Duran, Cyndi Lauper and Devo. Late 1970s new wave acts such as the Pretenders and the Cars were more likely to be found on classic rock playlists than on new wave playlists there. Reflecting its British origins, the 2004 study "Popular Music Genres: An Introduction" had one paragraph dedicated to 1970s new wave artists in its punk chapter in contrast to a 20-page chapter on early 1980s synthpop.

New wave represented a break from the blues and rock & roll sounds of late 1960s to mid-1970s music. According to Simon Reynolds, the music had a twitchy, agitated feel. New wave musicians often played choppy rhythm guitars with fast tempos, and keyboards were common, as were stop-start song structures and melodies. Reynolds noted that new wave vocalists sounded high-pitched, geeky and suburban. A nervous, nerdy persona was a common characteristic of new wave fans as well as acts such as Talking Heads, Devo and Elvis Costello. This took the forms of robotic dancing, jittery high-pitched vocals and clothing fashions such as suits and big glasses that hid the body.
This seemed radical to audiences accustomed to post-counterculture forms such as disco dancing and macho "cock rock" that had emphasized a "hang loose" philosophy, open sexuality and sexual bravado. The majority of American male new wave acts of the late 1970s were from Caucasian middle-class backgrounds, and Theo Cateforis of Syracuse University theorized that these acts intentionally presented these exaggerated nerdy tendencies associated with their "whiteness" to criticize it and/or to reflect their identity.

The British pub rock scene of the mid-1970s was the source of new wave acts such as Ian Dury, Nick Lowe, Eddie and the Hot Rods and Dr. Feelgood.

Singer-songwriters who were "angry" and "intelligent" and who "approached pop music with the sardonic attitude and tense, aggressive energy of punk" such as Elvis Costello, Joe Jackson and Graham Parker were also part of the new wave music scene.

A British revival of ska music on the 2 Tone label, led by the Specials, Madness, the English Beat and the Selecter were more politically oriented than other new wave genres.

The idea of rock music as a serious art form started in the late 1960s and was the dominant view of the genre at the time of new wave's arrival. New wave looked back or borrowed in various ways from the years just prior to this occurrence. One way this was done was by taking an ironic look at consumer and pop culture of the 1950s and early 1960s. The B-52's became most noted for a kitsch and camp presentation with their bouffant wigs and beach party and sci-fi movie references. Other groups that referenced the pre-progressive rock era were the Go-Go's, Blondie and Devo.

In the early 1980s, new wave acts embraced a crossover of rock music with African and African-American styles. Adam and the Ants and Bow Wow Wow, both acts with ties to former Sex Pistols manager Malcolm McLaren, used Burundi-style drumming. The Talking Heads album "Remain in Light" was marketed and positively reviewed as a breakthrough melding of new wave and African styles, although drummer Chris Frantz said that he found out about this supposed African influence after the fact. The 1981 U.S. number-one single "Rapture" by Blondie was an homage to rap music. The song name-checked rap artists and Fab 5 Freddie appeared in the song's video. Second British Invasion acts were influenced by funk and disco.

Power pop continued the guitar-based, singles-oriented British invasion sound of the mid-1960s into the 1970s and the present day. Although the term "power pop" had been around before punk (it is believed to have been coined by Pete Townshend in 1967), it became widely associated with new wave when "Bomp" and "Trouser Press" magazines (in March and April 1978, respectively) wrote cover stories touting power pop as a sound that could continue new wave's directness without the negativity associated with punk. Cheap Trick, the Romantics, the Records, Shoes, the Motors, the Only Ones, the Plimsouls, the dB's, the Beat, XTC, the Vapors, 20/20 and Squeeze were groups that found success playing this style. The Jam was the prime example of the mod sensibility of British power pop. By the end of 1979, a backlash had developed against power pop in general, particularly in regard to the Los Angeles scene. The skinny ties worn by L.A. power pop groups, epitomized by the Knack, became symbolic of the supposed lack of authenticity of the genre. Power pop's association with the genre was later forgotten.

The term "post-punk" was coined to describe groups such as Siouxsie and the Banshees, Wire, Magazine, Public Image Ltd, Joy Division, Gang of Four, the Fall, The Cure, the Psychedelic Furs and Echo and the Bunnymen, acts who were initially considered part of new wave but were more ambitious, serious and challenging, as well as being darker and less pop-oriented. Some of these groups would later adopt synths. While punk rock wielded a major influence on the popular music scene in the U.K., in the U.S. it remained a fixture of the underground.

The New Romantic scene developed in the London nightclubs Billy's and the Blitz in the late 1970s. Clubgoers wore flamboyant, eccentric costumes and makeup derived from the historical Romantic era. Beginning with David Bowie/Roxy Music-themed nights at these clubs, the scene was spearheaded by Steve Strange of Visage, with other soon-to-be pop acts also as regular fixtures, such as Boy George of Culture Club, and Spandau Ballet. Around the same time, Duran Duran emerged from a similar scene in Birmingham. Many of the acts that arose from the New Romantic club scene adopted synthpop in their own music, though all would credit Bowie and Roxy Music as primary influences, both musically and visually.

Kraftwerk were acclaimed for their groundbreaking use of synthesizers. Their 1975 pop single "Autobahn" reached number 11 in the United Kingdom. In 1978, Gary Numan saw a synthesizer left by another music act and started playing around with it. In 1979, he released two number-one albums and two number-one singles (one of each under his band name, Tubeway Army). Numan's admitted amateurism and deliberate lack of emotion was a sea change from the masculine and professional image that professional synth players had in an era when elaborate, lengthy solos were the norm. Numan's open desire to be a pop star broke from punk orthodoxy. The decreasing price and increasing ease of use of the synthesizer led acts to follow in Kraftwerk's and Numan's footsteps. While Numan also utilized conventional rock instruments, several acts that followed used only synthesizers. Synthpop (or "technopop" as it was described by the U.S. press) filled a void left by disco, and grew into a broad genre that included groups such as the Human League, Eurythmics, Dead or Alive, Depeche Mode, Soft Cell, a-ha, Alphaville, New Order, Orchestral Manoeuvres in the Dark, Japan, Yazoo, Talk Talk Ultravox, Kajagoogoo, Tears for Fears, China Crisis, Simple Minds, Duran Duran, A Flock of Seagulls and the Thompson Twins.

An African-American "new wave" of sorts also arose in the United States in the late 1970s and early 1980s, driven, as AllMusic points out, by "drum machines, synthesizers and programming [becoming] common studio tools." Following the musically stripped-down approach of Stevie Wonder and Parliament-Funkadelic, post-disco explored a more electronic and experimental side of African-American music by incorporating an eclectic range of styles, e.g. Jamaican music, electronic art music, jazz, blues and, in the latter years, European and Japanese synthesizer music. 

Stretching the boundaries of disco music, post-disco took many forms, some entirely R&B-based (NYC boogie), some post-punk–based (alternative dance), underground club culture-centered (Chicago house with its own style of dance called jacking) and futurism–leaning (Detroit techno). Embracing new wave music (synth-pop) proper was proven to be influential, as Afrika Bambaataa ("Renegades of Funk") and Arthur Baker point out, on both underground and mainstream black dance music (electro, dance-rock, Minneapolis sound).

In the summer of 1977 both "Time" and "Newsweek" wrote favorable lead stories on the "punk/new wave" movement.<ref name="punk/newwave">[ Genre Punk/New Wave Allmusic]</ref> Acts associated with the movement received little or no radio airplay or music industry support. Small scenes developed in major cities. Continuing into the next year, public support remained limited to select elements of the artistic, bohemian and intellectual population, as arena rock and disco dominated the charts.

Starting in late 1978 and continuing into 1979, acts associated with punk and acts that mixed punk with other genres began to make chart appearances and receive airplay on rock stations and rock discos. Blondie, Talking Heads, the Police and the Cars charted during this period. "My Sharona", a single from the Knack, was "Billboard" magazine's number one single of 1979. The success of "My Sharona", combined with the fact that new wave albums were much cheaper to produce during a time when the music industry was in its worst slump in decades, prompted record companies to sign new wave groups. New wave music scenes developed in Ohio and the college town of Athens, Georgia, with legendary bands such as the B-52s and R.E.M.. 1980 saw brief forays into new wave-styled music by non-new wave artists Billy Joel, Donna Summer and Linda Ronstadt.

Early in 1980, influential radio consultant Lee Abrams wrote a memo saying that, with a few exceptions, "we're not going to be seeing many of the new wave circuit acts happening very big over here (referring to America). As a movement, we don't expect it to have much influence." Lee Ferguson, a consultant to KWST, said in an interview that Los Angeles radio stations were banning disc jockeys from using the term and noted, "Most of the people who call music new wave are the ones looking for a way not to play it." Despite the success of Devo's socially critical but widely misperceived song "Whip It", second albums by artists who had successful debut albums, along with newly signed artists, failed to sell, and radio pulled most new wave programming.

The arrival of MTV in 1981 would usher in new wave's most successful era in the United States. British artists, unlike many of their American counterparts, had learned how to use the music video early on. Several British acts on independent labels were able to outmarket and outsell American artists on major labels. Journalists labeled this phenomenon a "Second British Invasion". MTV continued its heavy rotation of videos by new wave-oriented acts until 1987, when it changed to a heavy metal and rock dominated format.

In a December 1982 Gallup poll, 14% of teenagers rated new wave as their favorite type of music, making it the third most popular. New wave had its greatest popularity on the West Coast. Unlike other genres, race was not a factor in the popularity of new wave music, according to the poll. Urban Contemporary radio stations were the first to play dance-oriented new wave artists such as the B-52's, Culture Club, Duran Duran and ABC.

New wave soundtracks were used in mainstream Brat Pack films such as "Valley Girl", "Sixteen Candles", "Pretty in Pink" and "The Breakfast Club". John Hughes, the director of several of these films, was enthralled with British new wave music and placed songs from acts such as the Psychedelic Furs, Simple Minds, Orchestral Manoeuvres in the Dark and Echo and the Bunnymen in his films, helping to keep new wave in the mainstream. Several of these songs remain standards of the era. Critics described the MTV acts of the period as shallow or vapid. The homophobic slurs "faggot" and "art fag" were openly used to describe new wave musicians. Despite the criticism, the danceable quality of the music and the quirky fashion sense associated with new wave artists appealed to audiences.

In September 1988, "Billboard" launched its Modern Rock chart. While the acts on the chart reflected a wide variety of stylistic influences, new wave's legacy remained in the large influx of acts from Great Britain and acts that were popular in rock discos, as well as the chart's name, which reflected how new wave had been marketed as "modern". New wave's indie spirit would be crucial to the development of college rock and grunge/alternative rock in the latter half of the 1980s and beyond.

In the aftermath of grunge, the British music press launched a campaign to promote the new wave of new wave. This campaign involved overtly punk and new wave-influenced acts such as Elastica, but it was eclipsed by Britpop. Other acts of note during the 1990s included No Doubt, Metric, Six Finger Satellite and Brainiac. During that decade, the synthesizer-heavy dance sounds of British and European new wave acts influenced various incarnations of Euro disco and trance. Chris Martin was inspired to start Coldplay by a-ha.

During the 2000s, a number of acts emerged that mined a diversity of new wave and post-punk influences. Among these were the Strokes, the Bravery, Interpol, Yeah Yeah Yeahs, Franz Ferdinand, the Epoxies, VHS or Beta, the Rapture, She Wants Revenge, Bloc Party, Foals, Kaiser Chiefs and the Killers. These acts were sometimes labeled "New New Wave". The new wave revival reached its apex during the mid-2000s with acts such as the Sounds, the Ting Tings, Melody Club, Hot Chip, Passion Pit, the Presets, La Roux, Ladytron, Shiny Toy Guns, Hockey, Gwen Stefani and Ladyhawke. While some journalists and fans regarded this as a revival, others argued that the phenomenon was a continuation of the original movements.

The Drums are an example of the trend in the U.S. indie pop scene that employs both the sounds and attitudes of the British new wave era. A new wave-influenced genre called chillwave also developed in the late 2000s, exemplified by artists like Toro Y Moi, Neon Indian, Twin Shadow and Washed Out.

New wave had a seminal role in the development and popularity of contemporary electronic music.

During the late 1990s, new wave received a sudden surge of attention when it was fused with electro and techno during the short-lived electroclash movement. It received popular attention from musical acts such as I-F, Peaches, Fischerspooner and Vitalic, but largely faded when it combined with tech house to form the electro house genre.

During the mid 2000s, new rave combined new wave with elements from several other genres, such as indie rock and electro house, and added aesthetic elements archetypal of a rave, such as light shows and glow sticks. Despite the term itself stimulating controversy to the point where many affiliated artists rejected it, new rave as a musical genre was adopted by artists such as the Klaxons, NYPC, Shitdisco and Hadouken!

In the 2010s, nostalgia for 1980s new wave saw a resurgence in the form of synthwave, which is primarily characterized by new wave, soundtrack influences and a retrofuturistic, cyberpunk-like visual aesthetic. This term is applied to the music of artists such as Kavinsky, College, Power Glove, Mitch Murder and , as well as to soundtracks of films and video games such as "Drive", "", "Hotline Miami", "Kung Fury", "Turbo Kid" and "".






</doc>
<doc id="21160" url="https://en.wikipedia.org/wiki?curid=21160" title="Telecommunications in the Netherlands">
Telecommunications in the Netherlands

Communications in the Netherlands.

The postal service in the Netherlands is performed by PostNL in most cases—which has, as of 2008, a monopoly on letters lighter than 50 g. The monopoly is planned to expire in 2009. PostNL's competitors include Selekt Mail and Sandd. Post offices that are owned by Postbank and TNT Post have been earmarked for closure between 2008 and 2013.

Postal codes in the Netherlands are formed of four digits then two letters (in capitals), separated by a space—1234 AB, for example.

Telephones - main lines in use:
8.000.000 (2007)

Telephones - mobile cellular subscribers:
17.200.000 (2007)

Telephone system:
general assessment: highly developed and well maintained

domestic: extensive fixed-line fiber-optic network; cellular telephone system is one of the largest in Europe with three major network operators utilizing the third generation of the Global System for Mobile Communications (GSM).

"international:"
9 submarine cables; satellite earth stations - 3 Intelsat (1 Indian Ocean and 2 Atlantic Ocean), 1 Eutelsat, and 1 Inmarsat (Atlantic and Indian Ocean regions) (2004)


"Starting with"

Radio broadcast stations:
AM 4, FM 58, shortwave 3 (1998)
Radios:
15.3 million (1996)

Television broadcast stations:
25

Televisions:
6.700.000 (2002, CBS)
Internet Service Providers (ISPs):
33 (2007)

Country code (Top level domain): .nl




</doc>
<doc id="21161" url="https://en.wikipedia.org/wiki?curid=21161" title="Transport in the Netherlands">
Transport in the Netherlands

The Netherlands is both a very densely populated and a highly developed country, in which transport is a key factor of the economy. Correspondingly it has a very dense and modern infrastructure, facilitating transport with road, rail, air and water networks. In its Global Competitiveness Report for 2014-2015, the World Economic Forum ranked the Dutch transport infrastructure fourth in the world.

With a total road network of 139,000 km, including 3,530 km of expressways, the Netherlands has one of the densest road networks in the world; much denser than Germany and France, but still not as dense as Belgium. The Dutch also have a well developed railway network, that connects most major towns and cities, as well as a comprehensive dedicated cycling infrastructure, featuring some 35,000 km of track physically segregated from motorised traffic.
The port of Rotterdam is the world's largest seaport outside East Asia, and by far the largest port of Europe. It connects with its hinterland in Germany, Switzerland and France through rivers Rhine and Meuse. Two thirds of all inland water freight shipping within the EU, and 40% of containers, pass through the Netherlands.

Mobility in the Netherlands is considerable. On the roads it has grown continuously since the 1950s and now exceeds 200 billion km travelled per year, three quarters of which are done by car. Around half of all trips in the Netherlands are made by car, 25% by bicycle, 20% walking, and 5% by public transport. Additionally, Dutch airports handled at least 70 million passengers in 2016. Excluding air travel, the Dutch journey more than 30 km a day on average, which takes them just over an hour.
In 2010, 1.65 billion tons of goods traffic was registered, half of which moved by sea and inland shipping, and 40% by road transport. The remainder was mostly by pipelines; rail transport only handles 2% of freight movements through the Netherlands.

With 139,000 km of public roads, the Netherlands has one of the most dense road networks in the world - much denser than Germany and France, but still not as dense as Belgium. In 2013, 5,191 km were national roads, 7,778 km were provincial roads, and 125,230 km were municipality and other roads.
Dutch roads include 3,530 km of motorways and expressways, and with a motorway density of 64 kilometres per 1,000 km², the country also has one of the densest motorway networks in the world.
The Netherlands' main highway network ("hoofdwegennet") - comparable to Britain's network of trunk roads - consists of most of its 5,200 km of national roads, supplemented with the most prominent provincial roads. Although only about 2,500 km are fully constructed to motorway standards, much of the remainder are also expressways for fast motor vehicles only.
Mobility on Dutch roads has grown continuously since the 1950s and now exceeds 200 billion km travelled per year, three quarters of which are done by car, meaning that while Dutch roads are numerous, they are also used more intensely than in almost any other country. Car ownership in the Netherlands is high but not exceptional, and slightly lower than in surrounding countries. Goods vehicles account for 20% of total traffic.

The busiest Dutch motorway is the A13 between The Hague and Rotterdam, with a traffic volume of 140,000 motor vehicles per day. The widest Dutch motorway is the A15/A16 just south of Rotterdam with 16 lanes in a 4+4+4+4 setup.

Traffic congestion is common in the Netherlands. The high population density generates significant traffic volumes on both motorways and regular highways. Most congestion occurs in the Randstad, but congestion is a daily structural problem around many larger cities. The Netherlands tries to counter this with an advanced motorway network, with Variable Message Signs and electronic signalization across most of the network. The number of passing motorised vehicles is counted every minute of the day at some 20,000 measuring stations on the Dutch motorway network. A special feature of the motorways is the use of Porous Asphalt Concrete, which reduces noise levels, and allows rain water to be drained efficiently, for safety and expedient traffic flow under precipitation.

Cycling is a ubiquitous mode of transport in the Netherlands. 27% of all trips are by bicycle - the highest modal share of any country in the world. Moreover: 36% of the Dutch list the bike as their most frequent mode of transport on a typical day. Some 85% of the people own at least one bicycle. All in all the Dutch are estimated to have at least 18 million functioning bikes, which makes more than one per capita, and much more than the 11.3 million motor vehicles registered on the road. Almost as many passenger kilometres are covered by bicycle as by train.

Cycling infrastructure is comprehensive, and public policy, urban planning & laws are bike-friendly. Most roads except for motorways support cyclists, and bikeways are clearly signposted, well maintained and well lit. Dedicated cycle tracks are common on busy roads - some 35,000 km of track has been physically segregated from motor traffic, equal to a quarter of the country's entire road network. Busy junctions often give priority to cyclists, or they are equipped with cycle-specific traffic lights.<br>
There are large bicycle parking facilities, particularly in city centres and at train stations. Since the start of the 21st century, parking spaces for 450,000 bicycles were built and modernized at over 400 train stations, and Dutch railways organizations ProRail and NS are calling for an expansion by another 250,000 by 2027. Already half of all Dutch train travelers cycle to the railway station, amounting to half a million cyclists daily.

In 2013, the European Cyclists' Federation ranked the Netherlands, together with Denmark as the most bike-friendly country in Europe. <br>
Helmets are neither officially encouraged nor frequently worn.

Most distance travelled on Dutch public transport goes by rail. Like many other European countries, the Netherlands has a dense railway network, totalling between and of track, or 3,013 "route" km, three quarters of which has been electrified. The network is mostly focused on passenger transport and connects almost all major towns and cities, counting just over 400 train stations, more than there are municipalities in the Netherlands. The national rail infrastructure is managed by public task company ProRail, and a number of different operators have concessions to run their trains. ProRail also coordinates the totality of scheduling and proper meshing of the Dutch railway services.

Public passenger rail transport is operated mainly by Nederlandse Spoorwegen (NS) ("Dutch Railways"); minor parts by Arriva, Keolis Nederland, Connexxion, Breng, DB Regio, NMBS, Veolia and DB Regionalbahn Westfalen. During week days all railway stations are serviced at least twice an hour in each direction. Large parts of the network are serviced by two to four trains per hour on average. Heavily used routes can be serviced by 8 to 16 trains an hour.

In recent years, the four largest railway stations in the Netherlands, the central stations of each of the largest cities: Amsterdam, Rotterdam, The Hague and Utrecht, have all entered into major reconstruction and expansion. Rotterdam Central station was completely rebuilt, and was the first to complete, reopening in March 2014.
The Hague Central station and Utrecht Central station were reopened, after extensive reconstructions, in February and December 2016, respectively.
Amsterdam Central station has been undergoing a string of reconstruction works that started in 1997, and is yet to complete.

In 2015 a consultancy comparison of Europe's railway systems found the Dutch network the most cost effective for its performance, together with Finland's. Per kilometre of track, the Dutch rail network is the busiest in the European Union, handling over a million passengers a day. For 2019 some 2.2 million train journeys are scheduled to travel a record number of 165 million "train" kilometres (103 million train miles) — a growth of 28%, up from 124 million km in 2004. Until 2030 ProRail projects a further growth of "passenger" kilometres by another 45 percent. For 2019, also 8 percent more freight trains are scheduled than in 2018.

On the initiative of two European parties: RailNetEurope and Forum Train Europe, a project called "Redesign of the International Timetabling Process (TTR)" should help to harmonise planning freight- and passenger trains across Europe, to optimize usage of existing rail tracks. Currently, almost all freight trains (96%) deviate from their original schedule, due to the dynamic nature of cargo transport. The new TTR must facilitate ProRail to let unscheduled freight trains run more easily, without requiring complex shifting in the regular passenger train timetables. Furthermore, as of 2020, timetables will be detailed to tenths of minutes (six second units), instead of whole minutes, to further optimise planning.

In the long term, significant capacity gains could only be achieved by adding more rail tracks, but there is virtually no more available space, "or" transforming large portions of the Dutch railway system to run more like a metro / subway system, which could support up to 24 to 30 trains per hour on the busiest lines. This would however require a structural disentanglement of the current reality, in which trains, train drivers and conductors all have their own work schedules, following the Japanese model. However, at the moment there are no real plans for such steps.

For longer distances the main public transport in the Netherlands is the train. Long-distance buses are limited to a few missing railway connections. Regional / rural public transport, serving small(er) towns is by bus. Local / urban public transport is also generally by bus, but the three largest cities (Amsterdam, Rotterdam and The Hague) all have extensive tram systems, that in each case also connect with adjacent cities in their respective urban agglomerations.<br>
In addition, Amsterdam and Rotterdam also have several metro lines. Amsterdam's subway was expanded by a new ""North-South"" line in July 2018, after 15 years of construction, costing € 3.1 Billion.

Additionally, Rotterdam, The Hague and suburbs in between are connected by a light rail system called RandstadRail, and one line of the Rotterdam metro system connects all the way to The Hague Central station. Utrecht has its own light rail system, called fast tram, connecting the city with adjacent Nieuwegein and IJsselstein. Arnhem is the only Dutch city that still operates a trolleybus system.

Due to the large amount of waterways in the Netherlands, not every road connection has been bridged, and there are still some ferries in operation. In the Rotterdam and "-Drecht" towns region, a water bus public transport service operates as well.

Public transport operators are both the public transport companies run by the local government of the cities: GVB (Amsterdam), RET (Rotterdam) and HTM (The Hague), as well as private enterprise companies like Arriva, Connexxion, Qbuzz and Keolis Nederland.

Amsterdam Airport Schiphol, located southwest of Amsterdam, is the main international airport in the Netherlands, and the third busiest airport in Europe in terms of passengers. Moreover, offering direct flights to 326 destination airports around the planet, Schiphol is the world's second best connected airport.

Schiphol is the primary hub for Dutch flag carrier airline KLM and its regional affiliate KLM Cityhopper, as well as for other Dutch airlines Corendon Dutch Airlines, Martinair, Transavia and TUI Airlines Netherlands. The airport also serves as a European hub for Delta Air Lines, and as a base for EasyJet and Vueling airlines.
According to Schiphol's preliminary data, the airport handled 63.6 million passengers in 2016, a growth of 9.1% over 2015. Opened in 1916 as a military airbase, Schiphol saw 479,000 flights in 2016, and airfreight tonnage increased by 1.8% to 1.7 million metric tons.

In other regions there are much smaller international airports, the most prominent being Eindhoven Airport, Rotterdam The Hague Airport, Maastricht Aachen Airport and Groningen Airport. The airports of Eindhoven and Rotterdam / The Hague are both part of the Schiphol Group, and both experienced growth in 2016. Eindhoven Airport grew by 9.3% to 4.7 million passengers, whereas Rotterdam The Hague Airport's growth was a modest 0.2%, reaching 1.6 million travellers in 2016.
On Maastricht Aachen, and Groningen airports, a considerable share of flights is seasonal in nature. For transport within the country, air travel is hardly used.

Based on Schiphol Group's preliminary data, its airports alone handled a total of 70 million passengers in 2016.
In 2015 Dutch airports handled passengers at a ratio of 47 million on European flights versus 18 million on intercontinental flights, and in 2013 a slightly less 1.6 million metric tons of airfreight.

The Netherlands has thirteen seaports, three of which have international significance. Handling 440 million metric tons of cargo in 2013, the port of Rotterdam is the biggest port of Europe – as big as the next three biggest combined, and the eighth largest in the world. The Amsterdam seaport is the second in the country, and the fifth largest in Europe. Additionally, since 1998 the ports of Vlissingen and Terneuzen are working as one, under the name of Zeeland Seaports. Handling 34 million metric tons of cargo in 2012, this is now the third biggest Dutch seaport. For comparison: the nearby port of London handled 44 million tons in that year.
Through the rivers Rhine and Meuse, Rotterdam has excellent access to its hinterland upstream, reaching to Germany, France and Switzerland. The port's main activities are petrochemical industries and general cargo handling and transshipment. The harbour functions as an important transit point for bulk materials and between the European continent and overseas. From Rotterdam goods are transported by ship, river barge, train or road. In 2007, the Betuweroute, a new fast freight railway from Rotterdam to Germany, was completed.

Three Dutch ports are deepwater ports, that can handle fully laden Panamax ships: Rotterdam, Zeeland Seaports and the port of IJmuiden. Besides Rotterdam, Amsterdam and Zeeland, the ports of Moerdijk and Vlaardingen also support container liner shipping. Other notable port cities are Dordrecht, Haarlem and Den Helder, as well as Groningen, which controls the seaports of Delfzijl and Eemshaven. Den Helder is home to the Netherlands' main naval base.


"note:" many Dutch-owned ships are also operating under the ship registry of Netherlands Antilles (1998 est.)

6,237 km of rivers and canals are navigable for ships of 50 tons. Some 3,740 km of this consists of canals.
At least 4,326 km of waterways are usable by craft up to 400 metric ton capacity, and over 3,000 km are usable by ships up to 1,250 metric ton capacity. Although another source states that all of 6,230 km is navigable for craft up to 400 tons, and over 4,000 km is usable by ships up to 1,500 metric ton capacity.
The Dutch inland shipping fleet is the biggest in Europe. Consisting of some 7,000 vessels, it takes a share of 35% of the national total annual freight transport, and as much as 80% of bulk transport. Also two thirds of all inland water freight transports within the EU, and 40% of the EU's inland container shipping, pass through the Netherlands. All in all the Netherlands has so many waterways that virtually all major industrial areas and population centres can be reached by water via inland ports (200) and transhipment terminals (350).

pipeline transport:

The distribution network for natural gas is the most dense in Europe and of very high quality, with a total length of 12,200 kilometres of transmission pipelines and 136,400 kilometres of distribution pipelines. A technical investigation has concluded that the existing Dutch high-pressure gas infrastructure could feasibly be converted for transport of hydrogen in the future.

Transport in the Netherlands falls under the Ministry of Infrastructure and Water Management. With regard to public transport, not involving national rail, a total of 14 public bodies have been delegated the authority to grant concessions to public transport operators, namely the twelve provinces, plus the two transport-regions specifically for Amsterdam and Rotterdam / The Hague. These 14 parties are united in a cooperation called "DOVA" ("Decentrale Openbaar Vervoer Autoriteiten"), or "Decentralised Public Transport Authorities". The provinces in turn sometimes delegate this authority to their municipalities.

Roads are controlled by authorities at all four administrative levels in the Netherlands. About 5,200 km of national roads ("Rijkswegen") are controlled by central national government agency Rijkswaterstaat, and the country's twelve provinces manage about 7,800 km of provincial roads. Most motorways are national roads, and the remaining national roads are mostly expressways. Only a few motorways are provincial ones, and they are much shorter and serve mostly regional traffic. Frequently, they were previously national roads.

Municipality roads make up the bulk of the network, totalling some 120,000 km. They are mostly local roads. Aside from the division in provinces, the Netherlands is also divided in 21 water management boards. Together with miscellaneous authorities, they own and control another 7,500 km of roads. For some roads, it is because they are a physical element of water barriers, like dikes and dams while others provide primary access to critical water control structures and may not even be open to the public.

Although transport economics is much more than just the economy of the transport sector itself, the latter is much easier to quantify. In 2012 the Dutch goods transport and storage sectors by themselves accounted for almost 400,000 full-time jobs, employing some 500,000 people. Gross revenues totalled 77 billion euro, leading to results of 4.3 billion euro.




</doc>
<doc id="21162" url="https://en.wikipedia.org/wiki?curid=21162" title="Armed forces of the Netherlands">
Armed forces of the Netherlands

The Armed forces of the Netherlands consist of the Army, Navy, and Air Force.

The service branches consist of:

In addition, within the Kingdom of the Netherlands, there are small local conscript forces on the islands of Aruba (Arumil) and Curaçao (Antmil). These operate under the auspices of the Royal Netherlands Navy and Marines.

The military ranks of the Dutch armed forces have similarities with British and U.S. military ranks. The highest-ranking officer in the Dutch military is the Chief of Defence (Netherlands), who is a four-star officer (NATO OF-9).

The Dutch armed forces exist by declaration in the constitution of the Netherlands. Article 97 of this constitution determines that the armed forces exist

This means that the role and responsibility of the Dutch military in international stability and peacekeeping is constitutionally determined.

The same article of the constitution determines that supreme command of the Dutch military resides with the Government of the Netherlands. This has been the case since the constitution was changed in 1983; before then, supreme command of the armed forces of the Netherlands was held by the King of the Netherlands.

In addition, a second major change in military affairs was made in 2003. Before then, all citizens of the Netherlands were tasked with the defense of the kingdom. In keeping with the move to a professional military, this article was dropped.

The Netherlands' military is currently a fully professional military. Conscription in the Netherlands was suspended in 1996 with the exception of Aruba and Curaçao. All military branches and specialties are open to female recruits. In October 2018 the Dutch Ministry of Defence announced that the submarine service will also accept female recruits for positions as officer, NCO and sailor.

The Dutch Ministry of Defence employs over 61,000 personnel, including both civilian and military personnel.

The Dutch military is part of the NATO militaries and therefore conforms to the structure of a NATO military. It also uses conforming rank structures.
All Dutch military personnel, officers and enlisted personnel, are required to take an oath of allegiance. This oath is recorded in the law on General Military Personnel Regulations (Algemeen Militair Ambtenarenregelement) in Article 126a.

Unlike many military organizations, Dutch military members are allowed to form and join unions.

There are four of these unions:

All unions represent both current and retired military personnel and/or civilian personnel.

Since the 1990s, the Dutch military has been involved in four major military campaigns:

As part of Operation Enduring Freedom as a response to those attacks, the Netherlands deployed aircraft as part of the European Participating Air Force (EPAF) in support of ground operations in Afghanistan as well as Dutch naval frigates to police the waters of the Middle East/Indian Ocean. The Netherlands deployed further troops and helicopters to Afghanistan in 2006 as part of a new security operation in the south of the country. Dutch ground and air forces totalled almost 2,000 personnel during 2006, taking part in combat operations alongside British and Canadian forces as part of NATO's ISAF force in the south.

The Netherlands announced in December 2007 that it would begin withdrawing its troops from Afghanistan, which were mainly in Uruzgan Province, in July 2010. "I do not have assurances that other countries will be ready to replace Netherlands troops, but I am certain that Dutch troops will leave in 2010," Foreign Minister Maxime Verhagen said. "I indicated that in writing ... to the NATO secretary general, who has confirmed it." In January 2009, Prime Minister Jan Peter Balkenende reiterated that the 1,600 Dutch troops in Afghanistan would end their mission in 2010, saying "We will stop in Uruzgan in 2010." He ruled out the possibility of the Netherlands keeping its troops in Afghanistan past 2010 with any force comparable to its former deployment.

In December 2009, reacting to three requests received from the side of the U.S. by Vice President Biden, the special American representative to Afghanistan Holbrooke and Secretary of State Clinton and a request by Secretary General of NATO Rasmussen as well, the Dutch government announced that the final decision on the continuation of the mission in Uruzgan would be on its agenda in March 2010. Two ministers from the Labour Party (PvdA), Koenders (Development Aid) and Bos (Finance and Vice PM) in the meantime pleaded termination, which was also the opinion of the majority of the Dutch parliament.

On 10 December 2009, the Dutch daily newspaper De Telegraaf reported that the government was exploring areas elsewhere in Afghanistan to set up a new mission. The northern province of Kunduz was mentioned, where at the moment German and Belgian troops were deployed. On 9 December, allegedly PM Balkenende (CDA), the vice-PM's Bos (PvdA) and Rouvoet (ChristenUnie) and the three involved ministers Verhagen (CDA, Foreign Affairs), Van Middelkoop (ChristenUnie, Defense) and Koenders (PvdA, (Development Aid) secretly discussed the future Dutch engagement in Afghanistan, together with Commander of the Forces general Van Uhm.

In early February 2010, the disagreement between the PvdA on the one hand and CDA and ChristenUnie on the other about a request from NATO, by improper channels, for a renewed Dutch commitment in Afghanistan, came to a head. CDA and ChristenUnie wanted the freedom to consider this request—in spite of the decisions by the Minister of Defence and the votes in Parliament—whereas PvdA and a majority of the parties in the Dutch parliament stood by the earlier decision and refused any consideration of further Dutch involvement in Afghanistan. Thus, on 20 February, the PvdA had no choice but to resign their ministers from the Cabinet, leading to a collapse of the Dutch government. As a result, the NATO request could not be considered and Dutch troops withdrew later in 2010 according to the schedule agreed in 2007.

On 1 August 2010 the Dutch military formally declared its withdrawal from its four-year mission in Afghanistan; most soldiers are expected to be back in the Netherlands by September, excepting those working on the reset, redistribution and repatriation of materiel and supplies. The AH-64 Apache and F-16 squadron will remain longer in Afghanistan to support the withdrawal process and transports. The Dutch contingent has been replaced by soldiers from the U.S., Australia, Slovakia, and Singapore.



</doc>
<doc id="21163" url="https://en.wikipedia.org/wiki?curid=21163" title="Foreign relations of the Netherlands">
Foreign relations of the Netherlands

The foreign policy of the Netherlands is based on four basic commitments: to the Atlantic cooperation, to European integration, to international development and to international law. While historically the Kingdom of the Netherlands was a neutral state, since 1945 it has become a member of NATO, the United Nations, the European Union and many other international organizations. The Dutch economy is very open and relies on international trade. During and after the 17th century—its Golden Age--the Dutch built up a commercial and colonial empire. It was a leading shipping and naval power and was often at war with England, its main rival. Its main colonial holding was Indonesia, which fought for and achieved independence after 1945. The historical ties inherited from its colonial past still influence the foreign relations of the Netherlands. Foreign trade policy is handled by the European Union. The Dutch have been active in international peacekeeping roles.

In the Dutch Golden Age, which had its zenith around 1667, there was a flowering of trade, industry, the arts and the sciences. A rich worldwide Dutch empire developed and the Dutch East India Company became one of the earliest and most important of national mercantile companies based on entrepreneurship and trade.

During the 18th century, the power and wealth of the Netherlands declined. A series of wars with the more powerful British and French neighbors weakened it. Britain seized the North American colony of New Amsterdam, turning it into New York. There was growing unrest and conflict between the Orangists and the Patriots. The French Revolution spilled over after 1789, and a pro-French Batavian Republic was established in 1795–1806. Napoleon made it a satellite state, the Kingdom of Holland (1806–1810), and later simply a French imperial province.

In 1815–1940 it was neutral and played a minor role in world diplomacy, apart from a failed effort to control Belgium before giving up in 1839. It was invaded and cruelly treated by Germany in 1940–45, with starvation and killing the Jews the main Nazi policies.

The Dutch Government conducted a review of foreign policy main themes, organization, and funding in 1995. The document "The Foreign Policy of the Netherlands: A Review" outlined the new direction of Dutch foreign policy. The Netherlands prioritizes enhancing European integration, maintaining relations with neighboring states, ensuring European security and stability (mainly through the mechanism of NATO and emphasizing the important role the United States plays in the security of Europe), and participating in conflict management and peacekeeping missions. The foreign policy review also resulted in the reorganization of the Ministry of Foreign Affairs. Through the creation of regional departments, the Ministry coordinates tasks previously divided among the international cooperation, foreign affairs, and economic affairs sections.

Dutch security policy is based primarily on membership in NATO, which the Netherlands co-founded in 1949. Because of Dutch participation in NATO nuclear weapons are stationed in the Netherlands, see Volkel Air Base.

The Dutch also pursue defense cooperation within Europe, both multilaterally – in the context of the Western European Union and the European Security and Defence Policy of the EU – and bilaterally, as in the German-Netherlands Corps. In recent years, the Dutch have become significant contributors to UN peacekeeping efforts around the world as well as to the Stabilization Force in Bosnia and Herzegovina (SFOR) in Bosnia.

The Dutch have been strong advocates of European integration, and most aspects of their foreign, economic, and trade policies are coordinated through the European Union (EU). The Dutch postwar customs union with Belgium and Luxembourg (the Benelux group) paved the way for the formation of the European Community (precursor to the EU), of which the Netherlands was a founding member. Likewise, the Benelux abolition of internal border controls was a model for the wider Schengen Accord, which today has 29 European signatories (including the Netherlands) pledged to common visa policies and free movement of people across common borders.

The Dutch stood at the cradle of the 1992 Maastricht Treaty and have been the architects of the Treaty of Amsterdam concluded in 1998. The Dutch have thus played an important role in European political and monetary integration; indeed, until the year 2003, Dutchman Wim Duisenberg headed the European Central Bank. In addition, Dutch financial minister Gerrit Zalm was the main critic of the violation of the Stability and Growth Pact by France and Germany in 2004 and 2005.

The Netherlands is among the world's leading aid donors, giving almost $8  billion, about 0.8% of its gross national income (GNI) in official development assistance (ODA). It is one of five countries worldwide that meets the longstanding UN ODA target of 0.7% ODA/GNI. The country consistently contributes large amounts of aid through multilateral channels, especially the United Nations Development Programme, the international financial institutions, and EU programs. A large portion of Dutch aid funds also is channeled through private ("co-financing") organizations that have almost total autonomy in choice of projects.

The Netherlands is a member of the European Bank for Reconstruction and Development, which recently initiated economic reforms in central Europe. The Dutch strongly support the Middle East peace process and in 1998 earmarked $29  million in contributions to international donor-coordinated activities for the occupied territories and also for projects in which they worked directly with Palestinian authorities. These projects included improving environmental conditions and support for multilateral programs in cooperation with local non-governmental organizations. In 1998, the Dutch provided significant amounts of aid to the former Yugoslavia and Africa. The Dutch consistently provide significant amounts of humanitarian relief aid to the victims of the worst natural disasters, such as the Hurricane Mitch in Central America in 1998, 2004 Indian Ocean earthquake and tsunami in South and Southeast Asia, the Hurricane Katrina in the United States in 2005, 2010 Haiti earthquake, and more recent catastrophes in Pakistan and Burma including the Typhoon Haiyan in the Philippines in 2013, and 2015 Nepal earthquake.

"Developing countries aspiring to purchase foreign goods and services to invest in, inter alia, port facilities, roads, public transport, health care, or drinking water facilities may be eligible for a special Dutch grant facility. The grant facility, known as ORET (a Dutch acronym for Ontwikkelingsrelevante Exporttransacties, or Development-Related Export) serves to award grants to governments of developing countries for making payments to foreign suppliers."

A centuries-old tradition of legal scholarship has made the Netherlands the home of the International Court of Justice; the Iran-United States Claims Tribunal; the International Criminal Tribunal for the former Yugoslavia; the International Criminal Tribunal for Rwanda; and the International Criminal Court (ICC). In addition it hosts the European police organization, Europol; and the Organisation for the Prohibition of Chemical Weapons.

As a relatively small country, the Netherlands generally pursues its foreign policy interests within the framework of multilateral organizations. The Netherlands is an active and responsible participant in the United Nations system as well as other multilateral organizations such as the Organization for Security and Cooperation in Europe, Organisation for Economic Co-operation and Development (OECD), World Trade Organization (WTO), and International Monetary Fund.

The Netherlands is one of the founding members of what today is the European Union. It was one of the first countries to start European integration, through the Benelux in 1944 and the European Coal and Steel Community in 1952. Being a small country with a history of neutrality it was the host country for the important Maastricht Treaty and Amsterdam Treaty and is the seat of the International Court of Justice.

The country is one of the major producers of illicit amphetamines and other synthetic drugs. It also functions as an important gateway for cocaine, heroin, and hashish entering Europe. A large portion of the world's XTC consumption is supplied by illegal laboratories from the Netherlands.

The Dutch also work with the U.S. and other countries on international programs against drug trafficking and organized crime. The Dutch-U.S. cooperation focuses on joint anti-drug operations in the Caribbean, including an agreement establishing Forward Operating Locations on the Dutch Kingdom islands of Curaçao and Aruba. The Netherlands is a signatory to international counter-narcotics agreements, a member of the United Nations International Drug Control Program, the UN Commission on Narcotic Drugs, and is a contributor to international counter-narcotics.

From June 26 until December 22, 2006, two children, Ammar (12–13) and Sara (10–11), lived in the Dutch embassy in Damascus because of a child custody dispute between the Dutch mother, supported by Dutch law and the Hague Convention on the Civil Aspects of International Child Abduction, and the Syrian father, supported by Syrian law (Syria is no participant of this convention). The children had been living in Syria since 2004, after an alleged international child abduction by the father from the Netherlands to Syria, during a family contact in which he supposedly would visit Paris with them. The children fled to the embassy because they would like to live with their mother in the Netherlands. Minister of Foreign Affairs Ben Bot traveled to Damascus, negotiated and on December 22 the children finally could return to the Netherlands.

The father claims that the Dutch government has promised not to prosecute him for the abduction. However, a Dutch prosecutor claims that he is free to prosecute the father and may well do that and that the Dutch have only retracted the international request to arrest him outside the Netherlands.

Mark Rutte's government provided materials to the Levant Front rebel group in Syria. In September 2018, the Dutch public prosecution department declared the Levant Front to be a "criminal organisation of terrorist intent", describing it as a "salafist and jihadistic" group that "strives for the setting up of the caliphate".

In July 2019, the UN ambassadors from 22 nations, including the Netherlands, signed a joint letter to the UNHRC condemning China’s mistreatment of the Uyghurs as well as its mistreatment of other minority groups, urging the Chinese government to close the Xinjiang re-education camps.

The Caribbean islands of Aruba, Curaçao, Sint Maarten, Bonaire, Sint Eustatius and Saba are dependencies of the Netherlands. The latter three are part of the Netherlands proper and are collectively known as the Caribbean Netherlands. Suriname and Indonesia became independent of the Netherlands in the period of decolonization: Suriname in 1975 and Indonesia in 1945 (it was not until August 16, 2005 that the Dutch government recognized 1945 and not 1949 as the latter's year of independence).




</doc>
<doc id="21164" url="https://en.wikipedia.org/wiki?curid=21164" title="Drug policy of the Netherlands">
Drug policy of the Netherlands

While recreational use, possession and trade of non-medicinal drugs described by the Opium Law are all technically illegal under Dutch law, official policy since the late 20th century has been to openly tolerate all recreational use while tolerating the other two under certain circumstances. This pragmatic approach was motivated by the idea that a drug-free Dutch society is unrealistic and unattainable, and efforts would be better spent trying to minimize harm caused by recreational drug use. As a result of this gedoogbeleid (lit. "tolerance policy" or "policy of tolerance"), the Netherlands is typically seen as much more tolerant of drugs than most other countries.

Legal distinctions are made in the Opium Law between drugs with a low risk of harm and/or addiction, called soft drugs, and drugs with a high risk of harm and/or addiction, called hard drugs. Soft drugs include hash, marijuana, sleeping pills and sedatives, while hard drugs include heroin, cocaine, amphetamine, LSD and ecstasy. Policy has been to largely tolerate the sale of soft drugs while strongly suppressing the sale, circulation and use of hard drugs, effectively separating it into two markets. Establishments that have been permitted to sell soft drugs under certain circumstances are called "coffee shops". Laws established in January 2013 required visitors of coffee shops to be Dutch residents, but these laws were only applied in Zeeland, North Brabant and Limburg after much local criticism. Possession of a soft drug for personal use in quantities below a certain threshold (5 grams of cannabis or 5 cannabis plants) is tolerated, but larger quantities or possession of hard drugs may lead to prosecution. Prosecution for possession, trade and (in some rare cases) use are typically handled by the municipal government except where large-scale criminal activity is suspected.

Notably absent from toleration of drugs is its production, particularly the cultivation of cannabis. This has led to a seemingly paradoxical system where coffee shops are allowed to buy and sell soft drugs but where production is nearly always punished. Because coffee shops have to get their goods from somewhere, criticism has been raised over the years against continued prosecution of soft drug producers. It was first challenged in court in 2014 when a judge found two people guilty of producing cannabis in large quantities but refused to punish them. A significant change occurred in early 2017, when a slight majority in the House of Representatives allowed for a law to pass that would partly legalize production of cannabis. In late 2017, the newly formed coalition announced that they would seek to implement an experimental new system in certain cities where coffee shops could legally acquire cannabis from a state-appointed producer.

While the legalization of cannabis remains controversial, the introduction of heroin-assisted treatment in 1998 has been lauded for considerably improving the health and social situation of opiate-dependent patients in the Netherlands.

Large-scale dealing, production, import and export are prosecuted to the fullest extent of the law, even if it does not supply end users or "coffeeshops" with more than the allowed amounts. Exactly how coffeeshops get their supplies is rarely investigated, however. The average concentration of THC in the cannabis sold in coffeeshops has increased from 9% in 1998 to 18% in 2005. This means that less plant material has to be consumed to achieve the same effect. One of the reasons is plant breeding and use of greenhouse technology for illegal growing of cannabis in Netherlands.
The former minister of Justice Piet Hein Donner announced in June 2007 that cultivation of cannabis shall continue to be illegal.

The drug policy of the Netherlands is marked by its distinguishing between so called soft and hard drugs. An often used argument is that alcohol, which is claimed by some scientists as a hard drug, is legal and a soft drug can't be more dangerous to society if it's controlled. This may refer to the Prohibition in the 1920s, when the U.S. government decided to ban all alcohol. Prohibition created a golden opportunity for organized crime syndicates to smuggle alcohol, and as a result the syndicates were able to gain considerable power in some major cities.
Cannabis remains a controlled substance in the Netherlands and both possession and production for personal use are still misdemeanors, punishable by fines. Coffeeshops are also technically illegal but are flourishing nonetheless. However, a policy of non-enforcement has led to a situation where reliance upon non-enforcement has become common, and because of this the courts have ruled against the government when individual cases were prosecuted.

This is because the Dutch Ministry of Justice applies a "gedoogbeleid" (tolerance policy) with regard to the category of soft drugs: an official set of guidelines telling public prosecutors under which circumstances offenders should not be prosecuted. This is a more official version of a common practice in other European countries wherein law enforcement sets priorities regarding offenses on which it is important enough to spend limited resources.

According to current "gedoogbeleid" the possession of a maximum amount of five grams cannabis for personal use is not prosecuted. Cultivation is treated in a similar way. Cultivation of 5 plants or less is usually not prosecuted when they are renounced by the cultivator.

Proponents of "gedoogbeleid" argue that such a policy practices more consistency in legal protection than without it. Opponents of the Dutch drug policy either call for full legalization, or argue that laws should penalize morally wrong or deviant behavior, whether enforceable or not. In the Dutch courts, however, it has long been determined that the institutionalized non-enforcement of statutes with well defined limits constitutes "de facto" decriminalization. The statutes are kept on the books mainly due to international pressure and in adherence with international treaties. A November 2008 poll showed that a 60% majority of the Dutch population support the legalisation of soft drugs. The same poll showed that 85% supported closing of all cannabis coffeeshops within 250 meters walking distance from schools.

Importing and exporting of any classified drug is a serious offence. The penalty can run up to 12 to 16 years if it is hard drug trade, maximum 4 years for import or export of large quantities of cannabis. It is prohibited to operate a motor vehicle while under the influence of any drug that affects driving ability to such an extent that you are unable to drive properly. (Section 8 of the 1994 Road Traffic Act section 1). The Dutch police have the right to do a drug test if they suspect influenced driving. For example, anybody involved in a traffic accident may be tested. Causing an accident that inflicts bodily harm, while under influence of any drug, is seen as a crime that may be punished by up to 3 years in prison (9 years in case of a fatal accident). Suspension of driving license is also normal in such a case (maximum 5 years). Schiphol, a large international airport near Amsterdam, has long practiced a zero tolerance policy regarding airline passengers carrying drugs. In 2006 there were 20,769 drug crimes registered by public prosecutors and 4,392 persons received an unconditional prison sentence The rate of imprisonment for drug crimes is about the same as in Sweden, which has a zero tolerance policy for drug crimes.

Despite the high priority given by the Dutch government to fighting illegal drug trafficking, the Netherlands continue to be an important transit point for drugs entering Europe. The Netherlands is a major producer and leading distributor of cannabis, heroin, cocaine, amphetamines and other synthetic drugs, and a medium consumer of illicit drugs. Despite the crackdown by Interpol on traffic and illicit manufacture of temazepam, the country has also become a major exporter of illicit temazepam of the jelly variety, trafficking it to the United Kingdom and other European nations. The government has intensified cooperation with neighbouring countries and stepped up border controls. In recent years, it also introduced so-called 100% checks and bodyscans at Schiphol Airport on incoming flights from Dutch overseas territories Aruba and Netherlands Antilles to prevent importing cocaine by means of swallowing balloons by mules.

Although drug use, as opposed to trafficking, is seen primarily as a public health issue, responsibility for drug policy is shared by both the Ministry of Health, Welfare, and Sports, and the Ministry of Justice.

The Netherlands spends more than €130 million annually on facilities for addicts, of which about fifty percent goes to drug addicts. The Netherlands has extensive demand reduction programs, reaching about ninety percent of the country's 25,000 to 28,000 hard drug users. The number of hard drug addicts has stabilized in the past few years and their average age has risen to 38 years, which is generally seen as a positive trend. Notably, the number of drug-related deaths in the country remains amongst the lowest in Europe.

On 27 November 2003, the Dutch Justice Minister Piet Hein Donner announced that his government was considering rules under which coffeeshops would only be allowed to sell soft drugs to Dutch residents in order to satisfy both European neighbors' concerns about the influx of drugs from the Netherlands, as well as those of Netherlands border town residents unhappy with the influx of "drug tourists" from elsewhere in Europe. The European Court of Justice ruled in December 2010 that Dutch authorities can ban coffeeshops from selling cannabis to foreigners. The EU court said the southern Dutch city of Maastricht was within its rights when it introduced a "weed passport" in 2005 to prevent foreigners from entering cafés that sell cannabis.

In 2010 the owner of Netherlands's largest cannabis selling coffeeshop was fined 10 million euros for breaking drug laws by keeping more than the tolerated amount of cannabis in the shop. He was also sentenced to a 16-week prison term.

Criminal investigations into more serious forms of organized crime mainly involve drugs (72%). Most of these are investigations of hard drug crime (specifically cocaine and synthetic drugs) although the number of soft drug cases is rising and currently accounts for 69% of criminal investigations.

In a study of the levels of cannabis, cocaine, MDMA, methamphetamine and other amphetamine in wastewater from 42 major cities in Europe Amsterdam came near the top of the list in every category but methamphetamine.

The Netherlands tolerates the sale of soft drugs in ‘coffee shops’. A coffee shop is an establishment where cannabis may be sold subject to certain strict conditions, but no alcoholic drinks may be sold or consumed. The Dutch government does not prosecute members of the public for possession or use of small quantities of soft drugs.

In the province of North-Brabant in the south of the Netherlands, the organized crime organizations form the main producer of MDMA, amphetamine and cannabis in Europe. Together with the proximity of the ports of Antwerp and especially Rotterdam where heroin and cocaine enter the European continent, this causes these substances to be readily available for a relative low price. Therefore, there is a large quantity drugs of a relative high quality with few pollution available. This means that users will not have to rely on more polluted substances with greater health risks. Together with an approach that focuses on easily accessible health care, harm reduction and prevention, this causes the medical condition of the Dutch addicts to be less severe than that of many other countries.

The Netherlands is a party to the 1961 Single Convention on Narcotic Drugs, the 1971 Convention on Psychotropic Substances, and the 1988 United Nations Convention Against Illicit Traffic in Narcotic Drugs and Psychotropic Substances. The 1961 convention prohibits cultivation and trade of naturally occurring drugs such as cannabis; the 1971 treaty bans the manufacture and trafficking of synthetic drugs such as barbiturates and amphetamines; and the 1988 convention requires states to criminalize illicit drug possession:
Subject to its constitutional principles and the basic concepts of its legal system, each Party shall adopt such measures as may be necessary to establish as a criminal offence under its domestic law, when committed intentionally, the possession, purchase or cultivation of narcotic drugs or psychotropic substances for personal consumption contrary to the provisions of the 1961 Convention, the 1961 Convention as amended or the 1971 Convention.
The International Narcotics Control Board typically interprets this provision to mean that states must prosecute drug possession offenses. The conventions clearly state that controlled substances are to be restricted to scientific and medical uses. However, Cindy Fazey, former Chief of Demand Reduction for the United Nations Drug Control Programme, believes that the treaties have enough ambiguities and loopholes to allow some room to maneuver. In her report entitled "The Mechanics and Dynamics of the UN System for International Drug Control", she notes:
Many countries have now decided not to use the full weight of criminal sanctions against people who are in possession of drugs that are for their personal consumption. The Conventions say that there must be an offence under domestic criminal law, it does not say that the law has to be enforced, or that when it is what sanctions should apply. . . . Despite such grey areas latitude is by no means unlimited. The centrality of the principle of limiting narcotic and psychotropic drugs for medical and scientific purposes leaves no room for the legal possibility of recreational use. . . . Nations may currently be pushing the boundaries of the international system, but the pursuit of any action to formally legalize non-medical and non-scientific drug use would require either treaty revision or a complete or partial withdrawal from the current regime.
The Dutch policy of keeping anti-drug laws on the books while limiting enforcement of certain offenses is carefully designed to reduce harm while still complying with the letter of international drug control treaties. This is necessary in order to avoid criticism from the International Narcotics Board, which historically has taken a dim view of any moves to relax official drug policy. In their annual report, the Board has criticised many governments, including Canada, for permitting the medicinal use of cannabis, Australia for providing injecting rooms and the United Kingdom for proposing to downgrade the classification of cannabis, which it has since done (although this change was reversed by the Home Secretary on 7 May 2008 against the advice of its own commissioned report).

The liberal drug policy of the authorities in the Netherlands especially led to problems in "border hot spots" that attracted "drug tourism" as well as trafficking and related law enforcement problems in towns like Enschede in the East and Terneuzen, Venlo, Maastricht and Heerlen in the South. In 2006, Gerd Leers, then mayor of the border city of Maastricht, on the Dutch-Belgian border, criticised the current policy as inconsistent, by recording a song with the Dutch punk rock band De Heideroosjes. By allowing possession and retail sales of cannabis, but not cultivation or wholesale, the government creates numerous problems of crime and public safety, he alleges, and therefore he would like to switch to either legalising and regulating production, or to the full repression that his party (CDA) officially advocates. The latter suggestion has widely been interpreted as rhetorical. Leers's comments have garnered support from other local authorities and put the cultivation issue back on the agenda.

In November 2008, Pieter van Geel, the leader of the CDA (Christian Democrats) in the Dutch parliament, called for a ban on the cafés where cannabis is sold. He said the practice of allowing so-called coffeeshops to operate had failed. The CDA had the support of its smaller coalition partner, the CU (ChristenUnie), but the third party in government, PvdA (Labour), opposed. The coalition agreement worked out by the three coalition parties in 2007 stated that there would be no change in the policy of tolerance. Prominent CDA member Gerd Leers spoke out against him: cannabis users who now cause no trouble would be viewed as criminals if an outright ban was to be implemented. Van Geel later said that he respected the coalition agreement and would not press for a ban during the current government's tenure.

27 "coffeeshops" selling cannabis in Rotterdam, all within 200 metres from schools, were ordered to close down by 2009. This was nearly half of the "coffeeshops" that operated within its municipality. This was due to the new policy of city mayor Ivo Opstelten and the town council. The higher levels of the active ingredient in cannabis in Netherlands create a growing opposition to the traditional Dutch view of cannabis as a relatively innocent soft drug. Supporters of "coffeeshops" state that such claims are often exaggerated and ignore the fact that higher content means a user needs to use less of the plant to get the desired effects, making it in effect safer. Dutch research has however shown that an increase of THC content also increase the occurrence of impaired psychomotor skills, particularly among younger or inexperienced cannabis smokers, who do not adapt their smoking-style to the higher THC content. Closing of "coffeeshops" is not unique to Rotterdam. Many other towns have done the same in the last 10 years.

In 2008, the municipality of Utrecht imposed a Zero Tolerance Policy to all events like the big dance party Trance Energy held in Jaarbeurs. However, such zero-tolerance policy at dance parties are now becoming common in the Netherlands and are even stricter in cities like Arnhem.

The two towns Roosendaal and Bergen op Zoom announced in October 2008 that they would start closing all "coffeeshops", each week visited by up to 25,000 French and Belgian drug tourists, with closures beginning in February 2009.

In May 2011 the Dutch government announced that tourist are to be banned from Dutch coffeeshops, starting in the southern provinces and at the end of 2011 in the rest of the country. In a letter to the parliament, the Dutch health and justice ministers said that, "In order to tackle the nuisance and criminality associated with coffeeshops and drug trafficking, the open-door policy of coffeeshops will end".

A government committee delivered in June 2011 a report about Cannabis to the Dutch government. It includes a proposal that cannabis with more than 15 percent THC should be labeled as hard drugs. Higher concentrations of THC and drug tourism have challenged the current policy and led to a re-examination of the current approach; e.g. ban of all sales of cannabis to tourists in coffeeshops from end of 2011 was proposed but currently only the border city of Maastricht has adopted the measure in order to test out its feasibility. According to the initial measure, starting in 2012, each coffeeshop was to operate like a private club with some 1,000 to 1,500 members. In order to qualify for a membership card, applicants would have to be adult Dutch citizens, membership was only to be allowed in one club.

In Amsterdam 26 coffeeshops in the De Wallen area were ordered to close their doors between 1 September 2012 and 31 August 2015.

A Dutch judge has ruled that tourists can legally be banned from entering cannabis cafés, as part of new restrictions which come into force in 2012.

A study conducted by the European Monitoring Centre of Drugs and Drug Addiction report that 25.3% of Irish people smoked cannabis at some stage in their life. Whereas 25.7% of Dutch people have tried cannabis.

In October 2007, the prohibition of hallucinogenic or "magic mushrooms" was announced by the Dutch authorities.

On 25 April 2008, the Dutch government, backed by a majority of members of parliament, decided to ban cultivation and use of all magic mushrooms. Amsterdam mayor Job Cohen proposed a three-day cooling period in which clients would be informed three days before actually procuring the mushrooms and if they would still like to go through with it they could pick up their spores from the smart shop.
The ban has been considered a retreat from liberal drug policies. This followed a few deadly incidents mostly involving tourists. These deaths were not directly caused by the use of the drug "per se", but by deadly accidents occurring while under the influence of magic mushrooms.

As of 1 December 2008, all psychedelic mushrooms are banned. However, schlerotia (what are termed as "truffles"), mushroom spores, and active mycellium cultures remained legal and are readily available in the "smartshops", these truffles have the same effect as the "magic mushrooms", the stores in the Dutch cities that sell legal drugs, herbs and related gadgets.

The relatively recent increase in the cocaine trafficking business has been largely focused on the Caribbean area. Since early 2003, a special law court with prison facilities has been operational at Schiphol airport. Since the beginning of 2005, there has been 100% control of all flights from key countries in the Caribbean. In 2004, an average of 290 drug couriers per month were arrested, decreasing to 80 per month by early 2006.





</doc>
<doc id="21168" url="https://en.wikipedia.org/wiki?curid=21168" title="2001 in the Netherlands">
2001 in the Netherlands

This article lists some of the events that took place in the Netherlands in 2001.


















</doc>
<doc id="21170" url="https://en.wikipedia.org/wiki?curid=21170" title="Numeral system">
Numeral system

A numeral system (or system of numeration) is a writing system for expressing numbers; that is, a mathematical notation for representing numbers of a given set, using digits or other symbols in a consistent manner.

The same sequence of symbols may represent different numbers in different numeral systems. For example, "11" represents the number "eleven" in the decimal numeral system (used in common life), the number "three" in the binary numeral system (used in computers), and the number two in the unary numeral system (e.g. used in tallying scores).

The number the numeral represents is called its value.

Ideally, a numeral system will:

For example, the usual decimal representation of whole numbers gives every nonzero whole number a unique representation as a finite sequence of digits, beginning with a non-zero digit. However, when decimal representation is used for the rational or real numbers, such numbers, in general, have an infinite number of representations, for example 2.31 can also be written as 2.310, 2.3100000, 2.309999999..., etc., all of which have the same meaning except for some scientific and other contexts where greater precision is implied by a larger number of figures shown.

Numeral systems are sometimes called "number systems", but that name is ambiguous, as it could refer to different systems of numbers, such as the system of real numbers, the system of complex numbers, the system of "p"-adic numbers, etc. Such systems are, however, not the topic of this article.

The most commonly used system of numerals is the Hindu–Arabic numeral system. Two Indian mathematicians are credited with developing it. Aryabhata of Kusumapura developed the place-value notation in the 5th century and a century later Brahmagupta introduced the symbol for zero. The numeral system and the zero concept, developed by the Hindus in India, slowly spread to other surrounding countries due to their commercial and military activities with India. The Arabs modified it into simple numeral symbols as the hindi version was texts rather than symbols. The Arabic numeral system then spread to Europe along with many other science knowledge and due to merchants trading and using a stable simple numeral system. The Western world modified them and called them the Arabic numerals, as they learned them from the Arabs. Hence the current western numeral system is the modified version of the Hindu numeral system developed in India. It also exhibits a great similarity to the Sanskrit–Devanagari notation, which is still used in India and neighbouring Nepal.

The simplest numeral system is the unary numeral system, in which every natural number is represented by a corresponding number of symbols. If the symbol / is chosen, for example, then the number seven would be represented by ///////. Tally marks represent one such system still in common use. The unary system is only useful for small numbers, although it plays an important role in theoretical computer science. Elias gamma coding, which is commonly used in data compression, expresses arbitrary-sized numbers by using unary to indicate the length of a binary numeral.

The unary notation can be abbreviated by introducing different symbols for certain new values. Very commonly, these values are powers of 10; so for instance, if / stands for one, − for ten and + for 100, then the number 304 can be compactly represented as +++ //// and the number 123 as + − − /// without any need for zero. This is called sign-value notation. The ancient Egyptian numeral system was of this type, and the Roman numeral system was a modification of this idea.

More useful still are systems which employ special abbreviations for repetitions of symbols; for example, using the first nine letters of the alphabet for these abbreviations, with A standing for "one occurrence", B "two occurrences", and so on, one could then write C+ D/ for the number 304. This system is used when writing Chinese numerals and other East Asian numerals based on Chinese. The number system of the English language is of this type ("three hundred [and] four"), as are those of other spoken languages, regardless of what written systems they have adopted. However, many languages use mixtures of bases, and other features, for instance 79 in French is "soixante dix-neuf" () and in Welsh is "pedwar ar bymtheg a thrigain" () or (somewhat archaic) "pedwar ugain namyn un" (). In English, one could say "four score less one", as in the famous Gettysburg Address representing "87 years ago" as "four score and seven years ago".

More elegant is a "positional system", also known as place-value notation. Again working in base 10, ten different digits 0, ..., 9 are used and the position of a digit is used to signify the power of ten that the digit is to be multiplied with, as in or more precisely . Zero, which is not needed in the other systems, is of crucial importance here, in order to be able to "skip" a power. The Hindu–Arabic numeral system, which originated in India and is now used throughout the world, is a positional base 10 system.

Arithmetic is much easier in positional systems than in the earlier additive ones; furthermore, additive systems need a large number of different symbols for the different powers of 10; a positional system needs only ten different symbols (assuming that it uses base 10).

The positional decimal system is presently universally used in human writing. The base 1000 is also used (albeit not universally), by grouping the digits and considering a sequence of three decimal digits as a single digit. This is the meaning of the common notation 1,000,234,567 used for very large numbers.

In computers, the main numeral systems are based on the positional system in base 2 (binary numeral system), with two binary digits, 0 and 1. Positional systems obtained by grouping binary digits by three (octal numeral system) or four (hexadecimal numeral system) are commonly used. For very large integers, bases 2 or 2 (grouping binary digits by 32 or 64, the length of the machine word) are used, as, for example, in GMP.

In certain biological systems, the unary coding system is employed. Unary numerals used in the neural circuits responsible for birdsong production. The nucleus in the brain of the songbirds that plays a part in both the learning and the production of bird song is the HVC (high vocal center). The command signals for different notes in the birdsong emanate from different points in the HVC. This coding works as space coding which is an efficient strategy for biological circuits due to its inherent simplicity and robustness.

The numerals used when writing numbers with digits or symbols can be divided into two types that might be called the arithmetic numerals (0, 1, 2, 3, 4, 5, 6, 7, 8, 9) and the geometric numerals (1, 10, 100, 1000, 10000 ...), respectively. The sign-value systems use only the geometric numerals and the positional systems use only the arithmetic numerals. A sign-value system does not need arithmetic numerals because they are made by repetition (except for the Ionic system), and a positional system does not need geometric numerals because they are made by position. However, the spoken language uses "both" arithmetic and geometric numerals.

In certain areas of computer science, a modified base "k" positional system is used, called bijective numeration, with digits 1, 2, ..., "k" (), and zero being represented by an empty string. This establishes a bijection between the set of all such digit-strings and the set of non-negative integers, avoiding the non-uniqueness caused by leading zeros. Bijective base-"k" numeration is also called "k"-adic notation, not to be confused with "p"-adic numbers. Bijective base 1 is the same as unary.

In a positional base "b" numeral system (with "b" a natural number greater than 1 known as the radix), "b" basic symbols (or digits) corresponding to the first "b" natural numbers including zero are used. To generate the rest of the numerals, the position of the symbol in the figure is used. The symbol in the last position has its own value, and as it moves to the left its value is multiplied by "b".

For example, in the decimal system (base 10), the numeral 4327 means , noting that .

In general, if "b" is the base, one writes a number in the numeral system of base "b" by expressing it in the form and writing the enumerated digits in descending order. The digits are natural numbers between 0 and , inclusive.

If a text (such as this one) discusses multiple bases, and if ambiguity exists, the base (itself represented in base 10) is added in subscript to the right of the number, like this: number. Unless specified by context, numbers without subscript are considered to be decimal.

By using a dot to divide the digits into two groups, one can also write fractions in the positional system. For example, the base 2 numeral 10.11 denotes .

In general, numbers in the base "b" system are of the form:

The numbers "b" and "b" are the weights of the corresponding digits. The position "k" is the logarithm of the corresponding weight "w", that is formula_2. The highest used position is close to the order of magnitude of the number.

The number of tally marks required in the unary numeral system for "describing the weight" would have been w. In the positional system, the number of digits required to describe it is only formula_3, for "k" ≥ 0. For example, to describe the weight 1000 then four digits are needed because formula_4. The number of digits required to "describe the position" is formula_5 (in positions 1, 10, 100... only for simplicity in the decimal example).

A number has a terminating or repeating expansion if and only if it is rational; this does not depend on the base. A number that terminates in one base may repeat in another (thus ). An irrational number stays aperiodic (with an infinite number of non-repeating digits) in all integral bases. Thus, for example in base 2, can be written as the aperiodic 11.001001000011111...

Putting overscores, , or dots, "ṅ", above the common digits is a convention used to represent repeating rational expansions. Thus:

If "b" = "p" is a prime number, one can define base-"p" numerals whose expansion to the left never stops; these are called the "p"-adic numbers.

More general is using a mixed radix notation (here written little-endian) like formula_7 for formula_8, etc.

This is used in punycode, one aspect of which is the representation of a sequence of non-negative integers of arbitrary size in the form of a sequence without delimiters, of "digits" from a collection of 36: a–z and 0–9, representing 0–25 and 26–35 respectively. A digit lower than a threshold value marks that it is the most-significant digit, hence the end of the number. The threshold value depends on the position in the number. For example, if the threshold value for the first digit is b (i.e. 1) then a (i.e. 0) marks the end of the number (it has just one digit), so in numbers of more than one digit, range is only b–9 (1–35), therefore the weight "b" is 35 instead of 36. Suppose the threshold values for the second and third digits are c (2), then the third digit has a weight 34 × 35 = 1190 and we have the following sequence:

a (0), ba (1), ca (2), .., 9a (35), bb (36), cb (37), .., 9b (70), bca (71), .., 99a (1260), bcb (1261), etc.

Unlike a regular based numeral system, there are numbers like 9b where 9 and b each represents 35; yet the representation is unique because ac and aca are not allowed – the a would terminate the number.

The flexibility in choosing threshold values allows optimization depending on the frequency of occurrence of numbers of various sizes.

The case with all threshold values equal to 1 corresponds to bijective numeration, where the zeros correspond to separators of numbers with digits which are non-zero.




</doc>
<doc id="21173" url="https://en.wikipedia.org/wiki?curid=21173" title="Natural language">
Natural language

In neuropsychology, linguistics, and the philosophy of language, a natural language or ordinary language is any language that has evolved naturally in humans through use and repetition without conscious planning or premeditation. Natural languages can take different forms, such as speech or signing. They are distinguished from constructed and formal languages such as those used to program computers or to study logic.

Though the exact definition varies between scholars, natural language can broadly be defined in contrast to artificial or constructed languages (such as computer programming languages and international auxiliary languages) and to other communication systems in nature. Such examples include bees' waggle dance and whale song, to which researchers have found or applied the linguistic cognates of dialect and even syntax. However, classification of animal communication systems as languages is controversial.

All language varieties of world languages are natural languages, although some varieties are subject to greater degrees of published prescriptivism or language regulation than others. Thus nonstandard dialects can be viewed as a wild type in comparison with standard languages. But even an official language with a regulating academy, such as Standard French with the French Academy, is classified as a natural language (for example, in the field of natural language processing), as its prescriptive points do not make it either constructed enough to be classified as a constructed language or controlled enough to be classified as a controlled natural language.

Controlled natural languages are subsets of natural languages whose grammars and dictionaries have been restricted in order to reduce or eliminate both ambiguity and complexity (for instance, by cutting down on rarely used superlative or adverbial forms or irregular verbs). The purpose behind the development and implementation of a controlled natural language typically is to aid non-native speakers of a natural language in understanding it, or to ease computer processing of a natural language. An example of a widely used controlled natural language is Simplified English, which was originally developed for aerospace industry maintenance manuals.

Constructed international auxiliary languages such as Esperanto and Interlingua (even those that have native speakers) are not generally considered natural languages. Natural languages have been used to communicate and have evolved in a natural way, whereas Esperanto was designed by L. L. Zamenhof selecting elements from natural languages, not grown from natural fluctuations in vocabulary and syntax. Some natural languages have become naturally "standardized" by children's natural tendency to correct for illogical grammatical structures in their parents' speech, which can be seen in the development of pidgin languages into creole languages (as explained by Steven Pinker in "The Language Instinct"), but this is not the case in many languages, including constructed languages such as Esperanto, where strict rules are in place as an attempt to consciously remove such irregularities. The possible exception to this are true native speakers of such languages. More substantive basis for this designation is that the vocabulary, grammar, and orthography of Interlingua are natural; they have been standardized and presented by a linguistic research body, but they predated it and are not themselves considered a product of human invention. Most experts, however, consider Interlingua to be naturalistic rather than natural. Latino sine flexione, a second naturalistic auxiliary language, is also naturalistic in content but is no longer widely spoken.




</doc>
<doc id="21174" url="https://en.wikipedia.org/wiki?curid=21174" title="Nanook of the North">
Nanook of the North

Nanook of the North (also known as Nanook of the North: A Story Of Life and Love In the Actual Arctic) is a 1922 American silent documentary film by Robert J. Flaherty, with elements of docudrama, at a time when the concept of separating films into documentary and drama did not yet exist.

In the tradition of what would later be called salvage ethnography, Flaherty captured the struggles of the Inuk man named Nanook and his family in the Canadian Arctic. Some have criticized Flaherty for staging several sequences, but the film is generally viewed as standing "alone in its stark regard for the courage and ingenuity of its heroes."

In 1989, "Nanook of the North" was one of the first 25 films to be selected for preservation in the United States National Film Registry by the Library of Congress as being "culturally, historically, or aesthetically significant".

The documentary follows the lives of an Inuk, Nanook, and his family as they travel, search for food, and trade in the Ungava Peninsula of northern Quebec, Canada. Nanook; his wife, Nyla; and their family are introduced as fearless heroes who endure rigors no other race could survive. The audience sees Nanook, often with his family, hunt a walrus, build an igloo, go about his day, and perform other tasks.

In 1910 Flaherty was hired as an explorer and prospector along the Hudson Bay for the Canadian Pacific Railway. Learning about the lands and people there, Flaherty decided to bring a camera with him on his third expedition in 1913, but knowing nothing about film, Flaherty took a three-week course on cinematography in Rochester, New York.

Using a Bell & Howell camera, a portable developing and printing machine, and some lighting equipment, Flaherty spent 1914 and 1915 shooting hours of film of Inuit life. By 1916, Flaherty had enough footage that he began test screenings and was met with wide enthusiasm. However, in 1916, Flaherty dropped a cigarette onto the original camera negative (which was highly flammable nitrate stock) and lost 30,000 feet of film. With his first attempt ruined, Flaherty decided to not only return for new footage, but also to refocus the film on one Inuit family as he felt his earlier footage was too much of travelogue. Spending four years raising money, Flaherty was eventually funded by French fur company Revillon Frères and returned to the North and shot from August 1920 to August 1921. As a main character, Flaherty chose the celebrated hunter of the Itivimuit tribe, Allakariallak. The full collaboration of the Inuit was key to Flaherty's success as the Inuit were his film crew and many of them knew his camera better than he did.

Flaherty has been criticized for deceptively portraying staged events as reality. "Nanook" was in fact named Allakariallak (). Flaherty chose this nickname because of its seeming genuineness which makes it more marketable to euro-american audiences. The "wife" shown in the film was not really his wife. According to Charlie Nayoumealuk, who was interviewed in "Nanook Revisited" (1990), "the two women in "Nanook" - Nyla (Alice [?] Nuvalinga) and Cunayou (whose real name we do not know) were not Allakariallak's wives, but were in fact common-law wives of Flaherty." And although Allakariallak normally used a gun when hunting, Flaherty encouraged him to hunt after the fashion of his recent ancestors in order to capture the way the Inuit lived before European colonization of the Americas. Flaherty also exaggerated the peril to Inuit hunters with his claim, often repeated, that Allakariallak had died of starvation two years after the film was completed, whereas in fact he died at home, likely of tuberculosis.

Furthermore, It has been criticized for portraying inuit people as subhuman arctic beings, without technology or culture which reproduces the historical image that situates them outside modern history. It was also criticized for comparing inuit people to animals. The film is considered to be an artifact of popular culture at the time and also a result of a historical fascination for Inuit performers in exhibitions, zoos, fairs, museums and early cinema.

The building of the igloo is one of the most celebrated sequences in the film, but interior photography presented a problem. Building an igloo large enough for a camera to enter resulted in the dome collapsing, and when they finally succeeded in making the igloo it was too dark for photography. Instead, the images of the inside of the igloo in the film were actually shot in a special three-walled igloo for Flaherty's bulky camera so that there would be enough light for it to capture interior shots.

In the "Trade Post of the White Man" scene, Nanook and his family arrive in a kayak at the trading post and one family member after another emerge from a small kayak, akin to a clown car at the circus. Going to trade his hunt from the year, including the skins of foxes, seals, and polar bears, Nanook comes in contact with the white man and there is a funny interaction as the two cultures meet. The trader plays music on a gramophone and tries to explain how a man 'cans' his voice. Bending forward and staring at the machine, Nanook puts his ear closer as the trader cranks the mechanism again. The trader removes the record and hands it to Nanook who at first peers at it and then puts it in his mouth and bites it. The scene is meant to be a comical one as the audience laughs at the naivete of Nanook and people isolated from Western culture. In truth, the scene was entirely scripted and Allakariallak knew what a gramophone was.

It has been noted that in the 1920s, when Nanook was filmed, the Inuit had already begun integrating the use of Western clothing and were using rifles to hunt rather than harpoons, but this does not negate that the Inuit knew how to make traditional clothing from animals found in their environment, could still fashion traditional weapons and were perfectly able to make use of them if found to be preferable for a given situation.
Flaherty defended his work by stating, "one often has to distort a thing in order to catch its true spirit." Later filmmakers have pointed out that the only cameras available to Flaherty at the time were both large and immobile, making it impossible to effectively capture most interior shots or unstructured exterior scenes without significantly modifying the environment and subject action.

As the first "nonfiction" work of its scale, "Nanook of the North" was ground-breaking cinema. It captured many authentic details of a culture little known to outsiders, and it was filmed in a remote location. Hailed almost unanimously by critics, the film was a box-office success in the United States and abroad. In the following years, many others would try to follow Flaherty's success with "primitive peoples" films. In 2005 film critic Roger Ebert described the film's central figure, Nanook, as "one of the most vital and unforgettable human beings ever recorded on film." In a 2014 "Sight and Sound" poll, film critics voted "Nanook of the North" the seventh-best documentary film of all time.

At the time, few documentaries had been filmed and there was little precedent to guide Flaherty's work. Since Flaherty's time, staging, attempting to steer documentary action, or presenting re-enactment as naturally captured footage has come to be considered unethical.

In its earliest years (approx. 1895–1902), film production was dominated by actualities—short pictures of real people in real places. Robert Flaherty's great innovation was simply to combine the two forms of actuality, infusing the exotic journey with the details of indigenous work and play and life.

In 1999, "Nanook of the North" was digitally remastered and released on DVD by The Criterion Collection. It includes an interview with Flaherty's widow (and "Nanook of the North" co-editor), Frances Flaherty, photos from Flaherty's trip to the arctic, and excerpts from a TV documentary, "Flaherty and Film." In 2013, Flicker Alley released a remastered Blu-ray version that includes six other arctic films.







</doc>
<doc id="21175" url="https://en.wikipedia.org/wiki?curid=21175" title="Nitrogen">
Nitrogen

Nitrogen (latin "Nitrogenium") is the chemical element with the symbol N and atomic number 7. It was first discovered and isolated by Scottish physician Daniel Rutherford in 1772. Although Carl Wilhelm Scheele and Henry Cavendish had independently done so at about the same time, Rutherford is generally accorded the credit because his work was published first. The name "nitrogène" was suggested by French chemist Jean-Antoine-Claude Chaptal in 1790, when it was found that nitrogen was present in nitric acid and nitrates. Antoine Lavoisier suggested instead the name azote, from the Greek ἀζωτικός "no life", as it is an asphyxiant gas; this name is instead used in many languages, such as French, Russian, Romanian and Turkish, and appears in the English names of some nitrogen compounds such as hydrazine, azides and azo compounds.

Nitrogen is the lightest member of group 15 of the periodic table, often called the pnictogens. The name comes from the Greek πνίγειν "to choke", directly referencing nitrogen's asphyxiating properties. It is a common element in the universe, estimated at about seventh in total abundance in the Milky Way and the Solar System. At standard temperature and pressure, two atoms of the element bind to form dinitrogen, a colourless and odorless diatomic gas with the formula N. Dinitrogen forms about 78% of Earth's atmosphere, making it the most abundant uncombined element. Nitrogen occurs in all organisms, primarily in amino acids (and thus proteins), in the nucleic acids (DNA and RNA) and in the energy transfer molecule adenosine triphosphate. The human body contains about 3% nitrogen by mass, the fourth most abundant element in the body after oxygen, carbon, and hydrogen. The nitrogen cycle describes movement of the element from the air, into the biosphere and organic compounds, then back into the atmosphere.

Many industrially important compounds, such as ammonia, nitric acid, organic nitrates (propellants and explosives), and cyanides, contain nitrogen. The extremely strong triple bond in elemental nitrogen (N≡N), the second strongest bond in any diatomic molecule after carbon monoxide (CO), dominates nitrogen chemistry. This causes difficulty for both organisms and industry in converting N into useful compounds, but at the same time means that burning, exploding, or decomposing nitrogen compounds to form nitrogen gas releases large amounts of often useful energy. Synthetically produced ammonia and nitrates are key industrial fertilisers, and fertiliser nitrates are key pollutants in the eutrophication of water systems.

Apart from its use in fertilisers and energy-stores, nitrogen is a constituent of organic compounds as diverse as Kevlar used in high-strength fabric and cyanoacrylate used in superglue. Nitrogen is a constituent of every major pharmacological drug class, including antibiotics. Many drugs are mimics or prodrugs of natural nitrogen-containing signal molecules: for example, the organic nitrates nitroglycerin and nitroprusside control blood pressure by metabolizing into nitric oxide. Many notable nitrogen-containing drugs, such as the natural caffeine and morphine or the synthetic amphetamines, act on receptors of animal neurotransmitters.

Nitrogen compounds have a very long history, ammonium chloride having been known to Herodotus. They were well known by the Middle Ages. Alchemists knew nitric acid as "aqua fortis" (strong water), as well as other nitrogen compounds such as ammonium salts and nitrate salts. The mixture of nitric and hydrochloric acids was known as "aqua regia" (royal water), celebrated for its ability to dissolve gold, the king of metals.

The discovery of nitrogen is attributed to the Scottish physician Daniel Rutherford in 1772, who called it "noxious air". Though he did not recognise it as an entirely different chemical substance, he clearly distinguished it from Joseph Black's "fixed air", or carbon dioxide. The fact that there was a component of air that does not support combustion was clear to Rutherford, although he was not aware that it was an element. Nitrogen was also studied at about the same time by Carl Wilhelm Scheele, Henry Cavendish, and Joseph Priestley, who referred to it as "burnt air" or "phlogisticated air". Nitrogen gas was inert enough that Antoine Lavoisier referred to it as "mephitic air" or "azote", from the Greek word (azotikos), "no life". In an atmosphere of pure nitrogen, animals died and flames were extinguished. Though Lavoisier's name was not accepted in English, since it was pointed out that almost all gases (indeed, with the sole exception of oxygen) are mephitic, it is used in many languages (French, Italian, Portuguese, Polish, Russian, Albanian, Turkish, etc.; the German "Stickstoff" similarly refers to the same characteristic, viz. "ersticken" "to choke or suffocate") and still remains in English in the common names of many nitrogen compounds, such as hydrazine and compounds of the azide ion. Finally, it led to the name "pnictogens" for the group headed by nitrogen, from the Greek πνίγειν "to choke".

The English word nitrogen (1794) entered the language from the French "nitrogène", coined in 1790 by French chemist Jean-Antoine Chaptal (1756–1832), from the French "nitre" (potassium nitrate, also called saltpeter) and the French suffix "-gène", "producing", from the Greek -γενής (-genes, "begotten"). Chaptal's meaning was that nitrogen is the essential part of nitric acid, which in turn was produced from nitre. In earlier times, niter had been confused with Egyptian "natron" (sodium carbonate) – called νίτρον (nitron) in Greek – which, despite the name, contained no nitrate.

The earliest military, industrial, and agricultural applications of nitrogen compounds used saltpeter (sodium nitrate or potassium nitrate), most notably in gunpowder, and later as fertiliser. In 1910, Lord Rayleigh discovered that an electrical discharge in nitrogen gas produced "active nitrogen", a monatomic allotrope of nitrogen. The "whirling cloud of brilliant yellow light" produced by his apparatus reacted with mercury to produce explosive mercury nitride.

For a long time, sources of nitrogen compounds were limited. Natural sources originated either from biology or deposits of nitrates produced by atmospheric reactions. Nitrogen fixation by industrial processes like the Frank–Caro process (1895–1899) and Haber–Bosch process (1908–1913) eased this shortage of nitrogen compounds, to the extent that half of global food production (see Applications) now relies on synthetic nitrogen fertilisers. At the same time, use of the Ostwald process (1902) to produce nitrates from industrial nitrogen fixation allowed the large-scale industrial production of nitrates as feedstock in the manufacture of explosives in the World Wars of the 20th century.

A nitrogen atom has seven electrons. In the ground state, they are arranged in the electron configuration 1s2s2p2p2p. It therefore has five valence electrons in the 2s and 2p orbitals, three of which (the p-electrons) are unpaired. It has one of the highest electronegativities among the elements (3.04 on the Pauling scale), exceeded only by chlorine (3.16), oxygen (3.44), and fluorine (3.98). Following periodic trends, its single-bond covalent radius of 71 pm is smaller than those of boron (84 pm) and carbon (76 pm), while it is larger than those of oxygen (66 pm) and fluorine (57 pm). The nitride anion, N, is much larger at 146 pm, similar to that of the oxide (O: 140 pm) and fluoride (F: 133 pm) anions. The first three ionisation energies of nitrogen are 1.402, 2.856, and 4.577 MJ·mol, and the sum of the fourth and fifth is 16.920 MJ·mol. Due to these very high figures, nitrogen has no simple cationic chemistry.

The lack of radial nodes in the 2p subshell is directly responsible for many of the anomalous properties of the first row of the p-block, especially in nitrogen, oxygen, and fluorine. The 2p subshell is very small and has a very similar radius to the 2s shell, facilitating orbital hybridisation. It also results in very large electrostatic forces of attraction between the nucleus and the valence electrons in the 2s and 2p shells, resulting in very high electronegativities. Hypervalency is almost unknown in the 2p elements for the same reason, because the high electronegativity makes it difficult for a small nitrogen atom to be a central atom in an electron-rich three-center four-electron bond since it would tend to attract the electrons strongly to itself. Thus, despite nitrogen's position at the head of group 15 in the periodic table, its chemistry shows huge differences from that of its heavier congeners phosphorus, arsenic, antimony, and bismuth.

Nitrogen may be usefully compared to its horizontal neighbours carbon and oxygen as well as its vertical neighbours in the pnictogen column, phosphorus, arsenic, antimony, and bismuth. Although each period 2 element from lithium to oxygen shows some similarities to the period 3 element in the next group (from magnesium to chlorine; these are known as diagonal relationships), their degree drops off abruptly past the boron–silicon pair. The similarities of nitrogen to sulfur are mostly limited to sulfur nitride ring compounds when both elements are the only ones present.

While it does not share the proclivity of carbon for catenation, nitrogen chains composed of eight atoms (PhN=N–N(Ph)–N=N–N(Ph)–N=NPh) and more are obtainable. Like carbon, nitrogen tends to form ionic or metallic compounds with metals. Nitrogen forms an extensive series of nitrides with carbon, including those with chain-, graphitic-, and fullerenic-like structures.

It resembles oxygen with its high electronegativity and concomitant capability for hydrogen bonding and the ability to form coordination complexes by donating its lone pairs of electrons. There are some parallels between the chemistry of ammonia NH and water HO. For example, the capacity of both compounds to be pronated to give NH and H0 or deprotonated to give NH and OH, with all of these able to be isolated in solid compounds.

The high electronegativity of nitrogen is (partly) misleading. Nitrogen has a negative electron affinity, which means that energy is required to add an electron to it. This is because nitrogen has three p-orbitals each occupied with one electron. An incoming electron will experience significant repulsion from the electrons in these orbitals. This does not happen with carbon, which has one unoccupied "p" sub shell. Nor does it occur with oxygen, since the increased nuclear charge is sufficient to overcome inter-electron repulsion effects.

Nitrogen shares with both its horizontal neighbours a preference for forming multiple bonds, typically with carbon, oxygen, or other nitrogen atoms, through p–p interactions. Thus, for example, nitrogen occurs as diatomic molecules and therefore has very much lower melting (−210 °C) and boiling points (−196 °C) than the rest of its group, as the N molecules are only held together by weak van der Waals interactions and there are very few electrons available to create significant instantaneous dipoles.

This is not possible for its vertical neighbours; thus, the nitrogen oxides, nitrites, nitrates, nitro-, nitroso-, azo-, and diazo-compounds, azides, cyanates, thiocyanates, and imino-derivatives find no echo with phosphorus, arsenic, antimony, or bismuth. By the same token, however, the complexity of the phosphorus oxoacids finds no echo with nitrogen. Setting aside their differences, nitrogen and phosphorus form an extensive series of compounds with one another; these have chain, ring, and cage structures.

Nitrogen has two stable isotopes: N and N. The first is much more common, making up 99.634% of natural nitrogen, and the second (which is slightly heavier) makes up the remaining 0.366%. This leads to an atomic weight of around 14.007 u. Both of these stable isotopes are produced in the CNO cycle in stars, but N is more common as its neutron capture is the rate-limiting step. N is one of the five stable odd–odd nuclides (a nuclide having an odd number of protons and neutrons); the other four are H, Li, B, and Ta.

The relative abundance of N and N is practically constant in the atmosphere but can vary elsewhere, due to natural isotopic fractionation from biological redox reactions and the evaporation of natural ammonia or nitric acid. Biologically mediated reactions (e.g., assimilation, nitrification, and denitrification) strongly control nitrogen dynamics in the soil. These reactions typically result in N enrichment of the substrate and depletion of the product.

The heavy isotope N was first discovered by S. M. Naudé in 1929, soon after heavy isotopes of the neighbouring elements oxygen and carbon were discovered. It presents one of the lowest thermal neutron capture cross-sections of all isotopes. It is frequently used in nuclear magnetic resonance (NMR) spectroscopy to determine the structures of nitrogen-containing molecules, due to its fractional nuclear spin of one-half, which offers advantages for NMR such as narrower line width. N, though also theoretically usable, has an integer nuclear spin of one and thus has a quadrupole moment that leads to wider and less useful spectra. N NMR nevertheless has complications not encountered in the more common H and C NMR spectroscopy. The low natural abundance of N (0.36%) significantly reduces sensitivity, a problem which is only exacerbated by its low gyromagnetic ratio, (only 10.14% that of H). As a result, the signal-to-noise ratio for H is about 300 times as much as that for N at the same magnetic field strength. This may be somewhat alleviated by isotopic enrichment of N by chemical exchange or fractional distillation. N-enriched compounds have the advantage that under standard conditions, they do not undergo chemical exchange of their nitrogen atoms with atmospheric nitrogen, unlike compounds with labelled hydrogen, carbon, and oxygen isotopes that must be kept away from the atmosphere. The N:N ratio is commonly used in stable isotope analysis in the fields of geochemistry, hydrology, paleoclimatology and paleoceanography, where it is called "δ"N.

Of the ten other isotopes produced synthetically, ranging from N to N, N has a half-life of ten minutes and the remaining isotopes have half-lives on the order of seconds (N and N) or even milliseconds. No other nitrogen isotopes are possible as they would fall outside the nuclear drip lines, leaking out a proton or neutron. Given the half-life difference, N is the most important nitrogen radioisotope, being relatively long-lived enough to use in positron emission tomography (PET), although its half-life is still short and thus it must be produced at the venue of the PET, for example in a cyclotron via proton bombardment of O producing N and an alpha particle.

The radioisotope N is the dominant radionuclide in the coolant of pressurised water reactors or boiling water reactors during normal operation, and thus it is a sensitive and immediate indicator of leaks from the primary coolant system to the secondary steam cycle, and is the primary means of detection for such leaks. It is produced from O (in water) via an (n,p) reaction in which the O atom captures a neutron and expels a proton. It has a short half-life of about 7.1 s, but during its decay back to O produces high-energy gamma radiation (5 to 7 MeV). Because of this, access to the primary coolant piping in a pressurised water reactor must be restricted during reactor power operation.

Atomic nitrogen, also known as active nitrogen, is highly reactive, being a triradical with three unpaired electrons. Free nitrogen atoms easily react with most elements to form nitrides, and even when two free nitrogen atoms collide to produce an excited N molecule, they may release so much energy on collision with even such stable molecules as carbon dioxide and water to cause homolytic fission into radicals such as CO and O or OH and H. Atomic nitrogen is prepared by passing an electric discharge through nitrogen gas at 0.1–2 mmHg, which produces atomic nitrogen along with a peach-yellow emission that fades slowly as an afterglow for several minutes even after the discharge terminates.

Given the great reactivity of atomic nitrogen, elemental nitrogen usually occurs as molecular N, dinitrogen. This molecule is a colourless, odourless, and tasteless diamagnetic gas at standard conditions: it melts at −210 °C and boils at −196 °C. Dinitrogen is mostly unreactive at room temperature, but it will nevertheless react with lithium metal and some transition metal complexes. This is due to its bonding, which is unique among the diatomic elements at standard conditions in that it has an N≡N triple bond. Triple bonds have short bond lengths (in this case, 109.76 pm) and high dissociation energies (in this case, 945.41 kJ/mol), and are thus very strong, explaining dinitrogen's chemical inertness.

There are some theoretical indications that other nitrogen oligomers and polymers may be possible. If they could be synthesised, they may have potential applications as materials with a very high energy density, that could be used as powerful propellants or explosives. This is because they should all decompose to dinitrogen, whose N≡N triple bond (bond energy 946 kJ⋅mol) is much stronger than those of the N=N double bond (418 kJ⋅mol) or the N–N single bond (160 kJ⋅mol): indeed, the triple bond has more than thrice the energy of the single bond. (The opposite is true for the heavier pnictogens, which prefer polyatomic allotropes.) A great disadvantage is that most neutral polynitrogens are not expected to have a large barrier towards decomposition, and that the few exceptions would be even more challenging to synthesise than the long-sought but still unknown tetrahedrane. This stands in contrast to the well-characterised cationic and anionic polynitrogens azide (), pentazenium (), and pentazolide (cyclic aromatic ). Under extremely high pressures (1.1 million atm) and high temperatures (2000 K), as produced in a diamond anvil cell, nitrogen polymerises into the single-bonded cubic gauche crystal structure. This structure is similar to that of diamond, and both have extremely strong covalent bonds, resulting in its nickname "nitrogen diamond".
At atmospheric pressure, molecular nitrogen condenses (liquefies) at 77 K (−195.79 °C) and freezes at 63 K (−210.01 °C) into the beta hexagonal close-packed crystal allotropic form. Below 35.4 K (−237.6 °C) nitrogen assumes the cubic crystal allotropic form (called the alpha phase). Liquid nitrogen, a colourless fluid resembling water in appearance, but with 80.8% of the density (the density of liquid nitrogen at its boiling point is 0.808 g/mL), is a common cryogen. Solid nitrogen has many crystalline modifications. It forms a significant dynamic surface coverage on Pluto and outer moons of the Solar System such as Triton. Even at the low temperatures of solid nitrogen it is fairly volatile and can sublime to form an atmosphere, or condense back into nitrogen frost. It is very weak and flows in the form of glaciers and on Triton geysers of nitrogen gas come from the polar ice cap region.

The first example of a dinitrogen complex to be discovered was [Ru(NH)(N)] (see figure at right), and soon many other such complexes were discovered. These complexes, in which a nitrogen molecule donates at least one lone pair of electrons to a central metal cation, illustrate how N might bind to the metal(s) in nitrogenase and the catalyst for the Haber process: these processes involving dinitrogen activation are vitally important in biology and in the production of fertilisers.

Dinitrogen is able to coordinate to metals in five different ways. The more well-characterised ways are the end-on M←N≡N ("η") and M←N≡N→M ("μ", bis-"η"), in which the lone pairs on the nitrogen atoms are donated to the metal cation. The less well-characterised ways involve dinitrogen donating electron pairs from the triple bond, either as a bridging ligand to two metal cations ("μ", bis-"η") or to just one ("η"). The fifth and unique method involves triple-coordination as a bridging ligand, donating all three electron pairs from the triple bond ("μ"-N). A few complexes feature multiple N ligands and some feature N bonded in multiple ways. Since N is isoelectronic with carbon monoxide (CO) and acetylene (CH), the bonding in dinitrogen complexes is closely allied to that in carbonyl compounds, although N is a weaker "σ"-donor and "π"-acceptor than CO. Theoretical studies show that "σ" donation is a more important factor allowing the formation of the M–N bond than "π" back-donation, which mostly only weakens the N–N bond, and end-on ("η") donation is more readily accomplished than side-on ("η") donation.

Today, dinitrogen complexes are known for almost all the transition metals, accounting for several hundred compounds. They are normally prepared by three methods:
Occasionally the N≡N bond may be formed directly within a metal complex, for example by directly reacting coordinated ammonia (NH) with nitrous acid (HNO), but this is not generally applicable. Most dinitrogen complexes have colours within the range white-yellow-orange-red-brown; a few exceptions are known, such as the blue [{Ti("η"-CH)}-(N)].

Nitrogen bonds to almost all the elements in the periodic table except the first three noble gases, helium, neon, and argon, and some of the very short-lived elements after bismuth, creating an immense variety of binary compounds with varying properties and applications. Many binary compounds are known: with the exception of the nitrogen hydrides, oxides, and fluorides, these are typically called nitrides. Many stoichiometric phases are usually present for most elements (e.g. MnN, MnN, MnN, MnN, MnN, and MnN for 9.2 < "x" < 25.3). They may be classified as "salt-like" (mostly ionic), covalent, "diamond-like", and metallic (or interstitial), although this classification has limitations generally stemming from the continuity of bonding types instead of the discrete and separate types that it implies. They are normally prepared by directly reacting a metal with nitrogen or ammonia (sometimes after heating), or by thermal decomposition of metal amides:
Many variants on these processes are possible.The most ionic of these nitrides are those of the alkali metals and alkaline earth metals, LiN (Na, K, Rb, and Cs do not form stable nitrides for steric reasons) and MN (M = Be, Mg, Ca, Sr, Ba). These can formally be thought of as salts of the N anion, although charge separation is not actually complete even for these highly electropositive elements. However, the alkali metal azides NaN and KN, featuring the linear anion, are well-known, as are Sr(N) and Ba(N). Azides of the B-subgroup metals (those in groups 11 through 16) are much less ionic, have more complicated structures, and detonate readily when shocked.
Many covalent binary nitrides are known. Examples include cyanogen ((CN)), triphosphorus pentanitride (PN), disulfur dinitride (SN), and tetrasulfur tetranitride (SN). The essentially covalent silicon nitride (SiN) and germanium nitride (GeN) are also known: silicon nitride in particular would make a promising ceramic if not for the difficulty of working with and sintering it. In particular, the group 13 nitrides, most of which are promising semiconductors, are isoelectronic with graphite, diamond, and silicon carbide and have similar structures: their bonding changes from covalent to partially ionic to metallic as the group is descended. In particular, since the B–N unit is isoelectronic to C–C, and carbon is essentially intermediate in size between boron and nitrogen, much of organic chemistry finds an echo in boron–nitrogen chemistry, such as in borazine ("inorganic benzene"). Nevertheless, the analogy is not exact due to the ease of nucleophilic attack at boron due to its deficiency in electrons, which is not possible in a wholly carbon-containing ring.

The largest category of nitrides are the interstitial nitrides of formulae MN, MN, and MN (although variable composition is perfectly possible), where the small nitrogen atoms are positioned in the gaps in a metallic cubic or hexagonal close-packed lattice. They are opaque, very hard, and chemically inert, melting only at very high temperatures (generally over 2500 °C). They have a metallic lustre and conduct electricity as do metals. They hydrolyse only very slowly to give ammonia or nitrogen.

The nitride anion (N) is the strongest "π" donor known amongst ligands (the second-strongest is O). Nitrido complexes are generally made by thermal decomposition of azides or by deprotonating ammonia, and they usually involve a terminal {≡N} group. The linear azide anion (), being isoelectronic with nitrous oxide, carbon dioxide, and cyanate, forms many coordination complexes. Further catenation is rare, although (isoelectronic with carbonate and nitrate) is known.

Industrially, ammonia (NH) is the most important compound of nitrogen and is prepared in larger amounts than any other compound, because it contributes significantly to the nutritional needs of terrestrial organisms by serving as a precursor to food and fertilisers. It is a colourless alkaline gas with a characteristic pungent smell. The presence of hydrogen bonding has very significant effects on ammonia, conferring on it its high melting (−78 °C) and boiling (−33 °C) points. As a liquid, it is a very good solvent with a high heat of vaporisation (enabling it to be used in vacuum flasks), that also has a low viscosity and electrical conductivity and high dielectric constant, and is less dense than water. However, the hydrogen bonding in NH is weaker than that in HO due to the lower electronegativity of nitrogen compared to oxygen and the presence of only one lone pair in NH rather than two in HO. It is a weak base in aqueous solution (p"K" 4.74); its conjugate acid is ammonium, . It can also act as an extremely weak acid, losing a proton to produce the amide anion, . It thus undergoes self-dissociation, similar to water, to produce ammonium and amide. Ammonia burns in air or oxygen, though not readily, to produce nitrogen gas; it burns in fluorine with a greenish-yellow flame to give nitrogen trifluoride. Reactions with the other nonmetals are very complex and tend to lead to a mixture of products. Ammonia reacts on heating with metals to give nitrides.

Many other binary nitrogen hydrides are known, but the most important are hydrazine (NH) and hydrogen azide (HN). Although it is not a nitrogen hydride, hydroxylamine (NHOH) is similar in properties and structure to ammonia and hydrazine as well. Hydrazine is a fuming, colourless liquid that smells similarly to ammonia. Its physical properties are very similar to those of water (melting point 2.0 °C, boiling point 113.5 °C, density 1.00 g/cm). Despite it being an endothermic compound, it is kinetically stable. It burns quickly and completely in air very exothermically to give nitrogen and water vapour. It is a very useful and versatile reducing agent and is a weaker base than ammonia. It is also commonly used as a rocket fuel.

Hydrazine is generally made by reaction of ammonia with alkaline sodium hypochlorite in the presence of gelatin or glue:
(The attacks by hydroxide and ammonia may be reversed, thus passing through the intermediate NHCl instead.) The reason for adding gelatin is that it removes metal ions such as Cu that catalyses the destruction of hydrazine by reaction with monochloramine (NHCl) to produce ammonium chloride and nitrogen.

Hydrogen azide (HN) was first produced in 1890 by the oxidation of aqueous hydrazine by nitrous acid. It is very explosive and even dilute solutions can be dangerous. It has a disagreeable and irritating smell and is a potentially lethal (but not cumulative) poison. It may be considered the conjugate acid of the azide anion, and is similarly analogous to the hydrohalic acids.

All four simple nitrogen trihalides are known. A few mixed halides and hydrohalides are known, but are mostly unstable and uninteresting: examples include NClF, NClF, NBrF, NFH, NClH, and NClH.

Five nitrogen fluorides are known. Nitrogen trifluoride (NF, first prepared in 1928) is a colourless and odourless gas that is thermodynamically stable, and most readily produced by the electrolysis of molten ammonium fluoride dissolved in anhydrous hydrogen fluoride. Like carbon tetrafluoride, it is not at all reactive and is stable in water or dilute aqueous acids or alkalis. Only when heated does it act as a fluorinating agent, and it reacts with copper, arsenic, antimony, and bismuth on contact at high temperatures to give tetrafluorohydrazine (NF). The cations and are also known (the latter from reacting tetrafluorohydrazine with strong fluoride-acceptors such as arsenic pentafluoride), as is ONF, which has aroused interest due to the short N–O distance implying partial double bonding and the highly polar and long N–F bond. Tetrafluorohydrazine, unlike hydrazine itself, can dissociate at room temperature and above to give the radical NF•. Fluorine azide (FN) is very explosive and thermally unstable. Dinitrogen difluoride (NF) exists as thermally interconvertible "cis" and "trans" isomers, and was first found as a product of the thermal decomposition of FN.

Nitrogen trichloride (NCl) is a dense, volatile, and explosive liquid whose physical properties are similar to those of carbon tetrachloride, although one difference is that NCl is easily hydrolysed by water while CCl is not. It was first synthesised in 1811 by Pierre Louis Dulong, who lost three fingers and an eye to its explosive tendencies. As a dilute gas it is less dangerous and is thus used industrially to bleach and sterilise flour. Nitrogen tribromide (NBr), first prepared in 1975, is a deep red, temperature-sensitive, volatile solid that is explosive even at −100 °C. Nitrogen triiodide (NI) is still more unstable and was only prepared in 1990. Its adduct with ammonia, which was known earlier, is very shock-sensitive: it can be set off by the touch of a feather, shifting air currents, or even alpha particles. For this reason, small amounts of nitrogen triiodide are sometimes synthesised as a demonstration to high school chemistry students or as an act of "chemical magic". Chlorine azide (ClN) and bromine azide (BrN) are extremely sensitive and explosive.

Two series of nitrogen oxohalides are known: the nitrosyl halides (XNO) and the nitryl halides (XNO). The first are very reactive gases that can be made by directly halogenating nitrous oxide. Nitrosyl fluoride (NOF) is colourless and a vigorous fluorinating agent. Nitrosyl chloride (NOCl) behaves in much the same way and has often been used as an ionising solvent. Nitrosyl bromide (NOBr) is red. The reactions of the nitryl halides are mostly similar: nitryl fluoride (FNO) and nitryl chloride (ClNO) are likewise reactive gases and vigorous halogenating agents.

Nitrogen forms nine molecular oxides, some of which were the first gases to be identified: NO (nitrous oxide), NO (nitric oxide), NO (dinitrogen trioxide), NO (nitrogen dioxide), NO (dinitrogen tetroxide), NO (dinitrogen pentoxide), NO (nitrosylazide), and N(NO) (trinitramide). All are thermally unstable towards decomposition to their elements. One other possible oxide that has not yet been synthesised is oxatetrazole (NO), an aromatic ring.

Nitrous oxide (NO), better known as laughing gas, is made by thermal decomposition of molten ammonium nitrate at 250 °C. This is a redox reaction and thus nitric oxide and nitrogen are also produced as byproducts. It is mostly used as a propellant and aerating agent for sprayed canned whipped cream, and was formerly commonly used as an anaesthetic. Despite appearances, it cannot be considered to be the anhydride of hyponitrous acid (HNO) because that acid is not produced by the dissolution of nitrous oxide in water. It is rather unreactive (not reacting with the halogens, the alkali metals, or ozone at room temperature, although reactivity increases upon heating) and has the unsymmetrical structure N–N–O (N≡NO↔N=N=O): above 600 °C it dissociates by breaking the weaker N–O bond.

Nitric oxide (NO) is the simplest stable molecule with an odd number of electrons. In mammals, including humans, it is an important cellular signaling molecule involved in many physiological and pathological processes. It is formed by catalytic oxidation of ammonia. It is a colourless paramagnetic gas that, being thermodynamically unstable, decomposes to nitrogen and oxygen gas at 1100–1200 °C. Its bonding is similar to that in nitrogen, but one extra electron is added to a "π"* antibonding orbital and thus the bond order has been reduced to approximately 2.5; hence dimerisation to O=N–N=O is unfavourable except below the boiling point (where the "cis" isomer is more stable) because it does not actually increase the total bond order and because the unpaired electron is delocalised across the NO molecule, granting it stability. There is also evidence for the asymmetric red dimer O=N–O=N when nitric oxide is condensed with polar molecules. It reacts with oxygen to give brown nitrogen dioxide and with halogens to give nitrosyl halides. It also reacts with transition metal compounds to give nitrosyl complexes, most of which are deeply coloured.

Blue dinitrogen trioxide (NO) is only available as a solid because it rapidly dissociates above its melting point to give nitric oxide, nitrogen dioxide (NO), and dinitrogen tetroxide (NO). The latter two compounds are somewhat difficult to study individually because of the equilibrium between them, although sometimes dinitrogen tetroxide can react by heterolytic fission to nitrosonium and nitrate in a medium with high dielectric constant. Nitrogen dioxide is an acrid, corrosive brown gas. Both compounds may be easily prepared by decomposing a dry metal nitrate. Both react with water to form nitric acid. Dinitrogen tetroxide is very useful for the preparation of anhydrous metal nitrates and nitrato complexes, and it became the storable oxidiser of choice for many rockets in both the United States and USSR by the late 1950s. This is because it is a hypergolic propellant in combination with a hydrazine-based rocket fuel and can be easily stored since it is liquid at room temperature.

The thermally unstable and very reactive dinitrogen pentoxide (NO) is the anhydride of nitric acid, and can be made from it by dehydration with phosphorus pentoxide. It is of interest for the preparation of explosives. It is a deliquescent, colourless crystalline solid that is sensitive to light. In the solid state it is ionic with structure [NO][NO]; as a gas and in solution it is molecular ON–O–NO. Hydration to nitric acid comes readily, as does analogous reaction with hydrogen peroxide giving peroxonitric acid (HOONO). It is a violent oxidising agent. Gaseous dinitrogen pentoxide decomposes as follows:

Many nitrogen oxoacids are known, though most of them are unstable as pure compounds and are known only as aqueous solution or as salts. Hyponitrous acid (HNO) is a weak diprotic acid with the structure HON=NOH (p"K" 6.9, p"K" 11.6). Acidic solutions are quite stable but above pH 4 base-catalysed decomposition occurs via [HONNO] to nitrous oxide and the hydroxide anion. Hyponitrites (involving the anion) are stable to reducing agents and more commonly act as reducing agents themselves. They are an intermediate step in the oxidation of ammonia to nitrite, which occurs in the nitrogen cycle. Hyponitrite can act as a bridging or chelating bidentate ligand.

Nitrous acid (HNO) is not known as a pure compound, but is a common component in gaseous equilibria and is an important aqueous reagent: its aqueous solutions may be made from acidifying cool aqueous nitrite (, bent) solutions, although already at room temperature disproportionation to nitrate and nitric oxide is significant. It is a weak acid with p"K" 3.35 at 18 °C. They may be titrimetrically analysed by their oxidation to nitrate by permanganate. They are readily reduced to nitrous oxide and nitric oxide by sulfur dioxide, to hyponitrous acid with tin(II), and to ammonia with hydrogen sulfide. Salts of hydrazinium react with nitrous acid to produce azides which further react to give nitrous oxide and nitrogen. Sodium nitrite is mildly toxic in concentrations above 100 mg/kg, but small amounts are often used to cure meat and as a preservative to avoid bacterial spoilage. It is also used to synthesise hydroxylamine and to diazotise primary aromatic amines as follows:

Nitrite is also a common ligand that can coordinate in five ways. The most common are nitro (bonded from the nitrogen) and nitrito (bonded from an oxygen). Nitro-nitrito isomerism is common, where the nitrito form is usually less stable.
Nitric acid (HNO) is by far the most important and the most stable of the nitrogen oxoacids. It is one of the three most used acids (the other two being sulfuric acid and hydrochloric acid) and was first discovered by the alchemists in the 13th century. It is made by catalytic oxidation of ammonia to nitric oxide, which is oxidised to nitrogen dioxide, and then dissolved in water to give concentrated nitric acid. In the United States of America, over seven million tonnes of nitric acid are produced every year, most of which is used for nitrate production for fertilisers and explosives, among other uses. Anhydrous nitric acid may be made by distilling concentrated nitric acid with phosphorus pentoxide at low pressure in glass apparatus in the dark. It can only be made in the solid state, because upon melting it spontaneously decomposes to nitrogen dioxide, and liquid nitric acid undergoes self-ionisation to a larger extent than any other covalent liquid as follows:
Two hydrates, HNO·HO and HNO·3HO, are known that can be crystallised. It is a strong acid and concentrated solutions are strong oxidising agents, though gold, platinum, rhodium, and iridium are immune to attack. A 3:1 mixture of concentrated hydrochloric acid and nitric acid, called "aqua regia", is still stronger and successfully dissolves gold and platinum, because free chlorine and nitrosyl chloride are formed and chloride anions can form strong complexes. In concentrated sulfuric acid, nitric acid is protonated to form nitronium, which can act as an electrophile for aromatic nitration:
The thermal stabilities of nitrates (involving the trigonal planar anion) depends on the basicity of the metal, and so do the products of decomposition (thermolysis), which can vary between the nitrite (for example, sodium), the oxide (potassium and lead), or even the metal itself (silver) depending on their relative stabilities. Nitrate is also a common ligand with many modes of coordination.

Finally, although orthonitric acid (HNO), which would be analogous to orthophosphoric acid, does not exist, the tetrahedral orthonitrate anion is known in its sodium and potassium salts:
These white crystalline salts are very sensitive to water vapour and carbon dioxide in the air:
Despite its limited chemistry, the orthonitrate anion is interesting from a structural point of view due to its regular tetrahedral shape and the short N–O bond lengths, implying significant polar character to the bonding.

Nitrogen is one of the most important elements in organic chemistry. Many organic functional groups involve a carbon–nitrogen bond, such as amides (RCONR), amines (RN), imines (RC(=NR)R), imides (RCO)NR, azides (RN), azo compounds (RNR), cyanates and isocyanates (ROCN or RCNO), nitrates (RONO), nitriles and isonitriles (RCN or RNC), nitrites (RONO), nitro compounds (RNO), nitroso compounds (RNO), oximes (RCR=NOH), and pyridine derivatives. C–N bonds are strongly polarised towards nitrogen. In these compounds, nitrogen is usually trivalent (though it can be tetravalent in quaternary ammonium salts, RN), with a lone pair that can confer basicity on the compound by being coordinated to a proton. This may be offset by other factors: for example, amides are not basic because the lone pair is delocalised into a double bond (though they may act as acids at very low pH, being protonated at the oxygen), and pyrrole is not acidic because the lone pair is delocalised as part of an aromatic ring. The amount of nitrogen in a chemical substance can be determined by the Kjeldahl method. In particular, nitrogen is an essential component of nucleic acids, amino acids and thus proteins, and the energy-carrying molecule adenosine triphosphate and is thus vital to all life on Earth.

Nitrogen is the most common pure element in the earth, making up 78.1% of the entire volume of the atmosphere. Despite this, it is not very abundant in Earth's crust, making up only 19 parts per million of this, on par with niobium, gallium, and lithium. The only important nitrogen minerals are nitre (potassium nitrate, saltpetre) and sodanitre (sodium nitrate, Chilean saltpetre). However, these have not been an important source of nitrates since the 1920s, when the industrial synthesis of ammonia and nitric acid became common.

Nitrogen compounds constantly interchange between the atmosphere and living organisms. Nitrogen must first be processed, or "fixed", into a plant-usable form, usually ammonia. Some nitrogen fixation is done by lightning strikes producing the nitrogen oxides, but most is done by diazotrophic bacteria through enzymes known as nitrogenases (although today industrial nitrogen fixation to ammonia is also significant). When the ammonia is taken up by plants, it is used to synthesise proteins. These plants are then digested by animals who use the nitrogen compounds to synthesise their own proteins and excrete nitrogen–bearing waste. Finally, these organisms die and decompose, undergoing bacterial and environmental oxidation and denitrification, returning free dinitrogen to the atmosphere. Industrial nitrogen fixation by the Haber process is mostly used as fertiliser, although excess nitrogen–bearing waste, when leached, leads to eutrophication of freshwater and the creation of marine dead zones, as nitrogen-driven bacterial growth depletes water oxygen to the point that all higher organisms die. Furthermore, nitrous oxide, which is produced during denitrification, attacks the atmospheric ozone layer.

Many saltwater fish manufacture large amounts of trimethylamine oxide to protect them from the high osmotic effects of their environment; conversion of this compound to dimethylamine is responsible for the early odour in unfresh saltwater fish. In animals, free radical nitric oxide (derived from an amino acid), serves as an important regulatory molecule for circulation.

Nitric oxide's rapid reaction with water in animals results in production of its metabolite nitrite. Animal metabolism of nitrogen in proteins, in general, results in excretion of urea, while animal metabolism of nucleic acids results in excretion of urea and uric acid. The characteristic odour of animal flesh decay is caused by the creation of long-chain, nitrogen-containing amines, such as putrescine and cadaverine, which are breakdown products of the amino acids ornithine and lysine, respectively, in decaying proteins.

Nitrogen gas is an industrial gas produced by the fractional distillation of liquid air, or by mechanical means using gaseous air (pressurised reverse osmosis membrane or pressure swing adsorption). Nitrogen gas generators using membranes or pressure swing adsorption (PSA) are typically more cost and energy efficient than bulk delivered nitrogen. Commercial nitrogen is often a byproduct of air-processing for industrial concentration of oxygen for steelmaking and other purposes. When supplied compressed in cylinders it is often called OFN (oxygen-free nitrogen). Commercial-grade nitrogen already contains at most 20 ppm oxygen, and specially purified grades containing at most 2 ppm oxygen and 10 ppm argon are also available.

In a chemical laboratory, it is prepared by treating an aqueous solution of ammonium chloride with sodium nitrite.

Small amounts of the impurities NO and HNO are also formed in this reaction. The impurities can be removed by passing the gas through aqueous sulfuric acid containing potassium dichromate. Very pure nitrogen can be prepared by the thermal decomposition of barium azide or sodium azide.

The applications of nitrogen compounds are naturally extremely widely varied due to the huge size of this class: hence, only applications of pure nitrogen itself will be considered here. Two-thirds of nitrogen produced by industry is sold as the gas and the remaining one-third as the liquid. The gas is mostly used as an inert atmosphere whenever the oxygen in the air would pose a fire, explosion, or oxidising hazard. Some examples include:

Nitrogen is commonly used during sample preparation in chemical analysis. It is used to concentrate and reduce the volume of liquid samples. Directing a pressurised stream of nitrogen gas perpendicular to the surface of the liquid causes the solvent to evaporate while leaving the solute(s) and un-evaporated solvent behind.

Nitrogen can be used as a replacement, or in combination with, carbon dioxide to pressurise kegs of some beers, particularly stouts and British ales, due to the smaller bubbles it produces, which makes the dispensed beer smoother and headier. A pressure-sensitive nitrogen capsule known commonly as a "widget" allows nitrogen-charged beers to be packaged in cans and bottles. Nitrogen tanks are also replacing carbon dioxide as the main power source for paintball guns. Nitrogen must be kept at higher pressure than CO, making N tanks heavier and more expensive. Nitrogen gas has become the inert gas of choice for inert gas asphyxiation, and is under consideration as a replacement for lethal injection in Oklahoma. Nitrogen gas, formed from the decomposition of sodium azide, is used for the inflation of airbags.

Liquid nitrogen is a cryogenic liquid. When insulated in proper containers such as Dewar flasks, it can be transported without much evaporative loss.
Like dry ice, the main use of liquid nitrogen is as a refrigerant. Among other things, it is used in the cryopreservation of blood, reproductive cells (sperm and egg), and other biological samples and materials. It is used in the clinical setting in cryotherapy to remove cysts and warts on the skin. It is used in cold traps for certain laboratory equipment and to cool infrared detectors or X-ray detectors. It has also been used to cool central processing units and other devices in computers that are overclocked, and that produce more heat than during normal operation. Other uses include freeze-grinding and machining materials that are soft or rubbery at room temperature, shrink-fitting and assembling engineering components, and more generally to attain very low temperatures whenever necessary (around −200 °C). Because of its low cost, liquid nitrogen is also often used when such low temperatures are not strictly necessary, such as refrigeration of food, freeze-branding livestock, freezing pipes to halt flow when valves are not present, and consolidating unstable soil by freezing whenever excavation is going on underneath.

Liquid nitrogen is extensively used in vacuum pump systems.

Although nitrogen is non-toxic, when released into an enclosed space it can displace oxygen, and therefore presents an asphyxiation hazard. This may happen with few warning symptoms, since the human carotid body is a relatively poor and slow low-oxygen (hypoxia) sensing system. An example occurred shortly before the launch of the first Space Shuttle mission on March 19, 1981, when two technicians died from asphyxiation after they walked into a space located in the Shuttle's Mobile Launcher Platform that was pressurised with pure nitrogen as a precaution against fire.

When inhaled at high partial pressures (more than about 4 bar, encountered at depths below about 30 m in scuba diving), nitrogen is an anesthetic agent, causing nitrogen narcosis, a temporary state of mental impairment similar to nitrous oxide intoxication.

Nitrogen dissolves in the blood and body fats. Rapid decompression (as when divers ascend too quickly or astronauts decompress too quickly from cabin pressure to spacesuit pressure) can lead to a potentially fatal condition called decompression sickness (formerly known as caisson sickness or "the bends"), when nitrogen bubbles form in the bloodstream, nerves, joints, and other sensitive or vital areas. Bubbles from other "inert" gases (gases other than carbon dioxide and oxygen) cause the same effects, so replacement of nitrogen in breathing gases may prevent nitrogen narcosis, but does not prevent decompression sickness.

As a cryogenic liquid, liquid nitrogen can be dangerous by causing cold burns on contact, although the Leidenfrost effect provides protection for very short exposure (about one second). Ingestion of liquid nitrogen can cause severe internal damage. For example, in 2012, a young woman in England had to have her stomach removed after ingesting a cocktail made with liquid nitrogen.

Because the liquid-to-gas expansion ratio of nitrogen is 1:694 at 20 °C, a tremendous amount of force can be generated if liquid nitrogen is rapidly vaporised in an enclosed space. In an incident on January 12, 2006 at Texas A&M University, the pressure-relief devices of a tank of liquid nitrogen were malfunctioning and later sealed. As a result of the subsequent pressure buildup, the tank failed catastrophically. The force of the explosion was sufficient to propel the tank through the ceiling immediately above it, shatter a reinforced concrete beam immediately below it, and blow the walls of the laboratory 0.1–0.2 m off their foundations.

Liquid nitrogen readily evaporates to form gaseous nitrogen, and hence the precautions associated with gaseous nitrogen also apply to liquid nitrogen. For example, oxygen sensors are sometimes used as a safety precaution when working with liquid nitrogen to alert workers of gas spills into a confined space.

Vessels containing liquid nitrogen can condense oxygen from air. The liquid in such a vessel becomes increasingly enriched in oxygen (boiling point −183 °C, higher than that of nitrogen) as the nitrogen evaporates, and can cause violent oxidation of organic material.




</doc>
<doc id="21176" url="https://en.wikipedia.org/wiki?curid=21176" title="Nominalism">
Nominalism

Nominalism is a philosophical view which comes at least in two varieties. In one of them it is the rejection of abstract objects, in the other it is the rejection of universals. 

The opposite of nominalism is realism. Plato was perhaps the first writer in Western philosophy to clearly state a realist i.e. non-nominalist position:

What about someone who believes in beautiful things, but doesn't believe in the beautiful itself…? Don't you think he is living in a dream rather than a wakened state? ("Republic" 476c)

The Platonic universals corresponding to the names "bed" and "beautiful" were the Form of the Bed and the Form of the Beautiful, or the "Bed Itself" and the "Beautiful Itself". Platonic Forms were the first universals posited as such in philosophy.

Our term "universal" is due to the English translation of Aristotle's technical term "katholou" which he coined specially for the purpose of discussing the problem of universals. "Katholou" is a contraction of the phrase "kata holou", meaning "on the whole".

Aristotle famously rejected certain aspects of Plato's Theory of Forms, but he clearly rejected nominalism as well:

...'Man', and indeed every general predicate, signifies not an individual, but some quality, or quantity or relation, or something of that sort. ("Sophistical Refutations" xxii, 178b37, trans. Pickard-Cambridge)

The first philosophers to explicitly describe nominalist arguments were the Stoics, especially Chrysippus.

In medieval philosophy, the French philosopher and theologian Roscellinus (c. 1050 – c. 1125) was an early, prominent proponent of nominalism. Nominalist ideas can be found in the work of Peter Abelard and reached their flowering in William of Ockham, who was the most influential and thorough nominalist. Abelard's and Ockham's version of nominalism is sometimes called conceptualism, which presents itself as a middle way between nominalism and realism, asserting that there "is" something in common among like individuals, but that it is a concept in the mind, rather than a real entity existing independently of the mind. Ockham argued that only individuals existed and that universals were only mental ways of referring to sets of individuals. "I maintain", he wrote, "that a universal is not something real that exists in a subject... but that it has a being only as a thought-object in the mind [objectivum in anima]". As a general rule, Ockham argued against assuming any entities that were not necessary for explanations. Accordingly, he wrote, there is no reason to believe that there is an entity called "humanity" that resides inside, say, Socrates, and nothing further is explained by making this claim. This is in accord with the analytical method that has since come to be called Ockham's razor, the principle that the explanation of any phenomenon should make as few assumptions as possible. Critics argue that conceptualist approaches only answer the psychological question of universals. If the same concept is "correctly" and non-arbitrarily applied to two individuals, there must be some resemblance or shared property between the two individuals that justifies their falling under the same concept and that is just the metaphysical problem that universals were brought in to address, the starting-point of the whole problem (MacLeod & Rubenstein, 2006, §3d). If resemblances between individuals are asserted, conceptualism becomes moderate realism; if they are denied, it collapses into nominalism.

In modern philosophy, nominalism was revived by Thomas Hobbes and Pierre Gassendi.

In contemporary analytic philosophy, it has been defended by Rudolf Carnap, Nelson Goodman, H. H. Price, and D. C. Williams.

The debate between realism and nominalism also took place in Indian philosophy. Certain orthodox Hindu schools (eg., Purva Mimamsa, Nyaya and Vaisheshika) defended the realist position, saying that the referent of the word is both the individual thing perceived by the subject of knowledge and the class to which the thing belongs. According to Indian realism, both the individual and the class have objective existence, with the second underlying the former.

The Buddhists, especially those of the Yogacara school, took the nominalist position; they were of the opinion that words have as referent, not true objects, but only concepts produced in the intellect. These concepts are not real since they do not have efficient existence, that is, causal powers. Words, as linguistic conventions, are useful to thought and discourse, but even so, it should not be accepted that words apprehend reality as it is.

Dignaga, a Yogacara philosopher, formulated a nominalist theory of meaning called "apoha", or theory of exclusions. The theory seeks to explain how it is possible for words to refer to classes of objects even if no such class has an objective existence. Dignaga's thesis is that classes do not refer to positive qualities that their members share in common. On the contrary, classes are exclusions ("apoha"). As such, the "cow" class, for example, is composed of all exclusions common to individual cows: they are all non-horse, non-elephant, etc.

Among Hindu realists, this thesis was criticized for being negative.

Nominalism arose in reaction to the problem of universals, specifically accounting for the fact that some things are of the same type. For example, Fluffy and Kitzler are both cats, or, the fact that certain properties are repeatable, such as: the grass, the shirt, and Kermit the Frog are green. One wants to know by virtue of "what" are Fluffy and Kitzler both cats, and "what" makes the grass, the shirt, and Kermit green.

The Platonist answer is that all the green things are green in virtue of the existence of a universal: a single abstract thing that, in this case, is a part of all the green things. With respect to the color of the grass, the shirt and Kermit, one of their parts is identical. In this respect, the three parts are literally one. Greenness is repeatable because there is one thing that manifests itself wherever there are green things.

Nominalism denies the existence of universals. The motivation for this flows from several concerns, the first one being where they might exist. Plato famously held, on one interpretation, that there is a realm of abstract forms or universals apart from the physical world (see theory of the forms). Particular physical objects merely exemplify or instantiate the universal. But this raises the question: Where is this universal realm? One possibility is that it is outside space and time. A view sympathetic with this possibility holds that, precisely because some form is immanent in several physical objects, it must also transcend each of those physical objects; in this way, the forms are "transcendent" only insofar as they are "immanent" in many physical objects. In other words, immanence implies transcendence; they are not opposed to one another. (Nor, in this view, would there be a separate "world" or "realm" of forms that is distinct from the physical world, thus shirking much of the worry about where to locate a "universal realm".) However, naturalists assert that nothing is outside of space and time. Some Neoplatonists, such as the pagan philosopher Plotinus and the Christian philosopher Augustine, imply (anticipating conceptualism) that universals are contained within the "mind" of God. To complicate things, what is the nature of the instantiation or exemplification relation?

Conceptualists hold a position intermediate between nominalism and realism, saying that universals exist only within the mind and have no external or substantial reality.

Moderate realists hold that there is no realm in which universals exist, but rather universals are located in space and time wherever they are manifest. Now, recall that a universal, like greenness, is supposed to be a single thing. Nominalists consider it unusual that there could be a single thing that exists in multiple places simultaneously. The realist maintains that all the instances of greenness are held together by the exemplification relation, but this relation cannot be explained.

Finally, many philosophers prefer simpler ontologies populated with only the bare minimum of types of entities, or as W. V. O. Quine said "They have a taste for 'desert landscapes.'" They try to express everything that they want to explain without using universals such as "catness" or "greenness."

There are various forms of nominalism ranging from extreme to almost-realist. One extreme is predicate nominalism, which states that Fluffy and Kitzler, for example, are both cats simply because the predicate 'is a cat' applies to both of them. And this is the case for all similarity of attribute among objects. The main criticism of this view is that it does not provide a sufficient solution to the problem of universals. It fails to provide an account of what makes it the case that a group of things warrant having the same predicate applied to them.

Proponents of resemblance nominalism believe that 'cat' applies to both cats because Fluffy and Kitzler resemble an exemplar cat closely enough to be classed together with it as members of its kind, or that they differ from each other (and other cats) quite less than they differ from other things, and this warrants classing them together. Some resemblance nominalists will concede that the resemblance relation is itself a universal, but is the only universal necessary. Others argue that each resemblance relation is a particular, and is a resemblance relation simply in virtue of its resemblance to other resemblance relations. This generates an infinite regress, but many argue that it is not vicious.

Class nominalism argues that class membership forms the metaphysical backing for property relationships: two particular red balls share a property in that they are both members of classes corresponding to their properties—that of being red and being balls. A version of class nominalism that sees some classes as "natural classes" is held by Anthony Quinton.

Conceptualism is a philosophical theory that explains universality of particulars as conceptualized frameworks situated within the thinking mind. The conceptualist view approaches the metaphysical concept of universals from a perspective that denies their presence in particulars outside of the mind's perception of them.

Another form of nominalism is trope nominalism. A trope is a particular instance of a property, like the specific greenness of a shirt. One might argue that there is a primitive, objective resemblance relation that holds among like tropes. Another route is to argue that all apparent tropes are constructed out of more primitive tropes and that the most primitive tropes are the entities of complete physics. Primitive trope resemblance may thus be accounted for in terms of causal indiscernibility. Two tropes are exactly resembling if substituting one for the other would make no difference to the events in which they are taking part. Varying degrees of resemblance at the macro level can be explained by varying degrees of resemblance at the micro level, and micro-level resemblance is explained in terms of something no less robustly physical than causal power. David Armstrong, perhaps the most prominent contemporary realist, argues that such a trope-based variant of nominalism has promise, but holds that it is unable to account for the laws of nature in the way his theory of universals can.

Ian Hacking has also argued that much of what is called social constructionism of science in contemporary times is actually motivated by an unstated nominalist metaphysical view. For this reason, he claims, scientists and constructionists tend to "shout past each other".

A notion that philosophy, especially ontology and the philosophy of mathematics, should abstain from set theory owes much to the writings of Nelson Goodman (see especially Goodman 1940 and 1977), who argued that concrete and abstract entities having no parts, called "individuals" exist. Collections of individuals likewise exist, but two collections having the same individuals are the same collection. Goodman was himself drawing heavily on the work of Stanisław Leśniewski, especially his mereology, which was itself a reaction to the paradoxes associated with Cantorian set theory. Leśniewski denied the existence of the empty set and held that any singleton was identical to the individual inside it. Classes corresponding to what are held to be species or genera are concrete sums of their concrete constituting individuals. For example, the class of philosophers is nothing but the sum of all concrete, individual philosophers.

The principle of extensionality in set theory assures us that any matching pair of curly braces enclosing one or more instances of the same individuals denote the same set. Hence {"a", "b"}, {"b", "a"}, {"a", "b", "a", "b"} are all the same set. For Goodman and other proponents of mathematical nominalism, {"a", "b"} is also identical to {"a", {"b"} }, {"b", {"a", "b"} }, and any combination of matching curly braces and one or more instances of "a" and "b", as long as "a" and "b" are names of individuals and not of collections of individuals. Goodman, Richard Milton Martin, and Willard Quine all advocated reasoning about collectivities by means of a theory of "virtual sets" (see especially Quine 1969), one making possible all elementary operations on sets except that the universe of a quantified variable cannot contain any virtual sets.

In the foundations of mathematics, nominalism has come to mean doing mathematics without assuming that sets in the mathematical sense exist. In practice, this means that quantified variables may range over universes of numbers, points, primitive ordered pairs, and other abstract ontological primitives, but not over sets whose members are such individuals. To date, only a small fraction of the corpus of modern mathematics can be rederived in a nominalistic fashion.

As a category of late medieval thought, the concept of 'nominalism' has been increasingly queried. Traditionally, the fourteenth century has been regarded as the heyday of nominalism, with figures such as John Buridan and William of Ockham viewed as founding figures. However, the concept of 'nominalism' as a movement (generally contrasted with 'realism'), first emerged only in the late fourteenth century, and only gradually became widespread during the fifteenth century. The notion of two distinct ways, a "via antiqua", associated with realism, and a "via moderna", associated with nominalism, became widespread only in the later fifteenth century – a dispute which eventually dried up in the sixteenth century.

Aware that explicit thinking in terms of a divide between 'nominalism' and 'realism' only emerged in the fifteenth century, scholars have increasingly questioned whether a fourteenth-century school of nominalism can really be said to have existed. While one might speak of family resemblances between Ockham, Buridan, Marsilius and others, there are also striking differences. More fundamentally, Robert Pasnau has questioned whether any kind of coherent body of thought that could be called 'nominalism' can be discerned in fourteenth century writing. This makes it difficult, it has been argued, to follow the twentieth century narrative which portrayed late scholastic philosophy as a dispute which emerged in the fourteenth century between the "via moderna", nominalism, and the "via antiqua", realism, with the nominalist ideas of William of Ockham foreshadowing the eventual rejection of scholasticism in the seventeenth century.

A critique of nominalist reconstructions in mathematics was undertaken by Burgess (1983) and Burgess and Rosen (1997). Burgess distinguished two types of nominalist reconstructions. Thus, "hermeneutic nominalism" is the hypothesis that science, properly interpreted, already dispenses with mathematical objects
(entities) such as numbers and sets. Meanwhile, "revolutionary nominalism" is the project of replacing current scientific theories by alternatives dispensing with mathematical objects (see Burgess, 1983, p. 96). A recent study extends the Burgessian critique to three nominalistic reconstructions: the reconstruction of analysis by Georg Cantor, Richard Dedekind, and Karl Weierstrass that dispensed with infinitesimals; the constructivist re-reconstruction of Weierstrassian analysis by Errett Bishop that dispensed with the law of excluded middle; and the hermeneutic reconstruction, by Carl Boyer, Judith Grabiner, and others, of Cauchy's foundational contribution to analysis that dispensed with Cauchy's infinitesimals.





</doc>
<doc id="21178" url="https://en.wikipedia.org/wiki?curid=21178" title="Non-cognitivism">
Non-cognitivism

Non-cognitivism is the meta-ethical view that ethical sentences do not express propositions (i.e., statements) and thus cannot be true or false (they are not truth-apt). A noncognitivist denies the cognitivist claim that "moral judgments are capable of being objectively true, because they describe some feature of the world". If moral statements cannot be true, and if one cannot know something that is not true, noncognitivism implies that moral knowledge is impossible.

Non-cognitivism entails that non-cognitive attitudes underlie moral discourse and this discourse therefore consists of non-declarative speech acts, although accepting that its surface features may consistently and efficiently work as if moral discourse were cognitive. The point of interpreting moral claims as non-declarative speech acts is to explain what moral claims mean if they are neither true nor false (as philosophies such as logical positivism entail). Utterances like "Boo to killing!" and "Don't kill" are not candidates for truth or falsity, but have non-cognitive meaning.

Emotivism, associated with A. J. Ayer, the Vienna Circle and C. L. Stevenson, suggests that ethical sentences are primarily emotional expressions of one's own attitudes and are intended to influence the actions of the listener. Under this view, "Killing is wrong" is translated as "Killing, boo!" or "I disapprove of killing."

A close cousin of emotivism, developed by R. M. Hare, is called universal prescriptivism. Prescriptivists interpret ethical statements as being universal "imperatives", prescribing behavior for all to follow. According to prescriptivism, 
phrases like "Thou shalt not murder!" or "Do not steal!" are the clearest expressions of morality, while reformulations like "Killing is wrong" tend to obscure the meaning of moral sentences.

Other forms of non-cognitivism include Simon Blackburn's quasi-realism and Allan Gibbard's norm-expressivism.

Arguments for prescriptivism focus on the "function" of normative statements.

Prescriptivists argue that factual statements and prescriptions are totally different, because of different expectations of change in cases of a clash between word and world.
In a descriptive sentence, if one premises that "red is a number" then according to the rules of English grammar said statement would be false. Since said premise describes the objects "red" and "number", anyone with an adequate understanding of English would notice the falseness of such description and the falseness of said statement. However, if the norm "thou shalt not kill!" is uttered, and this premise is negated (by the fact of a person being murdered), the speaker is not to change his sentence upon observation of this into "kill other people!", but is to reiterate the moral outrage of the act of killing. Adjusting statements based upon objective reality and adjusting reality based upon statements are contrary uses of language; that is to say, descriptive statements are a different kind of sentence to normative statements. If truth is understood according to correspondence theory, the question of the truth or falsity of sentences not contingent upon external phenomena cannot be tested (see tautologies).

Some cognitivists argue that some expressions like "courageous" have both a factual as well as a normative component which cannot be distinguished by analysis. Prescriptivists argue that according to context, either the factual or the normative component of the meaning is dominant. The sentence "Hero A behaved courageously" is wrong, if A ran away in the face of danger. But the sentence "Be brave and fight for the glory of your country!" has no truth value and cannot be falsified by someone who doesn't join the army.

Prescriptivism is also supported by the actual way of speaking. Many moral statements are de facto uttered as recommendations or commands, e.g. when parents or teachers forbid children to do wrong actions. The most famous moral ideas are prescriptions: the Ten Commandments, the command of charity, the categorical imperative, and the Golden Rule command to do or not to do something rather than state that something is or is not the case.

Prescriptivism can fit the theist idea of morality as obedience towards god. It is however different from the cognitivist supernaturalism which interprets morality as subjective will of god, while prescriptivism claims that moral rules are universal and can be found by reason alone without reference to a god.

According to Hare, prescriptivists cannot argue that amoralists are logically wrong or contradictive. Everyone can choose to follow moral commands or not. This is the human condition according to the Christian reinterpretation of the Choice of Heracles. According to prescriptivism, morality is not about knowledge (of moral facts), but about character (to choose to do the right thing). Actors cannot externalize their responsibility and freedom of will towards some moral truth in the world, virtuous people don't need to wait for some cognition to choose what's right.

Prescriptivism is also supported by imperative logic, in which there are no truth values for imperatives, and by the idea of the naturalistic fallacy: even if someone could prove the existence of an ethical property and express it in a factual statement, he could never derive any command from this statement, so the search for ethical properties is pointless.

As with other anti-realist meta-ethical theories, non-cognitivism is largely supported by the argument from queerness: ethical properties, if they existed, would be different from any other thing in the universe, since they have no observable effect on the world. People generally have a negative attitude towards murder, which presumably keeps most of us from murdering. But does the actual "wrongness" of murder play an "independent" role? Is there any evidence that there is a property of wrongness that some types of acts have? Some people might think that the strong feelings we have when we see or consider a murder provide evidence of murder's wrongness. But it is not difficult to explain these feelings without saying that "wrongness" was their cause. Thus there is no way of discerning which, if any, ethical properties exist; by Occam's razor, the simplest assumption is that none do. The non-cognitivist then asserts that, since a proposition about an ethical property would have no referent, ethical statements must be something else.

Arguments for emotivism focus on what normative statements "express" when uttered by a speaker. A person who says that killing is wrong certainly expresses her disapproval of killing. Emotivists claim that this is "all" she does, that the statement "killing is wrong" is not a truth-apt declaration, and that the burden of evidence is on the cognitivists who want to show that in addition to expressing disapproval, the claim "killing is wrong" is also true. Emotivists ask whether there really is evidence that killing is wrong. We have evidence that Jupiter has a magnetic field and that birds are oviparous, but as yet, we do not seem to have found evidence of moral properties, such as "goodness". Emotivists ask why, without such evidence, we should think there "is" such a property. Ethical intuitionists think the evidence comes not from science or reason but from our own feelings: good deeds make us feel a certain way and bad deeds make us feel very differently. But is this enough to show that there are genuinely good and bad deeds? Emotivists think not, claiming that we do not need to postulate the existence of moral "badness" or "wrongness" to explain why considering certain deeds makes us feel disapproval; that all we really observe when we introspect are feelings of disapproval. Thus the emotivist asks why not adopt the simple explanation and say that this is all there is, rather than insist that some intrinsic "badness" (of murder, for example) must be causing feelings when a simpler explanation is available.

One argument against non-cognitivism is that it ignores the external "causes" of emotional and prescriptive reactions. If someone says, "John is a good person," something about John must have inspired that reaction. If John gives to the poor, takes care of his sick grandmother, and is friendly to others, and these are what inspire the speaker to think well of him, it is plausible to say, "John is a good person because he gives to the poor, takes care of his sick grandmother, and is friendly to others." If, in turn, the speaker responds positively to the idea of giving to the poor, then some aspect of that idea must have inspired a positive response; one could argue that that aspect is also the basis of its goodness.

Another argument is the "embedding problem." Consider the following sentences:

Attempts to translate these sentences in an emotivist framework seem to fail (e.g. "She does not realize, 'Boo on eating meat!'"). Prescriptivist translations fare only slightly better ("She does not realize that she is not to eat meat"). Even the act of forming such a construction indicates some sort of cognition in the process.

According to some non-cognitivist points of view, these sentences simply assume the false premise that ethical statements are either true or false. They might be literally translated as:

These translations, however, seem divorced from the way people actually use language. A non-cognitivist would have to disagree with someone saying, "'Eating meat is wrong' is a false statement" (since "Eating meat is wrong" is not truth-apt at all), but may be tempted to agree with a person saying, "Eating meat is not wrong."

One might more constructively interpret these statements to describe the underlying emotional statement that they express, i.e.: I disapprove/do not disapprove of eating meat, I used to, he doesn't, I do and she doesn't, etc.; however, this interpretation is closer to ethical subjectivism than to non-cognitivism proper.

A similar argument against non-cognitivism is that of ethical argument. A common argument might be, "If killing an innocent human is always wrong, and all fetuses are innocent humans, then killing a fetus is always wrong." Most people would consider such an utterance to represent an analytic proposition which is true "a priori". However, if ethical statements do not represent cognitions, it seems odd to use them as premises in an argument, and even odder to assume they follow the same rules of syllogism as true propositions. However, R.M. Hare, proponent of universal prescriptivism, has argued that the rules of logic are independent of grammatical mood, and thus the same logical relations may hold between imperatives as hold between indicatives.

Many objections to non-cognitivism based on the linguistic characteristics of what purport to be moral judgments were originally raised by Peter Glassen in "The Cognitivity of Moral Judgments", published in "Mind" in January 1959, and in Glassen's follow-up article in the January 1963 issue of the same journal.




</doc>
<doc id="21179" url="https://en.wikipedia.org/wiki?curid=21179" title="North Sea">
North Sea

The North Sea is a marginal sea of the Atlantic Ocean located between Great Britain (England and Scotland), Denmark, Norway, Germany, the Netherlands, Belgium and France. An epeiric (or "shelf") sea on the European continental shelf, it connects to the ocean through the English Channel in the south and the Norwegian Sea in the north. It is more than long and wide, with an area of .

The North Sea has long been the site of important European shipping lanes as well as a major fishery. The coast is a popular destination for recreation and tourism in bordering countries, and more recently the sea has developed into a rich source of energy resources, including fossil fuels, wind, and early efforts in wave power.

Historically, the North Sea has featured prominently in geopolitical and military affairs, particularly in Northern Europe. It was also important globally through the power northern Europeans projected worldwide during much of the Middle Ages and into the modern era. The North Sea was the centre of the Vikings' rise. Subsequently, the Hanseatic League, the Netherlands, and the British each sought to dominate the North Sea and thus access to the world's markets and resources. As Germany's only outlet to the ocean, the North Sea continued to be strategically important through both World Wars.

The coast of the North Sea presents a diversity of geological and geographical features. In the north, deep fjords and sheer cliffs mark the Norwegian and Scottish coastlines, whereas in the south, the coast consists primarily of sandy beaches and wide mudflats. Due to the dense population, heavy industrialization, and intense use of the sea and area surrounding it, there have been various environmental issues affecting the sea's ecosystems. Adverse environmental issues – commonly including overfishing, industrial and agricultural runoff, dredging, and dumping, among others – have led to a number of efforts to prevent degradation of the sea while still making use of its economic potential.

The North Sea is bounded by the Orkney Islands and east coast of Great Britain to the west and the northern and central European mainland to the east and south, including Norway, Denmark, Germany, the Netherlands, Belgium, and France. In the southwest, beyond the Straits of Dover, the North Sea becomes the English Channel connecting to the Atlantic Ocean. In the east, it connects to the Baltic Sea via the Skagerrak and Kattegat, narrow straits that separate Denmark from Norway and Sweden respectively. In the north it is bordered by the Shetland Islands, and connects with the Norwegian Sea, which lies in the very north-eastern part of the Atlantic.

The North Sea is more than long and wide, with an area of and a volume of . Around the edges of the North Sea are sizeable islands and archipelagos, including Shetland, Orkney, and the Frisian Islands. The North Sea receives freshwater from a number of European continental watersheds, as well as the British Isles. A large part of the European drainage basin empties into the North Sea, including water from the Baltic Sea. The largest and most important rivers flowing into the North Sea are the Elbe and the Rhine – Meuse. Around 185 million people live in the catchment area of the rivers discharging into the North Sea encompassing some highly industrialized areas.

For the most part, the sea lies on the European continental shelf with a mean depth of . The only exception is the Norwegian trench, which extends parallel to the Norwegian shoreline from Oslo to an area north of Bergen. It is between wide and has a maximum depth of .

The Dogger Bank, a vast moraine, or accumulation of unconsolidated glacial debris, rises to a mere below the surface. This feature has produced the finest fishing location of the North Sea. The Long Forties and the Broad Fourteens are large areas with roughly uniform depth in fathoms, (forty fathoms and fourteen fathoms or deep respectively). These great banks and others make the North Sea particularly hazardous to navigate, which has been alleviated by the implementation of satellite navigation systems. The Devil's Hole lies east of Dundee, Scotland. The feature is a series of asymmetrical trenches between long, wide and up to deep.

Other areas which are less deep are Cleaver Bank, Fisher Bank and Noordhinder Bank.

The International Hydrographic Organization defines the limits of the North Sea as follows:

"On the Southwest." A line joining the Walde Lighthouse (France, 1°55'E) and Leathercoat Point (England, 51°10'N).

"On the Northwest." From Dunnet Head (3°22'W) in Scotland to Tor Ness (58°47'N) in the Island of Hoy, thence through this island to the Kame of Hoy (58°55'N) on to Breck Ness on Mainland (58°58'N) through this island to Costa Head (3°14'W) and to Inga Ness (59'17'N) in Westray through Westray, to Bow Head, across to Mull Head (North point of Papa Westray) and on to Seal Skerry (North point of North Ronaldsay) and thence to Horse Island (South point of the Shetland Islands).

"On the North." From the North point (Fethaland Point) of the Mainland of the Shetland Islands, across to Graveland Ness (60°39'N) in the Island of Yell, through Yell to Gloup Ness (1°04'W) and across to Spoo Ness (60°45'N) in Unst island, through Unst to Herma Ness (60°51'N), on to the SW point of the Rumblings and to Muckle Flugga () all these being included in the North Sea area; thence up the meridian of 0°53' West to the parallel of 61°00' North and eastward along this parallel to the coast of Norway, the whole of Viking Bank being thus included in the North Sea.

"On the East." The Western limit of the Skagerrak [A line joining Hanstholm () and the Naze (Lindesnes, )].

The average temperature in summer is and in the winter. The average temperatures have been trending higher since 1988, which has been attributed to climate change. Air temperatures in January range on average between and in July between . The winter months see frequent gales and storms.

The salinity averages between of water. The salinity has the highest variability where there is fresh water inflow, such as at the Rhine and Elbe estuaries, the Baltic Sea exit and along the coast of Norway.

The main pattern to the flow of water in the North Sea is an anti-clockwise rotation along the edges.

The North Sea is an arm of the Atlantic Ocean receiving the majority of ocean current from the northwest opening, and a lesser portion of warm current from the smaller opening at the English Channel. These tidal currents leave along the Norwegian coast. Surface and deep water currents may move in different directions. Low salinity surface coastal waters move offshore, and deeper, denser high salinity waters move inshore.

The North Sea located on the continental shelf has different waves from those in deep ocean water. The wave speeds are diminished and the wave amplitudes are increased. In the North Sea there are two amphidromic systems and a third incomplete amphidromic system. In the North Sea the average tide difference in wave amplitude is between zero and .

The Kelvin tide of the Atlantic Ocean is a semidiurnal wave that travels northward. Some of the energy from this wave travels through the English Channel into the North Sea. The wave continues to travel northward in the Atlantic Ocean, and once past the northern tip of Great Britain, the Kelvin wave turns east and south and once again enters the North Sea.

The eastern and western coasts of the North Sea are jagged, formed by glaciers during the ice ages. The coastlines along the southernmost part are covered with the remains of deposited glacial sediment. The Norwegian mountains plunge into the sea creating deep fjords and archipelagos. South of Stavanger, the coast softens, the islands become fewer. The eastern Scottish coast is similar, though less severe than Norway. From north east of England, the cliffs become lower and are composed of less resistant moraine, which erodes more easily, so that the coasts have more rounded contours. In the Netherlands, Belgium and in East Anglia the littoral is low and marshy. The east coast and south-east of the North Sea (Wadden Sea) have coastlines that are mainly sandy and straight owing to longshore drift, particularly along Belgium and Denmark.

The southern coastal areas were originally amphibious flood plains and swampy land. In areas especially vulnerable to storm surges, people settled behind elevated levees and on natural areas of high ground such as spits and geestland. As early as 500 BC, people were constructing artificial dwelling hills higher than the prevailing flood levels. It was only around the beginning of the High Middle Ages, in 1200 AD, that inhabitants began to connect single ring dikes into a dike line along the entire coast, thereby turning amphibious regions between the land and the sea into permanent solid ground.

The modern form of the dikes supplemented by overflow and lateral diversion channels, began to appear in the 17th and 18th centuries, built in the Netherlands. The North Sea Floods of 1953 and 1962 were impetus for further raising of the dikes as well as the shortening of the coast line so as to present as little surface area as possible to the punishment of the sea and the storms. Currently, 27% of the Netherlands is below sea level protected by dikes, dunes, and beach flats.

Coastal management today consists of several levels. The dike slope reduces the energy of the incoming sea, so that the dike itself does not receive the full impact. Dikes that lie directly on the sea are especially reinforced. The dikes have, over the years, been repeatedly raised, sometimes up to and have been made flatter to better reduce wave erosion. Where the dunes are sufficient to protect the land behind them from the sea, these dunes are planted with beach grass ("Ammophila arenaria") to protect them from erosion by wind, water, and foot traffic.

Storm surges threaten, in particular, the coasts of the Netherlands, Belgium, Germany, and Denmark and low lying areas of eastern England particularly around The Wash and Fens.
Storm surges are caused by changes in barometric pressure combined with strong wind created wave action.

The first recorded storm tide flood was the "Julianenflut", on 17 February 1164. In its wake the Jadebusen, (a bay on the coast of Germany), began to form.
A storm tide in 1228 is recorded to have killed more than 100,000 people. In 1362, the Second Marcellus Flood, also known as the "Grote Manndrenke", hit the entire southern coast of the North Sea. Chronicles of the time again record more than 100,000 deaths, large parts of the coast were lost permanently to the sea, including the now legendary lost city of Rungholt.
In the 20th century, the North Sea flood of 1953 flooded several nations' coasts and cost more than 2,000 lives.
315 citizens of Hamburg died in the North Sea flood of 1962.

Though rare, the North Sea has been the site of a number of historically documented tsunamis. The Storegga Slides were a series of underwater landslides, in which a piece of the Norwegian continental shelf slid into the Norwegian Sea. The immense landslips occurred between 8150 BCE and 6000 BCE, and caused a tsunami up to high that swept through the North Sea, having the greatest effect on Scotland and the Faeroe Islands.
The Dover Straits earthquake of 1580 is among the first recorded earthquakes in the North Sea measuring between 5.6 and 5.9 on the Richter scale. This event caused extensive damage in Calais both through its tremors and possibly triggered a tsunami, though this has never been confirmed. The theory is a vast underwater landslide in the English Channel was triggered by the earthquake, which in turn caused a tsunami. The tsunami triggered by the 1755 Lisbon earthquake reached Holland, although the waves had lost their destructive power. The largest earthquake ever recorded in the United Kingdom was the 1931 Dogger Bank earthquake, which measured 6.1 on the Richter magnitude scale and caused a small tsunami that flooded parts of the British coast.

Shallow epicontinental seas like the current North Sea have since long existed on the European continental shelf. The rifting that formed the northern part of the Atlantic Ocean during the Jurassic and Cretaceous periods, from about , caused tectonic uplift in the British Isles. Since then, a shallow sea has almost continuously existed between the uplands of the Fennoscandian Shield and the British Isles. This precursor of the current North Sea has grown and shrunk with the rise and fall of the eustatic sea level during geologic time. Sometimes it was connected with other shallow seas, such as the sea above the Paris Basin to the south-west, the Paratethys Sea to the south-east, or the Tethys Ocean to the south.

During the Late Cretaceous, about , all of modern mainland Europe except for Scandinavia was a scattering of islands. By the Early Oligocene, , the emergence of Western and Central Europe had almost completely separated the North Sea from the Tethys Ocean, which gradually shrank to become the Mediterranean as Southern Europe and South West Asia became dry land. The North Sea was cut off from the English Channel by a narrow land bridge until that was breached by at least two catastrophic floods between 450,000 and 180,000 years ago. Since the start of the Quaternary period about , the eustatic sea level has fallen during each glacial period and then risen again. Every time the ice sheet reached its greatest extent, the North Sea became almost completely dry. The present-day coastline formed after the Last Glacial Maximum when the sea began to flood the European continental shelf.

In 2006 a bone fragment was found while drilling for oil in the north sea. Analysis indicated that it was a Plateosaurus from 199 to 216 million years ago. This was the deepest dinosaur fossil ever found and the first find for Norway.

Copepods and other zooplankton are plentiful in the North Sea. These tiny organisms are crucial elements of the food chain supporting many species of fish. Over 230 species of fish live in the North Sea. Cod, haddock, whiting, saithe, plaice, sole, mackerel, herring, pouting, sprat, and sandeel are all very common and are fished commercially. Due to the various depths of the North Sea trenches and differences in salinity, temperature, and water movement, some fish such as blue-mouth redfish and rabbitfish reside only in small areas of the North Sea.

Crustaceans are also commonly found throughout the sea. Norway lobster, deep-water prawns, and brown shrimp are all commercially fished, but other species of lobster, shrimp, oyster, mussels and clams all live in the North Sea. Recently non-indigenous species have become established including the Pacific oyster and Atlantic jackknife clam.

The coasts of the North Sea are home to nature reserves including the Ythan Estuary, Fowlsheugh Nature Preserve, and Farne Islands in the UK and the Wadden Sea National Parks in Denmark, Germany and the Netherlands. These locations provide breeding habitat for dozens of bird species. Tens of millions of birds make use of the North Sea for breeding, feeding, or migratory stopovers every year. Populations of black legged kittiwakes, Atlantic puffins, northern fulmars, and species of petrels, gannets, seaducks, loons (divers), cormorants, gulls, auks, and terns, and many other seabirds make these coasts popular for birdwatching.

The North Sea is also home to marine mammals. Common seals, and harbour porpoises can be found along the coasts, at marine installations, and on islands. The very northern North Sea islands such as the Shetland Islands are occasionally home to a larger variety of pinnipeds including bearded, harp, hooded and ringed seals, and even walrus. North Sea cetaceans include various porpoise, dolphin and whale species.

Plant species in the North Sea include species of wrack, among them bladder wrack, knotted wrack, and serrated wrack. Algae, macroalgal, and kelp, such as oarweed and laminaria hyperboria, and species of maerl are found as well. Eelgrass, formerly common in the entirety of the Wadden Sea, was nearly wiped out in the 20th century by a disease. Similarly, sea grass used to coat huge tracts of ocean floor, but have been damaged by trawling and dredging have diminished its habitat and prevented its return. Invasive Japanese seaweed has spread along the shores of the sea clogging harbours and inlets and has become a nuisance.

Due to the heavy human populations and high level of industrialization along its shores, the wildlife of the North Sea has suffered from pollution, overhunting, and overfishing. Flamingos and pelicans were once found along the southern shores of the North Sea, but became extinct over the 2nd millennium. Walruses frequented the Orkney Islands through the mid-16th century, as both Sable Island and Orkney Islands lay within its normal range. Gray whales also resided in the North Sea but were driven to extinction in the Atlantic in the 17th century Other species have dramatically declined in population, though they are still found. North Atlantic right whales, sturgeon, shad, rays, skates, salmon, and other species were common in the North Sea until the 20th century, when numbers declined due to overfishing. Other factors like the introduction of non-indigenous species, industrial and agricultural pollution, trawling and dredging, human-induced eutrophication, construction on coastal breeding and feeding grounds, sand and gravel extraction, offshore construction, and heavy shipping traffic have also contributed to the decline.
For example, a resident killer whale pod was lost in the 1960s, presumably due to the peak in PCB pollution in this time period.

The OSPAR commission manages the OSPAR convention to counteract the harmful effects of human activity on wildlife in the North Sea, preserve endangered species, and provide environmental protection. All North Sea border states are signatories of the MARPOL 73/78 Accords, which preserve the marine environment by preventing pollution from ships.
Germany, Denmark, and the Netherlands also have a trilateral agreement for the protection of the Wadden Sea, or mudflats, which run along the coasts of the three countries on the southern edge of the North Sea.

The North Sea has had various names through history. One of the earliest recorded names was "Septentrionalis Oceanus", or "Northern Ocean," which was cited by Pliny. The name "North Sea" probably came into English, however, via the Dutch "Noordzee", who named it thus either in contrast with the Zuiderzee ("South Sea"), located south of Frisia, or because the sea is generally to the north of the Netherlands. Before the adoption of "North Sea," the names used in English, in American English in particular, were "German Sea" or "German Ocean", referred to the Latin names "Mare Germanicum" and "Oceanus Germanicus", and these persisted in use until the First World War.

Other common names in use for long periods were the Latin terms "Mare Frisicum", as well as the English equivalent, "Frisian Sea".

The modern names of the sea in the other local languages are: ("West Sea") or "Nordsøen" , , , , , , , Northern Frisian: "Weestsiie" ("West Sea"), , , , , and Zeeuws: "Noôrdzeê".

North Sea has provided waterway access for commerce and conquest. Many areas have access to the North Sea because of its long coastline and the European rivers that empty into it. The British Isles had been protected from invasion by the North Sea waters until the Roman conquest of Britain in 43 CE. The Romans established organised ports, which increased shipping, and began sustained trade. When the Romans abandoned Britain in 410, the Germanic Angles, Saxons, and Jutes began the next great migration across the North Sea during the Migration Period. They made successive invasions of the island.

The Viking Age began in 793 with the attack on Lindisfarne; for the next quarter-millennium the Vikings ruled the North Sea. In their superior longships, they raided, traded, and established colonies and outposts along the coasts of the sea. From the Middle Ages through the 15th century, the northern European coastal ports exported domestic goods, dyes, linen, salt, metal goods and wine. The Scandinavian and Baltic areas shipped grain, fish, naval necessities, and timber. In turn the North Sea countries imported high-grade cloths, spices, and fruits from the Mediterranean region. Commerce during this era was mainly conducted by maritime trade due to underdeveloped roadways.

In the 13th century the Hanseatic League, though centred on the Baltic Sea, started to control most of the trade through important members and outposts on the North Sea. The League lost its dominance in the 16th century, as neighbouring states took control of former Hanseatic cities and outposts. Their internal conflict prevented effective cooperation and defence. As the League lost control of its maritime cities, new trade routes emerged that provided Europe with Asian, American, and African goods.

The 17th century Dutch Golden Age during which Dutch herring, cod and whale fisheries reached an all time high saw Dutch power at its zenith. Important overseas colonies, a vast merchant marine, powerful navy and large profits made the Dutch the main challengers to an ambitious England. This rivalry led to the first three Anglo-Dutch Wars between 1652 and 1673, which ended with Dutch victories. After the Glorious Revolution in 1688, the Dutch prince William ascended to the English throne. With unified leadership, commercial, military, and political power began to shift from Amsterdam to London.
The British did not face a challenge to their dominance of the North Sea until the 20th century.

Tensions in the North Sea were again heightened in 1904 by the Dogger Bank incident. During the Russo-Japanese War, several ships of the Russian Baltic Fleet, which was on its way to the Far East, mistook British fishing boats for Japanese ships and fired on them, and then upon each other, near the Dogger Bank, nearly causing Britain to enter the war on the side of Japan.

During the First World War, Great Britain's Grand Fleet and Germany's Kaiserliche Marine faced each other in the North Sea, which became the main theatre of the war for surface action. Britain's larger fleet and North Sea Mine Barrage were able to establish an effective blockade for most of the war, which restricted the Central Powers' access to many crucial resources. Major battles included the Battle of Heligoland Bight, the Battle of the Dogger Bank, and the Battle of Jutland.
World War I also brought the first extensive use of submarine warfare, and a number of submarine actions occurred in the North Sea.

The Second World War also saw action in the North Sea, though it was restricted more to aircraft reconnaissance, and action by fighter/bomber aircraft, submarines, and smaller vessels such as minesweepers and torpedo boats.

In the aftermath of the war, hundreds of thousands of tons of chemical weapons were disposed of by being dumped in the North Sea.

After the war, the North Sea lost much of its military significance because it is bordered only by NATO member-states. However, it gained significant economic importance in the 1960s as the states around the North Sea began full-scale exploitation of its oil and gas resources. The North Sea continues to be an active trade route.

Countries that border the North Sea all claim the of territorial waters, within which they have exclusive fishing rights. The Common Fisheries Policy of the European Union (EU) exists to coordinate fishing rights and assist with disputes between EU states and the EU border state of Norway.

After the discovery of mineral resources in the North Sea, the Convention on the Continental Shelf established country rights largely divided along the median line. The median line is defined as the line "every point of which is equidistant from the nearest points of the baselines from which the breadth of the territorial sea of each State is measured."
The ocean floor border between Germany, the Netherlands, and Denmark was only reapportioned after protracted negotiations and a judgement of the International Court of Justice.

As early as 1859, oil was discovered in onshore areas around the North Sea and natural gas as early as 1910. Onshore resources, for example the K12-B field in the Netherlands continue to be exploited today.

Offshore test drilling began in 1966 and then, in 1969, Phillips Petroleum Company discovered the Ekofisk oil field distinguished by valuable, low-sulphur oil. Commercial exploitation began in 1971 with tankers and, after 1975, by a pipeline, first to Teesside, England and then, after 1977, also to Emden, Germany.

The exploitation of the North Sea oil reserves began just before the 1973 oil crisis, and the climb of international oil prices made the large investments needed for extraction much more attractive.
The start in 1973 of the oil reserves by UK allowed them to stop the declining position in the international trade in 1974, and a huge increase after the discovery and exploitation of the huge oil filed of by Phillips group in 1977 as the Brae field.

Although the production costs are relatively high, the quality of the oil, the political stability of the region, and the proximity of important markets in western Europe has made the North Sea an important oil-producing region. The largest single humanitarian catastrophe in the North Sea oil industry was the destruction of the offshore oil platform Piper Alpha in 1988 in which 167 people lost their lives.

Besides the Ekofisk oil field, the Statfjord oil field is also notable as it was the cause of the first pipeline to span the Norwegian trench. The largest natural gas field in the North Sea, Troll gas field, lies in the Norwegian trench, dropping over , requiring the construction of the enormous Troll A platform to access it.

The price of Brent Crude, one of the first types of oil extracted from the North Sea, is used today as a standard price for comparison for crude oil from the rest of the world. The North Sea contains western Europe's largest oil and natural gas reserves and is one of the world's key non-OPEC producing regions.

In the UK sector of the North Sea, the oil industry invested £14.4 billion in 2013, and was on track to spend £13 billion in 2014. Industry body Oil & Gas UK put the decline down to rising costs, lower production, high tax rates, and less exploration.

As of January 2018 The North Sea region contains 184 offshore rigs, which makes it the region with the highest number of offshore rigs in the world.

The North Sea is Europe's main fishery accounting for over 5% of international commercial fish caught. Fishing in the North Sea is concentrated in the southern part of the coastal waters. The main method of fishing is trawling.
In 1995, the total volume of fish and shellfish caught in the North Sea was approximately 3.5 million tonnes. Besides fish, it is estimated that one million tonnes of unmarketable by-catch is caught and discarded each year.

In recent decades, overfishing has left many fisheries unproductive, disturbing marine food chain dynamics and costing jobs in the fishing industry. Herring, cod and plaice fisheries may soon face the same plight as mackerel fishing, which ceased in the 1970s due to overfishing.
The objective of the European Union Common Fisheries Policy is to minimize the environmental impact associated with resource use by reducing fish discards, increasing productivity of fisheries, stabilising markets of fisheries and fish processing, and supplying fish at reasonable prices for the consumer.

Whaling was an important economic activity from the 9th until the 13th century for Flemish whalers. The medieval Flemish, Basque and Norwegian whalers who were replaced in the 16th century by Dutch, English, Danes and Germans, took massive numbers of whales and dolphins and nearly depleted the right whales. This activity likely led to the extinction of the Atlantic population of the once common gray whale. By 1902 the whaling had ended. After being absent for 300 years a single gray whale returned, it probably was the first of many more to find its way through the now ice-free Northwest Passage.

In addition to oil, gas, and fish, the states along the North Sea also take millions of cubic metres per year of sand and gravel from the ocean floor. These are used for beach nourishment, land reclamation
and construction.
Rolled pieces of amber may be picked up on the east coast of England.

Due to the strong prevailing winds, and shallow water, countries on the North Sea, particularly Germany and Denmark, have used the shore for wind power since the 1990s. The North Sea is the home of one of the first large-scale offshore wind farms in the world, Horns Rev 1, completed in 2002. Since then many other wind farms have been commissioned in the North Sea (and elsewhere). As of 2013 the 630 megawatt (MW) London Array is the largest offshore wind farm in the world, with the 504 (MW) Greater Gabbard wind farm the second largest, followed by the 367 MW Walney Wind Farm. All are off the coast of the UK. These projects will be dwarfed by subsequent wind farms that are in the pipeline, including Dogger Bank at 4,800 MW, Norfolk Bank (7,200 MW), and Irish Sea (4,200 MW). At the end of June 2013 total European combined offshore wind energy capacity was 6,040 MW. UK installed 513.5 MW offshore windpower in the first half-year of 2013.

The expansion of offshore wind farms has met with some resistance. Concerns have included shipping collisions and environmental effects on ocean ecology and wildlife such as fish and migratory birds, however, these concerns were found to be negligible in a long-term study in Denmark released in 2006 and again in a UK government study in 2009.
There are also concerns about reliability, and the rising costs of constructing and maintaining offshore wind farms. Despite these, development of North Sea wind power is continuing, with plans for additional wind farms off the coasts of Germany, the Netherlands, and the UK. There have also been proposals for a transnational power grid in the North Sea to connect new offshore wind farms.

Energy production from tidal power is still in a pre-commercial stage. The European Marine Energy Centre has installed a wave testing system at Billia Croo on the Orkney mainland and a tidal power testing station on the nearby island of Eday. Since 2003, a prototype Wave Dragon energy converter has been in operation at Nissum Bredning fjord of northern Denmark.

The beaches and coastal waters of the North Sea are destinations for tourists. The Belgian, Dutch, German and Danish coasts are developed for tourism. The North Sea coast of the United Kingdom has tourist destinations with beach resorts and golf courses. Fife in Scotland is famous for its links golf courses; the coastal city of St. Andrews is renowned as the "Home of Golf". The coast of North East England has several tourist towns such as Scarborough, Bridlington, Seahouses, Whitby, Robin Hood's Bay and Seaton Carew, and has some long sandy beaches and links golfing locations such as Seaton Carew Golf Club and Goswick Golf Club.

The North Sea Trail is a long-distance trail linking seven countries around the North Sea. Windsurfing and sailing are popular sports because of the strong winds. Mudflat hiking, recreational fishing and birdwatching are among other activities.

The climatic conditions on the North Sea coast have been claimed to be healthy. As early as the 19th century, travellers visited the North Sea coast for curative and restorative vacations. The sea air, temperature, wind, water, and sunshine are counted among the beneficial conditions that are said to activate the body's defences, improve circulation, strengthen the immune system, and have healing effects on the skin and the respiratory system.

The North Sea is important for marine transport and its shipping lanes are among the busiest in the world. Major ports are located along its coasts: Rotterdam, the busiest port in Europe and the fourth busiest port in the world by tonnage , Antwerp (was 16th) and Hamburg (was 27th), Bremen/Bremerhaven and Felixstowe, both in the top 30 busiest container seaports, as well as the Port of Bruges-Zeebrugge, Europe's leading ro-ro port.

Fishing boats, service boats for offshore industries, sport and pleasure craft, and merchant ships to and from North Sea ports and Baltic ports must share routes on the North Sea. The Dover Strait alone sees more than 400 commercial vessels a day. Because of this volume, navigation in the North Sea can be difficult in high traffic zones, so ports have established elaborate vessel traffic services to monitor and direct ships into and out of port.

The North Sea coasts are home to numerous canals and canal systems to facilitate traffic between and among rivers, artificial harbours, and the sea. The Kiel Canal, connecting the North Sea with the Baltic Sea, is the most heavily used artificial seaway in the world reporting an average of 89 ships per day not including sporting boats and other small watercraft in 2009. It saves an average of , instead of the voyage around the Jutland peninsula. The North Sea Canal connects Amsterdam with the North Sea.





</doc>
<doc id="21180" url="https://en.wikipedia.org/wiki?curid=21180" title="Natural Born Killers">
Natural Born Killers

Natural Born Killers is a 1994 American satirical black comedy crime film directed by Oliver Stone and starring Woody Harrelson, Juliette Lewis, Robert Downey Jr., Tom Sizemore, and Tommy Lee Jones. The film tells the story of two victims of traumatic childhoods who became lovers and mass murderers, and are irresponsibly glorified by the mass media.

The film is based on an original screenplay by Quentin Tarantino that was heavily revised by Stone, writer David Veloz, and associate producer Richard Rutowski. Tarantino received a story credit. Jane Hamsher, Don Murphy, and Clayton Townsend produced the film, with Arnon Milchan, Thom Mount, and Stone as executive producers.

The film was released on August 26, 1994 in the United States, and also screened at the Venice Film Festival on August 29, 1994. It was a box office success, grossing over $50 million against a production budget of $34 million. Critics praised the cast's performances, the humor, plot and combination of action and romance; some found the film too violent and graphic. Notorious for its violent content and inspiring "copycat" crimes, the film was named the eighth most controversial film in history by "Entertainment Weekly" in 2006.

Mickey Knox and his wife Mallory stop at a diner in the New Mexico desert. A duo of rednecks arrive and begin sexually harassing Mallory as she dances by a jukebox. She initially encourages it before beating one of the men viciously. Mickey joins her, and the couple murder everyone in the diner, save one staff member, to whom they proudly declare their names before leaving. The couple camp in the desert, and Mallory reminisces about how she met Mickey, a meat deliveryman who serviced her family's household. After a whirlwind romance, the couple murdered Mallory's sexually abusive father and neglectful mother before having an unofficial marriage ceremony on a bridge. 

Later, Mickey and Mallory hold a woman hostage in their hotel room. Angered by Mickey's desire for a threesome, Mallory leaves, and Mickey rapes the hostage. Mallory drives to a nearby gas station, where she flirts with a mechanic. They begin to have sex on the hood of a car, but Mallory kills him after suffering a flashback of being raped by her father. The pair continue their killing spree, ultimately claiming fifty-two victims in New Mexico, Arizona, and Nevada. Pursuing them is Detective Jack Scagnetti, who became obsessed with mass murderers after witnessing his mother being shot and killed by Charles Whitman when he was eight. Beneath his heroic facade, he is also a violent psychopath and has murdered prostitutes in his past. Following the Knoxes murder spree is a self-serving tabloid journalist, Wayne Gale, who profiles them on his show, "American Maniacs", soon elevating them to cult hero status.

Mickey and Mallory get lost in the desert after taking psychedelic mushrooms, and stumble upon a ranch owned by Warren Red Cloud, a Navajo man who provides them food and shelter. As Mickey and Mallory sleep, Warren senses evil in the couple and attempts to exorcise the demon he perceives in Mickey, chanting over him as he sleeps. Mickey, who has nightmares recounting his abusive parents, awakens during the exorcism, and shoots Warren to death. As they couple flee, they feel inexplicably guilty, and come across a giant field of rattlesnakes, where they are badly bitten. They reach a drugstore to purchase snakebite antidote, but the store is sold out. A pharmacist recognizes the couple and sets off an alarm before Mickey kills him. Police arrive shortly after and accost the couple, which ends in a shootout followed by police beating the couple while a news crew films the action. 

One year later, an imprisoned Mickey and Mallory are scheduled to be transferred to psychiatric hospitals. Scagnetti orders Warden Dwight McClusky to kill the Knoxes during their transfer, and claim they tried to escape. Meanwhile, Gale has persuaded Mickey to give a live interview that will air after the Super Bowl. During the interview, Mickey declares himself a "natural born killer," a phrase that inspires other inmates to start a prison riot. After the interview is terminated by McClusky, Mickey is left alone with Gale, the film crew, and several guards; he manages to overpower a guard and kill most of the people in the room, taking Gale and several others hostage. Gale and his crew give a live television report that profiles the riot. Meanwhile, Scagnetti attempts to seduce Mallory in her cell. She responds by beating him viciously, and another guard subdues her with tear gas. Mickey and Gale reach Mallory's cell, where Mickey kills the guards and engages in a standoff with Scagnetti before Mallory murders him.

Gale's entire television crew is killed trying to escape the riot, while Gale himself begins indulging in violence, shooting at prison guards. Mickey and Mallory steal a van and escape into the woods with Gale, to whom they give a final interview before declaring that he must die. He attempts various arguments to change their minds, appealing to their trademark practice of leaving one survivor; Mickey informs him they are leaving a witness to tell the tale, his camera. Gale accepts his fate and is shot to death. Unbeknownst to the three, the entire exchange is transmitted to a horrified news anchor through Gale's in-ear microphone. 

Several years later, Mickey and Mallory, still on the run, travel in an RV, as a pregnant Mallory watches their two children play.

One of the central themes of "Natural Born Killers" is the relationship between real-life violence and the mass media's coverage of it. This thematic preoccupation was declared in the film's promotional materials, with its theatrical poster advertising it as a "bold new film that takes a look at a country seduced by fame, obsessed by crime, and consumed by the media."

The character of Wayne Gale, the television host of "American Maniacs", functions in the film as a figurehead of lurid true crime television documentaries, which recycle real-life incidents of violence and criminal activity into entertainment for the general public. On several occasions, expressionistic jump cuts featuring Gale as a blood-soaked Satan are interspersed into the film, which Muir suggests emphasizes the film's assertion that mass media and crime mutually reinforce one another.

Media representation of the nuclear family has been identified as another theme in the film, particularly with the depiction of Mallory's dysfunctional family life, which includes a neglectful mother and a father who sexually abuses her. Muir notes that the sequence depicting Mallory's home life—presented as a television sitcom with the title "I Love Mallory" (a parody of "I Love Lucy")—charts "the colossal gulf between the imagery sold to America regarding family life and the truth, for many Americans, of such family life in the 1990s." The "sitcom" representation of Mallory's household results in a visual dichotomy between her "life as she imagined it should be (replete with an oppressive laugh track eradicating any scary sense of ambiguity)" and the "grim truth of it."

"Natural Born Killers" was based on a screenplay written by Quentin Tarantino, in which a married couple suddenly decide to go on a killing spree. Tarantino had sold an option for his script to producers Jane Hamsher and Don Murphy for $10,000 after he had tried, and failed, to direct it himself for $500,000. Hamsher and Murphy subsequently sold the screenplay to Warner Bros. Around the same time, Oliver Stone was made aware of the script. He was keen to find something more straightforward than his previous production, "Heaven & Earth" (1993), a difficult shoot which had left him exhausted.

David Veloz, associate producer Richard Rutowski, and Stone rewrote Tarantino's script, keeping much of the dialogue but changing the focus of the film from journalist Wayne Gale to Mickey and Mallory. The script was revised so drastically that Tarantino was credited for the story only. In a 1993 interview, Tarantino stated that he did not hold any animosity towards Stone, and that he wished the film well.

Initially, when producers Hamsher and Murphy had first brought the script to Stone's attention, he had envisioned it as an action film; "something Arnold Schwarzenegger would be proud of." As the project developed however, incidents such as the O. J. Simpson case, the Menendez brothers case, the Tonya Harding/Nancy Kerrigan incident, the Rodney King incident, and the Federal assault of the Branch Davidian sect all took place. Stone came to feel that the media was heavily involved in the outcome of all of these cases, and that the media had become an all-pervasive entity which marketed violence and suffering for the good of ratings. As such, he changed the tone of the film from one of simple action to a satirical critique of the media in general, altering Tarantino's story into a "vicious, coldhearted farce." Coloring Stone's approach to the material, and contributing to the violent nature of the film, were the anger and sadness he felt at the breakdown of his second marriage. He also said in an interview that the film was influenced by the "vitality" of Indian cinema.

Stone cast Woody Harrelson partly because, "frankly, he had that American, trashy look. There's something about Woody that evokes Kentucky or white trash." At the time, Harrelson was primarily known for his comedic performances, namely his role on the sitcom "Cheers", and Stone was compelled to cast him against type. Stone cast Lewis for similar reason, noting that, despite her success as portraying a defiled teenage daughter in "Cape Fear" (1991), he felt she could "pull off white trash, too. Juliette has malice in her eyes. She's got adorable eyes, but they jump and they gleam. I just felt they [were both] right. They didn't feel like they were upper-class people." Stone tried to convince Lewis to gain muscle mass for her role as Mallory so that she looked tougher, but she refused, saying she wanted the character to look like a pushover, not a bodybuilder.

Robert Downey Jr. was cast as Wayne Gale, the reporter chronicling the Knoxes; Downey prepared for his role as reporter Wayne Gale by spending time with Australian TV shock-king Steve Dunleavy, and later convinced Stone to allow him to portray Gale with an Australian accent. Tom Sizemore was cast as Detective Jack Scagnetti, the psychotic police officer with murderous impulses himself, while Tommy Lee Jones was cast as Dwight McClusky, a prison warden who appears in the last act of the film. Rodney Dangerfield, primarily known as a stand-up comedian, portrayed Mallory's rapist father, and was allowed by Stone to rewrite all of his own character's lines.

Principal photography took 56 days to shoot. Filming locations included the Rio Grande Gorge Bridge just west of Taos, New Mexico, where the wedding scene was filmed, and Stateville Correctional Center in Joliet, Illinois, where the prison riot was filmed. In Stateville, 80% of the prisoners are incarcerated for violent crimes. For the first two weeks on location at the prison, the extras were actual inmates with rubber weapons. For the subsequent two weeks, 200 extras were needed because the Stateville inmates were on lockdown. According to Tom Sizemore, during filming on the prison set, Stone would play African tribal music at full blast between takes to keep the frantic energy up. While shooting the POV scene wherein Mallory runs into the wire mesh, director of photography Robert Richardson broke his finger and the replacement cameraman cut his eye. According to Oliver Stone, he was not popular with the camera department on set that day. For the scenes involving rear projection, the projected footage was shot prior to principal photography, then edited together, and projected onto the stage, behind the live actors. For example, when Mallory drives past a building and flames are projected onto the wall, this was shot live using footage projected onto the facade of a real building.

The famous Coca-Cola polar bear ad is seen twice during the film. According to Stone, Coca-Cola approved the use of the ad without having a full idea of what the film was about. When they saw the completed film, they were furious.

"Natural Born Killers" was filmed and edited in a frenzied and psychedelic style, and features both color and black and white cinematography, as well as animation, and other unusual color schemes and visual compositions. Editing of the film lasted approximately 11 months, with the final film containing almost 3,000 cuts (most films have 600–700). The film also employs a wide range of camera angles, featuring Dutch tilts prominently throughout, with the camera rarely angling along a horizontal field of vision. Film scholar Robert Kolker notes that the Dutch angle's employment in the film is "the visual equivalent of a profound dislocation, a loss of object constancy, the slipperiness of subjectivity itself." Kolker comments that, unlike such films as "Bonnie and Clyde" from which "Natural Born Killers" draws influence, "from the very beginning...  the viewer is forced into a dual situation, neither one of which allows easy access to the main characters. One situation, continued throughout the film, is a kind of rhythmic attention created by a startling flow of images. Stone builds his visuals on unexpected linkages and disorienting juxtapositions within the shots and edits."

Because the film is thematically preoccupied with media, Stone sought to implement visual elements of popular television into the film's visual tableau: "It had never quite been done before — a mixture of stocks and styles. I was influenced, I have to say, by MTV and some of the styles I saw in the early '80s and '90s on television. But no one had tried that style over the course of 90, 100 minutes." Commercials which were commonly on the air at the time of the film's release make brief, intermittent appearances as well. 

Concurrent with Stone's preoccupation with television as both a visual and thematic reference point, portions of the film are narrated through parodies of popular television series, including a sequence presented in the style of a sitcom about Mallory's dysfunctional family (titled "I Love Mallory"), a parody of "I Love Lucy". In the film's final montage, splices of real-life television news coverage of various criminal cases of the time are included, such as the O. J. Simpson case, the Menendez brothers, and the Tonya Harding/Nancy Kerrigan incident. Film scholar John Kenneth Muir notes this inclusion as an "exclamation point" concluding the film's thesis: "It seems to say, "Welcome to the tabloid-TV culture of America in the 1990, where crime pays and pays well.""

The film's soundtrack was produced by Stone and Trent Reznor of Nine Inch Nails, who reportedly watched the film over 50 times to "get in the mood". Reznor reportedly produced the soundtrack while on tour. On his approach to compiling the soundtrack, Reznor told MTV:

I suggested to Oliver [Stone] to try to turn the soundtrack into a collage-of-sound, kind of the way the movie used music: make edits, add dialog, and make it something interesting, rather than a bunch of previously released music.

Some songs were written especially for the film or soundtrack, such as "Burn" by Nine Inch Nails.

In its opening weekend, "Natural Born Killers" grossed a total of $11.2 million in 1,510 theaters, finishing 1st. It finished its theatrical run with a total gross of $50.3 million, against its $34 million budget.

On review aggregator Rotten Tomatoes, the film has an approval rating of 47% based on 38 reviews, with an average rating of 5.72/10. The website's critical consensus reads, ""Natural Born Killers" explodes off the screen with style, but its satire is too blunt to offer any fresh insight into celebrity or crime -- pummeling the audience with depravity until the effect becomes deadening." On Metacritic, the film has an average weighted score of 74 out of 100, based on 20 critics, indicating "generally favorable reviews". Audiences polled by CinemaScore gave the film an average grade of "B–" on an A+ to F scale.

Roger Ebert of the "Chicago Sun-Times" gave the film four stars out of four and wrote, "Seeing this movie once is not enough. The first time is for the visceral experience, the second time is for the meaning." On his television show, his partner Gene Siskel agreed with him, adding extra praise to the scene featuring Rodney Dangerfield.

Other critics found the film unsuccessful in its aims. Hal Hinson of "The Washington Post" claimed that "Stone's sensibility is white-hot and personal. As much as he'd like us to believe that his camera is turned outward on the culture, it's vividly clear that he can't resist turning it inward on himself. This wouldn't be so troublesome if Stone didn't confuse the public and the private." Janet Maslin of "The New York Times" wrote, "for all its surface passions, "Natural Born Killers" never digs deep enough to touch the madness of such events, or even to send them up in any surprising way. Mr. Stone's vision is impassioned, alarming, visually inventive, characteristically overpowering. But it's no match for the awful truth."

James Berardinelli gave the film a negative review but his criticism was different from many other such pans, which generally said that Oliver Stone was a hypocrite for making an ultra-violent film in the guise of a critique of American attitudes. Berardinelli noted that the movie "hits the bullseye" as a satire of America's lust for bloodshed, but repeated Stone's main point so often and so loudly that it became unbearable.

At the 1994 Stinkers Bad Movie Awards, Harrelson was nominated for Worst Actor but lost to Bruce Willis for "Color of Night" and "North". The film was nominated for Worst Picture but lost to "North".

"Natural Born Killers" was released on VHS in 1995 by Warner Home Video. A director's cut version of the film was released the following year on VHS by Vidmark/Lionsgate, who also released a non-anamorphic DVD of the director's cut in 2000. Distribution rights to Stone's director's cut reverted from Lionsgate to Warner Bros. in 2009, after which Warner issued an anamorphic DVD edition as well as a Blu-ray.

After Quentin Tarantino attempted to publish his original screenplay to "Natural Born Killers" as a paperback book, as he had done with his scripts for "True Romance" and his own directorial efforts, "Reservoir Dogs" and "Pulp Fiction", the producers of "Natural Born Killers" filed a lawsuit against Tarantino, claiming that when he sold the script to them, he had forfeited the publishing rights; eventually, Tarantino was allowed to publish his original script.

Tarantino disowned the film, saying, "I hated that fucking movie. If you like my stuff, don't watch that movie."

When the film was first handed in to the MPAA, they told Stone they would give it an NC-17 unless he cut it. As such, Stone toned down the violence by cutting approximately four minutes of footage, and the MPAA re-rated the film as an R. In 1996, a Director's Cut was released on home video by Vidmark Entertainment and Pioneer Entertainment, as Warner Bros. wanted nothing to do with that particular version. Warner Home Video later released this cut on Blu-ray.

The film was banned completely upon release in Ireland, including – controversially – from cinema clubs. The ban was later quietly lifted.

In the UK, though the cinema release was delayed while the BBFC investigated reports that the film caused copycat murders in the USA and France, it was finally shown in cinemas in February 1995.

The original intended UK home video release in March 1996 was cancelled due to the Dunblane massacre in Scotland. In the meantime, Channel Five showed the film in November 1997. It was finally released on video in July 2001.

"Entertainment Weekly" ranked the film as the eighth most controversial film ever.

From almost the moment of its release, the film has been accused of encouraging and inspiring numerous murderers in North America, including the Heath High School shooting and the Columbine High School massacre. The Columbine killers even code-named their attack: "NBK", an acronym for "Natural Born Killers".




 


</doc>
<doc id="21181" url="https://en.wikipedia.org/wiki?curid=21181" title="Nancy Reagan">
Nancy Reagan

Nancy Davis Reagan (born Anne Frances Robbins; July 6, 1921 – March 6, 2016) was an American film actress and the wife of Ronald Reagan, the 40th president of the United States. She was the first lady of the United States from 1981 to 1989.

She was born in New York City. After her parents separated, she lived in Maryland with an aunt and uncle for six years. When her mother remarried in 1929, she moved to Chicago and later took the name Davis from her stepfather. As Nancy Davis, she was a Hollywood actress in the 1940s and 1950s, starring in films such as "The Next Voice You Hear...", "Night into Morning", and "Donovan's Brain". In 1952, she married Ronald Reagan, who was then president of the Screen Actors Guild. They had two children together. Reagan was the first lady of California when her husband was governor from 1967 to 1975, and she began to work with the Foster Grandparents Program.

Reagan became First Lady of the United States in January 1981, following her husband's victory in the 1980 presidential election. Early in his first term, she was criticized largely due to her decision to replace the White House china, which had been paid for by private donations. Following years of lax formality, she decided to restore a Kennedyesque glamour to the White House, and her interest in high-end fashion garnered much attention as well as criticism. She championed recreational drug prevention causes when she founded the "Just Say No" drug awareness campaign, which was considered her major initiative as First Lady. More discussion of her role ensued following a 1988 revelation that she had consulted an astrologer to assist in planning the president's schedule after the attempted assassination of her husband in 1981. She generally had a strong influence on her husband and played a role in a few of his personnel and diplomatic decisions.

After Ronald Reagan's term as president ended, the couple returned to their home in Bel Air, Los Angeles, California. Nancy devoted most of her time to caring for her husband, who was diagnosed with Alzheimer's disease in 1994, until his death at the age of 93 on June 5, 2004. Reagan remained active within the Reagan Library and in politics, particularly in support of embryonic stem cell research, until her death from congestive heart failure at age 94 on March 6, 2016.
Anne Frances Robbins was born on July 6, 1921, at Sloane Hospital for Women in Midtown Manhattan. She was the only child of Kenneth Seymour Robbins (1892–1972), a farmer turned car salesman who had been born into a once-prosperous family, and his actress wife, Edith Prescott Luckett (1888–1987). Her godmother was silent-film-star Alla Nazimova. From birth, she was commonly called Nancy.

She lived her first two years in Flushing, Queens, a borough of New York City, in a two-story house on Roosevelt Avenue between 149th and 150th Streets. Her parents separated soon after her birth and were divorced in 1928. After their separation, her mother traveled the country to pursue acting jobs and Robbins was raised in Bethesda, Maryland, for six years by her aunt, Virginia Luckett, and uncle, Audley Gailbraith, where she attended Sidwell Friends School for kindergarten through second grade. Nancy later described longing for her mother during those years: "My favorite times were when Mother had a job in New York, and Aunt Virgie would take me by train to stay with her."

In 1929, her mother married Loyal Edward Davis (1896–1982), a prominent conservative neurosurgeon who moved the family to Chicago. Nancy and her stepfather got along very well; she later wrote that he was "a man of great integrity who exemplified old-fashioned values." He formally adopted her in 1938, and she would always refer to him as her father. At the time of the adoption, her name was legally changed to Nancy Davis. She attended the Girls' Latin School of Chicago (describing herself as an average student),from 1929, until she graduated in 1939, and later attended Smith College in Massachusetts, where she majored in English and drama, graduating in 1943.

In 1940, a young Davis had appeared as a National Foundation for Infantile Paralysis volunteer in a memorable short subject film shown in movie theaters to raise donations for the crusade against polio. "The Crippler" featured a sinister figure spreading over playgrounds and farms, laughing over its victims, until finally dispelled by the volunteer. It was very effective in raising contributions.

Following her graduation from college, Davis held jobs in Chicago as a sales clerk in Marshall Field's department store and as a nurse's aide. With the help of her mother's colleagues in theatre, including ZaSu Pitts, Walter Huston, and Spencer Tracy, she pursued a professional career as an actress. She first gained a part in Pitts' 1945 road tour of "Ramshackle Inn", moving to New York City. She landed the role of Si-Tchun, a lady-in-waiting, in the 1946 Broadway musical about the Orient, "Lute Song", starring Mary Martin and a pre-fame Yul Brynner. The show's producer told her, "You look like you could be Chinese."

After passing a screen test, she moved to California and signed a seven-year contract with Metro-Goldwyn-Mayer Studios Inc. (MGM) in 1949; she later remarked, "Joining Metro was like walking into a dream world." Her combination of attractive appearance—centered on her large eyes—and somewhat distant and understated manner made her hard at first for MGM to cast and publicize. Davis appeared in eleven feature films, usually typecast as a "loyal housewife", "responsible young mother", or "the steady woman". Jane Powell, Debbie Reynolds, Leslie Caron, and Janet Leigh were among the actresses with whom she competed for roles at MGM.

Davis' film career began with small supporting roles in two films that were released in 1949, "The Doctor and the Girl" with Glenn Ford and "East Side, West Side" starring Barbara Stanwyck. She played a child psychiatrist in the film noir "Shadow on the Wall" (1950) with Ann Sothern and Zachary Scott; her performance was called "beautiful and convincing" by "New York Times" critic A. H. Weiler. She co-starred in 1950's "The Next Voice You Hear...", playing a pregnant housewife who hears the voice of God from her radio. Influential reviewer Bosley Crowther of "The New York Times" wrote that "Nancy Davis [is] delightful as [a] gentle, plain, and understanding wife." In 1951, Davis appeared in "Night into Morning", her favorite screen role, a study of bereavement starring Ray Milland. Crowther said that Davis "does nicely as the fiancée who is widowed herself and knows the loneliness of grief," while another noted critic, "The Washington Post"<nowiki>'</nowiki>s Richard L. Coe, said Davis "is splendid as the understanding widow." MGM released Davis from her contract in 1952; she sought a broader range of parts, but also married Reagan, keeping her professional name as Davis, and had her first child that year. She soon starred in the science fiction film "Donovan's Brain" (1953); Crowther said that Davis, playing the role of a possessed scientist's "sadly baffled wife," "walked through it all in stark confusion" in an "utterly silly" film. In her next-to-last movie, "Hellcats of the Navy" (1957), she played nurse Lieutenant Helen Blair, and appeared in a film for the only time with her husband, playing what one critic called "a housewife who came along for the ride." Another reviewer, however, stated that Davis plays her part satisfactorily, and "does well with what she has to work with."

Author Garry Wills has said that Davis was generally underrated as an actress because her constrained part in "Hellcats" was her most widely seen performance. In addition, Davis downplayed her Hollywood goals: promotional material from MGM in 1949 said that her "greatest ambition" was to have a "successful happy marriage"; decades later, in 1975, she would say, "I was never really a career woman but [became one] only because I hadn't found the man I wanted to marry. I couldn't sit around and do nothing, so I became an actress." Ronald Reagan biographer Lou Cannon nevertheless characterized her as a "reliable" and "solid" performer who held her own in performances with better-known actors. After her final film, "Crash Landing" (1958), Davis appeared for a brief time as a guest star in television dramas, such as the "Zane Grey Theatre" episode "The Long Shadow" (1961), where she played opposite Ronald Reagan, as well as "Wagon Train" and "The Tall Man", until she retired as an actress in 1962.

During her career, Davis served for nearly ten years on the board of directors of the Screen Actors Guild. Decades later, Albert Brooks attempted to coax her out of acting retirement by offering her the title role opposite himself in his 1996 film "Mother". She declined in order to care for her husband, and Debbie Reynolds played the part.

During her Hollywood career, Davis dated many actors, including Clark Gable, Robert Stack, and Peter Lawford; she later called Gable the nicest of the stars she had met. On November 15, 1949, she met Ronald Reagan, who was then president of the Screen Actors Guild. She had noticed that her name had appeared on the Hollywood blacklist. Davis sought Reagan's help to maintain her employment as a guild actress in Hollywood and for assistance in having her name removed from the list. Ronald Reagan informed her that she had been confused with another actress of the same name. The two began dating and their relationship was the subject of many gossip columns; one Hollywood press account described their nightclub-free times together as "the romance of a couple who have no vices". Ronald Reagan was sceptical about marriage, however, following his painful 1949 divorce from Jane Wyman, and he still saw other women.

After three years of dating, they eventually decided to marry while discussing the issue in the couple's favorite booth at Chasen's, a restaurant in Beverly Hills. The couple wed on March 4, 1952, at the Little Brown Church in the San Fernando Valley of Los Angeles, in a simple and hastily arranged ceremony designed to avoid the press; the marriage was her first and his second. The only people in attendance were fellow actor William Holden (the best man) and his wife, actress Brenda Marshall (the matron of honor). Nancy was likely already pregnant during the ceremony; the couple's first child, Patricia Ann Reagan (later better known by her professional name, Patti Davis), was born less than eight months later on October 21, 1952. Their son, Ronald Prescott Reagan (later better known as Ron Reagan) was born six years later on May 20, 1958. Reagan also became stepmother to Maureen Reagan (1941–2001) and Michael Reagan (b. 1945), her husband's children from his first marriage to Jane Wyman.
Observers described Nancy and Ronald's relationship as intimate. As president and first lady, the Reagans were reported to display their affection frequently, with one press secretary noting, "They never took each other for granted. They never stopped courting." Ronald often called Nancy "Mommy"; she called him "Ronnie". While the president was recuperating in the hospital after the 1981 assassination attempt, Nancy wrote in her diary, "Nothing can happen to my Ronnie. My life would be over." In a letter to Nancy, Ronald wrote, "whatever I treasure and enjoy ... all would be without meaning if I didn't have you." In 1998, a few years after her husband had been given a diagnosis of Alzheimer's disease, Nancy told "Vanity Fair", "Our relationship is very special. We were very much in love and still are. When I say my life began with Ronnie, well, it's true. It did. I can't imagine life without him." Nancy was known for the focused and attentive look, termed "the Gaze", that she fastened upon her husband during his speeches and appearances.

President Reagan's death in June 2004 ended what Charlton Heston called "the greatest love affair in the history of the American Presidency."

Nancy's relationship with her children was not always as close as the bond with her husband. She frequently quarreled with her children and her stepchildren. Her relationship with Patti was the most contentious; Patti flouted American conservatism, rebelled against her parents by joining the nuclear freeze movement, and authored many anti-Reagan books. The nearly 20 years of family feuding left Patti very much estranged from both her mother and father. Soon after her father's Alzheimer's disease was diagnosed, Patti and her mother reconciled and began to speak on a daily basis. Nancy's disagreements with Michael were also public matters; in 1984, she was quoted as saying that the two were in an "estrangement right now". Michael responded that Nancy was trying to cover up for the fact she had not met his daughter, Ashley, who had been born nearly a year earlier. They too eventually made peace. Nancy was thought to be closest to her stepdaughter Maureen during the White House years, but each of the Reagan children experienced periods of estrangement from their parents.

Nancy Reagan was First Lady of California during her husband's two terms as governor. She disliked living in the state capital of Sacramento, which lacked the excitement, social life, and mild climate to which she was accustomed in Los Angeles. She first attracted controversy early in 1967; after four months' residence in the California Governor's Mansion in Sacramento, she moved her family into a wealthy suburb because fire officials had labelled the mansion as a "firetrap." Though the Reagans had leased the new house at their expense, the move was viewed as snobbish when the matter was brought to the attention of the general public. Reagan defended her actions as being for the good of her family, a judgment with which her husband readily agreed. Friends of the family later helped support the cost of the leased house, while Reagan supervised construction of a new ranch-style governor's residence in nearby Carmichael. The new residence was finished just as Ronald Reagan left office in 1975, but his successor, Jerry Brown, refused to live there. It was sold in 1982, and California governors lived in improvised arrangements until Brown moved into the Governor's Mansion in 2015.

In 1967, Governor Reagan appointed his wife to the California Arts Commission, and a year later she was named "Los Angeles Times"' Woman of the Year; in its profile, the "Times" labeled her "A Model First Lady". Her glamour, style, and youthfulness,
made her a frequent subject for press photographers. As first lady, Reagan visited veterans, the elderly, and the handicapped, and worked with a number of charities. She became involved with the Foster Grandparents Program, helping to popularize it in the United States and Australia. She later expanded her work with the organization after arriving in Washington, and wrote about her experiences in her 1982 book "To Love a Child". The Reagans held dinners for former POWs and Vietnam War veterans while governor and first lady.

Governor Reagan's gubernatorial time in office ended in 1975, and he did not run for a third term; instead, he met with advisors to discuss a possible bid for the 1976 presidency, challenging incumbent President Gerald Ford. Ronald still needed to convince a reluctant Nancy before running, however. She feared for her husband's health and his career as a whole, though she felt that he was the right man for the job and eventually approved. Nancy took on a traditional role in the campaign, holding coffees, luncheons, and talks. She also oversaw personnel, monitored her husband's schedule, and occasionally provided press conferences. The 1976 campaign included the so-called "battle of the queens", contrasting Nancy with First Lady Betty Ford. They both spoke out over the course of the campaign on similar issues, but with different approaches. Nancy was upset by the warmonger image that the Ford campaign had drawn of her husband.

Though he lost the 1976 Republican nomination, Ronald Reagan ran for the presidency a second time in 1980. He succeeded in winning the nomination and defeated incumbent rival Jimmy Carter in a landslide. During this second campaign, Nancy played a prominent role, and her management of staff became more apparent. She organized a meeting among feuding campaign managers John Sears and Michael Deaver and her husband, which resulted in Deaver leaving the campaign and Sears being given full control. After the Reagan camp lost the Iowa Caucus and fell behind in New Hampshire polls, Nancy organized a second meeting and decided it was time to fire Sears and his associates; she gave Sears a copy of the press release announcing his dismissal. Her influence on her husband became particularly notable; her presence at rallies, luncheons, and receptions increased his confidence.

Reagan became the first lady of the United States when Ronald Reagan was inaugurated as president in January 1981. Early in her husband's presidency, Reagan stated her desire to create a more suitable "first home" in the White House, as the building had fallen into a state of disrepair following years of neglect. White House aide Michael Deaver described the second and third floor family residence as having "cracked plaster walls, chipped paint [and] beaten up floors"; rather than use government funds to renovate and redecorate, she sought private donations. In 1981, Reagan directed a major renovation of several White House rooms, including all of the second and third floors and rooms adjacent to the Oval Office, including the press briefing room. The renovation included repainting walls, refinishing floors, repairing fireplaces, and replacing antique pipes, windows, and wires. The closet in the master bedroom was converted into a beauty parlor and dressing room, and the West bedroom was made into a small gymnasium.

The first lady secured the assistance of renowned interior designer Ted Graber, popular with affluent West Coast social figures, to redecorate the family living quarters. A Chinese-pattern, handpainted wallpaper was added to the master bedroom. Family furniture was placed in the president's private study. The first lady and her designer retrieved a number of White House antiques, which had been in storage, and placed them throughout the mansion. In addition, many of Reagan's own collectibles were put out for display, including around twenty-five Limoges Boxes, as well as some porcelain eggs and a collection of plates.

The extensive redecoration was paid for by private donations. Many significant and long-lasting changes occurred as a result of the renovation and refurbishment, of which Reagan said, "This house belongs to all Americans, and I want it to be something of which they can be proud." The renovations received some criticisms for being funded by tax-deductible donations, meaning some of it eventually did indirectly come from the tax-paying public.

Reagan's interest in fashion was another one of her trademarks. While her husband was still president-elect, press reports speculated about Reagan's social life and interest in fashion. In many press accounts, Reagan's sense of style was favorably compared to that of a previous first lady, Jacqueline Kennedy. Friends and those close to her remarked that, while fashionable like Kennedy, she would be different from other first ladies; close friend Harriet Deutsch was quoted as saying, "Nancy has her own imprint."

White House photographer Mary Anne Fackelman-Miner, who was assigned to Reagan, said of her, "She always photographed so easily and was at ease in front of the cameras."

Reagan's wardrobe consisted of dresses, gowns, and suits made by luxury designers, including James Galanos, Bill Blass, and Oscar de la Renta. Her white, hand-beaded, one shoulder Galanos 1981 inaugural gown was estimated to cost $10,000, while the overall price of her inaugural wardrobe was said to cost $25,000. She favored the color red, calling it "a picker-upper", and wore it accordingly. Her wardrobe included red so often that the fire-engine shade became known as "Reagan red". She employed two private hairdressers, who would style her hair on a regular basis in the White House.

Fashion designers were pleased with the emphasis Reagan placed on clothing. Adolfo said the first lady embodied an "elegant, affluent, well-bred, chic American look", while Bill Blass commented, "I don't think there's been anyone in the White House since Jacqueline Kennedy Onassis who has her flair." William Fine, president of cosmetic company Frances Denney, noted that she "stays in style, but she doesn't become trendy."

Though her elegant fashions and wardrobe were hailed as a "glamorous paragon of chic", they were also controversial subjects. In 1982, she revealed that she had accepted thousands of dollars in clothing, jewelry, and other gifts, but defended her actions by stating that she had borrowed the clothes, and that they would either be returned or donated to museums, and that she was promoting the American fashion industry. Facing criticism, she soon said she would no longer accept such loans. While often buying her clothes, she continued to borrow and sometimes keep designer clothes throughout her time as first lady, which came to light in 1988. None of this had been included on financial disclosure forms; the non-reporting of loans under $10,000 in liability was in violation of a voluntary agreement the White House had made in 1982, while not reporting more valuable loans or clothes not returned was a possible violation of the Ethics in Government Act. Reagan expressed through her press secretary "regrets that she failed to heed counsel's advice" on disclosing them.

Despite the controversy, many designers who allowed her to borrow clothing, noted that the arrangement was good for their businesses, as well as for the American fashion industry overall. In 1989, Reagan was honored at the annual gala awards dinner of the Council of Fashion Designers of America, during which she received the council's lifetime achievement award. Barbara Walters said of her, "She has served every day for eight long years the word 'style.'"

Approximately a year into her husband's first term, Nancy explored the idea of ordering new state china service for the White House. A full china service had not been purchased since the Truman administration in the 1940s, as only a partial service was ordered in the Johnson administration. She was quoted as saying, "The White House really badly, badly needs china." Working with Lenox, the primary porcelain manufacturer in America, the first lady chose a design scheme of a red with etched gold band, bordering the scarlet and cream colored ivory plates with a raised presidential seal etched in gold in the center. The full service comprised 4,370 pieces, with 19 pieces per individual set. The service totaled $209,508. Although it was paid for by private donations, some from the private J. P. Knapp Foundation, the purchase generated quite a controversy, for it was ordered at a time when the nation was undergoing an economic recession. Furthermore, news of the china purchase emerged at the same time that her husband's administration had proposed school lunch regulations that would allow ketchup to be counted as a vegetable.
The new china, White House renovations, expensive clothing, and her attendance at the wedding of Charles and Diana, Prince and Princess of Wales, gave her an aura of being "out of touch" with the American people during the recession. This built upon the reputation she had coming to Washington, wherein many people concluded that Reagan was a vain and shallow woman, and her taste for splendor inspired the derogatory nickname "Queen Nancy". While Jacqueline Kennedy had also faced some press criticism for her spending habits, Reagan's treatment was much more consistent and negative. In an attempt to deflect the criticism, she self-deprecatingly donned a baglady costume at the 1982 Gridiron Dinner and sang "Second-Hand Clothes", mimicking the song "Second-Hand Rose". The skit helped to restore her reputation.

Reagan reflected on the criticisms in her 1989 autobiography, "My Turn". She described lunching with former Democratic National Committee chairman Robert S. Strauss, wherein Strauss said to her, "When you first came to town, Nancy, I didn't like you at all. But after I got to know you, I changed my mind and said, 'She's some broad!'" Reagan responded, "Bob, based on the press reports I read then, I wouldn't have liked me either!"
After the presidency of Jimmy Carter (who dramatically reduced the formality of presidential functions), Reagan brought a Kennedy-esque glamour back into the White House. She hosted 56 state dinners over eight years. She remarked that hosting the dinners is "the easiest thing in the world. You don't have to do anything. Just have a good time and do a little business. And that's the way Washington works." The White House residence staff found Reagan demanding to work for during the preparation for the state dinners, with the first lady overseeing every aspect of meal presentations, and sometimes requesting one dessert after another be prepared, before finally settling on one she approved of.

In general, the first lady's desire for everything to appear just right in the White House led the residence staff to consider her not easy to work for, with tirades following what she perceived as mistakes. One staffer later recalled, "I remember hearing her call for her personal maid one day and it scared the dickens out of me—just her tone. I never wanted to be on the wrong side of her." She did show loyalty and respect to a number of the staff. In particular, she came to the public defense of a maid who was indicted on charges of helping to smuggle ammunition to Paraguay, providing an affidavit to the maid's good character (even though it was politically inopportune to do so at the time of the Iran–Contra affair); charges were subsequently dropped, and the maid returned to work at the White House.

In 1987, Mikhail Gorbachev became the first Soviet leader to visit Washington, D.C. since Nikita Khrushchev made the trip in 1959 at the height of the Cold War. Nancy was in charge of planning and hosting the important and highly anticipated state dinner, with the goal to impress both the Soviet leader and especially his wife Raisa Gorbacheva. After the meal, she recruited pianist Van Cliburn to play a rendition of "Moscow Nights" for the Soviet delegation, to which Mikhail and Raisa broke out into song. Secretary of State George P. Shultz later commented on the evening, saying "We felt the ice of the Cold War crumbling." Reagan concluded, "It was a perfect ending for one of the great evenings of my husband's presidency."

The first lady launched the "Just Say No" drug awareness campaign in 1982, which was her primary project and major initiative as first lady. Reagan first became aware of the need to educate young people about drugs during a 1980 campaign stop in Daytop village, New York. She remarked in 1981 that "Understanding what drugs can do to your children, understanding peer pressure and understanding why they turn to drugs is ... the first step in solving the problem." Her campaign focused on drug education and informing the youth of the danger of drug abuse.

In 1982, Reagan was asked by a schoolgirl what to do when offered drugs; Reagan responded: "Just say no." The phrase proliferated in the popular culture of the 1980s, and was eventually adopted as the name of club organizations and school anti-drug programs. Reagan became actively involved by traveling more than throughout the United States and several nations, visiting drug abuse prevention programs and drug rehabilitation centers. She also appeared on television talk shows, recorded public service announcements, and wrote guest articles. She appeared in single episodes of the television drama "Dynasty" and the sitcom "Diff'rent Strokes", to underscore support for the "Just Say No" campaign, and in a rock music video, "Stop the Madness" (1985).

In 1985, Reagan expanded the campaign to an international level by inviting the First Ladies of various nations to the White House for a conference on drug abuse. On October 27, 1986, President Reagan signed a drug enforcement bill into law, which granted $1.7 billion in funding to fight the perceived crisis and ensured a mandatory minimum penalty for drug offenses. Although the bill was criticized, Reagan considered it a personal victory. In 1988, she became the first first lady invited to address the United Nations General Assembly, where she spoke on international drug interdiction and trafficking laws.

Critics of Reagan's efforts questioned their purpose, labelled Reagan's approach to promoting drug awareness as simplistic, and argued that the program did not address many social issues associated with drug use, including unemployment, poverty, and family dissolution.

Reagan assumed the role of unofficial "protector" for her husband after the attempted assassination of him in 1981. On March 30 of that year, President Reagan and three others were shot by troubled 25-year old John Hinckley, Jr as they left the Washington Hilton hotel. Nancy was alerted and arrived at George Washington University Hospital, where the President was hospitalized. She recalled having seen "emergency rooms before, but I had never seen one like this – with my husband in it." She was escorted into a waiting room, and when granted access to see her husband, he quipped to her, "Honey, I forgot to duck", borrowing the defeated boxer Jack Dempsey's jest to his wife.

An early example of the first lady's protective nature occurred when Senator Strom Thurmond entered the President's hospital room that day in March, passing the Secret Service detail by claiming he was the President's "close friend", presumably to acquire media attention. Nancy was outraged and demanded he leave. While the President recuperated in the hospital, the first lady slept with one of his shirts to be comforted by the scent. When Ronald Reagan was released from the hospital on April 12, she escorted him back to the White House.

Press accounts framed Reagan as her husband's "chief protector", an extension of their general initial framing of her as a helpmate and a Cold War domestic ideal. As it happened, the day after her husband was shot, Reagan fell off a chair while trying to take down a picture to bring to him in the hospital; she suffered several broken ribs, but was determined to not reveal it publicly.

During the Reagan administration, Nancy Reagan consulted a San Francisco astrologer, Joan Quigley, who provided advice on which days and times would be optimal for the president's safety and success. White House Chief of Staff Donald Regan grew frustrated with this regimen, which created friction between him and the first lady. This friction escalated with the revelation of the Iran–Contra affair, an administration scandal, in which the first lady felt Regan was damaging the president. She thought he should resign, and expressed this to her husband, although he did not share her view. Regan wanted President Reagan to address the Iran-Contra matter in early 1987 by means of a press conference, though the first lady refused to allow her husband to overexert himself due to a recent prostate surgery and astrological warnings. She became so angry with Regan that he hung up on her during a 1987 telephone conversation. According to the recollections of ABC News correspondent Sam Donaldson, when the President heard of this treatment, he demanded—and eventually received—Regan's resignation. Vice President George H. W. Bush is also reported to have suggested to her to have Regan fired.

In his 1988 memoir, "For the Record: From Wall Street to Washington", Regan wrote the following about Nancy Reagan's consultations with an astrologer:

Regan further claimed that Quigley selected the date of the 1985 Geneva Summit. For her part, Quigley stated in 1998 that she had "'absolutely nothing'" to do with arranging the summit and added that others were "'overemphasizing'" her role; however, in 1990, she released a book in which she asserted that she was "in charge" of the President's scheduling during the Reagan administration.

Reagan acknowledged in her memoirs that she altered the President's schedule without his knowledge based on astrological advice, but argues that "no political decision was ever based [on astrology]". She added, "Astrology was simply one of the ways I coped with the fear I felt after my husband almost died ... Was astrology one of the reasons [further attempts did not occur]? I don't "really" believe it was, but I don't "really" believe it wasn't."

Nancy Reagan wielded a powerful influence over President Reagan. 
In her memoirs, Reagan stated, "I felt panicky every time [Ronald Reagan] left the White House". Following the assassination attempt, she strictly controlled access to the president; occasionally, she even attempted to influence her husband's decision making.

Beginning in 1985, she strongly encouraged her husband to hold "summit" conferences with Soviet general secretary Mikhail Gorbachev, and suggested they form a personal relationship beforehand. Both Ronald Reagan and Gorbachev had developed a productive relationship through their summit negotiations. The relationship between Nancy Reagan and Raisa Gorbacheva was anything but the friendly, diplomatic one between their husbands; Reagan found Gorbacheva hard to converse with and their relationship was described as "frosty". The two women usually had tea and discussed differences between the USSR and the United States. Visiting the United States for the first time in 1987, Gorbacheva irked Reagan with lectures on subjects ranging from architecture to socialism, reportedly prompting the American president's wife to quip, "Who does that dame think she is?"

Press framing of Reagan changed from that of just helpmate and protector to someone with hidden power. As the image of her as a political interloper grew, she sought to explicitly deny that she was the power behind the throne. At the end of her time as First Lady, however, she said that her husband had not been well-served by his staff. She acknowledged her role in reaction in influencing him on personnel decisions, saying "In no way do I apologize for it." She wrote in her memoirs, "I don't think I was as bad, or as extreme in my power or my weakness, as I was depicted," but went on, "However the first lady fits in, she has a unique and important role to play in looking after her husband. And it's only natural that she'll let him know what she thinks. I always did that for Ronnie, and I always will."

In October 1987, a mammogram detected a lesion in Reagan's left breast and she was subsequently diagnosed with breast cancer. She chose to undergo a mastectomy rather than a lumpectomy, and the breast was removed on October 17, 1987. Ten days after the operation, her 99-year-old mother, Edith Luckett Davis, died in Phoenix, Arizona, leading Reagan to dub the period "a terrible month".

After the surgery, more women across the country had mammograms, which exemplified the influence that the first lady possessed.

Though Reagan was a controversial first lady, 56 percent of Americans had a favorable opinion of her when her husband left office on January 20, 1989, with 18 percent having an unfavorable opinion, and the balance not giving an opinion. Compared to fellow First Ladies when their husbands left office, Reagan's approval was higher than those of Rosalynn Carter and Hillary Clinton. However, she was less popular than Barbara Bush, and her disapproval rating was double that of Carter's.

Upon leaving the White House, the couple returned to California, where they purchased a home in the wealthy East Gate Old Bel Air neighborhood of Bel Air, Los Angeles, dividing their time between Bel Air and the Reagan Ranch in Santa Barbara, California. Ronald and Nancy regularly attended the Bel Air Church as well. After leaving Washington, Reagan made numerous public appearances, many on behalf of her husband. She continued to reside at the Bel Air home, where she lived with her husband until he died on June 5, 2004.

In late 1989, the former first lady established the Nancy Reagan Foundation, which aimed to continue to educate people about the dangers of substance abuse. The Foundation teamed with the BEST Foundation For A Drug-Free Tomorrow in 1994, and developed the Nancy Reagan Afterschool Program. She continued to travel around the United States, speaking out against drug and alcohol abuse.

Her memoirs, "My Turn: The Memoirs of Nancy Reagan" (1989), are an account of her life in the White House, commenting openly about her influence within the Reagan administration, and discussing the myths and controversies that surrounded the couple. In 1991, the author Kitty Kelley wrote an unauthorized and largely uncited biography about Reagan, repeating accounts of a poor relationship with her children, and introducing rumors of alleged sexual relations with singer Frank Sinatra. A wide range of sources commented that Kelley's largely unsupported claims are most likely false.

In 1989, the IRS (Internal Revenue Service) began investigating the Reagans over allegations they owed additional tax on the gifts and loans of high-fashion clothes and jewellery to the first lady during their time in the White House (recipients benefiting from the display of such items recognize taxable income even if they are returned). In 1992, the IRS determined the Reagans had failed to include some $3 million worth of fashion items between 1983 and 1988 on their tax returns; they were billed for a large amount of back taxes and interest, which was subsequently paid.

After President Reagan revealed that he had been diagnosed with Alzheimer's disease in 1994, she made herself his primary caregiver, and became actively involved with the National Alzheimer's Association and its affiliate, the Ronald and Nancy Reagan Research Institute in Chicago, Illinois.

In April 1997, Nancy Reagan joined President Bill Clinton and former Presidents Ford and Bush in signing the Summit Declaration of Commitment in advocating for participation by private citizens in solving domestic issues within the United States.

Nancy Reagan was awarded the Presidential Medal of Freedom, the nation's highest civilian honor, by President George W. Bush on July 9, 2002. President Reagan received his own Presidential Medal of Freedom in January 1993. Reagan and her husband were jointly awarded the Congressional Gold Medal on May 16, 2002, at the United States Capitol building, and were only the third president and first lady to receive it; she accepted the medal on behalf of both of them.

Ronald Reagan died in their Bel Air home on June 5, 2004. During the seven-day state funeral, Nancy, accompanied by her children and military escort, led the nation in mourning. She kept a strong composure, traveling from her home to the Reagan Library for a memorial service, then to Washington, D.C., where her husband's body lay in state for 34 hours prior to a national funeral service in the Washington National Cathedral. She returned to the library in Simi Valley for a sunset memorial service and interment, where, overcome with emotion, she lost her composure and cried in public for the first time during the week. After receiving the folded flag, she kissed the casket and mouthed "I love you" before leaving. During the week, CNN journalist Wolf Blitzer said, "She's a very, very strong woman, even though she looks frail."

She had directed the detailed planning of the funeral, which included scheduling all the major events and asking former President George H. W. Bush, as well as former British Prime Minister Margaret Thatcher, former Soviet Union Leader Mikhail Gorbachev, and former Canadian Prime Minister Brian Mulroney to speak during the National Cathedral Service. She paid very close attention to the details, something she had always done in her husband's life. Betsy Bloomingdale, one of Reagan's closest friends, stated, "She looks a little frail. But she is very strong inside. She is. She has the strength. She is doing her last thing for Ronnie. And she is going to get it right." The funeral marked her first major public appearance since she delivered a speech to the 1996 Republican National Convention on her husband's behalf.

The funeral had a great impact on her public image. Following substantial criticism during her tenure as first lady, she was seen somewhat as a national heroine, praised by many for supporting and caring for her husband while he suffered from Alzheimer's disease. "U.S. News & World Report" opined, "after a decade in the shadows, a different, softer Nancy Reagan emerged."

Following her husband's death, Reagan remained active in politics, particularly relating to stem cell research. Beginning in 2004, she favored what many consider to be the Democratic Party's position, and urged President George W. Bush to support federally funded embryonic stem cell research, in the hope that this science could lead to a cure for Alzheimer's disease. Although she failed to change the president's position, she did support his campaign for a second term.
In 2005, Reagan was honored at a gala dinner at the Ronald Reagan Building in Washington, D.C., where guests included Dick Cheney, Harry Reid, and Condoleezza Rice.

In 2007, she attended the national funeral service for Gerald Ford in the Washington National Cathedral. Reagan hosted two 2008 Republican presidential debates at the Reagan Presidential Library, the first in May 2007 and the second in January 2008. On March 25, she formally endorsed Senator John McCain, then the presumptive Republican party nominee for president, but McCain would go on to lose the election to Barack Obama.

Reagan attended the funeral of Lady Bird Johnson in Austin, Texas, on July 14, 2007, and three days later accepted the highest Polish distinction, the Order of the White Eagle, on behalf of Ronald Reagan at the Reagan Library. The Reagan Library opened the temporary exhibit "Nancy Reagan: A First Lady's Style", which displayed over eighty designer dresses belonging to her.

Reagan's health and well-being became a prominent concern in 2008. In February, she suffered a fall at her Bel Air home and was taken to Saint John's Health Center in Santa Monica, California. Doctors reported that she did not break her hip as feared, and she was released from the hospital two days later. News commentators noted that Reagan's step had slowed significantly, as the following month she walked in very slow strides with John McCain.

In October 2008, Reagan was admitted to Ronald Reagan UCLA Medical Center after falling at home. Doctors determined that the 87-year-old had fractured her pelvis and sacrum, and could recuperate at home with a regimen of physical therapy. As a result of her mishap, medical articles were published containing information on how to prevent falls. In January 2009, Reagan was said to be "improving every day and starting to get out more and more."
In March 2009, she praised President Barack Obama for reversing the ban on federally funded embryonic stem cell research. She traveled to Washington, D.C. in June 2009 to unveil a statue of her late husband in the Capitol rotunda. She was also on hand as President Obama signed the Ronald Reagan Centennial Commission Act, and lunched privately with Michelle Obama. Reagan revealed in an interview with "Vanity Fair" that Michelle Obama had telephoned her for advice on living and entertaining in the White House. Following the death of Senator Ted Kennedy in August 2009, she said she was "terribly saddened ... Given our political differences, people are sometimes surprised how close Ronnie and I have been to the Kennedy family ... I will miss him." She attended the funeral of Betty Ford in Rancho Mirage, California, on July 12, 2011.

Reagan hosted a 2012 Republican presidential debate at the Reagan Presidential Library on September 7, 2011. She suffered a fall in March 2012. Two months later, she endured several broken ribs, which prevented her from attending a speech given by Paul Ryan in the Reagan Presidential Library in May 2012. She endorsed Republican presidential candidate Mitt Romney on May 31, 2012, explaining that her husband would have liked Romney's business background and what she called "strong principles". Following the death of former British Prime Minister Margaret Thatcher in April 2013, she stated, "The world has lost a true champion of freedom and democracy ... Ronnie and I knew her as a dear and trusted friend, and I will miss her."

Reagan was the second-longest-lived First Lady of the United States, after Bess Truman who died at the age of 97.

On March 6, 2016, Reagan died of congestive heart failure at the age of 94. On March 7, President Barack Obama issued a presidential proclamation ordering the flag of the United States to be flown at half-staff until sunset on the day of Reagan's interment.

Her funeral was held on March 11 at the Ronald Reagan Presidential Library in Simi Valley, California. Representatives from ten first families were in attendance, including former president George W. Bush and first ladies Michelle Obama, Laura Bush, Hillary Clinton, and Rosalynn Carter. The other representatives were presidential children Steven Ford, Tricia Nixon Cox, Luci Baines Johnson, and Caroline Kennedy, and presidential grandchild Anne Eisenhower Flottl. Barbara Bush declined to attend.

Other prominent individuals in attendance included California governor Jerry Brown and former governors Arnold Schwarzenegger and Pete Wilson, then-former House speaker Nancy Pelosi and former House speaker Newt Gingrich, and former members of the Reagan administration, including George P. Shultz and Edwin Meese. A sizable contingent from the Hollywood entertainment industry attended as well, including Mr. T, Maria Shriver (Schwarzenegger's then-wife), Wayne Newton, Johnny Mathis, Anjelica Huston, John Stamos, Tom Selleck, Bo Derek, and Melissa Rivers. In all there were some 1,000 guests.

Eulogies were given by former prime minister of Canada Brian Mulroney, former secretary of state James Baker, Diane Sawyer, Tom Brokaw, and her children Patti Davis and Ron Reagan. After the funeral, Nancy Reagan was interred next to her husband.

As noted earlier, Nancy Reagan was awarded the Presidential Medal of Freedom in 2002 and the Congressional Gold Medal, in the same year. 
In 1989, she received the Council of Fashion Designers of America's lifetime achievement award.

As First Lady, Nancy Reagan received an Honorary Doctorate of Laws degree from Pepperdine University in 1983.
Later, she received an Honorary Doctor of Humane Letters degree from Eureka College in Illinois, her husband's alma mater, in 2009.


As Nancy Davis, she also made a number of television appearances from 1953 to 1962, as a guest star in dramatic shows or installments of anthology series. These included "Ford Television Theatre" (her first appearance with Ronald Reagan came during a 1953 episode titled "First Born"), "Schlitz Playhouse of Stars", "Dick Powell's Zane Grey Theatre" (appearing with Ronald Reagan in the 1961 episode "The Long Shadow"), "Wagon Train", "The Tall Man", and "General Electric Theater" (hosted by Ronald Reagan).





</doc>
<doc id="21182" url="https://en.wikipedia.org/wiki?curid=21182" title="New Brunswick">
New Brunswick

New Brunswick (, ) is one of four Atlantic provinces on the east coast of Canada. According to the Constitution of Canada, New Brunswick is the only bilingual province. About two-thirds of the population declare themselves anglophones, and one third francophones. One-third of the population describes themselves as bilingual. Atypically for Canada, only about half of the population lives in urban areas, mostly in Greater Moncton, Greater Saint John and the capital Fredericton.

Unlike the other Maritime provinces, New Brunswick's terrain is mostly forested uplands, with much of the land further from the coast, giving it a harsher climate. New Brunswick is 83% forested and less densely-populated than the rest of the Maritimes.

Being relatively close to Europe, New Brunswick was among the first places in North America to be explored and settled by Europeans, starting with the French in the early 1600s, who displaced the indigenous Mi'kmaq, Maliseet, and the Passamaquoddy peoples. The French settlers were later displaced when the area became part of the British Empire. In 1784, after an influx of refugees from the American Revolutionary War, the province was partitioned from Nova Scotia. In 1785 Saint John became Canada's first incorporated city. The province prospered in the early 1800s and the population grew rapidly, reaching about a quarter of a million by mid-century. In 1867, New Brunswick was one of four founding provinces of the Canadian Confederation, along with Nova Scotia and the Province of Canada (now Ontario and Quebec).

After Confederation, wooden shipbuilding and lumbering declined, while protectionism disrupted trade ties with New England. The mid-1900s found New Brunswick to be one of the poorest regions of Canada, now mitigated by Canadian transfer payments and improved support for rural areas. As of 2002, provincial gross domestic product was derived as follows: services (about half being government services and public administration) 43%; construction, manufacturing, and utilities 24%; real estate rental 12%; wholesale and retail 11%; agriculture, forestry, fishing, hunting, mining, oil and gas extraction 5%; transportation and warehousing 5%.

Tourism accounts for about 9% of the labour force directly or indirectly. Popular destinations include Fundy National Park and the Hopewell Rocks, Kouchibouguac National Park, and Roosevelt Campobello International Park. In 2013, 64 cruise ships called at Port of Saint John carrying on average 2600 passengers each.

Indigenous peoples have been in the area since about 7000 BC. At the time of European contact, inhabitants were the Mi'kmaq, the Maliseet, and the Passamaquoddy. Although these tribes did not leave a written record, their language is present in many placenames, such as Aroostook, Bouctouche, Petitcodiac, Quispamsis, and Shediac.

New Brunswick may have been part of Vinland during the Norse exploration of North America, and Basque, Breton, and Norman fishermen may have visited the Bay of Fundy in the early 1500s.

The first documented European visits were by Jacques Cartier in 1534. In 1604, a party including Samuel de Champlain visited the mouth of the Saint John River on the eponymous Saint-Jean-Baptiste Day. Now Saint John, this was later the site of the first permanent European settlement in New Brunswick. French settlement eventually extended up the river to the site of present-day Fredericton. Other settlements in the southeast extended from Beaubassin, near the present-day border with Nova Scotia, to Baie Verte, and up the Petitcodiac, Memramcook, and Shepody Rivers.

By the early 1700s the French settlements formed a part of Acadia, a colonial division of New France. Acadia covered what is now the Maritimes, as well as bits of Quebec and Maine. The British conquest of most of the Acadian peninsula occurred during the Queen Anne's War, and was formalized in the Treaty of Utrecht of 1713. After the war, French Acadia was reduced to Île Saint-Jean (Prince Edward Island) and Île-Royale (Cape Breton Island). The ownership of continental Acadia (New Brunswick) remained disputed, with an informal border on the Isthmus of Chignecto. In an effort to limit British expansion into continental Acadia, the French built Fort Beauséjour at the isthmus in 1751.

From 1749 to 1755, the British engaged in a campaign to consolidate its control over Nova Scotia. The resulting conflict led to an Acadian Exodus to French controlled territories in North America, including portions of continental Acadia. In 1755, the British captured Fort Beauséjour, severing the Acadian supply lines to Nova Scotia, and Île-Royale. Unable to make most of the Acadians sign an unconditional oath of allegiance, British authorities undertook a campaign to expel the Acadians in the initial periods of the Seven Years' War.

Continental Acadia was eventually incorporated into the British colony of Nova Scotia, with nearly all of New France being surrendered to the British with the Treaty of Paris in 1763. Acadians that returned from exile discovered several thousand immigrants, mostly from New England, on their former lands. Some settled around Memramcook and along the Saint John River. In 1766, settlers from Pennsylvania founded Moncton, and English settlers from Yorkshire arrived in the Sackville area. However, settlement of the area remained slow in the mid 18th century.

After the American Revolution, about 10,000 loyalist refugees settled along the north shore of the Bay of Fundy, commemorated in the province's motto, ("hope restored"). The number reached almost 14,000 by 1784, with about one in ten eventually returning to America. New Brunswick was partitioned from Nova Scotia in 1784, and that year saw its first elected assembly. The colony was named New Brunswick in honour of George III, King of Great Britain, King of Ireland, and Prince-elector of Brunswick-Lüneburg in what is now Germany. In 1785, Saint John became Canada's first incorporated city. The population of the colony reached 26,000 in 1806 and 35,000 in 1812.

The 1800s saw an age of prosperity based on wood export and shipbuilding, bolstered by The Canadian–American Reciprocity Treaty of 1854 and demand from the American Civil War. St. Martins became the third most productive shipbuilding town in the Maritimes, producing over 500 vessels. In 1848, responsible home government was granted and the 1850s saw the emergence of political parties largely organised along religious and ethnic lines. The first half of the 1800s saw large-scale immigration from Ireland and Scotland, with the population reaching 252,047 by 1861.

The notion of unifying the separate colonies of British North America was discussed increasingly in the 1860s. Many felt that the American Civil war was the result of weak central government and wished to avoid such violence and chaos. The 1864 Charlottetown Conference was intended to discuss a Maritime Union, but concerns over possible conquest by the Americans, coupled with a belief that Britain was unwilling to defend its colonies against American attack, led to a request from the Province of Canada (now Ontario and Quebec) to expand the meeting's scope. In 1866 the US cancelled the Canadian–American Reciprocity Treaty, leading to loss of trade with New England and prompting a desire to build trade within British North America, while Fenian raids increased support for union. On 1 July 1867, New Brunswick entered the Canadian Confederation along with Nova Scotia and the Province of Canada.

Confederation brought into existence the Intercolonial Railway in 1872, a consolidation of the existing Nova Scotia Railway, European and North American Railway, and Grand Trunk Railway. In 1879 John A. Macdonald's Conservatives enacted the National Policy which called for high tariffs and opposed free trade, disrupting the trading relationship between the Maritimes and New England. The economic situation was worsened by the decline of the wooden ship building industry. The railways and tariffs did foster the growth of new industries in the province such as textile manufacturing, iron mills, and sugar refineries, many of which eventually failed to compete with better capitalized industry in central Canada.

In 1937 New Brunswick had the highest infant mortality and illiteracy rates in Canada. At the end of the Great Depression the New Brunswick standard of living was much below the Canadian average. In 1940 the Rowell–Sirois Commission reported that federal government attempts to manage the depression illustrated grave flaws in the Canadian constitution. While the federal government had most of the revenue gathering powers, the provinces had many expenditure responsibilities such as healthcare, education, and welfare, which were becoming increasingly expensive. The Commission recommended the creation of equalization payments, implemented in 1957.

After Canada joined World War II, 14 NB army units were organized, in addition to the The Royal New Brunswick Regiment, and first deployed in the Italian campaign in 1943. After the Normandy landings they redeployed to northwestern Europe, along with The North Shore Regiment. The British Commonwealth Air Training Plan, a training program for ally pilots, established bases in Moncton, Chatham, and Pennfield Ridge, as well as a military typing school in Saint John. While relatively unindustrialized before the war, New Brunswick became home to 34 plants on military contracts from which the province received over $78 million. Prime Minister William Lyon Mackenzie King, who had promised no conscription, asked the provinces if they would release the government of said promise. New Brunswick voted 69.1% yes. The policy was not implemented until 1944, too late for many of the conscripts to be deployed. There were 1808 NB fatalities among the armed forces.

The Acadians in northern New Brunswick had long been geographically and linguistically isolated from the more numerous English speakers to the south. The population of French origin grew dramatically after Confederation, from about 16 per cent in 1871 to 34 per cent in 1931. Government services were often not available in French, and the infrastructure in Francophone areas was less developed than elsewhere. In 1960 Premier Louis Robichaud embarked on the New Brunswick Equal Opportunity program, in which education, rural road maintenance, and healthcare fell under the sole jurisdiction of a provincial government that insisted on equal coverage throughout the province, rather than the former county-based system.

The flag of New Brunswick, based on the coat of arms, was adopted in 1965. The conventional heraldic representations of a lion and a ship represent colonial ties with Europe, and the importance of shipping at the time the coat of arms was assigned.

Roughly square, New Brunswick is bordered on the north by Quebec, on the east by the Atlantic Ocean, on the south by the Bay of Fundy, and on the west by the US state of Maine. The southeast corner of the province is connected to Nova Scotia at the isthmus of Chignecto.

Glaciation has left much of New Brunswick's uplands with only shallow, acidic soils which have discouraged settlement but which are home to enormous forests.

New Brunswick's climate is more severe than that of the other Maritime provinces, which are lower and have more shoreline along the moderating sea. New Brunswick has a humid continental climate, with slightly milder winters on the Gulf of St. Lawrence coastline. Elevated parts of the far north of the province have a subarctic climate.

Evidence of climate change in New Brunswick includes: more intense precipitation events, more frequent winter thaws, and one quarter to half the amount of snowpack. Today the sea level is about 30 cm higher than it was 100 years ago, and it is expected to rise twice that much again by the year 2100.

Most of New Brunswick is forested with secondary forest or tertiary forest. At the start of European settlement, the Maritimes were covered from coast to coast by a forest of mature trees, giants by today's standards. Today less than one per cent of old-growth Acadian forest remains, and the World Wide Fund for Nature lists the Acadian Forest as endangered. Following the frequent large scale disturbances caused by settlement and timber harvesting, the Acadian forest is not growing back as it was, but is subject to borealization. This means that exposure-resistant species that are well adapted to the frequent large scale disturbances common in the boreal forest are increasingly abundant. These include jack pine, balsam fir, black spruce, white birch, and poplar. Forest ecosystems support large carnivores such as the bobcat, Canada lynx, and black bear, and the large herbivores moose and white-tailed deer.

Fiddlehead greens are harvested from the Ostrich fern which grows on riverbanks. Furbish's lousewort a perennial herb endemic to the shores of the upper Saint John River, is an endangered species threatened by habitat destruction, riverside development, forestry, littering and recreational use of the riverbank. Many wetlands are being disrupted by the highly invasive Introduced species purple loosestrife.

Bedrock types range from 1 billion to 200 million years old.
Much of the bedrock in the west and north derives from ocean deposits in the Ordovician that were subject to folding and igneous intrusion and that were eventually covered with lava during the Paleozoic, peaking during the Acadian orogeny.

During the Carboniferous era, about 340 million years ago, New Brunswick was in the Maritimes Basin, a sedimentary basin near the equator. Sediments, brought by rivers from surrounding highlands, accumulated there; after being compressed, they produced the Albert oil shales of southern New Brunswick. Eventually sea water from the Panthalassic Ocean invaded the basin, forming the Windsor Sea. Once this receded, conglomerates, sandstones, and shales accumulated. The rust colour of these was caused by the oxidation of iron in the beds between wet and dry periods. Such late carboniferous rock formed the Hopewell Rocks, which have been shaped by the extreme tidal range of the Bay of Fundy.

In the early Triassic, as Pangea drifted north it was rent apart, forming the rift valley that is the Bay of Fundy. Magma pushed up through the cracks, forming basalt columns on Grand Manan.

New Brunswick lies entirely within the Appalachian Mountain range. All of the rivers of New Brunswick drain into the Gulf of Saint Lawrence to the east or the Bay of Fundy to the south. These watersheds include lands in Quebec and Maine.

New Brunswick and the rest of the Maritime Peninsula was covered by thick layers of ice during the last glacial period (the Wisconsinian glaciation). It cut U-shaped valleys in the Saint John and Nepisiguit River valleys and pushed granite boulders from the Miramichi highlands south and east, leaving them as erratics when the ice receded at the end of the Wisconsin glaciation, along with deposits such as the eskers between Woodstock and St George, today sources of sand and gravel.

The four Atlantic Provinces are Canada's least populated, with New Brunswick the third least populous at 747,101 in 2016. The Atlantic provinces also have higher rural populations. New Brunswick was largely rural until 1951; since then, the rural-urban split has been roughly even. Population density in the Maritimes is above average among Canadian provinces, which reflects their small size and the fact that they do not possess large, unpopulated hinterlands, as do the other seven provinces and three territories.

New Brunswick's 107 municipalities cover of the province's land mass but are home to of its population. The three major urban areas are in the south of the province and are Greater Moncton, population 126,424, Greater Saint John, population 122,389, and Greater Fredericton, population 85,688.

In the 2001 census, the most commonly reported ethnicities were British and Irish 60%, French Canadian or Acadian 31%, other European 7%, First Nations 3%, Asian Canadian 2%. Each person could choose more than one ethnicity.

According to the Canadian Constitution, both English and French are the official languages of New Brunswick, making it the only officially bilingual province. Anglophone New Brunswickers make up roughly two-thirds of the population, while about one-third are Francophone. Recently there has been growth in the numbers of people reporting themselves as bilingual, with 34% reporting that they speak both English and French. This reflects a trend across Canada.

In the 2011 census, 84% of provincial residents reported themselves as Christian: 52% were Roman Catholic, 8% Baptist, 8% United Church of Canada, and 7% Anglican. Fifteen percent of residents reported no religion.

As of October 2017 seasonally-adjusted employment is 73,400 for the goods-producing sector and 280,900 for the services-producing sector. Those in the goods-producing industries are mostly employed in manufacturing or construction, while those in services work in social assistance, trades, and health care. A large portion of the economy is controlled by the Irving Group of Companies, which consists of the holdings of the family of K. C. Irving. The companies have significant holdings in agriculture, forestry, food processing, freight transport (including railways and trucking), media, oil, and shipbuilding.

The United States is the province's largest export market, accounting for 92% of a foreign trade valued in 2014 at almost $13 billion, with refined petroleum making up 63% of that, followed by seafood products, pulp, paper and sawmill products and non-metallic minerals (chiefly potash). The value of exports, mostly to the United States, was $1.6 billion in 2016. About half of that came from lobster. Other products include salmon, crab, and herring. In 2015, spending on non-resident tourism in New Brunswick was $441 million, which provided $87 million in tax revenue.

A large number of residents from New Brunswick are employed in the primary sector of industry. More than 13,000 New Brunswickers work in agriculture, shipping products worth over $1 billion, half of which is from crops, and half of that from potatoes, mostly in the Saint John River valley. McCain Foods is one of the world's largest manufacturers of frozen potato products. Other products include apples, cranberries, and maple syrup. New Brunswick was in 2015 the biggest producer of wild blueberries in Canada. The value of the livestock sector is about a quarter of a billion dollars, nearly half of which is dairy. Other sectors include poultry, fur, and goats, sheep, and pigs.

About 83% of New Brunswick is forested. Historically important, it accounted for more than 80% of exports in the mid 1800s. By the end of the 1800s the industry, and shipbuilding, were declining due to external economic factors. The 1920s saw the development of a pulp and paper industry. In the mid-1960s, forestry practices changed from the controlled harvests of a commodity to the cultivation of the forests. The industry employs nearly 12,000, generating revenues around $437 million.

Mining was historically unimportant in the province, but has grown since the 1950s. The province's GDP from the Mining and Quarrying industry in 2015 was $299.5 Million. Mines in New Brunswick produce lead, zinc, copper, and potash.

Public education elementary and secondary education in the province is administered by the provincial Department of Education and Early Childhood Development. New Brunswick has a parallel system of Anglophone and Francophone public schools.

The province also operates five public post-secondary institutions, including a college, and four universities. Four public universities operate campuses in New Brunswick, including the oldest English-language university in the country, the University of New Brunswick. The other universities in the province include Mount Allison University, St. Thomas University, and the Université de Moncton. All four universities offer undergraduate, and postgraduate education. Additionally, the Université de Moncton, and the University of New Brunswick also offer professional education. Medical education programs have also been established at both the Université de Moncton and at UNBSJ in Saint John (affiliated with Université de Sherbrooke and Dalhousie University respectively).

Public colleges in the province are managed as a part of the New Brunswick Community College (NBCC) system. In addition to public institutions, the province is also home to several private vocational schools, such as the Moncton Flight College; and universities, the largest being Crandall University.

Under Canadian federalism, power is divided between federal and provincial governments. Among areas under federal jurisdiction are citizenship, foreign affairs, national defence, fisheries, criminal law, Indian policies, and many others. Provincial jurisdiction covers public lands, health, education, and local government, among other things. Jurisdiction is shared for immigration, pensions, agriculture, and welfare.

The parliamentary system of government is modelled on the British Westminster system. Forty-nine representatives, nearly always members of political parties, are elected to the Legislative Assembly of New Brunswick. The head of government is the Premier of New Brunswick, normally the leader of the party or coalition with the most seats in the legislative assembly. Governance is handled by the executive council (cabinet), with about 32 ministries. Ceremonial duties of the Monarchy in New Brunswick are mostly carried out by the Lieutenant Governor of New Brunswick.

Under amendments to the province's Legislative Assembly Act in 2007, a provincial election is held every four years. The two largest political parties are the New Brunswick Liberal Association and the Progressive Conservative Party of New Brunswick. Since the 2018 election, minor parties are the Green Party of New Brunswick and the People's Alliance of New Brunswick.

The Court of Appeal of New Brunswick is the highest provincial court. It hears appeals from:

The system consists of eight Judicial Districts, loosely based on the counties. The Chief Justice of New Brunswick serves at the apex of this court structure.

Ninety-two per cent of the land in the province, inhabited by about 35% of the population, is under provincial administration and has no local, elected representation. The 51% of the province that is Crown land is administered by the Department of Natural Resources and Energy Development.

Most of the province is administrated as a local service district (LSD), an unincorporated unit of local governance. As of 2017 there are 237 LSDs. Services, paid for by property taxes, include a variety of services such as fire protection, solid waste management, street lighting, and dog regulation. LSDs may elect advisory committees and work with the Department of Local Government to recommend how to spend locally collected taxes.

In 2006 there were three rural communities. This is a relatively new entity; to be created, it requires a population of 3,000 and a tax base of $200 million. In 2006 there were 101 municipalities.

Regional Service Commissions, which number 12, were introduced in 2013 to regulate regional planning and solid waste disposal, and provide a forum for discussion on a regional level of police and emergency services, climate change adaptation planning, and regional sport, recreational and cultural facilities. The commissions' administrative councils are populated by the mayors of each municipality or rural community within a region.

Historically the province was divided into counties with elected governance, but this was abolished in 1966. These were subdivided into 152 parishes, which also lost their political significance in 1966 but are still used as census subdivisions by Statistics Canada.

New Brunswick has the most poorly-performing economy of any Canadian province, with a per capita income of $28,000. The government has historically run at a large deficit. With about half of the population being rural, it is expensive for the government to provide education and health services, which account for 60 per cent of government expenditure. Thirty-six per cent of the provincial budget is covered by federal cash transfers.

The government has frequently attempted to create employment through subsidies, which has often failed to generate long-term economic prosperity and has resulted in bad debt, examples of which include Bricklin, Atcon, and the Marriott call centre in Fredericton.

According to a 2014 study by the Atlantic Institute for Market Studies, the large public debt is a very serious problem. Government revenues are shrinking because of a decline in federal transfer payments. Though expenditures are down (through government pension reform and a reduction in the number of public employees), they have increased relative to GDP, necessitating further measures to reduce debt in the future.

In the 2014–15 fiscal year, provincial debt reached $12.2 billion or 37.7 per cent of nominal GDP, an increase over the $10.1 billion recorded in 2011–12. The debt-to-GDP ratio is projected to fall to 36.7% in 2019–20.

Publicly-owned NB Power operates 13 of New Brunswick's generating stations, deriving power from fuel oil and diesel (1497 MW), hydro (889 MW), nuclear (660 MW), and coal (467 MW). There were 30 active natural gas production sites in 2012.

The Department of Transportation and Infrastructure maintains government facilities and the province's highway network and ferries. The Trans-Canada Highway is not under federal jurisdiction, and traverses the province from Edmundston following the Saint John River Valley, through Fredericton, Moncton, and on to Nova Scotia and Prince Edward Island.

Via Rail's Ocean service, which connects Montreal to Halifax, is currently the oldest continuously operated passenger route in North America, with stops from west to east at Campbellton, Charlo, Jacquet River, Petit Rocher, Bathurst, Miramichi, Rogersville, Moncton, and Sackville.

Canadian National Railway operates freight services along the same route, as well as a subdivision from Moncton to Saint John. The New Brunswick Southern Railway, a division of J. D. Irving Limited, together with its sister company Eastern Maine Railway form a continuous main line connecting Saint John and Brownville Junction, Maine.

There are about 61 historic places in New Brunswick, including Fort Beauséjour, Kings Landing Historical Settlement and the Village Historique Acadien. Established in 1842, the New Brunswick Museum in Saint John was designated as the provincial museum of New Brunswick. The province is also home to a number of other museums in addition to the provincial museum.

New Brunswick is home to a number of individuals that worked as musicians, in the performing arts, and/or the visual arts. Music of New Brunswick includes artists such as Henry Burr, Roch Voisine, Lenny Breau, and Édith Butler. Symphony New Brunswick, based in Saint John, tours extensively in the province. Symphony New Brunswick based in Saint John and the Atlantic Ballet Theatre of Canada (based in Moncton), tours nationally and internationally.

Theatre New Brunswick (based in Fredericton), tours plays around the province. Canadian playwright Norm Foster saw his early works premiere with Theatre New Brunswick. Other live theatre troops include the Théatre populaire d'Acadie in Caraquet, and Live Bait Theatre in Sackville. The refurbished Imperial and Capitol Theatres are found in Saint John and Moncton, respectively; the more modern Playhouse is in Fredericton.

Mount Allison University in Sackville began offering classes in 1854. The program came into its own under John A. Hammond, from 1893 to 1916. Alex Colville and Lawren Harris later studied and taught art there, and both Christopher Pratt and Mary Pratt were trained at Mount Allison. The university also opened an art gallery in 1895 and is named for its patron, John Owens of Saint John. The art gallery at Mount Allison University is presently the oldest university-operated art gallery in Canada. Modern New Brunswick artists include landscape painter Jack Humphrey, sculptor Claude Roussel, and Miller Brittain. The province is also home to the Beaverbrook Art Gallery, which was designated as the provincial art gallery in 1994.

Julia Catherine Beckwith, born in Fredericton, was Canada's first published novelist. Poet Bliss Carman and his cousin Charles G. D. Roberts were some of the first Canadians to achieve international fame for letters. Antonine Maillet was the first non-European winner of France's Prix Goncourt. Other modern writers include Alfred Bailey, Alden Nowlan, John Thompson, Douglas Lochhead, K. V. Johansen, David Adams Richards, Raymond Fraser, and France Daigle. A recent New Brunswick Lieutenant-Governor, Herménégilde Chiasson, is a poet and playwright. The Fiddlehead, established in 1945 at University of New Brunswick, is Canada's oldest literary magazine.

New Brunswick has four daily newspapers: the "Times & Transcript", serving eastern New Brunswick, the "Telegraph-Journal", based in Saint John and distributed province-wide, "The Daily Gleaner", based in Fredericton, and "L'Acadie Nouvelle", based in Caraquet. The three English-language dailies and the majority of the weeklies are owned and operated by Brunswick News—which is privately owned by James K. Irving. Due to its dominant position, Brunswick News has been accused by critics of being biased towards the Irving Group of Companies, including its reluctance to publish stories that are critical of the group.

The Canadian Broadcasting Corporation has Anglophone television and radio operations in Fredericton. Télévision de Radio-Canada is based in Moncton. CTV and Global also operate stations in New Brunswick, which operate largely as sub-feeds of their stations in Halifax as part of regional networks.




</doc>
<doc id="21184" url="https://en.wikipedia.org/wiki?curid=21184" title="Nova Scotia">
Nova Scotia

Nova Scotia (; ) is a province in eastern Canada. With a population of 923,598 as of 2016, it is the most populous of Canada's three Maritime provinces and the four Atlantic provinces. It is the country's second most-densely populated province and second-smallest province by area, both after neighbouring Prince Edward Island. Its area of includes Cape Breton Island and 3,800 other coastal islands. The peninsula that makes up Nova Scotia's mainland is connected to the rest of North America by the Isthmus of Chignecto, on which the province's land border with New Brunswick is located. The province borders the Bay of Fundy to the northwest and the Atlantic Ocean to the south and east, and is separated from Prince Edward Island and the island of Newfoundland by the Northumberland and Cabot straits, respectively.

The land that comprises what is now Nova Scotia has been inhabited by the indigenous Miꞌkmaq people for thousands of years. France's first settlement in North America, , was established in 1605 and intermittently served in various locations as the capital of the French colony of Acadia for over a hundred years. The Fortress of Louisbourg was a key focus point in the struggle between the British and French for control of the area, changing hands numerous times in the until France relinquished its claims with the Treaty of Paris in 1763. During the American Revolutionary War, thousands of Loyalists settled in Nova Scotia. In 1848, Nova Scotia became the first British colony to achieve responsible government, and it federated in July 1867 with New Brunswick and the Province of Canada (now Ontario and Quebec) to form what is now the country of Canada.

Nova Scotia's capital and largest city is Halifax, which is today home to about 45 per cent of the province's population and is the thirteenth-largest census metropolitan area in Canada.

"Nova Scotia" means "New Scotland" in Latin and is the recognized English-language name for the province. In both French and Scottish Gaelic, the province is directly translated as "New Scotland" (French: '. Gaelic: '). In general, Romance and Slavic languages use a direct translation of "New Scotland", while most other languages use direct transliterations of the Latin / English name. 

The province was first named by the English in the 1621 Royal Charter granting to Sir William Alexander in 1632 the right to settle lands including modern Nova Scotia, Cape Breton Island, Prince Edward Island, New Brunswick and the Gaspé Peninsula.

Nova Scotia is Canada's second-smallest province in area, after Prince Edward Island. The province's mainland is the Nova Scotia peninsula, surrounded by the Atlantic Ocean and including numerous bays and estuaries. Nowhere in Nova Scotia is more than from the ocean. Cape Breton Island, a large island to the northeast of the Nova Scotia mainland, is also part of the province, as is Sable Island, a small island notorious for being the site of offshore shipwrecks, approximately from the province's southern coast.

Nova Scotia has many ancient fossil-bearing rock formations. These formations are particularly rich on the Bay of Fundy's shores. Blue Beach near Hantsport, Joggins Fossil Cliffs, on the Bay of Fundy's shores, has yielded an abundance of Carboniferous-age fossils. Wasson's Bluff, near the town of Parrsboro, has yielded both Triassic- and Jurassic-age fossils.

The province contains 5,400 lakes.

Nova Scotia lies in the mid-temperate zone and, although the province is almost surrounded by water, the climate is closer to continental climate rather than maritime. The winter and summer temperature extremes of the continental climate are moderated by the ocean. However, winters are cold enough to be classified as continental—still being nearer the freezing point than inland areas to the west. The Nova Scotian climate is in many ways similar to the central Baltic Sea coast in Northern Europe, only wetter and snowier. This is true although Nova Scotia is some fifteen parallels further south. Areas not on the Atlantic coast experience warmer summers more typical of inland areas, and winter lows are a little colder.

Described on the provincial vehicle licence plate as Canada's Ocean Playground, Nova Scotia is surrounded by four major bodies of water: the Gulf of Saint Lawrence to the north, the Bay of Fundy to the west, the Gulf of Maine to the southwest, and the Atlantic Ocean to the east.

The province includes regions of the Mi'kmaq nation of Mi'kma'ki (""). (The territory of the Nation of Mi'kma'ki also includes the Maritimes, parts of Maine, Newfoundland and the Gaspé Peninsula.) The Mi'kmaq people are among the large Algonquian-language family and inhabited Nova Scotia at the time the first European colonists arrived.

Warfare was a notable feature in Nova Scotia during the 17th and 18th centuries. The French arrived in 1604, and Catholic Mi'kmaq and Acadians formed the majority of the population of the colony for the next 150 years. In 1605, French colonists established the first permanent European settlement in the future Canada (and the first north of Florida) at Port Royal, founding what would become known as Acadia.

During the first 80 years the French and Acadians lived in Nova Scotia, nine significant military clashes took place as the English and Scottish (later British), Dutch and French fought for possession of the area. These encounters happened at Port Royal, Saint John, Cap de Sable (present-day Port La Tour, Nova Scotia), Jemseg (1674 and 1758) and Baleine (1629). The Acadian Civil War took place from 1640 to 1645.

Beginning with King William's War in 1688, a series of six wars took place between the English/British and the French, with Nova Scotia being a consistent theatre of conflict between the two powers.

Hostilities between the English/British and French resumed from 1702 to 1713, known as Queen Anne's War. The British siege of Port Royal took place in 1710, ending French-rule in peninsular Acadia. The subsequent signing of the Treaty of Utrecht in 1713 formally recognized this, although saw the returned Cape Breton Island ("") to the French. Despite the British conquest of Acadia in 1710, Nova Scotia remained primarily occupied by Catholic Acadians and Mi'kmaq, who confined British forces to Annapolis and to Canso. Present-day New Brunswick then still formed a part of the French colony of Acadia. Immediately after the capture of Port Royal in 1710, Francis Nicholson announced it would be renamed Annapolis Royal in honor of Queen Anne.

As a result of Father Rale's War (1722–1725), the Mi'kmaq signed a series of treaties with Great Britain in 1725. The British signed a treaty (or "agreement") with the Mi'kmaq, but the authorities have often disputed its definition of the rights of the Mi'kmaq to hunt and fish on their lands. However, conflict between the Acadians, Mi'kmaq, French, and the British persisted in the following decades with King George's War (1744–1748). 

Father Le Loutre's War (1749–1755) began when Edward Cornwallis arrived to establish Halifax with 13 transports on 21 June 1749. A General Court, made up of the governor and the Council, was the highest court in the colony at the time. Jonathan Belcher was sworn in as chief justice of the Nova Scotia Supreme Court on 21 October 1754. The first legislative assembly in Halifax, under the Governorship of Charles Lawrence, met on 2 October 1758. During the French and Indian War of 1754–63 (the North American theatre of the Seven Years' War of 1756–1763), the British deported the Acadians and recruited New England Planters to resettle the colony. The 75-year period of war ended with the Halifax Treaties between the British and the Mi'kmaq (1761). After the war, some Acadians were allowed to return and the British made treaties with the Mi’kmaq.

In 1763, most of Acadia (Cape Breton Island, St. John's Island (now Prince Edward Island), and New Brunswick) became part of Nova Scotia. In 1765, the county of Sunbury was created. This included the territory of present-day New Brunswick and eastern Maine as far as the Penobscot River. In 1769, St. John's Island became a separate colony.

The American Revolution (1775–1783) had a significant impact on shaping Nova Scotia. Initially, Nova Scotia—"the 14th American Colony" as some called it—displayed ambivalence over whether the colony should join the more southern colonies in their defiance of Britain, and rebellion flared at the Battle of Fort Cumberland (1776) and at the Siege of Saint John (1777). Throughout the war, American privateers devastated the maritime economy by capturing ships and looting almost every community outside of Halifax. These American raids alienated many sympathetic or neutral Nova Scotians into supporting the British. By the end of the war Nova Scotia had outfitted a number of privateers to attack American shipping. British military forces based at Halifax succeeded in preventing American support for rebels in Nova Scotia and deterred any invasion of Nova Scotia. However the British navy failed to establish naval supremacy. While the British captured many American privateers in battles such as the Naval battle off Halifax (1782), many more continued attacks on shipping and settlements until the final months of the war. The Royal Navy struggled to maintain British supply lines, defending convoys from American and French attacks as in the fiercely fought convoy battle, the Naval battle off Cape Breton (1781).

After the Thirteen Colonies and their French allies forced the British forces to surrender (1781), approximately 33,000 Loyalists (the King's Loyal Americans, allowed to place "United Empire Loyalist" after their names) settled in Nova Scotia (14,000 of them in what became New Brunswick) on lands granted by the Crown as some compensation for their losses. (The British administration divided Nova Scotia and hived off Cape Breton and New Brunswick in 1784). The Loyalist exodus created new communities across Nova Scotia, including Shelburne, which briefly became one of the larger British settlements in North America, and infused Nova Scotia with additional capital and skills. There are also a number of Black loyalists buried in unmarked graves in the Old Burying Ground (Halifax, Nova Scotia).

However the migration also caused political tensions between Loyalist leaders and the leaders of the existing New England Planters settlement. The Loyalist influx also pushed Nova Scotia's 2000 Mi'kmaq People to the margins as Loyalist land grants encroached on ill-defined native lands. As part of the Loyalist migration, about 3,000 Black Loyalists arrived; they founded the largest free Black settlement in North America at Birchtown, near Shelburne. Many Nova Scotian communities were settled by British regiments that fought in the war.

During the War of 1812, Nova Scotia's contribution to the British war effort involved communities either purchasing or building various privateer ships to attack U.S. vessels. Perhaps the most dramatic moment in the war for Nova Scotia occurred when HMS "Shannon" escorted the captured American frigate USS "Chesapeake" into Halifax Harbour (1813). Many of the U.S. prisoners were kept at Deadman's Island, Halifax.

During this century, Nova Scotia became the first colony in British North America and in the British Empire to achieve responsible government in January–February 1848 and become self-governing through the efforts of Joseph Howe. Nova Scotia had established representative government in 1758, an achievement later commemorated by the erection of the Dingle Tower in 1908.

Nova Scotians fought in the Crimean War of 1853–1856. The Welsford-Parker Monument in Halifax is the second-oldest war monument in Canada (1860) and the only Crimean War monument in North America. It commemorates the 1854–55 Siege of Sevastopol. 

Thousands of Nova Scotians fought in the American Civil War (1861–1865), primarily on behalf of the North. The British Empire (including Nova Scotia) in the conflict. As a result, Britain (and Nova Scotia) continued to trade with both the South and the North. Nova Scotia's economy boomed during the Civil War.

Soon after the American Civil War, Pro-Canadian Confederation premier Charles Tupper led Nova Scotia into the Canadian Confederation on 1 July 1867, along with New Brunswick and the Province of Canada. The Anti-Confederation Party was led by Joseph Howe. Almost three months later, in the election of 18 September 1867, the Anti-Confederation Party won 18 out of 19 federal seats, and 36 out of 38 seats in the provincial legislature.

Throughout the 19th century, numerous businesses developed in Nova Scotia became of pan-Canadian and international importance: the Starr Manufacturing Company (first skate-manufacturer in Canada), the Bank of Nova Scotia, Cunard Line, Alexander Keith's Brewery, Morse's Tea Company (first tea company in Canada), among others. 

Nova Scotia became a world leader in both building and owning wooden sailing ships in the second half of the 19th century. Nova Scotia produced internationally recognized shipbuilders Donald McKay and William Dawson Lawrence. The fame Nova Scotia achieved from sailors was assured when Joshua Slocum became the first man to sail single-handedly around the world (1895). International attention continued into the following century with the many racing victories of the "Bluenose" schooner. Nova Scotia was also the birthplace and home of Samuel Cunard, a British shipping magnate (born at Halifax, Nova Scotia) who founded the Cunard Line.

In 1937, Everett Farmer was the last person hanged (for murder) in Nova Scotia.

According to the 2006 Canadian census the largest ethnic group in Nova Scotia is Scottish (31.9%), followed by English (31.8%), Irish (21.6%), French (17.9%), German (11.3%), Aboriginal origin (5.3%), Dutch (4.1%), Black Canadians (2.8%), Welsh (1.9%) Italian (1.5%), and Scandinavian (1.4%). 40.9% of respondents identified their ethnicity as "Canadian".

The 2011 Canadian census showed a population of 921,727. Of the 904,285 singular responses to the census question concerning mother tongue the most commonly reported languages were:
Figures shown are for the number of single-language responses and the percentage of total single-language responses.

Nova Scotia is home to the largest Scottish Gaelic-speaking community outside of Scotland, with a small number of native speakers in Pictou County, Antigonish County, and Cape Breton Island, and the language is taught in a number of secondary schools throughout the province. In 2018 the government launched a new Gaelic vehicle license plate to raise awareness of the language and help fund Gaelic language and culture initiatives. They estimated that there were 2,000 Gaelic speakers in the province.

In 1871, the largest religious denominations were Protestant with 103,500 (27%); Roman Catholic with 102,000 (26%); Baptist with 73,295 (19%); Anglican with 55,124 (14%); Methodist with 40,748 (10%), Lutheran with 4,958 (1.3%); and Congregationalist with 2,538 (0.65%).

According to the 2001 census, the largest denominations by number of adherents were the Roman Catholic Church with 327,940 (37%); the United Church of Canada with 142,520 (17%); and the Anglican Church of Canada with 120,315 (13%).There are also 8,505 (0.9%) Muslims and 1,850 Hindus (0.2%)according to 2011 census.

Nova Scotia's per capita GDP in 2016 was $44,924, significantly lower than the national average per capita GDP of $57,574. GDP growth has lagged behind the rest of the country for at least the past decade. As of 2017, the median family income in Nova Scotia was $85,970, below the national average of $92,990; in Halifax the figure rises to $98,870.

The province is the world's largest exporter of Christmas trees, lobster, gypsum, and wild berries. Its export value of fish exceeds $1 billion, and fish products are received by 90 countries around the world. Nevertheless, the province's imports far exceed its exports. While these numbers were roughly equal from 1992 until 2004, since that time the trade deficit has ballooned. In 2012, exports from Nova Scotia were 12.1% of provincial GDP, while imports were 22.6%.

Nova Scotia's traditionally resource-based economy has diversified in recent decades. The rise of Nova Scotia as a viable jurisdiction in North America, historically, was driven by the ready availability of natural resources, especially the fish stocks off the Scotian Shelf. The fishery was a pillar of the economy since its development as part of New France in the 17th century; however, the fishery suffered a sharp decline due to overfishing in the late 20th century. The collapse of the cod stocks and the closure of this sector resulted in a loss of approximately 20,000 jobs in 1992.

Other sectors in the province were also hit hard, particularly during the last two decades: coal mining in Cape Breton and northern mainland Nova Scotia has virtually ceased, and a large steel mill in Sydney closed during the 1990s. More recently, the high value of the Canadian dollar relative to the US dollar has hurt the forestry industry, leading to the shutdown of a long-running pulp and paper mill near Liverpool. Mining, especially of gypsum and salt and to a lesser extent silica, peat and barite, is also a significant sector. Since 1991, offshore oil and gas has become an important part of the economy, although production and revenue are now declining. However, agriculture remains an important sector in the province, particularly in the Annapolis Valley.

Nova Scotia's defence and aerospace sector generates approximately $500 million in revenues and contributes about $1.5 billion to the provincial economy each year. To date, 40% of Canada's military assets reside in Nova Scotia. Nova Scotia has the fourth-largest film industry in Canada hosting over 100 productions yearly, more than half of which are the products of international film and television producers. In 2015, the government of Nova Scotia eliminated tax credits to film production in the province, jeopardizing the industry given most other jurisdictions continue to offer such credits. The province also boasts a rapidly developing Information & Communication Technology (ICT) sector which consists of over 500 companies, and employs roughly 15,000 people. In 2006, the manufacturing sector brought in over $2.6 billion in chained GDP, the largest output of any industrial sector in Nova Scotia. Michelin remains by far the largest single employer in this sector, operating three production plants in the province.

The Nova Scotia tourism industry includes more than 6,500 direct businesses, supporting nearly 40,000 jobs. Cruise ships pay regular visits to the province. In 2010, the Port of Halifax received 261,000 passengers and Sydney 69,000. This industry contributes approximately $1.3 billion annually to the economy. A 2008 Nova Scotia tourism campaign included advertising a fictional mobile phone called Pomegranate and establishing website, which after reading about "new phone" redirected to tourism info about region.

Nova Scotia's tourism industry showcases Nova Scotia's culture, scenery and coastline. Nova Scotia has many museums reflecting its ethnic heritage, including the Glooscap Heritage Centre, Grand-Pré National Historic Site, Hector Heritage Quay and the Black Cultural Centre for Nova Scotia. Other museums tell the story of its working history, such as the Cape Breton Miners' Museum, and the Maritime Museum of the Atlantic.

Nova Scotia is home to several internationally renowned musicians and there are visitor centres in the home towns of Hank Snow, Rita MacNeil, and Anne Murray Centre. There are also numerous music and cultural festivals such as the Stan Rogers Folk Festival, Celtic Colours, the Nova Scotia Gaelic Mod, Royal Nova Scotia International Tattoo, the Atlantic Film Festival and the Atlantic Fringe Festival.

The province has 87 National Historic Sites of Canada, including the Habitation at Port-Royal, the Fortress of Louisbourg and Citadel Hill (Fort George) in Halifax. Nova Scotia has two national parks, Kejimkujik and Cape Breton Highlands, and many other protected areas. The Bay of Fundy has the highest tidal range in the world, and the iconic Peggys Cove is internationally recognized and receives 600,000-plus visitors a year. Old Town Lunenburg is a port town on the South Shore that was declared a UNESCO World Heritage Site.

Acadian Skies and Mi'kmaq Lands is a starlight reserve in southwestern Nova Scotia. It is the first certified UNESCO-Starlight Tourist Destination. Starlight tourist destinations are locations that offer conditions for observations of stars which are protected from light pollution.

Nova Scotia is ordered by a parliamentary government within the construct of constitutional monarchy; the monarchy in Nova Scotia is the foundation of the executive, legislative, and judicial branches. The sovereign is Queen Elizabeth II, who also serves as head of state of 15 other Commonwealth countries, each of Canada's nine other provinces, and the Canadian federal realm, and resides predominantly in the United Kingdom. As such, the Queen's representative, the Lieutenant Governor of Nova Scotia (at present Arthur Joseph LeBlanc), carries out most of the royal duties in Nova Scotia.

The direct participation of the royal and viceroyal figures in any of these areas of governance is limited, though; in practice, their use of the executive powers is directed by the Executive Council, a committee of ministers of the Crown responsible to the unicameral, elected House of Assembly and chosen and headed by the Premier of Nova Scotia (presently Stephen McNeil), the head of government. To ensure the stability of government, the lieutenant governor will usually appoint as premier the person who is the current leader of the political party that can obtain the confidence of a plurality in the House of Assembly. The leader of the party with the second-most seats usually becomes the Leader of Her Majesty's Loyal Opposition (presently Tim Houston) and is part of an adversarial parliamentary system intended to keep the government in check.

Each of the 51 Members of the Legislative Assembly in the House of Assembly is elected by single member plurality in an electoral district or riding. General elections must be called by the lieutenant governor on the advice of the premier, or may be triggered by the government losing a confidence vote in the House. There are three dominant political parties in Nova Scotia: the Liberal Party, the New Democratic Party, and the Progressive Conservative Party. The other two registered parties are the Green Party of Nova Scotia and the Atlantica Party, neither of which has a seat in the House of Assembly.

The province's revenue comes mainly from the taxation of personal and corporate income, although taxes on tobacco and alcohol, its stake in the Atlantic Lottery Corporation, and oil and gas royalties are also significant. In 2006–07, the province passed a budget of $6.9 billion, with a projected $72 million surplus. Federal equalization payments account for $1.385 billion, or 20.07% of the provincial revenue. The province participates in the HST, a blended sales tax collected by the federal government using the GST tax system.

Nova Scotia no longer has any incorporated cities; they were amalgamated into Regional Municipalities in 1996.

The cuisine of Nova Scotia is typically Canadian with an emphasis on local seafood. One endemic dish (in the sense of "peculiar to" and "originating from") is the Halifax donair, a distant variant of the doner kebab prepared using thinly sliced beef meatloaf and a sweet condensed milk sauce. As well, hodge podge, a creamy soup of fresh baby vegetables, is native to Nova Scotia.

The province is also known for a dessert called blueberry fungy or blueberry grunt.

There are a number of festivals and cultural events that are recurring in Nova Scotia, or notable in its history. The following is an incomplete list of festivals and other cultural gatherings in the province:
Nova Scotia has produced numerous film actors. Academy Award nominee Ellen Page ("Juno", "Inception") was born in Halifax, Nova Scotia; five-time Academy Award nominee Arthur Kennedy ("Lawrence of Arabia", "High Sierra") called Nova Scotia his home; and two time Golden Globe winner Donald Sutherland ("MASH", "Ordinary People") spent most of his youth in the province. Other actors include John Paul Tremblay, Robb Wells, Mike Smith and John Dunsworth of "Trailer Park Boys" and actress Joanne Kelly of "Warehouse 13".

Nova Scotia has also produced numerous film directors such as Thom Fitzgerald ("The Hanging Garden"), Daniel Petrie ("Resurrection"—Academy Award nominee) and Acadian film director Phil Comeau's multiple award-winning local story ("Le secret de Jérôme").

Nova Scotian stories are the subject of numerous feature films: "Margaret's Museum" (starring Helena Bonham Carter); "The Bay Boy" (directed by Daniel Petrie and starring Kiefer Sutherland); "New Waterford Girl"; "The Story of Adele H." (the story of unrequited love of Adèle Hugo); and two films of "Evangeline" (one starring Miriam Cooper and another starring Dolores del Río).

There is a significant film industry in Nova Scotia. Feature filmmaking began in Canada with "Evangeline" (1913), made by Canadian Bioscope Company in Halifax, which released six films before it closed. The film has since been lost. Some of the award-winning feature films made in the province are "Titanic" (starring Leonardo DiCaprio and Kate Winslet); "The Shipping News" (starring Kevin Spacey and Julianne Moore); "" (starring Harrison Ford and Liam Neeson); "Amelia" (starring Hilary Swank, Richard Gere and Ewan McGregor) and "The Lighthouse" (starring Robert Pattinson and William Dafoe).

Nova Scotia has also produced numerous television series: "This Hour Has 22 Minutes", "Don Messer's Jubilee", "Black Harbour", "Haven", "Trailer Park Boys", "Mr. D", "Call Me Fitz", and "Theodore Tugboat". The "Jesse Stone" film series on CBS starring Tom Selleck is also routinely produced in the province.

Nova Scotia has long been a centre for artistic and cultural excellence. The capital, Halifax, hosts institutions such as Nova Scotia College of Art and Design University, Art Gallery of Nova Scotia, Neptune Theatre, Dalhousie Arts Centre, Two Planks and a Passion Theatre, and the Ship's Company Theatre. The province is home to avant-garde visual art and traditional crafting, writing and publishing and a film industry.

Much of the historic public art sculptures in the province were made by New York sculptor J. Massey Rhind as well as Canadian sculptors Hamilton MacCarthy, George Hill, Emanuel Hahn and Louis-Philippe Hébert. Some of this public art was also created by Nova Scotian John Wilson. Nova Scotian George Lang was a stone sculptor who also built many landmark buildings in the province, including the Welsford-Parker Monument. Two valuable sculptures/ monuments in the province are in St. Paul's Church (Halifax): one by John Gibson (for Richard John Uniacke, Jr.) and another monument by Sir Francis Leggatt Chantrey (for Amelia Ann Smyth). Both Gibson and Chantry were famous British sculptors during the Victorian era and have numerou sculptures in the Tate, Museum of Fine Arts, Boston and Westminster Abbey.

Some of the province's greatest painters were Maud Lewis, William Valentine, Maria Morris, Jack L. Gray, Mabel Killiam Day, Ernest Lawson, Frances Bannerman, Alex Colville, Tom Forrestall and ship portrait artist John O'Brien. Some of most notable artists whose works have been acquired by Nova Scotia are British artist Joshua Reynolds (collection of Art Gallery of Nova Scotia); William Gush and William J. Weaver (both have works in Province House); Robert Field (Government House), as well as leading American artists Benjamin West (self portrait in The Halifax Club, portrait of chief justice in Nova Scotia Supreme Court), John Singleton Copley, Robert Feke, and Robert Field (the latter three have works in the Uniacke Estate). Two famous Nova Scotian photographers are Wallace R. MacAskill and Sherman Hines. Three of the most accomplished illustrators were George Wylie Hutchinson, Bob Chambers (cartoonist) and Donald A. Mackay.

There are numerous Nova Scotian authors who have achieved international fame: Thomas Chandler Haliburton ("The Clockmaker"), Alistair MacLeod ("No Great Mischief"), Evelyn Richardson "(We Keep A Light)", Margaret Marshall Saunders "(Beautiful Joe)," Laurence B. Dakin "(Marco Polo)," and Joshua Slocum "(Sailing Alone Around the World)." Other authors include Johanna Skibsrud "(The Sentimentalists)," Alden Nowlan "(Bread, Wine and Salt)," George Elliott Clarke "(Execution Poems)," Lesley Choyce "(Nova Scotia: Shaped by the Sea)," Thomas Raddall "(Halifax: Warden of the North)," Donna Morrissey "(Kit's Law)," and Frank Parker Day "(Rockbound)."

Nova Scotia has also been the subject of numerous literary books. Some of the international best-sellers are: "Last Man Out: The Story of the Springhill Mining Disaster" (by Melissa Fay Greene) ; "Curse of the Narrows: The Halifax Explosion 1917" (by Laura MacDonald); "In the Village" (short story by Pulitzer Prize–winning author Elizabeth Bishop); and National Book Critics Circle Award winner "Rough Crossings" (by Simon Schama). Other authors who have written novels about Nova Scotian stories include: Linden MacIntyre ("The Bishop's Man"); Hugh MacLennan ("Barometer Rising"); Rebecca McNutt ("Mandy and Alecto"); Ernest Buckler ("The Valley and the Mountain"); Archibald MacMechan ("Red Snow on Grand Pré"), Henry Wadsworth Longfellow (long poem "Evangeline"); Lawrence Hill ("The Book of Negroes") and John Mack Faragher ("Great and Nobel Scheme").

Nova Scotia is home to Symphony Nova Scotia, a symphony orchestra based in Halifax. The province has produced more than its fair share of famous musicians, including Grammy Award winners Denny Doherty (from The Mamas & the Papas), Anne Murray, and Sarah McLachlan, country singers Hank Snow, George Canyon, and Drake Jensen, jazz vocalist Holly Cole, classical performers Portia White and Barbara Hannigan, multi Juno Award nominated rapper Classified, and such diverse artists as Rita MacNeil, Matt Mays, Sloan, Feist, Todd Fancey, The Rankin Family, Susan Crowe, Buck 65, Joel Plaskett, and the bands April Wine and Grand Dérangement

There are numerous songs written about Nova Scotia: The Ballad of Springhill (written by Peggy Seeger and performed by Irish folk singer Luke Kelly, a member of The Dubliners); several songs by Stan Rogers including Bluenose, Watching The Apples Grow, The Jeannie C (mentions Little Dover, NS), Barrett's Privateers, Giant, and The Rawdon Hills; Farewell to Nova Scotia (traditional); Blue Nose (Stompin' Tom Connors); She's Called Nova Scotia (by Rita MacNeil); Cape Breton (by David Myles); Acadian Driftwood (by Robbie Robertson); Acadie (by Daniel Lanois); Song For The Mira (by Allister MacGillivray) and My Nova Scotia Home (by Hank Snow).

Nova Scotia has produced many significant songwriters, such as Grammy Award winning Gordie Sampson, who has written songs for Carrie Underwood ("Jesus, Take the Wheel", "Just a Dream", "Get Out of This Town"), Martina McBride ("If I Had Your Name", "You're Not Leavin Me"), LeAnn Rimes ("Long Night", "Save Myself"), and George Canyon ("My Name"). Many of Hank Snow's songs went on to be recorded by the likes of The Rolling Stones, Elvis Presley, and Johnny Cash. Cape Bretoners Allister MacGillivray and Leon Dubinsky have both written songs which, by being covered by so many popular artists, and by entering the repertoire of so many choirs around the world, have become iconic representations of Nova Scotian style, values and ethos. Dubinsky's pop ballad "We Rise Again" might be called the unofficial anthem of Cape Breton.

Music producer Brian Ahern is a Nova Scotian. He got his start by being music director for CBC television's Singalong Jubilee. He later produced 12 albums for Anne Murray ("Snowbird", "Danny's Song" and "You Won't See Me"); 11 albums for Emmylou Harris (whom he married at his home in Halifax on 9 January 1977). He also produced discs for Johnny Cash, George Jones, Roy Orbison, Glen Campbell, Don Williams, Jesse Winchester and Linda Ronstadt.

Sport is an important part of Nova Scotia culture. There are numerous semi pro, university and amateur sports teams, for example, The Halifax Mooseheads, 2013 Canadian Hockey League Memorial Cup Champions, and the Cape Breton Screaming Eagles, both of the Quebec Major Junior Hockey League. The Halifax Hurricanes of the National Basketball League of Canada is another team that calls Nova Scotia home, and were 2016 league champions. Professional soccer came to the province in 2019 in the form of Canadian Premier League club HFX Wanderers FC.

The Nova Scotia Open is a professional golf tournament on the Web.com Tour since 2014.

The province has also produced numerous athletes such as Sidney Crosby (ice hockey), Nathan Mackinnon (ice hockey), Brad Marchand (ice hockey), Colleen Jones (curling), Al MacInnis (ice hockey), TJ Grant (mixed martial arts), Rocky Johnson (wrestling, and father of Dwayne "The Rock" Johnson), George Dixon (boxing) and Kirk Johnson (boxing). The achievements of Nova Scotian athletes are presented at the Nova Scotia Sport Hall of Fame.

The Minister of Education is responsible for the administration and delivery of education, as defined by the Education Act and other acts relating to colleges, universities and private schools. The powers of the Minister and the Department of Education are defined by the Ministerial regulations and constrained by the Governor-In-Council regulations.

All children until the age of 16 are legally required to attend school or the parent needs to perform home schooling. Nova Scotia's education system is split up into eight different regions including; Tri-County (22 schools), Annapolis Valley (42 schools), South Shore (25 schools), Chignecto-Central (67 schools), Halifax (67 schools), Strait (20 schools) and Cape Breton-Victoria Regional Centre for Education (39 schools).

Nova Scotia has more than 450 public schools for children. The public system offers primary to Grade 12. There are also private schools in the province. Public education is administered by seven regional school boards, responsible primarily for English instruction and French immersion, and also province-wide by the Conseil Scolaire Acadien Provincial, which administers French instruction to students for whom the primary language is French.

The Nova Scotia Community College system has 13 campuses around the province. The college with its focus on training and education, was established in 1988 by amalgamating the province's former vocational schools. In addition to the provincial community college system, there are also more than 90 registered private commercial colleges in Nova Scotia.

Ten universities are also situated in Nova Scotia, including Dalhousie University, University of King's College, Saint Mary's University, Mount Saint Vincent University, NSCAD University, Acadia University, Université Sainte-Anne, Saint Francis Xavier University, Cape Breton University and the Atlantic School of Theology.




</doc>
<doc id="21186" url="https://en.wikipedia.org/wiki?curid=21186" title="Northwest Territories">
Northwest Territories

The Northwest Territories (abbr. NT or NWT; , abbr. "TNO"; ; ; ) is a federal territory of Canada. At a land area of approximately and a 2016 census population of 41,786, it is the second-largest and the most populous of the three territories in Northern Canada. Its estimated population as of 2019 is 44,895. Yellowknife became the territorial capital in 1967, following recommendations by the Carrothers Commission.

The Northwest Territories, a portion of the old North-Western Territory, entered the Canadian Confederation on July 15, 1870. Since then, the territory has been divided several times to create new provinces and territories or enlarge existing ones. Its current borders date from April 1, 1999, when the territory was divided to create Nunavut to the east, via the "Nunavut Act" and the Nunavut Land Claims Agreement. While Nunavut is mostly Arctic tundra, the Northwest Territories has a slightly warmer climate and is both boreal forest (taiga) and tundra, and its most northern regions form part of the Canadian Arctic Archipelago.

The Northwest Territories is bordered by Canada's two other territories, Nunavut to the east and Yukon to the west, and by the provinces of British Columbia, Alberta, and Saskatchewan to the south, and may touch Manitoba at a quadripoint to the southeast.

The name is descriptive, adopted by the British government during the colonial era to indicate where it lay in relation to Rupert's Land. It is shortened from North-Western Territory ("see" History). In Inuktitut, the Northwest Territories are referred to as (), "beautiful land." The northernmost region of the territory is home to Inuvialuit, part of Inuit Nunangat called Nunangit, while the southern portion is called (an Athabaskan language word meaning "our land"). is the vast Dene country, stretching from central Alaska to Hudson Bay, within which lie the homelands of the numerous Dene nations.

There was some discussion of changing the name of the Northwest Territories after the splitting off of Nunavut, possibly to a term from an Indigenous language. One proposal was "Denendeh," as advocated by the former premier Stephen Kakfwi, among others. One of the most popular proposals for a new name—to name the territory "Bob"—began as a prank, but for a while it was at or near the top in the public-opinion polls.

In the end, a poll conducted prior to division showed that strong support remained to keep the name "Northwest Territories." This name arguably became more appropriate following division than it had been when the territories extended far into Canada's north-central and northeastern areas.

Located in northern Canada, the territory borders Canada's two other territories, Yukon to the west and Nunavut to the east, as well as three provinces: British Columbia to the southwest, and Alberta and Saskatchewan to the south. It possibly meets Manitoba at a quadripoint to the extreme southeast, though surveys have not been completed. It has a land area of .

Geographical features include Great Bear Lake, the largest lake entirely within Canada, and Great Slave Lake, the deepest body of water in North America at , as well as the Mackenzie River and the canyons of the Nahanni National Park Reserve, a national park and UNESCO World Heritage Site. Territorial islands in the Canadian Arctic Archipelago include Banks Island, Borden Island, Prince Patrick Island, and parts of Victoria Island and Melville Island. Its highest point is Mount Nirvana near the border with Yukon at an elevation of .

The Northwest Territories extends for more than and has a large climate variant from south to north. The southern part of the territory (most of the mainland portion) has a subarctic climate, while the islands and northern coast have a polar climate.

Summers in the north are short and cool, daytime highs of 14–17 degrees Celsius (57–63 °F), and lows of 1–5 degrees Celsius (34–41 °F). Winters are long and harsh, with daytime highs , lows , and the coldest nights typically reaching each year.

Extremes are common with summer highs in the south reaching and lows reaching below . In winter in the south, it is not uncommon for the temperatures to reach , but they can also reach the low teens during the day. In the north, temperatures can reach highs of , and lows into the low negatives. In winter in the north it is not uncommon for the temperatures to reach but they can also reach single digits during the day.

Thunderstorms are not rare in the south. In the north they are very rare, but do occur. Tornadoes are extremely rare but have happened with the most notable one happening just outside Yellowknife that destroyed a communications tower. The Territory has a fairly dry climate due to the mountains in the west.

About half of the territory is above the tree line. There are not many trees in most of the eastern areas of the territory, or in the north islands.

Prior to the arrival of Europeans, a number of First Nations and Inuit nations occupied the area that became the Northwest Territories. Inuit nations include the Caribou, Central, and Copper nations. First Nations groups include the Beaver, Chipewyan, Dogrib, Nahanni, Sekani, Slavey, and Yellowknives.

In 1670, the Hudson's Bay Company (HBC) was formed from a royal charter, and was granted a commercial monopoly over Rupert's Land. Present day Northwest Territories laid northwest of Rupert's Land, known as the North-Western Territory. Although not formally part of Rupert's Land, the HBC made regular use of the region as a part of its trading area. The Treaty of Utrecht saw the British became the only European power with practical access to the North-Western Territory, with the French surrendering its claim to the Hudson Bay coast.

Europeans have visited the region for the purposes of fur trading, and exploration for new trade routes, including the Northwest Passage. Arctic expeditions launched in the 19th century include the Coppermine expedition.

In 1867, first Canadian residential school opened in the region in Fort Resolution. The opening of the school was followed by several others in regions across the territory, thus contributing to it reaching the highest percentage of students in residential schools compared to other area in Canada.

The present-day territory came under the authority of the Government of Canada in July 1870, after the Hudson's Bay Company transferred Rupert's Land and the North-Western Territory to the British Crown, which subsequently transferred them to Canada, giving it the name the North-west Territories. This immense region comprised all of today's Canada except British Columbia, early form of Manitoba (a small square area around Winnipeg), early forms of present-day Ontario and Quebec (the coast of the Great Lakes, the Saint Lawrence River valley and the southern third of modern Quebec), the Maritimes (Nova Scotia, Prince Edward Island and New Brunswick), Newfoundland, the Labrador coast, and the Arctic Islands (except the southern half of Baffin Island).

After the 1870 transfer, some of the North-West Territories was whittled away. The province of Manitoba was enlarged in 1881 to a rectangular region composing the modern province's south. By the time British Columbia joined Confederation on July 20, 1871, it had already (1866) been granted the portion of North-Western Territory south of 60 degrees north and west of 120 degrees west, an area that comprised most of the Stickeen Territories.

In the meantime, the Province of Ontario was enlarged northwestward in 1882. Quebec was also extended northwards in 1898. Yukon was made a separate territory that year, due to the Klondike Gold Rush, to free the North-west Territories government in Regina from the burden of addressing the problems caused by the sudden boom of population and economic activity, and the influx of non-Canadians. The provinces of Alberta and Saskatchewan were created in 1905. In 1906, the Parliament of Canada renamed the "North-West Territories" as the "Northwest Territories", dropping all hyphenated forms of it.

Manitoba, Ontario and Quebec acquired the last addition to their modern landmass from the Northwest Territories in 1912. This left only the districts of Mackenzie, Franklin (which absorbed the remnants of Ungava in 1920) and Keewatin within what was then given the name Northwest Territories. In 1925, the boundaries of the Northwest Territories were extended all the way to the North Pole on the sector principle, vastly expanding its territory onto the northern ice cap. Between 1925 and 1999, the Northwest Territories covered a land area of —larger than India.

On April 1, 1999, a separate Nunavut territory was formed from the eastern Northwest Territories to represent the Inuit people.

The NWT is one of two jurisdictions in Canada – Nunavut being the other – where Aboriginal peoples are in the majority, constituting 50.4% of the population.

According to the 2016 Canadian census, the 10 major ethnic groups were:

Population of the Northwest Territories since 1871

French was made an official language in 1877 by the territorial government. After a lengthy and bitter debate resulting from a speech from the throne in 1888 by Lieutenant Governor Joseph Royal, the members of the day voted on more than one occasion to nullify that and make English the only language used in the assembly. After some conflict with the Confederation Government in Ottawa, and a decisive vote on January 19, 1892, the assembly members voted for an English-only territory.

Currently, the Northwest Territories' "Official Languages Act" recognizes the following eleven official languages:
NWT residents have a right to use any of the above languages in a territorial court, and in the debates and proceedings of the legislature. However, the laws are legally binding only in their French and English versions, and the NWT government only publishes laws and other documents in the territory's other official languages when the legislature asks it to. Furthermore, access to services in any language is limited to institutions and circumstances where there is a significant demand for that language or where it is reasonable to expect it given the nature of the services requested. In practical terms, English language services are universally available, and there is no guarantee that other languages, including French, will be used by any particular government service, except for the courts.

The 2016 census returns showed a population of 41,786. Of the 40,565 singular responses to the census question regarding each inhabitant's "mother tongue", the most reported languages were the following (italics indicate an official language of the NWT):
There were also 630 responses of both English and a "non-official language"; 35 of both French and a "non-official language"; 145 of both English and French, and about 400 people who either did not respond to the question, or reported multiple non-official languages, or else gave some other unenumerable response. (Figures shown are for the number of single language responses and the percentage of total single-language responses.)

The largest denominations by number of adherents according to the 2001 census were Roman Catholic with 16,940 (46.7%); the Anglican Church of Canada with 5,510 (14.9%); and the United Church of Canada with 2,230 (6.0%), while a total of 6,465 (17.4%) people stated no religion.

As of 2014, there are 33 official communities in the NWT. These range in size from Yellowknife with a population of 19,569 to Kakisa with 36 people. Governance of each community differs, some are run under various types of First Nations control, while others are designated as a city, town, village or hamlet, but most communities are municipal corporations. Yellowknife is the largest community and has the largest number of Aboriginal peoples, 4,520 (23.4%) people. However, Behchokǫ̀, with a population of 1,874, is the largest First Nations community, 1,696 (90.9%), and Inuvik with 3,243 people is the largest Inuvialuit community, 1,315 (40.5%). There is one Indian reserve in the NWT, Hay River Reserve, located on the south shore of the Hay River.

The Gross Domestic Product of the Northwest Territories was C$4.856 billion in 2017.The Northwest Territories has the highest per capita GDP of all provinces or territories in Canada, C$76,000 in 2009. 

The NWT's geological resources include gold, diamonds, natural gas and petroleum. British Petroleum (BP) is the only oil company currently producing oil in the Territory. NWT diamonds are promoted as an alternative to purchasing blood diamonds. Two of the biggest mineral resource companies in the world, BHP Billiton and Rio Tinto mine many of their diamonds from the NWT. In 2010, NWT accounted for 28.5% of Rio Tinto's total diamond production (3.9 million carats, 17% more than in 2009, from the Diavik Diamond Mine) and 100% of BHP's (3.05 million carats from the EKATI mine).

During the winter, many international visitors go to Yellowknife to watch the auroras. Five areas managed by Parks Canada are situated within the territory. Aulavik National Park and Tuktut Nogait National Park are in the northern part of Northwest Territories. Portions of Wood Buffalo National Park are located within the Northwest Territories, although most of it is located in neighbouring Alberta. Parks Canada also manages two park reserves, Nááts'ihch'oh National Park Reserve, and Nahanni National Park Reserve.

As a territory, the NWT has fewer rights than the provinces. During his term, Premier Kakfwi pushed to have the federal government accord more rights to the territory, including having a greater share of the returns from the territory's natural resources go to the territory. Devolution of powers to the territory was an issue in the 20th general election in 2003, and has been ever since the territory began electing members in 1881.

The Commissioner of the NWT is the chief executive and is appointed by the Governor-in-Council of Canada on the recommendation of the federal Minister of Aboriginal Affairs and Northern Development. The position used to be more administrative and governmental, but with the devolution of more powers to the elected assembly since 1967, the position has become symbolic. The Commissioner had full governmental powers until 1980 when the territories were given greater self-government. The Legislative Assembly then began electing a cabinet and "Government Leader", later known as the Premier. Since 1985 the Commissioner no longer chairs meetings of the Executive Council (or cabinet), and the federal government has instructed commissioners to behave like a provincial Lieutenant Governor. Unlike Lieutenant Governors, the Commissioner of the Northwest Territories is not a formal representative of the Queen of Canada.

Unlike provincial governments and the government of Yukon, the government of the Northwest Territories does not have political parties, except for the period between 1898 and 1905. It is a consensus government called the Legislative Assembly. This group is composed of one member elected from each of the nineteen constituencies. After each general election, the new Assembly elects the Premier and the Speaker by secret ballot. Seven MLAs are also chosen as cabinet ministers, with the remainder forming the opposition.

The membership of the current Legislative Assembly was set by the 2019 Northwest Territories general election on October 1, 2019. Caroline Cochrane was selected as the new Premier on October 24, 2019.

The member of Parliament for the Northwest Territories is Michael McLeod (Liberal Party). The Commissioner of the Northwest Territories is Margaret Thom.

In the Parliament of Canada, the NWT comprises a single Senate division and a single House of Commons electoral district, titled Northwest Territories ("Western Arctic" until 2014).

The Northwest Territories is divided into five administrative regions (with regional seat):

The Government of Northwest Territories comprises the following departments:

Aboriginal issues in the Northwest Territories include the fate of the Dene who, in the 1940s, were employed to carry radioactive uranium ore from the mines on Great Bear Lake. Of the thirty plus miners who worked at the Port Radium site, at least fourteen have died due to various forms of cancer. A study was done in the community of Deline, called "A Village of Widows" by Cindy Kenny-Gilday, which indicated that the number of people involved were too small to be able to confirm or deny a link.

There has been racial tension based on a history of violent conflict between the Dene and the Inuit, who have now taken recent steps towards reconciliation.

Land claims in the NWT began with the Inuvialuit Final Agreement, signed on June 5, 1984. It was the first Land Claim signed in the Territory, and the second in Canada. It culminated with the creation of the Inuit homeland of Nunavut, the result of the Nunavut Land Claims Agreement, the largest land claim in Canadian history.

Another land claims agreement with the Tłı̨chǫ people created a region within the NWT called Tli Cho, between Great Bear and Great Slave Lakes, which gives the Tłı̨chǫ their own legislative bodies, taxes, resource royalties, and other affairs, though the NWT still maintains control over such areas as health and education. This area includes two of Canada's three diamond mines, at Ekati and Diavik.

Among the festivals in the region are the Great Northern Arts Festival, the Snowking Winter Festival, Folk on the Rocks music festival in Yellowknife, and Rockin the Rocks.

Northwest Territories has eight numbered highways. The longest is the Mackenzie Highway, which stretches from the Alberta Highway 35's northern terminus in the south at the Alberta – Northwest Territories border at the 60th parallel to Wrigley, Northwest Territories in the north. Ice roads and winter roads are also prominent and provide road access in winter to towns and mines which would otherwise be fly-in locations. Yellowknife Highway branches out from Mackenzie Highway and connects it to Yellowknife. Dempster Highway is the continuation of Klondike Highway. It starts just west of Dawson City, Yukon, and continues east for over to Inuvik. As of 2017, the all-season Inuvik-Tuktoyaktuk Highway connects Inuvik to communities along the Arctic Ocean as an extension of the Dempster Highway. 

Yellowknife did not have an all-season road access to the rest of Canada's highway network until the completion of Deh Cho Bridge in 2012. Prior to that, traffic relied on ferry service in summer and ice road in winter to cross the Mackenzie River. This became a problem during spring and fall time when the ice was not thick enough to handle vehicle load but the ferry could not pass through the ice, which would require all goods from fuel to groceries to be airlifted during the transition period.

Yellowknife Transit is the public transportation agency in the city, and is the only transit system within the Northwest Territories.

Yellowknife Airport is the largest airport in the territory in terms of aircraft movements and passengers. It is the gateway airport to other destinations within the Northwest Territories. As the airport of the territory capital, it is part of the National Airports System. It is the hub of multiple regional airlines. Major airlines serving destinations within Northwest Territories include Buffalo Airways, Canadian North, First Air, North-Wright Airways.




</doc>
<doc id="21187" url="https://en.wikipedia.org/wiki?curid=21187" title="Nez Perce people">
Nez Perce people

The Nez Perce (; autonym: , meaning "the walking people" or "we, the people") are an Indigenous people of the Plateau who have lived on the Columbia River Plateau in the Pacific Northwest region for at least 11,500 years.

Members of the Sahaptin language group, the Niimíipuu were the dominant people of the Columbia Plateau for much of that time, especially after acquiring the horses that led them to breed the appaloosa horse in the 18th century.

Prior to "first contact" with Western civilization the Nimiipuu were economically and culturally influential in trade and war, interacting with other indigenous nations in a vast network from the western shores of Oregon and Washington, the high plains of Montana, and the northern Great Basin in southern Idaho and northern Nevada.

After first contact, the name "Nez Perce" was given to the Niimíipuu and the nearby Chinook people by French explorers and trappers. The name means "pierced nose", but only the Chinook used that form of decoration.

Today they are a federally recognized tribe, the Nez Perce Tribe of Idaho, and govern their Indian reservation in Idaho through a central government headquartered in Lapwai, Idaho known as the Nez Perce Tribal Executive Committee (NPTEC). They are one of five federally recognized tribes in the state of Idaho. Some still speak their traditional language, and the Tribe owns and operates two casinos along the Clearwater River in Idaho in Kamiah, Idaho and outside of Lewiston, Idaho, health clinics, a police force and court, community centers, salmon fisheries, radio station, and other things that promote economic and cultural self-determination.

Cut off from most of their horticultural sites throughout the Camas Prairie by an 1863 treaty, confinement to reservations in Idaho, Washington and Oklahoma Indian Territory after the Nez Perce War of 1877, and Dawes Act of 1887 land allotments (today some Nez Perce lease land to farmers or loggers, but the Nez Perce only own 12% of their own reservation), the Nez Perce remain as a distinct culture and political economic influence within and outside their reservation. Today, hatching, harvesting and eating salmon is an important cultural and economic strength of the Nez Perce through full ownership or co-management of various salmon fish hatcheries, such as the Kooskia National Fish Hatchery in Kooskia, Idaho or the Dworshak National Fish Hatchery in Orofino, Idaho.

Their name for themselves is "Nimíipuu" (pronounced ), meaning, "The People", in their language, part of the Sahaptin family.

"Nez Percé" is an exonym given by French Canadian fur traders who visited the area regularly in the late 18th century, meaning literally "pierced nose". English-speaking traders and settlers adopted the name in turn. Since the late 20th century, the Nez Perce identify most often as Niimíipuu in Sahaptin. The Lakota/ Dakota named them the "Watopala", or "Canoe" people, from "Watopa". However, after Nez Perce became a more common name, they changed it to "Watopahlute". This comes from "pahlute", nasal passage and is simply a play on words. If translated literally, it would come out as either ""Nasal Passage of the Canoe"" (Watopa-pahlute) or ""Nasal Passage of the Grass"" (Wato-pahlute). The tribe also uses the term "Nez Perce", as does the United States Government in its official dealings with them, and contemporary historians. Older historical ethnological works and documents use the French spelling of "Nez Percé", with the diacritic. The original French pronunciation is , with three syllables.

The interpreter of the Lewis and Clark Expedition mistakenly identified this people as the Nez Perce when the team encountered the tribe in 1805. Writing in 1889, anthropologist Alice Fletcher, who the U.S. government had sent to Idaho to allot the Nez Perce Reservation, explained the mistaken naming. She wrote,

In his journals, William Clark referred to the people as the Chopunnish , a transliteration of a Sahaptin term. According to D.E. Walker in 1998, writing for the Smithsonian, this term is an adaptation of the term "cú·pŉitpeľu" (the Nez Perce people). The term is formed from "cú·pŉit" (piercing with a pointed object) and "peľu" (people). By contrast, the "Nez Perce Language Dictionary" has a different analysis than did Walker for the term "cúpnitpelu". The prefix "cú"- means "in single file". This prefix, combined with the verb "-piní", "to come out (e.g. of forest, bushes, ice)". Finally, with the suffix of "-pelú", meaning "people or inhabitants of". Together, these three elements: "cú"- + -"piní" + "pelú" = "cúpnitpelu", or "the People Walking Single File Out of the Forest". Nez Perce oral tradition indicates the name "Cuupn'itpel'uu" meant "we walked out of the woods or walked out of the mountains" and referred to the time before the Nez Perce had horses.

The Nez Perce language, or Niimiipuutímt, is a Sahaptian language related to the several dialects of Sahaptin. The Sahaptian sub-family is one of the branches of the Plateau Penutian family, which in turn may be related to a larger Penutian grouping.

The Nez Perce territory at the time of Lewis and Clark (1804–1806) was approximately and covered parts of present-day Washington, Oregon, Montana, and Idaho, in an area surrounding the Snake (Weyikespe), Grande Ronde River, Salmon (Naco’x kuus) ("Chinook salmon Water") and the Clearwater (Koos-Kai-Kai) ("Clear Water") rivers. The tribal area extended from the Bitterroots in the east (the door to the Northwestern Plains of Montana) to the Blue Mountains in the west between latitudes 45°N and 47°N.

In 1800, the Nez Perce had more than 100 permanent villages, ranging from 50 to 600 individuals, depending on the season and social grouping. Archeologists have identified a total of about 300 related sites including camps and villages, mostly in the Salmon River Canyon. In 1805, the Nez Perce were the largest tribe on the Columbia River Plateau, with a population of about 6,000. By the beginning of the 20th century, the Nez Perce had declined to about 1,800 due to epidemics, conflicts with non-Indians, and other factors. A total of 3,499 Nez Perce were counted in the 2010 Census.

Like other Plateau tribes, the Nez Perce had seasonal villages and camps in order to take advantage of natural resources throughout the year. Their migration followed a recurring pattern from permanent winter villages through several temporary camps, nearly always returning to the same locations each year. The Nez Perce traveled via the Lolo Trail (Salish: Naptnišaqs - "Nez Perce Trail") (Khoo-say-ne-ise-kit) far east as the Plains (Khoo-sayn / Kuseyn) ("Buffalo country") of Montana to hunt buffalo (Qoq'a lx) and as far west as the Pacific Coast (’Eteyekuus) ("Big Water"). Before 1957 construction of The Dalles Dam, which flooded this area, Celilo Falls (Silayloo) was a favored location on the Columbia River (Xuyelp) ("The Great River") for salmon (lé'wliks)-fishing.

The Nez Perce had many allies and trading partners among neighboring peoples, but also enemies and ongoing antagonist tribes. To the north of them lived the Coeur d’Alene (Schitsu'umsh) (’Iskíicu’mix), Spokane (Sqeliz) (Heyéeynimuu), and further north the Kalispel (Ql̓ispé) (Qem’éespel’uu, both meaning "Camas People"), Colville (Páapspaloo) and Kootenay / Kootenai (Ktunaxa) (Kuuspel’úu), to the northwest lived the Palus (Pelúucpuu) and to the west the Cayuse (Lik-si-yu) (Weyíiletpuu - "Ryegrass People"), west bound there were found the Umatilla (Imatalamłáma) (Hiyówatalampoo), Walla Walla, Wasco (Wecq’úupuu) and Sk'in (Tike’éspel’uu) and northwest of the latter various Yakama bands (Lexéyuu), to the south lived the Snake Indians (various Northern Paiute (Numu) bands (Hey’ǘuxcpel’uu) in the southwest and Bannock (Nimi Pan a'kwati)-Northern Shoshone (Newe) bands (Tiwélqe) in the southeast), to the east lived the Lemhi Shoshone (Lémhaay), north of them the Bitterroot Salish / Flathead (Seliš) (Séelix), further east and northeast on the Northern Plains were the Crow (Apsáalooke) (’Isúuxe) and two powerful alliances - the Iron Confedery (Nehiyaw-Pwat) (named after the dominating Plains and Woods Cree (Paskwāwiyiniwak and Sakāwithiniwak) and Assiniboine (Nakoda) (Wihnen’íipel’uu), an alliance of northern plains Native American nations based around the fur trade, and later included the Stoney (Nakoda), Western Saulteaux / Plains Ojibwe (Bungi or Nakawē), and Métis) and the Blackfoot Confederacy (Niitsitapi or Siksikaitsitapi) (’Isq’óyxnix) (composed of three Blackfoot speaking peoples - the Piegan or Peigan (Piikáni), the Kainai or Bloods (Káínaa), and the Siksika or Blackfoot (Siksikáwa), later joined by the unrelated Sarcee (Tsuu T'ina) and (for a time) by Gros Ventre or Atsina (A'aninin)).


Because of large amount of inter-marriage between Nez Perce bands and neighboring tribes or bands to forge alliances and peace (often living in mixed bilingual villages together), the following bands were also counted to the Nez Perce (which today are viewed as being linguistically and culturally closely related, but separate ethnic groups):

The semi-sedentary Nez Percés were Hunter-gatherer without agriculture living in a society in which most or all food is obtained by foraging (collecting wild plants and roots and pursuing wild animals). They depended on hunting, fishing, and the gathering of wild roots and berries.

Nez Perce people historically depended on various Pacific salmon and Pacific trout for their food: Chinook salmon or ""nacoox"" (Oncorhynchus tschawytscha) were eaten the most, but other species such as Pacific lamprey (Entosphenus tridentatus or Lampetra tridentata), and chiselmouth. Other important fishes included the Sockeye salmon (Oncorhynchus nerka), Silver salmon or "ka'llay" (Oncorhynchus kisutch), Chum salmon or dog salmon or "ka'llay" (Oncorhynchus keta), Mountain whitefish or ""ci'mey"" (Prosopium williamsoni), White sturgeon (Acipenser transmontanus), White sucker or ""mu'quc"" (Catostomus commersonii), and varieties of trout - West Coast steelhead or ""heyey"" (Oncorhynchus mykiss), brook trout or ""pi'ckatyo"" (Salvelinus fontinalis), bull trout or ""i'slam"" (Salvelinus confluentus), and Cutthroat trout or ""wawa'lam"" (Oncorhynchus clarkii).

Prior to contact with Europeans, the Nez Perce's traditional hunting and fishing areas spanned from the Cascade Range in the west to the Bitterroot Mountains in the east.

Historically, in late May and early June, Nez Perce villagers crowded to communal fishing sites to trap eels, steelhead, and chinook salmon, or haul in fish with large dip nets. Fishing took place throughout the summer and fall, first on the lower streams and then on the higher tributaries, and catches also included salmon, sturgeon, whitefish, suckers, and varieties of trout. Most of the supplies for winter use came from a second run in the fall, when large numbers of Sockeye salmon, silver, and dog salmon appeared in the rivers.

Fishing is traditionally an important ceremonial and commercial activity for the Nez Perce tribe. Today Nez Perce fishers participate in tribal fisheries in the mainstream Columbia River between Bonneville and McNary dams. The Nez Perce also fish for spring and summer Chinook salmon and Rainbow trout/steelhead in the Snake River and its tributaries. The Nez Perce tribe runs the Nez Perce Tribal Hatchery on the Clearwater River, as well as several satellite hatchery programs. 
The first fishing of the season was accompanied by prescribed rituals and a ceremonial feast known as ""kooyit"". Thanksgiving was offered to the Creator and to the fish for having returned and given themselves to the people as food. In this way, it was hoped that the fish would return the next year.

Like salmon, plants contributed to traditional Nez Perce culture in both material and spiritual dimensions.

Aside from fish and game, Plant foods provided over half of the dietary calories, with winter survival depending largely on dried roots, especially Kouse, or ""qáamsit"" (when fresh) and ""qáaws"" (when peeled and dried) (Lomatium especially Lomatium cous), and Camas, or ""qém'es"" (Nez Perce: "sweet") (Camassia quamash), the first being roasted in pits, while the other was ground in mortars and molded into cakes for future use, both plants had been traditionally an important food and trade item. Women were primarily responsible for the gathering and preparing of these root crops. Camas bulbs were gathered in the region between the Salmon and Clearwater river drainages. Techniques for preparing and storing winter foods enabled people to survive times of colder winters with little or no fresh foods.

Favorite fruits dried for winter were serviceberries or ""kel"" (Amelanchier alnifolia or Saskatoon berry), black huckleberries or ""cemi'tk"" (Vaccinium membranaceum), red elderberries or ""mi'ttip"" (Sambucus racemosa var. melanocarpa), and chokecherries or ""ti'ms"" (Prunus virginiana var. melanocarpa). Nez Perce textiles were made primarily from dogbane or ""qeemu"" (Apocynum cannabinum or Indian hemp), tules or ""to'ko"" (Schoenoplectus acutus var. acutus), and western redcedar or ""tala'tat"" (Thuja plicata). The most important industrial woods were redcedar, ponderosa pine or ""la'qa"" (Pinus ponderosa), Douglas fir or ""pa'ps"" (Pseudotsuga menziesii), sandbar willow or ""tax's"" (Salix exigua), and hard woods such as Pacific yew or ""ta'mqay"" (Taxus brevifolia) and syringa or ""sise'qiy"" (Philadelphus lewisii or Indian arrowwood).

Many fishes and plants important to Nez Perce culture are today state symbols: the black huckleberry or ""cemi'tk"" is the official state fruit and the Indian arrowwood or ""sise'qiy"", the Douglas fir or ""pa'ps"" is the state tree of Oregon and the ponderosa pine or ""la'qa"" of Montana, the Chinook salmon is the state fish of Oregon, the cutthroat trout or ""wawa'lam"" of Idaho, Montana and Wyoming, and the West Coast steelhead or "heyey" of Washington.
The Nez Perce believed in spirits called "weyekins" (Wie-a-kins) which would, they thought, offer a link to the invisible world of spiritual power". The weyekin would protect one from harm and become a personal guardian spirit. To receive a weyekin, a seeker would go to the mountains alone on a vision quest. This included fasting and meditation over several days. While on the quest, the individual may receive a vision of a spirit, which would take the form of a mammal or bird. This vision could appear physically or in a dream or trance. The weyekin was to bestow the animal's powers on its bearer—for example; a deer might give its bearer swiftness. A person's weyekin was very personal. It was rarely shared with anyone and was contemplated in private. The weyekin stayed with the person until death.

Helen Hunt Jackson, author of "A Century of Dishonor", written in 1889 refers to the Nez Perce as "the richest, noblest, and most gentle" of Indian peoples as well as the most industrious.

The museum at the Nez Perce National Historical Park, headquartered in Spalding, Idaho, and managed by the National Park Service includes a research center, archives, and library. Historical records are available for on-site study and interpretation of Nez Perce history and culture. The park includes 38 sites associated with the Nez Perce in the states of Idaho, Montana, Oregon, and Washington, many of which are managed by local and state agencies.

In 1805 William Clark was the first known Euro-American to meet any of the tribe, excluding the aforementioned French Canadian traders. While he, Meriwether Lewis and their men were crossing the Bitterroot Mountains, they ran low of food, and Clark took six hunters and hurried ahead to hunt. On September 20, 1805, near the western end of the Lolo Trail, he found a small camp at the edge of the camas-digging ground, which is now called Weippe Prairie. The explorers were favorably impressed by the Nez Perce whom they met. Preparing to make the remainder of their journey to the Pacific by boats on rivers, they entrusted the keeping of their horses until they returned to "2 brothers and one son of one of the Chiefs." One of these Indians was "Walammottinin" (meaning "Hair Bunched and tied," but more commonly known as Twisted Hair). He was the father of Chief Lawyer, who by 1877 was a prominent member of the "Treaty" faction of the tribe. The Nez Perce were generally faithful to the trust; the party recovered their horses without serious difficulty when they returned.

Recollecting the Nez Perce encounter with the Lewis and Clark party, in 1889 anthropologist Alice Fletcher wrote that "the Lewis and Clark explorers were the first white men that many of the people had ever seen and the women thought them beautiful." She wrote that the Nez Perce "were kind to the tired and hungry party. They furnished fresh horses and dried meat and fish with wild potatoes and other roots which were good to eat, and the refreshed white men went further on, westward, leaving their bony, wornout horses for the Indians to take care of and have fat and strong when Lewis and Clark should come back on their way home." On their return trip they arrived at the Nez Perce encampment the following spring, again hungry and exhausted. The tribe constructed a large tent for them and again fed them. Desiring fresh red meat, the party offered an exchange for a Nez Perce horse. Quoting from the Lewis and Clark diary, Fletcher writes, "The hospitality of the Chiefs was offended at the idea of an exchange. He observed that his people had an abundance of young horses and that if we were disposed to use that food, we might have as many as we wanted." The party stayed with the Nez Perce for a month before moving on.

The Nez Perce were one of the tribal nations at the Walla Walla Council (1855) (along with the Cayuse, Umatilla, Walla Walla, and Yakama), which signed the Treaty of Walla Walla.

Under pressure from the European Americans, in the late 19th century the Nez Perce split into two groups: one side accepted the coerced relocation to a reservation and the other refused to give up their fertile land in Idaho and Oregon. Those willing to go to a reservation made a treaty in 1877. The flight of the non-treaty Nez Perce began on June 15, 1877, with Chief Joseph, Looking Glass, White Bird, Ollokot, Lean Elk (Poker Joe) and Toohoolhoolzote leading 2,900 men, women and children in an attempt to reach a peaceful sanctuary. They intended to seek shelter with their allies the Crow but, upon the Crow's refusal to offer help, the Nez Perce tried to reach the camp in Canada of Lakota Chief Sitting Bull. He had migrated there instead of surrendering after the Indian victory at the Battle of the Little Bighorn.
The Nez Perce were pursued by over 2,000 soldiers of the U.S. Army on an epic flight to freedom of more than across four states and multiple mountain ranges. The 800 Nez Perce warriors defeated or held off the pursuing troops in 18 battles, skirmishes, and engagements. More than 300 US soldiers and 1,000 Nez Perce (including women and children) were killed in these conflicts.

A majority of the surviving Nez Perce were finally forced to surrender on October 5, 1877, after the Battle of the Bear Paw Mountains in Montana, from the Canada–US border. Chief Joseph surrendered to General Oliver O. Howard of the U.S. Cavalry. During the surrender negotiations, Chief Joseph sent a message, usually described as a speech, to the US soldiers. It has become renowned as one of the greatest American speeches: "...Hear me, my chiefs, I am tired. My heart is sick and sad. From where the sun now stands, I will fight no more forever."

The route of the Nez Perce flight is preserved by the Nez Perce National Historic Trail. The annual Cypress Hills ride in June commemorates the Nez Perce people's attempt to escape to Canada.

In 1994 the Nez Perce tribe began a breeding program, based on crossbreeding the Appaloosa and a Central Asian breed called Akhal-Teke, to produce what they called the Nez Perce Horse. They wanted to restore part of their traditional horse culture, where they had conducted selective breeding of their horses, long considered a marker of wealth and status, and trained their members in a high quality of horsemanship. Social disruption due to reservation life and assimilationist pressures by Americans and the government resulted in the destruction of their horse culture in the 19th century. The 20th-century breeding program was financed by the United States Department of Health and Human Services, the Nez Perce tribe, and the nonprofit called the First Nations Development Institute. It has promoted businesses in Native American country that reflect values and traditions of the peoples. The Nez Perce Horse breed is noted for its speed.

The current tribal lands consist of a reservation in north central Idaho at , primarily in the Camas Prairie region south of the Clearwater River, in parts of four counties. In descending order of surface area, the counties are Nez Perce, Lewis, Idaho, and Clearwater. The total land area is about , and the reservation's population at the 2000 census was 17,959.

Due to tribal loss of lands, the population on the reservation is predominantly white, nearly 90% in 1988. The largest community is the city of Orofino, near its northeast corner. Lapwai is the seat of tribal government, and it has the highest percentage of Nez Percé people as residents, at about 81.4 percent.

Similar to the opening of Native American lands in Oklahoma by allowing acquisition of surplus by non-natives after households received plots, the U.S. government opened the Nez Percé reservation for general settlement on November 18, 1895. The proclamation had been signed less than two weeks earlier by President Grover Cleveland. Thousands rushed to grab land on the reservation, staking out their claims even on land owned by Nez Percé families.




In addition, the Colville Indian Reservation in eastern Washington contains the Joseph band of Nez Percé.





</doc>
<doc id="21189" url="https://en.wikipedia.org/wiki?curid=21189" title="Neolithic">
Neolithic

The Neolithic (, also known as the "New Stone Age"), the final division of the Stone Age, began about 12,000 years ago when the first developments of farming appeared in the Epipalaeolithic Near East, and later in other parts of the world. 
The division lasted until the transitional period of the Chalcolithic from about 6,500 years ago (4500 BC), marked by the development of metallurgy, leading up to the Bronze Age and Iron Age. In Northern Europe, the Neolithic lasted until about 1700 BC, while in China it extended until 1200 BC. Other parts of the world (including the New World) remained broadly in the Neolithic stage of development until European contact.

The Neolithic comprises a progression of behavioral and cultural characteristics and changes, including the use of wild and domestic crops and of domesticated animals.

The term "Neolithic" derives from the Greek , "new" and , "stone", literally meaning "New Stone Age". The term was coined by Sir John Lubbock in 1865 as a refinement of the three-age system.

Following the ASPRO chronology, the Neolithic started in around 10,200 BC in the Levant, arising from the Natufian culture, when pioneering use of wild cereals evolved into early farming. The Natufian period or "proto-Neolithic" lasted from 12,500 to 9,500 BC, and is taken to overlap with the Pre-Pottery Neolithic (PPNA) of 10,200–8800 BC. As the Natufians had become dependent on wild cereals in their diet, and a sedentary way of life had begun among them, the climatic changes associated with the Younger Dryas (about 10,000 BC) are thought to have forced people to develop farming.

By 10,200–8800 BC farming communities had arisen in the Levant and spread to Asia Minor, North Africa and North Mesopotamia. Mesopotamia is the site of the earliest developments of the Neolithic Revolution from around 10,000 BC.

Early Neolithic farming was limited to a narrow range of plants, both wild and domesticated, which included einkorn wheat, millet and spelt, and the keeping of dogs, sheep and goats. By about 6900–6400 BC, it included domesticated cattle and pigs, the establishment of permanently or seasonally inhabited settlements, and the use of pottery.

Not all of these cultural elements characteristic of the Neolithic appeared everywhere in the same order: the earliest farming societies in the Near East did not use pottery. In other parts of the world, such as Africa, South Asia and Southeast Asia, independent domestication events led to their own regionally distinctive Neolithic cultures, which arose completely independently of those in Europe and Southwest Asia. Early Japanese societies and other East Asian cultures used pottery "before" developing agriculture.

In the Middle East, cultures identified as Neolithic began appearing in the 10th millennium BC. Early development occurred in the Levant (e.g. Pre-Pottery Neolithic A and Pre-Pottery Neolithic B) and from there spread eastwards and westwards. Neolithic cultures are also attested in southeastern Anatolia and northern Mesopotamia by around 8000 BC.

The prehistoric Beifudi site near Yixian in Hebei Province, China, contains relics of a culture contemporaneous with the Cishan and Xinglongwa cultures of about 6000–5000 BC, neolithic cultures east of the Taihang Mountains, filling in an archaeological gap between the two Northern Chinese cultures. The total excavated area is more than , and the collection of neolithic findings at the site encompasses two phases.

The Neolithic 1 (PPNA) period began roughly around 10,000 BC in the Levant. A temple area in southeastern Turkey at Göbekli Tepe, dated to around 9500 BC, may be regarded as the beginning of the period. This site was developed by nomadic hunter-gatherer tribes, as evidenced by the lack of permanent housing in the vicinity, and may be the oldest known human-made place of worship. At least seven stone circles, covering , contain limestone pillars carved with animals, insects, and birds. Stone tools were used by perhaps as many as hundreds of people to create the pillars, which might have supported roofs. Other early PPNA sites dating to around 9500–9000 BC have been found in Tell es-Sultan (ancient Jericho), Israel (notably Ain Mallaha, Nahal Oren, and Kfar HaHoresh), Gilgal in the Jordan Valley, and Byblos, Lebanon. The start of Neolithic 1 overlaps the Tahunian and Heavy Neolithic periods to some degree.

The major advance of Neolithic 1 was true farming. In the proto-Neolithic Natufian cultures, wild cereals were harvested, and perhaps early seed selection and re-seeding occurred. The grain was ground into flour. Emmer wheat was domesticated, and animals were herded and domesticated (animal husbandry and selective breeding).

In 2006, remains of figs were discovered in a house in Jericho dated to 9400 BC. The figs are of a mutant variety that cannot be pollinated by insects, and therefore the trees can only reproduce from cuttings. This evidence suggests that figs were the first cultivated crop and mark the invention of the technology of farming. This occurred centuries before the first cultivation of grains.

Settlements became more permanent, with circular houses, much like those of the Natufians, with single rooms. However, these houses were for the first time made of mudbrick. The settlement had a surrounding stone wall and perhaps a stone tower (as in Jericho). The wall served as protection from nearby groups, as protection from floods, or to keep animals penned. Some of the enclosures also suggest grain and meat storage.

The Neolithic 2 (PPNB) began around 8800 BC according to the ASPRO chronology in the Levant (Jericho, West Bank). As with the PPNA dates, there are two versions from the same laboratories noted above. This system of terminology, however, is not convenient for southeast Anatolia and settlements of the middle Anatolia basin. A settlement of 3,000 inhabitants was found in the outskirts of Amman, Jordan. Considered to be one of the largest prehistoric settlements in the Near East, called 'Ain Ghazal, it was continuously inhabited from approximately 7250 BC to approximately 5000 BC.

Settlements have rectangular mud-brick houses where the family lived together in single or multiple rooms. Burial findings suggest an ancestor cult where people preserved skulls of the dead, which were plastered with mud to make facial features. The rest of the corpse could have been left outside the settlement to decay until only the bones were left, then the bones were buried inside the settlement underneath the floor or between houses.

Work at the site of 'Ain Ghazal in Jordan has indicated a later Pre-Pottery Neolithic C period. Juris Zarins has proposed that a Circum Arabian Nomadic Pastoral Complex developed in the period from the climatic crisis of 6200 BCE, partly as a result of an increasing emphasis in PPNB cultures upon domesticated animals, and a fusion with Harifian hunter gatherers in the Southern Levant, with affiliate connections with the cultures of Fayyum and the Eastern Desert of Egypt. Cultures practicing this lifestyle spread down the Red Sea shoreline and moved east from Syria into southern Iraq.

The Neolithic 3 (PN) began around 6,400 BC in the Fertile Crescent. By then distinctive cultures emerged, with pottery like the Halafian (Turkey, Syria, Northern Mesopotamia) and Ubaid (Southern Mesopotamia). This period has been further divided into PNA (Pottery Neolithic A) and PNB (Pottery Neolithic B) at some sites.

The Chalcolithic (Stone-Bronze) period began about 4500 BC, then the Bronze Age began about 3500 BC, replacing the Neolithic cultures.

Around 10,000 BC the first fully developed Neolithic cultures belonging to the phase Pre-Pottery Neolithic A (PPNA) appeared in the Fertile Crescent. Around 10,700–9400 BC a settlement was established in Tell Qaramel, north of Aleppo. The settlement included two temples dating to 9650 BC. Around 9000 BC during the PPNA, one of the world's first towns, Jericho, appeared in the Levant. It was surrounded by a stone wall and contained a population of 2,000–3,000 people and a massive stone tower. Around 6400 BC the Halaf culture appeared in Syria and Northern Mesopotamia.

In 1981 a team of researchers from the Maison de l'Orient et de la Méditerranée, including Jacques Cauvin and Oliver Aurenche divided Near East neolithic chronology into ten periods (0 to 9) based on social, economic and cultural characteristics. In 2002 Danielle Stordeur and Frédéric Abbès advanced this system with a division into five periods. 
They also advanced the idea of a transitional stage between the PPNA and PPNB between 8800 and 8600 BC at sites like Jerf el Ahmar and Tell Aswad.

Alluvial plains (Sumer/Elam). Low rainfall makes irrigation systems necessary. Ubaid culture from 6,900 BC.

Domestication of sheep and goats reached Egypt from the Near East possibly as early as 6000 BC. Graeme Barker states "The first indisputable evidence for domestic plants and animals in the Nile valley is not until the early fifth millennium BC in northern Egypt and a thousand years later further south, in both cases as part of strategies that still relied heavily on fishing, hunting, and the gathering of wild plants" and suggests that these subsistence changes were not due to farmers migrating from the Near East but was an indigenous development, with cereals either indigenous or obtained through exchange. Other scholars argue that the primary stimulus for agriculture and domesticated animals (as well as mud-brick architecture and other Neolithic cultural features) in Egypt was from the Middle East.

In southeast Europe agrarian societies first appeared in the 7th millennium BC, attested by one of the earliest farming sites of Europe, discovered in Vashtëmi, southeastern Albania and dating back to 6500 BC. In Northwest Europe it is much later, typically lasting just under 3,000 years from c. 4500 BC–1700 BC.

Anthropomorphic figurines have been found in the Balkans from 6000 BC, and in Central Europe by around 5800 BC (La Hoguette). Among the earliest cultural complexes of this area are the Sesklo culture in Thessaly, which later expanded in the Balkans giving rise to Starčevo-Körös (Cris), Linearbandkeramik, and Vinča. Through a combination of cultural diffusion and migration of peoples, the Neolithic traditions spread west and northwards to reach northwestern Europe by around 4500 BC. The Vinča culture may have created the earliest system of writing, the Vinča signs, though archaeologist Shan Winn believes they most likely represented pictograms and ideograms rather than a truly developed form of writing.

The Cucuteni-Trypillian culture built enormous settlements in Romania, Moldova and Ukraine from 5300 to 2300 BC. The megalithic temple complexes of Ġgantija on the Mediterranean island of Gozo (in the Maltese archipelago) and of Mnajdra (Malta) are notable for their gigantic Neolithic structures, the oldest of which date back to around 3600 BC. The Hypogeum of Ħal-Saflieni, Paola, Malta, is a subterranean structure excavated around 2500 BC; originally a sanctuary, it became a necropolis, the only prehistoric underground temple in the world, and shows a degree of artistry in stone sculpture unique in prehistory to the Maltese islands. After 2500 BC, these islands were depopulated for several decades until the arrival of a new influx of Bronze Age immigrants, a culture that cremated its dead and introduced smaller megalithic structures called dolmens to Malta. In most cases there are small chambers here, with the cover made of a large slab placed on upright stones. They are claimed to belong to a population different from that which built the previous megalithic temples. It is presumed the population arrived from Sicily because of the similarity of Maltese dolmens to some small constructions found there.

Settled life, encompassing the transition from foraging to farming and pastoralism, began in South Asia in the region of Balochistan, Pakistan, around 7,000 BCE. At the site of Mehrgarh, Balochistan, presence can be documented of the domestication of wheat and barley, rapidly followed by that of goats, sheep, and cattle. In April 2006, it was announced in the scientific journal "Nature" that the oldest (and first "early Neolithic") evidence for the drilling of teeth "in vivo" (using bow drills and flint tips) was found in Mehrgarh.

In South India, the Neolithic began by 6500 BC and lasted until around 1400 BC when the Megalithic transition period began. South Indian Neolithic is characterized by Ash mounds from 2500 BC in Karnataka region, expanded later to Tamil Nadu.

In East Asia, the earliest sites include the Nanzhuangtou culture around 9500–9000 BC, Pengtoushan culture around 7500–6100 BC, and Peiligang culture around 7000–5000 BC.

The 'Neolithic' (defined in this paragraph as using polished stone implements) remains a living tradition in small and extremely remote and inaccessible pockets of West Papua (Indonesian New Guinea). Polished stone adze and axes are used in the present day () in areas where the availability of metal implements is limited. This is likely to cease altogether in the next few years as the older generation die off and steel blades and chainsaws prevail.

In 2012, news was released about a new farming site discovered in Munam-ri, Goseong, Gangwon Province, South Korea, which may be the earliest farmland known to date in east Asia. "No remains of an agricultural field from the Neolithic period have been found in any East Asian country before, the institute said, adding that the discovery reveals that the history of agricultural cultivation at least began during the period on the Korean Peninsula". The farm was dated between 3600 and 3000 BC. Pottery, stone projectile points, and possible houses were also found. "In 2002, researchers discovered prehistoric earthenware, jade earrings, among other items in the area". The research team will perform accelerator mass spectrometry (AMS) dating to retrieve a more precise date for the site.

In Mesoamerica, a similar set of events (i.e., crop domestication and sedentary lifestyles) occurred by around 4500 BC, but possibly as early as 11,000–10,000 BC. These cultures are usually not referred to as belonging to the Neolithic; in America different terms are used such as Formative stage instead of mid-late Neolithic, Archaic Era instead of Early Neolithic and Paleo-Indian for the preceding period. The Formative stage is equivalent to the Neolithic Revolution period in Europe, Asia, and Africa. In the southwestern United States it occurred from 500 to 1200 AD when there was a dramatic increase in population and development of large villages supported by agriculture based on dryland farming of maize, and later, beans, squash, and domesticated turkeys. During this period the bow and arrow and ceramic pottery were also introduced. In later periods cities of considerable size developed, and some metallurgy by 700 BCE.

Australia, in contrast to New Guinea, has generally been held not to have had a Neolithic period, with a hunter-gatherer lifestyle continuing until the arrival of Europeans. This view can be challenged in terms of the definition of agriculture, but "Neolithic" remains a rarely-used and not very useful concept in discussing Australian prehistory.

During most of the Neolithic age of Eurasia, people lived in small tribes composed of multiple bands or lineages. There is little scientific evidence of developed social stratification in most Neolithic societies; social stratification is more associated with the later Bronze Age. Although some late Eurasian Neolithic societies formed complex stratified chiefdoms or even states, generally states evolved in Eurasia only with the rise of metallurgy, and most Neolithic societies on the whole were relatively simple and egalitarian. Beyond Eurasia, however, states were formed during the local Neolithic in three areas, namely in the Preceramic Andes with the Norte Chico Civilization, Formative Mesoamerica and Ancient Hawaiʻi. However, most Neolithic societies were noticeably more hierarchical than the Upper Paleolithic cultures that preceded them and hunter-gatherer cultures in general.

The domestication of large animals (c. 8000 BC) resulted in a dramatic increase in social inequality in most of the areas where it occurred; New Guinea being a notable exception. Possession of livestock allowed competition between households and resulted in inherited inequalities of wealth. Neolithic pastoralists who controlled large herds gradually acquired more livestock, and this made economic inequalities more pronounced. However, evidence of social inequality is still disputed, as settlements such as Catal Huyuk reveal a striking lack of difference in the size of homes and burial sites, suggesting a more egalitarian society with no evidence of the concept of capital, although some homes do appear slightly larger or more elaborately decorated than others.

Families and households were still largely independent economically, and the household was probably the center of life. However, excavations in Central Europe have revealed that early Neolithic Linear Ceramic cultures (""Linearbandkeramik"") were building large arrangements of circular ditches between 4800 and 4600 BC. These structures (and their later counterparts such as causewayed enclosures, burial mounds, and henge) required considerable time and labour to construct, which suggests that some influential individuals were able to organise and direct human labour — though non-hierarchical and voluntary work remain possibilities.

There is a large body of evidence for fortified settlements at "Linearbandkeramik" sites along the Rhine, as at least some villages were fortified for some time with a palisade and an outer ditch. Settlements with palisades and weapon-traumatized bones, such as those found at the Talheim Death Pit, have been discovered and demonstrate that "...systematic violence between groups" and warfare was probably much more common during the Neolithic than in the preceding Paleolithic period. This supplanted an earlier view of the Linear Pottery Culture as living a "peaceful, unfortified lifestyle".

Control of labour and inter-group conflict is characteristic of tribal groups with social rank that are headed by a charismatic individual — either a 'big man' or a proto-chief — functioning as a lineage-group head. Whether a non-hierarchical system of organization existed is debatable, and there is no evidence that explicitly suggests that Neolithic societies functioned under any dominating class or individual, as was the case in the chiefdoms of the European Early Bronze Age. Theories to explain the apparent implied egalitarianism of Neolithic (and Paleolithic) societies have arisen, notably the Marxist concept of primitive communism.

The shelter of the early people changed dramatically from the Upper Paleolithic to the Neolithic era. In the Paleolithic, people did not normally live in permanent constructions. In the Neolithic, mud brick houses started appearing that were coated with plaster. The growth of agriculture made permanent houses possible. Doorways were made on the roof, with ladders positioned both on the inside and outside of the houses. The roof was supported by beams from the inside. The rough ground was covered by platforms, mats, and skins on which residents slept. Stilt-houses settlements were common in the Alpine and Pianura Padana (Terramare) region. Remains have been found at the Ljubljana Marshes in Slovenia and at the Mondsee and Attersee lakes in Upper Austria, for example.

A significant and far-reaching shift in human subsistence and lifestyle was to be brought about in areas where crop farming and cultivation were first developed: the previous reliance on an essentially nomadic hunter-gatherer subsistence technique or pastoral transhumance was at first supplemented, and then increasingly replaced by, a reliance upon the foods produced from cultivated lands. These developments are also believed to have greatly encouraged the growth of settlements, since it may be supposed that the increased need to spend more time and labor in tending crop fields required more localized dwellings. This trend would continue into the Bronze Age, eventually giving rise to permanently settled farming towns, and later cities and states whose larger populations could be sustained by the increased productivity from cultivated lands.

The profound differences in human interactions and subsistence methods associated with the onset of early agricultural practices in the Neolithic have been called the "Neolithic Revolution", a term coined in the 1920s by the Australian archaeologist Vere Gordon Childe.

One potential benefit of the development and increasing sophistication of farming technology was the possibility of producing surplus crop yields, in other words, food supplies in excess of the immediate needs of the community. Surpluses could be stored for later use, or possibly traded for other necessities or luxuries. Agricultural life afforded securities that nomadic life could not, and sedentary farming populations grew faster than nomadic.

However, early farmers were also adversely affected in times of famine, such as may be caused by drought or pests. In instances where agriculture had become the predominant way of life, the sensitivity to these shortages could be particularly acute, affecting agrarian populations to an extent that otherwise may not have been routinely experienced by prior hunter-gatherer communities. Nevertheless, agrarian communities generally proved successful, and their growth and the expansion of territory under cultivation continued.

Another significant change undergone by many of these newly agrarian communities was one of diet. Pre-agrarian diets varied by region, season, available local plant and animal resources and degree of pastoralism and hunting. Post-agrarian diet was restricted to a limited package of successfully cultivated cereal grains, plants and to a variable extent domesticated animals and animal products. Supplementation of diet by hunting and gathering was to variable degrees precluded by the increase in population above the carrying capacity of the land and a high sedentary local population concentration. In some cultures, there would have been a significant shift toward increased starch and plant protein. The relative nutritional benefits and drawbacks of these dietary changes and their overall impact on early societal development are still debated.

In addition, increased population density, decreased population mobility, increased continuous proximity to domesticated animals, and continuous occupation of comparatively population-dense sites would have altered sanitation needs and patterns of disease.

The identifying characteristic of Neolithic technology is the use of polished or ground stone tools, in contrast to the flaked stone tools used during the Paleolithic era.

Neolithic people were skilled farmers, manufacturing a range of tools necessary for the tending, harvesting and processing of crops (such as sickle blades and grinding stones) and food production (e.g. pottery, bone implements). They were also skilled manufacturers of a range of other types of stone tools and ornaments, including projectile points, beads, and statuettes. But what allowed forest clearance on a large scale was the polished stone axe above all other tools. Together with the adze, fashioning wood for shelter, structures and canoes for example, this enabled them to exploit their newly won farmland.

Neolithic peoples in the Levant, Anatolia, Syria, northern Mesopotamia and Central Asia were also accomplished builders, utilizing mud-brick to construct houses and villages. At Çatalhöyük, houses were plastered and painted with elaborate scenes of humans and animals. In Europe, long houses built from wattle and daub were constructed. Elaborate tombs were built for the dead. These tombs are particularly numerous in Ireland, where there are many thousand still in existence. Neolithic people in the British Isles built long barrows and chamber tombs for their dead and causewayed camps, henges, flint mines and cursus monuments. It was also important to figure out ways of preserving food for future months, such as fashioning relatively airtight containers, and using substances like salt as preservatives.

The peoples of the Americas and the Pacific mostly retained the Neolithic level of tool technology until the time of European contact. Exceptions include copper hatchets and spearheads in the Great Lakes region.

Most clothing appears to have been made of animal skins, as indicated by finds of large numbers of bone and antler pins that are ideal for fastening leather. Wool cloth and linen might have become available during the later Neolithic, as suggested by finds of perforated stones that (depending on size) may have served as spindle whorls or loom weights. The clothing worn in the Neolithic Age might be similar to that worn by Ötzi the Iceman, although he was not Neolithic (since he belonged to the later Copper age).

Neolithic human settlements include:

The world's oldest known engineered roadway, the Sweet Track in England, dates from 3800 BC and the world's oldest freestanding structure is the neolithic temple of Ġgantija in Gozo, Malta.

"Note: Dates are very approximate, and are only given for a rough estimate; consult each culture for specific time periods."

Early Neolithic 
"Periodization: The Levant: 9500–8000 BC; Europe: 5000–4000 BC; Elsewhere: varies greatly, depending on region."

Middle Neolithic
"Periodization: The Levant: 8000–6000 BC; Europe: 4000–3500 BC; Elsewhere: varies greatly, depending on region."

Later Neolithic 
"Periodization: 6500–4500 BC; Europe: 3500–3000 BC; Elsewhere: varies greatly, depending on region."


"Periodization: Near East: 4500–3300 BC; Europe: 3000–1700 BC; Elsewhere: varies greatly, depending on region. In the Americas, the Eneolithic ended as late as the 19th century AD for some peoples."



</doc>
<doc id="21190" url="https://en.wikipedia.org/wiki?curid=21190" title="Nomic">
Nomic

Nomic is a game created in 1982 by philosopher Peter Suber in which the of the game include mechanisms for the players to change those rules, usually beginning through a system of democratic voting. 

The initial was designed by Peter Suber, and first published in Douglas Hofstadter's column "Metamagical Themas" in "Scientific American" in June 1982. The column discussed Suber's then-upcoming book, "The Paradox of Self-Amendment", which was published some years later. Nomic now refers to many games, all based on the initial ruleset.

The game is in some ways modeled on modern government systems. It demonstrates that in any system where rule changes are possible, a situation may arise in which the resulting laws are contradictory or insufficient to determine what is in fact legal. Because the game models (and exposes conceptual questions about) a legal system and the problems of legal interpretation, it is named after (""), Greek for "law".

While the victory condition in Suber's initial ruleset is the accumulation of 100 points by the roll of dice, he once said that "this rule is deliberately boring so that players will quickly amend it to please themselves". Players can change the rules to such a degree that points can become irrelevant in favor of a true currency, or make victory an unimportant concern. Any rule in the game, including the rules specifying the criteria for winning and even the rule that rules must be obeyed, can be changed. Any loophole in the ruleset, however, may allow the first player to discover it the chance to pull a "scam" and modify the rules to win the game. Complicating this process is the fact that Suber's initial ruleset allows for the appointment of judges to preside over issues of rule interpretation.

The game can be played face-to-face with as many written notes as are required, or through any of a number of Internet media (usually an archived mailing list or Internet forum).

Initially, gameplay occurs in clockwise order, with each player taking a turn. In that turn, they propose a change in rules that all the other players vote on, and then roll a die to determine the number of points they add to their score. If this rule change is passed, it comes into effect at the end of their round. Any rule can be changed with varying degrees of difficulty, including the core rules of the game itself. As such, the gameplay may quickly change.

Under Suber's initial ruleset, rules are divided into two types: mutable and immutable. The main difference between these is that immutable rules must be changed into mutable rules (called "transmuting") before they can be modified or removed. Immutable rules also take precedence over mutable ones. A rule change may be:


Alternative starting rulesets exist for Internet and mail games, wherein gameplay occurs in alphabetical order by surname, and points added to the score are based on the success of a proposed rule change rather than random dice rolls.

Not only can every aspect of the rules be altered in some way over the course of a game of Nomic, but myriad variants also exist: some that have themes, begin with a single rule, or begin with a dictator instead of a democratic process to validate rules. Others combine Nomic with an existing game (such as Monopoly, chess, or in one humorously paradoxical attempt, Mornington Crescent). There is even a version in which the players are games of Nomic themselves. Even more unusual variants include a ruleset in which the rules are hidden from players' view, and a game which, instead of allowing voting on rules, splits into two sub-games, one with the rule, and one without it.

Online versions often have initial rulesets where play is not turn-based; typically, players in such games may propose rule changes at any time, rather than having to wait for their turn.

One spin-off of a now-defunct Nomic (Nomic World) is called the Fantasy Rules Committee; it adds every legal rule submitted by a player to the ruleset until the players run out of ideas, after which all the "fantasy rules" are repealed and the game begins again.

The game of Nomic is particularly suited to being played online, where all proposals and rules can be shared in web pages or email archives for ease of reference. Such games of Nomic sometimes last for a very long time – Agora has been running since 1993. The longevity of nomic games can pose a serious problem, in that the rulesets can grow so complex that current players do not fully understand them and prospective players are deterred from joining. One currently active game, BlogNomic, gets around this problem by dividing the game into "dynasties"; every time someone wins, a new dynasty begins, and all the rules except a privileged few are repealed. This keeps the game relatively simple and accessible. Nomicron (now defunct) was similar in that it had rounds – when a player won a round, a convention was started to plan for the next round. A game of Nomic on reddit, (now defunct), used a similar mechanism modeled on Nomicron's system.

Another facet of Nomic is the way in which the implementation of the rules affects the way the game of Nomic itself works. ThermodyNomic, for example, had a ruleset in which rule changes were carefully considered before implementation, and rules were rarely introduced which provide loopholes for the players to exploit. B Nomic, by contrast, was once described by one of its players as "the equivalent of throwing logical hand grenades".

This is essentially part of the differentiation between "procedural" games, where the aim (acknowledged or otherwise) is to tie the entire ruleset into a paradoxical condition during each turn (a player who has no legal move available wins), and "substantive" games, which try to avoid paradox and reward winning by achieving certain goals, such as attaining a given number of points.

While "Nomic" is traditionally capitalized as the proper name of the game it describes, it has also sometimes been used in a more informal way as a lowercased generic term, "nomic", referring to anything with Nomic-like characteristics, including games where the rules may be changed during play as well as non-gaming situations where it can be alleged that "rules lawyers" are tinkering with the process used to amend rules and policies (in an organization or community) in a manner akin to a game of Nomic.

In a computerized Nomic, the rules are interpreted by a computer, rather than by humans. This implies that the rules should be written in a language that a computer can understand, typically some sort of programming language or Game Description Language. Nomyx (now defunct) is such an implementation.




</doc>
<doc id="21197" url="https://en.wikipedia.org/wiki?curid=21197" title="Nintendo">
Nintendo

Nintendo was founded in 1889 by Fusajiro Yamauchi and originally produced handmade "hanafuda" playing cards. By 1963, the company had tried several small niche businesses, such as cab services and love hotels, without major success. Abandoning previous ventures in favor of toys in the 1960s, Nintendo developed into a video game company in the 1970s. Supplemented since the 1980s by its major divisions Nintendo of America and Nintendo of Europe, it ultimately became one of the most influential in the video game industry and one of Japan's most-valuable companies with a market value of over $37 billion in 2018.

Nintendo was founded as a playing card company by Fusajiro Yamauchi on 23 September 1889. Based in Kyoto, the business produced and marketed "hanafuda" cards. The handmade cards soon became popular, and Yamauchi hired assistants to mass-produce cards to satisfy demand. The company was formally established as an unlimited partnership titled Yamauchi Nintendo & Co. Ltd. in 1933. It changed its name to Nintendo Playing Card Co. Ltd. in 1951. Nintendo continues to manufacture playing cards in Japan and organizes its own contract bridge tournament called the "Nintendo Cup". The word "Nintendo" can be translated as "leave luck to heaven", or alternatively as "the temple of free hanafuda".

In 1956, Hiroshi Yamauchi, grandson of Fusajiro Yamauchi, visited the U.S. to talk with the United States Playing Card Company, the dominant playing card manufacturer there. He found that the biggest playing card company in the world was using only a small office. Yamauchi's realization that the playing card business had limited potential was a turning point. He then acquired the license to use Disney characters on playing cards to drive sales.

In 1963, Yamauchi renamed Nintendo Playing Card Co. Ltd. to Nintendo Co., Ltd. The company then began to experiment in other areas of business using newly injected capital during the period of time between 1963 and 1968. Nintendo set up a taxi company called "Daiya". This business was initially successful. However, Nintendo was forced to sell it because problems with the labor unions were making it too expensive to run the service. It also set up a love hotel chain, a TV network, a food company (selling instant rice) and several other ventures. All of these ventures eventually failed, and after the 1964 Tokyo Olympics, playing card sales dropped, and Nintendo's stock price plummeted to its lowest recorded level of ¥60.

In 1966, Nintendo moved into the Japanese toy industry with the Ultra Hand, an extendable arm developed by its maintenance engineer Gunpei Yokoi in his free time. Yokoi was moved from maintenance to the new "Nintendo Games" department as a product developer. Nintendo continued to produce popular toys, including the Ultra Machine, Love Tester and the "Kousenjuu" series of light gun games. Despite some successful products, Nintendo struggled to meet the fast development and manufacturing turnaround required in the toy market, and fell behind the well-established companies such as Bandai and Tomy. In 1973, its focus shifted to family entertainment venues with the Laser Clay Shooting System, using the same light gun technology used in Nintendo's "Kousenjuu" series of toys, and set up in abandoned bowling alleys. Following some success, Nintendo developed several more light gun machines (such as the light gun shooter game "Wild Gunman") for the emerging arcade scene. While the Laser Clay Shooting System ranges had to be shut down following excessive costs, Nintendo had found a new market.

Nintendo's first venture into the video game industry was securing rights to distribute the Magnavox Odyssey video game console in Japan in 1974. Nintendo began to produce its own hardware in 1977, with the Color TV-Game home video game consoles. Four versions of these consoles were produced, each including variations of a single game; for example, Color TV Game 6 features six versions of "Light Tennis".

A student product developer named Shigeru Miyamoto was hired by Nintendo at this time. He worked for Yokoi, and one of his first tasks was to design the casing for several of the Color TV-Game consoles. Miyamoto went on to create, direct and produce some of Nintendo's most famous video games and become one of the most recognizable figures in the video game industry.

In 1975, Nintendo moved into the video arcade game industry with "EVR Race", designed by their first game designer, Genyo Takeda, and several more games followed. Nintendo had some small success with this venture, but the release of "Donkey Kong" in 1981, designed by Miyamoto, changed Nintendo's fortunes dramatically. The success of the game and many licensing opportunities (such as ports on the Atari 2600, Intellivision and ColecoVision) gave Nintendo a huge boost in profit and in addition, the game also introduced an early iteration of Mario, then known in Japan as Jumpman, the eventual company mascot. Nintendo would continue to manufacture arcade games and systems until 1992.

In 1979, Gunpei Yokoi conceived the idea of a handheld video game, while observing a fellow bullet train commuter who passed the time by interacting idly with a portable LCD calculator. The idea became Game & Watch. In 1980, Nintendo launched "Game & Watch"—a handheld video game series developed by Yokoi. These systems do not contain interchangeable cartridges and thus the hardware was tied to the game. The first Game & Watch game, "Ball", was distributed worldwide. The modern "cross" D-pad design was developed in 1982, by Yokoi for a "Donkey Kong" version. Proven to be popular, the design was patented by Nintendo. It later earned a Technology & Engineering Emmy Award.

In 1983, Nintendo launched the Family Computer (colloquialized as "Famicom") home video game console in Japan, alongside ports of its most popular arcade games. In 1985, a cosmetically reworked version of the system known outside Japan as the Nintendo Entertainment System or NES, launched in North America. The practice of bundling the system along with select games helped to make "Super Mario Bros." one of the best-selling video games in history.

In 1988, Gunpei Yokoi and his team at Nintendo R&D1 conceived the new Game Boy handheld system, with the purpose of merging the two very successful ideas of the Game & Watch's portability along with the NES's cartridge interchangeability. Nintendo released the Game Boy in Japan on 21 April 1989, and in North America on 31 July 1989. Nintendo of America president Minoru Arakawa managed a deal to bundle the popular third-party game "Tetris" along with the Game Boy, and the pair launched as an instant success.

In 1989, Nintendo announced plans to release the successor to the Famicom, the Super Famicom. Based on a 16-bit processor, Nintendo boasted significantly superior hardware specifications of graphics, sound, and game speed over the original 8-bit Famicom. The Super Famicom was finally released relatively late to the market in Japan on 21 November 1990, and released as the Super Nintendo Entertainment System (officially abbreviated the Super NES or SNES and commonly shortened to Super Nintendo) in North America on 23 August 1991 and in Europe in 1992. Its main rival was the 16-bit Mega Drive, known in North America as Genesis, which had been advertised aggressively against the nascent 8-bit NES. A console war between Sega and Nintendo ensued during the early 1990s. From 1990 to 1992, Nintendo opened "World of Nintendo" shops in the United States where consumers could test and buy Nintendo products.

In August 1993, Nintendo announced the SNES's successor, codenamed "Project Reality". Featuring 64-bit graphics, the new system was developed as a joint venture between Nintendo and North-American-based technology company Silicon Graphics. The system was announced to be released by the end of 1995, but was subsequently delayed. Meanwhile, Nintendo continued the Nintendo Entertainment System family with the release of the NES-101, a smaller redesign of the original NES. Nintendo also announced a CD drive peripheral called the Super NES CD-ROM Adapter, which was co-developed first by Sony with the name "Play Station" and then by Philips. Bearing prototypes and joint announcements at the Consumer Electronics Show, it was on track for a 1994 release, but was controversially canceled.

In 1995, Nintendo announced that it had sold one billion game cartridges worldwide, ten percent of those being from the "Mario" franchise. Nintendo deemed 1994 the "Year of the Cartridge". To further their support for cartridges, Nintendo announced that Project Reality, which had now been renamed the Ultra 64, would not use a CD format as expected, but would rather use cartridges as its primary media format. Nintendo IRD general manager Genyo Takeda was impressed by video game development company Rare's progress with real-time 3D graphics technology, using state of the art Silicon Graphics workstations. As a result, Nintendo bought a 25% stake in the company, eventually expanding to 49%, and offered their catalog of characters to create a CGI game around, making Rare Nintendo's first western-based second-party developer. Their first game as partners with Nintendo was "Donkey Kong Country". The game was a critical success and sold over eight million copies worldwide, making it the second best-selling game in the SNES library. In September 1994, Nintendo, along with six other video game giants including Sega, Electronic Arts, Atari, Acclaim, Philips, and 3DO approached the United States Senate and demanded a ratings system for video games to be enforced, which prompted the decision to create the Entertainment Software Rating Board.

Aiming to produce an affordable virtual reality console, Nintendo released the Virtual Boy in 1995, designed by Gunpei Yokoi. The console consists of a head-mounted semi-portable system with one red-colored screen for each of the user's eyes, featuring stereoscopic graphics. Games are viewed through a binocular eyepiece and controlled using an affixed gamepad. Critics were generally disappointed with the quality of the games and the red-colored graphics, and complained of gameplay-induced headaches. The system sold poorly and was quietly discontinued. Amid the system's failure, Yokoi retired from Nintendo. During the same year, Nintendo launched the Satellaview in Japan, a peripheral for the Super Famicom. The accessory allowed users to play video games via broadcast for a set period of time. Various games were made exclusively for the platform, as well as various remakes.

In 1996, Nintendo renamed the Ultra 64 to Nintendo 64, releasing it in Japan and North America, and in 1997 in Europe and Australia. The Nintendo 64 continued what had become a Nintendo tradition of hardware design which is focused less on high performance specifications than on design innovations intended to inspire game development. With its market shares slipping to the Sega Saturn and partner-turned-rival Sony PlayStation, Nintendo revitalized its brand by launching a $185 million marketing campaign centered around the "Play it Loud" slogan. During the same year, Nintendo also released the Game Boy Pocket in Japan, a smaller version of the Game Boy that generated more sales for the platform. On 4 October 1997, famed Nintendo developer Gunpei Yokoi died in a car crash. In 1997, Nintendo released the SNS-101 (called Super Famicom Jr. in Japan), a smaller redesigned version of the Super Nintendo Entertainment System.

In 1998, the successor to the Game Boy, the Game Boy Color, was released. The system had improved technical specifications allowing it to run games made specifically for the system as well as games released for the Game Boy, albeit with added color. The Game Boy Camera and Printer were also released as accessories. In October 1998, Retro Studios was founded as an alliance between Nintendo and former Iguana Entertainment founder Jeff Spangenberg. Nintendo saw an opportunity for the new studio to create games for the upcoming GameCube targeting an older demographic, in the same vein as Iguana Entertainment's successful "" series for the Nintendo 64.

In 2001, Nintendo introduced the redesigned Game Boy Advance. The same year, Nintendo also released the GameCube to lukewarm sales, and it ultimately failed to regain the market share lost by the Nintendo 64. When Yamauchi, company president since 1949, retired on 24 May 2002, Satoru Iwata became first Nintendo president who was unrelated to the Yamauchi family through blood or marriage since its founding in 1889.

In 2003, Nintendo released the Game Boy Advance SP, a redesign of the Game Boy Advance that featured a clamshell design that would later be used in Nintendo's DS and 3DS handheld video game systems.

In 2004, Nintendo released the Nintendo DS, its fourth major handheld system. The DS is a dual screened handheld featuring touch screen capabilities, which respond to either a stylus or the touch of a finger. Former Nintendo president and chairman Hiroshi Yamauchi was translated by GameScience as explaining, "If we can increase the scope of the industry, we can re-energise the global market and lift Japan out of depression – that is Nintendo's mission." Regarding lukewarm GameCube sales which had yielded the company's first reported operating loss in over 100 years, Yamauchi continued: "The DS represents a critical moment for Nintendo's success over the next two years. If it succeeds, we rise to the heavens, if it fails, we sink into hell." Due to games such as "Nintendogs" and "Mario Kart DS", the DS became a success. In 2005, Nintendo released the Game Boy Micro in North America, a redesign of the Game Boy Advance. The last system in the Game Boy line, it is also the smallest Game Boy, and the least successful. In the middle of 2005, Nintendo opened the Nintendo World Store in New York City, which would sell Nintendo games, present a museum of Nintendo history, and host public parties such as for product launches. The store was renovated and renamed as Nintendo New York in 2016.
In the first half of 2006, Nintendo released the Nintendo DS Lite, a version of the original Nintendo DS with lighter weight, brighter screen, and better battery life. In addition to this streamlined design, its prolific subset of casual games appealed to the masses, such as the "Brain Age" series. Meanwhile, "New Super Mario Bros." provided a substantial addition to the "Mario" series when it was launched to the top of sales charts. The successful direction of the Nintendo DS had a big influence on Nintendo's next home console (including the common Nintendo Wi-Fi Connection), which had been codenamed "Revolution" and was now renamed to "Wii". In August 2006, Nintendo published ES, a now-dormant, open source research operating system project designed around web application integration but for no specific purpose.

In the latter half of 2006, Nintendo released the Wii as the backward-compatible successor to the GameCube. Based upon intricate Wii Remote motion controls and a balance board, the Wii inspired several new game franchises, some targeted at entirely new market segments of casual and fitness gaming. With more than 100 million units sold worldwide, the Wii is the best selling console of the seventh generation, regaining market share lost during the tenures of the Nintendo 64 and GameCube.

On 1 May 2007, Nintendo acquired an 80% stake in video game development company Monolith Soft, previously owned by Bandai Namco. Monolith Soft is best known for developing role-playing games such as the "Xenosaga", "", and "Xenoblade" series.

During the holiday season of 2008, Nintendo followed up the success of the DS with the release of the Nintendo DSi in Japan. The system features a more powerful CPU and more RAM, two cameras, one facing towards the player and one facing outwards, and had an online distribution store called DSiWare. The DSi was later released worldwide during 2009. In the latter half of 2009, Nintendo released the Nintendo DSi XL in Japan, a larger version of the DSi. This system was later released worldwide in 2010.

In 2011, Nintendo released the Nintendo 3DS, based upon a glasses-free stereoscopic 3D display. In February 2012, Nintendo acquired Mobiclip, a France-based research and development company specialized in highly optimized software technologies such as video compression. The company's name was later changed to Nintendo European Research & Development. During the fourth quarter of 2012, Nintendo released the Wii U. It sold slower than expected, despite being the first eighth generation console. By September 2013, however, sales had rebounded. Intending to broaden the 3DS market, Nintendo released 2013's cost-reduced Nintendo 2DS. The 2DS is compatible with but lacks the 3DS's more expensive but cosmetic autostereoscopic 3D feature. Nintendo also released the Wii Mini, a cheaper and non-networked redesign of the Wii.

On 25 September 2013, Nintendo announced it had purchased a 28% stake in a Panasonic spin-off company called PUX Corporation. The company specializes in face and voice recognition technology, with which Nintendo intends to improve the usability of future game systems. Nintendo has also worked with this company in the past to create character recognition software for a Nintendo DS touchscreen. After announcing a 30% dive in profits for the April to December 2013 period, president Satoru Iwata announced he would take a 50% pay-cut, with other executives seeing reductions by 20%–30%.

In January 2015, Nintendo announced its exit from the Brazilian market after four years of distributing products in the country. Nintendo cited high import duties and lack of local manufacturing operation as reasons for leaving. Nintendo continues its partnership with Juegos de Video Latinoamérica to distribute products to the rest of Latin America.

On 11 July 2015, Iwata died from a bile duct tumor at the age of 55. Following his death, representative directors Genyo Takeda and Shigeru Miyamoto jointly led the company on an interim basis until the appointment of Tatsumi Kimishima as Iwata's successor on 16 September 2015. In addition to Kimishima's appointment, the company's management organization was also restructured—Miyamoto was named "Creative Fellow" and Takeda was named "Technology Fellow".

On 17 March 2015, Nintendo announced a partnership with Japanese mobile developer DeNA to produce games for smart devices. The first of these, "Miitomo", was released in March 2016.

On the same day, Nintendo announced a new "dedicated games platform with a brand new concept" with the codename "NX" that would be further revealed in 2016. Reggie Fils-Aimé, president of Nintendo of America, referred to NX as "our next home console" in a June 2015 interview with "The Wall Street Journal". In a later article from October 2015, "The Wall Street Journal" relayed speculation from unnamed inside sources that the NX was intended to feature "industry leading" hardware specifications and be usable as both a home and portable console. It was also reported that Nintendo had begun distributing software development kits (SDKs) for it to third-party developers, with the unnamed source further speculating that these moves suggested that the company was on track to introduce it as early as 2016. At an investor's meeting on 27 April 2016, Nintendo announced that the NX would be released worldwide in March 2017. In an interview with "Asahi Shimbun" in May 2016, Kimishima stated that the NX was a new concept that would not succeed the 3DS or Wii U product lines. At a shareholders' meeting following E3 2016, Shigeru Miyamoto stated that the company chose not to present the NX during the conference due to concerns that competitors could copy from it if they revealed it too soon. The same day, Kimishima also revealed during a Q&A session with investors that they were also researching virtual reality.

In May 2015, Universal Parks & Resorts announced that it was partnering with Nintendo to create attractions at Universal theme parks based upon Nintendo properties. In May 2016, Nintendo also expressed a desire to enter the animated film market. In November 2016, it was stated that the area to be created at Universal theme parks is known as Super Nintendo World, which will be completed by 2020 at Universal Studios Japan in time of the 2020 Tokyo Olympics, whereas Universal Orlando Resort and Universal Studios Hollywood will get the themed area in an unspecified date after the Japanese version.

In July 2016, the company announced it was bringing back the NES in the form of the NES Classic Edition (called Nintendo Classic Mini in Europe). The plug-and-play console supports HDMI, two-player mode, and has a controller similar to the original NES controller. The controller is able to connect to a Wii Remote for use with Wii and Wii U Virtual Console games. The NES Classic Edition came with 30 games pre-installed, including "Final Fantasy", "Kid Icarus", "The Legend of Zelda", "", and "Dr. Mario", among others. It was released in November 2016. Additional controllers were also available.

The July 2016 release of the "Pokémon Go" mobile app by Niantic caused shares in Nintendo to double, due to investor misunderstanding that the software was the property of Nintendo. Later that month, Nintendo released a statement clarifying its relation with Niantic, Nintendo stated it owned 32% of Pokémon intellectual property owner The Pokémon Company, and though it would receive some licensing and other revenues from the game it expected the impact on Nintendo's total income to be limited. As a result of the statement Nintendo's share price fell substantially, losing 17% in one day of trading. After a reduction in shareprice from the "Pokémon Go" peak, the company was still valued at over 100 times its net income, a price–earnings ratio greatly exceeding the average on the Nikkei 225. Analysts speaking to Bloomberg L.P. and the "Financial Times" both commented on the potential future value of Nintendo's IP if transferred to the mobile phone game business.

In August 2016, Nintendo of America sold 90% of its controlling stake (55%) in the Seattle Mariners to a group of investors led by mobile phone businessman John Stanton for $640 million.

After the announcement of the mobile game "Super Mario Run" in September 2016, Nintendo's stock soared to just under its recent high point after the release and success of "Pokémon Go" earlier in the year, something noted by journalists as even more significant than "Pokémon Go", as "Super Mario Run" was developed in-house by Nintendo, which was not the case with "Pokémon Go". In a December 2016 interview prior to the release of "Super Mario Run", Miyamoto explained that the company believed that with some of their game franchises, "the longer you continue to make a series, the more complex the gameplay becomes, and the harder it becomes for new players to be able to get into the series", and that the company sees mobile games with simplified controls, such as "Super Mario Run", not only allows them to "make a game that the broadest audience of people could play", but to also reintroduce these properties to newer audiences and draw them to their consoles.

On 20 October 2016, Nintendo released a preview trailer about the NX, revealing the official name to be the Nintendo Switch. According to Fils-Aimé, the console gave game developers new abilities to bring their creative concepts to life by opening up the concept of gaming without limits. In December 2016, Nintendo released "Super Mario Run" for iOS devices, with the game surpassing over 50 million downloads within a week of its release. Kimishima stated that Nintendo would release a couple of mobile games each year from then on.

In September 2017, Nintendo announced a partnership with the Chinese gaming company Tencent to publish a global version of their commercially successful mobile game, "Honor of Kings", for the Nintendo Switch. The announcement lead some to believe that Nintendo could soon have a bigger footprint in China, a region where the Switch is not sold and is largely dominated by Tencent. In November 2017, it was reported that Nintendo would be teaming up with Illumination, an animation division of Universal Pictures, to make an animated "Mario" film. In April 2018, Nintendo announced that Kimishima would be stepping down as company president that June, with Shuntaro Furukawa, former managing executive officer and outside director of The Pokémon Company, succeeding him.

In January 2019, Nintendo announced it had made $958 million in profit and $5.59 billion in revenue during 2018. In February 2019, Nintendo of America president Reggie Fils-Aimé announced that he would be retiring, with Doug Bowser succeeding him on 15 April 2019.

Released in 1977, Nintendo's Color TV-Game was Japan's best-selling first-generation console, with more than three million units sold.

The Nintendo Entertainment System (NES) is an 8-bit video game console, which released in North America in 1985, and in Europe throughout 1986 and 1987. The console was initially released in Japan as the Family Computer (abbreviated as Famicom) in 1983. The best-selling gaming console of its time, the NES helped revitalize the US video game industry following the video game crash of 1983. With the NES, Nintendo introduced a now-standard business model of licensing third-party developers, authorizing them to produce and distribute games for Nintendo's platform. The NES was bundled with "Super Mario Bros.", one of the best-selling video games of all time, and received ports of Nintendo's most popular arcade games.

Nintendo produced a limited run of the NES Classic Edition in 2016. The NES Classic System was a dedicated console modeled after an NES with 30 built-in classic first- and third-party games from the NES library. By the end of its production in April 2017, Nintendo shipped over two million units.

The Super Nintendo Entertainment System (Super NES or SNES) is a 16-bit video game console, which was released in North America in 1991, and in Europe in 1992. The console was initially released in Japan in 1990 as the Super Famicom, officially adopting the colloquially abbreviated name of its predecessor. The console introduced advanced graphics and sound capabilities compared with other consoles at the time. Soon, the development of a variety of enhancement chips which were integrated onto each new game cartridge's circuit boards, progressed the SNES's competitive edge. While even crude three-dimensional graphics had previously rarely been seen on home consoles, the Super NES's enhancement chips suddenly enabled a new caliber of games containing increasingly sophisticated faux 3D effects as seen in 1991's "Pilotwings" and 1992's "Super Mario Kart". Argonaut Games developed the Super FX chip in order to replicate 3D graphics from their earlier Atari ST and Amiga "Starglider" series on the Super NES (more specifically, "Starglider 2"), starting with "Star Fox" in 1993. The SNES is the bestselling console of the 16-bit era although having experienced a relatively late start and fierce competition from Sega's Mega Drive/Genesis console.

Nintendo also released a limited run of the Super NES Classic Edition in September 2017 through the end of the year. Like the NES Classic Edition, the Super NES Classic Edition is a dedicated console with 21 built-in games from its library, including the never-before-released "Star Fox 2".

The Nintendo 64 was released in 1996, featuring 3D polygon model rendering capabilities and built-in multiplayer for up to four players. The system's controller introduced the analog stick and later introduced the Rumble Pak, an accessory for the controller that produces force feedback with compatible games. Both are the first such features to have come to market for home console gaming and eventually became the "de facto" industry standard. Announced in 1995, prior to the console's 1996 launch, the 64DD ("DD" standing for "Disk Drive") was designed to enable the development of new genre of video games by way of 64 MB writable magnetic disks, video editing, and Internet connectivity. Eventually released only in Japan in 1999, the 64DD peripheral's commercial failure there resulted in only nine games being released and precluded further worldwide release.

The GameCube (officially called Nintendo GameCube, abbreviated NGC in Japan and GCN in North America) was released in 2001, in Japan and North America, and in 2002 worldwide. The sixth-generation console is the successor to the Nintendo 64 and competed with Sony's PlayStation 2, Microsoft's Xbox, and Sega's Dreamcast. The GameCube is the first Nintendo console to use optical discs as its primary storage medium. The discs are similar to the miniDVD format, but the system was not designed to play standard DVDs or audio CDs. Nintendo introduced a variety of connectivity options for the GameCube. The GameCube's game library has sparse support for Internet gaming, a feature that requires the use of the aftermarket GameCube Broadband Adapter and Modem Adapter. The GameCube supports connectivity to the Game Boy Advance, allowing players to access exclusive in-game features using the handheld as a second screen and controller.

The Wii was released during the holiday season of 2006 worldwide. The system features the Wii Remote controller, which can be used as a handheld pointing device and which detects movement in three dimensions. Another notable feature of the console is WiiConnect24, which enables it to receive messages and updates over the Internet while in standby mode. It also features a game download service, called "Virtual Console", which features emulated games from past systems. Since its release, the Wii has spawned many peripheral devices, including the Wii Balance Board and Motion Plus, and has had several hardware revisions. The "Wii Family Edition" variant is identical to the original model, but is designed to sit horizontally and removes the GameCube compatibility. The "Wii Mini" is a smaller, redesigned Wii which lacks GameCube compatibility, online connectivity, the SD card slot and Wi-Fi support, and has only one USB port unlike the previous models' two.

The Wii U, the successor to the Wii, was released during the holiday season of 2012 worldwide. The Wii U is the first Nintendo console to support high-definition graphics. The Wii U's primary controller is the Wii U GamePad, which features an embedded touchscreen. Each game may be designed to use this touchscreen as supplemental to the main TV, or as the only screen for Off-TV Play. The system supports most Wii controllers and accessories, and the more classically shaped Wii U Pro Controller. The system is backward compatible with Wii software and accessories; this mode also utilizes Wii-based controllers, and it optionally offers the GamePad as its primary Wii display and motion sensor bar. The console has various online services powered by Nintendo Network, including: the Nintendo eShop for online distribution of software and content; and Miiverse, a social network which can be variously integrated with games and applications. As of 31 March 2018, worldwide Wii U sales had totaled over 13 million units, with over 100 million games and other software for it sold.

On 17 March 2015, Nintendo announced a new "dedicated games platform with a brand new concept" with the codename "NX" that would be further revealed in 2016. Reggie Fils-Aimé, president of Nintendo of America at the time, referred to NX as "our next home console" in a June 2015 interview with "The Wall Street Journal". In a later article on 16 October 2015, "The Wall Street Journal" relayed speculation from unnamed inside sources that, although the NX hardware specifications were unknown, it may be intended to feature "industry leading" hardware specifications and include both a console and a mobile unit that could either be used with the console or taken on the road for separate use. It was also reported that Nintendo had begun distributing software development kits (SDKs) for NX to third-party developers, with the unnamed source further speculating that these moves "[suggest that] the company is on track to introduce [NX] as early as [2016]." At an investor's meeting on 27 April 2016, Nintendo announced that the NX would be released worldwide in March 2017. In an interview with Asahi Shimbun in May 2016, Kimishima referred to the NX as "neither the successor to the Wii U nor to the 3DS", as well as it being a "new way of playing games," but it would "slow Wii U sales" upon reveal and dissemination. In June 2016, Miyamoto stated that the reason Nintendo had not released any information on the "NX" up until that point was because they were afraid of imitators, saying he and Nintendo thought other companies could copy "an idea that [they're] working on." The same day, Kimishima revealed during a Q&A session with investors that they were also researching virtual reality. On 19 October 2016, Nintendo announced they would release a trailer for the console the following day. The next day, Nintendo unveiled the trailer that revealed the final name of the platform called Nintendo Switch. By March 2018, over 17 million Switch units had been sold worldwide.

Game & Watch is a line of handheld electronic games produced by Nintendo from 1980 to 1991. Created by game designer Gunpei Yokoi, they were originally conceived after Yokoi noticed a bored business man on the train playing around with his calculator, and each "Game & Watch" features a single game to be played on an LCD screen in addition to a clock, an alarm, or both. It was the earliest Nintendo product to garner major success.

After the success of the "Game & Watch" series, Yokoi developed the Game Boy handheld console, which was released in 1989. Eventually becoming the bestselling handheld of all time, the Game Boy remained dominant for more than a decade, seeing critically and commercially popular games such as "Pokémon Yellow" released as late as 1998 in Japan, 1999 in North America, and 2000 in Europe. Incremental updates of the Game Boy, including "Game Boy Pocket", "Game Boy Light" and "Game Boy Color", did little to change the original formula, though the latter introduced color graphics to the Game Boy line.

The first major update to its handheld line since 1989, the Game Boy Advance features improved technical specifications similar to those of the SNES. The "Game Boy Advance SP" was the first revision to the GBA line and introduced screen lighting and a clam shell design, while later iteration, the "Game Boy Micro", brought a smaller form factor.

Although originally advertised as an alternative to the Game Boy Advance, the Nintendo DS replaced the Game Boy line after its initial release in 2004. It was distinctive for its dual screens and a microphone, as well as a touch-sensitive lower screen. The "Nintendo DS Lite" brought a smaller form factor while the "Nintendo DSi" features larger screens and two cameras, and was followed by an even larger model, the "Nintendo DSi XL", with a 90% bigger screen.

Further expanding the Nintendo DS line, the Nintendo 3DS uses the process of autostereoscopy to produce a stereoscopic three-dimensional effect without glasses. Released to major markets during 2011, the 3DS got off to a slow start, initially missing many key features that were promised before the system launched. Partially as a result of slow sales, Nintendo stock declined in value. Subsequent price cuts and game releases helped to boost 3DS and 3DS software sales and to renew investor confidence in the company. As of August 2013, the 3DS was the best selling console in the United States for four consecutive months. The "Nintendo 3DS XL" was introduced in August 2012 and includes a 90% larger screen, a 4 GB SD card and extended battery life. In August 2013, Nintendo announced the cost-reduced "Nintendo 2DS", a version of the 3DS without the 3D display. It has a slate-like design as opposed to the hinged, clamshell design of its predecessors.

A hardware revision, "New Nintendo 3DS", was unveiled in August 2014. It is produced in a standard-sized model and a larger XL model; both models feature upgraded processors and additional RAM, an eye-tracking sensor to improve the stability of the autostereoscopic 3D image, colored face buttons, and near-field communication support for native use of Amiibo products. The standard-sized model also features slightly larger screens, and support for faceplate accessories.

The is a handheld game console by Nintendo. It was released on September 20, 2019 as a handheld-only version of the Switch console, and is considered the successor to the New Nintendo 3DS.

Nintendo of America has engaged in several high-profile marketing campaigns to define and position its brand. One of its earliest and most enduring slogans was "Now you're playing with power!", used first to promote its Nintendo Entertainment System. It modified the slogan to include "SUPER power" for the Super Nintendo Entertainment System, and "PORTABLE power" for the Game Boy. Its 1994 "Play It Loud!" campaign played upon teenage rebellion and fostered an edgy reputation. During the Nintendo 64 era, the slogan was "Get N or get out." During the GameCube era, the "Who Are You?" suggested a link between the games and the players' identities. The company promoted its Nintendo DS handheld with the tagline "Touching is Good." For the Wii, they used the "Wii would like to play" slogan to promote the console with the people who tried the games including "Super Mario Galaxy" and "Super Paper Mario". The Nintendo 3DS used the slogan "Take a look inside". The Wii U used the slogan "How U will play next." The Nintendo Switch uses the slogan "Switch and Play" in North America, and "Play anywhere, anytime, with anyone" in Europe.

Used since the 1960s, Nintendo's most recognizable logo is the racetrack shape, especially the red-colored wordmark on a white background, primarily used in the Western markets from 1985 to 2006. In Japan, a monochromatic version that lacks a colored background is on Nintendo's own Famicom, Super Famicom, Nintendo 64, GameCube, and handheld console packaging and marketing. Since 2006, in conjunction with the launch of the Wii, Nintendo changed its logo to a gray variant that lacks a colored background inside the wordmark, making it transparent. Nintendo's official, corporate logo remains this variation. For consumer products and marketing, a white variant on a red background has been used since 2015, and has been in full effect since the launch of the Nintendo Switch in 2017.




Nintendo's internal research and development operations are divided into three main divisions: Nintendo Entertainment Planning & Development (or EPD), the main software development division of Nintendo, which focuses on video game and software development; Nintendo Platform Technology Development (or PTD), which focuses on home and handheld video game console hardware development; and Nintendo Business Development (or NBD), which focuses on refining business strategy and is responsible for overseeing the smart device arm of the business.

The Nintendo Entertainment Planning & Development division is the primary software development division at Nintendo, formed as a merger between their former Entertainment Analysis & Development and Software Planning & Development divisions in 2015. Led by Shinya Takahashi, the division holds the largest concentration of staff at the company, housing more than 800 engineers and designers.

The Nintendo Platform Technology Development division is a combination of Nintendo's former Integrated Research & Development (or IRD) and System Development (or SDD) divisions. Led by Ko Shiota, the division is responsible for designing hardware and developing Nintendo's operating systems, developer environment and internal network as well as maintenance of the Nintendo Network.

The Nintendo Business Development division was formed following Nintendo's foray into software development for smart devices such as mobile phones and tablets. They are responsible for refining Nintendo's business model for the dedicated video game system business, and for furthering Nintendo's venture into development for smart devices.

Headquartered in Kyoto, Japan since the beginning, Nintendo Co., Ltd. oversees the organization's global operations and manages Japanese operations specifically. The company's two major subsidiaries, Nintendo of America and Nintendo of Europe, manage operations in North America and Europe respectively. Nintendo Co., Ltd. moved from its original Kyoto location to a new office in Higashiyama-ku, Kyoto, in 2000, this became the research and development building when the head office relocated to its location in Minami-ku, Kyoto.

Nintendo founded its North American subsidiary in 1980 as Nintendo of America (NoA). Hiroshi Yamauchi appointed his son-in-law Minoru Arakawa as president, who in turn hired his own wife and Yamauchi's daughter Yoko Yamauchi as the first employee. The Arakawa family moved from Vancouver to select an office in Manhattan, New York, due to its central status in American commerce. Both from extremely affluent families, their goals were set more by achievement than moneyand all their seed capital and products would now also be automatically inherited from Nintendo in Japan, and their inaugural target is the existing $8 billion-per-year coin-op arcade video game market and largest entertainment industry in the US, which already outclassed movies and television combined. During the couple's arcade research excursions, NoA hired gamer youths to work in the filthy, hot, ratty warehouse in New Jersey for the receiving and service of game hardware from Japan.

In late 1980 NoA contracted the Seattle-based arcade sales and distribution company Far East Video, consisting solely of experienced arcade salespeople Ron Judy and Al Stone. The two had already built a decent reputation and a distribution network, founded specifically for the independent import and sales of games from Nintendo because the Japanese company had for years been the under-represented maverick in America. Now as direct associates to the new NoA, they told Arakawa they could always clear all Nintendo inventory if Nintendo produced better games. Far East Video took NoA's contract for a fixed per-unit commission on the exclusive American distributorship of Nintendo games, to be settled by their Seattle-based lawyer, Howard Lincoln.

Based on favorable test arcade sites in Seattle, Arakawa wagered most of NoA's modest finances on a huge order of 3,000 "Radar Scope" cabinets. He panicked when the game failed in the fickle market upon its arrival from its four-month boat ride from Japan. Far East Video was already in financial trouble due to declining sales and Ron Judy borrowed his aunt's life savings of $50,000, while still hoping Nintendo would develop its first "Pac-Man"-sized hit. Arakawa regretted founding the Nintendo subsidiary, with the distressed Yoko trapped between her arguing husband and father.

Amid financial threat, Nintendo of America relocated from Manhattan to the Seattle metro to remove major stressors: the frenetic New York and New Jersey lifestyle and commute, and the extra weeks or months on the shipping route from Japan as was suffered by the "Radar Scope" disaster. With the Seattle harbor being the US's closest to Japan at only nine days by boat, and having a lumber production market for arcade cabinets, Arakawa's real estate scouts found a warehouse for rent containing three officesone for Arakawa and one for Judy and Stone. This warehouse in the Tukwila suburb was owned by Mario Segale after whom the Mario character would be named, and was initially managed by former Far East Video employee Don James. After one month, James recruited his college friend Howard Phillips as assistant, who soon took over as warehouse manager. The company remained at fewer than 10 employees for some time, handling sales, marketing, advertising, distribution, and limited manufacturing of arcade cabinets and "Game & Watch" handheld units, all sourced and shipped from Nintendo.

Arakawa was still panicked over NoA's ongoing financial crisis. With the parent company having no new game ideas, he had been repeatedly pleading for Yamauchi to reassign some top talent away from existing Japanese products to develop something for Americaespecially to redeem the massive dead stock of "Radar Scope" cabinets. Since all of Nintendo's key engineers and programmers were busy, and with NoA representing only a tiny fraction of the parent's overall business, Yamauchi allowed only the assignment of Gunpei Yokoi's young assistant who had no background in engineering, Shigeru Miyamoto.

NoA's staffexcept the sole young gamer Howard Phillipswere uniformly revolted at the sight of the freshman developer Miyamoto's debut game, which they had imported in the form of emergency conversion kits for the overstock of "Radar Scope" cabinets. The kits transformed the cabinets into NoA's massive windfall gain of from Miyamoto's smash hit "Donkey Kong" in 1981–1983 alone. They sold 4,000 new arcade units each month in America, making the 24-year-old Phillips "the largest volume shipping manager for the entire Port of Seattle". Arakawa used these profits to buy of land in Redmond in July 1982 and to perform the $50 million launch of the Nintendo Entertainment System in 1985 which revitalized the entire video game industry from its devastating 1983 crash. A second warehouse in Redmond was soon secured, and managed by Don James. The company stayed at around 20 employees for some years.

The organization was reshaped nationwide in the following decades, and those core sales and marketing business functions are now directed by the office in Redwood City, California. The company's distribution centers are Nintendo Atlanta in Atlanta, Georgia, and Nintendo North Bend in North Bend, Washington. , the Nintendo North Bend facility processes more than 20,000 orders a day to Nintendo customers, which include retail stores that sell Nintendo products in addition to consumers who shop Nintendo's website. Nintendo of America operates two retail stores in the United States: Nintendo New York on Rockefeller Plaza in New York City, which is open to the public; and Nintendo Redmond, co-located at NoA headquarters in Redmond, Washington, which is open only to Nintendo employees and invited guests. Nintendo of America's Canadian branch, Nintendo of Canada, is based in Vancouver, British Columbia with a distribution center in Toronto, Ontario. Nintendo Treehouse is NoA's localization team, composed of around 80 staff who are responsible for translating text from Japanese to English, creating videos and marketing plans, and quality assurance.

Nintendo's European subsidiary was established in June 1990, based in Großostheim, Germany. The company handles operations across Europe excluding Scandinavia, as well as South Africa. Nintendo of Europe's United Kingdom branch (Nintendo UK) handles operations in that country and in Ireland from its headquarters in Windsor, Berkshire. In June 2014, NOE initiated a reduction and consolidation process, yielding a combined 130 layoffs: the closing of its office and warehouse, and termination of all employment, in Großostheim; and the consolidation of all of those operations into, and terminating some employment at, its Frankfurt location. As of July 2018, the company employs 850 people.

Nintendo's Australian subsidiary is based in Melbourne, Victoria. It handles the publishing, distribution, sales, and marketing of Nintendo products in Australia, New Zealand, and Oceania (Cook Islands, Fiji, New Caledonia, Papua New Guinea, Samoa, and Vanuatu). It also manufactures some Wii games locally. Nintendo Australia is also a third-party distributor of some games from Rising Star Games, Bandai Namco Entertainment, Atlus, The Tetris Company, Sega, Koei Tecmo, and Capcom.

Originally a Chinese joint venture between its founder, Wei Yen, and Nintendo, manufactures and distributes official Nintendo consoles and games for the mainland Chinese market, under the iQue brand. The product lineup for the Chinese market is considerably different from that for other markets. For example, Nintendo's only console in China is the iQue Player, a modified version of the Nintendo 64. In 2013, the company became a fully owned subsidiary of Nintendo.

Nintendo's South Korean subsidiary was established on 7 July 2006, and is based in Seoul. In March 2016, the subsidiary was heavily downsized due to a corporate restructuring after analyzing shifts in the current market, laying off 80% of its employees, leaving only ten people, including CEO Hiroyuki Fukuda. This did not affect any games scheduled for release in South Korea, and Nintendo continued operations there as usual.

Although most of the research and development is being done in Japan, there are some R&D facilities in the United States, Europe and China that are focused on developing software and hardware technologies used in Nintendo products. Although they all are subsidiaries of Nintendo (and therefore first party), they are often referred to as external resources when being involved in joint development processes with Nintendo's internal developers by the Japanese personal involved. This can be seen in the "Iwata asks..." interview series. Nintendo Software Technology (NST) and Nintendo Technology Development (NTD) are located in Redmond, Washington, United States, while Nintendo European Research & Development ("NERD") is located in Paris, France, and Nintendo Network Service Database (NSD) is located in Kyoto, Japan.

Most external first-party software development is done in Japan, since the only overseas subsidiary is Retro Studios in the United States. Although these studios are all subsidiaries of Nintendo, they are often referred to as external resources when being involved in joint development processes with Nintendo's internal developers by the Nintendo Entertainment Planning & Development (EPD) division. 1-Up Studio and Nd Cube are located in Tokyo, Japan, while Monolith Soft has one studio located in Tokyo and another in Kyoto. Retro Studios is located in Austin, Texas.

Nintendo also established The Pokémon Company alongside Creatures and Game Freak in order to effectively manage the Pokémon brand. Similarly, Warpstar Inc. was formed through a joint investment with HAL Laboratory, which was in charge of the "" animated series.

Bergsala, a third-party company based in Sweden, exclusively handles Nintendo operations in the Scandinavian region. Bergsala's relationship with Nintendo was established in 1981 when the company sought to distribute "Game & Watch" units to Sweden, which later expanded to the NES console by 1986. Bergsala is the only non-Nintendo owned distributor of Nintendo's products.

Nintendo has partnered with Tencent to release Nintendo products in China, following the lifting of the country's console ban in 2015. In addition to distributing hardware, Tencent will help bring Nintendo's games through the governmental approval process for video game software.

For many years, Nintendo had a policy of strict content guidelines for video games published on its consoles. Although Nintendo allowed graphic violence in its video games released in Japan, nudity and sexuality were strictly prohibited. Former Nintendo president Hiroshi Yamauchi believed that if the company allowed the licensing of pornographic games, the company's image would be forever tarnished. Nintendo of America went further in that games released for Nintendo consoles could not feature nudity, sexuality, profanity (including racism, sexism or slurs), blood, graphic or domestic violence, drugs, political messages or religious symbols (with the exception of widely unpracticed religions, such as the Greek Pantheon). The Japanese parent company was concerned that it may be viewed as a "Japanese Invasion" by forcing Japanese community standards on North American and European children. Past the strict guidelines, some exceptions have occurred: "Bionic Commando" (though swastikas were eliminated in the US version), "Smash TV" and "" contain human violence, the latter also containing implied sexuality and tobacco use; "River City Ransom" and "" contain nudity, and the latter also contains religious images, as do "" and "".

A known side effect of this policy is the Genesis version of "Mortal Kombat" having more than double the unit sales of the Super NES version, mainly because Nintendo had forced publisher Acclaim to recolor the red blood to look like white sweat and replace some of the more gory graphics in its release of the game, making it less violent. By contrast, Sega allowed blood and gore to remain in the Genesis version (though a code is required to unlock the gore). Nintendo allowed the Super NES version of "Mortal Kombat II" to ship uncensored the following year with a content warning on the packaging.

Video game ratings systems were introduced with the Entertainment Software Rating Board of 1994 and the Pan European Game Information of 2003, and Nintendo discontinued most of its censorship policies in favor of consumers making their own choices. Today, changes to the content of games are done primarily by the game's developer or, occasionally, at the request of Nintendo. The only clear-set rule is that ESRB AO-rated games will not be licensed on Nintendo consoles in North America, a practice which is also enforced by Sony and Microsoft, its two greatest competitors in the present market. Nintendo has since allowed several mature-content games to be published on its consoles, including these: "Perfect Dark", "Conker's Bad Fur Day", "Doom", "Doom 64", "BMX XXX", the "Resident Evil" series, "Killer7", the "Mortal Kombat" series, "", "BloodRayne", "Geist", "", "Bayonetta 2", "Devil's Third", and "". Certain games have continued to be modified, however. For example, Konami was forced to remove all references to cigarettes in the 2000 Game Boy Color game "Metal Gear Solid" (although the previous NES version of "Metal Gear" and the subsequent GameCube game "" both included such references, as did Wii game "MadWorld"), and maiming and blood were removed from the Nintendo 64 port of "Cruis'n USA". Another example is in the Game Boy Advance game "Mega Man Zero 3", in which one of the bosses, called Hellbat Schilt in the Japanese and European releases, was renamed Devilbat Schilt in the North American localization. In North America releases of the "Mega Man Zero" games, enemies and bosses killed with a saber attack do not gush blood as they do in the Japanese versions. However, the release of the Wii was accompanied by a number of even more controversial games, such as "Manhunt 2", "No More Heroes", "", and "MadWorld", the latter three of which were published exclusively for the console.

Nintendo of America also had guidelines before 1993 that had to be followed by its licensees to make games for the Nintendo Entertainment System, in addition to the above content guidelines. Guidelines were enforced through the 10NES lockout chip.

The last rule was circumvented in a number of ways; for example, Konami, wanting to produce more games for Nintendo's consoles, formed Ultra Games and later Palcom to produce more games as a technically different publisher. This disadvantaged smaller or emerging companies, as they could not afford to start additional companies. In another side effect, Square Co (now Square Enix) executives have suggested that the price of publishing games on the Nintendo 64 along with the degree of censorship and control that Nintendo enforced over its games, most notably "Final Fantasy VI", were factors in switching its focus towards Sony's PlayStation console.

In 1993, a class action suit was taken against Nintendo under allegations that their lockout chip enabled unfair business practices. The case was settled, with the condition that California consumers were entitled to a $3 discount coupon for a game of Nintendo's choice.

Nintendo has generally been proactive to assure its intellectual property in both hardware and software is protected. With the NES system, Nintendo employed a lock-out system that only allowed authorizes game cartridges they manufactured to be playable on the system.

Nintendo has used emulation by itself or licensed from third parties to provide means to re-release games from their older platforms on newer systems, with Virtual Console, which re-released classic games as downloadable titles, the NES and SNES library for Nintendo Switch Online subscribers, and with dedicated consoles like the NES Mini and SNES Mini. However, Nintendo has taken a hard stance against unlicensed emulation of its video games and consoles, stating that it is the single largest threat to the intellectual property rights of video game developers.

In recent years, Nintendo has taken legal action against sites that knowingly distribute ROM images of their games. On 19 July 2018, Nintendo sued Jacob Mathias, the owner of ROM image distribution websites LoveROMs and LoveRetro, for "brazen and mass-scale infringement of Nintendo's intellectual property rights." Nintendo settled with Mathias in November 2018 for more than along with relinquishing all ROM images in their ownership. While Nintendo is likely to have agreed to a smaller fine in private, the large amount was seen as a deterrent to prevent similar sites from sharing ROM images. Nintendo filed a separate suit against RomUniverse in September 2019 which also offered infringing copies of Nintendo DS and Switch games in addition to ROM images. Nintendo also successfully won a suit in the United Kingdom that same month to force the major Internet service providers in the country to block access to sites that offered copyright-infringing copies of Switch software or hacks for the Nintendo Switch to run unauthorized software.

Further, Nintendo has taken action against fan-made games which have used significant facets of their IP, issuing cease & desist letters to these projects or Digital Millennium Copyright Act-related complaints to services that host these projects.

The gold sunburst seal was first used by Nintendo of America, and later Nintendo of Europe. It is displayed on any game, system, or accessory licensed for use on one of its video game consoles, denoting the game has been properly approved by Nintendo. The seal is also displayed on any Nintendo-licensed merchandise, such as trading cards, game guides, or apparel, albeit with the words "Official Nintendo Licensed Product".

In 2008, game designer Sid Meier cited the Seal of Quality as one of the three most important innovations in video game history, as it helped set a standard for game quality that protected consumers from shovelware.

In NTSC regions, this seal is an elliptical starburst named the "Official Nintendo Seal". Originally, for NTSC countries, the seal was a large, black and gold circular starburst. The seal read as follows: "This seal is your assurance that NINTENDO has approved and guaranteed the quality of this product." This seal was later altered in 1988: "approved and guaranteed" was changed to "evaluated and approved." In 1989, the seal became gold and white, as it currently appears, with a shortened phrase, "Official Nintendo Seal of Quality." It was changed in 2003 to read "Official Nintendo Seal."

The seal currently reads:
In PAL regions, the seal is a circular starburst named the "Original Nintendo Seal of Quality." Text near the seal in the Australian Wii manual states:
In 1992, Nintendo teamed with the Starlight Children's Foundation to build Starlight Fun Center mobile entertainment units and install them in hospitals. 1,000 Starlight Nintendo Fun Center units were installed by the end of 1995. These units combine several forms of multimedia entertainment, including gaming, and serve as a distraction to brighten moods and boost kids' morale during hospital stays.

Nintendo has consistently been ranked last in Greenpeace's "Guide to Greener Electronics" due to Nintendo's failure to publish information. Similarly, they are ranked last in the Enough Project's "Conflict Minerals Company Rankings" due to Nintendo's refusal to respond to multiple requests for information.

Like many other electronics companies, Nintendo offers a take-back recycling program which allows customers to mail in old products they no longer use. Nintendo of America claimed that it took in 548 tons of returned products in 2011, 98% of which was either reused or recycled.

During the peak of Nintendo's success in the video game industry in the 1990s, their name was ubiquitously used to refer to any video game console, regardless of the manufacturer. To prevent their trademark from becoming generic, Nintendo pushed usage of the term "game console", and succeeded in preserving their trademark.




</doc>
<doc id="21201" url="https://en.wikipedia.org/wiki?curid=21201" title="Nobel Prize">
Nobel Prize

The Nobel Prize (, ; , ; ) is a set of annual international awards bestowed in several categories by Swedish and Norwegian institutions in recognition of academic, cultural, or scientific advances. The will of the Swedish chemist, engineer and industrialist Alfred Nobel established the five Nobel prizes in 1895. The prizes in Chemistry, Literature, Peace, Physics, and Physiology or Medicine were first awarded in 1901. The prizes are widely regarded as the most prestigious awards available in their respective fields.

In 1968, Sveriges Riksbank, Sweden's central bank, established the Sveriges Riksbank Prize in Economic Sciences in Memory of Alfred Nobel. The award is based on a donation received by the Nobel Foundation in 1968 from Sveriges Riksbank on the occasion of the bank's 300th anniversary. The first Prize in Economic Sciences was awarded to Ragnar Frisch and Jan Tinbergen in 1969. The Prize in Economic Sciences is awarded by the Royal Swedish Academy of Sciences, Stockholm, Sweden, according to the same principles as for the Nobel Prizes that have been awarded since 1901.

The Royal Swedish Academy of Sciences awards the Nobel Prize in Chemistry, the Nobel Prize in Physics, and the Sveriges Riksbank Prize in Economic Sciences in Memory of Alfred Nobel; the Nobel Assembly at the Karolinska Institute awards the Nobel Prize in Physiology or Medicine; the Swedish Academy grants the Nobel Prize in Literature; and the Norwegian Nobel Committee awards the Nobel Peace Prize.

Between 1901 and 2018, the Nobel Prizes (and the Prizes in Economic Sciences, from 1969 on) were awarded 590 times to 935 people and organizations. With some receiving the Nobel Prize more than once, this makes a total of 27 organizations and 908 individuals. The prize ceremonies take place annually in Stockholm, Sweden (with the exception of the Peace Prize ceremony, which is held in Oslo, Norway). Each recipient (known as a "laureate") receives a gold medal, a diploma, and a sum of money that has been decided by the Nobel Foundation. (, each prize is worth 9,000,000 SEK, or about , €848,678, or £716,224.) Medals made before 1980 were struck in 23-carat gold, and later in 18-carat green gold plated with a 24-carat gold coating.

The prize is not awarded posthumously; however, if a person is awarded a prize and dies before receiving it, the prize may still be presented. A prize may not be shared among more than three individuals, although the Nobel Peace Prize can be awarded to organizations of more than three people.

Alfred Nobel () was born on 21 October 1833 in Stockholm, Sweden, into a family of engineers. He was a chemist, engineer, and inventor. In 1894, Nobel purchased the Bofors iron and steel mill, which he made into a major armaments manufacturer. Nobel also invented ballistite. This invention was a precursor to many smokeless military explosives, especially the British smokeless powder cordite. As a consequence of his patent claims, Nobel was eventually involved in a patent infringement lawsuit over cordite. Nobel amassed a fortune during his lifetime, with most of his wealth coming from his 355 inventions, of which dynamite is the most famous.

In 1888, Nobel was astonished to read his own obituary, titled "The merchant of death is dead", in a French newspaper. It was Alfred's brother Ludvig who had died; the obituary was eight years premature. The article disconcerted Nobel and made him apprehensive about how he would be remembered. This inspired him to change his will. On 10 December 1896, Alfred Nobel died in his villa in San Remo, Italy, from a cerebral haemorrhage. He was 63 years old.

Nobel wrote several wills during his lifetime. He composed the last over a year before he died, signing it at the Swedish–Norwegian Club in Paris on 27 November 1895. To widespread astonishment, Nobel's last will specified that his fortune be used to create a series of prizes for those who confer the "greatest benefit on mankind" in physics, chemistry, physiology or medicine, literature, and peace. Nobel bequeathed 94% of his total assets, 31 million SEK (c. US$186 million, €150 million in 2008), to establish the five Nobel Prizes. Owing to skepticism surrounding the will, it was not approved by the Storting in Norway until 26 April 1897. The executors of the will, Ragnar Sohlman and Rudolf Lilljequist, formed the Nobel Foundation to take care of the fortune and to organise the awarding of prizes.

Nobel's instructions named a Norwegian Nobel Committee to award the Peace Prize, the members of whom were appointed shortly after the will was approved in April 1897. Soon thereafter, the other prize-awarding organizations were designated. These were Karolinska Institute on 7 June, the Swedish Academy on 9 June, and the Royal Swedish Academy of Sciences on 11 June. The Nobel Foundation reached an agreement on guidelines for how the prizes should be awarded; and, in 1900, the Nobel Foundation's newly created statutes were promulgated by King Oscar II. In 1905, the personal union between Sweden and Norway was dissolved.

According to his will and testament read in Stockholm on 30 December 1896, a foundation established by Alfred Nobel would reward those who serve humanity. The Nobel Prize was funded by Alfred Nobel's personal fortune. According to the official sources, Alfred Nobel bequeathed from the shares 94% of his fortune to the Nobel Foundation that now forms the economic base of the Nobel Prize.

The Nobel Foundation was founded as a private organization on 29 June 1900. Its function is to manage the finances and administration of the Nobel Prizes. In accordance with Nobel's will, the primary task of the Foundation is to manage the fortune Nobel left. Robert and Ludvig Nobel were involved in the oil business in Azerbaijan, and according to Swedish historian E. Bargengren, who accessed the Nobel family archive, it was this "decision to allow withdrawal of Alfred's money from Baku that became the decisive factor that enabled the Nobel Prizes to be established". Another important task of the Nobel Foundation is to market the prizes internationally and to oversee informal administration related to the prizes. The Foundation is not involved in the process of selecting the Nobel laureates. In many ways, the Nobel Foundation is similar to an investment company, in that it invests Nobel's money to create a solid funding base for the prizes and the administrative activities. The Nobel Foundation is exempt from all taxes in Sweden (since 1946) and from investment taxes in the United States (since 1953). Since the 1980s, the Foundation's investments have become more profitable and as of 31 December 2007, the assets controlled by the Nobel Foundation amounted to 3.628 billion Swedish "kronor" (c. US$560 million).

According to the statutes, the Foundation consists of a board of five Swedish or Norwegian citizens, with its seat in Stockholm. The Chairman of the Board is appointed by the Swedish King in Council, with the other four members appointed by the trustees of the prize-awarding institutions. An Executive Director is chosen from among the board members, a Deputy Director is appointed by the King in Council, and two deputies are appointed by the trustees. However, since 1995, all the members of the board have been chosen by the trustees, and the Executive Director and the Deputy Director appointed by the board itself. As well as the board, the Nobel Foundation is made up of the prize-awarding institutions (the Royal Swedish Academy of Sciences, the Nobel Assembly at Karolinska Institute, the Swedish Academy, and the Norwegian Nobel Committee), the trustees of these institutions, and auditors.

The capital of the Nobel Foundation today is invested 50% in shares, 20% bonds and 30% other investments (e.g. hedge funds or real estate). The distribution can vary by 10 percent. At the beginning of 2008, 64% of the funds were invested mainly in American and European stocks, 20% in bonds, plus 12% in real estate and hedge funds.

In 2011, the total annual cost was approximately 120 million krona, with 50 million krona as the prize money. Further costs to pay institutions and persons engaged in giving the prizes were 27.4 million krona. The events during the Nobel week in Stockholm and Oslo cost 20.2 million krona. The administration, Nobel symposium, and similar items had costs of 22.4 million krona. The cost of the Economic Sciences prize of 16.5 Million krona is paid by the Sveriges Riksbank.

Once the Nobel Foundation and its guidelines were in place, the Nobel Committees began collecting nominations for the inaugural prizes. Subsequently, they sent a list of preliminary candidates to the prize-awarding institutions.

The Nobel Committee's Physics Prize shortlist cited Wilhelm Röntgen's discovery of X-rays and Philipp Lenard's work on cathode rays. The Academy of Sciences selected Röntgen for the prize. In the last decades of the 19th century, many chemists had made significant contributions. Thus, with the Chemistry Prize, the Academy "was chiefly faced with merely deciding the order in which these scientists should be awarded the prize". The Academy received 20 nominations, eleven of them for Jacobus van 't Hoff. Van 't Hoff was awarded the prize for his contributions in chemical thermodynamics.

The Swedish Academy chose the poet Sully Prudhomme for the first Nobel Prize in Literature. A group including 42 Swedish writers, artists, and literary critics protested against this decision, having expected Leo Tolstoy to be awarded. Some, including Burton Feldman, have criticised this prize because they consider Prudhomme a mediocre poet. Feldman's explanation is that most of the Academy members preferred Victorian literature and thus selected a Victorian poet. The first Physiology or Medicine Prize went to the German physiologist and microbiologist Emil von Behring. During the 1890s, von Behring developed an antitoxin to treat diphtheria, which until then was causing thousands of deaths each year.

The first Nobel Peace Prize went to the Swiss Jean Henri Dunant for his role in founding the International Red Cross Movement and initiating the Geneva Convention, and jointly given to French pacifist Frédéric Passy, founder of the Peace League and active with Dunant in the Alliance for Order and Civilization.

In 1938 and 1939, Adolf Hitler's Third Reich forbade three laureates from Germany (Richard Kuhn, Adolf Friedrich Johann Butenandt, and Gerhard Domagk) from accepting their prizes. Each man was later able to receive the diploma and medal. Even though Sweden was officially neutral during the Second World War, the prizes were awarded irregularly. In 1939, the Peace Prize was not awarded. No prize was awarded in any category from 1940 to 1942, due to the occupation of Norway by Germany. In the subsequent year, all prizes were awarded except those for literature and peace.

During the occupation of Norway, three members of the Norwegian Nobel Committee fled into exile. The remaining members escaped persecution from the Germans when the Nobel Foundation stated that the Committee building in Oslo was Swedish property. Thus it was a safe haven from the German military, which was not at war with Sweden. These members kept the work of the Committee going, but did not award any prizes. In 1944, the Nobel Foundation, together with the three members in exile, made sure that nominations were submitted for the Peace Prize and that the prize could be awarded once again.

In 1968, Sweden's central bank Sveriges Riksbank celebrated its 300th anniversary by donating a large sum of money to the Nobel Foundation to be used to set up a prize in honour of Alfred Nobel. The following year, the Sveriges Riksbank Prize in Economic Sciences in Memory of Alfred Nobel was awarded for the first time. The Royal Swedish Academy of Sciences became responsible for selecting laureates. The first laureates for the Economics Prize were Jan Tinbergen and Ragnar Frisch "for having developed and applied dynamic models for the analysis of economic processes". The Board of the Nobel Foundation decided that after this addition, it would allow no further new prizes.

The award process is similar for all of the Nobel Prizes, the main difference being who can make nominations for each of them.
Nomination forms are sent by the Nobel Committee to about 3,000 individuals, usually in September the year before the prizes are awarded. These individuals are generally prominent academics working in a relevant area. Regarding the Peace Prize, inquiries are also sent to governments, former Peace Prize laureates, and current or former members of the Norwegian Nobel Committee. The deadline for the return of the nomination forms is 31 January of the year of the award. The Nobel Committee nominates about 300 potential laureates from these forms and additional names. The nominees are not publicly named, nor are they told that they are being considered for the prize. All nomination records for a prize are sealed for 50 years from the awarding of the prize.

The Nobel Committee then prepares a report reflecting the advice of experts in the relevant fields. This, along with the list of preliminary candidates, is submitted to the prize-awarding institutions. The institutions meet to choose the laureate or laureates in each field by a majority vote. Their decision, which cannot be appealed, is announced immediately after the vote. A maximum of three laureates and two different works may be selected per award. Except for the Peace Prize, which can be awarded to institutions, the awards can only be given to individuals.

Although posthumous nominations are not presently permitted, individuals who died in the months between their nomination and the decision of the prize committee were originally eligible to receive the prize. This has occurred twice: the 1931 Literature Prize awarded to Erik Axel Karlfeldt, and the 1961 Peace Prize awarded to UN Secretary General Dag Hammarskjöld. Since 1974, laureates must be thought alive at the time of the October announcement. There has been one laureate, William Vickrey, who in 1996 died after the prize (in Economics) was announced but before it could be presented. On 3 October 2011, the laureates for the Nobel Prize in Physiology or Medicine were announced; however, the committee was not aware that one of the laureates, Ralph M. Steinman, had died three days earlier. The committee was debating about Steinman's prize, since the rule is that the prize is not awarded posthumously. The committee later decided that as the decision to award Steinman the prize "was made in good faith", it would remain unchanged.

Nobel's will provided for prizes to be awarded in recognition of discoveries made "during the preceding year". Early on, the awards usually recognised recent discoveries. However, some of those early discoveries were later discredited. For example, Johannes Fibiger was awarded the 1926 Prize in Physiology or Medicine for his purported discovery of a parasite that caused cancer. To avoid repeating this embarrassment, the awards increasingly recognised scientific discoveries that had withstood the test of time. According to Ralf Pettersson, former chairman of the Nobel Prize Committee for Physiology or Medicine, "the criterion 'the previous year' is interpreted by the Nobel Assembly as the year when the full impact of the discovery has become evident."
The interval between the award and the accomplishment it recognises varies from discipline to discipline. The Literature Prize is typically awarded to recognise a cumulative lifetime body of work rather than a single achievement. The Peace Prize can also be awarded for a lifetime body of work. For example, 2008 laureate Martti Ahtisaari was awarded for his work to resolve international conflicts. However, they can also be awarded for specific recent events. For instance, Kofi Annan was awarded the 2001 Peace Prize just four years after becoming the Secretary-General of the United Nations. Similarly Yasser Arafat, Yitzhak Rabin, and Shimon Peres received the 1994 award, about a year after they successfully concluded the Oslo Accords.

Awards for physics, chemistry, and medicine are typically awarded once the achievement has been widely accepted. Sometimes, this takes decades – for example, Subrahmanyan Chandrasekhar shared the 1983 Physics Prize for his 1930s work on stellar structure and evolution. Not all scientists live long enough for their work to be recognised. Some discoveries can never be considered for a prize if their impact is realised after the discoverers have died.

Except for the Peace Prize, the Nobel Prizes are presented in Stockholm, Sweden, at the annual Prize Award Ceremony on 10 December, the anniversary of Nobel's death. The recipients' lectures are normally held in the days prior to the award ceremony. The Peace Prize and its recipients' lectures are presented at the annual Prize Award Ceremony in Oslo, Norway, usually on 10 December. The award ceremonies and the associated banquets are typically major international events. The Prizes awarded in Sweden's ceremonies' are held at the Stockholm Concert Hall, with the Nobel banquet following immediately at Stockholm City Hall. The Nobel Peace Prize ceremony has been held at the Norwegian Nobel Institute (1905–1946), at the auditorium of the University of Oslo (1947–1989), and at Oslo City Hall (1990–present).

The highlight of the Nobel Prize Award Ceremony in Stockholm occurs when each Nobel laureate steps forward to receive the prize from the hands of the King of Sweden. In Oslo, the Chairman of the Norwegian Nobel Committee presents the Nobel Peace Prize in the presence of the King of Norway. At first, King Oscar II did not approve of awarding grand prizes to foreigners. It is said that he changed his mind once his attention had been drawn to the publicity value of the prizes for Sweden.

After the award ceremony in Sweden, a banquet is held in the Blue Hall at the Stockholm City Hall, which is attended by the Swedish Royal Family and around 1,300 guests. The Nobel Peace Prize banquet is held in Norway at the Oslo Grand Hotel after the award ceremony. Apart from the laureate, guests include the President of the Storting, on occasion the Swedish prime minister, and, since 2006, the King and Queen of Norway. In total, about 250 guests attend.

According to the statutes of the Nobel Foundation, each laureate is required to give a public lecture on a subject related to the topic of their prize. The Nobel lecture as a rhetorical genre took decades to reach its current format. These lectures normally occur during Nobel Week (the week leading up to the award ceremony and banquet, which begins with the laureates arriving in Stockholm and normally ends with the Nobel banquet), but this is not mandatory. The laureate is only obliged to give the lecture within six months of receiving the prize, but some have happened even later. For example, US President Theodore Roosevelt received the Peace Prize in 1906 but gave his lecture in 1910, after his term in office. The lectures are organized by the same association which selected the laureates.

The Nobel Foundation announced on 30 May 2012 that it had awarded the contract for the production of the five (Swedish) Nobel Prize medals to Svenska Medalj AB. Between 1902 and 2010, the Nobel Prize medals were minted by Myntverket (the Swedish Mint), Sweden's oldest company, which ceased operations in 2011 after 107 years. In 2011, the Mint of Norway, located in Kongsberg, made the medals. The Nobel Prize medals are registered trademarks of the Nobel Foundation.

Each medal features an image of Alfred Nobel in left profile on the obverse. The medals for physics, chemistry, physiology or medicine, and literature have identical obverses, showing the image of Alfred Nobel and the years of his birth and death. Nobel's portrait also appears on the obverse of the Peace Prize medal and the medal for the Economics Prize, but with a slightly different design. For instance, the laureate's name is engraved on the rim of the Economics medal. The image on the reverse of a medal varies according to the institution awarding the prize. The reverse sides of the medals for chemistry and physics share the same design.

All medals made before 1980 were struck in 23 carat gold. Since then, they have been struck in 18 carat green gold plated with 24 carat gold. The weight of each medal varies with the value of gold, but averages about for each medal. The diameter is and the thickness varies between and . Because of the high value of their gold content and tendency to be on public display, Nobel medals are subject to medal theft. During World War II, the medals of German scientists Max von Laue and James Franck were sent to Copenhagen for safekeeping. When Germany invaded Denmark, Hungarian chemist (and Nobel laureate himself) George de Hevesy dissolved them in aqua regia (nitro-hydrochloric acid), to prevent confiscation by Nazi Germany and to prevent legal problems for the holders. After the war, the gold was recovered from solution, and the medals re-cast.

Nobel laureates receive a diploma directly from the hands of the King of Sweden, or in the case of the peace prize, the Chairman of the Norwegian Nobel Committee. Each diploma is uniquely designed by the prize-awarding institutions for the laureates that receive them. The diploma contains a picture and text in Swedish which states the name of the laureate and normally a citation of why they received the prize. None of the Nobel Peace Prize laureates has ever had a citation on their diplomas.

The laureates are given a sum of money when they receive their prizes, in the form of a document confirming the amount awarded. The amount of prize money depends upon how much money the Nobel Foundation can award each year. The purse has increased since the 1980s, when the prize money was 880,000 SEK per prize (c. 2.6 million SEK altogether, US$350,000 today). In 2009, the monetary award was 10 million SEK (US$1.4 million). In June 2012, it was lowered to 8 million SEK. If two laureates share the prize in a category, the award grant is divided equally between the recipients. If there are three, the awarding committee has the option of dividing the grant equally, or awarding one-half to one recipient and one-quarter to each of the others. It is common for recipients to donate prize money to benefit scientific, cultural, or humanitarian causes.

Among other criticisms, the Nobel Committees have been accused of having a political agenda, and of omitting more deserving candidates. They have also been accused of Eurocentrism, especially for the Literature Prize.


Among the most criticised Nobel Peace Prizes was the one awarded to Henry Kissinger and Lê Đức Thọ. This led to the resignation of two Norwegian Nobel Committee members. Kissinger and Thọ were awarded the prize for negotiating a ceasefire between North Vietnam and the United States in January 1973. However, when the award was announced, both sides were still engaging in hostilities. Critics sympathetic to the North announced that Kissinger was not a peace-maker but the opposite, responsible for widening the war. Those hostile to the North and what they considered its deceptive practices during negotiations were deprived of a chance to criticise Lê Đức Thọ, as he declined the award.

Yasser Arafat, Shimon Peres, and Yitzhak Rabin received the Peace Prize in 1994 for their efforts in making peace between Israel and Palestine. Immediately after the award was announced, one of the five Norwegian Nobel Committee members denounced Arafat as a terrorist and resigned. Additional misgivings about Arafat were widely expressed in various newspapers.

Another controversial Peace Prize was that awarded to Barack Obama in 2009. Nominations had closed only eleven days after Obama took office as President of the United States, but the actual evaluation occurred over the next eight months. Obama himself stated that he did not feel deserving of the award, or worthy of the company in which it would place him. Past Peace Prize laureates were divided, some saying that Obama deserved the award, and others saying he had not secured the achievements to yet merit such an accolade. Obama's award, along with the previous Peace Prizes for Jimmy Carter and Al Gore, also prompted accusations of a left-wing bias.


The award of the 2004 Literature Prize to Elfriede Jelinek drew a protest from a member of the Swedish Academy, Knut Ahnlund. Ahnlund resigned, alleging that the selection of Jelinek had caused "irreparable damage to all progressive forces, it has also confused the general view of literature as an art". He alleged that Jelinek's works were "a mass of text shovelled together without artistic structure". The 2009 Literature Prize to Herta Müller also generated criticism. According to "The Washington Post", many US literary critics and professors were ignorant of her work. This made those critics feel the prizes were too Eurocentric.


In 1949, the neurologist António Egas Moniz received the Physiology or Medicine Prize for his development of the prefrontal leucotomy. The previous year, Dr. Walter Freeman had developed a version of the procedure which was faster and easier to carry out. Due in part to the publicity surrounding the original procedure, Freeman's procedure was prescribed without due consideration or regard for modern medical ethics. Endorsed by such influential publications as "The New England Journal of Medicine", leucotomy or "lobotomy" became so popular that about 5,000 lobotomies were performed in the United States in the three years immediately following Moniz's receipt of the Prize.

The Norwegian Nobel Committee confirmed that Mahatma Gandhi was nominated for the Peace Prize in 1937–39, 1947 and, a few days before he was assassinated in January 1948. Later, members of the Norwegian Nobel Committee expressed regret that he was not given the prize. Geir Lundestad, Secretary of Norwegian Nobel Committee in 2006, said, "The greatest omission in our 106 year history is undoubtedly that Mahatma Gandhi never received the Nobel Peace prize. Gandhi could do without the Nobel Peace prize. Whether Nobel committee can do without Gandhi is the question". In 1948, the year of Gandhi's death, the Nobel Committee declined to award a prize on the grounds that "there was no suitable living candidate" that year. Later, when the 14th Dalai Lama was awarded the Peace Prize in 1989, the chairman of the committee said that this was "in part a tribute to the memory of Mahatma Gandhi". Other high-profile individuals with widely recognised contributions to peace have been missed out. "Foreign Policy" lists Eleanor Roosevelt, Václav Havel, Ken Saro-Wiwa, Sari Nusseibeh, and Corazon Aquino as people who "never won the prize, but should have".

In 1965, UN Secretary General U Thant was informed by the Norwegian Permanent Representative to the UN that he would be awarded that year's prize and asked whether or not he would accept. He consulted staff and later replied that he would. At the same time, Chairman Gunnar Jahn of the Nobel Peace prize committee, lobbied heavily against giving U Thant the prize and the prize was at the last minute awarded to UNICEF. The rest of the committee all wanted the prize to go to U Thant, for his work in defusing the Cuban Missile Crisis, ending the war in the Congo, and his ongoing work to mediate an end to the Vietnam War. The disagreement lasted three years and in 1966 and 1967 no prize was given, with Gunnar Jahn effectively vetoing an award to U Thant.
The Literature Prize also has controversial omissions. Adam Kirsch has suggested that many notable writers have missed out on the award for political or extra-literary reasons. The heavy focus on European and Swedish authors has been a subject of criticism. The Eurocentric nature of the award was acknowledged by Peter Englund, the 2009 Permanent Secretary of the Swedish Academy, as a problem with the award and was attributed to the tendency for the academy to relate more to European authors. This tendency towards European authors still leaves some European writers on a list of notable writers that have been overlooked for the Literature Prize, including Europe's Leo Tolstoy, Anton Chekhov, J. R. R. Tolkien, Émile Zola, Marcel Proust, Vladimir Nabokov, James Joyce, August Strindberg, Simon Vestdijk, Karel Čapek, the New World's Jorge Luis Borges, Ezra Pound, John Updike, Arthur Miller, Mark Twain, and Africa's Chinua Achebe.

Candidates can receive multiple nominations the same year. Gaston Ramon received a total of 155 nominations in physiology or medicine from 1930 to 1953, the last year with public nomination data for that award . He died in 1963 without being awarded. Pierre Paul Émile Roux received 115 nominations in physiology or medicine, and Arnold Sommerfeld received 84 in physics. These are the three most nominated scientists without awards in the data published . Otto Stern received 79 nominations in physics 1925–43 before being awarded in 1943.

The strict rule against awarding a prize to more than three people is also controversial. When a prize is awarded to recognise an achievement by a team of more than three collaborators, one or more will miss out. For example, in 2002, the prize was awarded to Koichi Tanaka and John Fenn for the development of mass spectrometry in protein chemistry, an award that did not recognise the achievements of Franz Hillenkamp and Michael Karas of the Institute for Physical and Theoretical Chemistry at the University of Frankfurt. According to one of the nominees for the prize in physics, the three person limit deprived him and two other members of his team of the honor in 2013: the team of Carl Hagen, Gerald Guralnik, and Tom Kibble published a paper in 1964 that gave answers to how the cosmos began, but did not share the 2013 Physics Prize awarded to Peter Higgs and François Englert, who had also published papers in 1964 concerning the subject. All five physicists arrived at the same conclusion, albeit from different angles. Hagen contends that an equitable solution is to either abandon the three limit restriction, or expand the time period of recognition for a given achievement to two years.

Similarly, the prohibition of posthumous awards fails to recognise achievements by an individual or collaborator who dies before the prize is awarded. The Economics Prize was not awarded to Fischer Black, who died in 1995, when his co-author Myron Scholes received the honor in 1997 for their landmark work on option pricing along with Robert C. Merton, another pioneer in the development of valuation of stock options. In the announcement of the award that year, the Nobel committee prominently mentioned Black's key role.

Political subterfuge may also deny proper recognition. Lise Meitner and Fritz Strassmann, who co-discovered nuclear fission along with Otto Hahn, may have been denied a share of Hahn's 1944 Nobel Chemistry Award due to having fled Germany when the Nazis came to power. The Meitner and Strassmann roles in the research was not fully recognised until years later, when they joined Hahn in receiving the 1966 Enrico Fermi Award.

Alfred Nobel left his fortune to finance annual prizes to be awarded "to those who, during the preceding year, shall have conferred the greatest benefit on mankind". He stated that the Nobel Prizes in Physics should be given "to the person who shall have made the most important 'discovery' or 'invention' within the field of physics". Nobel did not emphasise discoveries, but they have historically been held in higher respect by the Nobel Prize Committee than inventions: 77% of the Physics Prizes have been given to discoveries, compared with only 23% to inventions. Christoph Bartneck and Matthias Rauterberg, in papers published in "Nature" and "Technoetic Arts", have argued this emphasis on discoveries has moved the Nobel Prize away from its original intention of rewarding the greatest contribution to society.

In terms of the most prestigious awards in STEM fields, only a small proportion have been awarded to women. Out of 210 laureates in Physics, 181 in Chemistry and 216 in Medicine between 1901 and 2018, there were only three female laureates in physics, five in chemistry and 12 in medicine. Factors proposed to contribute to the discrepancy between this and the roughly equal human sex ratio include biased nominations, fewer women than men being active in the relevant fields, Nobel Prizes typically being awarded decades after the research was done (reflecting a time when gender bias in the relevant fields was greater), a greater delay in awarding Nobel Prizes for women's achievements making longevity a more important factor for women (Nobel Prizes are not awarded posthumously), and a tendency to omit women from jointly awarded Nobel Prizes. Despite these factors, Marie Curie is to date the only person awarded Nobel Prizes in two different sciences (Physics in 1903, Chemistry in 1911); she is one of only three people who have received two Nobel Prizes in sciences (see Multiple laureates below).

Four people have received two Nobel Prizes. Marie Curie received the Physics Prize in 1903 for her work on radioactivity and the Chemistry Prize in 1911 for the isolation of pure radium, making her the only person to be awarded a Nobel Prize in two different sciences. Linus Pauling was awarded the 1954 Chemistry Prize for his research into the chemical bond and its application to the structure of complex substances. Pauling was also awarded the Peace Prize in 1962 for his activism against nuclear weapons, making him the only laureate of two unshared prizes. John Bardeen received the Physics Prize twice: in 1956 for the invention of the transistor and in 1972 for the theory of superconductivity. Frederick Sanger received the prize twice in Chemistry: in 1958 for determining the structure of the insulin molecule and in 1980 for inventing a method of determining base sequences in DNA.

Two organizations have received the Peace Prize multiple times. The International Committee of the Red Cross received it three times: in 1917 and 1944 for its work during the world wars; and in 1963 during the year of its centenary. The United Nations High Commissioner for Refugees has been awarded the Peace Prize twice for assisting refugees: in 1954 and 1981.

The Curie family has received the most prizes, with four prizes awarded to five individual laureates. Marie Curie received the prizes in Physics (in 1903) and Chemistry (in 1911). Her husband, Pierre Curie, shared the 1903 Physics prize with her. Their daughter, Irène Joliot-Curie, received the Chemistry Prize in 1935 together with her husband Frédéric Joliot-Curie. In addition, the husband of Marie Curie's second daughter, Henry Labouisse, was the director of UNICEF when he accepted the Nobel Peace Prize in 1965 on that organisation's behalf.

Although no family matches the Curie family's record, there have been several with two laureates. The husband-and-wife team of Gerty Cori and Carl Ferdinand Cori shared the 1947 Prize in Physiology or Medicine as did the husband-and-wife team of May-Britt Moser and Edvard Moser in 2014 (along with John O'Keefe). J. J. Thomson was awarded the Physics Prize in 1906 for showing that electrons are particles. His son, George Paget Thomson, received the same prize in 1937 for showing that they also have the properties of waves. William Henry Bragg and his son, William Lawrence Bragg, shared the Physics Prize in 1915 for inventing the X-ray crystallography. Niels Bohr was awarded the Physics prize in 1922, as was his son, Aage Bohr, in 1975. Manne Siegbahn, who received the Physics Prize in 1924, was the father of Kai Siegbahn, who received the Physics Prize in 1981. Hans von Euler-Chelpin, who received the Chemistry Prize in 1929, was the father of Ulf von Euler, who was awarded the Physiology or Medicine Prize in 1970. C. V. Raman was awarded the Physics Prize in 1930 and was the uncle of Subrahmanyan Chandrasekhar, who was awarded the same prize in 1983. Arthur Kornberg received the Physiology or Medicine Prize in 1959; Kornberg's son, Roger later received the Chemistry Prize in 2006. Jan Tinbergen, who was awarded the first Economics Prize in 1969, was the brother of Nikolaas Tinbergen, who received the 1973 Physiology or Medicine Prize. Alva Myrdal, Peace Prize laureate in 1982, was the wife of Gunnar Myrdal who was awarded the Economics Prize in 1974. Economics laureates Paul Samuelson and Kenneth Arrow were brothers-in-law. Frits Zernike, who was awarded the 1953 Physics Prize, is the great-uncle of 1999 Physics laureate Gerard 't Hooft.

Two laureates have voluntarily declined the Nobel Prize. In 1964, Jean-Paul Sartre was awarded the Literature Prize but refused, stating, "A writer must refuse to allow himself to be transformed into an institution, even if it takes place in the most honourable form." Lê Đức Thọ, chosen for the 1973 Peace Prize for his role in the Paris Peace Accords, declined, stating that there was no actual peace in Vietnam.

During the Third Reich, Adolf Hitler hindered Richard Kuhn, Adolf Butenandt, and Gerhard Domagk from accepting their prizes. All of them were awarded their diplomas and gold medals after World War II. In 1958, Boris Pasternak declined his prize for literature due to fear of what the Soviet Union government might do if he travelled to Stockholm to accept his prize. In return, the Swedish Academy refused his refusal, saying "this refusal, of course, in no way alters the validity of the award." The Academy announced with regret that the presentation of the Literature Prize could not take place that year, holding it back until 1989 when Pasternak's son accepted the prize on his behalf.

Aung San Suu Kyi was awarded the Nobel Peace Prize in 1991, but her children accepted the prize because she had been placed under house arrest in Burma; Suu Kyi delivered her speech two decades later, in 2012. Liu Xiaobo was awarded the Nobel Peace Prize in 2010 while he and his wife were under house arrest in China as political prisoners, and he was unable to accept the prize in his lifetime.

Being a symbol of scientific or literary achievement that is recognisable worldwide, the Nobel Prize is often depicted in fiction. This includes films like "The Prize" and "Nobel Son" about fictional Nobel laureates as well as fictionalised accounts of stories surrounding real prizes such as "Nobel Chor", a film based on the theft of Rabindranath Tagore's prize.

The memorial symbol "Planet of Alfred Nobel" was opened in Dnipropetrovsk University of Economics and Law in 2008. On the globe, there are 802 Nobel laureates' reliefs made of a composite alloy obtained when disposing of military strategic missiles.




</doc>
<doc id="21210" url="https://en.wikipedia.org/wiki?curid=21210" title="Niels Bohr">
Niels Bohr

Niels Henrik David Bohr (; 7 October 1885 – 18 November 1962) was a Danish physicist who made foundational contributions to understanding atomic structure and quantum theory, for which he received the Nobel Prize in Physics in 1922. Bohr was also a philosopher and a promoter of scientific research.

Bohr developed the Bohr model of the atom, in which he proposed that energy levels of electrons are discrete and that the electrons revolve in stable orbits around the atomic nucleus but can jump from one energy level (or orbit) to another. Although the Bohr model has been supplanted by other models, its underlying principles remain valid. He conceived the principle of complementarity: that items could be separately analysed in terms of contradictory properties, like behaving as a wave or a stream of particles. The notion of complementarity dominated Bohr's thinking in both science and philosophy.

Bohr founded the Institute of Theoretical Physics at the University of Copenhagen, now known as the Niels Bohr Institute, which opened in 1920. Bohr mentored and collaborated with physicists including Hans Kramers, Oskar Klein, George de Hevesy, and Werner Heisenberg. He predicted the existence of a new zirconium-like element, which was named hafnium, after the Latin name for Copenhagen, where it was discovered. Later, the element bohrium was named after him.

During the 1930s, Bohr helped refugees from Nazism. After Denmark was occupied by the Germans, he had a famous meeting with Heisenberg, who had become the head of the German nuclear weapon project. In September 1943, word reached Bohr that he was about to be arrested by the Germans, and he fled to Sweden. From there, he was flown to Britain, where he joined the British Tube Alloys nuclear weapons project, and was part of the British mission to the Manhattan Project. After the war, Bohr called for international cooperation on nuclear energy. He was involved with the establishment of CERN and the Research Establishment Risø of the Danish Atomic Energy Commission and became the first chairman of the Nordic Institute for Theoretical Physics in 1957.

Bohr was born in Copenhagen, Denmark, on 7 October 1885, the second of three children of Christian Bohr, a professor of physiology at the University of Copenhagen, and Ellen Adler Bohr, who came from a wealthy Danish Jewish family prominent in banking and parliamentary circles. He had an elder sister, Jenny, and a younger brother Harald. Jenny became a teacher, while Harald became a mathematician and footballer who played for the Danish national team at the 1908 Summer Olympics in London. Niels was a passionate footballer as well, and the two brothers played several matches for the Copenhagen-based Akademisk Boldklub (Academic Football Club), with Niels as goalkeeper.
Bohr was educated at Gammelholm Latin School, starting when he was seven. In 1903, Bohr enrolled as an undergraduate at Copenhagen University. His major was physics, which he studied under Professor Christian Christiansen, the university's only professor of physics at that time. He also studied astronomy and mathematics under Professor Thorvald Thiele, and philosophy under Professor Harald Høffding, a friend of his father.

In 1905, a gold medal competition was sponsored by the Royal Danish Academy of Sciences and Letters to investigate a method for measuring the surface tension of liquids that had been proposed by Lord Rayleigh in 1879. This involved measuring the frequency of oscillation of the radius of a water jet. Bohr conducted a series of experiments using his father's laboratory in the university; the university itself had no physics laboratory. To complete his experiments, he had to make his own glassware, creating test tubes with the required elliptical cross-sections. He went beyond the original task, incorporating improvements into both Rayleigh's theory and his method, by taking into account the viscosity of the water, and by working with finite amplitudes instead of just infinitesimal ones. His essay, which he submitted at the last minute, won the prize. He later submitted an improved version of the paper to the Royal Society in London for publication in the "Philosophical Transactions of the Royal Society".

Harald became the first of the two Bohr brothers to earn a master's degree, which he earned for mathematics in April 1909. Niels took another nine months to earn his on the electron theory of metals, a topic assigned by his supervisor, Christiansen. Bohr subsequently elaborated his master's thesis into his much-larger Doctor of Philosophy (dr. phil.) thesis. He surveyed the literature on the subject, settling on a model postulated by Paul Drude and elaborated by Hendrik Lorentz, in which the electrons in a metal are considered to behave like a gas. Bohr extended Lorentz's model, but was still unable to account for phenomena like the Hall effect, and concluded that electron theory could not fully explain the magnetic properties of metals. The thesis was accepted in April 1911, and Bohr conducted his formal defence on 13 May. Harald had received his doctorate the previous year. Bohr's thesis was groundbreaking, but attracted little interest outside Scandinavia because it was written in Danish, a Copenhagen University requirement at the time. In 1921, the Dutch physicist Hendrika Johanna van Leeuwen would independently derive a theorem from Bohr's thesis that is today known as the Bohr–van Leeuwen theorem.
In 1910, Bohr met Margrethe Nørlund, the sister of the mathematician Niels Erik Nørlund. Bohr resigned his membership in the Church of Denmark on 16 April 1912, and he and Margrethe were married in a civil ceremony at the town hall in Slagelse on 1 August. Years later, his brother Harald similarly left the church before getting married. Bohr and Margrethe had six sons. The oldest, Christian, died in a boating accident in 1934, and another, Harald, died from childhood meningitis. Aage Bohr became a successful physicist, and in 1975 was awarded the Nobel Prize in physics, like his father. became a physician; , a chemical engineer; and Ernest, a lawyer. Like his uncle Harald, Ernest Bohr became an Olympic athlete, playing field hockey for Denmark at the 1948 Summer Olympics in London.

In September 1911, Bohr, supported by a fellowship from the Carlsberg Foundation, travelled to England. At the time, it was where most of the theoretical work on the structure of atoms and molecules was being done. He met J. J. Thomson of the Cavendish Laboratory and Trinity College, Cambridge. He attended lectures on electromagnetism given by James Jeans and Joseph Larmor, and did some research on cathode rays, but failed to impress Thomson. He had more success with younger physicists like the Australian William Lawrence Bragg, and New Zealand's Ernest Rutherford, whose 1911 small central nucleus Rutherford model of the atom had challenged Thomson's 1904 plum pudding model. Bohr received an invitation from Rutherford to conduct post-doctoral work at Victoria University of Manchester, where Bohr met George de Hevesy and Charles Galton Darwin (whom Bohr referred to as "the grandson of the real Darwin").

Bohr returned to Denmark in July 1912 for his wedding, and travelled around England and Scotland on his honeymoon. On his return, he became a "privatdocent" at the University of Copenhagen, giving lectures on thermodynamics. Martin Knudsen put Bohr's name forward for a "docent", which was approved in July 1913, and Bohr then began teaching medical students. His three papers, which later became famous as "the trilogy", were published in "Philosophical Magazine" in July, September and November of that year. He adapted Rutherford's nuclear structure to Max Planck's quantum theory and so created his Bohr model of the atom.

Planetary models of atoms were not new, but Bohr's treatment was. Taking the 1912 paper by Darwin on the role of electrons in the interaction of alpha particles with a nucleus as his starting point, he advanced the theory of electrons travelling in orbits around the atom's nucleus, with the chemical properties of each element being largely determined by the number of electrons in the outer orbits of its atoms. He introduced the idea that an electron could drop from a higher-energy orbit to a lower one, in the process emitting a quantum of discrete energy. This became a basis for what is now known as the old quantum theory.

In 1885, Johann Balmer had come up with his Balmer series to describe the visible spectral lines of a hydrogen atom:
where λ is the wavelength of the absorbed or emitted light and "R" is the Rydberg constant. Balmer's formula was corroborated by the discovery of additional spectral lines, but for thirty years, no one could explain why it worked. In the first paper of his trilogy, Bohr was able to derive it from his model:
where "m" is the electron's mass, "e" is its charge, "h" is Planck's constant and "Z" is the atom's atomic number (1 for hydrogen).

The model's first hurdle was the Pickering series, lines which did not fit Balmer's formula. When challenged on this by Alfred Fowler, Bohr replied that they were caused by ionised helium, helium atoms with only one electron. The Bohr model was found to work for such ions. Many older physicists, like Thomson, Rayleigh and Hendrik Lorentz, did not like the trilogy, but the younger generation, including Rutherford, David Hilbert, Albert Einstein, Enrico Fermi, Max Born and Arnold Sommerfeld saw it as a breakthrough. The trilogy's acceptance was entirely due to its ability to explain phenomena which stymied other models, and to predict results that were subsequently verified by experiments. Today, the Bohr model of the atom has been superseded, but is still the best known model of the atom, as it often appears in high school physics and chemistry texts.

Bohr did not enjoy teaching medical students. He decided to return to Manchester, where Rutherford had offered him a job as a reader in place of Darwin, whose tenure had expired. Bohr accepted. He took a leave of absence from the University of Copenhagen, which he started by taking a holiday in Tyrol with his brother Harald and aunt Hanna Adler. There, he visited the University of Göttingen and the Ludwig Maximilian University of Munich, where he met Sommerfeld and conducted seminars on the trilogy. The First World War broke out while they were in Tyrol, greatly complicating the trip back to Denmark and Bohr's subsequent voyage with Margrethe to England, where he arrived in October 1914. They stayed until July 1916, by which time he had been appointed to the Chair of Theoretical Physics at the University of Copenhagen, a position created especially for him. His docentship was abolished at the same time, so he still had to teach physics to medical students. New professors were formally introduced to King Christian X, who expressed his delight at meeting such a famous football player.

In April 1917, Bohr began a campaign to establish an Institute of Theoretical Physics. He gained the support of the Danish government and the Carlsberg Foundation, and sizeable contributions were also made by industry and private donors, many of them Jewish. Legislation establishing the Institute was passed in November 1918. Now known as the Niels Bohr Institute, it opened on 3 March 1921, with Bohr as its director. His family moved into an apartment on the first floor. Bohr's institute served as a focal point for researchers into quantum mechanics and related subjects in the 1920s and 1930s, when most of the world's best known theoretical physicists spent some time in his company. Early arrivals included Hans Kramers from the Netherlands, Oskar Klein from Sweden, George de Hevesy from Hungary, Wojciech Rubinowicz from Poland and Svein Rosseland from Norway. Bohr became widely appreciated as their congenial host and eminent colleague. Klein and Rosseland produced the Institute's first publication even before it opened.
The Bohr model worked well for hydrogen, but could not explain more complex elements. By 1919, Bohr was moving away from the idea that electrons orbited the nucleus and developed heuristics to describe them. The rare-earth elements posed a particular classification problem for chemists, because they were so chemically similar. An important development came in 1924 with Wolfgang Pauli's discovery of the Pauli exclusion principle, which put Bohr's models on a firm theoretical footing. Bohr was then able to declare that the as-yet-undiscovered element 72 was not a rare-earth element, but an element with chemical properties similar to those of zirconium. He was immediately challenged by the French chemist Georges Urbain, who claimed to have discovered a rare-earth element 72, which he called "celtium". At the Institute in Copenhagen, Dirk Coster and George de Hevesy took up the challenge of proving Bohr right and Urbain wrong. Starting with a clear idea of the chemical properties of the unknown element greatly simplified the search process. They went through samples from Copenhagen's Museum of Mineralogy looking for a zirconium-like element and soon found it. The element, which they named hafnium ("Hafnia" being the Latin name for Copenhagen) turned out to be more common than gold.

In 1922, Bohr was awarded the Nobel Prize in Physics "for his services in the investigation of the structure of atoms and of the radiation emanating from them". The award thus recognised both the Trilogy and his early leading work in the emerging field of quantum mechanics. For his Nobel lecture, Bohr gave his audience a comprehensive survey of what was then known about the structure of the atom, including the correspondence principle, which he had formulated. This states that the behaviour of systems described by quantum theory reproduces classical physics in the limit of large quantum numbers.

The discovery of Compton scattering by Arthur Holly Compton in 1923 convinced most physicists that light was composed of photons, and that energy and momentum were conserved in collisions between electrons and photons. In 1924, Bohr, Kramers and John C. Slater, an American physicist working at the Institute in Copenhagen, proposed the Bohr–Kramers–Slater theory (BKS). It was more a programme than a full physical theory, as the ideas it developed were not worked out quantitatively. BKS theory became the final attempt at understanding the interaction of matter and electromagnetic radiation on the basis of the old quantum theory, in which quantum phenomena were treated by imposing quantum restrictions on a classical wave description of the electromagnetic field.

Modelling atomic behaviour under incident electromagnetic radiation using "virtual oscillators" at the absorption and emission frequencies, rather than the (different) apparent frequencies of the Bohr orbits, led Max Born, Werner Heisenberg and Kramers to explore different mathematical models. They led to the development of matrix mechanics, the first form of modern quantum mechanics. The BKS theory also generated discussion of, and renewed attention to, difficulties in the foundations of the old quantum theory. The most provocative element of BKS – that momentum and energy would not necessarily be conserved in each interaction, but only statistically – was soon shown to be in conflict with experiments conducted by Walther Bothe and Hans Geiger. In light of these results, Bohr informed Darwin that "there is nothing else to do than to give our revolutionary efforts as honourable a funeral as possible".

The introduction of spin by George Uhlenbeck and Samuel Goudsmit in November 1925 was a milestone. The next month, Bohr travelled to Leiden to attend celebrations of the 50th anniversary of Hendrick Lorentz receiving his doctorate. When his train stopped in Hamburg, he was met by Wolfgang Pauli and Otto Stern, who asked for his opinion of the spin theory. Bohr pointed out that he had concerns about the interaction between electrons and magnetic fields. When he arrived in Leiden, Paul Ehrenfest and Albert Einstein informed Bohr that Einstein had resolved this problem using relativity. Bohr then had Uhlenbeck and Goudsmit incorporate this into their paper. Thus, when he met Werner Heisenberg and Pascual Jordan in Göttingen on the way back, he had become, in his own words, "a prophet of the electron magnet gospel".

Heisenberg first came to Copenhagen in 1924, then returned to Göttingen in June 1925, shortly thereafter developing the mathematical foundations of quantum mechanics. When he showed his results to Max Born in Göttingen, Born realised that they could best be expressed using matrices. This work attracted the attention of the British physicist Paul Dirac, who came to Copenhagen for six months in September 1926. Austrian physicist Erwin Schrödinger also visited in 1926. His attempt at explaining quantum physics in classical terms using wave mechanics impressed Bohr, who believed it contributed "so much to mathematical clarity and simplicity that it represents a gigantic advance over all previous forms of quantum mechanics".

When Kramers left the Institute in 1926 to take up a chair as professor of theoretical physics at the Utrecht University, Bohr arranged for Heisenberg to return and take Kramers's place as a "lektor" at the University of Copenhagen. Heisenberg worked in Copenhagen as a university lecturer and assistant to Bohr from 1926 to 1927.

Bohr became convinced that light behaved like both waves and particles, and in 1927, experiments confirmed the de Broglie hypothesis that matter (like electrons) also behaved like waves. He conceived the philosophical principle of complementarity: that items could have apparently mutually exclusive properties, such as being a wave or a stream of particles, depending on the experimental framework. He felt that it was not fully understood by professional philosophers.

In Copenhagen in 1927 Heisenberg developed his uncertainty principle, which Bohr embraced. In a paper he presented at the Volta Conference at Como in September 1927, he demonstrated that the uncertainty principle could be derived from classical arguments, without quantum terminology or matrices. Einstein preferred the determinism of classical physics over the probabilistic new quantum physics to which he himself had contributed. Philosophical issues that arose from the novel aspects of quantum mechanics became widely celebrated subjects of discussion. Einstein and Bohr had good-natured arguments over such issues throughout their lives.

In 1914, Carl Jacobsen, the heir to Carlsberg breweries, bequeathed his mansion to be used for life by the Dane who had made the most prominent contribution to science, literature or the arts, as an honorary residence (). Harald Høffding had been the first occupant, and upon his death in July 1931, the Royal Danish Academy of Sciences and Letters gave Bohr occupancy. He and his family moved there in 1932. He was elected president of the Academy on 17 March 1939.

By 1929, the phenomenon of beta decay prompted Bohr to again suggest that the law of conservation of energy be abandoned, but Enrico Fermi's hypothetical neutrino and the subsequent 1932 discovery of the neutron provided another explanation. This prompted Bohr to create a new theory of the compound nucleus in 1936, which explained how neutrons could be captured by the nucleus. In this model, the nucleus could be deformed like a drop of liquid. He worked on this with a new collaborator, the Danish physicist Fritz Kalckar, who died suddenly in 1938.

The discovery of nuclear fission by Otto Hahn in December 1938 (and its theoretical explanation by Lise Meitner) generated intense interest among physicists. Bohr brought the news to the United States where he opened the Fifth Washington Conference on Theoretical Physics with Fermi on 26 January 1939. When Bohr told George Placzek that this resolved all the mysteries of transuranic elements, Placzek told him that one remained: the neutron capture energies of uranium did not match those of its decay. Bohr thought about it for a few minutes and then announced to Placzek, Léon Rosenfeld and John Wheeler that "I have understood everything." Based on his liquid drop model of the nucleus, Bohr concluded that it was the uranium-235 isotope and not the more abundant uranium-238 that was primarily responsible for fission with thermal neutrons. In April 1940, John R. Dunning demonstrated that Bohr was correct. In the meantime, Bohr and Wheeler developed a theoretical treatment which they published in a September 1939 paper on "The Mechanism of Nuclear Fission".

Bohr read the 19th-century Danish Christian existentialist philosopher, Søren Kierkegaard. Richard Rhodes argued in "The Making of the Atomic Bomb" that Bohr was influenced by Kierkegaard through Høffding. In 1909, Bohr sent his brother Kierkegaard's "Stages on Life's Way" as a birthday gift. In the enclosed letter, Bohr wrote, "It is the only thing I have to send home; but I do not believe that it would be very easy to find anything better ... I even think it is one of the most delightful things I have ever read." Bohr enjoyed Kierkegaard's language and literary style, but mentioned that he had some disagreement with Kierkegaard's philosophy. Some of Bohr's biographers suggested that this disagreement stemmed from Kierkegaard's advocacy of Christianity, while Bohr was an atheist.

There has been some dispute over the extent to which Kierkegaard influenced Bohr's philosophy and science. David Favrholdt argued that Kierkegaard had minimal influence over Bohr's work, taking Bohr's statement about disagreeing with Kierkegaard at face value, while Jan Faye argued that one can disagree with the content of a theory while accepting its general premises and structure.

The rise of Nazism in Germany prompted many scholars to flee their countries, either because they were Jewish or because they were political opponents of the Nazi regime. In 1933, the Rockefeller Foundation created a fund to help support refugee academics, and Bohr discussed this programme with the President of the Rockefeller Foundation, Max Mason, in May 1933 during a visit to the United States. Bohr offered the refugees temporary jobs at the Institute, provided them with financial support, arranged for them to be awarded fellowships from the Rockefeller Foundation, and ultimately found them places at institutions around the world. Those that he helped included Guido Beck, Felix Bloch, James Franck, George de Hevesy, Otto Frisch, Hilde Levi, Lise Meitner, George Placzek, Eugene Rabinowitch, Stefan Rozental, Erich Ernst Schneider, Edward Teller, Arthur von Hippel and Victor Weisskopf.

In April 1940, early in the Second World War, Nazi Germany invaded and occupied Denmark. To prevent the Germans from discovering Max von Laue's and James Franck's gold Nobel medals, Bohr had de Hevesy dissolve them in aqua regia. In this form, they were stored on a shelf at the Institute until after the war, when the gold was precipitated and the medals re-struck by the Nobel Foundation. Bohr's own medal had been donated to an auction to the Fund for Finnish Relief, and was auctioned off in March 1940, along with the medal of August Krogh. The buyer later donated the two medals to the Danish Historical Museum in Frederiksborg Castle, where they are still kept.

Bohr kept the Institute running, but all the foreign scholars departed.

Bohr was aware of the possibility of using uranium-235 to construct an atomic bomb, referring to it in lectures in Britain and Denmark shortly before and after the war started, but he did not believe that it was technically feasible to extract a sufficient quantity of uranium-235. In September 1941, Heisenberg, who had become head of the German nuclear energy project, visited Bohr in Copenhagen. During this meeting the two men took a private moment outside, the content of which has caused much speculation, as both gave differing accounts.
According to Heisenberg, he began to address nuclear energy, morality and the war, to which Bohr seems to have reacted by terminating the conversation abruptly while not giving Heisenberg hints about his own opinions. Ivan Supek, one of Heisenberg's students and friends, claimed that the main subject of the meeting was Carl Friedrich von Weizsäcker, who had proposed trying to persuade Bohr to mediate peace between Britain and Germany.

In 1957, Heisenberg wrote to Robert Jungk, who was then working on the book "". Heisenberg explained that he had visited Copenhagen to communicate to Bohr the views of several German scientists, that production of a nuclear weapon was possible with great efforts, and this raised enormous responsibilities on the world's scientists on both sides. When Bohr saw Jungk's depiction in the Danish translation of the book, he drafted (but never sent) a letter to Heisenberg, stating that he never understood the purpose of Heisenberg's visit, was shocked by Heisenberg's opinion that Germany would win the war, and that atomic weapons could be decisive.

Michael Frayn's 1998 play "Copenhagen" explores what might have happened at the 1941 meeting between Heisenberg and Bohr. A BBC television film version of the play was first screened on 26 September 2002, with Stephen Rea as Bohr, and Daniel Craig as Heisenberg. The same meeting had previously been dramatised by the BBC's "Horizon" science documentary series in 1992, with Anthony Bate as Bohr, and Philip Anthony as Heisenberg. The meeting is also dramatized in the Norwegian/Danish/British miniseries "The Heavy Water War".

In September 1943, word reached Bohr and his brother Harald that the Nazis considered their family to be Jewish, since their mother was Jewish, and that they were therefore in danger of being arrested. The Danish resistance helped Bohr and his wife escape by sea to Sweden on 29 September. The next day, Bohr persuaded King Gustaf V of Sweden to make public Sweden's willingness to provide asylum to Jewish refugees. On 2 October 1943, Swedish radio broadcast that Sweden was ready to offer asylum, and the mass rescue of the Danish Jews by their countrymen followed swiftly thereafter. Some historians claim that Bohr's actions led directly to the mass rescue, while others say that, though Bohr did all that he could for his countrymen, his actions were not a decisive influence on the wider events. Eventually, over 7,000 Danish Jews escaped to Sweden.
When the news of Bohr's escape reached Britain, Lord Cherwell sent a telegram to Bohr asking him to come to Britain. Bohr arrived in Scotland on 6 October in a de Havilland Mosquito operated by the British Overseas Airways Corporation (BOAC). The Mosquitos were unarmed high-speed bomber aircraft that had been converted to carry small, valuable cargoes or important passengers. By flying at high speed and high altitude, they could cross German-occupied Norway, and yet avoid German fighters. Bohr, equipped with parachute, flying suit and oxygen mask, spent the three-hour flight lying on a mattress in the aircraft's bomb bay. During the flight, Bohr did not wear his flying helmet as it was too small, and consequently did not hear the pilot's intercom instruction to turn on his oxygen supply when the aircraft climbed to high altitude to overfly Norway. He passed out from oxygen starvation and only revived when the aircraft descended to lower altitude over the North Sea. Bohr's son Aage followed his father to Britain on another flight a week later, and became his personal assistant.

Bohr was warmly received by James Chadwick and Sir John Anderson, but for security reasons Bohr was kept out of sight. He was given an apartment at St James's Palace and an office with the British Tube Alloys nuclear weapons development team. Bohr was astonished at the amount of progress that had been made. Chadwick arranged for Bohr to visit the United States as a Tube Alloys consultant, with Aage as his assistant. On 8 December 1943, Bohr arrived in Washington, D.C., where he met with the director of the Manhattan Project, Brigadier General Leslie R. Groves, Jr. He visited Einstein and Pauli at the Institute for Advanced Study in Princeton, New Jersey, and went to Los Alamos in New Mexico, where the nuclear weapons were being designed. For security reasons, he went under the name of "Nicholas Baker" in the United States, while Aage became "James Baker". In May 1944 the Danish resistance newspaper De frie Danske reported that they had learned that 'the famous son of Denmark Professor Niels Bohr' in October the previous year had fled his country via Sweden to London and from there travelled to Moscow from where he could be assumed to support the war effort.

Bohr did not remain at Los Alamos, but paid a series of extended visits over the course of the next two years. Robert Oppenheimer credited Bohr with acting "as a scientific father figure to the younger men", most notably Richard Feynman. Bohr is quoted as saying, "They didn't need my help in making the atom bomb." Oppenheimer gave Bohr credit for an important contribution to the work on modulated neutron initiators. "This device remained a stubborn puzzle," Oppenheimer noted, "but in early February 1945 Niels Bohr clarified what had to be done."

Bohr recognised early that nuclear weapons would change international relations. In April 1944, he received a letter from Peter Kapitza, written some months before when Bohr was in Sweden, inviting him to come to the Soviet Union. The letter convinced Bohr that the Soviets were aware of the Anglo-American project, and would strive to catch up. He sent Kapitza a non-committal response, which he showed to the authorities in Britain before posting. Bohr met Churchill on 16 May 1944, but found that "we did not speak the same language". Churchill disagreed with the idea of openness towards the Russians to the point that he wrote in a letter: "It seems to me Bohr ought to be confined or at any rate made to see that he is very near the edge of mortal crimes."

Oppenheimer suggested that Bohr visit President Franklin D. Roosevelt to convince him that the Manhattan Project should be shared with the Soviets in the hope of speeding up its results. Bohr's friend, Supreme Court Justice Felix Frankfurter, informed President Roosevelt about Bohr's opinions, and a meeting between them took place on 26 August 1944. Roosevelt suggested that Bohr return to the United Kingdom to try to win British approval. When Churchill and Roosevelt met at Hyde Park on 19 September 1944, they rejected the idea of informing the world about the project, and the aide-mémoire of their conversation contained a rider that "enquiries should be made regarding the activities of Professor Bohr and steps taken to ensure that he is responsible for no leakage of information, particularly to the Russians".

In June 1950, Bohr addressed an "Open Letter" to the United Nations calling for international cooperation on nuclear energy. In the 1950s, after the Soviet Union's first nuclear weapon test, the International Atomic Energy Agency was created along the lines of Bohr's suggestion. In 1957 he received the first ever Atoms for Peace Award.

With the war now ended, Bohr returned to Copenhagen on 25 August 1945, and was re-elected President of the Royal Danish Academy of Arts and Sciences on 21 September. At a memorial meeting of the Academy on 17 October 1947 for King Christian X, who had died in April, the new king, Frederick IX, announced that he was conferring the Order of the Elephant on Bohr. This award was normally awarded only to royalty and heads of state, but the king said that it honoured not just Bohr personally, but Danish science. Bohr designed his own coat of arms which featured a taijitu (symbol of yin and yang) and a motto in , "opposites are complementary".

The Second World War demonstrated that science, and physics in particular, now required considerable financial and material resources. To avoid a brain drain to the United States, twelve European countries banded together to create CERN, a research organisation along the lines of the national laboratories in the United States, designed to undertake Big Science projects beyond the resources of any one of them alone. Questions soon arose regarding the best location for the facilities. Bohr and Kramers felt that the Institute in Copenhagen would be the ideal site. Pierre Auger, who organised the preliminary discussions, disagreed; he felt that both Bohr and his Institute were past their prime, and that Bohr's presence would overshadow others. After a long debate, Bohr pledged his support to CERN in February 1952, and Geneva was chosen as the site in October. The CERN Theory Group was based in Copenhagen until their new accommodation in Geneva was ready in 1957. Victor Weisskopf, who later became the Director General of CERN, summed up Bohr's role, saying that "there were other personalities who started and conceived the idea of CERN. The enthusiasm and ideas of the other people would not have been enough, however, if a man of his stature had not supported it."

Meanwhile, Scandinavian countries formed the Nordic Institute for Theoretical Physics in 1957, with Bohr as its chairman. He was also involved with the founding of the Research Establishment Risø of the Danish Atomic Energy Commission, and served as its first chairman from February 1956.

Bohr died of heart failure at his home in Carlsberg on 18 November 1962. He was cremated, and his ashes were buried in the family plot in the Assistens Cemetery in the Nørrebro section of Copenhagen, along with those of his parents, his brother Harald, and his son Christian. Years later, his wife's ashes were also interred there. On 7 October 1965, on what would have been his 80th birthday, the Institute for Theoretical Physics at the University of Copenhagen was officially renamed to what it had been called unofficially for many years: the Niels Bohr Institute.

Bohr received numerous honours and accolades. In addition to the Nobel Prize, he received the Hughes Medal in 1921, the Matteucci Medal in 1923, the Franklin Medal in 1926, the Copley Medal in 1938, the Order of the Elephant in 1947, the Atoms for Peace Award in 1957 and the Sonning Prize in 1961. He became foreign member of the Royal Netherlands Academy of Arts and Sciences in 1923, and of the Royal Society in 1926. The Bohr model's semicentennial was commemorated in Denmark on 21 November 1963 with a postage stamp depicting Bohr, the hydrogen atom and the formula for the difference of any two hydrogen energy levels: formula_3. Several other countries have also issued postage stamps depicting Bohr. In 1997, the Danish National Bank began circulating the 500-krone banknote with the portrait of Bohr smoking a pipe. An asteroid, 3948 Bohr, was named after him, as was the Bohr lunar crater and bohrium, the chemical element with atomic number 107.





</doc>
<doc id="21211" url="https://en.wikipedia.org/wiki?curid=21211" title="National Football League">
National Football League

The National Football League (NFL) is a professional American football league consisting of 32 teams, divided equally between the National Football Conference (NFC) and the American Football Conference (AFC). The NFL is one of the four major professional sports leagues in North America and the highest professional level of American football in the world. The NFL's 17-week regular season runs from early September to late December, with each team playing 16 games and having one bye week. Following the conclusion of the regular season, six teams from each conference (four division winners and two wild card teams) advance to the playoffs, a single-elimination tournament culminating in the Super Bowl, which is usually held on the first Sunday in February and is played between the champions of the NFC and AFC.

The NFL was formed in 1920 as the American Professional Football Association (APFA) before renaming itself the National Football League for the 1922 season. After initially determining champions through end-of-season standings, a playoff system was implemented in 1933 that culminated with the until 1966. Following an agreement to merge the NFL with the American Football League (AFL), the Super Bowl was first held in 1967 to determine a champion between the best teams from the two leagues and has remained as the final game of each NFL season since the merger was completed in 1970. Today, the NFL has the highest average attendance (67,591) of any professional sports league in the world and is the most popular sports league in the United States. The Super Bowl is also among the biggest club sporting events in the world, with the individual games accounting for many of the most watched television programs in American history and all occupying the Nielsen's Top 5 tally of the all-time most watched U.S. television broadcasts by 2015.

The Green Bay Packers hold the most combined NFL championships with 13, winning nine titles before the Super Bowl era and four Super Bowls afterwards. Since the creation of the Super Bowl, the Pittsburgh Steelers and New England Patriots both have the most championship titles at six. The Patriots are the NFL's current champions following their victory over the Los Angeles Rams in Super Bowl LIII.

On August 20, 1920, a meeting was held by representatives of the Akron Pros, Canton Bulldogs, Cleveland Indians, and Dayton Triangles at the Jordan and Hupmobile auto showroom in Canton, Ohio. This meeting resulted in the formation of the American Professional Football Conference (APFC), a group who, according to the "Canton Evening Repository", intended to "raise the standard of professional football in every way possible, to eliminate bidding for players between rival clubs and to secure cooperation in the formation of schedules".

Another meeting was held on September 17, 1920 with representatives from teams from four states: Akron, Canton, Cleveland, and Dayton from Ohio; the Hammond Pros and Muncie Flyers from Indiana; the Rochester Jeffersons from New York; and the Rock Island Independents, Decatur Staleys, and Racine (Chicago) Cardinals from Illinois. The league was renamed to the American Professional Football Association (APFA). The league elected Jim Thorpe as its first president, and consisted of 14 teams (the Buffalo All-Americans, Chicago Tigers, Columbus Panhandles, and Detroit Heralds joined the league during the year). The Massillon Tigers from Massillon, Ohio was also at the September 17 meeting, but did not field a team in 1920. Only two of these teams, the Decatur Staleys (now the Chicago Bears) and the Chicago Cardinals (now the Arizona Cardinals), remain.
Although the league did not maintain official standings for its 1920 inaugural season and teams played schedules that included non-league opponents, the APFA awarded the Akron Pros the championship by virtue of their (8 wins, 0 losses, and 3 ties) record. The first event occurred on September 26, 1920 when the Rock Island Independents defeated the non-league St. Paul Ideals 48–0 at Douglas Park. On October 3, 1920, the first full week of league play occurred.
The following season resulted in the Chicago Staleys controversially winning the title over the Buffalo All-Americans. On June 24, 1922, the APFA changed its name to the National Football League (NFL).

In 1932, the season ended with the Chicago Bears () and the Portsmouth Spartans () tied for first in the league standings. At the time, teams were ranked on a single table and the team with the highest winning percentage (not including ties, which were not counted towards the standings) at the end of the season was declared the champion; the only tiebreaker was that in the event of a tie, if two teams played twice in a season, the result of the second game determined the title (the source of the 1921 controversy). This method had been used since the league's creation in 1920, but no situation had been encountered where two teams were tied for first. The league quickly determined that a playoff game between Chicago and Portsmouth was needed to decide the league's champion. The teams were originally scheduled to play the playoff game, officially a regular season game that would count towards the regular season standings, at Wrigley Field in Chicago, but a combination of heavy snow and extreme cold forced the game to be moved indoors to Chicago Stadium, which did not have a regulation-size football field. Playing with altered rules to accommodate the smaller playing field, the Bears won the game 9–0 and thus won the championship. Fan interest in the "de facto" championship game led the NFL, beginning in 1933, to split into two divisions with a championship game to be played between the division champions. The 1934 season also marked the first of 12 seasons in which African Americans were absent from the league. The "de facto" ban was rescinded in 1946, following public pressure and coinciding with the removal of a similar ban in Major League Baseball.

The NFL was always the foremost professional football league in the United States; it nevertheless faced a large number of rival professional leagues through the 1930s and 1940s. Rival leagues included at least three separate American Football Leagues and the All-America Football Conference (AAFC), on top of various regional leagues of varying caliber. Three NFL teams trace their histories to these rival leagues, including the Los Angeles Rams (who came from a 1936 iteration of the American Football League), the Cleveland Browns and San Francisco 49ers (the last two of which came from the AAFC). By the 1950s, the NFL had an effective monopoly on professional football in the United States; its only competition in North America was the professional Canadian football circuit, which formally became the Canadian Football League (CFL) in 1958. With Canadian football being a different football code than the American game, the CFL established a niche market in Canada and still survives as an independent league.

A new professional league, the fourth American Football League (AFL), began play in 1960. The upstart AFL began to challenge the established NFL in popularity, gaining lucrative television contracts and engaging in a bidding war with the NFL for free agents and draft picks. The two leagues announced a merger on June 8, 1966, to take full effect in 1970. In the meantime, the leagues would hold a common draft and championship game. The game, the Super Bowl, was held four times before the merger, with the NFL winning Super Bowl I and Super Bowl II, and the AFL winning Super Bowl III and Super Bowl IV. After the league merged, it was reorganized into two conferences: the National Football Conference (NFC), consisting of most of the pre-merger NFL teams, and the American Football Conference (AFC), consisting of all of the AFL teams as well as three pre-merger NFL teams.

Today, the NFL is considered the most popular sports league in North America; much of its growth is attributed to former Commissioner Pete Rozelle, who led the league from 1960 to 1989. Overall annual attendance increased from three million at the beginning of his tenure to seventeen million by the end of his tenure, and 400 million global viewers watched 1989's Super Bowl XXIII. The NFL established NFL Properties in 1963. The league's licensing wing, NFL Properties earns the league billions of dollars annually; Rozelle's tenure also marked the creation of NFL Charities and a national partnership with United Way. Paul Tagliabue was elected as commissioner to succeed Rozelle; his seventeen-year tenure, which ended in 2006, was marked by large increases in television contracts and the addition of four expansion teams, as well as the introduction of league initiatives to increase the number of minorities in league and team management roles. The league's current Commissioner, Roger Goodell, has focused on reducing the number of illegal hits and making the sport safer, mainly through fining or suspending players who break rules. These actions are among many the NFL is taking to reduce concussions and improve player safety.

From 1920 to 1934, the NFL did not have a set number of games for teams to play, instead setting a minimum. The league mandated a 12-game regular season for each team beginning in 1935, later shortening this to 11 games in 1937 and 10 games in 1943, mainly due to World War II. After the war ended, the number of games returned to 11 games in 1946 and to 12 in 1947. The NFL went to a 14-game schedule in 1961, which it retained until switching to the current 16-game schedule in 1978. Proposals to increase the regular season to 18 games have been made, but have been rejected in labor negotiations with the National Football League Players Association (NFLPA).

The NFL operated in a two-conference system from 1933 to 1966, where the champions of each conference would meet in the . If two teams tied for the conference lead, they would meet in a one-game playoff to determine the conference champion. In 1967, the NFL expanded from 15 teams to 16 teams. Instead of just evening out the conferences by adding the expansion New Orleans Saints to the seven-member Western Conference, the NFL realigned the conferences and split each into two four-team divisions. The four division champions would meet in the NFL playoffs, a two-round playoff. The NFL also operated the Playoff Bowl (officially the Bert Bell Benefit Bowl) from 1960 to 1969. Effectively a third-place game, pitting the two conference runners-up against each other, the league considers Playoff Bowls to have been exhibitions rather than playoff games. The league discontinued the Playoff Bowl in 1970 due to its perception as a game for losers.

Following the addition of the former AFL teams into the NFL in 1970, the NFL split into two conferences with three divisions each. The expanded league, now with twenty-six teams, would also feature an expanded eight-team playoff, the participants being the three division champions from each conference as well as one 'wild card' team (the team with the best win percentage) from each conference. In 1978, the league added a second wild card team from each conference, bringing the total number of playoff teams to ten, and a further two wild card teams were added in 1990 to bring the total to twelve. When the NFL expanded to 32 teams in 2002, the league realigned, changing the division structure from three divisions in each conference to four divisions in each conference. As each division champion gets a playoff bid, the number of wild card teams from each conference dropped from three to two.

At the corporate level, the National Football League considers itself a trade association made up of and financed by its 32 member teams.<ref name="https://www.nytimes.com/2008/08/12/sports/football/12nfltax.html"></ref> Up until 2015, the league was an unincorporated nonprofit 501(c)(6) association. Section 501(c)(6) of the Internal Revenue Code provides an exemption from federal income taxation for "Business leagues, chambers of commerce, real-estate boards, boards of trade, or professional football leagues (whether or not administering a pension fund for football players), not organized for profit and no part of the net earnings of which inures to the benefit of any private shareholder or individual.". In contrast, each individual team (except the non-profit Green Bay Packers) is subject to tax because they make a profit.

The NFL gave up the tax exempt status in 2015 following public criticism; in a letter to the club owners, Commissioner Roger Goodell labeled it a "distraction", saying "the effects of the tax exempt status of the league office have been mischaracterized repeatedly in recent years... Every dollar of income generated through television rights fees, licensing agreements, sponsorships, ticket sales, and other means is earned by the 32 clubs and is taxable there. This will remain the case even when the league office and Management Council file returns as taxable entities, and the change in filing status will make no material difference to our business." As a result, the league office might owe around US$10 million in income taxes, but it is no longer required to disclose the salaries of its executive officers.

The league has three defined officers: the commissioner, secretary, and treasurer. Each conference has one defined officer, the president, which is essentially an honorary position with few powers and mostly ceremonial duties (such as awarding the conference championship trophy).

The commissioner is elected by affirmative vote of two-thirds or 18 (whichever is greater) of the members of the league, while the president of each conference is elected by an affirmative vote of three-fourths or ten of the conference members. The commissioner appoints the secretary and treasurer and has broad authority in disputes between clubs, players, coaches, and employees. He is the "principal executive officer" of the NFL and also has authority in hiring league employees, negotiating television contracts, disciplining individuals that own part or all of an NFL team, clubs, or employed individuals of an NFL club if they have violated league bylaws or committed "conduct detrimental to the welfare of the League or professional football". The commissioner can, in the event of misconduct by a party associated with the league, suspend individuals, hand down a fine of up to US$500,000, cancel contracts with the league, and award or strip teams of draft picks.

In extreme cases, the commissioner can offer recommendations to the NFL's Executive Committee up to and including the "cancellation or forfeiture" of a club's franchise or any other action he deems necessary. The commissioner can also issue sanctions up to and including a lifetime ban from the league if an individual connected to the NFL has bet on games or failed to notify the league of conspiracies or plans to bet on or fix games. The current Commissioner of the National Football League is Roger Goodell, who was elected in 2006 after Paul Tagliabue, the previous commissioner, retired.

NFL revenue is from three primary sources: NFL Ventures (merchandising), NFL Enterprises (NFL Network and NFL Sunday Ticket, which the league controls), and the television contract. The league distributes such revenue equally among teams, regardless of performance. each team receives $255 million annually from the league's television contract, up 150% from $99.9 million in 2010.

Most NFL teams' financial statements are secret. "The Kansas City Star" obtained the Kansas City Chiefs' tax returns for 2008–2010. According to the "Star", the team's revenue rose from $231 million in 2008 to $302 million in 2010. In 2010, two thirds of revenue came from the league: $99.8 million from NFL Ventures ($55.3 million) and NFL Enterprises ($44.6 million), and the $99.9 million share of the television contract. The remaining one third was from tickets ($42.4 million), corporate sponsorships ($6.6 million), food sales ($5 million), parking passes ($4.7 million), in-stadium advertising ($3.7 million), radio contract ($2.7 million), and miscellaneous sources.

The largest Chiefs expense in 2010 was $148 million for players, coaches, and other employees. Of the $38 million in operating income, Clark, Lamar Jr., two other children, and widow of former team owner Lamar Hunt divided $17.6 million, and reinvested the remaining $20 million into the team.

According to economist Richard D. Wolff, the NFL's revenue model is in contravention of the typical corporate structure. By redistributing profits to all teams the NFL is ensuring that one team will not dominate the league through excessive earnings. Roger Noll described the revenue sharing as the league's "most important structural weakness", however, as there is no disincentive against a team playing badly and the largest cost item, player salaries, is capped.

The NFL consists of 32 clubs divided into two conferences of 16 teams in each. Each conference is divided into four divisions of four clubs in each. During the regular season, each team is allowed a maximum of 53 players on its roster; only 46 of these may be active (eligible to play) on game days. Each team can also have a 10-player practice squad separate from its main roster, but the practice squad may only be composed of players who were not active for at least nine games in any of their seasons in the league. A player can only be on a practice squad for a maximum of three seasons.

Each NFL club is granted a franchise, the league's authorization for the team to operate in its home city. This franchise covers 'Home Territory' (the 75 miles surrounding the city limits, or, if the team is within 100 miles of another league city, half the distance between the two cities) and 'Home Marketing Area' (Home Territory plus the rest of the state the club operates in, as well as the area the team operates its training camp in for the duration of the camp). Each NFL member has the exclusive right to host professional football games inside its Home Territory and the exclusive right to advertise, promote, and host events in its Home Marketing Area. There are a couple of exceptions to this rule, mostly relating to teams with close proximity to each other: teams that operate in the same city (e.g. New York City and Los Angeles) or the same state (e.g. California, Florida, and Texas) share the rights to the city's Home Territory and the state's Home Marketing Area, respectively.

Every NFL team is based in the contiguous United States. Although no team is based in a foreign country, the Jacksonville Jaguars began playing one home game a year at Wembley Stadium in London, England, in 2013 as part of the NFL International Series. The Jaguars' agreement with Wembley was originally set to expire in 2016, but has since been extended through 2020. The Buffalo Bills played one home game every season at Rogers Centre in Toronto, Ontario, Canada, as part of the Bills Toronto Series from to . Mexico also hosted an NFL regular-season game, a 2005 game between the San Francisco 49ers and Arizona Cardinals known as "Fútbol Americano", and 39 international preseason games were played from 1986 to 2005 as part of the American Bowl series. The Raiders and Houston Texans played a game in Mexico City at Estadio Azteca on November 21, 2016.

According to "Forbes", the Dallas Cowboys, at approximately US$5 billion, are the most valuable NFL franchise and the most valuable sports team in the world. Also, 26 of the 32 NFL teams rank among the Top 50 most valuable sports teams in the world; and 16 of the NFL's owners are listed on the Forbes 400, the most of any sports league or organization.

The 32 teams are organized into eight geographic divisions of four teams each. These divisions are further organized into two conferences, the National Football Conference and the American Football Conference. The two-conference structure has its origins in a time when major American professional football was organized into two independent leagues, the National Football League and its younger rival, the American Football League. The leagues merged in the late 1960s, adopting the older league's name and reorganizing slightly to ensure the same number of teams in both conferences.

The NFL season format consists of a four-week preseason, a seventeen-week regular season (each team plays 16 games), and a twelve-team single-elimination playoff culminating in the Super Bowl, the league's championship game.

The NFL preseason begins with the Pro Football Hall of Fame Game, played at Fawcett Stadium in Canton.<ref name="NFL/Hall of Fame Game"></ref> Each NFL team is required to schedule four preseason games, two of which must be at its home stadium, but the teams involved in the Hall of Fame game, as well as any teams playing in an American Bowl game, play five preseason games. Preseason games are exhibition matches and do not count towards regular-season totals. Because the preseason does not count towards standings, teams generally do not focus on winning games; instead, they are used by coaches to evaluate their teams and by players to show their performance, both to their current team and to other teams if they get cut. The quality of preseason games has been criticized by some fans, who dislike having to pay full price for exhibition games, as well as by some players and coaches, who dislike the risk of injury the games have, while others have felt the preseason is a necessary part of the NFL season.

Currently, the thirteen opponents each team faces over the 16-game regular season schedule are set using a pre-determined formula: The league runs a seventeen-week, 256-game regular season. Since 2001, the season has begun the week after Labor Day (first Monday in September) and concluded the week after Christmas. The opening game of the season is normally a home game on a Thursday for the league's defending champion.

Most NFL games are played on Sundays, with a Monday night game typically held at least once a week and Thursday night games occurring on most weeks as well. NFL games are not normally played on Fridays or Saturdays until late in the regular season, as federal law prohibits professional football leagues from competing with college or high school football. Because high school and college teams typically play games on Friday and Saturday, respectively, the NFL cannot hold games on those days until the Friday before the third Saturday in December. While Saturday games late in the season are common, the league rarely holds Friday games, the most recent one being on Christmas Day in 2009. NFL games are rarely scheduled for Tuesday or Wednesday, and those days have only been used twice since 1948: in 2010, when a Sunday game was rescheduled to Tuesday due to a blizzard, and in 2012, when the Kickoff game was moved from Thursday to Wednesday to avoid conflict with the Democratic National Convention.

NFL regular season matchups are determined according to a scheduling formula. Within a division, all four teams play fourteen out of their sixteen games against common opponents – two games (home and away) are played against the other three teams in the division, while one game is held against all the members of a division from the NFC and a division from the AFC as determined by a rotating cycle (three years for the conference the team is in, and four years in the conference they are not in). The other two games are intraconference games, determined by the standings of the previous year – for example, if a team finishes first in its division, it will play two other first-place teams in its conference, while a team that finishes last would play two other last-place teams in the conference. In total, each team plays sixteen games and has one bye week, where they do not play any games.

Although a team's home and away opponents are known by the end of the previous year's regular season, the exact dates and times for NFL games are not determined until much later because the league has to account for, among other things, the Major League Baseball postseason and local events that could pose a scheduling conflict with NFL games. During the 2010 season, over 500,000 potential schedules were created by computers, 5,000 of which were considered "playable schedules" and were reviewed by the NFL's scheduling team. After arriving at what they felt was the best schedule out of the group, nearly 50 more potential schedules were developed to try to ensure that the chosen schedule would be the best possible one.

Following the conclusion of the regular season, the NFL Playoffs, a twelve-team single elimination tournament, is then held. Six teams are selected from each conference: the winners of each of the four divisions as well as two wild card teams (the two remaining teams with the best overall record). These teams are seeded according to overall record, with the division champions always ranking higher than either of the wild card teams. The top two teams (seeded one and two) from each conference are awarded a bye week, while the remaining four teams (seeded 3–6) from each conference compete in the first round of the playoffs, the Wild Card round, with the third seed competing against the sixth seed and the fourth seed competing against the fifth seed. The winners of the Wild Card round advance to the Divisional Round, which matches the lower seeded team against the first seed and the higher seeded team against the second seed. The winners of those games then compete in the Conference Championships, with the higher remaining seed hosting the lower remaining seed. The AFC and NFC champions then compete in the Super Bowl to determine the league champion.

The only other postseason event hosted by the NFL is the Pro Bowl, the league's all-star game. Since 2009, the Pro Bowl has been held the week before the Super Bowl; in previous years, the game was held the week following the Super Bowl, but in an effort to boost ratings, the game was moved to the week before. Because of this, players from the teams participating in the Super Bowl are exempt from participating in the game. The Pro Bowl is not considered as competitive as a regular-season game because the biggest concern of teams is to avoid injuries to the players.

The National Football League has used three different trophies to honor its champion over its existence. The first trophy, the Brunswick-Balke Collender Cup, was donated to the NFL (then APFA) in 1920 by the Brunswick-Balke Collender Corporation. The trophy, the appearance of which is only known by its description as a "silver loving cup", was intended to be a traveling trophy and not to become permanent until a team had won at least three titles. The league awarded it to the Akron Pros, champions of the inaugural 1920 season; however, the trophy was discontinued and its current whereabouts are unknown.

A second trophy, the Ed Thorp Memorial Trophy, was issued by the NFL from 1934 to 1967. The trophy's namesake, Ed Thorp, was a referee in the league and a friend to many early league owners; upon his death in 1934, the league created the trophy to honor him. In addition to the main trophy, which would be in the possession of the current league champion, the league issued a smaller replica trophy to each champion, who would maintain permanent control over it. The current location of the Ed Thorp Memorial Trophy, long thought to be lost, is believed to be possessed by the Green Bay Packers Hall of Fame.

The current trophy of the NFL is the Vince Lombardi Trophy. The Super Bowl trophy was officially renamed in 1970 after Vince Lombardi, who as head coach led the Green Bay Packers to victories in the first two Super Bowls. Unlike the previous trophies, a new Vince Lombardi Trophy is issued to each year's champion, who maintains permanent control of it. Lombardi Trophies are made by Tiffany & Co. out of sterling silver and are worth anywhere from US$25,000 to US$300,000. Additionally, each player on the winning team as well as coaches and personnel are awarded Super Bowl rings to commemorate their victory. The winning team chooses the company that makes the rings; each ring design varies, with the NFL mandating certain ring specifications (which have a degree of room for deviation), in addition to requiring the Super Bowl logo be on at least one side of the ring. The losing team are also awarded rings, which must be no more than half as valuable as the winners' rings, but those are almost never worn.

The conference champions receive trophies for their achievement. The champions of the NFC receive the George Halas Trophy, named after Chicago Bears founder George Halas, who is also considered as one of the co-founders of the NFL. The AFC champions receive the Lamar Hunt Trophy, named after Lamar Hunt, the founder of the Kansas City Chiefs and the principal founder of the American Football League. Players on the winning team also receive a conference championship ring.

The NFL recognizes a number of awards for its players and coaches at its annual NFL Honors presentation. The most prestigious award is the AP Most Valuable Player (MVP) award. Other major awards include the AP Offensive Player of the Year, AP Defensive Player of the Year, AP Comeback Player of the Year, and the AP Offensive and Defensive Rookie of the Year awards. Another prestigious award is the Walter Payton Man of the Year Award, which recognizes a player's off-field work in addition to his on-field performance. The NFL Coach of the Year award is the highest coaching award. The NFL also gives out weekly awards such as the FedEx Air & Ground NFL Players of the Week and the Pepsi MAX NFL Rookie of the Week awards.

In the United States, the National Football League has television contracts with four networks: CBS, ESPN, Fox, and NBC. Collectively, these contracts cover every regular season and postseason game. In general, CBS televises afternoon games in which the away team is an AFC team, and Fox carries afternoon games in which the away team belongs to the NFC. These afternoon games are not carried on all affiliates, as multiple games are being played at once; each network affiliate is assigned one game per time slot, according to a complicated set of rules. Since 2011, the league has reserved the right to give Sunday games that, under the contract, would normally air on one network to the other network (known as "flexible scheduling"). The only way to legally watch a regionally televised game not being carried on the local network affiliates is to purchase NFL Sunday Ticket, the league's out-of-market sports package, which is only available to subscribers to the DirecTV satellite service. The league also provides RedZone, an omnibus telecast that cuts to the most relevant plays in each game, live as they happen.

In addition to the regional games, the league also has packages of telecasts, mostly in prime time, that are carried nationwide. NBC broadcasts the primetime "Sunday Night Football" package', which includes the Thursday NFL Kickoff game that starts the regular season and a primetime Thanksgiving Day game. ESPN carries all Monday Night Football games. The NFL's own network, NFL Network, broadcasts a series titled "Thursday Night Football", which was originally exclusive to the network, but which in recent years has had several games simulcast on CBS (since 2014) and NBC (since 2016) (except the Thanksgiving and kickoff games, which remain exclusive to NBC). For the 2017 season, the NFL Network will broadcast 18 regular season games under its "Thursday Night Football" brand, 16 Thursday-evening contests (10 of which are simulcast on either NBC or CBS) as well as one of the NFL International Series games on a Sunday morning and one of the 2017 Christmas afternoon games. In addition, 10 of the Thursday night games will be streamed live on Amazon Prime. In 2017, the NFL games occupied the top three rates for a 30-second advertisement: $699,602 for Sunday Night Football, $550,709 for Thursday Night Football (NBC), and $549,791 for Thursday Night Football (CBS).

The Super Bowl television rights are rotated on a three-year basis between CBS, Fox, and NBC. In 2011, all four stations signed new nine-year contracts with the NFL, each running until 2022; CBS, Fox, and NBC are estimated by "Forbes" to pay a combined total of US$3 billion a year, while ESPN will pay US$1.9 billion a year. The league also has deals with Spanish-language broadcasters NBC Universo, Fox Deportes, and ESPN Deportes, which air Spanish language dubs of their respective English-language sister networks' games. The league's contracts do not cover preseason games, which individual teams are free to sell to local stations directly; a minority of preseason games are distributed among the league's national television partners.

Through the 2014 season, the NFL had a blackout policy in which games were 'blacked out' on local television in the home team's area if the home stadium was not sold out. Clubs could elect to set this requirement at only 85%, but they would have to give more ticket revenue to the visiting team; teams could also request a specific exemption from the NFL for the game. The vast majority of NFL games were not blacked out; only 6% of games were blacked out during the 2011 season, and only two games were blacked out in and none in . The NFL announced in March 2015 that it would suspend its blackout policy for at least the 2015 season. According to Nielsen, the NFL regular season since 2012 was watched by at least 200 million individuals, accounting for 80% of all television households in the United States and 69% of all potential viewers in the United States. NFL regular season games accounted for 31 out of the top 32 most-watched programs in the fall season and an NFL game ranked as the most-watched television show in all 17 weeks of the regular season. At the local level, NFL games were the highest-ranked shows in NFL markets 92% of the time. Super Bowls account for the 22 most-watched programs (based on total audience) in US history, including a record 167 million people that watched Super Bowl XLVIII, the conclusion to the 2013 season.

In addition to radio networks run by each NFL team, select NFL games are broadcast nationally by Westwood One (known as Dial Global for the 2012 season). These games are broadcast on over 500 networks, giving all NFL markets access to each primetime game. The NFL's deal with Westwood One was extended in 2012 and will run through 2017.

Some broadcasting innovations have either been introduced or popularized during NFL telecasts. Among them, the Skycam camera system was used for the first time in a live telecast, at a 1984 preseason NFL game in San Diego between the Chargers and 49ers, and televised by CBS. Commentator John Madden famously used a telestrator during games between the early 1980s to the mid-2000s, boosting the device's popularity.

The NFL, as a one-time experiment, distributed the October 25, 2015 International Series game from Wembley Stadium in London between the Buffalo Bills and Jacksonville Jaguars. The game was live streamed on the Internet exclusively via Yahoo!, except for over-the-air broadcasts on the local CBS-TV affiliates in the Buffalo and Jacksonville markets.

In 2015, the NFL began sponsoring a series of public service announcements to bring attention to domestic abuse and sexual assault in response to what was seen as poor handling of incidents of violence by players.

Each April (excluding 2014 when it took place in May), the NFL holds a draft of college players. The draft consists of seven rounds, with each of the 32 clubs getting one pick in each round. The draft order for non-playoff teams is determined by regular-season record; among playoff teams, teams are first ranked by the furthest round of the playoffs they reached, and then are ranked by regular-season record. For example, any team that reached the divisional round will be given a higher pick than any team that reached the conference championships, but will be given a lower pick than any team that did not make the divisional round. The Super Bowl champion always drafts last, and the losing team from the Super Bowl always drafts next-to-last. All potential draftees must be at least three years removed from high school in order to be eligible for the draft. Underclassmen that have met that criterion to be eligible for the draft must write an application to the NFL by January 15 renouncing their remaining college eligibility. Clubs can trade away picks for future draft picks, but cannot trade the rights to players they have selected in previous drafts.
Aside from the 7 picks each club gets, compensatory draft picks are given to teams that have lost more compensatory free agents than they have gained. These are spread out from rounds 3 to 7, and a total of 32 are given. Clubs are required to make their selection within a certain period of time, the exact time depending on which round the pick is made in. If they fail to do so on time, the clubs behind them can begin to select their players in order, but they do not lose the pick outright. This happened in the 2003 draft, when the Minnesota Vikings failed to make their selection on time. The Jacksonville Jaguars and Carolina Panthers were able to make their picks before the Vikings were able to use theirs. Selected players are only allowed to negotiate contracts with the team that picked them, but if they choose not to sign they become eligible for the next year's draft. Under the current collective bargaining contract, all contracts to drafted players must be four-year deals with a club option for a fifth. Contracts themselves are limited to a certain amount of money, depending on the exact draft pick the player was selected with. Players who were draft eligible but not picked in the draft are free to sign with any club.

The NFL operates several other drafts in addition to the NFL draft. The league holds a supplemental draft annually. Clubs submit emails to the league stating the player they wish to select and the round they will do so, and the team with the highest bid wins the rights to that player. The exact order is determined by a lottery held before the draft, and a successful bid for a player will result in the team forfeiting the rights to its pick in the equivalent round of the next NFL draft. Players are only eligible for the supplemental draft after being granted a petition for special eligibility. The league holds expansion drafts, the most recent happening in 2002 when the Houston Texans began play as an expansion team. Other drafts held by the league include an allocation draft in 1950 to allocate players from several teams that played in the dissolved All-America Football Conference and a supplemental draft in 1984 to give NFL teams the rights to players who had been eligible for the main draft but had not been drafted because they had signed contracts with the United States Football League or Canadian Football League.

Like the other major sports leagues in the United States, the NFL maintains protocol for a disaster draft. In the event of a 'near disaster' (less than 15 players killed or disabled) that caused the club to lose a quarterback, they could draft one from a team with at least three quarterbacks. In the event of a 'disaster' (15 or more players killed or disabled) that results in a club's season being canceled, a restocking draft would be held. Neither of these protocols has ever had to be implemented.

Free agents in the National Football League are divided into restricted free agents, who have three accrued seasons and whose current contract has expired, and unrestricted free agents, who have four or more accrued seasons and whose contract has expired. An accrued season is defined as "six or more regular-season games on a club's active/inactive, reserved/injured or reserve/physically unable to perform lists". Restricted free agents are allowed to negotiate with other clubs besides their former club, but the former club has the right to match any offer. If they choose not to, they are compensated with draft picks. Unrestricted free agents are free to sign with any club, and no compensation is owed if they sign with a different club.

Clubs are given one franchise tag to offer to any unrestricted free agent. The franchise tag is a one-year deal that pays the player 120% of his previous contract or no less than the average of the five highest-paid players at his position, whichever is greater. There are two types of franchise tags: exclusive tags, which do not allow the player to negotiate with other clubs, and non-exclusive tags, which allow the player to negotiate with other clubs but gives his former club the right to match any offer and two first-round draft picks if they decline to match it.

Clubs also have the option to use a transition tag, which is similar to the non-exclusive franchise tag but offers no compensation if the former club refuses to match the offer. Due to that stipulation, the transition tag is rarely used, even with the removal of the "poison pill" strategy (offering a contract with stipulations that the former club would be unable to match) that essentially ended the usage of the tag league-wide. Each club is subject to a salary cap, which is set at US$188.2 million for the 2019 season, US$11 million more than that of 2018.(for previous figures, see Salary cap#National Football League).

Members of clubs' practice squads, despite being paid by and working for their respective clubs, are also simultaneously a kind of free agent and are able to sign to any other club's active roster (provided their new club is not their previous club's next opponent within a set number of days) without compensation to their previous club; practice squad players cannot be signed to other clubs' practice squads, however, unless released by their original club first.




</doc>
<doc id="21212" url="https://en.wikipedia.org/wiki?curid=21212" title="Nazi Germany">
Nazi Germany

Nazi Germany is the common English name for Germany between 1933 and 1945, when Adolf Hitler and his Nazi Party (NSDAP) controlled the country through a dictatorship. Under Hitler's rule, Germany was transformed into a totalitarian state where nearly all aspects of life were controlled by the government. The official name of the state was Deutsches Reich (German Reich) until 1943 and Großdeutsches Reich (Greater German Reich) from 1943 to 1945. Nazi Germany is also known as the Third Reich ("Drittes Reich"), meaning "Third Realm" or "Third Empire", the first two being the Holy Roman Empire (800–1806) and the German Empire (1871–1918). The Nazi regime ended after the Allies defeated Germany in May 1945, ending World War II in Europe.

Hitler was appointed Chancellor of Germany by the President of the Weimar Republic, Paul von Hindenburg, on 30 January 1933. The NSDAP then began to eliminate all political opposition and consolidate its power. Hindenburg died on 2 August 1934 and Hitler became dictator of Germany by merging the offices and powers of the Chancellery and Presidency. A national referendum held 19 August 1934 confirmed Hitler as sole "Führer" (leader) of Germany. All power was centralised in Hitler's person and his word became the highest law. The government was not a coordinated, co-operating body, but a collection of factions struggling for power and Hitler's favour. In the midst of the Great Depression, the Nazis restored economic stability and ended mass unemployment using heavy military spending and a mixed economy. Using deficit spending, the regime undertook extensive public works, including the construction of "Autobahnen" (motorways). The return to economic stability boosted the regime's popularity.

Racism, especially antisemitism, was a central ideological feature of the regime. The Germanic peoples were considered by the Nazis to be the master race, the purest branch of the Aryan race. Discrimination and persecution against Jews and Romani people began in earnest after the seizure of power. The first concentration camps were established in March 1933. Jews and others deemed undesirable were imprisoned, and liberals, socialists, and communists were killed, imprisoned, or exiled. Christian churches and citizens that opposed Hitler's rule were oppressed, and many leaders imprisoned. Education focused on racial biology, population policy, and fitness for military service. Career and educational opportunities for women were curtailed. Recreation and tourism were organised via the Strength Through Joy program, and the 1936 Summer Olympics showcased Germany on the international stage. Propaganda Minister Joseph Goebbels made effective use of film, mass rallies, and Hitler's hypnotic oratory to influence public opinion. The government controlled artistic expression, promoting specific art forms and banning or discouraging others.

The Nazi regime dominated neighbours through military threats in the years leading up to war. Nazi Germany made increasingly aggressive territorial demands, threatening war if these were not met. It seized Austria and almost all of Czechoslovakia in 1938 and 1939. Germany signed a non-aggression pact with the USSR, and invaded Poland on 1 September 1939, launching World War II in Europe. By early 1941, Germany controlled much of Europe. "Reichskommissariats" took control of conquered areas and a German administration was established in the remainder of Poland. Germany exploited the raw materials and labour of both its occupied territories and its allies. "Einsatzgruppen" paramilitary death squads inside the occupied territories conducted mass killings of millions of Jews and other peoples deemed undesirable by the state. Many others were imprisoned, worked to death, or murdered in Nazi concentration camps and extermination camps. This genocide is known as the Holocaust.

While the German invasion of the Soviet Union in 1941 was initially successful, the Soviet resurgence and entry of the United States into the war meant the "Wehrmacht" (German armed forces) lost the initiative on the Eastern Front in 1943 and by late 1944 had been pushed back to the pre-1939 border. Large-scale aerial bombing of Germany escalated in 1944 and the Axis powers were driven back in Eastern and Southern Europe. After the Allied invasion of France, Germany was conquered by the Soviet Union from the east and the other Allies from the west, and capitulated in May 1945. Hitler's refusal to admit defeat led to massive destruction of German infrastructure and additional war-related deaths in the closing months of the war. The victorious Allies initiated a policy of denazification and put many of the surviving Nazi leadership on trial for war crimes at the Nuremberg trials.

The official name of the state was "Deutsches Reich" from 1933 to 1943 and "Großdeutsches Reich" from 1943 to 1945, while common English terms are "Nazi Germany" and "Third Reich". The latter, adopted by Nazi propaganda as "Drittes Reich", was first used in "Das Dritte Reich", a 1923 book by Arthur Moeller van den Bruck. The book counted the Holy Roman Empire (962–1806) as the first Reich and the German Empire (1871–1918) as the second.

Germany was known as the Weimar Republic during the years 1919 to 1933. It was a republic with a semi-presidential system. The Weimar Republic faced numerous problems, including hyperinflation, political extremism (including violence from left- and right-wing paramilitaries), contentious relationships with the Allied victors of World War I, and a series of failed attempts at coalition government by divided political parties. Severe setbacks to the German economy began after World War I ended, partly because of reparations payments required under the 1919 Treaty of Versailles. The government printed money to make the payments and to repay the country's war debt, but the resulting hyperinflation led to inflated prices for consumer goods, economic chaos, and food riots. When the government defaulted on their reparations payments in January 1923, French troops occupied German industrial areas along the Ruhr and widespread civil unrest followed.

The National Socialist German Workers' Party ("Nationalsozialistische Deutsche Arbeiterpartei", NSDAP; Nazi Party) was founded in 1920. It was the renamed successor of the German Workers' Party (DAP) formed one year earlier, and one of several far-right political parties then active in Germany. The NSDAP party platform included destruction of the Weimar Republic, rejection of the terms of the Treaty of Versailles, radical antisemitism, and anti-Bolshevism. They promised a strong central government, increased "Lebensraum" ("living space") for Germanic peoples, formation of a national community based on race, and racial cleansing via the active suppression of Jews, who would be stripped of their citizenship and civil rights. The Nazis proposed national and cultural renewal based upon the "Völkisch" movement. The party, especially its paramilitary organisation "Sturmabteilung" (SA; Storm Detachment; Brownshirts), used physical violence to advance their political position, disrupting the meetings of rival organisations and attacking their members (as well as Jewish people) on the streets. Such far-right armed groups were common in Bavaria, and were tolerated by the sympathetic far-right state government of Gustav Ritter von Kahr.

When the stock market in the United States crashed on 24 October 1929, the effect in Germany was dire. Millions were thrown out of work and several major banks collapsed. Hitler and the NSDAP prepared to take advantage of the emergency to gain support for their party. They promised to strengthen the economy and provide jobs. Many voters decided the NSDAP was capable of restoring order, quelling civil unrest, and improving Germany's international reputation. After the federal election of 1932, the NSDAP was the largest party in the Reichstag, holding 230 seats with 37.4 percent of the popular vote.

Although the Nazis won the greatest share of the popular vote in the two Reichstag general elections of 1932, they did not have a majority. Hitler therefore led a short-lived coalition government formed with the German National People's Party. Under pressure from politicians, industrialists, and the business community, President Paul von Hindenburg appointed Hitler as Chancellor of Germany on 30 January 1933. This event is known as the "Machtergreifung" ("seizure of power").

On the night of 27 February 1933, the Reichstag building was set afire. Marinus van der Lubbe, a Dutch communist, was found guilty of starting the blaze. Hitler proclaimed that the arson marked the start of a communist uprising. The Reichstag Fire Decree, imposed on 28 February 1933, rescinded most civil liberties, including rights of assembly and freedom of the press. The decree also allowed the police to detain people indefinitely without charges. The legislation was accompanied by a propaganda campaign that led to public support for the measure. Violent suppression of communists by the SA was undertaken nationwide and 4,000 members of the Communist Party of Germany were arrested.

In March 1933, the Enabling Act, an amendment to the Weimar Constitution, passed in the Reichstag by a vote of 444 to 94. This amendment allowed Hitler and his cabinet to pass laws—even laws that violated the constitution—without the consent of the president or the Reichstag. As the bill required a two-thirds majority to pass, the Nazis used intimidation tactics as well as the provisions of the Reichstag Fire Decree to keep several Social Democratic deputies from attending, and the Communists had already been banned. On 10 May, the government seized the assets of the Social Democrats, and they were banned on 22 June. On 21 June, the SA raided the offices of the German National People's Party – their former coalition partners – and they disbanded on 29 June. The remaining major political parties followed suit. On 14 July 1933 Germany became a one-party state with the passage of a law decreeing the NSDAP to be the sole legal party in Germany. The founding of new parties was also made illegal, and all remaining political parties which had not already been dissolved were banned. The Enabling Act would subsequently serve as the legal foundation for the dictatorship the NSDAP established. Further elections in November 1933, 1936, and 1938 were Nazi-controlled, with only members of the NSDAP and a small number of independents elected.

The Hitler cabinet used the terms of the Reichstag Fire Decree and later the Enabling Act to initiate the process of "Gleichschaltung" ("co-ordination"), which brought all aspects of life under party control. Individual states not controlled by elected Nazi governments or Nazi-led coalitions were forced to agree to the appointment of Reich Commissars to bring the states in line with the policies of the central government. These Commissars had the power to appoint and remove local governments, state parliaments, officials, and judges. In this way Germany became a "de facto" unitary state, with all state governments controlled by the central government under the NSDAP. The state parliaments and the "Reichsrat" (federal upper house) were abolished in January 1934, with all state powers being transferred to the central government.

All civilian organisations, including agricultural groups, volunteer organisations, and sports clubs, had their leadership replaced with Nazi sympathisers or party members; these civic organisations either merged with the NSDAP or faced dissolution. The Nazi government declared a "Day of National Labor" for May Day 1933, and invited many trade union delegates to Berlin for celebrations. The day after, SA stormtroopers demolished union offices around the country; all trade unions were forced to dissolve and their leaders were arrested. The Law for the Restoration of the Professional Civil Service, passed in April, removed from their jobs all teachers, professors, judges, magistrates, and government officials who were Jewish or whose commitment to the party was suspect. This meant the only non-political institutions not under control of the NSDAP were the churches.

The Nazi regime abolished the symbols of the Weimar Republic—including the black, red, and gold tricolour flag—and adopted reworked symbolism. The previous imperial black, white, and red tricolour was restored as one of Germany's two official flags; the second was the swastika flag of the NSDAP, which became the sole national flag in 1935. The NSDAP anthem "Horst-Wessel-Lied" ("Horst Wessel Song") became a second national anthem.

Germany was still in a dire economic situation, as six million people were unemployed and the balance of trade deficit was daunting. Using deficit spending, public works projects were undertaken beginning in 1934, creating 1.7 million new jobs by the end of that year alone. Average wages began to rise.

The SA leadership continued to apply pressure for greater political and military power. In response, Hitler used the "Schutzstaffel" (SS) and Gestapo to purge the entire SA leadership. Hitler targeted SA "Stabschef" (Chief of Staff) Ernst Röhm and other SA leaders who—along with a number of Hitler's political adversaries (such as Gregor Strasser and former chancellor Kurt von Schleicher)—were arrested and shot. Up to 200 people were killed from 30 June to 2 July 1934 in an event that became known as the Night of the Long Knives.

On 2 August 1934, Hindenburg died. The previous day, the cabinet had enacted the "Law Concerning the Highest State Office of the Reich", which stated that upon Hindenburg's death the office of president would be abolished and its powers merged with those of the chancellor. Hitler thus became head of state as well as head of government and was formally named as "Führer und Reichskanzler" ("Leader and Chancellor") – although eventually "Reichskanzler" was dropped. Germany was now a totalitarian state with Hitler at its head. As head of state, Hitler became Supreme Commander of the armed forces. The new law provided an altered loyalty oath for servicemen so that they affirmed loyalty to Hitler personally rather than the office of supreme commander or the state. On 19 August, the merger of the presidency with the chancellorship was approved by 90 percent of the electorate in a plebiscite.
Most Germans were relieved that the conflicts and street fighting of the Weimar era had ended. They were deluged with propaganda orchestrated by Minister of Public Enlightenment and Propaganda Joseph Goebbels, who promised peace and plenty for all in a united, Marxist-free country without the constraints of the Versailles Treaty. The NSDAP obtained and legitimised power through its initial revolutionary activities, then through manipulation of legal mechanisms, the use of police powers, and by taking control of the state and federal institutions. The first major Nazi concentration camp, initially for political prisoners, was opened at Dachau in 1933. Hundreds of camps of varying size and function were created by the end of the war.

Beginning in April 1933, scores of measures defining the status of Jews and their rights were instituted. These measures culminated in the establishment of the Nuremberg Laws of 1935, which stripped them of their basic rights. The Nazis would take from the Jews their wealth, their right to intermarry with non-Jews, and their right to occupy many fields of labour (such as law, medicine, or education). Eventually the Nazis declared the Jews as undesirable to remain among German citizens and society.

In the early years of the regime, Germany was without allies, and its military was drastically weakened by the Versailles Treaty. France, Poland, Italy, and the Soviet Union each had reasons to object to Hitler's rise to power. Poland suggested to France that the two nations engage in a preventive war against Germany in March 1933. Fascist Italy objected to German claims in the Balkans and on Austria, which Benito Mussolini considered to be in Italy's sphere of influence.

As early as February 1933, Hitler announced that rearmament must begin, albeit clandestinely at first, as to do so was in violation of the Versailles Treaty. On 17 May 1933, Hitler gave a speech before the Reichstag outlining his desire for world peace and accepted an offer from American President Franklin D. Roosevelt for military disarmament, provided the other nations of Europe did the same. When the other European powers failed to accept this offer, Hitler pulled Germany out of the World Disarmament Conference and the League of Nations in October, claiming its disarmament clauses were unfair if they applied only to Germany. In a referendum held in November, 95 percent of voters supported Germany's withdrawal.

In 1934, Hitler told his military leaders that a war in the east should begin in 1942. The Saarland, which had been placed under League of Nations supervision for 15 years at the end of World War I, voted in January 1935 to become part of Germany. In March 1935, Hitler announced the creation of an air force, and that the "Reichswehr" would be increased to 550,000 men. Britain agreed to Germany building a naval fleet with the signing of the Anglo-German Naval Agreement on 18 June 1935.

When the Italian invasion of Ethiopia led to only mild protests by the British and French governments, on 7 March 1936 Hitler used the Franco-Soviet Treaty of Mutual Assistance as a pretext to order the army to march 3,000 troops into the demilitarised zone in the Rhineland in violation of the Versailles Treaty. As the territory was part of Germany, the British and French governments did not feel that attempting to enforce the treaty was worth the risk of war. In the one-party election held on 29 March, the NSDAP received 98.9 percent support. In 1936, Hitler signed an Anti-Comintern Pact with Japan and a non-aggression agreement with Mussolini, who was soon referring to a "Rome-Berlin Axis".

Hitler sent military supplies and assistance to the Nationalist forces of General Francisco Franco in the Spanish Civil War, which began in July 1936. The German Condor Legion included a range of aircraft and their crews, as well as a tank contingent. The aircraft of the Legion destroyed the city of Guernica in 1937. The Nationalists were victorious in 1939 and became an informal ally of Nazi Germany.

In February 1938, Hitler emphasised to Austrian Chancellor Kurt Schuschnigg the need for Germany to secure its frontiers. Schuschnigg scheduled a plebiscite regarding Austrian independence for 13 March, but Hitler sent an ultimatum to Schuschnigg on 11 March demanding that he hand over all power to the Austrian NSDAP or face an invasion. German troops entered Austria the next day, to be greeted with enthusiasm by the populace.

The Republic of Czechoslovakia was home to a substantial minority of Germans, who lived mostly in the Sudetenland. Under pressure from separatist groups within the Sudeten German Party, the Czechoslovak government offered economic concessions to the region. Hitler decided not just to incorporate the Sudetenland into the Reich, but to destroy the country of Czechoslovakia entirely. The Nazis undertook a propaganda campaign to try to generate support for an invasion. Top German military leaders opposed the plan, as Germany was not yet ready for war.

The crisis led to war preparations by Britain, Czechoslovakia, and France (Czechoslovakia's ally). Attempting to avoid war, British Prime Minister Neville Chamberlain arranged a series of meetings, the result of which was the Munich Agreement, signed on 29 September 1938. The Czechoslovak government was forced to accept the Sudetenland's annexation into Germany. Chamberlain was greeted with cheers when he landed in London, saying the agreement brought "peace for our time". In addition to the German annexation, Poland seized a narrow strip of land near Cieszyn on 2 October, while as a consequence of the Munich Agreement, Hungary demanded and received along their northern border in the First Vienna Award on 2 November. Following negotiations with President Emil Hácha, Hitler seized the rest of the Czech half of the country on 15 March 1939 and created the Protectorate of Bohemia and Moravia, one day after the proclamation of the Slovak Republic in the Slovak half. Also on 15 March, Hungary occupied and annexed the recently proclaimed and unrecognized Carpatho-Ukraine and an additional sliver of land disputed with Slovakia.

Austrian and Czech foreign exchange reserves were seized by the Nazis, as were stockpiles of raw materials such as metals and completed goods such as weaponry and aircraft, which were shipped to Germany. The "Reichswerke Hermann Göring" industrial conglomerate took control of steel and coal production facilities in both countries.

In January 1934, Germany signed a non-aggression pact with Poland. In March 1939, Hitler demanded the return of the Free City of Danzig and the Polish Corridor, a strip of land that separated East Prussia from the rest of Germany. The British announced they would come to the aid of Poland if it was attacked. Hitler, believing the British would not actually take action, ordered an invasion plan should be readied for September 1939. On 23 May, Hitler described to his generals his overall plan of not only seizing the Polish Corridor but greatly expanding German territory eastward at the expense of Poland. He expected this time they would be met by force.

The Germans reaffirmed their alliance with Italy and signed non-aggression pacts with Denmark, Estonia, and Latvia whilst trade links were formalised with Romania, Norway, and Sweden. Foreign Minister Joachim von Ribbentrop arranged in negotiations with the Soviet Union a non-aggression pact, the Molotov–Ribbentrop Pact, signed in August 1939. The treaty also contained secret protocols dividing Poland and the Baltic states into German and Soviet spheres of influence.

Germany's wartime foreign policy involved the creation of allied governments controlled directly or indirectly from Berlin. They intended to obtain soldiers from allies such as Italy and Hungary and workers and food supplies from allies such as Vichy France. Hungary was the fourth nation to join the Axis, signing the Tripartite Pact on 27 September 1940. Bulgaria signed the pact on 17 November. German efforts to secure oil included negotiating a supply from their new ally, Romania, who signed the Pact on 23 November, alongside the Slovak Republic. By late 1942, there were 24 divisions from Romania on the Eastern Front, 10 from Italy, and 10 from Hungary. Germany assumed full control in France in 1942, Italy in 1943, and Hungary in 1944. Although Japan was a powerful ally, the relationship was distant, with little co-ordination or co-operation. For example, Germany refused to share their formula for synthetic oil from coal until late in the war.

Germany invaded Poland and captured the Free City of Danzig on 1 September 1939, beginning World War II in Europe. Honouring their treaty obligations, Britain and France declared war on Germany two days later. Poland fell quickly, as the Soviet Union attacked from the east on 17 September. Reinhard Heydrich, chief of the "Sicherheitspolizei" (SiPo; Security Police) and "Sicherheitsdienst" (SD; Security Service), ordered on 21 September that Polish Jews should be rounded up and concentrated into cities with good rail links. Initially the intention was to deport them further east, or possibly to Madagascar. Using lists prepared in advance, some 65,000 Polish intelligentsia, noblemen, clergy, and teachers were killed by the end of 1939 in an attempt to destroy Poland's identity as a nation. Soviet forces advanced into Finland in the Winter War, and German forces saw action at sea. But little other activity occurred until May, so the period became known as the "Phoney War".

From the start of the war, a British blockade on shipments to Germany affected its economy. Germany was particularly dependent on foreign supplies of oil, coal, and grain. Thanks to trade embargoes and the blockade, imports into Germany declined by 80 per cent. To safeguard Swedish iron ore shipments to Germany, Hitler ordered the invasion of Denmark and Norway, which began on 9 April. Denmark fell after less than a day, while most of Norway followed by the end of the month. By early June, Germany occupied all of Norway.

Against the advice of many of his senior military officers, Hitler ordered an attack on France and the Low Countries, which began in May 1940. They quickly conquered Luxembourg and the Netherlands. After outmanoeuvring the Allies in Belgium and forcing the evacuation of many British and French troops at Dunkirk, France fell as well, surrendering to Germany on 22 June. The victory in France resulted in an upswing in Hitler's popularity and an upsurge in war fever in Germany.

In violation of the provisions of the Hague Convention, industrial firms in the Netherlands, France, and Belgium were put to work producing war materiel for Germany.
The Nazis seized from the French thousands of locomotives and rolling stock, stockpiles of weapons, and raw materials such as copper, tin, oil, and nickel. Payments for occupation costs were levied upon France, Belgium, and Norway. Barriers to trade led to hoarding, black markets, and uncertainty about the future. Food supplies were precarious; production dropped in most of Europe. Famine was experienced in many occupied countries.

Hitler's peace overtures to the new British Prime Minister Winston Churchill were rejected in July 1940. Grand Admiral Erich Raeder had advised Hitler in June that air superiority was a pre-condition for a successful invasion of Britain, so Hitler ordered a series of aerial attacks on Royal Air Force (RAF) airbases and radar stations, as well as nightly air raids on British cities, including London, Plymouth, and Coventry. The German Luftwaffe failed to defeat the RAF in what became known as the Battle of Britain, and by the end of October, Hitler realised that air superiority would not be achieved. He permanently postponed the invasion, a plan which the commanders of the German army had never taken entirely seriously. Several historians, including Andrew Gordon, believe the primary reason for the failure of the invasion plan was the superiority of the Royal Navy, not the actions of the RAF.

In February 1941, the German "Afrika Korps" arrived in Libya to aid the Italians in the North African Campaign. On 6 April, Germany launched an invasion of Yugoslavia and Greece. All of Yugoslavia and parts of Greece were subsequently divided between Germany, Hungary, Italy, and Bulgaria.

On 22 June 1941, contravening the Molotov–Ribbentrop Pact, about 3.8 million Axis troops attacked the Soviet Union. In addition to Hitler's stated purpose of acquiring "Lebensraum", this large-scale offensive—codenamed Operation Barbarossa—was intended to destroy the Soviet Union and seize its natural resources for subsequent aggression against the Western powers. The reaction among Germans was one of surprise and trepidation as many were concerned about how much longer the war would continue or suspected that Germany could not win a war fought on two fronts.
The invasion conquered a huge area, including the Baltic states, Belarus, and west Ukraine. After the successful Battle of Smolensk in September 1941, Hitler ordered Army Group Centre to halt its advance to Moscow and temporarily divert its Panzer groups to aid in the encirclement of Leningrad and Kiev. This pause provided the Red Army with an opportunity to mobilise fresh reserves. The Moscow offensive, which resumed in October 1941, ended disastrously in December. On 7 December 1941, Japan attacked Pearl Harbor, Hawaii. Four days later, Germany declared war on the United States.

Food was in short supply in the conquered areas of the Soviet Union and Poland, as the retreating armies had burned the crops in some areas, and much of the remainder was sent back to the Reich. In Germany, rations were cut in 1942. In his role as Plenipotentiary of the Four Year Plan, Hermann Göring demanded increased shipments of grain from France and fish from Norway. The 1942 harvest was good, and food supplies remained adequate in Western Europe.

Germany and Europe as a whole was almost totally dependent on foreign oil imports. In an attempt to resolve the shortage, in June 1942 Germany launched "Fall Blau" ("Case Blue"), an offensive against the Caucasian oilfields. The Red Army launched a counter-offensive on 19 November and encircled the Axis forces, who were trapped in Stalingrad on 23 November. Göring assured Hitler that the 6th Army could be supplied by air, but this turned out to be infeasible. Hitler's refusal to allow a retreat led to the deaths of 200,000 German and Romanian soldiers; of the 91,000 men who surrendered in the city on 31 January 1943, only 6,000 survivors returned to Germany after the war.

Losses continued to mount after Stalingrad, leading to a sharp reduction in the popularity of the Nazi Party and deteriorating morale. Soviet forces continued to push westward after the failed German offensive at the Battle of Kursk in the summer of 1943. By the end of 1943 the Germans had lost most of their eastern territorial gains. In Egypt, Field Marshal Erwin Rommel's "Afrika Korps" were defeated by British forces under Field Marshal Bernard Montgomery in October 1942. The Allies landed in Sicily in July 1943 and in Italy in September. Meanwhile, American and British bomber fleets based in Britain began operations against Germany. Many sorties were intentionally given civilian targets in an effort to destroy German morale. German aircraft production could not keep pace with losses, and without air cover the Allied bombing campaign became even more devastating. By targeting oil refineries and factories, they crippled the German war effort by late 1944.

On 6 June 1944, American, British, and Canadian forces established a front in France with the D-Day landings in Normandy. On 20 July 1944, Hitler survived an assassination attempt. He ordered brutal reprisals, resulting in 7,000 arrests and the execution of more than 4,900 people. The failed Ardennes Offensive (16 December 1944 – 25 January 1945) was the last major German offensive on the western front, and Soviet forces entered Germany on 27 January. Hitler's refusal to admit defeat and his insistence that the war be fought to the last man led to unnecessary death and destruction in the war's closing months. Through his Justice Minister Otto Georg Thierack, Hitler ordered that anyone who was not prepared to fight should be court-martialed, and thousands of people were put to death. In many areas, people surrendered to the approaching Allies in spite of exhortations of local leaders to continue to fight. Hitler ordered the destruction of transport, bridges, industries, and other infrastructure—a scorched earth decree—but Armaments Minister Albert Speer prevented this order from being fully carried out.

During the Battle of Berlin (16 April 1945 – 2 May 1945), Hitler and his staff lived in the underground "Führerbunker" while the Red Army approached. On 30 April, when Soviet troops were within two blocks of the Reich Chancellery, Hitler, along with his girlfriend and by then wife Eva Braun committed suicide. On 2 May, General Helmuth Weidling unconditionally surrendered Berlin to Soviet General Vasily Chuikov. Hitler was succeeded by Grand Admiral Karl Dönitz as Reich President and Goebbels as Reich Chancellor. Goebbels and his wife Magda committed suicide the next day after murdering their six children. Between 4 and 8 May 1945, most of the remaining German armed forces unconditionally surrendered. The German Instrument of Surrender was signed 8 May, marking the end of the Nazi regime and the end of World War II in Europe.

Popular support for Hitler almost completely disappeared as the war drew to a close. Suicide rates in Germany increased, particularly in areas where the Red Army was advancing. Among soldiers and party personnel, suicide was often deemed an honourable and heroic alternative to surrender. First-hand accounts and propaganda about the uncivilised behaviour of the advancing Soviet troops caused panic among civilians on the Eastern Front, especially women, who feared being raped. More than a thousand people (out of a population of around 16,000) committed suicide in Demmin on and around 1 May 1945 as the 65th Army of 2nd Belorussian Front first broke into a distillery and then rampaged through the town, committing mass rapes, arbitrarily executing civilians, and setting fire to buildings. High numbers of suicides took place in many other locations, including Neubrandenburg (600 dead), Stolp in Pommern (1,000 dead), and Berlin, where at least 7,057 people committed suicide in 1945.

Estimates of the total German war dead range from 5.5 to 6.9 million persons. A study by German historian Rüdiger Overmans puts the number of German military dead and missing at 5.3 million, including 900,000 men conscripted from outside of Germany's 1937 borders. Richard Overy estimated in 2014 that about 353,000 civilians were killed in Allied air raids. Other civilian deaths include 300,000 Germans (including Jews) who were victims of Nazi political, racial, and religious persecution and 200,000 who were murdered in the Nazi euthanasia program. Political courts called "Sondergerichte" sentenced some 12,000 members of the German resistance to death, and civil courts sentenced an additional 40,000 Germans. Mass rapes of German women also took place.

As a result of their defeat in World War I and the resulting Treaty of Versailles, Germany lost Alsace-Lorraine, Northern Schleswig, and Memel. The Saarland became a protectorate of France under the condition that its residents would later decide by referendum which country to join, and Poland became a separate nation and was given access to the sea by the creation of the Polish Corridor, which separated Prussia from the rest of Germany, while Danzig was made a free city.

Germany regained control of the Saarland through a referendum held in 1935 and annexed Austria in the "Anschluss" of 1938. The Munich Agreement of 1938 gave Germany control of the Sudetenland, and they seized the remainder of Czechoslovakia six months later. Under threat of invasion by sea, Lithuania surrendered the Memel district in March 1939.

Between 1939 and 1941, German forces invaded Poland, Denmark, Norway, France, Luxembourg, the Netherlands, Belgium, Yugoslavia, Greece, and the Soviet Union. Germany annexed parts of northern Yugoslavia in April 1941, while Mussolini ceded Trieste, South Tyrol, and Istria to Germany in 1943.

Some of the conquered territories were incorporated into Germany as part of Hitler's long-term goal of creating a Greater Germanic Reich. Several areas, such as Alsace-Lorraine, were placed under the authority of an adjacent "Gau" (regional district). The "Reichskommissariate" (Reich Commissariats), quasi-colonial regimes, were established in some occupied countries. Areas placed under German administration included the Protectorate of Bohemia and Moravia, "Reichskommissariat Ostland" (encompassing the Baltic states and Belarus), and "Reichskommissariat Ukraine". Conquered areas of Belgium and France were placed under control of the Military Administration in Belgium and Northern France. Belgian Eupen-Malmedy, which had been part of Germany until 1919, was annexed. Part of Poland was incorporated into the Reich, and the General Government was established in occupied central Poland. The governments of Denmark, Norway ("Reichskommissariat Norwegen"), and the Netherlands ("Reichskommissariat Niederlande") were placed under civilian administrations staffed largely by natives. Hitler intended to eventually incorporate many of these areas into the Reich. Germany occupied the Italian protectorate of Albania and the Italian governorate of Montenegro in 1943 and installed a puppet government in occupied Serbia in 1941.

The NSDAP was a far-right fascist political party which arose during the social and financial upheavals that occurred following the end of World War I. The NSDAP remained small and marginalised, receiving 2.6% of the federal vote in 1928, prior to the onset of the Great Depression in 1929. By 1930 the NSDAP won 18.3% of the federal vote, making it the Reichstag's second largest political party. While in prison after the failed Beer Hall Putsch of 1923, Hitler wrote "Mein Kampf", which laid out his plan for transforming German society into one based on race. Nazi ideology brought together elements of antisemitism, racial hygiene, and eugenics, and combined them with pan-Germanism and territorial expansionism with the goal of obtaining more "Lebensraum" for the Germanic people. The regime attempted to obtain this new territory by attacking Poland and the Soviet Union, intending to deport or kill the Jews and Slavs living there, who were viewed as being inferior to the Aryan master race and part of a Jewish-Bolshevik conspiracy. The Nazi regime believed that only Germany could defeat the forces of Bolshevism and save humanity from world domination by International Jewry. Other people deemed life unworthy of life by the Nazis included the mentally and physically disabled, Romani people, homosexuals, Jehovah's Witnesses, and social misfits.

Influenced by the "Völkisch" movement, the regime was against cultural modernism and supported the development of an extensive military at the expense of intellectualism. Creativity and art were stifled, except where they could serve as propaganda media. The party used symbols such as the Blood Flag and rituals such as the Nazi Party rallies to foster unity and bolster the regime's popularity.

Hitler ruled Germany autocratically by asserting the "Führerprinzip" ("leader principle"), which called for absolute obedience of all subordinates. He viewed the government structure as a pyramid, with himself—the infallible leader—at the apex. Party rank was not determined by elections, and positions were filled through appointment by those of higher rank. The party used propaganda to develop a cult of personality around Hitler. Historians such as Kershaw emphasise the psychological impact of Hitler's skill as an orator. Roger Gill states: "His moving speeches captured the minds and hearts of a vast number of the German people: he virtually hypnotized his audiences".

While top officials reported to Hitler and followed his policies, they had considerable autonomy. He expected officials to "work towards the Führer" – to take the initiative in promoting policies and actions in line with party goals and Hitler's wishes, without his involvement in day-to-day decision-making. The government was a disorganised collection of factions led by the party elite, who struggled to amass power and gain the Führer's favour. Hitler's leadership style was to give contradictory orders to his subordinates and to place them in positions where their duties and responsibilities overlapped. In this way he fostered distrust, competition, and infighting among his subordinates to consolidate and maximise his own power.

Successive "Reichsstatthalter" decrees between 1933 and 1935 abolished the existing "Länder" (constituent states) of Germany and replaced them with new administrative divisions, the "Gaue", governed by NSDAP leaders ("Gauleiters"). The change was never fully implemented, as the Länder were still used as administrative divisions for some government departments such as education. This led to a bureaucratic tangle of overlapping jurisdictions and responsibilities typical of the administrative style of the Nazi regime.

Jewish civil servants lost their jobs in 1933, except for those who had seen military service in World War I. Members of the NSDAP or party supporters were appointed in their place. As part of the process of "Gleichschaltung", the Reich Local Government Law of 1935 abolished local elections, and mayors were appointed by the Ministry of the Interior.

In August 1934, civil servants and members of the military were required to swear an oath of unconditional obedience to Hitler. These laws became the basis of the "Führerprinzip", the concept that Hitler's word overrode all existing laws. Any acts that were sanctioned by Hitler—even murder—thus became legal. All legislation proposed by cabinet ministers had to be approved by the office of Deputy Führer Rudolf Hess, who could also veto top civil service appointments.

Most of the judicial system and legal codes of the Weimar Republic remained in place to deal with non-political crimes. The courts issued and carried out far more death sentences than before the Nazis took power. People who were convicted of three or more offences—even petty ones—could be deemed habitual offenders and jailed indefinitely. People such as prostitutes and pickpockets were judged to be inherently criminal and a threat to the community. Thousands were arrested and confined indefinitely without trial.
A new type of court, the "Volksgerichtshof" ("People's Court"), was established in 1934 to deal with political cases. This court handed out over 5,000 death sentences until its dissolution in 1945. The death penalty could be issued for offences such as being a communist, printing seditious leaflets, or even making jokes about Hitler or other officials. The Gestapo was in charge of investigative policing to enforce National Socialist ideology as they located and confined political offenders, Jews, and others deemed undesirable. Political offenders who were released from prison were often immediately re-arrested by the Gestapo and confined in a concentration camp.

The Nazis used propaganda to promulgate the concept of "Rassenschande" ("race defilement") to justify the need for racial laws. In September 1935, the Nuremberg Laws were enacted. These laws initially prohibited sexual relations and marriages between Aryans and Jews and were later extended to include "Gypsies, Negroes or their bastard offspring". The law also forbade the employment of German women under the age of 45 as domestic servants in Jewish households. The Reich Citizenship Law stated that only those of "German or related blood" could be citizens. Thus Jews and other non-Aryans were stripped of their German citizenship. The law also permitted the Nazis to deny citizenship to anyone who was not supportive enough of the regime. A supplementary decree issued in November defined as Jewish anyone with three Jewish grandparents, or two grandparents if the Jewish faith was followed.

The unified armed forces of Germany from 1935 to 1945 were called the "Wehrmacht" (defence force). This included the "Heer" (army), "Kriegsmarine" (navy), and the "Luftwaffe" (air force). From 2 August 1934, members of the armed forces were required to pledge an oath of unconditional obedience to Hitler personally. In contrast to the previous oath, which required allegiance to the constitution of the country and its lawful establishments, this new oath required members of the military to obey Hitler even if they were being ordered to do something illegal. Hitler decreed that the army would have to tolerate and even offer logistical support to the "Einsatzgruppen"—the mobile death squads responsible for millions of deaths in Eastern Europe—when it was tactically possible to do so. "Wehrmacht" troops also participated directly in the Holocaust by shooting civilians or committing genocide under the guise of anti-partisan operations. The party line was that the Jews were the instigators of the partisan struggle and therefore needed to be eliminated. On 8 July 1941, Heydrich announced that all Jews in the eastern conquered territories were to be regarded as partisans and gave the order for all male Jews between the ages of 15 and 45 to be shot. By August this was extended to include the entire Jewish population.

In spite of efforts to prepare the country militarily, the economy could not sustain a lengthy war of attrition. A strategy was developed based on the tactic of "Blitzkrieg" ("lightning war"), which involved using quick coordinated assaults that avoided enemy strong points. Attacks began with artillery bombardment, followed by bombing and strafing runs. Next the tanks would attack and finally the infantry would move in to secure the captured area. Victories continued through mid-1940, but the failure to defeat Britain was the first major turning point in the war. The decision to attack the Soviet Union and the decisive defeat at Stalingrad led to the retreat of the German armies and the eventual loss of the war. The total number of soldiers who served in the "Wehrmacht" from 1935 to 1945 was around 18.2 million, of whom 5.3 million died.

The "Sturmabteilung" (SA; Storm Detachment; Brownshirts), founded in 1921, was the first paramilitary wing of the NSDAP; their initial assignment was to protect Nazi leaders at rallies and assemblies. They also took part in street battles against the forces of rival political parties and violent actions against Jews and others. Under Ernst Röhm's leadership the SA grew by 1934 to over half a million members—4.5 million including reserves—at a time when the regular army was still limited to 100,000 men by the Versailles Treaty.

Röhm hoped to assume command of the army and absorb it into the ranks of the SA. Hindenburg and Defence Minister Werner von Blomberg threatened to impose martial law if the activities of the SA were not curtailed. Therefore, less than a year and a half after seizing power, Hitler ordered the deaths of the SA leadership, including Rohm. After the purge of 1934, the SA was no longer a major force.

Initially a small bodyguard unit under the auspices of the SA, the "Schutzstaffel" (SS; Protection Squadron) grew to become one of the largest and most powerful groups in Nazi Germany. Led by "Reichsführer-SS" Heinrich Himmler from 1929, the SS had over a quarter million members by 1938. Himmler initially envisioned the SS as being an elite group of guards, Hitler's last line of defence. The Waffen-SS, the military branch of the SS, evolved into a second army. It was dependent on the regular army for heavy weaponry and equipment, and most units were under tactical control of the High Command of the Armed Forces (OKW). By the end of 1942, the stringent selection and racial requirements that had initially been in place were no longer followed. With recruitment and conscription based only on expansion, by 1943 the Waffen-SS could not longer claim to be an elite fighting force.

SS formations committed many war crimes against civilians and allied servicemen. From 1935 onward, the SS spearheaded the persecution of Jews, who were rounded up into ghettos and concentration camps. With the outbreak of World War II, the SS "Einsatzgruppen" units followed the army into Poland and the Soviet Union, where from 1941 to 1945 they killed more than two million people, including 1.3 million Jews. A third of the "Einsatzgruppen" members were recruited from Waffen-SS personnel. The "SS-Totenkopfverbände" (death's head units) ran the concentration camps and extermination camps, where millions more were killed. Up to 60,000 Waffen-SS men served in the camps.

In 1931, Himmler organised an SS intelligence service which became known as the "Sicherheitsdienst" (SD; Security Service) under his deputy, Heydrich. This organisation was tasked with locating and arresting communists and other political opponents. Himmler established the beginnings of a parallel economy under the auspices of the SS Economy and Administration Head Office. This holding company owned housing corporations, factories, and publishing houses.

The most pressing economic matter the Nazis initially faced was the 30 percent national unemployment rate. Economist Dr. Hjalmar Schacht, President of the Reichsbank and Minister of Economics, created a scheme for deficit financing in May 1933. Capital projects were paid for with the issuance of promissory notes called Mefo bills. When the notes were presented for payment, the Reichsbank printed money. Hitler and his economic team expected that the upcoming territorial expansion would provide the means of repaying the soaring national debt. Schacht's administration achieved a rapid decline in the unemployment rate, the largest of any country during the Great Depression. Economic recovery was uneven, with reduced hours of work and erratic availability of necessities, leading to disenchantment with the regime as early as 1934.

In October 1933, the Junkers Aircraft Works was expropriated. In concert with other aircraft manufacturers and under the direction of Aviation Minister Göring, production was ramped up. From a workforce of 3,200 people producing 100 units per year in 1932, the industry grew to employ a quarter of a million workers manufacturing over 10,000 technically advanced aircraft annually less than ten years later.

An elaborate bureaucracy was created to regulate imports of raw materials and finished goods with the intention of eliminating foreign competition in the German marketplace and improving the nation's balance of payments. The Nazis encouraged the development of synthetic replacements for materials such as oil and textiles. As the market was experiencing a glut and prices for petroleum were low, in 1933 the Nazi government made a profit-sharing agreement with IG Farben, guaranteeing them a 5 percent return on capital invested in their synthetic oil plant at Leuna. Any profits in excess of that amount would be turned over to the Reich. By 1936, Farben regretted making the deal, as excess profits were by then being generated. In another attempt to secure an adequate wartime supply of petroleum, Germany intimidated Romania into signing a trade agreement in March 1939.

Major public works projects financed with deficit spending included the construction of a network of "Autobahnen" and providing funding for programmes initiated by the previous government for housing and agricultural improvements. To stimulate the construction industry, credit was offered to private businesses and subsidies were made available for home purchases and repairs. On the condition that the wife would leave the workforce, a loan of up to 1,000 Reichsmarks could be accessed by young couples of Aryan descent who intended to marry, and the amount that had to be repaid was reduced by 25 percent for each child born. The caveat that the woman had to remain unemployed outside the home was dropped by 1937 due to a shortage of skilled labourers.

Envisioning widespread car ownership as part of the new Germany, Hitler arranged for designer Ferdinand Porsche to draw up plans for the "KdF-wagen" (Strength Through Joy car), intended to be an automobile that everyone could afford. A prototype was displayed at the International Motor Show in Berlin on 17 February 1939. With the outbreak of World War II, the factory was converted to produce military vehicles. None were sold until after the war, when the vehicle was renamed the Volkswagen (people's car).

Six million people were unemployed when the Nazis took power in 1933 and by 1937 there were fewer than a million. This was in part due to the removal of women from the workforce. Real wages dropped by 25 percent between 1933 and 1938. After the dissolution of the trade unions in May 1933, their funds were seized and their leadership arrested, including those who attempted to co-operate with the NSDAP. A new organisation, the German Labour Front, was created and placed under NSDAP functionary Robert Ley. The average work week was 43 hours in 1933; by 1939 this increased to 47 hours.

By early 1934, the focus shifted towards rearmament. By 1935, military expenditures accounted for 73 percent of the government's purchases of goods and services. On 18 October 1936, Hitler named Göring as Plenipotentiary of the Four Year Plan, intended to speed up rearmament. In addition to calling for the rapid construction of steel mills, synthetic rubber plants, and other factories, Göring instituted wage and price controls and restricted the issuance of stock dividends. Large expenditures were made on rearmament in spite of growing deficits. Plans unveiled in late 1938 for massive increases to the navy and air force were impossible to fulfil, as Germany lacked the finances and material resources to build the planned units, as well as the necessary fuel required to keep them running. With the introduction of compulsory military service in 1935, the "Reichswehr", which had been limited to 100,000 by the terms of the Versailles Treaty, expanded to 750,000 on active service at the start of World War II, with a million more in the reserve. By January 1939, unemployment was down to 301,800 and it dropped to only 77,500 by September.

The Nazi war economy was a mixed economy that combined a free market with central planning. Historian Richard Overy describes it as being somewhere in between the command economy of the Soviet Union and the capitalist system of the United States.

In 1942, after the death of Armaments Minister Fritz Todt, Hitler appointed Albert Speer as his replacement. Wartime rationing of consumer goods led to an increase in personal savings, funds which were in turn lent to the government to support the war effort. By 1944, the war was consuming 75 percent of Germany's gross domestic product, compared to 60 percent in the Soviet Union and 55 percent in Britain. Speer improved production by centralising planning and control, reducing production of consumer goods, and using forced labour and slavery. The wartime economy eventually relied heavily upon the large-scale employment of slave labour. Germany imported and enslaved some 12 million people from 20 European countries to work in factories and on farms. Approximately 75 percent were Eastern European. Many were casualties of Allied bombing, as they received poor air raid protection. Poor living conditions led to high rates of sickness, injury, and death, as well as sabotage and criminal activity. The wartime economy also relied upon large-scale robbery, initially through the state seizing the property of Jewish citizens and later by plundering the resources of occupied territories.

Foreign workers brought into Germany were put into four classifications: guest workers, military internees, civilian workers, and Eastern workers. Each group was subject to different regulations. The Nazis issued a ban on sexual relations between Germans and foreign workers.

By 1944 over a half million women served as auxiliaries in the German armed forces. The number of women in paid employment only increased by 271,000 (1.8 percent) from 1939 to 1944. As the production of consumer goods had been cut back, women left those industries for employment in the war economy. They also took jobs formerly held by men, especially on farms and in family-owned shops.

Very heavy strategic bombing by the Allies targeted refineries producing synthetic oil and gasoline, as well as the German transportation system, especially rail yards and canals. The armaments industry began to break down by September 1944. By November, fuel coal was no longer reaching its destinations and the production of new armaments was no longer possible. Overy argues that the bombing strained the German war economy and forced it to divert up to one-fourth of its manpower and industry into anti-aircraft resources, which very likely shortened the war.

During the course of the war, the Nazis extracted considerable plunder from occupied Europe. Historian and war correspondent William L. Shirer writes: "The total amount of [Nazi] loot will never be known; it has proved beyond man's capacity to accurately compute." Gold reserves and other foreign holdings were seized from the national banks of occupied nations, while large "occupation costs" were usually imposed. By the end of the war, occupation costs were calculated by the Nazis at 60 billion Reichsmarks, with France alone paying 31.5 billion. The Bank of France was forced to provide 4.5 billion Reichsmarks in "credits" to Germany, while a further 500,000 Reichsmarks were assessed against Vichy France by the Nazis in the form of "fees" and other miscellaneous charges. The Nazis exploited other conquered nations in a similar way. After the war, the United States Strategic Bombing Survey concluded Germany had obtained 104 billion Reichsmarks in the form of occupation costs and other wealth transfers from occupied Europe, including two-thirds of the gross domestic product of Belgium and the Netherlands.

Nazi plunder included private and public art collections, artefacts, precious metals, books, and personal possessions. Hitler and Göring in particular were interested in acquiring looted art treasures from occupied Europe, the former planning to use the stolen art to fill the galleries of the planned "Führermuseum" (Leader's Museum), and the latter for his personal collection. Göring, having stripped almost all of occupied Poland of its artworks within six months of Germany's invasion, ultimately grew a collection valued at over 50 million Reichsmarks. In 1940, the Reichsleiter Rosenberg Taskforce was established to loot artwork and cultural material from public and private collections, libraries, and museums throughout Europe. France saw the greatest extent of Nazi plunder. Some 26,000 railroad cars of art treasures, furniture, and other looted items were sent to Germany from France. By January 1941, Rosenberg estimated the looted treasures from France to be valued at over one billion Reichsmarks. In addition, soldiers looted or purchased goods such as produce and clothing—items, which were becoming harder to obtain in Germany—for shipment home.

Goods and raw materials were also taken. In France, an estimated of cereals were seized during the course of the war, including 75 percent of its oats. In addition, 80 percent of the country's oil and 74 percent of its steel production were taken. The valuation of this loot is estimated to be 184.5 billion francs. In Poland, Nazi plunder of raw materials began even before the German invasion had concluded.

Following Operation Barbarossa, the Soviet Union was also plundered. In 1943 alone, 9,000,000 tons of cereals, of fodder, of potatoes, and of meats were sent back to Germany. During the course of the German occupation, some 12 million pigs and 13 million sheep were taken. The value of this plunder is estimated at 4 billion Reichsmarks. This relatively low number in comparison to the occupied nations of Western Europe can be attributed to the devastating fighting on the Eastern Front.

Racism and antisemitism were basic tenets of the NSDAP and the Nazi regime. Nazi Germany's racial policy was based on their belief in the existence of a superior master race. The Nazis postulated the existence of a racial conflict between the Aryan master race and inferior races, particularly Jews, who were viewed as a mixed race that had infiltrated society and were responsible for the exploitation and repression of the Aryan race.

Discrimination against Jews began immediately after the seizure of power. Following a month-long series of attacks by members of the SA on Jewish businesses and synagogues, on 1 April 1933 Hitler declared a national boycott of Jewish businesses. The Law for the Restoration of the Professional Civil Service passed on 7 April forced all non-Aryan civil servants to retire from the legal profession and civil service. Similar legislation soon deprived other Jewish professionals of their right to practise, and on 11 April a decree was promulgated that stated anyone who had even one Jewish parent or grandparent was considered non-Aryan. As part of the drive to remove Jewish influence from cultural life, members of the National Socialist Student League removed from libraries any books considered un-German, and a nationwide book burning was held on 10 May.

The regime used violence and economic pressure to encourage Jews to voluntarily leave the country. Jewish businesses were denied access to markets, forbidden to advertise, and deprived of access to government contracts. Citizens were harassed and subjected to violent attacks. Many towns posted signs forbidding entry to Jews.

In November 1938 a young Jewish man requested an interview with the German ambassador in Paris and met with a legation secretary, whom he shot and killed to protest his family's treatment in Germany. This incident provided the pretext for a pogrom the NSDAP incited against the Jews on 9 November 1938. Members of the SA damaged or destroyed synagogues and Jewish property throughout Germany. At least 91 German Jews were killed during this pogrom, later called "Kristallnacht", the Night of Broken Glass. Further restrictions were imposed on Jews in the coming months – they were forbidden to own businesses or work in retail shops, drive cars, go to the cinema, visit the library, or own weapons, and Jewish pupils were removed from schools. The Jewish community was fined one billion marks to pay for the damage caused by "Kristallnacht" and told that any insurance settlements would be confiscated. By 1939, around 250,000 of Germany's 437,000 Jews had emigrated to the United States, Argentina, Great Britain, Palestine, and other countries. Many chose to stay in continental Europe. Emigrants to Palestine were allowed to transfer property there under the terms of the Haavara Agreement, but those moving to other countries had to leave virtually all their property behind, and it was seized by the government.

Like the Jews, the Romani people were subjected to persecution from the early days of the regime. The Romani were forbidden to marry people of German extraction. They were shipped to concentration camps starting in 1935 and many were killed. Following the invasion of Poland, 2,500 Roma and Sinti people were deported from Germany to the General Government, where they were imprisoned in labour camps. The survivors were likely exterminated at Bełżec, Sobibor, or Treblinka. A further 5,000 Sinti and Austrian Lalleri people were deported to the Łódź Ghetto in late 1941, where half were estimated to have died. The Romani survivors of the ghetto were subsequently moved to the Chełmno extermination camp in early 1942.

The Nazis intended on deporting all Romani people from Germany, and confined them to "Zigeunerlager" (Gypsy camps) for this purpose. Himmler ordered their deportation from Germany in December 1942, with few exceptions. A total of 23,000 Romani were deported to Auschwitz concentration camp, of whom 19,000 died. Outside of Germany, the Romani people were regularly used for forced labour, though many were killed. In the Baltic states and the Soviet Union, 30,000 Romani were killed by the SS, the German Army, and "Einsatzgruppen". In occupied Serbia, 1,000 to 12,000 Romani were killed, while nearly all 25,000 Romani living in the Independent State of Croatia were killed. The estimates at end of the war put the total death toll at around 220,000, which equalled approximately 25 percent of the Romani population in Europe.

Action T4 was a programme of systematic murder of the physically and mentally handicapped and patients in psychiatric hospitals that took place mainly from 1939 to 1941, and continued until the end of the war. Initially the victims were shot by the "Einsatzgruppen" and others; gas chambers and gas vans using carbon monoxide were used by early 1940. Under the Law for the Prevention of Hereditarily Diseased Offspring, enacted on 14 July 1933, over 400,000 individuals underwent compulsory sterilisation. Over half were those considered mentally deficient, which included not only people who scored poorly on intelligence tests, but those who deviated from expected standards of behaviour regarding thrift, sexual behaviour, and cleanliness. Most of the victims came from disadvantaged groups such as prostitutes, the poor, the homeless, and criminals. Other groups persecuted and killed included Jehovah's Witnesses, homosexuals, social misfits, and members of the political and religious opposition.

Germany's war in the East was based on Hitler's long-standing view that Jews were the great enemy of the German people and that "Lebensraum" was needed for Germany's expansion. Hitler focused his attention on Eastern Europe, aiming to conquer Poland and the Soviet Union. After the occupation of Poland in 1939, all Jews living in the General Government were confined to ghettos, and those who were physically fit were required to perform compulsory labour. In 1941 Hitler decided to destroy the Polish nation completely; within 15 to 20 years the General Government was to be cleared of ethnic Poles and resettled by German colonists. About 3.8 to 4 million Poles would remain as slaves, part of a slave labour force of 14 million the Nazis intended to create using citizens of conquered nations.

The "Generalplan Ost" ("General Plan for the East") called for deporting the population of occupied Eastern Europe and the Soviet Union to Siberia, for use as slave labour or to be murdered. To determine who should be killed, Himmler created the "Volksliste", a system of classification of people deemed to be of German blood. He ordered that those of Germanic descent who refused to be classified as ethnic Germans should be deported to concentration camps, have their children taken away, or be assigned to forced labour. The plan also included the kidnapping of children deemed to have Aryan-Nordic traits, who were presumed to be of German descent. The goal was to implement "Generalplan Ost" after the conquest of the Soviet Union, but when the invasion failed Hitler had to consider other options. One suggestion was a mass forced deportation of Jews to Poland, Palestine, or Madagascar.

In addition to eliminating Jews, the Nazis planned to reduce the population of the conquered territories by 30 million people through starvation in an action called the Hunger Plan. Food supplies would be diverted to the German army and German civilians. Cities would be razed and the land allowed to return to forest or resettled by German colonists. Together, the Hunger Plan and "Generalplan Ost" would have led to the starvation of 80 million people in the Soviet Union. These partially fulfilled plans resulted in the democidal deaths of an estimated 19.3 million civilians and prisoners of war (POWs) throughout the USSR and elsewhere in Europe. During the course of the war, the Soviet Union lost a total of 27 million people; less than nine million of these were combat deaths. One in four of the Soviet population were killed or wounded.

Around the time of the failed offensive against Moscow in December 1941, Hitler resolved that the Jews of Europe were to be exterminated immediately. While the murder of Jewish civilians had been ongoing in the occupied territories of Poland and the Soviet Union, plans for the total eradication of the Jewish population of Europe—eleven million people—were formalised at the Wannsee Conference on 20 January 1942. Some would be worked to death and the rest would be killed in the implementation of the Final Solution to the Jewish Question. Initially the victims were killed by "Einsatzgruppen" firing squads, then by stationary gas chambers or by gas vans, but these methods proved impractical for an operation of this scale. By 1942 extermination camps equipped with gas chambers were established at Auschwitz, Chełmno, Sobibor, Treblinka, and elsewhere. The total number of Jews murdered is estimated at 5.5 to six million, including over a million children.

The Allies received information about the murders from the Polish government-in-exile and Polish leadership in Warsaw, based mostly on intelligence from the Polish underground. German citizens had access to information about what was happening, as soldiers returning from the occupied territories reported on what they had seen and done. Historian Richard J. Evans states that most German citizens disapproved of the genocide.


</doc>
<doc id="21214" url="https://en.wikipedia.org/wiki?curid=21214" title="Naraoiidae">
Naraoiidae

Naraoiidae is a family, of extinct, soft-shelled trilobite-like arthropods, that belongs to the order Nectaspida. Species included in the Naraoiidae are known from the second half of the Lower Cambrian to the end of the Upper Silurian. The total number of collection sites is limited and distributed over a vast period of time: Maotianshan Shale and Balang Formation (China), Burgess Shale and Bertie Formation (Canada), the Šárka Formation (Czech Republic), Emu Bay Shale (Australia), Idaho and Utah (USA). This is probably due to the rare occurrence of the right circumstances for soft tissue preservation, needed for these non-calcified exoskeletons.

Naraoiids probably were deposit feeders ("Naraoia" and "Pseudonaraoia"), predators or scavengers ("Misszhouia"), living on the sea floor.

The species of the family "Naraoiidae" are almost flat (dorso-ventrally). The upper (or dorsal) side of the body consists of a non-calcified transversely oval or semi-circular headshield (cephalon), and a circular to long oval tailshield (pygidium) equal to or longer than the cephalon, without any body segments in between. The body is narrowed at the articulation between cephalon and pygidium. The antennas are long and many-segmented. There are no eyes. The 17 to 25 pairs of legs have two branches on a common basis, like trilobites. The outer (dorsal) branches of the limbs (exopods) have flattened side branches (setae) on the shaft (probably acting as gills). The inner branches (or endopods are composed of 6 or 7 segments (or podomeres).

Naraoiidae lack thoracic segments (or tergites), while the species of the sister family Liwiidae have between 3 and 6 tergites.

The taxonomic placement of the Naraoiidae has long been debated until detailed appendages were uncovered, that showed that "N. compacta" shares biramous legs of very comparable anatomy with trilobites. Some debate is still going on if the parent taxon "Nektaspida" should be included in the Trilobita, or is better placed as a sister group.



</doc>
<doc id="21215" url="https://en.wikipedia.org/wiki?curid=21215" title="Northwest Passage">
Northwest Passage

The Northwest Passage (NWP) is the sea route to the Pacific Ocean through the Arctic Ocean, along the northern coast of North America via waterways through the Canadian Arctic Archipelago. The eastern route along the Arctic coasts of Norway and Siberia is accordingly called the Northeast Passage (NEP).

The various islands of the archipelago are separated from one another and from the Canadian mainland by a series of Arctic waterways collectively known as the Northwest Passages or Northwestern Passages.

For centuries, European explorers sought a navigable passage as a possible trade route to Asia. An ice-bound northern route was discovered in 1850 by the Irish explorer Robert McClure; it was through a more southerly opening in an area explored by the Scotsman John Rae in 1854 that Norwegian Roald Amundsen made the first complete passage in 1903–1906. Until 2009, the Arctic pack ice prevented regular marine shipping throughout most of the year. Arctic sea ice decline has rendered the waterways more navigable for ice navigation.

The contested sovereignty claims over the waters may complicate future shipping through the region: the Canadian government maintains that the Northwestern Passages are part of Canadian Internal Waters, but the United States and various European countries claim that they are an international strait and transit passage, allowing free and unencumbered passage. If, as has been claimed, parts of the eastern end of the Passage are barely deep, the route's viability as a Euro-Asian shipping route is reduced. In 2016 a Chinese shipping line expressed a desire to make regular voyages of cargo ships using the passage to the eastern United States and Europe, after a successful passage by "Nordic Orion" of 73,500 tonnes deadweight tonnage in September 2013. Fully loaded, "Nordic Orion" sat too deep in the water to sail through the Panama Canal.

Before the Little Ice Age (late Middle Ages to the 19th century), Norwegian Vikings sailed as far north and west as Ellesmere Island, Skraeling Island and Ruin Island for hunting expeditions and trading with the Inuit and people of the Dorset culture who already inhabited the region. Between the end of the 15th century and the 20th century, colonial powers from Europe dispatched explorers in an attempt to discover a commercial sea route north and west around North America. The Northwest Passage represented a new route to the established trading nations of Asia.

England called the hypothetical northern route the "Northwest Passage". The desire to establish such a route motivated much of the European exploration of both coasts of North America, also known as the New World. When it became apparent that there was no route through the heart of the continent, attention turned to the possibility of a passage through northern waters. There was a lack of scientific knowledge about conditions; for instance, some people believed that seawater was incapable of freezing. (As late as the mid-18th century, Captain James Cook had reported that Antarctic icebergs had yielded fresh water, seemingly confirming the hypothesis). Explorers thought that an open water route close to the North Pole must exist. The belief that a route lay to the far north persisted for several centuries and led to numerous expeditions into the Arctic. Many ended in disaster, including that by Sir John Franklin in 1845. While searching for him the McClure Arctic Expedition discovered the Northwest Passage in 1850.

In 1906, the Norwegian explorer Roald Amundsen first successfully completed a passage from Greenland to Alaska in the sloop . Since that date, several fortified ships have made the journey.

From east to west, the direction of most early exploration attempts, expeditions entered the passage from the Atlantic Ocean via the Davis Strait and through Baffin Bay, both of which are in Canada. Five to seven routes have been taken through the Canadian Arctic Archipelago, via the McClure Strait, Dease Strait, and the Prince of Wales Strait, but not all of them are suitable for larger ships. From there ships passed through waterways through the Beaufort Sea, Chukchi Sea, and Bering Strait (separating Russia and Alaska), into the Pacific Ocean.

In the 21st century, major changes to the ice pack due to climate change have stirred speculation that the passage may become clear enough of ice to permit safe commercial shipping for at least part of the year. On August 21, 2007, the Northwest Passage became open to ships without the need of an icebreaker. According to Nalan Koc of the Norwegian Polar Institute, this was the first time the Passage has been clear since they began keeping records in 1972. The Northwest Passage opened again on August 25, 2008. It is usually reported in mainstream media that ocean thawing will open up the Northwest Passage (and the Northern Sea Route) for various kind of ships, making it possible to sail around the Arctic ice cap and possibly cutting thousands of miles off shipping routes. Warning that the NASA satellite images indicated the Arctic may have entered a "death spiral" caused by climate change, Professor Mark Serreze, a sea ice specialist at the U.S. National Snow and Ice Data Center (NSIDC) said: "The passages are open. It's a historic event. We are going to see this more and more as the years go by."

On the other hand, some thick sections of ice will remain hard to melt in the shorter term. Such drifting and large chunks of ice, especially in springtime, can be problematic as they can clog entire straits or severely damage a ship's hull. Cargo routes may therefore be slower and uncertain, depending on prevailing conditions and the ability to predict them. Because a plurality of containerized traffic operates in a just-in-time mode (which does not tolerate delays well) and the relative isolation of the passage (which impedes shipping companies from optimizing their operations by grouping multiple stopovers on the same itinerary), the Northwest Passage and other Arctic routes are not always seen as promising shipping lanes by industry insiders, at least for the time being. The uncertainty related to physical damage to ships is also thought to translate into higher insurance premiums, especially because of the technical challenges posed by Arctic navigation (as of 2014, only 12 percent of Canada's Arctic waters have been charted to modern standards).

The Beluga group of Bremen, Germany, sent the first Western commercial vessels through the Northern Sea Route (Northeast Passage) in 2009. Canada's Prime Minister Stephen Harper announced that "ships entering the North-West passage should first report to his government."

The first commercial cargo ship to have sailed through the Northwest Passage was in August 1969. SS "Manhattan", of 115,000 deadweight tonnage, was the largest commercial vessel ever to navigate the Northwest Passage.

The largest passenger ship to navigate the Northwest Passage was the cruise liner of gross tonnage 69,000. Starting on August 10, 2016, the ship sailed from Vancouver to New York City with 1,500 passengers and crew, taking 28 days.

In 2018, two of the freighters leaving Baffinland's port in the Milne Inlet, on Baffin Island's north shore, were bound for ports in Asia. Those freighters did not sail west through the remainder of the Northwest Passage, they sailed east, rounded the tip of Greenland, and transitted Russia's Northern Sea Route.

The Northwest Passage includes three sections:

Many attempts were made to find a salt water exit west from Hudson Bay, but the Fury and Hecla Strait in the far north is blocked by ice. The eastern entrance and main axis of the northwest passage, the Parry Channel, was found in 1819. The approach from the west through Bering Strait is impractical because of the need to sail around ice near Point Barrow. East of Point Barrow the coast is fairly clear in summer. This area was mapped in pieces from overland in 1821–1839. This leaves the large rectangle north of the coast, south of Parry Channel and east of Baffin Island. This area was mostly mapped in 1848–1854 by ships looking for Franklin's lost expedition. The first crossing was made by Amundsen in 1903–1905. He used a small ship and hugged the coast.

The International Hydrographic Organization defines the limits of the Northwestern Passages as follows:

As a result of their westward explorations and their settlement of Greenland, the Vikings sailed as far north and west as Ellesmere Island, Skraeling Island for hunting expeditions and trading with Inuit groups. The subsequent arrival of the Little Ice Age is thought to have been one of the reasons that European seafaring into the Northwest Passage ceased until the late 15th century.

In 1539, Hernán Cortés commissioned Francisco de Ulloa to sail along the Baja California Peninsula on the western coast of North America. Ulloa concluded that the Gulf of California was the southernmost section of a strait supposedly linking the Pacific with the Gulf of Saint Lawrence. His voyage perpetuated the notion of the Island of California and saw the beginning of a search for the Strait of Anián.

The strait probably took its name from Ania, a Chinese province mentioned in a 1559 edition of Marco Polo's book; it first appears on a map issued by Italian cartographer Giacomo Gastaldi about 1562. Five years later Bolognino Zaltieri issued a map showing a narrow and crooked Strait of Anian separating Asia from the Americas. The strait grew in European imagination as an easy sea lane linking Europe with the residence of Khagan (the Great Khan) in Cathay (northern China).

Cartographers and seamen tried to demonstrate its reality. Sir Francis Drake sought the western entrance in 1579. The Greek pilot Juan de Fuca, sailing from Acapulco (in Mexico) under the flag of the Spanish crown, claimed he had sailed the strait from the Pacific to the North Sea and back in 1592. The Spaniard Bartholomew de Fonte claimed to have sailed from Hudson Bay to the Pacific via the strait in 1640.

The first recorded attempt to discover the Northwest Passage was the east-west voyage of John Cabot in 1497, sent by Henry VII in search of a direct route to the Orient. In 1524, Charles V sent Estêvão Gomes to find a northern Atlantic passage to the Spice Islands. An English expedition was launched in 1576 by Martin Frobisher, who took three trips west to what is now the Canadian Arctic in order to find the passage. Frobisher Bay, which he first charted, is named after him.

As part of another expedition, in July 1583 Sir Humphrey Gilbert, who had written a treatise on the discovery of the passage and was a backer of Frobisher, claimed the territory of Newfoundland for the English crown. On August 8, 1585, the English explorer John Davis entered Cumberland Sound, Baffin Island.

The major rivers on the east coast were also explored in case they could lead to a transcontinental passage. Jacques Cartier's explorations of the Saint Lawrence River in 1535 were initiated in hope of finding a way through the continent. Cartier became persuaded that the St. Lawrence was the Passage; when he found the way blocked by rapids at what is now Montreal, he was so certain that these rapids were all that was keeping him from China (in French, "la Chine"), that he named the rapids for China. Samuel de Champlain renamed them Sault Saint-Louis in 1611, but the name was changed to Lachine Rapids in the mid-19th century.

In 1602, George Weymouth became the first European to explore what would later be called Hudson Strait when he sailed into the Strait. Weymouth's expedition to find the Northwest Passage was funded jointly by the British East India Company and the Muscovy Company. "Discovery" was the same ship used by Henry Hudson on his final voyage.

John Knight, employed by the British East India Company and the Muscovy Company, set out in 1606 to follow up on Weymouth's discoveries and find the Northwest Passage. After his ship ran aground and was nearly crushed by ice, Knight disappeared while searching for a better anchorage.

In 1609, Henry Hudson sailed up what is now called the Hudson River in search of the Passage; encouraged by the saltiness of the water in the estuary, he reached present-day Albany, New York, before giving up. On September 14, 1609, the explorer Henry Hudson entered the Tappan Zee while sailing upstream from New York Harbor. At first, Hudson believed the widening of the river indicated that he had found the Northwest Passage. He proceeded upstream as far as present-day Troy before concluding that no such strait existed there. He later explored the Arctic and Hudson Bay.

In 1611, while in James Bay, Hudson's crew mutinied. They set Hudson and his teenage son John, along with seven sick, infirm, or loyal crewmen, adrift in a small open boat. He was never seen again. Cree oral legend reports that the survivors lived and traveled with the Cree for more than a year.

A mission was sent out in 1612, again in "Discovery", commanded by Sir Thomas Button to find Henry Hudson and continue through the Northwest Passage. After failing to find Hudson, and exploring the west coast of Hudson Bay, Button returned home due to illness in the crew. In 1614, William Gibbons attempted to find the Passage, but was turned back by ice. The next year, 1615, Robert Bylot, a survivor of Hudson's crew, returned to Hudson Strait in "Discovery", but was turned back by ice. Bylot tried again in 1616 with William Baffin. They sailed as far as Lancaster Sound and reached 77°45′ North latitude, a record which stood for 236 years, before being blocked by ice.

On May 9, 1619, under the auspices of King Christian IV of Denmark–Norway, Jens Munk set out with 65 men and the king's two ships, "Einhörningen" (Unicorn), a small frigate, and "Lamprenen" (Lamprey), a sloop, which were outfitted under his own supervision. His mission was to discover the Northwest Passage to the Indies and China. Munk penetrated Davis Strait as far north as 69°, found Frobisher Bay, and then spent almost a month fighting his way through Hudson Strait. In September 1619, he found the entrance to Hudson Bay and spent the winter near the mouth of the Churchill River. Cold, famine, and scurvy destroyed so many of his men that only he and two other men survived. With these men, he sailed for home with "Lamprey" on July 16, 1620, reaching Bergen, Norway, on September 20, 1620.

René-Robert Cavelier, Sieur de La Salle built the sailing ship, , in his quest to find the Northwest Passage via the upper Great Lakes. "Le Griffon" disappeared in 1679 on the return trip of her maiden voyage. In the spring of 1682, La Salle made his famous voyage down the Mississippi River to the Gulf of Mexico. La Salle led an expedition from France in 1684 to establish a French colony on the Gulf of Mexico. He was murdered by his followers in 1687.
Henry Ellis, born in Ireland, was part of a company aiming to discover the Northwest Passage in May 1746. After the difficult extinction of a fire on board the ship, he sailed to Greenland, where he traded goods with the Inuit peoples on July 8, 1746. He crossed to the town of Fort Nelson and spent the summer on the Hayes River. He renewed his efforts in June 1747, without success, before returning to England.

In 1772, Samuel Hearne travelled overland northwest from Hudson Bay to the Arctic Ocean, thereby proving that there was no strait connecting Hudson Bay to the Pacific Ocean.

 Most Northwest Passage expeditions originated in Europe or on the east coast of North America, seeking to traverse the Passage in the westbound direction. Some progress was made in exploring the western reaches of the imagined passage.

In 1728 Vitus Bering, a Danish Navy officer in Russian service, used the strait first discovered by Semyon Dezhnyov in 1648 but later accredited to and named after Bering (the Bering Strait). He concluded that North America and Russia were separate land masses by sailing between them. In 1741 with Lieutenant Aleksei Chirikov, he explored seeking further lands beyond Siberia. While they were separated, Chirikov discovered several of the Aleutian Islands while Bering charted the Alaskan region. His ship was wrecked off the Kamchatka Peninsula, as many of his crew were disabled by scurvy.

The Spanish made several voyages to the northwest coast of North America during the late 18th century. Determining whether a Northwest Passage existed was one of the motives for their efforts. Among the voyages that involved careful searches for a Passage included the 1775 and 1779 voyages of Juan Francisco de la Bodega y Quadra. The journal of Francisco Antonio Mourelle, who served as Quadra's second in command in 1775, fell into English hands. It was translated and published in London, stimulating exploration.

Captain James Cook made use of the journal during his explorations of the region. In 1791 Alessandro Malaspina sailed to Yakutat Bay, Alaska, which was rumoured to be a Passage. In 1790 and 1791 Francisco de Eliza led several exploring voyages into the Strait of Juan de Fuca, searching for a possible Northwest Passage and finding the Strait of Georgia. To fully explore this new inland sea, an expedition under Dionisio Alcalá Galiano was sent in 1792. He was explicitly ordered to explore all channels that might turn out to be a Northwest Passage.

In 1776, Captain James Cook was dispatched by the Admiralty in Great Britain on an expedition to explore the Passage. A 1745 act, when extended in 1775, promised a £20,000 prize for whoever discovered the passage. Initially the Admiralty had wanted Charles Clerke to lead the expedition, with Cook (in retirement following his exploits in the Pacific) acting as a consultant. However, Cook had researched Bering's expeditions, and the Admiralty ultimately placed their faith in the veteran explorer to lead, with Clerke accompanying him.

After journeying through the Pacific, to make an attempt from the west, Cook began at Nootka Sound in April 1778. He headed north along the coastline, charting the lands and searching for the regions sailed by the Russians 40 years previously. The Admiralty's orders had commanded the expedition to ignore all inlets and rivers until they reached a latitude of 65°N. Cook, however, failed to make any progress in sighting a Northwestern Passage.

Various officers on the expedition, including William Bligh, George Vancouver, and John Gore, thought the existence of a route was 'improbable'. Before reaching 65°N they found the coastline pushing them further south, but Gore convinced Cook to sail on into the Cook Inlet in the hope of finding the route. They continued to the limits of the Alaskan peninsula and the start of the chain of Aleutian Islands. Despite reaching 70°N, they encountered nothing but icebergs.

From 1792 to 1794, the Vancouver Expedition (led by George Vancouver who had previously accompanied Cook) surveyed in detail all the passages from the Northwest Coast. He confirmed that there was no such passage south of the Bering Strait. This conclusion was supported by the evidence of Alexander MacKenzie, who explored the Arctic and Pacific Oceans in 1793.

In the first half of the 19th century, some parts of the Northwest Passage (north of the Bering Strait) were explored separately by many expeditions, including those by John Ross, Elisha Kent Kane, William Edward Parry, and James Clark Ross; overland expeditions were also led by John Franklin, George Back, Peter Warren Dease, Thomas Simpson, and John Rae. In 1826 Frederick William Beechey explored the north coast of Alaska, discovering Point Barrow.

Sir Robert McClure was credited with the discovery of the Northwest Passage in 1851 when he looked across McClure Strait from Banks Island and viewed Melville Island. However, this strait was not navigable to ships at that time. The only usable route linking the entrances of Lancaster Sound and Dolphin and Union Strait was discovered by John Rae in 1854.

In 1845, a lavishly equipped two-ship expedition led by Sir John Franklin sailed to the Canadian Arctic to chart the last unknown swaths of the Northwest Passage. Confidence was high, as they estimated there was less than remaining of unexplored Arctic mainland coast. When the ships failed to return, relief expeditions and search parties explored the Canadian Arctic, which resulted in a thorough charting of the region, along with a possible passage. Many artifacts from the expedition were found over the next century and a half, including notes that the ships were ice-locked in 1846 near King William Island, about halfway through the passage, and unable to break free. Records showed Franklin died in 1847 and Captain Francis Rawdon Moira Crozier took over command. In 1848 the expedition abandoned the two ships and its members tried to escape south across the tundra by sledge. Although some of the crew may have survived into the early 1850s, no evidence has ever been found of any survivors. In 1853 explorer John Rae was told by local Inuit about the disastrous fate of Franklin's expedition, but his reports were not welcomed in Britain.

Starvation, exposure and scurvy all contributed to the men's deaths. In 1981 Owen Beattie, an anthropologist from the University of Alberta, examined remains from sites associated with the expedition. This led to further investigations and the examination of tissue and bone from the frozen bodies of three seamen, John Torrington, William Braine and John Hartnell, exhumed from the permafrost of Beechey Island. Laboratory tests revealed high concentrations of lead in all three (the expedition carried 8,000 tins of food sealed with a lead-based solder). Another researcher has suggested botulism caused deaths among crew members. New evidence, confirming reports first made by John Rae in 1854 based on Inuit accounts, has shown that the last of the crew resorted to cannibalism of deceased members in an effort to survive.

During the search for Franklin, Commander Robert McClure and his crew in traversed the Northwest Passage from west to east in the years 1850 to 1854, partly by ship and partly by sledge. McClure started out from England in December 1849, sailed the Atlantic Ocean south to Cape Horn and entered the Pacific Ocean. He sailed the Pacific north and passed through the Bering Strait, turning east at that point and reaching Banks Island.

McClure's ship was trapped in the ice for three winters near Banks Island, at the western end of Viscount Melville Sound. Finally McClure and his crew—who were by that time dying of starvation—were found by searchers who had travelled by sledge over the ice from a ship of Sir Edward Belcher's expedition. They rescued McClure and his crew, returning with them to Belcher's ships, which had entered the Sound from the east. McClure and his crew returned to England in 1854 on one of Belcher's ships. They were the first people known to circumnavigate the Americas and to discover and transit the Northwest Passage, albeit by ship and by sledge over the ice. (Both McClure and his ship were found by a party from HMS "Resolute", one of Belcher's ships, so his sledge journey was relatively short.)

This was an astonishing feat for that day and age, and McClure was knighted and promoted in rank. (He was made rear-admiral in 1867.) Both he and his crew also shared £10,000 awarded them by the British Parliament. In July 2010 Canadian archaeologists found his ship, HMS "Investigator," fairly intact but sunk about below the surface.

The expeditions by Franklin and McClure were in the tradition of British exploration: well-funded ship expeditions using modern technology, and usually including British Naval personnel. By contrast, John Rae was an employee of the Hudson's Bay Company, which operated a far-flung trade network and drove exploration of the Canadian North. They adopted a pragmatic approach and tended to be land-based. While Franklin and McClure tried to explore the passage by sea, Rae explored by land. He used dog sleds and techniques of surviving in the environment which he had learned from the native Inuit. The Franklin and McClure expeditions each employed hundreds of personnel and multiple ships. John Rae's expeditions included fewer than ten people and succeeded. Rae was also the explorer with the best safety record, having lost only one man in years of traversing Arctic lands. In 1854, Rae returned to the cities with information from the Inuit about the disastrous fate of the Franklin expedition.

The first explorer to conquer the Northwest Passage solely by ship was the Norwegian explorer Roald Amundsen. In a three-year journey between 1903 and 1906, Amundsen explored the passage with a crew of six. Amundsen, who had sailed to escape creditors seeking to stop the expedition, completed the voyage in the converted 45 net register tonnage () herring boat "Gjøa". "Gjøa" was much smaller than vessels used by other Arctic expeditions and had a shallow draft. Amundsen intended to hug the shore, live off the limited resources of the land and sea through which he was to travel, and had determined that he needed to have a tiny crew to make this work. (Trying to support much larger crews had contributed to the catastrophic failure of John Franklin's expedition fifty years previously). The ship's shallow draft was intended to help her traverse the shoals of the Arctic straits.

Amundsen set out from Kristiania (Oslo) in June 1903 and was west of the Boothia Peninsula by late September. "Gjøa" was put into a natural harbour on the south shore of King William Island; by October 3 she was iced in. There the expedition remained for nearly two years, with the expedition members learning from the local Inuit people and undertaking measurements to determine the location of the North Magnetic Pole. The harbour, now known as Gjoa Haven, later developed as the only permanent settlement on the island.

After completing the Northwest Passage portion of this trip and having anchored near Herschel Island, Amundsen skied to the city of Eagle, Alaska. He sent a telegram announcing his success and skied the return to rejoin his companions. Although his chosen east–west route, via the Rae Strait, contained young ice and thus was navigable, some of the waterways were extremely shallow ( deep), making the route commercially impractical.

The first traversal of the Northwest Passage via dog sled was accomplished by Greenlander Knud Rasmussen while on the Fifth Thule Expedition (1921–1924). Rasmussen and two Greenland Inuit travelled from the Atlantic to the Pacific over the course of 16 months via dog sled.

Canadian Royal Canadian Mounted Police officer Henry Larsen was the second to sail the passage, crossing west to east, leaving Vancouver on June 23, 1940 and arriving at Halifax on October 11, 1942. More than once on this trip, he was uncertain whether , a Royal Canadian Mounted Police "ice-fortified" schooner, would survive the pressures of the sea ice. At one point, Larsen wondered "if we had come this far only to be crushed like a nut on a shoal and then buried by the ice." The ship and all but one of her crew survived the winter on Boothia Peninsula. Each of the men on the trip was awarded a medal by Canada's sovereign, King George VI, in recognition of this feat of Arctic navigation.

Later in 1944, Larsen's return trip was far more swift than his first. He made the trip in 86 days to sail back from Halifax, Nova Scotia, to Vancouver, British Columbia. He set a record for traversing the route in a single season. The ship, after extensive upgrades, followed a more northerly, partially uncharted route.

In 1954, completed the east-to-west transit, under the command of Captain O.C.S. Robertson, conducting hydrographic soundings along the route. She was the first warship (and the first deep draft ship) to transit the Northwest Passage and the first warship to circumnavigate North America. In 1956, HMCS "Labrador" again completed the east-to-west transit, this time under the command of Captain T.C. Pullen.

On July 1, 1957, the United States Coast Guard cutter departed in company with and to search for a deep-draft channel through the Arctic Ocean and to collect hydrographic information. The US Coast Guard Squadron was escorted through Bellot Strait and the Eastern Arctic by HMCS "Labrador". Upon her return to Greenland waters, "Storis" became the first U.S.-registered vessel to circumnavigate North America. Shortly after her return in late 1957, she was reassigned to her new home port of Kodiak, Alaska.

In 1960, completed the first submarine transit of the Northwest Passage, heading east-to-west.

In 1969, SS "Manhattan" made the passage, accompanied by the Canadian icebreakers and . The U.S. Coast Guard icebreakers and also sailed in support of the expedition.

"Manhattan" was a specially reinforced supertanker sent to test the viability of the passage for the transport of oil. While "Manhattan" succeeded, the route was deemed not to be cost-effective. The United States built the Alaska Pipeline instead.

In June 1977, sailor Willy de Roos left Belgium to attempt the Northwest Passage in his steel yacht "Williwaw". He reached the Bering Strait in September and after a stopover in Victoria, British Columbia, went on to round Cape Horn and sail back to Belgium, thus being the first sailor to circumnavigate the Americas entirely by ship.

In 1981 as part of the Transglobe Expedition, Ranulph Fiennes and Charles R. Burton completed the Northwest Passage. They left Tuktoyaktuk on July 26, 1981, in the open Boston Whaler and reached Tanquary Fiord on August 31, 1981. Their journey was the first open-boat transit from west to east and covered around , taking a route through Dolphin and Union Strait following the south coast of Victoria and King William islands, north to Resolute Bay via Franklin Strait and Peel Sound, around the south and east coasts of Devon Island, through Hell Gate and across Norwegian Bay to Eureka, Greely Bay and the head of Tanquary Fiord. Once they reached Tanquary Fiord, they had to trek via Lake Hazen to Alert before setting up their winter base camp.

In 1984, the commercial passenger vessel (which sank in the Antarctic Ocean in 2007) became the first cruise ship to navigate the Northwest Passage.

In July 1986, Jeff MacInnis and Mike Beedell set out on an catamaran called "Perception" on a 100-day sail, west to east, through the Northwest Passage. This pair was the first to sail the passage, although they had the benefit of doing so over a couple of summers.

In July 1986, David Scott Cowper set out from England in a lifeboat named "Mabel El Holland", and survived three Arctic winters in the Northwest Passage before reaching the Bering Strait in August 1989. He continued around the world via the Cape of Good Hope to return to England on September 24, 1990. His was the first vessel to circumnavigate the world via the Northwest Passage.

On July 1, 2000, the Royal Canadian Mounted Police patrol vessel , having assumed the name "St Roch II", departed Vancouver on a "Voyage of Rediscovery". "Nadon"s mission was to circumnavigate North America via the Northwest Passage and the Panama Canal, recreating the epic voyage of her predecessor, "St. Roch." The Voyage of Rediscovery was intended to raise awareness concerning "St. Roch" and kick off the fund-raising efforts necessary to ensure the continued preservation of "St. Roch". The voyage was organized by the Vancouver Maritime Museum and supported by a variety of corporate sponsors and agencies of the Canadian government.
"Nadon" is an aluminum, catamaran-hulled, high-speed patrol vessel. To make the voyage possible, she was escorted and supported by the Canadian Coast Guard icebreaker . The Coast Guard vessel was chartered by the Voyage of Rediscovery and crewed by volunteers. Throughout the voyage, she provided a variety of necessary services, including provisions and spares, fuel and water, helicopter facilities, and ice escort; she also conducted oceanographic research during the voyage. The Voyage of Rediscovery was completed in five and a half months, with "Nadon" reaching Vancouver on December 16, 2000.

On September 1, 2001, "Northabout", an aluminium sailboat with diesel engine, built and captained by Jarlath Cunnane, completed the Northwest Passage east-to-west from Ireland to the Bering Strait. The voyage from the Atlantic to the Pacific was completed in 24 days. Cunnane cruised in "Northabout" in Canada for two years before returning to Ireland in 2005 via the Northeast Passage; he completed the first east-to-west circumnavigation of the pole by a single sailboat. The Northeast Passage return along the coast of Russia was slower, starting in 2004, requiring an ice stop and winter over in Khatanga, Siberia. He returned to Ireland via the Norwegian coast in October 2005. On January 18, 2006, the Cruising Club of America awarded Jarlath Cunnane their Blue Water Medal, an award for "meritorious seamanship and adventure upon the sea displayed by amateur sailors of all nationalities."

On July 18, 2003, a father-and-son team, Richard and Andrew Wood, with Zoe Birchenough, sailed the yacht "Norwegian Blue" into the Bering Strait. Two months later she sailed into the Davis Strait to become the first British yacht to transit the Northwest Passage from west to east. She also became the only British vessel to complete the Northwest Passage in one season, as well as the only British sailing yacht to return from there to British waters.

In 2006, a scheduled cruise liner () successfully ran the Northwest Passage, helped by satellite images telling the location of sea ice.

On May 19, 2007, a French sailor, Sébastien Roubinet, and one other crew member left Anchorage, Alaska, in "Babouche", a ice catamaran designed to sail on water and slide over ice. The goal was to navigate west to east through the Northwest Passage by sail only. Following a journey of more than , Roubinet reached Greenland on September 9, 2007, thereby completing the first Northwest Passage voyage made in one season without engine.
In April 2009, planetary scientist Pascal Lee and a team of four on the Northwest Passage Drive Expedition drove the HMP "Okarian" Humvee rover a record-setting on sea-ice from Kugluktuk to Cambridge Bay, Nunavut, the longest distance driven on sea-ice in a road vehicle. The HMP "Okarian" was being ferried from the North American mainland to the Haughton–Mars Project (HMP) Research Station on Devon Island, where it would be used as a simulator of future pressurized rovers for astronauts on the Moon and Mars. The HMP "Okarian" was eventually flown from Cambridge Bay to Resolute Bay in May 2009, and then driven again on sea-ice by Lee and a team of five from Resolute to the West coast of Devon Island in May 2010. The HMP "Okarian" reached the HMP Research Station in July 2011. The Northwest Passage Drive Expedition is captured in the motion picture documentary film "Passage To Mars" (2016).

In 2009, sea ice conditions were such that at least nine small vessels and two cruise ships completed the transit of the Northwest Passage. These trips included one by Eric Forsyth on board the Westsail sailboat "Fiona", a boat he built in the 1980s. Self-financed, Forsyth, a retired engineer from the Brookhaven National Laboratory, and winner of the Cruising Club of America's Blue Water Medal, sailed the Canadian Archipelago with sailor Joey Waits, airline captain Russ Roberts and carpenter David Wilson. After successfully sailing the Passage, the 77-year-old Forsyth completed the circumnavigation of North America, returning to his home port on Long Island, New York.

Cameron Dueck and his crew aboard the 40-foot sailing yacht Silent Sound also transited in the summer of 2009. Their voyage began in Victoria, BC on June 6 and they arrived in Halifax on October 10. Dueck wrote a book about the voyage called The New Northwest Passage.

On August 28, 2010, Bear Grylls and a team of five were the first rigid inflatable boat (RIB) crew to complete a point-to-point navigation between Pond Inlet on Baffin Island and Tuktoyaktuk in the Northwest Territories. A Northwest Passage requires crossing the Arctic Circle twice, once each in the Atlantic and the Pacific oceans.

On August 30, 2012 Sailing yacht , , an English SY, successfully completed the Northwest Passage in Nome, Alaska, while sailing a northern route never sailed by a sailing pleasure vessel before. After six cruising seasons in the Arctic (Greenland, Baffin Bay, Devon Island, Kane Basin, Lancaster Sound, Peel Sound, Regent Sound) and four seasons in the South (Antarctic Peninsula, Patagonia, Falkland Islands, South Georgia), SY "Billy Budd", owned by and under the command of an Italian sporting enthusiast, Mariacristina Rapisardi. Crewed by Marco Bonzanigo, five Italian friends, one Australian, one Dutch, one South African, and one New Zealander, it sailed through the Northwest Passage. The northernmost route was chosen. "Billy Budd" sailed through the Parry Channel, Viscount Melville Sound and Prince of Wales Strait, a channel long and wide which flows south into the Amundsen Gulf. During the passage "Billy Budd" – likely a first for a pleasure vessel – anchored in Winter Harbour in Melville Island, the very same site where almost 200 years ago Sir William Parry was blocked by ice and forced to winter.

On August 29, 2012, the Swedish yacht "Belzebub II," a fibreglass cutter captained by Canadian Nicolas Peissel, Swede Edvin Buregren and Morgan Peissel, became the first sailboat in history to sail through McClure Strait, part of a journey of achieving the most northerly Northwest Passage. "Belzebub II" departed Newfoundland following the coast of Greenland to Qaanaaq before tracking the sea ice to Grise Fiord, Canada's most northern community. From there the team continued through Parry Channel into McClure Strait and the Beaufort Sea, tracking the highest latitudes of 2012's record sea ice depletion before completing their Northwest Passage September 14, 2012. The expedition received extensive media coverage, including recognition by former U.S. Vice President Al Gore. The accomplishment is recorded in the Polar Scott Institute's record of Northwest Passage Transits and recognized by the Explorers Club and the Royal Canadian Geographic Society.

At 18:45 GMT on September 18, 2012, "Best Explorer", a steel cutter , skipper Nanni Acquarone, passing between the two Diomedes, was the first Italian sailboat to complete the Northwest Passage along the classical Amundsen route. Twenty-two Italian amateur sailors took part of the trip, in eight legs from Tromsø, Norway, to King Cove, Alaska, totalling . Later in 2019 "Best Explorer" skppered again by Nanni Acquarone became the first Italian sailboat to circumnavigate the Arctic sailing north of Siberia from Petropavlovsk-Kamchatsky to Tromsø and the second ever to do it clockwise. 

Setting sail from Nome, Alaska, on August 18, 2012, and reaching Nuuk, Greenland, on September 12, 2012, became the largest passenger vessel to transit the Northwest Passage. The ship, carrying 481 passengers, for 26 days and at sea, followed in the path of Captain Roald Amundsen. "The World" transit of the Northwest Passage was documented by "National Geographic" photographer Raul Touzon.

In September 2013, became the first commercial bulk carrier to transit the Northwest Passage. She was carrying a cargo of of coking coal from Port Metro Vancouver, Canada, to the Finnish Port of Pori, more than would have been possible via the traditional Panama Canal route. The Northwest Passage shortened the distance by compared to traditional route via the Panama Canal.

In August and September 2016 a cruise ship was sailed through the Northwest Passage. The ship "Crystal Serenity", (with 1,000 passengers, and 600 crew) left Seward, Alaska, used Amundsen's route and reached New York on September 17. Tickets for the 32-day trip started at $22,000 and were quickly sold out. The trip was repeated in 2017. In 2017 33 vessels made a complete transit, breaking the prior record of 20 in 2012.

In September 2018, sailing yacht "Infinity" (a 36·6 m ketch) and her 22 person crew successfully sailed through the Northwest Passage. This was part of their mission to plant the Flag of Planet Earth on the remaining Arctic ice. Supported by the initiative, EarthToday, this voyage was a symbol for future global collaboration against climate change. The Flag of Planet Earth was planted on September 21, 2018, the International Day of Peace.

The Canadian government claims that some of the waters of the Northwest Passage, particularly those in the Canadian Arctic Archipelago, are internal waters of Canada, giving Canada the right to bar transit through these waters. Most maritime nations, including the United States and those of the European Union, classify these waters as an international strait, where foreign vessels have the right of "transit passage". In such a regime, Canada would have the right to enact fishing and environmental regulation, and fiscal and smuggling laws, as well as laws intended for the safety of shipping, but not the right to close the passage. If the passage's deep waters become completely ice-free in summer months, they will be particularly enticing for supertankers that are too big to pass through the Panama Canal and must otherwise navigate around the tip of South America.

The dispute between Canada and the United States arose in 1969 with the trip of the U.S. oil tanker through the Arctic Archipelago. The prospect of more American traffic headed to the Prudhoe Bay Oil Field made the Canadian government realize that political action was required should it decide to consider the archipelago as internal waters.

In 1985, the U.S. Coast Guard icebreaker passed through from Greenland to Alaska; the ship submitted to inspection by the Canadian Coast Guard before passing through, but the event infuriated the Canadian public and resulted in a diplomatic incident. The United States government, when asked by a Canadian reporter, indicated that they did not ask for permission as they were not legally required to. The Canadian government issued a declaration in 1986 reaffirming Canadian rights to the waters. The United States refused to recognize the Canadian claim. In 1988 the governments of Canada and the United States signed an agreement, "Arctic Cooperation", that resolved the practical issue without solving the sovereignty questions. Under the law of the sea, ships engaged in transit passage are not permitted to engage in research. The agreement states that all U.S. Coast Guard vessels are engaged in research, and so would require permission from the Government of Canada to pass through.

In late 2005, it was reported that U.S. nuclear submarines had travelled unannounced through Canadian Arctic waters, sparking outrage in Canada. In his first news conference after the 2006 federal election, Prime Minister-designate Stephen Harper contested an earlier statement made by the U.S. ambassador that Arctic waters were international, stating the Canadian government's intention to enforce its sovereignty there. The allegations arose after the U.S. Navy released photographs of surfaced at the North Pole.

On April 9, 2006, Canada's Joint Task Force (North) declared that the Canadian Forces will no longer refer to the region as the Northwest Passage, but as the Canadian Internal Waters. The declaration came after the successful completion of Operation Nunalivut (Inuktitut for "the land is ours"), which was an expedition into the region by five military patrols.

In 2006 a report prepared by the staff of the Parliamentary Information and Research Service of Canada suggested that because of the September 11 attacks, the United States might be less interested in pursuing the international waterways claim in the interests of having a more secure North American perimeter. This report was based on an earlier paper, "The Northwest Passage Shipping Channel: Is Canada's Sovereignty Really Floating Away?" by Andrea Charron, given to the 2004 Canadian Defence and Foreign Affairs Institute Symposium. Later in 2006 former United States Ambassador to Canada, Paul Cellucci agreed with this position; however, the succeeding ambassador, David Wilkins, stated that the Northwest Passage was in international waters.

On July 9, 2007, Prime Minister Harper announced the establishment of a deep-water port in the far North. In the press release Harper said, "Canada has a choice when it comes to defending our sovereignty over the Arctic. We either use it or lose it. And make no mistake, this Government intends to use it. Because Canada's Arctic is central to our national identity as a northern nation. It is part of our history. And it represents the tremendous potential of our future."

On July 10, 2007, Rear Admiral Timothy McGee of the U.S. Navy and Rear Admiral Brian Salerno of the U.S. Coast Guard announced that the United States would be increasing its ability to patrol the Arctic.

In June 2019, the U.S. State Department spokesperson Morgan Ortagus said the United States "view Canada's claim that the waters of the Northwest Passage are internal waters of Canada as inconsistent with international law."

In the summer of 2000, two Canadian ships took advantage of thinning summer ice cover on the Arctic Ocean to make the crossing. It is thought that climate change is likely to open the passage for increasing periods, making it potentially attractive as a major shipping route. However, the passage through the Arctic Ocean would require significant investment in escort vessels and staging ports, and it would remain seasonal. Therefore, the Canadian commercial marine transport industry does not anticipate the route as a viable alternative to the Panama Canal within the next 10 to 20 years (as of 2004).

On September 14, 2007, the European Space Agency stated that ice loss that year had opened up the historically impassable passage, setting a new low of ice cover as seen in satellite measurements which went back to 1978. According to the Arctic Climate Impact Assessment, the latter part of the 20th century and the start of the 21st had seen marked shrinkage of ice cover. The extreme loss in 2007 rendered the passage "fully navigable". However, the ESA study was based only on analysis of satellite images and could in practice not confirm anything about the actual navigation of the waters of the passage. ESA suggested the passage would be navigable "during reduced ice cover by multi-year ice pack" (namely sea ice surviving one or more summers) where previously any traverse of the route had to be undertaken during favourable seasonable climatic conditions or by specialist vessels or expeditions. The agency's report speculated that the conditions prevalent in 2007 had shown the passage may "open" sooner than expected. An expedition in May 2008 reported that the passage was not yet continuously navigable even by an icebreaker and not yet ice-free.

Scientists at a meeting of the American Geophysical Union on December 13, 2007, revealed that NASA satellites observing the western Arctic showed a 16% decrease in cloud coverage during the summer of 2007 compared to 2006. This would have the effect of allowing more sunlight to penetrate Earth's atmosphere and warm the Arctic Ocean waters, thus melting sea ice and contributing to the opening the Northwest Passage.

In 2006 the cruise liner MS "Bremen" successfully ran the Northwest Passage, helped by satellite images telling where sea ice was.

On November 28, 2008, the Canadian Broadcasting Corporation reported that the Canadian Coast Guard confirmed the first commercial ship sailed through the Northwest Passage. In September 2008, , owned by Desgagnés Transarctik Inc. and, along with the Arctic Cooperative, is part of Nunavut Sealift and Supply Incorporated (NSSI), transported cargo from Montreal to the hamlets of Cambridge Bay, Kugluktuk, Gjoa Haven, and Taloyoak. A member of the crew is reported to have claimed that "there was no ice whatsoever". Shipping from the east was to resume in the fall of 2009. Although sealift is an annual feature of the Canadian Arctic this is the first time that the western communities have been serviced from the east. The western portion of the Canadian Arctic is normally supplied by Northern Transportation Company Limited (NTCL) from Hay River, and the eastern portion by NNSI and NTCL from Churchill and Montreal.

In January 2010, the ongoing reduction in the Arctic sea ice led telecoms cable specialist Kodiak-Kenai Cable to propose the laying of a fiberoptic cable connecting London and Tokyo, by way of the Northwest Passage, saying the proposed system would nearly cut in half the time it takes to send messages from the United Kingdom to Japan.

In September 2013, the first large ice strengthened sea freighter, "Nordic Orion", used the passage.

In 2016 a new record was set when the cruise ship "Crystal Serenity" transited with 1,700 passengers and crew. "Crystal Serenity" is the largest cruise ship to navigate the Northwest Passage. Starting on August 10, 2016, the ship sailed from Vancouver to New York City, taking 28 days for the journey.

Scientists believe that reduced sea ice in the Northwest Passage has permitted some new species to migrate across the Arctic Ocean. The gray whale "Eschrichtius robustus" has not been seen in the Atlantic since it was hunted to extinction there in the 18th century, but in May 2010, one such whale turned up in the Mediterranean. Scientists speculated the whale had followed its food sources through the Northwest Passage and simply kept on going.

The plankton species "Neodenticula seminae" had not been recorded in the Atlantic for 800,000 years. Over the past few years, however, it has become increasingly prevalent there. Again, scientists believe that it got there through the reopened Northwest Passage.

In August 2010, two bowhead whales from West Greenland and Alaska respectively, entered the Northwest Passage from opposite directions and spent approximately 10 days in the same area.





</doc>
<doc id="21216" url="https://en.wikipedia.org/wiki?curid=21216" title="Nevada">
Nevada

Nevada ( or ) is a state in the Western United States. It is bordered by Oregon to the northwest, Idaho to the northeast, California to the west, Arizona to the southeast, and Utah to the east. Nevada is the 7th most extensive, the 32nd most populous, and the 9th least densely populated of the U.S. states. Nearly three-quarters of Nevada's people live in Clark County, which contains the Las Vegas–Paradise metropolitan area, including three of the state's four largest incorporated cities. Nevada's capital is Carson City.

Nevada is officially known as the "Silver State" because of the importance of silver to its history and economy. It is also known as the "Battle Born State" because it achieved statehood during the Civil War (the words "Battle Born" also appear on the state flag); as the "Sagebrush State", for the native plant of the same name; and as the "Sage-hen State".

Nevada is largely desert and semi-arid, much of it within the Great Basin. Areas south of the Great Basin are within the Mojave Desert, while Lake Tahoe and the Sierra Nevada lie on the western edge. About 86% of the state's land is managed by various jurisdictions of the U.S. federal government, both civilian and military.

Before European contact, American Indians of the Paiute, Shoshone, and Washoe tribes inhabited the land that is now Nevada. The first Europeans to explore the region were Spanish. They called the region "Nevada" (snowy) because of the snow which covered the mountains in winter. The area formed part of the Viceroyalty of New Spain, and became part of Mexico when it gained independence in 1821. The United States annexed the area in 1848 after its victory in the Mexican–American War, and it was incorporated as part of Utah Territory in 1850. The discovery of silver at the Comstock Lode in 1859 led to a population boom that became an impetus to the creation of Nevada Territory out of western Utah Territory in 1861. Nevada became the 36th state on October 31, 1864, as the second of two states added to the Union during the Civil War (the first being West Virginia).

Nevada has a reputation for its libertarian laws. In 1940, with a population of just over 110,000 people, Nevada was by far the least-populated state, with less than half the population of the next least-populated state. However, legalized gambling and lenient marriage and divorce laws transformed Nevada into a major tourist destination in the 20th century. Nevada is the only U.S. state where prostitution is legal, though it is illegal in Clark County (Las Vegas), Washoe County (Reno) and Carson City (which, as an independent city, is not within the boundaries of any county). The tourism industry remains Nevada's largest employer, with mining continuing as a substantial sector of the economy: Nevada is the fourth-largest producer of gold in the world. 

The name "Nevada" comes from the Spanish "nevada" , meaning "snow-covered",

Most Nevadans pronounce the second syllable with the "a" as in "trap" () while elsewhere it is pronounced with the "a" as in "palm" (). Although the latter pronunciation is closer to the Spanish pronunciation, it is not the pronunciation preferred by most Nevadans. State Assemblyman Harry Mortenson proposed a bill to recognize the alternate (quasi-Spanish) pronunciation of Nevada, though the bill was not supported by most legislators and never received a vote. The Nevadan pronunciation is the one used by the state legislature. At one time, the state's official tourism organization, TravelNevada, stylized the name of the state as "Nevăda", with a breve over the "a" indicating the locally preferred pronunciation which is also available as a license plate design.

Nevada is almost entirely within the Basin and Range Province and is broken up by many north-south mountain ranges. Most of these ranges have endorheic valleys between them, which belies the image portrayed by the term Great Basin.

Much of the northern part of the state is within the Great Basin, a mild desert that experiences hot temperatures in the summer and cold temperatures in the winter. Occasionally, moisture from the Arizona Monsoon will cause summer thunderstorms; Pacific storms may blanket the area with snow. The state's highest recorded temperature was in Laughlin (elevation of ) on June 29, 1994. The coldest recorded temperature was set in San Jacinto in 1972, in the northeastern portion of the state.

The Humboldt River crosses the state from east to west across the northern part of the state, draining into the Humboldt Sink near Lovelock. Several rivers drain from the Sierra Nevada eastward, including the Walker, Truckee, and Carson rivers. All of these rivers are endorheic basins, ending in Walker Lake, Pyramid Lake, and the Carson Sink, respectively. However, not all of Nevada is within the Great Basin. Tributaries of the Snake River drain the far north, while the Colorado River, which also forms much of the boundary with Arizona, drains much of southern Nevada.

The mountain ranges, some of which have peaks above , harbor lush forests high above desert plains, creating sky islands for endemic species. The valleys are often no lower in elevation than , while some in central Nevada are above .

The southern third of the state, where the Las Vegas area is situated, is within the Mojave Desert. The area receives less rain in the winter but is closer to the Arizona Monsoon in the summer. The terrain is also lower, mostly below , creating conditions for hot summer days and cool to chilly winter nights.

Nevada and California have by far the longest diagonal line (in respect to the cardinal directions) as a state boundary at just over . This line begins in Lake Tahoe nearly offshore (in the direction of the boundary), and continues to the Colorado River where the Nevada, California, and Arizona boundaries merge southwest of the Laughlin Bridge.

The largest mountain range in the southern portion of the state is the Spring Mountain Range, just west of Las Vegas. The state's lowest point is along the Colorado River, south of Laughlin.

Nevada has 172 mountain summits with of prominence. Nevada ranks second in the United States by the number of mountains, behind Alaska, and ahead of California, Montana, and Washington. Nevada is the most mountainous state in the contiguous United States.

Nevada is the driest state in the United States. It is made up of mostly desert and semi-arid climate regions, and, with the exception of the Las Vegas Valley, the average summer diurnal temperature range approaches in much of the state. While winters in northern Nevada are long and fairly cold, the winter season in the southern part of the state tends to be of short duration and mild. Most parts of Nevada receive scarce precipitation during the year. The most rain that falls in the state falls on the lee side (east and northeast slopes) of the Sierra Nevada.

The average annual rainfall per year is about ; the wettest parts get around . Nevada's highest recorded temperature is at Laughlin on June 29, 1994 and the lowest recorded temperature is at San Jacinto on January 8, 1937. Nevada's reading is the third highest statewide record high temperature of a U.S. state, just behind Arizona's reading and California's reading.

The vegetation of Nevada is diverse and differs by state area. Nevada contains six biotic zones: alpine, sub-alpine, ponderosa pine, pinion-juniper, sagebrush and creosotebush.

Nevada is divided into political jurisdictions designated as "counties". Carson City is officially a consolidated municipality; however, for many purposes under state law, it is considered to be a county. As of 1919, there were 17 counties in the state, ranging from .

Lake County, one of the original nine counties formed in 1861, was renamed Roop County in 1862. Part of the county became Lassen County, California in 1864. In 1883, Washoe County annexed the portion that remained in Nevada.

In 1969, Ormsby County was dissolved and the Consolidated Municipality of Carson City was created by the Legislature in its place coterminous with the old boundaries of Ormsby County.

Bullfrog County was formed in 1987 from part of Nye County. After the creation was declared unconstitutional, the county was abolished in 1989.

Humboldt county was designated as a county in 1856 by Utah Territorial Legislature and again in 1861 by the new Nevada Legislature.

Clark County is the most populous county in Nevada, accounting for nearly three-quarters of its residents. Las Vegas, Nevada's most populous city, has been the county seat since the county was created in 1909 from a portion of Lincoln County, Nevada. Before that, it was a part of Arizona Territory. Clark County attracts numerous tourists: An estimated 44 million people visited Clark County in 2014.

Washoe County is the second-most populous county of Nevada. Its county seat is Reno. Washoe County includes the Reno–Sparks metropolitan area.

Lyon County is the third most populous county. It was one of the nine original counties created in 1861. It was named after Nathaniel Lyon, the first Union General to be killed in the Civil War. Its current county seat is Yerington. Its first county seat was established at Dayton on November 29, 1861.

Francisco Garcés was the first European in the area, Nevada was annexed as a part of the Spanish Empire in the northwestern territory of New Spain. Administratively, the area of Nevada was part of the Commandancy General of the Provincias Internas in the Viceroyalty of New Spain. Nevada became a part of Alta California ("Upper California") province in 1804 when the Californias were split. With the Mexican War of Independence won in 1821, the province of Alta California became a territory (state) of Mexico, with a small population. Jedediah Smith entered the Las Vegas Valley in 1827, and Peter Skene Ogden traveled the Humboldt River in 1828. When the Mormons created the State of Deseret in 1847, they laid claim to all of Nevada within the Great Basin and the Colorado watershed. They also founded the first white settlement in what is now Nevada, Mormon Station (modern-day Genoa), in 1851. In June 1855, William Bringhurst and 29 fellow Mormon missionaries from Utah arrived at a site just northeast of downtown Las Vegas and built a 150-foot square adobe fort, the first permanent structure erected in the valley, which remained under the control of Salt Lake City until the winter of 1858–1859.

As a result of the Mexican–American War and the Treaty of Guadalupe Hidalgo, Mexico permanently lost Alta California in 1848. The new areas acquired by the United States continued to be administered as territories. As part of the Mexican Cession (1848) and the subsequent California Gold Rush that used Emigrant Trails through the area, the state's area evolved first as part of the Utah Territory, then the Nevada Territory (March 2, 1861; named for the Sierra Nevada).

See History of Utah, History of Las Vegas, and the discovery of the first major U.S. deposit of silver ore in Comstock Lode under Virginia City, Nevada in 1859.

On March 2, 1861, the Nevada Territory separated from the Utah Territory and adopted its current name, shortened from "The Sierra Nevada" (Spanish for "snow-covered mountain range").

The 1861 southern boundary is commemorated by Nevada Historical Markers 57 and 58 in Lincoln and Nye counties.

Eight days before the presidential election of 1864, Nevada became the 36th state in the union, despite lacking the minimum requisite 60,000 residents in order to become a state. (At the time Nevada's population was little more than 10,000.) Rather than sending the Nevada constitution to Washington by Pony Express, the full text was sent by telegraph at a cost of $3,416.77—the most costly telegraph on file for a single dispatch. Finally, the response from Washington came on October 31, 1864: "the pain is over, the child is born, Nevada this day was admitted into the Union". Statehood was rushed to the date of October 31 to help ensure Abraham Lincoln's reelection on November 8 and post-Civil War Republican dominance in Congress, as Nevada's mining-based economy tied it to the more industrialized Union. As it turned out, however, Lincoln and the Republicans won the election handily and did not need Nevada's help.

Nevada is one of only two states to significantly expand its borders after admission to the Union. (The other is Missouri, which acquired additional territory in 1837 due to the Platte Purchase.)

In 1866 another part of the western Utah Territory was added to Nevada in the eastern part of the state, setting the current eastern boundary.

Nevada achieved its current southern boundaries on January 18, 1867, when it absorbed the portion of Pah-Ute County in the Arizona Territory west of the Colorado River, essentially all of present-day Nevada south of the 37th parallel. The transfer was prompted by the discovery of gold in the area, and officials thought Nevada would be better able to oversee the expected population boom. This area includes most of what is now Clark County and the Las Vegas metropolitan area.

Mining shaped Nevada's economy for many years (see "Silver mining in Nevada"). When Mark Twain lived in Nevada during the period described in "Roughing It", mining had led to an industry of speculation and immense wealth. However, both mining and population declined in the late 19th century. However, the rich silver strike at Tonopah in 1900, followed by strikes in Goldfield and Rhyolite, again put Nevada's population on an upward trend.

Unregulated gambling was commonplace in the early Nevada mining towns but was outlawed in 1909 as part of a nationwide anti-gambling crusade. Because of subsequent declines in mining output and the decline of the agricultural sector during the Great Depression, Nevada again legalized gambling on March 19, 1931, with approval from the legislature. Governor Fred B. Balzar's signature enacted the most liberal divorce laws in the country and open gambling. The reforms came just eight days after the federal government presented the $49 million construction contract for Boulder Dam (now Hoover Dam).

The Nevada Test Site, northwest of the city of Las Vegas, was founded on January 11, 1951, for the testing of nuclear weapons. The site consists of about of the desert and mountainous terrain. Nuclear testing at the Nevada Test Site began with a bomb dropped on Frenchman Flat on January 27, 1951. The last atmospheric test was conducted on July 17, 1962, and the underground testing of weapons continued until September 23, 1992. The location is known for having the highest concentration of nuclear-detonated weapons in the U.S.

Over 80% of the state's area is owned by the federal government. The primary reason for this is homesteads were not permitted in large enough sizes to be viable in the arid conditions that prevail throughout desert Nevada. Instead, early settlers would homestead land surrounding a water source, and then graze livestock on the adjacent public land, which is useless for agriculture without access to water (this pattern of ranching still prevails).

The United States Census Bureau estimates the population of Nevada on July 1, 2018, was 3,034,392, an increase of 61,987 residents (2.1%) since the 2017 US Census estimate and an increase of 333,841 residents (12.4%) since the 2010 United States Census. Nevada had the first highest percentage growth in population from 2017 to 2018. At the 2010 Census, 6.9% of the state's population were reported as under 5, 24.6% were under 18, and 12.0% were 65 or older. Females made up about 49.5% of the population.

Since the 2010 census, the population of Nevada had a natural increase of 87,581 (the net difference between 222,508 births and 134,927 deaths); and an increase due to net migration of 146,626 (of which 104,032 was due to domestic and 42,594 was due to international migration).

The center of population of Nevada is in southern Nye County. In this county, the unincorporated town of Pahrump, west of Las Vegas on the California state line, has grown very rapidly from 1980 to 2010. At the 2010 census, the town had 36,441 residents. Las Vegas grew from a gulch of 100 people in 1900 to 10,000 by 1950 to 100,000 by 1970, and was America's fastest-growing city and metropolitan area from 1960 to 2000.

From about the 1940s until 2003, Nevada was the fastest-growing state in the US percentage-wise. Between 1990 and 2000, Nevada's population increased by 66%, while the US's population increased by 13%. Over two-thirds of the population of the state lives in Clark County, which is coextensive with the Las Vegas metropolitan area. Thus, in terms of population, Nevada is one of the most centralized states in the nation.

Henderson and North Las Vegas are among the top 20 fastest-growing U.S. cities with populations of over 100,000. The rural community of Mesquite northeast of Las Vegas was an example of micropolitan growth in the 1990s and 2000s. Other desert towns like Indian Springs and Searchlight on the outskirts of Las Vegas have seen some growth as well.

Since 1950, the rate of population born in Nevada has never peaked 27 percent, the lowest rate of all states. In 2012, only 25% of Nevadans were born in-state.

Large numbers of new residents in the state originate from California, which led some locals to feel their state is being "Californicated".

According to the 2016 American Community Survey, 27.8% of Nevada's population were of Hispanic or Latino origin (of any race): Mexican (21.3%), Puerto Rican (0.9%), Cuban (0.9%), and other Hispanic or Latino origin (4.7%). The five largest non-Hispanic White ancestry groups were: German (11.3%), Irish (9.0%), English (6.9%), Italian (5.8%), and American (4.7%).

In 1980, non-Hispanic whites made up 83.3% of the state's population.

As of 2011, 63.6% of Nevada's population younger than age 1 were minorities. Las Vegas is a minority majority city. According to the United States Census Bureau estimates, as of July 1, 2018, non-Hispanic Whites made up 48.7% of Nevada's population.

In Douglas, Mineral, and Pershing counties, a plurality of residents are of Mexican ancestry. In Nye County and Humboldt County, residents are mostly of German ancestry; Washoe County has many Irish Americans. Americans of English descent form pluralities in Lincoln County, Churchill County, Lyon County, White Pine County, and Eureka County.

Asian Americans lived in the state since the California Gold Rush of the 1850s brought thousands of Chinese miners to Washoe county. They were followed by a few hundred Japanese farmworkers in the late 19th century. By the late 20th century, many immigrants from China, Japan, Korea, the Philippines, Bangladesh, India, and Vietnam came to the Las Vegas metropolitan area. The city now has one of America's most prolific Asian American communities, with a mostly Chinese and Taiwanese area known as "Chinatown" west of I-15 on Spring Mountain Road. Filipino Americans form the largest Asian American group in the state, with a population of more than 113,000. They comprise 56.5% of the Asian American population in Nevada and constitute about 4.3% of the entire state's population.

Largely African American sections of Las Vegas and Reno can be found. Many current African-American Nevadans are newly transplanted residents from California.

Las Vegas was a major destination for immigrants from South Asia and Latin America seeking employment in the gaming and hospitality industries during the 1990s and first decade of the 21st century, but farming and construction are the biggest employers of immigrant labor.

The religious makeup of Nevadans includes large communities of members of The Church of Jesus Christ of Latter-day Saints, Roman Catholics, and Evangelicals; each is known for higher birth rates and a younger than national average age. American Jews represent a large proportion of the active adult retirement community.

"Note: Births within the table do not add up, due to Hispanics being counted both by their ethnicity and by their race, giving a higher overall number."


A small percentage of Nevada's population lives in rural areas. The culture of these places differs significantly from major metropolitan areas. People in these rural counties tend to be native Nevada residents, unlike in the Las Vegas and Reno areas, where the vast majority of the population was born in another state. The rural population is also less diverse in terms of race and ethnicity. Mining plays an important role in the economies of the rural counties, with tourism being less prominent. Ranching also has a long tradition in rural Nevada.

Church attendance in Nevada is among the lowest of all U.S. states. In a 2009 Gallup poll only 30% of Nevadans said they attended church weekly or almost weekly, compared to 42% of all Americans (only four states were found to have a lower attendance rate than Nevada).

Major religious affiliations of the people of Nevada are: Protestant 35%, no religion 28%, Roman Catholic 25%, Latter-day Saint 4%, Jewish 2%, Hindu less than 1%, Buddhist 0.5% and Islam less than 0.1%. Parts of Nevada (in the eastern parts of the state) are situated in the Mormon Corridor.

The largest denominations by number of adherents in 2010 were the Roman Catholic Church with 451,070; The Church of Jesus Christ of Latter-day Saints with 175,149; and the Southern Baptist Convention with 45,535; Buddhist congregations 14,727; Bahá'í 1,723; and Muslim 1,700. The Jewish community is represented by The Rohr Jewish Learning Institute and Chabad.

The economy of Nevada is tied to tourism (especially entertainment and gambling related), mining, and cattle ranching. Nevada's industrial outputs are tourism, mining, machinery, printing and publishing, food processing, and electric equipment. The Bureau of Economic Analysis estimates Nevada's total state product in 2018 was $170 billion. The state's per capita personal income in 2018 was $43,820, ranking 35th in the nation. Nevada's state debt in 2012 was calculated to be $7.5 billion, or $3,100 per taxpayer. As of December 2014, the state's unemployment rate was 6.8%.

The economy of Nevada has long been tied to vice industries. "[Nevada was] founded on mining and refounded on sin—beginning with prizefighting and easy divorce a century ago and later extending to gaming and prostitution", said the August 21, 2010 issue of "The Economist".

In portions of the state outside of the Las Vegas and Reno metropolitan areas mining plays a major economic role. By value, gold is by far the most important mineral mined. In 2004, of gold worth $2.84 billion were mined in Nevada, and the state accounted for 8.7% of world gold production (see "Gold mining in Nevada"). Silver is a distant second, with worth $69 million mined in 2004 (see "Silver mining in Nevada"). Other minerals mined in Nevada include construction aggregates, copper, gypsum, diatomite and lithium. Despite its rich deposits, the cost of mining in Nevada is generally high, and output is very sensitive to world commodity prices.

Cattle ranching is a major economic activity in rural Nevada. Nevada's agricultural outputs are cattle, hay, alfalfa, dairy products, onions, and potatoes. As of January 1, 2006, there were an estimated 500,000 head of cattle and 70,000 head of sheep in Nevada. Most of these animals forage on rangeland in the summer, with supplemental feed in the winter. Calves are generally shipped to out-of-state feedlots in the fall to be fattened for the market. Over 90% of Nevada's of cropland is used to grow hay, mostly alfalfa, for livestock feed.

The largest employers in the state, as of the first fiscal quarter of 2011, are the following, according to the Nevada Department of Employment, Training and Rehabilitation:

Amtrak's "California Zephyr" train uses the Union Pacific's original transcontinental railroad line in daily service from Chicago to Emeryville, California, serving Elko, Winnemucca, and Reno. Las Vegas has had no passenger train service since Amtrak's Desert Wind was discontinued in 1997. Amtrak Thruway Motorcoaches provide connecting service from Las Vegas to trains at Needles, California, Los Angeles, and Bakersfield, California; and from Stateline, Nevada, to Sacramento, California. There have been a number of proposals to re-introduce service to either Los Angeles or Southern California.

The Union Pacific Railroad has some railroads in the north and south of Nevada. Greyhound Lines provide some bus service to the state.

Interstate 15 passes through the southern tip of the state, serving Las Vegas and other communities. I-215 and spur route I-515 also serve the Las Vegas metropolitan area. Interstate 80 crosses through the northern part of Nevada, roughly following the path of the Humboldt River from Utah in the east and the Truckee River westward through Reno into California. It has a spur route, I-580. Nevada also is served by several U.S. highways: US 6, US 50, US 93, US 95 and US 395. There are also 189 Nevada state routes. Many of Nevada's counties have a system of county routes as well, though many are not signed or paved in rural areas. Nevada is one of a few states in the U.S. that does not have a continuous interstate highway linking its two major population centers—the road connection between the Las Vegas and Reno areas is a combination of several different Interstate and U.S. highways. The Interstate 11 proposed routing may eventually remedy this.

The state is one of just a few in the country to allow semi-trailer trucks with three trailers—what might be called a "road train" in Australia. But American versions are usually smaller, in part because they must ascend and descend some fairly steep mountain passes.

RTC Transit is the public transit system in the Las Vegas metropolitan area. The agency is the largest transit agency in the state and operates a network of bus service across the Las Vegas Valley, including the use of The Deuce, double-decker buses, on the Las Vegas Strip and several outlying routes. RTC RIDE operates a system of local transit bus service throughout the Reno-Sparks metropolitan area. Other transit systems in the state include Carson City's JAC. Most other counties in the state do not have public transportation at all.

Additionally, a monorail system provides public transportation in the Las Vegas area. The Las Vegas Monorail line services several casino properties and the Las Vegas Convention Center on the east side of the Las Vegas Strip, running near Paradise Road, with a possible future extension to McCarran International Airport. Several hotels also run their own monorail lines between each other, which are typically several blocks in length.

McCarran International Airport in Las Vegas is the busiest airport serving Nevada. The Reno-Tahoe International Airport (formerly known as the Reno Cannon International Airport) is the other major airport in the state.

Nevada has had a thriving solar energy sector. An independent study in 2013 concluded that solar users created a $36m net benefit. However, in December 2015, the Public Utility Commission let the state's only power company, NV Energy, charge higher rates and fees to solar panel users, leading to an immediate collapse of rooftop solar panel use 

In December 1987, Congress amended the Nuclear Waste Policy Act to designate Yucca Mountain nuclear waste repository as the only site to be characterized as a permanent repository for all of the nation's highly radioactive waste.

Under the Constitution of the State of Nevada, the powers of the Nevada government are divided among three separate departments: the Executive consisting of the Governor of Nevada and their cabinet along with the other elected constitutional officers; the Legislative consisting of the Nevada Legislature, which includes the Assembly and the Senate; and the Judicial consisting of the Supreme Court of Nevada and lower courts.

The Governor of Nevada is the chief magistrate of Nevada, the head of the executive department of the state's government, and the commander-in-chief of the state's military forces. The current Governor of Nevada is Steve Sisolak, a Democrat.

The Nevada Legislature is a bicameral body divided into an Assembly and Senate. Members of the Assembly serve for 2 years, and members of the Senate serve for 4 years. Both houses of the Nevada Legislature will be impacted by term limits starting in 2010, as Senators and Assemblymen/women will be limited to a maximum of 12 years service in each house (by appointment or election which is a lifetime limit)—a provision of the constitution which was recently upheld by the Supreme Court of Nevada in a unanimous decision. Each session of the Legislature meets for a constitutionally mandated 120 days in every odd-numbered year, or longer if the Governor calls a special session.

On December 18, 2018, Nevada became the first in the United States with a female majority in its legislature. Women hold nine of the 21 seats in the Nevada Senate, and 23 of the 42 seats in the Nevada Assembly.

The Supreme Court of Nevada is the state supreme court and the head of the Nevada Judiciary. Original jurisdiction is divided between the district courts (with general jurisdiction), and justice courts and municipal courts (both of limited jurisdiction). Appeals from District Courts are made directly to the Nevada Supreme Court, which under a deflective model of jurisdiction, has the discretion to send cases to the Court of Appeals for final resolution.

Incorporated towns in Nevada, known as cities, are given the authority to legislate anything not prohibited by law. A recent movement has begun to permit home rule to incorporate Nevada cities to give them more flexibility and fewer restrictions from the Legislature. Town Boards for unincorporated towns are limited local governments created by either the local county commission, or by referendum, and form a purely advisory role and in no way diminish the responsibilities of the county commission that creates them.

State departments and agencies:

In 1900, Nevada's population was the smallest of all states and was shrinking, as the difficulties of living in a "barren desert" began to outweigh the lure of silver for many early settlers. Historian Lawrence Friedman has explained what happened next:

Nevada, in a burst of ingenuity, built an economy by exploiting its sovereignty. Its strategy was to legalize all sorts of things that were illegal in California ... after the easy divorce came easy marriage and casino gaming. Even prostitution is legal in Nevada, in any county that decides to allow it. Quite a few of them do.

With the advent of air conditioning for summertime use and Southern Nevada's mild winters, the fortunes of the state began to turn around, as it did for Arizona, making these two states the fastest growing in the Union.

Nevada is the only state where prostitution is legal (under the form of licensed brothels).

Prostitution is specifically illegal by state law in the state's larger jurisdictions, which include Clark County (which contains Las Vegas), Washoe County (which contains Reno), and the independent city of Carson City. Otherwise, it is legal in those counties which specifically vote to permit it. When permitted, brothels are only in rural or isolated parts of counties.

Nevada's early reputation as a "divorce haven" arose from the fact that before the no-fault divorce revolution in the 1970s, divorces were difficult to obtain in the United States. Already having legalized gambling and prostitution, Nevada continued the trend of boosting its profile by adopting one of the most liberal divorce statutes in the nation. This resulted in "Williams v. North Carolina (1942)", , in which the U.S. Supreme Court ruled North Carolina had to give "full faith and credit" to a Nevada divorce. The Court modified its decision in "Williams v. North Carolina" (1945), , by holding a state need not recognize a Nevada divorce unless one of the parties was domiciled there at the time the divorce was granted and the forum state was entitled to make its own determination.

As of 2009, Nevada's divorce rate was above the national average.

Nevada's tax laws are intended to draw new residents and businesses to the state. Nevada has no personal income tax or corporate income tax. Since Nevada does not collect income data it cannot share such information with the federal government, the IRS.

The state sales tax (similar to VAT or GST) in Nevada is variable depending upon the county. The statewide tax rate is 6.85%, with five counties (Elko, Esmeralda, Eureka, Humboldt, and Mineral) charging this amount. Counties may impose additional rates via voter approval or through approval of the state legislature; therefore, the applicable sales tax varies by county from 6.85% to 8.1% (Clark County). Clark County, which includes Las Vegas, imposes four separate county option taxes in addition to the statewide rate: 0.25% for flood control, 0.50% for mass transit, 0.25% for infrastructure, and 0.25% for more cops. In Washoe County, which includes Reno, the sales tax rate is 7.725%, due to county option rates for flood control, the ReTRAC train trench project, and mass transit, and an additional county rate approved under the Local Government Tax Act of 1991. The minimum Nevada sales tax rate changed on July 1, 2009.

The lodging tax rate in unincorporated Clark County, which includes the Las Vegas Strip, is 12%. Within the boundaries of the cities of Las Vegas and Henderson, the lodging tax rate is 13%.

Corporations such as Apple Inc. allegedly have set up investment companies and funds in Nevada to avoid paying taxes.

In 2009, the Nevada Legislature passed a bill creating a domestic partnership registry that enables gay couples to enjoy the same rights as married couples. In June 2015, gay marriage became legal in Nevada.

Nevada provides a friendly environment for the formation of corporations, and many (especially California) businesses have incorporated in Nevada to take advantage of the benefits of the Nevada statute. Nevada corporations offer great flexibility to the Board of Directors and simplify or avoid many of the rules that are cumbersome to business managers in some other states. In addition, Nevada has no franchise tax, although it does require businesses to have a license for which the business has to pay the state.

Similarly, many U.S. states have usury laws limiting the amount of interest a lender can charge, but federal law allows corporations to 'import' these laws from their home state.

Nevada has very liberal alcohol laws. Bars are permitted to remain open 24 hours, with no "last call". Liquor stores, convenience stores and supermarkets may also sell alcohol 24  hours per day and may sell beer, wine and spirits.

In 2016, Nevada voters approved Question 2, which legalized the possession, transportation and cultivation of personal use amounts of marijuana for adults age 21 years and older, and authorized the creation of a regulated market for the sale of marijuana to adults age 21 years and older through state-licensed retail outlets. Nevada voters had previously approved medical marijuana in 2000, but rejected marijuana legalization in a similar referendum in 2006. Marijuana in all forms remains illegal under federal law.

Aside from cannabis legalization, non-alcohol drug laws are a notable exception to Nevada's otherwise libertarian principles. It is notable for having the harshest penalties for drug offenders in the country. Nevada remains the only state to still use mandatory minimum sentencing guidelines for possession of drugs.

Nevada voters enacted a smoking ban ("The Nevada Clean Indoor Air Act") in November 2006 that became effective on December 8, 2006. It outlaws smoking in most workplaces and public places. Smoking is permitted in bars, but only if the bar serves no food, or the bar is inside a larger casino. Smoking is also permitted in casinos, certain hotel rooms, tobacco shops, and brothels. However, some businesses do not obey this law and the government tends not to enforce it. In 2011, smoking restrictions in Nevada were loosened for certain places which allow only people age 21 or older inside.

In 2006, the crime rate in Nevada was about 24% higher than the national average rate, though crime has since decreased. Property crimes accounted for about 85% of the total crime rate in Nevada, which was 21% higher than the national rate. The remaining 20.3% were violent crimes. A complete listing of crime data in the state for 2013 can be found here:

Due to heavy growth in the southern portion of the state, there is a noticeable divide between the politics of northern and southern Nevada. The north has long maintained control of key positions in state government, even while the population of southern Nevada is larger than the rest of the state combined. The north sees the high population south becoming more influential and perhaps commanding majority rule. The south sees the north as the "old guard" trying to rule as an oligarchy. This has fostered some resentment, however, due to a term limit amendment passed by Nevada voters in 1994, and again in 1996, some of the north's hold over key positions will soon be forfeited to the south, leaving northern Nevada with less power.

Historically, northern Nevada has been very Republican. The more rural counties of the north are among the most conservative regions of the country. Carson City, the state's capital, is a Republican-leaning swing city/county. Washoe County, home to Reno, has historically been strongly Republican, but now has become more of a Democratic-leaning swing county. Clark County, home to Las Vegas, has been a stronghold for the Democratic Party since it was founded in 1909, having voted Republican only six times and once for a third-party candidate.
Clark and Washoe counties have long dominated the state's politics. Between them, they cast 87 percent of Nevada's vote, and elect a substantial majority of the state legislature. The last Republican to carry Clark County was George H.W. Bush in 1988, and the last Republican to carry Washoe County was George W. Bush in 2004. The great majority of the state's elected officials are either from Las Vegas or Reno.

Nevada voted for the winner in nearly every presidential election from 1912 to 2012, with the exception in 1976 when it voted for Gerald Ford over Jimmy Carter. This includes Nevada supporting Democrats John F. Kennedy and Lyndon B. Johnson in 1960 and 1964, respectively. Republican Richard Nixon in 1968 and in 1972, Republican Ronald Reagan in 1980 and in 1984, Republican George H.W. Bush in 1988, Democrat Bill Clinton in 1992 and 1996, Republican George W. Bush in 2000 and 2004, and Democrat Barack Obama winning the state in both 2008 and 2012. This gives the state status as a political bellwether. From 1912 to 2012, Nevada has been carried by the presidential victor the most out of any state (26 of 27 elections). In 2016, Nevada lost its bellwether status when it narrowly cast its votes for Hillary Clinton. Nevada was one of only three states won by John F. Kennedy in the American West in the election of 1960, albeit narrowly.

The state's U.S. Senators are Democrats Catherine Cortez Masto and Jacky Rosen. The Governorship is held by Steve Sisolak, a Democrat.

Nevada is the only U.S. state to have a none of the above option available on its ballots. Officially called None of These Candidates, the option was first added to the ballot in 1975 and is used in all statewide elections, including president, US Senate and all state constitutional positions. In the event "None of These Candidates" receives a plurality of votes in the election, the candidate with the next-highest total is elected.

Education in Nevada is achieved through public and private elementary, middle, and high schools, as well as colleges and universities.

A May 2015 educational reform law expanded school choice options to 450,000 Nevada students who are at up to 185% of the federal poverty level. Education savings accounts (ESAs) are enabled by the new law to help pay the tuition for private schools. Alternatively, families "can use funds in these accounts to also pay for textbooks and tutoring."

Public school districts in Nevada include:


The Nevada Aerospace Hall of Fame provides educational resources and promotes the aerospace and aviation history of the state.



There are 68 designated wilderness areas in Nevada, protecting some under the jurisdiction of the National Park Service, U.S. Forest Service, and Bureau of Land Management.

The Nevada state parks comprise protected areas managed by the state of Nevada, including state parks, state historic sites, and state recreation areas. There are 24 state park units, including Van Sickle Bi-State Park which opened in July 2011 and is operated in partnership with the state of California.

Resort areas like Las Vegas, Reno, Lake Tahoe, and Laughlin attract visitors from around the nation and world. In FY08 the total of 266 casinos with gaming revenue over $1m for the year, brought in revenue of $12 billion in gaming revenue, and $13 billion in non-gaming revenue. A review of gaming statistics can be found at Nevada gaming area.

Nevada has by far the most hotel rooms per capita in the United States. According to the American Hotel and Lodging Association, there were 187,301 rooms in 584 hotels (of 15 or more rooms). The state is ranked just below California, Texas, Florida, and New York in the total number of rooms, but those states have much larger populations. Nevada has one hotel room for every 14 residents, far above the national average of one hotel room per 67 residents.

Prostitution is legal in parts of Nevada in licensed brothels, but only counties with populations under 400,000 have the option to legalize it. Although prostitution is not a major part of the Nevada economy, employing roughly 300 women as independent contractors, it is a very visible endeavor. Of the 14 counties permitted to legalize prostitution under state law, 8 have chosen to legalize brothels. State law prohibits prostitution in Clark County (which contains Las Vegas), and Washoe County (which contains Reno). However, prostitution is legal in Storey County, which is part of the Reno–Sparks metropolitan area.

The Las Vegas Valley is home to the Vegas Golden Knights of the National Hockey League who began to play in the 2017–18 NHL season at T-Mobile Arena on the Las Vegas Strip in Paradise, Nevada, the Las Vegas Raiders of the National Football League who begin play at Allegiant Stadium in Las Vegas in 2020 after moving from Oakland, California, and the Las Vegas Aces of the WNBA who began playing in 2018 at Mandalay Bay Events Center. The team moved from San Antonio. 

Nevada takes pride in college sports, most notably its college football. College teams in the state include the Nevada Wolf Pack (representing the University of Nevada, Reno) and the UNLV Rebels (representing the University of Nevada, Las Vegas), both in the Mountain West Conference (MW).

UNLV is most remembered for its men's basketball program, which experienced its height of supremacy in the late 1980s and early 1990s. Coached by Jerry Tarkanian, the Runnin' Rebels became one of the most elite programs in the country. In 1990, UNLV won the Men's Division I Championship by defeating Duke 103–73, which set tournament records for most points scored by a team and largest margin of victory in the national title game.

In 1991, UNLV finished the regular season undefeated, a feat that would not be matched in Division I men's basketball for more than 20 years. Forward Larry Johnson won several awards, including the Naismith Award. UNLV reached the Final Four yet again, but lost their national semifinal against Duke 79–77. The Runnin' Rebels were the Associated Press pre-season No. 1 back to back (1989–90, 1990–91). North Carolina is the only other team to accomplish that (2007–08, 2008–09).

The state's involvement in major-college sports is not limited to its local schools. In the 21st century, the Las Vegas area has become a significant regional center for college basketball conference tournaments. The MW, West Coast Conference, and Western Athletic Conference all hold their men's and women's tournaments in the area, and the Pac-12 holds its men's tournament there as well. The Big Sky Conference, after decades of holding its men's and women's conference tournaments at campus sites, began holding both tournaments in Reno in 2016.

Las Vegas has hosted several professional boxing matches, most recently at the MGM Grand Garden Arena with bouts such as Mike Tyson vs. Evander Holyfield, Evander Holyfield vs. Mike Tyson II, Oscar De La Hoya vs. Floyd Mayweather and Oscar De La Hoya vs. Manny Pacquiao and at the newer T-Mobile Arena with Canelo Álvarez vs. Amir Khan.

Along with significant rises in popularity in mixed martial arts (MMA), a number of fight leagues such as the UFC have taken interest in Las Vegas as a primary event location due to the number of suitable host venues. The Mandalay Bay Events Center and MGM Grand Garden Arena are among some of the more popular venues for fighting events such as MMA and have hosted several UFC and other MMA title fights. The city has held the most UFC events with 86 events.

The state is also home to the Las Vegas Motor Speedway, which hosts the Kobalt Tools 400. Two venues in the immediate Las Vegas area host major annual events in rodeo. The Thomas & Mack Center, built for UNLV men's basketball, hosts the National Finals Rodeo. The PBR World Finals, operated by the bull riding-only Professional Bull Riders, was also held at the Thomas & Mack Center before moving to T-Mobile Arena in 2016.

The state is also home to one of the most famous tennis players of all time, Andre Agassi, and current baseball superstar Bryce Harper.

Several United States Navy ships have been named USS "Nevada" in honor of the state. They include:

Area 51 is near Groom Lake, a dry salt lake bed. The much smaller Creech Air Force Base is in Indian Springs, Nevada; Hawthorne Army Depot in Hawthorne; the Tonopah Test Range near Tonopah; and Nellis AFB in the northeast part of the Las Vegas Valley. Naval Air Station Fallon in Fallon; NSAWC, (pronounced "EN-SOCK") in western Nevada. NSAWC consolidated three Command Centers into a single Command Structure under a flag officer on July 11, 1996. The Naval Strike Warfare Center (STRIKE "U") based at NAS Fallon since 1984, was joined with the Navy Fighter Weapons School (TOPGUN) and the Carrier Airborne Early Warning Weapons School (TOPDOME) which both moved from NAS Miramar as a result of a Base Realignment and Closure (BRAC) decision in 1993 which transferred that installation back to the Marine Corps as MCAS Miramar. The Seahawk Weapon School was added in 1998 to provide tactical training for Navy helicopters.

These bases host a number of activities including the Joint Unmanned Aerial Systems Center of Excellence, the Naval Strike and Air Warfare Center, Nevada Test and Training Range, Red Flag, the U.S. Air Force Thunderbirds, the United States Air Force Warfare Center, the United States Air Force Weapons School, and the United States Navy Fighter Weapons School.

Nevada enjoys many economic advantages, and the southern portion of the state enjoys mild winter weather, but rapid growth has led to some overcrowded roads and schools. Nevada has the nation's 5th largest school district in the Clark County School District (projected fall 2007 enrollment is 314,000 students grades K-12).

Coyote Springs is a proposed community for 240,000 inhabitants in Clark and Lincoln counties. It would be Nevada's largest planned city. The town is being developed by Harvey Whittemore and has generated some controversy because of environmental concerns and allegations of political favoritism.





</doc>
<doc id="21217" url="https://en.wikipedia.org/wiki?curid=21217" title="Native Americans in the United States">
Native Americans in the United States

Native Americans, also known as American Indians, Indigenous Americans and other terms, are the indigenous peoples of the United States, except Hawaii and territories of the United States. More than 570 federally recognized tribes live within the US, about half of which are associated with Indian reservations. The term "American Indian" excludes Native Hawaiians and some Alaskan Natives, while "Native Americans" (as defined by the US Census) are American Indians, plus Alaska Natives of all ethnicities. The US Census does not include Native Hawaiians or Chamorro, instead being included in the Census grouping of "Native Hawaiian and other Pacific Islander".

The ancestors of living Native Americans arrived in what is now the United States at least 15,000 years ago, possibly much earlier, from Asia via Beringia. A vast variety of peoples, societies and cultures subsequently developed. Native Americans were greatly affected by the European colonization of the Americas, which began in 1492, and their population declined precipitously overwhelmingly due to introduced diseases as well as warfare, including biological warfare, territorial confiscation and slavery. After its creation, the United States, as part of its policy of settler colonialism, waged war and perpetrated massacres against many Native American peoples, removed them from their ancestral lands, and subjected them to one-sided treaties and to discriminatory government policies into the 20th century. Since the 1960s, Native American self-determination movements have resulted in changes to the lives of Native Americans, though there are still many contemporary issues faced by Native Americans. Today, there are over five million Native Americans in the United States, 78% of whom live outside reservations.

When the United States was created, established Native American tribes were generally considered semi-independent nations, as they generally lived in communities separate from British settlers. The federal government signed treaties at a government-to-government level until the Indian Appropriations Act of 1871 ended recognition of independent native nations, and started treating them as "domestic dependent nations" subject to federal law. This law did preserve the rights and privileges agreed to under the treaties, including a large degree of tribal sovereignty. For this reason, many (but not all) Native American reservations are still independent of state law and actions of tribal citizens on these reservations are subject only to tribal courts and federal law.

The Indian Citizenship Act of 1924 granted U.S. citizenship to all Native Americans born in the United States who had not yet obtained it. This emptied the "Indians not taxed" category established by the United States Constitution, allowed natives to vote in state and federal elections, and extended the Fourteenth Amendment protections granted to people "subject to the jurisdiction" of the United States. However, some states continued to deny Native Americans voting rights for several decades. Bill of Rights protections do not apply to tribal governments, except for those mandated by the Indian Civil Rights Act of 1968.

Since the end of the 15th century, the migration of Europeans to the Americas has led to centuries of population, cultural, and agricultural transfer and adjustment between Old and New World societies, a process known as the Columbian exchange. As most Native American groups had historically preserved their histories by oral traditions and artwork, the first written sources of the conflict were written by Europeans.
Ethnographers commonly classify the indigenous peoples of North America into ten geographical regions with shared cultural traits, called cultural areas. Some scholars combine the Plateau and Great Basin regions into the Intermontane West, some separate Prairie peoples from Great Plains peoples, while some separate Great Lakes tribes from the Northeastern Woodlands. The ten cultural areas are as follows:


At the time of the first contact, the indigenous cultures were quite different from those of the proto-industrial and mostly Christian immigrants. Some Northeastern and Southwestern cultures, in particular, were matrilineal and operated on a more collective basis than that with which Europeans were familiar. The majority of indigenous American tribes maintained their hunting grounds and agricultural lands for use of the entire tribe. Europeans at that time had patriarchal cultures and had developed concepts of individual property rights with respect to land that were extremely different. The differences in cultures between the established Native Americans and immigrant Europeans, as well as shifting alliances among different nations in times of war, caused extensive political tension, ethnic violence, and social disruption.

Even before the European settlement of what is now the United States, Native Americans suffered high fatalities from contact with new European diseases, to which they had not yet acquired immunity; the diseases were endemic to the Spanish and other Europeans, and spread by direct contact and likely through pigs that escaped from expeditions. Smallpox epidemics are thought to have caused the greatest loss of life for indigenous populations. William M. Denevan, noted author and Professor Emeritus of Geography at the University of Wisconsin-Madison, said on this subject in his essay "The Pristine Myth: The Landscape of the Americas in 1492"; "The decline of native American populations was rapid and severe, probably the greatest demographic disaster ever. Old World diseases were the primary killer. In many regions, particularly the tropical lowlands, populations fell by 90 percent or more in the first century after the contact. "

Estimates of the pre-Columbian population of what today constitutes the U.S. vary significantly, ranging from William M. Denevan's 3.8 million in his 1992 work "The Native Population of the Americas in 1492", to 18 million in Henry F. Dobyns' "Their Number Become Thinned" (1983). Henry F. Dobyns' work, being the highest single point estimate by far within the realm of professional academic research on the topic, has been criticized for being "politically motivated". Perhaps Dobyns' most vehement critic is David Henige, a bibliographer of Africana at the University of Wisconsin, whose "Numbers From Nowhere" (1998) is described as "a landmark in the literature of demographic fulmination". "Suspect in 1966, it is no less suspect nowadays," Henige wrote of Dobyns's work. "If anything, it is worse."

After the thirteen colonies revolted against Great Britain and established the United States, President George Washington and Secretary of War Henry Knox conceived of the idea of "civilizing" Native Americans in preparation for assimilation as U.S. citizens. Assimilation (whether voluntary, as with the Choctaw, or forced) became a consistent policy through American administrations. During the 19th century, the ideology of manifest destiny became integral to the American nationalist movement. Expansion of European-American populations to the west after the American Revolution resulted in increasing pressure on Native American lands, warfare between the groups, and rising tensions. In 1830, the U.S. Congress passed the Indian Removal Act, authorizing the government to relocate Native Americans from their homelands within established states to lands west of the Mississippi River, accommodating European-American expansion. This resulted in the ethnic cleansing of many tribes, with the brutal, forced marches coming to be known as The Trail of Tears.

Contemporary Native Americans have a unique relationship with the United States because they may be members of nations, tribes, or bands with sovereignty and treaty rights. Cultural activism since the late 1960s has increased political participation and led to an expansion of efforts to teach and preserve indigenous languages for younger generations and to establish a greater cultural infrastructure: Native Americans have founded independent newspapers and online media, recently including First Nations Experience, the first Native American television channel; established Native American studies programs, tribal schools, and universities, and museums and language programs; and have increasingly been published as authors in numerous genres.

The terms used to refer to Native Americans have at times been controversial. The ways Native Americans refer to themselves vary by region and generation, with many older Native Americans self-identifying as "Indians" or "American Indians", while younger Native Americans often identify as "Indigenous" or "Aboriginal". The term "Native American" has not traditionally included Native Hawaiians or certain Alaskan Natives, such as Aleut, Yup'ik, or Inuit peoples. By comparison, the indigenous peoples of Canada are generally known as First Nations.

It is not definitively known how or when the Native Americans first settled the Americas and the present-day United States. The prevailing theory proposes that people migrated from Eurasia across Beringia, a land bridge that connected Siberia to present-day Alaska during the Ice Age, and then spread southward throughout the Americas over the subsequent generations. Genetic evidence suggests at least three waves of migrants arrived from Asia, with the first occurring at least 15 thousand years ago. These migrations may have begun as early as 30,000 years ago and continued through to about 10,000 years ago, when the land bridge became submerged by the rising sea level caused by the ending of the last glacial period.

The pre-Columbian era incorporates all period subdivisions in the history and prehistory of the Americas before the appearance of significant European influences on the American continents, spanning the time of the original settlement in the Upper Paleolithic period to European colonization during the Early Modern period. While technically referring to the era before Christopher Columbus' voyages of 1492 to 1504, in practice the term usually includes the history of American indigenous cultures until they were conquered or significantly influenced by Europeans, even if this happened decades or even centuries after Columbus' initial landing.

Native American cultures are not normally included in characterizations of advanced stone age cultures as "Neolithic," which is a category that more often includes only the cultures in Eurasia, Africa, and other regions. The archaeological periods used are the classifications of archaeological periods and cultures established in Gordon Willey and Philip Phillips' 1958 book "Method and Theory in American Archaeology". They divided the archaeological record in the Americas into five phases; see Archaeology of the Americas.

Numerous Paleoindian cultures occupied North America, with some arrayed around the Great Plains and Great Lakes of the modern United States and Canada, as well as adjacent areas to the West and Southwest. According to the oral histories of many of the indigenous peoples of the Americas, they have been living on this continent since their genesis, described by a wide range of traditional creation stories. Other tribes have stories that recount migrations across long tracts of land and a great river, believed to be the Mississippi River. Genetic and linguistic data connect the indigenous people of this continent with ancient northeast Asians. Archeological and linguistic data has enabled scholars to discover some of the migrations within the Americas.

Archeological evidence at the Gault site near Austin, Texas, demonstrates that pre-Clovis peoples settled in Texas some 16,000—20,000 years ago. Evidence of pre-Clovis cultures have also been found in the Paisley Caves in south-central Oregon and butchered mastodon bones in a sinkhole near Tallahassee, Florida. More convincingly but also controversially, another pre-Clovis has been discovered at Monte Verde, Chile.

The Clovis culture, a megafauna hunting culture, is primarily identified by the use of fluted spear points. Artifacts from this culture were first excavated in 1932 near Clovis, New Mexico. The Clovis culture ranged over much of North America and also appeared in South America. The culture is identified by the distinctive Clovis point, a flaked flint spear-point with a notched flute, by which it was inserted into a shaft. Dating of Clovis materials has been by association with animal bones and by the use of carbon dating methods. Recent reexaminations of Clovis materials using improved carbon-dating methods produced results of 11,050 and 10,800 radiocarbon years B.P. (roughly 9100 to 8850 BCE).
The Folsom Tradition was characterized by the use of Folsom points as projectile tips and activities known from kill sites, where slaughter and butchering of bison took place. Folsom tools were left behind between 9000 BCE and 8000 BCE.

Na-Dené-speaking peoples entered North America starting around 8000 BCE, reaching the Pacific Northwest by 5000 BCE, and from there migrating along the Pacific Coast and into the interior. Linguists, anthropologists, and archaeologists believe their ancestors comprised a separate migration into North America, later than the first Paleo-Indians. They migrated into Alaska and northern Canada, south along the Pacific Coast, into the interior of Canada, and south to the Great Plains and the American Southwest. Na-Dené-speaking peoples were the earliest ancestors of the Athabascan-speaking peoples, including the present-day and historical Navajo and Apache. They constructed large multi-family dwellings in their villages, which were used seasonally. People did not live there year-round, but for the summer to hunt and fish, and to gather food supplies for the winter.

Since the 1990s, archeologists have explored and dated eleven Middle Archaic sites in present-day Louisiana and Florida at which early cultures built complexes with multiple earthwork mounds; they were societies of hunter-gatherers rather than the settled agriculturalists believed necessary according to the theory of Neolithic Revolution to sustain such large villages over long periods. The prime example is Watson Brake in northern Louisiana, whose 11-mound complex is dated to 3500 BCE, making it the oldest, dated site in North America for such complex construction. It is nearly 2,000 years older than the Poverty Point site. Construction of the mounds went on for 500 years until the site was abandoned about 2800 BCE, probably due to changing environmental conditions.

The Oshara Tradition people lived from 700–1000 CE. They were part of the Southwestern Archaic Tradition centered in north-central New Mexico, the San Juan Basin, the Rio Grande Valley, southern Colorado, and southeastern Utah.

Poverty Point culture is a Late Archaic archaeological culture that inhabited the area of the lower Mississippi Valley and surrounding Gulf Coast. The culture thrived from 2200 BCE to 700 BCE, during the Late Archaic period. Evidence of this culture has been found at more than 100 sites, from the major complex at Poverty Point, Louisiana (a UNESCO World Heritage Site) across a range to the Jaketown Site near Belzoni, Mississippi.

The Formative, Classic and post-Classic stages are sometimes incorporated together as the Post-archaic period, which runs from 1000 BCE onward. Sites & cultures include: Adena, Old Copper, Oasisamerica, Woodland, Fort Ancient, Hopewell tradition and Mississippian cultures.

The Woodland period of North American pre-Columbian cultures refers to the time period from roughly 1000 BCE to 1000 CE in the eastern part of North America. The Eastern Woodlands cultural region covers what is now eastern Canada south of the Subarctic region, the Eastern United States, along to the Gulf of Mexico. The Hopewell tradition describes the common aspects of the culture that flourished along rivers in the northeastern and midwestern United States from 100 BCE to 500 CE, in the Middle Woodland period. The Hopewell tradition was not a single culture or society, but a widely dispersed set of related populations. They were connected by a common network of trade routes, This period is considered a developmental stage without any massive changes in a short period, but instead having a continuous development in stone and bone tools, leather working, textile manufacture, tool production, cultivation, and shelter construction.

The indigenous peoples of the Pacific Northwest Coast were of many nations and tribal affiliations, each with distinctive cultural and political identities, but they shared certain beliefs, traditions, and practices, such as the centrality of salmon as a resource and spiritual symbol. Their gift-giving feast, potlatch, is a highly complex event where people gather in order to commemorate special events. These events include the raising of a Totem pole or the appointment or election of a new chief. The most famous artistic feature of the culture is the Totem pole, with carvings of animals and other characters to commemorate cultural beliefs, legends, and notable events.

The Mississippian culture was a mound-building Native American civilization archaeologists date from approximately 800 CE to 1600 CE, varying regionally. It was composed of a series of urban settlements and satellite villages (suburbs) linked together by a loose trading network, the largest city being Cahokia, believed to be a major religious center. The civilization flourished in what is now the Midwestern, Eastern, and Southeastern United States.

Numerous pre-Columbian societies were sedentary, such as the Pueblo peoples, Mandan, Hidatsa and others, and some established large settlements, even cities, such as Cahokia, in what is now Illinois. The Iroquois League of Nations or "People of the Long House" was a politically advanced, democratic society, which is thought by some historians to have influenced the United States Constitution, with the Senate passing a resolution to this effect in 1988. Other historians have contested this interpretation and believe the impact was minimal, or did not exist, pointing to numerous differences between the two systems and the ample precedents for the constitution in European political thought.

After 1492, European exploration and colonization of the Americas revolutionized how the Old and New Worlds perceived themselves. Many of the first major contacts were in Florida and the Gulf coast by Spanish explorers.

From the 16th through the 19th centuries, the population of Native Americans sharply declined. Most mainstream scholars believe that, among the various contributing factors, epidemic disease was the overwhelming cause of the population decline of the Native Americans because of their lack of immunity to new diseases brought from Europe. It is difficult to estimate the number of pre-Columbian Native Americans who were living in what is today the United States of America. Estimates range from a low of 2.1 million to a high of 18 million (Dobyns 1983). By 1800, the Native population of the present-day United States had declined to approximately 600,000, and only 250,000 Native Americans remained in the 1890s. Chicken pox and measles, endemic but rarely fatal among Europeans (long after being introduced from Asia), often proved deadly to Native Americans. In the 100 years following the arrival of the Spanish to the Americas, large disease epidemics depopulated large parts of the eastern United States in the 16th century.

There are a number of documented cases where diseases were deliberately spread among Native Americans as a form of biological warfare. The most well-known example occurred in 1763, when Sir Jeffery Amherst, Commander-in-Chief of the Forces of the British Army, wrote praising the use of smallpox-infected blankets to "extirpate" the Indian race. Blankets infected with smallpox were given to Native Americans besieging Fort Pitt. The effectiveness of the attempt is unclear.

In 1634, Fr. Andrew White of the Society of Jesus established a mission in what is now the state of Maryland, and the purpose of the mission, stated through an interpreter to the chief of an Indian tribe there, was "to extend civilization and instruction to his ignorant race, and show them the way to heaven". Fr. Andrew's diaries report that by 1640, a community had been founded which they named St. Mary's, and the Indians were sending their children there "to be educated among the English". This included the daughter of the Piscataway Indian chief Tayac, which exemplifies not only a school for Indians, but either a school for girls, or an early co-ed school. The same records report that in 1677, "a school for humanities was opened by our Society in the centre of [Maryland], directed by two of the Fathers; and the native youth, applying themselves assiduously to study, made good progress. Maryland and the recently established school sent two boys to St. Omer who yielded in abilities to few Europeans, when competing for the honor of being first in their class. So that not gold, nor silver, nor the other products of the earth alone, but men also are gathered from thence to bring those regions, which foreigners have unjustly called ferocious, to a higher state of virtue and cultivation."

Through the mid-17th century the Beaver Wars were fought over the fur trade between the Iroquois and the Hurons, the northern Algonquians, and their French allies. During the war the Iroquois destroyed several large tribal confederacies, including the Huron, Neutral, Erie, Susquehannock, and Shawnee, and became dominant in the region and enlarged their territory.

In 1727, the Sisters of the Order of Saint Ursula founded Ursuline Academy in New Orleans, which is currently the oldest continuously operating school for girls and the oldest Catholic school in the United States. From the time of its foundation, it offered the first classes for Native American girls, and would later offer classes for female African-American slaves and free women of color.
Between 1754 and 1763, many Native American tribes were involved in the French and Indian War/Seven Years' War. Those involved in the fur trade tended to ally with French forces against British colonial militias. The British had made fewer allies, but it was joined by some tribes that wanted to prove assimilation and loyalty in support of treaties to preserve their territories. They were often disappointed when such treaties were later overturned. The tribes had their own purposes, using their alliances with the European powers to battle traditional Native enemies. Some Iroquois who were loyal to the British, and helped them fight in the American Revolution, fled north into Canada.

After European explorers reached the West Coast in the 1770s, smallpox rapidly killed at least 30% of Northwest Coast Native Americans. For the next eighty to one hundred years, smallpox and other diseases devastated native populations in the region. Puget Sound area populations, once estimated as high as 37,000 people, were reduced to only 9,000 survivors by the time settlers arrived en masse in the mid-19th century.

Smallpox epidemics in 1780–82 and 1837–38 brought devastation and drastic depopulation among the Plains Indians. By 1832, the federal government established a smallpox vaccination program for Native Americans ("The Indian Vaccination Act of 1832"). It was the first federal program created to address a health problem of Native Americans.

With the meeting of two worlds, animals, insects, and plants were carried from one to the other, both deliberately and by chance, in what is called the Columbian Exchange. In the 16th century, Spaniards and other Europeans brought horses to Mexico. Some of the horses escaped and began to breed and increase their numbers in the wild. As Native Americans adopted use of the animals, they began to change their cultures in substantial ways, especially by extending their nomadic ranges for hunting. The reintroduction of the horse to North America had a profound impact on Native American culture of the Great Plains.

King Philip's War, also called Metacom's War or Metacom's Rebellion, was the last major armed conflict between Native American inhabitants of present-day southern New England and English colonists and their Native American allies from 1675 to 1676. It continued in northern New England (primarily on the Maine frontier) even after King Philip was killed, until a treaty was signed at Casco Bay in April 1678.

Some European philosophers considered Native American societies to be truly "natural" and representative of a golden age known to them only in folk history.

During the American Revolution, the newly proclaimed United States competed with the British for the allegiance of Native American nations east of the Mississippi River. Most Native Americans who joined the struggle sided with the British, based both on their trading relationships and hopes that colonial defeat would result in a halt to further colonial expansion onto Native American land. The first native community to sign a treaty with the new United States Government was the Lenape.

In 1779 the Sullivan Expedition was carried out during the American Revolutionary War against the British and the four allied nations of the Iroquois. George Washington gave orders that made it clear he wanted the Iroquois threat completely eliminated:

The British made peace with the Americans in the Treaty of Paris (1783), through which they ceded vast Native American territories to the United States without informing or consulting with the Native Americans.

The United States was eager to expand, develop farming and settlements in new areas, and satisfy land hunger of settlers from New England and new immigrants. The national government initially sought to purchase Native American land by treaties. The states and settlers were frequently at odds with this policy.

United States policy toward Native Americans continued to evolve after the American Revolution. George Washington and Henry Knox believed that Native Americans were equals but that their society was inferior. Washington formulated a policy to encourage the "civilizing" process. Washington had a six-point plan for civilization which included:

In the late 18th century, reformers starting with Washington and Knox, supported educating native children and adults, in efforts to "civilize" or otherwise assimilate Native Americans to the larger society (as opposed to relegating them to reservations). The Civilization Fund Act of 1819 promoted this civilization policy by providing funding to societies (mostly religious) who worked on Native American improvement.

The population of California Indians was reduced by 90% during the 19th century—from more than 200,000 in the early 19th century to approximately 15,000 at the end of the century, mostly due to disease. Epidemics swept through California Indian Country, such as the 1833 malaria epidemic. The population went into decline as a result of the Spanish authorities forcing Native Californians to live in the missions where they contracted diseases from which they had little immunity. Dr. Cook estimates that 15,250 or 45% of the population decrease in the Missions was caused by disease. Two epidemics of measles, one in 1806 and the other in 1828, caused many deaths. The mortality rates were so high that the missions were constantly dependent upon new conversions. During the California Gold Rush, many natives were killed by incoming settlers as well as by militia units financed and organized by the California government. Some scholars contend that the state financing of these militias, as well as the US government's role in other massacres in California, such as the Bloody Island and Yontoket Massacres, in which up to 400 or more natives were killed in each massacre, constitutes a campaign of genocide against the native people of California.

As American expansion continued, Native Americans resisted settlers' encroachment in several regions of the new nation (and in unorganized territories), from the Northwest to the Southeast, and then in the West, as settlers encountered the Native American tribes of the Great Plains. East of the Mississippi River, an intertribal army led by Tecumseh, a Shawnee chief, fought a number of engagements in the Northwest during the period 1811–12, known as Tecumseh's War. During the War of 1812, Tecumseh's forces allied themselves with the British. After Tecumseh's death, the British ceased to aid the Native Americans south and west of Upper Canada and American expansion proceeded with little resistance. Conflicts in the Southeast include the Creek War and Seminole Wars, both before and after the Indian Removals of most members of the Five Civilized Tribes.

In the 1830s, President Andrew Jackson signed the Indian Removal Act of 1830, a policy of relocating Indians from their homelands to Indian Territory and reservations in surrounding areas to open their lands for non-native settlements. This resulted in the Trail of Tears.
In July 1845, the New York newspaper editor John L. O'Sullivan coined the phrase, "Manifest Destiny", as the "design of Providence" supporting the territorial expansion of the United States. Manifest Destiny had serious consequences for Native Americans, since continental expansion for the U.S. took place at the cost of their occupied land. A justification for the policy of conquest and subjugation of the indigenous people emanated from the stereotyped perceptions of all Native Americans as "merciless Indian savages" (as described in the United States Declaration of Independence). Sam Wolfson in "The Guardian" writes, "The declaration's passage has often been cited as an encapsulation of the dehumanizing attitude toward indigenous Americans that the US was founded on."

The Indian Appropriations Act of 1851 set the precedent for modern-day Native American reservations through allocating funds to move western tribes onto reservations since there were no more lands available for relocation.

Native American nations on the plains in the west continued armed conflicts with the U.S. throughout the 19th century, through what were called generally Indian Wars. Notable conflicts in this period include the Dakota War, Great Sioux War, Snake War, Colorado War, and Texas-Indian Wars. Expressing the frontier anti-Indian sentiment, Theodore Roosevelt believed the Indians were destined to vanish under the pressure of white civilization, stating in an 1886 lecture:

One of the last and most notable events during the Indian wars was the Wounded Knee Massacre in 1890. In the years leading up to it the U.S. government had continued to seize Lakota lands. A Ghost Dance ritual on the Northern Lakota reservation at Wounded Knee, South Dakota, led to the U.S. Army's attempt to subdue the Lakota. The dance was part of a religious movement founded by the Northern Paiute spiritual leader Wovoka that told of the return of the Messiah to relieve the suffering of Native Americans and promised that if they would live righteous lives and perform the Ghost Dance properly, the European American colonists would vanish, the bison would return, and the living and the dead would be reunited in an Edenic world. On December 29 at Wounded Knee, gunfire erupted, and U.S. soldiers killed up to 300 Indians, mostly old men, women, and children.

Native Americans served in both the Union and Confederate military during the American Civil War. At the outbreak of the war, for example, the minority party of the Cherokees gave its allegiance to the Confederacy, while originally the majority party went for the North. Native Americans fought knowing they might jeopardize their independence, unique cultures, and ancestral lands if they ended up on the losing side of the Civil War. 28,693 Native Americans served in the Union and Confederate armies during the Civil War, participating in battles such as Pea Ridge, Second Manassas, Antietam, Spotsylvania, Cold Harbor, and in Federal assaults on Petersburg. A few Native American tribes, such as the Creek and the Choctaw, were slaveholders and found a political and economic commonality with the Confederacy. The Choctaw owned over 2,000 slaves.

In the 19th century, the incessant westward expansion of the United States incrementally compelled large numbers of Native Americans to resettle further west, often by force, almost always reluctantly. Native Americans believed this forced relocation illegal, given the Treaty of Hopewell of 1785. Under President Andrew Jackson, United States Congress passed the Indian Removal Act of 1830, which authorized the President to conduct treaties to exchange Native American land east of the Mississippi River for lands west of the river.

As many as 100,000 Native Americans relocated to the West as a result of this Indian removal policy. In theory, relocation was supposed to be voluntary and many Native Americans did remain in the East. In practice, great pressure was put on Native American leaders to sign removal treaties. The most egregious violation, the Trail of Tears, was the removal of the Cherokee by President Jackson to Indian Territory. The 1864 deportation of the Navajos by the U.S. government occurred when 8,000 Navajos were forced to an internment camp in Bosque Redondo, where, under armed guards, more than 3,500 Navajo and Mescalero Apache men, women, and children died from starvation and disease.

In 1817, the Cherokee became the first Native Americans recognized as U.S. citizens. Under Article 8 of the 1817 Cherokee treaty, "Upwards of 300 Cherokees (Heads of Families) in the honest simplicity of their souls, made an election to become American citizens".

Factors establishing citizenship included:

After the American Civil War, the Civil Rights Act of 1866 states, "that all persons born in the United States, and not subject to any foreign power, excluding Indians not taxed, are hereby declared to be citizens of the United States".

In 1871, Congress added a rider to the Indian Appropriations Act, signed into law by President Ulysses S. Grant, ending United States recognition of additional Native American tribes or independent nations, and prohibiting additional treaties.

After the Indian wars in the late 19th century, the government established Native American boarding schools, initially run primarily by or affiliated with Christian missionaries. At this time, American society thought that Native American children needed to be acculturated to the general society. The boarding school experience was a total immersion in modern American society, but it could prove traumatic to children, who were forbidden to speak their native languages. They were taught Christianity and not allowed to practice their native religions, and in numerous other ways forced to abandon their Native American identities.

Before the 1930s, schools on the reservations provided no schooling beyond the sixth grade. To obtain more, boarding school was usually necessary. Small reservations with a few hundred people usually sent their children to nearby public schools. The "Indian New Deal" of the 1930s closed many of the boarding schools, and downplayed the assimilationist goals. The Indian Division of the Civilian Conservation Corps operated large-scale construction projects on the reservations, building thousands of new schools and community buildings. Under the leadership of John Collier the Bureau of Indian Affairs (BIA) brought in progressive educators to reshape Indian education. The BIA by 1938 taught 30,000 students in 377 boarding and day schools, or 40% of all Indian children in school. The Navajo largely opposed schooling of any sort, but the other tribes accepted the system. There were now high schools on larger reservations, educating not only teenagers but also an adult audience. There were no Indian facilities for higher education. They deemphasized textbooks, emphasized self-esteem, and started teaching Indian history. They promoted traditional arts and crafts of the sort that could be conducted on the reservations, such as making jewelry. The New Deal reformers met significant resistance from parents and teachers, and had mixed results. World War II brought younger Indians in contact with the broader society through military service and work in the munitions industries. The role of schooling was changed to focus on vocational education for jobs in urban America.

Since the rise of self-determination for Native Americans, they have generally emphasized education of their children at schools near where they live. In addition, many federally recognized tribes have taken over operations of such schools and added programs of language retention and revival to strengthen their cultures. Beginning in the 1970s, tribes have also founded colleges at their reservations, controlled, and operated by Native Americans, to educate their young for jobs as well as to pass on their cultures.

On August 29, 1911, Ishi, generally considered to have been the last Native American to live most of his life without contact with European-American culture, was discovered near Oroville, California.

In 1919, the United States under President Woodrow Wilson granted citizenship to all Native Americans who had served in World War I. Nearly 10,000 men had enlisted and served, a high number in relation to their population. Despite this, in many areas Native Americans faced local resistance when they tried to vote and were discriminated against with barriers to voter registration.

On June 2, 1924, U.S. President Calvin Coolidge signed the Indian Citizenship Act, which made all Native Americans born in the United States and its territories American citizens. Prior to passage of the act, nearly two-thirds of Native Americans were already U.S. citizens, through marriage, military service or accepting land allotments. The Act extended citizenship to "all non-citizen Indians born within the territorial limits of the United States".

Charles Curtis, a Congressman and longtime US Senator from Kansas, was of Kaw, Osage, Potawatomi, and European ancestry. After serving as a United States Representative and being repeatedly re-elected as United States Senator from Kansas, Curtis served as Senate Minority Whip for 10 years and as Senate Majority Leader for five years. He was very influential in the Senate. In 1928 he ran as the vice-presidential candidate with Herbert Hoover for president, and served from 1929 to 1933. He was the first person with significant Native American ancestry and the first person with acknowledged non-European ancestry to be elected to either of the highest offices in the land.

American Indians today in the United States have all the rights guaranteed in the U.S. Constitution, can vote in elections, and run for political office. Controversies remain over how much the federal government has jurisdiction over tribal affairs, sovereignty, and cultural practices.

Mid-century, the Indian termination policy and the Indian Relocation Act of 1956 marked a new direction for assimilating Native Americans into urban life.

The census counted 332,000 Indians in 1930 and 334,000 in 1940, including those on and off reservations in the 48 states. Total spending on Indians averaged $38 million a year in the late 1920s, dropping to a low of $23 million in 1933, and returning to $38 million in 1940.

Some 44,000 Native Americans served in the United States military during World War II: at the time, one-third of all able-bodied Indian men from eighteen to fifty years of age. Described as the first large-scale exodus of indigenous peoples from the reservations since the removals of the 19th century, the men's service with the U.S. military in the international conflict was a turning point in Native American history. The overwhelming majority of Native Americans welcomed the opportunity to serve; they had a voluntary enlistment rate that was 40% higher than those drafted.

Their fellow soldiers often held them in high esteem, in part since the legend of the tough Native American warrior had become a part of the fabric of American historical legend. White servicemen sometimes showed a lighthearted respect toward Native American comrades by calling them "chief". The resulting increase in contact with the world outside of the reservation system brought profound changes to Native American culture. "The war", said the U.S. Indian Commissioner in 1945, "caused the greatest disruption of Native life since the beginning of the reservation era", affecting the habits, views, and economic well-being of tribal members. The most significant of these changes was the opportunity—as a result of wartime labor shortages—to find well-paying work in cities, and many people relocated to urban areas, particularly on the West Coast with the buildup of the defense industry.

There were also losses as a result of the war. For instance, a total of 1,200 Pueblo men served in World War II; only about half came home alive. In addition, many more Navajo served as code talkers for the military in the Pacific. The code they made, although cryptologically very simple, was never cracked by the Japanese.

Military service and urban residency contributed to the rise of American Indian activism, particularly after the 1960s and the occupation of Alcatraz Island (1969–1971) by a student Indian group from San Francisco. In the same period, the American Indian Movement (AIM) was founded in Minneapolis, and chapters were established throughout the country, where American Indians combined spiritual and political activism. Political protests gained national media attention and the sympathy of the American public.

Through the mid-1970s, conflicts between governments and Native Americans occasionally erupted into violence. A notable late 20th-century event was the Wounded Knee incident on the Pine Ridge Indian Reservation. Upset with tribal government and the failures of the federal government to enforce treaty rights, about 300 Oglala Lakota and AIM activists took control of Wounded Knee on February 27, 1973.

Indian activists from around the country joined them at Pine Ridge, and the occupation became a symbol of rising American Indian identity and power. Federal law enforcement officials and the national guard cordoned off the town, and the two sides had a standoff for 71 days. During much gunfire, one United States Marshal was wounded and paralyzed. In late April, a Cherokee and local Lakota man were killed by gunfire; the Lakota elders ended the occupation to ensure no more lives were lost.

In June 1975, two FBI agents seeking to make an armed robbery arrest at Pine Ridge Reservation were wounded in a firefight, and killed at close range. The AIM activist Leonard Peltier was sentenced in 1976 to two consecutive terms of life in prison in the FBI deaths.

In 1968, the government enacted the Indian Civil Rights Act. This gave tribal members most of the protections against abuses by tribal governments that the Bill of Rights accords to all U.S. citizens with respect to the federal government. In 1975, the U.S. government passed the Indian Self-Determination and Education Assistance Act, marking the culmination of fifteen years of policy changes. It resulted from American Indian activism, the Civil Rights Movement, and community development aspects of President Lyndon Johnson's social programs of the 1960s. The Act recognized the right and need of Native Americans for self-determination. It marked the U.S. government's turn away from the 1950s policy of termination of the relationship between tribes and the government. The U.S. government encouraged Native Americans' efforts at self-government and determining their futures. Tribes have developed organizations to administer their own social, welfare and housing programs, for instance. Tribal self-determination has created tension with respect to the federal government's historic trust obligation to care for Indians; however, the Bureau of Indian Affairs has never lived up to that responsibility.

Navajo Community College, now called Diné College, the first tribal college, was founded in Tsaile, Arizona, in 1968 and accredited in 1979. Tensions immediately arose between two philosophies: one that the tribal colleges should have the same criteria, curriculum and procedures for educational quality as mainstream colleges, the other that the faculty and curriculum should be closely adapted to the particular historical culture of the tribe. There was a great deal of turnover, exacerbated by very tight budgets. In 1994, the U.S. Congress passed legislation recognizing the tribal colleges as land-grant colleges, which provided opportunities for large-scale funding. Thirty-two tribal colleges in the United States belong to the American Indian Higher Education Consortium. By the early 21st century, tribal nations had also established numerous language revival programs in their schools.

In addition, Native American activism has led major universities across the country to establish Native American studies programs and departments, increasing awareness of the strengths of Indian cultures, providing opportunities for academics, and deepening research on history and cultures in the United States. Native Americans have entered academia; journalism and media; politics at local, state and federal levels; and public service, for instance, influencing medical research and policy to identify issues related to American Indians.

In 2009, an "apology to Native Peoples of the United States" was included in the Defense Appropriations Act. It stated that the U.S. "apologizes on behalf of the people of the United States to all Native Peoples for the many instances of violence, maltreatment, and neglect inflicted on Native Peoples by citizens of the United States".

In 2013, jurisdiction over persons who were not tribal members under the Violence Against Women Act was extended to Indian Country. This closed a gap which prevented arrest or prosecution by tribal police or courts of abusive partners of tribal members who were not native or from another tribe.

Migration to urban areas continued to grow with 70% of Native Americans living in urban areas in 2012, up from 45% in 1970 and 8% in 1940. Urban areas with significant Native American populations include Minneapolis, Denver, Albuquerque, Phoenix, Tucson, Chicago, Oklahoma City, Houston, New York City, Los Angeles, and Rapid City. Many lived in poverty. Racism, unemployment, drugs and gangs were common problems which Indian social service organizations such as the Little Earth housing complex in Minneapolis attempted to address. Grassroots efforts to support urban Indigenous populations have also taken place, as in the case of Bringing the Circle Together in Los Angeles.

The 2010 Census showed that the U.S. population on April 1, 2010, was 308.7 million. Out of the total U.S. population, 2.9 million people, or 0.9 percent, reported American Indian or Alaska Native alone. In addition, 2.3 million people, or another 0.7 percent, reported American Indian or Alaska Native in combination with one or more other races. Together, these two groups totaled 5.2 million people. Thus, 1.7 percent of all people in the United States identified as American Indian or Alaska Native, either alone or in combination with one or more other races.

The definition of American Indian or Alaska Native used in the 2010 census:

According to Office of Management and Budget, "American Indian or Alaska Native" refers to a person having origins in any of the original peoples of North and South America (including Central America) and who maintains tribal affiliation or community attachment.

The 2010 census permitted respondents to self-identify as being of one or more races. Self-identification dates from the census of 1960; prior to that the race of the respondent was determined by opinion of the census taker. The option to select more than one race was introduced in 2000. If American Indian or Alaska Native was selected, the form requested the individual provide the name of the "enrolled or principal tribe".

The census counted 248,000 Native Americans in 1890, 332,000 in 1930 and 334,000 in 1940, including those on and off reservations in the 48 states. Total spending on Native Americans averaged $38 million a year in the late 1920s, dropping to a low of $23 million in 1933, and returning to $38 million in 1940.
78% of Native Americans live outside a reservation. Full-blood individuals are more likely to live on a reservation than mixed-blood individuals. The Navajo, with 286,000 full-blood individuals, is the largest tribe if only full-blood individuals are counted; the Navajo are the tribe with the highest proportion of full-blood individuals, 86.3%. The Cherokee have a different history; it is the largest tribe with 819,000 individuals, and it has 284,000 full-blood individuals.

As of 2012, 70% of Native Americans live in urban areas, up from 45% in 1970 and 8% in 1940. Urban areas with significant Native American populations include Minneapolis, Denver, Phoenix, Tucson, Chicago, Oklahoma City, Houston, New York City, and Los Angeles. Many live in poverty. Racism, unemployment, drugs and gangs are common problems which Indian social service organizations such as the Little Earth housing complex in Minneapolis attempt to address.

According to 2003 United States Census Bureau estimates, a little over one third of the 2,786,652 Native Americans in the United States live in three states: California (413,382), Arizona (294,137) and Oklahoma (279,559).

In 2010, the U.S. Census Bureau estimated that about 0.8% of the U.S. population was of American Indian or Alaska Native descent. This population is unevenly distributed across the country. Below, all fifty states, as well as the District of Columbia and Puerto Rico, are listed by the proportion of residents citing American Indian or Alaska Native ancestry, based on the 2010 U.S. Census.
In 2006, the U.S. Census Bureau estimated that about less than 1.0% of the U.S. population was of Native Hawaiian or Pacific Islander descent. This population is unevenly distributed across twenty-six states. Below, are the twenty-six states that had at least 0.1%. They are listed by the proportion of residents citing Native Hawaiian or Pacific Islander ancestry, based on 2006 estimates:

Below are numbers for U.S. citizens self-identifying to selected tribal grouping, according to the 2000 U.S. census.

There are 573 federally recognized tribal governments in the United States. These tribes possess the right to form their own governments, to enforce laws (both civil and criminal) within their lands, to tax, to establish requirements for membership, to license and regulate activities, to zone, and to exclude persons from tribal territories. Limitations on tribal powers of self-government include the same limitations applicable to states; for example, neither tribes nor states have the power to make war, engage in foreign relations, or coin money (this includes paper currency).

Many Native Americans and advocates of Native American rights point out that the U.S. federal government's claim to recognize the "sovereignty" of Native American peoples falls short, given that the United States wishes to govern Native American peoples and treat them as subject to U.S. law. Such advocates contend that full respect for Native American sovereignty would require the U.S. government to deal with Native American peoples in the same manner as any other sovereign nation, handling matters related to relations with Native Americans through the Secretary of State, rather than the Bureau of Indian Affairs. The Bureau of Indian Affairs reports on its website that its "responsibility is the administration and management of of land held in trust by the United States for American Indians, Indian tribes, and Alaska Natives". Many Native Americans and advocates of Native American rights believe that it is condescending for such lands to be considered "held in trust" and regulated in any fashion by other than their own tribes, whether the U.S. or Canadian governments, or any other non-Native American authority.

As of 2000, the largest groups in the United States by population were Navajo, Cherokee, Choctaw, Sioux, Chippewa, Apache, Blackfeet, Iroquois, and Pueblo. In 2000, eight of ten Americans with Native American ancestry were of mixed ancestry. It is estimated that by 2100 that figure will rise to nine out of ten.

In addition, there are a number of tribes that are recognized by individual states, but not by the federal government. The rights and benefits associated with state recognition vary from state to state.

Some tribal groups have been unable to document the cultural continuity required for federal recognition. The Muwekma Ohlone of the San Francisco bay area are pursuing litigation in the federal court system to establish recognition. Many of the smaller eastern tribes, long considered remnants of extinct peoples, have been trying to gain official recognition of their tribal status. Several tribes in Virginia and North Carolina have gained state recognition. Federal recognition confers some benefits, including the right to label arts and crafts as Native American and permission to apply for grants that are specifically reserved for Native Americans. But gaining federal recognition as a tribe is extremely difficult; to be established as a tribal group, members have to submit extensive genealogical proof of tribal descent and continuity of the tribe as a culture.
In July 2000, the Washington State Republican Party adopted a resolution recommending that the federal and legislative branches of the U.S. government terminate tribal governments. In 2007, a group of Democratic Party congressmen and congresswomen introduced a bill in the U.S. House of Representatives to "terminate" the Cherokee Nation. This was related to their voting to exclude Cherokee Freedmen as members of the tribe unless they had a Cherokee ancestor on the Dawes Rolls, although all Cherokee Freedmen and their descendants had been members since 1866.

As of 2004, various Native Americans are wary of attempts by others to gain control of their reservation lands for natural resources, such as coal and uranium in the West.

In the state of Virginia, Native Americans face a unique problem. Until 2017 Virginia previously had no federally recognized tribes but the state had recognized eight. This is related historically to the greater impact of disease and warfare on the Virginia Indian populations, as well as their intermarriage with Europeans and Africans. Some people confused the ancestry with culture, but groups of Virginia Indians maintained their cultural continuity. Most of their early reservations were ended under the pressure of early European settlement.

Some historians also note the problems of Virginia Indians in establishing documented continuity of identity, due to the work of Walter Ashby Plecker (1912–1946). As registrar of the state's Bureau of Vital Statistics, he applied his own interpretation of the one-drop rule, enacted in law in 1924 as the state's Racial Integrity Act. It recognized only two races: "white" and "colored".

Plecker, a segregationist, believed that the state's Native Americans had been "mongrelized" by intermarriage with African Americans; to him, ancestry determined identity, rather than culture. He thought that some people of partial black ancestry were trying to "pass" as Native Americans. Plecker thought that anyone with any African heritage had to be classified as colored, regardless of appearance, amount of European or Native American ancestry, and cultural/community identification. Plecker pressured local governments into reclassifying all Native Americans in the state as "colored", and gave them lists of family surnames to examine for reclassification based on his interpretation of data and the law. This led to the state's destruction of accurate records related to families and communities who identified as Native American (as in church records and daily life). By his actions, sometimes different members of the same family were split by being classified as "white" or "colored". He did not allow people to enter their primary identification as Native American in state records. In 2009, the Senate Indian Affairs Committee endorsed a bill that would grant federal recognition to tribes in Virginia.

To achieve federal recognition and its benefits, tribes must prove continuous existence since 1900. The federal government has maintained this requirement, in part because through participation on councils and committees, federally recognized tribes have been adamant about groups' satisfying the same requirements as they did.

The Civil Rights Movement was a very significant moment for the rights of Native Americans and other people of color. Native Americans faced racism and prejudice for hundreds of years, and this increased after the American Civil War. Native Americans like African Americans were subjected to the Jim Crow Laws and segregation in the Deep South especially after they were made citizens through the Indian Citizenship Act of 1924. As a body of law, Jim Crow institutionalized economic, educational, and social disadvantages for Native Americans, and other people of color living in the south. Native American identity was especially targeted by a system that only wanted to recognize white or colored, and the government began to question the legitimacy of some tribes because they had intermarried with African Americans. Native Americans were also discriminated and discouraged from voting in the southern and western states.

In the south segregation was a major problem for Native Americans seeking education, but the NAACP's legal strategy would later change this. Movements such as Brown v. Board of Education was a major victory for the Civil Rights Movement headed by the NAACP, and inspired Native Americans to start participating in the Civil Rights Movement. Dr. Martin Luther King Jr. began assisting Native Americans in the south in the late 1950s after they reached out to him. At that time the remaining Creek in Alabama were trying to completely desegregate schools in their area. In this case, light-complexioned Native children were allowed to ride school buses to previously all white schools, while dark-skinned Native children from the same band were barred from riding the same buses. Tribal leaders, upon hearing of King's desegregation campaign in Birmingham, Alabama, contacted him for assistance. He promptly responded and through his intervention the problem was quickly resolved. Dr. King would later make trips to Arizona visiting Native Americans on reservations, and in churches encouraging them to be involved in the Civil Rights Movement. In King's book "Why We Can't Wait" he writes:
Our nation was born in genocide when it embraced the doctrine that the original American, the Indian, was an inferior race. Even before there were large numbers of Negroes on our shores, the scar of racial hatred had already disfigured colonial society. From the sixteenth century forward, blood flowed in battles over racial supremacy. We are perhaps the only nation which tried as a matter of national policy to wipe out its indigenous population. Moreover, we elevated that tragic experience into a noble crusade. Indeed, even today we have not permitted ourselves to reject or to feel remorse for this shameful episode. Our literature, our films, our drama, our folklore all exalt it.

Native Americans would then actively participate and support the NAACP, and the Civil Rights Movement. The National Indian Youth Council (NIYC) would soon rise in 1961 to fight for Native American rights during the Civil Rights Movement, and were strong supporters of Dr. Martin Luther King Jr.. During the 1963 March on Washington there was a sizable Native American contingent, including many from South Dakota, and many from the Navajo nation. Native Americans also participated the Poor People's Campaign in 1968. The NIYC were very active supporters of the Poor People's Campaign unlike the National Congress of American Indians (NCAI); the NIYC and other Native organizations met with King in March 1968 but the NCAI disagreed on how to approach the anti-poverty campaign; the NCAI decided against participating in the march. The NCAI wished to pursue their battles in the courts and with Congress, unlike the NIYC. The NAACP also inspired the creation of the Native American Rights Fund (NARF) which was patterned after the NAACP's Legal Defense and Education Fund. Furthermore, the NAACP continued to organize to stop mass incarceration and end the criminalization of Native Americans and other communities of people of color. The following is an excerpt from a statement from Mel Thom on May 1, 1968, during a meeting with Secretary of State Dean Rusk: (It was written by members of the Workshop on American Indian Affairs and the NIYC)

Native American struggles amid poverty to maintain life on the reservation or in larger society have resulted in a variety of health issues, some related to nutrition and health practices. The community suffers a vulnerability to and disproportionately high rate of alcoholism.

Recent studies also point to rising rates of stroke, heart disease, and diabetes in the Native American population.

In a study conducted in 2006–2007, non-Native Americans admitted they rarely encountered Native Americans in their daily lives. While sympathetic toward Native Americans and expressing regret over the past, most people had only a vague understanding of the problems facing Native Americans today. For their part, Native Americans told researchers that they believed they continued to face prejudice, mistreatment, and inequality in the broader society.

Federal contractors and subcontractors, such as businesses and educational institutions, are legally required to adopt equal opportunity employment and affirmative action measures intended to prevent discrimination against employees or applicants for employment on the basis of "color, religion, sex, or national origin". For this purpose, a Native American is defined as "A person having origins in any of the original peoples of North and South America (including Central America), and who maintains a tribal affiliation or community attachment". The passing of the Indian Relocation Act saw a 56% increase in Native American city dwellers over 40 years. The Native American urban poverty rate exceeds that of reservation poverty rates due to discrimination in hiring processes. However, self-reporting is permitted: "Educational institutions and other recipients should allow students and staff to self-identify their race and ethnicity unless self-identification is not practicable or feasible."

Self-reporting opens the door to "box checking" by people who, despite not having a substantial relationship to Native American culture, innocently or fraudulently check the box for Native American.

The difficulties that Native Americans face in the workforce, for example, a lack of promotions and wrongful terminations are attributed to racial stereotypes and implicit biases. Native American business owners are seldom offered auxiliary resources that are crucial for entrepreneurial success.

American Indian activists in the United States and Canada have criticized the use of Native American mascots in sports, as perpetuating stereotypes. This is considered cultural appropriation.
There has been a steady decline in the number of secondary school and college teams using such names, images, and mascots. Some tribal team names have been approved by the tribe in question, such as the Seminole Tribe of Florida's approving use of their name for the teams of Florida State University.

Among professional teams, only the NBA's Golden State Warriors discontinued use of Native American-themed logos in 1971. Controversy has remained regarding teams such as the NFL's Washington Redskins, whose name is considered to be a racial slur, and MLB's Cleveland Indians, whose usage of a caricature called Chief Wahoo has also faced protest.

Native Americans have been depicted by American artists in various ways at different periods. A number of 19th- and 20th-century United States and Canadian painters, often motivated by a desire to document and preserve Native culture, specialized in Native American subjects. Among the most prominent of these were Elbridge Ayer Burbank, George Catlin, Seth Eastman, Paul Kane, W. Langdon Kihn, Charles Bird King, Joseph Henry Sharp, and John Mix Stanley.

In the 20th century, early portrayals of Native Americans in movies and television roles were first performed by European Americans dressed in mock traditional attire. Examples included "The Last of the Mohicans" (1920), "Hawkeye and the Last of the Mohicans" (1957), and "F Troop" (1965–67). In later decades, Native American actors such as Jay Silverheels in "The Lone Ranger" television series (1949–57) came to prominence. Roles of Native Americans were limited and not reflective of Native American culture. By the 1970s some Native American film roles began to show more complexity, such as those in "Little Big Man" (1970), "Billy Jack" (1971), and "The Outlaw Josey Wales" (1976), which depicted Native Americans in minor supporting roles.

For years, Native people on U.S. television were relegated to secondary, subordinate roles. During the years of the series "Bonanza" (1959–1973), no major or secondary Native characters appeared on a consistent basis. The series "The Lone Ranger" (1949–1957), "Cheyenne" (1955–1963), and "Law of the Plainsman" (1959–1963) had Native characters who were essentially aides to the central white characters. This continued in such series as "How the West Was Won". These programs resembled the "sympathetic" yet contradictory film "Dances With Wolves" of 1990, in which, according to Ella Shohat and Robert Stam, the narrative choice was to relate the Lakota story as told through a Euro-American voice, for wider impact among a general audience.
Like the 1992 remake of "The Last of the Mohicans" and "" (1993), "Dances with Wolves" employed a number of Native American actors, and made an effort to portray Indigenous languages.

In 2009 "We Shall Remain" (2009), a television documentary by Ric Burns and part of the "American Experience" series, presented a five-episode series "from a Native American perspective". It represented "an unprecedented collaboration between Native and non-Native filmmakers and involves Native advisors and scholars at all levels of the project". The five episodes explore the impact of King Philip's War on the northeastern tribes, the "Native American confederacy" of Tecumseh's War, the U.S.-forced relocation of Southeastern tribes known as the Trail of Tears, the pursuit and capture of Geronimo and the Apache Wars, and concludes with the Wounded Knee incident, participation by the American Indian Movement, and the increasing resurgence of modern Native cultures since.

Native Americans are often known as Indians or American Indians. The term "Native American" was introduced in the United States in preference to the older term "Indian" to distinguish the indigenous peoples of the Americas from the people of India and to avoid negative stereotypes associated with the term "Indian". In 1995, a plurality of indigenous Americans, however, preferred the term "American Indian" and many tribes include the word Indian in their formal title.

Criticism of the neologism "Native American" comes from diverse sources. Russell Means, an American Indian activist, opposed the term "Native American" because he believed it was imposed by the government without the consent of American Indians. He has also argued that the use of the word "Indian" derives not from a confusion with India but from a Spanish expression "en Dios" meaning "in God" (and a near-homophone of the Spanish word for "Indians", "indios").

A 1995 U.S. Census Bureau survey found that more Native Americans in the United States preferred "American Indian" to "Native American". Most American Indians are comfortable with "Indian", "American Indian", and "Native American", and the terms are often used interchangeably. The traditional term is reflected in the name chosen for the National Museum of the American Indian, which opened in 2004 on the Mall in Washington, D.C.

Gambling has become a leading industry. Casinos operated by many Native American governments in the United States are creating a stream of gambling revenue that some communities are beginning to leverage to build diversified economies. Although many Native American tribes have casinos, the impact of Native American gaming is widely debated. Some tribes, such as the Winnemem Wintu of Redding, California, feel that casinos and their proceeds destroy culture from the inside out. These tribes refuse to participate in the gambling industry.

Numerous tribes around the country have entered the financial services market including the Otoe-Missouria, Tunica-Biloxi, and the Rosebud Sioux. Because of the challenges involved in starting a financial services business from scratch, many tribes hire outside consultants and vendors to help them launch these businesses and manage the regulatory issues involved.
Similar to the tribal sovereignty debates that occurred when tribes first entered the gaming industry, the tribes, states, and federal government are currently in disagreement regarding who possesses the authority to regulate these e-commerce business entities.

Prosecution of serious crime, historically endemic on reservations, was required by the 1885 Major Crimes Act, 18 U.S.C. §§1153, 3242, and court decisions to be investigated by the federal government, usually the Federal Bureau of Investigation, and prosecuted by United States Attorneys of the United States federal judicial district in which the reservation lies.

A December 13, 2009 "New York Times" article about growing gang violence on the Pine Ridge Indian Reservation estimated that there were 39 gangs with 5,000 members on that reservation alone. Navajo country recently reported 225 gangs in its territory.

As of 2012, a high incidence of rape continued to impact Native American women and Alaskan native women. According to the Department of Justice, 1 in 3 Native women have suffered rape or attempted rape, more than twice the national rate. About 46 percent of Native American women have been raped, beaten, or stalked by an intimate partner, according to a 2010 study by the Centers for Disease Control. According to Professor N. Bruce Duthu, "More than 80 percent of Indian victims identify their attacker as non-Indian".

Today, other than tribes successfully running casinos, many tribes struggle, as they are often located on reservations isolated from the main economic centers of the country. The estimated 2.1 million Native Americans are the most impoverished of all ethnic groups. According to the 2000 Census, an estimated 400,000 Native Americans reside on reservation land. While some tribes have had success with gaming, only 40% of the 562 federally recognized tribes operate casinos. According to a 2007 survey by the U.S. Small Business Administration, only 1% of Native Americans own and operate a business.

The barriers to economic development on Native American reservations have been identified by Joseph Kalt and Stephen Cornell of the Harvard Project on American Indian Economic Development at Harvard University, in their report: "What Can Tribes Do? Strategies and Institutions in American Indian Economic Development" (2008), are summarized as follows:

A major barrier to development is the lack of entrepreneurial knowledge and experience within Indian reservations. "A general lack of education and experience about business is a significant challenge to prospective entrepreneurs", was the report on Native American entrepreneurship by the Northwest Area Foundation in 2004. "Native American communities that lack entrepreneurial traditions and recent experiences typically do not provide the support that entrepreneurs need to thrive. Consequently, experiential entrepreneurship education needs to be embedded into school curricula and after-school and other community activities. This would allow students to learn the essential elements of entrepreneurship from a young age and encourage them to apply these elements throughout life". "Rez Biz" magazine addresses these issues.

Some scholars argue that the existing theories and practices of economic development are not suitable for Native American communities—given the lifestyle, economic, and cultural differences, as well as the unique history of Native American-U.S. relations. Most economic development research were not conducted on Native American communities. The federal government fails to consider place-based issues of American Indian poverty by generalizing the demographic. In addition, the concepts of economic development threatens to upend the multidimensionality of Native American culture. The dominance of federal government involvement in indigenous developmental activities perpetuates and exacerbates the salvage paradigm.

Native land that is owned by individual Native Americans sometimes cannot be developed because of fractionalization. Fractionalization occurs when a landowner dies, and their land is inherited by their children, but not subdivided. This means that one parcel might be owned by 50 different individuals. A majority of those holding interest must agree to any proposal to develop the land, and establishing this consent is time-consuming, cumbersome, and sometimes impossible.
Another landownership issue on reservations is checkerboarding, where Tribal land is interspersed with land owned by the federal government on behalf of Native's, individually owned plots, and land owned by non-Native individuals. This prevents Tribal governments to secure plots of land large enough for economic development or agricultural uses.
Because reservation land is owned “in trust” by the federal government, individuals living on reservations cannot build equity in their homes. This bars Native Americans from getting a loan, as there is nothing that a bank can collect if the loan is not paid. Past efforts to encourage landownership (such as the Dawes Act) resulted in a net loss of Tribal land. After they were familiarized with their smallholder status, Native American landowners were lifted of trust restrictions and their land would get transferred back to them, contingent of a transactional fee to the federal government. The transfer fee discouraged Native American land ownership, with 65% of tribal owned land being sold to non-Native Americans by the 1920s. Activists against property rights point to historical evidence of communal ownership of land and resources by tribes. They claim that because of this history, property rights are foreign to Natives and have no place in the modern reservation system. Those in favor of property rights cite examples of tribes negotiating with colonial communities or other tribes about fishing and hunting rights in an area. Land ownership was also a challenge because of the different definitions of land that the Natives and the Europeans had. Most Native American tribes thought of property rights more as "borrowing" the land, while those from Europe thought of land as individual property.

State-level efforts such as the Oklahoma Indian Welfare Act were attempts to contain tribal land in Native American hands. However, more bureaucratic decisions only expanded the size of the bureaucracy. The knowledge disconnect between the decision-making bureaucracy and Native American stakeholders resulted in ineffective development efforts.

Traditional Native American entrepreneurship does not prioritize profit maximization, rather, business transactions must have align with their social and cultural values. In response to indigenous business philosophy, the federal government created policies that aimed to formalize their business practices, which undermined the Native American status quo. Additionally, legal disputes interfered with tribal land leasing, which were settled with the verdict against tribal sovereignty.

Often, bureaucratic overseers of development are far removed from Native American communities, and lack the knowledge and understanding to develop plans or make resource allocation decisions. The top-down heavy involvement in developmental operations corrupts bureaucrats into further self-serving agenda. Such incidences include fabricated reports that exaggerate results.

While Native American urban poverty is attributed to hiring and workplace discrimination in a heterogeneous setting, reservation and trust land poverty rates are endogenous to deserted opportunities in isolated regions.

Historical trauma is described as collective emotional and psychological damage throughout a person's lifetime and across multiple generations. Examples of historical trauma can be seen through the Wounded Knee Massacre of 1890, where over 200 unarmed Lakota were killed, and the Dawes Allotment Act of 1887, when American Indians lost four-fifths of their land.

American Indian youth have higher rates of substance and alcohol abuse deaths than the general population. Many American Indians can trace the beginning of their substance and alcohol abuse to a traumatic event related to their offender's own substance abuse. A person's substance abuse can be described as a defense mechanism against the user's emotions and trauma. For American Indians alcoholism is a symptom of trauma passed from generation to generation and influenced by oppressive behaviors and policies by the dominant Euro-American society. Boarding schools were made to "Kill the Indian, Save the man". Shame among American Indians can be attributed to the hundreds of years of discrimination.

The culture of Pre-Columbian North America is usually defined by the concept of the culture area, namely a geographical region where shared cultural traits occur. The northwest culture area, for example shared common traits such as salmon fishing, woodworking, and large villages or towns and a hierarchical social structure.

Though cultural features, language, clothing, and customs vary enormously from one tribe to another, there are certain elements which are encountered frequently and shared by many tribes. Early European American scholars described the Native Americans as having a society dominated by clans.

European colonization of the Americas had a major impact on Native American culture through what is known as the Columbian exchange. The Columbian exchange, also known as the Columbian interchange, was the widespread transfer of plants, animals, culture, human populations, technology, and ideas between the Americas and the Old World in the 15th and 16th centuries, following Christopher Columbus's 1492 voyage. The Columbian exchange generally had a destructive impact on Native American culture through disease, and a 'clash of cultures', whereby European values of private property, the family, and labor, led to conflict, appropriation of traditional communal lands and changed how the indigenous tribes practiced slavery.

The impact of the Columbian exchange was not entirely negative however. For example, the re-introduction of the horse to North America allowed the Plains Indian to revolutionize their way of life by making hunting, trading, and warfare far more effective, and to greatly improve their ability to transport possessions and move their settlements.

The Great Plains tribes were still hunting the bison when they first encountered the Europeans. The Spanish reintroduction of the horse to North America in the 17th century and Native Americans' learning to use them greatly altered the Native Americans' culture, including changing the way in which they hunted large game. Horses became such a valuable, central element of Native lives that they were counted as a measure of wealth.

In the early years, as these native peoples encountered European explorers and settlers and engaged in trade, they exchanged food, crafts, and furs for blankets, iron and steel implements, horses, trinkets, firearms, and alcoholic beverages.

The Na-Dené, Algic, and Uto-Aztecan families are the largest in terms of number of languages. Uto-Aztecan has the most speakers (1.95 million) if the languages in Mexico are considered (mostly due to 1.5 million speakers of Nahuatl); Na-Dené comes in second with approximately 200,000 speakers (nearly 180,000 of these are speakers of Navajo), and Algic in third with about 180,000 speakers (mainly Cree and Ojibwe). Na-Dené and Algic have the widest geographic distributions: Algic currently spans from northeastern Canada across much of the continent down to northeastern Mexico (due to later migrations of the Kickapoo) with two outliers in California (Yurok and Wiyot); Na-Dené spans from Alaska and western Canada through Washington, Oregon, and California to the U.S. Southwest and northern Mexico (with one outlier in the Plains). Several families consist of only 2 or 3 languages. Demonstrating genetic relationships has proved difficult due to the great linguistic diversity present in North America. Two large (super-) family proposals, Penutian and Hokan, look particularly promising. However, even after decades of research, a large number of families remain.

A number of English words have been derived from Native American languages.

To counteract a shift to English, some Native American tribes have initiated language immersion schools for children, where a native Indian language is the medium of instruction. For example, the Cherokee Nation initiated a 10-year language preservation plan that involved raising new fluent speakers of the Cherokee language from childhood on up through school immersion programs as well as a collaborative community effort to continue to use the language at home. This plan was part of an ambitious goal that, in 50 years, will result in 80% or more of the Cherokee people being fluent in the language. The Cherokee Preservation Foundation has invested $3 million in opening schools, training teachers, and developing curricula for language education, as well as initiating community gatherings where the language can be actively used. Formed in 2006, the Kituwah Preservation & Education Program (KPEP) on the Qualla Boundary focuses on language immersion programs for children from birth to fifth grade, developing cultural resources for the general public and community language programs to foster the Cherokee language among adults.

There is also a Cherokee language immersion school in Tahlequah, Oklahoma, that educates students from pre-school through eighth grade. Because Oklahoma's official language is English, Cherokee immersion students are hindered when taking state-mandated tests because they have little competence in English. The Department of Education of Oklahoma said that in 2012 state tests: 11% of the school's sixth-graders showed proficiency in math, and 25% showed proficiency in reading; 31% of the seventh-graders showed proficiency in math, and 87% showed proficiency in reading; 50% of the eighth-graders showed proficiency in math, and 78% showed proficiency in reading. The Oklahoma Department of Education listed the charter school as a Targeted Intervention school, meaning the school was identified as a low-performing school but has not so that it was a Priority School. Ultimately, the school made a C, or a 2.33 grade point average on the state's A-F report card system. The report card shows the school getting an F in mathematics achievement and mathematics growth, a C in social studies achievement, a D in reading achievement, and an A in reading growth and student attendance. "The C we made is tremendous," said school principal Holly Davis, "[t]here is no English instruction in our school's younger grades, and we gave them this test in English." She said she had anticipated the low grade because it was the school's first year as a state-funded charter school, and many students had difficulty with English. Eighth graders who graduate from the Tahlequah immersion school are fluent speakers of the language, and they usually go on to attend Sequoyah High School where classes are taught in both English and Cherokee.

Historical diets of Native Americans differed dramatically region to region. Different peoples might have relayed more heavily of agriculture, horticulture, hunting, fishing, or gathering of wild plants and fungi. Tribes developed diets best suited for their environments. 

Iñupiat, Yupiit, Unangan, and fellow Alaska Natives fished, hunted, and harvested wild plants, but did not rely on agriculture. Coastal peoples relied more heavily on sea mammals, fish, and fish eggs, while inland peoples hunted caribou and moose. Alaskan Natives prepared and preserved dried and smoked meat and fish.

Pacific Northwest tribes crafted seafaring dugouts long for fishing.

In the Eastern Woodlands, early peoples independently invented agricultural and by 1800 BCE developed the crops of the Eastern Agricultural Complex, which include squash ("Cucurbita pepo ssp. ovifera"), sunflower ("Helianthus annuus var. macrocarpus"), goosefoot ("Chenopodium berlandieri"), and marsh elder ("Iva annua var. macrocarpa").

The Sonoran desert region including parts of Arizona and California, part of a region known as Aridoamerica, relied heavily on the tepary bean ("Phaseolus acutifolius") as a staple crop. This and other desert crops, mesquite bead pods, "tunas" (prickly pear fruit), cholla buds, saguaro cactus fruit, and acorns are being actively promoted today by Tohono O'odham Community Action. In the Southwest, some communities developed irrigation techniques while others, such as the Hopi dry-farmed. They filled storehouses with grain as protection against the area's frequent droughts.

Maize or corn, first cultivated in what is now Mexico was traded north into Aridoamerica and Oasisamerica, southwest. From there, maize cultivation spread throughout the Great Plains and Eastern Woodlands by 200 CE. Native farmers practiced polycropping maize, beans, and squash; these crops are known as the Three Sisters. The beans would replace the nitrogen, which the maize leached from the ground, as well as using corn stalks for support for climbing. 

The agriculture gender roles of the Native Americans varied from region to region. In the Southwest area, men prepared the soil with hoes. The women were in charge of planting, weeding, and harvesting the crops. In most other regions, the women were in charge of most agriculture, including clearing the land. Clearing the land was an immense chore since the Native Americans rotated fields.

Europeans in the eastern part of the continent observed that Native Americans cleared large areas for cropland. Their fields in New England sometimes covered hundreds of acres. Colonists in Virginia noted thousands of acres under cultivation by Native Americans.
Early farmers commonly used tools such as the hoe, maul, and dibber. The hoe was the main tool used to till the land and prepare it for planting; then it was used for weeding. The first versions were made out of wood and stone. When the settlers brought iron, Native Americans switched to iron hoes and hatchets. The dibber was a digging stick, used to plant the seed. Once the plants were harvested, women prepared the produce for eating. They used the maul to grind the corn into mash. It was cooked and eaten that way or baked as corn bread.

Native Americans religious practice different widely across the country. These spiritualities may accompany adherence to another faith, or can represent a person's primary religious identity. While much Native American spiritualism exists in a tribal-cultural continuum, and as such cannot be easily separated from tribal identity itself.

Cultural religious practices of some tribes include the use of sacred herbs such as tobacco, sweetgrass or sage. Many Plains tribes have sweatlodge ceremonies, though the specifics of the ceremony vary among tribes. Fasting, singing and prayer in the ancient languages of their people, and sometimes drumming are also common.

The Midewiwin Lodge is a medicine society inspired by the oral history and prophesies of the Ojibwa (Chippewa) and related tribes.

Another significant religious body among Native peoples is known as the Native American Church. It is a syncretistic church incorporating elements of Native spiritual practice from a number of different tribes as well as symbolic elements from Christianity. Its main rite is the peyote ceremony. Prior to 1890, traditional religious beliefs included Wakan Tanka. In the American Southwest, especially New Mexico, a syncretism between the Catholicism brought by Spanish missionaries and the native religion is common; the religious drums, chants, and dances of the Pueblo people are regularly part of Masses at Santa Fe's Saint Francis Cathedral. Native American-Catholic syncretism is also found elsewhere in the United States. (e.g., the National Kateri Tekakwitha Shrine in Fonda, New York, and the National Shrine of the North American Martyrs in Auriesville, New York).

The eagle feather law (Title 50 Part 22 of the Code of Federal Regulations) stipulates that only individuals of certifiable Native American ancestry enrolled in a federally recognized tribe are legally authorized to obtain eagle feathers for religious or spiritual use. The law does not allow Native Americans to give eagle feathers to non-Native Americans.

Gender roles are differentiated in many Native American tribes. Many Natives have historically defied colonial expectations of sexuality and gender, and continue to do so in contemporary life.

Whether a particular tribe is predominantly matrilineal or patrilineal, often both sexes have some degree of decision-making power within the tribe. Many Nations, such as the Haudenosaunee Five Nations and the Southeast Muskogean tribes, have matrilineal or Clan Mother systems, in which property and hereditary leadership are controlled by and passed through the maternal lines. In these Nations, the children are considered to belong to the mother's clan. In Cherokee culture, women own the family property. When traditional young women marry, their husbands may join them in their mother's household.

Matrilineal structures enable young women to have assistance in childbirth and rearing, and protect them in case of conflicts between the couple. If a couple separates or the man dies, the woman has her family to assist her. In matrilineal cultures the mother's brothers are usually the leading male figures in her children's lives; fathers have no standing in their wife and children's clan, as they still belong to their own mother's clan. Hereditary clan chief positions pass through the mother's line and chiefs have historically been selected on recommendation of women elders, who could also disapprove of a chief.

In the patrilineal tribes, such as the Omaha, Osage, Ponca, and Lakota, hereditary leadership passes through the male line, and children are considered to belong to the father and his clan. In patrilineal tribes, if a woman marries a non-Native, she is no longer considered part of the tribe, and her children are considered to share the ethnicity and culture of their father.

In patriarchal tribes, gender roles tend to be rigid. Men have historically hunted, traded and made war while, as life-givers, women have primary responsibility for the survival and welfare of the families (and future of the tribe). Women usually gather and cultivate plants, use plants and herbs to treat illnesses, care for the young and the elderly, make all the clothing and instruments, and process and cure meat and skins from the game. Some mothers use cradleboards to carry an infant while working or traveling. In matriarchal and egalitarian nations, the gender roles are usually not so clear-cut, and are even less so in the modern era.

At least several dozen tribes allowed polygyny to sisters, with procedural and economic limits.

Lakota, Dakota, and Nakota girls are encouraged to learn to ride, hunt and fight. Though fighting in war has mostly been left to the boys and men, occasionally women have fought as well – both in battles and in defense of the home – especially if the tribe was severely threatened.

Native American leisure time led to competitive individual and team sports. Jim Thorpe, Joe Hipp, Notah Begay III, Chris Wondolowski, Jacoby Ellsbury, Joba Chamberlain, Kyle Lohse, Sam Bradford, Jack Brisco, Tommy Morrison, Billy Mills, Angel Goodrich, Shoni Schimmel, and Kyrie Irving are well known professional athletes.
Native American ball sports, sometimes referred to as lacrosse, stickball, or baggataway, were often used to settle disputes, rather than going to war, as a civil way to settle potential conflict. The Choctaw called it "isitoboli" ("Little Brother of War"); the Onondaga name was "dehuntshigwa'es" ("men hit a rounded object"). There are three basic versions, classified as Great Lakes, Iroquoian, and Southern.

The game is played with one or two rackets or sticks and one ball. The object of the game is to land the ball in the opposing team's goal (either a single post or net) to score and to prevent the opposing team from scoring on your goal. The game involves as few as 20 or as many as 300 players with no height or weight restrictions and no protective gear. The goals could be from around apart to about ; in lacrosse the field is .

Chunkey was a game that consisted of a stone-shaped disk that was about 1–2 inches in diameter. The disk was thrown down a corridor so that it could roll past the players at great speed. The disk would roll down the corridor, and players would throw wooden shafts at the moving disk. The object of the game was to strike the disk or prevent your opponents from hitting it.
Jim Thorpe, a Sauk and Fox Native American, was an all-round athlete playing football and baseball in the early 20th century. Future President Dwight Eisenhower injured his knee while trying to tackle the young Thorpe. In a 1961 speech, Eisenhower recalled Thorpe: "Here and there, there are some people who are supremely endowed. My memory goes back to Jim Thorpe. He never practiced in his life, and he could do anything better than any other football player I ever saw."

In the 1912 Olympics, Thorpe could run the 100-yard dash in 10 seconds flat, the 220 in 21.8 seconds, the 440 in 51.8 seconds, the 880 in 1:57, the mile in 4:35, the 120-yard high hurdles in 15 seconds, and the 220-yard low hurdles in 24 seconds. He could long jump 23 ft 6 in and high-jump 6 ft 5 in. He could pole vault , put the shot , throw the javelin , and throw the discus . Thorpe entered the U.S. Olympic trials for the pentathlon and the decathlon.

Louis Tewanima, Hopi people, was an American two-time Olympic distance runner and silver medalist in the 10,000 meter run in 1912. He ran for the Carlisle Indian School where he was a teammate of Jim Thorpe. His silver medal in 1912 remained the best U.S. achievement in this event until another Indian, Billy Mills, won the gold medal in 1964. Tewanima also competed at the 1908 Olympics, where he finished in ninth place in the marathon.[1]

Ellison Brown, of the Narragansett people from Rhode Island, better known as "Tarzan" Brown, won two Boston Marathons (1936, 1939) and competed on the United States Olympic team in the 1936 Olympic Games in Berlin, Germany, but did not finish due to injury. He qualified for the 1940 Olympic Games in Helsinki, Finland, but the games were canceled due to the outbreak of World War II.

Billy Mills, a Lakota and USMC officer, won the gold medal in the 10,000 meter run at the 1964 Tokyo Olympics. He was the only American ever to win the Olympic gold in this event. An unknown before the Olympics, Mills finished second in the U.S. Olympic trials.

Billy Kidd, part Abenaki from Vermont, became the first American male to medal in alpine skiing in the Olympics, taking silver at age 20 in the slalom in the 1964 Winter Olympics at Innsbruck, Austria. Six years later at the 1970 World Championships, Kidd won the gold medal in the combined event and took the bronze medal in the slalom.

Ashton Locklear (Lumbee), an uneven bars specialist was an alternate for the 2016 Summer Olympics U.S. gymnastics team, the Final Five. In 2016, Kyrie Irving (Sioux) also helped Team USA win the gold medal at the 2016 Summer Olympics. With the win, he became just the fourth member of Team USA to capture the NBA championship and an Olympic gold medal in the same year, joining LeBron James, Michael Jordan, and Scottie Pippen.

Traditional Native American music is almost entirely monophonic, but there are notable exceptions. Native American music often includes drumming or the playing of rattles or other percussion instruments but little other instrumentation. Flutes and whistles made of wood, cane, or bone are also played, generally by individuals, but in former times also by large ensembles (as noted by Spanish conquistador de Soto). The tuning of modern flutes is typically pentatonic.

Performers with Native American parentage have occasionally appeared in American popular music such as Rita Coolidge, Wayne Newton, Gene Clark, Buffy Sainte-Marie, Blackfoot, Tori Amos, Redbone (members are also of Mexican descent), and CocoRosie. Some, such as John Trudell, have used music to comment on life in Native America. Other musicians such as R. Carlos Nakai, Joanne Shenandoah and Robert "Tree" Cody integrate traditional sounds with modern sounds in instrumental recordings, whereas the music by artist Charles Littleleaf is derived from ancestral heritage as well as nature. A variety of small and medium-sized recording companies offer an abundance of recent music by Native American performers young and old, ranging from pow-wow drum music to hard-driving rock-and-roll and rap. In the International world of ballet dancing Maria Tallchief was considered America's first major prima ballerina, and was the first person of Native American descent to hold the rank. along with her sister Marjorie Tallchief both became star ballerinas.

The most widely practiced public musical form among Native Americans in the United States is that of the pow-wow. At pow-wows, such as the annual Gathering of Nations in Albuquerque, New Mexico, members of drum groups sit in a circle around a large drum. Drum groups play in unison while they sing in a native language and dancers in colorful regalia dance clockwise around the drum groups in the center. Familiar pow-wow songs include honor songs, intertribal songs, crow-hops, sneak-up songs, grass-dances, two-steps, welcome songs, going-home songs, and war songs. Most indigenous communities in the United States also maintain traditional songs and ceremonies, some of which are shared and practiced exclusively within the community.

The Iroquois, living around the Great Lakes and extending east and north, used strings or belts called "wampum" that served a dual function: the knots and beaded designs mnemonically chronicled tribal stories and legends, and further served as a medium of exchange and a unit of measure. The keepers of the articles were seen as tribal dignitaries.

Pueblo peoples crafted impressive items associated with their religious ceremonies. "Kachina" dancers wore elaborately painted and decorated masks as they ritually impersonated various ancestral spirits.
Pueblo people are particularly noted for their traditional high-quality pottery, often with geometric designs and floral, animal and bird motifs. Sculpture was not highly developed, but carved stone and wood fetishes were made for religious use. Superior weaving, embroidered decorations, and rich dyes characterized the textile arts. Both turquoise and shell jewelry were created, as were formalized pictorial arts.

Navajo spirituality focused on the maintenance of a harmonious relationship with the spirit world, often achieved by ceremonial acts, usually incorporating sandpainting. For the Navajo the sand painting is not merely a representational object, but a dynamic spiritual entity with a life of its own, which helped the patient at the centre of the ceremony re-establish a connection with the life force. These vivid, intricate, and colorful sand creations were erased at the end of the healing ceremony.

The Native American arts and crafts industry brings in more than a billion in gross sales annually.

Native American art comprises a major category in the world art collection. Native American contributions include pottery, paintings, jewellery, weavings, sculpture, basketry, and carvings. Franklin Gritts was a Cherokee artist who taught students from many tribes at Haskell Institute (now Haskell Indian Nations University) in the 1940s, the "Golden Age" of Native American painters. The integrity of certain Native American artworks is protected by the Indian Arts and Crafts Act of 1990, that prohibits representation of art as Native American when it is not the product of an enrolled Native American artist. Attorney Gail Sheffield and others claim that this law has had "the unintended consequence of sanctioning discrimination against Native Americans whose tribal affiliation was not officially recognized". Native artists such as Jeanne Rorex Bridges (Echota Cherokee) who was not enrolled ran the risk of fines or imprisonment if they continued to sell their art while affirming their Indian heritage.

Interracial relations between Native Americans, Europeans, and Africans is a complex issue that has been mostly neglected with "few in-depth studies on interracial relationships". Some of the first documented cases of European/Native American intermarriage and contact were recorded in Post-Columbian Mexico. One case is that of Gonzalo Guerrero, a European from Spain, who was shipwrecked along the Yucatan Peninsula, and fathered three Mestizo children with a Mayan noblewoman. Another is the case of Hernán Cortés and his mistress La Malinche, who gave birth to another of the first multi-racial people in the Americas.

European impact was immediate, widespread, and profound already during the early years of colonization and nationhood. Europeans living among Native Americans were often called "white indians". They "lived in native communities for years, learned native languages fluently, attended native councils, and often fought alongside their native companions".

Early contact was often charged with tension and emotion, but also had moments of friendship, cooperation, and intimacy. Marriages took place in English, Spanish, and French colonies between Native Americans and Europeans though Native American women were also the victims of rape. Given the preponderance of men among the colonists in the early years, generally European men tried to turn to Native American women for sexual relationships either through marriage, informal relationships, or rape.

There was fear on both sides, as the different peoples realized how different their societies were. The whites regarded the Indians as "savage" because they were not Christian. They were suspicious of cultures which they did not understand. The Native American author, Andrew J. Blackbird, wrote in his "History of the Ottawa and Chippewa Indians of Michigan" (1897), that white settlers introduced some immoralities into Native American tribes. Many Native Americans suffered because the Europeans introduced alcohol and the whiskey trade resulted in alcoholism among the people, who were alcohol-intolerant.

Blackbird wrote:

The U.S. government had two purposes when making land agreements with Native Americans: to open it up more land for white settlement, and to ease tensions between whites and Native Americans by forcing the Native Americans to use the land in the same way as did the whites—for subsistence farms. The government used a variety of strategies to achieve these goals; many treaties required Native Americans to become farmers in order to keep their land. Government officials often did not translate the documents which Native Americans were forced to sign, and native chiefs often had little or no idea what they were signing.
For a Native American man to marry a white woman, he had to get consent of her parents, as long as "he can prove to support her as a white woman in a good home". In the early 19th century, the Shawnee Tecumseh and blonde hair, blue-eyed Rebbecca Galloway had an interracial affair. In the late 19th century, three European-American middle-class women teachers at Hampton Institute married Native American men whom they had met as students.

As European-American women started working independently at missions and Indian schools in the western states, there were more opportunities for their meeting and developing relationships with Native American men. For instance, Charles Eastman, a man of European and Lakota descent whose father sent both his sons to Dartmouth College, got his medical degree at Boston University and returned to the West to practice. He married Elaine Goodale, whom he met in South Dakota. He was the grandson of Seth Eastman, a military officer from Maine, and a chief's daughter. Goodale was a young European-American teacher from Massachusetts and a reformer, who was appointed as the U.S. superintendent of Native American education for the reservations in the Dakota Territory. They had six children together.

The majority of Native American tribes did practice some form of slavery before the European introduction of African slavery into North America, but none exploited slave labor on a large scale. Most Native American tribes did not barter captives in the pre-colonial era, although they sometimes exchanged enslaved individuals with other tribes in peace gestures or in exchange for their own members. When Europeans arrived as colonists in North America, Native Americans changed their practice of slavery dramatically. Native Americans began selling war captives to Europeans rather than integrating them into their own societies as they had done before. As the demand for labor in the West Indies grew with the cultivation of sugar cane, Europeans enslaved Native Americans for the Thirteen Colonies, and some were exported to the "sugar islands". The British settlers, especially those in the southern colonies, purchased or captured Native Americans to use as forced labor in cultivating tobacco, rice, and indigo. Accurate records of the numbers enslaved do not exist because vital statistics and census reports were at best infrequent. Scholars estimate tens to hundreds of thousands of Native Americans may have been enslaved by the Europeans, being sold by Native Americans themselves or Europeans. 
Slaves became a caste of people who were foreign to the English (Native Americans, Africans and their descendants) and non-Christians. The Virginia General Assembly defined some terms of slavery in 1705:

The slave trade of Native Americans lasted only until around 1750. It gave rise to a series of devastating wars among the tribes, including the Yamasee War. The Indian Wars of the early 18th century, combined with the increasing importation of African slaves, effectively ended the Native American slave trade by 1750. Colonists found that Native American slaves could easily escape, as they knew the country. The wars cost the lives of numerous colonial slave traders and disrupted their early societies. The remaining Native American groups banded together to face the Europeans from a position of strength. Many surviving Native American peoples of the southeast strengthened their loose coalitions of language groups and joined confederacies such as the Choctaw, the Creek, and the Catawba for protection. Even after the Indian Slave Trade ended in 1750 the enslavement of Native Americans continued in the west, and also in the Southern states mostly through kidnappings.

Both Native American and African enslaved women suffered rape and sexual harassment by male slaveholders and other white men.

African and Native Americans have interacted for centuries. The earliest record of Native American and African contact occurred in April 1502, when Spanish colonists transported the first Africans to Hispaniola to serve as slaves.
Sometimes Native Americans resented the presence of African Americans. The "Catawaba tribe in 1752 showed great anger and bitter resentment when an African American came among them as a trader". To gain favor with Europeans, the Cherokee exhibited the strongest color prejudice of all Native Americans. Because of European fears of a unified revolt of Native Americans and African Americans, the colonists tried to encourage hostility between the ethnic groups: "Whites sought to convince Native Americans that African Americans worked against their best interests." In 1751, South Carolina law stated:

In addition, in 1758 the governor of South Carolina James Glen wrote:

Europeans considered both races inferior and made efforts to make both Native Americans and Africans enemies. Native Americans were rewarded if they returned escaped slaves, and African Americans were rewarded for fighting in the late 19th-century Indian Wars.

"Native Americans, during the transitional period of Africans becoming the primary race enslaved, were enslaved at the same time and shared a common experience of enslavement. They worked together, lived together in communal quarters, produced collective recipes for food, shared herbal remedies, myths and legends, and in the end they intermarried." Because of a shortage of men due to warfare, many tribes encouraged marriage between the two groups, to create stronger, healthier children from the unions.

In the 18th century, many Native American women married freed or runaway African men due to a decrease in the population of men in Native American villages. Records show that many Native American women bought African men but, unknown to the European sellers, the women freed and married the men into their tribe. When African men married or had children by a Native American woman, their children were born free, because the mother was free (according to the principle of "partus sequitur ventrem", which the colonists incorporated into law).

While numerous tribes used captive enemies as servants and slaves, they also often adopted younger captives into their tribes to replace members who had died. In the Southeast, a few Native American tribes began to adopt a slavery system similar to that of the American colonists, buying African American slaves, especially the Cherokee, Choctaw, and Creek. Though less than 3% of Native Americans owned slaves, divisions grew among the Native Americans over slavery. Among the Cherokee, records show that slave holders in the tribe were largely the children of European men who had shown their children the economics of slavery. As European colonists took slaves into frontier areas, there were more opportunities for relationships between African and Native American peoples.

In the 2010 Census, nearly 3 million people indicated that their race was Native American (including Alaska Native). Of these, more than 27% specifically indicated "Cherokee" as their ethnic origin. Many of the First Families of Virginia claim descent from Pocahontas or some other "Indian princess". This phenomenon has been dubbed the "Cherokee Syndrome". Across the US, numerous individuals cultivate an opportunistic ethnic identity as Native American, sometimes through Cherokee heritage groups or Indian Wedding Blessings.

Many tribes, especially those in the Eastern United States, are primarily made up of individuals with an unambiguous Native American identity, despite being predominantly of European ancestry. More than 75% of those enrolled in the Cherokee Nation have less than one-quarter Cherokee blood, and the current Principal Chief of the Cherokee Nation, Bill John Baker, is 1/32 Cherokee, amounting to about 3%.

Historically, numerous Native Americans assimilated into colonial and later American society, e.g. through adopting English and converting to Christianity. In many cases, this process occurred through forced assimilation of children sent off to special boarding schools far from their families. Those who could pass for white had the advantage of white privilege Today, after generations of racial whitening through hypergamy and interracial marriage, many Native Americans are visually indistinguishable from White Americans, unlike mestizos in the United States, who may in fact have little or no non-indigenous ancestry.

Native Americans are more likely than any other racial group to practice interracial marriage, resulting in an ever-declining proportion of indigenous blood among those who claim a Native American identity. Some tribes will even resort to disenrollment of tribal members unable to provide scientific "proof" of Native ancestry, usually through a Certificate of Degree of Indian Blood. Disenrollment has become a contentious issue in Native American reservation politics.

Intertribal mixing was common among many Native American tribes prior to European contact, as they would adopt captives taken in warfare. Individuals often had ancestry from more than one tribe, particularly after tribes lost so many members from disease in the colonial era and after. Bands or entire tribes occasionally split or merged to form more viable groups in reaction to the pressures of climate, disease and warfare.

A number of tribes traditionally adopted captives into their group to replace members who had been captured or killed in battle. Such captives were from rival tribes and later were taken from raids on European settlements. Some tribes also sheltered or adopted white traders and runaway slaves, and others owned slaves of their own. Tribes with long trading histories with Europeans show a higher rate of European admixture, reflecting years of intermarriage between Native American women and European men, often seen as advantageous to both sides. A number of paths to genetic and ethnic diversity among Native Americans have occurred.

In recent years, genetic genealogists have been able to determine the proportion of Native American ancestry carried by the African-American population. The literary and history scholar Henry Louis Gates, Jr., had experts on his TV programs who discussed African-American ancestry. They stated that 5% of African Americans have at least 12.5% Native American ancestry, or the equivalent to one great-grandparent, which may represent more than one distant ancestor. A greater percentage could have a smaller proportion of Indian ancestry, but their conclusions show that popular estimates of Native American admixture may have been too high. More recent genetic testing research of 2015, have found varied ancestries which show different tendencies by region and sex of ancestors. Though DNA testing is limited these studies found that on average, African Americans have 73.2–82.1% West African, 16.7%–29% European, and 0.8–2% Native American genetic ancestry, with large variation between individuals.

DNA testing is not sufficient to qualify a person for specific tribal membership, as it cannot distinguish among Native American tribes; however some tribes such as the Meskwaki Nation require a DNA test in order to enroll in the tribe.

Native American identity has historically been based on culture, not just biology, as many American Indian peoples adopted captives from their enemies and assimilated them into their tribes. The Indigenous Peoples Council on Biocolonialism (IPCB) notes that:

"Native American markers" are not found solely among Native Americans. While they occur more frequently among Native Americans, they are also found in people in other parts of the world.

Geneticists state:

Not all Native Americans have been tested; especially with the large number of deaths due to disease such as smallpox, it is unlikely that Native Americans only have the genetic markers they have identified [so far], even when their maternal or paternal bloodline does not include a [known] non-Native American.

To receive tribal services, a Native American must be a certified (or enrolled) member of a federally recognized tribal organization. Each tribal government makes its own rules for eligibility of citizens or tribal members. Among tribes, qualification for enrollment may be based upon a required percentage of Native American "blood" (or the "blood quantum") of an individual seeking recognition, or documented descent from an ancestor on the Dawes Rolls or other registers. But, the federal government has its own standards related to who qualifies for services available to certified Native Americans. For instance, federal scholarships for Native Americans require the student both to be enrolled in a federally recognized tribe "and" to be of at least one-quarter Native American descent (equivalent to one grandparent), attested to by a Certificate of Degree of Indian Blood (CDIB) card issued by the federal government.

Some tribes have begun requiring genealogical DNA testing of individuals' applying for membership, but this is usually related to an individual's proving parentage or direct descent from a certified member. Requirements for tribal membership vary widely by tribe. The Cherokee require documented direct genealogical descent from a Native American listed on the early 1906 Dawes Rolls. Tribal rules regarding recognition of members who have heritage from multiple tribes are equally diverse and complex.

Tribal membership conflicts have led to a number of legal disputes, court cases, and the formation of activist groups. One example of this are the Cherokee Freedmen. Today, they include descendants of African Americans once enslaved by the Cherokees, who were granted, by federal treaty, citizenship in the historic Cherokee Nation as freedmen after the Civil War. The modern Cherokee Nation, in the early 1980s, passed a law to require that all members must prove descent from a Cherokee Native American (not Cherokee Freedmen) listed on the Dawes Rolls, resulting in the exclusion of some individuals and families who had been active in Cherokee culture for years.

Since the census of 2000, people may identify as being of more than one race. Since the 1960s, the number of people claiming Native American ancestry has grown significantly and by the 2000 census, the number had more than doubled. Sociologists attribute this dramatic change to "ethnic shifting" or "ethnic shopping"; they believe that it reflects a willingness of people to question their birth identities and adopt new ethnicities which they find more compatible.

The author Jack Hitt writes:

The journalist Mary Annette Pember notes that identifying with Native American culture may be a result of a person's increased interest in genealogy, the romanticization of the lifestyle, and a family tradition of Native American ancestors in the distant past. There are different issues if a person wants to pursue enrollment as a member of a tribe. Different tribes have different requirements for tribal membership; in some cases persons are reluctant to enroll, seeing it as a method of control initiated by the federal government; and there are individuals who are 100% Native American but, because of their mixed tribal heritage, do not qualify to belong to any individual tribe. Pember concludes:

The genetic history of indigenous peoples of the Americas primarily focuses on human Y-chromosome DNA haplogroups and human mitochondrial DNA haplogroups. "Y-DNA" is passed solely along the patrilineal line, from father to son, while "mtDNA" is passed down the matrilineal line, from mother to offspring of both sexes. Neither recombines, and thus Y-DNA and mtDNA change only by chance mutation at each generation with no intermixture between parents' genetic material. Autosomal "atDNA" markers are also used, but differ from mtDNA or Y-DNA in that they overlap significantly. Autosomal DNA is generally used to measure the average continent-of-ancestry genetic admixture in the entire human genome and related isolated populations.

The genetic pattern indicates Indigenous Americans experienced two very distinctive genetic episodes; first with the initial-peopling of the Americas, and secondly with European colonization of the Americas. The former is the determinant factor for the number of gene lineages, zygosity mutations and founding haplotypes present in today's Indigenous Amerindian populations.

Human settlement of the New World occurred in stages from the Bering sea coast line, with an initial 15,000 to 20,000-year layover on Beringia for the small founding population. The micro-satellite diversity and distributions of the Y lineage specific to South America indicates that certain Amerindian populations have been isolated since the initial colonization of the region. The Na-Dené, Inuit and Indigenous Alaskan populations exhibit haplogroup Q-M242 (Y-DNA) mutations, however, that are distinct from other indigenous Amerindians, and that have various mtDNA and atDNA mutations. This suggests that the paleo-Indian migrants into the northern extremes of North America and Greenland were descended from a later, independent migrant population.






</doc>
