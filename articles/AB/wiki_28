<doc id="15514" url="https://en.wikipedia.org/wiki?curid=15514" title="Iblis">
Iblis

Iblīs (alternatively Eblis or Ibris) is a figure frequently occurring in the Quran, commonly in relation to the creation of Adam and the command to prostrate himself before him. After he refused, he was cast out of heaven. For many classical scholars, he was an angel, but regarded as a jinn in most contemporary scholarship. Due to his fall from God's grace, he is often compared to Satan in Christian traditions. In Islamic tradition, Iblis is often identified with "Al-Shaitan" ("the Devil"). However, while "Shaitan" is used exclusively for an evil force, Iblis himself holds a more ambivalent role in Islamic traditions.

The term "Iblis" () may have been derived from the Arabic verbal root (with the broad meaning of "remain in grief") or "(", "he despaired"). Furthermore, the name is related to "talbis" meaning confusion. Another possibility is that it is derived from Ancient Greek "()", via a Syriac intermediary, which is also the source of the English word 'devil'. Yet, another possibility relates this name back to the "bene Elohim" (Sons of God), who had been identified with fallen angels in the early centuries, but had been singularised under the name of their leader. However, there is no general agreement on the root of the term. The name itself could not be found before the Quran in Arabic literature, but can be found in Kitab al Magall.

In Islamic traditions, Iblis is known by many alternative names or titles, such as "Abu Murrah" (Father of Bitterness), "adūw-Allāh" or "aduwallah" (enemy of God) and Abu Al-Harith (the father of the plowmen).

Although Iblis is often compared to the devil in Christian theology, Islam rejects the idea that the devil is an opponent of God. Furthermore, there is no mention of Iblis trying to take God's throne. According to the Quran, he was banished due to his disdain for humanity, a narrative already occurring in early apocrypha. As a mere creature, Iblis can not be the cause or creator of evil in the world; he is merely a tempter who takes advantage of humanity's weakness and self-centeredness and leads them away from God's path.

Iblis is mentioned 11 times in the Quran by name, nine times related to his rebellion against God's command to prostrate himself before Adam. The term Shaitan is more prevalent, although Iblis is sometimes referred to as Shaitan; the terms are not interchangeable. The different fragments of Iblis' story are scattered across the Quran. In the aggregate, the story can be summarized as follows:

When God created Adam, He ordered all the angels to bow before the new creation. All the angels bowed down, but Iblis refused to do so. He argued that since he himself was created from fire, he is superior to humans, made from Clay-mud, and that he should not prostrate himself before Adam. As punishment for his haughtiness, God banished Iblis from heaven and condemned him to hell. Later, Iblis made a request for the ability to try to mislead Adam and his descendants. God granted his request but also warned him that he will have no power over God's servants.

Sufism developed another perspective of Iblis' refusal by regarding Muhammed and Iblis as the two true monotheists. Therefore, some Sufis hold, Iblis refused to bow to Adam because he was devoted to God alone and refused to bow to anyone else. By weakening the evil in the Satanic figure, dualism is also degraded, that corresponds with the Sufi cosmology of unity of existence rejecting dualistic tendencies. The belief in dualism or that "evil" is caused by something else than God, even if only by one's own will, is regarded as "shirk" by some Sufis. For Iblis' preference to be damned to hell, than prostrating himself before someone else other than the "Beloved" (here referring to God), Iblis also became an example for unrequited love.

A famous narration about an encounter between Moses and Iblis on the slopes of Sinai, told by Mansur al-Hallaj, Ruzbihan Baqli and Ghazzali, emphasizes the nobility of Iblis. Accordingly, Moses asks Iblis why he refused God's order. Iblis replied that the command was actually a test. Then Moses replied, obviously Iblis was punished by being turned from an angel to a devil. Iblis responds, his form is just temporary and his love towards God remains the same.

However, not all Sufis are in agreement with a positive depiction of Iblis. Rumi's viewpoint on Iblis is much more in tune with Islamic orthodoxy. Rumi views Iblis as the manifestation of the great sins of haughtiness and envy. He states: "(Cunning) intelligence is from Iblis, and love from Adam." Iblis represents the principle of "one-eyed" intellect; he only saw the outward earthly form of Adam, but was blind to the Divine spark hidden in him, using an illicit method of comparison. Hasan of Basra holds that Iblis was the first who used "analogy", comparing himself to someone else, this causing his sin. Iblis therefore also represents humans' psyche moving towards sin or shows how love can cause envy and anxiety.

Islam differs in regard of Iblis' nature. Some scholars such as Tabari, Ash'ari, Al-Tha`labi, Al-Baydawi and Mahmud al-Alusi, regard him as an angel. Tabari argued for an angelic origin of Iblis in his tafsir: "The reason people held this opinion [that Iblis was not an angel] is that God stated in His Book that He created Iblis from the fire of the Samum (15:27) and from smokeless fire (55:15), but did not state that He created the angels from any like of that. And God states he was of the jinn, so they said that it is not possible that he should be related to that which God does not relate him to; they said that Iblis had progeny and offspring, but the angels do not procreate or have children.

But these reasons only bespeak the weakness of these people's knowledge, for there is nothing objectionable in that God should have created the categories of His angels from all kinds of things that He had created: He created some of them from light, some of them from fire, and some of them from what He willed apart from that. There is thus nothing in God's omitting to state what He created His angels from, and in His stating what He created Iblis from, which necessarily implies that Iblis is outside of the meaning of [angel], for it is possible that He created a category of His angels, among whom was Iblis, from fire, and even that Iblis was unique in that He created him, and no other angels of His, from the fire of the Samum.
Likewise, he cannot be excluded from being an angel by fact that he had progeny or offspring, because passion and lust, from which the other angels were free, was compounded in him when God willed disobedience in him. As for God's statement that he was <one of the jinn>, it is not to be rejected that everything which hides itself (ijtanna) from the sight is a 'jinn', . . . and Iblis and the angels should then be among them, because they hide themselves from the eyes of mankind."

On the other hand, the Quranic exegete Ibn Kathir, preferred to regard Iblis as a genie, an opinion shared by scholars such as Hasan of Basra, Ja'far al-Sadiq, Fakhr al-Din al-Razi, Ibn Taimiyya and Al-Munajjid, stating in his tafsir:

"When Allah commanded the angels to prostrate before Adam, Iblis was included in this command. Although Iblis was not an angel, he was trying- and pretending - to imitate the angels' behavior and deeds, and this is why he was also included in the command to the angels to prostrate before Adam. Satan was criticized for defying that command, (. . .)

When matters crucial every vessel leaks that which to contains and is betrayed by its true nature. Iblis used to do, what the angels did and resembled them in their devotion and worship, so he was included when they were addressed, but he disobeyed and went what he was told to do. So Allah points out here that he was one of the Jinn, he was created from fire, as He says elsewhere."

The common viewpoints about Iblis' affiliation can be summarized as follows:
Apart from the Quranic narrative, within Islamic exegesis offers two different accounts of Iblis' origin, according to one, he was a noble angel, to the other he was an ignoble jinn, who worked his way up to heaven.

As an angel, Iblis is described as an Archangel, the leader and teacher of the other angels, and a keeper of heaven. At the same time, he was the closest to the Throne of God. God gave him authority over the lower heavens and the earth. Iblis is also considered as the leader of those angels who battled the earthly jinn. Therefore, Iblis and his army drove the jinn to the edge of the world, Mount Qaf. Knowing about the corruption of the former earthen inhabitants, Iblis protested, when he was instructed to prostrate himself before the new earthen inhabitant, that is Adam. He assumed that the angels who "praise God's glory day and night" are superior in contrast to the mud-made human and their bodily flaws. He even regarded himself superior in comparison to the other angels, since he was (one of those) created from fire. However, he was degraded by God for his arrogance. But Iblis made a request to prove that he is actually right, therefore God entrusted him as a tempter for humanity as long as his punishment endures, concurrently giving him a chance to redeem himself. Since Iblis does not act upon free-will, but as an instrument of God, he will his abode in hell could be a merely temporary place, until the Judgement Day and after his assignment as a tempter is over, he might return to God as one of the most cherished angels. His final salvation develops from the idea of that Iblis is only an instrument of God's anger, not due to his meritorious personality. Attar compares Iblis damnation and salvation to the situation of Benjamin, since both were accused to show people a greater meaning, but were finally not condemned.

Furthermore, the transformation of Iblis from angelic into demonic is a reminder of God's capacity to reverse injustice even on an ontological level. It is both a warning and a reminder that the special gifts given by God can also be taken away by Him.

On the other hand, as a genie, Iblis is commonly placed as one of the jinn, who lived on earth during the battle of the angels. When the angels took prisoners, Iblis was one of them and carried to heaven. Since he, unlike the other jinn, was pious, the angels were impressed by his nobility and Iblis was allowed to join the company of angels and elevated to their rank. However, although he got the outer appearance of an angel, he was still a jinn in essence, thus he was able to choose when the angels and Iblis were commanded to prostrate themselves before Adam. Iblis, abusing his free-will, disobeyed the command of God. Iblis considered himself superior because of his physical nature constituted of fire and not of clay. God sentenced Iblis to hell forever, but granted him a favor for his former worship, that is to take revenge on humans by attempting to mislead them until the Day of Judgment. Here, Iblis damnation is clear and he and his host are the first who enter hell to dwell therein forever, when he is not killed in a battle by the Mahdi, an interpretation especially prevalent among Shia Muslims.

Illustrations of Iblis in Islamic paintings often depict him black-faced, a feature which would later symbolize any Satanic figure or heretic, and with a black body, to symbolize his corrupted nature. Another common depiction of Iblis shows him wearing special headcovering, clearly different from the traditional Islamic turban. In one painting, however, Iblis wears a traditional Islamic headcovering. The turban probably refers to a narration of Iblis' fall: there he wore a turban, then he was sent down from heaven. Many other pictures show and describe Iblis at the moment, when the angels prostrate themselves before Adam. Here, he is usually seen beyond the outcrop, his face transformed from that of an angel created from fire, to the envious countenance of a devil.

Islamic traditions are undecided about the exact nature of Iblis. He may either be a fallen angel or a jinni or something entirely unique. This lack of final specification arises from the Quran itself, while Iblis is included into the command addressed to the angels and apparently among them, he is identified as a "jinni" ('الجِنِّ') in Surah . in the Quran. This combined with the fact, he himself boasts to be created from fire, suggests that he is not an angel but a "jinni", since according to "hadith" the angels are created from light and the jinn from fire. But the term "jinni" itself is ambiguous. It has been suggested that in Pre-Islamic Arabia the term denoted any type of invisible creature including angels known from Arab Christians, Arab Jews and Zoroastrians. Due to the otherwise unusual usage of the term "jinn" in the Quran led some scholars conclude, Iblis' identification was merely temporary or a later interpolation. Strikely, the Quran describes the fire of which jinn are created with special features not mentioned regarding the fire from which Iblis is made of. This was further used to indicate, that Iblis as created from fire was not a support to identify Iblis with the jinn apart from the occurrence in Surah 18. Additionally, the Quran does not mention light as a separate source from which the angels are supposed to be created. In Ancient Near Eastern traditions, the nature of angels was associated with fire, therefore Iblis could indeed be intended to represent an angel, such as a Seraph.

Otherwise, the nature of the jinn in later Islamic tradition is not always clear either. Some hold the jinn to be a sub-category of "fiery angels" who are guardians of "jannah", differing from the earthly jinn, who are like monsters or demons. Accordingly, they are named 'Jinni', because of their relation to heaven. On the other hand, in another story, the earthen jinn themselves are related to angels. Therefore, they were angels sent down to earth to experience bodily pleasure and although they remained obedient towards God during the beginning, they later found themselves lost in wars, bloodshed, and other unjust deeds. Iblis, disgusted by his fellow beings, prayed for his return to heaven until his prayers were answered.

Assuming Iblis was one of the jinn, who differ from the angels, scholars tried to explain his stay among the angels. According to a narrative provided by Ibn Kathir, Iblis was once an ordinary earthly creature, but, due to his piety and constant worship, elevated among the angels. He lived there for thousands of years, until his non-angelic origin was forgotten and only God remembered Iblis' true identity. To reveal his haughtiness, God commanded the angels, Iblis, due to his rank among the angels included, to prostrate himself before Adam. But Iblis refused, thus his own nature betrayed him, leading to his downfall.

Other scholars, such as Hasan of Basra and Ibn Taymiyyah, do not provide an explanation for his abode among the angels. In this case, his stay in heaven is self-explanatory, because every creature is created in heaven first. Here, although created in heaven, Iblis is not regarded as an angel, but the equivalent father of the jinn, compared to what Adam is to humanity. Iblis, as the father of the jinn, was cast out of heaven due to his own sin, just as Adam was banished after his corresponding transgression of God's order not to eat from the Forbidden Tree.

Those scholars, who argue against Iblis' angelic origin also refer to his progeny, since angels do not procreate in Islam, pointing at . Islamic study scholar Fritz Meier also insists, that the Islamic Iblis can not be held as an angel, since angels have no progeny by definition. Otherwise Walther Eickmann argued that the "progeny of Iblis" does not correspond with "progeny" in a literal sense, but just refers to the cohorts of Iblis. On another place in the Quran, the progeny of Iblis are said to be created, therefore they can not be literal progeny. Actually, according to some Islamic traditions, Iblis is indeed an asexuel being just like the other angels. On the other hand, he occurs as a hermaphrodite creature, whose children split from himself, for that he lays eggs, as "šayāṭīn" ("demons"). The Quran exegete Tabari however, who defends Iblis' angelic origin, asserts, that Iblis did not procreate until he lost his angelic state and became a demon. Therefore, the fact Iblis has progeny could not exclude him from an angelic origin.

Another central argument to determine Iblis essence, also relating to his theological significance, deals with his disobedience. Since angels are, according to Islam, merely servants of God, Iblis' disobedience speaks against his angelic nature, as opponents of Iblis' angelic origin argue. Unlike the angels, he was endowed with the ability to choose, but he decided to disobey due to his own arrogance. His nature to disregard God is thought of a part of the free-will given to jinn. On the other hand, scholars who adhere to Iblis' angelic nature, regards him as just another instrument of God, a tester who acts within God's plan and not someone, who choose sin. Therefore, his disobedience was in accordance with God's will. Although early scholars, who held him to be an angel (Ibn Abbas, Ibn Masud), described him as an infidel (kafir), in early Islamic period, but he did not actually sin. As thought in early Islamic period, he could not understand sin or expiate it. Therefore, Iblis was created as a rebellious angel. Abu Hanifa, founder of the Hanafi schools jurisprudence, is reported as distinguishing between obedient angels, disobedient angels such as Harut and Marut and unbelievers among the angels, like Iblis.

Several narratives attempt to explain the reason why he chose to refuse the command, unlike the other angels. According to one, Iblis, as the teachers of the angels, was more knowledgeable than the others and knew about a command, not to prostrate himself, when all the other angels do. In another narrative, Iblis has stolen the secret writings of heaven, therefore he had insight into the future. Knowing about Adam's future, he was no longer able to prostrate himself. However, this narrative is more unconvincing, since other angels protested alike, knowing about the corruption. In another explanation, Iblis is endowed with the task to seduce humans, comparable to other angels, such as Gabriel, is endowed with the transmission of revelation, and created for this purpose from fire differing from the other angels.

In some interpretations, Iblis is associated with "light" that misleads people. Hasan of Basra was quoted as saying: "If Iblis were to reveal his light to mankind, they would worship him as god." Additionally, based on Iblis' role as "keeper of heaven" and "ruler of earth", Ayn al-Quzat Hamadani stated, Iblis represents the "Dark light" that is the earthen world, standing in opposite to the Muhammadan Light that represents the heavens. Quzat Hamadani traces back his interpretation to Sahl al-Tustari and Shayban Ar-Ra'i who in return claim to derive their opinions from Khidr. Quzat Hamadani relates his interpretation of "Iblis' light" to the "shahada": Accordingly, people whose service for God is just superficial, are trapped within the circle of "la ilah" (the first part of "shahada" meaning "there is no God") just worshipping their nafs rather than God. Only those who are worthy to leave this circle, can pass Iblis towards the circle of "illa Allah" the Divine presence.

Although the serpent is not mentioned in the Quran, Quranic commentaries as well as the Stories of the Prophets added the serpent borrowed from Gnostic and Jewish oral tradition circulating in the Arabian Peninsula. Iblis tries to enter the abode of Adam, but the angelic guardian keeps him away. Then Iblis invents a plan to trick the guardian. He approaches a peacock and tells him, that all creatures will die and the peacock's beauty will perish. But if he gets the fruit of eternity, every creature will last forever. Therefore, the serpent convinces the peacock to slip Iblis into the Garden, by carrying him in his mouth. In another, yet similar narration, Iblis is warded of by Riḍwan's burning sword for 100 years. Then he found the serpent. He says, since he was one of the first cherubim, he will one day return to God's grace, and promises to show gratitude if the serpent does him a favor. In both narratives, in the Garden, Iblis speaks through the serpent to Adam and Eve, and tricks them into eating from the forbidden tree. Modern Muslims accuse the Yazidis of devil-worship for venerating the peacock.

In Umm al Kitab, an Ismaili work offering a hermeneutic interpretation of the Quran, the "peacock" and the "serpent" were born after men mated with demonic women sent by Iblis.

In the Shahnameh by Ferdowsi, Iblis appears as a substitute for Ahriman, the Zoroastrian principle of evil and leader of the malevolent Diws. He supports Zahhak to usurp the throne and kissed his shoulders, whereupon serpents grew from the spot Iblis kissed, a narrative rooting in ancient Avesta.

In Muhammad Iqbal's poetry, Iblis is critical about overstressed obedience, that caused of his own downfall. But Iblis is not happy about human's obedience towards himself either, rather he longs for humans who resist him, so he might evantually prostrate himself before the perfect human, that leads to his own salvation.


</doc>
<doc id="15516" url="https://en.wikipedia.org/wiki?curid=15516" title="Intelsat">
Intelsat

Intelsat Corporation—formerly INTEL-SAT, INTELSAT, Intelsat—is a communications satellite services provider. Originally formed as International Telecommunications Satellite Organization ("ITSO", or INTELSAT), it was—from (), to 2001—an intergovernmental consortium owning and managing a constellation of communications satellites providing international broadcast services.

, Intelsat operates a fleet of 52 communications satellites, which is one of the world's largest fleet of commercial satellites. They claim to serve around 1,500 customers and employ a staff of approximately 1,100 people.

John F. Kennedy instigated the creation of "INTELSAT" with his speech to the United Nations on the 25th of September 1961. Less than a year later, John F. Kennedy signed the Communications Satellite Act of 1962. "INTELSAT" was originally formed as International Telecommunications Satellite Organization ("ITSO") and operated from 1964 to 2001 as an intergovernmental consortium owning and managing a constellation of communications satellites providing international broadcast services. In 2001, the international satellite market was fully commercialized, and the US predominant role in INTELSAT was fully privatized after 2001 as Intelsat was formed up as a private Luxembourg corporation.

The International Governmental Organization (IGO) began on (), with 7 participating countries. The 1964 agreement was an interim arrangement on a path to a more permanent agreement. The permanent international organization was established in 1973, following inter-nation negotiations from 1969 to 1971. The most difficult issue to "resolve concerned the shift from management of the system by a national entity to management by the international organization itself."

On 6 April 1965, INTELSAT's first satellite, the Intelsat I (nicknamed "Early Bird"), was placed in geostationary orbit above the Atlantic Ocean by a Delta D rocket.

In 1973, the name was changed and there were 81 signatories. INTELSAT was "governed initially by two international agreements: The Agreement setting forth the basic provisions and principles and structure of the organization, signed by the governments through their foreign ministries, and an Operating Agreement setting forth more detailed financial and technical provisions and signed by the governments or their designated telecommunications entities."—in most cases the latter are the ministries of communications of the party countries, but in the case of the United States, was the Communications Satellite Corporation (COMSAT), a private corporation established by federal legislation to represent the US in international governance for the global communication satellite system.
INTELSAT at that time directly owned and managed a global communications satellite system, and structurally consisted of three parts: 

The 1973 Agreement called for a seven-year transition from national to international management, but continued until 1976 to carve out "technical and operational management of the system [to the US signatory] the Communications Satellite Corporation [which had also] served as the Manager of the global system under the interim arrangements in force from 1964 to 1973." 
Later phases of the transition resulted in full international governance by 1980.
Financial contribution to the organization, it's so-called "investment share," was strictly proportional to each member's use of the system, determined annually; and this corresponded to the weighted vote each would have on the Board of Governors.

As of 2018, Intelsat provides service to over 600 Earth stations in more than 149 countries, territories and dependencies. By 2001, INTELSAT had over 100 members. It was also this year that INTELSAT privatized and changed its name to Intelsat.

Since its inception, Intelsat has used several versions (blocks) of its dedicated Intelsat satellites. Intelsat completes each block of spacecraft independently, leading to a variety of contractors over the years. Intelsat's largest spacecraft supplier is Space Systems/Loral, having built 31 spacecraft (as of 2003), or nearly half of the fleet.

The network in its early years was not as robust as it is now. A failure of the Atlantic satellite in the spring of 1969 threatened to stop the "Apollo 11" mission; a replacement satellite went into a bad orbit and could not be recovered in time; NASA had to resort to using undersea cable telephone circuits to bring Apollo's communications to NASA during the mission. During the Apollo 11 moonwalk, the moon was over the Pacific Ocean, and so other antennas were used, as well as INTELSAT III, which was in geostationary orbit over the Pacific.

By the 1990s, building and launching satellites was no longer exclusively a government domain and as country-specific telecommunications systems were privatized, several private satellite operators arose to meet the growing demand. In the U.S., satellite operators such as PanAmSat, Orion Communications, Columbia Communications, Iridium, Globalstar, TRW and others formed under the umbrella of the Alliance for Competitive International Satellite Services (ACISS) to press for an end to the IGOs and the monopoly position of COMSAT the US signatory to Intelsat and Inmarsat. In March 2001, the US Congress passed the Open Market Reorganization for the Betterment of International Telecommunications (ORBIT) Act to privatize COMSAT and reform the role of the international organizations. In April 1998, to address US government concerns about market power, Intelsat's senior management spun off five of its older satellites to a private Dutch entity, New Skies Satellites, which became a direct competitor to Intelsat. To avert the US government's interference with Intelsat, Intelsat's senior management unsuccessfully considered relocating the IGO to another country.

On 18 July 2001, Intelsat became a private company, 37 years after formation. Prior to Intelsat's privatization in 2001, ownership and investment in INTELSAT (measured in shares) was distributed among INTELSAT members according to their use of services. Investment shares determined each member's percentage of the total contribution needed to finance capital expenditures. The organization's primary source of revenue was satellite usage fees which, after deduction of operating costs, was redistributed to INTELSAT members in proportion to their shares as repayment of capital and compensation for use of capital. Satellite services were available to any organization (both INTELSAT members and non-members), and all users paid the same rates.

Today, the number of Intelsat satellites, as well as ocean-spanning fiber-optic lines, allows rapid rerouting of traffic when one satellite fails. Modern satellites are more robust, lasting longer with a much larger capacity.

Intelsat Americas-7 (known formerly as Telstar 7 and now known as Galaxy 27) experienced a several-day power failure on 29 November 2004. The satellite returned to service with reduced capacity.
Intelsat was sold for U.S. $3.1bn in January 2005 to four private equity firms: Madison Dearborn Partners, Apax Partners, Permira and Apollo Global Management. The company acquired PanAmSat on 3 July 2006, and is now the world's largest provider of fixed satellite services, operating a fleet of 52 satellites in prime orbital locations.

In June 2007 BC Partners announced they had acquired 76 percent of Intelsat for about 3.75 billion euros.

BC Partners has since sold all their share and Intelsat is a stand-alone company.

In April 2013, the renamed Intelsat S.A. undertook an initial public offering on the New York Stock Exchange, raising a net US$550 million, of which $492 million was paid immediately to reduce outstanding company debts of US$15.9 billion. In May, the company announced it would be purchasing four new high-performance Boeing EpicNG 702 MP satellites.

There were talks that Intelsat was to merge with Softbank-backed OneWeb. However, on 1 June 2017 it was announced that the bondholders would not accept the offer and the merger would be terminated as of 2 June 2017.

In 2015 Intelsat reincorporated in Delaware and became Intelsat Corporation.

Intelsat maintains its corporate headquarters in Luxembourg, with a majority of staff and satellite functions. Administrative headquarters is located at the Intelsat Corporation offices in Tysons Corner, Virginia. A highly international business, Intelsat sources the majority of its revenue from non-U.S. located customers. Intelsat's biggest teleport is the Teleport Fuchsstadt in Germany.
, Intelsat has agreed to purchase one-half of the propellant payload that an MDA Corporation spacecraft satellite-servicing demonstration project would take to geostationary orbit. Catching up in orbit with four or five Intelsat communication satellites, a fuel load of of fuel delivered to each satellite would add somewhere between two and four years of additional service life.
A near-end-of-life Intelsat satellite will be moved to a graveyard orbit above the geostationary belt where the refueling will be done, "without consequence" to the Intelsat business.

, the business model was still evolving. MDA "could ask customers to pay per kilogram of fuel successfully added to [each] satellite, with the per-kilogram price being a function of the additional revenue the operator can expect to generate from the spacecraft’s extended operational life."

The plan is that the fuel-depot vehicle would maneuver to several satellites, dock at the target satellite's apogee-kick motor, remove a small part of the target spacecraft's thermal protection blanket, connect to a fuel-pressure line and deliver the propellant. "MDA officials estimate the docking maneuver would take the communications satellite out of service for about 20 minutes."

On February 1, 2007, Intelsat changed the names of 16 of its satellites formerly known under the Intelsat Americas and PanAmSat brands to Galaxy and Intelsat, respectively.


Over time, Intelsat has worked with most of the commercial launch services providers worldwide. Their satellites are often among the most massive of their generation, requiring the most powerful and reliable rockets on the market at a given time. In the 21st century, most Intelsat missions were conducted by Arianespace with the European Ariane 4 and Ariane 5 launchers, and by ILS with Proton-K and Proton-M rockets manufactured by Khrunichev in Russia. Intelsat also took advantage of the equatorial Sea Launch offering with Zenit-3SL rockets launched from the Ocean Odyssey floating platform, until they suspended operations in 2014. On May 30, 2012, Intelsat signed a contract with SpaceX for one of the first Falcon Heavy launch vehicles, marking the return of Intelsat to American launchers after many flights on Atlas II in the 1990s and a single Atlas V launch in 2009.





</doc>
<doc id="15517" url="https://en.wikipedia.org/wiki?curid=15517" title="ITSO">
ITSO

ITSO may stand for:


</doc>
<doc id="15521" url="https://en.wikipedia.org/wiki?curid=15521" title="Devanagari numerals">
Devanagari numerals

The Devanagari numerals are the symbols used to write numbers in the Devanagari script, the predominant script in India. They are used in the context of the decimal Hindu–Arabic numeral system, related to the Arabic numerals used in Europe.

Since Sanskrit is an Indo-European language, the words for numerals closely resemble those of Greek and Latin. The word "Shunya" for zero was translated into Arabic as "صفر" "sifr", meaning 'nothing' which became the term "zero" in many European languages from Medieval Latin, "zephirum".

Devanagari digits shapes may vary depending on geographical area.




</doc>
<doc id="15524" url="https://en.wikipedia.org/wiki?curid=15524" title="Ian Botham">
Ian Botham

Sir Ian Terence Botham (born 24 November 1955) is an English cricket commentator and a former cricketer who has been chairman of Durham County Cricket Club since 2017. Widely regarded as one of the greatest all-rounders in cricket history, Botham represented England in both Test and One-Day International cricket. He played most of his first-class cricket for Somerset, and also for Worcestershire, Durham and Queensland. He was an aggressive right-handed batsman and, as a right arm fast-medium bowler, was noted for his swing bowling. He generally fielded close to the wicket, predominantly in the slips. In Test cricket, Botham scored 14 centuries with a highest score of 208, and from 1986 to 1988, he held the world record for the most Test wickets until overtaken by fellow all-rounder Sir Richard Hadlee. He took five wickets in an innings 27 times and 10 wickets in a match four times. In 1980, he became the second player in Test history to complete the "match double" of scoring 100 runs and taking 10 wickets in the same match.

Botham has at times been involved in controversy including a highly publicised court case involving rival all-rounder Imran Khan and an ongoing dispute with the Royal Society for the Protection of Birds (RSPB). These incidents, allied to his on-field success, have attracted media attention, especially from the tabloid press. Botham has made effective use of the fame given to him by the publicity because he is actively concerned about leukaemia in children and has undertaken several long distance walks to raise money for research into the disease. These efforts have been highly successful and have realised millions of pounds for Bloodwise, of which he became president. In recognition of his services to charity, he was awarded a knighthood in the 2007 New Years Honours List. On 8 August 2009, he was inducted into the ICC Cricket Hall of Fame.

Botham has a wide range of sporting interests outside cricket. He was a talented footballer at school and had to choose between cricket and football as a career. He chose cricket but, even so, he did play professional football for a few seasons and made eleven appearances in the Football League for Scunthorpe United. He is a keen golfer and his other pastimes include angling and shooting.

On the occasion of England's 1000th Test in August 2018, he was named in the country's greatest Test XI by the ECB.

Ian Botham was born in Heswall, Cheshire, to Herbert Leslie ("Les") Botham and Violet Marie, Collett. His father had been in the Fleet Air Arm for twenty years spanning the Second World War; his mother was a nurse. The family moved to Yeovil before Botham's third birthday after his father got a job as a test engineer at Westland Helicopters. Both his parents played cricket: his father for Westland Sports Club while his mother captained a nursing services team at Sherborne. Botham developed an eagerness for the game before he had started school: he would climb through the fence of the Yeovil Boys' Grammar School to watch the pupils play cricket. At the age of around four, he came home with a cricket ball and asked his mother "Do you know how to hold a ball when you're going to bowl a daisy-cutter?" He subsequently demonstrated the grip and went away to practise bowling it.

Botham attended Milford Junior School in the town and it was there that his "love affair" with sport began. He played both cricket and football for the school's teams at the age of nine; two years earlier than most of his contemporaries. Playing against the older boys forced Botham to learn to hit the ball hard, and improve to their standard. At the same age he went to matches with his father, who played for Westland Sports Club, and if one of the teams was short, he would try to get a match. His father recalled that though he never got to bowl, and rarely got to bat, he received praise for the standard of his fielding. He joined the Boys' Brigade where more sporting opportunities were available. By the time he was nine, he had begun to "haunt" local recreation grounds with his kit always ready, looking to play for any team that was short of players. By the age of twelve he was playing occasional matches for Yeovil Cricket Club's second team.

Botham went on to Bucklers Mead Comprehensive School in Yeovil, where he continued to do well in sport and played for the school's cricket and football teams. He became captain of their under-16 cricket team when he was thirteen. His performances for the school drew the attention of Somerset County Cricket Club's youth coach Bill Andrews. Still thirteen, he scored 80 runs on debut for Somerset's under-15s side against Wiltshire, but the team captain Phil Slocombe did not call on him to bowl as he considered him to be a specialist batsman. Two years later, Botham had the opportunity to choose between football and cricket: Bert Head, manager of Crystal Palace offered him apprentice forms with the First Division club. He already had a contract with Somerset and, after discussing the offer with his father, decided to continue to pursue a cricket career, as he believed he was a better cricketer. When informed that he wanted to be a sportsman, Botham's careers teacher said to him: "Fine, everyone wants to play sport, but what are you really going to do?"
In 1972, at the age of 16, Botham left school intent on playing cricket for Somerset, who retained his contract but felt he was too young to justify a full professional deal. So, Botham joined the ground staff at Lord's. As a ground boy, he had numerous tasks such as "cleaning the pavilion windows, pushing the roller on matchdays, selling scorecards, pressing electronic buttons on the scoreboards and rushing bowling analyses to the dressing-room". He also received coaching and plenty of time in the practice nets, and was often the first to arrive and the last to leave practice. Despite his time in the nets, Botham was only considered by Marylebone Cricket Club (MCC) coach Harry Sharp to have the potential to become a "good, average county cricketer." Botham travelled to play for Somerset under-25s a number of times during the season, but failed to excel in any of the matches. His appearances for the MCC were of a similar vein: he rarely scored more than 50 runs, and was used sparingly as a bowler. In one such match against "Scotland A", the MCC Young Cricketers used eight bowlers in their second innings, but Botham was not among them.

The following year, still a ground boy at Lord's, Botham was asked to return to play for Somerset's under-25s more often. Against Glamorgan U-25, he scored 91 runs and took three tail-end wickets, while just under a month later he claimed a further three wickets against Hampshire. He advanced to play for the county's second team in the Minor Counties Championship, and although he was still used sparingly as a bowler, he made some good scores with the bat, most significantly against Cornwall, against whom he aggregated 194 runs in four innings. During winter nets prior to the season, Botham had caught the eye of the former England Test cricketer Tom Cartwright, who coached at Millfield School in addition to playing for Somerset. Cartwright was impressed with Botham's foot-work and physical co-ordination, and helped him learn the basics of swing bowling, something Botham picked up "astonishly quickly" according to Cartwright.

Botham had done well for the Second XI and he later acknowledged the help and advice he received from Somerset players Peter Robinson, Graham Burgess and Ken Palmer. Botham made his senior debut, aged 17, for Somerset on Sunday, 2 September 1973 when he played in a List A John Player League (JPL) match (38 overs each) against Sussex at the County Ground, Hove. The match was in the same week that his time on the Lord's ground staff was completed. Somerset batted first and Botham, number seven in the batting order, scored two runs before he was dismissed leg before wicket (lbw) by Mike Buss. Somerset totalled 139 for 9. Sussex won comfortably by six wickets, reaching 141 for four with fifteen deliveries remaining. Botham bowled three overs without success, conceding 22 runs. He did impress, however, by taking a diving catch to dismiss his future England colleague Tony Greig off the bowling of his captain Brian Close.

A week later, Botham made a second appearance in the JPL against Surrey at The Oval in the final match of the season. Somerset were well beaten by 68 runs. Botham had his first bowling success when he dismissed Geoff Howarth lbw. He bowled four overs and took one for 14. As in his first match, he scored two batting at number seven, this time being caught and bowled by Intikhab Alam. These were his only two senior appearances in 1973, Somerset finishing 11th in the JPL. In summary, Botham scored four runs, took one wicket for 14 and held one catch.

Aged 18, Botham was a regular in the Somerset team from the beginning of the 1974 season and made his first-class début 8–10 May in a County Championship match against Lancashire at the County Ground, Taunton. Viv Richards, from Antigua and Barbuda, made his County Championship début for Somerset in the same match and Lancashire's team included Clive Lloyd, two players who would loom large in Botham's future Test career. Brian Close won the toss and decided to bat first. On day one, Somerset were all out for 285 and Lancashire reached 41 for none. Botham batted at number seven and scored 13 before being caught. Day two was rain-affected and Lancashire advanced to 200 for none. Their innings closed on the final day at 381 for eight. Botham bowled only three overs and his figures were none for 15; he held one catch to dismiss Jack Simmons. Somerset played for the draw and were 104 for two at the end. Botham did not bat again.

On 12 June 1974, he played against Hampshire at Taunton in a Benson & Hedges Cup (B&H Cup) quarter-final. Hampshire won the toss and decided to bat. They scored 182 all out with Botham taking two for 33 including the prize wicket of Barry Richards, bowled for 13. Botham was number nine in Somerset's batting order and came in with his team struggling at 113 for 7. Almost immediately, that became 113 for 8 and he had only the tailenders Hallam Moseley and Bob Clapp to support him. He was facing the West Indian fast bowler Andy Roberts who delivered a bouncer which hit him in the mouth. Despite heavy bleeding and the eventual loss of four teeth, Botham refused to leave the field and carried on batting. He hit two sixes and made 45*, enabling Somerset to win by one wicket. He won the Gold Award. Later, he said he should have left the field but was full of praise for Moseley and Clapp.

In a County Championship match on 13 July 1974, Botham scored his first half-century in first-class cricket. He made 59 in Somerset's first innings against Middlesex at Taunton, the highest individual score in a low-scoring match which Somerset won by 73 runs. Middlesex's captain was Mike Brearley, who would become a very influential figure in Botham's career. A month later, in a match against Leicestershire at Clarence Park, Weston-super-Mare, Botham achieved his first-ever five wickets in an innings (5wI) with five for 59. He took seven in the match which Somerset won by 179 runs, largely thanks to Close who scored 59 and 114*.

Botham showed great promise in 1974, his first full season in which Somerset finished fifth in the County Championship and a close second to Leicestershire in the JPL. They also reached the semi-finals in both the Gillette Cup and the B&H Cup. In 18 first-class appearances, Botham scored 441 runs with a highest of 59, took 30 first-class wickets with a best of five for 59 and held 15 catches. He played in 18 List A matches too, scoring 222 runs with a highest of 45* (his Gold Award innings against Hampshire), took 12 wickets with a best of two for 16 and held four catches.

Botham continued to make progress in 1975. Somerset struggled in the County Championship, winning only four of their twenty matches and finished joint 12th. In the JPL, they slumped badly from second to 14th. They reached the quarter-final of the B&H Cup but only the second round of the Gillette Cup. Botham played in 22 first-class and 23 List A matches so it was a busy season for him. In first-class, he scored 584 runs with a highest of 65, one of two half-centuries, and held 18 catches. He took 62 wickets, doubling his 1974 tally, with a best of five for 69, his only 5wI that season. In List A, he scored 232 runs with a highest of 38* and held seven catches. He took 32 wickets with a best of three for 34.

1976 was a significant season for Botham as he scored over 1,000 runs for the first time, completed his first century and earned international selection by England in two Limited Overs Internationals. Somerset improved in the County Championship to finish seventh, winning seven matches. They were one of five teams tied for first place in the JPL but their run rate was less than that of Kent, who were declared the champions. Somerset lost their opening match in the Gillette Cup and were eliminated at the group stage of the B&H Cup. Botham, though, came on in leaps and bounds. He totalled 1,022 first-class runs in 20 matches with a highest of 167*, his first-ever century and he also scored six half-centuries. With the ball, he took 66 wickets with a best of six for 16. He had four 5wI and, for the first time, ten wickets in a match (10wM). He played in a total of 22 List A matches, including the two for England, scoring 395 runs with a highest of 46. He took 33 wickets with a best of four for 41.

In the County Championship match against Sussex at Hove in May, Botham came very close to his maiden century but was dismissed for 97, his highest score to date. The match was drawn. At the end of the month, Somerset played Gloucestershire in a remarkable match at Taunton. Batting first, Somerset scored 333 for seven (innings closed) and then, thanks to six for 25 by Botham, bowled out Gloucestershire for only 79. The follow-on was enforced but Gloucestershire proved a much tougher nut to crack second time around. With Zaheer Abbas scoring 141, they made 372 and left Somerset needing 118 to win. Botham took five for 125 in the second innings for a match analysis of 11 for 150, his maiden 10wM. This match ended the same way as the famous Test at Headingley in 1981 but the boot was on the other foot for Botham here because he was on the team that enforced the follow-on – and lost. Mike Procter and Tony Brown did the damage and bowled Somerset out for 110 in 42 overs, Gloucestershire winning by just eight runs.

Botham scored his maiden first-class century at Trent Bridge on Tuesday 3 August 1976 in the County Championship game against Nottinghamshire (Notts) who won the toss and decided to bat first. Derek Randall scored 204* and the Notts innings closed at 364 for 4 (Botham one for 59). Somerset were 52 for one at close of play. On day two, Somerset scored 304 for 8 (innings closed) and Botham, batting at number six, scored 80. At close of play, Notts in their second innings were 107 for four, thus extending their lead to 167 with six wickets standing. On day three, Notts advanced to 240 for nine declared (Botham one for 16), leaving Somerset with a difficult target of 301. At 40 for two and with both their openers gone, Brian Close changed his batting order and summoned Botham to come in at number four. Close himself had gone in at three but he was out soon afterwards for 35. With support from Graham Burgess (78), Botham laid into the Notts bowling and scored an impressive 167 not out. Somerset reached 302 for four in only 65 overs and won by six wickets.

Botham's international début for England was on 26 August 1976 in a Limited Overs International (LOI) against the West Indies at the North Marine Road Ground, Scarborough. The series was called the Prudential Trophy and the teams had 55 overs each per innings. Botham, still only 20, was the youngest player. At Scarborough, England captain Alan Knott lost the toss and Clive Lloyd, captaining the West Indies, elected to field first. Botham was number seven in the batting order and came in at 136 for five to join Graham Barlow. He scored only one before he was caught by Roy Fredericks off the bowling of his future "Sky Sports" colleague Michael Holding. England's innings closed at 202 for eight with Barlow 80 not out. West Indies lost Fredericks almost immediately but that brought Viv Richards to the crease and he hit 119 not out, winning the man of the match award, and leading West Indies to victory in only 41 overs by six wickets. Botham had the consolation of taking his first international wicket when he had Lawrence Rowe caught by Mike Hendrick for 10. He bowled only three overs and took some punishment from Richards, his return being one for 26.

In the second match at Lord's, Botham was replaced by returning England captain Tony Greig. England lost by 36 runs as Richards, this time with 97, was again the difference between the teams. Having lost the series, England recalled Botham for the final match at Edgbaston on 30–31 August. The match was extended to two days and overs reduced to 32 per side. Tony Greig won the toss and decided to field. England began well and dismissed Fredericks and Richards, for a duck, in only the second over. West Indies were then seven for one but a powerful innings by Clive Lloyd pulled them out of trouble and they reached 223 for nine, innings closed. Botham bowled three very expensive overs, conceding 31 runs, but he did manage to bowl out Michael Holding for his second international wicket. England were never in the hunt and were bowled out for 173, West Indies winning by 50 runs and claiming the series 3–0. Botham again batted at number seven and made a good start, scoring 20 at a run a ball, but he was then caught by Bernard Julien off Fredericks and England were 151 for seven with only Knott and the tailenders left.

In the winter of 1976–77, after he had made his first two international appearances, Botham played District Cricket in Melbourne, Australia for the University of Melbourne Cricket Club. He was joined by Yorkshire's Graham Stevenson. They were signed for the second half of the season on a sponsorship arranged through the Test and County Cricket Board (TCCB) by Whitbread's Brewery. Five of the competition's 15 rounds were abandoned because of adverse weather. It was apparently on this trip that Botham originally fell out with the former Australian captain Ian Chappell. The cause seems to have been a cricket-related argument in a bar, which may have resulted in Chappell being pushed off his stool (the story is widely sourced but accounts differ). This became a long-running feud and, as late as the 2010–11 Ashes series, there was an altercation between Botham and Chappell in a car park at the Adelaide Oval.

Botham produced a number of good batting and bowling performances for Somerset in 1977 and these impressed the Test selectors who included him in the team for the third Test against Australia at Trent Bridge, starting on 28 July. Having captured 36 first-class wickets through May and June, Botham had something of a purple patch in July which earned him his Test call-up. In the match against Sussex at Hove, which Somerset won by an innings and 37 runs, he took four for 111 and six for 50 for his second 10wM. In Somerset's innings of 448 for eight, he shared a 4th wicket partnership of 174 with Viv Richards. Botham scored 62, Richards 204. He took 22 more wickets, including two 5wI, in the next three County Championship games before his Test debut. In the whole season, playing 17 first-class matches, he took 88 wickets with six 5wI and one 10wM, his second innings return at Hove being his best. His batting was not quite as good as in 1976 as his average was down but he scored 738 runs with a highest of 114, which was his sole century, and five half-centuries. He scored the century in July against Hampshire at Taunton, 114 in Somerset's first innings of 284, and followed it with bowling returns of four for 69 and four for 43, another impressive all-round effort which earned Somerset a win by 152 runs. Somerset had a good season in the County Championship, finishing fourth. They reached the semi-final of the Gillette Cup but, without the injured Botham, were well beaten by eventual winners Middlesex. They were a poor tenth in the JPL and were eliminated from the B&H Cup at the group stage.

Botham made his Test début at Trent Bridge on 28 July 1977 in the third Test against Australia. His début was somewhat overshadowed by the return from self-imposed Test exile of Geoffrey Boycott. England went into the match with a 1–0 series lead having won the second Test after the first had been drawn. The series was played against the background of the so-called "Packer Affair" which resulted in the establishment of World Series Cricket in the next Australian season. Because of Tony Greig's involvement, he had been stripped of the England captaincy but remained in the team under new captain Mike Brearley. England had three all-rounders at Trent Bridge with Greig, Geoff Miller and Botham all playing. Australian captain Greg Chappell won the toss and decided to bat first. Australia scored 243 and were all out shortly before the close on day one. Botham, aged 21, made an immediate impact and took five for 74, the highlight being the wicket of Chappell, bowled for just 19. England batted all through day two and into day three as Boycott, in his first Test innings since 1974, and Knott both made centuries. Botham came in at number eight on day three and scored 25 before he was bowled by Max Walker. England were all out not long afterwards for 364, a first innings lead of 121. Botham had no joy in Australia's second innings with none for 60. A century by Rick McCosker enabled Australia to score 309 before they were all out in the evening session on day four. Bob Willis took five for 88. England needed 189 to win and completed the job, by seven wickets, well into the final day with Brearley scoring 81 and Boycott, who batted on all five days, 80 not out. Botham didn't get a second innings.

Botham's impressive bowling at Trent Bridge meant he was an automatic choice for the fourth Test at Headingley two weeks later. England won the toss, decided to bat first and went on to win by an innings and 85 runs to secure a winning 3–0 lead in the series and regain The Ashes, which they had lost in 1974–75. The match is famous for Boycott's one hundredth career century, scored on his home county ground and in his second Test since his return to the England fold. Botham was bowled third ball by Ray Bright without scoring. He made amends with the ball by taking five for 21 in only eleven overs, Australia being bowled out for only 103. The follow-on was enforced and Australia this time made 248, but Botham (none for 47) did not take a wicket. He was injured during the second innings when he accidentally trod on the ball and broke a bone in his foot. He was unable to play again in the 1977 season.

His promising start as Test player resulted in two awards. He was named Young Cricketer of the Year for 1977 by the Cricket Writers' Club; and was selected as one of the "Wisden Cricketers of the Year" (i.e., for 1977 but announced in the 1978 edition). "Wisden" commented that his 1977 season "was marred only by a week's cricket idleness carrying the drinks at the Prudential matches, and a foot injury which ruined for him the end of the season and probably robbed him of a rare double. He finished with 88 wickets and 738 runs". Importantly, the foot injury was a broken toe sustained when he trod on the ball at Headingley and Botham subsequently needed treatment for it at his local hospital in Taunton. It was while going to one of his appointments that he took a wrong turn and ended up on a children's ward where he learned that some of the children were dying of leukaemia. This incident sparked his charitable crusade on behalf of leukaemia research.

England were in Pakistan from November 1977 to January 1978, playing three Tests and three LOIs. Botham was almost fully recovered from his foot injury but did not play in any of the Tests. He took part in all three LOIs and in some of the first-class matches against club teams. From January to March, England were in New Zealand for a three-match Test series under the captaincy of Geoff Boycott. Botham impressed in a first-class match against Canterbury at Lancaster Park, scoring 126 not out in the second innings against an attack including Richard Hadlee and was selected for the first Test at Basin Reserve. Botham had an indifferent game there and England, twice bowled out by Hadlee, lost by 72 runs. In the next match at Carisbrook against Otago, Botham achieved a 10wM with seven for 58 (his career best return to date) in the second innings, enabling the England XI to win by six wickets. England won the second Test at Lancaster Park by 174 runs after an outstanding all-round performance by Botham who scored 103 and 30 not out and took five for 73 and three for 38. He also held three catches. In the second innings, promoted up the order to get quick runs before an overnight declaration, he was responsible for calling for a risky run that led to the run-out dismissal of acting-captain Geoff Boycott: Botham's own published autobiography alleges that this was deliberately done, on the orders of acting vice-captain Bob Willis, because Boycott was scoring too slowly. The final Test was played at Eden Park and was drawn, the series ending 1–1. New Zealand batted first and totalled 315 with Geoff Howarth scoring 122. Botham took five for 109 in 34 overs. England replied with 429 all out (Clive Radley 158, Botham 53). New Zealand then chose to bat out time and Howarth scored his second century of the match (Botham none for 51). Botham's form in New Zealand cemented his place in the England team.

In the 1978 English season, Pakistan and New Zealand both visited to play three Tests each and Botham featured in all six matches. Having scored exactly 100 in the first Test against Pakistan at Edgbaston, England winning by an innings and 57 runs, Botham in the second at Lord's scored 108 and then, after none for 17 in the first innings, achieved his Test and first-class career best return of eight for 34 in the second, England winning by an innings and 120 runs. The third Test was ruined by the weather and England won the series 2–0. Against New Zealand, Botham did little with the bat but his bowling was outstanding. In the second Test he took nine wickets in the match as England won by an innings and then a 10wM in the final match at Lord's with six for 101 and five for 39. England won the series 3–0.

Due to his England commitments, Botham appeared infrequently for Somerset in 1978. His best performances for them were a return of seven for 61 against Glamorgan and an innings of 80 against Sussex in the Gillette Cup final at Lord's. This was Somerset's first limited overs final and they lost by five wickets despite Botham's effort. They were involved in a tight contest for the JPL title and were placed second on run rate after tying with Hampshire and Leicestershire on 48 points each. Somerset did quite well in the County Championship, finishing fifth after winning nine matches, and reached the semi-final of the B&H Cup.

Botham's first tour of Australia was in 1978–79. England, defending the Ashes they had regained in 1977, played six Tests under Mike Brearley's leadership. Australia had what was effectively "a reserve team" because their leading players were contracted to World Series Cricket for the season. The difference in standard was evident on the first day of the first Test at the Gabba as Botham, Chris Old and Bob Willis bowled them out for only 116 in just 38 overs, England going on to win easily enough by seven wickets. Apart from a surprise defeat in the third Test, England were never troubled and won the series 5–1. Botham's performance in the series was satisfactory but there were no headlines and only modest averages. He took 23 wickets at 24.65 with a best return of four for 42. He scored 291 runs with a highest of 74 at 29.10. He held 11 catches.

Botham played for England in the 1979 Cricket World Cup and was a member of their losing team in the final. He was again an infrequent member of the Somerset team because of the World Cup and the Test series against India. It became a memorable season for Somerset as they built on their form in 1978 to win both the Gillette Cup and the JPL, their first-ever senior trophies. Botham played in the Gillette Cup final at Lord's, in which they defeated Northamptonshire by 45 runs, thanks to a century by Viv Richards. They slipped to eighth in the County Championship. In the B&H Cup, however, they were expelled from the competition for bringing the game into disrepute after an unsporting declaration, designed to protect the team's run rate, by team captain Brian Rose.

The England v India series in 1979 took place after the World Cup ended and four Tests were played. England won the first at Edgbaston by an innings and 83 runs after opening with a massive total of 633 for five declared. Botham scored 33 and then took two for 86 and five for 70. On the first day of the second Test at Lord's, Botham swept through the Indian batting with five for 35 and a catch off Mike Hendrick to dismiss them for only 96 in 56 overs. Surprisingly, however, India recovered to salvage a draw. In the third Test at Headingley, it was Botham the batsman who did the business, scoring 137 from 152 balls in England's first innings total of 270 (the next highest innings was 31 by Geoff Boycott). The match was ruined by the weather and was drawn. In the final Test at The Oval, England opened with 305 (Botham 38); India replied with 202 (Botham four for 65); and England with 334 for eight declared (Botham run out for a duck) extended their lead to 437 with four sessions remaining. Thanks to a brilliant 221 by Sunil Gavaskar, India came agonisingly close to pulling off a remarkable last day victory but ran out of time on 429 for eight (Botham three for 97), just nine runs short, and so England won the series 1–0 with three draws.

The shambolic state of international cricket at the end of the 1970s was illustrated by the panic resulting from a hastily convened settlement between World Series Cricket and the Australian Board of Control. Although they had visited Australia only twelve months earlier to play for the Ashes, England were persuaded to go there again and play another three Tests, but with the Ashes not at stake. As "Wisden" put it, the programme did not have the best interests of cricket at heart, particularly Australian cricket below Test level, which had been "swamped by the accent on Test and one-day internationals, neatly parcelled to present a cricketing package suitable for maximum exploitation on television". The matches were widely perceived to be semi-official only and received "a definite thumbs down". Botham was a member of the England team and played in all three matches which, rightly or wrongly, count towards his Test statistics. England were largely faithful to the players who had toured Australia the previous winter and Derek Underwood was the only World Series player they recalled; they did not recall Alan Knott, for example, while Tony Greig was beyond the pale. Australia recalled Greg Chappell, Dennis Lillee, Rod Marsh and Jeff Thomson, fielding a team that was a mixture of old and new. In the first match, played at the WACA Ground, Botham had match figures of eleven for 176 but to no avail as Australia won by 138 runs. Having excelled with the ball in that match, Botham did so with his bat in the third one, scoring an unbeaten 119 in the second innings of the third. Australia won all three matches of a series best forgotten for all its attendant politics, but Botham had enhanced his reputation as a world-class all-rounder.

Botham's third overseas tour was to India in February 1980. It was the fiftieth anniversary of India's entry into Test cricket and so England played a single commemorative Test at the Wankhede Stadium in Bombay. It turned into a personal triumph for Botham who became the first player in Test history to score a century and take ten wickets in the same match. England's wicketkeeper Bob Taylor held ten catches in the match, eight of them off Botham's bowling.

India won the toss and decided to bat first but, with Botham taking six for 58, they were all out on day one for 242. England replied with 296, the highlight being Botham's 114 from just 144 balls; he began his innings with England in trouble at 57 for four. This quickly became 58 for five and Botham was joined by England's other match hero Taylor. England's first five batsmen had contributed just 51 to the total. Botham was often unfairly labelled a "big hitter" but in fact his style was very orthodox (i.e., he "played straight") and in this innings he scored 17 fours but, significantly, no sixes. Taylor provided dogged support and their sixth wicket partnership realised 171 runs. When Botham was out near the end of day two, the score was 229 for six and England reached 232 for six at close of play, still ten runs behind. On the third morning, Taylor led England past India's total and, with useful batting performances by the specialist bowlers, England totalled 296 to gain a first innings lead of 54.

India's second innings was a disaster and they lost eight wickets by the close of play on the third day with only Kapil Dev offering any resistance. They were all out early on the fourth day for 149. Botham was the outstanding performer again, taking seven for 48 which gave him match figures of thirteen for 106. Geoffrey Boycott and Graham Gooch scored the necessary runs for England to win by ten wickets with a day to spare.

Mike Brearley announced his retirement from Test cricket after the Jubilee Test in Bombay and, somewhat surprisingly given his lack of captaincy experience, Botham was appointed to replace him as England's captain for the forthcoming home series against West Indies, who were at the time the world's outstanding team. Botham led England in twelve Tests in 1980 and 1981 but he was unsuccessful, the team achieving no wins, eight draws and four defeats under his leadership. In addition, his form suffered and was eventually dismissed from the post, although he did actually resign just before the selectors were about to fire him. In Botham's defence, nine of his matches as captain were against West Indies, who afterwards won twelve of their next thirteen Tests against England. The other three were all against Australia.

In 1980, which was a wet summer, West Indies arguably had the better of all five Test matches, although, with the rain constantly intervening, they were able to win only one of them. Ironically it was the one which they came closest to losing, West Indies winning the first Test by only two wickets, and being at one stage 180/7 chasing a tricky 208. Rain saved England from a probable heavy defeat in the 2nd and 5th Tests: they fared better in between. In the 3rd, England conceded a first-innings lead of 110, but replied strongly in the second innings with a painstakingly slow and defensive 391/7, which would have resulted in a difficult target for the Windies had there been another day to chase it - but the third day had been rained off, and time ran out. In the Fourth Test, England picked up their only first-innings lead of the series - of 105 runs - but collapsed catastrophically in the second, before being saved by a century partnership for the last wicket between Willey (100*) and Willis (24*) to reach a total 201/9, and again the loss of a day and a half to rain left no time for the Windies to chase a potentially tough target above 300. Botham had a poor season as a bowler and, in all first-class cricket, took just 40 wickets at the high average of 34.67 with a best return of only four for 38. He did better as a batsman, scoring 1,149 runs (the second time, after 1976, that he topped a thousand in a season) at 42.55: but this did not translate to form in the Tests. He completed two centuries and six other half-centuries for his county. His highest score in the season was ultimately the highest of his career: 228 for Somerset against Gloucestershire at Taunton in May. He batted for just over three hours, hitting 27 fours and ten sixes. With Gloucestershire batting out time for a draw on the final day, Somerset used all eleven players as bowlers. Apart from an innings of 57 in the first Test, Botham contributed little to England in the series and that innings was the only time he reached 50 in all his twelve Tests as England captain.

Somerset came close to retaining their JPL title in 1980 but had to be content with second place, only two points behind Warwickshire. They finished a credible fifth in the County Championship but were eliminated from both the Gillette and B&H Cups in the opening phase.

Botham led England on the controversial tour of the West Indies from January to April 1981. The second Test, scheduled to be played at Bourda, was cancelled after the Guyanese government revoking the visa of Robin Jackman because of his playing and coaching links with South Africa. The other four Tests were played and West Indies won the series 2–0 but England were helped by rain in the two drawn matches. Botham took the most wickets for England, but "Wisden" said "his bowling never recovered the full rhythm of a year before". His batting, however, apart from one good LOI performance in the first one-day international "was found wanting in technique, concentration and eventually in confidence". In "Wisden's" view, Botham's loss of form "could be cited as eloquent evidence of the undesirability of saddling a fast bowler and vital all-rounder with the extra burden of captaincy".. The closest England came to a victory was in the first ODI, in which England bowled the West Indies out for 127 but, thanks to six wickets from Colin Croft, failed by two runs in the chase which was anchored by Botham's 60: this was, at the time, the lowest ODI total batting first to be successfully defended.

The England captaincy had affected Botham's form as a player and in his last Test as captain, against Australia at Lord's in 1981, he was dismissed for a pair. According to "Wisden" editor Matthew Engel, writing in "ESPNcricinfo", Botham "resigned (a minute before being sacked), his form shot to pieces" after that match. Australia were then leading the series 1–0 after two Tests with four more to be played. Botham was replaced by the returning Mike Brearley, who had been his predecessor until retiring from Test cricket in 1980.

Botham continued to play for England under Brearley and achieved the highpoint of his career in the next three Tests as England recovered to win The Ashes. In the third Test at Headingley, Australia opened with 401 for 9 declared, despite good bowling by Botham who took 6 for 95. England responded poorly and were dismissed for 174. Botham was the only batsman to perform at all well and scored 50, which was his first Test half-century since he had been awarded the captaincy thirteen Tests earlier. Having been forced to follow-on, England collapsed again and at 135 for 7 on the afternoon of the fourth day, an innings defeat looked certain. Bookmakers had reportedly been offering odds of 500/1 against an England win after the follow-on was enforced. Botham, himself not long at the wicket, was the remaining recognised batsman as he was joined by the fast bowler Graham Dilley, number nine in the batting order, with only Chris Old and Bob Willis to come. With able support from Dilley (56) and Old (29), Botham hit out and by the close of play was 145 not out with Willis hanging on at the other end on 1 not out. England's lead was just 124 but there remained a glimmer of hope. On the final day's play, there was time for four more runs from Botham before Willis was out and Botham was left on 149 not out. Australia, with plenty of time remaining, needed 130 to win and were generally expected to get them. After Botham took the first wicket, Willis took 8 for 43 to dismiss Australia for only 111. England had won by 18 runs and it was only the second time in history that a team following on had won a Test match.

Botham's outstanding form continued through the next two Tests. In the fourth at Edgbaston, a low-scoring match left Australia batting last and needing 151 to win. They reached 105 for 5 and were still favourites at that point but, in an inspired spell of bowling, Botham then took five wickets for only one run in 28 balls to give England victory by 29 runs. In the fifth Test at Old Trafford, Botham scored 118 in a partnership of 149 with Chris Tavaré before he was dismissed. He hit six sixes in that innings. England won that match to take a winning 3–1 series lead. The last Test at The Oval was drawn, Botham achieving a 10wM by taking six for 125 and four for 128. He was named Man of the Series after scoring 399 runs, taking 34 wickets and holding 12 catches.

Somerset won the Benson & Hedges Cup for the first time in 1981 and did well in the County Championship too, finishing third. They were again runners-up in the JPL but a long way behind the winners Essex. In the renamed NatWest Trophy (formerly Gillette Cup), Somerset were knocked out in the second round. Botham played in the B&H final at Lord's, in which Somerset defeated Surrey by seven wickets. He took no wickets but provided Viv Richards (132 not out) with good support in the run chase. Botham ended the season with 67 wickets at 25.55, a best return of six for 90 (for Somerset v Sussex) and one 10wM (sixth Test). He scored 925 runs with a highest of 149* (third Test) at 42.04; and held 19 catches.

During this period, Botham played in 25 Tests. There were home series against both India and Pakistan in 1982; and New Zealand in 1983. His overseas tours were to India and Sri Lanka in 1981–82 (he took part in the inaugural Test played by Sri Lanka); to Australia in 1982–83; and to New Zealand and Pakistan in 1983–84. He played for England in the 1983 Cricket World Cup and was a member of their losing team in the semi-final.

Botham's return to India was less than triumphant and "Wisden" took him to task for his "ineffectiveness with the ball". Having achieved a match analysis of nine for 133 at Bombay, where England were beaten on a poor pitch, Botham took only eight more wickets, at 65 each, in the last five Tests and "Wisden" said this "was a telling blow to England's chance of levelling the series".

1982 was a good all-round season for Botham, especially as Somerset retained the Benson & Hedges Cup. In 17 first-class matches, he scored 1,241 runs with a highest of 208 against India (this was ultimately his career highest in Test cricket) at a good average of 44.32. He took 66 wickets at the low average of 22.98 with a best return of five for 46. England won their Test series against Pakistan by 2–1 and the one against India 1–0. Botham scored two centuries against India: 128 at Old Trafford and his career high 208 at The Oval. Somerset finished sixth and ninth in the County Championship and the JPL respectively. They reached the quarter-final of the NatWest Trophy and their season highlight was retaining the B&H Cup they won in 1981. In the final at Lord's, Somerset dismissed Nottinghamshire for only 130 (Botham two for 19)and won easily by nine wickets.

Botham toured Australia again in 1982–83 with England seeking to retain the Ashes, but Australia won the series 2–1 despite England winning, at the Melbourne Cricket Ground (MCG), a Test described by "Wisden" as "one of the most exciting Test matches ever played". Botham had a poor series and tour. He played in nine first-class matches and scored only 434 runs at the low average of 24.11 with a highest of 65. He was no better with the ball, taking just 29 wickets for a too-high 35.62 with a best return of four for 43. He did, however, field well and held 17 catches, nearly two a match.
In the 1983 English season, Somerset won the NatWest Trophy for the first time, defeating Kent in the Lord's final by 24 runs with Botham as their captain. They were very close to taking the JPL title too but, having tied with Yorkshire on 46 points, they were placed second on run rate. In the County Championship, they won only three matches and finished tenth. They were knocked out of the B&H Cup early. Botham had a good season with the bat, scoring 852 runs in his 14 first-class matches at 40.57 with a highest score of 152 among three centuries. He did less well with the ball: only 22 wickets at the high average of 33.09. New Zealand played a four-match Test series against England after the World Cup and, at the 29th attempt, finally defeated England for the first time in a Test match in England. England won the other three matches convincingly, however, to take the series 3–1. Botham did little with the ball, the same story as in his whole season, but he did score a century (103) in the final Test at Trent Bridge (see photo).

In the winter of 1983–84, England toured New Zealand from January to February and Pakistan in March. Apart from one innings at Basin Reserve in the first Test against New Zealand, Botham was a disappointment on this tour, especially as a bowler. He scored 138 in the first Test, sharing in a sixth wicket partnership of 232 with Derek Randall (164), but the match was drawn. It was a poor tour for England, all told, and described by "Wisden" as "ranking among the unhappiest they have ever undertaken". England lost both series 1–0. Botham left Pakistan after the first Test there, the one England lost, to have a knee problem investigated at home.

After ten seasons as a first-team regular, Botham was appointed Somerset club captain in 1984 and 1985. In the County Championship, they finished seventh in 1984 and then dropped to 17th (bottom of the table) in 1985. In the JPL, they were 15th in 1984 and eleventh in 1985. They made little impression in either of the B&H Cup or the NatWest Trophy so, all in all, Botham's captaincy period was a lean time for the club who had enjoyed its most successful period ever in the preceding seasons.

Botham played in 18 Tests from 1984 to 1986, ten of them (five home, five away) against West Indies. Throughout Botham's Test career, the highest international standards were set by West Indies and Botham was generally unsuccessful against them. In both of these series, 1984 and 1985–86, West Indies beat England 5–0 in whitewashes that were dubbed "blackwash". 

Ironically, his highest score and both his best and worst bowling performances against West Indies occurred in the same match at Lord's in 1984. Clive Lloyd won the toss and, perhaps mistakenly, elected to field. The first day was rain-affected and England, 167 for two overnight, scored 286 thanks to a century by Graeme Fowler; Botham scored a useful 30. West Indies lost three quick wickets, all of them to Botham who was a "reminder of his old self" in the words of "Wisden", but recovered to reach 119 for three at the close of play on day two. In the third morning, Viv Richards was dismissed by Botham under dubious circumstances but Botham was inspired by the capture of his great friend's wicket and went on to take eight for 103, dismissing West Indies for 245 and for once giving England a chance of victory against the world's best team, with a first innings lead of 41. This was Botham's best-ever bowling performance against West Indies by some distance. England began their second innings and had been reduced to 88 for four when Botham joined Allan Lamb. They reached 114 for four at day three close. There was no Sunday play and England resumed on the Monday 155 runs ahead with six wickets standing. Botham and Lamb added 128 for the fifth wicket before Botham was out for 81, including nine fours and one six, easily his highest score and best innings against West Indies. Lamb made a century and England were all out on the Tuesday morning (final day) for exactly 300. West Indies needed 342 to win in five and a half hours. They lost Desmond Haynes to a run out at 57 for 0, whereupon Larry Gomes (92 not out) joined Gordon Greenidge (214 not out) and West Indies went on to win by nine wickets with 11.5 of the last twenty overs to spare. Although "Wisden" does not name Botham except as an "inattentive" fielder who dropped a catch, it describes the England bowlers "looking second-rate and nobody but Willis bowling the right line or setting the right field to the powerful and phlegmatic Greenidge". Botham bowled the most overs, 20, and with nought for 117 he conceded almost a run a ball (Willis had nought for 48 from 15 overs). In mitigation, "Wisden" conceded that Greenidge played "the innings of his life, and his ruthless batting probably made the bowling look worse that it was".

He also played in the one-off Test against Sri Lanka: not bowling particularly well in the first innings although he took the first wicket (1/114 out of 491), and being dismissed for 6 as England batted (370). Toward the end of Sri Lanka's second innings as the match meandered to a draw, in absolutely ferocious heat Botham dispensed with his usual fast bowler's long run-up and switched to bowling off-spin off a few paces, surprising everybody (himself included) by taking several wickets with it, out of an analysis of 6/90. He decided to take a rest over the winter, and sit out of the 1984-85 tour of India.

In 1985, Botham played in all six Tests against a poor Australian team as England, themselves a second-rate team based on their recent performances, comfortably regained the Ashes and he was the leading wicket-taker, but the series was dominated by England's specialist batsmen, especially Mike Gatting and David Gower. Botham, who by this time had adopted a dyed blonde mullet haircut as a trademark, contributed relatively little with the bat, compared with the massive totals amassed by Gower, Gatting, Graham Gooch and Tim Robinson. He scored 250 runs at 31.25 with a highest of 85. He did take the most wickets (31 at 27.58 with a best of five for 109) but he was rarely impressive and he was bowling to a weak batting side, Allan Border apart. England's best bowler was Richard Ellison who played only twice and took 17 wickets at only 10.88 with a best of six for 77 and one 10wM.

Botham was suspended for 63 days by the England and Wales Cricket Board in 1986 after he admitted in an interview that he had smoked cannabis. Due to the ban, Botham played in only one Test which was the final one of the series against New Zealand. He made his mark on that Test though: beginning it by taking the wicket of Bruce Edgar with his very first delivery, to go level with Dennis Lillee on 355 as holder of the world record for Test wickets. The next delivery was edged through the slip cordon by Jeff Crowe. Botham went past the mark in his second over to hold the record outright, by trapping Crowe leg-before. Then on the fourth day of the match, coming in after centuries from Gatting and Gower, he bashed a quickfire half-century in just 32 balls, including 24 off one over from Derek Stirling - equalling the record at the time, for most runs off a single over in Tests... a record which he himself was responsible for, but from the other side, having conceded 24 runs to Andy Roberts back in the 1980/81 tour of the West Indies. England declared with a massive first-innings lead, but rain came after lunch on the fourth day and only one further over was bowled.

Botham was succeeded by Peter Roebuck as Somerset captain for 1986 but, during the season, tensions arose in the Somerset dressing room which eventually exploded into a full-scale row and resulted in the sacking by the club of Botham's friends Viv Richards and Joel Garner. Botham, who supported Richards and Garner, decided to resign at the end of the season. 1986 was not a season for Botham to remember except for one brilliant List A innings when he made his career highest score in the limited overs form of 175 not out for Somerset against Northamptonshire in a 39-over JPL match at the Wellingborough School ground. It was to no avail, however, as the weather intervened and the game ended in no result. His innings remains a ground record.

Botham's final tour of Australia was in 1986–87 under Mike Gatting's captaincy. He played in four Tests and England won the Ashes for the last time until 2005. In many ways, the series was also Botham's last hurrah because he scored his final Test century (138 in the first Test at Brisbane which England won by seven wickets) and took his final Test 5wI (five for 41 in the fourth Test at the MCG which England won by an innings and 14 runs). "Wisden" pointed out that although Botham had a modest series statistically, "he was an asset to the side" because of his enthusiasm and "going out of his way to encourage younger players, especially Phil DeFreitas". Unfortunately he suffered a severe rib injury in the Second Test in Perth, which kept him out of the 3rd Test entirely and reduced the pace of his bowling for the remainder of the tour as he tried to manage it: as a result, with reasonable success, he changed his bowling style to a defensive, miserly military-medium pace. England also won the two one-day tournaments, the one-off Benson & Hedges Perth Challenge (against Australia, West Indies and Pakistan) and the World Series (against Australia and Windies): Botham produced several match-winning performances with both bat and ball despite being not fully fit, and was Man of the Match in both matches of the best-of-three final of the World Series - with the bat in the first, opening the batting for 71 (scored out of 91 while he was at the crease), and with the ball in the second, for a particularly miserly spell which also took three wickets as England defended a low total by nine runs, to win the finals 2-0. It was also in this tournament that England tried the experiment of having Botham open the batting in ODIs, with the idea of hitting the ball over the top to counter the fielding restrictions which forced most of the fielders to be close to the bat inside the early overs.

After his resignation from Somerset, Botham joined Worcestershire for the 1987 season and spent five seasons with them. In 1987, he scored 126* against his old county but otherwise he was more successful as a limited overs batsman, scoring two centuries and averaging 40.94. His bowling too was much better in the shorter form, wherein he averaged 21.29 against 42.04 in first-class. His limited overs efforts helped Worcestershire to win the Sunday League. They finished ninth in the County Championship and were unsuccessful in the two knockout trophies. Worcestershire, taking a leaf from England's winter tactic, sometimes used Botham to open the batting in one-day matches, in partnership with regular opener Tim Curtis.

Botham played in the five 1987 Tests against Pakistan, the last time he represented England in a full series. He scored 232 runs in the series with one half-century (51*) at 33.14; and took only seven wickets which were enormously expensive. Pakistan won by an innings at Headingley with the other four Tests drawn, although England were in superior positions in the First and Fourth tests which lost much time to rain, and only narrowly failed to level the series in the Fourth, running out of overs chasing a small target. When Pakistan totalled 708 at The Oval, the 217 runs conceded by Botham, from 52 overs, were the most by an England bowler, passing the 204 by Ian Peebles, from 71 overs, against Australia at The Oval in 1930, although he took three wickets and also ran out Imran Khan. The half-century, his final and by far his slowest Test fifty, was a dogged, defensive effort occupying most of the last day in a drawn match, in an unbroken partnership with Gatting (150*) to save the 5th test and keep England's margin of defeat at 1-0. He declined to go on tour with England the following winter, either for the 1987 World Cup in India, Pakistan and Sri Lanka (in which England reached the final) or for the subsequent tours of Pakistan (lost 1-0) and New Zealand (a rain-ruined 0-0 drawn series).

Botham spent the 1987–88 Australian season with Queensland, playing for them in the Sheffield Shield. Queensland were one of the better state teams in the 1980s and were always in the Shield's top three from 1983–84 to 1990–91 but didn't win it. In Botham's season there, his teammates including Allan Border (captain), wicketkeeper Ian Healy and pace bowler Craig McDermott, they finished second to Western Australia. Botham scored several half-centuries and took a reasonable number of wickets and helped Queensland make the Sheffield Shield final. When the Queensland team flew to Perth for the final, Botham was involved in an altercation where he allegedly assaulted a fellow airline passenger who had intervened in an argument between the Queensland players. Queensland lost the final. Botham was fined $800 by a magistrate and $5,000 by the Australian Cricket Board. He was consequently sacked by Queensland.

Botham was unfit for most of the 1988 season and played in only four first-class and seven limited overs matches during April and May. He did not play for England. Nevertheless, Worcestershire won both the County Championship and the Sunday League. Botham was out of action for eleven months, having had an operation to fuse vertebrae in his spine in response to a long-standing back problem.

He returned in May 1989 and, bowling well in the County Championship, helped Worcestershire to a second successive title. With England struggling against Allan Border's rebuilt Australian team which featured the likes of Healy, McDermott, Steve Waugh, Merv Hughes and Mark Taylor, Botham was recalled for the third, fourth and fifth Tests of the pivotal Ashes 1989 series. He could do little to stem a tide which had now turned completely in Australia's favour and looked completely out of his depth. He scored only 62 runs at the very low average of 15.50 - two thirds of them in one innings - and took just three wickets at an enormously expensive 80.33.. The summer of 1989 saw more controversy for England with the organisation of a rebel tour to South Africa, all participants being banned for three years: Botham declined the rebel tour, hoping to be selected for the winter tour of the West Indies, only to be dropped for his poor form.

Another two-year absence from international cricket ensued until he was recalled again to play against West Indies in 1991, on the strength of belting 161* for Worcestershire against them in their early-season tour match against the county - it was to be his only century ever against the West Indies. He was selected for the early-season ODI series at first: he took a wicket in his first over, and four in his ten-over spell, but later tore a hamstring, going for a quick single while batting. He could have retired hurt, but opted to continue with a runner, only to be dismissed by the next delivery. The injury put him out of the remaining ODIs (both won by England) and the first couple of Tests (which England won and drew to lead 1-0): then, on his comeback in a county match, another injury caused him to be unavailable for the 3rd and 4th Tests (both lost by England). He was recalled for the 5th Test with England needing a victory to tie the series: batting in the first innings, he scored a respectable 31 before attempting to hook Curtly Ambrose and being dismissed "hit wicket", in circumstances which caused an infamous giggling fit in the TV commentary box. Used sparingly with the ball, he took 1/27 and 2/40 as West Indies were bowled out, forced to follow on and bowled out again, by Tufnell (6/25) and Lawrence (5/106) in the first and second innings respectively. His only Test victory against the Windies was completed when he himself hit the winning runs - a boundary off his first delivery - as England chased a target of 143 with five wickets to spare, and tied the series. Two weeks later, he played against Sri Lanka at Lord's, achieving little of note. He helped Worcestershire to win the B&H Cup for the only time in 1991.

Botham's final tour was to Australia and New Zealand in 1991–92. He played in the World Cup in Australia, and in the third Test and the ODIs in New Zealand. Botham did not win any man of the match awards in the World Cup until 1992 when he won two. Against India at the WACA Ground, he bowled tightly and restricted India, needing 237, to only 27 runs from his ten overs, an economy rate of 2.70 which was significantly lower than anyone else's. He captured two wickets and one of them was Sachin Tendulkar. England won by nine runs. Against Australia at Sydney Cricket Ground later in the competition, Botham won the award for the sort of all-round performance which had made his reputation. Australia won the toss and decided to bat first. They scored 171 all out in 49 overs and Botham took four for 31 in his ten. He then opened the England innings with Graham Gooch - the tactic England had trialled in Australia five years before, and again in the ODIs against NZ at the end of the tour before the World Cup - and scored 53 from only 77 balls in a partnership with Gooch of 107. England went on to win by eight wickets with nine overs to spare. He was less successful in the final, where previously economical bowling figures were ruined by a late assault from the Pakistani batting line-up, and then he was given out caught-behind for a duck (perhaps unfortunately, since he appeared not to have touched the ball according to the camera replays) in Aaqib Javed's first over, England losing the match.

In 1992, Botham joined County Championship newcomers Durham, scoring a century in the second innings in their inaugural first-class match against Leicestershire: and he played in the first two Tests against Pakistan, the second one at Lord's being his final Test appearance. Botham scored 2 and 6, cheaply dismissed each time by the pace of Waqar Younis. As a bowler, he was used for only five overs, his final Test return being none for nine. England lost the match by two wickets and Pakistan went on to win the series 2–1. Botham did however play in the ODI series, in all five matches, which England won 4-1: these were his last international matches. England's batting was so dominant in all but one of the matches, that Botham only came in right at the end of the innings, or not at all, reverting to his old place in the middle order, and he had little to do: except in the 4th match, where he opened the batting again (in Gooch's absence) and scored a respectable and workmanlike 40, but saw England lose their last four wickets for ten runs and the match by three runs. His bowling was similarly unremarkable, usually capturing one or two wickets at about four an over: he neither scored a run (did not bat) nor took a wicket (0-43) in his final match.

It was in 1992 that Botham was appointed an Officer of the Order of the British Empire (OBE) for services to cricket and for his charity work in the Queen's Birthday Honours.

Botham retired from cricket midway through the 1993 season, his last match being for Durham against the visiting Australians at The Racecourse 17–19 July 1993. Durham batted first and scored 385 for eight declared (Wayne Larkins 151). In his final first-class innings, Botham scored 32. In reply, Australia could only make 221, thanks to Simon Brown who took seven for 70 (Botham none for 21). Being 164 behind, Australia had to follow on and a victory for Durham was possible but centuries by Matthew Hayden and David Boon saved Australia and the match was drawn. Botham's final bowling return was none for 45 from eleven overs. In the final over of the game, Botham also kept wicket, without wearing gloves or pads.

Botham's Test career spanned 16 seasons and he played in 102 matches. He scored 5,200 runs at an average of 33.54 with a highest score of 208 in his 14 centuries. He took 383 wickets at an average of 28.40 with a best return of eight for 34 and achieved ten wickets in a match four times. He held 120 catches.

In 116 LOIs from 1976 to 1992, he scored 2,113 runs with a highest score of 79; took 145 wickets with a best return of four for 31; and held 36 catches. A straight comparison of these totals with those of his Test career reveal that he was less effective in the limited overs form of the game. He did have some outstanding LOI matches, however, winning six man of the match awards. Botham took part in three editions of the Cricket World Cup: 1979, 1983 and 1992. He played in 22 World Cup matches including the finals in 1979 and 1992, both of which England lost, and he was in England's losing team in the 1983 semi-final.

Botham was the 21st player to achieve the "double" of 1,000 runs and 100 wickets in Test cricket and he went on to score 5,200 runs and take 383 wickets, as well as holding 120 catches.

He held the world record for the greatest number of Test wickets from 21 August 1986 to 12 November 1988. His predecessor was Dennis Lillee who had retired with 355 wickets in 70 matches. Botham extended the record to 373 in 94 matches before he was overtaken by Richard Hadlee. Botham ended with 383 wickets in 102 matches while Hadlee extended the record to 431 in 86 matches. See List of Test cricket records#Career.

As described above, Botham in 1980 became the second player to achieve the "match double" of 100 runs and ten wickets in Test cricket, following Alan Davidson in 1960–61. Botham was, however, the first to score a century and take ten wickets in a Test match (Davidson scored 44 and 80). The century and ten double has since been achieved by Imran Khan who scored 117 and took six for 98 and five for 82 against India at the Iqbal Stadium in Faisalabad in January 1983.

Compared with many of cricket's greatest players, most of whom were specialists, Botham's averages seem fairly ordinary but this overlooks the fact that he was a genuine all-rounder and it is rare for this type of player to achieve world-class status. Since the Second World War, Botham is one of perhaps a dozen or so world-class all-rounders whereas there have been numerous world-class specialists. Some of the great all-rounders, such as Garfield Sobers and Jacques Kallis as batsmen or Alan Davidson and Richard Hadlee as bowlers, could justifiably be described as world-class specialists in their main discipline who were effective practitioners of the other. The genuine all-rounders to achieve world-class status during the era, besides Botham himself, have included Keith Miller, Richie Benaud, Mike Procter, Clive Rice, Imran Khan, Kapil Dev and Andrew Flintoff.

Of note, Botham's first 202 wickets came at 21.20 per wicket, while his final 181 cost on average 36.43 apiece; the first average is one that would make Botham one of the greatest bowlers of the modern era, ranking alongside the West Indian greats Curtly Ambrose (career average 20.99), Malcolm Marshall (career average 20.94), and Joel Garner (career average 20.97), but the second average depicts a player who, as a specialist bowler, would be unable to sustain a place in many Test teams. This difference can be largely attributed to the longer term effects of a back injury he sustained in 1980; this limited his bowling pace and his ability to swing the ball.

Botham's batting – although never the equal of his bowling abilities – declined as well, with a batting average of 38.80 for his first 51 Tests substantially higher than the 28.87 he managed in his last 51 Tests, again a number that would be considered unsatisfactory for a specialist batsman in most Test sides. In the first 5 years of Botham's Test career, when not playing as captain, he scored 2,557 runs at an average of 49.17 including 11 centuries and a highest score of 208, took 196 wickets at an average of 21.28 including nineteen 5 wicket hauls and held 50 catches. Such figures denote a player who would easily maintain a place in any Test side as a specialist batsman or bowler alone. During this period his reputation as one of the leading Test all-rounders was firmly established.

Botham had an affinity with Brian Close, his first county captain who became a mentor to him, as they shared a determination to do well and win matches. "Wisden" has commented on another shared characteristic: "outstanding courage", mainly because Botham would readily field anywhere, generally in the slips but also in dangerous positions near the batsman and he was a brilliant fielder. As a batsman, Botham was often wrongly labelled by the tabloid press as a "big hitter" (effectively inferring that he was a "slogger") but, while it is true that his strength enabled him to drive a ball for six and his courage to hook one for six, Botham actually had a very correct batting style as he stood side-on and played straight: "Wisden" praised his "straight hitting and square cutting". Botham might not have been good enough to retain a regular England place as a specialist batsman (his Test career batting average was a fairly modest 33.54) but as a bowler who was capable of taking 383 Test wickets, he certainly would. "Wisden" praised Tom Cartwright for helping to develop Botham's technique as a swing bowler and, by the time he made his Test debut in 1977, Botham had mastered change of pace, the outswinger and the fast inswinging yorker, all formidable parts of his repertoire which eventually enabled him to break the world Test wicket record.

Writing in "Barclays World of Cricket" (1986), former England captain Tony Lewis commented upon Botham's strength, enthusiasm and aggression "which he took into every game". Lewis, however, pointed out that Botham's exuberance often reduced the efficiency of his play, in that he would take too many risks or refuse to give up on a bowling tactic despite ongoing heavy cost. He summarised Botham as an exciting cricketer who lacked self-discipline. Botham was in the middle of his career when the book was published but Lewis emphasised the speed at which Botham had achieved certain milestones such as 1,000 runs and 100 wickets in Test cricket. At that time, there seemed no reason why Botham should not go on reaching milestones but he had already peaked and, in retrospect, his career had a meteoric aspect. His rival Imran Khan asserted this when he said: "Botham was someone who I don't think ever did justice to his talent. When he started he could have done anything, but he declined very quickly. In a way our careers were the opposite of each other. I started quite slowly but got better, maximised my talent. He went the other way, I think".

The tabloid/juvenile hagiography of Botham has caused many knowledgeable commentators to assert that Botham was overrated, a problem for him that dates right back to his first Test series in 1977. When naming him as a Cricketer of the Year in its 1978 edition, "Wisden" described Botham as "a determined character who knows where he is aiming, and who will, quite naturally and fiercely, address himself to the interesting view that he is overrated". Denis Compton, another great English cricketer who was idolised by the media, dismissed Botham as "overrated" and said he "only did well because all the best players had joined Packer": i.e., for World Series Cricket (WSC).

Given all the arguments about whether Botham was the greatest or whether he was overrated, it must be stressed that there is no evidence anywhere of Botham himself claiming, Muhammad Ali-style (or even Fred Trueman-style), that he ever was "the greatest" or of him "revelling in superstar status". Rather, he would readily give praise to his colleagues and effectively assert that cricket is a team game in which he always did his best and played to win (just like Brian Close, his mentor): for example, the credit which Botham gave to his batting partners Hallam Moseley and Bob Clapp after the 1974 Benson and Hedges quarter-final against Hampshire; and to Bob Willis who, after all, was the actual match-winner at Headingley in 1981. Botham's innings there was an outstanding performance but, in match terms, it gave England a ray of hope which, without Willis's brilliant bowling on the final day, would have been extinguished for, as "Wisden" said: "This was Willis' hour". Botham has turned all the publicity to good use in one important respect as it made him famous outside cricket and that has generated increased public interest, and investment, in his charity fundraising efforts.

As a Test batsman, he scored 14 centuries with a highest score of 208 against India in 1982. Thirteen of his centuries were scored before his thirtieth birthday in November 1985. It is a similar picture in terms of his Test bowling. He took ten wickets in a match four times and five wickets in an innings 27 times. Apart from a five for 71 in 1985–86 and a five for 41 in 1986–87, all those successes were achieved before his thirtieth birthday.

In 1994, the year after he retired, Botham became embroiled in a legal dispute with Imran Khan who, in an article for "India Today", had accused Botham and Allan Lamb of bringing cricket into disrepute. Botham and Lamb instigated a libel action in response. The case was heard at the High Court in 1996 with the court choosing to hear on the second day a separate action brought solely by Botham against Khan, who had suggested in a newspaper article that Botham had been involved in ball-tampering. This would become the subject of a court case later on, one that Khan would go on to win. Botham was liable for all expenses in the court case in the ruling, including those incurred by Khan.

Botham was a talented footballer but, believing he was better at cricket, he chose the latter for his full-time career. Even so, he played football as a centre half from 1978 to 1985 for Yeovil Town and Scunthorpe United. He made eleven appearances in the Football League for Scunthorpe. While with Yeovil, Botham made an appearance for the Football Association XI (a representative side for non-League footballers) against the Northern Football League at Croft Park during the 1984–85 season.

Botham has been a prodigious fundraiser for charitable causes, undertaking a total of 12 long-distance charity walks. His first, in 1985, was a 900-mile trek from John o' Groats to Land's End. His efforts were inspired after a visit to Taunton's Musgrove Park Hospital in 1977 whilst receiving treatment for a broken toe. When he took a wrong turn into a children's ward, he was devastated to learn that some of the children had only weeks to live, and why. At the time, he was an expectant father himself. Since then, his efforts have raised more than £12 million for charity, with leukaemia research the main cause to benefit. In recognition of this work, Botham in 2003 became the first-ever President of Bloodwise, the UK's leading blood cancer charity.

On 10 October 2007, he was invested a Knight Bachelor by Queen Elizabeth II at Buckingham Palace, having been appointed in the Queen's Birthday Honours "for services to Charity and to Cricket".

After retiring from cricket, Botham became involved in the media and has worked as an analyst and commentator for Sky Sports for many years. He has earned much respect as a broadcaster because of his deep knowledge and understanding of cricket; he imparts information and opinion objectively, giving praise where it is due and constructive criticism where that is due. Unlike Fred Trueman and others, he does not hark back to "in my day". "Wisden" editor Matthew Engel remarked on Botham's calmness, wit and sagacity as a TV commentator, though admitting he was surprised by it.

On 9 August 2009, while commentating on the fourth Ashes Test at Headingley that season, Botham was invited to take part in an on-field ceremony to induct him into the ICC Cricket Hall of Fame along with the Yorkshire greats Wilfred Rhodes, Fred Trueman and Geoffrey Boycott. Geoff Boycott was also in attendance, along with Fred Trueman's widow Veronica and Colin Graves who, as Yorkshire County Cricket Club chairman, accepted the honour on behalf of Wilfred Rhodes. Botham said: "To be named amongst 55 of the most prolific players in cricketing history is a great honour for me. To have my cricketing career recognised in the ICC Cricket Hall of Fame is not something I would have thought when I began playing cricket but to be receiving this award today is something I'm extremely grateful for". Colin Graves included Botham in his tribute to Rhodes when he said: "It is a great honour to accept the cap on behalf of a Yorkshire legend. Wilfred Rhodes was an exceedingly gifted player and is rightly regarded as one of England's greatest all-rounders. I am also delighted to see two other great Yorkshiremen and another great all-rounder inducted into the ICC Cricket Hall of Fame today".

He was the subject of "This Is Your Life" in 1981 when he was surprised by Eamonn Andrews.

Botham is colour blind. In 1976, in Doncaster, Botham married Kathryn ("Kathy") Waller (now Lady Botham) whom he first met in June 1974. After their marriage, they lived until the late 1980s in Epworth, near Scunthorpe. They have one son, Liam (born August 1977), and two daughters. Liam is a former professional cricketer and rugby player. The family currently live in Almería, owning two houses, and Botham frequently plays golf there. His daughter Sarah owns a restaurant and wine bar in the town.

Botham is an avid trout and salmon angler. As a result, he was invited to present a TV series called "Botham on the Fly". He has also been a team captain on the BBC series "A Question of Sport".

Besides angling and golf, Botham enjoys game shooting and owns a grouse moor. This has resulted in a high-profile dispute with the Royal Society for the Protection of Birds (RSPB). In August 2016, he called for Chris Packham to be sacked by the BBC as part of a campaign funded by the grouse shooting industry, after Packham had highlighted the industry's involvement in the illegal killing of endangered species of birds of prey.

According to the "New Statesman" in 2015, "Botham is an old-fashioned Englishman [...] he is conservative with a small and upper-case C" and "a robust monarchist". Botham is a staunch supporter of Britain's withdrawal from the European Union. He was quoted: "Personally, I think that England is an island. I think that England should be England. And I think that we should keep that." He appeared at a number of pro-leave campaign events in the run-up to the United Kingdom's European Union membership referendum in 2016.




</doc>
<doc id="15526" url="https://en.wikipedia.org/wiki?curid=15526" title="Id Software">
Id Software

id Software LLC () is an American video game developer based in Dallas, Texas. The company was founded on February 1, 1991, by four members of the computer company Softdisk, programmers John Carmack and John Romero, game designer Tom Hall, and artist Adrian Carmack (no relation to John Carmack). Business manager Jay Wilbur was also involved. id Software made important technological developments in video game technologies for the PC (running MS-DOS and Windows), including work done for the "Wolfenstein", "Doom", and "Quake" franchises. id's work was particularly important in 3D computer graphics technology and in game engines that are used throughout the video game industry. The company was involved in the creation of the first-person shooter (FPS) genre. "Wolfenstein 3D" is often considered to be the first true FPS, "Doom" is a game that popularized the genre and PC gaming in general, and "Quake" was id's first true 3D FPS.

On June 24, 2009, ZeniMax Media acquired the company. In 2015, they opened a second studio in Frankfurt, Germany.

The founders of id Software met in the offices of Softdisk developing multiple games for Softdisk's monthly publishing, including "Dangerous Dave". In September 1990, John Carmack developed an efficient way to rapidly side-scroll graphics on the PC. Upon making this breakthrough, Carmack and Tom Hall stayed up late into the night making a replica of the first level of the popular 1988 NES game "Super Mario Bros. 3", inserting stock graphics of John Romero's Dangerous Dave character in lieu of Mario. When Romero saw the demo, entitled "Dangerous Dave in Copyright Infringement", he realized that Carmack's breakthrough could have potential. The team that would later form id Software immediately began moonlighting, going so far as to "borrow" company computers that were not being used over the weekends and at nights while they designed their own remake of "Super Mario Bros. 3".

Despite their work, Nintendo turned them down, saying they had no interest in expanding to the PC market, and that Mario games were to remain exclusive to Nintendo consoles. Around this time, Scott Miller of Apogee Software learned of the group and their exceptional talent, having played one of Romero's Softdisk games, "Dangerous Dave", and contacted Romero under the guise of multiple fan letters that Romero came to realize all originated from the same address. When he confronted Miller, Miller explained that the deception was necessary since Softdisk screened letters it received. Although disappointed by not actually having received mail from multiple fans, Romero and other Softdisk developers began proposing ideas to Miller, including "Commander Keen" in December 1990, which became a very successful shareware game. After their first royalty check, Romero, Carmack, and Adrian Carmack (no relation) decided to start their own company. After hiring Hall, the group finished the "Commander Keen" series, then hired Jay Wilbur and Kevin Cloud and began working on "Wolfenstein 3D". Id Software was officially founded by Romero, John and Adrian Carmack and Hall on February 1, 1991.

The shareware distribution method was initially employed by id Software through Apogee Software to sell their products, such as the "Commander Keen", "Wolfenstein" and "Doom" games. They would release the first part of their trilogy as shareware, then sell the other two installments by mail order. Only later (about the time of the release of "Doom II") did id Software release their games via more traditional shrink-wrapped boxes in stores (through other game publishers).

After "Wolfenstein 3D"s great success, id began working on "Doom". After Hall left the company, Sandy Petersen and Dave Taylor were hired before the release of "Doom" in December 1993.

On June 24, 2009, it was announced that id Software had been acquired by ZeniMax Media (owner of Bethesda Softworks). The deal would eventually affect publishing deals id Software had before the acquisition, namely "Rage", which was being published through Electronic Arts. ZeniMax received in July a $105 million investment from StrongMail Systems for the id acquisition, it's unknown if that was the exact price of the deal. id Software moved from the "cube-shaped" Mesquite office to a location in Richardson, Texas during the spring of 2011.

On June 26, 2013, id Software president Todd Hollenshead quit after 17 years of service.

On November 22, 2013, it was announced id Software co-founder and Technical Director John Carmack had fully resigned from the company to work full-time at Oculus VR which he joined as CTO in August 2013. He was the last of the original founders to leave the company.

Tim Willits left the company in 2019

The company writes its name with a lowercase "id", which is pronounced as in "did" or "kid", and, according to the book "Masters of Doom", the group identified itself as "Ideas from the Deep" in the early days of Softdisk but that, in the end, the name 'id' came from the phrase "in demand". Disliking "in demand" as "lame", someone suggested a connection with Sigmund Freud's psychological concept of id, which the others accepted. Evidence of the reference can be found as early as "Wolfenstein 3D" with the statement "that's id, as in the id, ego, and superego in the psyche" appearing in the game's documentation. Prior to an update to the website, id's History page made a direct reference to Freud.


Arranged in chronological order:

Starting with their first shareware game series, "Commander Keen", id Software has licensed the core source code for the game, or what is more commonly known as the engine. Brainstormed by John Romero, id Software held a weekend session titled "The id Summer Seminar" in the summer of 1991 with prospective buyers including Scott Miller, George Broussard, Ken Rogoway, Jim Norwood and Todd Replogle. One of the nights, id Software put together an impromptu game known as "Wac-Man" to demonstrate not only the technical prowess of the "Keen" engine, but also how it worked internally.

id Software has developed their own game engine for each of their titles when moving to the next technological milestone, including "Commander Keen", "Wolfenstein 3D", "ShadowCaster", "Doom", "Quake", "Quake II", and "Quake III", as well as the technology used in making "Doom 3". After being used first for id Software's in-house game, the engines are licensed out to other developers. According to "Eurogamer.net", "id Software has been synonymous with PC game engines since the concept of a detached game engine was first popularized". During the mid to late 1990s, "the launch of each successive round of technology it's been expected to occupy a headlining position", with the "Quake III" engine being most widely adopted of their engines. However id Tech 4 had far fewer licensees than the Unreal Engine from Epic Games, due to the long development time that went into "Doom 3" which id Software had to release before licensing out that engine to others.

Despite his enthusiasm for open source code, Carmack revealed in 2011 that he had no interest in licensing the technology to the mass market. Beginning with Wolfenstein 3D, he felt bothered when third-party companies started "pestering" him to licence the id tech engine, adding that he wanted to focus on new technology instead of providing support to existing ones. He felt very strongly that this was not why he signed up to be a game programmer for; to be "holding the hands" of other game developers. Carmack commended Epic Games for pursuing the licensing to the market beginning with Unreal Engine 3. Even though the said company has gained more success with its game engine than id Software over the years, Carmack had no regrets by his decision and continued to focus on open source until his departure from the company in 2013.

In conjunction with his self-professed affinity for sharing source code, John Carmack has open-sourced most of the major id Software engines under the GNU General Public License. Historically, the source code for each engine has been released once the code base is 5 years old. Consequently, many home grown projects have sprung up porting the code to different platforms, cleaning up the source code, or providing major modifications to the core engine. "Wolfenstein 3D", "DOOM" and "Quake" engine ports are ubiquitous to nearly all platforms capable of running games, such as hand-held PCs, iPods, the PSP, the Nintendo DS and more. Impressive core modifications include DarkPlaces which adds stencil shadow volumes into the original "Quake" engine along with a more efficient network protocol. Another such project is ioquake3, which maintains a goal of cleaning up the source code, adding features and fixing bugs. Even earlier id Software code, namely for "Hovertank 3D" and "Catacomb 3D", was released in June 2014 by Flat Rock Software.

The GPL release of the "Quake III" engine's source code was moved from the end of 2004 to August 2005 as the engine was still being licensed to commercial customers who would otherwise be concerned over the sudden loss in value of their recent investment.

On August 4, 2011, John Carmack revealed during his QuakeCon 2011 keynote that they will be releasing the source code of the "Doom 3" engine (id Tech 4) during the year.

id Software publicly stated they would not support the Wii console (possibly due to technical limitations), although they have since indicated that they may release titles on that platform (although it would be limited to their games released during the 1990s). They did the same thing with the Wii U but for Nintendo Switch, they collaborated with Panic Button to release 2016's Doom and .

Since id Software revealed their engine id Tech 5, they call their engines "id Tech", followed by a version number. Older engines have retroactively been renamed to fit this scheme, with the "Doom" engine as id Tech 1.

id Software was an early pioneer in the Linux gaming market, and id Software's Linux games have been some of the most popular of the platform. Many id Software games won the Readers' and Editors' Choice awards of Linux Journal. Some id Software titles ported to Linux are "Doom" (the first id Software game to be ported), "Quake", "Quake II", "Quake III Arena", "Return to Castle Wolfenstein", "", "Doom 3", "Quake 4", and "". Since id Software and some of its licensees released the source code for some of their previous games, several games which were not ported (such as "Wolfenstein 3D", "Spear of Destiny", "Heretic", "", "Hexen II", and "Strife") can run on Linux and other operating systems natively through the use of source ports. "Quake Live" also launched with Linux support, although this, alongside OS X support, was later removed when changed to a standalone title.

The tradition of porting to Linux was first started by Dave D. Taylor, with David Kirsch doing some later porting. Since "Quake III Arena", Linux porting had been handled by Timothee Besset. The majority of all id Tech 4 games, including those made by other developers, have a Linux client available, the only current exceptions being "Wolfenstein" and "Brink". Similarly, almost all of the games utilizing the Quake II engine have Linux ports, the only exceptions being those created by Ion Storm ("Daikatana" later received a community port). Despite fears by the Linux gaming community that id Tech 5 would not be ported to that platform, Timothee Besset in his blog stated "I'll be damned if we don't find the time to get Linux builds done". Besset explained that id Software's primary justification for releasing Linux builds was better code quality, along with a technical interest in the platform. However, on January 26, 2012, Besset announced that he had left id.

John Carmack has expressed his stance with regard to Linux builds in the past. In December 2000 Todd Hollenshead expressed support for Linux: "All said, we will continue to be a leading supporter of the Linux platform because we believe it is a technically sound OS and is the OS of choice for many server ops." However, on April 25, 2012, Carmack revealed that "there are no plans for a native Linux client" of id's most recent game, "Rage". In February 2013, Carmack argued for improving emulation as the "proper technical direction for gaming on Linux", though this was also due to ZeniMax's refusal to support "unofficial binaries", given all prior ports (except for "Quake III Arena", via Loki Software, and earlier versions of "Quake Live") having only ever been unofficial. Carmack didn't mention official games "Quake: The Offering" and "Quake II: Colossus" ported by id Software to Linux and published by Macmillan Computer Publishing USA.
"Commander Keen in Invasion of the Vorticons", a platform game in the style of those for the Nintendo Entertainment System, was one of the first MS-DOS games with smooth horizontal-scrolling. Published by Apogee Software, the title and follow-ups brought id Software success as a shareware developer. It is the series of id Software that designer Tom Hall is most affiliated with. The first "Commander Keen" trilogy was released on December 14, 1990.

The company's breakout product was released on May 5, 1992: "Wolfenstein 3D", a first-person shooter (FPS) with smooth 3D graphics that were unprecedented in computer games, and with violent gameplay that many gamers found engaging. After essentially founding an entire genre with this game, id Software created "Doom", "", "Quake", "Quake II", "Quake III Arena", "Quake 4", and "Doom 3". Each of these first-person shooters featured progressively higher levels of graphical technology. "Wolfenstein 3D" spawned a prequel and a sequel: the prequel called "Spear of Destiny", and the second, "Return to Castle Wolfenstein", using the id Tech 3 engine. A third "Wolfenstein" sequel, simply titled "Wolfenstein", was released by Raven Software, using the id Tech 4 engine. Another sequel, named ""; was developed by MachineGames using the id Tech 5 engine and released in 2014, with it getting a prequel by the name of "" a year later; followed by a direct sequel titled "" in 2017.

Eighteen months after their release of "Wolfenstein 3D", on December 10, 1993, id Software released "Doom" which would again set new standards for graphic quality and graphic violence in computer gaming. "Doom" featured a sci-fi/horror setting with graphic quality that had never been seen on personal computers or even video game consoles. "Doom" became a cultural phenomenon and its violent theme would eventually launch a new wave of criticism decrying the dangers of violence in video games. "Doom" was ported to numerous platforms, inspired many knock-offs, and was eventually followed by the technically similar "". id Software made its mark in video game history with the shareware release of "Doom", and eventually revisited the theme of this game in 2004 with their release of "Doom 3". John Carmack said in an interview at QuakeCon 2007 that there would be a "Doom 4". It began development on May 7, 2008. "Doom", the fourth installation and a reboot of the Doom series, was released on Microsoft Windows, PlayStation 4, and Xbox One on May 13, 2016, and was later released on Nintendo Switch on November 10, 2017. In June 2018, the sequel to the 2016 reboot, "Doom Eternal" was officially announced at E3 2018 with a teaser trailer, followed by a gameplay reveal at QuakeCon in August 2018.

On June 22, 1996, the release of "Quake" marked the second milestone in id Software history. "Quake" combined a cutting edge fully 3D engine, the "Quake" engine, with a distinctive art style to create critically acclaimed graphics for its time. Audio was not neglected either, having recruited Nine Inch Nails frontman Trent Reznor to facilitate unique sound effects and ambient music for the game. (A small homage was paid to Nine Inch Nails in the form of the band's logo appearing on the ammunition boxes for the nailgun weapon.) It also included the work of Michael Abrash. Furthermore, "Quake"'s main innovation, the capability to play a deathmatch (competitive gameplay between living opponents instead of against computer-controlled characters) over the Internet (especially through the add-on "QuakeWorld"), seared the title into the minds of gamers as another smash hit.

In 2008, id Software was honored at the 59th Annual Technology & Engineering Emmy Awards for the pioneering work "Quake" represented in user modifiable games. id Software is the only game development company ever honored twice by the National Academy of Television Arts & Sciences, having been given an Emmy Award in 2007 for creation of the 3D technology that underlies modern shooter video games.

The "Quake" series continued with "Quake II" in 1997. Activision purchased a 49% stake in id Software, making it a second party which took publishing duties until 2009. However, the game is not a storyline sequel, and instead focuses on an assault on an alien planet, Stroggos, in retaliation for Strogg attacks on Earth. Most of the subsequent entries in the "Quake" franchise follow this storyline. "Quake III Arena" (1999), the next title in the series, has minimal plot, but centers around the "Arena Eternal", a gladiatorial setting created by an alien race known as the Vadrigar and populated by combatants plucked from various points in time and space. Among these combatants are some characters either drawn from or based on those in "Doom" ("Doomguy"), "Quake" (Ranger, Wrack), and "Quake II" (Bitterman, Tank Jr., Grunt, Stripe). "Quake IV" (2005) picks up where "Quake II" left off – finishing the war between the humans and Strogg. The spin-off "" acts as a prequel to "Quake II", when the Strogg first invade Earth. "Quake IV" and "Enemy Territory: Quake Wars" were made by outside developers and not id.

There have also been other spin-offs such as Quake Mobile in 2005 and "Quake Live", an internet browser based modification of "Quake III". A game called "Quake Arena DS" was planned and canceled for the Nintendo DS. John Carmack stated, at QuakeCon 2007, that the "id Tech 5" engine would be used for a new "Quake" game.

Todd Hollenshead announced in May 2007 that id Software had begun working on an all new series that would be using a new engine. Hollenshead also mentioned that the title would be completely developed in-house, marking the first game since 2004's "Doom 3" to be done so. At 2007's WWDC, John Carmack showed the new engine called id Tech 5. Later that year, at QuakeCon 2007, the title of the new game was revealed as "Rage".

On July 14, 2008, id Software announced at the 2008 E3 event that they would be publishing "Rage" through Electronic Arts, and not id's longtime publisher Activision. However, since then ZeniMax has also announced that they are publishing "Rage" through Bethesda Softworks.

On August 12, 2010, during Quakecon 2010, id Software announced "Rage" US ship date of September 13, 2011, and a European ship date of September 15, 2011. During the keynote, id Software also demonstrated a "Rage" spin-off title running on the iPhone. This technology demo later became "Rage HD".

On May 14, 2018, Bethesda Softworks announced "Rage 2", a co-development between id Software and Avalanche Studios.

During its early days, id Software produced much more varied games; these include the early 3D first-person shooter experiments that led to "Wolfenstein 3D" and "Doom" – "Hovertank 3D" and "Catacomb 3D". There was also the "Rescue Rover" series, which had two games – "Rescue Rover" and "Rescue Rover 2". Also there was John Romero's "Dangerous Dave" series, which included such notables as the tech demo ("In Copyright Infringement") which led to the "Commander Keen" engine, and the decently popular "Dangerous Dave in the Haunted Mansion". "In the Haunted Mansion" was powered by the same engine as the earlier id Software game "Shadow Knights", which was one of the several games written by id Software to fulfill their contractual obligation to produce games for Softdisk, where the id Software founders had been employed. id Software has also overseen several games using its technology that were not made in one of their IPs such as "ShadowCaster", (early-id Tech 1), "Heretic", "" (id Tech 1), "Hexen II" ("Quake" engine), and "Orcs and Elves" ("Doom RPG" engine).

id Software has also published novels based on the Doom series "Doom" novels. After a brief hiatus from publishing, id resumed and re-launched the novel series in 2008 with Matthew J. Costello's (a story consultant for "Doom 3" and now "Rage") new "Doom 3" novels: "" and "".

id Software became involved in film development when they oversaw the film adaption of their "Doom" franchise in 2005. In August 2007, Todd Hollenshead stated at QuakeCon 2007 that a "Return to Castle Wolfenstein" movie is in development which re-teams the "Silent Hill" writer/producer team, Roger Avary as writer and director and Samuel Hadida as producer. A new "Doom" film, titled "", was released in 2019, although id itself stressed its lack of involvement.

id Software was the target of controversy over two of their most popular games, "Doom" and the earlier "Wolfenstein 3D":

"Doom" was notorious for its high levels of gore and occultism along with satanic imagery, which generated controversy from a broad range of groups. Yahoo! Games listed it as one of the top ten most controversial games of all time.

The game again sparked controversy throughout a period of school shootings in the United States when it was found that Eric Harris and Dylan Klebold, who committed the Columbine High School massacre in 1999, were avid players of the game. While planning for the massacre, Harris said that the killing would be "like playing "Doom"", and "it'll be like the LA riots, the Oklahoma bombing, World War II, Vietnam, "Duke Nukem" and "Doom" all mixed together", and that his shotgun was "straight out of the game". A rumor spread afterwards that Harris had designed a "Doom" level that looked like the high school, populated with representations of Harris's classmates and teachers, and that Harris practiced for his role in the shootings by playing the level over and over. Although Harris did design "Doom" levels, none of them were based on Columbine High School.

While "Doom" and other violent video games have been blamed for nationally covered school shootings, 2008 research featured by Greater Good Science Center shows that the two are not closely related. Harvard Medical School researchers Cheryl Olson and Lawrence Kutner found that violent video games did not correlate to school shootings. The U.S. Secret Service and Department of Education analyzed 37 incidents of school violence and sought to develop a profile of school shooters; they discovered that the most common traits among shooters were that they were male and had histories of depression and attempted suicide. While many of the killers—like the vast majority of young teenage boys—did play video games, this study did not find a relationship between game play and school shootings. In fact, only one eighth of the shooters showed any special interest in violent video games, far less than the number of shooters who seemed attracted to books and movies with violent content.

As for "Wolfenstein 3D", due to its use of Nazi symbols such as the swastika and the anthem of the Nazi Party, "Horst-Wessel-Lied", as theme music, the PC version of the game was withdrawn from circulation in Germany in 1994, following a verdict by the Amtsgericht München on January 25, 1994. Despite the fact that Nazis are portrayed as the enemy in "Wolfenstein", the use of those symbols is a federal offense in Germany unless certain circumstances apply. Similarly, the Atari Jaguar version was confiscated following a verdict by the Amtsgericht Berlin Tiergarten on December 7, 1994.

Due to concerns from Nintendo of America, the Super NES version was modified to not include any swastikas or Nazi references; furthermore, blood was replaced with sweat to make the game seem less violent, and the attack dogs in the game were replaced by giant mutant rats. Employees of id Software are quoted in "The Official DOOM Player Guide" about the reaction to "Wolfenstein", claiming it to be ironic that it was morally acceptable to shoot people and rats, but not dogs. Two new weapons were added as well. The Super NES version was not as successful as the PC version.

In 2003, the book "Masters of Doom" chronicled the development of id Software, concentrating on the personalities and interaction of John Carmack and John Romero. Below are the key people involved with id's success.

Carmack's skill at 3D programming is widely recognized in the software industry and from its inception, he was id's lead programmer. On August 7, 2013, he joined Oculus VR, a company developing virtual reality headsets, and left id Software on November 22, 2013.

John Romero, who was forced to resign in 1996 after the release of "Quake", later formed the ill-fated company Ion Storm. There, he became infamous through the development of "Daikatana", which was received negatively from reviewers and gamers alike upon release.

Both Tom Hall and John Romero have reputations as designers and idea men who have helped shape some of the key PC gaming titles of the 1990s.

Tom Hall was forced to resign by id Software during the early days of "Doom" development, but not before he had some impact; for example, he was responsible for the inclusion of teleporters in the game. He was let go before the shareware release of "Doom" and then went to work for Apogee, developing "Rise of the Triad" with the "Developers of Incredible Power". When he finished work on that game, he found he was not compatible with the "Prey" development team at Apogee, and therefore left to join his ex-id Software compatriot John Romero at Ion Storm. Hall has frequently commented that if he could obtain the rights to "Commander Keen", he would immediately develop another Keen title.

Sandy Petersen was a level designer for 19 of the 27 levels in the original "Doom" title as well as 17 of the 32 levels of "Doom II". As a fan of H.P. Lovecraft, his influence is apparent in the Lovecraftian feel of the monsters for "Quake", and he created "Inferno", the third "episode" of the first DOOM. He was forced to resign from id Software during the production of "Quake II" and most of his work was scrapped before the title was released.

American McGee was a level designer for "Doom II", "The Ultimate Doom", "Quake", and "Quake II". He was asked to resign after the release of "Quake II", then moved to Electronic Arts where he gained industry notoriety with the development of his own game "American McGee's Alice". After leaving Electronic Arts, he became an independent entrepreneur and game developer. McGee now heads independent game development house Spicy Horse in Shanghai, where he works on various projects.



</doc>
<doc id="15531" url="https://en.wikipedia.org/wiki?curid=15531" title="Isaac Stern">
Isaac Stern

Isaac Stern (July 21, 1920 – September 22, 2001) was an American violinist.

The son of Solomon and Clara Stern, Isaac Stern was born in Kremenets, Poland (now Ukraine), into a Jewish family. He was 14 months old when his family moved to San Francisco in 1921. He received his first music lessons from his mother. In 1928, he enrolled at the San Francisco Conservatory of Music, where he studied until 1931 before going on to study privately with Louis Persinger. He returned to the San Francisco Conservatory to study for five years with Naoum Blinder, to whom he said he owed the most. At his public début on February 18, 1936, aged 15, he played Saint-Saëns' Violin Concerto No. 3 in B minor with the San Francisco Symphony under the direction of Pierre Monteux. Reflecting on his background, Stern once memorably quipped that cultural exchanges between the U.S. and Soviet Russia were simple affairs:

Stern toured the Soviet Union in 1951, the first American violinist to do so. In 1967, Stern stated his refusal to return to the USSR until the Soviet regime allowed artists to enter and leave the country freely. His only visit to Germany was in 1999, for a series of master classes, but he never performed publicly in Germany.

Stern was married three times. His first marriage, in 1948 to ballerina Nora Kaye, ended in divorce after 18 months, but the two of them subsequently remained friends. On August 17, 1951, he married Vera Lindenblit (1927-2015). They had three children together, including conductors Michael and David Stern. Their marriage ended in divorce in 1994 after 43 years. In 1996, Stern married his third wife, Linda Reynolds. His third wife, his three children, and his five grandchildren survived him.

Stern died September 22, 2001 of heart failure in a Manhattan, New York, hospital after an extended stay.

In 1940, Stern began performing with Russian-born pianist Alexander Zakin, collaborating until 1977. Within musical circles, Stern became renowned both for his recordings and for championing certain younger players. Among his discoveries were cellists Yo-Yo Ma and Jian Wang, and violinists Itzhak Perlman and Pinchas Zukerman.

In the 1960s, he played a major role in saving New York City's Carnegie Hall from demolition, by organising the Citizens' Committee to Save Carnegie Hall. Following the purchase of Carnegie Hall by New York City, the Carnegie Hall Corporation was formed, and Stern was chosen as its first president, a title he held until his death. Carnegie Hall later named its main auditorium in his honor.

Among Stern's many recordings are concertos by Brahms, Bach, Beethoven, Mendelssohn, Sibelius, Tchaikovsky, and Vivaldi and modern works by Barber, Bartók, Stravinsky, Bernstein, Rochberg, and Dutilleux. The Dutilleux concerto, entitled "L'arbre des songes" ["The Tree of Dreams"] was a 1985 commission by Stern himself. He also dubbed actors' violin-playing in several films, such as "Fiddler on the Roof".

Stern served as musical advisor for the 1946 film, "Humoresque", about a rising violin star and his patron, played respectively by John Garfield and Joan Crawford. He was also the featured violin soloist on the soundtrack for the 1971 film of Fiddler on the Roof. In 1999, he appeared in the film "Music of the Heart", along with Itzhak Perlman and several other famed violinists, with a youth orchestra led by Meryl Streep (the film was based on the true story of a gifted violin teacher in Harlem who eventually took her musicians to play a concert in Carnegie Hall).
In his autobiography, co-authored with Chaim Potok, "My First 79 Years", Stern cited Nathan Milstein and Arthur Grumiaux as major influences on his style of playing.

He won Grammys for his work with Eugene Istomin and Leonard Rose in their famous chamber music trio in the 1960s and '70s, while also continuing his duo work with Alexander Zakin during this time. Stern recorded a series of piano quartets in the 1980s and 1990s with Emanuel Ax, Jaime Laredo and Yo-Yo Ma, including those of Mozart, Beethoven, Schumann and Fauré, winning another Grammy in 1992 for the Brahms quartets Opp. 25 and 26.

In 1979, seven years after Richard Nixon made the first official visit by a US President to the country, the People's Republic of China offered Stern and pianist David Golub an unprecedented invitation to tour the country. While there, he collaborated with the China Central Symphony Society (now China National Symphony) under the direction of conductor Li Delun. Their visit was filmed and resulted in the Oscar-winning documentary, "".

Stern maintained close ties with Israel. Stern began performing in the country in 1949. In 1973, he performed for wounded Israeli soldiers during the Yom Kippur War. During the 1991 Gulf War and Iraq's Scud missile attacks on Israel, he played in the Jerusalem Theater. During his performance, an air raid siren sounded, causing the audience to panic. Stern then stepped onto the stage and began playing a movement of Bach. The audience then calmed down, donned gas masks, and sat throughout the rest of his performance. Stern was a supporter of several educational projects in Israel, among them the America-Israel Foundation and the Jerusalem Music Center.

Stern's favorite instrument was the Ysaÿe Guarnerius, one of the violins produced by the Cremonese luthier Giuseppe Guarneri del Gesù. It had previously been played by the violin virtuoso and composer Eugène Ysaÿe.

Among other instruments, Stern played the "Kruse-Vormbaum" Stradivarius (1728), the "ex-Stern" Bergonzi (1733), the "Panette" Guarneri del Gesù (1737), a Michele Angelo Bergonzi (1739–1757), the "Arma Senkrah" Guadagnini (1750), a Giovanni Guadagnini (1754), a J. B. Vuillaume copy of the "Panette" Guarneri del Gesu of 1737 (c.1850), and the "ex-Nicolas I" J.B. Vuillaume (1840). He also owned two contemporary instruments by Samuel Zygmuntowicz and modern Italian Jago Peternella Violins.

In 2001, Stern's collection of instruments, bows and musical ephemera was sold through Tarisio Auctions. The May 2003 auction set a number of world records and was at the time the second highest grossing violin auction of all time, with total sales of over $3.3M.


In 2012, a street in Tel Aviv was named for Stern.











</doc>
<doc id="15532" url="https://en.wikipedia.org/wiki?curid=15532" title="Integral">
Integral

In mathematics, an integral assigns numbers to functions in a way that can describe displacement, area, volume, and other concepts that arise by combining infinitesimal data. Integration is one of the two main operations of calculus, with its inverse operation, differentiation, being the other. Given a function of a real variable and an interval of the real line, the definite integral

is defined informally as the signed area of the region in the -plane that is bounded by the graph of , the -axis and the vertical lines and . The area above the -axis adds to the total and that below the -axis subtracts from the total.

The operation of integration, up to an additive constant, is the inverse of the operation of differentiation. For this reason, the term "integral" may also refer to the related notion of the antiderivative, a function whose derivative is the given function . In this case, it is called an indefinite integral and is written:

The integrals discussed in this article are those termed "definite integrals". It is the fundamental theorem of calculus that connects differentiation with the definite integral: if is a continuous real-valued function defined on a closed interval , then, once an antiderivative of is known, the definite integral of over that interval is given by

The principles of integration were formulated independently by Isaac Newton and Gottfried Wilhelm Leibniz in the late 17th century, who thought of the integral as an infinite sum of rectangles of infinitesimal width. Bernhard Riemann gave a rigorous mathematical definition of integrals. It is based on a limiting procedure that approximates the area of a curvilinear region by breaking the region into thin vertical slabs. Beginning in the 19th century, more sophisticated notions of integrals began to appear, where the type of the function as well as the domain over which the integration is performed has been generalised. A line integral is defined for functions of two or more variables, and the interval of integration is replaced by a curve connecting the two endpoints. In a surface integral, the curve is replaced by a piece of a surface in three-dimensional space.

The first documented systematic technique capable of determining integrals is the method of exhaustion of the ancient Greek astronomer Eudoxus ("ca." 370 BC), which sought to find areas and volumes by breaking them up into an infinite number of divisions for which the area or volume was known. This method was further developed and employed by Archimedes in the 3rd century BC and used to calculate areas for parabolas and an approximation to the area of a circle.

A similar method was independently developed in China around the 3rd century AD by Liu Hui, who used it to find the area of the circle. This method was later used in the 5th century by Chinese father-and-son mathematicians Zu Chongzhi and Zu Geng to find the volume of a sphere (; ).

In the Middle East, Hasan Ibn al-Haytham, Latinized as Alhazen ( ) derived a formula for the sum of fourth powers. He used the results to carry out what would now be called an integration of this function, where the formulae for the sums of integral squares and fourth powers allowed him to calculate the volume of a paraboloid.

The next significant advances in integral calculus did not begin to appear until the 17th century. At this time, the work of Cavalieri with his method of Indivisibles, and work by Fermat, began to lay the foundations of modern calculus, with Cavalieri computing the integrals of up to degree in Cavalieri's quadrature formula. Further steps were made in the early 17th century by Barrow and Torricelli, who provided the first hints of a connection between integration and differentiation. Barrow provided the first proof of the fundamental theorem of calculus. Wallis generalized Cavalieri's method, computing integrals of to a general power, including negative powers and fractional powers.

The major advance in integration came in the 17th century with the independent discovery of the fundamental theorem of calculus by Leibniz and Newton. Leibniz published his work on calculus before Newton. The theorem demonstrates a connection between integration and differentiation. This connection, combined with the comparative ease of differentiation, can be exploited to calculate integrals. In particular, the fundamental theorem of calculus allows one to solve a much broader class of problems. Equal in importance is the comprehensive mathematical framework that both Leibniz and Newton developed. Given the name infinitesimal calculus, it allowed for precise analysis of functions within continuous domains. This framework eventually became modern calculus, whose notation for integrals is drawn directly from the work of Leibniz.
While Newton and Leibniz provided a systematic approach to integration, their work lacked a degree of rigour. Bishop Berkeley memorably attacked the vanishing increments used by Newton, calling them "ghosts of departed quantities". Calculus acquired a firmer footing with the development of limits. Integration was first rigorously formalized, using limits, by Riemann. Although all bounded piecewise continuous functions are Riemann-integrable on a bounded interval, subsequently more general functions were considered—particularly in the context of Fourier analysis—to which Riemann's definition does not apply, and Lebesgue formulated a different definition of integral, founded in measure theory (a subfield of real analysis). Other definitions of integral, extending Riemann's and Lebesgue's approaches, were proposed. These approaches based on the real number system are the ones most common today, but alternative approaches exist, such as a definition of integral as the standard part of an infinite Riemann sum, based on the hyperreal number system.

The notation for the indefinite integral was introduced by Gottfried Wilhelm Leibniz in 1675 (; ). He adapted the integral symbol, ∫, from the letter "ſ" (long s), standing for "summa" (written as "ſumma"; Latin for "sum" or "total"). The modern notation for the definite integral, with limits above and below the integral sign, was first used by Joseph Fourier in "Mémoires" of the French Academy around 1819–20, reprinted in his book of 1822 (; ).

Isaac Newton used a small vertical bar above a variable to indicate integration, or placed the variable inside a box. The vertical bar was easily confused with or , which are used to indicate differentiation, and the box notation was difficult for printers to reproduce, so these notations were not widely adopted.

Integrals are used extensively in many areas of mathematics as well as in many other areas that rely on mathematics.

For example, in probability theory, integrals are used to determine the probability of some random variable falling within a certain range. Moreover, the integral under an entire probability density function must equal 1, which provides a test of whether a function with no negative values could be a density function or not.

Integrals can be used for computing the area of a two-dimensional region that has a curved boundary, as well as computing the volume of a three-dimensional object that has a curved boundary. The area of a two-dimensional region can be calculated using the aforementioned definite integral.

The volume of a three-dimensional object such as a disc or washer, as outlined in Disc integration can be computed using the equation for the volume of a cylinder, formula_4, where formula_5 is the radius, which in this case would be the distance from the curve of a function to the line about which it is being rotated. For a simple disc, the radius will be the equation of the function minus the given formula_6-value or formula_7-value of the line. For instance, the radius of a disc created by rotating a quadratic formula_8 around the line formula_9 would be given by the expression formula_10or formula_11. In order to find the volume for this same shape, an integral with bounds formula_12 and formula_13 such that formula_12 and formula_13 are intersections of the line formula_8 and formula_9 would be used as follows:formula_18The components of the above integral represent the variables in the equation for the volume of a cylinder, formula_4. The constant pi is factored out, while the radius, formula_11, is squared within the integral. The height, represented in the volume formula by formula_21, is given in this integral by the infinitesimally small (in order to approximate the volume with the greatest possible accuracy) term formula_22.

Integrals are also used in physics, in areas like kinematics to find quantities like displacement, time, and velocity. For example, in rectilinear motion, the displacement of an object over the time interval formula_23 is given by:

where formula_25 is the velocity expressed as a function of time. The work done by a force formula_26 (given as a function of position) from an initial position formula_27 to a final position formula_28 is:

Integrals are also used in thermodynamics, where thermodynamic integration is used to calculate the difference in free energy between two given states.

The integral with respect to of a real-valued function of a real variable on the interval is written as

The integral sign represents integration. The symbol , called the differential of the variable , indicates that the variable of integration is . The function to be integrated is called the integrand. The symbol is separated from the integrand by a space (as shown). A function is said to be integrable if the integral of the function over its domain is finite. The points and are called the limits of the integral. An integral where the limits are specified is called a definite integral. The integral is said to be over the interval .

If the integral goes from a finite value "a" to the upper limit infinity, the integral expresses the limit of the integral from "a" to a value "b" as "b" goes to infinity. If the value of the integral gets closer and closer to a finite value, the integral is said to converge to that value. If not, the integral is said to diverge.

When the limits are omitted, as in
the integral is called an indefinite integral, which represents a class of functions (the antiderivative) whose derivative is the integrand. The fundamental theorem of calculus relates the evaluation of definite integrals to indefinite integrals. Occasionally, limits of integration are omitted for definite integrals when the same limits occur repeatedly in a particular context. Usually, the author will make this convention clear at the beginning of the relevant text.

There are several extensions of the notation for integrals to encompass integration on unbounded domains and/or in multiple dimensions (see later sections of this article).

Historically, the symbol "dx" was taken to represent an infinitesimally "small piece" of the independent variable "x" to be multiplied by the integrand and summed up in an infinite sense. While this notion is still heuristically useful, later mathematicians have deemed infinitesimal quantities to be untenable from the standpoint of the real number system. In introductory calculus, the expression "dx" is therefore not assigned an independent meaning; instead, it is viewed as part of the symbol for integration and serves as its delimiter on the right side of the expression being integrated.

In more sophisticated contexts, "dx" can have its own significance, the meaning of which depending on the particular area of mathematics being discussed. When used in one of these ways, the original Leibnitz notation is co-opted to apply to a generalization of the original definition of the integral. Some common interpretations of "dx" include: an integrator function in Riemann-Stieltjes integration (indicated by "dα"("x") in general), a measure in Lebesgue theory (indicated by "dμ" in general), or a differential form in exterior calculus (indicated by formula_32 in general). In the last case, even the letter "d" has an independent meaning — as the exterior derivative operator on differential forms.

Conversely, in advanced settings, it is not uncommon to leave out "dx" when only the simple Riemann integral is being used, or the exact type of integral is immaterial. For instance, one might write formula_33 to express the linearity of the integral, a property shared by the Riemann integral and all generalizations thereof.

In modern Arabic mathematical notation, a reflected integral symbol is used instead of the symbol , since the Arabic script and mathematical expressions go right to left.

Some authors, particularly of European origin, use an upright "d" to indicate the variable of integration (i.e., instead of ), since properly speaking, "d" is not a variable.

The symbol is not always placed after , as for instance in
In the first expression, the differential is treated as an infinitesimal "multiplicative" factor, formally following a "commutative property" when "multiplied" by the expression 3/("x"+1). In the second expression, showing the differentials first highlights and clarifies the variables that are being integrated with respect to, a practice particularly popular with physicists.

Integrals appear in many practical situations. If a swimming pool is rectangular with a flat bottom, then from its length, width, and depth we can easily determine the volume of water it can contain (to fill it), the area of its surface (to cover it), and the length of its edge (to rope it). But if it is oval with a rounded bottom, all of these quantities call for integrals. Practical approximations may suffice for such trivial examples, but precision engineering (of any discipline) requires exact and rigorous values for these elements.
To start off, consider the curve between and with (see figure). We ask:
and call this (yet unknown) area the (definite) integral of . The notation for this integral will be

As a first approximation, look at the unit square given by the sides to and and . Its area is exactly 1. Actually, the true value of the integral must be somewhat less than 1. Decreasing the width of the approximation rectangles and increasing the number of rectangles gives a better result; so cross the interval in five steps, using the approximation points 0, 1/5, 2/5, and so on to 1. Fit a box for each step using the right end height of each curve piece, thus , , and so on to . Summing the areas of these rectangles, we get a better approximation for the sought integral, namely

We are taking a sum of finitely many function values of , multiplied with the differences of two subsequent approximation points. We can easily see that the approximation is still too large. Using more steps produces a closer approximation, but will always be too high and will never be exact. Alternatively, replacing these subintervals by ones with the left end height of each piece, we will get an approximation that is too low: for example, with twelve such subintervals we will get an approximate value for the area of 0.6203.

The key idea is the transition from adding "finitely many" differences of approximation points multiplied by their respective function values to using infinitely many fine, or "infinitesimal" steps. When this transition is completed in the above example, it turns out that the area under the curve within the stated bounds is 2/3.

The notation
conceives the integral as a weighted sum, denoted by the elongated , of function values, , multiplied by infinitesimal step widths, the so-called "differentials", denoted by .

Historically, after the failure of early efforts to rigorously interpret infinitesimals, Riemann formally defined integrals as a limit of weighted sums, so that the suggested the limit of a difference (namely, the interval width). Shortcomings of Riemann's dependence on intervals and continuity motivated newer definitions, especially the Lebesgue integral, which is founded on an ability to extend the idea of "measure" in much more flexible ways. Thus the notation
refers to a weighted sum in which the function values are partitioned, with measuring the weight to be assigned to each value. Here denotes the region of integration.

There are many ways of formally defining an integral, not all of which are equivalent. The differences exist mostly to deal with differing special cases which may not be integrable under other definitions, but also occasionally for pedagogical reasons. The most commonly used definitions of integral are Riemann integrals and Lebesgue integrals.

The Riemann integral is defined in terms of Riemann sums of functions with respect to "tagged partitions" of an interval. Let be a closed interval of the real line; then a "tagged partition" of is a finite sequence

This partitions the interval into sub-intervals indexed by , each of which is "tagged" with a distinguished point . A "Riemann sum" of a function with respect to such a tagged partition is defined as
thus each term of the sum is the area of a rectangle with height equal to the function value at the distinguished point of the given sub-interval, and width the same as the sub-interval width. Let be the width of sub-interval ; then the "mesh" of such a tagged partition is the width of the largest sub-interval formed by the partition, . The "Riemann integral" of a function over the interval is equal to if:
When the chosen tags give the maximum (respectively, minimum) value of each interval, the Riemann sum becomes an upper (respectively, lower) Darboux sum, suggesting the close connection between the Riemann integral and the Darboux integral.

It is often of interest, both in theory and applications, to be able to pass to the limit under the integral. For instance, a sequence of functions can frequently be constructed that approximate, in a suitable sense, the solution to a problem. Then the integral of the solution function should be the limit of the integrals of the approximations. However, many functions that can be obtained as limits are not Riemann-integrable, and so such limit theorems do not hold with the Riemann integral. Therefore, it is of great importance to have a definition of the integral that allows a wider class of functions to be integrated .

Such an integral is the Lebesgue integral, that exploits the following fact to enlarge the class of integrable functions: if the values of a function are rearranged over the domain, the integral of a function should remain the same. Thus Henri Lebesgue introduced the integral bearing his name, explaining this integral thus in a letter to Paul Montel:
As puts it, "To compute the Riemann integral of , one partitions the domain into subintervals", while in the Lebesgue integral, "one is in effect partitioning the range of ". The definition of the Lebesgue integral thus begins with a measure, μ. In the simplest case, the Lebesgue measure of an interval is its width, , so that the Lebesgue integral agrees with the (proper) Riemann integral when both exist. In more complicated cases, the sets being measured can be highly fragmented, with no continuity and no resemblance to intervals.

Using the "partitioning the range of " philosophy, the integral of a non-negative function should be the sum over of the areas between a thin horizontal strip between and . This area is just . Let }. The Lebesgue integral of is then defined by 
where the integral on the right is an ordinary improper Riemann integral ( is a strictly decreasing positive function, and therefore has a well-defined improper Riemann integral). For a suitable class of functions (the measurable functions) this defines the Lebesgue integral.

A general measurable function is Lebesgue-integrable if the sum of the absolute values of the areas of the regions between the graph of and the -axis is finite:
In that case, the integral is, as in the Riemannian case, the difference between the area above the -axis and the area below the -axis:
where

Although the Riemann and Lebesgue integrals are the most widely used definitions of the integral, a number of others exist, including:

The collection of Riemann-integrable functions on a closed interval forms a vector space under the operations of pointwise addition and multiplication by a scalar, and the operation of integration

is a linear functional on this vector space. Thus, firstly, the collection of integrable functions is closed under taking linear combinations; and, secondly, the integral of a linear combination is the linear combination of the integrals,

Similarly, the set of real-valued Lebesgue-integrable functions on a given measure space with measure is closed under taking linear combinations and hence form a vector space, and the Lebesgue integral

is a linear functional on this vector space, so that

More generally, consider the vector space of all measurable functions on a measure space , taking values in a locally compact complete topological vector space over a locally compact topological field . Then one may define an abstract integration map assigning to each function an element of or the symbol ,
that is compatible with linear combinations. In this situation, the linearity holds for the subspace of functions whose integral is an element of (i.e. "finite"). The most important special cases arise when is , , or a finite extension of the field of p-adic numbers, and is a finite-dimensional vector space over , and when and is a complex Hilbert space.

Linearity, together with some natural continuity properties and normalisation for a certain class of "simple" functions, may be used to give an alternative definition of the integral. This is the approach of Daniell for the case of real-valued functions on a set , generalized by Nicolas Bourbaki to functions with values in a locally compact topological vector space. See for an axiomatic characterisation of the integral.

A number of general inequalities hold for Riemann-integrable functions defined on a closed and bounded interval and can be generalized to other notions of integral (Lebesgue and Daniell).







In this section, is a real-valued Riemann-integrable function. The integral
over an interval is defined if . This means that the upper and lower sums of the function are evaluated on a partition whose values are increasing. Geometrically, this signifies that integration takes place "left to right", evaluating within intervals where an interval with a higher index lies to the right of one with a lower index. The values and , the end-points of the interval, are called the limits of integration of . Integrals can also be defined if :

This, with , implies:

The first convention is necessary in consideration of taking integrals over subintervals of ; the second says that an integral taken over a degenerate interval, or a point, should be zero. One reason for the first convention is that the integrability of on an interval implies that is integrable on any subinterval , but in particular integrals have the property that:

With the first convention, the resulting relation
is then well-defined for any cyclic permutation of , , and .

The "fundamental theorem of calculus" is the statement that differentiation and integration are inverse operations: if a continuous function is first integrated and then differentiated, the original function is retrieved. An important consequence, sometimes called the "second fundamental theorem of calculus", allows one to compute integrals by using an antiderivative of the function to be integrated.

Let be a continuous real-valued function defined on a closed interval . Let be the function defined, for all in , by
Then, is continuous on , differentiable on the open interval , and

for all in .

Let be a real-valued function defined on a closed interval [] that admits an antiderivative on . That is, and are functions such that for all in ,

If is integrable on then

The second fundamental theorem allows many integrals to be calculated explicitly. For example, to calculate the integral
of the square root function between 0 and 1, it is sufficient to find an antiderivative, that is, a function whose derivative equals :
One such function is . Then the value of the integral in question is

This is a case of a general rule, that for , with , an antiderivative is Tables of this and similar antiderivatives can be used to calculate integrals explicitly, in much the same way that tables of derivatives can be used.

A "proper" Riemann integral assumes the integrand is defined and finite on a closed and bounded interval, bracketed by the limits of integration. An improper integral occurs when one or more of these conditions is not satisfied. In some cases such integrals may be defined by considering the limit of a sequence of proper Riemann integrals on progressively larger intervals.

If the interval is unbounded, for instance at its upper end, then the improper integral is the limit as that endpoint goes to infinity.
If the integrand is only defined or finite on a half-open interval, for instance , then again a limit may provide a finite result.

That is, the improper integral is the limit of proper integrals as one endpoint of the interval of integration approaches either a specified real number, or , or . In more complicated cases, limits are required at both endpoints, or at interior points.

Just as the definite integral of a positive function of one variable represents the area of the region between the graph of the function and the "x"-axis, the "double integral" of a positive function of two variables represents the volume of the region between the surface defined by the function and the plane that contains its domain. For example, a function in two dimensions depends on two real variables, "x" and "y", and the integral of a function "f" over the rectangle "R" given as the Cartesian product of two intervals formula_74 can be written

where the differential indicates that integration is taken with respect to area. This double integral can be defined using Riemann sums, and represents the (signed) volume under the graph of over the domain "R". Under suitable conditions (e.g., if "f" is continuous), then Fubini's theorem guarantees that this integral can be expressed as an equivalent iterated integral

This reduces the problem of computing a double integral to computing one-dimensional integrals. Because of this, another notation for the integral over "R" uses a double integral sign:

Integration over more general domains is possible. The integral of a function "f", with respect to volume, over a subset "D" of ℝ is denoted by notation such as

or similar. See volume integral.

The concept of an integral can be extended to more general domains of integration, such as curved lines and surfaces. Such integrals are known as line integrals and surface integrals respectively. These have important applications in physics, as when dealing with vector fields.

A "line integral" (sometimes called a "path integral") is an integral where the function to be integrated is evaluated along a curve. Various different line integrals are in use. In the case of a closed curve it is also called a "contour integral".

The function to be integrated may be a scalar field or a vector field. The value of the line integral is the sum of values of the field at all points on the curve, weighted by some scalar function on the curve (commonly arc length or, for a vector field, the scalar product of the vector field with a differential vector in the curve). This weighting distinguishes the line integral from simpler integrals defined on intervals. Many simple formulas in physics have natural continuous analogs in terms of line integrals; for example, the fact that work is equal to force, , multiplied by displacement, , may be expressed (in terms of vector quantities) as:
For an object moving along a path in a vector field such as an electric field or gravitational field, the total work done by the field on the object is obtained by summing up the differential work done in moving from to . This gives the line integral

A "surface integral" generalizes double integrals to integration over a surface (which may be a curved set in space); it can be thought of as the double integral analog of the line integral. The function to be integrated may be a scalar field or a vector field. The value of the surface integral is the sum of the field at all points on the surface. This can be achieved by splitting the surface into surface elements, which provide the partitioning for Riemann sums.

For an example of applications of surface integrals, consider a vector field on a surface ; that is, for each point in , is a vector. Imagine that we have a fluid flowing through , such that determines the velocity of the fluid at . The flux is defined as the quantity of fluid flowing through in unit amount of time. To find the flux, we need to take the dot product of with the unit surface normal to at each point, which will give us a scalar field, which we integrate over the surface:
The fluid flux in this example may be from a physical fluid such as water or air, or from electrical or magnetic flux. Thus surface integrals have applications in physics, particularly with the classical theory of electromagnetism.

In complex analysis, the integrand is a complex-valued function of a complex variable instead of a real function of a real variable . When a complex function is integrated along a curve formula_82 in the complex plane, the integral is denoted as follows

This is known as a contour integral.

A differential form is a mathematical concept in the fields of multivariable calculus, differential topology, and tensors. Differential forms are organized by degree. For example, a one-form is a weighted sum of the differentials of the coordinates, such as:
where "E", "F", "G" are functions in three dimensions. A differential one-form can be integrated over an oriented path, and the resulting integral is just another way of writing a line integral. Here the basic differentials "dx", "dy", "dz" measure infinitesimal oriented lengths parallel to the three coordinate axes.

A differential two-form is a sum of the form
Here the basic two-forms formula_86 measure oriented areas parallel to the coordinate two-planes. The symbol formula_87 denotes the wedge product, which is similar to the cross product in the sense that the wedge product of two forms representing oriented lengths represents an oriented area. A two-form can be integrated over an oriented surface, and the resulting integral is equivalent to the surface integral giving the flux of formula_88.

Unlike the cross product, and the three-dimensional vector calculus, the wedge product and the calculus of differential forms makes sense in arbitrary dimension and on more general manifolds (curves, surfaces, and their higher-dimensional analogs). The exterior derivative plays the role of the gradient and curl of vector calculus, and Stokes' theorem simultaneously generalizes the three theorems of vector calculus: the divergence theorem, Green's theorem, and the Kelvin-Stokes theorem.

The discrete equivalent of integration is summation. Summations and integrals can be put on the same foundations using the theory of Lebesgue integrals or time scale calculus.

The most basic technique for computing definite integrals of one real variable is based on the fundamental theorem of calculus. Let be the function of to be integrated over a given interval . Then, find an antiderivative of ; that is, a function such that on the interval. Provided the integrand and integral have no singularities on the path of integration, by the fundamental theorem of calculus,

The integral is not actually the antiderivative, but the fundamental theorem provides a way to use antiderivatives to evaluate definite integrals.

The most difficult step is usually to find the antiderivative of . It is rarely possible to glance at a function and write down its antiderivative. More often, it is necessary to use one of the many techniques that have been developed to evaluate integrals. Most of these techniques rewrite one integral as a different one which is hopefully more tractable. Techniques include:
Alternative methods exist to compute more complex integrals. Many nonelementary integrals can be expanded in a Taylor series and integrated term by term. Occasionally, the resulting infinite series can be summed analytically. The method of convolution using Meijer G-functions can also be used, assuming that the integrand can be written as a product of Meijer G-functions. There are also many less common ways of calculating definite integrals; for instance, Parseval's identity can be used to transform an integral over a rectangular region into an infinite sum. Occasionally, an integral can be evaluated by a trick; for an example of this, see Gaussian integral.

Computations of volumes of solids of revolution can usually be done with disk integration or shell integration.

Specific results which have been worked out by various techniques are collected in the list of integrals.

Many problems in mathematics, physics, and engineering involve integration where an explicit formula for the integral is desired. Extensive tables of integrals have been compiled and published over the years for this purpose. With the spread of computers, many professionals, educators, and students have turned to computer algebra systems that are specifically designed to perform difficult or tedious tasks, including integration. Symbolic integration has been one of the motivations for the development of the first such systems, like Macsyma.

A major mathematical difficulty in symbolic integration is that in many cases, a closed formula for the antiderivative of a rather simple-looking function does not exist. For instance, it is known that the antiderivatives of the functions and cannot be expressed in the closed form involving only rational and exponential functions, logarithm, trigonometric functions and inverse trigonometric functions, and the operations of multiplication and composition; in other words, none of the three given functions is integrable in elementary functions, which are the functions which may be built from rational functions, roots of a polynomial, logarithm, and exponential functions. The Risch algorithm provides a general criterion to determine whether the antiderivative of an elementary function is elementary, and, if it is, to compute it. Unfortunately, it turns out that functions with closed expressions of antiderivatives are the exception rather than the rule. Consequently, computerized algebra systems have no hope of being able to find an antiderivative for a randomly constructed elementary function. On the positive side, if the 'building blocks' for antiderivatives are fixed in advance, it may be still be possible to decide whether the antiderivative of a given function can be expressed using these blocks and operations of multiplication and composition, and to find the symbolic answer whenever it exists. The Risch algorithm, implemented in Mathematica and other computer algebra systems, does just that for functions and antiderivatives built from rational functions, radicals, logarithm, and exponential functions.

Some special integrands occur often enough to warrant special study. In particular, it may be useful to have, in the set of antiderivatives, the special functions (like the Legendre functions, the hypergeometric function, the gamma function, the incomplete gamma function and so on — see Symbolic integration for more details). Extending the Risch's algorithm to include such functions is possible but challenging and has been an active research subject.

More recently a new approach has emerged, using "D"-finite functions, which are the solutions of linear differential equations with polynomial coefficients. Most of the elementary and special functions are "D"-finite, and the integral of a "D"-finite function is also a "D"-finite function. This provides an algorithm to express the antiderivative of a "D"-finite function as the solution of a differential equation.

This theory also allows one to compute the definite integral of a "D"-function as the sum of a series given by the first coefficients, and provides an algorithm to compute any coefficient.

Some integrals found in real applications can be computed by closed-form antiderivatives. Others are not so accommodating. Some antiderivatives do not have closed forms, some closed forms require special functions that themselves are a challenge to compute, and others are so complex that finding the exact answer is too slow. This motivates the study and application of numerical approximations of integrals. This subject, called "numerical integration" or "numerical quadrature", arose early in the study of integration for the purpose of making hand calculations. The development of general-purpose computers made numerical integration more practical and drove a desire for improvements. The goals of numerical integration are accuracy, reliability, efficiency, and generality, and sophisticated modern methods can vastly outperform a naive method by all four measures (; ; ).

Consider, for example, the integral
which has the exact answer . (In ordinary practice, the answer is not known in advance, so an important task — not explored here — is to decide when an approximation is good enough.) A “calculus book” approach divides the integration range into, say, 16 equal pieces, and computes function values.

Using the left end of each piece, the rectangle method sums 16 function values and multiplies by the step width, , here 0.25, to get an approximate value of 3.94325 for the integral. The accuracy is not impressive, but calculus formally uses pieces of infinitesimal width, so initially this may seem little cause for concern. Indeed, repeatedly doubling the number of steps eventually produces an approximation of 3.76001. However, 2 pieces are required, a great computational expense for such little accuracy; and a reach for greater accuracy can force steps so small that arithmetic precision becomes an obstacle.

A better approach replaces the rectangles used in a Riemann sum with trapezoids. The trapezoid rule is almost as easy to calculate; it sums all 17 function values, but weights the first and last by one half, and again multiplies by the step width. This immediately improves the approximation to 3.76925, which is noticeably more accurate. Furthermore, only 2 pieces are needed to achieve 3.76000, substantially less computation than the rectangle method for comparable accuracy. The idea behind the trapezoid rule, that more accurate approximations to the function yield better approximations to the integral, can be carried further. Simpson's rule approximates the integrand by a piecewise quadratic function. Riemann sums, the trapezoid rule, and Simpson's rule are examples of a family of quadrature rules called Newton–Cotes formulas. The degree Newton–Cotes quadrature rule approximates the polynomial on each subinterval by a degree polynomial. This polynomial is chosen to interpolate the values of the function on the interval. Higher degree Newton-Cotes approximations can be more accurate, but they require more function evaluations (already Simpson's rule requires twice the function evaluations of the trapezoid rule), and they can suffer from numerical inaccuracy due to Runge's phenomenon. One solution to this problem is Clenshaw–Curtis quadrature, in which the integrand is approximated by expanding it in terms of Chebyshev polynomials. This produces an approximation whose values never deviate far from those of the original function.

Romberg's method builds on the trapezoid method to great effect. First, the step lengths are halved incrementally, giving trapezoid approximations denoted by , and so on, where is half of . For each new step size, only half the new function values need to be computed; the others carry over from the previous size (as shown in the table above). But the really powerful idea is to interpolate a polynomial through the approximations, and extrapolate to . With this method a numerically "exact" answer here requires only four pieces (five function values). The Lagrange polynomial interpolating {(4.00,6.128), (2.00,4.352), (1.00,3.908)} is 3.76 + 0.148, producing the extrapolated value 3.76 at .

Gaussian quadrature often requires noticeably less work for superior accuracy. In this example, it can compute the function values at just two positions, , then double each value and sum to get the numerically exact answer. The explanation for this dramatic success lies in the choice of points. Unlike Newton–Cotes rules, which interpolate the integrand at evenly spaced points, Gaussian quadrature evaluates the function at the roots of a set of orthogonal polynomials. An -point Gaussian method is exact for polynomials of degree up to . The function in this example is a degree 3 polynomial, plus a term that cancels because the chosen endpoints are symmetric around zero. (Cancellation also benefits the Romberg method.)

In practice, each method must use extra evaluations to ensure an error bound on an unknown function; this tends to offset some of the advantage of the pure Gaussian method, and motivates the popular Gauss–Kronrod quadrature formulae. More broadly, adaptive quadrature partitions a range into pieces based on function properties, so that data points are concentrated where they are needed most.

The computation of higher-dimensional integrals (for example, volume calculations) makes important use of such alternatives as Monte Carlo integration.

A calculus text is no substitute for numerical analysis, but the reverse is also true. Even the best adaptive numerical code sometimes requires a user to help with the more demanding integrals. For example, improper integrals may require a change of variable or methods that can avoid infinite function values, and known properties like symmetry and periodicity may provide critical leverage. For example, the integral formula_91 is difficult to evaluate numerically because it is infinite at . However, the substitution transforms the integral into formula_92, which has no singularities at all.

The area of an arbitrary two-dimensional shape can be determined using a measuring instrument called planimeter. The volume of irregular objects can be measured with precision by the fluid displaced as the object is submerged.

Area can sometimes be found via geometrical compass-and-straightedge constructions of an equivalent square.







</doc>
<doc id="15533" url="https://en.wikipedia.org/wiki?curid=15533" title="Zionist political violence">
Zionist political violence

Zionist political violence refers to acts of violence or terror committed by Zionists. 

The period of Zionist political violence started on June 30, 1924, and continued on a sporadic basis until September 17, 1948. There have not been any acts of Zionist political violence since the time of the Israeli War of Independence in 1948, after which the Lehi was disbanded. 

Actions were carried out by individuals and Jewish paramilitary groups such as the Irgun, the Lehi, the Haganah and the Palmach as part of a conflict between Jews, British authorities, and Palestinian Arabs, regarding land, immigration, and control over Palestine.

British soldiers and officials, United Nations personnel, Palestinian Arab fighters and civilians, and Jewish fighters and civilians were targets or victims of these actions. Domestic, commercial, and government property, infrastructure, and material have also been attacked.

During World War I, Zionist volunteers fought in the Jewish Legion of the British Army against the Ottoman Turks

During the 1920 Nebi Musa riots, the 1921 Jaffa riots and the 1929 Palestine riots, Palestinian Arabs manifested hostility against Zionist immigration, which provoked the reaction of Jewish militias. In 1935, the Irgun, a Zionist underground military organization, split off from the Haganah. The Irgun were the armed expression of the nascent ideology of Revisionist Zionism founded by Ze'ev Jabotinsky. He expressed this ideology as ""every Jew had the right to enter Palestine; only active retaliation would deter the Arab and the British; only Jewish armed force would ensure the Jewish state"".

During the 1936–39 Arab revolt in Palestine, Palestinian Arabs fought for the end of the Mandate and the creation of an Arab state based on the whole of Palestine. They attacked both British and Jews as well as some Palestinian Arabs who supported a Pan-Arabism. Mainstream Zionists, represented by the Vaad Leumi and the Haganah, practiced the policy of Havlagah (restraint), while Irgun militants did not follow this policy and called themselves "Havlagah breakers." The Irgun began bombing Palestinian Arab civilian targets in 1938. While the Palestinian Arabs were "carefully disarmed" by the British Mandatory authorities by 1939, the Zionists were not.

After the beginning of World War II, the Haganah and Irgun suspended their activity against the British in support of their war against Nazi Germany. The smaller Lehi continued anti-British attacks and direct action throughout the war. At that time, the British also supported the creation and the training of Palmach, as a unit that could withstand a German offensive in the area, with the consent of Yishuv which saw an opportunity to get trained units and soldiers for the planned Jewish state and during 1944–1945, the most mainstream Jewish paramilitary organization, Haganah, cooperated with the British authorities against the Lehi and Etzel.

After World War II, between 1945 and the 29 November 1947 Partition vote, British soldiers and policemen were targeted by Irgun and Lehi. Haganah and Palmah first collaborated with the British against them, particularly during the Hunting Season, before actively joining them in the Jewish Resistance Movement, then finally choosing an official neutral position after 1946 while the Irgun and the Lehi went on their attacks against the British.

The Haganah carried out violent attacks in Palestine, such as the liberation of interned immigrants from the Atlit camp, the bombing of the country's railroad network, sabotage raids on radar installations and bases of the British Palestine police. It also continued to organize illegal immigration.

In February 1947, the British announced that they would end the mandate and withdraw from Palestine and they asked the arbitration of the United Nations. After the vote of the Partition Plan for Palestine on 30 November 1947, civil war broke out in Palestine. Jewish and Arab communities fought each other violently in campaigns of attacks, retaliations and counter-retaliations which provoked around 800 deaths after two months. Arab volunteers entered Palestine to fight alongside the Palestinian Arabs. In April, 6 weeks before the termination of the Mandate, the Jewish militias launched wide operations to control the territory dedicated to them by the Partition Plan. Many atrocities occurred during this time. The Arab population in the mixed cities of Tiberias, Safed, Haifa, Jaffa, Beisan and Acre and in the neighbouring villages fled or were expelled during this period. During the Battle for Jerusalem (1948) where the Jewish community of 100,000 people was besieged, most Arab villages of the Tel Aviv – Jerusalem corridor were captured by Jewish militias and leveled.

At the beginning of the civil war, the Jewish militias organized several bombing attacks against civilians and military Arab targets. On 12 December, Irgun placed a car bomb opposite the Damascus Gate, killing 20 people. On 4 January 1948, the Lehi detonated a lorry bomb against the headquarters of the paramilitary Najjada located in Jaffa's Town Hall, killing 15 Arabs and injuring 80. During the night between 5 and 6 January, the Haganah bombed the Semiramis Hotel in Jerusalem that had been reported to hide Arab militiamen, killing 24 people. The next day, Irgun members in a stolen police van rolled a barrel bomb into a large group of civilians who were waiting for a bus by the Jaffa Gate, killing around 16. Another Irgun bomb went off in the Ramla market on February 18, killing 7 residents and injuring 45. On 28 February, the Palmah organised a bombing attack against a garage at Haifa, killing 30 people.

Irgun was described as a terrorist organization by the United Nations, British, and United States governments, and in media such as "The New York Times" newspaper, and by the Anglo-American Committee of Inquiry. In 1946, The World Zionist Congress strongly condemned terrorist activities in Palestine and "the shedding of innocent blood as a means of political warfare". Irgun was specifically condemned.

Menachem Begin was called a terrorist and a fascist by Albert Einstein and 27 other prominent Jewish intellectuals in a letter to the New York Times which was published on December 4, 1948. Specifically condemned was the participation of the Irgun in the Deir Yassin massacre:


The letter warns American Jews against supporting Begin's request for funding of his political party Herut, and ends with the warning:

Lehi was described as a terrorist organization by the British authorities and United Nations mediator Ralph Bunche.

During the conflict between Arabs and Jews in Palestine before the war, the criterion of "Purity of arms" was used to distinguish between the respective attitudes of the Irgun and Haganah towards Arabs, with the latter priding itself on its adherence to principle. The Jewish society in the British Mandate Palestine generally disapproved and denounced violent attacks both on grounds moral rejection and political disagreement, stressing that terrorism is counter-productive in the Zionist quest for Jewish self-determination. Generally speaking, this precept requires that "weapons remain pure [and that] they are employed only in self-defence and [never] against innocent civilians and defenceless people". But if it "remained a central value in education" it was "rather vague and intentionally blurred" at the practical level.

In 1946, at a meeting held between the heads of the Haganah, David Ben-Gurion predicted a confrontation between the Arabs of Palestine and the Arab states. Concerning the "principle of purity of arms", he stressed that: "The end does not justify all means. Our war is based on moral grounds" and during the 1948 War, the Mapam, the political party affiliated to Palmach, asked "a strict observance of the Jewish Purity of arms to secure the moral character of [the] war". When he was later criticized by Mapam members for his attitude concerning the Arab refugee problem, Ben-Gurion reminded them of the Palestinian exodus from Lydda and Ramle and the fact Palmah officers had been responsible for the "outrage that had encouraged the Arabs' flight made the party uncomfortable."

According to Avi Shlaim, this condemnation of the use of violence is one of the key features of 'the conventional Zionist account or old history' whose 'popular-heroic-moralistic version' is 'taught in Israeli schools and used extensively in the quest for legitimacy abroad'. Benny Morris adds that '[t]he Israelis' collective memory of fighters characterized by "purity of arms" is also undermined by the evidence of [the dozen case] of rapes committed in conquered towns and villages.' According to him, 'after the 1948 war, the Israelis tended to hail the "purity of arms" of its militiamen and soldiers to contrast this with Arab barbarism, which on occasion expressed itself in the mutilation of captured Jewish corpses.' According to him, 'this reinforced the Israelis' positive self-image and helped them "sell" the new state abroad and (...) demonized the enemy'.

Some Israelis justify acts of political violence. Sixty years after participating in the assassination of Count Bernadotte, Geula Cohen had no regrets. As a broadcaster on Lehi's radio, she recalled the threats against Bernadotte in advance of the assassination. "I told him if you are not going to leave Jerusalem and go to your Stockholm, you won't be any more." Asked if it was right to assassinate Bernadotte, she replied, "There is no question about it. We would not have Jerusalem any more." In July 2006, the Menachem Begin Heritage Center organized a conference to mark the 60th anniversary of the King David Hotel bombing. The conference was attended by past and future Prime Minister Benjamin Netanyahu and former members of Irgun. The British Ambassador in Tel Aviv and the Consul-General in Jerusalem protested that a plaque commemorating the bombing stated "For reasons known only to the British, the hotel was not evacuated." Netanyahu, then chairman of Likud and Leader of the Opposition in the Knesset, opined that the bombing was a legitimate act with a military target, distinguishing it from an act of terror intended to harm civilians, since Irgun sent warnings to evacuate the building. He said "Imagine that Hamas or Hizbullah would call the military headquarters in Tel Aviv and say, 'We have placed a bomb and we are asking you to evacuate the area.' They don't do that. That is the difference." The British Ambassador in Tel Aviv and the Consul-General in Jerusalem protested, saying "We do not think that it is right for an act of terrorism, which led to the loss of many lives, to be commemorated", and wrote to the Mayor of Jerusalem that such an "act of terror" could not be honored. The British government also demanded the removal of the plaque, pointing out that the statement on it accusing the British of failing to evacuate the hotel was untrue and "did not absolve those who planted the bomb." To prevent a diplomatic incident, changes were made in the plaque's text. The final English version says "Warning phone calls have been made to the hotel, The Palestine Post and the French Consulate, urging the hotel's occupants to leave immediately. The hotel was not evacuated and after 25 minutes the bombs exploded. To the Irgun's regret, 92 persons were killed."





</doc>
<doc id="15536" url="https://en.wikipedia.org/wiki?curid=15536" title="List of airports">
List of airports

An airport is an aerodrome with facilities for flights to take off and land. Airports often have facilities to store and maintain aircraft, and a control tower. An airport consists of a landing area, which comprises an aerially accessible open space including at least one operationally active surface such as a runway for a plane to take off or a helipad, and often includes adjacent utility buildings such as control towers, hangars and terminals.

An airport with a helipad for rotorcraft but no runway is called a heliport. An airport for use by seaplanes and amphibious aircraft is called a seaplane base. Such a base typically includes a stretch of open water for takeoffs and landings, and seaplane docks for tying-up.

An international airport has additional facilities for customs and immigration.





</doc>
<doc id="15538" url="https://en.wikipedia.org/wiki?curid=15538" title="Inclusion body myositis">
Inclusion body myositis

Inclusion body myositis (IBM) [my-oh-SIGH-tis] (sometimes called sporadic inclusion body myositis, sIBM) is the most common inflammatory muscle disease in older adults. The disease is characterized by slowly progressive weakness and wasting of both distal and proximal muscles, most apparent in the finger flexors and knee extensors. IBM is often confused with an entirely different class of diseases, called hereditary inclusion body myopathies (hIBM). The "M" in hIBM is an abbreviation for "myopathy" while the "M" in IBM is an abbreviation for "myositis". These diseases should not be confused with each other. In IBM, two processes appear to occur in the muscles in parallel, one autoimmune and the other degenerative. Inflammation is evident from the invasion of muscle fibers by immune cells. Degeneration is characterized by the appearance of holes, deposits of abnormal proteins, and filamentous inclusions in the muscle fibers. sIBM is a rare disease, with a prevalence ranging from 1 to 71 individuals per million.

Weakness comes on slowly (over months to years) in an asymmetric manner and progresses steadily, leading to severe weakness and wasting of arm and leg muscles. IBM is more common in men than women. Patients may become unable to perform activities of daily living and most require assistive devices within 5 to 10 years of symptom onset. sIBM is not considered a fatal disorder, but the risk of serious injury due to falls is increased. Death in IBM is sometimes related to malnutrition and respiratory failure. There is no effective treatment for the disease.

How sIBM affects individuals is quite variable as is the age of onset (which generally varies from the forties upwards). Because sIBM affects different people in different ways and at different rates, there is no "textbook case."

Eventually, sIBM results in general, progressive muscle weakness. The quadriceps and forearm muscles are usually affected early on. Common early symptoms include frequent tripping and falling, weakness going up stairs and trouble manipulating the fingers (including difficulty with tasks such as turning doorknobs or gripping keys). Foot drop in one or both feet has been a symptom of IBM and advanced stages of polymyositis (PM).

During the course of the illness, the patient's mobility is progressively restricted as it becomes hard for him or her to bend down, reach for things, walk quickly and so on. Many patients say they have balance problems and fall easily, as the muscles cannot compensate for an off-balanced posture. Because sIBM makes the leg muscles weak and unstable, patients are very vulnerable to serious injury from tripping or falling down. Although pain has not been traditionally part of the "textbook" description, many patients report severe muscle pain, especially in the thighs.

When present, difficulty swallowing (dysphagia) is a progressive condition in those with inclusion body myositis and often leads to death from aspiration pneumonia. Dysphagia is present in 40 to 85% of IBM cases.

IBM can also result in diminished capacity for aerobic exercise. This decline is most likely a consequence of the sedentary lifestyle that is often associated with the symptoms of IBM (i.e. progressive muscle weakness, decreased mobility, and increased level of fatigue). Therefore, one focus of treatment should be the improvement of aerobic capacity.

Patients with sIBM usually eventually need to resort to a cane or a walker and in most cases, a wheelchair eventually becomes a necessity.

"The progressive course of s-IBM leads slowly to severe disability. Finger functions can become very impaired, such as for manipulating pens, keys, buttons, and zippers, pulling handles, and firmly grasping handshakes. Arising from a chair becomes difficult. Walking becomes more precarious. Sudden falls, sometimes resulting in major injury to the skull or other bones, can occur, even from walking on minimally-irregular ground or from other minor imbalances outside or in the home, due to weakness of quadriceps and gluteus muscles depriving the patient of automatic posture maintenance. A foot-drop can increase the likelihood of tripping. Dysphagia can occur, usually caused by upper esophageal constriction that often can be symptomatically improved, for several months to years, by bougie dilation per a GI or ENT physician. Respiratory muscle weakness can sometimes eventuate."

The cause of IBM is unknown. IBM likely results from the interaction of a number of genetic and environmental factors.

There are two major theories about how sIBM is caused. One hypothesis suggests that the inflammation-immune reaction, caused by an unknown trigger – likely an undiscovered virus or an autoimmune disorder– is the primary cause of sIBM and that the degeneration of muscle fibers and protein abnormalities are secondary features. Despite the arguments "in favor of an adaptive immune response in sIBM, a purely autoimmune hypothesis for sIBM is untenable because of the disease's resistance to most immunotherapy."

The second school of thought advocates the theory that sIBM is a degenerative disorder related to aging of the muscle fibers and that abnormal, potentially pathogenic protein accumulations in myofibrils play a key causative role in sIBM (apparently before the immune system comes into play). This hypothesis emphasizes the abnormal intracellular accumulation of many proteins, protein aggregation and misfolding, proteosome inhibition, and endoplasmic reticulum (ER) stress.

One review discusses the "limitations in the beta-amyloid-mediated theory of IBM myofiber injury."

Dalakas (2006) suggested that a chain of events causes IBM—some sort of virus, likely a retrovirus, triggers the cloning of T cells. These T cells appear to be driven by specific antigens to invade muscle fibers. In people with sIBM, the muscle cells display “flags” telling the immune system that they are infected or damaged (the muscles ubiquitously express MHC class I antigens) and this immune process leads to the death of muscle cells. The chronic stimulation of these antigens also causes stress inside the muscle cell in the endoplasmic reticulum (ER) and this ER stress may be enough to cause a self-sustaining T cell response (even after a virus has dissipated). In addition, this ER stress may cause the misfolding of protein. The ER is in charge of processing and folding molecules carrying antigens. In IBM, muscle fibers are overloaded with these major histocompatibility complex (MHC) molecules that carry the antigen protein pieces, leading to more ER stress and more protein misfolding.

A self-sustaining T cell response would make sIBM a type of autoimmune disorder. When studied carefully, it has not been impossible to detect an ongoing viral infection in the muscles. One theory is that a chronic viral infection might be the initial triggering factor setting IBM in motion. There have been a handful of IBM cases—approximately 15—that have shown clear evidence of a virus called HTLV-1. The HTLV-1 virus can cause leukemia, but in most cases lies dormant and most people end up being lifelong carriers of the virus. One review says that the best evidence points towards a connection with some type of retrovirus and that a retroviral infection combined with immune recognition of the retrovirus is enough to trigger the inflammation process.


sIBM is not inherited and is not passed on to the children of IBM patients. There are genetic features that do not directly cause IBM but that appear to predispose a person to getting IBM — having this particular combination of genes increases one's susceptibility to getting IBM. Some 67% of IBM patients have a particular combination of human leukocyte antigen genes in a section of the 8.1 ancestral haplotype in the center of the MHC class II region. sIBM is not passed on from generation to generation, although the susceptibility region of genes may be.

There are also several rare forms of hereditary inclusion body myopathy that are linked to specific genetic defects and that are passed on from generation to generation. Since these forms do not show features of muscle inflammation, they are classified as myopathies rather than forms of myositis. Because they do not display inflammation as a primary symptom, they may in fact be similar, but different diseases to sporadic inclusion body myositis. There are several different types, each inherited in different ways. See hereditary inclusion body myopathy.

A 2007 review concluded there is no indication that the genes responsible for the familial or hereditary conditions are involved in sIBM.

Elevated creatine kinase (CK) levels in the blood (at most ~10 times normal) are typical in sIBM but affected individuals can also present with normal CK levels. Electromyography (EMG) studies usually display abnormalities. Muscle biopsy may display several common findings including; inflammatory cells invading muscle cells, vacuolar degeneration, inclusions or plaques of abnormal proteins. sIBM is a challenge to the pathologist and even with a biopsy, diagnosis can be ambiguous.

A diagnosis of inclusion body myositis was historically dependent on muscle biopsy results. Antibodies to cytoplasmic 5'-nucleotidase (cN1A; NT5C1A) have been strongly associated with the condition. In the clinical context of a classic history and positive antibodies, a muscle biopsy might be unnecessary.

IBM is often initially misdiagnosed as polymyositis. A course of prednisone is typically completed with no improvement and eventually sIBM is confirmed. sIBM weakness comes on over months or years and progresses steadily, whereas polymyositis has an onset of weeks or months. Other forms of muscular dystrophy (e.g. limb girdle) must be considered as well.


There is no standard course of treatment to slow or stop the progression of the disease. sIBM patients do not reliably respond to the anti-inflammatory, immunosuppressant, or immunomodulatory medications. Management is symptomatic. Prevention of falls is an important consideration. Specialized exercise therapy may supplement treatment to enhance quality of life. Physical therapy is recommended to teach the patient a home exercise program, to teach how to compensate during mobility-gait training with an assistive device, transfers and bed mobility.

When sIBM was originally described, the major feature noted was muscle inflammation. Two other disorders were also known to display muscle inflammation, and sIBM was classified along with them. They are dermatomyositis (DM) and polymyositis (PM) and all three illnesses were called idiopathic (of unknown origin) myositis or inflammatory myopathies.

It appears that sIBM and polymyositis share some features, especially the initial sequence of immune system activation, however, polmyositis comes on over weeks or months, does not display the subsequent muscle degeneration and protein abnormalities as seen in IBM, and as well, polymyositis tends to respond well to treatments, IBM does not. IBM is often confused with (misdiagnosed as) polymyositis. Polymyositis that does not respond to treatment is likely IBM.

Dermatomyositis shares a number of similar physical symptoms and histopathological traits as polymyositis, but exhibits a skin rash not seen in polymyositis or sIBM. It may have different root causes unrelated to either polymyositis or sIBM.

Mutations in valosin-containing protein (VCP) cause multisystem proteinopathy (MSP), which can present (among others) as a rare form of inclusion body myopathy.



</doc>
<doc id="15539" url="https://en.wikipedia.org/wiki?curid=15539" title="Ion implantation">
Ion implantation

Ion implantation is a low-temperature process by which ions of one element are accelerated into a solid target, thereby changing the physical, chemical, or electrical properties of the target. Ion implantation is used in semiconductor device fabrication and in metal finishing, as well as in materials science research. The ions can alter the elemental composition of the target (if the ions differ in composition from the target) if they stop and remain in the target. Ion implantation also causes chemical and physical changes when the ions impinge on the target at high energy. The crystal structure of the target can be damaged or even destroyed by the energetic collision cascades, and ions of sufficiently high energy (10s of MeV) can cause nuclear transmutation.

Ion implantation equipment typically consists of an ion source, where ions of the desired element are produced, an accelerator, where the ions are electrostatically accelerated to a high energy, and a target chamber, where the ions impinge on a target, which is the material to be implanted. Thus ion implantation is a special case of particle radiation. Each ion is typically a single atom or molecule, and thus the actual amount of material implanted in the target is the integral over time of the ion current. This amount is called the dose. The currents supplied by implants are typically small (micro-amperes), and thus the dose which can be implanted in a reasonable amount of time is small. Therefore, ion implantation finds application in cases where the amount of chemical change required is small.

Typical ion energies are in the range of 10 to 500 keV (1,600 to 80,000 aJ). Energies in the range 1 to 10 keV (160 to 1,600 aJ) can be used, but result in a penetration of only a few nanometers or less. Energies lower than this result in very little damage to the target, and fall under the designation ion beam deposition. Higher energies can also be used: accelerators capable of 5 MeV (800,000 aJ) are common. However, there is often great structural damage to the target, and because the depth distribution is broad (Bragg peak), the net composition change at any point in the target will be small.

The energy of the ions, as well as the ion species and the composition of the target determine the depth of penetration of the ions in the solid: A monoenergetic ion beam will generally have a broad depth distribution. The average penetration depth is called the range of the ions. Under typical circumstances ion ranges will be between 10 nanometers and 1 micrometer. Thus, ion implantation is especially useful in cases where the chemical or structural change is desired to be near the surface of the target. Ions gradually lose their energy as they travel through the solid, both from occasional collisions with target atoms (which cause abrupt energy transfers) and from a mild drag from overlap of electron orbitals, which is a continuous process. The loss of ion energy in the target is called stopping and can be simulated with the binary collision approximation method.

Accelerator systems for ion implantation are generally classified into medium current (ion beam currents between 10 μA and ~2 mA), high current (ion beam currents up to ~30 mA), high energy (ion energies above 200 keV and up to 10 MeV), and very high dose (efficient implant of dose greater than 10ions/cm).

All varieties of ion implantation beamline designs contain certain general groups of functional components (see image). The first major segment of an ion beamline includes a device known as an ion source to generate the ion species. The source is closely coupled to biased electrodes for extraction of the ions into the beamline and most often to some means of selecting a particular ion species for transport into the main accelerator section. The "mass" selection is often accompanied by passage of the extracted ion beam through a magnetic field region with an exit path restricted by blocking apertures, or "slits", that allow only ions with a specific value of the product of mass and velocity/charge to continue down the beamline. If the target surface is larger than the ion beam diameter and a uniform distribution of implanted dose is desired over the target surface, then some combination of beam scanning and wafer motion is used. Finally, the implanted surface is coupled with some method for collecting the accumulated charge of the implanted ions so that the delivered dose can be measured in a continuous fashion and the implant process stopped at the desired dose level.

Semiconductor doping with boron, phosphorus, or arsenic is a common application of ion implantation. When implanted in a semiconductor, each dopant atom can create a charge carrier in the semiconductor after annealing. A hole can be created for a p-type dopant, and an electron for an n-type dopant. This modifies the conductivity of the semiconductor in its vicinity. The technique is used, for example, for adjusting the threshold of a MOSFET.

Ion implantation was developed as a method of producing the p-n junction of photovoltaic devices in the late 1970s and early 1980s, along with the use of pulsed-electron beam for rapid annealing, although it has not to date been used for commercial production.

One prominent method for preparing silicon on insulator (SOI) substrates from conventional silicon substrates is the "SIMOX" (separation by implantation of oxygen) process, wherein a buried high dose oxygen implant is converted to silicon oxide by a high temperature annealing process.

Mesotaxy is the term for the growth of a crystallographically matching phase underneath the surface of the host crystal (compare to epitaxy, which is the growth of the matching phase on the surface of a substrate). In this process, ions are implanted at a high enough energy and dose into a material to create a layer of a second phase, and the temperature is controlled so that the crystal structure of the target is not destroyed. The crystal orientation of the layer can be engineered to match that of the target, even though the exact crystal structure and lattice constant may be very different. For example, after the implantation of nickel ions into a silicon wafer, a layer of nickel silicide can be grown in which the crystal orientation of the silicide matches that of the silicon.

Nitrogen or other ions can be implanted into a tool steel target (drill bits, for example). The structural change caused by the implantation produces a surface compression in the steel, which prevents crack propagation and thus makes the material more resistant to fracture. The chemical change can also make the tool more resistant to corrosion.

In some applications, for example prosthetic devices such as artificial joints, it is desired to have surfaces very resistant to both chemical corrosion and wear due to friction. Ion implantation is used in such cases to engineer the surfaces of such devices for more reliable performance. As in the case of tool steels, the surface modification caused by ion implantation includes both a surface compression which prevents crack propagation and an alloying of the surface to make it more chemically resistant to corrosion.

Ion implantation can be used to achieve ion beam mixing, i.e. mixing up atoms of different elements at an interface. This may be useful for achieving graded interfaces or strengthening adhesion between layers of immiscible materials.

Ion implantation may be used to induce nano-dimensional particles in oxides such as sapphire and silica. The particles may be formed as a result of precipitation of the ion implanted species, they may be formed as a result of the production of an mixed oxide species that contains both the ion-implanted element and the oxide substrate, and they may be formed as a result of a reduction of the substrate, first reported by Hunt and Hampikian. Typical ion beam energies used to produce nanoparticles range from 50 to 150 keV, with ion fluences that range from 10 to 10 ions/cm. The table below summarizes some of the work that has been done in this field for a sapphire substrate. A wide variety of nanoparticles can be formed, with size ranges from 1 nm on up to 20 nm and with compositions that can contain the implanted species, combinations of the implanted ion and substrate, or that are comprised solely from the cation associated with the substrate.

Composite materials based on dielectrics such as sapphire that contain dispersed metal nanoparticles are promising materials for optoelectronics and nonlinear optics.

Each individual ion produces many point defects in the target crystal on impact such as vacancies and interstitials. Vacancies are crystal lattice points unoccupied by an atom: in this case the ion collides with a target atom, resulting in transfer of a significant amount of energy to the target atom such that it leaves its crystal site. This target atom then itself becomes a projectile in the solid, and can cause successive collision events.
Interstitials result when such atoms (or the original ion itself) come to rest in the solid, but find no vacant space in the lattice to reside. These point defects can migrate and cluster with each other, resulting in dislocation loops and other defects.

Because ion implantation causes damage to the crystal structure of the target which is often unwanted, ion implantation processing is often followed by a thermal annealing. This can be referred to as damage recovery.

The amount of crystallographic damage can be enough to completely amorphize the surface of the target: i.e. it can become an amorphous solid (such a solid produced from a melt is called a glass). In some cases, complete amorphization of a target is preferable to a highly defective crystal: An amorphized film can be regrown at a lower temperature than required to anneal a highly damaged crystal. Amorphisation of the substrate can occur as a result of the beam damage. For example, yttrium ion implantation into sapphire at an ion beam energy of 150 keV to a fluence of 5*10 Y/cm produces an amorphous glassy layer approximately 110 nm in thickness, measured from the outer surface. [Hunt, 1999]

Some of the collision events result in atoms being ejected (sputtered) from the surface, and thus ion implantation will slowly etch away a surface. The effect is only appreciable for very large doses.

If there is a crystallographic structure to the target, and especially in semiconductor substrates where the crystal structure is more open, particular crystallographic directions offer much lower stopping than other directions. The result is that the range of an ion can be much longer if the ion travels exactly along a particular direction, for example the <110> direction in silicon and other diamond cubic materials. This effect is called "ion channelling", and, like all the channelling effects, is highly nonlinear, with small variations from perfect orientation resulting in extreme differences in implantation depth. For this reason, most implantation is carried out a few degrees off-axis, where tiny alignment errors will have more predictable effects.

Ion channelling can be used directly in Rutherford backscattering and related techniques as an analytical method to determine the amount and depth profile of damage in crystalline thin film materials.

In fabricating wafers, toxic materials such as arsine and phosphine are often used in the ion implanter process. Other common carcinogenic, corrosive, flammable, or toxic elements include antimony, arsenic, phosphorus, and boron. Semiconductor fabrication facilities are highly automated, but residue of hazardous elements in machines can be encountered during servicing and in vacuum pump hardware.

High voltage power supplies used in ion accelerators necessary for ion implantation can pose a risk of electrical injury. In addition, high-energy atomic collisions can generate X-rays and, in some cases, other ionizing radiation and radionuclides. In addition to high voltage, particle accelerators such as radio frequency linear particle accelerators and laser wakefield plasma accelerators other hazards.



</doc>
<doc id="15570" url="https://en.wikipedia.org/wiki?curid=15570" title="John Ford (disambiguation)">
John Ford (disambiguation)

John Ford (1894–1973) was an American film director who won four Academy Awards.

John or Johnny Ford may also refer to:









</doc>
<doc id="15571" url="https://en.wikipedia.org/wiki?curid=15571" title="John Woo">
John Woo

John Woo Yu-Sen SBS (; born 1 May 1946) is a Hong Kong film director, producer and screenwriter. He is considered a major influence on the action genre, known for his highly chaotic action sequences, stylized imagery, Mexican standoffs, frequent use of slow motion and allusions to neo-noir, "wuxia" and Western cinema.

Considered one of the major figures of Hong Kong cinema, Woo has directed several notable action films in his adopted home, among them, "A Better Tomorrow" (1986), "The Killer" (1989), "Hard Boiled" (1992), and "Red Cliff" (2008/2009).
Woo's Hollywood films include the action films "Hard Target" (1993) and "Broken Arrow" (1996), the sci-fi action thriller "Face/Off" (1997) and the action spy film "" (2000). He also created the comic series "Seven Brothers", published by Virgin Comics. He cites his three favorite films as David Lean's "Lawrence of Arabia", Akira Kurosawa's "Seven Samurai" and Jean-Pierre Melville's "Le Samouraï". He is the founder and chairman of the production company Lion Rock Productions.

Woo was born Wu Yu-seng (Ng Yu-sum in Cantonese) in Guangzhou, China, amidst the chaos of the Chinese Civil War at the end of October 1946. Due to school age restrictions, his mother changed his birth date to 22 September 1948, which is what remains on his passport. The Woo family, Christians faced with persecution during Mao Zedong's early anti-bourgeois purges after the communist revolution in China, fled to Hong Kong when he was five.

Impoverished, the Woo family lived in the slums at Shek Kip Mei. His father was a teacher, though rendered unable to work by tuberculosis, and his mother was a manual laborer on construction sites. The family was rendered homeless by the Shek Kip Mei fire of 1953. Charitable donations from disaster relief efforts enabled the family to relocate; however, violent crime had by then become commonplace in Hong Kong housing projects. At age three he was diagnosed with a serious medical condition. Following surgery on his spine, he was unable to walk correctly until eight years old, and as a result his right leg is shorter than his left leg.

His Christian upbringing shows influences in his films. As a young boy, Woo had wanted to be a Christian minister. He later found a passion for movies influenced by the French New Wave especially Jean-Pierre Melville. Woo has said he was shy and had difficulty speaking, but found making movies a way to explore his feelings and thinking and would "use movies as a language".

The local cinema would prove a haven of retreat. Woo found respite in musical films, such as "The Wizard of Oz" and in American Westerns. He has stated the final scene of "Butch Cassidy and the Sundance Kid" made a particular impression on him in his youth: the device of two comrades, each of whom fire pistols from each hand, is a recurrent spectacle later found in his own work.

In 1969, Woo was hired as a script supervisor at Cathay Studios. In 1971, he became an assistant director at Shaw Studios. His directorial debut in 1974 was the feature film "The Young Dragons" (鐵漢柔情, "Tiě hàn róu qíng").

In the Kung fu action genre, it was choreographed by Jackie Chan and featured dynamic camera-work and elaborate action scenes. The film was picked up by Golden Harvest Studio where he went on to direct more martial arts films. He later had success as a comedy director with "Money Crazy" (發錢寒, "Fā qián hàn") (1977), starring Hong Kong comedian Ricky Hui.

By the mid-1980s, Woo was experiencing occupational burnout. Several of his films were commercial disappointments, and he felt a distinct lack of creative control. It was during this period of self-imposed exile that director/producer Tsui Hark provided the funding for Woo to film a longtime pet project, "A Better Tomorrow" (1986).

The story of two brothers—one a law enforcement officer, the other a criminal—the film was a financial blockbuster. "A Better Tomorrow" became a defining achievement in Hong Kong action cinema for its combination of emotional drama, slow-motion gunplay, and gritty atmospherics. Its signature visual device of two-handed, two-gunned shootouts within confined quarters—often referred to as "gun fu"—was novel, and its diametrical inversion of the "good-guys-bad guys" formula in its characterization would influence later American films.

Woo would make several more Heroic Bloodshed films in the late 1980s and early 1990s, nearly all starring Chow Yun-Fat. These violent gangster thrillers typically focus on men bound by honor and loyalty, at odds with contemporary values of impermanence and expediency. The protagonists of these films, therefore, may be said to present a common lineage with the Chinese literary tradition of loyalty among generals depicted in classics such as "Romance of the Three Kingdoms".

Woo gained international recognition with the release of "The Killer", which became the most successful Hong Kong film in American release since Bruce Lee's "Enter the Dragon" (1973) and garnered Woo an American cult following. "Bullet in the Head" followed a year later failed to find an audience that accepted its political undertones, and failed to recoup its massive budget.

His last Hong Kong film before emigrating to the United States was "Hard Boiled" (1992), a police thriller that served as the antithesis of his previous glorification of gangsters. Most notable of its numerous action scenes is a 30-minute climax set within a hospital. One particular long take follows two characters for exactly 2 minutes and 42 seconds as they fight their way between hospital floors. On the Criterion DVD and laserdisc, this chapter is referenced as "2 minutes, 42 seconds." The film was considerably darker than most of Woo's previous films, depicting a police force nearly helpless to stop the influx of gangsters in the city, and the senseless slaughter of innocents. As a result, it did not match the success of his other films, but nonetheless garnered positive critical reception and became one of his most popular films in later years.

"John Woo: Interviews" includes a new 36-page interview with Woo by editor Robert K. Elder, which documents the years 1968 to 1990, from Woo's early career in working on comedies and kung fu films (in which he gave Jackie Chan in one of his first major film roles), to his gunpowder morality plays in Hong Kong.

An émigré in 1993, the director experienced difficulty in cultural adjustment while contracted with Universal Studios to direct Jean-Claude Van Damme in "Hard Target". As characteristics of other foreign national film directors confronted the Hollywood environment, Woo was unaccustomed to pervasive management concerns, such as limitations on violence and completion schedules. When initial cuts failed to yield an "R" rated film, the studio assumed control of the project and edited footage to produce a cut "suitable for American audiences". A "rough cut" of the film, supposedly the original unrated version, is still circulated among his admirers.

A three-year hiatus saw Woo next direct John Travolta and Christian Slater in "Broken Arrow." A frenetic chase-themed film, the director once again found himself hampered by studio management and editorial concerns. Despite a larger budget than his previous "Hard Target," the final feature lacked the trademark Woo style. Public reception saw modest financial success.

Reluctant to pursue projects which would necessarily entail front-office controls, the director cautiously rejected the script for "Face/Off" several times until it was rewritten to suit him. (The futuristic setting was changed to a contemporary one.) Paramount Pictures also offered the director significantly more freedom to exercise his speciality: emotional characterisation and elaborate action. A complex story of adversaries—each of whom surgically alters their identity—law enforcement agent John Travolta and terrorist Nicolas Cage play a cat-and-mouse game, trapped in each other's outward appearance. "Face/Off" opened in 1997 to critical acclaim and strong attendance. Grosses in the United States exceeded $100 million. "Face/Off" was also nominated for an Academy Award in the category Sound Effects Editing (Mark Stoeckinger) at the 70th Academy Awards.

In 2003, Woo directed a television pilot entitled "The Robinsons: Lost in Space" for The WB Television Network, based on the 1960s television series "Lost in Space". The pilot was not purchased, although bootleg copies have been made available by fans.

John Woo has made three additional films in Hollywood: "", "Windtalkers" and "Paycheck". "Mission: Impossible 2" was the highest-grossing film in America in 2000 despite its receiving mixed reviews. "Windtalkers" and "Paycheck" fared poorly at the box office and were summarily dismissed by critics. Woo directed and produced the 2007 video game "Stranglehold", which is a sequel to his 1992 film, "Hard Boiled". That same year he produced the anime movie, "", the sequel to Shinji Aramaki's 2004 film "Appleseed".

In 2008, Woo returned to Asian cinema with the completion of the two-part epic war film "Red Cliff", based on a historical battle from "Records of the Three Kingdoms". Produced on a grand scale, it is his first film in China since he emigrated from Hong Kong to the United States in 1993. Part 1 of the film was released throughout Asia in July 2008, to generally favourable reviews and strong attendance. Part 2 was released in China in January 2009.

John Woo was presented with a Golden Lion award for lifetime achievement at the Venice Film Festival in 2010.

He followed "Red Cliff" with another two-part film, "The Crossing", in 2014 and 2015. Featuring an all-star cast, the four-hour epic tells the parallel stories of several characters who all ultimately find themselves passengers on the doomed Taiping steamer, which sank in 1949 en route from mainland China to Taiwan and has been described as "China's "Titanic"".

Following the box-office disappointment of "The Crossing", Woo and producer Terence Chang disbanded Lion Rock Productions.

A CGI Mighty Mouse film was announced in 2003 although, , nothing has yet been produced. There have been rumours that Woo will direct a film version of the videogame "Metroid", however the rights he optioned have since expired.

Woo's next projects are "The Divide", a western concerning the friendship between two workers, one Chinese, the other Irish, on the transcontinental rail-road, while "The Devil's Soldier" is a biopic on Frederick Townsend Ward, an American brought to China in the mid 19th century by the Emperor to suppress rebellion. "Rendezvous in Black" will be an adaptation of the drama/thriller novel of the same name, and "Psi-Ops" is a science fiction thriller about a telepathic agent, and a remake of "Blind Spot".

In May 2008, Woo announced in Cannes that his next movie would be "1949", an epic love story set between the end of World War II and Chinese Civil War to the founding of the People's Republic of China, the shooting of which would take place in China and Taiwan. Its production was due to begin by the end of 2008, with a theatrical release planned in December 2009. However, in early April 2009, the film was cancelled due to script right issues. Reports indicated that Woo might be working on another World War II film, this time about the American Volunteer Group, or the Flying Tigers. The movie was tentatively titled "Flying Tiger Heroes" and Woo is reported as saying it will feature "The most spectacular aerial battle scenes ever seen in Chinese cinema." It was not clear whether Woo would not be directing the earlier war film, or whether it was put on the back burner. Woo has stated that Flying Tiger Heroes would be an "extremely important production" and will "emphasise US-Chinese friendship and the contributions of the Flying Tigers and the Yunnan people during the war of resistance." Woo has announced he will be using IMAX cameras to film the "Flying Tigers" project. "It has always been a dream of mine to explore shooting with IMAX cameras and to work in the IMAX format, and the strong visual element of this film is incredibly well-suited to the tastes of cinemagoers today [...] Using IMAX for Flying Tigers would create a new experience for the audience, and I think it would be another breakthrough for Chinese movies".

After the death of Japanese actor Ken Takakura in 2014, Woo announced his next film "Manhunt", a film based on the novel by Juko Nishimura. The novel had previously been adapted by Junya Satō in 1976 as "Kimi yo Fundo no Kawa o Watare", starring Takakura. Andy Lau, Takeshi Kaneshiro and Shu Qi were in discussion to star in the film. In March 2016, it was confirmed that Zhang Hanyu, Masaharu Fukuyama, and Qi Wei would be starring in the film. Ha Ji-won was additionally confirmed as being attached to the project. Lee Byung-hun was slated to join, but had to drop out due to scheduling conflicts. Taking place and being shot in Japan, the film will have Chinese, Korean, and English dialogue. It was set for a tentative 2017 release.

Woo had been married to Annie Woo Ngau Chun-lung since 1976, they have two daughters, Woo Sheung-fong, Angeles Woo, and a son Woo Yee-fong. He is a Christian and told the BBC in a September 2014 interview that he has the utmost admiration for Jesus, whom he calls "a great philosopher".

Producer only







</doc>
<doc id="15573" url="https://en.wikipedia.org/wiki?curid=15573" title="Japan">
Japan

Japan (, "Nippon" or "Nihon" ) is an island country located in East Asia. It is bordered by the Sea of Japan to the west and the Pacific Ocean to the east, and spans more than along the coast of the continent from the Sea of Okhotsk in the north to the East China Sea and Philippine Sea in the south. Part of the Pacific Ring of Fire, Japan encompasses a stratovolcanic archipelago of about 6,852 islands, with five main islands (Hokkaido, Honshu, Kyushu, Shikoku, and Okinawa) comprising 97% of the country's total area of .

Japan is officially divided into 47 prefectures and traditionally into eight regions. Approximately two-thirds of the country's terrain is mountainous and heavily forested, and less than one-eighth of land is suitable for agriculture. Consequently, Japan is among the most densely populated and urbanized countries in the world, with over 90% of its population living in urban areas. The largest of these is the metropolitan area centered on the capital city of Tokyo, which is the most populous in the world and home to more than 38 million people. Japan itself is the world's eleventh most populous country with a population of 126.2 million, of which 97.8% are ethnically Japanese.

The kanji (or "Chinese characters") that make up the name of Japan in the Japanese language mean "sun origin"; in the Western world, the country is often known by the sobriquet "Land of the Rising Sun". Periods of influence from other regions, primarily China, followed by periods of isolation, particularly from Western Europe, have characterized the history of Japan.

While archaeological evidence indicates that Japan was inhabited as early as the Upper Paleolithic period, the first written mention of the archipelago appears in Chinese texts from the first century AD. Between the fourth and ninth centuries, the kingdoms of Japan became gradually unified under an Emperor and imperial court based in Heian-kyō (modern Kyoto). However, beginning in the twelfth century, "de facto" political power came to be held by a succession of military dictators ("shōgun") and feudal lords ("daimyō") and enforced by a class of warrior nobility known as samurai. After a century-long period of civil war, Japan was reunified in 1603 under the rule of the Tokugawa shogunate, which established a government in Edo (modern Tokyo) and enacted a policy of isolationism. This period ended in 1853 when a United States fleet forced Japan to open to the West, leading to the fall of the shogunate and the restoration of imperial power in 1868. In the following Meiji era, Japan adopted a Western-style government and pursued a program of industrialization and modernization; this transformed the feudal society into a great power, with Japan establishing a colonial empire in East Asia after decisive victories in the First Sino-Japanese War and Russo-Japanese War. In 1937, the Empire of Japan invaded China, beginning the Second Sino-Japanese War; in 1940, it joined the Axis powers of World War II. After suffering major defeats in the Pacific and two atomic bombings, Japan surrendered to the Allies in 1945, coming under a brief occupation and adopting a new post-war constitution. Japan has since maintained a unitary parliamentary constitutional monarchy with the Emperor as a ceremonial head of state and an elected legislature known as the National Diet.

Today, Japan is a member of numerous international institutions, including the United Nations, the OECD, the G7, and the G20. Although it has officially renounced its right to declare war, Japan maintains a modern military for peacekeeping and self-defense, which has been ranked as the world's fourth most powerful. Following World War II, Japan experienced record economic growth, recovering from the war to become the world's second-largest economy by 1980. Today, Japan's economy is the world's third-largest by nominal GDP and fourth-largest by purchasing power parity; it is also the fourth-largest importer and exporter and a global leader in the automotive and electronics industries. Japan is ranked "very high" on the Human Development Index; its population enjoys high levels of education and the second-highest life expectancy in the world, though it currently is experiencing a projected decline due to low birth rates. Culturally, Japan is globally renowned for its art, cuisine, literature, cinema, music, and popular culture, including its prominent comics, animation, and video game industries.

The Japanese word for Japan is , which is pronounced "Nihon" or "Nippon" and literally means "the origin of the sun". The character means "sun" or "day"; means "base" or "origin". The compound therefore means "origin of the sun" and is the source of the popular Western epithet "Land of the Rising Sun".

The earliest record of the name "Nihon" appears in the Chinese historical records of the Tang dynasty, the "Old Book of Tang". At the end of the seventh century, a delegation from Japan requested that "Nihon" be used as the name of their country. This name may have its origin in a letter sent in 607 and recorded in the official history of the Sui dynasty. Prince Shōtoku, the Regent of Japan, sent a mission to China with a letter in which he called himself . The message said: "Here, I, the emperor of the country where the sun rises, send a letter to the emperor of the country where the sunsets. How are you[?]".

Prior to the adoption of "Nihon", other terms such as and were used. The term is a homophone of "Wo" (pronounced "Wa" by the Japanese), which has been used by the Chinese as a designation for the Japanese as early as the third century Three Kingdoms period. Another form of , "Wei" in Chinese) was used for an early state in Japan called Nakoku during the Han dynasty. However, the Japanese disliked some connotation of Wa (which has been associated in China with concepts like "dwarf" or "pygmy"), and it was therefore replaced with the substitute character , meaning "togetherness, harmony".

The English word Japan possibly derives from the historical Chinese pronunciation of . Japan was recorded by Marco Polo as "Cipangu". In modern Shanghainese, a Wu dialect, the pronunciation of characters Japan is "Zeppen" . The old Malay word for Japan, "Japun" or "Japang", was borrowed from a southern coastal Chinese dialect, probably Fukienese or Ningpo – and this Malay word was encountered by Portuguese traders in Southeast Asia in the 16th century. These Early Portuguese traders then brought the word to Europe. The first record of this name in English is in a book published in 1577 and spelled "Giapan", in a translation of a 1565 letter written by a Portuguese Jesuit Luís Fróis.

From the Meiji Restoration until the end of World War II, the full title of Japan was , meaning "the Empire of Great Japan". Today, the name is used as a formal modern-day equivalent with the meaning of "the State of Japan". Countries like Japan whose long form does not contain a descriptive designation are generally given a name appended by the character , meaning "country", "nation" or "state".

A Paleolithic culture around 30,000 BC constitutes the first known habitation of the Japanese archipelago. This was followed from around 14,000 BC (the start of the Jōmon period) by a Mesolithic to Neolithic semi-sedentary hunter-gatherer culture characterized by pit dwelling and rudimentary agriculture, including by ancestors of contemporary Ainu people and Yamato people. The Jōmon pottery and decorated clay vessels from this period are some of the oldest surviving examples of pottery in the world. Around 300 BC, the Yayoi people began to enter the Japanese islands, intermingling with the Jōmon. The Yayoi period, starting around 500 BC, saw the introduction of practices like wet-rice farming, a new style of pottery and metallurgy, introduced from China and Korea.

Japan first appears in written history in the Chinese "Book of Han". According to the "Records of the Three Kingdoms", the most powerful kingdom on the archipelago during the third century was called Yamataikoku.

Buddhism was introduced to Japan from Baekje, Korea and was promoted by Prince Shōtoku, but the subsequent development of Japanese Buddhism was primarily influenced by China. Despite early resistance, Buddhism was promoted by the ruling class and gained widespread acceptance beginning in the Asuka period (592–710). Due to the defeat in Battle of Baekgang by Chinese Tang empire, the Japanese government devised and implemented the far-reaching Taika Reforms. The Reform began with land reform, based on Confucian ideas and philosophies from China. It nationalized all land in Japan, to be distributed equally among cultivators, and ordered the compilation of a household registry as the basis for a new system of taxation. The true aim of the reforms was to bring about greater centralization and to enhance the power of the imperial court, which was also based on the governmental structure of China. Envoys and students were dispatched to China to learn seemingly everything from the Chinese writing system, literature, religion, and architecture, to even dietary habits at this time. Even today, the impact of the reforms can still be seen in Japanese cultural life. After the reforms, the Jinshin War of 672, a bloody conflict between Prince Ōama and his nephew Prince Ōtomo, two rivals to the throne, became a major catalyst for further administrative reforms. These reforms culminated with the promulgation of the Taihō Code, which consolidated existing statutes and established the structure of the central government and its subordinate local governments. These legal reforms created the "ritsuryō" state, a system of Chinese-style centralized government that remained in place for half a millennium.

The Nara period (710–784) marked an emergence of the centralized Japanese state centered on the Imperial Court in Heijō-kyō (modern Nara). The Nara period is characterized by the appearance of a nascent literature as well as the development of Buddhist-inspired art and architecture. The smallpox epidemic of 735–737 is believed to have killed as much as one-third of Japan's population. In 784, Emperor Kanmu moved the capital from Nara to Nagaoka-kyō, then to Heian-kyō (modern Kyoto) in 794.

This marked the beginning of the Heian period (794–1185), during which a distinctly indigenous Japanese culture emerged, noted for its art, poetry and prose. Murasaki Shikibu's "The Tale of Genji" and the lyrics of Japan's national anthem "Kimigayo" were written during this time.

Buddhism began to spread during the Heian era chiefly through two major sects, Tendai by Saichō and Shingon by Kūkai. Pure Land Buddhism (Jōdo-shū, Jōdo Shinshū) became greatly popular in the latter half of the 11th century.

Japan's feudal era was characterized by the emergence and dominance of a ruling class of warriors, the samurai. In 1185, following the defeat of the Taira clan in the Genpei War, sung in the epic Tale of Heike, samurai Minamoto no Yoritomo was appointed "shōgun" by Emperor Go-Toba. In 1192, the shōgun Yoritomo and the Minamoto clan established a feudal military government in Kamakura. What distinguishes Japan from other countries is that Japan was near continuously ruled by the military class with the shōgun and the samurai in the top of the Japanese social structure for 676 years (from 1192 till 1868 CE). The Emperor was above the shōgun and revered as the sovereign, but merely a figurehead. The Imperial Court nobility was a nominal ruling court with little influence. The actual ruling class were Japanese military figures: the shōgun (military dictator), daimyo (feudal lords) and the samurai (military nobility and officers). After Yoritomo's death, the Hōjō clan came to power as regents for the "shōguns".

The Zen school of Buddhism was introduced from China in the Kamakura period (1185–1333) and became popular among the samurai class. The Kamakura shogunate repelled Mongol invasions in 1274 and 1281, but was eventually overthrown by Emperor Go-Daigo. Emperor Go-Daigo was himself defeated by Ashikaga Takauji in 1336.

Ashikaga Takauji established the shogunate in Muromachi, Kyoto. This was the start of the Muromachi period (1336–1573). The Ashikaga shogunate achieved glory at the age of Ashikaga Yoshimitsu, and the culture based on Zen Buddhism (the art of "Miyabi") prospered. This evolved to Higashiyama Culture, and prospered until the 16th century. On the other hand, the succeeding Ashikaga shogunate failed to control the feudal warlords ("daimyōs") and a civil war (the Ōnin War) began in 1467, opening the century-long Sengoku period ("Warring States").
During the 16th century, Portuguese traders and Jesuit missionaries like the Spaniard Francis Xavier reached Japan for the first time, initiating direct commercial and cultural exchange between Japan and the West. This allowed Oda Nobunaga to obtain European technology and firearms, which he used to conquer many other "daimyōs". His consolidation of power began what was known as the Azuchi–Momoyama period (1573–1603). After Nobunaga was assassinated in 1582 by Akechi Mitsuhide, his successor Toyotomi Hideyoshi unified the nation in 1590 and launched two unsuccessful invasions of Korea in 1592 and 1597.

Tokugawa Ieyasu served as regent for Hideyoshi's son and used his position to gain political and military support. When open war broke out, Ieyasu defeated rival clans in the Battle of Sekigahara in 1600. Tokugawa Ieyasu was appointed "shōgun" by Emperor Go-Yōzei in 1603 and established the Tokugawa shogunate in Edo (modern Tokyo). The shogunate enacted measures including "buke shohatto", as a code of conduct to control the autonomous "daimyōs"; and in 1639 the isolationist "sakoku" ("closed country") policy that spanned the two and a half centuries of tenuous political unity known as the Edo period (1603–1868). The study of Western sciences, known as "rangaku", continued through contact with the Dutch enclave at Dejima in Nagasaki. The Edo period also gave rise to "kokugaku" ("national studies"), the study of Japan by the Japanese.

On March 31, 1854, Commodore Matthew Perry and the "Black Ships" of the United States Navy forced the opening of Japan to the outside world with the Convention of Kanagawa. Subsequent similar treaties with Western countries in the Bakumatsu period brought economic and political crises. The resignation of the "shōgun" led to the Boshin War and the establishment of a centralized state nominally unified under the Emperor (the Meiji Restoration).

Plunging itself through an active process of Westernization during the Meiji Restoration in 1868, Japan adopted Western political, judicial and military institutions and Western cultural influences integrated with its traditional culture for modern industrialization. The Cabinet organized the Privy Council, introduced the Meiji Constitution, and assembled the Imperial Diet. The Meiji Restoration transformed the Empire of Japan into an industrialized world power that pursued military conflict to expand its sphere of influence. Although France and Britain showed some interest, the European powers largely ignored Japan and instead concentrated on the much greater attractions of China. France was also set back by its failures in Mexico and defeat by the Germans. After victories in the First Sino-Japanese War (1894–1895) and the Russo-Japanese War (1904–1905), Japan gained control of Taiwan, Korea and the southern half of Sakhalin. In addition to imperialistic success, Japan also invested much more heavily in its own economic growth, leading to a period of economic flourishing in the country which lasted until the Great Depression. Japan's population grew from 35 million in 1873 to 70 million by 1935.
In World War I, Japan joined the Allies and captured German possessions, and made advances into China. The early 20th century saw a period of Taishō democracy (1912–1926), but the 1920s saw a fragile democracy buckle under a political shift towards statism, the passing of laws against political dissent and a series of attempted coups. This process accelerated during the 1930s, spawning a number of new Radical Nationalist groups that shared a hostility to liberal democracy and a dedication to expansion in Asia. Japanese expansionism and militarization along with totalitarianism and ultranationalism reshaped the country. In 1931 Japan invaded and occupied Manchuria and following international condemnation of this occupation, it quit the League of Nations in 1933. In 1936, Japan signed the Anti-Comintern Pact with Germany and the 1940 Tripartite Pact made it one of the Axis Powers.
The Empire of Japan invaded other parts of China in 1937, precipitating the Second Sino-Japanese War (1937–1945). The Imperial Japanese Army swiftly captured the capital Nanjing and conducted the Nanjing Massacre. In 1940, the Empire invaded French Indochina, after which the United States placed an oil embargo on Japan. On December 7–8, 1941, Japanese forces carried out surprise attacks on Pearl Harbor, British forces in Malaya, Singapore and Hong Kong and declared war on the United States and the British Empire, bringing the United States and the United Kingdom into World War II in the Pacific. After Allied victories across the Pacific during the next four years, which culminated in the Soviet invasion of Manchuria and the atomic bombings of Hiroshima and Nagasaki in 1945, Japan agreed to an unconditional surrender on August 15. The war cost Japan, its colonies, China and the war's other combatants tens of millions of lives and left much of Japan's industry and infrastructure destroyed. The Allies (led by the United States) repatriated millions of ethnic Japanese from colonies and military camps throughout Asia, largely eliminating the Japanese empire and its influence over its conquered territories. The Allies also convened the International Military Tribunal for the Far East on May 3, 1946, to prosecute some senior generals for war crimes.

In 1947, during the post-war Shōwa period, Japan adopted a new constitution emphasizing liberal democratic practices. The Allied occupation ended with the Treaty of San Francisco in 1952 and Japan was granted membership in the United Nations in 1956. Japan later achieved rapid growth to become the second-largest economy in the world, until surpassed by China in 2010. This ended in the mid-1990s when Japan suffered a major recession. In the beginning of the 21st century, positive growth has signaled a gradual economic recovery. On March 11, 2011, Japan suffered one of the largest earthquakes in its recorded history; this triggered the Fukushima Daiichi nuclear disaster, one of the worst disasters in the history of nuclear power. On May 1, 2019, after the historic abdication of Emperor Akihito on April 30 and the first since 1817, his son Naruhito became the new Emperor. In addition to the new Emperor, Japan changed its Imperial Era from Heisei to Reiwa.

Japan has a total of 6,852 islands extending along the Pacific coast. It is over long from the Sea of Okhotsk to the Philippine Sea in the Pacific Ocean. The country, including all of the islands it controls, lies between latitudes 24° and 46°N, and longitudes 122° and 146°E. The five main islands, from north to south, are Hokkaido, Honshu, Shikoku, Kyushu and Okinawa. The Ryukyu Islands, which include Okinawa, are a chain to the south of Kyushu. The Nanpō Islands are south and east of the main islands of Japan. Together they are often known as the Japanese archipelago. , Japan's territory is . Japan is the 4th largest island country in the world and the largest island country in East Asia. Japan has the sixth longest coastline in the world (). It does not have land borders. Due to its many far-flung outlying islands, Japan has the eighth largest Exclusive Economic Zone in the world covering .

About 73 percent of Japan is forested, mountainous and unsuitable for agricultural, industrial or residential use. As a result, the habitable zones, mainly located in coastal areas, have extremely high population densities. Japan is one of the most densely populated countries in the world.

Approximately 0.5% of Japan's total area is reclaimed land (umetatechi). It began in the 12th century. Late 20th and early 21st century projects include artificial islands such as Chubu Centrair International Airport in Ise Bay, Kansai International Airport in the middle of Osaka Bay, Yokohama Hakkeijima Sea Paradise and Wakayama Marina City. The village of Ogata in Akita, Japan, was established on land reclaimed from Lake Hachirōgata starting in 1957. By 1977, the amount of land reclaimed totaled . The in Isahaya, Nagasaki started in 1989 and a total of has been reclaimed as of 2018.
The islands of Japan are located in a volcanic zone on the Pacific Ring of Fire. They are primarily the result of large oceanic movements occurring over hundreds of millions of years from the mid-Silurian to the Pleistocene as a result of the subduction of the Philippine Sea Plate beneath the continental Amurian Plate and Okinawa Plate to the south, and subduction of the Pacific Plate under the Okhotsk Plate to the north. The Boso Triple Junction off the coast of Japan is a triple junction where the North American Plate, the Pacific Plate and the Philippine Sea Plate meets. Japan was originally attached to the eastern coast of the Eurasian continent. The subducting plates pulled Japan eastward, opening the Sea of Japan around 15 million years ago.

Japan has 108 active volcanoes. During the twentieth century several new volcanoes emerged, including Shōwa-shinzan on Hokkaido and Myōjin-shō off the Bayonnaise Rocks in the Pacific. Destructive earthquakes, often resulting in tsunami, occur several times each century. The 1923 Tokyo earthquake killed over 140,000 people. More recent major quakes are the 1995 Great Hanshin earthquake and the 2011 Tōhoku earthquake, a 9.1-magnitude quake which hit Japan on March 11, 2011, and triggered a large tsunami. Japan is substantially prone to earthquakes, tsunami and volcanoes due to its location along the Pacific Ring of Fire. It has the 15th highest natural disaster risk as measured in the 2013 World Risk Index.

The climate of Japan is predominantly temperate, but varies greatly from north to south. Japan's geographical features divide it into six principal climatic zones: Hokkaido, Sea of Japan, Central Highland, Seto Inland Sea, Pacific Ocean, and Ryukyu Islands. The northernmost zone, Hokkaido, has a humid continental climate with long, cold winters and very warm to cool summers. Precipitation is not heavy, but the islands usually develop deep snowbanks in the winter.

In the Sea of Japan zone on Honshu's west coast, northwest winter winds bring heavy snowfall. In the summer, the region is cooler than the Pacific area, though it sometimes experiences extremely hot temperatures because of the foehn. The Central Highland has a typical inland humid continental climate, with large temperature differences between summer and winter seasons, as well as large diurnal variation; precipitation is light, though winters are usually snowy. The mountains of the Chūgoku and Shikoku regions shelter the Seto Inland Sea from seasonal winds, bringing mild weather year-round.

The Pacific coast features a humid subtropical climate that experiences milder winters with occasional snowfall and hot, humid summers because of the southeast seasonal wind. The Ryukyu Islands and Nanpō Islands have a subtropical climate, with warm winters and hot summers. Precipitation is very heavy, especially during the rainy season.

The average winter temperature in Japan is and the average summer temperature is . The highest temperature ever measured in Japan was recorded on July 23, 2018. The main rainy season begins in early May in Okinawa, and the rain front gradually moves north until reaching Hokkaido in late July. In most of Honshu, the rainy season begins before the middle of June and lasts about six weeks. In late summer and early autumn, typhoons often bring heavy rain.

Japan has nine forest ecoregions which reflect the climate and geography of the islands. They range from subtropical moist broadleaf forests in the Ryūkyū and Bonin Islands, to temperate broadleaf and mixed forests in the mild climate regions of the main islands, to temperate coniferous forests in the cold, winter portions of the northern islands. Japan has over 90,000 species of wildlife, including the brown bear, the Japanese macaque, the Japanese raccoon dog, the large Japanese field mouse, and the Japanese giant salamander. A large network of national parks has been established to protect important areas of flora and fauna as well as thirty-seven Ramsar wetland sites. Four sites have been inscribed on the UNESCO World Heritage List for their outstanding natural value.

In the period of rapid economic growth after World War II, environmental policies were downplayed by the government and industrial corporations; as a result, environmental pollution was widespread in the 1950s and 1960s. Responding to rising concern about the problem, the government introduced several environmental protection laws in 1970. The oil crisis in 1973 also encouraged the efficient use of energy because of Japan's lack of natural resources. 

, more than 40 coal-fired power plants are planned or under construction in Japan, following the switching-off of Japan's nuclear fleet following the 2011 Fukushima nuclear disaster. Prior to this incident, Japan's emissions had been on the decline, largely due to nuclear power plants creating no emissions. The NGO Climate Action Network announced Japan as the winner of its "Fossil of the Day" award for "doing the most to block progress on climate action".

Japan ranks 20th in the 2018 Environmental Performance Index, which measures a nation's commitment to environmental sustainability. As the host and signatory of the 1997 Kyoto Protocol, Japan is under treaty obligation to reduce its carbon dioxide emissions and to take other steps to curb climate change. Current environmental issues include urban air pollution (NOx, suspended particulate matter, and toxics), waste management, water eutrophication, nature conservation, climate change, chemical management and international co-operation for conservation.

Japan is a constitutional monarchy and sovereign state whereby the power of the Emperor is very limited. As a ceremonial figurehead, he is defined by the constitution to be "the symbol of the State and of the unity of the people". Executive power is wielded chiefly by the Prime Minister and his cabinet, while sovereignty is vested in the Japanese people. The Constitution of Japan is the oldest unamended constitution in the world. It has not changed since its adoption on 3 May 1947.

Japan's legislative body is the National Diet, seated in Chiyoda, Tokyo. The Diet is a bicameral body, comprising the lower House of Representatives with 465 seats, elected by popular vote every four years or when dissolved; and the upper House of Councillors with 242 seats, whose popularly elected members serve six-year terms. There is universal suffrage for adults over 18 years of age, with a secret ballot for all elected offices. The Diet is currently dominated by the conservative Liberal Democratic Party (LDP), with the largest opposition party being the social-liberal Constitutional Democratic Party (CDP). The LDP has enjoyed near-continuous electoral success since 1955, except for brief periods between 1993 and 1994 and from 2009 to 2012. , it holds 285 seats in the lower house and 113 seats in the upper house.

The Prime Minister of Japan is the head of government and is appointed by the Emperor after being designated by the Diet from among its members. The Prime Minister is the head of the Cabinet, and appoints and dismisses the Ministers of State. Following the LDP's landslide victory in the 2012 general election, Shinzō Abe replaced Yoshihiko Noda as the Prime Minister on December 26, 2012.

Historically influenced by Chinese law, the Japanese legal system developed independently during the Edo period through texts such as "Kujikata Osadamegaki". However, since the late 19th century the judicial system has been largely based on the civil law of Europe, notably Germany. For example, in 1896, the Japanese government established a civil code based on a draft of the German Bürgerliches Gesetzbuch; with the code remaining in effect with post–World War II modifications. Statutory law originates in Japan's legislature and has the rubber stamp of the Emperor. Japan's court system is divided into four basic tiers: the Supreme Court and three levels of lower courts. The main body of Japanese statutory law is called the Six Codes.

Japan is divided into 47 prefectures, each overseen by an elected governor, legislature and administrative bureaucracy. Each prefecture is further divided into cities, towns and villages. The nation is currently undergoing administrative reorganization by merging many of the cities, towns and villages with each other. This process will reduce the number of sub-prefecture administrative regions and is expected to cut administrative costs.

Japan has diplomatic relations with nearly all independent nations and has been an active member of the United Nations since December 1956. Japan is a member of the G7, APEC, and "ASEAN Plus Three", and is a participant in the East Asia Summit. Japan signed a security pact with Australia in March 2007 and with India in October 2008. It is the world's fifth largest donor of official development assistance, donating US$9.2 billion in 2014. In 2017, Japan had the fifth largest diplomatic network in the world.

Japan has close ties to the United States. Since Japan's defeat by the United States and allies in World War II, the two countries have maintained close economic and defense relations. The United States is a major market for Japanese exports and the primary source of Japanese imports, and is committed to defending the country, having military bases in Japan for partially that purpose. After Japan's defeat in World War II, the Japanese-ruled Northern Mariana Islands came under control of the United States.

Japan contests Russia's control of the Southern Kuril Islands (including Etorofu, Kunashiri, Shikotan, and the Habomai group) which were occupied by the Soviet Union in 1945. South Korea's control of Liancourt Rocks (Japanese: "Takeshima", Korean: "Dokdo") are acknowledged, but not accepted and are claimed by Japan. Japan has strained relations with the People's Republic of China (PRC) and the Republic of China (ROC) over the Senkaku Islands; and with the People's Republic of China over the status of Okinotorishima.

Japan's relationship with South Korea has been strained due to Japan's treatment of Koreans during Japanese colonial rule, particularly over the issue of comfort women. These women were essentially sex slaves, and although there is no exact number on how many women were subjected to this treatment, experts believe it could be in the tens or hundreds of thousands. Between 1910 and 1945, the Japanese government rebuilt Korean infrastructure. Despite this, modernization in Korea was always linked to Japanese interests and therefore did not imply a "revolutionization" of social structures. For instance, Japan kept Korea's primitive feudalistic agriculture because it served Japanese interests. Further developments on Japan's imperialism in Korea included establishing a slew of police stations all over the country, replacing taxes in kind with taxes in fixed money, and taking much of the communal land which had belonged to villages to give them to private companies in Japan (causing many peasants to lose their land.) Japan also introduced over 800,000 Japanese immigrants onto the peninsula and carried out a campaign of cultural suppression through efforts to ban the Korean language in schools and force Koreans to adopt Japanese names.
The Korean Peninsula once again became independent with the surrender of Japan and the Axis at the end of WWII in 1945. Despite their historical tensions, in December 2015, Japan agreed to settle the comfort women dispute with South Korea by issuing a formal apology, taking responsibility for the issue and paying money to the surviving comfort women. Today, South Korea and Japan have a stronger and more economically-driven relationship. Since the 1990s, the Korean Wave has created a large fanbase in East Asia. Japan is the number one importer of Korean music (K-pop), television (K-dramas), and films, but this was only made possible after the South Korean government lifted the 30-year ban on cultural exchange with Japan that had been in place since 1948.

Korean pop cultural products' success in the Japanese market is partially explained by the borrowing of Japanese ideas such as the star-marketing system and heavy promotion of new television shows and music. Korean dramas such as "Winter Sonata" and "Coffee Prince," as well as K-pop artists such as BIGBANG and SHINee are very popular with Japanese consumers. Most recently, South Korean President Moon Jae-in met with Japanese Prime Minister Shinzo Abe at the 2017 G-20 Summit in Hamburg, Germany to discuss the future of their relationship and specifically how to cooperate on finding solutions for North Korean aggression in the region. Both leaders restated their commitment to solving the comfort women dispute, building positive relations in the region, and pressuring China to be more assertive with North Korea as it continues to test nuclear weapons and isolate themselves further form the international community.

Japan maintains one of the largest military budgets of any country in the world. The country's military (the Japan Self-Defense Forces – JSDF) is restricted by Article 9 of the Japanese Constitution, which renounces Japan's right to declare war or use military force in international disputes. Accordingly, Japan's Self-Defense Forces is an unusual military that has never fired shots outside Japan. Japan is the highest-ranked Asian country in the Global Peace Index. A Credit Suisse survey published in 2015 ranked Japan as the world's fourth most-powerful conventional (non-nuclear) military behind the United States, Russia and China. Other studies rank Japan around seventh or eighth.

The military is governed by the Ministry of Defense, and primarily consists of the Japan Ground Self-Defense Force (JGSDF), the Japan Maritime Self-Defense Force (JMSDF) and the Japan Air Self-Defense Force (JASDF). The Japan Maritime Self-Defense Force (JMSDF) is a regular participant in RIMPAC maritime exercises. The forces have been recently used in peacekeeping operations; the deployment of troops to Iraq marked the first overseas use of Japan's military since World War II. Japan Business Federation has called on the government to lift the ban on arms exports so that Japan can join multinational projects such as the Joint Strike Fighter.

The 21st century is witnessing a rapid change in global power balance along with globalization. The security environment around Japan has become increasingly severe as represented by nuclear and missile development by North Korea. Transnational threats grounded on technological progress including international terrorism and cyber attacks are also increasing their significance. Japan, including its Self-Defense Forces, has contributed to the maximum extent possible to the efforts to maintain and restore international peace and security, such as UN peacekeeping operations. Building on the ongoing efforts as a peaceful state, the Government of Japan has been making various efforts on its security policy which include: the establishment of the National Security Council (NSC), the adoption of the National Security Strategy (NSS), and the National Defense Program Guidelines (NDPG). These efforts are made based on the belief that Japan, as a "Proactive Contributor to Peace", needs to contribute more actively to the peace and stability of the region and the international community, while coordinating with other countries including its ally, the United States.

Japan has close economic and military relations with the United States; the US-Japan security alliance acts as the cornerstone of the nation's foreign policy. A member state of the United Nations since 1956, Japan has served as a non-permanent Security Council member for a total of 20 years, most recently for 2009 and 2010. It is one of the G4 nations seeking permanent membership in the Security Council.

In May 2014, Prime Minister Shinzō Abe said Japan wanted to shed the passiveness it has maintained since the end of World War II and take more responsibility for regional security. He said Japan wanted to play a key role and offered neighboring countries Japan's support. In recent years, they have been engaged in international peacekeeping operations including the UN peacekeeping. Recent tensions, particularly with North Korea, have reignited the debate over the status of the JSDF and its relation to Japanese society. New military guidelines, announced in December 2010, will direct the JSDF away from its Cold War focus on the former Soviet Union to a focus on China, especially regarding the territorial dispute over the Senkaku Islands.

Domestic security in Japan is provided mainly by the Prefectural Police Departments, under the oversight of the National Police Agency, and supervised by the Criminal Affairs Bureau of the National Police Agency. As the central coordinating body for the Prefectural Police Departments, the National Police Agency is itself administered by the National Public Safety Commission.

The Special Assault Team comprises national-level counter-terrorism tactical units that cooperate with territorial-level Anti-Firearms Squads and Counter-NBC Terrorism Squads.

Additionally, there is the Japan Coast Guard which guards territorial waters in accordance with international law and domestic law. The coast guard patrols the sea surrounding Japan and uses surveillance and control countermeasures against smuggling, marine environmental crime, poaching, piracy, spy ships, unauthorized foreign fishing vessels, illegal immigration, etc.

The Firearm and Sword Possession Control Law strictly regulates the civilian ownership of guns, swords and other weaponry, in accordance with a 1958 Japanese law which states: "No person shall possess a firearm or firearms or a sword or swords" and there are few exceptions. According to statistics of the United Nations Office on Drugs and Crime, among the 192 member states of the UN, and among the countries reporting statistics of criminal and criminal justice, the incidence rate of violent crimes such as murder, abduction, forced sexual intercourse and robbery is very low in Japan.

Japan is the third largest national economy in the world, after the United States and China, in terms of nominal GDP, and the fourth largest national economy in the world, after the United States, China and India, in terms of purchasing power parity. , Japan's public debt was estimated at more than 230 percent of its annual gross domestic product, the largest of any nation in the world. In August 2011, Moody's rating has cut Japan's long-term sovereign debt rating one notch from Aa3 to Aa2 inline with the size of the country's deficit and borrowing level. The large budget deficits and government debt since the 2009 global recession, followed by the earthquake and tsunami in March 2011, caused the rating downgrade. The service sector accounts for three quarters of the gross domestic product.

Japan has a large industrial capacity, and is home to some of the largest and most technologically advanced producers of motor vehicles, electronics, machine tools, steel and nonferrous metals, ships, chemical substances, textiles, and processed foods. Agricultural businesses in Japan cultivate 13 percent of Japan's land, and Japan accounts for nearly 15 percent of the global fish catch, second only to China. , Japan's labor force consisted of some 65.9 million workers. Japan has a low unemployment rate of around four percent. Some 20 million people, around 17 per cent of the population, were below the poverty line in 2007. Housing in Japan is characterized by limited land supply in urban areas.

Japan's exports amounted to US$4,210 per capita in 2005. , Japan's main export markets were the United States (20.2 percent), China (17.5 percent), South Korea (7.1 percent), Hong Kong (5.6 percent) and Thailand (4.5 percent). Its main exports are transportation equipment, motor vehicles, iron and steel products, semiconductors and auto parts. Japan's main import markets were China (24.8 percent), the United States (10.5 percent), Australia (5.4 percent) and South Korea (4.1 percent).

Japan's main imports are machinery and equipment, fossil fuels, foodstuffs (in particular beef), chemicals, textiles and raw materials for its industries. By market share measures, domestic markets are the least open of any OECD country. Junichirō Koizumi's administration began some pro-competition reforms, and foreign investment in Japan has soared.

Japan ranks 34th of 190 countries in the 2018 ease of doing business index and has one of the smallest tax revenues of the developed world. The Japanese variant of capitalism has many distinct features: keiretsu enterprises are influential, and lifetime employment and seniority-based career advancement are relatively common in the Japanese work environment. Japanese companies are known for management methods like "The Toyota Way", and shareholder activism is rare. Japan's top global brands include Toyota, Honda, Canon, Nissan, Sony, Mitsubishi UFJ (MUFG), Panasonic, Uniqlo, Lexus, Subaru, Nintendo, Bridgestone, Mazda and Suzuki.

Japan also has a large cooperative sector, with three of the ten largest cooperatives in the world located in Japan, including the largest consumer cooperative and the largest agricultural cooperative in the world.

Modern Japan's economic growth began in the Edo period. Some of the surviving elements of the Edo period are roads and water transportation routes, as well as financial instruments such as futures contracts, banking and insurance of the Osaka rice brokers. During the Meiji period from 1868, Japan expanded economically with the embrace of the market economy. Many of today's enterprises were founded at the time, and Japan emerged as the most developed nation in Asia. The period of overall real economic growth from the 1960s to the 1980s has been called the Japanese post-war economic miracle: it averaged 7.5 percent in the 1960s and 1970s, and 3.2 percent in the 1980s and early 1990s.

Growth slowed in the 1990s during the "Lost Decade" due to after-effects of the Japanese asset price bubble and government policies intended to wring speculative excesses from the stock and real estate markets. Efforts to revive economic growth were unsuccessful and further hampered by the global slowdown in 2000.

Today, Japan ranks highly for competitiveness and economic freedom. It is ranked sixth in the Global Competitiveness Report for 2015–2016.

The Japanese agricultural sector accounts for about 1.4% of the total country's GDP. Only 12% of Japan's land is suitable for cultivation. Due to this lack of arable land, a system of terraces is used to farm in small areas. This results in one of the world's highest levels of crop yields per unit area, with an overall agricultural self-sufficiency rate of about 50% on fewer than cultivated.

Japan's small agricultural sector, however, is also highly subsidized and protected, with government regulations that favor small-scale cultivation instead of large-scale agriculture as practiced in North America. There has been a growing concern about farming as the current farmers are aging with a difficult time finding successors.

Rice accounts for almost all of Japan's cereal production. Japan is the second-largest agricultural product importer in the world. Rice, the most protected crop, is subject to tariffs of 777.7%.

In 1996, Japan ranked fourth in the world in tonnage of fish caught. Japan captured 4,074,580 metric tons of fish in 2005, down from 4,987,703 tons in 2000, 9,558,615 tons in 1990, 9,864,422 tons in 1980, 8,520,397 tons in 1970, 5,583,796 tons in 1960 and 2,881,855 tons in 1950. In 2003, the total aquaculture production was predicted at 1,301,437 tonnes. In 2010, Japan's total fisheries production was 4,762,469 fish. Offshore fisheries accounted for an average of 50% of the nation's total fish catches in the late 1980s although they experienced repeated ups and downs during that period.

Today, Japan maintains one of the world's largest fishing fleets and accounts for nearly 15% of the global catch, prompting some claims that Japan's fishing is leading to depletion in fish stocks such as tuna. Japan has also sparked controversy by supporting quasi-commercial whaling.

Japan's industrial sector makes up approximately 27.5% of its GDP. Japan's major industries are motor vehicles, electronics, machine tools, metals, ships, chemicals and processed foods; some major Japanese industrial companies include Toyota, Canon Inc., Toshiba and Nippon Steel.

Japan is the third largest automobile producer in the world, and is home to Toyota, the world's largest automobile company. The Japanese consumer electronics industry, once considered the strongest in the world, is currently in a state of decline as competition arises in countries like South Korea, the United States and China. However, despite also facing similar competition from South Korea and China, the Japanese shipbuilding industry is expected to remain strong due to an increased focus on specialized, high-tech designs.

Japan's service sector accounts for about three-quarters of its total economic output. Banking, insurance, real estate, retailing, transportation, and telecommunications are all major industries, with companies such as Mitsubishi UFJ, Mizuho, NTT, TEPCO, Nomura, Mitsubishi Estate, ÆON, Mitsui Sumitomo, Softbank, JR East, Seven & I, KDDI and Japan Airlines listed as some of the largest in the world. Four of the five most circulated newspapers in the world are Japanese newspapers. Japan Post Holdings, one of the country's largest providers of savings and insurance services, was slated for privatization by 2015. The six major keiretsus are the Mitsubishi, Sumitomo, Fuyo, Mitsui, Dai-Ichi Kangyo and Sanwa Groups.

Japan attracted 19.73 million international tourists in 2015 and increased by 21.8% to attract 24.03 million international tourists in 2016. Tourism from abroad is one of the few promising businesses in Japan. Foreign visitors to Japan doubled in last decade and reached 10 million people for the first time in 2013, led by increase of Asian visitors.

In 2008, the Japanese government has set up Japan Tourism Agency and set the initial goal to increase foreign visitors to 20 million in 2020. In 2016, having met the 20 million target, the government has revised up its target to 40 million by 2020 and to 60 million by 2030.

Japan has 20 World Heritage Sites, including Himeji Castle, Historic Monuments of Ancient Kyoto and Nara. Popular tourist attractions include Tokyo and Hiroshima, Mount Fuji, ski resorts such as Niseko in Hokkaido, Okinawa, riding the shinkansen and taking advantage of Japan's hotel and hotspring network.

For inbound tourism, Japan was ranked 16th in the world in 2015. In 2009, the "Yomiuri Shimbun" published a modern list of famous sights under the name "Heisei Hyakkei" (the Hundred Views of the Heisei period). The "Travel and Tourism Competitiveness Report 2017" ranks Japan 4th out of 141 countries overall, which was the best in Asia. Japan gained relatively high scores in almost all aspects, especially health and hygiene, safety and security, cultural resources and business travel.

Chinese travelers are the highest spenders in Japan by country, spending an estimated 196.4 billion yen (US$2.4 billion) in 2011, or almost a quarter of total expenditure by foreign visitors, according to data from the Japan Tourism Agency. In 2018, 31,191,929 foreign tourists visited Japan. In 2017, 3 out of 4 foreign tourists came from South Korea, China, Taiwan and Hong Kong, according to the Japan National Tourism Organization.

Japan is a leading nation in scientific research, particularly in fields related to the natural sciences and engineering. The country ranks second among the most innovative countries in the Bloomberg Innovation Index. Nearly 700,000 researchers share a US$130 billion research and development budget. The amount spent on research and development relative to gross domestic product is the third highest in the world. The country is a world leader in fundamental scientific research, having produced twenty-two Nobel laureates in either physics, chemistry or medicine and three Fields medalists.

Japanese scientists and engineers have contributed to the advancement of agricultural sciences, electronics, industrial robotics, optics, chemicals, semiconductors, life sciences and various fields of engineering. Japan leads the world in robotics production and use, possessing more than 20% (300,000 of 1.3 million) of the world's industrial robots  – though its share was historically even higher, representing one-half of all industrial robots worldwide in 2000. Japan boasts the third highest number of scientists, technicians, and engineers per capita in the world with 83 scientists, technicians and engineers per 10,000 employees.

The Japanese electronics and automotive manufacturing industry is well known throughout the world, and the country's electronic and automotive products account for a large share in the global market, compared to a majority of other countries. Brands such as Fujifilm, Canon, Sony, Nintendo, Panasonic, Toyota, Nissan and Honda are internationally famous. It is estimated that 16% of the world's gold and 22% of the world's silver is contained in Japanese electronics.

The Japan Aerospace Exploration Agency (JAXA) is Japan's national space agency; it conducts space, planetary, and aviation research, and leads development of rockets and satellites. It is a participant in the International Space Station: the Japanese Experiment Module (Kibō) was added to the station during Space Shuttle assembly flights in 2008. The space probe "Akatsuki" was launched May 20, 2010, and achieved orbit around Venus on December 9, 2015. Japan's plans in space exploration include: developing the "Mercury Magnetospheric Orbiter" to be launched in 2018; and building a moon base by 2030.

On September 14, 2007, it launched lunar explorer SELENE (Selenological and Engineering Explorer) on a H-IIA (Model H2A2022) carrier rocket from Tanegashima Space Center. SELENE is also known as Kaguya, after the lunar princess of "The Tale of the Bamboo Cutter". Kaguya is the largest lunar mission since the Apollo program. Its purpose is to gather data on the moon's origin and evolution. It entered a lunar orbit on October 4, flying at an altitude of about . The probe's mission was ended when it was deliberately crashed by JAXA into the Moon on June 11, 2009.

Japan's road spending has been extensive. Its of paved road are the main means of transportation. , Japan has approximately of roads made up of of city, town and village roads, of prefectural roads, of general national highways and of national expressways. A single network of high-speed, divided, limited-access toll roads connects major cities on Honshu, Shikoku and Kyushu. Hokkaido has a separate network, and Okinawa Island has a highway of this type. A single network of high-speed, divided, limited-access toll roads connects major cities and is operated by toll-collecting enterprises. New and used cars are inexpensive; car ownership fees and fuel levies are used to promote energy efficiency. However, at just 50 percent of all distance traveled, car usage is the lowest of all G8 countries.

Since privatization in 1987, dozens of Japanese railway companies compete in regional and local passenger transportation markets; major companies include seven JR enterprises, Kintetsu, Seibu Railway and Keio Corporation. Some 250 high-speed Shinkansen trains connect major cities and Japanese trains are known for their safety and punctuality. A new Maglev line called the Chūō Shinkansen is being constructed between Tokyo and Nagoya. It is due to be completed in 2027.

There are 175 airports in Japan; the largest domestic airport, Haneda Airport in Tokyo, is Asia's second-busiest airport. The largest international gateways are Narita International Airport, Kansai International Airport and Chūbu Centrair International Airport. Nagoya Port is the country's largest and busiest port, accounting for 10 percent of Japan's trade value.

, 46.1% of energy in Japan was produced from petroleum, 21.3% from coal, 21.4% from natural gas, 4.0% from nuclear power and 3.3% from hydropower. Nuclear power produced 9.2 percent of Japan's electricity, , down from 24.9 percent the previous year. However, by May 2012 all of the country's nuclear power plants had been taken offline because of ongoing public opposition following the Fukushima Daiichi nuclear disaster in March 2011, though government officials continued to try to sway public opinion in favor of returning at least some of Japan's 50 nuclear reactors to service. Reactors at Sendai restarted in 2015. Japan lacks significant domestic reserves and so has a heavy dependence on imported energy. Japan has therefore aimed to diversify its sources and maintain high levels of energy efficiency.

The government took responsibility for regulating the water and sanitation sector is shared between the Ministry of Health, Labor and Welfare in charge of water supply for domestic use; the Ministry of Land, Infrastructure, Transport and Tourism in charge of water resources development as well as sanitation; the Ministry of the Environment in charge of ambient water quality and environmental preservation; and the Ministry of Internal Affairs and Communications in charge of performance benchmarking of utilities.

Access to an improved water source is universal in Japan. 97% of the population receives piped water supply from public utilities and 3% receive water from their own wells or unregulated small systems, mainly in rural areas.

Japan is the second most populous island country with a population of 126.3 million (2019). 124.8 million are Japanese nationals (2019). Honshū is the world's 2nd most populous island and it has 80% of Japan's population. Due to the rugged and mountainous terrain with 66% forest, the population is clustered in urban areas on the coast, plains and valleys. Japan is an urban society with only 5% of the labor force working in agriculture. About 80 million of the urban population is heavily concentrated on the Pacific coast of Honshu. In 2010, 90.7% of the total Japanese population lived in cities.

The capital city Tokyo has a population of 13.8 million (2018). It is part of the Greater Tokyo Area, the biggest metropolitan area in the world with 38,140,000 people (2016). The area is and the metro area has a population density of 2,642/km.

Japanese society is linguistically, ethnically and culturally homogeneous, composed of 98.1% ethnic Japanese, with small populations of foreign workers. Zainichi Koreans, Chinese, Filipinos, Brazilians mostly of Japanese descent, Peruvians mostly of Japanese descent and Americans are among the small minority groups in Japan. In 2003, there were about 134,700 non-Latin American Western (not including more than 33,000 American military personnel and their dependents stationed throughout the country) and 345,500 Latin American expatriates, 274,700 of whom were Brazilians (said to be primarily Japanese descendants, or "nikkeijin", along with their spouses), the largest community of Westerners.
The most dominant native ethnic group is the Yamato people; primary minority groups include the indigenous Ainu and Ryukyuan people, as well as social minority groups like the "burakumin". There are persons of mixed ancestry incorporated among the Yamato, such as those from Ogasawara Archipelago. In 2014, foreign-born non-naturalized workers made up only 1.5% of the total population. Japan is widely regarded as ethnically homogeneous, and does not compile ethnicity or race statistics for Japanese nationals; sources varies regarding such claim, with at least one analysis describing Japan as a multiethnic society while another analysis put the number of Japanese nationals of recent foreign descent to be minimal. Most Japanese continue to see Japan as a monocultural society. Former Japanese Prime Minister and current Finance Minister Tarō Asō described Japan as being a nation of "one race, one civilization, one language and one culture", which drew criticism from representatives of ethnic minorities such as the Ainu.

Japan has the second longest overall life expectancy at birth of any country in the world: 83.5 years for persons born in the period 2010–2015. The Japanese population is rapidly aging as a result of a post–World War II baby boom followed by a decrease in birth rates. In 2012, about 24.1 percent of the population was over 65, and the proportion is projected to rise to almost 40 percent by 2050.

On September 15, 2018, for the first time, one in five Japanese residents was aged 70 or older, according to the Ministry of Internal Affairs and Communications. 26.18 million people are 70 or older and accounted for 20.7 percent of the population. Elderly women crossed the 20 million line at 20.12 million, substantially outnumbering the nation's 15.45 million elderly men.

In 2018, the number of resident foreigners was 2.22 million in Japan (1.76% of the population). In 2018, net immigration rose for the sixth straight year with 165,000. The number of foreign workers was 1.46 million in 2018, 29.7% are in the manufacturing sector. 389,000 are from Vietnam and 316,000 are from China. On April 1, 2019, Japan's revised immigration law was enacted. The revision clarifies and better protects the rights of foreign workers. This helps reduce labor shortage in certain sectors of the economy. The reform changes the status of foreign workers to regular employees.

Japan has full religious freedom based on Article 20 of its Constitution. Upper estimates suggest that 84–96 percent of the Japanese population subscribe to Shinto as its indigenous religion (50% to 80% of which considering degrees of syncretism with Buddhism, shinbutsu-shūgō). However, these estimates are based on people affiliated with a temple, rather than the number of true believers. Many Japanese people practice both Shinto and Buddhism, they can either identify with both religions or describe themselves as non-religious or spiritual, despite participating in religious ceremonies as a cultural tradition, as a result religious statistics are often under-reported in Japan. The number of Shinto shrines in Japan is estimated to be around 100,000. Other studies have suggested that only 30 percent of the population identify themselves as belonging to a religion. According to Edwin Reischauer and Marius Jansen, some 70–80% of the Japanese do not consider themselves believers in any religion. Nevertheless, the level of participation remains high, especially during festivals and occasions such as the first shrine visit of the New Year. Taoism and Confucianism from China have also influenced Japanese beliefs and customs. Japanese streets are decorated on Tanabata, Obon and Christmas.

Shinto is the largest religion in Japan, practiced by nearly 80% of the population, yet only a small percentage of these identify themselves as "Shintoists" in surveys. This is due to the fact that "Shinto" has different meanings in Japan: most of the Japanese attend Shinto shrines and beseech kami without belonging to Shinto organisations, and since there are no formal rituals to become a member of folk Shinto, Shinto membership is often estimated counting those who join organised Shinto sects. Shinto has 100,000 shrines and 78,890 priests in the country. Buddhism first arrived in Japan in the 6th century; it was introduced in the year 538 or 552 from the kingdom of Baekje in Korea.

Christianity was first introduced into Japan by Jesuit missions starting in 1549. Today, fewer than 1% to 2.3% are Christians, most of them living in the western part of the country, where the missionaries' activities were greatest during the 16th century. Nagasaki Prefecture has the highest percentage of Christians: about 5.1% in 1996. , there were 32,036 Christian priests and pastors in Japan. Throughout the latest century, some Western customs originally related to Christianity (including Western style weddings, Valentine's Day and Christmas) have become popular as secular customs among many Japanese.

Islam in Japan is estimated to constitute about 80–90% of foreign born migrants and their children, primarily from Indonesia, Pakistan, Bangladesh, and Iran. Many of the ethnic Japanese Muslims are those who convert upon marrying immigrant Muslims. The Pew Research Center estimated that there were 185,000 Muslims in Japan in 2010.

Other minority religions include Hinduism, Sikhism, Judaism, and Bahá'í Faith; since the mid-19th century numerous new religious movements have emerged in Japan.

More than 99 percent of the population speaks Japanese as their first language. Japanese is an agglutinative language distinguished by a system of honorifics reflecting the hierarchical nature of Japanese society, with verb forms and particular vocabulary indicating the relative status of speaker and listener. Japanese writing uses kanji (Chinese characters) and two sets of kana (syllabaries based on cursive script and radical of kanji), as well as the Latin alphabet and Arabic numerals.

Besides Japanese, the Ryukyuan languages (Amami, Kunigami, Okinawan, Miyako, Yaeyama, Yonaguni), also part of the Japonic language family, are spoken in the Ryukyu Islands chain. Few children learn these languages, but in recent years the local governments have sought to increase awareness of the traditional languages. The Okinawan Japanese dialect is also spoken in the region. The Ainu language, which has no proven relationship to Japanese or any other language, is moribund, with only a few elderly native speakers remaining in Hokkaido. Public and private schools generally require students to take Japanese language classes as well as English language courses.

The changes in demographic structure have created a number of social issues, particularly a potential decline in workforce population and increase in the cost of social security benefits such as the public pension plan. A growing number of younger Japanese are not marrying or remain childless. In 2011, Japan's population dropped for a fifth year, falling by 204,000 people to 126.24 million people. This was the greatest decline since at least 1947, when comparable figures were first compiled. This decline was made worse by the March 2011 earthquake and tsunami, which killed nearly 16,000 people.

Japan's population is expected to drop to 95 million by 2050; demographers and government planners are currently in a major debate over how to cope with this problem. Immigration and birth incentives are sometimes suggested as a solution to provide younger workers to support the nation's ageing population. Japan accepts an average flow of 9,500 new Japanese citizens by naturalization per year. According to the UNHCR, in 2012 Japan accepted just 18 refugees for resettlement, while the United States took in 76,000.

Japan suffers from a high suicide rate. In 2009, the number of suicides exceeded 30,000 for the twelfth successive year. Suicide is the leading cause of death for people under 30.

Primary schools, secondary schools and universities were introduced in 1872 as a result of the Meiji Restoration. Since 1947, compulsory education in Japan comprises elementary and junior high school, which together last for nine years (from age 6 to age 15). Almost all children continue their education at a three-year senior high school. The two top-ranking universities in Japan are the University of Tokyo and Kyoto University, which have produced 16 Nobel Prize laureates.

Japan's education system played a central part in the country's recovery and rapid economic growth in the decades following the end of World War II. After World War II, the Fundamental Law of Education and the School Education Law were enacted. The latter law defined the school system that would be in effect for many decades: six years of elementary school, three years of junior high school, three years of high school, and two or four years of university. Starting in April 2016, various schools began the academic year with elementary school and junior high school integrated into one nine-year compulsory schooling program, in hopes to mitigate bullying and truancy; MEXT plans for this approach to be adopted nationwide in the coming years.

The Programme for International Student Assessment coordinated by the OECD currently ranks the overall knowledge and skills of Japanese 15-year-olds as the third best in the world. Japan is one of the top-performing OECD countries in reading literacy, maths and sciences with the average student scoring 529 and has one of the world's highest-educated labor forces among OECD countries. The Japanese populace is well educated and its society highly values education as a platform for social mobility and for gaining employment in the country's competitive high-tech economy. The country's large pool of highly educated and skilled individuals is largely responsible for ushering Japan's post-war economic growth. Tertiary-educated adults in Japan, particularly graduates in sciences and engineering benefit economically and socially from their education and skills in the country's high tech economy. Spending on education as a proportion of GDP is below the OECD average. Although expenditure per student is comparatively high in Japan, total expenditure relative to GDP remains small. In 2015, Japan's public spending on education amounted to just 4.1 percent of its GDP, below the OECD average of 5.0 percent. In 2017, the country ranked third for the percentage of 25 to 64 year-olds that have attained tertiary education with 51 percent. In addition, 60.4 percent Japanese aged 25 to 34 have some form of tertiary education qualification and bachelor's degrees are held by 30.4 percent of Japanese aged 25 to 64, the second most in the OECD after South Korea. As the Japanese economy is largely scientific and technological based, the labor market demands people who have achieved some form of higher education, particularly related to science and engineering in order to gain a competitive edge when searching for employment opportunities.

In Japan, health care is provided by national and local governments. Payment for personal medical services is offered through a universal health insurance system that provides relative equality of access, with fees set by a government committee. People without insurance through employers can participate in a national health insurance program administered by local governments. Since 1973, all elderly persons have been covered by government-sponsored insurance. Patients are free to select the physicians or facilities of their choice.

Japanese culture has evolved greatly from its origins. Contemporary culture combines influences from Asia, Europe and North America. Traditional Japanese arts include crafts such as ceramics, textiles, lacquerware, swords and dolls; performances of bunraku, kabuki, noh, dance, and rakugo; and other practices, the tea ceremony, ikebana, martial arts, calligraphy, origami, onsen, Geisha and games. Japan has a developed system for the protection and promotion of both tangible and intangible Cultural Properties and National Treasures. Twenty-two sites have been inscribed on the UNESCO World Heritage List, eighteen of which are of cultural significance.

Throughout the millennia, since the prehistoric Jōmon period, Japan developed a sophisticated culture and etiquette while absorbing influences from Asia, Europe, and North America.

The code of etiquette in Japan governs the expectations of social behavior. They are considered very important in Japan. The etiquette varies greatly depending on one's status relative to the person in question. Some customs have changed over time. These distinct cultural values make Japanese etiquette substantially different from western and other countries.

Japan is regarded by sociologists as a high-context culture. People are more observant of hierarchical differences and communicate less explicitly and verbosely. High context cultures such as Japan are more focused upon in-groups while low context cultures are focused upon individuals. Face-saving (to avoid being disgraced or humiliated) is generally considered as more important in Japan's high context culture than in low-context ones such as the United States or Germany.

There are differences in advertising and marketing in Japan due to the high-context culture. In Japan advertising uses more colors, images, gestures and sounds with powerful meaning behind them. Dialogue is not a central part of the advertising. Every vocal and non-vocal expression is explored, because Japanese people are more sensitive to it. Comparatively in low-context cultures advertising is more straightforward.

Japanese architecture is a combination between local and other influences. It has traditionally been typified by wooden structures, elevated slightly off the ground, with tiled or thatched roofs. Sliding doors ("fusuma") were used in place of walls, allowing the internal configuration of a space to be customized for different occasions. People usually sat on cushions or otherwise on the floor, traditionally; chairs and high tables were not widely used until the 20th century. Since the 19th century, however, Japan has incorporated much of Western, modern, and post-modern architecture into construction and design, and is today a leader in cutting-edge architectural design and technology.

The introduction of Buddhism during the sixth century was a catalyst for large-scale temple building using complicated techniques in wood. Influence from the Chinese Tang and Sui dynasties led to the foundation of the first permanent capital in Nara. Its checkerboard street layout used the Chinese capital of Chang'an as a template for its design. A gradual increase in the size of buildings led to standard units of measurement as well as refinements in layout and garden design. The introduction of the tea ceremony emphasised simplicity and modest design as a counterpoint to the excesses of the aristocracy.

During the Meiji Restoration of 1868 the history of Japanese architecture was radically changed by two important events. The first was the Kami and Buddhas Separation Act of 1868, which formally separated Buddhism from Shinto and Buddhist temples from Shinto shrines, breaking an association between the two which had lasted well over a thousand years.

Second, it was then that Japan underwent a period of intense Westernization in order to compete with other developed countries. Initially architects and styles from abroad were imported to Japan but gradually the country taught its own architects and began to express its own style. Architects returning from study with western architects introduced the International Style of modernism into Japan. However, it was not until after the Second World War that Japanese architects made an impression on the international scene, firstly with the work of architects like Kenzō Tange and then with theoretical movements like Metabolism.

Japanese philosophy has historically been a fusion of both foreign, particularly Chinese and Western, and uniquely Japanese elements. In its literary forms, Japanese philosophy began about fourteen centuries ago.

Archaeological evidence and early historical accounts suggest that Japan was originally an animistic culture, which viewed the world as infused with or sacred presence as taught by Shinto, though it is not a philosophy as such, but has greatly influenced all other philosophies in their Japanese interpretations.

Confucianism entered Japan from China around the 5th century AD, as did Buddhism. Confucian ideals are still evident today in the Japanese concept of society and the self, and in the organization of the government and the structure of society. Buddhism has profoundly impacted Japanese psychology, metaphysics, and aesthetics.

Indigenous ideas of loyalty and honor have been held since the 16th century. Western philosophy has had its major impact in Japan only since the middle of the 19th century.

The Shrines of Ise have been celebrated as the prototype of Japanese architecture. Largely of wood, traditional housing and many temple buildings see the use of tatami mats and sliding doors that break down the distinction between rooms and indoor and outdoor space. Japanese sculpture, largely of wood, and Japanese painting are among the oldest of the Japanese arts, with early figurative paintings dating back to at least 300 BC. The history of Japanese painting exhibits synthesis and competition between native Japanese aesthetics and adaptation of imported ideas.

The interaction between Japanese and European art has been significant: for example ukiyo-e prints, which began to be exported in the 19th century in the movement known as Japonism, had a significant influence on the development of modern art in the West, most notably on post-Impressionism. Famous ukiyo-e artists include Hokusai and Hiroshige.

Japanese manga developed in the 20th century and have become popular worldwide. Rakuten Kitazawa was first to use the word "manga" in the modern sense.

Japan has one of the oldest and largest film industries in the world; movies have been produced in Japan since 1897. Three Japanese films ("Rashomon", "Seven Samurai" and "Tokyo Story") made the "Sight & Sound"'s 2002 Critics and Directors Poll for the best films of all time. Ishirō Honda's "Godzilla" became an international icon of Japan and spawned an entire subgenre of "kaiju" films, as well as the longest-running film franchise in history. Japan has won the Academy Award for the Best Foreign Language Film four times, more than any other Asian country.

Japanese music is eclectic and diverse. Many instruments, such as the koto, were introduced in the 9th and 10th centuries. The accompanied recitative of the Noh drama dates from the 14th century and the popular folk music, with the guitar-like shamisen, from the sixteenth. Western classical music, introduced in the late 19th century, now forms an integral part of Japanese culture. The imperial court ensemble Gagaku has influenced the work of some modern Western composers.

Notable classical composers from Japan include Toru Takemitsu and Rentarō Taki. Popular music in post-war Japan has been heavily influenced by American and European trends, which has led to the evolution of J-pop, or Japanese popular music. Karaoke is the most widely practiced cultural activity in Japan. A 1993 survey by the Cultural Affairs Agency found that more Japanese had sung karaoke that year than had participated in traditional pursuits such as flower arranging (ikebana) or tea ceremonies.

The earliest works of Japanese literature include the "Kojiki" and "Nihon Shoki" chronicles and the "Man'yōshū" poetry anthology, all from the 8th century and written in Chinese characters. In the early Heian period, the system of phonograms known as "kana" (hiragana and katakana) was developed. "The Tale of the Bamboo Cutter" is considered the oldest Japanese narrative. An account of Heian court life is given in "The Pillow Book" by Sei Shōnagon, while "The Tale of Genji" by Murasaki Shikibu is often described as the world's first novel.

During the Edo period, the chōnin ("townspeople") overtook the samurai aristocracy as producers and consumers of literature. The popularity of the works of Saikaku, for example, reveals this change in readership and authorship, while Bashō revivified the poetic tradition of the Kokinshū with his haikai (haiku) and wrote the poetic travelogue "Oku no Hosomichi". The Meiji era saw the decline of traditional literary forms as Japanese literature integrated Western influences. Natsume Sōseki and Mori Ōgai were the first "modern" novelists of Japan, followed by Ryūnosuke Akutagawa, Jun'ichirō Tanizaki, Yukio Mishima and, more recently, Haruki Murakami. Japan has two Nobel Prize-winning authors – Yasunari Kawabata (1968) and Kenzaburō Ōe (1994).

Japanese comics or graphic novels, known as manga, developed in the 20th century and have become popular worldwide. Rakuten Kitazawa was first to use the word "manga" in the modern sense. Anime are influenced by manga, and are often adapted from them.

Japanese animated films and television series, known as anime, were largely influenced by Japanese manga and have been extensively popular in the West. Japan is a world-renowned powerhouse of animation.

Japanese cuisine is based on combining staple foods, typically Japanese rice or noodles, with a soup and "okazu" – dishes made from fish, vegetable, tofu and such – to add flavor to the staple food. In the early modern era ingredients such as red meats that had previously not been widely used in Japan were introduced.

Japanese cuisine is known for its emphasis on seasonality of food, quality of ingredients and presentation. Japanese cuisine offers a vast array of regional specialties that use traditional recipes and local ingredients. The phrase refers to the makeup of a typical meal served, but has roots in classic "kaiseki", "honzen", and "yūsoku" cuisine. The term is also used to describe the first course served in standard "kaiseki" cuisine nowadays. Japanese curry, since its introduction to Japan from British India, is so widely consumed that it can be called a national dish.

Traditional Japanese sweets are known as "wagashi". Ingredients such as red bean paste and mochi are used. More modern-day tastes includes green tea ice cream, a very popular flavor. Kakigōri is a shaved ice dessert flavored with syrup or condensed milk. It is usually sold and eaten at summer festivals. Popular Japanese beverages such as sake, which is a brewed rice beverage that, typically, contains 14%–17% alcohol and is made by multiple fermentation of rice. Beer has been brewed in Japan since the late 1800s, and is produced in many regions by companies including Asahi Breweries, Kirin Brewery, and Sapporo Brewery – claiming to be the oldest named brand of beer in Japan.

Officially, Japan has 16 national, government-recognized holidays. Public holidays in Japan are regulated by the of 1948. Beginning in 2000, Japan implemented the Happy Monday System, which moved a number of national holidays to Monday in order to obtain a long weekend. In 2006, the country decided to add Shōwa Day, a new national holiday, in place of Greenery Day on April 29, and to move Greenery Day to May 4. These changes took effect in 2007. In 2014, the House of Councillors decided to add to the Japanese calendar on August 11, after lobbying by the Japanese Alpine Club. It is intended to coincide with the Bon Festival vacation time, giving Japanese people an opportunity to appreciate Japan's mountains.

The national holidays in Japan are New Year's Day on January 1, Coming of Age Day on Second Monday of January, National Foundation Day on February 11, The Emperor's Birthday on February 23, Vernal Equinox Day on March 20 or 21, Shōwa Day on April 29, Constitution Memorial Day on May 3, Greenery Day on May 4, Children's Day on May 5, Marine Day on Third Monday of July, Mountain Day on August 11, Respect for the Aged Day on Third Monday of September, Autumnal Equinox on September 23 or 24, Health and Sports Day on Second Monday of October, Culture Day on November 3, and Labor Thanksgiving Day on November 23.

There are many festivals in Japan, which are called in Japanese which are celebrated annually. There are no specific festival days for all of Japan; dates vary from area to area, and even within a specific area, but festival days do tend to cluster around traditional holidays such as Setsubun or Obon. Festivals are often based around one event, with food stalls, entertainment, and carnival games to keep people entertained. Its usually sponsored by a local shrine or temple, though they can be secular.

Notable festivals often feature processions which may include elaborate floats. Preparation for these processions is usually organised at the level of neighborhoods, or . Prior to these, the local kami may be ritually installed in mikoshi and paraded through the streets, such as Gion in Kyoto, and Hadaka in Okayama.

Traditionally, sumo is considered Japan's national sport. Japanese martial arts such as judo, karate and kendo are also widely practiced and enjoyed by spectators in the country. After the Meiji Restoration, many Western sports were introduced in Japan and began to spread through the education system.

Japan hosted the Summer Olympics in Tokyo in 1964 and the Winter Olympics in Sapporo in 1972 and Nagano in 1998. Further, the country hosted the official 2006 Basketball World Championship. Tokyo will host the 2020 Summer Olympics, making Tokyo the first Asian city to host the Olympics twice. The country gained the hosting rights for the official Women's Volleyball World Championship on five occasions (1967, 1998, 2006, 2010, 2018), more than any other nation. Japan is the most successful Asian Rugby Union country, winning the Asian Five Nations a record 6 times and winning the newly formed IRB Pacific Nations Cup in 2011. Japan will host the 2019 IRB Rugby World Cup.
Baseball is currently the most popular spectator sport in the country. Japan's top professional league, now known as Nippon Professional Baseball, was established in 1936 and is widely considered to be the highest level of professional baseball in the world outside of the North American Major Leagues. Since the establishment of the Japan Professional Football League in 1992, association football has also gained a wide following. Japan was a venue of the Intercontinental Cup from 1981 to 2004 and co-hosted the 2002 FIFA World Cup with South Korea. Japan has one of the most successful football teams in Asia, winning the Asian Cup four times. Also, Japan recently won the FIFA Women's World Cup in 2011. Golf is also popular in Japan, as are forms of auto racing like the Super GT series and Formula Nippon. The country has also produced three players who have succeeded in the NBA.

Video gaming in Japan is a major industry. Japan became a major exporter of video games during the golden age of arcade video games, an era that began with the release of Taito's "Space Invaders" in 1978 and ended around the mid-1980s. Japanese-made video game consoles have been popular since the 1980s. Japan became the most dominant country within the global video game industry, since the release of the Nintendo Famicom and the third generation of consoles. Japan's dominance within the industry would continue for the next two decades, until Microsoft's Xbox consoles began challenging Sony and Nintendo in the 2000s.

In the Japanese gaming industry, arcades have remained popular through to the present day. , $6 billion of Japan's $20 billion gaming market is generated from arcades, which represent the largest sector of the Japanese video game market, followed by home console games and mobile games at $3.5 billion and $2 billion, respectively.

In the present day, Japan is the world's largest market for mobile games. The country's traditional console gaming market itself is today largely dominated by handheld game consoles rather than home consoles. In 2014, Japan's consumer video game market grossed $9.6 billion, with $5.8 billion coming from mobile gaming.

Television and newspapers take an important role in Japanese mass media, though radio and magazines also take a part. For a long time, newspapers were regarded as the most influential information medium in Japan, although audience attitudes towards television changed with the emergence of commercial news broadcasting in the mid-1980s. Over the 1990s, television surpassed newspapers as Japan's main information and entertainment medium.

There are 6 nationwide television networks: NHK (public broadcasting), Nippon Television (NTV), Tokyo Broadcasting System (TBS), Fuji Network System (FNS), TV Asahi (EX) and TV Tokyo Network (TXN). For the most part, television networks were established based on capital investments by existing radio networks. Variety shows, serial dramas, and news constitute a large percentage of Japanese television shows. According to the 2015 NHK survey on television viewing in Japan, 79 percent of Japanese watch television every day. The average daily duration of television viewing was three hours.

Japanese readers have a choice of approximately 120 daily newspapers with a total of 50 million copies of set paper with an average subscription rate of 1.13 newspapers per household. The main newspapers' publishers are the "Yomiuri Shimbun", "Asahi Shimbun", "Mainichi Shimbun", "Nikkei Shimbun" and "Sankei Shimbun". According to a survey conducted by the Japanese Newspaper Association in June 1999, 85.4 per cent of men and 75 per cent of women read a newspaper every day. Average daily reading times vary with 27.7 minutes on weekdays and 31.7 minutes on holidays and Sunday.






</doc>
<doc id="15575" url="https://en.wikipedia.org/wiki?curid=15575" title="Geography of Japan">
Geography of Japan

Japan is an island country comprising a stratovolcanic archipelago over along East Asia's Pacific coast. It consists of 6,852 islands. The 5 main islands are Hokkaido, Honshu, Kyushu, Shikoku and Okinawa. There are 6,847 'remote islands'. The Ryukyu Islands and Nanpō Islands are south and east of the main islands.

The territory extends . It is the 4th largest island country in the world and the largest island country in East Asia. Japan has the sixth longest coastline and the eighth largest Exclusive Economic Zone of in the world.

The terrain is mostly rugged and mountainous with 66% forest. The population is clustered in urban areas on the coast, plains and valleys. Japan is located in the northwestern Ring of Fire on multiple tectonic plates. East of the Japanese archipelago are three oceanic trenches. The Japan Trench is created as the oceanic Pacific Plate subducts beneath the continental Okhotsk Plate. The continuous subduction process causes frequent earthquakes, tsunami and stratovolcanoes. The islands are also affected by typhoons. The subduction plates have pulled the Japanese archipelago eastward, created the Sea of Japan and separated it from the Asian continent by back-arc spreading 15 million years ago.

The climate of the Japanese archipelago varies from humid continental in the north (Hokkaido) to humid subtropical and tropical rainforest in the south (Okinawa Prefecture). These differences in climate and landscape have allowed the development of a diverse flora and fauna, with some rare endemic species, especially in the Ogasawara Islands.

Japan extends from 20° to 45° north latitude (Okinotorishima to Benten-jima) and from 122° to 153° east longitude (Yonaguni to Minami Torishima). Japan is surrounded by seas. To the north the Sea of Okhotsk separates it from the Russian Far East, to the west the Sea of Japan separates it from the Korean Peninsula, to the southwest the East China Sea separates the Ryukyu Islands from China and Taiwan, to the east is the Pacific Ocean.

The Japanese archipelago is over long in a north-to-southwardly direction from the Sea of Okhotsk to the Philippine Sea in the Pacific Ocean. It is narrow since no point in Japan is more than from the sea. There are 6,852 islands in total (2007). The five main islands are (from north to south) Hokkaido, Honshu, Shikoku, Kyushu and Okinawa. The 6,847 smaller islands are called 'remote islands'. This includes the Nansei Islands, the Nanpō Islands and islets, with 430 inhabited islands and others are uninhabited. In total, as of 2018, Japan's territory is , of which is land and water. Japan has the sixth longest coastline in the world (). It is the largest island country in East Asia and fourth largest island country in the world. There are a wide range of climatic zones and ecosystems.

Due to Japan's many far-flung outlying islands and long coastline, the country has extensive marine life and mineral resources in the ocean. The Exclusive Economic Zone of Japan covers and is the eighth largest in the world. It is more than 11 times the land area of the country.

Japan has a population of 126 million in 2019. It is the eleventh most populous country in the world and second most populous island country. 81% of the population lives on Honshu, 10% on Kyushu, 4.2% on Hokkaido, 3% on Shikoku, 1.1% in Okinawa Prefecture and 0.7% on other Japanese islands such as the Nanpō Islands.


Location: Japan is a long island chain between the Sea of Okhotsk, the Sea of Japan and the Philippine Sea. It is in the Pacific Ocean, East Asia and North East Asia. Japan is east of Siberia, the Korean Peninsula and Taiwan.

Map references: Asia, East Asia, North East Asia, Pacific Ocean

Terrain: mostly rugged and mountainous with about 70% mountainous land (comparable to Norway).

Land boundaries: the ocean, no land borders.

Coastline: 

Population: 126,317,000 (2019)


Climate: varies from humid continental climate in the north (Hokkaido) to humid subtropical and tropical rainforest climate in the south (Okinawa Prefecture) of the Japanese archipelago.

Natural resources: small deposits of coal, oil, iron and minerals. There is a major fishing industry and untapped marine life and mineral resources in the Exclusive Economic Zone of Japan.


Irrigated land: (2010)

Total renewable water resources: (2011)

Freshwater withdrawal (domestic/industrial/agricultural):

Japan is informally divided into eight regions from northeast (Hokkaidō) to southwest (Ryukyu Islands):

Each region contains several prefectures, except the Hokkaido region, which comprises only Hokkaido Prefecture.

The regions are not official administrative units, but have been traditionally used as the regional division of Japan in a number of contexts. For example, maps and geography textbooks divide Japan into the eight regions, weather reports usually give the weather by region, and many businesses and institutions use their home region as part of their name (Kinki Nippon Railway, Chūgoku Bank, Tohoku University, etc.). While Japan has eight High Courts, their jurisdictions do not correspond with the eight regions.

About 73% of Japan is mountainous, with a mountain range running through each of the main islands. Japan's highest mountain is Mount Fuji, with an elevation of . Japan's forest cover rate is 68.55% since the mountains are heavily forested. The only other developed nations with such a high forest cover percentage are Finland and Sweden.

Since there is little level ground, many hills and mountainsides at lower elevations around towns and cities are often cultivated. As Japan is situated in a volcanic zone along the Pacific deeps, frequent low-intensity earth tremors and occasional volcanic activity are felt throughout the islands. Destructive earthquakes occur several times a century. Hot springs are numerous and have been exploited as an economic capital by the leisure industry.

The Geospatial Information Authority of Japan measures Japan's territory annually in order to continuously grasp the state of the national land. As of October 1, 2019 (Reiwa 1) Japan's territory is . It increases in area due to volcanic eruptions such as Nishinoshima (西之島), the natural expansion of the islands and land reclamation. 

This table shows the land use in 2002 (Heisei 14).

The Japanese archipelago is relatively far away from the Asian continent. Kyushu is closest to the southernmost point of the Korean peninsula with a distance of . That's almost 6 times farther away than from England to France . Thus historically Kyushu was the gateway between Asia and Japan. China is separated by sea from Japan's big main islands. Hokkaido is near Sakhalin, but North East Asia is sparsely populated. The southern half was Karafuto from 1905 to 1945. Most of the population lives on the Pacific coast side of Honshū. The west coast facing the Sea of Japan is less densely populated.

The Japanese archipelago was difficult to reach since before ancient history. During the Paleolithic period around 20,000 BCE at the height of the Last Glacial Maximum there was a land bridge between Hokkaido and Sakhalin (Karafuto) which linked Japan with the North East Asian continent. The land bridge disappeared when the sea levels rose in the Jōmon period around 10,000 BCE. The invention of the airplane made Japan more accessible in the 20th century.

Japan's remote location, surrounded by vast seas, rugged, mountainous terrain and steep rivers make it secure against invaders and uncontrolled migration from the Asian continent. The Japanese can close their civilization with an isolationist foreign policy. During the Edo period the Tokugawa Shogunate enforced the Sakoku policy which prohibited most foreign contact and trade from 1641 to 1853. In modern times, the inflow of people is managed via the seaports, airports and spaceports. Thus Japan is fairly insulated from continental issues.

Throughout history, Japan was never fully invaded nor colonized by foreigners. Such as when the Mongols conquered China, Central Asia and East Europe they established the Mongol Empire from 1206 to 1294 CE. The Mongols tried to invade Japan twice and failed in 1274 and 1281. Japan capitulated only once after nuclear attacks in World War II. At the time Japan didn't have nuclear technology. The insular geography is a major factor for the isolationist, semi-open and expansionist periods of Japanese history.

The mountainous islands of the Japanese archipelago form a crescent off the eastern coast of Asia. They are separated from the continent by the Sea of Japan, which serves as a protective barrier. The country consists of five main islands: Hokkaido, Honshu, Shikoku, Kyushu and Okinawa; with more than 6,800 adjacent smaller islands and islets ("island" defined as land more than 100 m in circumference). This includes the Izu Islands, Ogasawara Islands and Volcano Islands (Kazan Retto) in the Nanpō Islands, and the Satsunan Islands, Okinawa Islands, and Sakishima Islands of the Ryukyu Islands. Japan claims the southern Kuril islands from Russia with the Kuril Islands dispute (). The Ryukyu Islands curve 970 kilometers southward from Kyūshū. The four major islands (Hokkaido, Honshu, Kyushu and Shikoku) are separated by narrow straits of the Seto Inland Sea and form a natural entity. Japan has 108 active volcanoes (10% of the world's active volcanoes) due to the active plate tectonics in the ring of fire.

The Japanese islands are the summits of mountain ridges uplifted near the outer edge of the continental shelf. About 73 percent of Japan's area is mountainous, and scattered plains and intermontane basins (in which the population is concentrated) cover only about 27 percent. A long chain of mountains runs down the middle of the archipelago, dividing it into two halves, the "face", fronting on the Pacific Ocean, and the "back", toward the Sea of Japan. On the Pacific side are steep mountains 1,500 to 3,000 meters high, with deep valleys and gorges.

Central Japan is marked by the convergence of the three mountain chains—the Hida, Kiso, and Akaishi mountains—that form the Japanese Alps (Nihon Arupusu), several of whose peaks are higher than 3,000 meters. The highest point in the Japanese Alps is Mount Kita at 3,193 meters. The highest point in the country is Mount Fuji (Fujisan, also erroneously called Fujiyama), a volcano dormant since 1707 that rises to above sea level in Shizuoka Prefecture. On the Sea of Japan side are plateaus and low mountain districts, with altitudes of 500 to 1,500 meters.

There are three major plains in central Honshū. The largest is the Kantō Plain which covers in the Kantō region. The capital Tokyo and the largest metropolitan population is located there. The second largest plain is the Nōbi Plain with the third-most-populous urban area Nagoya. The third largest plain is the Osaka Plain which covers in the Kinki region. It features the second largest urban area of Osaka (part of the Keihanshin metropolitan area). Osaka and Nagoya extend inland from their bays until they reach steep mountains. The Osaka Plain is connected with Kyoto and Nara. Kyoto is located in the Yamashiro Basin and Nara is in the Nara Basin .

The Kantō Plain, Osaka Plain and Nōbi Plain are the most important economical, political and cultural areas of Japan. These plains had the biggest agricultural production and large bays with ports for fishing and trade. This made them the biggest population centers. Kyoto and Nara are the ancient capitals and cultural heart of Japan. The Kantō Plain became Japan's center of power, because it's the biggest plain with a central location and historically it had the most agricultural production that could be taxed. The Tokugawa Shogunate established a bakufu in Kamakura in 1603 CE. This evolved into the capital Tokyo in 1868 CE.

Hokkaido has multiple plains such as the Ishikari Plain , Tokachi Plain , the Kushiro Plain is the largest wetland in Japan and Sarobetsu Plain . There are many farms that produce a plethora of agricultural products. The average farm size in Hokkaido is 26 hectares per farmer in 2013. That's almost 11 times bigger than the national average of 2.4 hectares. This made Hokkaido the most agriculturally rich prefecture of Japan. Nearly one fourth of Japan's arable land and 22% of Japan's forests are in Hokkaido.

Other important plains are e.g. the Sendai Plain around the city of Sendai in northeastern Honshū. Many of these plains are along the coast, and their areas have been increased by land reclamation throughout recorded history.

Rivers are generally steep and swift, and few are suitable for navigation except in their lower reaches. Although most rivers are less than 300 kilometers in length, their rapid flow from the mountains provides a valuable, renewable resource: hydroelectric power generation. Japan's hydroelectric power potential has been exploited almost to capacity. Seasonal variations in flow have led to extensive development of flood control measures. Most of the rivers are relatively short. The longest, the Shinano River, which winds through Nagano Prefecture to Niigata Prefecture and flows into the Sea of Japan, is long. The largest freshwater lake is Lake Biwa , northeast of Kyoto.

Extensive coastal shipping, especially around the Seto Inland Sea (Seto Naikai), compensates for the lack of navigable rivers. The Pacific coastline south of Tokyo is characterized by long, narrow, gradually shallowing inlets produced by sedimentation, which has created many natural harbors. The Pacific coastline north of Tokyo, the coast of Hokkaidō, and the Sea of Japan coast are generally unindented, with few natural harbors.

In November 2008, Japan filed a request to expand its claimed continental shelf. In April 2012, the U.N. Commission on the Limits of the Continental Shelf recognized around of seabed around Okinotorishima, giving Japan priority over access to seabed resources in nearby areas. According to U.N. Commission on the Limits of the Continental Shelf, the approved expansion is equal to about 82% of Japan's total land area. The People's Republic of China and South Korea have opposed Japan's claim because they view Okinotorishima not as an island, but as a group of rocks.

The Japanese archipelago is mainly rugged and mountainous (73%) so the relatively small amount of habitable land has prompted significant terrain modification by humans over many centuries. The Japanese archipelago has been transformed by humans into a sort of continuous land, in which the four main islands (Hokkaido, Honshu, Kyushu, Shikoku except Okinawa) are entirely reachable and passable by rail and road transportation thanks to the construction of huge bridges and tunnels that connect each other and various islands.

Approximately 0.5% of Japan's total area is reclaimed land (umetatechi). It began in the 12th century. Land was reclaimed from the sea and from river deltas by building dikes and drainage and rice paddies on terraces carved into mountainsides. The majority of land reclamation projects occurred after World War II during the Japanese economic miracle. Reclamation of 80% to 90% of all the tidal flatland was done. Big land reclamation projects with landfill were done in coastal areas for maritime and industrial factories. Such as Higashi Ogishima in Kawasaki, Osaka Bay and Nagasaki Airport. Port Island, Rokkō Island and Kobe Airport were built in Kobe. Late 20th and early 21st century projects include artificial islands such as Chubu Centrair International Airport in Ise Bay, Kansai International Airport in the middle of Osaka Bay, Yokohama Hakkeijima Sea Paradise and Wakayama Marina City.

The village of Ogata in Akita, was established on land reclaimed from Lake Hachirōgata (Japan's second largest lake at the time) starting in 1957. By 1977, the amount of land reclaimed totaled .

Examples of land reclamation in Japan:


Much reclaimed land is made up of landfill from waste materials, dredged earth, sand, sediment, sluge and soil removed from construction sites. It is used to build man-made islands in harbors and embankments in inland areas.

From November 8, 2011, Tokyo City began accepting rubble and waste from the 2011 Tōhoku earthquake and tsunami region. This rubble was processed and when it had the appropriate radiation levels it was used as landfill to build new artificial islands in Tokyo Bay. Yamashita Park in Yokohama City was made with rubble from the great Kantō earthquake in 1923.

There is a risk of contamination on artificial islands with landfill and reclaimed land if there was industry that spilled (toxic) chemicals into the ground. For example, the artificial island Toyosu was once occupied by a Tokyo gas factory. Toxic substances were discovered in the soil and groundwater at Toyosu. The Tokyo Metropolitan Government spent an additional 3.8 billion yen ($33.5 million) to pump out groundwater by digging hundreds of wells. In June 2017, plans to move the Tsukiji fish market were restarted. but delayed in July to the autumn of 2018. After the new site was declared safe following a cleanup operation, the opening date of Toyosu Market was set for 11 October 2018.

It's important to look at the sea in three-dimensional, spatial terms. Because most valuable are the natural resources below the sea surface. That means the total depth from the surface of the sea to the seabed. Japan's sea territory is . Japan ranks 4th with its exclusive economic zone (EEZ) ocean water volume from 0 to depth. Japan ranks 5th with sea volume of 2000–3000 meters, fourth with 3000–4000 meters, 3rd with 4000–5000 meters and Japan ranks first with volume of 5000 to over 6000 meters. The relief map of the Japanese archipelago shows that 50% of Japan's sea territory has an ocean volume between 0 to depth. The other 50% has a depth of to over . 19% has a depth of 0 to . Thus Japan possesses one of the largest ocean territories with a combination of all depths from shallow to very deep sea. Multiple long undersea mountain ranges stretch from Japan's main islands to the south. They occasionally reach above the sea surface as islands. East of the undersea mountain ranges are three oceanic trenches: the Kuril–Kamchatka Trench (max depth ), Japan Trench (max depth ) and Izu-Ogasawara Trench (max depth ).

There are large quantities of marine life and mineral resources in the EEZ and seabed of Japan. At a depth of over there are minerals such as manganese nodules, cobalt in the crust and hydrothermal deposits. Greenhouse gas (CO2) could be stored in the deep sea at a depth over to combat climate change. The large volume of seawater could be used for various purposes. For example to generate renewable energy from the ocean currents. There are technological obstacles for humans to operate and utilize resources in the deep sea. New technologies can be developed to manage and conserve the ocean. Just like space, the deep sea is a final frontier of humanity. It is said that humans know more about the Moon than the deepest parts of the ocean. Numerous scientists believe that the only way to really understand the oceanic environment is to be there. Ocean colonization with underwater habitats would be cheaper and easier than space colonies.

Most of the marine resources are invisible on the surface of the sea. Underwater vision is very limited in the ocean. Light penetrates the ocean until about in the sunlight (euphotic) zone. After that sunlight and visibility decreases rapidly in the twilight (dysphotic) zone. The sea water can be murky. At a depth of there is perpetual darkness in the midnight (aphotic) zone. So other methods must be used for humans to see in the ocean.

The Pelagic zone divides the ocean depths in water columns. The abundance and biomass of marine life decreases per zone. The Epipelagic zone (above 200 m) has the highest concentration of marine life such as plankton, tuna and sharks. The Mesopelagic zone (200–1000 m) has e.g. shrimp, swordfish, squid, cuttlefish and marine hatchet fish. Many deep sea creatures go to the Epipelagic zone to feed at night. The Bathyal zone (1000–4000 m) has bioluminescent organisms, angler fish, giant squid and tripod fish, but no plants due to total darkness. They mainly consume the detritus that falls from the zones above. In the Abyssal zone (4000–6000 m) are few living creatures due to extremely high pressure, cold temperatures and darkness. There are creatures such as echinoderms, basket star, scotoplanes and sea spiders. The Hadal zone (6000 m) is the deepest zone in oceanic trenches. There is fauna such as benthos, fish, sea cucumber, bristle worms, bivalves, isopods, sea anemones, amphipods and gastropods. The seabed and mineral resources are located at different depths based on the marine geology.

The islands of Japan were created by tectonic plate movements over several 100 millions of years from the mid-Silurian (443.8 Mya) to the Pleistocene (11,700 years ago).


The Pacific Plate and Philippine Plate are subduction plates. They are deeper than the Eurasian plate. The Philippine Sea Plate moves beneath the continental Amurian Plate and Okinawa Plate to the south. The Pacific Plate moves under the Okhotsk Plate to the north. These subduction plates have pulled Japan eastward and opened the Sea of Japan by back-arc spreading around 15 million years ago. The Strait of Tartary and the Korea Strait opened much later. La Pérouse Strait formed about 60,000 to 11,000 years ago closing the path used by mammoths which had earlier moved to northern Hokkaido.

The subduction zone is where the oceanic crust slides beneath the continental crust or other oceanic plates. This is because the oceanic plate's litosphere has a higher density.Subduction zones are sites that usually have a high rate of volcanism and earthquakes. Additionally, subduction zones develop belts of deformation The subduction zones on the east side of the Japanese archipelago cause frequent low intensity earth tremors. Major earthquakes, volcanic eruptions and tsunamis occur several times per century. It is part of the Pacific Ring of Fire. Northeastern Japan, north of Tanakura fault had high volcanic activity 14–17 million years before present.

The (aka Median Tectonic Line or MTL), is Japan's longest fault system. The MTL begins near Ibaraki Prefecture, where it connects with the Itoigawa-Shizuoka Tectonic Line (ISTL) and the Fossa Magna. It runs parallel to Japan's volcanic arc, passing through central Honshū to near Nagoya, through Mikawa Bay, then through the Inland Sea from the Kii Channel and Naruto Strait to Shikoku along the Sadamisaki Peninsula and the Bungo Channel and Hōyo Strait to Kyūshū.

The Japan Median Tectonic Line moves right-lateral strike-slip, at about 5–10 millimeter per year. The sense of motion is consistent with the direction of the Nankai Trough's oblique convergence. The rate of motion on the MTL is much less than the rate of convergence at the plate boundary. This makes it difficult to distinguish the motion on the MTL from interseismic elastic straining in GPS data.

East of the Japanese archipelago are three oceanic trenches in the Pacific Ring of Fire.


The Japan Trench is created as the oceanic Pacific Plate subducts beneath the continental Okhotsk Plate. The subduction process causes bending of the down going plate, creating a deep trench. Continuous movement on the subduction zone associated with the Japan Trench is one of the main causes of tsunamis and earthquakes in northern Japan, including the megathrust 2011 Tōhoku earthquake and tsunami. The rate of subduction associated with the Japan Trench has been recorded at about 7.9–9.2 cm/yr.

The Japanese archipelago is the result of several generations of subducting tectonic plates. Approximately of oceanic floor has passed under the Japanese archipelago in the last 450 million years, with most being fully subducted. It is considered a mature island arc.

The Japanese islands are formed of the mentioned geological units parallel to the subduction front. The parts of islands facing the Pacific Ocean's Plate are typically younger and display a larger proportion of volcanic products, while island parts facing the Sea of Japan are mostly heavily faulted and folded sedimentary deposits. In north-west Japan are thick Quaternary deposits. This makes determination of the geological history and composition difficult and it is not yet fully understood.

The Japanese island arc system has distributed volcanic series where the volcanic rocks change from tholeiite—calc-alkaline—alkaline with increasing distance from the trench. The geologic province of Japan is mostly basin and a bit extended crust.

The Japanese Archipelago grows gradually due to perpetual tectonic plate movements, earthquakes, stratovolcanoes and land reclamation in the Ring of Fire.

For example, during the twentieth century several new volcanoes emerged, including Shōwa-shinzan on Hokkaido and Myōjin-shō off the Bayonnaise Rocks in the Pacific. The 1914 Sakurajima eruption produced lava flows which connected the former island with the Ōsumi Peninsula in Kyushu. It is the most active volcano in Japan. The subduction of the Pacific Plate beneath the Philippine Sea Plate created the Izu Islands and Bonin Islands on the Izu-Bonin-Mariana Arc system.

During the 2013 eruption southeast of Nishinoshima, a new unnamed volcanic island emerged from the sea. Due to erosion and shifting sands, the new island merged with Nishinoshima and ceased to be a separate entity. A 1911 survey determined the caldera was at its deepest. This land formed naturally and increased the size of Japan.

The 2011 Tōhoku earthquake and tsunami caused portions of northeastern Japan to shift by closer to North America. This made some sections of Japan's landmass wider than before. The areas of Japan closest to the epicenter experienced the largest shifts. A stretch of coastline dropped vertically by , allowing the tsunami to travel farther and faster onto land. On 6 April the Japanese coast guard said that the earthquake shifted the seabed near the epicenter and elevated the seabed off the coast of Miyagi Prefecture by . A report by the Japan Agency for Marine-Earth Science and Technology, published in "Science" on 2 December 2011, concluded that the seabed in the area between the epicenter and the Japan Trench moved east-southeast and rose about as a result of the quake. The report also stated that the quake caused several major landslides on the seabed in the affected area.

During the Pleistocene (2.58 million years BCE) glacial cycles, the Japanese islands may have occasionally been connected to the Eurasian Continent via the Korea Strait and the Korean Peninsula or Sakhalin (Karafuto). The Sea of Japan was considered to be a frozen inner lake due to the lack of the warm Tsushima Current. Various plants and large animals, such as the "Palaeoloxodon naumanni" migrated into the Japanese archipelago.

The Sea of Japan was a landlocked sea when the land bridge of East Asia existed circa 18,000 BCE. During the glacial maximum the marine elevation was 200 meters lower than 2018 CE. Thus Tsushima island in the Korea Strait was a land bridge that connected Kyushu and the southern tip of Honshu with the Korean peninsula. There was still several kilometers of sea to the west of the Ryukyu islands and most of the Sea of Japan was open sea due it having a mean depth of . Comparatively, most of the Yellow Sea (Yellow Plane) had a semi-arid climate (dry steppe), due it being relatively shallow with a mean depth of . The Korean Peninsula was landlocked on the entire west and south side in the Yellow Plane. The onset of formation of the Japan Arc was in the Early Miocene (23 million years ago). The Early Miocene period was when the Sea of Japan started to open, and the northern and southern parts of the Japanese archipelago separated from each other. The Sea of Japan expanded during the Miocene.

The northern part of the Japanese archipelago was further fragmented until orogenesis of the northeastern Japanese archipelago began in the Late Miocene. The orogenesis of the high mountain ranges in northeastern Japan started in the Late Miocene and lasted in the Pliocene. The south part of the Japanese archipelago remained as a relatively large landmass. The land area expanded northward during the Miocene.

During the advance of the last Ice Age (115,000 BCE till 9682 BCE) the world sea level dropped. This dried and closed the exit straits of the Sea of Japan one by one. The deepest, and thus the last to close, is the western channel of the Korea Strait. There is controversy as to whether or not the Sea of Japan became a huge cold inland lake. The Japanese archipelago's Honshu, Kyushu, Shikoku, the Ryukyu islands and Nanpō Islands had a taiga biome (open boreal woodlands). It was characterized by coniferous forests consisting mostly of pines, spruces and larches. Hokkaido, Karafuto (Sakhalin) and the Kuril islands had mammoth steppe biome (steppe-tundra). The vegetation was dominated by palatable high-productivity grasses, herbs and willow shrubs.

The Sea of Japan has a surface area of , a mean depth of and a maximum depth of . It has a carrot-like shape, with the major axis extending from southwest to northeast and a wide southern part narrowing toward the north. The coastal length is about with the largest part () belonging to Russia. The sea extends from north to south for more than and has a maximum width of about .

There are three major basins: the "Yamato Basin" in the southeast, the "Japan Basin" in the north and the "Tsushima Basin" in the southwest. The Japan Basin has an oceanic crust and it's the deepest part of the sea, whereas the Tsushima Basin is the shallowest with depths below . The Yamato Basin and Tsushima Basin have thick ocean crusts. The continental shelves of the sea are wide on the eastern shores along Japan. On the western shores, they are narrow particularly along the Korean and Russian coast, averaging about .

The geographical location of the Japanese archipelago has defined the Sea of Japan for millions of years. Without the Japanese archipelago it would just be the Pacific Ocean. The term has been the international standard since at least the early 19th century. The International Hydrographic Organization, the international governing body for the naming bodies of water around the world, in 2012 recognized the term "Sea of Japan" as the only title for the sea.

The Japanese archipelago is surrounded by eight ocean currents. These are 1. Kuroshio 2. Kuroshio extension 3. Kuroshio countercurrent 4. Tsushima Current 5. Tsugaru Current 6. Sōya Current 7. Oyashio 8. Liman Current.

The is a warm north-flowing ocean current on the west side of the Ryukyu Islands and along the east coast of Kyushu, Shikoku and Honshu. It is a strong western boundary current and part of the North Pacific ocean gyre.

The Kuroshio Current starts in the east coast of Luzon, Philippines, Taiwan and flows northeastward past Japan, where it merges with the easterly drift of the North Pacific Current. It transports warm, tropical water northward toward the polar region. The Kuroshio extension is a northward continuation of the Kuroshio Current in the northwestern Pacific Ocean. The Kuroshio countercurrent flows southward to the east of the Kuroshio current in the Pacific Ocean and Philippine Sea.

The winter spawning Japanese Flying Squid are associated with the Kuroshio Current. The eggs and larvae develop during winter in the East China Sea and the adults travel with minimum energy via the Kuroshio Current to the rich northern feeding grounds near northwestern Honshu and Hokkaido.

The is a branch of the Kuroshio Current. It flows along the west coast of Kyushu and Honshu into the Sea of Japan.

The current is a cold subarctic ocean current that flows southward and circulates counterclockwise along the east coast of Hokkaido and northeastern Honshu in the western North Pacific Ocean. The waters of the Oyashio Current originate in the Arctic Ocean and flow southward via the Bering Sea, passing through the Bering Strait and transporting cold water from the Arctic Sea into the Pacific Ocean and the Sea of Okhotsk. It collides with the Kuroshio Current off the eastern shore of Japan to form the North Pacific Current. The nutrient-rich Oyashio is named for its metaphorical role as the that provides for and nurtures marine organisms.

The Liman Current is a southward flowing cold ocean current that flows from the Strait of Tartary along the Asian continent in the Sea of Japan.

The originates when the Tsushima Current is divided in two as it flows through the west entrance of the Tsugaru Strait and along the La Perouse Strait it becomes the at the north coast of Hokkaido. The flow rate is 1 to 3 knots. There is a relatively stronger flow in the summer than in the winter.

There are small deposits of coal, oil, iron and minerals in the Japanese archipelago. Japan is scarce in critical natural resources and has long been heavily dependent on imported energy and raw materials. The oil crisis in 1973 encouraged the efficient use of energy. Japan has therefore aimed to diversify its sources and maintain high levels of energy efficiency. In regards to agricultural products, the self-sufficiency rate of most items is less than 100% except for rice. Rice has a 100% food self-sufficiency. This makes it difficult to meet Japan's food demand without imports.

The Exclusive economic zone of Japan has an estimated large quantities of mineral resources such as methane clathrate, natural gas, metallic minerals and rare-earth mineral reserves. Seabed mineral resources such as manganese nodules, cobalt-rich crust and submarine hydrothermal deposits are located at depths over . Most of these deep sea resources are unexplored at the seabed. Much of the seabed has a depth of to . Japan's mining law restricts offshore oil and gas production. There are technological hurdles to mine at such extreme depths and to limit the ecological impact. There are no successful commercial ventures that mine the deep sea yet. So currently there are few deep sea mining projects to retrieve minerals or deepwater drilling on the ocean floor.

It is estimated that there are approximately 40 trillion cubic feet of methane clathrate in the eastern Nankai Trough of Japan. As of 2019, the Methane clathrate in the deep sea remains unexploited, because the necessary technology is not established yet. This is why currently Japan has very limited proven reserves like crude oil.

The Kanto region alone is estimated to have over 400 billion cubic meters of natural gas reserves. It forms a Minami Kantō gas field in the area spanning Saitama, Tokyo, Kanagawa, Ibaraki, and Chiba prefectures. However, mining is strictly regulated in many areas because it is directly below Tokyo, and is only slightly mined in the Bōsō Peninsula. In Tokyo and Chiba Prefecture, there have been frequent accidents with natural gas that was released naturally from the Minami Kantō gas field.

In 2018, south of Minami-Tori-shima at deep, approximately 16 million tons of rare-earth minerals were discovered by JAMSTEC in collaboration with Waseda University and the University of Tokyo.

There is a big fishing industry due to Japan's large territorial waters with marine life. Japan maintains one of the world's largest fishing fleets and accounts for nearly 15% of the global catch (2014). In 2005, Japan ranked sixth in the world in tonnage of fish caught. Japan captured 4,074,580 metric tons of fish in 2005, down from 4,987,703 tons in 2000 and 9,864,422 tons in 1980. In 2003, the total aquaculture production was predicted at 1,301,437 tonnes. In 2010, Japan's total fisheries production was 4,762,469 fish. Offshore fisheries accounted for an average of 50% of the nation's total fish catches in the late 1980s although they experienced repeated ups and downs during that period.

, 46.1% of energy in Japan was produced from petroleum, 21.3% from coal, 21.4% from natural gas, 4.0% from nuclear power and 3.3% from hydropower. Nuclear power is a major domestic source of energy and produced 9.2 percent of Japan's electricity, , down from 24.9 percent the previous year. Following the 2011 Tōhoku earthquake and tsunami disaster in 2011, the nuclear reactors were shut down. Thus Japan's industrial sector became even more dependent than before on imported fossil fuels. By May 2012 all of the country's nuclear power plants were taken offline because of ongoing public opposition following the Fukushima Daiichi nuclear disaster in March 2011, though government officials continued to try to sway public opinion in favor of returning at least some of Japan's 50 nuclear reactors to service. Shinzo Abe’s government seeks to restart the nuclear power plants that meet strict new safety standards and is emphasizing nuclear energy's importance as a base-load electricity source. , two reactors at Sendai are likely to restart in early 2015. In August 2015, Japan successfully restarted one nuclear reactor at the Sendai Nuclear Power Plant in Kagoshima prefecture, and several other reactors around the country have since resumed operations. Opposition from local governments has delayed several restarts that remain pending.

Reforms of the electricity and gas sectors, including full liberalization of Japan's energy market in April 2016 and gas market in April 2017, constitute an important part of Prime Minister Abe's economic program.

Japan has the third largest geothermal reserves in the world. Geothermal energy is being heavily focused on as a source of power following the Fukushima disaster. The Ministry of Economy, Trade, and Industry is exploring over 40 locations for potential geothermal energy plants.

On 3 July 2018, Japan's government pledged to increase renewable energy sources from 15% to 22–24% including wind and solar by 2030. Nuclear energy will provide 20% of the country's energy needs as an emissions-free energy source. This will help Japan meet climate change commitments.

Japan has 34 and 56 in 2019. These are designated and managed for protection and sustainable usage by the Ministry of the Environment under the of 1957. The Quasi-National Parks have slightly less beauty, size, diversity, or preservation. They are recommended for ministerial designation and managed by the Prefectures under the supervision of the Ministry of the Environment.

The over long Japanese archipelago has diverse landscapes. For example, the northern part of Hokkaido has a taiga biome. Hokkaido has 22% of Japan's forestland with coniferous trees (Sakhalin fir and Sakhalin spruce) and broad-leaved trees (Japanese oak, birch and Painted maple). The seasonal views change throughout the year. In the south, the Yaeyama Islands are in the subtropics with numerous species of subtropical and tropical plants, and mangrove forests. Most natural islands have mountain ranges in the center with coastal plains.


The Places of Scenic Beauty and Natural Monuments are selected by the government via the Agency for Cultural Affairs in order to protect Japan's cultural heritage. As of November 17, 2017 there are 1,027 and 410 . The highest classification are 75 and 36 .

The is the canonical list of Japan's three most celebrated scenic sights, attributed to 1643 and scholar Hayashi Gahō. These are traditionally the pine-clad islands of Matsushima in Miyagi Prefecture, the pine-clad sandbar of Amanohashidate in Kyoto Prefecture, and Itsukushima Shrine in Hiroshima Prefecture. In 1915, the New Three Views of Japan were selected with a national election by the Jitsugyo no Nihon Sha (株式会社実業之日本社). In 2003, the Three Major Night Views of Japan were selected by the "New Three Major Night Views of Japan and the 100 Night Views of Japan Club" (新日本三大夜景・夜景100選事務局).

Most regions of Japan, such as much of Honshu, Shikoku and Kyushu, belong to the temperate zone with humid subtropical climate (Köppen climate classification "Cfa") characterized by four distinct seasons. However, its climate varies from cool humid continental climate (Köppen climate classification "Dfb") in the north such as northern Hokkaido, to warm tropical rainforest climate (Köppen climate classification "Af") in the south such as the Yaeyama Islands and Minami-Tori-shima.

Japan's varied geographical features divide it into six principal climatic zones.


As an island nation, Japan has the 6th longest coastline in the world. A few prefectures are landlocked: Gunma, Tochigi, Saitama, Nagano, Yamanashi, Gifu, Shiga, and Nara. As Mt. Fuji and the coastal Japanese Alps provide a rain shadow, Nagano and Yamanashi Prefectures receive the least precipitation in Honshu, though it still exceeds annually. A similar effect is found in Hokkaido, where Okhotsk Subprefecture receives as little as per year. All other prefectures have coasts on the Pacific Ocean, Sea of Japan, Seto Inland Sea or have a body of salt water connected to them. Two prefectures—Hokkaido and Okinawa—are composed entirely of islands.

Japan is generally a rainy country with high humidity. Because of its wide range of latitude, seasonal winds and different types of ocean currents, Japan has a variety of climates, with a latitude range of the inhabited islands from 24° to 46° north, which is comparable to the range between Nova Scotia and The Bahamas in the east coast of North America. Tokyo is at about 35 degrees north latitude, comparable to that of Tehran, Athens, or Las Vegas.

Regional climatic variations range from humid continental in the northern island of Hokkaido extending down through northern Japan to the Central Highland, then blending with and eventually changing to a humid subtropical climate on the Pacific Coast and ultimately reaching tropical rainforest climate on the Yaeyama Islands of the Ryukyu Islands. Climate also varies dramatically with altitude and with location on the Pacific Ocean or on the Sea of Japan.

Northern Japan has warm summers but long, cold winters with heavy snow. Central Japan in its elevated position, has hot summers and moderate to short winters with some areas having very heavy snow, and southwestern Japan has long hot summer and short mild winters. The generally temperate climate exhibits marked seasonal variation such as the blooming of the spring cherry blossoms, the calls of the summer cicada and fall foliage colors that are celebrated in art and literature.

The hottest temperature ever measured in Japan, , occurred in Kumagaya on 23 July 2018. and the coldest was recorded at Asahikawa, Hokkaidō on 25 January 1902.

The climate from June to September is marked by hot, wet weather brought by tropical airflows from the Pacific Ocean and Southeast Asia. These airflows are full of moisture and deposit substantial amounts of rain when they reach land. There is a marked rainy season, beginning in early June and continuing for about a month. It is followed by hot, sticky weather. Five or six typhoons pass over or near Japan every year from early August to early October, sometimes resulting in significant damage. Annual precipitation averages between except for the areas such as Kii Peninsula and Yakushima Island which is Japan's wettest place with the annual precipitation being one of the world's highest at 4,000 to 10,000 mm.

Maximum precipitation, like the rest of East Asia, occurs in the summer months except on the Sea of Japan coast where strong northerly winds produce a maximum in late autumn and early winter. Except for a few sheltered inland valleys during December and January, precipitation in Japan is above of rainfall equivalent in all months of the year, and in the wettest coastal areas it is above per month throughout the year.

Mid June to mid July is generally the rainy season in Honshu, Shikoku and Kyushu, excluding Hokkaidō since the seasonal rain front or dissipates in northern Honshu before reaching Hokkaido. In Okinawa, the rainy season starts early in May and continues until mid June. Unlike the rainy season in mainland Japan, it rains neither everyday nor all day long during the rainy season in Okinawa. Between July and October, typhoons, grown from tropical depressions generated near the equator, can attack Japan with furious rainstorms.

In winter, the Siberian High develops over the Eurasian land mass and the Aleutian Low develops over the northern Pacific Ocean. The result is a flow of cold air southeastward across Japan that brings freezing temperatures and heavy snowfalls to the central mountain ranges facing the Sea of Japan, but clear skies to areas fronting on the Pacific.

The warmest winter temperatures are found in the Nanpō and Bonin Islands, which enjoy a tropical climate due to the combination of latitude, distance from the Asian continent, and warming effect of winds from the Kuroshio, as well as the Volcano Islands (at the latitude of the southernmost of the Ryukyu Islands, 24° N). The coolest summer temperatures are found on the northeastern coast of Hokkaidō in Kushiro and Nemuro Subprefectures.

Sunshine, in accordance with Japan's uniformly heavy rainfall, is generally modest in quantity, though no part of Japan receives the consistently gloomy fogs that envelope the Sichuan Basin or Taipei. Amounts range from about six hours per day in the Inland Sea coast and sheltered parts of the Pacific Coast and Kantō Plain to four hours per day on the Sea of Japan coast of Hokkaidō. In December there is a very pronounced sunshine gradient between the Sea of Japan and Pacific coasts, as the former side can receive less than 30 hours and the Pacific side as much as 180 hours. In summer, however, sunshine hours are lowest on exposed parts of the Pacific coast where fogs from the Oyashio current create persistent cloud cover similar to that found on the Kuril Islands and Sakhalin.

The highest recorded temperature in Japan was 41.1 °C (106.0 °F) on 23 July 2018, an unverified record of 42.7 °C was taken in Adachi on 20 July 2004. The lowest was −41.0 °C (−41.8 °F) in Asahikawa on 25 January 1902. However an unofficial −41.5 °C was taken in Bifuka on 27 January 1931. Mount Fuji broke the Japanese record lows for each month except January, February, March, and December. Record lows for any month were taken as recent as 1984.

Minami-Tori-shima has a tropical savanna climate (Köppen climate classification "Aw") and the highest average temperature in Japan of 25 degrees Celsius.

Japan has a population of 126.3 million in 2019. It is the eleventh most populous country and second most populous island country in the world.

The terrain of Japan is mostly rugged and mountainous with 66% forest. This caused the population to be clustered in urban areas on the coast, plains and valleys. In 2010, 90.7% of the total Japanese population lived in cities. Japan is an urban society with about only 5% of the labor force working in agriculture. About 80 million of the urban population is heavily concentrated on the Pacific coast of Honshu.

81% of the population lives on Honshu, 10% on Kyushu, 4.2% on Hokkaido, 3% on Shikoku, 1.1% in Okinawa Prefecture and 0.7% on other Japanese islands such as the Nanpō Islands. Nearly 1 in 3 Japanese people live in the Greater Tokyo Area.

 is the largest island of Japan and the 2nd most populous island in the world. It has a population of 104,000,000 with a population density of (2010). Honshu is roughly long and ranges from wide, and the total area is . It is the 7th largest island in the world. This makes it slightly larger than the island of Great Britain .

The Greater Tokyo Area on Honshu is the biggest metropolitan area (megacity) in the world with people (2016). The area is and has a population density of .

 is the third largest island of Japan of the five main islands. , Kyushu has a population of 12,970,479 and covers . It has the second highest population density of (2016).

 is the second smallest of the five main islands (after Okinawa island), . It is located south of Honshu and north east of Kyushu. It has the second smallest population of 3,845,534 million (2015) and the third highest population density of .

 is the second largest island of Japan, and the largest and northernmost prefecture. The Tsugaru Strait separates Hokkaido from Honshu. It has the third largest population of the five main islands with 5,383,579 (2015) and the lowest population density with just (2016). The island area ranks 21st in the world by area. It is 3.6% smaller than the island of Ireland.

 is the southernmost prefecture of Japan. It encompasses two thirds of the Ryukyu Islands over long. It has a population of 1,445,812 (2017) and a density of . is the smallest and most southwestern of the five main islands, . It has the smallest population of 1,301,462 (2014) and the highest population density of .

 are the groups of islands that are located to the south and east of the main islands of the Japanese archipelago. They extend from the Izu Peninsula west of Tokyo Bay southward for about , to within of the Mariana Islands. The Nanpō Islands are all administered by Tokyo Metropolis. Approximately 0.7% of the Japanese population lives there.

The Taiheiyō Belt is a megalopolis that includes the Greater Tokyo Area and Keihanshin megapoles. It's almost long from Ibaraki Prefecture in the northeast to Fukuoka Prefecture in the southwest. Satellite images at night show a dense and continuous strip of light (demarcating urban zones) that delineates the region with overlapping metropolitan areas in Japan. It has a total population of approximately 81,859,345 (2016).

There are plans to build underwater habitats in Japan's Exclusive Economic Zone. Currently no underwater city is constructed yet. For example, the Ocean Spiral by Shimizu Corporation would have a floating dome 500 meters in diameter with hotels, residential and commercial complexes. It could be 15 km long. This allows mining of the seabed, research and production of methane from carbon dioxide with micro-organisms. The Ocean Spiral was co-developed with JAMSTEC and Tokyo University.

Japan extends from 20° to 45° north latitude (Okinotorishima to Benten-jima) and from 122° to 153° east longitude (Yonaguni to Minami Torishima). These are the points that are farther north, south, east or west than any other location in Japan.

The five main islands of Japan are Hokkaidō, Honshū, Kyūshū, Shikoku and Okinawa. These are also called the mainland. All of these points are accessible to the public.

These are the 50 largest islands of Japan. It excludes the disputed Kuril islands known as the northern territories.

Japan has a longstanding claim of the Southern Kuril Islands (Etorofu, Kunashiri, Shikotan, and the Habomai Islands). These islands were occupied by the Soviet Union in 1945. The Kuril Islands historically belong to Japan. The Kuril Islands were first inhabited by the Ainu people and then controlled by the Japanese Matsumae clan in the Edo Period. The Soviet Union did not sign the San Francisco Treaty in 1951. The U.S. Senate Resolution of April 28, 1952, ratifying of the San Francisco Treaty, explicitly stated that the USSR had no title to the Kurils, This dispute has prevented the signing of a peace treaty between Japan and Russia.

Geographically the Kuril Islands are a northeastern extension of Hokkaido. Kunashiri and the Habomai Islands are visible from the north-eastern coast of Hokkaido. Japan considers the Northern territories (aka Southern Chishima) part of Nemuro Subprefecture of Hokkaido Prefecture.

There is 1 time zone called Japan Standard Time (Nihon Hyōjunji) in the whole Japanese archipelago. It is 9 hours ahead of UTC. There is no daylight saving time. The easternmost Japanese island Minami-Tori-shima also uses Japan Standard Time while it is geographically southeast of Tokyo and in the time zone. 

Sakhalin uses even though it is located above Hokkaido. The Northern Territories and the Kuril islands use although they are geographically in .


Japan is substantially prone to earthquakes, tsunami and volcanoes due to its location along the Pacific Ring of Fire. It has the 15th highest natural disaster risk as measured in the 2013 World Risk Index.

As many as 1,500 earthquakes are recorded yearly, and magnitudes of 4 to 7 are common. Minor tremors occur almost daily in one part of the country or another, causing slight shaking of buildings. Major earthquakes occur infrequently; the most famous in the twentieth century was the great Kantō earthquake of 1923, in which 130,000 people died. Undersea earthquakes also expose the Japanese coastline to danger from .

Destructive earthquakes, often resulting in tsunami, occur several times each century. The 1923 Tokyo earthquake killed over 140,000 people. More recent major quakes are the 1995 Great Hanshin earthquake and the 2011 Tōhoku earthquake, a 9.1-magnitude quake which hit Japan on March 11, 2011. It triggered a large tsunami and the Fukushima Daiichi nuclear disaster, one of the worst disasters in the history of nuclear power.

The 2011 Tōhoku earthquake was the largest ever recorded in Japan and is the world's fourth largest earthquake to strike since 1900, according to the U.S. Geological Service. It struck offshore about northeast of Tokyo and east of the city of Sendai, and created a massive tsunami that devastated Japan's northeastern coastal areas. At least 100 aftershocks registering a 6.0 magnitude or higher have followed the main shock. At least 15,000 people died as a result.

Reclaimed land and man-made islands are particularly susceptible to liquefaction during an earthquake. As a result, there are specific earthquake resistance standards and ground reform work that applies to all construction in these areas. In an area that was possibly reclaimed in the past, old maps and land condition drawings are checked and drilling is carried out to determine the strength of the ground. However this can be very costly, so for a private residential block of land, a Swedish weight sounding test is more common.

Japan has become a world leader in research on causes and prediction of earthquakes. The development of advanced technology has permitted the construction of skyscrapers even in earthquake-prone areas. Extensive civil defence efforts focus on training in protection against earthquakes, in particular against accompanying fire, which represents the greatest danger.

Japan has 108 active volcanoes. That's 10% of all active volcanoes in the world. Japan has stratovolcanoes near the subduction zones of the tectonic plates. During the twentieth century several new volcanoes emerged, including Shōwa-shinzan on Hokkaido and Myōjin-shō off the Bayonnaise Rocks in the Pacific. In 1991, Japan's Unzen Volcano on Kyushu about east of Nagasaki, awakened from its 200-year slumber to produce a new lava dome at its summit. Beginning in June, repeated collapse of this erupting dome generated ash flows that swept down the mountain's slopes at speeds as high as . Unzen erupted in 1792 and killed more than 15,000 people. It is the worst volcanic disaster in the country's recorded history.

Mount Fuji is a dormant stratovolcano that last erupted on 16 December 1707 till about 1 January 1708. The Hōei eruption of Mount Fuji didn't have a lava flow, but it did release some of volcanic ash. It spread over vast areas around the volcano and reached Edo almost away. Cinders and ash fell like rain in Izu, Kai, Sagami, and Musashi provinces. In Edo, the volcanic ash was several centimeters thick. The eruption is rated a 5 on the Volcanic Explosivity Index.

During a volcanic eruption the volcano spews large quantities of hot ash. The volcanic ash consists of tiny fragments of volcanic glass, minerals and jagged rock. This ash is deadly for humans when inhaled in large quantities. The pyroclastic surge burns and asphyxiates any living beings and can reach temperatures of . The surface would be covered with several centimeters of thick ash. The clouds of ash and debris would block sunlight from reaching the surface. Roofs of buildings could collapse under the weight of the ash. If the ash mixes with rainfall then it could become dangerous mudflows. Wind and rain will gradually remove the ash from the surface.

There are three VEI-7 volcanoes in Japan. These are the Aira Caldera, Kikai Caldera and Aso Caldera. These giant caldera are remnants of past eruptions. Mount Aso is the largest active volcano in Japan. 300,000 to 90,000 years ago there were four eruptions of Mount Aso which emitted huge amounts of volcanic ash that covered all of Kyushu and up to Yamaguchi Prefecture.




Surveys by KOBEC (Kobe Ocean-Bottom Exploration Center) confirmed that a giant lava dome of 23 cubic kilometers formed after the Kikai Caldera erupted in 4,300 BC. There's a 1% chance of a giant caldera eruption in the Japanese archipelago within the next 100 years. Appropriately 40 cubic kilometers of magma would be released in one burst and cause enormous damage.

According to a 2014 study by KOBEC of Kobe University in a worst-case scenario if there is a VEI-7 eruption of the Aso Caldera and if the Volcanic ash is carried by westerly winds then pyroclastic flows of several would cover the 7 million population near the Aso Caldera within two hours. The pyroclastic flows could reach 2/3rd of Kyushu. Beyond the pyroclastic area is volcanic ash that falls from the sky. If the Volcanic ash continuously flows eastward, then the ash fall would make it impossible to live in most parts of Japan (the main islands) due to a paralysis of traffic and lifelines for a limited period until the eruption subsides. In this scenario, the exception would be eastern (and northern) Hokkaido (the Ryukyu Islands and southern Nanpo Islands would also be excepted). Professor Yoshiyuki Tatsumi, head of KOBEC told the Mainichi Shimbun “Although the probability of a gigantic caldera eruption hitting the Japanese archipelago is 1 percent in the next 100 years, it is estimated that the death toll could rise to approximately 100 million in the worst-case scenario”. The potential exists for tens of millions of humans and other living beings to die during a VEI-7 volcanic eruption with significant short-term effects on the global climate. If in another scenario, the wind blows in a different direction then the Volcanic ash could flow westward or southward and affect e.g. the East Asian continent or South-East Asia. Since the Kikai Caldera is submerged, it is unclear how much damage the hot ash clouds would cause if much volcanic ash stays below the ocean surface. The underwater ash would be swept away by ocean currents. However, every eruption is different based on various factors. So it is usually not a worst-case scenario.

Improving technology and methods to predict volcano and giant caldera eruptions would help to prepare and evacuate people earlier. Technology is needed to accurately capture the state of the magma chamber that spreads thinly with a thickness of less than several kilometers around the middle of the crust. The underground area of Kyushu must be monitored, because it is a dangerous area with a potential caldera eruption.

The most protective measure is to stop the hot ash clouds from spreading and devastating areas near the eruption so that people don't need to evacuate. This requires more advanced technology.

There are currently no protective measures to minimize the spread of millions of tons of deadly hot ash during a VEI-7 or VEI-8 eruption. For example, a dome structure could be built to contain the hot ash clouds from spreading. The dome would cover a volcano or caldera to contain the pyroclastic surge, pressure and withstand the temperatures of . Then other areas wouldn't be affected and sunlight wouldn't be blocked by debris and hot ash clouds. The flow of molten rock cannot be controlled.

In 2018 NASA published a theoretical plan to prevent a volcanic eruption by pumping large quantities of cold water down a borehole into the hydrothermal system of a supervolcano. The water would cool the huge body of magma in the chambers below the volcano so that the liquid magma becomes semi-solid. Thus enough heat could be extracted to prevent an eruption. The heat could be used by a geothermal plant to generate geothermal energy and electricity.

Another common hazard are several typhoons that reach Japan from the Pacific every year. Heavy snowfall during the winter in the snow country regions, cause landslides, flooding, and avalanches.

In the 2006 environment annual report, the Ministry of Environment reported that current major issues are: global warming and preservation of the ozone layer, conservation of the atmospheric environment, water and soil, waste management and recycling, measures for chemical substances, conservation of the natural environment and the participation in the international cooperation.

"Party to": Antarctic-Environmental Protocol, Antarctic Treaty, Biodiversity, Climate Change, Desertification, Endangered Species, Environmental Modification, Hazardous Wastes (Basel Convention), Law of the Sea, Marine Dumping, Ozone Layer Protection (Montreal Protocol), Ship Pollution (MARPOL 73/78), Tropical Timber 83, Tropical Timber 94, Wetlands (Ramsar Convention), Whaling <br>
"Signed and ratified": Climate Change-Kyoto Protocol





</doc>
<doc id="15576" url="https://en.wikipedia.org/wiki?curid=15576" title="Demographics of Japan">
Demographics of Japan

The demographic features of the population of Japan include population density, ethnicity, education level, health of the populace, economic status, religious affiliations and other aspects regarding the population.

For information on historical demographic data in Japan prior to 1945 refer to:

According to the World Bank, the population of Japan as of 2018 is at 126.5 million, including foreign residents. The population of only Japanese nationals was 124.8 million in January 2019.

Japan was the world's tenth-most populous country as of 2018. Total population had declined by 0.8 percent from the time of the census five years previously, the first time it had declined since the 1945 census.

Since 2010, Japan has experienced net population loss due to falling birth rates and minimal immigration, despite having one of the highest life expectancies in the world, at 85.00 years (it stood at 81.25 as of 2006). Using the annual estimate for October of each year, the population peaked in 2008 at 128,083,960 and had fallen 285,256 by October 2011.

Based on 2012 data from the National Institute of Population and Social Security Research, Japan's population will keep declining by about one million people every year in the coming decades, which would leave it with a population of around 70 million by 2060 and 42 million by early 22nd century if the current projections do not change. More than 40% of the population is expected to be over the age of 65 in 2060. In 2012 the population had for six consecutive years declined by 212,000, the largest drop on record since 1947 and also reflecting a record low of 1.03 million births. In 2014 a new record of population decrease - 268,000 people - occurred. more than 20 percent of the population of Japan were aged 65 and over.

The world population-ranking of Japan dropped from 7th to 8th in 1990, to 9th in 1998, and to 10th in the early 21st century. In 2015 it dropped further to 11th place, according both to the UN and to the PRB. Over the period of 2010 to 2015, the population shrank by almost a million.

Japan collects census information every five years. The exercise is conducted by the Statistics Bureau of the Ministry of Internal Affairs.

Japan's population density was 336 people per square kilometer as of 2014 (874 people per square mile) according to World Development Indicators. It ranks 35th in a list of countries by population density, ranking directly above Philippines (347 per km) and directly below Curacao (359 per km). Between 1955 and 1989, land prices in the six largest cities increased 15,000% (+12% a year). Urban land prices generally increased 40% from 1980 to 1987; in the six largest cities, the price of land doubled over that period. For many families, this trend put housing in central cities out of reach.
The result was lengthy commutes for many workers in the big cities, especially in Tokyo area where daily commutes of two hours each way are common. In 1991, as the bubble economy started to collapse, land prices began a steep decline, and within a few years fell 60% below their peak. After a decade of declining land prices, residents began moving back into central city areas (especially Tokyo's 23 wards), as evidenced by 2005 census figures. Despite nearly 70% of Japan being covered by forests, parks in many major cities—especially Tokyo and Osaka—are smaller and scarcer than in major West European or North American cities. As of 2014, parkland per inhabitant in Tokyo is 5.78 square meters, which is roughly half of the 11.5 square meters of Madrid.

National and regional governments devote resources to making regional cities and rural areas more attractive by developing transportation networks, social services, industry, and educational institutions in attempts to decentralize settlement and improve the quality of life. Nevertheless, major cities, especially Tokyo, Yokohama, and Fukuoka, and to a lesser extent Kyoto, Osaka and Nagoya, remain attractive to young people seeking education and jobs.

Japan has a high population concentration in urban areas on the plains since 75% of Japan’s land area is made up of mountains, and also Japan has a forest cover rate of 68.5% (the only other developed countries with such a high forest cover percentage are Finland and Sweden).
The 2010 census shows 90.7% of the total Japanese population live in cities.

Japan is an urban society with about only 5% of the labor force working in agriculture. Many farmers supplement their income with part-time jobs in nearby towns and cities. About 80 million of the urban population is heavily concentrated on the Pacific shore of Honshu.

Metropolitan Tokyo-Yokohama, with its population of 35 million residents, is the world's most populous city. Japan faces the same problems that confront urban industrialized societies throughout the world: overcrowded cities and congested highways.

Japan's population is aging faster than that of any other nation. The population of those 65 years or older roughly doubled in 24 years, from 7.1% of the population in 1970 to 14.1% in 1994. The same increase took 61 years in Italy, 85 years in Sweden, and 115 years in France. In 2014, 26% of Japan's population was estimated to be 65 years or older, and the Health and Welfare Ministry has estimated that over-65s will account for 40% of the population by 2060. The demographic shift in Japan's age profile has triggered concerns about the nation's economic future and the viability of its welfare state.

The population consisted of 47,062,743 households, with 78.7% in urban areas (July 2000). High population density; 329.5 people per square kilometer for total area; 1,523 persons per square kilometer for habitable land. More than 50% of the population lives on 2% of the land. (July 1993). According to research in 2018, the population to land density ratio has gradually increased, now at 127 million per 337 km2. Compared to the findings of July 1993 as well as in July 2000, the population density has greatly increased, from 50% of the population living on 2% of the land to 77%. However, as the years have progressed since the last recordings of the population, Japan’s population has decreased, raising concern about the future of Japan. There are many causes, such as the declining birthrates, as well as the ratio of men to women since the last measurements from the years of 2006 and 2010. According to the Japanese Health Ministry, the population is estimated to drop from its current state of 126.26 million to 86.74 million by the year 2060.

Adult prevalence rate

People living with HIV/AIDS

Deaths

Naturalized Japanese citizens and native-born Japanese nationals with multi-ethnic background are all considered to be Japanese in the population census of Japan.

Live births, birth and death rates and overall fertility rate in Japan from 1899 to present.
Japan's total fertility rate (TFR) in 2012 was estimated at 1.41 children per woman, increasing slightly from 1.32 in the 2001–05 period. In 2012, the highest TFR was 1.90, in Okinawa, and the lowest was 1.09, in Tokyo. TFR by prefecture for 2000–05, as well as future estimates, have been released.

Sources: Our World In Data and the United Nations.

1865-1949

1950-2015

Source: "UN World Population Prospects"


Between 6 million and 7 million people moved their residences each year during the 1980s. About 50% of these moves were within the same prefecture; the others were relocations from one prefecture to another. During Japan's economic development in the twentieth century, and especially during the 1950s and 1960s, migration was characterized by urbanization as people from rural areas in increasing numbers moved to the larger metropolitan areas in search of better jobs and education. Out-migration from rural prefectures continued in the late 1980s, but more slowly than in previous decades.

In the 1980s, government policy provided support for new urban development away from the large cities, particularly Tokyo, and assisted regional cities to attract young people to live and work there. Regional cities offered familiarity to those from nearby areas, lower costs of living, shorter commutes, and, in general, a more relaxed lifestyle than could be had in larger cities. Young people continued to move to large cities, however, to attend universities and find work, but some returned to regional cities (a pattern known as U-turn) or to their prefecture of origin (a pattern referred to as "J-turn").

Government statistics show that in the 1980s significant numbers of people left the largest central cities (Tokyo and Osaka) to move to suburbs within their metropolitan areas. In 1988 more than 500,000 people left Tokyo, which experienced a net loss through migration of nearly 73,000 for the year. Osaka had a net loss of nearly 36,000 in the same year.

With a decreasing total population, internal migration results in only 8 prefectures showing an increase in population. These are Okinawa(2.9%), Tokyo(2.7%), Aichi(1.0%), Saitama(1.0%), Kanagawa(0.9%), Fukuoka(0.6%), Shiga(0.2%), and Chiba(0.1%).

About 663,300 Japanese were living abroad, approximately 75,000 of whom had permanent foreign residency, more than six times the number who had that status in 1975. More than 200,000 Japanese went abroad in 1990 for extended periods of study, research, or business assignments. As the government and private corporations have stressed internationalization, greater numbers of individuals have been directly affected, decreasing Japan's historical insularity. By the late 1980s, these problems, particularly the bullying of returnee children in schools, had become a major public issue both in Japan and in Japanese communities abroad.

Cities with significant populations of Japanese nationals

Note: The above data shows the number of Japanese nationals living overseas. It was published by the Ministry of Foreign Affairs of Japan and relates to 2015.

According to the Japanese immigration centre, the number of foreign residents in Japan has steadily increased, and the number of foreign residents (excluding a small number of illegal immigrants and short-term visitors, such as foreign nationals staying less than 90 days in Japan), exceeded 2.2 million people in 2008.

In 2010, the number of foreigners in Japan was 2,134,151. This includes 209,373 Filipinos, many of whom are married to Japanese nationals, 210,032 Brazilians, the majority possessing some degree of Japanese ancestry, 687,156 Chinese and 565,989 Koreans. Chinese, Filipinos, Koreans, and Brazilians account for about 69.5% of foreign residents in Japan. In 2019 the number of foreigners in Japan was 2,382,822

The current issue of the shrinking workforce in Japan alongside its aging population has resulted in a recent need to attract foreign labour to the country. Reforms which took effect in 2015 relax visa requirements for "Highly Skilled Foreign Professionals" and create a new type of residence status with an unlimited period of stay.

The number of naturalizations peaked in 2008 at 16,000, declining to over 9,000 in the most recent year for which data are available. Most of the decline is accounted for by a steep reduction in the number of Japan-born Koreans taking Japanese citizenship. Historically the bulk of those taking Japanese citizenship have not been foreign-born immigrants but rather Japanese-born descendants of Koreans and Taiwanese who lost their citizenship in the Japanese Empire in 1947 as part of the American Occupation policy for Japan.

Japanese statistical authorities do not collect information on ethnicity, only nationality. As a result, both native and naturalized Japanese citizens are counted in a single group. Japanese society is linguistically, ethnically and culturally homogeneous. It is composed of 98.1% ethnic Japanese. Although official statistics show near homogeneity, one analysis describe the population as “multi-ethnic”, although unofficial statistics still show that ethnic minorities are small compared with many other countries. There is an increase of foreign residents, but they are not Japanese nationals and most temporarily live in Japan for a few months or years.

In 2015 the Japanese government under prime minister Shinzō Abe announced that its policy of restricting immigration would not change despite the current declining population. In the long term, its plan is to improve technology to address the labour shortage, while increasing Japanese fertility rates from the current level of 1.4 to 1.8, eventually stabilizing the population at approximately 100 million.

The Japanese society of Yamato people is linguistically homogeneous with small populations of Koreans (0.9 million), Chinese/Taiwanese (0.65 million), Filipino (306,000 some being Japanese Filipino; children of Japanese and Filipino parentage). Brazilians (300,000, many of whom are ethnically Japanese) as well as Peruvians and Argentineans of both Latin American and Japanese descent. Japan has indigenous minority groups such as the Ainu and Ryukyuans, who generally speak Japanese.

Japanese citizenship is conferred "jus sanguinis", and monolingual Japanese-speaking minorities often reside in Japan for generations under permanent residency status without acquiring citizenship in their country of birth, although legally they are allowed to do so. This is because Japanese law does not recognise dual citizenship after the age of adulthood, and so people becoming naturalised Japanese citizens must relinquish citizenship of other countries when they reach the age of 20. Some ethnic Koreans and Chinese and their descendants (who may speak only Japanese and may never have even visited the country whose nationality they hold) do not wish to abandon this other citizenship.

In addition, people taking Japanese citizenship must take a name using the Japanese character sets hiragana, katakana, and/or kanji. Names using Western alphabet, Korean alphabet, Arabic characters, etc. are not acceptable as legal names. Chinese characters are usually legally acceptable as nearly all Chinese characters are recognized as valid by the Japanese government. Transliterations of non-Japanese names using katakana (e.g. 　"" for "Smith") are also legally acceptable.

However, some naturalizing foreigners feel that becoming a Japanese citizen should mean that they have a Japanese name and that they should abandon their foreign name, and some foreign residents do not wish to do this—although most Special Permanent Resident Koreans and Chinese already use Japanese names. Nonetheless, some 10,000 Zainichi Koreans naturalize every year. Approximately 98.6% of the population are Japanese citizens, and 99% of the population speak Japanese as their first language. Non-ethnic Japanese in the past, and to an extent in the present, also live in small numbers in the Japanese archipelago.

Japanese people enjoy a high standard of living, and nearly 90% of the population consider themselves part of the middle class. However, many studies on happiness and satisfaction with life tend to find that Japanese people average relatively low levels of life satisfaction and happiness when compared with most of the highly developed world; the levels have remained consistent if not declining slightly over the last half century. Japanese have been surveyed to be relatively lacking in financial satisfaction.

The suicide rates per 100,000 in Japan in 2009 were 29.2 for men and 10.5 for women. In 2010, 32,000 Japanese committed suicide, which translates to an average of 88 Japanese suicides a day in 2010.

Three native Japanese minority groups can be identified. The largest are the "hisabetsu buraku" or "discriminated communities", also known as the "burakumin". These descendants of premodern outcast hereditary occupational groups, such as butchers, leatherworkers, funeral directors, and certain entertainers, may be considered a Japanese analog of India's Dalits. Discrimination against these occupational groups arose historically because of Buddhist prohibitions against killing and Shinto notions of pollution, as well as governmental attempts at social control.

During the Edo period, such people were required to live in special "buraku" and, like the rest of the population, were bound by sumptuary laws based on the inheritance of social class. The Meiji government abolished most derogatory names applied to these discriminated communities in 1871, but the new laws had little effect on the social discrimination faced by the former outcasts and their descendants. The laws, however, did eliminate the economic monopoly they had over certain occupations. The "buraku" continued to be treated as social outcasts and some casual interactions with the majority caste were perceived taboo until the era after World War II.

Estimates of their number range from 2 to 4 million (about 2% to 3% of the national population). Although members of these discriminated communities are physically indistinguishable from other Japanese, they often live in urban ghettoes or in the traditional special hamlets in rural areas, and membership can be surmised from the location of the family home, occupation, dialect, or mannerisms. Checks on family background designed to ferret out "buraku" were commonly performed as part of marriage arrangements and employment applications, but have been illegal since 1985 in Osaka.

Past and current discrimination has resulted in lower educational attainment and socioeconomic status among "hisabetsu buraku" than among the majority of Japanese. Movements with objectives ranging from "liberation" to encouraging integration have tried to change this situation, with some success. Nadamoto Masahisa of the Buraku History Institute estimates that as of 1998, between 60 and 80% of burakumin marry a non-burakumin.

One of the largest minority groups among Japanese citizens is the Ryukyuan people. They are primarily distinguished from their use of several distinct Ryukyuan languages though use of Ryukyuan is dying out. The Ryukyuan people and language originated in the Ryukyu Islands, which are in Okinawa prefecture.

The third largest minority group among Japanese citizens is the Ainu, whose language is an isolate. Historically, the Ainu were an indigenous hunting and gathering population who occupied most of northern Honshū as late as the Nara period (A.D. 710–94). As Japanese settlement expanded, the Ainu were pushed northward, by the Tokugawa shogunate, the Ainu were pushed into the island of Hokkaido.

Characterized as remnants of a primitive circumpolar culture, the fewer than 20,000 Ainu in 1990 were considered racially distinct and thus not fully Japanese. Disease and a low birth rate had severely diminished their numbers over the past two centuries, and intermarriage had brought about an almost completely mixed population.

Although no longer in daily use, the Ainu language is preserved in epics, songs, and stories transmitted orally over succeeding generations. Distinctive rhythmic music and dances and some Ainu festivals and crafts are preserved, but mainly in order to take advantage of tourism.

Hāfu is a term used for people who are biracial and ethnically half Japanese. Of the 1 million children born in Japan in 2013, 2.2% had one or more non-Japanese parent. According to the Japanese Ministry of Health, Labor and Welfare, one in forty-nine babies born in Japan today are born into families with one non-Japanese parent. Most intermarriages in Japan are between Japanese men and women from other Asian countries, including China, the Philippines and South Korea. Southeast Asia too, also has significant populations of people with half-Japanese ancestry, particularly in the Philippines, Indonesia, Malaysia, Singapore and Thailand.
In the 1940s, biracial Japanese children (Ainoko), specifically Amerasian children, encountered social problems such as poverty, perception of impurity and discrimination due to negative treatment in Japan. In the 21st century, discrimination against hāfu occurs based on how different their identity, behavior and appearance is from a typical Japanese person.

In 2005, there were 1,555,505 foreign residents in Japan, representing 1.22% of the Japanese population. Foreign Army personnel, of which there were up to 430,000 from the SCAP (post-occupation, United States Forces Japan) and 40,000 BCOF in the immediate post-war years, have not been at any time included in Japanese foreign resident statistics. Most foreign residents in Japan come from Brazil or from other Asian countries, particularly from China, South Korea, the Philippines, Vietnam and Nepal.

A number of long-term resident Koreans in Japan today retain familial links with the descendants of Koreans, that either immigrated voluntarily or were forcibly relocated during the Japanese Occupation of the Korea. Within this group, a number hold Special Permanent Resident status, granted under the terms of the Normalisation Treaty (22. June 1965) between South Korea and Japan. In many cases special residents, despite being born in Japan and speaking Japanese, have chosen not to take advantage of the mostly automatic granting of citizenship to special resident applicants.

Beginning in 1947 the Japanese government started to repatriate Korean nationals, who had nominally been granted Japanese citizenship during the years of military occupation. When the Treaty of San Francisco came into force many ethnic Koreans lost their Japanese citizenship from April 28, 1952 and with it the right to welfare grants, to hold a government job of any kind or to attend Japanese schools. In the following year the government contrived, with the help of the Red Cross, a scheme to "repatriate" Korean residents, who mainly were from the Southern Provinces, to their "home" of North Korea. Between 1959 and 1984 93,430 people used this route. 6,737 were Japanese or Chinese dependents. Most of these departures – 78,276 – occurred before 1962.

All non-Japanese without special residential status (people whose residential roots go back to before WWII) are required by law to register with the government and carry alien registration cards. From the early 1980s, a civil disobedience movement encouraged refusal of the fingerprinting that accompanied registration every five years.

Opponents of fingerprinting argued that it was discriminatory because the only Japanese who were fingerprinted were criminals. The courts upheld fingerprinting, but the law was changed so that fingerprinting was done once rather than with each renewal of the registration, which until a law reform in 1989 was usually required every six months for anybody from the age of 16. Those refusing fingerprinting were denied re-entry permits, thus depriving them of freedom of movement.

Of these foreign residents below, the new wave started 2014 comes to Japan as students or trainees. These foreigners are registered under student visa or trainee visa which gives them the student residency status, Most of these new foreigners are under this visa. Almost all of these foreign students and trainees will return to their home country after 3–4 years (one valid period), few students extend their visa. Vietnamese makes the largest increase, however Burmese, Cambodians, Filipinos and Chinese are also increasing.

Asian migrant wives of Japanese men have also contributed to the foreign-born population in the country. Many young single Japanese male farmers choose foreign wives, mainly from the Philippines, Sri Lanka, Thailand, China and South Korea, due to a lack of interest from Japanese women living a farming life. Migrant wives often travel as mail-order brides as a result of arranged marriages with Japanese men. Additionally, Japanese men in urban parts of the country have also begun marrying foreign Asian women.

There was an increase of 110,358 foreign residents from 2014 to 2015. Vietnamese made the largest proportion of these new foreign residents, whilst Nepalese, Filipino, Chinese and Taiwanese are also significant in numbers. Together these countries makes up 91,126 or 82.6% of all new residents from 2014 to 2015. However, the majority of these immigrants will only remain in Japan for a maximum of five years, as many of them have entered the country in order to complete trainee programmes. Once they complete their programmes, they will be required to return to their home countries.

As of December 2014 there were 2,121,831 foreigners residing in Japan, 677,019 of whom were long-term residents in Japan, according to national demographics figures. The majority of long-term residents were from Asia, totalling 478,953. Chinese made up the largest portion of them with 215,155, followed by Filipinos with 115,857, and Koreans with 65,711. Thai, Vietnamese, and Taiwanese long-term residents totaled 47,956, and those from other Asian countries totaled 34,274. The Korean figures do not include zainichi Koreans with "tokubetsu eijusha" ("special permanent resident") visas, of whom there were 354,503 (of a total of 358,409 of all nationalities with such visas). The total number of permanent residents had declined over the previous 5 years due to high cost of living.

In 2018, the number of resident foreigners was 2.22 million in Japan. This is an all-time high and 1.76% of the population. In 2018, net immigration rose for the sixth straight year with 165,000. More than half of all resident foreigners (1.15 million) are in their 20s and 30s. The number of foreign workers was 1.46 million in 2018, 29.7% are in the manufacturing sector. 389,000 are from Vietnam and 316,000 are from China.

On April 1, 2019, Japan's revised immigration law was enacted. The revision clarifies and better protects the rights of foreign workers. Japan formally accepts foreign blue-collar workers. This helps reduce labour shortage in certain sectors of the economy. The reform changes the status of foreign workers to regular employees and they can obtain permanent residence status. The reform includes a new visa status called . In order to qualify, applicants must pass a language and skills test (level N4 or higher of the Japanese-Language Proficiency Test). In the old "Technical Trainee programme" a foreign employee was tied to their employer. This caused numerous cases of exploitation. The revision gives foreign workers more freedom to leave and change their employer.

A significant number of foreign residents of Japan are employed on a short term contractual basis under programs administered by the Japanese government. Well known programs include:


In the light of current demographic trends Japan is likely to experience a decrease in tax revenue without a corresponding decrease in welfare expenses for an increasingly elderly population. Given growing manpower shortages, immigrant workers continue to play an important role taking low skilled and manual labour jobs. A recent growth in blue collar employment using documented short term contractual labour from developing countries has also contributed to the rise in the resident foreign population. The government administered Technical Intern Training Program, first established in 1993, provided over 190,000 short term contracted workers in 2015. However, it has been claimed that many of these workers often work at reduced pay and are required to undertake significant amounts of overtime in order to make up for labor shortages. As trainees, labor standards law and minimum wage legislation has on occasion been ignored by unscrupulous employers. The Japanese government has begun to examine this problem and has sought to both strengthen the vocational training aspect of the work program oversight.

Foreign residents were recorded only in an alien registration system separate from the "koseki" (family registry) and "jūminhyō" (resident registry) systems in which Japanese citizens were registered until a new registration system was enacted in July 2012. Since then, all residents are recorded by municipal offices in the "jūminhyō" system. The "koseki" system continues for Japanese citizens, while foreigners are recorded in a separate residency management system administered by immigration offices which combines the previous immigration status and local alien registration systems.

The Japanese Ministry of Justice maintains a website and hotline for "receiving report on illegal stay foreigner." The criteria for reporting include "feeling anxious about a foreigner", and anonymous submissions are permitted. Japanese immigration authorities work in unison with police to investigate those reported, and human rights groups such as Amnesty International have argued that those reported do not receive proper legal protection.

The Daiyo Kangoku system allows police to detain suspects without charges, access to legal counsel or telephone calls for up to 23 days. In October 2006, the foreigner reporting hotline's operating hours were extended to include Saturday, Sunday and national holidays.

As of November 20, 2007, all foreigners entering Japan must be biometrically registered (photograph and fingerprints) on arrival; this includes people living in Japan on visas as well as permanent residents, but excludes people with special permanent resident permission, diplomats, and those under 16.

Shinto and Buddhism are Japan's two major religions. They have co-existed for more than a thousand years. However, most Japanese people generally do not exclusively identify themselves as adherents of one religion, but rather incorporate various elements in a syncretic fashion. There are small Christian and other minorities as well, with the Christian population dating to as early as the 1500s, as a result of European missionary work before sakoku was implemented from 1635–1853.





</doc>
<doc id="15577" url="https://en.wikipedia.org/wiki?curid=15577" title="Politics of Japan">
Politics of Japan

The politics of Japan are conducted in a framework of a multi-party bicameral parliamentary representative democratic constitutional monarchy whereby the Emperor is the ceremonial head of state and the Prime Minister is the head of government and the head of the Cabinet, which directs the executive branch.

Legislative power is vested in the National Diet, which consists of the House of Representatives and the House of Councillors. Judicial power is vested in the Supreme Court and lower courts, and sovereignty is vested in the Japanese people by the Constitution. Japan is considered a constitutional monarchy with a system of civil law.

The Constitution of Japan defines the Emperor to be "the symbol of the State and of the unity of the people". He performs ceremonial duties and holds no real power. Political power is held mainly by the Prime Minister and other elected members of the Diet. The Imperial Throne is succeeded by a member of the Imperial House as designated by the Imperial Household Law.

The chief of the executive branch, the Prime Minister, is appointed by the Emperor as directed by the Diet. He is a member of either house of the Diet and must be a civilian. The Cabinet members are nominated by the Prime Minister, and are also required to be civilian. With the Liberal Democratic Party (LDP) in power, it has been convention that the President of the party serves as the Prime Minister.

Several political parties exist in Japan. However, the politics of Japan have primarily been dominated by the LDP since 1955, with the DPJ playing an important role as opposition several times. LDP was a ruling party during decades since 1955. Despite the existence of multiple parties, other parties were completely ignored. Most of the prime ministers were elected from inner factions of the LDP. 

Despite an increasingly unpredictable domestic and international environment, policy making conforms to well established postwar patterns. The close collaboration of the ruling party, the elite bureaucracy and important interest groups often make it difficult to tell who exactly is responsible for specific policy decisions.

After a largely informal process within elite circles in which ideas were discussed and developed, steps might be taken to institute more formal policy development. This process often took place in deliberation councils ("shingikai"). There were about 200 "shingikai", each attached to a ministry; their members were both officials and prominent private individuals in business, education, and other fields. The "shingikai" played a large role in facilitating communication among those who ordinarily might not meet.

Given the tendency for real negotiations in Japan to be conducted privately (in the "nemawashi", or root binding, process of consensus building), the "shingikai" often represented a fairly advanced stage in policy formulation in which relatively minor differences could be thrashed out and the resulting decisions couched in language acceptable to all. These bodies were legally established but had no authority to oblige governments to adopt their recommendations. The most important deliberation council during the 1980s was the Provisional Commission for Administrative Reform, established in March 1981 by Prime Minister Suzuki Zenko. The commission had nine members, assisted in their deliberations by six advisers, twenty-one "expert members," and around fifty "councillors" representing a wide range of groups. Its head, Keidanren president Doko Toshio, insisted that government agree to take its recommendations seriously and commit itself to reforming the administrative structure and the tax system.

In 1982, the commission had arrived at several recommendations that by the end of the decade had been actualized. These implementations included tax reform, a policy to limit government growth, the establishment in 1984 of the Management and Coordination Agency to replace the Administrative Management Agency in the Office of the Prime Minister, and privatization of the state-owned railroad and telephone systems. In April 1990, another deliberation council, the Election Systems Research Council, submitted proposals that included the establishment of single-seat constituencies in place of the multiple-seat system.

Another significant policy-making institution in the early 1990s were the Liberal Democratic Party's Policy Research Council. It consisted of a number of committees, composed of LDP Diet members, with the committees corresponding to the different executive agencies. Committee members worked closely with their official counterparts, advancing the requests of their constituents, in one of the most effective means through which interest groups could state their case to the bureaucracy through the channel of the ruling party. 
"See also:" Industrial policy of Japan; Monetary and fiscal policy of Japan; Mass media and politics in Japan

Political parties had begun to revive almost immediately after the occupation began. Left-wing organizations, such as the Japan Socialist Party and the Japanese Communist Party, quickly reestablished themselves, as did various conservative parties. The old Rikken Seiyūkai and Rikken Minseitō came back as, respectively, the Liberal Party (Nihon Jiyūtō) and the Japan Progressive Party (Nihon Shimpotō). The first postwar elections were held in 1948 (women were given the franchise for the first time in 1947), and the Liberal Party's vice president, Yoshida Shigeru (1878–1967), became prime minister.

For the 1947 elections, anti-Yoshida forces left the Liberal Party and joined forces with the Progressive Party to establish the new Democratic Party (Minshutō). This divisiveness in conservative ranks gave a plurality to the Japan Socialist Party, which was allowed to form a cabinet, which lasted less than a year. Thereafter, the socialist party steadily declined in its electoral successes. After a short period of Democratic Party administration, Yoshida returned in late 1948 and continued to serve as prime minister until 1954.

Even before Japan regained full sovereignty, the government had rehabilitated nearly 80,000 people who had been purged, many of whom returned to their former political and government positions. A debate over limitations on military spending and the sovereignty of the Emperor ensued, contributing to the great reduction in the Liberal Party's majority in the first post-occupation elections (October 1952). After several reorganizations of the armed forces, in 1954 the Japan Self-Defense Forces were established under a civilian director. Cold War realities and the hot war in nearby Korea also contributed significantly to the United States-influenced economic redevelopment, the suppression of communism, and the discouragement of organized labor in Japan during this period.

Continual fragmentation of parties and a succession of minority governments led conservative forces to merge the Liberal Party (Jiyūtō) with the Japan Democratic Party (Nihon Minshutō), an offshoot of the earlier Democratic Party, to form the Liberal Democratic Party (Jiyū-Minshutō; LDP) in November 1955, called 1955 System. This party continuously held power from 1955 through 1993, except for short when it was replaced by a new minority government. LDP leadership was drawn from the elite who had seen Japan through the defeat and occupation. It attracted former bureaucrats, local politicians, businessmen, journalists, other professionals, farmers, and university graduates.

In October 1955, socialist groups reunited under the Japan Socialist Party, which emerged as the second most powerful political force. It was followed closely in popularity by the Kōmeitō, founded in 1964 as the political arm of the Soka Gakkai (Value Creation Society), until 1991, a lay organization affiliated with the Nichiren Shoshu Buddhist sect. The Komeito emphasized the traditional Japanese beliefs and attracted urban laborers, former rural residents, and women. Like the Japan Socialist Party, it favored the gradual modification and dissolution of the Japan-United States Mutual Security Assistance Pact.

The LDP domination lasted until the Diet Lower House elections on 18 July 1993, in which LDP failed to win a majority. A coalition of new parties and existing opposition parties formed a governing majority and elected a new prime minister, Morihiro Hosokawa, in August 1993. His government's major legislative objective was political reform, consisting of a package of new political financing restrictions and major changes in the electoral system. The coalition succeeded in passing landmark political reform legislation in January 1994.

In April 1994, Prime Minister Hosokawa resigned. Prime Minister Tsutomu Hata formed the successor coalition government, Japan's first minority government in almost 40 years. Prime Minister Hata resigned less than two months later. Prime Minister Tomiichi Murayama formed the next government in June 1994 with the coalition of Japan Socialist Party (JSP), the LDP, and the small New Party Sakigake. The advent of a coalition containing the JSP and LDP shocked many observers because of their previously fierce rivalry.

Prime Minister Murayama served from June 1994 to January 1996. He was succeeded by Prime Minister Ryutaro Hashimoto, who served from January 1996 to July 1998. Prime Minister Hashimoto headed a loose coalition of three parties until the July 1998 Upper House election, when the two smaller parties cut ties with the LDP. Hashimoto resigned due to a poor electoral performance by the LDP in the Upper House elections. He was succeeded as party president of the LDP and prime minister by Keizo Obuchi, who took office on 30 July 1998. The LDP formed a governing coalition with the Liberal Party in January 1999, and Keizo Obuchi remained prime minister. The LDP-Liberal coalition expanded to include the New Komeito Party in October 1999.

Prime Minister Obuchi suffered a stroke in April 2000 and was replaced by Yoshirō Mori. After the Liberal Party left the coalition in April 2000, Prime Minister Mori welcomed a Liberal Party splinter group, the New Conservative Party, into the ruling coalition. The three-party coalition made up of the LDP, New Komeito, and the New Conservative Party maintained its majority in the Diet following the June 2000 Lower House elections.

After a turbulent year in office in which he saw his approval ratings plummet to the single digits, Prime Minister Mori agreed to hold early elections for the LDP presidency in order to improve his party's chances in crucial July 2001 Upper House elections. On 24 April 2001, riding a wave of grassroots desire for change, maverick politician Junichiro Koizumi defeated former Prime Minister Hashimoto and other party stalwarts on a platform of economic and political reform.

Koizumi was elected as Japan's 56th Prime Minister on 26 April 2001. On 11 October 2003, Prime Minister Koizumi dissolved the lower house and he was re-elected as the president of the LDP. Likewise, that year, the LDP won the election, even though it suffered setbacks from the new opposition party, the liberal and social-democratic Democratic Party (DPJ). A similar event occurred during the 2004 Upper House elections as well.

In a strong move, on 8 August 2005, Prime Minister Junichiro Koizumi called for a snap election to the lower house, as threatened, after LDP stalwarts and opposition DPJ parliamentarians defeated his proposal for a large-scale reform and privatization of Japan Post, which besides being Japan's state-owned postal monopoly is arguably the world's largest financial institution, with nearly 331 trillion yen of assets. The election was scheduled for 11 September 2005, with the LDP achieving a landslide victory under Junichiro Koizumi's leadership.

The ruling LDP started losing hold since 2006. No prime minister except Koizumi had good public support. On 26 September 2006, new LDP President Shinzō Abe was elected by a special session of the Diet to succeed Junichiro Koizumi as Prime Minister. He was the Japan's youngest post-World War II prime minister and the first born after the war. On 12 September 2007, Abe surprised Japan by announcing his resignation from office. He was replaced by Yasuo Fukuda, a veteran of LDP.

In the meantime, on 4 November 2007, leader of the main opposition party, Ichirō Ozawa announced his resignation from the post of party president, after controversy over an offer to the DPJ to join the ruling coalition in a grand coalition, but has since, with some embarrassment, rescinded his resignation.

On 11 January 2008, Prime Minister Yasuo Fukuda forced a bill allowing ships to continue a refueling mission in the Indian Ocean in support of US-led operations in Afghanistan. To do so, PM Fukuda used the LDP's overwhelming majority in the Lower House to ignore a previous "no-vote" of the opposition-controlled Upper House. This was the first time in 50 years that the Lower House voted to ignore the opinion of the Upper House. Fukuda resigned suddenly on 1 September 2008, just a few weeks after reshuffling his cabinet. On 1 September 2008, Fukuda's resignation was designed so that the LDP did not suffer a "power vacuum". It thus caused a leadership election within the LDP, and the winner, Tarō Asō was chosen as the new party president and on 24 September 2008, he was appointed as 92nd Prime Minister after the House of Representatives voted in his favor in the extraordinary session of Diet.

Later, on 21 July 2009, Prime Minister Asō dissolved the House of Representatives and elections were held on 30 August.
The election results for the House of Representatives were announced on 30 and 31 August 2009. The opposition party DPJ led by Yukio Hatoyama, won a majority by gaining 308 seats (10 seats were won by its allies the Social Democratic Party and the People's New Party). On 16 September 2009, president of DPJ, Hatoyama was elected by the House of Representatives as the 93rd Prime Minister of Japan.

On 2 June 2010, Hatoyama resigned due to lack of fulfillments of his policies, both domestically and internationally and soon after, on 8 June, Akihito, Emperor of Japan ceremonially swore in the newly elected DPJ's president, Naoto Kan as prime minister. Kan suffered an early setback in the 2010 Japanese House of Councillors election. In a routine political change in Japan, DPJ’s new president and former finance minister of Naoto Kan’s cabinet, Yoshihiko Noda was cleared and elected by the Diet as 95th prime minister on 30 August 2011. He was officially appointed as prime minister in the attestation ceremony at imperial palace on 2 September 2011.

In an undesired move, Noda dissolved the lower house on 16 November 2012 (as he fails to get support outside the Diet on various domestic issues i.e. tax, nuclear energy) and elections were held on 16 December. The results were in the favor of LDP, which won absolute majority in the leadership of former Prime Minister Shinzō Abe. He was appointed as the 96th Prime Minister of Japan on 26 December 2012. With the changing political situation, earlier in November 2014, Prime Minister Abe called for fresh mandate for the Lower House. In an opinion poll the government failed to win the public trust due to bad economic achievements in the two consecutive quarters and on the tax reforms.

The election was held on 14 December 2014, and the results were in the favor of LDP and its ally New Komeito. Together they managed to secure a huge majority by winning 325 seats for the Lower House. The opposition, DPJ, could not manage to provide the alternatives to the voters with its policies and programs. "Abenomics", the ambitious self-titled fiscal policy of the current prime minister, managed to attract more voters in this election, many Japanese voters supported the policies. Shinzō Abe was sworn as the 97th prime minister on 24 December 2014 and would like go ahead with his agenda of economic revitalization and structural reforms in Japan.

Japan is a member state of the United Nations and pursues a permanent membership of the Security Council - Japan is one of the "G4 nations" seeking permanent membership. Japan plays an important role in East Asia. The Japanese Constitution prohibits the use of military forces to wage war against other countries. The government maintains a "Self-Defense Force", which include air, land and sea components. Japan's deployment of non-combat troops to Iraq marked the first overseas use of its military since World War II.

As an economic power, Japan is a member of the G7 and Asia-Pacific Economic Cooperation (APEC), and has developed relations with ASEAN as a member of "ASEAN plus three" and the East Asia Summit. Japan is a major donor in international aid and development efforts, donating 0.19% of its Gross National Income in 2004.

Japan has territorial disputes with Russia over the Kuril Islands (Northern Territories), with South Korea over Liancourt Rocks (known as "Dokdo" in Korea, "Takeshima" in Japan), with China and Taiwan over the Senkaku Islands and with China over the status of Okinotorishima. These disputes are in part about the control of marine and natural resources, such as possible reserves of crude oil and natural gas. Japan has an ongoing dispute with North Korea over its abduction of Japanese citizens and nuclear weapons program.





</doc>
<doc id="15578" url="https://en.wikipedia.org/wiki?curid=15578" title="Economy of Japan">
Economy of Japan

The economy of Japan is a highly developed free-market economy. It is the third-largest in the world by nominal GDP and the fourth-largest by purchasing power parity (PPP). and is the world's second largest developed economy. Japan is a member of the G7. According to the International Monetary Fund, the country's per capita GDP (PPP) was at $38,937(2016). Due to a volatile currency exchange rate, Japan's GDP as measured in dollars fluctuates sharply. Accounting for these fluctuations through the use of the Atlas method, Japan is estimated to have a GDP per capita of around $38,490. The Japanese economy is forecast by the Quarterly Tankan survey of business sentiment conducted by the Bank of Japan. The Nikkei 225 presents the monthly report of top blue chip equities on Japan Exchange Group, which is the world's third-largest stock exchange by market capitalisation. In 2018, Japan was the world's fourth-largest importer and the fourth-largest exporter. It has the world's second-largest foreign-exchange reserves worth $1.3 trillion. It ranks 39th on Ease of doing business index and 5th on Global Competitiveness Report. Japan is also the world's third-largest consumer market. 

Japan is the world's third largest automobile manufacturing country, has the largest electronics goods industry, and is often ranked among the world's most innovative countries leading several measures of global patent filings. Facing increasing competition from China and South Korea, manufacturing in Japan today now focuses primarily on high-tech and precision goods, such as optical instruments, hybrid vehicles, and robotics. Besides the Kantō region, the Kansai region is one of the leading industrial clusters and manufacturing centers for the Japanese economy.<ref name="Profile of Osaka/Kansai"></ref> The size and industrial structure of cities in Japan have maintained tight regularities despite substantial churning of population and industries across cities overtime. Japan is the world's largest creditor nation. Japan generally runs an annual trade surplus and has a considerable net international investment surplus. As of 2010, Japan possesses 13.7% of the world's private financial assets (the third largest in the world) at an estimated $13.5 trillion. As of 2017, 51 of the Fortune Global 500 companies are based in Japan, down from 62 in 2013.

Japan has the highest ratio of public debt to GDP of any developed nation, with national debt at 236% relative to GDP as of 2017. This debt is predominantly owned by Japanese nationals. The Japanese economy faces considerable challenges posed by a declining population, which peaked at 128 million in 2010 and has fallen to 126.5 million as of 2018. Projections suggest the population will continue to fall to potentially lower than 100 million by the middle of the 21st century.

In the three decades of economic development following 1960, rapid economic growth referred to as the Japanese post-war economic miracle occurred. By the guidance of Ministry of Economy, Trade and Industry, with average growth rates of 10% in the 1960s, 5% in the 1970s, and 4% in the 1980s, Japan was able to establish and maintain itself as the world's second largest economy from 1978 until 2010, when it was surpassed by the People's Republic of China. By 1990, income per capita in Japan equalled or surpassed that in most countries in the West.

During the second half of the 1980s, rising stock and real estate prices created an economic bubble. The economic bubble came to an abrupt end as the Tokyo Stock Exchange crashed in 1990–92 and real estate prices peaked in 1991. Growth in Japan throughout the 1990s at 1.5% was slower than global growth, giving rise to the term Lost Decade. After another decade of low growth rate, the term became the Lost 20 Years. Nonetheless, GDP per capita growth from 2001 to 2010 has still managed to outpace Europe and the United States.

With this low growth rate, the national debt of Japan has expanded due to its considerable social welfare spending in an aging society with a shrinking tax-base. The scenario of "Abandoned homes" continues to spread from rural areas to urban areas in Japan.

A mountainous, volcanic island country, Japan has inadequate natural resources to support its growing economy and large population, and therefore exports goods in which it has a comparative advantage such as engineering-oriented, research and development-led industrial products in exchange for the import of raw materials and petroleum. Japan is among the top-three importers for agricultural products in the world next to the European Union and United States in total volume for covering of its own domestic agricultural consumption. Japan is the world's largest single national importer of fish and fishery products. Tokyo Metropolitan Central Wholesale Market is the largest wholesale market for primary products in Japan, including the renowned Tsukiji fish market. Japanese whaling, ostensibly for research purposes, has been sued as illegal under international law.

Although many kinds of minerals were extracted throughout the country, most mineral resources had to be imported in the postwar era. Local deposits of metal-bearing ores were difficult to process because they were low grade. The nation's large and varied forest resources, which covered 70 percent of the country in the late 1980s, were not utilized extensively. Because of political decisions on local, prefectural, and national levels, Japan decided not to exploit its forest resources for economic gain. Domestic sources only supplied between 25 and 30 percent of the nation's timber needs. Agriculture and fishing were the best developed resources, but only through years of painstaking investment and toil. The nation, therefore, built up the manufacturing and processing industries to convert raw materials imported from abroad. This strategy of economic development necessitated the establishment of a strong economic infrastructure to provide the needed energy, transportation, communications, and technological know-how.

Deposits of gold, magnesium, and silver meet current industrial demands, but Japan is dependent on foreign sources for many of the minerals essential to modern industry. Iron ore, copper, bauxite, and alumina must be imported, as well as many forest products.

The economic history of Japan is one of the most studied economies for its spectacular growth in three different periods. First was the foundation of Edo (in 1603) to whole inland economic developments, second was the Meiji Restoration (in 1868) to be the first non-European power, third was after the defeat of World War II (in 1945) when the island nation rose to become the world's second largest economy.

Japan was considered as a country rich in precious metals, mainly owing to Marco Polo's accounts of gilded temples and palaces, but also due to the relative abundance of surface ores characteristic of a massive huge volcanic country, before large-scale deep-mining became possible in Industrial times. Japan was to become a major exporter of silver, copper, and gold during the period until exports for those minerals were banned.

Renaissance Japan was also perceived as a sophisticated feudal society with a high culture and a strong pre-industrial technology. It was densely populated and urbanized. Prominent European observers of the time seemed to agree that the Japanese ""excel not only all the other Oriental peoples, they surpass the Europeans as well"" (Alessandro Valignano, 1584, "Historia del Principo y Progresso de la Compania de Jesus en las Indias Orientales).

Early European visitors were amazed by the quality of Japanese craftsmanship and metalsmithing. This stems from the fact that Japan itself is rather rich in natural resources found commonly in Europe, especially iron.

The cargo of the first Portuguese ships (usually about 4 smaller-sized ships every year) arriving in Japan almost entirely consisted of Chinese goods (silk, porcelain). The Japanese were very much looking forward to acquiring such goods, but had been prohibited from any contacts with the Emperor of China, as a punishment for Wakō pirate raids. The Portuguese (who were called "Nanban", lit. Southern Barbarians) therefore found the opportunity to act as intermediaries in Asian trade.

The beginning of the Edo period coincides with the last decades of the Nanban trade period, during which intense interaction with European powers, on the economic and religious plane, took place. It is at the beginning of the Edo period that Japan built her first ocean-going Western-style warships, such as the "San Juan Bautista", a 500-ton galleon-type ship that transported a Japanese embassy headed by Hasekura Tsunenaga to the Americas, which then continued to Europe. Also during that period, the "bakufu" commissioned around 350 Red Seal Ships, three-masted and armed trade ships, for intra-Asian commerce. Japanese adventurers, such as Yamada Nagamasa, were active throughout Asia.

In order to eradicate the influence of Christianization, Japan entered in a period of isolation called sakoku, during which its economy enjoyed stability and mild progress. But not long after, in the 1650s, the production of Japanese export porcelain increased greatly when civil war put the main Chinese center of porcelain production, in Jingdezhen, out of action for several decades. For the rest of the 17th century, most Japanese porcelain production was for export, mostly in Kyushu. The trade dwindled under renewed Chinese competition by the 1740s, before resuming after the opening of Japan in the mid-19th century. 

Economic development during the Edo period included urbanization, increased shipping of commodities, a significant expansion of domestic and, initially, foreign commerce, and a diffusion of trade and handicraft industries. The construction trades flourished, along with banking facilities and merchant associations. Increasingly, "han" authorities oversaw the rising agricultural production and the spread of rural handicrafts.

By the mid-eighteenth century, Edo had a population of more than 1 million and Osaka and Kyoto each had more than 400,000 inhabitants. Many other castle towns grew as well. Osaka and Kyoto became busy trading and handicraft production centers, while Edo was the center for the supply of food and essential urban consumer goods.

Rice was the base of the economy, as the daimyō collected the taxes from the peasants in the form of rice. Taxes were high, about 40% of the harvest. The rice was sold at the "fudasashi" market in Edo. To raise money, the daimyō used forward contracts to sell rice that was not even harvested yet. These contracts were similar to modern futures trading.

During the period, Japan progressively studied Western sciences and techniques (called "rangaku", literally "Dutch studies") through the information and books received through the Dutch traders in Dejima. The main areas that were studied included geography, medicine, natural sciences, astronomy, art, languages, physical sciences such as the study of electrical phenomena, and mechanical sciences as exemplified by the development of Japanese clockwatches, or wadokei, inspired from Western techniques.

Since the mid-19th century, after the Meiji Restoration, the country was opened up to Western commerce and influence and Japan has gone through two periods of economic development. The first began in earnest in 1868 and extended through to World War II; the second began in 1945 and continued into the mid-1980s.

Economic developments of the prewar period began with the "Rich State and Strong Army Policy" by the Meiji government. During the Meiji period (1868–1912), leaders inaugurated a new Western-based education system for all young people, sent thousands of students to the United States and Europe, and hired more than 3,000 Westerners to teach modern science, mathematics, technology, and foreign languages in Japan (Oyatoi gaikokujin). The government also built railroads, improved road, and inaugurated a land reform program to prepare the country for further development.

To promote industrialization, the government decided that, while it should help private business to allocate resources and to plan, the public sector was best equipped to stimulate economic growth. The greatest role of government was to help provide good economic conditions for business. In short, government was to be the guide and business the producer. In the early Meiji period, the government built factories and shipyards that were sold to entrepreneurs at a fraction of their value. Many of these businesses grew rapidly into the larger conglomerates. Government emerged as chief promoter of private enterprise, enacting a series of probusiness policies.

In the mid-1930s, the Japanese nominal wage rates were "10 times less" than the one of the U.S (based on mid-1930s exchange rates), while the price level is estimated to have been about 44% the one of the U.S.

From the 1960s to the 1980s, overall real economic growth was extremely large: a 10% average in the 1960s, a 5% average in the 1970s and a 4% average in the 1980s. By the end of said period, Japan had moved into being a high-wage economy.

Growth slowed markedly in the late 1990s also termed the Lost Decade after the collapse of the Japanese asset price bubble. As a consequence Japan ran massive budget deficits (added trillions in Yen to Japanese financial system) to finance large public works programs.

By 1998, Japan's public works projects still could not stimulate demand enough to end the economy's stagnation. In desperation, the Japanese government undertook "structural reform" policies intended to wring speculative excesses from the stock and real estate markets. Unfortunately, these policies led Japan into deflation on numerous occasions between 1999 and 2004. The Bank of Japan used quantitative easing to expand the country's money supply in order to raise expectations of inflation and spur economic growth. Initially, the policy failed to induce any growth, but it eventually began to affect inflationary expectations. By late 2005, the economy finally began what seems to be a sustained recovery. GDP growth for that year was 2.8%, with an annualized fourth quarter expansion of 5.5%, surpassing the growth rates of the US and European Union during the same period. Unlike previous recovery trends, domestic consumption has been the dominant factor of growth.

Despite having interest rates down near zero for a long period of time, the quantitative easing strategy did not succeed in stopping price deflation. This led some economists, such as Paul Krugman, and some Japanese politicians, to advocate the generation of higher inflation expectations. In July 2006, the zero-rate policy was ended. In 2008, the Japanese Central Bank still had the lowest interest rates in the developed world, but deflation had still not been eliminated and the Nikkei 225 has fallen over approximately 50% (between June 2007 and December 2008). However, on 5 April 2013, the Bank of Japan announced that it would be purchasing 60–70 trillion yen in bonds and securities in an attempt to eliminate deflation by doubling the money supply in Japan over the course of two years. Markets around the world have responded positively to the government's current proactive policies, with the Nikkei 225 adding more than 42% since November 2012. The Economist has suggested that improvements to bankruptcy law, land transfer law, and tax laws will aid Japan's economy. In recent years, Japan has been the top export market for almost 15 trading nations worldwide.

In 2005, one half of Japan's energy was produced from petroleum, a fifth from coal, and 14% from natural gas. Nuclear power in Japan made a quarter of electricity production but due to the Fukushima Daiichi nuclear disaster there has been a large desire to end Japan's nuclear power program. In September 2013, Japan closed its last 50 nuclear power plants nationwide, causing the nation to be nuclear free.

Japan's spendings on roads has been considered large. The 1.2 million kilometers of paved road are one of the major means of transportation. Japan has left-hand traffic. A single network of speed, divided, limited-access toll roads connects major cities and are operated by toll-collecting enterprises. New and used cars are inexpensive, and the Japanese government has encouraged people to buy hybrid vehicles. Car ownership fees and fuel levies are used to promote energy-efficiency.

Rail transport is a major means of transport in Japan. Dozens of Japanese railway companies compete in regional and local passenger transportation markets; for instance, 6 passenger JR enterprises, Kintetsu Railway, Seibu Railway, and Keio Corporation. Often, strategies of these enterprises contain real estate or department stores next to stations, and many major stations have major department stores near them. The Japanese cities of Fukuoka, Kobe, Kyoto, Nagoya, Osaka, Sapporo, Sendai, Tokyo and Yokohama all have subway systems. Some 250 high-speed Shinkansen trains connect major cities. All trains are known for punctuality, and a delay of 90 seconds can be considered late for some train services.

There are 98 passenger and 175 total airports in Japan, and flying is a popular way to travel. The largest domestic airport, Tokyo International Airport, is Asia's second busiest airport. The largest international gateways are Narita International Airport (Tokyo area), Kansai International Airport (Osaka/Kobe/Kyoto area), and Chūbu Centrair International Airport (Nagoya area). The largest ports in Japan include Nagoya Port, the Port of Yokohama, the Port of Tokyo and the Port of Kobe.

About 84% of Japan's energy is imported from other countries. Japan is the world's largest liquefied natural gas importer, second largest coal importer, and third largest net oil importer. Given its heavy dependence on imported energy, Japan has aimed to diversify its sources. Since the oil shocks of the 1970s, Japan has reduced dependence on petroleum as a source of energy from 77.4% in 1973 to about 43.7% in 2010 and increased dependence on natural gas and nuclear power.In September 2019, Japan will invest $10 billion on liquefied natural gas projects worldwide, in a strategy to boost the global LNG market and reinforce the security of energy supply. Other important energy source includes coal, and hydroelectricity is Japan's biggest renewable energy source. Japan's solar market is also currently booming. Kerosene is also used extensively for home heating in portable heaters, especially farther north. Many taxi companies run their fleets on liquefied natural gas. A recent success towards greater fuel economy was the introduction of mass-produced Hybrid vehicles. Prime Minister Shinzō Abe, who was working on Japan's economic revival, signed a treaty with Saudi Arabia and UAE about the rising prices of oil, ensuring Japan's stable deliveries from that region.

This is a chart of trend of gross domestic product of Japan at market prices estimated by the International Monetary Fund with figures in millions of Japanese Yen. See also

For purchasing power parity comparisons, the US dollar was exchanged at ￥109 in 2010.

Industries by GDP value-added 2012. Values are converted using the exchange rate on 13 April 2013.

The following table shows the main economic indicators in 1980–2018. Inflation under 2 % is in green.

The Japanese agricultural sector accounts for about 1.4% of the total country's GDP. Only 12% of Japan's land is suitable for cultivation. Due to this lack of arable land, a system of terraces is used to farm in small areas. This results in one of the world's highest levels of crop yields per unit area, with an overall agricultural self-sufficiency rate of about 50% on fewer than 56,000 km² (14 million acres) cultivated.

Japan's small agricultural sector, however, is also highly subsidized and protected, with government regulations that favor small-scale cultivation instead of large-scale agriculture as practiced in North America. There has been a growing concern about farming as the current farmers are aging with a difficult time finding successors.

Rice accounts for almost all of Japan's cereal production. Japan is the second-largest agricultural product importer in the world. Rice, the most protected crop, is subject to tariffs of 777.7%.

Although Japan is usually self-sufficient in rice (except for its use in making rice crackers and processed foods) and wheat, the country must import about 50% of its requirements of other grain and fodder crops and relies on imports for half of its supply of meat. Japan imports large quantities of wheat and soybeans. Japan is the 5th largest market for EU agricultural exports. Over 90% of mandarin oranges in Japan are grown in Japan. Apples are also grown due to restrictions on apple imports.

Japan ranked fourth in the world in 1996 in tonnage of fish caught. Japan captured 4,074,580 metric tons of fish in 2005, down from 4,987,703 tons in 2000, 9,558,615 tons in 1990, 9,864,422 tons in 1980, 8,520,397 tons in 1970, 5,583,796 tons in 1960 and 2,881,855 tons in 1950. In 2003, the total aquaculture production was predicted at 1,301,437 tonnes. In 2010, Japan's total fisheries production was 4,762,469 fish. Offshore fisheries accounted for an average of 50% of the nation's total fish catches in the late 1980s although they experienced repeated ups and downs during that period.

Coastal fishing by small boats, set nets, or breeding techniques accounts for about one third of the industry's total production, while offshore fishing by medium-sized boats makes up for more than half the total production. Deep-sea fishing from larger vessels makes up the rest. Among the many species of seafood caught are sardines, skipjack tuna, crab, shrimp, salmon, pollock, squid, clams, mackerel, sea bream, sauries, tuna and Japanese amberjack. Freshwater fishing, including salmon, trout and eel hatcheries and fish farms, takes up about 30% of Japan's fishing industry. Among the nearly 300 fish species in the rivers of Japan are native varieties of catfish, chub, herring and goby, as well as such freshwater crustaceans as crabs and crayfish. Marine and freshwater aquaculture is conducted in all 47 prefectures in Japan.

Japan maintains one of the world's largest fishing fleets and accounts for nearly 15% of the global catch, prompting some claims that Japan's fishing is leading to depletion in fish stocks such as tuna. Japan has also sparked controversy by supporting quasi-commercial whaling.

Japanese manufacturing and industry is very diversified, with a variety of advanced industries that are highly successful. Industry accounts for 24% of the nation's GDP.

Industry is concentrated in several regions, with the Kantō region surrounding Tokyo, (the Keihin industrial region) as well as the Kansai region surrounding Osaka (the Hanshin industrial region) and the Tōkai region surrounding Nagoya (the Chūkyō–Tōkai industrial region) the main industrial centers. Other industrial centers include the southwestern part of Honshū and northern Shikoku around the Seto Inland Sea (the Setouchi industrial region); and the northern part of Kyūshū (Kitakyūshū). In addition, a long narrow belt of industrial centers called the Taiheiyō Belt is found between Tokyo and Fukuoka, established by particular industries, that have developed as mill towns.

Japan enjoys high technological development in many fields, including consumer electronics, automobile manufacturing, semiconductor manufacturing, optical fibers, optoelectronics, optical media, facsimile and copy machines, and fermentation processes in food and biochemistry. However, many Japanese companies are facing emerging rivals from the United States, South Korea, and China.

Japan is the third biggest producer of automobiles in the world. Toyota is currently the world largest car maker, and the Japanese car makers Nissan, Honda, Suzuki, and Mazda also count for some of the largest car makers in the world.

Japan's mining production has been minimal, and Japan has very little mining deposits. However, massive deposits of rare earths have been found off the coast of Japan. In the 2011 fiscal year, the domestic yield of crude oil was 820 thousand kiloliters, which was 0.4% of Japan's total crude processing volume.

Japan's service sector accounts for about three-quarters of its total economic output. Banking, insurance, real estate, retailing, transportation, and telecommunications are all major industries such as Mitsubishi UFJ, Mizuho, NTT, TEPCO, Nomura, Mitsubishi Estate, ÆON, Mitsui Sumitomo, Softbank, JR East, Seven & I, KDDI and Japan Airlines counting as one of the largest companies in the world. Four of the five most circulated newspapers in the world are Japanese newspapers. The Koizumi government set Japan Post, one of the country's largest providers of savings and insurance services for privatization by 2015. The six major keiretsus are the Mitsubishi, Sumitomo, Fuyo, Mitsui, Dai-Ichi Kangyo and Sanwa Groups. Japan is home to 251 companies from the Forbes Global 2000 or 12.55% (as of 2013).

In 2012, Japan was the fifth most visited country in Asia and the Pacific, with over 8.3 million tourists. In 2013, due to the weaker yen and easier visa requirements for southwest Asian countries, Japan received a record 11.25 million visitors, which was higher than the government's projected goal of 10 million visitors. The government hopes to attract 40 million visitors a year by the 2020 Summer Olympics in Tokyo. Some of the most popular visited places include the Shinjuku, Ginza, Shibuya and Asakusa areas in Tokyo, and the cities of Osaka, Kobe and Kyoto, as well as Himeji Castle. Hokkaido is also a popular winter destination for visitors with several ski resorts and luxury hotels being built there.

The Tokyo Stock Exchange is the third largest stock exchange in the world by market capitalization, as well as the 2nd largest stock market in Asia, with 2,292 listed companies. The Nikkei 225 and the TOPIX are the two important stock market indexes of the Tokyo Stock Exchange. The Tokyo Stock Exchange and the Osaka Stock Exchange, another major stock exchange in Japan, merged on 1 January 2013, creating one of the world's largest stock exchanges. Other stock exchanges in Japan include the Nagoya Stock Exchange, Fukuoka Stock Exchange and Sapporo Securities Exchange.

The unemployment rate in December 2013 was 3.7%, down 1.5 percentage points from the claimed unemployment rate of 5.2% in June 2009 due to the strong economic recovery.

In 2008 Japan's labor force consisted of some 66 million workers—40% of whom were women—and was rapidly shrinking.
One major long-term concern for the Japanese labor force is its low birthrate. In the first half of 2005, the number of deaths in Japan exceeded the number of births, indicating that the decline in population, initially predicted to start in 2007, had already started. While one countermeasure for a declining birthrate would be to remove barriers to immigration, despite taking new steps towards it, the Japanese government has been reluctant to do so, since foreign immigration to Japan has been unpopular among citizens.

In 1989, the predominantly public sector union confederation, SOHYO (General Council of Trade Unions of Japan), merged with RENGO (Japanese Private Sector Trade Union Confederation) to form the Japanese Trade Union Confederation. Labor union membership is about 12 million.

Japan ranks 27th of 185 countries in the ease of doing business index 2013.

Japan has one of the smallest tax rates in the developed world. After deductions, the majority of workers are free from personal income taxes. Consumption tax rate is only 8%, while corporate tax rates are high, second highest corporate tax rate in the world, at 36.8%. However, the House of Representatives has passed a bill which will increase the consumption tax to 10% in October 2015. The government has also decided to reduce corporate tax and to phase out automobile tax.

In 2016, the IMF encouraged Japan to adopt an income policy that pushes firms to raise employee wages in combination with reforms to tackle the labor market dual tiered employment system to drive higher wages, on top of monetary and fiscal stimulus. Shinzo Abe has encouraged firms to raise wages by at least three percent annually (the inflation target plus average productivity growth).

Shareholder activism is rare despite the fact that the corporate law gives shareholders strong powers over managers. Under Prime Minister Shinzō Abe, corporate governance reform has been a key initiative to encourage economic growth. In 2012 around 40% of leading Japanese companies had any independent directors while in 2016 most all have begun to appoint independent directors.

The government's liabilities include the second largest public debt of any nation with debt of over one quadrillion yen, or $8,535,340,000,000 in USD. Former Prime Minister Naoto Kan has called the situation 'urgent'.

Japan's central bank has the second largest foreign-exchange reserves after the People's Republic of China, with over one trillion US Dollars in foreign reserves.

Nemawashi (根回し), or "consensus building", in Japanese culture is an informal process of quietly laying the foundation for some proposed change or project, by talking to the people concerned, gathering support and feedback, and so forth. It is considered an important element in any major change, before any formal steps are taken, and successful "nemawashi" enables changes to be carried out with the consent of all sides.

Japanese companies are known for management methods such as "The Toyota Way". Kaizen (改善, Japanese for "improvement") is a Japanese philosophy that focuses on continuous improvement throughout all aspects of life. When applied to the workplace, Kaizen activities continually improve all functions of a business, from manufacturing to management and from the CEO to the assembly line workers. By improving standardized activities and processes, Kaizen aims to eliminate waste (see Lean manufacturing). Kaizen was first implemented in several Japanese businesses during the country's recovery after World War II, including Toyota, and has since spread to businesses throughout the world. Within certain value systems, it is ironic that Japanese workers labor amongst the most hours per day, even though kaizen is supposed to improve all aspects of life.

Some companies have powerful enterprise unions and "shuntō". The Nenko System or Nenko Joretsu, as it is called in Japan, is the Japanese system of promoting an employee based on his or her proximity to retirement. The advantage of the system is that it allows older employees to achieve a higher salary level before retirement and it usually brings more experience to the executive ranks. The disadvantage of the system is that it does not allow new talent to be combined with experience and those with specialized skills cannot be promoted to the already crowded executive ranks. It also does not guarantee or even attempt to bring the "right person for the right job".

Relationships between government bureaucrats and companies are often close. is the institutionalised practice where Japanese senior bureaucrats retire to high-profile positions in the private and public sectors. The practice is increasingly viewed as corrupt and a limitation on efforts to reduce ties between the private sector and the state that prevent economic and political reforms. Lifetime employment ("shūshin koyō") and seniority-based career advancement have been common in the Japanese work environment. Japan has begun to gradually move away from some of these norms.

An office lady, often abbreviated OL (Japanese: オーエル "Ōeru"), is a female office worker in Japan who performs generally pink collar tasks such as serving tea and secretarial or clerical work. Like many unmarried Japanese, OLs often live with their parents well into early adulthood. Office ladies are usually full-time permanent staff, although the jobs they do usually have little opportunity for promotion, and there is usually the tacit expectation that they leave their jobs once they get married.

, which can be translated quite literally from Japanese as "death from overwork", is occupational sudden death. The major medical causes of karōshi deaths are heart attack and stroke due to stress.

, (sometimes also translated as "corporate bouncers", "meeting-men", or "corporate blackmailers") are a form of specialized racketeer unique to Japan, and often associated with the yakuza that extort money from or blackmail companies by threatening to publicly humiliate companies and their management, usually in their . is a Japanese term for moneylender, or loan shark. It is a contraction of the Japanese words for salaryman and cash. Around 14 million people, or 10% of the Japanese population, have borrowed from a "sarakin". In total, there are about 10,000 firms (down from 30,000 a decade ago); however, the top seven firms make up 70% of the market. The value of outstanding loans totals $100 billion. The biggest "sarakin" are publicly traded and often allied with big banks.

The first "Western-style" department store in Japan was Mitsukoshi, founded in 1904, which has its root as a kimono store called Echigoya from 1673. When the roots are considered, however, Matsuzakaya has an even longer history, dated from 1611. The kimono store changed to a department store in 1910. In 1924, Matsuzakaya store in Ginza allowed street shoes to be worn indoors, something innovative at the time. These former kimono shop department stores dominated the market in its earlier history. They sold, or rather displayed, luxurious products, which contributed for their sophisticated atmospheres. Another origin of Japanese department store is that from railway company. There have been many private railway operators in the nation, and from the 1920s, they started to build department stores directly linked to their lines' termini. Seibu and Hankyu are the typical examples of this type. From the 1980s onwards, Japanese department stores face fierce competition from supermarkets and convenience stores, gradually losing their presences. Still, "depāto" are bastions of several aspects of cultural conservatism in the country. Gift certificates for prestigious department stores are frequently given as formal presents in Japan. Department stores in Japan generally offer a wide range of services and can include foreign exchange, travel reservations, ticket sales for local concerts and other events.

A is a set of companies with interlocking business relationships and shareholdings. It is a type of business group. The prototypical "keiretsu" appeared in Japan during the "economic miracle" following World War II. Before Japan's surrender, Japanese industry was controlled by large family-controlled vertical monopolies called "zaibatsu". The Allies dismantled the "zaibatsu" in the late 1940s, but the companies formed from the dismantling of the "zaibatsu" were reintegrated. The dispersed corporations were re-interlinked through share purchases to form horizontally integrated alliances across many industries. Where possible, "keiretsu" companies would also supply one another, making the alliances vertically integrated as well. In this period, official government policy promoted the creation of robust trade corporations that could withstand pressures from intensified world trade competition.

The major "keiretsu" were each centered on one bank, which lent money to the "keiretsu's" member companies and held equity positions in the companies. Each central bank had great control over the companies in the "keiretsu" and acted as a monitoring entity and as an emergency bail-out entity. One effect of this structure was to minimize the presence of hostile takeovers in Japan, because no entities could challenge the power of the banks.

There are two types of "keiretsu": vertical and horizontal. Vertical "keiretsu" illustrates the organization and relationships within a company (for example all factors of production of a certain product are connected), while a horizontal "keiretsu" shows relationships between entities and industries, normally centered on a bank and trading company. Both are complexly woven together and sustain each other.

The Japanese recession in the 1990s had profound effects on the keiretsu. Many of the largest banks were hit hard by bad loan portfolios and forced to merge or go out of business. This had the effect of blurring the lines between the keiretsu: Sumitomo Bank and Mitsui Bank, for instance, became Sumitomo Mitsui Banking Corporation in 2001, while Sanwa Bank (the banker for the Hankyu-Toho Group) became part of Bank of Tokyo-Mitsubishi UFJ. Additionally, many companies from outside the keiretsu system, such as Sony, began outperforming their counterparts within the system.

Generally, these causes gave rise to a strong notion in the business community that the old keiretsu system was not an effective business model, and led to an overall loosening of keiretsu alliances. While the keiretsu still exist, they are not as centralized or integrated as they were before the 1990s. This, in turn, has led to a growing corporate acquisition industry in Japan, as companies are no longer able to be easily "bailed out" by their banks, as well as rising derivative litigation by more independent shareholders.

Japanese companies have been involved in 50,759 deals between 1985 and 2018. This cumulates to a total value of 2,636 bil. USD which translates to 281,469.9 bil. YEN. In the year 1999 there was an all-time high in terms of value of deals with almost 220 bil. USD. The most active year so far was 2017 with over 3,150 deals, but only a total value of 114 bil. USD (see graph "M&A in Japan by number and value").

Here is a list of the most important deals (ranked by value in bil. USD) in Japanese history:

Among the top 50 deals by value, 92% of the time the acquiring nation is Japan. Foreign direct investment is playing a much smaller role than national M&A in Japan.

Net international investment position: 266,223 \ billion (1st)

Industrial Production Growth Rate: 7.5% (2010 est.)

Investment (gross fixed): 20.3% of GDP (2010 est.)

Household income or consumption by percentage share:
Agriculture – Products: rice, sugar beets, vegetables, fruit, pork, poultry, dairy products, eggs, fish

Exports – Commodities: machinery and equipment, motor vehicles, semiconductors, chemicals

Imports – Commodities: machinery and equipment, fuels, foodstuffs, chemicals, textiles, raw materials (2001)

Exchange rates:<br>
"Japanese Yen per US$1" – 88.67 (2010), 93.57 (2009), 103.58 (2008), 117.99 (2007), 116.18 (2006), 109.69 (2005), 115.93 (2003), 125.39 (2002), 121.53 (2001), 105.16 (January 2000), 113.91 (1999), 130.91 (1998), 120.99 (1997), 108.78 (1996), 94.06 (1995)

Electricity:

Electricity – Production by source:

Electricity – Standards:

Oil:




</doc>
<doc id="15579" url="https://en.wikipedia.org/wiki?curid=15579" title="Communications in Japan">
Communications in Japan

The nation of Japan currently possesses one of the most advanced communication networks in the world. For example, by 2008 the Japanese government's Internal Affairs and Communications Ministry stated that about 75 million people used mobile phones to access the Internet, said total accounting for about 82% of individual Internet users.

Telephones and ISDN – main lines in use: 52.3981 million (2007)

IP phone lines in use: 16.766 million (2007)

Mobile and PHS lines in use: 105.297 million (2007)

There are five nationwide mobile phone service providers: NTT DoCoMo, KDDI, SoftBank Mobile, EMOBILE, and Willcom.

Radio broadcast stations: AM 190, FM 88, shortwave 24 (1999)

Radios: 120.5 million (1997)

Television broadcast stations: 7,108 (plus 441 repeaters; note – in addition, US Forces are served by 3 TV stations and 2 TV cable services) (1999)

Televisions: 86.5 million (1997)

Amateur radio: 446,602 licensed stations as of October 2011. See Amateur radio call signs of Japan.


Number of Broadband Users by Access (April 2005)

Number of Broadband Users by Access (June 2004)

Number of Broadband Users by Access (June 2002)

Country code (Top-level domain): JP

Japan's first modern postal service got started in 1871, with mail professionally traveling between Kyoto and Tokyo as well as the latter city and Osaka. This took place in the midst of the rapid industrialization and social reorganization that the Meiji period symbolized in Japanese history. Given how the nation's railroad technology was in its infancy, Japan's growing postal system relied heavily on human-powered transport, including rickshaws, as well as horse-drawn methods of delivery. For example, while commemorating the 50th anniversary of Japan's postal service, the country's 1921 government released decorative postcards depicting intrepid horseback riders carrying the mail.

In communication terms, British technicians had already been employed in assisting with Japanese lighthouses, and the country's budding mail system looked to hybridize British ideas with local practicalities. Shipping along the nation's coastline in particular demonstrates a key instance of how the Japanese economy developed: the government closely working with private companies to industrially expand in a way that met social needs while also allowing for large profits. Mitsubishi's contract for mail transport by sea proved lucrative enough that it assisted with the firm becoming one of the famous "zaibatsu".

Since 2007, the nation's post offices have been managed by the firm Japan Post Network, which, in turn, is a part of the larger Japan Post Holdings conglomerate. As of December 2017, the smaller company has been managed by CEO Koji Furukawa. The simple Japanese postal mark, predating mass literacy in the nation, is still used to this day.

An example of the dawn of modern Japanese communications is the shift in newspaper publication. News vendors of the Tokugawa period, taking place from 1603 to 1867, typically promoted publications by reading the contents aloud and handed out papers that were printed from hand-graven blocks. Widespread adoption of movable type took place as Japanese society modernized. In particular, "Yomiuri Shimbun", a national daily newspaper that became the country's largest by circulation, was founded in 1874 and designed to be read in detail using standard Japanese vernacular. Five such dailies got started early in the Meiji period, taking place from 1868 to 1912. "Yomiuri" specifically took direct influence from American publications controlled by William Randolph Hearst.

The first such mass newspaper to be founded was the "Nagasaki Shipping List & Advertiser", established in 1861 in Nagasaki by the Englishman A.W. Hansard. Its first issue ran 22 June of that year. The newspaper, which notably discussed matters in the English language, laid the groundwork for Hansard's later publication "Japan Herald".

The broadcast industry has been dominated by the Japan Broadcasting Corporation (Nippon Hoso Kyokai—NHK) since its founding in 1925.

In the postwar period, NHK's budget and operations were under the purview of the Ministry of Posts and Telecommunications, the Broadcasting Law of 1950 provides for independent management and programming by NHK. Television broadcasting began in 1953, and color television was introduced in 1960. Cable television was introduced in 1969. In 1978 an experimental broadcast satellite with two color television channels was launched. Operational satellites for television use were launched between 1984 and 1990. Television viewing spread so rapidly that, by 1987, 99 percent of Japan's households had color television sets and the average family had its set on at least five hours a day. Starting in 1987, NHK began full-scale experimental broadcasting on two channels using satellite-to-audience signals, thus bringing service to remote and mountainous parts of the country that earlier had experienced poor reception. The new system also provided twenty-four hours a day, nonstop service.

In the late 1980s, NHK operated two public television and three radio networks nationally, producing about 1,700 programs per week. Its general and education programs were broadcast through more than 6,900 television stations and nearly 330 AM and more than 500 FM radio transmitting stations. Comprehensive service in twenty-one languages is available throughout the world.

Rapid improvements, innovations, and diversification in communications technology, including optical fiber cables, communications satellites, and fax machines, led to rapid growth of the communications industry in the 1980s. Nippon Telegraph and Telephone Corporation, owned by the government until 1985, had dominated the communications industry until April 1985, when new common carriers, including Daini Denden, were permitted to enter the field. NTT Worldwide Telecommunications Corp (Kokusai Denshin Denwa Company, commonly known as KDD, now part of KDDI Inc.) lost its monopoly hold on international communications activities in 1989, when Nihon Kokusai Tsushin and other private overseas communications firms began operations.

In 1992 Japan also had more than 12,000 televisions stations, and the country had more than 350 radio stations, 300 AM radio stations and 58 FM. Broadcasting innovations in the 1980s included sound multiplex (two-language or stereo) broadcasting, satellite broadcasting, and in 1985 the University of the Air and teletext services were inaugurated.

Japan has been the world leader in telecommunications in the 1980s, but this position that has been challenged by the United States' dot-com industry in the 1990s and the emerging tiger states in Asia. While the United States is leading in digital content, South Korea is leading in broadband access, India is leading in software, and Taiwan is leading in research and development.

Japan went into the 21st century after achieving widespread saturation with telecommunication devices. For instance, by 2008 the government's Internal Affairs and Communications Ministry stated that about 75 million people used mobile phones to access the Internet, said total accounting for about 82% of individual internet users.



</doc>
<doc id="15580" url="https://en.wikipedia.org/wiki?curid=15580" title="Transport in Japan">
Transport in Japan

Transportation in Japan is modern and highly developed. Japan's transport sector stands out for its energy efficiency: it uses less energy per person compared to other countries, thanks to a high share of rail transport and low overall travel distances. Transport in Japan is also very expensive in international comparison, reflecting high tolls and taxes, particularly on automobile transport.

Japan's spending on roads has been large. The 1.2 million kilometres of paved road are the main means of transport. Japan has left-hand traffic. A single network of high-speed, divided, limited-access toll roads connects major cities, which are operated by toll-collecting enterprises.

Dozens of Japanese railway companies compete in regional and local passenger transport markets; for instance, seven JR Group companies, Kintetsu Railway, Seibu Railway, and Keio Corporation. Often, strategies of these enterprises contain real estate or department stores next to stations. Some 250 high-speed Shinkansen trains connect major cities. All trains are known for punctuality.

There are 176 airports, and the largest domestic airport, Haneda Airport, is Asia's busiest airport. The largest international gateways are Narita International Airport (Tokyo area), Kansai International Airport (Osaka/Kobe/Kyoto area), and Chūbu Centrair International Airport (Nagoya area). The largest ports include Nagoya Port.

In Japan, railways are a major means of passenger transport, especially for mass and high-speed transport between major cities and for commuter transport in metropolitan areas. Seven Japan Railways Group companies, state-owned until 1987, cover most parts of Japan. There also are railway services operated by private rail companies, regional governments, and companies funded by both regional governments and private companies.

Total railways of 27,182 km include several track gauges, the most common of which is narrow gauge, with 22,301 km of track of which 15,222 km is electrified.

Fukuoka, Kobe, Kyoto, Nagoya, Osaka, Sapporo, Sendai, Tokyo, and Yokohama have subway systems.

Most Japanese people travelled on foot until the later part of the 19th century. The first railway was built between Tokyo's Shimbashi Station and Yokohama's former Yokohama Station (now Sakuragichō Station) in 1872. Many more railways developed soon afterward. Japan, as we know it today, is home to one of the world's most developed transport networks. Mass transport is well developed in Japan, but the road system lags behind and is inadequate for the number of cars owned in Japan. This is often attributed to the fact that road construction is difficult in Japan because of its uniquely high population density, and the limited amount of available usable land for road construction.

The Shinkansen, or "bullet trains", as they are often known, are the high-speed rail trains that run across Japan. The of 8 Shinkansen lines run on completely separate lines from their commuting train counterparts, with a few exceptions. Shinkansen take up a large portion of the long distance travel in Japan, with the whole system carrying over 10 billion passengers in its lifetime. 1,114 journeys are made daily, with the fastest train being the JR East E5 and E6 series trains, which operate at a maximum speed of . Shinkansen trains are known to be very safe, with no accident-related deaths or injuries from passengers in its 50-plus year history. Shinkansen trains are also known to be very punctual, following suit with all other Japanese transport; in 2003, the average delay per train on the Tokaido Shinkansen was a mere 6 seconds. Japan has been trying to sell its Shinkansen technology overseas, and has struck deals to help build systems in India, Thailand, and the United States.

The first Shinkansen line opened between Tokyo and Osaka in 1964, and trains can now make the journey in 2 hours and 25 minutes. Additional Shinkansen lines connect Tokyo to Aomori, Niigata, Kanazawa, and Hakodate and Osaka to Fukuoka and Kagoshima, with new lines under construction to Tsuruga, Sapporo and Nagasaki.

Japan has been developing maglev technology trains, and broke the world maglev speed record in April 2015 with a train travelling at the speed of . The Chūō Shinkansen, a commercial maglev service, is currently under construction from Tokyo to Nagoya and Osaka, and when completed in 2045 will cover the distance in 67 minutes, half the time of the current Shinkansen.

According to Japan Statistical Yearbook 2015, Japan in April 2012 had approximately 1,215,000 km of roads made up of 1,022,000 km of city, town and village roads, 129,000 km of prefectural roads, 55,000 km of general national highways and 8,050 km of national expressways. The Foreign Press Center/Japan cites a total length of expressways at 7,641 km (fiscal 2008). A single network of high-speed, divided, limited-access toll roads connects major cities on Honshu, Shikoku and Kyushu. Hokkaido has a separate network, and Okinawa Island has a highway of this type. In the year 2005, the toll collecting companies, formerly Japan Highway Public Corporation, have been transformed into private companies in public ownership, and there are plans to sell parts of them. The aim of this policy is to encourage competition and decrease tolls.

Road passenger and freight transport expanded considerably during the 1980s as private ownership of motor vehicles greatly increased along with the quality and extent of the nation's roads. Bus companies including the JR Bus companies operate long-distance bus services on the nation's expanding expressway network. In addition to relatively low fares and deluxe seating, the buses are well utilised because they continue service during the night, when air and train services are limited.

The cargo sector grew rapidly in the 1980s, recording 274.2 billion tonne-kilometres in 1990. The freight handled by motor vehicles, mainly trucks, in 1990, was over 6 billion tonnes, accounting for 90 percent of domestic freight tonnage and about 50 percent of tonne-kilometres.

Recent large infrastructure projects were the construction of the Great Seto Bridge and the Tokyo Bay Aqua-Line (opened 1997).

Although road fatalities have been decreasing, due in part to stricter enforcement of drunk driving laws, 2004 still saw 7,358 deaths on Japanese roads.

In 2013 Japan had the fourth largest passenger air market in the world with 105,913,000 passengers. In 2013 Japan had 98 airports. The main international gateways are Narita International Airport (Tokyo area), Kansai International Airport (Osaka/Kobe/Kyoto area), and Chūbu Centrair International Airport (Nagoya area). The main domestic hub is Tokyo International Airport (Haneda Airport), Asia's busiest airport and the world's 4th busiest airport; other major traffic hubs include Osaka International Airport, New Chitose Airport outside Sapporo, and Fukuoka Airport. 14 heliports are estimated to exist (1999).

The two main airlines are Japan Airlines and All Nippon Airways. Other passenger carriers include Skymark Airlines, Skynet Asia Airways, Air Do, Star Flyer and Fuji Dream Airlines. United Airlines and Delta Air Lines, formerly Northwest Airlines, are major international operators from Narita Airport.

Domestic air travel in Japan has historically been highly regulated. From 1972, the three major domestic airlines (JAL, ANA, and JAS) were allocated certain routes, with JAL and ANA sharing trunk routes, and ANA and JAS sharing local feeder routes. JAL and JAS have since been merged to help compete with ANA. JAL also had a flag-carrier monopoly on international routes until 1986. Airfares were set by the government until 2000, although carriers had freedom to adjust the standard fares starting in 1995 (when discounts of up to 50% were permitted). Today, fares can be set by carriers, but the government retains the ability to veto fares that are too high.

There are 1770 km of waterways in Japan; seagoing craft ply all coastal inland seas.

There are some 994 ports in Japan as of April 2014. There are overlapping classifications of these ports, some of which are multi-purpose, e.g. cargo, passenger, naval, and fishery. The five designated "super" container ports are: Yokkaichi, Yokohama, Nagoya, Kobe and Osaka. 23 are designated major/international, 125 designated as important, while there are also purely fisherman ports.

The twenty-three major seaports designated as special, important ports by the Ministry of Land, Infrastructure, Transport and Tourism : Chiba, Fushiki/Toyama, Himeji, Hiroshima, Kawasaki, Kitakyūshū, Kobe, Kudamatsu, Muroran, Nagoya, Niigata, Osaka, Sakai/Senpoku, Sendai/Shiogama, Shimizu, Shimonoseki, Tokyo, Tomakomai, Wakayama, Yokkaichi, and Yokohama.

Japan has 988 ships of or over on its national ship register, totaling . However, only 17% of Japanese-owned capacity is registered in Japan. UNCTAD estimates that 224 million dwt of tonnage is controlled by Japanese owners, making Japan the second largest beneficial owner of tonnage after Greece. 

Ferries connect Hokkaido to Honshu, and Okinawa Island to Kyushu and Honshu. They also connect other smaller islands and the main islands. The scheduled international passenger routes are to China, Russia, South Korea and Taiwan. Coastal and cross-channel ferries on the main islands decreased in routes and frequencies following the development of bridges and expressways but some are still operating (as of 2007).

Japan has 84 km of pipelines for crude oil, 322 km for petroleum products, and 1,800 km for natural gas.





</doc>
<doc id="15582" url="https://en.wikipedia.org/wiki?curid=15582" title="Foreign relations of Japan">
Foreign relations of Japan

The are handled by the Ministry of Foreign Affairs of Japan.
Japan maintains diplomatic relations with every United Nations member state except for North Korea, in addition to UN observer states Holy See, as well as the Kosovo, Cook Islands and Niue.

Japanese foreign relations had earliest beginnings in 14th century and after their opening to the world in 1854 with the Convention of Kanagawa. Japan rapidly modernized and built a strong military. It was imperialistic seeking control of nearby areas—with major wars against China and Russia. It gained control of parts of China and Manchuria, as well as Korea and islands such as Taiwan and Okinawa. It lost in World War II and was stripped of all of its foreign conquests and possessions. See History of Japanese foreign relations. American general Douglas MacArthur, acting for the Allied powers, supervised occupied Japan 1945–51. Since occupation ended diplomatic policy has been based on close partnership with the United States and seeking trade agreements, In the Cold War, Japan was demilitarized but it allied with the U.S. in the confrontation with the Soviet Union. It played a major support role in the Korean War (1950-1953). In the rapid economic developments in the 1960s and 1970s, Japan became the second largest economy and was one of the major economic powers in the world. Memories of Japanese atrocities continue to sour relations with China, South Korea and others.

By the 1990s Japan participated in the Peacekeeping operations by the UN, and sent troops to Cambodia, Mozambique, Golan Heights and the East Timor. After the 9/11 terror attacks in 2001, Japanese naval vessels have been assigned to resupply duties in the Indian Ocean to the present date. The Ground Self-Defense Force also dispatched their troops to Southern Iraq for the restoration of basic infrastructures.

Beyond its immediate neighbors, Japan has pursued a more active foreign policy in recent years, recognizing the responsibility which accompanies its economic strength. Japanese Prime Minister Yasuo Fukuda stressed a changing direction in a policy speech to the National Diet: "Japan aspires to become a hub of human resource development as well as for research and intellectual contribution to further promote cooperation in the field of peace-building." This follows the modest success of a Japanese-conceived peace plan which became the foundation for nationwide elections in Cambodia in 1998.


Japan is increasingly active in Africa. In May 2008, the first Hideyo Noguchi Africa Prize will be awarded at Fourth Tokyo International Conference on African Development (TICAD IV), which signals a changing emphasis in bilateral relations.

Japan has continued to extend significant support to development and technical assistance projects in Latin America.

By 1990 Japan's interaction with the vast majority of Asia-Pacific countries, especially its burgeoning economic exchanges, was multifaceted and increasingly important to the recipient countries. The developing countries of the Association of Southeast Asian Nations (ASEAN) regarded Japan as critical to their development. Japan's aid to the ASEAN countries totaled US$1.9 billion in Japanese fiscal year (FY) 1988 versus about US$333 million for the United States during U.S. FY 1988. Japan was the number one foreign investor in the ASEAN countries, with cumulative investment as of March 1989 of about US$14.5 billion, more than twice that of the United States. Japan's share of total foreign investment in ASEAN countries in the same period ranged from 70 to 80 percent in Thailand to 20 percent in Indonesia.

In the late 1980s, the Japanese government was making a concerted effort to enhance its diplomatic stature, especially in Asia. Toshiki Kaifu's much publicized spring 1991 tour of five Southeast Asian nations—Malaysia, Brunei, Thailand, Singapore, and the Philippines—culminated in a 3 May major foreign policy address in Singapore, in which he called for a new partnership with the ASEAN and pledged that Japan would go beyond the purely economic sphere to seek an "appropriate role in the political sphere as a nation of peace." As evidence of this new role, Japan took an active part in promoting negotiations to resolve the Cambodian conflict.

In 1997, the ASEAN member nations and the People's Republic of China, South Korea and Japan agreed to hold yearly talks to further strengthen regional cooperation, the ASEAN Plus Three meetings. In 2005 the ASEAN plus Three countries together with India, Australia and New Zealand held the inaugural East Asia Summit (EAS).

In South Asia, Japan's role is mainly that of an aid donor. Japan's aid to seven South Asian countries totaled US$1.1 billion in 1988 and 1989, dropping to just under US$900 million in 1990. Except for Pakistan, which received heavy inputs of aid from the United States, all other South Asian countries receive most of their aid from Japan. Four South Asian nations—India, Pakistan, Bangladesh, and Sri Lanka—are in the top ten list of Tokyo's aid recipients worldwide. A point to note is that Indian Government has a no receive aid policy since the tsunami that struck India but Indian registered NGOs look to Japan for much investment in their projects

Prime Minister Toshiki Kaifu signaled a broadening of Japan's interest in South Asia with his swing through the region in April 1990. In an address to the Indian parliament, Kaifu stressed the role of free markets and democracy in bringing about "a new international order," and he emphasized the need for a settlement of the Kashmir territorial dispute between India and Pakistan and for economic liberalization to attract foreign investment and promote dynamic growth. To India, which was very short of hard currency, Kaifu pledged a new concessional loan of ¥100 billion (about US$650 million) for the coming year.

In what became known as the Tenshō embassy, the first ambassadors from Japan to European powers reached Lisbon, Portugal in August 1584. From Lisbon, the ambassadors left for the Vatican in Rome, which was the main goal of their journey. The embassy returned to Japan in 1590, after which time the four nobleman ambassadors were ordained by Alessandro Valignano as the first Japanese Jesuit fathers.

A second embassy, headed by Hasekura Tsunenaga and sponsored by Date Masamune, was also a diplomatic mission to the Vatican. The embassy left 28 October 1613 from Ishinomaki, Miyagi Prefecture, in the northern Tōhoku region of Japan, where Date was "daimyō". It traveled to Europe by way of New Spain, arriving in Acapulco on 25 January 1614, Mexico City in March, Havana in July, and finally Seville on 23 October 1614. After a short stop-over in France, the embassy reached Rome in November 1615, where it was received by Pope Paul V. After return travel by way of New Spain and the Philippines, the embassy reached the harbor of Nagasaki in August 1620. While the embassy was gone, Japan had undergone significant change, starting with the 1614 Osaka Rebellion, leading to a 1616 decree from the Tokugawa shogunate that all interaction with non-Chinese foreigners was confined to Hirado and Nagasaki. In fact, the only western country that was allowed to trade with Japan was the Dutch Republic. This was the beginning of "sakoku", where Japan was essentially closed to the western world until 1854.

The cultural and non-economic ties with Western Europe grew significantly during the 1980s, although the economic nexus remained by far the most important element of Japanese – West European relations throughout the decade. Events in West European relations, as well as political, economic, or even military matters, were topics of concern to most Japanese commentators because of the immediate implications for Japan. The major issues centred on the effect of the coming West European economic unification on Japan's trade, investment, and other opportunities in Western Europe. Some West European leaders were anxious to restrict Japanese access to the newly integrated European Union, but others appeared open to Japanese trade and investment. In partial response to the strengthening economic ties among nations in Western Europe and to the United States–Canada–Mexico North American Free Trade Agreement, Japan and other countries along the Asia-Pacific rim began moving in the late 1980s toward greater economic cooperation.

On 18 July 1991, after several months of difficult negotiations, Prime Minister Toshiki Kaifu signed a joint statement with the Dutch prime minister and head of the European Community Council, Ruud Lubbers, and with the European Commission president, Jacques Delors, pledging closer Japanese – European Community consultations on foreign relations, scientific and technological cooperation, assistance to developing countries, and efforts to reduce trade conflicts. Japanese Ministry of Foreign Affairs officials hoped that this agreement would help to broaden Japanese – European Community political links and raise them above the narrow confines of trade disputes.

Japan has formally issued apologies for its military occupations before and during World War II, but that has done little in helping to improve its relations with its neighbors, especially China, North Korea and South Korea. They still insist that Japan has yet to formally express remorse for its wrongdoings in the 20th century, despite some formal statements of regret from Prime Ministers Hosokawa Morihiro and Murayama Tomiichi. Japan's official stance claims that all war-related reparation claims have been resolved (except with North Korea). Unofficial visits to the controversial Yasukuni Jinja by past Prime Ministers belonging to the Liberal Democratic Party and the exclusion or generalization of some elements of Japan's military history in a number school textbooks have also clouded the issue. In 2004, China and the two Koreas criticized Japan for sending its Ground Self Defence Forces to Iraq, which was seen as signalling a return to militarism. The government of Japan claimed that its forces would only participate in reconstruction and humanitarian aid missions.

As a result, there is a strong anti-Japanese sentiment in China and the two Koreas, although Antagonism is not inevitable. Both Japan and South Korea successfully hosted the 2002 FIFA World Cup, bridging a physical and political gap between the two countries. Additionally, the great popularity in Japan of Bae Yong-joon, a South Korean actor, has also been seen as a sign that the two countries have moved closer together.

Japan has several territorial disputes with its neighbors concerning the control of certain outlying islands.

Japan contests Russia's control of the Southern Kuril Islands (including Etorofu, Kunashiri, Shikotan, and the Habomai group) which were occupied by the Soviet Union in 1945. South Korea's assertions concerning Liancourt Rocks (Japanese: "Takeshima", Korean: "Dokdo") are acknowledged, but not accepted by Japan. Japan has strained relations with the People's Republic of China (PRC) and the Republic of China (Taiwan) over the Senkaku Islands; and with the People's Republic of China over the status of Okinotorishima.

These disputes are in part about irredentism; and they are also about the control of marine and natural resources, such as possible reserves of crude oil and natural gas.





</doc>
<doc id="15587" url="https://en.wikipedia.org/wiki?curid=15587" title="Joshua Jackson">
Joshua Jackson

Joshua Jackson (born June 11, 1978) is a Canadian-American actor. He is known for his starring role as Pacey Witter in the teen drama series "Dawson's Creek" (1998–2003), Peter Bishop in the science fiction series "Fringe" (2008–2013), Cole Lockhart in the drama series "The Affair" (2014–18), and Mickey Joseph in the drama miniseries "When They See Us" (2019).

Jackson's best known films include "The Mighty Ducks" film series (1992–96), "Cruel Intentions" (1999), "The Skulls" (2000), and "Shutter" (2008). For his performance in the Canadian independent film "One Week" (2008), Jackson won the Genie Award for Best Performance by an Actor in a Leading Role.

Jackson was born in Vancouver, British Columbia, to parents John Carter and Fiona Jackson. His mother is a casting director. Jackson's father is from Texas; and his mother is a native of Ballyfermot, Dublin, Ireland, having immigrated to North America in the late 1960s. He has a younger sister, Aisleagh, and two older half brothers, Jonathan and Lyman. He was raised Catholic.

Jackson grew up in California until the age of 8. He moved to Vancouver with his mother and younger sister. He attended Ideal Mini School and later switched to Kitsilano Secondary School. In an interview with "The New York Times", Jackson said he was kicked out of high school once because of "The Jon Stewart Show": "[The show] played, at least where I grew up, at 1:30 in the morning, so I would stay up at night to watch Jon Stewart, but then I'd be too tired—or too lazy—to go to school in the morning. So I'd just take the first couple of classes off, 'cause I wanted to be fresh when I got there." He claims that the first time was because of "attitude" problems and that he "wasn't in the school spirit".

Jackson started acting in a small role in the film "Crooked Hearts" in 1991. The next year, he played the role of Charlie in a musical version of "Willie Wonka and the Chocolate Factory". At this point, with the help of the play's casting director Laura Kennedy, he joined the William Morris Agency. Soon after, he landed the role of Charlie (#96) in "The Mighty Ducks" series, playing a young and aspiring hockey player.

Joshua Jackson went on to appear as Pacey Witter on "Dawson's Creek", which ran on the WB network from 1998–2003, and also starred James Van Der Beek, Michelle Williams and Katie Holmes. While the show was on hiatus, he appeared in several movies including "Cruel Intentions" (a New York yuppie adaptation of "Les Liaisons dangereuses" that also starred Sarah Michelle Gellar and Ryan Phillippe), "The Skulls", "The Safety of Objects", "The Laramie Project" and a short cameo in the remake of "Ocean's Eleven" in which he appears as himself in a poker scene with Brad Pitt, George Clooney and Holly Marie Combs, among others. In 2000, he also guest-starred in Season 12 of "The Simpsons", voicing the character of Jesse Grass, a "hunky environmentalist" and love interest for Lisa Simpson in the episode "Lisa the Tree Hugger".

Shortly after "Dawson's Creek" ended in 2003, Jackson played the lead role in films alongside Dennis Hopper ("Americano"), Harvey Keitel ("Shadows in the Sun"), and Donald Sutherland ("Aurora Borealis"). In 2005, Jackson moved to the UK and made his stage debut on the London West End with Patrick Stewart in David Mamet's two-man play, "A Life in the Theatre". The play was a critical and popular success, and ran from February to April of that year. Jackson said that he would consider returning to the stage, to try his hand on Broadway. His next film role was in "Bobby", directed by Emilio Estevez, Jackson's co-star from "The Mighty Ducks". He played a lead role in "Shutter", a US remake of a Thai horror film of the same name. He starred and acted as executive producer in the Canadian independent film "One Week", which opened on March 6, 2009.

From 2008 to 2013, Jackson played the lead role of Peter Bishop in the science-fiction series "Fringe", created by JJ Abrams, Roberto Orci and Alex Kurtzman. The series appeared on the Fox TV network and was the second-highest rated new show of the 2008–2009 season after CBS's "The Mentalist". BuddyTV ranked him #9 on its "TV's 100 Sexiest Men of 2010" list, #19 in 2011 and #14 in 2012.

Jackson was nominated for Genie Award for Best Performance by an Actor in a Leading Role for the film "One Week". He won the award on April 12, 2010.
He held and hosted Pacey-Con in 2010, directly across the street from the San Diego Comic-Con, sporting a bowling shirt and giving out fan fiction he wrote himself to those waiting in the Comic-Con entrance line. Footage of the event was recorded for a video, entitled 'Pacey-Con', which he was filming for Will Ferrell's Funny or Die celebrity humor website.
In 2013 Jackson appeared in the IFC film "Inescapable" with Marisa Tomei and Alexander Siddig. Jackson wrote the first story from the comic book trilogy "Beyond the Fringe", titled "Peter and the Machine". Jackson starred in the successful Showtime television show, "The Affair", where he played Cole Lockhart, the protagonist husband of the unfaithful Alison Lockhart.

In March 2018, Jackson makes a theatrical debut in Broadway, "Children of a Lesser God", where he plays James Leeds, an unconventional teacher at school for the deaf who got in a conflicted professional and romantic relationship with a former deaf student, Sarah Norman (Lauren Ridloff). The play ran through May 2018.

In 2019, Jackson starred as defense attorney Mickey Joseph in the Netflix drama miniseries "When They See Us".

In May 2019, Jackson joined the cast of Hulu's miniseries "Little Fires Everywhere" based off the book by Celeste Ng.

Jackson was in a relationship with "Dawson's Creek" co-star Katie Holmes during the first two seasons of the show's run. Holmes claims Jackson was her first love.

Jackson began dating German actress Diane Kruger in 2006; the couple shared residences in Paris, Los Angeles and Vancouver. Jackson and Kruger ended their relationship in 2016, after 10 years together. He owns his childhood home in Topanga, California. He previously lived in Wilmington, North Carolina, where "Dawson's Creek" was filmed; and in New York, where "Fringe" filmed its first season. In 2009, he moved back to Vancouver for the shooting of the four following seasons before the show aired its last episode on January 18, 2013.

Jackson has been in a relationship with British model and actress Jodie Turner-Smith since 2018. They married in 2019. The couple are expecting their first child.

Jackson is a fan of the Vancouver Canucks ice hockey team. He was arrested on November 9, 2002, at a Carolina Hurricanes ice hockey game in Raleigh, North Carolina, after a quarrel with a security guard. He was charged with assault, affray, and public intoxication and disruption, having a 0.14 blood alcohol content. Prosecutors agreed to dismiss the assault charge, and Jackson agreed to attend an alcohol education program and perform 24 hours of community service in order to have the remaining charge dropped.



</doc>
<doc id="15588" url="https://en.wikipedia.org/wiki?curid=15588" title="Jung (disambiguation)">
Jung (disambiguation)

Carl Gustav Jung (1875–1961) was the founder of analytical psychology.

Jung may also refer to:



</doc>
<doc id="15593" url="https://en.wikipedia.org/wiki?curid=15593" title="JFK (disambiguation)">
JFK (disambiguation)

JFK are the initials by which John F. Kennedy (1917–1963), the 35th President of the United States, was often referred to.
JFK may also refer to:





</doc>
<doc id="15596" url="https://en.wikipedia.org/wiki?curid=15596" title="John Ray">
John Ray

John Ray FRS (29 November 1627 – 17 January 1705) was an English naturalist widely regarded as one of the earliest of the English parson-naturalists. Until 1670, he wrote his name as John Wray. From then on, he used 'Ray', after "having ascertained that such had been the practice of his family before him". He published important works on botany, zoology, and natural theology. His classification of plants in his "Historia Plantarum", was an important step towards modern taxonomy. Ray rejected the system of dichotomous division by which species were classified according to a pre-conceived, either/or type system , and instead classified plants according to similarities and differences that emerged from observation. He was among the first to attempt a biological definition for the concept of "species".

John Ray was born in the village of Black Notley in Essex. He is said to have been born in the smithy, his father having been the village blacksmith. After studying at Braintree school, he was sent at the age of sixteen to Cambridge University: studying at Trinity College. Initially at Catharine Hall, his tutor was Daniel Duckfield, and later transferred to Trinity where his tutor was James Duport, and his intimate friend and fellow-pupil the celebrated Isaac Barrow. Ray was chosen minor fellow of Trinity in 1649, and later major fellow. He held many college offices, becoming successively lecturer in Greek (1651), mathematics (1653), and humanity (1655), "praelector" (1657), frias (1657), and college steward (1659 and 1660); and according to the habit of the time, he was accustomed to preach in his college chapel and also at Great St Mary's, long before he took holy orders on 23 December 1660. Among these sermons were his discourses on "The wisdom of God manifested in the works of the creation", and "Deluge and Dissolution of the World". Ray was also highly regarded as a tutor and he communicated his own passion for natural history to several pupils. Ray's student, Isaac Barrow, helped Francis Willughby learn mathematics and the Ray collaborated with Willughby later. It was at Trinity that he came under the influence of John Wilkins, when the latter was appointed master of the college in 1659. 

After leaving Cambridge in 1662 he spent some time travelling both in Britain and the continent. In 1673, Ray married Margaret Oakley of Launton in Oxfordshire; in 1676 he went to Middleton Hall near Tamworth, and in 1677 to Falborne (or Faulkbourne) Hall in Essex. Finally, in 1679, he removed to his birthplace at Black Notley, where he afterwards remained. His life there was quiet and uneventful, although he had poor health, including chronic sores. Ray kept writing books and corresponded widely on scientific matters, collaborating with his doctor and contemporary Samuel Dale. He lived, in spite of his infirmities, to the age of seventy-seven, dying at Black Notley. He is buried in the churchyard of St Peter and St Paul where there is a memorial to him. He is widely regarded as one of the earliest of the English parson-naturalists.

At Cambridge, Ray spent much of his time in the study of natural history, a subject which would occupy him for most of his life, from 1660 to the beginning of the eighteenth century. When Ray found himself unable to subscribe as required by the ‘Bartholomew Act’ of 1662 he, along with 13 other college fellows, resigned his fellowship on 24 August 1662 rather than swear to the declaration that the Solemn League and Covenant was not binding on those who had taken it. Tobias Smollett quoted the reasoning given in the biography of Ray by William Derham:
"The reason of his refusal was not (says his biographer) as some have imagined, his having taken the solemn league and covenant; for that he never did, and often declared that he ever thought it an unlawful oath: but he said he could not say, for those that had taken the oath, that no obligation lay upon them, but feared there might."
His religious views were generally in accord with those imposed under the restoration of Charles II of England, and (though technically a nonconformist) he continued as a layman in the Established Church of England.

From this time onwards he seems to have depended chiefly on the bounty of his pupil Francis Willughby, who made Ray his constant companion while he lived. Willughby arranged that after his death, Ray would have 6 shillings a year for educating Willughby's two sons.

In the spring of 1663 Ray started together with Willughby and two other pupils (Philip Skippon and Nathaniel Bacon) on a tour through Europe, from which he returned in March 1666, parting from Willughby at Montpellier, whence the latter continued his journey into Spain. He had previously in three different journeys (1658, 1661, 1662) travelled through the greater part of Great Britain, and selections from his private notes of these journeys were edited by George Scott in 1760, under the title of "Mr Ray's Itineraries". Ray himself published an account of his foreign travel in 1673, entitled "Observations topographical, moral, and physiological, made on a Journey through part of the Low Countries, Germany, Italy, and France". From this tour Ray and Willughby returned laden with collections, on which they meant to base complete systematic descriptions of the animal and vegetable kingdoms. Willughby undertook the former part, but, dying in 1672, left only an ornithology and ichthyology for Ray to edit; while Ray used the botanical collections for the groundwork of his "Methodus plantarum nova" (1682), and his great "Historia generalis plantarum" (3 vols., 1686, 1688, 1704). The plants gathered on his British tours had already been described in his "Catalogus plantarum Angliae" (1670), which formed the basis for later English floras.

In 1667 Ray was elected Fellow of the Royal Society, and in 1669 he and Willughby published a paper on "Experiments concerning the Motion of Sap in Trees". In 1671, he presented the research of Francis Jessop on formic acid to the Royal Society.

In the 1690s, he published three volumes on religion—the most popular being "The Wisdom of God Manifested in the Works of the Creation" (1691), an essay describing evidence that all in nature and space is God's creation as in Bible is affirmed. In this volume, he moved on from the naming and cataloguing of species like his successor Carl Linnaeus. Instead, Ray considered species' lives and how nature worked as a whole, giving facts that are arguments for God's will expressed in His creation of all 'visible and invisible' (Colossians 1:16).
Ray gave an early description of dendrochronology, explaining for the ash tree how to find its age from its tree-rings.

Ray's work on plant taxonomy spanned a wide range of thought, starting with an approach that was predominantly in the tradition of the herbalists and Aristotelian, but becoming increasingly theoretical and finally rejecting Aristotelianism. Despite his early adherence to Aristotelian tradition, his first botanical work, the "Catalogus plantarum circa Cantabrigiam nascentium" (1660), was almost entirely descriptive, being arranged alphabetically. His model was an account by Bauhin of the plants growing around Basel in 1622 and was the first English county flora, covering about 630 species. However at the end of the work he appended a brief taxonomy which he stated followed the usage Bauhin and other herbalists. 

Ray's system, starting with his Cambridge catalogue, began with the division between the imperfect or lower plants (Cryptogams), and perfect ("planta perfecta") higher plants (Seed plants). The latter he divided by life forms, e.g. trees ("arbores"), shrubs ("frutices"), subshrubs ("suffrutices") and herbaceous plants ("herbae") and lastly grouping them by common characteristics. The trees he divided into 8 groups, e.g. "Pomiferae" (including apple and pear). The shrubs he placed in 2 groups, "Spinosi" (Berberis etc.) and "Non Spinosi" (Jasmine etc.). The subshrubs formed a single group and the herbs into 21 groups.

Division of Herbae;


As outlined in his "Historia Plantarum" (1685–1703):

Ray was the first person to produce a biological definition of species, in his 1686 "History of Plants":

Ray published about 23 works, depending on how they are counted. The biological works were usually in Latin, the rest in English. His first publication, while at Cambridge, was the "Catalogus plantarum circa Cantabrigiam nascentium" (1660), followed by many works, botanical, zoological,theological and literary. Until 1670, he wrote his name as John Wray. From then on, he used 'Ray', after "having ascertained that such had been the practice of his family before him".



Including the various editions, there are 172 works of Ray, of which most are rare. The only libraries with substantial holdings are all in England. The list in order of holdings is:

Ray's biographer, Charles Raven, commented that "Ray sweeps away the litter of mythology and fable... and always insists upon accuracy of observation and description and the testing of every new discovery". Ray's works were directly influential on the development of taxonomy by Carl Linnaeus.

The Ray Society, named after John Ray, was founded in 1844. It is a scientific text publication society and registered charity, based at the Natural History Museum, London, which exists to publish books on natural history, with particular (but not exclusive) reference to the flora and fauna of the British Isles. As of 2017, the Society had published 179 volumes. 

The John Ray Society (a separate organisation) is the Natural Sciences Society at St Catharine's College, Cambridge. It organises a programme of events of interest to science students in the college. 

In 1986, to mark the 300th anniversary of the publication of Ray's "Historia Plantarum", there was a celebration of Ray's legacy in Braintree, Essex. A "John Ray Gallery" was opened in the Braintree Museum.

The John Ray Initiative (JRI) is an educational charity that seeks to reconcile scientific and Christian understandings of the environment. It was formed in 1997 in response to the global environmental crisis and the challenges of sustainable development and environmental stewardship. John Ray's writings proclaimed God as creator whose wisdom is "manifest in the works of creation", and as redeemer of all things. JRI aims to teach appreciation of nature, increase awareness of the state of the global environment, and to promote a Christian understanding of environmental issues.







</doc>
<doc id="15600" url="https://en.wikipedia.org/wiki?curid=15600" title="James Joyce">
James Joyce

James Augustine Aloysius Joyce (2 February 1882 – 13 January 1941) was an Irish novelist, short story writer, poet, teacher, and literary critic. He contributed to the modernist avant-garde and is regarded as one of the most influential and important authors of the 20th century. Joyce is best known for "Ulysses" (1922), a landmark work in which the episodes of Homer's "Odyssey" are paralleled in a variety of literary styles, most famously stream of consciousness. Other well-known works are the short-story collection "Dubliners" (1914), and the novels "A Portrait of the Artist as a Young Man" (1916) and "Finnegans Wake" (1939). His other writings include three books of poetry, a play, his published letters and occasional journalism.

Joyce was born in Dublin into a middle-class family. A brilliant student, he briefly attended the Christian Brothers-run O'Connell School before excelling at the Jesuit schools Clongowes and Belvedere, despite the chaotic family life imposed by his father's unpredictable finances. He went on to attend University College Dublin.

In 1904, in his early twenties, Joyce emigrated to continental Europe with his partner (and later wife) Nora Barnacle. They lived in Trieste, Paris, and Zürich. Although most of his adult life was spent abroad, Joyce's fictional universe centres on Dublin and is populated largely by characters who closely resemble family members, enemies and friends from his time there. "Ulysses" in particular is set with precision in the streets and alleyways of the city. Shortly after the publication of "Ulysses", he elucidated this preoccupation somewhat, saying, "For myself, I always write about Dublin, because if I can get to the heart of Dublin I can get to the heart of all the cities of the world. In the particular is contained the universal."

On 2 February 1882, Joyce was born at 41 Brighton Square, Rathgar, Dublin, Ireland. Joyce's father was John Stanislaus Joyce and his mother was Mary Jane "May" Murray. He was the eldest of ten surviving siblings; two died of typhoid. James was baptised according to the Rites of the Catholic Church in the nearby St Joseph's Church in Terenure on 5 February 1882 by Rev. John O'Mulloy. Joyce's godparents were Philip and Ellen McCann.

John Stanislaus Joyce's family came from Fermoy in County Cork, and had owned a small salt and lime works. Joyce's paternal grandfather, James Augustine Joyce, married Ellen O'Connell, daughter of John O'Connell, a Cork Alderman who owned a drapery business and other properties in Cork City. Ellen's family claimed kinship with Daniel O'Connell, "The Liberator". The Joyce family's purported ancestor, Seán Mór Seoighe (fl. 1680) was a stonemason from Connemara.

In 1887, his father was appointed rate collector by Dublin Corporation; the family subsequently moved to the fashionable adjacent small town of Bray, from Dublin. Around this time Joyce was attacked by a dog, leading to his lifelong cynophobia. He suffered from astraphobia; a superstitious aunt had described thunderstorms as a sign of God's wrath.

In 1891 Joyce wrote a poem on the death of Charles Stewart Parnell. His father was angry at the treatment of Parnell by the Catholic Church, the Irish Home Rule Party and the British Liberal Party and the resulting collaborative failure to secure Home Rule for Ireland. The Irish Party had dropped Parnell from leadership. But the Vatican's role in allying with the British Conservative Party to prevent Home Rule left a lasting impression on the young Joyce. The elder Joyce had the poem printed and even sent a part to the Vatican Library. In November, John Joyce was entered in "Stubbs' Gazette" (a publisher of bankruptcies) and suspended from work. In 1893, John Joyce was dismissed with a pension, beginning the family's slide into poverty caused mainly by his drinking and financial mismanagement.

Joyce had begun his education at Clongowes Wood College, a Jesuit boarding school near Clane, County Kildare, in 1888 but had to leave in 1892 when his father could no longer pay the fees. Joyce then studied at home and briefly at the Christian Brothers O'Connell School on North Richmond Street, Dublin, before he was offered a place in the Jesuits' Dublin school, Belvedere College, in 1893. This came about because of a chance meeting his father had with a Jesuit priest called John Conmee who knew the family and Joyce was given a reduction in fees to attend Belvedere. In 1895, Joyce, now aged 13, was elected to join the Sodality of Our Lady by his peers at Belvedere. The philosophy of Thomas Aquinas continued to have a strong influence on him for most of his life.

Joyce enrolled at the recently established University College Dublin (UCD) in 1898, studying English, French and Italian. He became active in theatrical and literary circles in the city. In 1900 his laudatory review of Henrik Ibsen's "When We Dead Awaken" was published in "The Fortnightly Review"; it was his first publication and, after learning basic Norwegian to send a fan letter to Ibsen, he received a letter of thanks from the dramatist. Joyce wrote a number of other articles and at least two plays (since lost) during this period. Many of the friends he made at University College Dublin appeared as characters in Joyce's works. His closest colleagues included leading figures of the generation, most notably, Tom Kettle, Francis Sheehy-Skeffington and Oliver St. John Gogarty. Joyce was first introduced to the Irish public by Arthur Griffith in his newspaper, "United Irishman", in November 1901. Joyce had written an article on the Irish Literary Theatre and his college magazine refused to print it. Joyce had it printed and distributed locally. Griffith himself wrote a piece decrying the censorship of the student James Joyce. In 1901, the National Census of Ireland lists James Joyce (19) as an English- and Irish-speaking scholar living with his mother and father, six sisters and three brothers at Royal Terrace (now Inverness Road), Clontarf, Dublin.

After graduating from UCD in 1902, Joyce left for Paris to study medicine, but he soon abandoned this. Richard Ellmann suggests that this may have been because he found the technical lectures in French too difficult. Joyce had already failed to pass chemistry in English in Dublin. But Joyce claimed ill health as the problem and wrote home that he was unwell and complained about the cold weather. He stayed on for a few months, appealing for finance his family could ill-afford and reading late in the Bibliothèque Sainte-Geneviève. When his mother was diagnosed with cancer, his father sent a telegram which read, "NOTHER DYING COME HOME FATHER". Joyce returned to Ireland. Fearing for her son's impiety, his mother tried unsuccessfully to get Joyce to make his confession and to take communion. She finally passed into a coma and died on 13 August, James and his brother Stanislaus having refused to kneel with other members of the family praying at her bedside. After her death he continued to drink heavily, and conditions at home grew quite appalling. He scraped together a living reviewing books, teaching, and singing—he was an accomplished tenor, and won the bronze medal in the 1904 Feis Ceoil.

On 7 January 1904, Joyce attempted to publish "A Portrait of the Artist", an essay-story dealing with aesthetics, only to have it rejected by the free-thinking magazine "Dana". He decided, on his twenty-second birthday, to revise the story into a novel he called "Stephen Hero". It was a fictional rendering of Joyce's youth, but he eventually grew frustrated with its direction and abandoned this work. It was never published in this form, but years later, in Trieste, Joyce completely rewrote it as "A Portrait of the Artist as a Young Man". The unfinished "Stephen Hero" was published after his death.

Also in 1904, he met Nora Barnacle, a young woman from Galway city who was working as a chambermaid. On 16 June 1904 they had their first outing together, walking to the Dublin suburb of Ringsend, where Nora masturbated him. This event was commemorated by providing the date for the action of "Ulysses" (as "Bloomsday").

Joyce remained in Dublin for some time longer, drinking heavily. After one of his drinking binges, he got into a fight over a misunderstanding with a man in St Stephen's Green; he was picked up and dusted off by a minor acquaintance of his father, Alfred H. Hunter, who took him into his home to tend to his injuries. Hunter was rumoured to be a Jew and to have an unfaithful wife and would serve as one of the models for Leopold Bloom, the protagonist of "Ulysses". He took up with the medical student Oliver St. John Gogarty, who informed the character for Buck Mulligan in "Ulysses". After six nights in the Martello Tower that Gogarty was renting in Sandycove, he left in the middle of the night following an altercation which involved another student he lived with, the unstable Dermot Chenevix Trench (Haines in "Ulysses"), who fired a pistol at some pans hanging directly over Joyce's bed. Joyce walked the back to Dublin to stay with relatives for the night, and sent a friend to the tower the next day to pack his trunk. Shortly after, the couple left Ireland to live on the continent.

Joyce and Nora went into self-imposed exile, moving first to Zürich in Switzerland, where he ostensibly taught English at the Berlitz Language School through an agent in England. It later became evident that the agent had been swindled; the director of the school sent Joyce on to Trieste, which was then part of Austria-Hungary (until the First World War), and is today part of Italy. Once again, he found there was no position for him, but with the help of Almidano Artifoni, director of the Trieste Berlitz School, he finally secured a teaching position in Pola, then also part of Austria-Hungary (today part of Croatia). He stayed there, teaching English mainly to Austro-Hungarian naval officers stationed at the Pola base, from October 1904 until March 1905, when the Austrians—having discovered an espionage ring in the city—expelled all aliens. With Artifoni's help, he moved back to Trieste and began teaching English there. He remained in Trieste for most of the next ten years.

Later that year Nora gave birth to their first child, George (known as Giorgio). Joyce persuaded his brother, Stanislaus, to join him in Trieste, and secured a teaching position for him at the school. Joyce sought to augment his family's meagre income with his brother's earnings. Stanislaus and Joyce had strained relations while they lived together in Trieste, arguing about Joyce's drinking habits and frivolity with money.

Joyce became frustrated with life in Trieste and moved to Rome in late 1906, taking employment as a clerk in a bank. He disliked Rome and returned to Trieste in early 1907. His daughter Lucia was born later that year.

Joyce returned to Dublin in mid-1909 with George, to visit his father and work on getting "Dubliners" published. He visited Nora's family in Galway and liked Nora's mother very much. While preparing to return to Trieste he decided to take one of his sisters, Eva, back with him to help Nora run the home. He spent a month in Trieste before returning to Dublin, this time as a representative of some cinema owners and businessmen from Trieste. With their backing he launched Ireland's first cinema, the Volta Cinematograph, which was well-received, but fell apart after Joyce left. He returned to Trieste in January 1910 with another sister, Eileen, in tow. Eva became homesick for Dublin and returned there a few years later, but Eileen spent the rest of her life on the continent, eventually marrying the Czech bank cashier Frantisek Schaurek.

Joyce returned to Dublin again briefly in mid-1912 during his years-long fight with Dublin publisher George Roberts over the publication of "Dubliners". His trip was once again fruitless, and on his return he wrote the poem "Gas from a Burner", an invective against Roberts. After this trip, he never again came closer to Dublin than London, despite many pleas from his father and invitations from his fellow Irish writer William Butler Yeats.

One of his students in Trieste was Ettore Schmitz, better known by the pseudonym Italo Svevo. They met in 1907 and became lasting friends and mutual critics. Schmitz was a Catholic of Jewish origin and became a primary model for Leopold Bloom; most of the details about the Jewish faith in "Ulysses" came from Schmitz's responses to queries from Joyce. While living in Trieste, Joyce was first beset with eye problems that ultimately required over a dozen surgical operations.

Joyce concocted a number of money-making schemes during this period, including an attempt to become a cinema magnate in Dublin. He frequently discussed but ultimately abandoned a plan to import Irish tweed to Trieste. Correspondence relating to that venture with the Irish Woollen Mills were for a long time displayed in the windows of their premises in Dublin. Joyce's skill at borrowing money saved him from indigence. What income he had came partially from his position at the Berlitz school and partially from teaching private students.

In 1915, after most of his students in Trieste were conscripted to fight in the First World War, Joyce moved to Zürich. Two influential private students, Baron Ambrogio Ralli and Count Francesco Sordina, petitioned officials for an exit permit for the Joyces, who in turn agreed not to take any action against the emperor of Austria-Hungary during the war.

During this period Joyce took an active interest in socialism. He had attended socialist meetings when he was still in Dublin and 1905, while in Trieste, he described his politics as "those of a socialist artist." Although his practical engagement waned after 1907 due to the "endless internecine warfare" he observed in socialist organizations, many Joyce scholars such as Richard Ellmann, Dominic Manganiello, Robert Scholes, and George J. Watson agree that Joyce's interest in socialism and pacifistic anarchism continued for much of his life, and that both the form and content of Joyce's work reflect a sympathy for democratic and socialist ideas. In 1918 he declared himself "against every state" and found much succor in the individualist philosophies of Benjamin Tucker and Oscar Wilde's "The Soul of Man Under Socialism".

Joyce set himself to finishing "Ulysses" in Paris, delighted to find that he was gradually gaining fame as an avant-garde writer. A further grant from Harriet Shaw Weaver meant he could devote himself full-time to writing again, as well as consort with other literary figures in the city. During this time, Joyce's eyes began to give him more and more problems and he often wore an eyepatch. He was treated by Louis Borsch in Paris, undergoing nine operations before Borsch's death in 1929. Throughout the 1930s he travelled frequently to Switzerland for eye surgeries and for treatments for his daughter Lucia, who, according to the Joyces, suffered from schizophrenia. Lucia was analysed by Carl Jung at the time, who after reading "Ulysses" is said to have concluded that her father had schizophrenia. Jung said that she and her father were two people heading to the bottom of a river, except that Joyce was diving and Lucia was sinking.

In Paris, Maria and Eugene Jolas nursed Joyce during his long years of writing "Finnegans Wake". Were it not for their support (along with Harriet Shaw Weaver's constant financial support), there is a good possibility that his books might never have been finished or published. In their literary magazine "transition", the Jolases published serially various sections of "Finnegans Wake" under the title "Work in Progress". Joyce returned to Zürich in late 1940, fleeing the Nazi occupation of France. Joyce used his contacts to help some sixteen Jews escape Nazi persecution.

The issue of Joyce's relationship with religion is somewhat controversial. Early in life, he lapsed from Catholicism, according to first-hand testimonies coming from himself, his brother Stanislaus Joyce, and his wife:

My mind rejects the whole present social order and Christianity—home, the recognised virtues, classes of life and religious doctrines. ... Six years ago I left the Catholic church, hating it most fervently. I found it impossible for me to remain in it on account of the impulses of my nature. I made secret war upon it when I was a student and declined to accept the positions it offered me. By doing this I made myself a beggar but I retained my pride. Now I make open war upon it by what I write and say and do.

When the arrangements for Joyce's burial were being made, a Catholic priest offered a religious service, which Joyce's wife, Nora, declined, saying, "I couldn't do that to him."

Leonard Strong, William T. Noon, Robert Boyle and others have argued that Joyce, later in life, reconciled with the faith he rejected earlier in life and that his parting with the faith was succeeded by a not so obvious reunion, and that "Ulysses" and "Finnegans Wake" are essentially Catholic expressions. Likewise, Hugh Kenner and T.S. Eliot believed they saw between the lines of Joyce's work the outlook of a serious Christian and that beneath the veneer of the work lies a remnant of Catholic belief and attitude. Kevin Sullivan maintains that, rather than reconciling with the faith, Joyce never left it. Critics holding this view insist that Stephen, the protagonist of the semi-autobiographical "A Portrait of the Artist as a Young Man" as well as "Ulysses", is not Joyce. Somewhat cryptically, in an interview after completing Ulysses, in response to the question "When did you leave the Catholic Church", Joyce answered, "That's for the Church to say." Eamonn Hughes maintains that Joyce takes a dialectic approach, both affirming and denying, saying that Stephen's much noted "non-serviam" is qualified—"I will not serve "that which I no longer believe"...", and that the "non-serviam" will always be balanced by Stephen's "I am a servant..." and Molly's "yes". He attended Catholic Mass and Orthodox Divine Liturgy, especially during Holy Week, purportedly for aesthetic reasons. His sisters noted his Holy Week attendance and that he did not seek to dissuade them. One friend witnessed him cry "secret tears" upon hearing Jesus' words on the cross and another accused him of being a "believer at heart" because of his frequent attendance at church.

Umberto Eco compares Joyce to the ancient "episcopi vagantes" (wandering bishops) in the Middle Ages. They left a discipline, not a cultural heritage or a way of thinking. Like them, the writer retains the sense of blasphemy held as a liturgical ritual.

Some critics and biographers have opined along the lines of Andrew Gibson: "The modern James Joyce may have vigorously resisted the oppressive power of Catholic tradition. But there was another Joyce who asserted his allegiance to that tradition, and never left it, or wanted to leave it, behind him." Gibson argues that Joyce "remained a Catholic intellectual if not a believer" since his thinking remained influenced by his cultural background, even though he lived apart from that culture. His relationship with religion was complex and not easily understood, even perhaps by himself. He acknowledged the debt he owed to his early Jesuit training. Joyce told the sculptor August Suter, that from his Jesuit education, he had 'learnt to arrange things in such a way that they become easy to survey and to judge.'

On 11 January 1941, Joyce underwent surgery in Zürich for a perforated duodenal ulcer. He fell into a coma the following day. He awoke at 2 a.m. on 13 January 1941, and asked a nurse to call his wife and son, before losing consciousness again. They were en route when he died 15 minutes later. Joyce was less than a month short of his 59th birthday.

His body was buried in the Fluntern Cemetery, Zürich. The Swiss tenor Max Meili sang "Addio terra, addio cielo" from Monteverdi's "L'Orfeo" at the burial service. Although two senior Irish diplomats were in Switzerland at the time, neither attended Joyce's funeral, and the Irish government later declined Nora's offer to permit the repatriation of Joyce's remains. When Joseph Walshe, secretary at the Department of External Affairs in Dublin, was informed of Joyce's death by Frank Cremins, "chargé d'affaires" at Bern, Walshe responded "Please wire details of Joyce's death. If possible find out did he die a Catholic? Express sympathy with Mrs Joyce and explain inability to attend funeral". Buried originally in an ordinary grave, Joyce was moved in 1966 to a more prominent "honour grave," with a seated portrait statue by American artist Milton Hebald nearby. Nora, whom he had married in 1931, survived him by 10 years. She is buried by his side, as is their son Giorgio, who died in 1976.

In October 2019 a motion was put to Dublin City Council to plan and budget for the costs of the exhumations and reburials of Joyce and his family somewhere in Dublin, subject to his family's wishes. The proposal immediately became controversial, with the Irish Times commenting: '.. it is hard not to suspect that there is a calculating, even mercantile, aspect to contemporary Ireland’s relationship to its great writers, whom we are often more keen to “celebrate”, and if possible monetise, than read'.

"Dubliners" is a collection of fifteen short stories by Joyce, first published in 1914. They form a naturalistic depiction of Irish middle-class life in and around Dublin in the early years of the 20th century.

The stories were written when Irish nationalism was at its peak and a search for a national identity and purpose was raging; at a crossroads of history and culture, Ireland was jolted by converging ideas and influences. The stories centre on Joyce's idea of an epiphany: a moment when a character experiences a life-changing self-understanding or illumination. Many of the characters in "Dubliners" later appear in minor roles in Joyce's novel "Ulysses". The initial stories in the collection are narrated by child protagonists. Subsequent stories deal with the lives and concerns of progressively older people. This aligns with Joyce's tripartite division of the collection into childhood, adolescence and maturity.

"A Portrait of the Artist as a Young Man" is a nearly complete rewrite of the abandoned novel "Stephen Hero". Joyce attempted to burn the original manuscript in a fit of rage during an argument with Nora, though to his subsequent relief it was rescued by his sister. A "Künstlerroman", "Portrait" is a heavily autobiographical coming-of-age novel depicting the childhood and adolescence of the protagonist Stephen Dedalus and his gradual growth into artistic self-consciousness. Some hints of the techniques Joyce frequently employed in later works, such as stream of consciousness, interior monologue, and references to a character's psychic reality rather than to his external surroundings are evident throughout this novel.

Despite early interest in the theatre, Joyce published only one play, "Exiles", begun shortly after the outbreak of the First World War in 1914 and published in 1918. A study of a husband-and-wife relationship, the play looks back to "The Dead" (the final story in "Dubliners") and forward to "Ulysses", which Joyce began around the time of the play's composition.

Joyce published a number of books of poetry. His first mature published work was the satirical broadside "The Holy Office" (1904), in which he proclaimed himself to be the superior of many prominent members of the Celtic Revival. His first full-length poetry collection, "Chamber Music" (1907; referring, Joyce joked, to the sound of urine hitting the side of a chamber pot), consisted of 36 short lyrics. This publication led to his inclusion in the "Imagist Anthology", edited by Ezra Pound, who was a champion of Joyce's work. Other poetry Joyce published in his lifetime include "Gas from a Burner" (1912), "Pomes Penyeach" (1927) and "Ecce Puer" (written in 1932 to mark the birth of his grandson and the recent death of his father). It was published by the Black Sun Press in "Collected Poems" (1936).

As he was completing work on "Dubliners" in 1906, Joyce considered adding another story featuring a Jewish advertising canvasser called Leopold Bloom under the title "Ulysses". Although he did not pursue the idea further at the time, he eventually commenced work on a novel using both the title and basic premise in 1914. The writing was completed in October 1921. Three more months were devoted to working on the proofs of the book before Joyce halted work shortly before his self-imposed deadline, his 40th birthday (2 February 1922).

Thanks to Ezra Pound, serial publication of the novel in the magazine "The Little Review" began in March 1918. This magazine was edited by Margaret C. Anderson and Jane Heap, with the intermittent financial backing of John Quinn, a successful New York commercial lawyer with an interest in contemporary experimental art and literature.

This provoked the first accusations of obscenity with which the book would be identified for so long. Its amorphous structure with frank, intimate musings (‘stream of consciousness’) were seen to offend both church and state. The publication encountered problems with New York Postal Authorities; serialisation ground to a halt in December 1920; the editors were convicted of publishing obscenity in February 1921. Although the conviction was based on the "Nausicaä" episode of "Ulysses", "The Little Review" had fuelled the fires of controversy with dada poet Elsa von Freytag-Loringhoven's defence of "Ulysses" in an essay "The Modest Woman." Joyce's novel was not published in the United States until 1934.

Partly because of this controversy, Joyce found it difficult to get a publisher to accept the book, but it was published in 1922 by Sylvia Beach from her well-known Rive Gauche bookshop, "Shakespeare and Company". An English edition published the same year by Joyce's patron, Harriet Shaw Weaver, ran into further difficulties with the United States authorities, and 500 copies that were shipped to the States were seized and possibly destroyed. The following year, John Rodker produced a print run of 500 more intended to replace the missing copies, but these were burned by English customs at Folkestone. A further consequence of the novel's ambiguous legal status as a banned book was that a number of "bootleg" versions appeared, most notably a number of pirate versions from the publisher Samuel Roth. In 1928, a court injunction against Roth was obtained and he ceased publication.

With the appearance of both "Ulysses" and T.S. Eliot's poem, "The Waste Land", 1922 was a key year in the history of English-language literary modernism. In "Ulysses", Joyce employs stream of consciousness, parody, jokes, and virtually every other literary technique to present his characters. The action of the novel, which takes place in a single day, 16 June 1904, sets the characters and incidents of the Odyssey of Homer in modern Dublin and represents Odysseus (Ulysses), Penelope and Telemachus in the characters of Leopold Bloom, his wife Molly Bloom and Stephen Dedalus, parodically contrasted with their lofty models. The book explores various areas of Dublin life, dwelling on its squalor and monotony. Nevertheless, the book is also an affectionately detailed study of the city, and Joyce claimed that if Dublin were to be destroyed in some catastrophe it could be rebuilt, brick by brick, using his work as a model. In order to achieve this level of accuracy, Joyce used the 1904 edition of Thom's Directory—a work that listed the owners and/or tenants of every residential and commercial property in the city. He also bombarded friends still living there with requests for information and clarification.

The book consists of 18 chapters, each covering roughly one hour of the day, beginning around about 8 a.m. and ending sometime after 2 a.m. the following morning. Each of the 18 chapters of the novel employs its own literary style. Each chapter also refers to a specific episode in Homer's Odyssey and has a specific colour, art or science and bodily organ associated with it. This combination of kaleidoscopic writing with an extreme formal, schematic structure represents one of the book's major contributions to the development of 20th century modernist literature. Other contributions include the use of classical mythology as a framework for his book and the near-obsessive focus on external detail in a book in which much of the significant action is happening inside the minds of the characters. Nevertheless, Joyce complained that, "I may have oversystematised "Ulysses"," and played down the mythic correspondences by eliminating the chapter titles that had been taken from Homer. Joyce was reluctant to publish the chapter titles because he wanted his work to stand separately from the Greek form. It was only when Stuart Gilbert published his critical work on "Ulysses" in 1930 that the schema was supplied by Joyce to Gilbert. But as Terrence Killeen points out this schema was developed after the novel had been written and was not something that Joyce consulted as he wrote the novel.

Having completed work on "Ulysses", Joyce was so exhausted that he did not write a line of prose for a year. On 10 March 1923 he informed his patron, Harriet Shaw Weaver: "Yesterday I wrote two pages—the first I have since the final "Yes" of "Ulysses". Having found a pen, with some difficulty I copied them out in a large handwriting on a double sheet of foolscap so that I could read them. "Il lupo perde il pelo ma non il vizio", the Italians say. 'The wolf may lose his skin but not his vice' or 'the leopard cannot change his spots.'" Thus was born a text that became known, first, as "Work in Progress" and later "Finnegans Wake".

By 1926 Joyce had completed the first two parts of the book. In that year, he met Eugene and Maria Jolas who offered to serialise the book in their magazine "transition". For the next few years, Joyce worked rapidly on the new book, but in the 1930s, progress slowed considerably. This was due to a number of factors, including the death of his father in 1931, concern over the mental health of his daughter Lucia, and his own health problems, including failing eyesight. Much of the work was done with the assistance of younger admirers, including Samuel Beckett. For some years, Joyce nursed the eccentric plan of turning over the book to his friend James Stephens to complete, on the grounds that Stephens was born in the same hospital as Joyce exactly one week later, and shared the first name of both Joyce and of Joyce's fictional alter-ego, an example of Joyce's superstitions.

Reaction to the work was mixed, including negative comment from early supporters of Joyce's work, such as Pound and the author's brother, Stanislaus Joyce. To counteract this hostile reception, a book of essays by supporters of the new work, including Beckett, William Carlos Williams and others was organised and published in 1929 under the title "Our Exagmination Round His Factification for Incamination of Work in Progress". At his 57th birthday party at the Jolases' home, Joyce revealed the final title of the work and "Finnegans Wake" was published in book form on 4 May 1939. Later, further negative comments surfaced from doctor and author Hervey Cleckley, who questioned the significance others had placed on the work. In his book "The Mask of Sanity", Cleckley refers to "Finnegans Wake" as "a 628-page collection of erudite gibberish indistinguishable to most people from the familiar word salad produced by hebephrenic patients on the back wards of any state hospital."

Joyce's method of stream of consciousness, literary allusions and free dream associations was pushed to the limit in "Finnegans Wake", which abandoned all conventions of plot and character construction and is written in a peculiar and obscure English, based mainly on complex multi-level puns. This approach is similar to, but far more extensive than that used by Lewis Carroll in "Jabberwocky". This has led many readers and critics to apply Joyce's oft-quoted description in the "Wake" of "Ulysses" as his "usylessly unreadable Blue Book of Eccles" to the "Wake" itself. However, readers have been able to reach a consensus about the central cast of characters and general plot.

Much of the wordplay in the book stems from the use of multilingual puns which draw on a wide range of languages. The role played by Beckett and other assistants included collating words from these languages on cards for Joyce to use and, as Joyce's eyesight worsened, of writing the text from the author's dictation.

The view of history propounded in this text is very strongly influenced by Giambattista Vico, and the metaphysics of Giordano Bruno of Nola are important to the interplay of the "characters". Vico propounded a cyclical view of history, in which civilisation rose from chaos, passed through theocratic, aristocratic, and democratic phases, and then lapsed back into chaos. The most obvious example of the influence of Vico's cyclical theory of history is to be found in the opening and closing words of the book. "Finnegans Wake" opens with the words "riverrun, past Eve and Adam's, from swerve of shore to bend of bay, brings us by a commodius vicus of recirculation back to Howth Castle and Environs" ("vicus" is a pun on Vico) and ends "A way a lone a last a loved a long the". In other words, the book ends with the beginning of a sentence and begins with the end of the same sentence, turning the book into one great cycle. Indeed, Joyce said that the ideal reader of the "Wake" would suffer from "ideal insomnia" and, on completing the book, would turn to page one and start again, and so on in an endless cycle of reading.

Joyce's work has been an important influence on writers and scholars such as Samuel Beckett, Seán Ó Ríordáin, Jorge Luis Borges, Flann O'Brien, Salman Rushdie, Robert Anton Wilson, John Updike, David Lodge, Cormac McCarthy, and Joseph Campbell. "Ulysses" has been called "a demonstration and summation of the entire [Modernist] movement". The Bulgarian-French literary theorist Julia Kristeva characterised Joyce's novel writing as "polyphonic" and a hallmark of postmodernity alongside the poets Mallarmé and Rimbaud.
Some scholars, notably Vladimir Nabokov, have reservations, often championing some of his fiction while condemning other works. In Nabokov's opinion, "Ulysses" was brilliant, while "Finnegans Wake" was horrible.

Joyce's influence is also evident in fields other than literature. The sentence "Three quarks for Muster Mark!" in Joyce's "Finnegans Wake" is the source of the word "quark", the name of one of the elementary particles proposed by the physicist Murray Gell-Mann in 1963.

The work and life of Joyce is celebrated annually on 16 June, known as Bloomsday, in Dublin and in an increasing number of cities worldwide, and critical studies in scholarly publications, such as the "James Joyce Quarterly", continue. Both popular and academic uses of Joyce's work were hampered by restrictions imposed by Stephen J. Joyce, Joyce's grandson and executor of his literary estate. On 1 January 2012, those restrictions were lessened by the expiry of copyright protection of much of the published work of James Joyce.

In April 2013 the Central Bank of Ireland issued a silver €10 commemorative coin in honour of Joyce that misquoted a famous line from "Ulysses".




Fiction

Non-Fiction


Joyce Papers, National Library of Ireland

Electronic editions

Resources


</doc>
<doc id="15601" url="https://en.wikipedia.org/wiki?curid=15601" title="Judo">
Judo

The philosophy and subsequent pedagogy developed for judo became the model for other modern Japanese martial arts that developed from . Judo also spawned a number of derivative martial arts across the world, such as Brazilian jiu-jitsu, Krav Maga and Sambo.

The early history of judo is inseparable from its founder, Japanese polymath and educator , born . Kano was born into a relatively affluent family. His father, Jirosaku, was the second son of the head priest of the Shinto Hiyoshi shrine in Shiga Prefecture. He married Sadako Kano, daughter of the owner of Kiku-Masamune sake brewing company and was adopted by the family, changing his name to Kano. He ultimately became an official in the Shogunal government.

Jigoro Kano had an academic upbringing and, from the age of seven, he studied English, and the under a number of tutors. When he was fourteen, Kano began boarding at an English-medium school, Ikuei-Gijuku in Shiba, Tokyo. The culture of bullying endemic at this school was the catalyst that caused Kano to seek out a at which to train.

Early attempts to find a jujutsu teacher who was willing to take him on met with little success. With the fall of the Tokugawa shogunate in the Meiji Restoration of 1868, jujutsu had become unfashionable in an increasingly westernized Japan. Many of those who had once taught the art had been forced out of teaching or become so disillusioned with it that they had simply given up. Nakai Umenari, an acquaintance of Kanō's father and a former soldier, agreed to show him "kata", but not to teach him. The caretaker of Jirosaku's second house, Katagiri Ryuji, also knew jujutsu, but would not teach it as he believed it was no longer of practical use. Another frequent visitor, Imai Genshiro of school of jujutsu, also refused. Several years passed before he finally found a willing teacher.

In 1877, as a student at the Tokyo-"Kaisei" school (soon to become part of the newly founded Tokyo Imperial University), Kano learned that many jujutsu teachers had been forced to pursue alternative careers, frequently opening . After inquiring at a number of these, Kano was referred to Fukuda Hachinosuke (c.1828–1880), a teacher of the of jujutsu, who had a small nine mat dojo where he taught five students. Fukuda is said to have emphasized technique over formal exercise, sowing the seeds of Kano's emphasis on in judo.

On Fukuda's death in 1880, Kano, who had become his keenest and most able student in both "randori" and , was given the of the Fukuda dojo. Kano chose to continue his studies at another "Tenjin Shin'yō-ryū" school, that of Iso Masatomo (c.1820–1881). Iso placed more emphasis on the practice of "kata", and entrusted "randori" instruction to assistants, increasingly to Kano. Iso died in June 1881 and Kano went on to study at the dojo of Iikubo Tsunetoshi (1835–1889) of . Like Fukuda, Iikubo placed much emphasis on "randori", with "Kitō-ryū" having a greater focus on .

In February 1882, Kano founded a school and dojo at the , a Buddhist temple in what was then the Shitaya ward of Tokyo (now the Higashi Ueno district of Taitō ward). Iikubo, Kano's "Kitō-ryū" instructor, attended the dojo three days a week to help teach and, although two years would pass before the temple would be called by the name , and Kano had not yet received his in "Kitō-ryū", this is now regarded as the Kodokan founding.

The "Eisho-ji" dojo was originally shoin. It was a relatively small affair, consisting of a 12 jo (214 sq ft) training area. Kano took in resident and non-resident students, the first two being Tomita Tsunejirō and Shiro Saigo. In August, the following year, the pair were granted grades, the first that had been awarded in any martial art.

Central to Kano's vision for judo were the principles of and . He illustrated the application of "seiryoku zen'yō" with the concept of :

Kano realised that "seiryoku zen'yō", initially conceived as a jujutsu concept, had a wider philosophical application. Coupled with the Confucianist-influenced "jita kyōei", the wider application shaped the development of judo from a to a . Kano rejected techniques that did not conform to these principles and emphasised the importance of efficiency in the execution of techniques. He was convinced that practice of jujutsu while conforming to these ideals was a route to self-improvement and the betterment of society in general. He was, however, acutely conscious of the Japanese public's negative perception of jujutsu:

Kano believed that ""jūjutsu"" was insufficient to describe his art: although means "art" or "means", it implies a method consisting of a collection of physical techniques. Accordingly, he changed the second character to , meaning way, road or path, which implies a more philosophical context than "jutsu" and has a common origin with the Chinese concept of "tao". Thus Kano renamed it .

There are three basic categories of in judo: , and . Judo is mostly known for "nage-waza" and "katame-waza".

Judo practitioners typically devote a portion of each practice session to , in order that "nage-waza" can be practiced without significant risk of injury. Several distinct types of "ukemi" exist, including ; ; ; and 

The person who performs a "Waza" is known as and the person to whom it is performed is known as .

"Nage-waza" include all techniques in which "tori" attempts to throw or trip "uke", usually with the aim of placing "uke" on his back. Each technique has three distinct stages:

"Nage-waza" are typically drilled by the use of , repeated turning-in, taking the throw up to the point of "kake".

Traditionally, "nage-waza" are further categorised into , throws that are performed with "tori" maintaining an upright position, and , throws in which "tori" sacrifices his upright position in order to throw "uke".

"Tachi-waza" are further subdivided into , in which "tori" predominantly uses his arms to throw "uke"; throws that predominantly use a lifting motion from the hips; and , throws in which "tori" predominantly utilises his legs.

"Katame-waza" is further categorised into , in which "tori" traps and pins "uke" on his back on the floor; , in which "tori" attempts to force a submission by choking or strangling "uke"; and , in which "tori" attempts to submit "uke" by painful manipulation of his joints.

A related concept is that of , in which "waza" are applied from a non-standing position.

In competitive judo, "Kansetsu-waza" is currently limited to elbow joint manipulation. Manipulation and locking of other joints can be found in various kata, such as "Katame-no-kata" and "Kodokan goshin jutsu".

"Atemi-waza" are techniques in which "tori" disables "uke" with a strike to a vital point. "Atemi-waza" are not permitted outside of "kata".

Judo pedagogy emphasizes . This term covers a variety of forms of practice, and the intensity at which it is carried out varies depending on intent and the level of expertise of the participants. At one extreme, is a compliant style of randori, known as , in which neither participant offers resistance to their partner's attempts to throw. A related concept is that of , in which an experienced judoka allows himself to be thrown by his less-experienced partner. At the opposite extreme from "yakusoku geiko" is the hard style of randori that seeks to emulate the style of judo seen in competition. While hard randori is the cornerstone of judo, over-emphasis of the competitive aspect is seen as undesirable by traditionalists if the intent of the randori is to "win" rather than to learn.

 are pre-arranged patterns of techniques and in judo, with the exception of the "Seiryoku-Zen'yō Kokumin-Taiiku", they are all practised with a partner. Their purposes include illustrating the basic principles of judo, demonstrating the correct execution of a technique, teaching the philosophical tenets upon which judo is based, allowing for the practice of techniques that are not allowed in randori, and to preserve ancient techniques that are historically important but are no longer used in contemporary judo.

There are ten kata that are recognized by the Kodokan today:


In addition, there are a number of commonly practiced kata that are not recognised by the Kodokan. Some of the more common kata include:



 is a vitally important aspect of judo. In 1899, Kano was asked to chair a committee of the Dai Nippon Butoku Kai to draw up the first formal set of contest rules for jujutsu. These rules were intended to cover contests between different various traditional schools of jujutsu as well as practitioners of Kodokan judo. Contests were 15 minutes long and were judged on the basis of nage waza and katame waza, excluding atemi waza. Wins were by two ippons, awarded in every four-main different path of winning alternatives, by "Throwing", where the opponent's back strikes flat onto the mat with sufficient force, by "Pinning" them on their back for a "sufficient" amount of time, or by Submission, which could be achieved via "Shime-waza" or "Kansetsu-waza", in which the opponent was forced to give himself or herself up or summon a referee's or corner-judge's stoppage. Finger, toe and ankle locks were prohibited. In 1900, these rules were adopted by the Kodokan with amendments made to prohibit all joint locks for kyu grades and added wrist locks to the prohibited kansetsu-waza for "dan" grades. It was also stated that the ratio of tachi-waza to ne-waza should be between 70% to 80% for kyu grades and 60% to 70% for dan grades.

In 1916, additional rulings were brought in to further limit "kansetsu waza" with the prohibition of "ashi garami" and neck locks, as well as "do jime". These were further added to in 1925.

The first time judo was seen in the Olympic Games was in an informal demonstration hosted by Kano at the 1932 Games. However, Kano was ambivalent about judo's potential inclusion as an Olympic sport:
Nevertheless, judo became an Olympic sport for men in the 1964 Games in Tokyo. The Olympic Committee initially dropped judo for the 1968 Olympics, meeting protests. Dutchman Anton Geesink won the first Olympic gold medal in the open division of judo by defeating Akio Kaminaga of Japan. The women's event was introduced at the Olympics in 1988 as a demonstration event, and an official medal event in 1992.

Penalties may be given for: passivity or preventing progress in the match; for safety infringements for example by using prohibited techniques, or for behavior that is deemed to be against the spirit of judo. Fighting must be stopped if a participant is outside the designated area on the mat.

There are currently seven weight divisions, subject to change by governing bodies, and may be modified based on the age of the competitors:

A throw that places the opponent on his back with impetus and control scores an , winning the contest. A lesser throw, where the opponent is thrown onto his back, but with insufficient force to merit an ippon, scores a . Two scores of waza-ari equal an ippon . This rule was cancelled in 2017, but it was resumed in 2018. Formerly, a throw that places the opponent onto his side scores a .

The International Judo Federation recently announced changes in evaluation of points. There will only be ippon and waza-ari scores given during a match with yuko scores now included within waza-ari. Multiple waza-ari scores are no longer converted into ippon scores.

Ippon is scored in "ne-waza" for pinning an opponent on his back with a recognised "osaekomi-waza" for 20 seconds or by forcing a submission through "shime-waza" or "kansetsu-waza". A submission is signalled by tapping the mat or the opponent at least twice with the hand or foot, or by saying . A pin lasting for less than 20 seconds, but more than 10 seconds scores waza-ari (formerly waza-ari was awarded for holds of longer than 15 seconds and yuko for holds of longer than 10 seconds).

Formerly, there was an additional score that was lesser to yuko, that of . This has since been removed.

If the scores are identical at the end of the match, the contest is resolved by the "Golden Score" rule. "Golden Score" is a sudden death situation where the clock is reset to match-time, and the first contestant to achieve any score wins. If there is no score during this period, then the winner is decided by , the majority opinion of the referee and the two corner judges.

There have been changes to the scoring. In January 2013, the Hantei was removed and the "Golden Score" no longer has a time limit. The match would continue until a judoka scored through a technique or if the opponent is penalised (Shido).

Two types of penalties may be awarded. A shido (指導 - literally "guidance") is awarded for minor rule infringements. A shido can also be awarded for a prolonged period of non-aggression. Recent rule changes allow for the first shidos to result in only warnings. If there is a tie, then and only then, will the number of shidos (if less than three) be used to determine the winner. After three shidos are given, the victory is given to the opponent, constituting an indirect hansoku-make (反則負け - literally "foul-play defeat"), but does not result in expulsion from the tournament. Note: Prior to 2017, the 4th shido was hansoku-make. If hansoku-make is awarded for a major rule infringement, it results not just in loss of the match, but in the expulsion from the tournament of the penalized player.

Several judo practitioners have made an impact in mixed martial arts. Notable judo-trained MMA fighters include Olympic medalists Hidehiko Yoshida (Gold, 1992), Naoya Ogawa (Silver, 1992), Paweł Nastula (Gold, 1996), Makoto Takimoto (Gold, 2000), Satoshi Ishii (Gold, 2008) and Ronda Rousey (Bronze, 2008), former Russian national judo championship Bronze medalist Fedor Emelianenko, Yoshihiro Akiyama, Don Frye, Rick Hawn, Daniel Kelly, Hector Lombard, Khabib Nurmagomedov, Karo Parisyan, Antônio Silva, Oleg Taktarov, and Dong-Sik Yoon.

Kano Jigoro's Kodokan judo is the most popular and well-known style of judo, but is not the only one. The terms judo and jujutsu were quite interchangeable in the early years, so some of these forms of judo are still known as jujutsu or jiu-jitsu either for that reason, or simply to differentiate them from mainstream judo. From Kano's original style of judo, several related forms have evolved—some now widely considered to be distinct arts:


Kano's vision for judo was one of a martial way that could be practiced realistically. Randori (free practice) was a central part of judo pedagogy and shiai (competition) a crucial test of a judoka's understanding of judo. Safety necessitated some basic innovations that shaped judo's development. Atemi waza (striking techniques) were entirely limited to kata (prearranged forms) early in judo's history. Kansetsu waza (joint manipulation techniques) were limited to techniques that focused on the elbow joint. Various throwing techniques that were judged to be too dangerous to practice safely were also prohibited in shiai. To maximise safety in nage waza (throwing techniques), judoka trained in ukemi (break falls) and practiced on tatami (rice straw mats).

The application of joint manipulation and strangulation/choking techniques is generally safe under controlled conditions typical of judo dojo and in competition. It is usual for there to be age restrictions on the practice and application of these types of techniques, but the exact nature of these restrictions will vary from country to country and from organization to organization.

Safety in the practice of throwing techniques depends on the skill level of both tori and uke. Inexpertly applied throws have the potential to injure both tori and uke, for instance when tori compensates for poor technique by powering through the throw. Similarly, poor ukemi can result in injury, particularly from more powerful throws that uke lacks the skill to breakfall from. For these reasons, throws are normally taught in order of difficulty for both tori and uke. This is exemplified in the "Gokyo" , a traditional grouping of throws arranged in order of difficulty of ukemi. Those grouped in are relatively simple to breakfall from whereas those grouped in are difficult to breakfall from.

A practitioner of judo is known as a . The modern meaning of "judoka" in English is a judo practitioner of any level of expertise, but traditionally those below the rank of 4th "dan" were called ; and only those of 4th "dan" or higher were called "judoka". (The suffix , when added to a noun, means a person with expertise or special knowledge on that subject).

A judo teacher is called . The word "sensei" comes from "sen" or "saki" (before) and "sei" (life) – i.e. one who has preceded you. In Western dojo, it is common to call an instructor of any "dan" grade "sensei". Traditionally, that title was reserved for instructors of 4th "dan" and above.

Judo practitioners traditionally wear white uniforms called or sometimes abbreviated in the west as "gi". It comprises a heavy cotton kimono-like jacket called an , similar to traditional fastened by an , coloured to indicate rank, and cotton draw-string . Early examples of keikogi had short sleeves and trouser legs and the modern long-sleeved judogi was adopted in 1906.

The modern use of the blue judogi for high level competition was first suggested by Anton Geesink at the 1986 Maastricht IJF DC Meeting.
For competition, a blue judogi is worn by one of the two competitors for ease of distinction by judges, referees, and spectators. In Japan, both judoka use a white judogi and the traditional red obi (based on the colors of the Japanese flag) is affixed to the belt of one competitor. Outside Japan, a colored obi may also be used for convenience in minor competitions, the blue judogi only being mandatory at the regional or higher levels, depending on organization. Japanese practitioners and traditionalists tend to look down on the use of blue because of the fact that judo is considered a pure sport, and replacing the pure white judogi for the impure blue is an offense.

For events organized under the auspices of the International judo Federation (IJF), judogi have to bear the IJF Official Logo Mark Label. This label demonstrates that the judogi has passed a number of quality control tests to ensure it conforms to construction regulations ensuring it is not too stiff, flexible, rigid or slippery to allow the opponent to grip or to perform techniques.
The international governing body for judo is the International Judo Federation (IJF), founded in 1951. Members of the IJF include the African Judo Union (AJU), the Pan-American Judo Confederation (PJC), the Judo Union of Asia (JUA), the European Judo Union (EJU) and the Oceania Judo Union (OJU), each comprising a number of national judo associations. The IJF is responsible for organising international competition and hosts the World Judo Championships and is involved in running the Olympic Judo events.

Judo is a hierarchical art, where seniority of judoka is designated by what is known as the - ranking system. This system was developed by Jigoro Kano and was based on the ranking system in the board game Go. 
Beginning students progress through kyu grades towards dan grades.

A judoka's position within the kyu-dan ranking system is displayed by the color of their belt. Beginning students typically wear a white belt, progressing through descending kyu ranks until they are deemed to have achieved a level of competence sufficient to be a dan grade, at which point they wear the . The kyu-dan ranking system has since been widely adopted by modern martial arts.

The ninth degree black belt "kudan", and higher ranks, have no formal requirements and are decided by the president of the Kodokan, currently Kano Jigoro's grandson Yukimitsu Kano. As of 2011, fifteen Japanese men have been promoted to the tenth degree black belt "judan" by the Kodokan, three of whom are still alive; the IJF and Western and Asian national federations have promoted another eleven who are not recognized (at that level of rank) by the Kodokan. On July 28, 2011, the promotion board of USA Judo awarded Keiko Fukuda the rank of 10th "dan", who was the first woman to be promoted to judo's highest level, albeit not a Kodokan-recognized rank.

Although "dan" ranks tend to be consistent between national organizations there is more variation in the "kyū" grades, with some countries having more "kyū" grades. Although initially "kyū" grade belt colours were uniformly white, today a variety of colours are used. The first black belts to denote a dan rank in the 1880s, initially the wide obi was used; as practitioners trained in kimono, only white and black obi were used. It was not until the early 1900s, after the introduction of the judogi, that an expanded colored belt system of awarding rank was created.






</doc>
<doc id="15604" url="https://en.wikipedia.org/wiki?curid=15604" title="James Bond">
James Bond

The James Bond series focuses on a fictional British Secret Service agent created in 1953 by writer Ian Fleming, who featured him in twelve novels and two short-story collections. Since Fleming's death in 1964, eight other authors have written authorised Bond novels or novelizations: Kingsley Amis, Christopher Wood, John Gardner, Raymond Benson, Sebastian Faulks, Jeffery Deaver, William Boyd and Anthony Horowitz. The latest novel is "Forever and a Day" by Anthony Horowitz, published in May 2018. Additionally Charlie Higson wrote a series on a young James Bond, and Kate Westbrook wrote three novels based on the diaries of a recurring series character, Moneypenny.

The character has also been adapted for television, radio, comic strip, video games and film. The films are the longest continually running film series of all time and have grossed over $7.040 billion in total, making it the sixth-highest-grossing film series to date, which started in 1962 with "Dr. No", starring Sean Connery as Bond. As of 2020, there have been twenty-four films in the Eon Productions series. The most recent Bond film, "Spectre" (2015), stars Daniel Craig in his fourth portrayal of Bond; he is the sixth actor to play Bond in the Eon series. There have also been two independent productions of Bond films: "Casino Royale" (a 1967 spoof) and "Never Say Never Again" (a 1983 remake of an earlier Eon-produced film, "Thunderball"). In 2015 the series was estimated to be worth $19.9 billion, making "James Bond" one of the highest-grossing media franchises of all time.

The Bond films are renowned for a number of features, including the musical accompaniment, with the theme songs having received Academy Award nominations on several occasions, and two wins. Other important elements which run through most of the films include Bond's cars, his guns, and the gadgets with which he is supplied by Q Branch. The films are also noted for Bond's relationships with various women, who are sometimes referred to as "Bond girls".

Ian Fleming created the fictional character of James Bond as the central figure for his works. Bond is an intelligence officer in the Secret Intelligence Service, commonly known as MI6. Bond is known by his code number, 007, and was a Royal Naval Reserve Commander. Fleming based his fictional creation on a number of individuals he came across during his time in the Naval Intelligence Division and 30 Assault Unit during the Second World War, admitting that Bond "was a compound of all the secret agents and commando types I met during the war". Among those types were his brother, Peter, who had been involved in behind-the-lines operations in Norway and Greece during the war. Aside from Fleming's brother, a number of others also provided some aspects of Bond's make up, including Conrad O'Brien-ffrench, Patrick Dalzel-Job and Bill "Biffy" Dunderdale.

The name James Bond came from that of the American ornithologist James Bond, a Caribbean bird expert and author of the definitive field guide "Birds of the West Indies". Fleming, a keen birdwatcher himself, had a copy of Bond's guide and he later explained to the ornithologist's wife that "It struck me that this brief, unromantic, Anglo-Saxon and yet very masculine name was just what I needed, and so a second James Bond was born". He further explained that:

On another occasion, Fleming said: "I wanted the simplest, dullest, plainest-sounding name I could find, 'James Bond' was much better than something more interesting, like 'Peregrine Carruthers'. Exotic things would happen to and around him, but he would be a neutral figure—an anonymous, blunt instrument wielded by a government department."
Fleming decided that Bond should resemble both American singer Hoagy Carmichael and himself and in "Casino Royale", Vesper Lynd remarks, "Bond reminds me rather of Hoagy Carmichael, but there is something cold and ruthless." Likewise, in "Moonraker", Special Branch Officer Gala Brand thinks that Bond is "certainly good-looking ... Rather like Hoagy Carmichael in a way. That black hair falling down over the right eyebrow. Much the same bones. But there was something a bit cruel in the mouth, and the eyes were cold."

Fleming endowed Bond with many of his own traits, including sharing the same golf handicap, the taste for scrambled eggs and using the same brand of toiletries. Bond's tastes are also often taken from Fleming's own as was his behaviour, with Bond's love of golf and gambling mirroring Fleming's own. Fleming used his experiences of his espionage career and all other aspects of his life as inspiration when writing, including using names of school friends, acquaintances, relatives and lovers throughout his books.

It was not until the penultimate novel, "You Only Live Twice", that Fleming gave Bond a sense of family background. The book was the first to be written after the release of "Dr. No" in cinemas and Sean Connery's depiction of Bond affected Fleming's interpretation of the character, to give Bond both a sense of humour and Scottish antecedents that were not present in the previous stories. In a fictional obituary, purportedly published in "The Times", Bond's parents were given as Andrew Bond, from the village of Glencoe, Scotland, and Monique Delacroix, from the canton of Vaud, Switzerland. Fleming did not provide Bond's date of birth, but John Pearson's fictional biography of Bond, "", gives Bond a birth date on 11 November 1920, while a study by John Griswold puts the date at 11 November 1921.

Whilst serving in the Naval Intelligence Division, Fleming had planned to become an author and had told a friend, "I am going to write the spy story to end all spy stories." On 17 February 1952, he began writing his first James Bond novel, "Casino Royale", at his Goldeneye estate in Jamaica, where he wrote all his Bond novels during the months of January and February each year. He started the story shortly before his wedding to his pregnant girlfriend, Ann Charteris, in order to distract himself from his forthcoming nuptials.

After completing the manuscript for "Casino Royale", Fleming showed it to his friend (and later editor) William Plomer to read. Plomer liked it and submitted it to the publishers, Jonathan Cape, who did not like it as much. Cape finally published it in 1953 on the recommendation of Fleming's older brother Peter, an established travel writer. Between 1953 and 1966, two years after his death, twelve novels and two short-story collections were published, with the last two books – "The Man with the Golden Gun" and "Octopussy and The Living Daylights" – published posthumously. All the books were published in the UK through Jonathan Cape.

After Fleming's death a continuation novel, "Colonel Sun", was written by Kingsley Amis (as Robert Markham) and published in 1968. Amis had already written a literary study of Fleming's Bond novels in his 1965 work "The James Bond Dossier". Although novelizations of two of the Eon Productions Bond films appeared in print, "James Bond, The Spy Who Loved Me" and "James Bond and Moonraker", both written by screenwriter Christopher Wood, the series of novels did not continue until the 1980s. In 1981 the thriller writer John Gardner picked up the series with "Licence Renewed". Gardner went on to write sixteen Bond books in total; two of the books he wrote – "Licence to Kill" and "GoldenEye" – were novelizations of Eon Productions films of the same name. Gardner moved the Bond series into the 1980s, although he retained the ages of the characters as they were when Fleming had left them. In 1996 Gardner retired from writing James Bond books due to ill health.

In 1996 the American author Raymond Benson became the author of the Bond novels. Benson had previously been the author of "The James Bond Bedside Companion", first published in 1984.
By the time he moved on to other, non-Bond related projects in 2002, Benson had written six Bond novels, three novelizations and three short stories.

After a gap of six years, Sebastian Faulks was commissioned by Ian Fleming Publications to write a new Bond novel, which was released on 28 May 2008, the 100th anniversary of Fleming's birth. The book—titled "Devil May Care"—was published in the UK by Penguin Books and by Doubleday in the US. American writer Jeffery Deaver was then commissioned by Ian Fleming Publications to produce "Carte Blanche", which was published on 26 May 2011. The book updated Bond into a post-9/11 agent, independent of MI5 or MI6. On 26 September 2013, "Solo" by William Boyd, set in 1969, was published. In October 2014, it was announced that Anthony Horowitz was to write a "Bond" continuation novel. Set in the 1950s two weeks after the events of "Goldfinger", it contains material written, but previously unreleased, by Fleming. "Trigger Mortis" was released on 8 September 2015. Horowitz's second Bond novel, "Forever and a Day", tells the origin story of Bond as a 00 agent prior to the events of "Casino Royale". The novel, also based on unpublished material from Fleming, was released on 31 May 2018.

The "Young Bond" series of novels was started by Charlie Higson and, between 2005 and 2009, five novels and one short story were published. The first Young Bond novel, "SilverFin" was also adapted and released as a graphic novel on 2 October 2008 by Puffin Books. In October 2013 Ian Fleming Publications announced that Stephen Cole would continue the series, with the first edition scheduled to be released in Autumn 2014.

"The Moneypenny Diaries" are a trilogy of novels chronicling the life of Miss Moneypenny, M's personal secretary. The novels are penned by Samantha Weinberg under the pseudonym Kate Westbrook, who is depicted as the book's "editor". The first instalment of the trilogy, subtitled "", was released on 10 October 2005 in the UK. A second volume, subtitled "" was released on 2 November 2006 in the UK, published by John Murray. A third volume, subtitled "" was released on 1 May 2008.

In 1954 CBS paid Ian Fleming $1,000 ($ in dollars) to adapt his novel "Casino Royale" into a one-hour television adventure as part of its "Climax!" series. The episode aired live on 21 October 1954 and starred Barry Nelson as "Card Sense" James Bond and Peter Lorre as Le Chiffre. The novel was adapted for American audiences to show Bond as an American agent working for "Combined Intelligence", while the character Felix Leiter—American in the novel—became British onscreen and was renamed "Clarence Leiter".

In 1973 a BBC documentary "Omnibus: The British Hero" featured Christopher Cazenove playing a number of such title characters (e.g. Richard Hannay and Bulldog Drummond). The documentary included James Bond in dramatised scenes from
"Goldfinger"—notably featuring 007 being threatened with the novel's circular saw, rather than the film's laser beam—and "Diamonds Are Forever". In 1991 a kids's spin-off TV cartoon series, "James Bond Jr.", was produced with Corey Burton in the role of Bond's nephew, also called James Bond.

In 1958, the novel "Moonraker" was adapted for broadcast on South African radio, with Bob Holness providing the voice of Bond. According to "The Independent", "listeners across the Union thrilled to Bob's cultured tones as he defeated evil master criminals in search of world domination".

The BBC have adapted five of the Fleming novels for broadcast: in 1990 "You Only Live Twice" was adapted into a 90-minute radio play for BBC Radio 4 with Michael Jayston playing James Bond. The production was repeated a number of times between 2008 and 2011. On 24 May 2008 BBC Radio 4 broadcast an adaptation of "Dr. No". The actor Toby Stephens, who played Bond villain Gustav Graves in the Eon Productions version of "Die Another Day", played Bond, while Dr. No was played by David Suchet. Following its success, a second story was adapted and on 3 April 2010 BBC Radio 4 broadcast "Goldfinger" with Stephens again playing Bond. Sir Ian McKellen was Goldfinger and Stephens' "Die Another Day" co-star Rosamund Pike played Pussy Galore. The play was adapted from Fleming's novel by Archie Scottney and was directed by Martin Jarvis.
In 2012 the novel "From Russia, with Love" was dramatized for Radio 4; it featured a full cast again starring Stephens as Bond. In May 2014 Stephens again played Bond, in "On Her Majesty's Secret Service", with Alfred Molina as Blofeld, and Joanna Lumley as Irma Bunt.

In 1957 the "Daily Express" approached Ian Fleming to adapt his stories into comic strips, offering him £1,500 per novel and a share of takings from syndication. After initial reluctance, Fleming, who felt the strips would lack the quality of his writing, agreed. To aid the "Daily Express" in illustrating Bond, Fleming commissioned an artist to create a sketch of how he believed James Bond looked. The illustrator, John McLusky, however, felt that Fleming's 007 looked too "outdated" and "pre-war" and changed Bond to give him a more masculine look. The first strip, "Casino Royale" was published from 7 July 1958 to 13 December 1958 and was written by Anthony Hern and illustrated by John McLusky.

Most of the Bond novels and short stories have since been adapted for illustration, as well as Kingsley Amis's "Colonel Sun"; the works were written by Henry Gammidge or Jim Lawrence with Yaroslav Horak replacing McClusky as artist in 1966. After the Fleming and Amis material had been adapted, original stories were produced, continuing in the "Daily Express" and "Sunday Express" until May 1977.

Several comic book adaptations of the James Bond films have been published through the years: at the time of "Dr. No"'s release in October 1962, a comic book adaptation of the screenplay, written by Norman J. Nodel, was published in Britain as part of the "Classics Illustrated" anthology series. It was later reprinted in the United States by DC Comics as part of its "Showcase" anthology series, in January 1963. This was the first American comic book appearance of James Bond and is noteworthy for being a relatively rare example of a British comic being reprinted in a fairly high-profile American comic. It was also one of the earliest comics to be censored on racial grounds (some skin tones and dialogue were changed for the American market).

With the release of the 1981 film "For Your Eyes Only", Marvel Comics published a two-issue comic book adaptation of the film. When "Octopussy" was released in the cinemas in 1983, Marvel published an accompanying comic; Eclipse also produced a one-off comic for "Licence to Kill", although Timothy Dalton refused to allow his likeness to be used. New Bond stories were also drawn up and published from 1989 onwards through Marvel, Eclipse Comics, Dark Horse Comics and Dynamite Entertainment.

Eon Productions, the company of Canadian Harry Saltzman and American Albert R. "Cubby" Broccoli, released the first cinema adaptation of an Ian Fleming novel, "Dr. No" (1962), based on the eponymous 1958 novel and featuring Sean Connery as 007. Connery starred in a further four films before leaving the role after "You Only Live Twice" (1967), which was taken up by George Lazenby for "On Her Majesty's Secret Service" (1969). Lazenby left the role after just one appearance and Connery was brought back for his last Eon-produced film "Diamonds Are Forever".

Roger Moore was appointed to the role of 007 for "Live and Let Die" (1973). He played Bond a further six times over twelve years, before being replaced by Timothy Dalton for two films. After a six-year hiatus, during which a legal wrangle threatened Eon's productions of the Bond films, Irish actor Pierce Brosnan was cast as Bond in "GoldenEye" (1995); he remained in the role for a total of four films, before leaving in 2002. In 2006, Daniel Craig was given the role of Bond for "Casino Royale" (2006), which rebooted the series. Craig has appeared for a total of four films, and his fifth is scheduled for release in 2020. The series has grossed almost $7 billion to date, making it the third-highest-grossing film series (behind the "Harry Potter" and Marvel Cinematic Universe films), and the single most successful adjusted for inflation.

In 1967 "Casino Royale" was adapted into a parody Bond film starring David Niven as Sir James Bond and Ursula Andress as Vesper Lynd. Niven had been Fleming's preference for the role of Bond. The result of a court case in the High Court in London in 1963 allowed Kevin McClory to produce a remake of "Thunderball" titled "Never Say Never Again" in 1983. The film, produced by Jack Schwartzman's Taliafilm production company and starring Sean Connery as Bond, was not part of the Eon series of Bond films. In 1997 the Sony Corporation acquired all or some of McClory's rights in an undisclosed deal, which were then subsequently acquired by MGM, whilst on 4 December 1997, MGM announced that the company had purchased the rights to "Never Say Never Again" from Taliafilm. , Eon holds the full adaptation rights to all of Fleming's Bond novels.

The "James Bond Theme" was written by Monty Norman and was first orchestrated by the John Barry Orchestra for 1962's "Dr. No", although the actual authorship of the music has been a matter of controversy for many years. In 2001, Norman won £30,000 in libel damages from "The Sunday Times" newspaper, which suggested that Barry was entirely responsible for the composition. The theme, as written by Norman and arranged by Barry, was described by another Bond film composer, David Arnold, as "bebop-swing vibe coupled with that vicious, dark, distorted electric guitar, definitely an instrument of rock 'n' roll ... it represented everything about the character you would want: It was cocky, swaggering, confident, dark, dangerous, suggestive, sexy, unstoppable. And he did it in two minutes." Barry composed the scores for eleven Bond films and had an uncredited contribution to "Dr. No" with his arrangement of the Bond Theme.

A Bond film staple are the theme songs heard during their title sequences sung by well-known popular singers. Several of the songs produced for the films have been nominated for Academy Awards for Original Song, including Paul McCartney's "Live and Let Die", Carly Simon's "Nobody Does It Better", Sheena Easton's "For Your Eyes Only", Adele's "Skyfall", and Sam Smith's "Writing's on the Wall". Adele won the award at the 85th Academy Awards, and Smith won at the 88th Academy Awards. For the non-Eon produced "Casino Royale", Burt Bacharach's score included "The Look of Love", which was nominated for an Academy Award for Best Song.

In 1983 the first Bond video game, developed and published by Parker Brothers, was released for the Atari 2600, the Atari 5200, the Atari 800, the Commodore 64 and the ColecoVision. Since then, there have been numerous video games either based on the films or using original storylines. In 1997 the first-person shooter video game "GoldenEye 007" was developed by Rare for the Nintendo 64, based on the 1995 Pierce Brosnan film "GoldenEye". The game received very positive reviews, won the BAFTA Interactive Entertainment Award for UK Developer of the Year in 1998 and sold over eight million copies worldwide, grossing $250 million.

In 1999 Electronic Arts acquired the licence and released "Tomorrow Never Dies" on 16 December 1999. In October 2000, they released for the Nintendo 64 followed by "007 Racing" for the PlayStation on 21 November 2000. In 2003, the company released "", which included the likenesses and voices of Pierce Brosnan, Willem Dafoe, Heidi Klum, Judi Dench and John Cleese, amongst others. In November 2005, Electronic Arts released a video game adaptation of "", which involved Sean Connery's image and voice-over for Bond. In 2006 Electronic Arts announced a game based on then-upcoming film "Casino Royale": the game was cancelled because it would not be ready by the film's release in November of that year. With MGM losing revenue from lost licensing fees, the franchise was removed from EA to Activision. Activision subsequently released the "" game on 31 October 2008, based on the film of the same name.

A new version of "GoldenEye 007" featuring Daniel Craig was released for the Wii and a handheld version for the Nintendo DS in November 2010. A year later a new version was released for Xbox 360 and PlayStation 3 under the title "". In October 2012 "007 Legends" was released, which featured one mission from each of the Bond actors of the Eon Productions' series.

For the first five novels, Fleming armed Bond with a Beretta 418 until he received a letter from a thirty-one-year-old Bond enthusiast and gun expert, Geoffrey Boothroyd, criticising Fleming's choice of firearm for Bond, calling it "a lady's gun – and not a very nice lady at that!" Boothroyd suggested that Bond should swap his Beretta for a 7.65mm Walther PPK and this exchange of arms made it to "Dr. No". Boothroyd also gave Fleming advice on the Berns-Martin triple draw shoulder holster and a number of the weapons used by SMERSH and other villains. In thanks, Fleming gave the MI6 Armourer in his novels the name Major Boothroyd and, in "Dr. No", M introduces him to Bond as "the greatest small-arms expert in the world". Bond also used a variety of rifles, including the Savage Model 99 in "For Your Eyes Only" and a Winchester .308 target rifle in "The Living Daylights". Other handguns used by Bond in the Fleming books included the Colt Detective Special and a long-barrelled Colt .45 Army Special.

The first Bond film, "Dr. No", saw M ordering Bond to leave his Beretta behind and take up the Walther PPK, which the film Bond used in eighteen films. In "Tomorrow Never Dies" and the two subsequent films, Bond's main weapon was the Walther P99 semi-automatic pistol.
In the early Bond stories Fleming gave Bond a battleship-grey Bentley Litre with an Amherst Villiers supercharger. After Bond's car was written off by Hugo Drax in "Moonraker", Fleming gave Bond a Mark II Continental Bentley, which he used in the remaining books of the series. During "Goldfinger", Bond was issued with an Aston Martin DB Mark III with a homing device, which he used to track Goldfinger across France. Bond returned to his Bentley for the subsequent novels.

The Bond of the films has driven a number of cars, including the Aston Martin V8 Vantage, during the 1980s, the V12 Vanquish and DBS during the 2000s, as well as the Lotus Esprit; the BMW Z3, BMW 750iL and the BMW Z8. He has, however, also needed to drive a number of other vehicles, ranging from a Citroën 2CV to a Routemaster Bus, amongst others.

Bond's most famous car is the silver grey Aston Martin DB5, first seen in "Goldfinger"; it later featured in "Thunderball", "GoldenEye", "Tomorrow Never Dies", "Casino Royale", "Skyfall" and "Spectre". The films have used a number of different Aston Martins for filming and publicity, one of which was sold in January 2006 at an auction in the US for $2,1 million to an unnamed European collector. In 2010, another DB5 used in Goldfinger was sold at auction for $4.6m million (£2.6 million).

Fleming's novels and early screen adaptations presented minimal equipment such as the booby-trapped attaché case in "From Russia, with Love", although this situation changed dramatically with the films. However, the effects of the two Eon-produced Bond films "Dr. No" and "From Russia with Love" had an effect on the novel "The Man with the Golden Gun", through the increased number of devices used in Fleming's final story.

For the film adaptations of Bond, the pre-mission briefing by Q Branch became one of the motifs that ran through the series. "Dr. No" provided no spy-related gadgets, but a Geiger counter was used; industrial designer Andy Davey observed that the first ever onscreen spy-gadget was the attaché case shown in "From Russia with Love", which he described as "a classic 007 product". The gadgets assumed a higher profile in the 1964 film "Goldfinger". The film's success encouraged further espionage equipment from Q Branch to be supplied to Bond, although the increased use of technology led to an accusation that Bond was over-reliant on equipment, particularly in the later films.
Davey noted that "Bond's gizmos follow the zeitgeist more closely than any other ... nuance in the films" as they moved from the potential representations of the future in the early films, through to the brand-name obsessions of the later films. It is also noticeable that, although Bond uses a number of pieces of equipment from Q Branch, including the Little Nellie autogyro, a jet pack and the exploding attaché case, the villains are also well-equipped with custom-made devices, including Scaramanga's golden gun, Rosa Klebb's poison-tipped shoes, Oddjob's steel-rimmed bowler hat and Blofeld's communication devices in his agents' vanity case.

Cinematically, Bond has been a major influence within the spy genre since the release of "Dr. No" in 1962, with 22 secret agent films released in 1966 alone attempting to capitalise on the Bond franchise's popularity and success. The first parody was the 1964 film "Carry On Spying", which shows the villain Dr. Crow being overcome by agents who included James Bind (Charles Hawtry) and Daphne Honeybutt (Barbara Windsor). One of the films that reacted against the portrayal of Bond was the Harry Palmer series, whose first film, "The Ipcress File" was released in 1965. The eponymous hero of the series was what academic Jeremy Packer called an "anti-Bond", or what Christoph Lindner calls "the thinking man's Bond". The Palmer series were produced by Harry Saltzman, who also used key crew members from the Bond series, including designer Ken Adam, editor Peter R. Hunt and composer John Barry. The four "Matt Helm" films starring Dean Martin (released between 1966 and 1969), the "Flint" series starring James Coburn (comprising two films, one each in 1966 and 1969), while "The Man from U.N.C.L.E." also moved onto the cinema screen, with eight films released: all were testaments to Bond's prominence in popular culture. More recently, the "Austin Powers" series by writer, producer and comedian Mike Myers, and other parodies such as the "Johnny English" trilogy of films, have also used elements from or parodied the Bond films.

Following the release of the film "Dr. No" in 1962, the line "Bond ... James Bond", became a catch phrase that entered the lexicon of Western popular culture: writers Cork and Scivally said of the introduction in "Dr. No" that the "signature introduction would become the most famous and loved film line ever". In 2001, it was voted as the "best-loved one-liner in cinema" by British cinema goers, and in 2005, it was honoured as the 22nd greatest quotation in cinema history by the American Film Institute as part of their 100 Years Series. The 2005 American Film Institute's '100 Years' series recognised the character of James Bond himself as the third greatest film hero. He was also placed at number 11 on a similar list by "Empire" and as the fifth greatest movie character of all time by "Premiere".

The 23 James Bond films produced by Eon Productions, which have grossed $4,910 million in box office returns alone, have made the series one of the highest-grossing ever. It is estimated that since "Dr. No", a quarter of the world's population have seen at least one Bond film. The UK Film Distributors' Association have stated that the importance of the Bond series of films to the British film industry cannot be overstated, as they "form the backbone of the industry".

Television also saw the effect of Bond films, with the NBC series "The Man from U.N.C.L.E.", which was described as the "first network television imitation" of Bond, largely because Fleming provided advice and ideas on the development of the series, even giving the main character the name Napoleon Solo. Other 1960s television series inspired by Bond include "I Spy", and "Get Smart".

A British cultural icon, by 2012, James Bond had become such a symbol of the United Kingdom that the character, played by Craig, appeared in the opening ceremony of the 2012 London Olympics as Queen Elizabeth II's escort. From 1968 to 2003, and since 2016, the Cadbury chocolate box Milk Tray has been advertised by the 'Milk Tray Man', a tough James Bond–style figure who undertakes daunting 'raids' to surreptitiously deliver a box of Milk Tray chocolates to a lady.

Throughout the life of the film series, a number of tie-in products have been released. In 2018 a James Bond museum opened atop of Austrian Alps. The futuristic museum is constructed on the summit of Gaislachkogl Mountain in Sölden at 3,048 m above sea level.

The James Bond character and related media have triggered a number of criticisms and reactions across the political spectrum, and are still highly debated in popular culture studies. Some observers accuse the Bond novels and films of misogyny and sexism. Geographers have considered the role of exotic locations in the movies in the dynamics of the Cold War, with power struggles among blocs playing out in the peripheral areas. Other critics claim that the Bond films reflect imperial nostalgia. American conservative critics, particularly in the 1960s and 1970s, saw Bond as a nihilistic, hedonistic, and amoral character that challenged family values.




</doc>
<doc id="15606" url="https://en.wikipedia.org/wiki?curid=15606" title="Japanese language">
Japanese language

Little is known of the language's prehistory, or when it first appeared in Japan. Chinese documents from the 3rd century recorded a few Japanese words, but substantial texts did not appear until the 8th century. During the Heian period (794–1185), Chinese had considerable influence on the vocabulary and phonology of Old Japanese. Late Middle Japanese (1185–1600) included changes in features that brought it closer to the modern language, and the first appearance of European loanwords. The standard dialect moved from the Kansai region to the Edo (modern Tokyo) region in the Early Modern Japanese period (early 17th century–mid-19th century). Following the end in 1853 of Japan's self-imposed isolation, the flow of loanwords from European languages increased significantly. English loanwords, in particular, have become frequent, and Japanese words from English roots have proliferated.

Japanese is an agglutinative, mora-timed language with simple phonotactics, a pure vowel system, phonemic vowel and consonant length, and a lexically significant pitch-accent. Word order is normally subject–object–verb with particles marking the grammatical function of words, and sentence structure is topic–comment. Sentence-final particles are used to add emotional or emphatic impact, or make questions. Nouns have no grammatical number or gender, and there are no articles. Verbs are conjugated, primarily for tense and voice, but not person. Japanese equivalents of adjectives are also conjugated. Japanese has a complex system of honorifics with verb forms and vocabulary to indicate the relative status of the speaker, the listener, and persons mentioned.

Japanese has no genetic relationship with Chinese, but it makes extensive use of Chinese characters, or , in its writing system, and a large portion of its vocabulary is borrowed from Chinese. Along with "kanji", the Japanese writing system primarily uses two syllabic (or moraic) scripts, and . Latin script is used in a limited fashion, such as for imported acronyms, and the numeral system uses mostly Arabic numerals alongside traditional Chinese numerals.

Proto-Japonic, the common ancestor of the Japanese and Ryukyuan languages, is thought to have been brought to Japan by settlers coming from either continental Asia or nearby Pacific islands sometime in the early- to mid-2nd century BC (the Yayoi period), replacing the languages of the original Jōmon inhabitants, including the ancestor of the modern Ainu language. Very little is known about the Japanese of this period. Because writing like the "Kanji" which later devolved into the writing systems "Hiragana" and "Katakana" had yet to be introduced from China, there is no direct evidence, and anything that can be discerned about this period of Japanese must be based on the reconstructions of Old Japanese.

Old Japanese is the oldest attested stage of the Japanese language. Through the spread of Buddhism, the Chinese writing system was imported to Japan. The earliest texts found in Japan are written in Classical Chinese, but they may have been meant to be read as Japanese by the kanbun method. Some of these Chinese texts show the influences of Japanese grammar, such as the word order (for example, placing the verb after the object). In these hybrid texts, Chinese characters are also occasionally used phonetically to represent Japanese particles. The earliest text, the "Kojiki", dates to the early 8th century, and was written entirely in Chinese characters. The end of Old Japanese coincides with the end of the Nara period in 794. Old Japanese uses the Man'yōgana system of writing, which uses "kanji" for their phonetic as well as semantic values. Based on the Man'yōgana system, Old Japanese can be reconstructed as having 88 distinct syllables. Texts written with Man'yōgana use two different "kanji" for each of the syllables now pronounced . (The "Kojiki" has 88, but all later texts have 87. The distinction between mo and mo apparently was lost immediately following its composition.) This set of syllables shrank to 67 in Early Middle Japanese, though some were added through Chinese influence.

Due to these extra syllables, it has been hypothesized that Old Japanese's vowel system was larger than that of Modern Japanese – it perhaps contained up to eight vowels. According to Shinkichi Hashimoto, the extra syllables in Man'yōgana derive from differences between the vowels of the syllables in question. These differences would indicate that Old Japanese had an eight-vowel system, in contrast to the five vowels of later Japanese. The vowel system would have to have shrunk some time between these texts and the invention of the "kana" ("hiragana" and "katakana") in the early 9th century. According to this view, the eight-vowel system of ancient Japanese would resemble that of the Uralic and Altaic language families. However, it is not fully certain that the alternation between syllables necessarily reflects a difference in the vowels rather than the consonants – at the moment, the only undisputed fact is that they are different syllables. A newer reconstruction of ancient Japanese shows striking similarities with Southeast-Asian languages, especially with Austronesian languages.

Old Japanese does not have , but rather (preserved in modern "fu", ), which has been reconstructed to an earlier *. Man'yōgana also has a symbol for , which merges with before the end of the period.

Several fossilizations of Old Japanese grammatical elements remain in the modern language – the genitive particle "tsu" (superseded by modern "no") is preserved in words such as "matsuge" ("eyelash", lit. "hair of the eye"); modern "mieru" ("to be visible") and "kikoeru" ("to be audible") retain what may have been a mediopassive suffix -"yu(ru)" ("kikoyu" → "kikoyuru" (the attributive form, which slowly replaced the plain form starting in the late Heian period) > "kikoeru" (as all shimo-nidan verbs in modern Japanese did)); and the genitive particle "ga" remains in intentionally archaic speech.

Early Middle Japanese is the Japanese of the Heian period, from 794 to 1185. Early Middle Japanese sees a significant amount of Chinese influence on the language's phonology – length distinctions become phonemic for both consonants and vowels, and series of both labialised (e.g. "kwa") and palatalised ("kya") consonants are added. Intervocalic merges with by the 11th century.
The end of Early Middle Japanese sees the beginning of a shift where the attributive form (Japanese "rentaikei") slowly replaces the uninflected form ("shūshikei") for those verb classes where the two were distinct.

Late Middle Japanese covers the years from 1185 to 1600, and is normally divided into two sections, roughly equivalent to the Kamakura period and the Muromachi period, respectively. The later forms of Late Middle Japanese are the first to be described by non-native sources, in this case the Jesuit and Franciscan missionaries; and thus there is better documentation of Late Middle Japanese phonology than for previous forms (for instance, the "Arte da Lingoa de Iapam"). Among other sound changes, the sequence merges to , in contrast with ; is reintroduced from Chinese; and merges with . Some forms rather more familiar to Modern Japanese speakers begin to appear – the continuative ending -"te" begins to reduce onto the verb (e.g. "yonde" for earlier "yomite"), the -k- in the final syllable of adjectives drops out ("shiroi" for earlier "shiroki"); and some forms exist where modern standard Japanese has retained the earlier form (e.g. "hayaku" > "hayau" > "hayɔɔ", where modern Japanese just has "hayaku", though the alternative form is preserved in the standard greeting "o-hayō gozaimasu" "good morning"; this ending is also seen in "o-medetō" "congratulations", from "medetaku").

Late Middle Japanese has the first loanwords from European languages – now-common words borrowed into Japanese in this period include "pan" ("bread") and "tabako" ("tobacco", now "cigarette"), both from Portuguese.

Early Modern Japanese, not to be confused with Modern Japanese, was the dialect used after the Meiji Restoration. Because the two languages are extremely similar, Early Modern Japanese is commonly referred to as Modern Japanese. Early Modern Japanese gradually evolved into Modern Japanese during the 19th century. Only after 1945, shortly after World War II, did Modern Japanese become the standard language, seeing use in most official communications. In this time period the Japanese in addition to their use of Katakana and Hiragana also used traditional Chinese characters called "Han" which later developed in "Kanji" which is a form of writing used to express ideas in the Japanese and Chinese languages.

Modern Japanese is considered to begin with the Edo period, which lasted between 1603 and 1868. Since Old Japanese, the de facto standard Japanese had been the Kansai dialect, especially that of Kyoto. However, during the Edo period, Edo (now Tokyo) developed into the largest city in Japan, and the Edo-area dialect became standard Japanese. Since the end of Japan's self-imposed isolation in 1853, the flow of loanwords from European languages has increased significantly. The period since 1945 has seen many words borrowed from other languagessuch as German, Portuguese and English. Many English loan words especially relate to technologyfor example, "pasokon" (short for "personal computer"), "intānetto" ("internet"), and "kamera" ("camera"). Due to the large quantity of English loanwords, modern Japanese has developed a distinction between and , and and , with the latter in each pair only found in loanwords.

Although Japanese is spoken almost exclusively in Japan, it has been spoken outside. Before and during World War II, through Japanese annexation of Taiwan and Korea, as well as partial occupation of China, the Philippines, and various Pacific islands, locals in those countries learned Japanese as the language of the empire. As a result, many elderly people in these countries can still speak Japanese.

Japanese emigrant communities (the largest of which are to be found in Brazil, with 1.4 million to 1.5 million Japanese immigrants and descendants, according to Brazilian IBGE data, more than the 1.2 million of the United States) sometimes employ Japanese as their primary language. Approximately 12% of Hawaii residents speak Japanese, with an estimated 12.6% of the population of Japanese ancestry in 2008. Japanese emigrants can also be found in Peru, Argentina, Australia (especially in the eastern states), Canada (especially in Vancouver where 1.4% of the population has Japanese ancestry), the United States (notably Hawaii, where 16.7% of the population has Japanese ancestry, and California), and the Philippines (particularly in Davao region and Laguna province).

Japanese has no official status, but is the "de facto" national language of Japan. There is a form of the language considered standard: , meaning "standard Japanese", or , "common language". The meanings of the two terms are almost the same. "Hyōjungo" or "kyōtsūgo" is a conception that forms the counterpart of dialect. This normative language was born after the from the language spoken in the higher-class areas of Tokyo (see Yamanote). "Hyōjungo" is taught in schools and used on television and even in official communications. It is the version of Japanese discussed in this article.

Formerly, standard was different from . The two systems have different rules of grammar and some variance in vocabulary. "Bungo" was the main method of writing Japanese until about 1900; since then "kōgo" gradually extended its influence and the two methods were both used in writing until the 1940s. "Bungo" still has some relevance for historians, literary scholars, and lawyers (many Japanese laws that survived World War II are still written in "bungo", although there are ongoing efforts to modernize their language). "Kōgo" is the dominant method of both speaking and writing Japanese today, although "bungo" grammar and vocabulary are occasionally used in modern Japanese for effect.

Dozens of dialects are spoken in Japan. The profusion is due to many factors, including the length of time the Japanese Archipelago has been inhabited, its mountainous island terrain, and Japan's long history of both external and internal isolation. Dialects typically differ in terms of pitch accent, inflectional morphology, vocabulary, and particle usage. Some even differ in vowel and consonant inventories, although this is uncommon.

The main distinction in Japanese accents is between and . Within each type are several subdivisions. Kyoto-Osaka-type dialects are in the central region, roughly formed by Kansai, Shikoku, and western Hokuriku regions.

Dialects from peripheral regions, such as Tōhoku or Kagoshima, may be unintelligible to speakers from the other parts of the country. There are some language islands in mountain villages or isolated islands such as Hachijō-jima island whose dialects are descended from the Eastern dialect of Old Japanese. Dialects of the Kansai region are spoken or known by many Japanese, and Osaka dialect in particular is associated with comedy (see Kansai dialect). Dialects of Tōhoku and North Kantō are associated with typical farmers.

The Ryūkyūan languages, spoken in Okinawa and the Amami Islands (politically part of Kagoshima), are distinct enough to be considered a separate branch of the Japonic family; not only is each language unintelligible to Japanese speakers, but most are unintelligible to those who speak other Ryūkyūan languages. However, in contrast to linguists, many ordinary Japanese people tend to consider the Ryūkyūan languages as dialects of Japanese. The imperial court also seems to have spoken an unusual variant of the Japanese of the time. Most likely being the spoken form of Classical Japanese language, a writing style that was prevalent during the Heian period, but began decline during the late Meiji period. The Ryūkyūan languages are spoken by a decreasing number of elderly people so UNESCO classified it as endangered, because they could become extinct by 2050. Young people mostly use Japanese and cannot understand the Ryukyuan languages. Okinawan Japanese is a variant of Standard Japanese influenced by the Ryukyuan languages. It is the primary dialect spoken among young people in the Ryukyu Islands.

Modern Japanese has become prevalent nationwide (including the Ryūkyū islands) due to education, mass media, and an increase of mobility within Japan, as well as economic integration.

Japanese is a member of the Japonic languages family, which also includes the languages spoken throughout the Ryūkyū Islands. As these closely related languages are commonly treated as dialects of the same language, Japanese is often called a language isolate.

According to Martine Irma Robbeets, Japanese has been subject to more attempts to show its relation to other languages than any other language in the world. Since Japanese first gained the consideration of linguists in the late 19th century, attempts have been made to show its genealogical relation to languages or language families such as Ainu, Korean, Chinese, Tibeto-Burman, Ural-Altaic, Altaic, Uralic, Mon–Khmer, Malayo-Polynesian and Ryukyuan. At the fringe, some linguists have suggested a link to Indo-European languages, including Greek, and to Lepcha. As it stands, only the link to Ryukyuan has wide support.

Modern main theories tried to link Japanese on the one hand to northern Asian languages, like Korean or the bigger Altaic family (also sometimes known as "Transeurasian") and on the other hand to various Southeast Asian languages, especially to Austronesian. None of these proposals have gained wide acceptance and the Altaic language family itself is now considered controversial.

Other theories view the Japanese language as an early creole language formed through inputs from at least two distinct language groups or as a distinct language of its own that has absorbed various aspects from neighbouring languages.

For now, Japanese is classificated as member of the Japonic languages or as a language isolate with no known living relatives if Ryukyuan is counted as dialects.

All Japanese vowels are purethat is, there are no diphthongs, only monophthongs. The only unusual vowel is the high back vowel , which may be compressed rather than rounded and fronted. Japanese has five vowels, and vowel length is phonemic, with each having both a short and a long version. Elongated vowels are usually denoted with a line over the vowel (a macron) in rōmaji, a repeated vowel character in hiragana, or a chōonpu succeeding the vowel in katakana.

Some Japanese consonants have several allophones, which may give the impression of a larger inventory of sounds. However, some of these allophones have since become phonemic. For example, in the Japanese language up to and including the first half of the 20th century, the phonemic sequence was palatalized and realized phonetically as , approximately "chi" ; however, now and are distinct, as evidenced by words like "tī" "Western style tea" and "chii" "social status".

The "r" of the Japanese language is of particular interest, ranging between an apical central tap and a lateral approximant. The "g" is also notable; unless it starts a sentence, it may be pronounced , in the Kanto prestige dialect and in other eastern dialects.

The syllabic structure and the phonotactics are very simple: the only consonant clusters allowed within a syllable consist of one of a subset of the consonants plus . This type of cluster only occurs in onsets. However, consonant clusters across syllables are allowed as long as the two consonants are a nasal followed by a homorganic consonant. Consonant length (gemination) is also phonemic.

The phonology of Japanese also includes a pitch accent system, which is a system that helps differentiate words with identical Hiragana spelling or words in different Japanese dialects. An example of words with identical Hiragana would be the words ("chopsticks") and ("bridge"), both spelled (はし, "hashi") in Hiragana. The stresses differentiate the words.

Japanese word order is classified as subject–object–verb. Unlike many Indo-European languages, the only strict rule of word order is that the verb must be placed at the end of a sentence (possibly followed by sentence-end particles). This is because Japanese sentence elements are marked with particles that identify their grammatical functions.

The basic sentence structure is topic–comment. For example, "Kochira wa Tanaka-san desu" (). "kochira" ("this") is the topic of the sentence, indicated by the particle " wa". The verb "de aru" ("desu" is a contraction of its polite form "de arimasu") is a copula, commonly translated as "to be" or "it is" (though there are other verbs that can be translated as "to be"), though technically it holds no meaning and is used to give a sentence 'politeness'. As a phrase, "Tanaka-san desu" is the comment. This sentence literally translates to "As for this person, (it) is Mr./Ms. Tanaka." Thus Japanese, like many other Asian languages, is often called a topic-prominent language, which means it has a strong tendency to indicate the topic separately from the subject, and that the two do not always coincide. The sentence "Zō wa hana ga nagai " () literally means, "As for elephant(s), (the) nose(s) (is/are) long". The topic is "zō" "elephant", and the subject is "hana" "nose".

In Japanese, the subject or object of a sentence need not be stated if it is obvious from context. As a result of this grammatical permissiveness, there is a tendency to gravitate towards brevity; Japanese speakers tend to omit pronouns on the theory they are inferred from the previous sentence, and are therefore understood. In the context of the above example, "hana-ga nagai" would mean "[their] noses are long," while "nagai" by itself would mean "[they] are long." A single verb can be a complete sentence: "Yatta!" () "[I / we / they / etc] did [it]!". In addition, since adjectives can form the predicate in a Japanese sentence (below), a single adjective can be a complete sentence: "Urayamashii!" () "[I'm] jealous [of it]!".

While the language has some words that are typically translated as pronouns, these are not used as frequently as pronouns in some Indo-European languages, and function differently. In some cases Japanese relies on special verb forms and auxiliary verbs to indicate the direction of benefit of an action: "down" to indicate the out-group gives a benefit to the in-group; and "up" to indicate the in-group gives a benefit to the out-group. Here, the in-group includes the speaker and the out-group does not, and their boundary depends on context. For example, "oshiete moratta" () (literally, "explained" with a benefit from the out-group to the in-group) means "[he/she/they] explained [it] to [me/us]". Similarly, "oshiete ageta" () (literally, "explained" with a benefit from the in-group to the out-group) means "[I/we] explained [it] to [him/her/them]". Such beneficiary auxiliary verbs thus serve a function comparable to that of pronouns and prepositions in Indo-European languages to indicate the actor and the recipient of an action.

Japanese "pronouns" also function differently from most modern Indo-European pronouns (and more like nouns) in that they can take modifiers as any other noun may. For instance, one does not say in English:

The amazed he ran down the street. (grammatically incorrect insertion of a pronoun)

But one "can" grammatically say essentially the same thing in Japanese:

<poem>
"Odoroita kare wa michi o hashitte itta." (grammatically correct)</poem>

This is partly because these words evolved from regular nouns, such as "kimi" "you" ( "lord"), "anata" "you" ( "that side, yonder"), and "boku" "I" ( "servant"). This is why some linguists do not classify Japanese "pronouns" as pronouns, but rather as referential nouns, much like Spanish "usted" (contracted from "vuestra merced", "your [(flattering majestic) plural] grace") or Portuguese "o senhor". Japanese personal pronouns are generally used only in situations requiring special emphasis as to who is doing what to whom.

The choice of words used as pronouns is correlated with the sex of the speaker and the social situation in which they are spoken: men and women alike in a formal situation generally refer to themselves as "watashi" ( "private") or "watakushi" (also ), while men in rougher or intimate conversation are much more likely to use the word "ore" ( "oneself", "myself") or "boku". Similarly, different words such as "anata", "kimi", and "omae" (, more formally "the one before me") may be used to refer to a listener depending on the listener's relative social position and the degree of familiarity between the speaker and the listener. When used in different social relationships, the same word may have positive (intimate or respectful) or negative (distant or disrespectful) connotations.

Japanese often use titles of the person referred to where pronouns would be used in English. For example, when speaking to one's teacher, it is appropriate to use "sensei" (, teacher), but inappropriate to use "anata". This is because "anata" is used to refer to people of equal or lower status, and one's teacher has higher status.

Japanese nouns have no grammatical number, gender or article aspect. The noun "hon" () may refer to a single book or several books; "hito" () can mean "person" or "people", and "ki" () can be "tree" or "trees". Where number is important, it can be indicated by providing a quantity (often with a counter word) or (rarely) by adding a suffix, or sometimes by duplication (e.g. , "hitobito", usually written with an iteration mark as ). Words for people are usually understood as singular. Thus "Tanaka-san" usually means "Mr./Ms. Tanaka". Words that refer to people and animals can be made to indicate a group of individuals through the addition of a collective suffix (a noun suffix that indicates a group), such as "-tachi", but this is not a true plural: the meaning is closer to the English phrase "and company". A group described as "Tanaka-san-tachi" may include people not named Tanaka. Some Japanese nouns are effectively plural, such as "hitobito" "people" and "wareware" "we/us", while the word "tomodachi" "friend" is considered singular, although plural in form.

Verbs are conjugated to show tenses, of which there are two: past and present (or non-past) which is used for the present and the future. For verbs that represent an ongoing process, the "-te iru" form indicates a continuous (or progressive) aspect, similar to the suffix "ing" in English. For others that represent a change of state, the "-te iru" form indicates a perfect aspect. For example, "kite iru" means "He has come (and is still here)", but "tabete iru" means "He is eating".

Questions (both with an interrogative pronoun and yes/no questions) have the same structure as affirmative sentences, but with intonation rising at the end. In the formal register, the question particle "-ka" is added. For example, "ii desu" () "It is OK" becomes "ii desu-ka" () "Is it OK?". In a more informal tone sometimes the particle "-no" () is added instead to show a personal interest of the speaker: "Dōshite konai-no?" "Why aren't (you) coming?". Some simple queries are formed simply by mentioning the topic with an interrogative intonation to call for the hearer's attention: "Kore wa?" "(What about) this?"; "O-namae wa?" () "(What's your) name?".

Negatives are formed by inflecting the verb. For example, "Pan o taberu" () "I will eat bread" or "I eat bread" becomes "Pan o tabenai" () "I will not eat bread" or "I do not eat bread". Plain negative forms are actually "i"-adjectives (see below) and inflect as such, e.g. "Pan o tabenakatta" () "I did not eat bread".

The so-called "-te" verb form is used for a variety of purposes: either progressive or perfect aspect (see above); combining verbs in a temporal sequence ("Asagohan o tabete sugu dekakeru" "I'll eat breakfast and leave at once"), simple commands, conditional statements and permissions ("Dekakete-mo ii?" "May I go out?"), etc.

The word "da" (plain), "desu" (polite) is the copula verb. It corresponds approximately to the English "be", but often takes on other roles, including a marker for tense, when the verb is conjugated into its past form "datta" (plain), "deshita" (polite). This comes into use because only "i"-adjectives and verbs can carry tense in Japanese. Two additional common verbs are used to indicate existence ("there is") or, in some contexts, property: "aru" (negative "nai") and "iru" (negative "inai"), for inanimate and animate things, respectively. For example, "Neko ga iru" "There's a cat", "Ii kangae-ga nai" "[I] haven't got a good idea".

The verb "to do" ("suru", polite form "shimasu") is often used to make verbs from nouns ("ryōri suru" "to cook", "benkyō suru" "to study", etc.) and has been productive in creating modern slang words. Japanese also has a huge number of compound verbs to express concepts that are described in English using a verb and an adverbial particle (e.g. "tobidasu" "to fly out, to flee," from "tobu" "to fly, to jump" + "dasu" "to put out, to emit").

There are three types of adjectives (see Japanese adjectives):

Both "keiyōshi" and "keiyōdōshi" may predicate sentences. For example,

<poem> "Gohan ga atsui." "The rice is hot."

Both inflect, though they do not show the full range of conjugation found in true verbs.
The "rentaishi" in Modern Japanese are few in number, and unlike the other words, are limited to directly modifying nouns. They never predicate sentences. Examples include "ookina" "big", "kono" "this", "iwayuru" "so-called" and "taishita" "amazing".

Both "keiyōdōshi" and "keiyōshi" form adverbs, by following with "ni" in the case of "keiyōdōshi":

and by changing "i" to "ku" in the case of "keiyōshi":

The grammatical function of nouns is indicated by postpositions, also called particles. These include for example:

It is also used for the lative case, indicating a motion to a location.

Note: The subtle difference between wa and ga in Japanese cannot be derived from the English language as such, because the distinction between sentence topic and subject is not made there. While "wa" indicates the topic, which the rest of the sentence describes or acts upon, it carries the implication that the subject indicated by "wa" is not unique, or may be part of a larger group.

"Ikeda-san wa yonjū-ni sai da." "As for Mr. Ikeda, he is forty-two years old." Others in the group may also be of that age.

Absence of "wa" often means the subject is the focus of the sentence.

"Ikeda-san ga yonjū-ni sai da." "It is Mr. Ikeda who is forty-two years old." This is a reply to an implicit or explicit question, such as "who in this group is forty-two years old?"

Japanese has an extensive grammatical system to express politeness and formality. This reflects the hierarchical nature of Japanese society.

The Japanese language can express differing levels in social status. The differences in social position are determined by a variety of factors including job, age, experience, or even psychological state (e.g., a person asking a favour tends to do so politely). The person in the lower position is expected to use a polite form of speech, whereas the other person might use a plainer form. Strangers will also speak to each other politely. Japanese children rarely use polite speech until they are teens, at which point they are expected to begin speaking in a more adult manner. "See uchi-soto".

Whereas "teineigo" () (polite language) is commonly an inflectional system, "sonkeigo" () (respectful language) and "kenjōgo" () (humble language) often employ many special honorific and humble alternate verbs: "iku" "go" becomes "ikimasu" in polite form, but is replaced by "irassharu" in honorific speech and "ukagau" or "mairu" in humble speech.

The difference between honorific and humble speech is particularly pronounced in the Japanese language. Humble language is used to talk about oneself or one's own group (company, family) whilst honorific language is mostly used when describing the interlocutor and their group. For example, the "-san" suffix ("Mr" "Mrs." or "Miss") is an example of honorific language. It is not used to talk about oneself or when talking about someone from one's company to an external person, since the company is the speaker's in-group. When speaking directly to one's superior in one's company or when speaking with other employees within one's company about a superior, a Japanese person will use vocabulary and inflections of the honorific register to refer to the in-group superior and their speech and actions. When speaking to a person from another company (i.e., a member of an out-group), however, a Japanese person will use the plain or the humble register to refer to the speech and actions of their own in-group superiors. In short, the register used in Japanese to refer to the person, speech, or actions of any particular individual varies depending on the relationship (either in-group or out-group) between the speaker and listener, as well as depending on the relative status of the speaker, listener, and third-person referents.

Most nouns in the Japanese language may be made polite by the addition of "o-" or "go-" as a prefix. "o-" is generally used for words of native Japanese origin, whereas "go-" is affixed to words of Chinese derivation. In some cases, the prefix has become a fixed part of the word, and is included even in regular speech, such as "gohan" 'cooked rice; meal.' Such a construction often indicates deference to either the item's owner or to the object itself. For example, the word "tomodachi" 'friend,' would become "o-tomodachi" when referring to the friend of someone of higher status (though mothers often use this form to refer to their children's friends). On the other hand, a polite speaker may sometimes refer to "mizu" 'water' as "o-mizu" in order to show politeness.

Most Japanese people employ politeness to indicate a lack of familiarity. That is, they use polite forms for new acquaintances, but if a relationship becomes more intimate, they no longer use them. This occurs regardless of age, social class, or gender.

There are three main sources of words in the Japanese language, the "yamato kotoba" (大和言葉) or "wago" (和語), "kango" (漢語), and "gairaigo" (外来語).

The original language of Japan, or at least the original language of a certain population that was ancestral to a significant portion of the historical and present Japanese nation, was the so-called "yamato kotoba" ( or infrequently , i.e. "Yamato words"), which in scholarly contexts is sometimes referred to as "wago" ( or rarely , i.e. the "Wa language"). In addition to words from this original language, present-day Japanese includes a number of words that were either borrowed from Chinese or constructed from Chinese roots following Chinese patterns. These words, known as "kango" (), entered the language from the 5th century onwards via contact with Chinese culture. According to the "Shinsen Kokugo Jiten" (新選国語辞典) Japanese dictionary, "kango" comprise 49.1% of the total vocabulary, "wago" make up 33.8%, other foreign words or "gairaigo" () account for 8.8%, and the remaining 8.3% constitute hybridized words or "konshugo" () that draw elements from more than one language.

There are also a great number of words of mimetic origin in Japanese, with Japanese having a rich collection of sound symbolism, both onomatopoeia for physical sounds, and more abstract words. A small number of words have come into Japanese from the Ainu language. "Tonakai" (reindeer), "rakko" (sea otter) and "shishamo" (smelt, a type of fish) are well-known examples of words of Ainu origin.

Words of different origins occupy different registers in Japanese. Like Latin-derived words in English, "kango" words are typically perceived as somewhat formal or academic compared to equivalent Yamato words. Indeed, it is generally fair to say that an English word derived from Latin/French roots typically corresponds to a Sino-Japanese word in Japanese, whereas a simpler Anglo-Saxon word would best be translated by a Yamato equivalent.

Incorporating vocabulary from European languages, "gairaigo", began with borrowings from Portuguese in the 16th century, followed by words from Dutch during Japan's long isolation of the Edo period. With the Meiji Restoration and the reopening of Japan in the 19th century, borrowing occurred from German, French, and English. Today most borrowings are from English.

In the Meiji era, the Japanese also coined many neologisms using Chinese roots and morphology to translate European concepts; these are known as wasei kango (Japanese-made Chinese words). Many of these were then imported into Chinese, Korean, and Vietnamese via their kanji in the late 19th and early 20th centuries. For example, "seiji" 政治 ("politics"), and "kagaku" 化学 ("chemistry") are words derived from Chinese roots that were first created and used by the Japanese, and only later borrowed into Chinese and other East Asian languages. As a result, Japanese, Chinese, Korean, and Vietnamese share a large common corpus of vocabulary in the same way many Greek- and Latin-derived words – both inherited or borrowed into European languages, or modern coinages from Greek or Latin roots – are shared among modern European languages – see classical compound.

In the past few decades, "wasei-eigo" ("made-in-Japan English") has become a prominent phenomenon. Words such as "wanpatān" (< "one" + "pattern", "to be in a rut", "to have a one-track mind") and "sukinshippu" (< "skin" + "-ship", "physical contact"), although coined by compounding English roots, are nonsensical in most non-Japanese contexts; exceptions exist in nearby languages such as Korean however, which often use words such as "skinship" and "rimokon" (remote control) in the same way as in Japanese.

The popularity of many Japanese cultural exports has made some native Japanese words familiar in English, including "futon, haiku, judo, kamikaze, karaoke, karate, ninja, origami, rickshaw" (from "jinrikisha"), "samurai, sayonara, Sudoku, sumo, sushi, tsunami, tycoon". See list of English words of Japanese origin for more.

Literacy was introduced to Japan in the form of the Chinese writing system, by way of Baekje before the 5th century. Using this language, the Japanese king Bu presented a petition to Emperor Shun of Liu Song in AD 478. After the ruin of Baekje, Japan invited scholars from China to learn more of the Chinese writing system. Japanese emperors gave an official rank to Chinese scholars (続守言/薩弘格/ 袁晋卿) and spread the use of Chinese characters from the 7th century to the 8th century.

At first, the Japanese wrote in Classical Chinese, with Japanese names represented by characters used for their meanings and not their sounds. Later, during the 7th century AD, the Chinese-sounding phoneme principle was used to write pure Japanese poetry and prose, but some Japanese words were still written with characters for their meaning and not the original Chinese sound. This is when the history of Japanese as a written language begins in its own right. By this time, the Japanese language was already very distinct from the Ryukyuan languages.

An example of this mixed style is the Kojiki, which was written in AD 712. They then started to use Chinese characters to write Japanese in a style known as "man'yōgana", a syllabic script which used Chinese characters for their sounds in order to transcribe the words of Japanese speech syllable by syllable.

Over time, a writing system evolved. Chinese characters (kanji) were used to write either words borrowed from Chinese, or Japanese words with the same or similar meanings. Chinese characters were also used to write grammatical elements, were simplified, and eventually became two syllabic scripts: hiragana and katakana which were developed based on Manyogana from Baekje. However this hypothesis "Manyogana from Baekje" is denied by other scholars.

Hiragana and Katakana were first simplified from Kanji, and Hiragana, emerging somewhere around the 9th century, was mainly used by women. Hiragana was seen as an informal language, whereas Katakana and Kanji were considered more formal and was typically used by men and in official settings. However, because of hiragana's accessibility, more and more people began using it. Eventually, by the 10th century, hiragana was used by everyone.

Modern Japanese is written in a mixture of three main systems: kanji, characters of Chinese origin used to represent both Chinese loanwords into Japanese and a number of native Japanese morphemes; and two syllabaries: hiragana and katakana. The Latin script (or romaji in Japanese) is used to a certain extent, such as for imported acronyms and to transcribe Japanese names and in other instances where non-Japanese speakers need to know how to pronounce a word (such as "ramen" at a restaurant). Arabic numerals are much more common than the kanji when used in counting, but kanji numerals are still used in compounds, such as "tōitsu" ("unification").

Historically, attempts to limit the number of kanji in use commenced in the mid-19th century, but did not become a matter of government intervention until after Japan's defeat in the Second World War. During the period of post-war occupation (and influenced by the views of some U.S. officials), various schemes including the complete abolition of kanji and exclusive use of rōmaji were considered. The "jōyō kanji" ("common use kanji", originally called "tōyō kanji" [kanji for general use]) scheme arose as a compromise solution.

Japanese students begin to learn kanji from their first year at elementary school. A guideline created by the Japanese Ministry of Education, the list of "kyōiku kanji" ("education kanji", a subset of "jōyō kanji"), specifies the 1,006 simple characters a child is to learn by the end of sixth grade. Children continue to study another 1,130 characters in junior high school, covering in total 2,136 "jōyō kanji". The official list of "jōyō kanji" was revised several times, but the total number of officially sanctioned characters remained largely unchanged.

As for kanji for personal names, the circumstances are somewhat complicated. "Jōyō kanji" and "jinmeiyō kanji" (an appendix of additional characters for names) are approved for registering personal names. Names containing unapproved characters are denied registration. However, as with the list of "jōyō kanji", criteria for inclusion were often arbitrary and led to many common and popular characters being disapproved for use. Under popular pressure and following a court decision holding the exclusion of common characters unlawful, the list of "jinmeiyō kanji" was substantially extended from 92 in 1951 (the year it was first decreed) to 983 in 2004. Furthermore, families whose names are not on these lists were permitted to continue using the older forms.

"Hiragana" are used for words without kanji representation, for words no longer written in kanji, and also following kanji to show conjugational endings. Because of the way verbs (and adjectives) in Japanese are conjugated, kanji alone cannot fully convey Japanese tense and mood, as kanji cannot be subject to variation when written without losing their meaning. For this reason, hiragana are appended to kanji to show verb and adjective conjugations. Hiragana used in this way are called okurigana. Hiragana can also be written in a superscript called furigana above or beside a kanji to show the proper reading. This is done to facilitate learning, as well as to clarify particularly old or obscure (or sometimes invented) readings.

"Katakana", like hiragana, constitute a syllabary; katakana are primarily used to write foreign words, plant and animal names, and for emphasis. For example, "Australia" has been adapted as "Ōsutoraria" (), and "supermarket" has been adapted and shortened into "sūpā" ().

Many major universities throughout the world provide Japanese language courses, and a number of secondary and even primary schools worldwide offer courses in the language. This is much changed from before World War II; in 1940, only 65 Americans not of Japanese descent were able to read, write and understand the language.

International interest in the Japanese language dates from the 19th century but has become more prevalent following Japan's economic bubble of the 1980s and the global popularity of Japanese popular culture (such as anime and video games) since the 1990s. As of 2015, more than 3.6 million people studied the language worldwide, primarily in East and Southeast Asia. Nearly one million Chinese, 745,000 Indonesians, 556,000 South Koreans and 357,000 Australians studied Japanese in lower and higher educational institutions. Between 2012 and 2015, considerable growth of learners originated in Australia (20.5%), Thailand (34.1%), Vietnam (38.7%) and the Philippines (54.4%).

As of 2017, more than 267,000 foreign students study at Japanese universities and Japanese language schools, including 107,260 Chinese, 61,670 Vietnamese and 21,500 Nepalese. In addition, local governments and some NPO groups provide free Japanese language classes for foreign residents, including Japanese Brazilians and foreigners married to Japanese nationals. In the United Kingdom, study of the Japanese language is supported by the British Association for Japanese Studies. In Ireland, Japanese is offered as a language in the Leaving Certificate in some schools.

The Japanese government provides standardized tests to measure spoken and written comprehension of Japanese for second language learners; the most prominent is the Japanese Language Proficiency Test (JLPT), which features five levels of exams (changed from four levels in 2010), ranging from elementary (N5) to advanced (N1). The JLPT is offered twice a year. The Japanese External Trade Organization JETRO organizes the "Business Japanese Proficiency Test" which tests the learner's ability to understand Japanese in a business setting. The Japan Kanji Aptitude Testing Foundation, which took over the BJT from JETRO in 2009, announced in August 2010 that the test would be discontinued in 2011 due to financial pressures on the Foundation. However, it has since issued a statement to the effect that the test will continue to be available as a result of support from the Japanese government.





</doc>
<doc id="15608" url="https://en.wikipedia.org/wiki?curid=15608" title="Johnny Got His Gun">
Johnny Got His Gun

Johnny Got His Gun is an anti-war novel written in 1938 by American novelist, and later blacklisted screenwriter, Dalton Trumbo, and published in September 1939 by J. B. Lippincott. The novel won one of the early National Book Awards: the Most Original Book of 1939. A 1971 film adaptation was written for the screen and directed by Trumbo himself.

Joe Bonham, a young American soldier serving in World War I, awakens in a hospital bed after being caught in the blast of an exploding artillery shell. He gradually realizes that he has lost his arms, legs, and all of his face (including his eyes, ears, teeth, and tongue), but that his mind functions perfectly, leaving him a prisoner in his own body.

Joe later attempts suicide by suffocation, but finds that he has had a tracheotomy that he can neither remove nor control. At first Joe wishes to die, but he later decides that he desires to be placed in a glass box and toured around the country in order to show others the true horrors of war. Joe successfully communicates these desires with military officials after months and months of banging his head on his pillow in Morse code. However, he realizes that the military will not grant his wishes, as it is "against regulations". It is implied that he will live the rest of his natural life in his condition.

As Joe drifts between reality and fantasy, he remembers his old life with his family and girlfriend, and reflects upon the myths and realities of war.

Joe Bonham is the main character. "The novel mainly consists of his reminiscences of childhood and his current struggle to remain sane and, finally, to communicate."

"As a caretaker, capable of great humanistic love, the regular day nurse stands apart from the terse medical establishment, represented by the Morse code man, yet is not capable of the perceptive sympathy of the new day nurse."

Joe's father, Bill Bonham, courted Joe's mother and raised a family with her in Colorado. "His character comes to stand for Joe's nostalgia for an older way of life." It is also said that Bill passes away (chapter 1) leaving his mother and his younger sisters alone (one aged 13 years, the other aged about 9 years).

Joe's mother, Marcia Bonham, was always close to Joe and Bill. She is referenced regularly in the book singing, cooking/baking and playing the piano often.

Kareen (who was aged 19 years at the time of Joe's departure) is mentioned throughout the book as Joe floats between reality and fantasy. She and Joe sleep together for the first time (chapter 3) the night before he leaves, with her father's approval.

Diane is only mentioned in chapter 4. In that chapter it is mentioned that she cheated on Joe with a boy named Glen Hogan. She also cheats on Joe with his best friend, Bill Harper (who told him that she cheated with Hogan).

Bill Harper warns Joe that Diane has cheated on him with Glen Hogan. Joe, who doesn't believe the news, hits Bill. Joe later finds out Bill was truthful and decides that he wants to renew their friendship. However, he finds Bill and Diane making out at her home and is hurt by both. The end of chapter 4 references how Bill was killed at Belleau Wood.

Joe meets Howie (chapter 4) after his troubles with Diane and Glen Hogan. It seems that Howie was never able to keep a girl in his life, and his girlfriend Onie also cheated on him with Glen Hogan. Joe and Howie decide not only to forget about their girlfriends but also about Glen Hogan. Joe and Howie join a group of Mexicans working on a railroad. However, once Howie receives an apologetic telegram from Onie, the boys decide to return home.

José worked at a bakery with Joe. He was given the job at the bakery through the local homeless shelter. José has many stories that set him apart from the other homeless workers, including the fact that he refused marriage to a wealthy woman. José wanted to work in Hollywood. When the opportunity presented itself to work for a picture company, José purposely gets fired because he feels his own personal honor will not allow him to quit on the boss that gave him his original opportunity.

The new day nurse was the first person to successfully communicate with Joe after his injuries. She moved her finger on his bare chest in the shape of the letter M until Joe signaled that he understood "M". She then spelled out "MERRY CHRISTMAS" and Joe signaled that he understood. The new day nurse then deduced that Joe's head-banging was in Morse Code and fetched someone who knew Morse Code.

The title is a play on the phrase "Johnny get your gun",
a rallying call that was commonly used to encourage young American men to enlist in the military in the late 19th and early 20th centuries. That phrase was popularized in the George M. Cohan song "Over There", which was widely recorded in the first year of American involvement in World War I; the versions by Al Jolson, Enrico Caruso, and Nora Bayes are believed to have sold the most copies on phonograph records at the time. "Johnny Get Your Gun" is also the name of a 1919 film directed by Donald Crisp.

Many of protagonist Joe Bonham's early memories are based on Dalton Trumbo's early life in Colorado and Los Angeles. The novel was inspired by an article he read about the Prince of Wales' visit to a Canadian veterans hospital to see a soldier who had lost all of his senses and his limbs. "Though the novel was a pacifist piece published in wartime, it was well reviewed and won an American Booksellers Award in 1940."

Serialized in the "Daily Worker" in March 1940, the book became "a rally point for the political left" which had opposed involvement in World War II during the period of the Molotov–Ribbentrop Pact. Shortly after the 1941 German invasion of the Soviet Union, Trumbo and his publishers decided to suspend reprinting the book until the end of the war. After receiving letters from right-wing isolationists requesting copies of the book, Trumbo contacted the FBI and turned these letters over to them. Trumbo regretted this decision, which he later called "foolish," after two FBI agents showed up at his home and it became clear that "their interest lay not in the letters but in me."









</doc>
<doc id="15611" url="https://en.wikipedia.org/wiki?curid=15611" title="Simon–Ehrlich wager">
Simon–Ehrlich wager

The Simon–Ehrlich wager was a 1980 scientific wager between business professor Julian L. Simon and biologist Paul Ehrlich, betting on a mutually agreed-upon measure of resource scarcity over the decade leading up to 1990. The widely-followed contest originated in the pages of "Social Science Quarterly", where Simon challenged Ehrlich to put his money where his mouth was. In response to Ehrlich's published claim that "If I were a gambler, I would take even money that England will not exist in the year 2000" Simon offered to take that bet, or, more realistically, "to stake US$10,000 ... on my belief that the cost of non-government-controlled raw materials (including grain and oil) will not rise in the long run."

Simon challenged Ehrlich to choose any raw material he wanted and a date more than a year away, and he would wager on the inflation-adjusted prices decreasing as opposed to increasing. Ehrlich chose copper, chromium, nickel, tin, and tungsten. The bet was formalized on September 29, 1980, with September 29, 1990, as the payoff date. Ehrlich lost the bet, as all five commodities that were bet on declined in price from 1980 through 1990, the wager period.

In 1968, Ehrlich published "The Population Bomb", which argued that mankind was facing a demographic catastrophe with the rate of population growth quickly outstripping growth in the supply of food and resources. Simon was highly skeptical of such claims, so proposed a wager, telling Ehrlich to select any raw material he wanted and select "any date more than a year away," and Simon would bet that the commodity's price on that date would be lower than what it was at the time of the wager.

Ehrlich and his colleagues picked five metals that they thought would undergo big price increases: chromium, copper, nickel, tin, and tungsten. Then, on paper, they bought $200 worth of each, for a total bet of $1,000, using the prices on September 29, 1980, as an index. They designated September 29, 1990, 10 years hence, as the payoff date. If the inflation-adjusted prices of the various metals rose in the interim, Simon would pay Ehrlich the combined difference. If the prices fell, Ehrlich et al. would pay Simon.

Between 1980 and 1990, the world's population grew by more than 800 million, the largest increase in one decade in all of history. But by September 1990, the price of each of Ehrlich's selected metals had fallen. Chromium, which had sold for $3.90 a pound in 1980, was down to $3.70 in 1990. Tin, which was $8.72 a pound in 1980, was down to $3.88 a decade later.

As a result, in October 1990, Paul Ehrlich mailed Julian Simon a check for $576.07 to settle the wager in Simon's favor.

Julian Simon won because the price of three of the five metals went down in nominal terms and all five of the metals fell in price in inflation-adjusted terms, with both tin and tungsten falling by more than half. In his book "Betrayal of Science and Reason", Ehrlich wrote that Simon "[asserted] that humanity would never run out of anything". Ehrlich added that he and fellow scientists viewed renewable resources as more important indicators of the state of planet Earth, but that he decided to go along with the bet anyway. Afterward, Simon offered to raise the wager to $20,000 and to use any resources at any time that Ehrlich preferred. Ehrlich countered with a challenge to bet that temperatures would increase in the future. The two were unable to reach an agreement on the terms of a second wager before Simon died.

Ehrlich could have won if the bet had been for a different ten-year period. Ehrlich wrote that the five metals in question had increased in price between the years 1950 and 1975. Asset manager Jeremy Grantham wrote that if the Simon–Ehrlich wager had been for a longer period (from 1980 to 2011), then Simon would have lost on four of the five metals. He also noted that if the wager had been expanded to "all of the most important commodities," instead of just five metals, over that longer period of 1980 to 2011, then Simon would have lost "by a lot." 

Economist Mark J. Perry noted that for an even longer period of time, from 1934 to 2013, the inflation-adjusted price of the Dow Jones-AIG Commodities Index showed "an overall significant downward trend" and concluded that Simon was "more right than lucky". Economist Tim Worstall wrote that "The end result of all of this is that yes, it is true that Ehrlich could have, would have, won the bet depending upon the starting date. ... But the long term trend for metals at least is downwards."

Understanding that Simon wanted to bet again, Ehrlich and climatologist Stephen Schneider counter-offered, challenging Simon to bet on 15 current trends, betting $1000 that each will get worse (as in the previous wager) over a ten-year future period.

The trends they bet would continue to worsen were:

Simon declined Ehrlich and Schneider's offer to bet, and used the following analogy to explain why he did so:

In his 1981 book "The Ultimate Resource", Simon noted that not all decreases in resources or increases in unwanted effects correspond to overall decreases in human wellbeing. Hence there can be an "optimal level of pollution" which accepts some increases in certain kinds of pollution in a way that increases overall wellbeing, while acknowledging that any increase in pollution is nevertheless a cost which must be considered in any such calculation (p. 143). Some of the trends listed above are actually predicted by Simon's theory of resource development, and do not in themselves even count as costs (as pollution does). E.g., he pointed out that due to increased efficiency, the amount of cropland required and actually used to grow food for each person has decreased over time and is likely to continue to do so (p. 5). The same might potentially be true of decreased reliance on firewood in developing countries, and per capita use of specific food sources like rice, wheat, and fish, if economic development makes a diverse range of alternative foods available. Some have also proven false, e.g., the amount of ozone in the lower atmosphere has decreased from 1994 to 2004.

In 1996, Simon bet $1000 with David South, professor of the Auburn University School of Forestry, that the inflation-adjusted price of timber would decrease in the following five years. Simon paid out early on the bet in 1997 (before his death in 1998) based on his expectation that prices would remain above 1996 levels (which they did).

In 1999, when "The Economist" headlined an article entitled, "$5 a barrel oil soon?" and with oil trading in the $12/barrel range, David South offered $1000 to any economist who would bet with him that the price of oil would be greater than $12/barrel in 2010. No economist took him up on the offer. However, in October 2000, Zagros Madjd-Sadjadi, an economist with The University of the West Indies, bet $1000 with David South that the inflation-adjusted price of oil would decrease to an inflation-adjusted price of $25 by 2010 (down from what was then $30/barrel). Madjd-Sadjadi paid South an inflation-adjusted $1,242 in January 2010. The price of oil at the time was $81/barrel.





</doc>
<doc id="15612" url="https://en.wikipedia.org/wiki?curid=15612" title="John Tenniel">
John Tenniel

Sir John Tenniel (28 February 1820 – 25 February 1914) was an English illustrator, graphic humorist, and political cartoonist prominent in the second half of the 19th century. He was knighted for his artistic achievements in 1893. Tenniel is remembered especially as the principal political cartoonist for "Punch" magazine for over 50 years, and for his illustrations to Lewis Carroll's "Alice's Adventures in Wonderland" (1865) and "Through the Looking-Glass, and What Alice Found There" (1871).

Tenniel was born in Bayswater, West London, to John Baptist Tenniel, a fencing and dancing master of Huguenot descent, and Eliza Maria Tenniel. Tenniel had five siblings; two brothers and three sisters. One sister, Mary, was later to marry Thomas Goodwin Green, owner of the pottery that produced Cornishware. Tenniel was a quiet and introverted person, both as a boy and as an adult. He was content to remain firmly out of the limelight and seemed unaffected by competition or change. His biographer Rodney Engen wrote that Tenniel's "life and career was that of the supreme gentlemanly outside, living on the edge of respectability."

In 1840, Tenniel, while practising fencing with his father, received a serious eye wound from his father's foil, which had accidentally lost its protective tip. Over the years, Tenniel gradually lost sight in his right eye; he never told his father of the severity of the wound, as he did not wish to upset his father further.

In spite of his tendency towards high art, Tenniel was already known and appreciated as a humorist and his early companionship with Charles Keene fostered and developed his talent for scholarly caricature.

Tenniel became a student of the Royal Academy of Arts in 1842 by probation – he was admitted because he had made enough copies of classical sculptures to fill the necessary admission portfolio. So it was here that Tenniel returned to his earlier independent education.

While Tenniel's more formal training at the Royal Academy and other institutions was beneficial in nurturing his artistic ambitions, it failed in Tenniel's mind because he disagreed with the school's teaching methods, and so set about educating himself for his career. Tenniel studied classical sculptures through painting. However, he was frustrated in this because he lacked instruction in drawing. Tenniel would draw the classical statues at the London's Townley Gallery, copy illustrations from books of costumes and armour in the British Museum, and draw animals from the zoo in Regent's Park, as well as actors from London theatres, which he drew from the pits. These studies taught Tenniel to love detail, yet he became impatient in his work and was happiest when he could draw from memory. Though he was blessed with a photographic memory, it undermined his early formal training and restricted his artistic ambitions.

Another "formal" means of training was Tenniel's participation in an artists' group, free from the rules of the Academy that were stifling him. In the mid-1840s he joined the Artist's Society or Clipstone Street Life Academy, and it could be said that Tenniel first emerged as a satirical draughtsman.

Tenniel's first book illustration was for Samuel Carter Hall's "The Book of British Ballads", in 1842. While engaged with his first book illustrations, various contests were taking place in London, as a way in which the government could combat the growing Germanic Nazarenes style and promote a truly national English school of art. Tenniel planned to enter the 1845 House of Lords competition amongst artists to win the opportunity to design the mural decoration of the new Palace of Westminster. Despite missing the deadline, he submitted a cartoon, "An Allegory of Justice", to a competition for designs for the mural decoration of the new Palace of Westminster. For this he received a £200 premium and a commission to paint a fresco in the Upper Waiting Hall (or Hall of Poets) in the House of Lords.

As the influential result of his position as the chief cartoon artist for "Punch", John Tenniel remained through satirical, often radical and at times vitriolic images of the world Britain's steadfast witness to sweeping changes in political and social reform. At Christmas 1850 he was invited by Mark Lemon to fill the position of joint cartoonist (with John Leech) on "Punch", having been selected on the strength of recent illustrations to Aesop's "Fables". He contributed his first drawing in the initial letter appearing on p. 224, vol. xix. This was entitled "Lord Jack the Giant Killer" and showed Lord John Russell assailing Cardinal Wiseman.

In 1861, Tenniel was offered John Leech's position at "Punch", as political cartoonist, but Tenniel still maintained a sense of decorum and restraint in the heated social and political issues of the day.

His task was to follow the willful choices of his "Punch" editors, who probably took their cue from "The Times" and would have felt the suggestions of political tensions from Parliament as well. Tenniel's work could be scathing in effect. The restlessness in the issues of working-class radicalism, labor, war, economy, and other national themes were the targets of "Punch", which in turn settled the nature of Tenniel's subjects. His cartoons of the 1860s popularized a portrait of the Irishman as a sub-human being, wanton in his appetites and resembling an orangutan in facial features and posture. Many of Tenniel's political cartoons expressed strong hostility to Irish Nationalism, with Fenians and Land leagues depicted as monstrous, ape-like brutes, while "Hibernia" – the personification of Ireland – was depicted as a beautiful, helpless girl threatened by such "monsters" and turning for protection to an "elder sister" in the shape of a powerful armoured Britannia.

"An Unequal Match", his drawing published in "Punch" on 8 October 1881, depicted a police officer fighting a criminal with only a baton for protection, trying to put a point across to the public that policing methods needed to be changed.

When examined separately from the book illustrations he did over time, Tenniel's work at "Punch" alone, expressing decades of editorial viewpoints, often controversial and socially sensitive, was created to echo the voices of the British public. Tenniel drew 2,165 cartoons for "Punch", a liberal and politically active publication that mirrored the Victorian public's mood for liberal social changes; thus Tenniel, in his cartoons, represented for years the conscience of the British majority.

Tenniel contributed around 2,300 cartoons, innumerable minor drawings, many double-page cartoons for "Punch's Almanac" and other specials, and 250 designs for "Punch's Pocket-books". By 1866 he could "command ten to fifteen guineas for the reworking of a single "Punch" cartoon as a pencil sketch," alongside his "comfortable" "Punch" salary "of about £800 a year".

Despite the thousands of political cartoons and hundreds of illustrative works attributed to him, much of Tenniel's fame stems from his illustrations for "Alice". Tenniel drew 92 drawings for Lewis Carroll's "Alice's Adventures in Wonderland" (London: Macmillan, 1865) and "Through the Looking-Glass and What Alice Found There" (London: Macmillan, 1871).

Lewis Carroll originally illustrated "Wonderland" himself, but his artistic abilities were limited. Engraver Orlando Jewitt, who had worked for Carroll in 1859 and reviewed Carroll's drawings for "Wonderland", suggested that he employ a professional. Carroll was a regular reader of "Punch" and therefore familiar with Tenniel, who in 1865 had long talks with Carroll before illustrating the first edition of "Alice's Adventures in Wonderland".

The first print run of 2,000 was sold in the United States, rather than England, because Tenniel objected to the print quality. A new edition was released in December 1865, carrying an 1866 date, and became an instant best-seller, increasing Tenniel's fame. His drawings for both books have become some of the most famous literary illustrations. After 1872, when the Carroll projects were finished, Tenniel largely abandoned literary illustration. Carroll did later approach Tenniel to undertake another project for him. To this Tenniel replied:
Tenniel's illustrations for the "Alice" books were engraved onto blocks of deal wood by the Brothers Dalziel. These engravings were then used as masters for making the electrotype copies for the actual printing of the books. The original wood blocks are held in the collection of the Bodleian Library in Oxford. They are not usually on public display, but were exhibited in 2003.

The style associated with the Nazarene movement of the 19th century influenced many later artists, including Tenniel. It can be characterized as "shaded outlines", where the lines on the side of figures or objects are given extra thickness or drawn double to suggest shading or volume. Furthermore, this style is extremely precise, with the artist making a hard clear outline for its figures, dignifying them and the compositions, while giving restraint in expression and paleness of tone. Though Tenniel's early illustrations in the Nazarene style were not well received, his encounter with the style pointed him in a good direction.

After the 1850s, Tenniel's style modernized to incorporate more detail in backgrounds and in figures. The inclusion of background details corrected the previously weak Germanic staging of his illustrations. Tenniel's more precisely-designed illustrations depicted specific moments of time, locale, and individual character instead of just generalized scenes.

In addition to a change in specificity of background, Tenniel developed a new interest in human types, expressions, and individualized representation, something that would carry over into Tenniel's illustrations of Wonderland. Referred to by many as theatricalism, this hallmark of Tenniel's style probably stemmed from his earlier interest in caricature. In Tenniel's first years on "Punch" he developed this caricaturist's interest in the uniqueness of persons and things, almost giving a human like personality to the objects in the environment. For example, in a comparison to one of John Everett Millais's illustration of a girl in a chair with Tenniel's illustration of Alice in a chair, one can see how where Millais's chair is just a prop, Tenniel's chair possesses a menacing and towering presence.

Another change in style was his shaded lines. These transformed from mechanical horizontal lines to vigorously hand-drawn hatching that greatly intensified darker areas.

Tenniel's "grotesqueness" was one reason why Lewis Carroll wanted Tenniel as his illustrator for the "Alice" books, in the sense of imparting a disturbing sense that the real world may have ceased to be reliable. Tenniel's style was characteristically grotesque through dark, atmospheric compositions of exaggerated fantasy creatures carefully drawn in outline. Often the mechanism was to use animal heads on recognizable human bodies or vice versa, as Grandville had done in the Parisian satirical journal "Charivari". In Tenniel's illustrations, the grotesque is found also in mergers of beings and things, deformities in and violence to the human body (e. g. when Alice drinks the potion and grows huge), and a proclivity to deal with ordinary things of this world while presenting such phenomena. The most noticeably grotesque is Tenniel's famous Jabberwock drawing in "Alice".

The "Alice" illustrations combine fantasy and reality. Scholars such as Morris trace Tenniel's stylistic change to the late 1850s trend towards realism. For the grotesque to operate, "it is our world which has to be transformed and not some fantasy realm." The illustrations constantly but subtly remind us of the real world, as do some of Tenniel's scenes derived from a medieval town, the portico of a Georgian town, or the checked jacket on the White Rabbit. Additionally, Tenniel closely follows Carroll's text, so that see the similitude between the written text and the illustrations. These touches of realism help to convince readers that all these seemingly grotesque inhabitants of Wonderland are simply themselves, simply real, not just performing.

One unusual aspect of the "Alice" books is the placing of Tenniel's illustrations on the pages. This physical relation of illustrations to text meshes them together. Carroll and Tenniel expressed this in various ways. One was bracketing: two relevant sentences would bracket an image as a way of imparting the moment that Tenniel was trying to illustrate. This bracketing of Tenniel's pictures by the text adds to their "dramatic immediacy." However, other, less frequent illustrations work with the texts as captions.

Another link between illustration and text is the use of broader and narrower illustrations. Broader ones are meant to be centred on the page, narrower ones to be "let in" or run flush to the margin, alongside a narrow column of continuing text. Still, words run in parallel with the depiction of those things. For example, when Alice says, "Oh, my poor little feet!", it not only occurs at the foot of the page but is right next to her feet in the illustration. Some of these narrower illustrations are "L"-shaped, and of great importance as some of his most memorable work. The top or base of the illustrations runs the full width of the page. but the other end leaves room on one side for the text.

A selected list:

Entirely by Tenniel

Tenniel's different collaborations:

An ultimate tribute came to an elderly Tenniel as he was knighted for his public service in 1893 by Queen Victoria. It was the first such honour ever bestowed on an illustrator or cartoonist, and his fellows saw his knighting as gratitude for "raising what had been a fairly lowly profession to an unprecedented level of respectability". With knighthood, Tenniel elevated the social status of the black and white illustrator, and sparked a new sense of recognition of his profession. When he retired in January 1901, Tenniel was honoured with a farewell banquet (12 June), at which AJ Balfour, then Leader of the House of Commons, presided.

Tenniel died on 25 February 1914, aged 93.

"Punch" historian M. H. Spielmann, who knew Tenniel, wrote that the political clout contained in his "Punch" cartoons was capable of "swaying parties and people, too... (the cartoons) exercised great influence" on the ideas of popular reform skirting throughout the British public. Two days after his death, "The Daily Graphic" recalled Tenniel: "He had an influence on the political feeling of this time which is hardly measurable ... While Tenniel was drawing them (his subjects), we always looked to the Punch cartoon to crystallize the national and international situation, and the popular feeling about it—and never looked in vain." This condition of social influence resulted from the weekly publishing over a fifty-year span of his political cartoons, whereby Tenniel's fame allowed for a want and need for his particular illustrative work, away from the newspaper. Tenniel became not only one of Victorian Britain's most published illustrators, but as a "Punch" cartoonist he became one of the "supreme social observers" of British society, and an integral component of a powerful journalistic force. Also in 1914, the "New-York Tribune" journalist George W. Smalley referred to John Tenniel as "one of the greatest intellectual forces of his time, (who) understood social laws and political energies."

Public exhibitions of Sir John Tenniel's work were held in 1895 and in 1900. Sir John Tenniel is also the author of one of the mosaics, "Leonardo da Vinci", in the South Court in the Victoria and Albert Museum; his highly stippled watercolour drawings appeared from time to time in the exhibitions of the Royal Institute of Painters in Water Colours, of which he had been elected a member in 1874.

A Bayswater street, Tenniel Close, near his former studio, is named after him.




</doc>
<doc id="15613" url="https://en.wikipedia.org/wiki?curid=15613" title="Jazz">
Jazz

Jazz is a music genre that originated in the African-American communities of New Orleans, United States. It originated in the late 19th and early 20th centuries, and developed from roots in blues and ragtime. Jazz is seen by many as "America's classical music". Since the 1920s Jazz Age, jazz has become recognized as a major form of musical expression. It then emerged in the form of independent traditional and popular musical styles, all linked by the common bonds of African-American and European-American musical parentage with a performance orientation. Jazz is characterized by swing and blue notes, call and response vocals, polyrhythms and improvisation. Jazz has roots in West African cultural and musical expression, and in African-American music traditions including blues and ragtime, as well as European military band music. Intellectuals around the world have hailed jazz as "one of America's original art forms".

As jazz spread around the world, it drew on national, regional, and local musical cultures, which gave rise to different styles. New Orleans jazz began in the early 1910s, combining earlier brass-band marches, French quadrilles, biguine, ragtime and blues with collective polyphonic improvisation. In the 1930s, heavily arranged dance-oriented swing big bands, Kansas City jazz, a hard-swinging, bluesy, improvisational style and Gypsy jazz (a style that emphasized musette waltzes) were the prominent styles. Bebop emerged in the 1940s, shifting jazz from danceable popular music toward a more challenging "musician's music" which was played at faster tempos and used more chord-based improvisation. Cool jazz developed near the end of the 1940s, introducing calmer, smoother sounds and long, linear melodic lines.

The 1950s saw the emergence of free jazz, which explored playing without regular meter, beat and formal structures, and in the mid-1950s, hard bop emerged, which introduced influences from rhythm and blues, gospel, and blues, especially in the saxophone and piano playing. Modal jazz developed in the late 1950s, using the mode, or musical scale, as the basis of musical structure and improvisation. Jazz-rock fusion appeared in the late 1960s and early 1970s, combining jazz improvisation with rock music's rhythms, electric instruments, and highly amplified stage sound. In the early 1980s, a commercial form of jazz fusion called smooth jazz became successful, garnering significant radio airplay. Other styles and genres abound in the 2000s, such as Latin and Afro-Cuban jazz.

The origin of the word "jazz" has resulted in considerable research, and its history is well documented. It is believed to be related to "jasm", a slang term dating back to 1860 meaning "pep, energy". The earliest written record of the word is in a 1912 article in the "Los Angeles Times" in which a minor league baseball pitcher described a pitch which he called a "jazz ball" "because it wobbles and you simply can't do anything with it".

The use of the word in a musical context was documented as early as 1915 in the "Chicago Daily Tribune." Its first documented use in a musical context in New Orleans was in a November 14, 1916 "Times-Picayune" article about "jas bands". In an interview with NPR, musician Eubie Blake offered his recollections of the slang connotations of the term, saying, "When Broadway picked it up, they called it 'J-A-Z-Z'. It wasn't called that. It was spelled 'J-A-S-S'. That was dirty, and if you knew what it was, you wouldn't say it in front of ladies." The American Dialect Society named it the Word of the 20th Century.

Jazz is difficult to define because it encompasses a wide range of music spanning a period of over 100 years, from ragtime to the rock-infused fusion. Attempts have been made to define jazz from the perspective of other musical traditions, such as European music history or African music. But critic Joachim-Ernst Berendt argues that its terms of reference and its definition should be broader, defining jazz as a "form of art music which originated in the United States through the confrontation of the Negro with European music" and arguing that it differs from European music in that jazz has a "special relationship to time defined as 'swing. Jazz involves "a spontaneity and vitality of musical production in which improvisation plays a role" and contains a "sonority and manner of phrasing which mirror the individuality of the performing jazz musician". In the opinion of Robert Christgau, "most of us would say that inventing meaning while letting loose is the essence and promise of jazz".

A broader definition that encompasses different eras of jazz has been proposed by Travis Jackson: "it is music that includes qualities such as swing, improvising, group interaction, developing an 'individual voice', and being open to different musical possibilities". Krin Gibbard argued that "jazz is a construct" which designates "a number of musics with enough in common to be understood as part of a coherent tradition". In contrast to commentators who have argued for excluding types of jazz, musicians are sometimes reluctant to define the music they play. Duke Ellington, one of jazz's most famous figures, said, "It's all music."

Although jazz is considered difficult to define, in part because it contains many subgenres, improvisation is one of its defining elements. The centrality of improvisation is attributed to the influence of earlier forms of music such as blues, a form of folk music which arose in part from the work songs and field hollers of African-American slaves on plantations. These work songs were commonly structured around a repetitive call-and-response pattern, but early blues was also improvisational. Classical music performance is evaluated more by its fidelity to the musical score, with less attention given to interpretation, ornamentation, and accompaniment. The classical performer's goal is to play the composition as it was written. In contrast, jazz is often characterized by the product of interaction and collaboration, placing less value on the contribution of the composer, if there is one, and more on the performer. The jazz performer interprets a tune in individual ways, never playing the same composition twice. Depending on the performer's mood, experience, and interaction with band members or audience members, the performer may change melodies, harmonies, and time signatures.

In early Dixieland, a.k.a. New Orleans jazz, performers took turns playing melodies and improvising countermelodies. In the swing era of the 1920s–'40s, big bands relied more on arrangements which were written or learned by ear and memorized. Soloists improvised within these arrangements. In the bebop era of the 1940s, big bands gave way to small groups and minimal arrangements in which the melody was stated briefly at the beginning and most of the song was improvised. Modal jazz abandoned chord progressions to allow musicians to improvise even more. In many forms of jazz, a soloist is supported by a rhythm section of one or more chordal instruments (piano, guitar), double bass, and drums. The rhythm section plays chords and rhythms that outline the song structure and complement the soloist. In avant-garde and free jazz, the separation of soloist and band is reduced, and there is license, or even a requirement, for the abandoning of chords, scales, and meters.

Since the emergence of bebop, forms of jazz that are commercially oriented or influenced by popular music have been criticized. According to Bruce Johnson, there has always been a "tension between jazz as a commercial music and an art form". Traditional jazz enthusiasts have dismissed bebop, free jazz, and jazz fusion as forms of debasement and betrayal. An alternative view is that jazz can absorb and transform diverse musical styles. By avoiding the creation of norms, jazz allows avant-garde styles to emerge.

For some African Americans, jazz has drawn attention to African-American contributions to culture and history. For others, jazz is a reminder of "an oppressive and racist society and restrictions on their artistic visions". Amiri Baraka argues that there is a "white jazz" genre that expresses whiteness. White jazz musicians appeared in the midwest and in other areas throughout the U.S. Papa Jack Laine, who ran the Reliance band in New Orleans in the 1910s, was called "the father of white jazz". The Original Dixieland Jazz Band, whose members were white, were the first jazz group to record, and Bix Beiderbecke was one of the most prominent jazz soloists of the 1920s. The Chicago Style was developed by white musicians such as Eddie Condon, Bud Freeman, Jimmy McPartland, and Dave Tough. Others from Chicago such as Benny Goodman and Gene Krupa became leading members of swing during the 1930s. Many bands included both black and white musicians. These musicians helped change attitudes toward race in the U.S.

Female jazz performers and composers have contributed to jazz throughout its history. Although Betty Carter, Ella Fitzgerald, Adelaide Hall, Billie Holiday, Abbey Lincoln, Anita O'Day, Dinah Washington, and Ethel Waters were recognized for their vocal talent, less familiar were bandleaders, composers, and instrumentalists such as pianist Lil Hardin Armstrong and songwriters Irene Higginbotham and Dorothy Fields. Women began playing instruments in jazz in the early 1920s, drawing particular recognition on piano.

When male jazz musicians were drafted during World War II, many all-female bands replaced them. The International Sweethearts of Rhythm, which was founded in 1937, was a popular band that became the first all-female integrated band in the U.S. and the first to travel with the USO, touring Europe in 1945. Women were members of the big bands of Woody Herman and Gerald Wilson. Beginning in the 1950s, many women jazz instrumentalists were prominent, some sustaining long careers. Some of the most distinctive improvisers, composers, and bandleaders in jazz have been women.

Jazz originated in the late-19th to early-20th century as interpretations of American and European classical music entwined with African and slave folk songs and the influences of West African culture. Its composition and style have changed many times throughout the years with each performer's personal interpretation and improvisation, which is also one of the greatest appeals of the genre.

 By the 18th century, slaves in the New Orleans area gathered socially at a special market, in an area which later became known as Congo Square, famous for its African dances.

By 1866, the Atlantic slave trade had brought nearly 400,000 Africans to North America. The slaves came largely from West Africa and the greater Congo River basin and brought strong musical traditions with them. The African traditions primarily use a single-line melody and call-and-response pattern, and the rhythms have a counter-metric structure and reflect African speech patterns.

An 1885 account says that they were making strange music (Creole) on an equally strange variety of 'instruments'—washboards, washtubs, jugs, boxes beaten with sticks or bones and a drum made by stretching skin over a flour-barrel.

Lavish festivals with African-based dances to drums were organized on Sundays at Place Congo, or Congo Square, in New Orleans until 1843. There are historical accounts of other music and dance gatherings elsewhere in the southern United States. Robert Palmer said of percussive slave music:

Usually such music was associated with annual festivals, when the year's crop was harvested and several days were set aside for celebration. As late as 1861, a traveler in North Carolina saw dancers dressed in costumes that included horned headdresses and cow tails and heard music provided by a sheepskin-covered "gumbo box", apparently a frame drum; triangles and jawbones furnished the auxiliary percussion. There are quite a few [accounts] from the southeastern states and Louisiana dating from the period 1820–1850. Some of the earliest [Mississippi] Delta settlers came from the vicinity of New Orleans, where drumming was never actively discouraged for very long and homemade drums were used to accompany public dancing until the outbreak of the Civil War.
Another influence came from the harmonic style of hymns of the church, which black slaves had learned and incorporated into their own music as spirituals. The origins of the blues are undocumented, though they can be seen as the secular counterpart of the spirituals. However, as Gerhard Kubik points out, whereas the spirituals are homophonic, rural blues and early jazz "was largely based on concepts of heterophony."

During the early 19th century an increasing number of black musicians learned to play European instruments, particularly the violin, which they used to parody European dance music in their own cakewalk dances. In turn, European-American minstrel show performers in blackface popularized the music internationally, combining syncopation with European harmonic accompaniment. In the mid-1800s the white New Orleans composer Louis Moreau Gottschalk adapted slave rhythms and melodies from Cuba and other Caribbean islands into piano salon music. New Orleans was the main nexus between the Afro-Caribbean and African-American cultures.

The Black Codes outlawed drumming by slaves, which meant that African drumming traditions were not preserved in North America, unlike in Cuba, Haiti, and elsewhere in the Caribbean. African-based rhythmic patterns were retained in the United States in large part through "body rhythms" such as stomping, clapping, and patting juba dancing.

In the opinion of jazz historian Ernest Borneman, what preceded New Orleans jazz before 1890 was "Afro-Latin music", similar to what was played in the Caribbean at the time. A three-stroke pattern known in Cuban music as "tresillo" is a fundamental rhythmic figure heard in many different slave musics of the Caribbean, as well as the Afro-Caribbean folk dances performed in New Orleans Congo Square and Gottschalk's compositions (for example "Souvenirs From Havana" (1859)). Tresillo (shown below) is the most basic and most prevalent duple-pulse rhythmic cell in sub-Saharan African music traditions and the music of the African Diaspora.

\new RhythmicStaff {
</score>

Tresillo is heard prominently in New Orleans second line music and in other forms of popular music from that city from the turn of the 20th century to present. "By and large the simpler African rhythmic patterns survived in jazz ... because they could be adapted more readily to European rhythmic conceptions," jazz historian Gunther Schuller observed. "Some survived, others were discarded as the Europeanization progressed."

In the post-Civil War period (after 1865), African Americans were able to obtain surplus military bass drums, snare drums and fifes, and an original African-American drum and fife music emerged, featuring tresillo and related syncopated rhythmic figures. This was a drumming tradition that was distinct from its Caribbean counterparts, expressing a uniquely African-American sensibility. "The snare and bass drummers played syncopated cross-rhythms," observed the writer Robert Palmer, speculating that "this tradition must have dated back to the latter half of the nineteenth century, and it could have not have developed in the first place if there hadn't been a reservoir of polyrhythmic sophistication in the culture it nurtured."

African-American music began incorporating Afro-Cuban rhythmic motifs in the 19th century when the habanera (Cuban contradanza) gained international popularity. Musicians from Havana and New Orleans would take the twice-daily ferry between both cities to perform, and the habanera quickly took root in the musically fertile Crescent City. John Storm Roberts states that the musical genre habanera "reached the U.S. twenty years before the first rag was published." For the more than quarter-century in which the cakewalk, ragtime, and proto-jazz were forming and developing, the habanera was a consistent part of African-American popular music.

Habaneras were widely available as sheet music and were the first written music which was rhythmically based on an African motif (1803). From the perspective of African-American music, the "habanera rhythm" (also known as "congo"), "tango-congo", or tango. can be thought of as a combination of tresillo and the backbeat. The habanera was the first of many Cuban music genres which enjoyed periods of popularity in the United States and reinforced and inspired the use of tresillo-based rhythms in African-American music.

</score>

New Orleans native Louis Moreau Gottschalk's piano piece "Ojos Criollos (Danse Cubaine)" (1860) was influenced by the composer's studies in Cuba: the habanera rhythm is clearly heard in the left hand. In Gottschalk's symphonic work "A Night in the Tropics" (1859), the tresillo variant cinquillo appears extensively. The figure was later used by Scott Joplin and other ragtime composers.

\new RhythmicStaff {
</score>

Comparing the music of New Orleans with the music of Cuba, Wynton Marsalis observes that tresillo is the New Orleans "clave", a Spanish word meaning "code" or "key", as in the key to a puzzle, or mystery. Although the pattern is only half a clave, Marsalis makes the point that the single-celled figure is the guide-pattern of New Orleans music. Jelly Roll Morton called the rhythmic figure the Spanish tinge and considered it an essential ingredient of jazz.

The abolition of slavery in 1865 led to new opportunities for the education of freed African Americans. Although strict segregation limited employment opportunities for most blacks, many were able to find work in entertainment. Black musicians were able to provide entertainment in dances, minstrel shows, and in vaudeville, during which time many marching bands were formed. Black pianists played in bars, clubs, and brothels, as ragtime developed.

Ragtime appeared as sheet music, popularized by African-American musicians such as the entertainer Ernest Hogan, whose hit songs appeared in 1895. Two years later, Vess Ossman recorded a medley of these songs as a banjo solo known as "Rag Time Medley". Also in 1897, the white composer William Krell published his "Mississippi Rag" as the first written piano instrumental ragtime piece, and Tom Turpin published his "Harlem Rag", the first rag published by an African-American.

Classically trained pianist Scott Joplin produced his "Original Rags" in 1898 and, in 1899, had an international hit with "Maple Leaf Rag", a multi-strain ragtime march with four parts that feature recurring themes and a bass line with copious seventh chords. Its structure was the basis for many other rags, and the syncopations in the right hand, especially in the transition between the first and second strain, were novel at the time. The last four measures of Scott Joplin's "Maple Leaf Rag" (1899) are shown below.

</score>

African-based rhythmic patterns such as tresillo and its variants, the habanera rhythm and cinquillo, are heard in the ragtime compositions of Joplin and Turpin. Joplin's "Solace" (1909) is generally considered to be in the habanera genre: both of the pianist's hands play in a syncopated fashion, completely abandoning any sense of a march rhythm. Ned Sublette postulates that the tresillo/habanera rhythm "found its way into ragtime and the cakewalk," whilst Roberts suggests that "the habanera influence may have been part of what freed black music from ragtime's European bass."

Blues is the name given to both a musical form and a music genre, which originated in African-American communities of primarily the Deep South of the United States at the end of the 19th century from their spirituals, work songs, field hollers, shouts and chants and rhymed simple narrative ballads.

The African use of pentatonic scales contributed to the development of blue notes in blues and jazz. As Kubik explains:

Many of the rural blues of the Deep South are "stylistically" an extension and merger of basically two broad accompanied song-style traditions in the west central Sudanic belt:

W. C. Handy became interested folk blues of the Deep South while traveling through the Mississippi Delta. In this folk blues form, the singer would improvise freely within a limited melodic range, sounding like a field holler, and the guitar accompaniment was slapped rather than strummed, like a small drum which responded in syncopated accents, functioning as another "voice". Handy and his band members were formally trained African-American musicians who had not grown up with the blues, yet he was able to adapt the blues to a larger band instrument format and arrange them in a popular music form.

Handy wrote about his adopting of the blues:

The primitive southern Negro, as he sang, was sure to bear down on the third and seventh tone of the scale, slurring between major and minor. Whether in the cotton field of the Delta or on the Levee up St. Louis way, it was always the same. Till then, however, I had never heard this slur used by a more sophisticated Negro, or by any white man. I tried to convey this effect ... by introducing flat thirds and sevenths (now called blue notes) into my song, although its prevailing key was major ... , and I carried this device into my melody as well.

The publication of his "Memphis Blues" sheet music in 1912 introduced the 12-bar blues to the world (although Gunther Schuller argues that it is not really a blues, but "more like a cakewalk"). This composition, as well as his later "St. Louis Blues" and others, included the habanera rhythm, and would become jazz standards. Handy's music career began in the pre-jazz era and contributed to the codification of jazz through the publication of some of the first jazz sheet music.

The music of New Orleans had a profound effect on the creation of early jazz. In New Orleans, slaves could practice elements of their culture such as voodoo and playing drums. Many early jazz musicians played in the bars and brothels of the red-light district around Basin Street called Storyville. In addition to dance bands, there were marching bands which played at lavish funerals (later called jazz funerals). The instruments used by marching bands and dance bands became the instruments of jazz: brass, drums, and reeds tuned in the European 12-tone scale. Small bands contained a combination of self-taught and formally educated musicians, many from the funeral procession tradition. These bands traveled in black communities in the deep south. Beginning in 1914, Creole and African-American musicians played in vaudeville shows which carried jazz to cities in the northern and western parts of the U.S.

In New Orleans, a white bandleader named Papa Jack Laine integrated blacks and whites in his marching band. He was known as "the father of white jazz" because of the many top players he employed, such as George Brunies, Sharkey Bonano, and future members of the Original Dixieland Jass Band. During the early 1900s, jazz was mostly performed in African-American and mulatto communities due to segregation laws. Storyville brought jazz to a wider audience through tourists who visited the port city of New Orleans. Many jazz musicians from African-American communities were hired to perform in bars and brothels. These included Buddy Bolden and Jelly Roll Morton in addition to those from other communities, such as Lorenzo Tio and Alcide Nunez. Louis Armstrong started his career in Storyville and found success in Chicago. Storyville was shut down by the U.S. government in 1917.

Cornetist Buddy Bolden played in New Orleans from 1895 to 1906. No recordings by him exist. His band is credited with creating the big four: the first syncopated bass drum pattern to deviate from the standard on-the-beat march. As the example below shows, the second half of the big four pattern is the habanera rhythm.

</score>

Afro-Creole pianist Jelly Roll Morton began his career in Storyville. Beginning in 1904, he toured with vaudeville shows to southern cities, Chicago, and New York City. In 1905, he composed "Jelly Roll Blues", which became the first jazz arrangement in print when it was published in 1915. In introduced more musicians to the New Orleans style.

Morton considered the tresillo/habanera, which he called the Spanish tinge, an essential ingredient of jazz. "Now in one of my earliest tunes, "New Orleans Blues," you can notice the Spanish tinge. In fact, if you can't manage to put tinges of Spanish in your tunes, you will never be able to get the right seasoning, I call it, for jazz."

An excerpt of "New Orleans Blues" is shown below. In the excerpt, the left hand plays the tresillo rhythm, while the right hand plays variations on cinquillo.

</score>

Morton was a crucial innovator in the evolution from the early jazz form known as ragtime to jazz piano, and could perform pieces in either style; in 1938, Morton made a series of recordings for the Library of Congress in which he demonstrated the difference between the two styles. Morton's solos, however, were still close to ragtime, and were not merely improvisations over chord changes as in later jazz, but his use of the blues was of equal importance.

Morton loosened ragtime's rigid rhythmic feeling, decreasing its embellishments and employing a swing feeling. Swing is the most important and enduring African-based rhythmic technique used in jazz. An oft quoted definition of swing by Louis Armstrong is: "if you don't feel it, you'll never know it." "The New Harvard Dictionary of Music" states that swing is: "An intangible rhythmic momentum in jazz...Swing defies analysis; claims to its presence may inspire arguments." The dictionary does nonetheless provide the useful description of triple subdivisions of the beat contrasted with duple subdivisions: swing superimposes six subdivisions of the beat over a basic pulse structure or four subdivisions. This aspect of swing is far more prevalent in African-American music than in Afro-Caribbean music. One aspect of swing, which is heard in more rhythmically complex Diaspora musics, places strokes in-between the triple and duple-pulse "grids".

New Orleans brass bands are a lasting influence, contributing horn players to the world of professional jazz with the distinct sound of the city whilst helping black children escape poverty. The leader of New Orleans' Camelia Brass Band, D'Jalma Ganier, taught Louis Armstrong to play trumpet; Armstrong would then popularize the New Orleans style of trumpet playing, and then expand it. Like Jelly Roll Morton, Armstrong is also credited with the abandonment of ragtime's stiffness in favor of swung notes. Armstrong, perhaps more than any other musician, codified the rhythmic technique of swing in jazz and broadened the jazz solo vocabulary.

The Original Dixieland Jass Band made the music's first recordings early in 1917, and their "Livery Stable Blues" became the earliest released jazz record. That year, numerous other bands made recordings featuring "jazz" in the title or band name, but most were ragtime or novelty records rather than jazz. In February 1918 during World War I, James Reese Europe's "Hellfighters" infantry band took ragtime to Europe, then on their return recorded Dixieland standards including "Darktown Strutters' Ball".

In the northeastern United States, a "hot" style of playing ragtime had developed, notably James Reese Europe's symphonic Clef Club orchestra in New York City, which played a benefit concert at Carnegie Hall in 1912. The Baltimore rag style of Eubie Blake influenced James P. Johnson's development of stride piano playing, in which the right hand plays the melody, while the left hand provides the rhythm and bassline.

In Ohio and elsewhere in the midwest the major influence was ragtime, until about 1919. Around 1912, when the four-string banjo and saxophone came in, musicians began to improvise the melody line, but the harmony and rhythm remained unchanged. A contemporary account states that blues could only be heard in jazz in the gut-bucket cabarets, which were generally looked down upon by the Black middle-class.

From 1920 to 1933, Prohibition in the United States banned the sale of alcoholic drinks, resulting in illicit speakeasies which became lively venues of the "Jazz Age", hosting popular music, dance songs, novelty songs, and show tunes. Jazz began to get a reputation as immoral, and many members of the older generations saw it as a threat to the old cultural values by promoting the decadent values of the Roaring 20s. Henry van Dyke of Princeton University wrote, "... it is not music at all. It's merely an irritation of the nerves of hearing, a sensual teasing of the strings of physical passion." "The New York Times" reported that Siberian villagers used jazz to scare away bears, but the villagers had used pots and pans; another story claimed that the fatal heart attack of a celebrated conductor was caused by jazz.

In 1919, Kid Ory's Original Creole Jazz Band of musicians from New Orleans began playing in San Francisco and Los Angeles, where in 1922 they became the first black jazz band of New Orleans origin to make recordings. During the same year, Bessie Smith made her first recordings. Chicago was developing "Hot Jazz", and King Oliver joined Bill Johnson. Bix Beiderbecke formed The Wolverines in 1924.

Despite its Southern black origins, there was a larger market for jazzy dance music played by white orchestras. In 1918, Paul Whiteman and his orchestra became a hit in San Francisco. He signed a contract with Victor and became the top bandleader of the 1920s, giving hot jazz a white component, hiring white musicians such as Bix Beiderbecke, Jimmy Dorsey, Tommy Dorsey, Frankie Trumbauer, and Joe Venuti. In 1924, Whiteman commissioned George Gershwin's "Rhapsody in Blue", which was premiered by his orchestra. Jazz began to be recognized as a notable musical form. Olin Downes, reviewing the concert in "The New York Times", wrote, "This composition shows extraordinary talent, as it shows a young composer with aims that go far beyond those of his ilk, struggling with a form of which he is far from being master. ... In spite of all this, he has expressed himself in a significant and, on the whole, highly original form. ... His first theme ... is no mere dance-tune ... it is an idea, or several ideas, correlated and combined in varying and contrasting rhythms that immediately intrigue the listener."

After Whiteman's band successfully toured Europe, huge hot jazz orchestras in theater pits caught on with other whites, including Fred Waring, Jean Goldkette, and Nathaniel Shilkret. According to Mario Dunkel, Whiteman's success was based on a "rhetoric of domestication" according to which he had elevated and rendered valuable (read "white") a previously inchoate (read "black") kind of music.

Whiteman's success caused blacks to follow suit, including Earl Hines (who opened in The Grand Terrace Cafe in Chicago in 1928), Duke Ellington (who opened at the Cotton Club in Harlem in 1927), Lionel Hampton, Fletcher Henderson, Claude Hopkins, and Don Redman, with Henderson and Redman developing the "talking to one another" formula for "hot" swing music.

In 1924, Louis Armstrong joined the Fletcher Henderson dance band for a year, as featured soloist. The original New Orleans style was polyphonic, with theme variation and simultaneous collective improvisation. Armstrong was a master of his hometown style, but by the time he joined Henderson's band, he was already a trailblazer in a new phase of jazz, with its emphasis on arrangements and soloists. Armstrong's solos went well beyond the theme-improvisation concept and extemporized on chords, rather than melodies. According to Schuller, by comparison, the solos by Armstrong's bandmates (including a young Coleman Hawkins), sounded "stiff, stodgy," with "jerky rhythms and a grey undistinguished tone quality." The following example shows a short excerpt of the straight melody of "Mandy, Make Up Your Mind" by George W. Meyer and Arthur Johnston (top), compared with Armstrong's solo improvisations (below) (recorded 1924). Armstrong's solos were a significant factor in making jazz a true 20th-century language. After leaving Henderson's group, Armstrong formed his Hot Five band, where he popularized scat singing.

The 1930s belonged to popular swing big bands, in which some virtuoso soloists became as famous as the band leaders. Key figures in developing the "big" jazz band included bandleaders and arrangers Count Basie, Cab Calloway, Jimmy and Tommy Dorsey, Duke Ellington, Benny Goodman, Fletcher Henderson, Earl Hines, Harry James, Jimmie Lunceford, Glenn Miller and Artie Shaw. Although it was a collective sound, swing also offered individual musicians a chance to "solo" and improvise melodic, thematic solos which could at times be complex "important" music.

Over time, social strictures regarding racial segregation began to relax in America: white bandleaders began to recruit black musicians and black bandleaders white ones. In the mid-1930s, Benny Goodman hired pianist Teddy Wilson, vibraphonist Lionel Hampton and guitarist Charlie Christian to join small groups. In the 1930s, Kansas City Jazz as exemplified by tenor saxophonist Lester Young marked the transition from big bands to the bebop influence of the 1940s. An early 1940s style known as "jumping the blues" or jump blues used small combos, uptempo music and blues chord progressions, drawing on boogie-woogie from the 1930s.

While swing was reaching the height of its popularity, Duke Ellington spent the late 1920s and 1930s developing an innovative musical idiom for his orchestra. Abandoning the conventions of swing, he experimented with orchestral sounds, harmony, and musical form with complex compositions that still translated well for popular audiences; some of his tunes became hits, and his own popularity spanned from the United States to Europe.

Ellington called his music "American Music", rather than "jazz", and liked to describe those who impressed him as "beyond category." These included many musicians from his orchestra, some of whom are considered among the best in jazz in their own right, but it was Ellington who melded them into one of the most popular jazz orchestras in the history of jazz. He often composed for the style and skills of these individuals, such as "Jeep's Blues" for Johnny Hodges, "Concerto for Cootie" for Cootie Williams (which later became "Do Nothing Till You Hear from Me" with Bob Russell's lyrics), and "The Mooche" for Tricky Sam Nanton and Bubber Miley. He also recorded songs written by his bandsmen, such as Juan Tizol's "Caravan" and "Perdido", which brought the "Spanish Tinge" to big-band jazz. Several members of the orchestra remained with him for several decades. The band reached a creative peak in the early 1940s, when Ellington and a small hand-picked group of his composers and arrangers wrote for an orchestra of distinctive voices who displayed tremendous creativity.

As only a limited number of American jazz records were released in Europe, European jazz traces many of its roots to American artists such as James Reese Europe, Paul Whiteman, and Lonnie Johnson, who visited Europe during and after World War I. It was their live performances which inspired European audiences' interest in jazz, as well as the interest in all things American (and therefore exotic) which accompanied the economic and political woes of Europe during this time. The beginnings of a distinct European style of jazz began to emerge in this interwar period.

British jazz began with a tour by the Original Dixieland Jazz Band in 1919. In 1926, Fred Elizalde and His Cambridge Undergraduates began broadcasting on the BBC. Thereafter jazz became an important element in many leading dance orchestras, and jazz instrumentalists became numerous.

This style entered full swing in France with the Quintette du Hot Club de France, which began in 1934. Much of this French jazz was a combination of African-American jazz and the symphonic styles in which French musicians were well-trained; in this, it is easy to see the inspiration taken from Paul Whiteman since his style was also a fusion of the two. Belgian guitarist Django Reinhardt popularized gypsy jazz, a mix of 1930s American swing, French dance hall "musette", and Eastern European folk with a languid, seductive feel; the main instruments were steel stringed guitar, violin, and double bass. Solos pass from one player to another as guitar and bass form the rhythm section. Some researchers believe Eddie Lang and Joe Venuti pioneered the guitar-violin partnership characteristic of the genre, which was brought to France after they had been heard live or on Okeh Records in the late 1920s.

The outbreak of World War II marked a turning point for jazz. The swing-era jazz of the previous decade had challenged other popular music as being representative of the nation's culture, with big bands reaching the height of the style's success by the early 1940s; swing acts and big bands traveled with U.S. military overseas to Europe, where it also became popular. Stateside, however, the war presented difficulties for the big-band format: conscription shortened the number of musicians available; the military's need for shellac (commonly used for pressing gramophone records) limited record production; a shortage of rubber (also due to the war effort) discouraged bands from touring via road travel; and a demand by the musicians' union for a commercial recording ban limited music distribution between 1942 and 1944.

Many of the big bands who were deprived of experienced musicians because of the war effort began to enlist young players who were below the age for conscription, as was the case with saxophonist Stan Getz's entry in a band as a teenager. This coincided with a nationwide resurgence in the Dixieland style of pre-swing jazz; performers such as clarinetist George Lewis, cornetist Bill Davison, and trombonist Turk Murphy were hailed by conservative jazz critics as more authentic than the big bands. Elsewhere, with the limitations on recording, small groups of young musicians developed a more uptempo, improvisational style of jazz, collaborating and experimenting with new ideas for melodic development, rhythmic language, and harmonic substitution, during informal, late-night jam sessions hosted in small clubs and apartments. Key figures in this development were largely based in New York and included pianists Thelonious Monk and Bud Powell, drummers Max Roach and Kenny Clarke, saxophonist Charlie Parker, and trumpeter Dizzy Gillespie. This musical development became known as bebop.

Bebop and subsequent post-war jazz developments featured a wider set of notes, played in more complex patterns and at faster tempos than previous jazz. According to Clive James, bebop was "the post-war musical development which tried to ensure that jazz would no longer be the spontaneous sound of joy ... Students of race relations in America are generally agreed that the exponents of post-war jazz were determined, with good reason, to present themselves as challenging artists rather than tame entertainers." The end of the war marked "a revival of the spirit of experimentation and musical pluralism under which it had been conceived", along with "the beginning of a decline in the popularity of jazz music in America", according to American academic Michael H. Burchett.

With the rise of bebop and the end of the swing era after the war, jazz lost its cachet as pop music. Vocalists of the famous big bands moved on to being marketed and performing as solo pop singers; these included Frank Sinatra, Peggy Lee, Dick Haymes, and Doris Day. Older musicians who still performed their pre-war jazz, such as Armstrong and Ellington, were gradually viewed in the mainstream as passé. Other younger performers, such as singer Big Joe Turner and saxophonist Louis Jordan, who were discouraged by bebop's increasing complexity pursued more lucrative endeavors in rhythm and blues, jump blues, and eventually rock and roll. Some, including Gillespie, composed intricate yet danceable songs for bebop musicians in an effort to make them more accessible, but bebop largely remained on the fringes of American audiences' purview. "The new direction of postwar jazz drew a wealth of critical acclaim, but it steadily declined in popularity as it developed a reputation as an academic genre that was largely inaccessible to mainstream audiences", Burchett said. "The quest to make jazz more relevant to popular audiences, while retaining its artistic integrity, is a constant and prevalent theme in the history of postwar jazz." During its swing period, jazz had been an uncomplicated musical scene; according to Paul Trynka, this changed in the post-war years:

In the early 1940s, bebop-style performers began to shift jazz from danceable popular music toward a more challenging "musician's music". The most influential bebop musicians included saxophonist Charlie Parker, pianists Bud Powell and Thelonious Monk, trumpeters Dizzy Gillespie and Clifford Brown, and drummer Max Roach. Divorcing itself from dance music, bebop established itself more as an art form, thus lessening its potential popular and commercial appeal.

Composer Gunther Schuller wrote: "In 1943 I heard the great Earl Hines band which had Bird in it and all those other great musicians. They were playing all the flatted fifth chords and all the modern harmonies and substitutions and Dizzy Gillespie runs in the trumpet section work. Two years later I read that that was 'bop' and the beginning of modern jazz ... but the band never made recordings."

Dizzy Gillespie wrote: "People talk about the Hines band being 'the incubator of bop' and the leading exponents of that music ended up in the Hines band. But people also have the erroneous impression that the music was new. It was not. The music evolved from what went before. It was the same basic music. The difference was in how you got from here to here to here...naturally each age has got its own shit."

Since bebop was meant to be listened to, not danced to, it could use faster tempos. Drumming shifted to a more elusive and explosive style, in which the ride cymbal was used to keep time while the snare and bass drum were used for accents. This led to a highly syncopated music with a linear rhythmic complexity.

Bebop musicians employed several harmonic devices which were not previously typical in jazz, engaging in a more abstracted form of chord-based improvisation. Bebop scales are traditional scales with an added chromatic passing note; bebop also uses "passing" chords, substitute chords, and altered chords. New forms of chromaticism and dissonance were introduced into jazz, and the dissonant tritone (or "flatted fifth") interval became the "most important interval of bebop" Chord progressions for bebop tunes were often taken directly from popular swing-era songs and reused with a new and more complex melody and/or reharmonized with more complex chord progressions to form new compositions, a practice which was already well-established in earlier jazz, but came to be central to the bebop style. Bebop made use of several relatively common chord progressions, such as blues (at base, I-IV-V, but often infused with ii-V motion) and 'rhythm changes' (I-VI-ii-V) – the chords to the 1930s pop standard "I Got Rhythm". Late bop also moved towards extended forms that represented a departure from pop and show tunes.

The harmonic development in bebop is often traced back to a moment experienced by Charlie Parker while performing "Cherokee" at Clark Monroe's Uptown House, New York, in early 1942. "I'd been getting bored with the stereotyped changes that were being used...and I kept thinking there's bound to be something else. I could hear it sometimes. I couldn't play it...I was working over 'Cherokee,' and, as I did, I found that by using the higher intervals of a chord as a melody line and backing them with appropriately related changes, I could play the thing I'd been hearing. It came alive." Gerhard Kubik postulates that harmonic development in bebop sprang from blues and African-related tonal sensibilities rather than 20th-century Western classical music. "Auditory inclinations were the African legacy in [Parker's] life, reconfirmed by the experience of the blues tonal system, a sound world at odds with the Western diatonic chord categories. Bebop musicians eliminated Western-style functional harmony in their music while retaining the strong central tonality of the blues as a basis for drawing upon various African matrices."

Samuel Floyd states that blues was both the bedrock and propelling force of bebop, bringing about a new harmonic conception using extended chord structures that led to unprecedented harmonic and melodic variety, a developed and even more highly syncopated, linear rhythmic complexity and a melodic angularity in which the blue note of the fifth degree was established as an important melodic-harmonic device; and reestablishment of the blues as the primary organizing and functional principle. Kubik wrote:

While for an outside observer, the harmonic innovations in bebop would appear to be inspired by experiences in Western "serious" music, from Claude Debussy to Arnold Schoenberg, such a scheme cannot be sustained by the evidence from a cognitive approach. Claude Debussy did have some influence on jazz, for example, on Bix Beiderbecke's piano playing. And it is also true that Duke Ellington adopted and reinterpreted some harmonic devices in European contemporary music. West Coast jazz would run into such debts as would several forms of cool jazz, but bebop has hardly any such debts in the sense of direct borrowings. On the contrary, ideologically, bebop was a strong statement of rejection of any kind of eclecticism, propelled by a desire to activate something deeply buried in self. Bebop then revived tonal-harmonic ideas transmitted through the blues and reconstructed and expanded others in a basically non-Western harmonic approach. The ultimate significance of all this is that the experiments in jazz during the 1940s brought back to African-American music several structural principles and techniques rooted in African traditions

These divergences from the jazz mainstream of the time met a divided, sometimes hostile response among fans and musicians, especially swing players who bristled at the new harmonic sounds. To hostile critics, bebop seemed filled with "racing, nervous phrases". But despite the friction, by the 1950s bebop had become an accepted part of the jazz vocabulary.

The general consensus among musicians and musicologists is that the first original jazz piece to be overtly based in clave was "Tanga" (1943), composed by Cuban-born Mario Bauza and recorded by Machito and his Afro-Cubans in New York City. "Tanga" began as a spontaneous descarga (Cuban jam session), with jazz solos superimposed on top.

This was the birth of Afro-Cuban jazz. The use of clave brought the African "timeline", or "key pattern", into jazz. Music organized around key patterns convey a two-celled (binary) structure, which is a complex level of African cross-rhythm. Within the context of jazz, however, harmony is the primary referent, not rhythm. The harmonic progression can begin on either side of clave, and the harmonic "one" is always understood to be "one". If the progression begins on the "three-side" of clave, it is said to be in "3–2 clave" (shown below). If the progression begins on the "two-side", it is in "2–3 clave".

\new RhythmicStaff {
</score>

Mario Bauzá introduced bebop innovator Dizzy Gillespie to Cuban conga drummer and composer Chano Pozo. Gillespie and Pozo's brief collaboration produced some of the most enduring Afro-Cuban jazz standards. "Manteca" (1947) is the first jazz standard to be rhythmically based on clave. According to Gillespie, Pozo composed the layered, contrapuntal guajeos (Afro-Cuban ostinatos) of the A section and the introduction, while Gillespie wrote the bridge. Gillespie recounted: "If I'd let it go like [Chano] wanted it, it would have been strictly Afro-Cuban all the way. There wouldn't have been a bridge. I thought I was writing an eight-bar bridge, but ... I had to keep going and ended up writing a sixteen-bar bridge." The bridge gave "Manteca" a typical jazz harmonic structure, setting the piece apart from Bauza's modal "Tanga" of a few years earlier.

Gillespie's collaboration with Pozo brought specific African-based rhythms into bebop. While pushing the boundaries of harmonic improvisation, "cu-bop" also drew from African rhythm. Jazz arrangements with a Latin A section and a swung B section, with all choruses swung during solos, became common practice with many Latin tunes of the jazz standard repertoire. This approach can be heard on pre-1980 recordings of "Manteca", "A Night in Tunisia", "Tin Tin Deo", and "On Green Dolphin Street".

Cuban percussionist Mongo Santamaria first recorded his composition "Afro Blue" in 1959.
"Afro Blue" was the first jazz standard built upon a typical African three-against-two (3:2) cross-rhythm, or hemiola. The song begins with the bass repeatedly playing 6 cross-beats per each measure of , or 6 cross-beats per 4 main beats—6:4 (two cells of 3:2).

The following example shows the original ostinato "Afro Blue" bass line. The cross noteheads indicate the main beats (not bass notes).

</score>

When John Coltrane covered "Afro Blue" in 1963, he inverted the metric hierarchy, interpreting the tune as a jazz waltz with duple cross-beats superimposed (2:3). Originally a B pentatonic blues, Coltrane expanded the harmonic structure of "Afro Blue."

Perhaps the most respected Afro-cuban jazz combo of the late 1950s was vibraphonist Cal Tjader's band. Tjader had Mongo Santamaria, Armando Peraza, and Willie Bobo on his early recording dates.

In the late 1940s, there was a revival of Dixieland, harking back to the contrapuntal New Orleans style. This was driven in large part by record company reissues of jazz classics by the Oliver, Morton, and Armstrong bands of the 1930s. There were two types of musicians involved in the revival: the first group was made up of those who had begun their careers playing in the traditional style and were returning to it (or continuing what they had been playing all along), such as Bob Crosby's Bobcats, Max Kaminsky, Eddie Condon, and Wild Bill Davison. Most of these players were originally Midwesterners, although there were a small number of New Orleans musicians involved. The second group of revivalists consisted of younger musicians, such as those in the Lu Watters band, Conrad Janis, and Ward Kimball and his Firehouse Five Plus Two Jazz Band. By the late 1940s, Louis Armstrong's Allstars band became a leading ensemble. Through the 1950s and 1960s, Dixieland was one of the most commercially popular jazz styles in the US, Europe, and Japan, although critics paid little attention to it.

Hard bop is an extension of bebop (or "bop") music that incorporates influences from blues, rhythm and blues, and gospel, especially in saxophone and piano playing. Hard bop was developed in the mid-1950s, coalescing in 1953 and 1954; it developed partly in response to the vogue for cool jazz in the early 1950s and paralleled the rise of rhythm and blues. Miles Davis' 1954 performance of "Walkin'" at the first Newport Jazz Festival announced the style to the jazz world. The quintet Art Blakey and the Jazz Messengers, led by Blakey and featuring pianist Horace Silver and trumpeter Clifford Brown, were leaders in the hard bop movement with Davis.

Modal jazz is a development which began in the later 1950s which takes the mode, or musical scale, as the basis of musical structure and improvisation. Previously, a solo was meant to fit into a given chord progression, but with modal jazz, the soloist creates a melody using one (or a small number of) modes. The emphasis is thus shifted from harmony to melody: "Historically, this caused a seismic shift among jazz musicians, away from thinking vertically (the chord), and towards a more horizontal approach (the scale)," explained pianist Mark Levine.

The modal theory stems from a work by George Russell. Miles Davis introduced the concept to the greater jazz world with "Kind of Blue" (1959), an exploration of the possibilities of modal jazz which would become the best selling jazz album of all time. In contrast to Davis' earlier work with hard bop and its complex chord progression and improvisation, "Kind of Blue" was composed as a series of modal sketches in which the musicians were given scales that defined the parameters of their improvisation and style.

"I didn't write out the music for "Kind of Blue", but brought in sketches for what everybody was supposed to play because I wanted a lot of spontaneity," recalled Davis. The track "So What" has only two chords: D-7 and E-7.

Other innovators in this style include Jackie McLean, and two of the musicians who had also played on "Kind of Blue": John Coltrane and Bill Evans.

Free jazz, and the related form of avant-garde jazz, broke through into an open space of "free tonality" in which meter, beat, and formal symmetry all disappeared, and a range of world music from India, Africa, and Arabia were melded into an intense, even religiously ecstatic or orgiastic style of playing. While loosely inspired by bebop, free jazz tunes gave players much more latitude; the loose harmony and tempo was deemed controversial when this approach was first developed. The bassist Charles Mingus is also frequently associated with the avant-garde in jazz, although his compositions draw from myriad styles and genres.

The first major stirrings came in the 1950s with the early work of Ornette Coleman (whose 1960 album "" coined the term) and Cecil Taylor. In the 1960s, exponents included Albert Ayler, Gato Barbieri, Carla Bley, Don Cherry, Larry Coryell, John Coltrane, Bill Dixon, Jimmy Giuffre, Steve Lacy, Michael Mantler, Sun Ra, Roswell Rudd, Pharoah Sanders, and John Tchicai. In developing his late style, Coltrane was especially influenced by the dissonance of Ayler's trio with bassist Gary Peacock and drummer Sunny Murray, a rhythm section honed with Cecil Taylor as leader. In November 1961, Coltrane played a gig at the Village Vanguard, which resulted in the classic "Chasin' the 'Trane", which "Down Beat" magazine panned as "anti-jazz". On his 1961 tour of France, he was booed, but persevered, signing with the new Impulse! Records in 1960 and turning it into "the house that Trane built", while championing many younger free jazz musicians, notably Archie Shepp, who often played with trumpeter Bill Dixon, who organized the 4-day "October Revolution in Jazz" in Manhattan in 1964, the first free jazz festival.

A series of recordings with the Classic Quartet in the first half of 1965 show Coltrane's playing becoming increasingly abstract, with greater incorporation of devices like multiphonics, utilization of overtones, and playing in the altissimo register, as well as a mutated return to Coltrane's sheets of sound. In the studio, he all but abandoned his soprano to concentrate on the tenor saxophone. In addition, the quartet responded to the leader by playing with increasing freedom. The group's evolution can be traced through the recordings "The John Coltrane Quartet Plays", "Living Space" and "Transition" (both June 1965), "New Thing at Newport" (July 1965), "Sun Ship" (August 1965), and "First Meditations" (September 1965).

In June 1965, Coltrane and 10 other musicians recorded "Ascension", a 40-minute-long piece without breaks that included adventurous solos by young avante-garde musicians as well as Coltrane, and was controversial primarily for the collective improvisation sections that separated the solos. Dave Liebman later called it "the torch that lit the free jazz thing.". After recording with the quartet over the next few months, Coltrane invited Pharoah Sanders to join the band in September 1965. While Coltrane used over-blowing frequently as an emotional exclamation-point, Sanders would opt to overblow his entire solo, resulting in a constant screaming and screeching in the altissimo range of the instrument.

Free jazz was played in Europe in part because musicians such as Ayler, Taylor, Steve Lacy, and Eric Dolphy spent extended periods of time there, and European musicians such as Michael Mantler and John Tchicai traveled to the U.S. to experience American music firsthand. European contemporary jazz was shaped by Peter Brötzmann, John Surman, Krzysztof Komeda, Zbigniew Namysłowski, Tomasz Stanko, Lars Gullin, Joe Harriott, Albert Mangelsdorff, Kenny Wheeler, Graham Collier, Michael Garrick and Mike Westbrook. They were eager to develop approaches to music that reflected their heritage.

Since the 1960s, creative centers of jazz in Europe have developed, such as the creative jazz scene in Amsterdam. Following the work of drummer Han Bennink and pianist Misha Mengelberg, musicians started to explore by improvising collectively until a form (melody, rhythm, a famous song) is found Jazz critic Kevin Whitehead documented the free jazz scene in Amsterdam and some of its main exponents such as the ICP (Instant Composers Pool) orchestra in his book "New Dutch Swing". Since the 1990s Keith Jarrett has defended free jazz from criticism. British writer Stuart Nicholson has argued European contemporary jazz has an identity different from American jazz and follows a different trajectory.

Latin jazz is jazz that employs Latin American rhythms and is generally understood to have a more specific meaning than simply jazz from Latin America. A more precise term might be "Afro-Latin jazz", as the jazz subgenre typically employs rhythms that either have a direct analog in Africa or exhibit an African rhythmic influence beyond what is ordinarily heard in other jazz. The two main categories of Latin jazz are Afro-Cuban jazz and Brazilian jazz.

In the 1960s and 1970s, many jazz musicians had only a basic understanding of Cuban and Brazilian music, and jazz compositions which used Cuban or Brazilian elements were often referred to as "Latin tunes", with no distinction between a Cuban son montuno and a Brazilian bossa nova. Even as late as 2000, in Mark Gridley's "Jazz Styles: History and Analysis", a bossa nova bass line is referred to as a "Latin bass figure." It was not uncommon during the 1960s and 1970s to hear a conga playing a Cuban tumbao while the drumset and bass played a Brazilian bossa nova pattern. Many jazz standards such as "Manteca", "On Green Dolphin Street" and "Song for My Father" have a "Latin" A section and a swung B section. Typically, the band would only play an even-eighth "Latin" feel in the A section of the head and swing throughout all of the solos. Latin jazz specialists like Cal Tjader tended to be the exception. For example, on a 1959 live Tjader recording of "A Night in Tunisia", pianist Vince Guaraldi soloed through the entire form over an authentic mambo.

For most of its history, Afro-Cuban jazz had been a matter of superimposing jazz phrasing over Cuban rhythms. But by the end of the 1970s, a new generation of New York City musicians had emerged who were fluent in both salsa dance music and jazz, leading to a new level of integration of jazz and Cuban rhythms. This era of creativity and vitality is best represented by the Gonzalez brothers Jerry (congas and trumpet) and Andy (bass). During 1974–1976, they were members of one of Eddie Palmieri's most experimental salsa groups: salsa was the medium, but Palmieri was stretching the form in new ways. He incorporated parallel fourths, with McCoy Tyner-type vamps. The innovations of Palmieri, the Gonzalez brothers and others led to an Afro-Cuban jazz renaissance in New York City.

This occurred in parallel with developments in Cuba The first Cuban band of this new wave was Irakere. Their "Chékere-son" (1976) introduced a style of "Cubanized" bebop-flavored horn lines that departed from the more angular guajeo-based lines which were typical of Cuban popular music and Latin jazz up until that time. It was based on Charlie Parker's composition "Billie's Bounce", jumbled together in a way that fused clave and bebop horn lines. In spite of the ambivalence of some band members towards Irakere's Afro-Cuban folkloric / jazz fusion, their experiments forever changed Cuban jazz: their innovations are still heard in the high level of harmonic and rhythmic complexity in Cuban jazz and in the jazzy and complex contemporary form of popular dance music known as timba.

Brazilian jazz, such as bossa nova, is derived from samba, with influences from jazz and other 20th-century classical and popular music styles. Bossa is generally moderately paced, with melodies sung in Portuguese or English, whilst the related jazz-samba is an adaptation of street samba into jazz.

The bossa nova style was pioneered by Brazilians João Gilberto and Antônio Carlos Jobim and was made popular by Elizete Cardoso's recording of "Chega de Saudade" on the "Canção do Amor Demais" LP. Gilberto's initial releases, and the 1959 film "Black Orpheus", achieved significant popularity in Latin America; this spread to North America via visiting American jazz musicians. The resulting recordings by Charlie Byrd and Stan Getz cemented bossa nova's popularity and led to a worldwide boom, with 1963's "Getz/Gilberto", numerous recordings by famous jazz performers such as Ella Fitzgerald and Frank Sinatra, and the eventual entrenchment of the bossa nova style as a lasting influence in world music.

Brazilian percussionists such as Airto Moreira and Naná Vasconcelos also influenced jazz internationally by introducing Afro-Brazilian folkloric instruments and rhythms into a wide variety of jazz styles, thus attracting a greater audience to them.

There was a resurgence of interest in jazz and other forms of African-American cultural expression during the Black Arts Movement and Black nationalist period of the 1960s and 1970s. African themes became popular, and many new jazz compositions were given African-related titles: "Black Nile" (Wayne Shorter), "Blue Nile" (Alice Coltrane), "Obirin African" (Art Blakey), "Zambia" (Lee Morgan), "Appointment in Ghana" (Jackie McLean), "Marabi" (Cannonball Adderley), "Yoruba" (Hubert Laws), and many more. Pianist Randy Weston's music incorporated African elements, such as in the large-scale suite "Uhuru Africa" (with the participation of poet Langston Hughes) and "Highlife: Music From the New African Nations." Both Weston and saxophonist Stanley Turrentine covered the Nigerian Bobby Benson's piece "Niger Mambo", which features Afro-Caribbean and jazz elements within a West African Highlife style. Some musicians, including Pharoah Sanders, Hubert Laws, and Wayne Shorter, began using African instruments such as kalimbas, bells, beaded gourds and other instruments which were not traditional to jazz.

During this period, there was an increased use of the typical African 12/8 cross-rhythmic structure in jazz. Herbie Hancock's "Succotash" on "Inventions and Dimensions" (1963) is an open-ended modal improvised jam, in which Hancock's pattern of attack-points, rather than the pattern of pitches, is the primary focus of his improvisations, accompanied by Paul Chambers on bass, percussionist Osvaldo Martinez playing a traditional Afro-Cuban chekeré part and Willie Bobo playing an Abakuá bell pattern on a snare drum with brushes.

The first jazz standard composed by a non-Latino to use an overt African cross-rhythm was Wayne Shorter's "Footprints" (1967). On the version recorded on "Miles Smiles" by Miles Davis, the bass switches to a tresillo figure at 2:20. "Footprints" is not, however, a Latin jazz tune: African rhythmic structures are accessed directly by Ron Carter (bass) and Tony Williams (drums) via the rhythmic sensibilities of swing. Throughout the piece, the four beats, whether sounded or not, are maintained as the temporal referent. The following example shows the and forms of the bass line. The slashed noteheads indicate the main beats (not bass notes), where one ordinarily taps their foot to "keep time."

</score>

The use of pentatonic scales was another trend associated with Africa. The use of pentatonic scales in Africa probably goes back thousands of years.

McCoy Tyner perfected the use of the pentatonic scale in his solos, and also used parallel fifths and fourths, which are common harmonies in West Africa.

The minor pentatonic scale is often used in blues improvisation, and like a blues scale, a minor pentatonic scale can be played over all of the chords in a blues. The following pentatonic lick was played over blues changes by Joe Henderson on Horace Silver's "African Queen" (1965).

Jazz pianist, theorist, and educator Mark Levine refers to the scale generated by beginning on the fifth step of a pentatonic scale as the "V pentatonic scale".

Levine points out that the V pentatonic scale works for all three chords of the standard II-V-I jazz progression. This is a very common progression, used in pieces such as Miles Davis' "Tune Up." The following example shows the V pentatonic scale over a II-V-I progression.

Accordingly, John Coltrane's "Giant Steps" (1960), with its 26 chords per 16 bars, can be played using only three pentatonic scales. Coltrane studied Nicolas Slonimsky's "Thesaurus of Scales and Melodic Patterns", which contains material that is virtually identical to portions of "Giant Steps". The harmonic complexity of "Giant Steps" is on the level of the most advanced 20th-century art music. Superimposing the pentatonic scale over "Giant Steps" is not merely a matter of harmonic simplification, but also a sort of "Africanizing" of the piece, which provides an alternate approach for soloing. Mark Levine observes that when mixed in with more conventional "playing the changes", pentatonic scales provide "structure and a feeling of increased space."

In the late 1960s and early 1970s, the hybrid form of jazz-rock fusion was developed by combining jazz improvisation with rock rhythms, electric instruments and the highly amplified stage sound of rock musicians such as Jimi Hendrix and Frank Zappa. Jazz fusion often uses mixed meters, odd time signatures, syncopation, complex chords, and harmonies.

According to AllMusic:

... until around 1967, the worlds of jazz and rock were nearly completely separate. [However, ...] as rock became more creative and its musicianship improved, and as some in the jazz world became bored with hard bop and did not want to play strictly avant-garde music, the two different idioms began to trade ideas and occasionally combine forces.

In 1969, Davis fully embraced the electric instrument approach to jazz with "In a Silent Way", which can be considered his first fusion album. Composed of two side-long suites edited heavily by producer Teo Macero, this quiet, static album would be equally influential to the development of ambient music.

As Davis recalls:

The music I was really listening to in 1968 was James Brown, the great guitar player Jimi Hendrix, and a new group who had just come out with a hit record, "Dance to the Music", Sly and the Family Stone ... I wanted to make it more like rock. When we recorded "In a Silent Way" I just threw out all the chord sheets and told everyone to play off of that.

Two contributors to "In a Silent Way" also joined organist Larry Young to create one of the early acclaimed fusion albums: "Emergency!" by The Tony Williams Lifetime.

Weather Report's self-titled electronic and psychedelic "Weather Report" debut album caused a sensation in the jazz world on its arrival in 1971, thanks to the pedigree of the group's members (including percussionist Airto Moreira), and their unorthodox approach to music. The album featured a softer sound than would be the case in later years (predominantly using acoustic bass with Shorter exclusively playing soprano saxophone, and with no synthesizers involved), but is still considered a classic of early fusion. It built on the avant-garde experiments which Joe Zawinul and Shorter had pioneered with Miles Davis on "Bitches Brew", including an avoidance of head-and-chorus composition in favour of continuous rhythm and movement – but took the music further. To emphasise the group's rejection of standard methodology, the album opened with the inscrutable avant-garde atmospheric piece "Milky Way", which featured by Shorter's extremely muted saxophone inducing vibrations in Zawinul's piano strings while the latter pedalled the instrument. "Down Beat" described the album as "music beyond category", and awarded it Album of the Year in the magazine's polls that year.

Weather Report's subsequent releases were creative funk-jazz works.

Although some jazz purists protested against the blend of jazz and rock, many jazz innovators crossed over from the contemporary hard bop scene into fusion. As well as the electric instruments of rock (such as electric guitar, electric bass, electric piano and synthesizer keyboards), fusion also used the powerful amplification, "fuzz" pedals, wah-wah pedals and other effects that were used by 1970s-era rock bands. Notable performers of jazz fusion included Miles Davis, Eddie Harris, keyboardists Joe Zawinul, Chick Corea, and Herbie Hancock, vibraphonist Gary Burton, drummer Tony Williams (drummer), violinist Jean-Luc Ponty, guitarists Larry Coryell, Al Di Meola, John McLaughlin, Ryo Kawasaki, and Frank Zappa, saxophonist Wayne Shorter and bassists Jaco Pastorius and Stanley Clarke. Jazz fusion was also popular in Japan, where the band Casiopea released over thirty fusion albums.

According to jazz writer Stuart Nicholson, "just as free jazz appeared on the verge of creating a whole new musical language in the 1960s ... jazz-rock briefly suggested the promise of doing the same" with albums such as Williams' "Emergency!" (1970) and Davis' "Agharta" (1975), which Nicholson said "suggested the potential of evolving into something that might eventually define itself as a wholly independent genre quite apart from the sound and conventions of anything that had gone before." This development was stifled by commercialism, Nicholson said, as the genre "mutated into a peculiar species of jazz-inflected pop music that eventually took up residence on FM radio" at the end of the 1970s.

By the mid-1970s, the sound known as jazz-funk had developed, characterized by a strong back beat (groove), electrified sounds and, often, the presence of electronic analog synthesizers. Jazz-funk also draws influences from traditional African music, Afro-Cuban rhythms and Jamaican reggae, notably Kingston bandleader Sonny Bradshaw. Another feature is the shift of emphasis from improvisation to composition: arrangements, melody and overall writing became important. The integration of funk, soul, and R&B music into jazz resulted in the creation of a genre whose spectrum is wide and ranges from strong jazz improvisation to soul, funk or disco with jazz arrangements, jazz riffs and jazz solos, and sometimes soul vocals.

Early examples are Herbie Hancock's Headhunters band and Miles Davis' "On the Corner" album, which, in 1972, began Davis' foray into jazz-funk and was, he claimed, an attempt at reconnecting with the young black audience which had largely forsaken jazz for rock and funk. While there is a discernible rock and funk influence in the timbres of the instruments employed, other tonal and rhythmic textures, such as the Indian tambora and tablas and Cuban congas and bongos, create a multi-layered soundscape. The album was a culmination of sorts of the "musique concrète" approach that Davis and producer Teo Macero had begun to explore in the late 1960s.

The 1980s saw something of a reaction against the fusion and free jazz that had dominated the 1970s. Trumpeter Wynton Marsalis emerged early in the decade, and strove to create music within what he believed was the tradition, rejecting both fusion and free jazz and creating extensions of the small and large forms initially pioneered by artists such as Louis Armstrong and Duke Ellington, as well as the hard bop of the 1950s. It is debatable whether Marsalis' critical and commercial success was a cause or a symptom of the reaction against Fusion and Free Jazz and the resurgence of interest in the kind of jazz pioneered in the 1960s (particularly modal jazz and post-bop); nonetheless there were many other manifestations of a resurgence of traditionalism, even if fusion and free jazz were by no means abandoned and continued to develop and evolve.

For example, several musicians who had been prominent in the fusion genre during the 1970s began to record acoustic jazz once more, including Chick Corea and Herbie Hancock. Other musicians who had experimented with electronic instruments in the previous decade had abandoned them by the 1980s; for example, Bill Evans, Joe Henderson, and Stan Getz. Even the 1980s music of Miles Davis, although certainly still fusion, adopted a far more accessible and recognisably jazz-oriented approach than his abstract work of the mid-1970s, such as a return to a theme-and-solos approach.

The emergence of young jazz talent beginning to perform in older, established musicians' groups further impacted the resurgence of traditionalism in the jazz community. In the 1970s, the groups of Betty Carter and Art Blakey and the Jazz Messengers retained their conservative jazz approaches in the midst of fusion and jazz-rock, and in addition to difficulty booking their acts, struggled to find younger generations of personnel to authentically play traditional styles such as hard bop and bebop. In the late 1970s, however, a resurgence of younger jazz players in Blakey's band began to occur. This movement included musicians such as Valery Ponomarev and Bobby Watson, Dennis Irwin and James Williams.
In the 1980s, in addition to Wynton and Branford Marsalis, the emergence of pianists in the Jazz Messengers such as Donald Brown, Mulgrew Miller, and later, Benny Green, bassists such as Charles Fambrough, Lonnie Plaxico (and later, Peter Washington and Essiet Essiet) horn players such as Bill Pierce, Donald Harrison and later Javon Jackson and Terence Blanchard emerged as talented jazz musicians, all of whom made significant contributions in the 1990s and 2000s.

The young Jazz Messengers' contemporaries, including Roy Hargrove, Marcus Roberts, Wallace Roney and Mark Whitfield were also influenced by Wynton Marsalis's emphasis toward jazz tradition. These younger rising stars rejected avant-garde approaches and instead championed the acoustic jazz sound of Charlie Parker, Thelonious Monk and early recordings of the first Miles Davis quintet. This group of "Young Lions" sought to reaffirm jazz as a high art tradition comparable to the discipline of classical music.

In addition, Betty Carter's rotation of young musicians in her group foreshadowed many of New York's preeminent traditional jazz players later in their careers. Among these musicians were Jazz Messenger alumni Benny Green, Branford Marsalis and Ralph Peterson Jr., as well as Kenny Washington, Lewis Nash, Curtis Lundy, Cyrus Chestnut, Mark Shim, Craig Handy, Greg Hutchinson and Marc Cary, Taurus Mateen and Geri Allen.

O.T.B. ensemble included a rotation of young jazz musicians such as Kenny Garrett, Steve Wilson, Kenny Davis, Renee Rosnes, Ralph Peterson Jr., Billy Drummond, and Robert Hurst.

A similar reaction took place against free jazz. According to Ted Gioia:

the very leaders of the avant garde started to signal a retreat from the core principles of free jazz. Anthony Braxton began recording standards over familiar chord changes. Cecil Taylor played duets in concert with Mary Lou Williams, and let her set out structured harmonies and familiar jazz vocabulary under his blistering keyboard attack. And the next generation of progressive players would be even more accommodating, moving inside and outside the changes without thinking twice. Musicians such as David Murray or Don Pullen may have felt the call of free-form jazz, but they never forgot all the other ways one could play African-American music for fun and profit.

Pianist Keith Jarrett—whose bands of the 1970s had played only original compositions with prominent free jazz elements—established his so-called 'Standards Trio' in 1983, which, although also occasionally exploring collective improvisation, has primarily performed and recorded jazz standards. Chick Corea similarly began exploring jazz standards in the 1980s, having neglected them for the 1970s.

In 1987, the United States House of Representatives and Senate passed a bill proposed by Democratic Representative John Conyers Jr. to define jazz as a unique form of American music, stating "jazz is hereby designated as a rare and valuable national American treasure to which we should devote our attention, support and resources to make certain it is preserved, understood and promulgated." It passed in the House on September 23, 1987 and in the Senate on November 4, 1987.

In the early 1980s, a commercial form of jazz fusion called "pop fusion" or "smooth jazz" became successful, garnering significant radio airplay in "quiet storm" time slots at radio stations in urban markets across the U.S. This helped to establish or bolster the careers of vocalists including Al Jarreau, Anita Baker, Chaka Khan, and Sade, as well as saxophonists including Grover Washington Jr., Kenny G, Kirk Whalum, Boney James, and David Sanborn. In general, smooth jazz is downtempo (the most widely played tracks are of 90–105 beats per minute), and has a lead melody-playing instrument (saxophone, especially soprano and tenor, and legato electric guitar are popular).

In his "Newsweek" article "The Problem With Jazz Criticism", Stanley Crouch considers Miles Davis' playing of fusion to be a turning point that led to smooth jazz. Critic Aaron J. West has countered the often negative perceptions of smooth jazz, stating:

I challenge the prevalent marginalization and malignment of smooth jazz in the standard jazz narrative. Furthermore, I question the assumption that smooth jazz is an unfortunate and unwelcomed evolutionary outcome of the jazz-fusion era. Instead, I argue that smooth jazz is a long-lived musical style that merits multi-disciplinary analyses of its origins, critical dialogues, performance practice, and reception.

Acid jazz developed in the UK in the 1980s and 1990s, influenced by jazz-funk and electronic dance music. Acid jazz often contains various types of electronic composition (sometimes including Sampling (music) or a live DJ cutting and scratching), but it is just as likely to be played live by musicians, who often showcase jazz interpretation as part of their performance. Richard S. Ginell of AllMusic considers Roy Ayers "one of the prophets of acid jazz."

Nu jazz is influenced by jazz harmony and melodies, and there are usually no improvisational aspects. It can be very experimental in nature and can vary widely in sound and concept. It ranges from the combination of live instrumentation with the beats of jazz house (as exemplified by St Germain, Jazzanova, and Fila Brazillia) to more band-based improvised jazz with electronic elements (for example, The Cinematic Orchestra, Kobol and the Norwegian "future jazz" style pioneered by Bugge Wesseltoft, Jaga Jazzist, and Nils Petter Molvær).

Jazz rap developed in the late 1980s and early 1990s and incorporates jazz influences into hip hop. In 1988, Gang Starr released the debut single "Words I Manifest", which sampled Dizzy Gillespie's 1962 "Night in Tunisia", and Stetsasonic released "Talkin' All That Jazz", which sampled Lonnie Liston Smith. Gang Starr's debut LP "No More Mr. Nice Guy" (1989) and their 1990 track "Jazz Thing" sampled Charlie Parker and Ramsey Lewis. The groups which made up the Native Tongues Posse tended toward jazzy releases: these include the Jungle Brothers' debut "Straight Out the Jungle" (1988), and A Tribe Called Quest's "People's Instinctive Travels and the Paths of Rhythm" (1990) and "The Low End Theory" (1991). Rap duo Pete Rock & CL Smooth incorporated jazz influences on their 1992 debut "Mecca and the Soul Brother". Rapper Guru's Jazzmatazz series began in 1993 using jazz musicians during the studio recordings.

Although jazz rap had achieved little mainstream success, Miles Davis' final album "Doo-Bop" (released posthumously in 1992) was based on hip hop beats and collaborations with producer Easy Mo Bee. Davis' ex-bandmate Herbie Hancock also absorbed hip-hop influences in the mid-1990s, releasing the album "Dis Is Da Drum" in 1994.

The relaxation of orthodoxy which was concurrent with post-punk in London and New York City led to a new appreciation of jazz. In London, the Pop Group began to mix free jazz and dub reggae into their brand of punk rock. In New York, No Wave took direct inspiration from both free jazz and punk. Examples of this style include Lydia Lunch's "Queen of Siam", Gray, the work of James Chance and the Contortions (who mixed Soul with free jazz and punk) and the Lounge Lizards (the first group to call themselves "punk jazz").

John Zorn took note of the emphasis on speed and dissonance that was becoming prevalent in punk rock, and incorporated this into free jazz with the release of the "Spy vs. Spy" album in 1986, a collection of Ornette Coleman tunes done in the contemporary thrashcore style. In the same year, Sonny Sharrock, Peter Brötzmann, Bill Laswell, and Ronald Shannon Jackson recorded the first album under the name Last Exit, a similarly aggressive blend of thrash and free jazz. These developments are the origins of "jazzcore", the fusion of free jazz with hardcore punk.

The M-Base movement started in the 1980s, when a loose collective of young African-American musicians in New York which included Steve Coleman, Greg Osby, and Gary Thomas developed a complex but grooving sound.

In the 1990s, most M-Base participants turned to more conventional music, but Coleman, the most active participant, continued developing his music in accordance with the M-Base concept.

Coleman's audience decreased, but his music and concepts influenced many musicians, according to pianist Vijay Iver and critic Ben Ratlifff of "The New York Times".

M-Base changed from a movement of a loose collective of young musicians to a kind of informal Coleman "school", with a much advanced but already originally implied concept. Steve Coleman's music and M-Base concept gained recognition as "next logical step" after Charlie Parker, John Coltrane, and Ornette Coleman.

Since the 1990s, jazz has been characterized by a pluralism in which no one style dominates, but rather a wide range of styles and genres are popular. Individual performers often play in a variety of styles, sometimes in the same performance. Pianist Brad Mehldau and The Bad Plus have explored contemporary rock music within the context of the traditional jazz acoustic piano trio, recording instrumental jazz versions of songs by rock musicians. The Bad Plus have also incorporated elements of free jazz into their music. A firm avant-garde or free jazz stance has been maintained by some players, such as saxophonists Greg Osby and Charles Gayle, while others, such as James Carter, have incorporated free jazz elements into a more traditional framework.

Harry Connick Jr. began his career playing stride piano and the dixieland jazz of his home, New Orleans, beginning with his first recording when he was ten years old. Some of his earliest lessons were at the home of pianist Ellis Marsalis. Connick had success on the pop charts after recording the soundtrack to the movie "When Harry Met Sally", which sold over two million copies. Crossover success has also been achieved by Diana Krall, Norah Jones, Cassandra Wilson, Kurt Elling, and Jamie Cullum.

A number of players who usually perform in largely straight-ahead settings have emerged since the 1990s, including pianists Jason Moran and Vijay Iyer, guitarist Kurt Rosenwinkel, vibraphonist Stefon Harris, trumpeters Roy Hargrove and Terence Blanchard, saxophonists Chris Potter and Joshua Redman, clarinetist Ken Peplowski and bassist Christian McBride.

Although jazz-rock fusion reached the height of its popularity in the 1970s, the use of electronic instruments and rock-derived musical elements in jazz continued in the 1990s and 2000s. Musicians using this approach include Pat Metheny, John Abercrombie, John Scofield and the Swedish group e.s.t. Since the beginning of the 90s, electronic music had significant technical improvements that popularized and created new possibilities for the genre. Jazz elements such as improvisation, rhythmic complexities and harmonic textures were introduced to the genre and consequently had a big impact in new listeners and in some ways kept the versatility of jazz relatable to a newer generation that did not necessarily relate to what the traditionalists call real jazz (bebop, cool and modal jazz). Artists such as Squarepusher, Aphex Twin, Flying Lotus and sub genres like IDM, Drum n' Bass, Jungle and Techno ended up incorporating a lot of these elements. Squarepusher being cited as one big influence for jazz performers drummer Mark Guiliana and pianist Brad Mehldau, showing the correlations between jazz and electronic music are a two-way street.

In 2001, Ken Burns's documentary "Jazz" was premiered on PBS, featuring Wynton Marsalis and other experts reviewing the entire history of American jazz to that time. It received some criticism, however, for its failure to reflect the many distinctive non-American traditions and styles in jazz that had developed, and its limited representation of US developments in the last quarter of the 20th century.

The mid-2010s have seen an increasing influence of R&B, hip-hop, and pop music on jazz. In 2015, Kendrick Lamar released his third studio album, "To Pimp a Butterfly". The album heavily featured prominent contemporary jazz artists such as Thundercat and redefined jazz rap with a larger focus on improvisation and live soloing rather than simply sampling. In that same year, saxophonist Kamasi Washington released his nearly three-hour long debut, "The Epic". Its hip-hop inspired beats and R&B vocal interludes was not only acclaimed by critics for being innovative in keeping jazz relevant, but also sparked a small resurgence in jazz on the internet.

Another internet-aided trend of 2010's jazz is that of extreme reharmonization, inspired by both virtuosic players known for their speed and rhythm such as Art Tatum, as well as players known for their ambitious voicings and chords such as Bill Evans. Supergroup Snarky Puppy has adopted this trend and has allowed for players like Cory Henry to shape the grooves and harmonies of modern jazz soloing. YouTube phenomenon Jacob Collier also gained recognition for his ability to play an incredibly large number of instruments and his ability to use microtones, advanced polyrhythms, and blend a spectrum of genres in his largely homemade production process.




</doc>
<doc id="15614" url="https://en.wikipedia.org/wiki?curid=15614" title="Jonathan Swift">
Jonathan Swift

Jonathan Swift (30 November 1667 – 19 October 1745) was an Anglo-Irish satirist, essayist, political pamphleteer (first for the Whigs, then for the Tories), poet and cleric who became Dean of St Patrick's Cathedral, Dublin, hence his common sobriquet, "Dean Swift".

Swift is remembered for works such as "A Tale of a Tub" (1704), "An Argument Against Abolishing Christianity" (1712), "Gulliver's Travels" (1726), and "A Modest Proposal" (1729). He is regarded by the "Encyclopædia Britannica" as the foremost prose satirist in the English language, and is less well known for his poetry. He originally published all of his works under pseudonyms – such as Lemuel Gulliver, Isaac Bickerstaff, M. B. Drapier – or anonymously. He was a master of two styles of satire, the Horatian and Juvenalian styles.

His deadpan, ironic writing style, particularly in "A Modest Proposal", has led to such satire being subsequently termed "Swiftian".

Jonathan Swift was born on 30 November 1667 in Dublin, Ireland. He was the second child and only son of Jonathan Swift (1640–1667) and his wife Abigail Erick (or Herrick) of Frisby on the Wreake. His father was a native of Goodrich, Herefordshire, but he accompanied his brothers to Ireland to seek their fortunes in law after their Royalist father's estate was brought to ruin during the English Civil War. His maternal grandfather, James Ericke, was the vicar of Thornton in Leicestershire. In 1634 the vicar was convicted of Puritan practices. Some time thereafter, Ericke and his family, including his young daughter Abilgail, fled to Ireland.

Swift's father joined his elder brother, Godwin, in the practice of law in Ireland. He died in Dublin about seven months before his namesake was born. He died of syphilis, which he said he got from dirty sheets when out of town.

At the age of one, child Jonathan was taken by his wet nurse to her hometown of Whitehaven, Cumberland, England. He said that there he learned to read the Bible. His nurse returned him to his mother, still in Ireland, when he was three.

His mother returned to England after his birth, leaving him in the care of his uncle Godwin Swift (1628–1695), a close friend and confidant of Sir John Temple, whose son later employed Swift as his secretary.
Swift's family had several interesting literary connections. His grandmother Elizabeth (Dryden) Swift was the niece of Sir Erasmus Dryden, grandfather of poet John Dryden. The same grandmother's aunt Katherine (Throckmorton) Dryden was a first cousin of Elizabeth, wife of Sir Walter Raleigh. His great-great grandmother Margaret (Godwin) Swift was the sister of Francis Godwin, author of "The Man in the Moone" which influenced parts of Swift's "Gulliver's Travels". His uncle Thomas Swift married a daughter of poet and playwright Sir William Davenant, a godson of William Shakespeare.

Swift's benefactor and uncle Godwin Swift took primary responsibility for the young man, sending him with one of his cousins to Kilkenny College (also attended by philosopher George Berkeley). He arrived there at the age of six, where he was expected to have already learned the basic declensions in Latin. He had not, and thus began his schooling in a lower form. Swift graduated in 1682, when he was 15.

He attended Dublin University (Trinity College, Dublin) in 1682, financed by Godwin's son Willoughby. The four-year course followed a curriculum largely set in the Middle Ages for the priesthood. The lectures were dominated by Aristotelian logic and philosophy. The basic skill taught the students was debate, and they were expected to be able to argue both sides of any argument or topic. Swift was an above-average student but not exceptional, and received his B.A. in 1686 "by special grace."

Swift was studying for his master's degree when political troubles in Ireland surrounding the Glorious Revolution forced him to leave for England in 1688, where his mother helped him get a position as secretary and personal assistant of Sir William Temple at Moor Park, Farnham. Temple was an English diplomat who arranged the Triple Alliance of 1668. He had retired from public service to his country estate, to tend his gardens and write his memoirs. Gaining his employer's confidence, Swift "was often trusted with matters of great importance". Within three years of their acquaintance, Temple had introduced his secretary to William III and sent him to London to urge the King to consent to a bill for triennial Parliaments.

Swift took up his residence at Moor Park where he met Esther Johnson, then eight years old, the daughter of an impoverished widow who acted as companion to Temple's sister Lady Giffard. Swift was her tutor and mentor, giving her the nickname "Stella", and the two maintained a close but ambiguous relationship for the rest of Esther's life.

In 1690, Swift left Temple for Ireland because of his health, but returned to Moor Park the following year. The illness consisted of fits of vertigo or giddiness, now known to be Ménière's disease, and it continued to plague him throughout his life. During this second stay with Temple, Swift received his M.A. from Hart Hall, Oxford, in 1692. He then left Moor Park, apparently despairing of gaining a better position through Temple's patronage, in order to become an ordained priest in the Established Church of Ireland. He was appointed to the prebend of Kilroot in the Diocese of Connor in 1694, with his parish located at Kilroot, near Carrickfergus in County Antrim.

Swift appears to have been miserable in his new position, being isolated in a small, remote community far from the centres of power and influence. While at Kilroot, however, he may well have become romantically involved with Jane Waring, whom he called "Varina", the sister of an old college friend. A letter from him survives, offering to remain if she would marry him and promising to leave and never return to Ireland if she refused. She presumably refused, because Swift left his post and returned to England and Temple's service at Moor Park in 1696, and he remained there until Temple's death. There he was employed in helping to prepare Temple's memoirs and correspondence for publication. During this time, Swift wrote "The Battle of the Books", a satire responding to critics of Temple's "Essay upon Ancient and Modern Learning" (1690), though "Battle" was not published until 1704.

Temple died on 27 January 1699. Swift, normally a harsh judge of human nature, said that all that was good and amiable in mankind had died with Temple. He stayed on briefly in England to complete editing Temple's memoirs, and perhaps in the hope that recognition of his work might earn him a suitable position in England. Unfortunately, his work made enemies among some of Temple's family and friends, in particular Temple's formidable sister Lady Giffard, who objected to indiscretions included in the memoirs. Swift's next move was to approach King William directly, based on his imagined connection through Temple and a belief that he had been promised a position. This failed so miserably that he accepted the lesser post of secretary and chaplain to the Earl of Berkeley, one of the Lords Justice of Ireland. However, when he reached Ireland, he found that the secretaryship had already been given to another. He soon obtained the living of Laracor, Agher, and Rathbeggan, and the prebend of Dunlavin in St Patrick's Cathedral, Dublin.

Swift ministered to a congregation of about 15 at Laracor, which was just over four and half miles (7.5 km) from Summerhill, County Meath, and from Dublin. He had abundant leisure for cultivating his garden, making a canal after the Dutch fashion of Moor Park, planting willows, and rebuilding the vicarage. As chaplain to Lord Berkeley, he spent much of his time in Dublin and travelled to London frequently over the next ten years. In 1701, he anonymously published the political pamphlet "A Discourse on the Contests and Dissentions in Athens and Rome".

Swift had residence in Trim, County Meath, after 1700. He wrote many of his works during this time period. In February 1702, Swift received his Doctor of Divinity degree from Trinity College, Dublin. That spring he travelled to England and then returned to Ireland in October, accompanied by Esther Johnson—now 20—and his friend Rebecca Dingley, another member of William Temple's household. There is a great mystery and controversy over Swift's relationship with Esther Johnson, nicknamed "Stella". Many, notably his close friend Thomas Sheridan, believed that they were secretly married in 1716; others, like Swift's housekeeper Mrs Brent and Rebecca Dingley (who lived with Stella all through her years in Ireland) dismissed the story as absurd. Swift certainly did not wish her to marry anyone else: in 1704, when their mutual friend William Tisdall informed Swift that he intended to propose to Stella, Swift wrote to him to dissuade him from the idea. Although the tone of the letter was courteous, Swift privately expressed his disgust for Tisdall as an "interloper", and they were estranged for many years.

During his visits to England in these years, Swift published "A Tale of a Tub" and "The Battle of the Books" (1704) and began to gain a reputation as a writer. This led to close, lifelong friendships with Alexander Pope, John Gay, and John Arbuthnot, forming the core of the Martinus Scriblerus Club (founded in 1713).

Swift became increasingly active politically in these years. Swift supported the Glorious Revolution and early in his life belonged to the Whigs. As a member of the Anglican Church, he feared a return of the Catholic monarchy and "Papist" absolutism. From 1707 to 1709 and again in 1710, Swift was in London unsuccessfully urging upon the Whig administration of Lord Godolphin the claims of the Irish clergy to the First-Fruits and Twentieths ("Queen Anne's Bounty"), which brought in about £2,500 a year, already granted to their brethren in England. He found the opposition Tory leadership more sympathetic to his cause, and, when they came to power in 1710, he was recruited to support their cause as editor of "The Examiner". In 1711, Swift published the political pamphlet "The Conduct of the Allies", attacking the Whig government for its inability to end the prolonged war with France. The incoming Tory government conducted secret (and illegal) negotiations with France, resulting in the Treaty of Utrecht (1713) ending the War of the Spanish Succession.

Swift was part of the inner circle of the Tory government, and often acted as mediator between Henry St John (Viscount Bolingbroke), the secretary of state for foreign affairs (1710–15), and Robert Harley (Earl of Oxford), lord treasurer and prime minister (1711–1714). Swift recorded his experiences and thoughts during this difficult time in a long series of letters to Esther Johnson, collected and published after his death as "A Journal to Stella". The animosity between the two Tory leaders eventually led to the dismissal of Harley in 1714. With the death of Queen Anne and accession of George I that year, the Whigs returned to power, and the Tory leaders were tried for treason for conducting secret negotiations with France.

Swift has been described by scholars as "a Whig in politics and Tory in religion" and Swift related his own views in similar terms, stating that as "a lover of liberty, I found myself to be what they called a Whig in politics...But, as to religion, I confessed myself to be an High-Churchman." In his "Thoughts on Religion", fearing the intense partisan strife waged over religious belief in the seventeenth century England, Swift wrote that "Every man, as a member of the commonwealth, ought to be content with the possession of his own opinion in private." However, it should be borne in mind that, during Swift's time period, terms like "Whig" and "Tory" both encompassed a wide array of opinions and factions, and neither term aligns with a modern political party or modern political alignments.

Also during these years in London, Swift became acquainted with the Vanhomrigh family (Dutch merchants who had settled in Ireland, then moved to London) and became involved with one of the daughters, Esther. Swift furnished Esther with the nickname "Vanessa" (derived by adding "Essa", a pet form of Esther, to the "Van" of her surname, Vanhomrigh), and she features as one of the main characters in his poem "Cadenus and Vanessa". The poem and their correspondence suggest that Esther was infatuated with Swift, and that he may have reciprocated her affections, only to regret this and then try to break off the relationship. Esther followed Swift to Ireland in 1714, and settled at her old family home, Celbridge Abbey. Their uneasy relationship continued for some years; then there appears to have been a confrontation, possibly involving Esther Johnson. Esther Vanhomrigh died in 1723 at the age of 35, having destroyed the will she had made in Swift's favour. Another lady with whom he had a close but less intense relationship was Anne Long, a toast of the Kit-Cat Club.

Before the fall of the Tory government, Swift hoped that his services would be rewarded with a church appointment in England. However, Queen Anne appeared to have taken a dislike to Swift and thwarted these efforts. Her dislike has been attributed to "A Tale of a Tub", which she thought blasphemous, compounded by "The Windsor Prophecy", where Swift, with a surprising lack of tact, advised the Queen on which of her bedchamber ladies she should and should not trust. The best position his friends could secure for him was the Deanery of St Patrick's; this was not in the Queen's gift, and Anne, who could be a bitter enemy, made it clear that Swift would not have received the preferment if she could have prevented it. With the return of the Whigs, Swift's best move was to leave England and he returned to Ireland in disappointment, a virtual exile, to live "like a rat in a hole".

Once in Ireland, however, Swift began to turn his pamphleteering skills in support of Irish causes, producing some of his most memorable works: "Proposal for Universal Use of Irish Manufacture" (1720), "Drapier's Letters" (1724), and "A Modest Proposal" (1729), earning him the status of an Irish patriot. This new role was unwelcome to the Government, which made clumsy attempts to silence him. His printer, Edward Waters, was convicted of seditious libel in 1720, but four years later a grand jury refused to find that the "Drapier's Letters" (which, though written under a pseudonym, were universally known to be Swift's work) were seditious. Swift responded with an attack on the Irish judiciary almost unparalleled in its ferocity, his principal target being the "vile and profligate villain" William Whitshed, Lord Chief Justice of Ireland.

Also during these years, he began writing his masterpiece, "Travels into Several Remote Nations of the World, in Four Parts, by Lemuel Gulliver, first a surgeon, and then a captain of several ships", better known as "Gulliver's Travels". Much of the material reflects his political experiences of the preceding decade. For instance, the episode in which the giant Gulliver puts out the Lilliputian palace fire by urinating on it can be seen as a metaphor for the Tories' illegal peace treaty; having done a good thing in an unfortunate manner. In 1726 he paid a long-deferred visit to London, taking with him the manuscript of "Gulliver's Travels". During his visit he stayed with his old friends Alexander Pope, John Arbuthnot and John Gay, who helped him arrange for the anonymous publication of his book. First published in November 1726, it was an immediate hit, with a total of three printings that year and another in early 1727. French, German, and Dutch translations appeared in 1727, and pirated copies were printed in Ireland.

Swift returned to England one more time in 1727, and stayed once again with Alexander Pope. The visit was cut short when Swift received word that Esther Johnson was dying, and rushed back home to be with her. On 28 January 1728, Johnson died; Swift had prayed at her bedside, even composing prayers for her comfort. Swift could not bear to be present at the end, but on the night of her death he began to write his "The Death of Mrs Johnson". He was too ill to attend the funeral at St Patrick's. Many years later, a lock of hair, assumed to be Johnson's, was found in his desk, wrapped in a paper bearing the words, "Only a woman's hair".
Death became a frequent feature of Swift's life from this point. In 1731 he wrote "Verses on the Death of Dr. Swift", his own obituary, published in 1739. In 1732, his good friend and collaborator John Gay died. In 1735, John Arbuthnot, another friend from his days in London, died. In 1738 Swift began to show signs of illness, and in 1742 he may have suffered a stroke, losing the ability to speak and realising his worst fears of becoming mentally disabled. ("I shall be like that tree", he once said, "I shall die at the top.") He became increasingly quarrelsome, and long-standing friendships, like that with Thomas Sheridan, ended without sufficient cause. To protect him from unscrupulous hangers on, who had begun to prey on the great man, his closest companions had him declared of "unsound mind and memory". However, it was long believed by many that Swift was actually insane at this point. In his book "Literature and Western Man", author J. B. Priestley even cites the final chapters of "Gulliver's Travels" as proof of Swift's approaching "insanity". Bewley attributes his decline to 'terminal dementia'.

In part VIII of his series, "The Story of Civilization", Will Durant describes the final years of Swift's life as such:

"Definite symptoms of madness appeared in 1738. In 1741, guardians were appointed to take care of his affairs and watch lest in his outbursts of violence he should do himself harm. In 1742, he suffered great pain from the inflammation of his left eye, which swelled to the size of an egg; five attendants had to restrain him from tearing out his eye. He went a whole year without uttering a word."

In 1744, Alexander Pope died. Then on 19 October 1745, Swift, at nearly 80, died. After being laid out in public view for the people of Dublin to pay their last respects, he was buried in his own cathedral by Esther Johnson's side, in accordance with his wishes. The bulk of his fortune (£12,000) was left to found a hospital for the mentally ill, originally known as St Patrick's Hospital for Imbeciles, which opened in 1757, and which still exists as a psychiatric hospital.

Jonathan Swift wrote his own epitaph:
W. B. Yeats poetically translated it from the Latin as:

Swift was a prolific writer, notable for his satires. The most recent collection of his prose works (Herbert Davis, ed. Basil Blackwell, 1965–) comprises fourteen volumes. A recent edition of his complete poetry (Pat Rodges, ed. Penguin, 1983) is 953 pages long. One edition of his correspondence (David Woolley, ed. P. Lang, 1999) fills three volumes.

Swift's first major prose work, "A Tale of a Tub", demonstrates many of the themes and stylistic techniques he would employ in his later work. It is at once wildly playful and funny while being pointed and harshly critical of its targets. In its main thread, the "Tale" recounts the exploits of three sons, representing the main threads of Christianity, who receive a bequest from their father of a coat each, with the added instructions to make no alterations whatsoever. However, the sons soon find that their coats have fallen out of current fashion, and begin to look for loopholes in their father's will that will let them make the needed alterations. As each finds his own means of getting around their father's admonition, they struggle with each other for power and dominance. Inserted into this story, in alternating chapters, the narrator includes a series of whimsical "digressions" on various subjects.

In 1690, Sir William Temple, Swift's patron, published "An Essay upon Ancient and Modern Learning" a defence of classical writing (see Quarrel of the Ancients and the Moderns), holding up the "Epistles of Phalaris" as an example. William Wotton responded to Temple with "Reflections upon Ancient and Modern Learning" (1694), showing that the "Epistles" were a later forgery. A response by the supporters of the Ancients was then made by Charles Boyle (later the 4th Earl of Orrery and father of Swift's first biographer). A further retort on the Modern side came from Richard Bentley, one of the pre-eminent scholars of the day, in his essay "Dissertation upon the Epistles of Phalaris" (1699). The final words on the topic belong to Swift in his "Battle of the Books" (1697, published 1704) in which he makes a humorous defence on behalf of Temple and the cause of the Ancients.
In 1708, a cobbler named John Partridge published a popular almanac of astrological predictions. Because Partridge falsely determined the deaths of several church officials, Swift attacked Partridge in "Predictions for the Ensuing Year" by Isaac Bickerstaff, a parody predicting that Partridge would die on 29 March. Swift followed up with a pamphlet issued on 30 March claiming that Partridge had in fact died, which was widely believed despite Partridge's statements to the contrary. According to other sources, Richard Steele used the persona of Isaac Bickerstaff, and was the one who wrote about the "death" of John Partridge and published it in "The Spectator", not Jonathan Swift.

The "Drapier's Letters" (1724) was a series of pamphlets against the monopoly granted by the English government to William Wood to mint copper coinage for Ireland. It was widely believed that Wood would need to flood Ireland with debased coinage in order to make a profit. In these "letters" Swift posed as a shop-keeper—a draper—to criticise the plan. Swift's writing was so effective in undermining opinion in the project that a reward was offered by the government to anyone disclosing the true identity of the author. Though hardly a secret (on returning to Dublin after one of his trips to England, Swift was greeted with a banner, "Welcome Home, Drapier") no one turned Swift in, although there was an unsuccessful attempt to prosecute the publisher Harding. Thanks to the general outcry against the coinage, Wood's patent was rescinded in September 1725 and the coins were kept out of circulation. In "Verses on the Death of Dr. Swift" (1739) Swift recalled this as one of his best achievements.

"Gulliver's Travels", a large portion of which Swift wrote at Woodbrook House in County Laois, was published in 1726. It is regarded as his masterpiece. As with his other writings, the "Travels" was published under a pseudonym, the fictional Lemuel Gulliver, a ship's surgeon and later a sea captain. Some of the correspondence between printer Benj. Motte and Gulliver's also-fictional cousin negotiating the book's publication has survived. Though it has often been mistakenly thought of and published in bowdlerised form as a children's book, it is a great and sophisticated satire of human nature based on Swift's experience of his times. "Gulliver's Travels" is an anatomy of human nature, a sardonic looking-glass, often criticised for its apparent misanthropy. It asks its readers to refute it, to deny that it has adequately characterised human nature and society. Each of the four books—recounting four voyages to mostly fictional exotic lands—has a different theme, but all are attempts to deflate human pride. Critics hail the work as a satiric reflection on the shortcomings of Enlightenment thought.

In 1729, Swift published "A Modest Proposal for Preventing the Children of Poor People in Ireland Being a Burden on Their Parents or Country, and for Making Them Beneficial to the Publick", a satire in which the narrator, with intentionally grotesque arguments, recommends that Ireland's poor escape their poverty by selling their children as food to the rich: "I have been assured by a very knowing American of my acquaintance in London, that a young healthy child well nursed is at a year old a most delicious nourishing and wholesome food..." Following the satirical form, he introduces the reforms he is actually suggesting by deriding them:
Therefore let no man talk to me of other expedients...taxing our absentees...using [nothing] except what is of our own growth and manufacture...rejecting...foreign luxury...introducing a vein of parsimony, prudence and temperance...learning to love our country...quitting our animosities and factions...teaching landlords to have at least one degree of mercy towards their tenants...Therefore I repeat, let no man talk to me of these and the like expedients, till he hath at least some glympse of hope, that there will ever be some hearty and sincere attempt to put them into practice.





John Ruskin named him as one of the three people in history who were the most influential for him.

George Orwell named him as one of the writers he most admired, despite disagreeing with him on almost every moral and political issue. Modernist poet Edith Sitwell wrote a fictional biography of Swift, titled "I Live Under a Black Sun" and published in 1937.

Swift crater, a crater on Mars's moon Deimos, is named after Jonathan Swift, who predicted the existence of the moons of Mars.

In honour of Swift's long-time residence in Trim, there are several monuments in the town marking his legacy. Most notable is Swift's Street, named after him. Trim also holds a recurring festival in honour of Swift, called the 'Trim Swift Festival'.

Jake Arnott features him in his 2017 novel "The Fatal Tree".

A 2017 analysis of library holdings data revealed that Swift is the most popular Irish author, and that "Gulliver’s Travels" is the most widely held work of Irish literature in libraries globally.



Online works


</doc>
<doc id="15616" url="https://en.wikipedia.org/wiki?curid=15616" title="Jello Biafra">
Jello Biafra

Eric Reed Boucher (born June 17, 1958), better known by his professional name Jello Biafra, is an American singer, musician, and spoken word artist. He is the former lead singer and songwriter for the San Francisco punk rock band Dead Kennedys.

Initially active from 1979 to 1986, Dead Kennedys were known for rapid-fire music topped with Biafra's sardonic lyrics and biting social commentary, delivered in his "unique quiver of a voice." When the band broke up in 1986, he took over the influential independent record label Alternative Tentacles, which he had founded in 1979 with Dead Kennedys bandmate East Bay Ray. In a 2000 lawsuit, upheld on appeal in 2003 by the California Supreme Court, Biafra was found liable for breach of contract, fraud and malice in withholding a decade's worth of royalties from his former bandmates and ordered to pay over $200,000 in compensation and punitive damages; the band subsequently reformed without Biafra. Although now focused primarily on spoken word performances, Biafra has continued as a musician in numerous collaborations. He has also occasionally appeared in cameo roles in films.

Politically, Biafra is a member of the Green Party of the United States and supports various political causes. He ran for the party's presidential nomination in the 2000 presidential election, finishing a distant second to Ralph Nader. He is a staunch believer in a free society, and utilizes shock value and advocates direct action and pranksterism in the name of political causes. Biafra is known to use absurdist media tactics, in the leftist tradition of the Yippies, to highlight issues of civil rights and social justice.

Eric Reed Boucher was born in Boulder, Colorado, the son of Virginia (née Parker), a librarian, and Stanley Wayne Boucher, a psychiatric social worker and poet. He had a sister, Julie J. Boucher, the Associate Director of the Library Research Service at the Colorado State Library (who died in a mountain-climbing accident on October 12, 1996). Biafra is 1/8 Jewish, but was unaware of this until relatively recently and grew up in a secular household.

As a child, Boucher developed an interest in international politics that was encouraged by his parents. An avid news watcher, one of his earliest memories was of the John F. Kennedy assassination. Biafra says he has been a fan of rock music since first hearing it in 1965, when his parents accidentally tuned in to a rock radio station. Boucher ignored his high school guidance counselor's advice that he spend his adolescence preparing to become a dental hygienist.

He began his career in music in January 1977 as a roadie for the punk rock band The Ravers (who later changed their name to The Nails), soon joining his friend John Greenway in a band called The Healers. The Healers became well known locally for their mainly improvised lyrics and avant garde music. In the autumn of that year, he began attending the University of California, Santa Cruz.

In June 1978, he responded to an advertisement placed in a store by guitarist East Bay Ray, stating; "guitarist wants to form punk band," and together they formed the Dead Kennedys. He began performing with the band under the stage name Occupant, but soon began to use his current stage name, a combination of the brand name Jell-O and the short-lived African state Biafra. The band's lyrics were written by Biafra. The lyrics were mostly political in nature and displayed a sardonic, sometimes absurdist, sense of humor despite their serious subject matter. In the tradition of UK anarcho-punk bands like Crass and the Subhumans, the Dead Kennedys were one of the first US punk bands to write politically themed songs. The lyrics Biafra wrote helped popularize the use of humorous lyrics in punk and other types of hard-core music. Biafra cites Joey Ramone as the inspiration for his use of humor in his songs (as well as being the musician who made him interested in punk rock), noting in particular songs by the Ramones such as "Beat on the Brat" and "Now I Wanna Sniff Some Glue".

Biafra initially attempted to compose music on guitar, but his lack of experience on the instrument and his own admission of being "a fumbler with my hands" led Dead Kennedys bassist Klaus Flouride to suggest that Biafra simply sing the parts he envisioned to the band.<ref name="re/search">V. Vale, "Incredibly Strange Music, Vol. 2", RE/Search Publications, 1995</ref> Biafra sang his riffs and melodies into a tape recorder, which he brought to the band's rehearsal and/or recording sessions. This later became a problem when the other members of the Dead Kennedys sued Biafra over royalties and publishing rights. By all accounts, including his own, Biafra is not a conventionally skilled musician, though he and his collaborators (Joey Shithead of D.O.A. in particular) attest that he is a skilled composer and his work, particularly with the Dead Kennedys, is highly respected by punk-oriented critics and fans.

Biafra's first popular song was the first single by the Dead Kennedys, "California Über Alles." The song, which spoofed California governor Jerry Brown, was the first of many political songs by the group and Biafra. The song's popularity resulted in its being covered by other musicians, such as The Disposable Heroes of Hiphoprisy (who rewrote the lyrics to parody Pete Wilson), John Linnell of They Might Be Giants and Six Feet Under on their "Graveyard Classics" album of cover versions. Not long after, the Dead Kennedys had a second and bigger hit with "Holiday in Cambodia" from their debut album "Fresh Fruit for Rotting Vegetables". "AllMusic" cites this song as "possibly the most successful single of the American hardcore scene" and Biafra counts it as his personal favorite Dead Kennedy's song. Minor hits from the album included "Kill the Poor" (about potential abuse of the then-new neutron bomb) and a satirical cover of Elvis Presley's "Viva Las Vegas."

The Dead Kennedys received some controversy in the spring of 1981 over the single "Too Drunk to Fuck." The song became a hit in Britain, and the BBC feared that it would manage to be a big enough hit to appear among the top 30 songs on the national charts, requiring a mention on "Top of the Pops". However, the single peaked at number 31 in the charts.

Later albums also contained memorable songs, but with less popularity than the earlier ones. The EP "In God We Trust, Inc." contained the song "Nazi Punks Fuck Off!" as well as "We've Got A Bigger Problem Now," a rewritten version of "California Über Alles" about Ronald Reagan. Punk musician and scholar Vic Bondi considers the latter song to be the song that "defined the lyrical agenda of much of hardcore music, and represented its break with punk". The band's most controversial album, "Frankenchrist", brought with it the song "MTV Get Off the Air," which accused MTV of promoting poor quality music and sedating the public. The album also contained a controversial poster by Swiss surrealist artist H. R. Giger entitled "Penis Landscape".

The Dead Kennedys toured widely during their career, starting in the late 1970s. They began playing at San Francisco's Mabuhay Gardens (their home base) and other Bay Area venues, later branching out to shows in southern Californian clubs (most notably the Whisky a Go Go), but eventually they moved to major clubs across the country, including CBGB in New York. Later, they played to larger audiences such as at the 1980 Bay Area Music Awards (where they played the notorious "Pull My Strings" for the only time), and headlined the 1983 Rock Against Reagan festival.

On May 7, 1994, punk rock fans who believed Biafra was a "sell out" attacked him at the 924 Gilman Street club in Berkeley, California. Biafra claims that he was attacked by a man nicknamed Cretin, who crashed into him while moshing. The crash injured Biafra's leg, causing an argument between the two men. During the argument, Cretin pushed Biafra to the floor and five or six friends of Cretin assaulted Biafra while he was down, yelling "Sellout rock star, kick him," and attempting to pull out his hair. Biafra was later hospitalized with serious injuries. The attack derailed Biafra's plans for both a Canadian spoken-word tour and an accompanying album, and the production of "Pure Chewing Satisfaction" was halted. However, Biafra returned to the Gilman club a few months after the incident to perform a spoken-word performance as an act of reconciliation with the club.

Biafra has been a prominent figure of the Californian punk scene and was one of the third generation members of the San Francisco punk community. Many later hardcore bands have cited the Dead Kennedys as a major influence. Hardcore punk author Steven Blush describes Biafra as hardcore's "biggest star" who was a "powerful presence whose political insurgence and rabid fandom made him the father figure of a burgeoning subculture [and an] inspirational force [who] could also be a real prick ... Biafra was a visionary, incendiary [performer]."

After the Dead Kennedys disbanded, Biafra's new songs were recorded with other bands, and he released only spoken word albums as solo projects. These collaborations had less popularity than Biafra's earlier work. However, his song "That's Progress", originally recorded with D.O.A. for the album "Last Scream of the Missing Neighbors", received considerable exposure when it appeared on the album "Rock Against Bush, Vol. 1".

In April 1986, police officers raided his house in response to complaints by the Parents Music Resource Center (PMRC). In June 1986, L.A. deputy city attorney Michael Guarino, working under City Attorney James Hahn, brought Biafra to trial in Los Angeles for distributing "harmful material to minors" in the Dead Kennedys album "Frankenchrist". However, the dispute was about neither the music nor the lyrics from the album, but rather the print of the H. R. Giger poster "Landscape XX" ("Penis Landscape") included with the album. Biafra believes the trial was politically motivated; it was often reported that the PMRC took Biafra to court as a cost-effective way of sending a message out to other musicians with content considered offensive in their music.

Music author Reebee Garofalo argued that Biafra and Alternative Tentacles may have been targeted because the label was a "small, self-managed and self-supported company that could ill afford a protracted legal battle." Facing the possible sentence of a year in jail and a $2,000 fine, Biafra, Dirk Dirksen, and Suzanne Stefanac founded the No More Censorship Defense Fund, a benefit featuring several punk rock bands, to help pay for his legal fees, which neither he nor his record label could afford. The jury deadlocked 5 to 7 in favor of acquittal, prompting a mistrial; despite a motion to re-try the case, the judge ordered all charges dropped. The Dead Kennedys disbanded during the trial, in December 1986, due to the mounting legal costs; in the wake of their disbandment, Biafra made a career of his spoken word performances.

Biafra has a cameo role in the 1988 film "Tapeheads". He plays an FBI agent who arrests the two protagonists (played by Tim Robbins and John Cusack). While arresting them his character asks "Remember what we did to Jello Biafra?" lampooning the obscenity prosecution.

On March 25, 2005, Biafra appeared on the U.S. radio program "This American Life", "Episode 285: Know Your Enemy", which featured a phone call between Jello Biafra and Michael Guarino, the prosecutor in the "Frankenchrist" trial.

In October 1998, three former members of the Dead Kennedys sued Biafra for nonpayment of royalties. The other members of Dead Kennedys alleged that Biafra, in his capacity as the head of Alternative Tentacles records, discovered an accounting error amounting to some $75,000 in unpaid royalties over almost a decade. Rather than informing his bandmates of this mistake, the suit alleged, Biafra knowingly concealed the information until a whistleblower employee at the record label notified the band.

According to Biafra, the suit resulted from his refusal to allow one of the band's most well-known singles, "Holiday in Cambodia", to be used in a commercial for Levi's Dockers; Biafra opposes Levi's because of his belief that they use unfair business practices and sweatshop labor. Biafra maintained that he had never denied them royalties, and that he himself had not even received royalties for re-releases of their albums or "posthumous" live albums which had been licensed to other labels by the Decay Music partnership. Decay Music denied this charge and have posted what they say are his cashed royalty checks, written to his legal name of Eric Boucher. Biafra also complained about the songwriting credits in new reissues and archival live albums of songs, alleging that he was the sole composer of songs that were wrongly credited to the entire band.

In May 2000, a jury found Biafra and Alternative Tentacles liable by not promptly informing his former bandmates of the accounting error and instead withholding the information during subsequent discussions and contractual negotiations. Biafra was ordered to pay $200,000, including $20,000 in punitive damages. After an appeal by Biafra's lawyers, in June 2003, the California Court of Appeal unanimously upheld all the conditions of the 2000 verdict against Biafra and Alternative Tentacles. Furthermore, the plaintiffs were awarded the rights to most of Dead Kennedys recorded works—which accounted for about half the sales for Alternative Tentacles. Now in control of the Dead Kennedys name, Biafra's former bandmates went on tour with a new lead vocalist.

In the early 1980s, Biafra collaborated with musicians Christian Lunch and Adrian Borland (of The Sound) for the electropunk musical project The Witch Trials, releasing one self-titled EP in its lifetime.

In 1988, Biafra, with Al Jourgensen and Paul Barker of the band Ministry, and Jeff Ward, formed Lard. The band became yet another side project for Ministry, with Biafra providing vocals and lyrics. According to a March 2009 interview with Jourgensen, he and Biafra are working on a new Lard album, which is being recorded in Jourgensen's El Paso studio. While working on the film "Terminal City Ricochet" in 1989, Biafra did a song for the film's soundtrack with D.O.A.. As a result, Biafra worked with D.O.A. on the album "Last Scream of the Missing Neighbors". Biafra also worked with Nomeansno on the soundtrack, which led to their collaboration on the album "The Sky Is Falling and I Want My Mommy" the following year. Biafra also provided lyrics for the song "Biotech is Godzilla" for Sepultura's 1993 album "Chaos A.D.".

In 1999, Biafra and other members of the anti-globalization movement protested the WTO Meeting of 1999 in Seattle. Along with other prominent West Coast musicians, he formed the short-lived band the No WTO Combo to help promote the movement's cause. The band was originally scheduled to play during the protest, but the performance was canceled due to riots. The band performed a short set the following night at the Showbox in downtown Seattle (outside the designated area), along with the hiphop group Spearhead. No WTO Combo later released a CD of recordings from the concert, entitled "Live from the Battle in Seattle".

As of late 2005, Biafra was performing with the band The Melvins under the name "Jello Biafra and the Melvins", though fans sometimes refer to them as "The Jelvins." Together they have released two albums, and worked on material for a third collaborative release, much of which was premiered live at two concerts at the Great American Music Hall in San Francisco during an event called Biafra Five-O, commemorating Biafra's 50th birthday, the 30th anniversary of the founding of the Dead Kennedys, and the beginning of legalized same-sex marriage in California. Biafra was also working with a band known as Jello Biafra and the Guantanamo School of Medicine, which included Ralph Spight of Victims Family on guitar and Billy Gould of Faith No More on bass. This group debuted during Biafra Five-O.

In 2011, Biafra appeared in a singular concert event with an all-star cast of Southern musicians including members from Cowboy Mouth, Dash Rip Rock, Mojo Nixon and Down entitled, "Jello Biafra and the New Orleans Raunch & Soul All Stars" who performed an array of classic Soul covers to a packed house at the 12-Bar in New Orleans, Louisiana. He would later reunite with many of the same musicians during the Carnival season 2014 to revisit many of these classics at Siberia, New Orleans. A live album from the 2011 performance, "Walk on Jindal's Splinters", and a companion single, "Fannie May"/"Just a Little Bit", were released in 2015.

In June 1979, Biafra co-founded the record label Alternative Tentacles, with which the Dead Kennedys released their first single, "California Über Alles". The label was created to allow the band to release albums without having to deal with pressure from major labels to change their music, although the major labels were not willing to sign the band due to their songs being deemed too controversial. After dealing with Cherry Red in the UK and IRS Records in the US for their first album "Fresh Fruit for Rotting Vegetables", the band released all later albums, and later pressings of "Fresh Fruit" on Alternative Tentacles. The exception being live albums released after the band's break-up, which the other band members compiled from recordings in the band partnership's vaults without Biafra's input or endorsement.. Biafra has been the owner of the company since its founding, though he does not receive a salary for his position; Biafra has referred to his position in the company as "absentee thoughtlord".

Biafra is an ardent collector of unusual vinyl records of all kinds, from 1950s and 1960s ethno-pop recordings by the likes of Les Baxter and Esquivel to vanity pressings that have circulated regionally, to German crooner Heino (for whom he would later participate in the documentary "Heino: Made In Germany"); he cites his always growing collection as one of his biggest musical influences. In 1993 he gave an interview to RE/Search Publications for their second "Incredibly Strange Music" book focusing primarily on these records, and later participated in a two-part episode of Fuse TV's program "Crate Diggers" on the same subject. His interest in such recordings, often categorized as outsider music, led to his discovery of the prolific (and schizophrenic) singer/songwriter/artist Wesley Willis, whom he signed to Alternative Tentacles in 1994, preceding Willis' major label deal with American Recordings. His collection grew so large that on October 1, 2005, Biafra donated a portion of his collection to an annual yard sale co-promoted by Alternative Tentacles and held at their warehouse in Emeryville, California.

In 2006, along with Alternative Tentacles employee and The Frisk lead singer Jesse Luscious, Biafra began co-hosting "The Alternative Tentacles Batcast", a downloadable podcast hosted by alternativetentacles.com. The show primarily focuses on interviews with artists and bands that are currently signed to the Alternative Tentacles label, although there are also occasional episodes where Biafra devoted the show to answering fan questions.

Biafra became a spoken word artist in January 1986 with a performance at University of California, Los Angeles. In his performance he combined humor with his political beliefs, much in the same way that he did with the lyrics to his songs. Despite his continued spoken word performances, he did not begin recording spoken word albums until after the disbanding of the Dead Kennedys.

His ninth spoken word album, "In the Grip of Official Treason", was released in October 2006.

Biafra was also featured in the British band Pitchshifter's song "As Seen on TV" reciting the words of dystopian futuristic radio advertisements.

Biafra was an anarchist in the 1980s, but has shifted away from his former anti-government views. In a 2012 interview, Biafra said "I'm very pro-tax as long as it goes for the right things. I don't mind paying more money as long as it's going to provide shelter for people sleeping in the street or getting the schools fixed back up, getting the infrastructure up to the standards of other countries, including a high speed rail system. I'm totally down with that."

In the autumn of 1979, Biafra ran for mayor of San Francisco, using the Jell-O ad campaign catchphrase, "There's always room for Jello", as his campaign slogan. Having entered the race before creating a campaign platform, Biafra later wrote his platform on a napkin while attending a Pere Ubu concert where Dead Kennedys drummer Ted told Biafra, "Biafra, you have such a big mouth that you should run for Mayor." As he campaigned, Biafra wore campaign T-shirts from his opponent Quentin Kopp's previous campaign and at one point vacuumed leaves off the front lawn of another opponent, current U.S. Senator Dianne Feinstein, to mock her publicity stunt of sweeping streets in downtown San Francisco for a few hours. He also made a whistlestop campaign tour along the BART line. Supporters committed equally odd actions; two well known signs held by supporters said "If he doesn't win I'll kill myself" and "What if he does win?"

In San Francisco any individual could legally run for mayor if a petition was signed by 1500 people or if $1500 was paid. Biafra paid $900 and got signatures over time and eventually became a legal candidate, meaning he received statements put in voters' pamphlets and equal news coverage.

His platform included unconventional points such as forcing businessmen to wear clown suits within city limits, erecting statues of Dan White, who assassinated Mayor George Moscone and City Supervisor Harvey Milk in 1978, around the city and allowing the parks department to sell eggs and tomatoes with which people could pelt the statues, hiring workers who'd lost their jobs due to a tax initiative to panhandle in wealthy neighborhoods (including Dianne Feinstein's), and a citywide ban on cars. Biafra has expressed irritation that these parts of his platform attained such notoriety, preferring instead to be remembered for serious proposals such as legalizing squatting in vacant, tax-delinquent buildings and requiring police officers to run for election by the people of the neighborhoods they patrol.

He finished third out of a field of ten, receiving 3.79% of the vote (6,591 votes); the election ended in a runoff that did not involve him (Feinstein was declared the winner).

In 2000, the New York State Green Party drafted Biafra as a candidate for the Green Party presidential nomination, and a few supporters were elected to the party's nominating convention in Denver, Colorado. Biafra chose death row inmate Mumia Abu-Jamal as his running mate. The party overwhelmingly chose Ralph Nader as the presidential candidate with 295 of the 319 delegate votes. Biafra received 10 votes.

Biafra, along with a camera crew (dubbed by Biafra as "The Camcorder Truth Jihad"), later reported for the Independent Media Center at the Republican and Democratic conventions.

After losing the 2000 nomination, Jello became highly active in Ralph Nader's presidential campaign, as well as in 2004 and 2008. During the 2008 campaign Jello played at rallies and answered questions for journalists in support of Ralph Nader. When gay rights activists accused Nader of costing Al Gore the 2000 election, Biafra reminded them that Tipper Gore's Parents Music Resource Center wanted warning stickers on albums with homosexual content.

After Barack Obama won the general election, Jello wrote an open letter making suggestions on how to run his term as president. Biafra criticized Obama during his term, stating that "Obama even won the award for best advertising campaign of 2008." Biafra dubbed Obama "Barackstar O'Bummer". Biafra refused to support Obama in 2012. Biafra has stated that he feels that Obama continued many of George W. Bush's policies, summarizing Obama's policies as containing "worse and worse laws against human rights and more and more illegal unconstitutional spying."

On September 18, 2015, it was announced that Jello would be supporting Bernie Sanders in his campaign for the 2016 presidential election. He has strongly criticised the political position of Donald Trump, saying "how can people be so fucking stupid" on hearing the election result, and later adding "The last person we want with their finger on the nuclear button is somebody connected to this extreme Christianist doomsday cult."

In the summer of 2011 Jello Biafra and his band were scheduled to play at the Barby Club in Tel Aviv. They came under heavy pressure by the pro-Palestinian Boycott, Divestment and Sanctions (BDS) campaign, and finally decided to cancel the gig – after a debate which according to Biafra "deeply tore at the fabric of our band ... This whole controversy has been one of the most intense situations of my life – and I thrive on intense situations".
Biafra then decided to travel to Israel and the Palestinian Occupied Territories, at his own expense, and talk with Israeli and Palestinian activists as well as with fans disappointed at his cancellation. In the article stating his conclusions he wrote:
"I will not perform in Israel unless it is a pro-human rights, anti-occupation event, that does not violate the spirit of the boycott. Each musician, artist, etc. must decide this for themselves. I am staying away for now, but am also really creeped out by the attitudes of some of the hardliners and hope some day to find a way to contribute something positive here. I will not march or sign on with anyone who runs around calling people Zionazis and is more interested in making threats than making friends."

Biafra married Theresa Soder, a.k.a. Ninotchka, lead singer of San Francisco-area punk band the Situations, on October 31, 1981. The wedding was conducted by Flipper vocalist/bassist Bruce Loose, who became a Universal Life Church minister just to conduct the ceremony, which took place in a graveyard. The wedding reception, which members of Flipper, Black Flag, and D.O.A. attended, was held at director Joe Rees' Target Video studios. The marriage ended in 1986.

Biafra lives in San Francisco, California.

"For a more complete list, see the Jello Biafra discography."








</doc>
<doc id="15621" url="https://en.wikipedia.org/wiki?curid=15621" title="John Grierson">
John Grierson

John Grierson CBE (26 April 1898 – 19 February 1972) was a pioneering Scottish documentary maker, often considered the father of British and Canadian documentary film. In 1926, Grierson coined the term "documentary" in a review of Robert Flaherty's "Moana".

Grierson was born in the old schoolhouse in Deanston, near Doune, Scotland, to his father a schoolmaster Robert Morrison Grierson from Boddam, near Peterhead and mother Jane Anthony a teacher from Ayrshire. His mother a suffragette and ardent Labour Party activist, she often took the chair at Tom Johnston's election meetings.

The family moved to Cambusbarron, Stirling in 1900, when the children were still young after Grierson's father was appointed headmaster of Cambusbarron school. When the family moved, John had three elder sisters Agnes, Janet and Margaret, and a younger brother called Anthony. John and Anthony were enrolled at Cambusbarron school in November 1903, his sister Margaret died in 1906; however, the family continued to grow as John gained three younger sisters in Dorothy, Ruby and Marion.

From an early age, both parents steeped their son in liberal politics, humanistic ideals, and Calvinist moral and religious philosophies, particularly the notion that education was essential to individual freedom and that hard and meaningful work was the way to prove oneself worthy in the sight of God. John was enrolled in the High School at Stirling in September 1908, where he played football and rugby for the school.

In July 1915, he left school with an overall subject mark of 82%; John had sat the bursary examination at Gilmorehill the month before as his parents wanted him to follow his elder sisters, Janet and Agnes in going to the University of Glasgow. The results for the bursary examination were not posted until October 1915; John applied to work at the munitions at Alexandria, the munitions building had been the original home of the Argyll Motor Company which had earlier in the twentieth century built the first complete motor car in Scotland.

John Grierson was the second name on the bursary list and received the John Clark bursary which was tenable for four years. Grierson entered the University of Glasgow in 1916; however, he was unhappy with his efforts to help in World War I were only through his work at the munitions. John wanted to join the navy, his family on his father's side had long been lighthouse keepers, and John had many memories of visiting lighthouses and being beside the sea. John went to the Crystal Palace, London to train with the Royal Naval Volunteer Reserve, in his recruitment letter he had added an extra year so that he could attend.

On 7 January 1916, John was sent to the wireless telegraphy station at Aultbea, Cromarty as an ordinary telegraphist but was promoted to telegraphist on 2 June 1916. On 23 January 1917, he became a telegraphist on the minesweeper H.M.S "Surf" and served there until 13 October 1917, the next day he joined H.M.S "Rightwhale" where he was promoted to leading telegraphist on 2 June 1918, and remained on the vessel until he was demobilised. John walked away from his time in the navy with a British War Medal and the Victory Medal.

John returned to University in 1919, he joined the Fabian Society in 1919 and dissolved it in 1921. The New University Labour Club was initiated by John as well as the Critic's Club; he also had poetry published in the Glasgow University magazine from November 1920 until February 1923. Grierson received the Buchan Prize in the Ordinary Class of English Language in the academic year of 1919-20, he also received the prize and first-class certificate in the academic year of 1920-21 in the Ordinary Class of Moral Philosophy and graduated with a Master of Arts in English and Moral Philosophy in 1923.

In 1923, he received a Rockefeller Research Fellowship to study in the United States at the University of Chicago, and later at Columbia and the University of Wisconsin–Madison. His research focus was the psychology of propaganda—the impact of the press, film, and other mass media on forming public opinion. Grierson was particularly interested in the popular appeal and influence of the "yellow" (tabloid) press, and the influence and role of these journals on the education of new American citizens from abroad.

In his review of Robert Flaherty's film "Moana" (1926) in the "New York Sun" (8 February 1926), Grierson wrote that it had 'documentary' value.
In his essay "First Principles of Documentary" (1932), Grierson argued that the principles of documentary were that cinema's potential for observing life could be exploited in a new art form; that the "original" actor and "original" scene are better guides than their fiction counterparts to interpreting the modern world; and that materials "thus taken from the raw" can be more real than the acted article. In this regard, Grierson's views align with the Soviet filmmaker Dziga Vertov's contempt for dramatic fiction as "bourgeois excess", though with considerably more subtlety. Grierson's definition of documentary as "creative treatment of actuality" has gained some acceptance, though it presents philosophical questions about documentaries containing stagings and reenactments.

Like many social critics of the time, Grierson was profoundly concerned about what he perceived to be clear threats to democracy. In the US, he encountered a marked tendency toward political reaction, anti-democratic sentiments, and political apathy. He read and agreed with the journalist and political philosopher Walter Lippmann's book "Public Opinion" which blamed the erosion of democracy in part on the fact that the political and social complexities of contemporary society made it difficult if not impossible for the public to comprehend and respond to issues vital to the maintenance of democratic society.

In Grierson's view, a way to counter these problems was to involve citizens in their government with the kind of engaging excitement generated by the popular press, which simplified and dramatized public affairs. It was during this time that Grierson developed a conviction that motion pictures could play a central role in promoting this process. (It has been suggested [by whom?] that some of Grierson's notions regarding the social and political uses of film were influenced by reading Lenin's writing about film as education and propaganda.)

Grierson's emerging view of film was as a form of social and political communication—a mechanism for social reform, education, and perhaps spiritual uplift. His view of Hollywood movie-making was considerably less sanguine:

Grierson's emerging and outspoken film philosophies caught the attention of New York film critics at the time. He was asked to write criticism for the "New York Sun". At the "Sun", Grierson wrote articles on film aesthetics and audience reception, and developed broad contacts in the film world. According to popular myth, in the course of this writing stint, Grierson coined the term "documentary" in writing about Robert J. Flaherty's film "Moana" (1926): "Of course "Moana", being a visual account of events in the daily life of a Polynesian youth and his family, has documentary value."

During this time, Grierson was also involved in scrutinizing the film industries of other countries. He may have been involved in arranging to bring Sergei Eisenstein's groundbreaking film "The Battleship Potemkin" (1925) to US audiences for the first time. Eisenstein's editing techniques and film theories, particularly the use of montage, would have a significant influence on Grierson's own work.

Grierson returned to Great Britain in 1927 armed with the sense that film could be enlisted to deal with the problems of the Great Depression, and to build national morale and national consensus. Filmmaking for Grierson was an exalted calling; the Filmmaker a patriot. In all of this, there was more than a little elitism, a stance reflected in Grierson's many dicta of the time: "The elect have their duty." "I look on cinema as a pulpit, and use it as a propagandist."

In the US Grierson had met pioneering documentary filmmaker Robert Flaherty. Grierson respected Flaherty immensely for his contributions to documentary form and his attempts to use the camera to bring alive the lives of everyday people and everyday events. Less commendable in Grierson's view was Flaherty's focus on exotic and faraway cultures. ("In the profounder kind of way", wrote Grierson of Flaherty, "we live and prosper each of us by denouncing the other"). In Grierson's view, the focus of film should be on the everyday drama of ordinary people. As Grierson wrote in his diaries: "Beware the ends of the earth and the exotic: the drama is on your doorstep wherever the slums are, wherever there is malnutrition, wherever there is exploitation and cruelty." "'You keep your savages in the far place Bob; we are going after the savages of Birmingham,' I think I said to him pretty early on. And we did.")

On his return to England, Grierson was employed on a temporary basis as an Assistant Films Officer of the Empire Marketing Board (EMB), a governmental agency which had been established in 1926 to promote British world trade and British unity throughout the empire. One of the major functions of the EMB was publicity, which the Board accomplished through exhibits, posters, and publications and films. It was within the context of this State-funded organization that the "documentary" as we know it today got its start.

In late 1929 Grierson and his cameraman, Basil Emmott completed his first film, "Drifters", which he wrote, produced and directed. The film, which follows the heroic work of North Sea herring fishermen, was a radical departure from anything being made by the British film industry or Hollywood. A large part of its innovation lies in the fierce boldness in bringing the camera to rugged locations such as a small boat in the middle of a gale while leaving relatively less of the action staged. The choice of topic was chosen less from Grierson's curiosity than the fact that he discovered that the Financial Secretary had made the herring industry his hobbyhorse. It premiered in a private film club in London in November 1929 on a double-bill with Eisenstein's -then controversial- film "The Battleship Potemkin" (which was banned from general release in Britain until 1954) and received high praise from both its sponsors and the press. The film was shown from 9 December 1929, in the Stoll in Kingsway and then was later screened throughout Britain.

After this success, Grierson moved away from film direction into a greater focus on production and administration within the EMB. He became a tireless organizer and recruiter for the EMB, enlisting a stable of energetic young filmmakers into the film unit between 1930 and 1933. Those enlisted included filmmakers Basil Wright, Edgar Anstey, Stuart Legg, Paul Rotha, Arthur Elton, Humphrey Jennings, Harry Watt, and Alberto Cavalcanti. This group formed the core of what was to become known as the British Documentary Film Movement. Robert Flaherty himself also worked briefly for the unit. In 1933 the EMB Film Unit was disbanded, a casualty of Depression-era economics.

Grierson's boss at the EMB moved to the General Post Office (GPO) as its first public relations officer, with the stipulation that he could bring the EMB film unit with him. Grierson's crew were charged with demonstrating how the Post Office facilitated modern communication and brought the nation together, a task aimed as much at GPO workers as the general public. During Grierson's administration, the GPO Film Unit produced a series of groundbreaking films, including "Night Mail" (dir. Basil Wright and Harry Watt, 1936) and "Coal Face" (dir. Alberto Cavalcanti, 1935). In 1934 he produced at the GPO Film Unit the award-winning "The Song of Ceylon" (dir. Basil Wright) which was sponsored jointly by the Ceylon Tea Propaganda Bureau and the EMB.

In 1934, Grierson sailed on the "Isabella Greig" out of Granton to film "Granton Trawler" on Viking Bank which is between Shetland and the Norwegian coast. The footage from his voyage was handed over to Edgar Anstey, who pulled footage of when the camera had fallen over on the deck of the boat to create a storm scene. "Granton Trawler" was a favourite film of Grierson's, he saw it as a homage to the "Isabella Greig" that was sunk in 1941 by German bombs when it went out to fish and was never seen again. "The Private Life of Gannets" was also filmed on the "Isabella Greig;" the film was shot on Grassholm with Grierson shooting the slow-motion sequence of the gannets diving for fish which took only one afternoon to shoot near Bass Rock in the Firth of Forth. The Private Life of Gannets went on to pick up an Academy Award in 1937.

Grierson eventually grew restless with having to work within the bureaucratic and budgetary confines of government sponsorship. Grierson resigned from the G.P.O. on 30 June 1937, which gave him more time to pursue his passions and the freedom to speak his mind on issues around the world. In response, he sought out private industry sponsorship for film production. He was finally successful in getting the British gas industry to underwrite an annual film program. Perhaps the most significant works produced during this time were "Housing Problems" (dir. Arthur Elton, Edgar Anstey, John Taylor, and Grierson's sister Ruby Grierson, 1935).

In 1938, Grierson was invited by the Canadian government to study the country's film production. Grierson sailed at the end of May in 1938 for Canada and arrived on 17 June. Grierson met with the Prime Minister, William Lyon Mackenzie King and also spoke with many important figures across Canada, they were all in agreement of the importance of film in reducing sectionalism and in promoting the relationship of Canada between home and abroad. The head of the Motion Picture Bureau for Canada, Frank Bagdley, did not appreciate Grierson's assessment and criticism of the films made by the Bureau which was that they focused too much on Canada as a place to holiday. Grierson delivered his report on government film propaganda and the weaknesses he had found in Canadian film production; his suggestion was to create a national coordinating body for the production of films. An abridged version of the report ran to 66 pages, which was prepared by August in London. Grierson returned to Britain but was invited back to Canada on 14 October 1938; he returned in the November.

In 1939, Canada created the National Film Commission, which would later become the National Film Board of Canada. The bill to create a National Film Board was drafted by Grierson; the bill was introduced in March 1939 and given Royal Assent on 2 May 1939. Grierson was appointed the first Commissioner of the National Film Board in October 1939. When Canada entered World War II in 1939, the NFB focused on the production of propaganda films, many of which Grierson directed. For example, captured footage of German war activity was incorporated in documentaries that were distributed to the then-neutral United States.

Grierson grieved the death of his sister Ruby in 1940; she was on "City of Benares" while it was evacuating children to Canada. "The City of Benares" was torpedoed, and of the 406 on board, only 248 survived. Grierson resigned from his position in January 1941, over his year as Commissioner at the National Film Board 40 films were made, the year before the Motion Picture Bureau had made only one and a half. Recommendations for the future running were made for the National Film Board, and Grierson was persuaded to stay for a further six months to oversee the changes.

During WW II, Grierson was a consultant to prime minister William Lyon Mackenzie King as a minister of the Wartime Information Board. He remained on the National Film Board and managed to complete his duties to Wartime Information Board as well through his deputies that aided him in the task. Grierson was asked to keep his dual role until January 1944, however, he resigned in 1943 as the job he had been asked to complete had been finished as far as he was concerned. Before he finished with the Wartime Information Bureau Grierson was also offered the role of chairman of the Canadian Broadcasting Corporation but turned it down as he believed that this would give him too much power.

On 26 February 1942, Grierson attended the Academy Awards and received the award on behalf of the National Film Board for "Churchill's Island". Grierson also presented the award for the best documentary, the first time that this award was given by the Academy. After the Dieppe Raid, there were reports that Canadians that had been taken as prisoners of war had been manacled under Hitler's orders. Grierson proposed that the Film Board show how the German prisoners of war were being treated in Canada through a film. Ham Wright directed the film showing the German sailors that had been captured; playing football, enjoying meals and looking healthy. Only one copy of the film was made, it was sent to the Swiss Red Cross who deliberately let it fall into German hands. Grierson was to learn at a later date that Hitler had indeed watched the film and ordered that the Canadian prisoners of war released from their manacles.

After the war, the National Film Board focused on producing documentaries that reflected the lives of Canadians. The National Film Board has become recognized around the world for producing quality films, some of which have won Academy Awards. The National Film Board had become one of the largest film studios and was respected around the world for what it had achieved; it had especially had influence in Czechoslovakia and China.

In December 1943 Grierson was elected by the Permanent Film Committee of the National Council for Canadian-Soviet Friendship to become honorary chairman. One of the tasks at the National Film Board that Grierson strongly pushed for the films being produced to be in French as well as English. He also pushed for a French unit in the National Film Board.

Grierson concentrated on documentary film production in New York after resigning his post following in August 1945; his resignation was to take effect in November 1945. In 1946 Grierson was asked to testify regarding communist spies in the National Film Board and the Wartime Information Board, rumours spread that he had been a leader of a spy ring during his offices with the Canadian government, a rumour he denied. Due to the rumours, the projects that Grierson had been trying to put together were not commissioned.

Grierson was appointed as a foreign adviser to the Commission on Freedom of the Press in December 1943, which had been set up by the University of Chicago. Grierson was able to make a large contribution to the committee which included Robert M. Hutchins, William E. Hocking, Harold D. Lasswell, Archibald McLeish and Charles Merriam. "A Free and Responsible Press" was published in 1947.

Grierson was offered the position of head of information at UNESCO at the end of 1946; he attended the first General Conference of UNESCO from 26 November until 10 December in Paris. He had the idea for the "Unesco Courier" which was published in published in several languages across the world, first as a tabloid and later as a magazine. Grierson was invited to open the Edinburgh International Film Festival in 1947, from 31 August to 7 September. At the start of 1948 he resigned from his position as director for Mass Communications and Public Information, he left in April to return to Britain.

In February 1948, Grierson was appointed the controller of the Central Office of Information's film operations to co-ordinate the work of the Crown Film Unit and Films Division, and to take overall charge of the planning, production and distribution of government films. On 23 June 1948, he accepted an honorary degree, an LL.D from the University of Glasgow. He left in 1950 due to financial restrictions on the documentaries that he wished to make.

Grierson was appointed to the position of executive producer of Group 3 at the end of 1950; it was a film production enterprise that received loans of government money through the National Film Finance Corporation. They filmed at Southall Studios in West London but later moved to Beaconsfield Studios. Group 3 was to have continuous production from 1951 until 1955 when it stopped producing films, the organisation had made a loss of over £400,000 as production of the films usually ran over the time allocated, and there had also been difficulty getting the films shown in cinemas.

During this time Grierson had been diagnosed with tuberculosis in May 1953, he spent a fortnight in hospital and then had a year of convalescing at his home, Tog Hill in Calstone. Grierson spent much of his time corresponding with the directors at Group 3, as well as commenting on scripts and story ideas. He had recovered enough to attend the Cannes Film Festival in April 1954, taking the production of "Man of Africa". At the Edinburgh Film Festival in the same year, a dinner was held in Grierson's honour to celebrate twenty-five years of documentary.

Grierson joined the newly revived Films of Scotland Committee in 1955, also on the committee was Norman Wilson, Forsyth Hardy, George Singleton, C. A. Oakley and Neil Paterson. In 1956, Grierson was the president of the Venice Film Festival's jury; he was also jury president at the Cork Film Festival and the South American Film Festival in 1958. In 1957, Grierson received a special Canadian Film Award. Grierson wrote the script for, "Seawards the Great Ship," it was directed by Hilary Harris and awarded an Academy Award in 1961, a feat for the Films of Scotland Committee.

The first programme of This Wonderful World was aired on 11 October 1957 in Scotland; it was on "The Culbin Sands" which focused on how the Forestry Commission had replanted six thousand acres of woodland along the mouth of Findhorn. In the seventeenth century wild sand had blown into the mouth and covered the land, the successful replanting of the forest was a great success for the Commission. This Wonderful World was shown weekly, other topics for episodes included Leonardo da Vinci, ballet, King Penguins and Norman McLaren's "Boogie Doodle".

This Wonderful World began to be aired in England In February 1959, it ran for a further eight years and was in the Top Ten programmes for the week for the UK in 1960. In 1961, Grierson was appointed a Commander of the Order of the British Empire in the Queen's Birthday Honours. In 1962, he was a member of the jury for the Vancouver Film Festival, during his visit to Canada he also received the Royal Canadian Academy of Arts Medal for his contribution to the visual arts. In 1963, he was busy with This Wonderful World and the Films of Scotland Committee but still found time to attend the twenty-fifth anniversary of the National Film Board in Montreal.

In 1965, Grierson was the patron of the Commonwealth Film Festival which took place in Cardiff in that year. In 1966, he was offered the role of Governor of the British Film Institute; however, he turned down the position. This Wonderful World changed the title to John Grierson Presents.

In 1967, after returning from the Oberhausen Film Festival where he had been the President of Honour of the jury, Grierson suffered a bout of bronchitis which lasted eight days. His brother Anthony, who had trained to be a doctor was called and diagnosed Grierson with emphysema, his coughing fits were a cause for concern, and he was admitted to Manor Hospital. Grierson decided to give up smoking and drinking to benefit his health.

Grierson opened the new primary school at Cambusbarron on 10 October 1967, his sister Dorothy attended the day with him. The BBC expressed their wishes to make a programme about Grierson in the year of his seventieth birthday which he turned down three times In the year of his seventieth birthday, Grierson received many tributes from across the globe, he was made an honorary member of the Association of Cinematograph, Television and Allied Technicians which he pressed for the ceremony to be held in Glasgow. He also received the Golden Thistle Award for Outstanding Achievement in the Art of Cinema at the Edinburgh Film Festival.

In January 1969, Grierson left for Canada to lecture at McGill University, enrollment for his classes grew to around seven hundred students, he also lectured at Carleton University once a fortnight. At Heriot-Watt University in Edinburgh on 8 July 1969, Grierson also received an Honorary Doctorate of Literature. A few days earlier on 4 July 1969, Grierson had opened the Scottish Fisheries Museum in Anstruther.

Grierson was a member of the jury for the Canadian Film Awards in 1970. He spent a few months in 1971, travelling around India instilling the importance of having small production units throughout the country. He returned to the UK in December 1971 and was meant to travel back to India however it was delayed due to Indo-Pakistani War. Grierson went into hospital for a health check-up in January 1972, he was diagnosed with lung and liver cancer and was given months to live. During his time in hospital he spent time dictating letters to his wife Margaret and received visitors; however, he fell unconscious on 18 February and died on the 19th. He had been detailed in his wishes for his funeral and wished to be cremated, his urn was to be placed in the sea off the Old Head in Kinsale and his brother Anthony's ashes, who had died in August 1971, were to be placed at the same time. A small flotilla followed the "Able Seaman," and when the urns were lowered into the water, the fishing boats sounded their sirens.

The Grierson Archive at the University of Stirling Archives was opened by Angus Macdonald in October 1977.

Filmography as director:

Filmography as producer/creative contributor:




The Grierson Documentary Film Awards were established in 1972 to commemorate John Grierson and
are currently supervised by The Grierson Trust. The aim of the awards is to recognise "outstanding films that demonstrate integrity, originality and technical excellence, together with social or cultural significance".

Grierson Awards are presented annually in nine categories:

The Canadian Film Awards had presented a Grierson Award for "an outstanding contribution to Canadian cinema in the spirit of John Grierson."




 


</doc>
<doc id="15622" url="https://en.wikipedia.org/wiki?curid=15622" title="James Cameron">
James Cameron

James Francis Cameron (born August 16, 1954) is a Canadian filmmaker, artist, and environmentalist, who is best known for making science fiction and epic films for the Hollywood mainstream. 
Cameron first gained recognition for directing "The Terminator" (1984). He found further critical and commercial success with "Aliens" (1986), "The Abyss" (1989), "" (1991) and "True Lies" (1994). His greatest big-budget productions have been "Titanic" (1997) and "Avatar" (2009), the former earning him Academy Awards in Best Picture, Best Director and Best Film Editing. "Avatar," filmed in 3D technology, also garnered him nominations in the same categories.

He also co-founded Lightstorm Entertainment, Digital Domain and Earthship Productions. In addition to his filmmaking, he is a National Geographic explorer of the sea and has produced a number of documentaries on the subject. Cameron contributed to underwater filming and remote vehicle technologies and helped create the digital 3D Fusion Camera System. In 2012, Cameron became the first person to perform a solo descent to the bottom of the Mariana Trench, the deepest part of the Earth's ocean, in the "Deepsea Challenger" submersible.

In total, Cameron's films have grossed approximately US$2 billion in North America and US$6 billion worldwide. Cameron's "Avatar" and "Titanic" are the second and third highest-grossing films of all time, earning $2.78 billion and $2.19 billion, respectively. Cameron holds the achievement of having directed the first two of the five films in history to gross over $2 billion worldwide. In 2010, "Time" magazine named Cameron one of the 100 most influential people in the world.

Cameron was born in Kapuskasing, Ontario, Canada, to Philip Cameron, an electrical engineer, and Shirley (née Lowe), an artist and nurse. His paternal great-great-great-grandfather emigrated from Balquhidder, Scotland, in 1825. Cameron is the eldest of five siblings and as a child he described the Lord's Prayer as a "tribal chant". He attended Stamford Collegiate School in Niagara Falls. At age 17, Cameron and his family moved from Chippawa, Ontario to Brea, California. He attended Sonora High School and then moved to Brea Olinda High School. Classmates recalled that he was not a sportsman but instead enjoyed building things that "either went up into the air or into the deep".

After high school, Cameron enrolled at Fullerton College, a community college in 1973 to study physics. He switched subjects to English, but left the college at the end of 1974. He worked odd jobs, including as a truck driver and janitor, but writing in his free time. During this period, he learnt about special effects by reading other students' work on "optical printing, or front screen projection, or dye transfers, anything that related to film technology" at the library. After excitement of seeing "Star Wars" in 1977, Cameron quit his job as a truck driver to enter the film industry.

Cameron's directing career began in 1978. After borrowing money from a consortium of dentists, he learnt to direct, write and produce his first short film, "Xenogenesis" (1978) with a friend. Learning as they went, he has said that he felt like a doctor doing his first surgical procedure. He then served as a production assistant for "Rock and Roll High School" (1979). While educating himself about film-making techniques, Cameron started a job as a miniature model maker at Roger Corman Studios. He was soon employed as an art director in the science-fiction film "Battle Beyond the Stars" (1980). He carried out the special effects for John Carpenter's "Escape from New York" (1981), served as production designer for "Galaxy of Terror" (1981), and consulted on the design for "Android" (1982).

Cameron was hired as the special effects director for the sequel to "Piranha" (1978), titled "" in 1982. The original director, Miller Drake, left the project due to creative differences with producer Ovidio Assonitis. Shot in Rome, Italy and on Grand Cayman Island, the film gave Cameron the opportunity to become director for a major film for the first time. However, Cameron later said that it did not feel like his first movie due to power-struggles with Assonitis. Disillusioned from being in Rome and suffering from a fever, Cameron had a nightmare about an invincible robot hit-man sent from the future to assassinate him, which later led to the inspiration of "The Terminator" (1984). Upon release of "Piranha II: The Spawning", critics were not impressed. Tim Healey, in his book, called it "a marvellously bad movie which splices cliches from every conceivable source."

Inspired by John Carpenter's "Halloween" (1978) and other science fiction work, Cameron wrote the script for "The Terminator" (1984) in 1982, which is a thriller about cyborg sent from the future to carry out a lethal mission. Cameron wanted to sell the script so that he could direct the movie. Whilst some film studios expressed interested in the project, many executives were unwilling to let a new and unfamiliar director make the movie. Gale Anne Hurd, a colleague and founder of Pacific Western Productions, to whom Cameron was married from 1984 to 1989, agreed to buy Cameron's screenplay for one dollar, on the condition that Cameron direct the film. Eventually, he convinced the president of Hemdale Pictures to make the film, with Cameron as director and Hurd as a producer. Lance Henriksen, who had starred in "", was considered for the lead role, but Cameron decided that Arnold Schwarzenegger was more suitable as the cyborg villain due to his bodybuilder appearance. Henriksen was given a smaller role instead. Michael Biehn and Cameron's future wife, Linda Hamilton, also joined the cast. "The Terminator" was a box office success, exceeding expectations set by Orion Pictures, who thought that the film would be short-lived in theaters. The movie proved popular with audiences and earned over $78 million worldwide, from a budget of $6.5 million. In 2008, the film was selected for preservation in the United States National Film Registry, being deemed "culturally, historically, or aesthetically significant".

In 1984, Cameron co-wrote the screenplay to "" with Sylvester Stallone. Soon, Cameron moved onto his next directorial feature, which was the sequel to "Alien" (1979), a science fiction horror by Ridley Scott. After titling the sequel "Aliens" (1986), Cameron recast Sigourney Weaver as Ellen Ripley, who first appeared in "Alien". "Aliens" follows the protagonist, Ripley, as she helps a group of marines fight off extraterrestrials. Despite conflicts with cast and crew during production, and having to replace one of the lead actors—James Remar with Michael Biehn—"Aliens" was a box office success, generating over $130 million worldwide. The film was nominated for seven Academy Awards in 1987; Best Actress, Best Art Direction, Best Film Editing, Best Original Score and Best Sound. It won awards for Best Sound Editing and Best Visual Effects. In addition, the film including Weaver made the cover of "TIME" magazine in July 1986.

After "Aliens", Cameron and Gale Anne Hurd decided to make "The Abyss", a story of oil-rig workers who discover strange intelligent life in the ocean. Based on an idea which Cameron had conceived of during high school, the film was initially budgeted at $41 million, although it ran considerably over this amount. It starred Ed Harris, Mary Elizabeth Mastrantonio and Michael Biehn. The production process began in the Cayman Islands and then at South Carolina, inside the building of an unfinished nuclear power plant with two huge tanks. The cast and crew recall Cameron's tough demands and filming the underwater scenes which were physically exhausting for everyone. Upon the film's release, "The Abyss" was praised for its special effects, and earned $90 million at the worldwide box office. "The Abyss" received four Academy Award nominations and won Best Visual Effects.

In 1990, Cameron co-founded the firm Lightstorm Entertainment with partner Lawrence Kasanoff. In 1991, Cameron served as executive producer for "Point Break" (1991), directed by former wife Kathryn Bigelow. After the success of "The Terminator", there were discussions for a sequel. In the late 1980s, Mario Kassar of Carolco Pictures secured the rights to the sequel, allowing Cameron to begin production of the film, titled "" (1991). Written by Cameron and William Wisher Jr., lead actors Schwarzenegger and Linda Hamilton reprised their earlier roles. The story follows on from the first "Terminator" film, depicting a new villain (T-1000), possessing shape-shifting ability and hunts for Sarah Connor's son. Cameron cast Robert Patrick as T-1000 because of his lean and thin appearance—a sharp contrast to Schwarzenegger. Cameron explained, "I wanted someone who was extremely fast and agile. If the T-800 is a human Panzer tank, then the T-1000 is a Porsche." Like its predecessor, "Terminator 2" was one of the most expensive films to be produced, costing at least $94 million. Despite the challenging use of computer-generated imagery, the film was completed on time and released on July 3, 1991. "Terminator 2: Judgment Day" broke box office records (including the opening weekend record for an R-rated film), earning over $200 million in the North America and being the first to earn over $300 million worldwide. It won four Academy Awards: Best Makeup, Best Sound Mixing, Best Sound Effects Editing, and Best Visual Effects. It also received nominations for Best Cinematography and Best Film Editing, but lost both to political thriller "JFK".

In subsequent years, Cameron planned to do a third "Terminator" film but plans never materialized. The rights to the "Terminator" franchise were eventually purchased by Kassar from a bankruptcy sale of Carolco's assets. He moved onto other projects and in 1993, Cameron co-founded Digital Domain, a visual effects production company. In 1994, Cameron and Schwarzenegger reunited for their third collaboration, titled "True Lies" (1994)"," a remake of the 1991 French comedy "La Totale!" The story depicts an American secret agent who leads a double life as a married man, whose wife believes he is a computer salesman. The film co-stars Jamie Lee Curtis, Eliza Dushku and Tom Arnold. Cameron's Lightstorm Entertainment signed a deal with 20th Century Fox for the production of "True Lies". Budgeted at a minimum of $100 million, the film earned $146 million in North America, and $232 million worldwide. The film was nominated for an Academy Award for Best Visual Effects. Curtis won a Golden Globe Award for Best Actress in a Comedy or Musical. In 1995, Cameron co-produced "Strange Days" (1995), a science fiction thriller. The film was directed by Kathryn Bigelow and co-written by Jay Cocks. "Strange Days" was critically and financially unsuccessful. In 1996, Cameron reunited with the cast of "Terminator 2" to film "", an attraction at Universal Studios Florida and at other parks around the world.

His next major project was "Titanic" (1997), an epic film about which sank in 1912 after striking an iceberg. With a production budget of $200 million, "Titanic" is one of the most expensive films ever made. The production was troubled for being over-budget and exceeding its filming schedule, which made headlines before the film's release. Starting in 1995, Cameron took several dives to the bottom of the Atlantic Ocean to capture footage of the wreck, which would later be used in the film. A replica of the ship was built in Rosarito Beach and principal photography began in September 1996. His completed screenplay depicts two star-crossed lovers, portrayed by Leonardo DiCaprio and Kate Winslet, from different social classes who fall in love amid the backdrop of the tragedy—a sharp turn from Cameron's previous films. The supporting cast included Billy Zane, Kathy Bates, Frances Fisher, Gloria Stuart, Bernard Hill, Jonathan Hyde, Victor Garber, Danny Nucci, David Warner and Bill Paxton.After months of delay, "Titanic" premiered on December 19, 1997. "Titanic" received strong critical acclaim and became the highest-grossing film of all time worldwide in 1998, and held this position for twelve years until Cameron's "Avatar" (2009) beat the record in 2010. The costumes and sets were very realistic, and "The Washington Post" considered the CGI graphics to be spectacular. "Titanic" received a record-tie of fourteen nominations (tied with "All About Eve" (1950)) at the 1998 Academy Awards. It won eleven of the awards (tying the record for most wins with "Ben-Hur" (1959) and later, "" (2003), including: Best Picture, Best Director, Best Art Direction, Best Cinematography, Best Visual Effects, Best Film Editing, Best Costume Design, Best Sound Mixing, Best Sound Editing, Best Original Dramatic Score, Best Original Song. Upon receiving the Best Picture Award, Cameron along with Jon Landau, asked for a moment of silence to remember the 1,500 people who died when the ship sank. Film critic Roger Ebert praised the film for being able to combine drama and history, stating "It is flawlessly crafted, intelligently constructed, strongly acted, and spellbinding". Reflecting on "Titanic" in 1999, Sandler and Studlar writes that the mix of romance, historical nostalgia and James Horner's music, contributed to the film's cultural phenomenon. "Titanic" is Cameron's second film to be selected for preservation in the United States National Film Registry.

Following the huge publicity of "Titanic", Cameron maintained a lower profile. In 1998, he and his brother, John, formed Earthship Productions, a company for streaming documentaries on the deep sea, one of Cameron's passions. He had planned to do a film about Spider-Man, a project developed by Menahem Golan of Cannon Films. Columbia hired David Koepp to adapt Cameron's ideas into a screenplay, but due to various disagreements, Cameron abandoned the project. In 2002, "Spider-Man" was released with the screenplay credited solely to Koepp. In 2000, Cameron ventured into television and co-created "Dark Angel" with Charles H. Eglee, a television series influenced by cyberpunk, biopunk, contemporary superheroes and third-wave feminism. "Dark Angel" starred Jessica Alba as Max Guevara, a genetically enhanced super-soldier created by a secretive organization. While the first season was moderately successful, the second season did less well, which led to its cancellation.

In 2002, Cameron served as producer on the 2002 film "Solaris", a science fiction drama directed by Steven Soderbergh. The film received mixed reviews and did poorly at the box office. Keen to make documentaries, Cameron directed "," a documentary about the German Battleship "Bismarck." In 2003, he directed "Ghosts of the Abyss," a documentary about RMS "Titanic" which was released by Walt Disney Pictures and Walden Media and designed for 3D theaters. Cameron also told "The Guardian" his intention for filming everything in 3D. In 2005, Cameron co-directed "Aliens of the Deep," a documentary about the various forms of life in the ocean. He also starred in "Titanic Adventure" with Tony Robinson"," another documentary about the "Titanic" shipwreck. Then in 2006, Cameron co-created and narrated "The Exodus Decoded," a documentary exploring the Biblical account of the Exodus. In 2007, Cameron and fellow director Simcha Jacobovici, produced "The Lost Tomb of Jesus." Broadcast on Discovery Channel on March 4, 2007, the documentary was controversial for arguing that the Talpiot Tomb was the burial place of Jesus of Nazareth.

By the mid-2000s, Cameron returned to directing and producing another big-budget, mainstream film since 1997's "Titanic". Cameron had mentioned two projects as early as June 2005. Titled "Avatar" (2009) and "" (2019) (the latter which he produced), both films were to be shot in 3D technology. He also wanted to make "Alita:" "Battle Angel" first, followed by "Avatar" but switched the order in February 2006. Although Cameron had written an 80-page treatment for "Avatar" in 1995, Cameron stated that he wanted the necessary technology to improve before starting production. "Avatar," with the story line set in the mid-22nd century, had an estimated budget in excess of $300 million. The cast includes Sam Worthington, Zoe Saldana, Stephen Lang, Michelle Rodriguez and Sigourney Weaver. It was composed entirely with computer-generated animation, using an advanced version of the performance capture technique, previously used by director Robert Zemeckis in "The Polar Express". Cameron intended "Avatar" to be 3D-only but decided to adapt it for conventional viewing as well.

Intended for release in May 2009, "Avatar" eventually premiered on December 18, 2009. This delay allowed more time for post-production and the opportunity for theatres to install 3D projectors. On release, "Avatar" broke several box office records during its initial theatrical run. It grossed $749.7 million in the United States and Canada and more than $2.74 billion worldwide, becoming the highest-grossing film of all time in the United States and Canada, surpassing "Titanic" (1997). It was the first film to ever earn more than $2 billion worldwide. "Avatar" was nominated for nine Academy Awards, including Best Picture and Best Director, and won three for Best Art Direction, Best Cinematography and Best Visual Effects. In July 2010, an extended theatrical re-release generated a worldwide total of $33.2 million at the box office. "Vanity Fair" reported that Cameron earned $257 million in 2010, making him the highest earner in Hollywood for that year.

In 2011, Cameron served as an executive producer for "Sanctum" (2011), a disaster-survival film about a cave diving expedition which turns deadly. Although receiving mixed reviews, the film earned a fair $108 million at the box office. Cameron re-investigated the sinking of RMS "Titanic" with eight experts in a 2012 TV documentary special, "Titanic: The Final Word with James Cameron", which premiered on April 8 on the National Geographic Channel. In the documentary, the experts revised the CGI animation of the sinking conceived in 1995. In March 2010, Cameron revealed that "Titanic" (1997) will be converted and re-released in 3D to commemorate the centennial anniversary of the tragedy. On March 27, 2012, Cameron attended the premiere at Royal Albert Hall, London with his wife and several cast members. He also served as executive producer of "" and "Deepsea Challenge 3D" in 2012 and 2014, respectively.

Cameron starred in the documentary "Atlantis Rising," with previous collaborator Simcha Jacobovci. The pair go on an adventure to explore the existence of the city of Atlantis. The programme aired on January 29, 2017 on the National Geographic channel. Next, Cameron produced and appeared in a documentary about the history of science fiction, stating, "Without Jules Verne and H. G. Wells, there wouldn't have been Ray Bradbury or Robert A. Heinlein, and without them, there wouldn't be [George] Lucas, [Steven] Spielberg, Ridley Scott or me." Titled "James Cameron’s Story of Science Fiction," the six-episodic series was broadcast on AMC in 2018. The series featured interviews with guests including Steven Spielberg, George Lucas, Christopher Nolan and Ridley Scott.

"" (2019) was finally released after being in parallel development with "Avatar". Written by Cameron and close friend, Jon Landau, the film was directed by Robert Rodriguez. The film, based on a 1990s Japanese manga series "Battle Angel Alita," depicts a cyborg who cannot remember anything of her past life and tries to uncover the truth. Produced with similar techniques and technology as used in "Avatar," the film starred Rosa Salazar, Christoph Waltz, Jennifer Connelly, Mahershala Ali, Ed Skrein, Jackie Earle Haley and Keean Johnson. The film premiered on January 31, 2019 in London and received generally positive reviews from critics, and was financially successful, earning $404 million worldwide. In her review, Monica Castillo of "RogerEbert.com" called it, "an awe-inspiring jump for [Rodriguez]" and "a visual bonanza" despite the bulky script. Cameron returned to the "Terminator" franchise as producer and writer for "" (2019), with Tim Miller as director. The film opened on November 1, 2019.

In August 2013, Cameron announced plans to direct three sequels to "Avatar" simultaneously, for release in December 2016, 2017, and 2018. However, the release dates have been postponed to December 17, 2021, with the following three sequels to be released, respectively, on December 22, 2023, December 19, 2025 and December 17, 2027. "Deadline Hollywood" estimated that the budget for these would be over $1 billion in total. "Avatar 2" and "Avatar 3" began simultaneous production in Manhattan Beach, California on August 15, 2017. Principal photography began in New Zealand on September 25, 2017. The other sequels are expected to begin production as soon as "Avatar 2" and "3" have finished. Although the sequels "4" and "5" have been given the green-light, Cameron stated in a 2017 interview, "Let's face it, if "Avatar 2" and "3" don't make enough money, there's not going to be a "4" and "5"".

Lightstorm Entertainment bought the film rights to the Taylor Stevens novel, "The Informationist," a thriller set in Africa. Cameron plans to direct it. He is also working on a film adaptation of the Charles R. Pellegrino book "The Last Train from Hiroshima," which is about the survivors of the atomic bombings of Hiroshima and Nagasaki. Cameron met with survivor, Tsutomu Yamaguchi, before his death in 2010.

As of 2012, Cameron and his family have adopted a vegan diet. Cameron states that "by changing what you eat, you will change the entire contract between the human species and the natural world". He and his wife Suzy are advocates of plant-based food and have called for constructive actions to produce more plant-based food and less meat to mitigate the impact of climate change. In 2006, Cameron's wife co-founded MUSE School, which became the first K-12 vegan school in the United States. In early 2014, Cameron purchased the Beaufort Vineyard and Estate Winery in Courtenay, British Columbia for $2.7 million, to pursue his passion for sustainable agribusiness. In 2018, Cameron served as executive producer of "The Game Changers", a documentary showcasing vegan athletes and other celebrities. In June 2019, Cameron announced a business venture with film director Peter Jackson, to produce plant-based meat, cheese, and dairy products in New Zealand. He suggested that we need "a nice transition to a meatless or relatively meatless world in 20 or 30 years."

In June 2010, Cameron met with officials of the Environmental Protection Agency to discuss possible solutions to the Deepwater Horizon oil spill. It was reported that he offered his assistance to help stop the oil well from leaking but was ignored. Cameron is a member of the NASA Advisory Council and he worked with the space agency to build cameras for the Curiosity rover sent for Mars. However, NASA, launched the rover without Cameron's technology due to a lack of time during testing. He has expressed interest in a project about Mars, stating "I've been very interested in the Humans to Mars movement [...] and I've done a tremendous amount of personal research for a novel, a miniseries, and a 3D film." Cameron is a member of the Mars Society, a non-profit organization lobbying for the colonization of Mars. In 2016, Cameron endorsed Democratic candidate Hillary Clinton for the 2016 U.S. presidential election.

Cameron has married five times. He was married to Sharon Williams from 1978 to 1984. A year after he and Sharon divorced, Cameron married film producer Gale Anne Hurd, a close collaborator for his 1980s films. They divorced in 1989. Soon after separating from Hurd, Cameron met the director Kathryn Bigelow whom he wed in 1989, but they divorced in 1991. Cameron then began a relationship with Linda Hamilton, actress in "The Terminator" series. Their daughter was born in 1993. Cameron married Hamilton in 1997. Amid speculation of an affair between Cameron and actress Suzy Amis, Cameron and Hamilton separated after two years of marriage, with Hamilton receiving a settlement of $50 million. He married Amis, his fifth wife, in 2000. They have one son and two daughters together.

Cameron has resided in the United States since 1971, but he remains a Canadian citizen. Cameron applied for American citizenship in 2004, but withdrew his application after George W. Bush won the presidential election. Captivated by New Zealand while filming "Avatar", Cameron bought a home there. He divides his time between California and New Zealand. Cameron has said he is a "Converted Agnostic", adding "I've sworn off agnosticism, which I now call cowardly atheism". Cameron met close friend Guillermo del Toro on the production of his 1993 film, "Cronos". In 1998, del Toro's father was kidnapped in Guadalajara. Cameron gave del Toro more than $1 million in cash to pay a ransom and have his father released.

Cameron became an expert on deep-sea exploration, in part because of his work on "The Abyss" and "Titanic", as well as his childhood fascination with shipwrecks. In 2011, Cameron became a National Geographic explorer-in-residence. In his role, on March 7, 2012, he dived five-mile deep to the bottom of the New Britain Trench with the "Deepsea Challenger". 19 days later, Cameron reached the Challenger Deep, the deepest part of the Mariana Trench. He spent more than three hours exploring the ocean floor, becoming the first to accomplish the trip alone. During his dive to the Challenger Deep, he discovered new species of sea cucumber, squid worm and a giant single-celled amoeba. He was preceded by unmanned dives in 1995 and 2009, as well as by Jacques Piccard and Don Walsh, the first men to reach the bottom of the Mariana Trench aboard the Bathyscaphe Trieste in 1960.

In June 2013, British artist Roger Dean filed a copyright complaint against Cameron, seeking damages of $50 million. Accused of "wilful and deliberate copying, dissemination and exploitation" of his original images (relating to "Avatar"), the case was dismissed by U.S district judge Jesse Ferman in 2014. In 2016, Premier Exhibitions, owner of many RMS "Titanic" artifacts, filed for bankruptcy. Cameron supported the U.K.'s National Maritime Museum and National Museums Northern Ireland decision to bid for the artifacts, but they were acquired by an investment group before a formal bid took place.

Cameron has been regarded as an innovative filmmaker in the industry, as well as not easy to work for. According to Ed Harris, who worked with Cameron on "The Abyss" (1989), Cameron behaved in an autocratic manner. Keegan, author of "The Futurist: The Life and Films of James Cameron," describes Cameron as "comically hands-on" and would try to do every job on the set. Andrew Gumbel, of "The Independent" says Cameron "is a nightmare to work with. Studios [...] fear his habit of straying way over schedule and over budget. He is notorious on set for his uncompromising and dictatorial manner, as well as his flaming temper." Keller writes that Cameron is an egomaniac, obsessed with vision but praises his "technological ingenuity" at creating a "visceral viewing experience".

Speaking of her experience of filming "Titanic", Kate Winslet said that she admired Cameron but "there were times I was genuinely frightened of him". Describing him as having "a temper like you wouldn't believe", she had said she wouldn't work with him again unless it was "for a lot of money". Her co-star, Leonardo DiCaprio, told "Esquire" magazine, "when somebody felt a different way on the set, there was a confrontation. He lets you know exactly how he feels", but complimented Cameron, "he's of the lineage of John Ford. He knows what he wants his film to be." Sam Worthington, who starred in "Avatar", said that if a mobile phone rang during filming, Cameron would "nail it to the wall with a nail gun." Film score composer James Horner was also not immune to Cameron's demands; he recalls having to write music in a short time frame for Cameron's 1986 film "Aliens." After the uneasy experience, Horner did not work with Cameron for a decade. In 1996, they reconciled their friendship and Horner produced the soundtracks for "Titanic" and "Avatar".

Despite this reputation, Bill Paxton and Sigourney Weaver have praised Cameron's perfectionism and attention to detail. Weaver said, "He really does want us to risk our lives and limbs for the shot, but he doesn't mind risking his own". In 2015, Weaver, along with Jamie Lee Curtis, applauded Cameron again. Curtis remarked, "he can do every other job [than acting]. I'm talking about every single department, from art direction to props to wardrobe to cameras, he knows more than everyone doing the job [..] He is so generous to actors." Weaver referred to Cameron as a "genius". Michael Biehn, a frequent collaborator, also praised Cameron, saying "Jim is a really passionate person. He cares more about his movies than other directors care about their movies", adding, "I've never seen him yell at anybody." Biehn, however, acknowledged that Cameron is "not real ["sic"] sensitive when it comes to actors and their trailers, and waiting for actors to come to the set". Sam Worthington commented, "He demands excellence. If you don't give it to him, you're going to get chewed out. And that's a good thing." When asked in 2012 about his reputation, Cameron drily responded, “I don’t have to shout any more, because the word is out there already."

Cameron's work has had an influence in the Hollywood film industry. "The Avengers" (2012), a film directed by Joss Whedon, was inspired by Cameron's approach to action sequences. Whedon also admires Cameron's ability for writing heroic female characters such as Ellen Ripley (of "Aliens"), adding that he is "the leader and the teacher and the Yoda".<ref name="http://www.slashfilm.com/film-interview-joss-whedon-writer-director-the-avengers/"></ref> Film director, Michael Bay idolizes Cameron and was convinced by him to use 3D cameras for filming "" (2011).<ref name="http://www.hollywoodreporter.com/news/michael-bay-reveals-james-camerons-191774"></ref> Cameron's approach to 3D also inspired Baz Luhrmann during the production of "The Great Gatsby" (2013). Other directors that have been inspired by Cameron include Peter Jackson, Neill Blomkamp, and Xavier Dolan.<ref name="https://web.archive.org/web/20071225035055/http://tbhl.theonering.net/peter/faq.html"></ref>

Cameron's films are often based on themes which explore: the conflicts between intelligent machines and humanity or nature, dangers of corporate greed, strong female characters and a romance subplot. Characters suffering from emotionally intense and dramatic environments in the sea wilderness are explored in "The Abyss" and "Titanic. The" "Terminator" series amplifies technology as an enemy which could lead to devastation of mankind. Similarly, "Avatar" views tribal people as an honest group, whereas a "technologically advanced imperial culture is fundamentally evil."

Cameron received the inaugural Ray Bradbury Award from the Science Fiction and Fantasy Writers of America in 1992 for "". In recognition of "a distinguished career as a Canadian filmmaker", Carleton University, Ottawa, awarded Cameron the honorary degree of Doctor of Fine Arts on June 13, 1998. He also received an honorary doctorate in 1998 from Brock University in St. Catharines, Ontario, for his accomplishments in the international film industry.

That year, Cameron attended a convocation to receive an honorary degree from Ryerson University, Toronto. The university awards its highest honor to those who have made extraordinary contributions in Canada or internationally. A year later, Cameron received the honorary Doctor of Fine Arts degree from California State University, Fullerton. He accepted the degree at the university's summer annual commencement exercise.

For his work in film, Cameron's films have been recognized by the Academy of Motion Picture Arts and Sciences. For "Titanic", he won Best Director, Best Picture (shared with Jon Landau) and Best Film Editing (shared with Conrad Buff and Richard A. Harris). Cameron is one of the few directors to have won three Academy Awards in a single year. In 2009, Cameron was nominated for awards in Best Film Editing (shared with John Refoua and Stephen E. Rivkin, Best Director and Best Picture for "Avatar." Cameron has won two Golden Globes: Best Director for "Titanic" and "Avatar". He was nominated for a number of BAFTA Awards, such as in Best Film for the same titles.

In recognition of his contributions to underwater filming and remote vehicle technology, University of Southampton awarded Cameron the honorary degree of Doctor of the University in July 2004. Cameron accepted the award at the National Oceanography Centre. In 2008, Cameron received a star on Canada's Walk of Fame and a year later, received the 2,396th star on the Hollywood Walk of Fame. On February 28, 2010, Cameron was honored with a Visual Effects Society (VES) Lifetime Achievement Award. In June 2012, Cameron was inducted to The Science Fiction Hall of Fame at the Museum of Pop Culture for his contribution to the science fiction and fantasy field. Inspired by "Avatar", Disney constructed "Pandora – The World of Avatar", a themed area at Disney's Animal Kingdom in Florida. It opened to the public on May 27, 2017. A species of frog, "Pristimantis jamescameroni," was named after Cameron for his work in promoting environmental awareness and advocacy of veganism.

In 2010, Cameron was ranked at the top of the list in "The Guardian" Film Power 100. In the same year, British magazine "New Statesman" ranked Cameron 30th place in their list of "The World's 50 Most Influential Figures 2010".

In 2013, Cameron received the Nierenberg Prize for Science in the Public, which is annually awarded by the Scripps Institution of Oceanography.

In 2019 Cameron was appointed as a Companion of the Order of Canada by Governor General Julie Payette. This will give him the Post Nominal Letters "CC" for Life. 

As a director:
Cameron has frequently cast the same actors in films that he has directed, including Arnold Schwarzenegger and Michael Biehn. Bill Paxton appeared in five of Cameron's films before Paxton's death in 2017. Lance Henriksen and Jenette Goldstein have appeared in four and three of Cameron's films, respectively. For the "Avatar" sequels, much of the original cast will be reuniting with Cameron: C.C.H. Pounder, Giovanni Ribisi, Sam Worthington, Sigourney Weaver, Stephen Lang and Zoe Saldana.




</doc>
<doc id="15624" url="https://en.wikipedia.org/wiki?curid=15624" title="Judaism">
Judaism

Judaism (originally from Hebrew , "Yehudah", "Judah"; via Latin and Greek) is an ethnic religion comprising the collective religious, cultural and legal tradition and civilization of the Jewish people. Judaism is considered by religious Jews to be the expression of the covenant that God established with the Children of Israel. It encompasses a wide body of texts, practices, theological positions, and forms of organization. The Torah is part of the larger text known as the Tanakh or the Hebrew Bible, and supplemental oral tradition represented by later texts such as the Midrash and the Talmud. With between 14.5 and 17.4 million adherents worldwide, Judaism is the tenth largest religion in the world.

Within Judaism there are a variety of movements, most of which emerged from Rabbinic Judaism, which holds that God revealed his laws and commandments to Moses on Mount Sinai in the form of both the Written and Oral Torah. Historically, all or part of this assertion was challenged by various groups such as the Sadducees and Hellenistic Judaism during the Second Temple period; the Karaites and Sabbateans during the early and later medieval period; and among segments of the modern non-Orthodox denominations. Modern branches of Judaism such as Humanistic Judaism may be nontheistic. Today, the largest Jewish religious movements are Orthodox Judaism (Haredi Judaism and Modern Orthodox Judaism), Conservative Judaism, and Reform Judaism. Major sources of difference between these groups are their approaches to Jewish law, the authority of the Rabbinic tradition, and the significance of the State of Israel. Orthodox Judaism maintains that the Torah and Jewish law are divine in origin, eternal and unalterable, and that they should be strictly followed. Conservative and Reform Judaism are more liberal, with Conservative Judaism generally promoting a more traditionalist interpretation of Judaism's requirements than Reform Judaism. A typical Reform position is that Jewish law should be viewed as a set of general guidelines rather than as a set of restrictions and obligations whose observance is required of all Jews. Historically, special courts enforced Jewish law; today, these courts still exist but the practice of Judaism is mostly voluntary. Authority on theological and legal matters is not vested in any one person or organization, but in the sacred texts and the rabbis and scholars who interpret them.

Judaism has its roots as an organized religion in the Middle East during the Bronze Age. It evolved from ancient Israelite religions around 500 BCE, and is considered one of the oldest monotheistic religions. The Hebrews and Israelites were already referred to as "Jews" in later books of the Tanakh such as the Book of Esther, with the term Jews replacing the title "Children of Israel". Judaism's texts, traditions and values strongly influenced later Abrahamic religions, including Christianity, Islam and the Baha'i Faith. Many aspects of Judaism have also directly or indirectly influenced secular Western ethics and civil law. Hebraism was just as important a factor in the ancient era development of Western civilization as Hellenism, and Judaism, as the background of Christianity, has considerably shaped Western ideals and morality since Early Christianity.

Jews are an ethnoreligious group including those born Jewish, in addition to converts to Judaism. In 2015, the world Jewish population was estimated at about 14.3 million, or roughly 0.2% of the total world population. About 43% of all Jews reside in Israel and another 43% reside in the United States and Canada, with most of the remainder living in Europe, and other minority groups spread throughout Latin America, Asia, Africa, and Australia.

Unlike other ancient Near Eastern gods, the Hebrew God is portrayed as unitary and solitary; consequently, the Hebrew God's principal relationships are not with other gods, but with the world, and more specifically, with the people he created. Judaism thus begins with ethical monotheism: the belief that God is one and is concerned with the actions of mankind. According to the Tanakh (Hebrew Bible), God promised Abraham to make of his offspring a great nation. Many generations later, he commanded the nation of Israel to love and worship only one God; that is, the Jewish nation is to reciprocate God's concern for the world. He also commanded the Jewish people to love one another; that is, Jews are to imitate God's love for people. These commandments are but two of a large corpus of commandments and laws that constitute this covenant, which is the substance of Judaism.

Thus, although there is an esoteric tradition in Judaism (Kabbalah), Rabbinic scholar Max Kadushin has characterized normative Judaism as "normal mysticism", because it involves everyday personal experiences of God through ways or modes that are common to all Jews. This is played out through the observance of the Halakha (Jewish law) and given verbal expression in the Birkat Ha-Mizvot, the short blessings that are spoken every time a positive commandment is to be fulfilled.
Whereas Jewish philosophers often debate whether God is immanent or transcendent, and whether people have free will or their lives are determined, Halakha is a system through which any Jew acts to bring God into the world.

Ethical monotheism is central in all sacred or normative texts of Judaism. However, monotheism has not always been followed in practice. The Jewish Bible (Tanakh) records and repeatedly condemns the widespread worship of other gods in ancient Israel. In the Greco-Roman era, many different interpretations of monotheism existed in Judaism, including the interpretations that gave rise to Christianity.

Moreover, some have argued that Judaism is a non-creedal religion that does not require one to believe in God. For some, observance of Jewish law is more important than belief in God "per se". In modern times, some liberal Jewish movements do not accept the existence of a personified deity active in history. The debate about whether one can speak of authentic or normative Judaism is not only a debate among religious Jews but also among historians.

Scholars throughout Jewish history have proposed numerous formulations of Judaism's core tenets, all of which have met with criticism. The most popular formulation is Maimonides' thirteen principles of faith, developed in the 12th century. According to Maimonides, any Jew who rejects even one of these principles would be considered an apostate and a heretic. Jewish scholars have held points of view diverging in various ways from Maimonides' principles.

In Maimonides' time, his list of tenets was criticized by Hasdai Crescas and Joseph Albo. Albo and the Raavad argued that Maimonides' principles contained too many items that, while true, were not fundamentals of the faith.

Along these lines, the ancient historian Josephus emphasized practices and observances rather than religious beliefs, associating apostasy with a failure to observe Jewish law and maintaining that the requirements for conversion to Judaism included circumcision and adherence to traditional customs. Maimonides' principles were largely ignored over the next few centuries. Later, two poetic restatements of these principles (""Ani Ma'amin"" and ""Yigdal"") became integrated into many Jewish liturgies, leading to their eventual near-universal acceptance.

In modern times, Judaism lacks a centralized authority that would dictate an exact religious dogma. Because of this, many different variations on the basic beliefs are considered within the scope of Judaism. Even so, all Jewish religious movements are, to a greater or lesser extent, based on the principles of the Hebrew Bible and various commentaries such as the Talmud and Midrash. Judaism also universally recognizes the Biblical Covenant between God and the Patriarch Abraham as well as the additional aspects of the Covenant revealed to Moses, who is considered Judaism's greatest prophet. In the Mishnah, a core text of Rabbinic Judaism, acceptance of the Divine origins of this covenant is considered an essential aspect of Judaism and those who reject the Covenant forfeit their share in the World to Come.

Establishing the core tenets of Judaism in the modern era is even more difficult, given the number and diversity of the contemporary Jewish denominations. Even if to restrict the problem to the most influential intellectual trends of the nineteenth and twentieth century, the matter remains complicated. Thus for instance, Joseph Soloveitchik's (associated with the Modern Orthodox movement) answer to modernity is constituted upon the identification of Judaism with following the halakha whereas its ultimate goal is to bring the holiness down to the world. Mordecai Kaplan, the founder of the Reconstructionist Judaism, abandons the idea of religion for the sake of identifying Judaism with civilization and by means of the latter term and secular translation of the core ideas, he tries to embrace as many Jewish denominations as possible. In turn, Solomon Schechter's Conservative Judaism was identical with the tradition understood as the interpretation of Torah, in itself being the history of the constant updates and adjustment of the Law performed by means of the creative interpretation. Finally, David Philipson draws the outlines of the Reform movement in Judaism by opposing it to the strict and traditional rabbinical approach and thus comes to the conclusions similar to that of the Conservative movement.

The following is a basic, structured list of the central works of Jewish practice and thought.

Many traditional Jewish texts are available online in various Torah databases (electronic versions of the Traditional Jewish Bookshelf). Many of these have advanced search options available.

The basis of Jewish law and tradition (halakha) is the Torah (also known as the Pentateuch or the Five Books of Moses). According to rabbinic tradition, there are 613 commandments in the Torah. Some of these laws are directed only to men or to women, some only to the ancient priestly groups, the Kohanim and Leviyim (members of the tribe of Levi), some only to farmers within the Land of Israel. Many laws were only applicable when the Temple in Jerusalem existed, and only 369 of these commandments are still applicable today.

While there have been Jewish groups whose beliefs were based on the written text of the Torah alone (e.g., the Sadducees, and the Karaites), most Jews believe in the oral law. These oral traditions were transmitted by the Pharisee school of thought of ancient Judaism and were later recorded in written form and expanded upon by the rabbis.

According to Rabbinical Jewish tradition, God gave both the Written Law (the Torah) and the Oral law to Moses on Mount Sinai. The Oral law is the oral tradition as relayed by God to Moses and from him, transmitted and taught to the sages (rabbinic leaders) of each subsequent generation.

For centuries, the Torah appeared only as a written text transmitted in parallel with the oral tradition. Fearing that the oral teachings might be forgotten, Rabbi Judah haNasi undertook the mission of consolidating the various opinions into one body of law which became known as the "Mishnah".

The Mishnah consists of 63 tractates codifying Jewish law, which are the basis of the "Talmud." According to Abraham ben David, the "Mishnah" was compiled by Rabbi Judah haNasi after the destruction of Jerusalem, in anno mundi 3949, which corresponds to 189 CE.

Over the next four centuries, the Mishnah underwent discussion and debate in both of the world's major Jewish communities (in Israel and Babylonia). The commentaries from each of these communities were eventually compiled into the two Talmuds, the Jerusalem Talmud ("Talmud Yerushalmi") and the Babylonian Talmud ("Talmud Bavli"). These have been further expounded by commentaries of various Torah scholars during the ages.

In the text of the Torah, many words are left undefined and many procedures are mentioned without explanation or instructions. Such phenomena are sometimes offered to validate the viewpoint that the Written Law has always been transmitted with a parallel oral tradition, illustrating the assumption that the reader is already familiar with the details from other, i.e., oral, sources.

Halakha, the rabbinic Jewish way of life, then, is based on a combined reading of the Torah, and the oral tradition—the Mishnah, the halakhic Midrash, the Talmud and its commentaries. The Halakha has developed slowly, through a precedent-based system. The literature of questions to rabbis, and their considered answers, is referred to as responsa (in Hebrew, "Sheelot U-Teshuvot".) Over time, as practices develop, codes of Jewish law are written that are based on the responsa; the most important code, the Shulchan Aruch, largely determines Orthodox religious practice today.

Jewish philosophy refers to the conjunction between serious study of philosophy and Jewish theology. Major Jewish philosophers include Solomon ibn Gabirol, Saadia Gaon, Judah Halevi, Maimonides, and Gersonides. Major changes occurred in response to the Enlightenment (late 18th to early 19th century) leading to the post-Enlightenment Jewish philosophers. Modern Jewish philosophy consists of both Orthodox and non-Orthodox oriented philosophy. Notable among Orthodox Jewish philosophers are Eliyahu Eliezer Dessler, Joseph B. Soloveitchik, and Yitzchok Hutner. Well-known non-Orthodox Jewish philosophers include Martin Buber, Franz Rosenzweig, Mordecai Kaplan, Abraham Joshua Heschel, Will Herberg, and Emmanuel Lévinas.

Orthodox and many other Jews do not believe that the revealed Torah consists solely of its written contents, but of its interpretations as well. The study of Torah (in its widest sense, to include both poetry, narrative, and law, and both the Hebrew Bible and the Talmud) is in Judaism itself a sacred act of central importance. For the sages of the Mishnah and Talmud, and for their successors today, the study of Torah was therefore not merely a means to learn the contents of God's revelation, but an end in itself. According to the Talmud,
In Judaism, "the study of Torah can be a means of experiencing God". Reflecting on the contribution of the Amoraim and Tanaim to contemporary Judaism, Professor Jacob Neusner observed:
To study the Written Torah and the Oral Torah in light of each other is thus also to study "how" to study the word of God.

In the study of Torah, the sages formulated and followed various logical and hermeneutical principles. According to David Stern, all Rabbinic hermeneutics rest on two basic axioms:
These two principles make possible a great variety of interpretations. According to the Talmud,
Observant Jews thus view the Torah as dynamic, because it contains within it a host of interpretations.

According to Rabbinic tradition, all valid interpretations of the written Torah were revealed to Moses at Sinai in oral form, and handed down from teacher to pupil (The oral revelation is in effect coextensive with the Talmud itself). When different rabbis forwarded conflicting interpretations, they sometimes appealed to hermeneutic principles to legitimize their arguments; some rabbis claim that these principles were themselves revealed by God to Moses at Sinai.

Thus, Hillel called attention to seven commonly used hermeneutical principles in the interpretation of laws (baraita at the beginning of Sifra); R. Ishmael, thirteen (baraita at the beginning of Sifra; this collection is largely an amplification of that of Hillel). Eliezer b. Jose ha-Gelili listed 32, largely used for the exegesis of narrative elements of Torah. All the hermeneutic rules scattered through the Talmudim and Midrashim have been collected by Malbim in "Ayyelet ha-Shachar", the introduction to his commentary on the Sifra. Nevertheless, R. Ishmael's 13 principles are perhaps the ones most widely known; they constitute an important, and one of Judaism's earliest, contributions to logic, hermeneutics, and jurisprudence. Judah Hadassi incorporated Ishmael's principles into Karaite Judaism in the 12th century. Today R. Ishmael's 13 principles are incorporated into the Jewish prayer book to be read by observant Jews on a daily basis.

The term "Judaism" derives from "Iudaismus", a Latinized form of the Ancient Greek "Ioudaismos" (Ἰουδαϊσμός) (from the verb , "to side with or imitate the [Judeans]"). Its ultimate source was the Hebrew יהודה, "Yehudah", "Judah", which is also the source of the Hebrew term for Judaism: יַהֲדוּת, "Yahadut". The term "Ἰουδαϊσμός" first appears in the Hellenistic Greek book of 2 Maccabees in the 2nd century BCE. In the context of the age and period it meant "seeking or forming part of a cultural entity" and it resembled its antonym "hellenismos", a word that signified a people's submission to Hellenic (Greek) cultural norms. The conflict between "iudaismos" and "hellenismos" lay behind the Maccabean revolt and hence the invention of the term "iudaismos".

Shaye J. D. Cohen writes in his book "The Beginnings of Jewishness":

According to the "Oxford English Dictionary" the earliest citation in English where the term was used to mean "the profession or practice of the Jewish religion; the religious system or polity of the Jews" is Robert Fabyan's "The newe cronycles of Englande and of Fraunce" (1516). "Judaism" as a direct translation of the Latin "Iudaismus" first occurred in a 1611 English translation of the apocrypha (Deuterocanon in Catholic and Eastern Orthodoxy), 2 Macc. ii. 21: "Those that behaved themselves manfully to their honour for Iudaisme."

According to Daniel Boyarin, the underlying distinction between religion and ethnicity is foreign to Judaism itself, and is one form of the dualism between spirit and flesh that has its origin in Platonic philosophy and that permeated Hellenistic Judaism. Consequently, in his view, Judaism does not fit easily into conventional Western categories, such as religion, ethnicity, or culture. Boyarin suggests that this in part reflects the fact that much of Judaism's more than 3,000-year history predates the rise of Western culture and occurred outside the West (that is, Europe, particularly medieval and modern Europe). During this time, Jews experienced slavery, anarchic and theocratic self-government, conquest, occupation, and exile. In the Diaspora, they were in contact with, and influenced by, ancient Egyptian, Babylonian, Persian, and Hellenic cultures, as well as modern movements such as the Enlightenment (see Haskalah) and the rise of nationalism, which would bear fruit in the form of a Jewish state in their ancient homeland, the Land of Israel. They also saw an elite population convert to Judaism (the Khazars), only to disappear as the centers of power in the lands once occupied by that elite fell to the people of Rus and then the Mongols. Thus, Boyarin has argued that "Jewishness disrupts the very categories of identity, because it is not national, not genealogical, not religious, but all of these, in dialectical tension."

In contrast to this point of view, practices such as Humanistic Judaism reject the religious aspects of Judaism, while retaining certain cultural traditions.

According to Rabbinic Judaism, a Jew is anyone who was either born of a Jewish mother or who converted to Judaism in accordance with Jewish Law. Reconstructionist Judaism and the larger denominations of worldwide Progressive Judaism (also known as Liberal or Reform Judaism) accept the child as Jewish if one of the parents is Jewish, if the parents raise the child with a Jewish identity, but not the smaller regional branches. All mainstream forms of Judaism today are open to sincere converts, although conversion has traditionally been discouraged since the time of the Talmud. The conversion process is evaluated by an authority, and the convert is examined on his or her sincerity and knowledge. Converts are called "ben Abraham" or "bat Abraham", (son or daughter of Abraham). Conversions have on occasion been overturned. In 2008, Israel's highest religious court invalidated the conversion of 40,000 Jews, mostly from Russian immigrant families, even though they had been approved by an Orthodox rabbi.

Rabbinical Judaism maintains that a Jew, whether by birth or conversion, is a Jew forever. Thus a Jew who claims to be an atheist or converts to another religion is still considered by traditional Judaism to be Jewish. According to some sources, the Reform movement has maintained that a Jew who has converted to another religion is no longer a Jew, and the Israeli Government has also taken that stance after Supreme Court cases and statutes. However, the Reform movement has indicated that this is not so cut and dried, and different situations call for consideration and differing actions. For example, Jews who have converted under duress may be permitted to return to Judaism "without any action on their part but their desire to rejoin the Jewish community" and "A proselyte who has become an apostate remains, nevertheless, a Jew".

Karaite Judaism believes that Jewish identity can only be transmitted by patrilineal descent. Although a minority of modern Karaites believe that Jewish identity requires that both parents be Jewish, and not only the father. They argue that only patrilineal descent can transmit Jewish identity on the grounds that all descent in the Torah went according to the male line.

The question of what determines Jewish identity in the State of Israel was given new impetus when, in the 1950s, David Ben-Gurion requested opinions on "mihu Yehudi" ("Who is a Jew") from Jewish religious authorities and intellectuals worldwide in order to settle citizenship questions. This is still not settled, and occasionally resurfaces in Israeli politics.

Historical definitions of Jewish identity have traditionally been based on "halakhic" definitions of matrilineal descent, and halakhic conversions. Historical definitions of who is a Jew date back to the codification of the Oral Torah into the Babylonian Talmud, around 200 CE. Interpretations of sections of the Tanakh, such as Deuteronomy 7:1–5, by Jewish sages, are used as a warning against intermarriage between Jews and Canaanites because "[the non-Jewish husband] will cause your child to turn away from Me and they will worship the gods (i.e., idols) of others." says that the son in a marriage between a Hebrew woman and an Egyptian man is "of the community of Israel." This is complemented by , where Israelites returning from Babylon vow to put aside their gentile wives and their children. A popular theory is that the rape of Jewish women in captivity brought about the law of Jewish identity being inherited through the maternal line, although scholars challenge this theory citing the Talmudic establishment of the law from the pre-exile period. Since the anti-religious "Haskalah" movement of the late 18th and 19th centuries, "halakhic" interpretations of Jewish identity have been challenged.

The total number of Jews worldwide is difficult to assess because the definition of "who is a Jew" is problematic; not all Jews identify themselves as Jewish, and some who identify as Jewish are not considered so by other Jews. According to the "Jewish Year Book" (1901), the global Jewish population in 1900 was around 11 million. The latest available data is from the World Jewish Population Survey of 2002 and the Jewish Year Calendar (2005). In 2002, according to the Jewish Population Survey, there were 13.3 million Jews around the world. The Jewish Year Calendar cites 14.6 million. Jewish population growth is currently near zero percent, with 0.3% growth from 2000 to 2001.

Rabbinic Judaism (or in some Christian traditions, Rabbinism) (Hebrew: "Yahadut Rabanit" – יהדות רבנית) has been the mainstream form of Judaism since the 6th century CE, after the codification of the Talmud. It is characterised by the belief that the Written Torah (Written Law) cannot be correctly interpreted without reference to the Oral Torah and the voluminous literature specifying what behavior is sanctioned by the Law.

The Jewish Enlightenment of the late 18th century resulted in the division of Ashkenazi (Western) Jewry into religious movements or denominations, especially in North America and Anglophone countries. The main denominations today outside Israel (where the situation is rather different) are Orthodox, Conservative, and Reform.

While traditions and customs (see also "Sephardic law and customs") vary between discrete communities, it can be said that Sephardi and Mizrahi Jewish communities do not generally adhere to the "movement" framework popular in and among Ashkenazi Jewry. Historically, Sephardi and Mizrahi communities have eschewed denominations in favour of a "big tent" approach. This is particularly the case in contemporary Israel, which is home to the largest communities of Sephardi and Mizrahi Jews in the world. (However, individual Sephardi and Mizrahi Jews may be members of or attend synagogues that do adhere to one Ashkenazi-inflected movement or another.)

Sephardi and Mizrahi observance of Judaism tends toward the conservative, and prayer rites are reflective of this, with the text of each rite being largely unchanged since their respective inception. Observant Sephardim may follow the teachings of a particular rabbi or school of thought; for example, the Sephardic Chief Rabbi of Israel.

Most Jewish Israelis classify themselves as "secular" ("hiloni"), "traditional" ("masorti"), "religious" ("dati") or "Haredi". The term "secular" is more popular as a self-description among Israeli families of western (European) origin, whose Jewish identity may be a very powerful force in their lives, but who see it as largely independent of traditional religious belief and practice. This portion of the population largely ignores organized religious life, be it of the official Israeli rabbinate (Orthodox) or of the liberal movements common to diaspora Judaism (Reform, Conservative).

The term "traditional" ("masorti") is most common as a self-description among Israeli families of "eastern" origin (i.e., the Middle East, Central Asia, and North Africa). This term, as commonly used, has nothing to do with the Conservative Judaism, which also names itself "Masorti" outside North America. There is a great deal of ambiguity in the ways "secular" and "traditional" are used in Israel: they often overlap, and they cover an extremely wide range in terms of worldview and practical religious observance. The term "Orthodox" is not popular in Israeli discourse, although the percentage of Jews who come under that category is far greater than in the diaspora. What would be called "Orthodox" in the diaspora includes what is commonly called "dati" (religious) or "haredi" (ultra-Orthodox) in Israel. The former term includes what is called "Religious Zionism" or the "National Religious" community, as well as what has become known over the past decade or so as "haredi-leumi" (nationalist "haredi"), or "Hardal", which combines a largely "haredi" lifestyle with nationalist ideology. (Some people, in Yiddish, also refer to observant Orthodox Jews as "frum", as opposed to "frei" (more liberal Jews)).

"Haredi" applies to a populace that can be roughly divided into three separate groups along both ethnic and ideological lines: (1) "Lithuanian" (non-hasidic) "haredim" of Ashkenazic origin; (2) Hasidic "haredim" of Ashkenazic origin; and (3) Sephardic "haredim".

Karaite Judaism defines itself as the remnants of the non-Rabbinic Jewish sects of the Second Temple period, such as the Sadducees. The Karaites ("Scripturalists") accept only the Hebrew Bible and what they view as the Peshat ("simple" meaning); they do not accept non-biblical writings as authoritative. Some European Karaites do not see themselves as part of the Jewish community at all, although most do.

The Samaritans, a very small community located entirely around Mount Gerizim in the Nablus/Shechem region of the West Bank and in Holon, near Tel Aviv in Israel, regard themselves as the descendants of the Israelites of the Iron Age kingdom of Israel. Their religious practices are based on the literal text of the written Torah (Five Books of Moses), which they view as the only authoritative scripture (with a special regard also for the Samaritan Book of Joshua).
"See also: Haymanot; Beta Israel."

Haymanot (meaning "religion" in Ge'ez and Amharic) refers the Judaism practiced by Ethiopian Jews. This version of Judaism differs substantially from Rabbinic, Karaite, and Samaritan Judaisms, Ethiopian Jews having diverged from their coreligionists earlier. Sacred scriptures (the Orit) are written in Ge'ez, not Hebrew, and dietary laws are based strictly on the text of the Orit, without explication from ancillary commentaries. Holidays also differ, with some Rabbinic holidays not observed in Ethiopian Jewish communities, and some additional holidays, like Sigd.

Jewish ethics may be guided by halakhic traditions, by other moral principles, or by central Jewish virtues. Jewish ethical practice is typically understood to be marked by values such as justice, truth, peace, loving-kindness (chesed), compassion, humility, and self-respect. Specific Jewish ethical practices include practices of charity (tzedakah) and refraining from negative speech (lashon hara). Proper ethical practices regarding sexuality and many other issues are subjects of dispute among Jews.

Traditionally, Jews recite prayers three times daily, Shacharit, Mincha, and Ma'ariv with a fourth prayer, Mussaf added on Shabbat and holidays. At the heart of each service is the "Amidah" or "Shemoneh Esrei". Another key prayer in many services is the declaration of faith, the "Shema Yisrael" (or "Shema"). The "Shema" is the recitation of a verse from the Torah (Deuteronomy 6:4): "Shema Yisrael Adonai Eloheinu Adonai Echad"—"Hear, O Israel! The Lord is our God! The Lord is One!"

Most of the prayers in a traditional Jewish service can be recited in solitary prayer, although communal prayer is preferred. Communal prayer requires a quorum of ten adult Jews, called a "minyan". In nearly all Orthodox and a few Conservative circles, only male Jews are counted toward a "minyan"; most Conservative Jews and members of other Jewish denominations count female Jews as well.

In addition to prayer services, observant traditional Jews recite prayers and benedictions throughout the day when performing various acts. Prayers are recited upon waking up in the morning, before eating or drinking different foods, after eating a meal, and so on.

The approach to prayer varies among the Jewish denominations. Differences can include the texts of prayers, the frequency of prayer, the number of prayers recited at various religious events, the use of musical instruments and choral music, and whether prayers are recited in the traditional liturgical languages or the vernacular. In general, Orthodox and Conservative congregations adhere most closely to tradition, and Reform and Reconstructionist synagogues are more likely to incorporate translations and contemporary writings in their services. Also, in most Conservative synagogues, and all Reform and Reconstructionist congregations, women participate in prayer services on an equal basis with men, including roles traditionally filled only by men, such as reading from the Torah. In addition, many Reform temples use musical accompaniment such as organs and mixed choirs.

A "kippah" (Hebrew: כִּפָּה, plural "kippot"; Yiddish: יאַרמלקע, "yarmulke") is a slightly rounded brimless skullcap worn by many Jews while praying, eating, reciting blessings, or studying Jewish religious texts, and at all times by some Jewish men. In Orthodox communities, only men wear kippot; in non-Orthodox communities, some women also wear kippot. "Kippot" range in size from a small round beanie that covers only the back of the head to a large, snug cap that covers the whole crown.

"Tzitzit" (Hebrew: צִיציִת) (Ashkenazi pronunciation: "tzitzis") are special knotted "fringes" or "tassels" found on the four corners of the "tallit" (Hebrew: טַלִּית) (Ashkenazi pronunciation: "tallis"), or prayer shawl. The "tallit" is worn by Jewish men and some Jewish women during the prayer service. Customs vary regarding when a Jew begins wearing a tallit. In the Sephardi community, boys wear a tallit from bar mitzvah age. In some Ashkenazi communities, it is customary to wear one only after marriage. A "tallit katan" (small tallit) is a fringed garment worn under the clothing throughout the day. In some Orthodox circles, the fringes are allowed to hang freely outside the clothing.

Tefillin (Hebrew: תְפִלִּין), known in English as phylacteries (from the Greek word φυλακτήριον, meaning "safeguard" or "amulet"), are two square leather boxes containing biblical verses, attached to the forehead and wound around the left arm by leather straps. They are worn during weekday morning prayer by observant Jewish men and some Jewish women.

A "kittel" (Yiddish: קיטל), a white knee-length overgarment, is worn by prayer leaders and some observant traditional Jews on the High Holidays. It is traditional for the head of the household to wear a kittel at the Passover seder in some communities, and some grooms wear one under the wedding canopy. Jewish males are buried in a "tallit" and sometimes also a "kittel" which are part of the "tachrichim" (burial garments).

Jewish holidays are special days in the Jewish calendar, which celebrate moments in Jewish history, as well as central themes in the relationship between God and the world, such as creation, revelation, and redemption.

"Shabbat", the weekly day of rest lasting from shortly before sundown on Friday night to nightfall on Saturday night, commemorates God's day of rest after six days of creation. It plays a pivotal role in Jewish practice and is governed by a large corpus of religious law. At sundown on Friday, the woman of the house welcomes the Shabbat by lighting two or more candles and reciting a blessing. The evening meal begins with the Kiddush, a blessing recited aloud over a cup of wine, and the Mohtzi, a blessing recited over the bread. It is customary to have challah, two braided loaves of bread, on the table. During Shabbat, Jews are forbidden to engage in any activity that falls under 39 categories of "melakhah", translated literally as "work". In fact the activities banned on the Sabbath are not "work" in the usual sense: They include such actions as lighting a fire, writing, using money and carrying in the public domain. The prohibition of lighting a fire has been extended in the modern era to driving a car, which involves burning fuel and using electricity.

Jewish holy days ("chaggim"), celebrate landmark events in Jewish history, such as the Exodus from Egypt and the giving of the Torah, and sometimes mark the change of seasons and transitions in the agricultural cycle. The three major festivals, Sukkot, Passover and Shavuot, are called "regalim" (derived from the Hebrew word "regel", or foot). On the three regalim, it was customary for the Israelites to make pilgrimages to Jerusalem to offer sacrifices in the Temple.

The High Holidays ("Yamim Noraim" or "Days of Awe") revolve around judgment and forgiveness.

Purim (Hebrew: "Pûrîm" "lots") is a joyous Jewish holiday that commemorates the deliverance of the Persian Jews from the plot of the evil Haman, who sought to exterminate them, as recorded in the biblical Book of Esther. It is characterized by public recitation of the Book of Esther, mutual gifts of food and drink, charity to the poor, and a celebratory meal (Esther 9:22). Other customs include drinking wine, eating special pastries called hamantashen, dressing up in masks and costumes, and organizing carnivals and parties.

Purim has celebrated annually on the 14th of the Hebrew month of Adar, which occurs in February or March of the Gregorian calendar.

Hanukkah (, "dedication") also known as the Festival of Lights, is an eight-day Jewish holiday that starts on the 25th day of Kislev (Hebrew calendar). The festival is observed in Jewish homes by the kindling of lights on each of the festival's eight nights, one on the first night, two on the second night and so on.

The holiday was called Hanukkah (meaning "dedication") because it marks the re-dedication of the Temple after its desecration by Antiochus IV Epiphanes. Spiritually, Hanukkah commemorates the "Miracle of the Oil". According to the Talmud, at the re-dedication of the Temple in Jerusalem following the victory of the Maccabees over the Seleucid Empire, there was only enough consecrated oil to fuel the eternal flame in the Temple for one day. Miraculously, the oil burned for eight days—which was the length of time it took to press, prepare and consecrate new oil.

Hanukkah is not mentioned in the Bible and was never considered a major holiday in Judaism, but it has become much more visible and widely celebrated in modern times, mainly because it falls around the same time as Christmas and has national Jewish overtones that have been emphasized since the establishment of the State of Israel.

Tisha B'Av ( or , "the Ninth of Av") is a day of mourning and fasting commemorating the destruction of the First and Second Temples, and in later times, the expulsion of the Jews from Spain.

There are three more minor Jewish fast days that commemorate various stages of the destruction of the Temples. They are the 17th Tamuz, the 10th of Tevet and Tzom Gedaliah (the 3rd of Tishrei).

The modern holidays of Yom Ha-shoah (Holocaust Remembrance Day), Yom Hazikaron (Israeli Memorial Day) and Yom Ha'atzmaut (Israeli Independence Day) commemorate the horrors of the Holocaust, the fallen soldiers of Israel and victims of terrorism, and Israeli independence, respectively.

There are some who prefer to commemorate those who were killed in the Holocaust on the 10th of Tevet.

The core of festival and Shabbat prayer services is the public reading of the Torah, along with connected readings from the other books of the Tanakh, called Haftarah. Over the course of a year, the whole Torah is read, with the cycle starting over in the autumn, on Simchat Torah.

Synagogues are Jewish houses of prayer and study. They usually contain separate rooms for prayer (the main sanctuary), smaller rooms for study, and often an area for community or educational use. There is no set blueprint for synagogues and the architectural shapes and interior designs of synagogues vary greatly. The Reform movement mostly refer to their synagogues as temples. Some traditional features of a synagogue are:

In addition to synagogues, other buildings of significance in Judaism include yeshivas, or institutions of Jewish learning, and mikvahs, which are ritual baths.

The Jewish dietary laws are known as "kashrut". Food prepared in accordance with them is termed kosher, and food that is not kosher is also known as "treifah" or "treif". People who observe these laws are colloquially said to be "keeping kosher".

Many of the laws apply to animal-based foods. For example, in order to be considered kosher, mammals must have split hooves and chew their cud. The pig is arguably the most well-known example of a non-kosher animal. Although it has split hooves, it does not chew its cud. For seafood to be kosher, the animal must have fins and scales. Certain types of seafood, such as shellfish, crustaceans, and eels, are therefore considered non-kosher. Concerning birds, a list of non-kosher species is given in the Torah. The exact translations of many of the species have not survived, and some non-kosher birds' identities are no longer certain. However, traditions exist about the "kashrut" status of a few birds. For example, both chickens and turkeys are permitted in most communities. Other types of animals, such as amphibians, reptiles, and most insects, are prohibited altogether.

In addition to the requirement that the species be considered kosher, meat and poultry (but not fish) must come from a healthy animal slaughtered in a process known as "shechitah". Without the proper slaughtering practices even an otherwise kosher animal will be rendered "treif". The slaughtering process is intended to be quick and relatively painless to the animal. Forbidden parts of animals include the blood, some fats, and the area in and around the sciatic nerve.

Jewish law also forbids the consumption of meat and dairy products together. The waiting period between eating meat and eating dairy varies by the order in which they are consumed and by community, and can extend for up to six hours. Based on the Biblical injunction against cooking a kid in its mother's milk, this rule is mostly derived from the Oral Torah, the Talmud and Rabbinic law. Chicken and other kosher birds are considered the same as meat under the laws of "kashrut", but the prohibition is Rabbinic, not Biblical.

The use of dishes, serving utensils, and ovens may make food "treif" that would otherwise be kosher. Utensils that have been used to prepare non-kosher food, or dishes that have held meat and are now used for dairy products, render the food "treif" under certain conditions.

Furthermore, all Orthodox and some Conservative authorities forbid the consumption of processed grape products made by non-Jews, due to ancient pagan practices of using wine in rituals. Some Conservative authorities permit wine and grape juice made without rabbinic supervision.

The Torah does not give specific reasons for most of the laws of "kashrut". However, a number of explanations have been offered, including maintaining ritual purity, teaching impulse control, encouraging obedience to God, improving health, reducing cruelty to animals and preserving the distinctness of the Jewish community. The various categories of dietary laws may have developed for different reasons, and some may exist for multiple reasons. For example, people are forbidden from consuming the blood of birds and mammals because, according to the Torah, this is where animal souls are contained. In contrast, the Torah forbids Israelites from eating non-kosher species because "they are unclean". The Kabbalah describes sparks of holiness that are released by the act of eating kosher foods, but are too tightly bound in non-kosher foods to be released by eating.

Survival concerns supersede all the laws of "kashrut", as they do for most halakhot.

The Tanakh describes circumstances in which a person who is "tahor" or ritually pure may become "tamei" or ritually impure. Some of these circumstances are contact with human corpses or graves, seminal flux, vaginal flux, menstruation, and contact with people who have become impure from any of these. In Rabbinic Judaism, Kohanim, members of the hereditary caste that served as priests in the time of the Temple, are mostly restricted from entering grave sites and touching dead bodies. During the Temple period, such priests (Kohanim) were required to eat their bread offering (Terumah) in a state of ritual purity, which laws eventually led to more rigid laws being enacted, such as hand-washing which became a requisite of all Jews before consuming ordinary bread.

An important subcategory of the ritual purity laws relates to the segregation of menstruating women. These laws are also known as "niddah", literally "separation", or family purity. Vital aspects of halakha for traditionally observant Jews, they are not usually followed by Jews in liberal denominations.

Especially in Orthodox Judaism, the Biblical laws are augmented by Rabbinical injunctions. For example, the Torah mandates that a woman in her normal menstrual period must abstain from sexual intercourse for seven days. A woman whose menstruation is prolonged must continue to abstain for seven more days after bleeding has stopped. The Rabbis conflated ordinary "niddah" with this extended menstrual period, known in the Torah as "zavah", and mandated that a woman may not have sexual intercourse with her husband from the time she begins her menstrual flow until seven days after it ends. In addition, Rabbinical law forbids the husband from touching or sharing a bed with his wife during this period. Afterwards, purification can occur in a ritual bath called a mikveh.

Traditional Ethiopian Jews keep menstruating women in separate huts and, similar to Karaite practice, do not allow menstruating women into their temples because of a temple's special sanctity. Emigration to Israel and the influence of other Jewish denominations have led to Ethiopian Jews adopting more normative Jewish practices.
Life-cycle events, or rites of passage, occur throughout a Jew's life that serves to strengthen Jewish identity and bind him/her to the entire community.

The role of the priesthood in Judaism has significantly diminished since the destruction of the Second Temple in 70 CE when priests attended to the Temple and sacrifices. The priesthood is an inherited position, and although priests no longer have any but ceremonial duties, they are still honored in many Jewish communities. Many Orthodox Jewish communities believe that they will be needed again for a future Third Temple and need to remain in readiness for future duty.

From the time of the Mishnah and Talmud to the present, Judaism has required specialists or authorities for the practice of very few rituals or ceremonies. A Jew can fulfill most requirements for prayer by himself. Some activities—reading the Torah and "haftarah" (a supplementary portion from the Prophets or Writings), the prayer for mourners, the blessings for bridegroom and bride, the complete grace after meals—require a "minyan", the presence of ten Jews.

The most common professional clergy in a synagogue are:

Jewish prayer services do involve two specified roles, which are sometimes, but not always, filled by a rabbi or hazzan in many congregations. In other congregations these roles are filled on an ad-hoc basis by members of the congregation who lead portions of services on a rotating basis:

Many congregations, especially larger ones, also rely on a:

The three preceding positions are usually voluntary and considered an honor. Since the Enlightenment large synagogues have often adopted the practice of hiring rabbis and hazzans to act as "shatz" and "baal kriyah", and this is still typically the case in many Conservative and Reform congregations. However, in most Orthodox synagogues these positions are filled by laypeople on a rotating or ad-hoc basis. Although most congregations hire one or more Rabbis, the use of a professional hazzan is generally declining in American congregations, and the use of professionals for other offices is rarer still.

At its core, the Tanakh is an account of the Israelites' relationship with God from their earliest history until the building of the Second Temple (c. 535 BCE). Abraham is hailed as the first Hebrew and the father of the Jewish people. As a reward for his act of faith in one God, he was promised that Isaac, his second son, would inherit the Land of Israel (then called Canaan). Later, the descendants of Isaac's son Jacob were enslaved in Egypt, and God commanded Moses to lead the Exodus from Egypt. At Mount Sinai, they received the Torah—the five books of Moses. These books, together with Nevi'im and Ketuvim are known as "Torah Shebikhtav" as opposed to the Oral Torah, which refers to the Mishnah and the Talmud. Eventually, God led them to the land of Israel where the tabernacle was planted in the city of Shiloh for over 300 years to rally the nation against attacking enemies. As time went on, the spiritual level of the nation declined to the point that God allowed the Philistines to capture the tabernacle. The people of Israel then told Samuel the prophet that they needed to be governed by a permanent king, and Samuel appointed Saul to be their King. When the people pressured Saul into going against a command conveyed to him by Samuel, God told Samuel to appoint David in his stead.

Once King David was established, he told the prophet Nathan that he would like to build a permanent temple, and as a reward for his actions, God promised David that he would allow his son, Solomon, to build the First Temple and the throne would never depart from his children.

Rabbinic tradition holds that the details and interpretation of the law, which are called the "Oral Torah" or "oral law", were originally an unwritten tradition based upon what God told Moses on Mount Sinai. However, as the persecutions of the Jews increased and the details were in danger of being forgotten, these oral laws were recorded by Rabbi Judah HaNasi (Judah the Prince) in the Mishnah, redacted "circa" 200 CE. The Talmud was a compilation of both the Mishnah and the Gemara, rabbinic commentaries redacted over the next three centuries. The Gemara originated in two major centers of Jewish scholarship, Palestine and Babylonia. Correspondingly, two bodies of analysis developed, and two works of Talmud were created. The older compilation is called the Jerusalem Talmud. It was compiled sometime during the 4th century in Palestine. The Babylonian Talmud was compiled from discussions in the houses of study by the scholars Ravina I, Ravina II, and Rav Ashi by 500 CE, although it continued to be edited later.

According to critical scholars, the Torah consists of inconsistent texts edited together in a way that calls attention to divergent accounts. Several of these scholars, such as Professor Martin Rose and John Bright, suggest that during the First Temple period the people of Israel believed that each nation had its own god, but that their god was superior to other gods. Some suggest that strict monotheism developed during the Babylonian Exile, perhaps in reaction to Zoroastrian dualism. In this view, it was only by the Hellenic period that most Jews came to believe that their god was the only god and that the notion of a clearly bounded Jewish nation identical with the Jewish religion formed. John Day argues that the origins of biblical Yahweh, El, Asherah, and Ba'al, may be rooted in earlier Canaanite religion, which was centered on a pantheon of gods much like the Greek pantheon.

According to the Hebrew Bible, the United Monarchy was established under Saul and continued under King David and Solomon with its capital in Jerusalem. After Solomon's reign, the nation split into two kingdoms, the Kingdom of Israel (in the north) and the Kingdom of Judah (in the south). The Kingdom of Israel was conquered by the Assyrian ruler Sargon II in the late 8th century BCE with many people from the capital Samaria being taken captive to Media and the Khabur River valley. The Kingdom of Judah continued as an independent state until it was conquered by a Babylonian army in the early 6th century BCE, destroying the First Temple that was at the center of ancient Jewish worship. The Judean elite was exiled to Babylonia and this is regarded as the first Jewish Diaspora. Later many of them returned to their homeland after the subsequent conquest of Babylonia by the Persians seventy years later, a period known as the Babylonian Captivity. A new Second Temple was constructed, and old religious practices were resumed.

During the early years of the Second Temple, the highest religious authority was a council known as the Great Assembly, led by Ezra of the Book of Ezra. Among other accomplishments of the Great Assembly, the last books of the Bible were written at this time and the canon sealed.

Hellenistic Judaism spread to Ptolemaic Egypt from the 3rd century BCE. After the Great Revolt (66–73 CE), the Romans destroyed the Temple. Hadrian built a pagan idol on the Temple grounds and prohibited circumcision; these acts of ethnocide provoked the Bar Kokhba revolt 132–136 CE after which the Romans banned the study of the Torah and the celebration of Jewish holidays, and forcibly removed virtually all Jews from Judea. In 200 CE, however, Jews were granted Roman citizenship and Judaism was recognized as a "religio licita" ("legitimate religion") until the rise of Gnosticism and Early Christianity in the fourth century.

Following the destruction of Jerusalem and the expulsion of the Jews, Jewish worship stopped being centrally organized around the Temple, prayer took the place of sacrifice, and worship was rebuilt around the community (represented by a minimum of ten adult men) and the establishment of the authority of rabbis who acted as teachers and leaders of individual communities (see Jewish diaspora).

Around the 1st century CE, there were several small Jewish sects: the Pharisees, Sadducees, Zealots, Essenes, and Christians. After the destruction of the Second Temple in 70 CE, these sects vanished. Christianity survived, but by breaking with Judaism and becoming a separate religion; the Pharisees survived but in the form of Rabbinic Judaism (today, known simply as "Judaism"). The Sadducees rejected the divine inspiration of the Prophets and the Writings, relying only on the Torah as divinely inspired. Consequently, a number of other core tenets of the Pharisees' belief system (which became the basis for modern Judaism), were also dismissed by the Sadducees. (The Samaritans practiced a similar religion, which is traditionally considered separate from Judaism.)

Like the Sadducees who relied only on the Torah, some Jews in the 8th and 9th centuries rejected the authority and divine inspiration of the oral law as recorded in the Mishnah (and developed by later rabbis in the two Talmuds), relying instead only upon the Tanakh. These included the Isunians, the Yudganites, the Malikites, and others. They soon developed oral traditions of their own, which differed from the rabbinic traditions, and eventually formed the Karaite sect. Karaites exist in small numbers today, mostly living in Israel. Rabbinical and Karaite Jews each hold that the others are Jews, but that the other faith is erroneous.

Over a long time, Jews formed distinct ethnic groups in several different geographic areas—amongst others, the Ashkenazi Jews (of central and Eastern Europe), the Sephardi Jews (of Spain, Portugal, and North Africa), the Beta Israel of Ethiopia, and the Yemenite Jews from the southern tip of the Arabian Peninsula. Many of these groups have developed differences in their prayers, traditions and accepted canons; however, these distinctions are mainly the result of their being formed at some cultural distance from normative (rabbinic) Judaism, rather than based on any doctrinal dispute.

Antisemitism arose during the Middle Ages, in the form of persecutions, pogroms, forced conversions, expulsions, social restrictions and ghettoization.

This was different in quality from the repressions of Jews which had occurred in ancient times. Ancient repressions were politically motivated and Jews were treated the same as members of other ethnic groups. With the rise of the Churches, the main motive for attacks on Jews changed from politics to religion and the religious motive for such attacks was specifically derived from Christian views about Jews and Judaism. During the Middle Ages, Jewish people who lived under Muslim rule generally experienced tolerance and integration, but there were occasional outbreaks of violence like Almohad's persecutions.

Hasidic Judaism was founded by Yisroel ben Eliezer (1700–1760), also known as the "Ba'al Shem Tov" (or "Besht"). It originated in a time of persecution of the Jewish people when European Jews had turned inward to Talmud study; many felt that most expressions of Jewish life had become too "academic", and that they no longer had any emphasis on spirituality or joy. Its adherents favored small and informal gatherings called Shtiebel, which, in contrast to a traditional synagogue, could be used both as a place of worship and for celebrations involving dancing, eating, and socializing. Ba'al Shem Tov's disciples attracted many followers; they themselves established numerous Hasidic sects across Europe. Unlike other religions, which typically expanded through word of mouth or by use of print, Hasidism spread largely owing to Tzadiks, who used their influence to encourage others to follow the movement. Hasidism appealed to many Europeans because it was easy to learn, did not require full immediate commitment, and presented a compelling spectacle. Hasidic Judaism eventually became the way of life for many Jews in Eastern Europe. Waves of Jewish immigration in the 1880s carried it to the United States. The movement itself claims to be nothing new, but a "refreshment" of original Judaism. As some have put it: ""they merely re-emphasized that which the generations had lost"". Nevertheless, early on there was a serious schism between Hasidic and non-Hasidic Jews. European Jews who rejected the Hasidic movement were dubbed by the Hasidim as Misnagdim, (lit. "opponents"). Some of the reasons for the rejection of Hasidic Judaism were the exuberance of Hasidic worship, its deviation from tradition in ascribing infallibility and miracles to their leaders, and the concern that it might become a messianic sect. Over time differences between the Hasidim and their opponents have slowly diminished and both groups are now considered part of Haredi Judaism.

In the late 18th century CE, Europe was swept by a group of intellectual, social and political movements known as the Enlightenment. The Enlightenment led to reductions in the European laws that prohibited Jews to interact with the wider secular world, thus allowing Jews access to secular education and experience. A parallel Jewish movement, Haskalah or the "Jewish Enlightenment", began, especially in Central Europe and Western Europe, in response to both the Enlightenment and these new freedoms. It placed an emphasis on integration with secular society and a pursuit of non-religious knowledge through reason. With the promise of political emancipation, many Jews saw no reason to continue to observe Jewish law and increasing numbers of Jews assimilated into Christian Europe. Modern religious movements of Judaism all formed in reaction to this trend.

In Central Europe, followed by Great Britain and the United States, Reform (or Liberal) Judaism developed, relaxing legal obligations (especially those that limited Jewish relations with non-Jews), emulating Protestant decorum in prayer, and emphasizing the ethical values of Judaism's Prophetic tradition. Modern Orthodox Judaism developed in reaction to Reform Judaism, by leaders who argued that Jews could participate in public life as citizens equal to Christians while maintaining the observance of Jewish law. Meanwhile, in the United States, wealthy Reform Jews helped European scholars, who were Orthodox in practice but critical (and skeptical) in their study of the Bible and Talmud, to establish a seminary to train rabbis for immigrants from Eastern Europe. These left-wing Orthodox rabbis were joined by right-wing Reform rabbis who felt that Jewish law should not be entirely abandoned, to form the Conservative movement. Orthodox Jews who opposed the Haskalah formed Haredi Orthodox Judaism. After massive movements of Jews following The Holocaust and the creation of the state of Israel, these movements have competed for followers from among traditional Jews in or from other countries.

Countries such as the United States, Israel, Canada, United Kingdom, Argentina and South Africa contain large Jewish populations. Jewish religious practice varies widely through all levels of observance. According to the 2001 edition of the National Jewish Population Survey, in the United States' Jewish community—the world's second largest—4.3 million Jews out of 5.1 million had some sort of connection to the religion. Of that population of connected Jews, 80% participated in some sort of Jewish religious observance, but only 48% belonged to a congregation, and fewer than 16% attend regularly.

Birth rates for American Jews have dropped from 2.0 to 1.7. (Replacement rate is 2.1.) Intermarriage rates range from 40–50% in the US, and only about a third of children of intermarried couples are raised as Jews. Due to intermarriage and low birth rates, the Jewish population in the US shrank from 5.5 million in 1990 to 5.1 million in 2001. This is indicative of the general population trends among the Jewish community in the Diaspora, but a focus on total population obscures growth trends in some denominations and communities, such as Haredi Judaism. The Baal teshuva movement is a movement of Jews who have "returned" to religion or become more observant.

Christianity was originally a sect of Second Temple Judaism, but the two religions diverged in the first century. The differences between Christianity and Judaism originally centered on whether Jesus was the Jewish Messiah but eventually became irreconcilable. Major differences between the two faiths include the nature of the Messiah, of atonement and sin, the status of God's commandments to Israel, and perhaps most significantly of the nature of God himself. Due to these differences, Judaism traditionally regards Christianity as Shituf or worship of the God of Israel which is not monotheistic. Christianity has traditionally regarded Judaism as obsolete with the invention of Christianity and Jews as a people replaced by the Church, though a Christian belief in dual-covenant theology emerged as a phenomenon following Christian reflection on how their theology influenced the Nazi Holocaust.

Since the time of the Middle Ages, the Catholic Church upheld the "Constitutio pro Judæis" (Formal Statement on the Jews), which stated 

Until their emancipation in the late 18th and the 19th century, Jews in Christian lands were subject to humiliating legal restrictions and limitations. They included provisions requiring Jews to wear specific and identifying clothing such as the Jewish hat and the yellow badge, restricting Jews to certain cities and towns or in certain parts of towns (ghettos), and forbidding Jews to enter certain trades (for example selling new clothes in medieval Sweden). Disabilities also included special taxes levied on Jews, exclusion from public life, restraints on the performance of religious ceremonies, and linguistic censorship. Some countries went even further and completely expelled Jews, for example, England in 1290 (Jews were readmitted in 1655) and Spain in 1492 (readmitted in 1868). The first Jewish settlers in North America arrived in the Dutch colony of New Amsterdam in 1654; they were forbidden to hold public office, open a retail shop, or establish a synagogue. When the colony was seized by the British in 1664 Jewish rights remained unchanged, but by 1671 Asser Levy was the first Jew to serve on a jury in North America.
In 1791, Revolutionary France was the first country to abolish disabilities altogether, followed by Prussia in 1848. Emancipation of the Jews in the United Kingdom was achieved in 1858 after an almost 30-year struggle championed by Isaac Lyon Goldsmid with the ability of Jews to sit in parliament with the passing of the Jews Relief Act 1858. The newly created German Empire in 1871 abolished Jewish disabilities in Germany, which were reinstated in the Nuremberg Laws in 1935.

Jewish life in Christian lands was marked by frequent blood libels, expulsions, forced conversions and massacres. Religious prejudice was an underlying source against Jews in Europe. Christian rhetoric and antipathy towards Jews developed in the early years of Christianity and was reinforced by ever increasing anti-Jewish measures over the ensuing centuries. The action taken by Christians against Jews included acts of violence, and murder culminating in the Holocaust. These attitudes were reinforced by Christian preaching, in art and popular teaching for two millennia which expressed contempt for Jews, as well as statutes which were designed to humiliate and stigmatise Jews. The Nazi Party was known for its persecution of Christian Churches; many of them, such as the Protestant Confessing Church and the Catholic Church, as well as Quakers and Jehovah's Witnesses, aided and rescued Jews who were being targeted by the antireligious régime.

The attitude of Christians and Christian Churches toward the Jewish people and Judaism have changed in a mostly positive direction since World War II. Pope John Paul II and the Catholic Church have "upheld the Church's acceptance of the continuing and permanent election of the Jewish people" as well as a reaffirmation of the covenant between God and the Jews. In December 2015, the Vatican released a 10,000-word document that, among other things, stated that Catholics should work with Jews to fight antisemitism.

Both Judaism and Islam track their origins from the patriarch Abraham, and they are therefore considered Abrahamic religions. In both Jewish and Muslim tradition, the Jewish and Arab peoples are descended from the two sons of Abraham—Isaac and Ishmael, respectively. While both religions are monotheistic and share many commonalities, they differ based on the fact that Jews do not consider Jesus or Muhammad to be prophets. The religions' adherents have interacted with each other since the 7th century when Islam originated and spread in the Arabian peninsula. Indeed, the years 712 to 1066 CE under the Ummayad and the Abbasid rulers have been called the Golden age of Jewish culture in Spain. Non-Muslim monotheists living in these countries, including Jews, were known as dhimmis. Dhimmis were allowed to practice their own religions and administer their own internal affairs, but they were subject to certain restrictions that were not imposed on Muslims. For example, they had to pay the jizya, a per capita tax imposed on free adult non-Muslim males, and they were also forbidden to bear arms or testify in court cases involving Muslims. Many of the laws regarding dhimmis were highly symbolic. For example, dhimmis in some countries were required to wear distinctive clothing, a practice not found in either the Qur'an or the hadiths but invented in early medieval Baghdad and inconsistently enforced. Jews in Muslim countries were not entirely free from persecution—for example, many were killed, exiled or forcibly converted in the 12th century, in Persia, and by the rulers of the Almohad dynasty in North Africa and Al-Andalus, as well as by the Zaydi imams of Yemen in the 17th century (see: Mawza Exile). At times, Jews were also restricted in their choice of residence—in Morocco, for example, Jews were confined to walled quarters (mellahs) beginning in the 15th century and increasingly since the early 19th century.

In the mid-20th century, Jews were expelled from nearly all of the Arab countries. Most have chosen to live in Israel. Today, antisemitic themes including Holocaust denial have become commonplace in the propaganda of Islamic movements such as Hizbullah and Hamas, in the pronouncements of various agencies of the Islamic Republic of Iran, and even in the newspapers and other publications of Refah Partisi.

There are some movements that combine elements of Judaism with those of other religions. The most well-known of these is Messianic Judaism, a religious movement, which arose in the 1960s, that incorporates elements of Judaism with the tenets of Christianity. The movement generally states that Jesus is the Jewish Messiah, that he is one of the Three Divine Persons, and that salvation is only achieved through acceptance of Jesus as one's savior. Some members of the movement argue that Messianic Judaism is a sect of Judaism. Jewish organizations of every denomination reject this, stating that Messianic Judaism is a Christian sect, because it teaches creeds which are identical to those of Pauline Christianity.

Other examples of syncretism include Semitic neopaganism, a loosely organized sect which incorporates pagan or Wiccan beliefs with some Jewish religious practices; Jewish Buddhists, another loosely organized group that incorporates elements of Asian spirituality in their faith; and some Renewal Jews who borrow freely and openly from Buddhism, Sufism, Native American religions, and other faiths.

The Kabbalah Centre, which employs teachers from multiple religions, is a New Age movement that claims to popularize the kabbalah, part of the Jewish esoteric tradition.



Jews in Islamic countries:










See also Torah database for links to more Judaism e-texts.


Text study projects at . In many instances, the Hebrew versions of these projects are more fully developed than the English.


</doc>
<doc id="15626" url="https://en.wikipedia.org/wiki?curid=15626" title="John Stuart Mill">
John Stuart Mill

John Stuart Mill (20 May 1806 – 7 May 1873), usually cited as J. S. Mill, was a British philosopher, political economist, and civil servant. One of the most influential thinkers in the history of classical liberalism, he contributed widely to social theory, political theory, and political economy. Dubbed "the most influential English-speaking philosopher of the nineteenth century", Mill's conception of liberty justified the freedom of the individual in opposition to unlimited state and social control.

Mill was a proponent of utilitarianism, an ethical theory developed by his predecessor Jeremy Bentham. He contributed to the investigation of scientific methodology, though his knowledge of the topic was based on the writings of others, notably William Whewell, John Herschel, and Auguste Comte, and research carried out for Mill by Alexander Bain. Mill engaged in written debate with Whewell.

A member of the Liberal Party and author of the early feminist work The Subjection of Women, he was also the second Member of Parliament to call for women's suffrage after Henry Hunt in 1832.

John Stuart Mill was born at 13 Rodney Street in Pentonville, Middlesex, the eldest son of the Scottish philosopher, historian and economist James Mill, and Harriet Barrow. John Stuart was educated by his father, with the advice and assistance of Jeremy Bentham and Francis Place. He was given an extremely rigorous upbringing, and was deliberately shielded from association with children his own age other than his siblings. His father, a follower of Bentham and an adherent of associationism, had as his explicit aim to create a genius intellect that would carry on the cause of utilitarianism and its implementation after he and Bentham had died.

Mill was a notably precocious child. He describes his education in his autobiography. At the age of three he was taught Greek. By the age of eight, he had read "Aesop's Fables", Xenophon's "Anabasis", and the whole of Herodotus, and was acquainted with Lucian, Diogenes Laërtius, Isocrates and six dialogues of Plato. He had also read a great deal of history in English and had been taught arithmetic, physics and astronomy.

At the age of eight, Mill began studying Latin, the works of Euclid, and algebra, and was appointed schoolmaster to the younger children of the family. His main reading was still history, but he went through all the commonly taught Latin and Greek authors and by the age of ten could read Plato and Demosthenes with ease. His father also thought that it was important for Mill to study and compose poetry. One of Mill's earliest poetic compositions was a continuation of the Iliad. In his spare time he also enjoyed reading about natural sciences and popular novels, such as "Don Quixote" and "Robinson Crusoe".

His father's work, "The History of British India" was published in 1818; immediately thereafter, at about the age of twelve, Mill began a thorough study of the scholastic logic, at the same time reading Aristotle's logical treatises in the original language. In the following year he was introduced to political economy and studied Adam Smith and David Ricardo with his father, ultimately completing their classical economic view of factors of production. Mill's "comptes rendus" of his daily economy lessons helped his father in writing "Elements of Political Economy" in 1821, a textbook to promote the ideas of Ricardian economics; however, the book lacked popular support. Ricardo, who was a close friend of his father, used to invite the young Mill to his house for a walk in order to talk about political economy.

At the age of fourteen, Mill stayed a year in France with the family of Sir Samuel Bentham, brother of Jeremy Bentham. The mountain scenery he saw led to a lifelong taste for mountain landscapes. The lively and friendly way of life of the French also left a deep impression on him. In Montpellier, he attended the winter courses on chemistry, zoology, logic of the "Faculté des Sciences", as well as taking a course in higher mathematics. While coming and going from France, he stayed in Paris for a few days in the house of the renowned economist Jean-Baptiste Say, a friend of Mill's father. There he met many leaders of the Liberal party, as well as other notable Parisians, including Henri Saint-Simon.

Mill went through months of sadness and pondered suicide at twenty years of age. According to the opening paragraphs of Chapter V of his autobiography, he had asked himself whether the creation of a just society, his life's objective, would actually make him happy. His heart answered "no", and unsurprisingly he lost the happiness of striving towards this objective. Eventually, the poetry of William Wordsworth showed him that beauty generates compassion for others and stimulates joy. With renewed joy he continued to work towards a just society, but with more relish for the journey. He considered this one of the most pivotal shifts in his thinking. In fact, many of the differences between him and his father stemmed from this expanded source of joy.

Mill had been engaged in a pen-friendship with Auguste Comte, the founder of positivism and sociology, since Mill first contacted Comte in November 1841. Comte's "sociologie" was more an early philosophy of science than we perhaps know it today, and the "positive" philosophy aided in Mill's broad rejection of Benthamism.

As a nonconformist who refused to subscribe to the Thirty-Nine Articles of the Church of England, Mill was not eligible to study at the University of Oxford or the University of Cambridge. Instead he followed his father to work for the East India Company, and attended University College, London, to hear the lectures of John Austin, the first Professor of Jurisprudence. He was elected a Foreign Honorary Member of the American Academy of Arts and Sciences in 1856.

Mill's career as a colonial administrator at the British East India Company spanned from when he was 17 years old in 1823 until 1858, when the Company was abolished in favor of direct rule by the British crown over India. In 1836, he was promoted to the Company's Political Department, where he was responsible for correspondence pertaining to the Company's relations with the princely states, and in 1856, was finally promoted to the position of Examiner of Indian Correspondence. In "On Liberty", "A Few Words on Non-Intervention", and other works, Mill defended British imperialism by arguing that a fundamental distinction existed between civilized and barbarous peoples. Mill viewed countries such as India and China as having once been progressive, but that were now stagnant and barbarous, thus legitimizing British rule as benevolent despotism, "provided the end is [the barbarians'] improvement." When the crown proposed to take direct control over the colonies in India, he was tasked with defending Company rule, penning "Memorandum on the Improvements in the Administration of India during the Last Thirty Years" among other petitions. He was offered a seat on the Council of India, the body created to advise the new Secretary of State for India, but declined, citing his disapproval of the new system of rule.

In 1851, Mill married Harriet Taylor after 21 years of intimate friendship. Taylor was married when they met, and their relationship was close but generally believed to be chaste during the years before her first husband died in 1849. The couple waited two years before marrying in 1851. Brilliant in her own right, Taylor was a significant influence on Mill's work and ideas during both friendship and marriage. His relationship with Harriet Taylor reinforced Mill's advocacy of women's rights. J. S. Mill said that in his stand against domestic violence, and for women's rights he was “chiefly an amanuensis to my wife”. He called her mind a “perfect instrument”, and said she was “the most eminently qualified of all those known to the author”. He cites her influence in his final revision of "On Liberty", which was published shortly after her death. Taylor died in 1858 after developing severe lung congestion, after only seven years of marriage to Mill.

Between the years 1865 and 1868 Mill served as Lord Rector of the University of St. Andrews. During the same period, 1865–68, he was a Member of Parliament for City and Westminster. He was sitting for the Liberal Party. During his time as an MP, Mill advocated easing the burdens on Ireland. In 1866, Mill became the first person in the history of Parliament to call for women to be given the right to vote, vigorously defending this position in subsequent debate. Mill became a strong advocate of such social reforms as labour unions and farm cooperatives. In "Considerations on Representative Government", Mill called for various reforms of Parliament and voting, especially proportional representation, the single transferable vote, and the extension of suffrage. In April 1868, Mill favoured in a Commons debate the retention of capital punishment for such crimes as aggravated murder; he termed its abolition "an effeminacy in the general mind of the country."

He was godfather to the philosopher Bertrand Russell.

In his views on religion, Mill was an agnostic and a skeptic.

Mill died in 1873 of erysipelas in Avignon, France, where his body was buried alongside his wife's.

Mill joined the debate over scientific method which followed on from John Herschel's 1830 publication of "A Preliminary Discourse on the study of Natural Philosophy", which incorporated inductive reasoning from the known to the unknown, discovering general laws in specific facts and verifying these laws empirically. William Whewell expanded on this in his 1837 "History of the Inductive Sciences, from the Earliest to the Present Time" followed in 1840 by "The Philosophy of the Inductive Sciences, Founded Upon their History", presenting induction as the mind superimposing concepts on facts. Laws were self-evident truths, which could be known without need for empirical verification. Mill countered this in 1843 in "A System of Logic, Ratiocinative and Inductive, Being a Connected View of the Principles of Evidence, and the Methods of Scientific Investigation." In Mill's Methods of induction, like Herschel's, laws were discovered through observation and induction, and required empirical verification.

Mill's "On Liberty" addresses the nature and limits of the power that can be legitimately exercised by society over the individual. However Mill is clear that his concern for liberty does not extend to all individuals and all societies. He states that "Despotism is a legitimate mode of government in dealing with barbarians".

Mill states that it is not a crime to harm oneself as long as the person doing so is not harming others. He favors the harm principle: "The only purpose for which power can be rightfully exercised over any member of a civilized community, against his will, is to prevent harm to others." Mill excuses those who are "incapable of self-government" from this principle, such as young children or those living in "backward states of society".

Though this principle seems clear, there are a number of complications. For example, Mill explicitly states that "harms" may include acts of omission as well as acts of commission. Thus, failing to rescue a drowning child counts as a harmful act, as does failing to pay taxes, or failing to appear as a witness in court. All such harmful omissions may be regulated, according to Mill. By contrast, it does not count as harming someone if – without force or fraud – the affected individual consents to assume the risk: thus one may permissibly offer unsafe employment to others, provided there is no deception involved. (Mill does, however, recognise one limit to consent: society should not permit people to sell themselves into slavery). In these and other cases, it is important to bear in mind that the arguments in "On Liberty" are grounded on the principle of Utility, and not on appeals to natural rights.

The question of what counts as a self-regarding action and what actions, whether of omission or commission, constitute harmful actions subject to regulation, continues to exercise interpreters of Mill. It is important to emphasise that Mill did not consider giving offence to constitute "harm"; an action could not be restricted because it violated the conventions or morals of a given society.

"On Liberty" involves an impassioned defense of free speech. Mill argues that free discourse is a necessary condition for intellectual and social progress. We can never be sure, he contends, that a silenced opinion does not contain some element of the truth. He also argues that allowing people to air false opinions is productive for two reasons. First, individuals are more likely to abandon erroneous beliefs if they are engaged in an open exchange of ideas. Second, by forcing other individuals to re-examine and re-affirm their beliefs in the process of debate, these beliefs are kept from declining into mere dogma. It is not enough for Mill that one simply has an unexamined belief that happens to be true; one must understand why the belief in question is the true one. Along those same lines Mill wrote, "unmeasured vituperation, employed on the side of prevailing opinion, really does deter people from expressing contrary opinions, and from listening to those who express them."

Mill believed that "the struggle between Liberty and Authority is the most conspicuous feature in the portions of history". For him, liberty in antiquity was a "contest ... between subjects, or some classes of subjects, and the government." Mill defined "social liberty" as protection from "the tyranny of political rulers". He introduced a number of different concepts of the form tyranny can take, referred to as social tyranny, and tyranny of the majority.

Social liberty for Mill meant putting limits on the ruler's power so that he would not be able to use that power to further his own wishes and thus make decisions that could harm society. In other words, people should have the right to have a say in the government's decisions. He said that social liberty was "the nature and limits of the power which can be legitimately exercised by society over the individual". It was attempted in two ways: first, by obtaining recognition of certain immunities (called political liberties or rights) and second, by establishment of a system of "constitutional checks".

However, in Mill's view, limiting the power of government was not enough. He stated: "Society can and does execute its own mandates: and if it issues wrong mandates instead of right, or any mandates at all in things with which it ought not to meddle, it practices a social tyranny more formidable than many kinds of political oppression, since, though not usually upheld by such extreme penalties, it leaves fewer means of escape, penetrating much more deeply into the details of life, and enslaving the soul itself."

John Stuart Mill's view on liberty, which was influenced by Joseph Priestley and Josiah Warren, is that the individual ought to be free to do as she/he wishes unless she/he harms others. Individuals are rational enough to make decisions about their well being. Government should interfere when it is for the protection of society. Mill explained:

The sole end for which mankind are warranted, individually or collectively, in interfering with the liberty of action of any of their number, is self-protection. That the only purpose for which power can be rightfully exercised over any member of a civilized community, against his will, is to prevent harm to others. His own good, either physical or moral, is not sufficient warrant. He cannot rightfully be compelled to do or forbear because it will be better for him to do so, because it will make him happier, because, in the opinion of others, to do so would be wise, or even right ... The only part of the conduct of anyone, for which he is amenable to society, is that which concerns others. In the part which merely concerns him, his independence is, of right, absolute. Over himself, over his own body and mind, the individual is sovereign.

An influential advocate of freedom of speech, Mill objected to censorship. He says:

I choose, by preference the cases which are least favourable to me – In which the argument opposing freedom of opinion, both on truth and that of utility, is considered the strongest. Let the opinions impugned be the belief of God and in a future state, or any of the commonly received doctrines of morality ... But I must be permitted to observe that it is not the feeling sure of a doctrine (be it what it may) which I call an assumption of infallibility. It is the undertaking to decide that question "for others", without allowing them to hear what can be said on the contrary side. And I denounce and reprobate this pretension not the less if it is put forth on the side of my most solemn convictions. However positive anyone's persuasion may be, not only of the faculty but of the pernicious consequences, but (to adopt expressions which I altogether condemn) the immorality and impiety of opinion. – yet if, in pursuance of that private judgement, though backed by the public judgement of his country or contemporaries, he prevents the opinion from being heard in its defence, he assumes infallibility. And so far from the assumption being less objectionable or less dangerous because the opinion is called immoral or impious, this is the case of all others in which it is most fatal.

Mill outlines the benefits of 'searching for and discovering the truth' as a way to further knowledge. He argued that even if an opinion is false, the truth can be better understood by refuting the error. And as most opinions are neither completely true nor completely false, he points out that allowing free expression allows the airing of competing views as a way to preserve partial truth in various opinions. Worried about minority views being suppressed, Mill also argued in support of freedom of speech on political grounds, stating that it is a critical component for a representative government to have in order to empower debate over public policy. Mill also eloquently argued that freedom of expression allows for personal growth and self-realization. He said that freedom of speech was a vital way to develop talents and realise a person's potential and creativity. He repeatedly said that eccentricity was preferable to uniformity and stagnation.

The belief that the freedom of speech will advance the society was formed with trust of the public's ability to filter. If any argument is really wrong or harmful, the public will judge it as wrong or harmful, and then those arguments cannot be sustained and will be excluded. Mill argued that even any arguments which are used in justifying murder or rebellion against the government shouldn't be politically suppressed or socially persecuted. According to him, if rebellion is really necessary, people should rebel; if murder is truly proper, it should be allowed. But, the way to express those arguments should be a public speech or writing, not in a way that causes actual harm to others. This is the harm principle.

At the beginning of the twentieth century, Associate Justice Oliver Wendell Holmes Jr. made the standard of "clear and present danger" based on Mill's idea. In the majority opinion, Holmes writes:

Holmes suggested that shouting out "Fire!" in a dark theatre, which makes people panic and gets them injured, would be such a case of speech that creates an illegal danger. But if the situation allows people to reason by themselves and decide to accept it or not, any argument or theology should not be blocked.

Nowadays, Mill's argument is generally accepted by many democratic countries, and they have laws at least guided by the harm principle. For example, in American law some exceptions limit free speech such as obscenity, defamation, breach of peace, and "fighting words".

Mill, an employee for the British East India Company from 1823 to 1858, argued in support of what he called a "benevolent despotism" with regard to the colonies. Mill argued that "To suppose that the same international customs, and the same rules of international morality, can obtain between one civilized nation and another, and between civilized nations and barbarians, is a grave error. ... To characterize any conduct whatever towards a barbarous people as a violation of the law of nations, only shows that he who so speaks has never considered the subject."

In 1850, Mill sent an anonymous letter (which came to be known under the title "The Negro Question"), in rebuttal to Thomas Carlyle's anonymous letter to "Fraser's Magazine for Town and Country" in which Carlyle argued for slavery. Mill supported abolition in the United States.

In Mill's essay from 1869, "The Subjection of Women", he expressed his opposition to slavery:

This absolutely extreme case of the law of force, condemned by those who can tolerate almost every other form of arbitrary power, and which, of all others, presents features the most revolting to the feeling of all who look at it from an impartial position, was the law of civilized and Christian England within the memory of persons now living: and in one half of Anglo-Saxon America three or four years ago, not only did slavery exist, but the slave trade, and the breeding of slaves expressly for it, was a general practice between slave states. Yet not only was there a greater strength of sentiment against it, but, in England at least, a less amount either of feeling or of interest in favour of it, than of any other of the customary abuses of force: for its motive was the love of gain, unmixed and undisguised: and those who profited by it were a very small numerical fraction of the country, while the natural feeling of all who were not personally interested in it, was unmitigated abhorrence.

Mill's view of history was that right up until his time "the whole of the female" and "the great majority of the male sex" were simply "slaves". He countered arguments to the contrary, arguing that relations between sexes simply amounted to "the legal subordination of one sex to the other – [which] is wrong itself, and now one of the chief hindrances to human improvement; and that it ought to be replaced by a principle of perfect equality." With this, Mill can be considered among the earliest male proponents of gender equality. His book "The Subjection of Women" (1861, published 1869) is one of the earliest written on this subject by a male author. In "The Subjection of Women" Mill attempts to make a case for perfect equality. He talks about the role of women in marriage and how it needed to be changed. There, Mill comments on three major facets of women's lives that he felt are hindering them: society and gender construction, education, and marriage. He argued that the oppression of women was one of the few remaining relics from ancient times, a set of prejudices that severely impeded the progress of humanity.

As a Member of Parliament, Mill introduced an unsuccessful amendment to the Reform Bill to substitute the word "person" in place of "man".

The canonical statement of Mill's utilitarianism can be found in "Utilitarianism". This philosophy has a long tradition, although Mill's account is primarily influenced by Jeremy Bentham and Mill's father James Mill.

John Stuart Mill believed in the philosophy of Utilitarianism. He would describe Utilitarianism as the principle that holds "that actions are right in the proportion as they tend to promote happiness, wrong as they tend to produce the reverse of happiness." By happiness he means, "intended pleasure, and the absence of pain; by unhappiness, pain, and the privation of pleasure". It is clear that we do not all value virtues as a path to happiness and that we sometimes only value them for selfish reasons. However, Mill asserts that upon reflection, even when we value virtues for selfish reasons we are in fact cherishing them as a part of our happiness.

Jeremy Bentham's famous formulation of utilitarianism is known as the "greatest-happiness principle". It holds that one must always act so as to produce the greatest aggregate happiness among all sentient beings, within reason. In a similar vein, Mill's method of determining the best utility is that a moral agent, when given the choice between two or more actions, ought to choose the action that contributes most to (maximizes) the total happiness in the world. Happiness in this context is understood as the production of pleasure or privation of pain. Given that determining the action that produces the most utility is not always so clear cut, Mill suggests that the utilitarian moral agent, when attempting to rank the utility of different actions, should refer to the general experience of persons. That is, if people generally experience more happiness following action X than they do action Y, the utilitarian should conclude that action X produces more utility than, and is thus favorable to, action Y.

Utilitarianism is built upon the basis of consequentialism, that is, the means are justified based solely off the result of one's actions. The overarching goal of Utilitarianism – the ideal consequence – is to achieve the "greatest good for the greatest number as the end result of human action". Mill states in his writings on Utilitarianism that "happiness is the sole end of human action." This statement brought about a bit of controversy, which is why Mill took it a step further, explaining how the very nature of humans wanting happiness, and who "take it to be reasonable under free consideration", demands that happiness is indeed desirable. In other words, free will leads everyone to make actions inclined on their own happiness, unless reasoned that it would improve the happiness of others, in which case, the greatest utility is still being achieved. To that extent, the Utilitarianism that Mill is describing is a default lifestyle that he believes is what people who have not studied a specific opposing field of ethics would naturally and subconsciously utilize when faced with decision. Utilitarianism is thought of by some of its activists to be a more developed and overarching ethical theory of Kant's belief in good will however, and not just some default cognitive process of humans. Where Kant would argue that reason can only be used properly by good will, Mill would say that the only way to universally create fair laws and systems would be to step back to the consequences, whereby Kant's ethical theories become based around the ultimate good – utility. By this logic the only valid way to discern what is proper reason would be to view the consequences of any action and weigh the good and the bad, even if on the surface, the ethical reasoning seems to indicate a different train of thought.

Mill's major contribution to utilitarianism is his argument for the qualitative separation of pleasures. Bentham treats all forms of happiness as equal, whereas Mill argues that intellectual and moral pleasures (higher pleasures) are superior to more physical forms of pleasure (lower pleasures). Mill distinguishes between happiness and contentment, claiming that the former is of higher value than the latter, a belief wittily encapsulated in the statement that "it is better to be a human being dissatisfied than a pig satisfied; better to be Socrates dissatisfied than a fool satisfied. And if the fool, or the pig, are of a different opinion, it is because they only know their own side of the question."

This made Mill believe that "our only ultimate end" is happiness. One unique part of Mill's Utilitarian view, that is not seen in others, is the idea of higher and lower pleasures. Mill explains the different pleasures as:

He defines higher pleasures as mental, moral, and aesthetic pleasures, and lower pleasures as being more sensational. He believed that higher pleasures should be seen as preferable to lower pleasures since they have a greater quality in virtue. He holds that pleasures gained in activity are of a higher quality than those gained passively.

Mill defines the difference between higher and lower forms of pleasure with the principle that those who have experienced both tend to prefer one over the other. This is, perhaps, in direct contrast with Bentham's statement that "Quantity of pleasure being equal, push-pin is as good as poetry", that, if a simple child's game like hopscotch causes more pleasure to more people than a night at the opera house, it is more imperative upon a society to devote more resources to propagating hopscotch than running opera houses. Mill's argument is that the "simple pleasures" tend to be preferred by people who have no experience with high art, and are therefore not in a proper position to judge. Mill also argues that people who, for example, are noble or practice philosophy, benefit society more than those who engage in individualist practices for pleasure, which are lower forms of happiness. It is not the agent's own greatest happiness that matters "but the greatest amount of happiness altogether".

Mill separated his explanation of Utilitarianism into five different sections; General Remarks, What Utilitarianism Is, Of the Ultimate Sanction of the Principle of Utility, Of What Sort of Proof the Principle of Utility is Susceptible, and Of the Connection between Justice and Utility. In the General Remarks portion of his essay he speaks how next to no progress has been made when it comes to judging what is right and what is wrong of morality and if there is such a thing as moral instinct (which he argues that there may not be). However he agrees that in general "Our moral faculty, according to all those of its interpreters who are entitled to the name of thinkers, supplies us only with the general principles of moral judgments". In the second chapter of his essay he focuses no longer on background information but Utilitarianism itself. He quotes Utilitarianism as "The greatest happiness principle" And defines this theory by saying that pleasure and no pain are the only inherently good things in the world and expands on it by saying that "actions are right in proportion as they tend to promote happiness, wrong as they tend to produce the reverse of happiness. By happiness is intended pleasure, and the absence of pain; by unhappiness, pain, and the privation of pleasure." He views it not as an animalistic concept because he sees seeking out pleasure as a way of using our higher facilities. He also says in this chapter that the happiness principle is based not exclusively on the individual but mainly on the community.

Mill also defends the idea of a "strong utilitarian conscience (i.e. a strong feeling of obligation to the general happiness)" He argued that humans have a desire to be happy and that that desire causes us to want to be in unity with other humans. This causes us to care about the happiness of others, as well as the happiness of complete strangers. But this desire also causes us to experience pain when we perceive harm to other people. He believes in internal sanctions that make us experience guilt and appropriate our actions. These internal sanctions make us want to do good because we do not want to feel guilty for our actions. Happiness is our ultimate end because it is our duty. He argues that we do not need to be constantly motivated by the concern of people's happiness because the most of the actions done by people are done out of good intention, and the good of the world is made up of the good of the people.

In Mill's fourth chapter he speaks of what proofs of Utility are affected. He starts this chapter off by saying that all of his claims cannot be backed up by reasoning. He claims that the only proof that something brings one pleasure is if someone finds it pleasurable. Next he talks about how morality is the basic way to achieve happiness. He also discusses in this chapter that Utilitarianism is beneficial for virtue. He says that "it maintains not only that virtue is to be desired, but that it is to be desired disinterestedly, for itself." In his final chapter Mill looks at the connection between Utilitarianism and justice. He contemplates the question of whether justice is something distinct from Utility or not. He reasons this question in several different ways and finally comes to the conclusion that in certain cases justice is essential for Utility, but in others social duty is far more important than justice. Mill believes that "justice must give way to some other moral principle, but that what is just in ordinary cases is, by reason of that other principle, not just in the particular case."

The qualitative account of happiness that Mill advocates thus sheds light on his account presented in "On Liberty". As Mill suggests in that text, utility is to be conceived in relation to humanity "as a progressive being", which includes the development and exercise of rational capacities as we strive to achieve a "higher mode of existence". The rejection of censorship and paternalism is intended to provide the necessary social conditions for the achievement of knowledge and the greatest ability for the greatest number to develop and exercise their deliberative and rational capacities.

Mill redefines the definition of happiness as; "the ultimate end, for the sake of which all other things are desirable (whether we are considering our own good or that of other people) is an existence as free as possible from pain and as rich as possible in enjoyments". He firmly believed that moral rules and obligations could be referenced to promoting happiness, which connects to having a noble character. While John Stuart Mill is not a standard act or rule utilitarian, he is a minimizing utilitarian, which "affirms that it would be "desirable" to maximize happiness for the greatest number, but not that we are not morally "required" to do so".

Mill's thesis distinguishes between higher and lower pleasures. He frequently discusses the importance of acknowledgement of higher pleasures. "To suppose that life has (as they express it) no higher end than pleasure- no better and nobler object of desire and pursuit they designate as utterly mean and groveling; as a doctrine worthy only of swine". When he says higher pleasures, he means the pleasures that access higher abilities and capacities in humans such as intellectual prosperity, whereas lower pleasures would mean bodily or temporary pleasures. "But it must be admitted that when utilitarian writers have said that mental pleasures are better than bodily ones they have mainly based this on mental pleasures being more permanent, safer, less costly and so on – i.e. from their circumstantial advantages rather than from their intrinsic nature". All of this factors into John Mill's own definition of utilitarianism, and shows why it differs from other definitions.

Mill's early economic philosophy was one of free markets. However, he accepted interventions in the economy, such as a tax on alcohol, if there were sufficient utilitarian grounds. He also accepted the principle of legislative intervention for the purpose of animal welfare. Mill originally believed that "equality of taxation" meant "equality of sacrifice" and that progressive taxation penalised those who worked harder and saved more and was therefore "a mild form of robbery".

Given an equal tax rate regardless of income, Mill agreed that inheritance should be taxed. A utilitarian society would agree that everyone should be equal one way or another. Therefore, receiving inheritance would put one ahead of society unless taxed on the inheritance. Those who donate should consider and choose carefully where their money goes – some charities are more deserving than others. Considering public charities boards such as a government will disburse the money equally. However, a private charity board like a church would disburse the monies fairly to those who are in more need than others.

Later he altered his views toward a more socialist bent, adding chapters to his Principles of Political Economy in defence of a socialist outlook, and defending some socialist causes. Within this revised work he also made the radical proposal that the whole wage system be abolished in favour of a co-operative wage system. Nonetheless, some of his views on the idea of flat taxation remained, albeit altered in the third edition of the "Principles of Political Economy" to reflect a concern for differentiating restrictions on "unearned" incomes, which he favoured, and those on "earned" incomes, which he did not favour.

Mill's "Principles", first published in 1848, was one of the most widely read of all books on economics in the period. As Adam Smith's "Wealth of Nations" had during an earlier period, Mill's "Principles" dominated economics teaching. In the case of Oxford University it was the standard text until 1919, when it was replaced by Marshall's "Principles of Economics".

His main objection of socialism was on that of what he saw its destruction of competition stating, "I utterly dissent from the most conspicuous and vehement part of their teaching – their declamations against competition." Mill was an egalitarian, but he argued more so for equal opportunity and placed meritocracy above all other ideals in this regard. According to Mill, a socialist society would only be attainable through the provision of basic education for all, promoting economic democracy instead of capitalism, in the manner of substituting capitalist businesses with worker cooperatives. He says:

Mill's major work on political democracy, "Considerations on Representative Government", defends two fundamental principles: extensive participation by citizens and enlightened competence of rulers. The two values are obviously in tension, and some readers have concluded that he is an elitist democrat, while others count him as an earlier participatory democrat. In one section he appears to defend plural voting, in which more competent citizens are given extra votes (a view he later repudiated). But in chapter 3 he presents what is still one of the most eloquent cases for the value of participation by all citizens. He believed that the incompetence of the masses could eventually be overcome if they were given a chance to take part in politics, especially at the local level.

Mill is one of the few political philosophers ever to serve in government as an elected official. In his three years in Parliament, he was more willing to compromise than the "radical" principles expressed in his writing would lead one to expect.

Mill demonstrated an early insight into the value of the natural world – in particular in Book IV, chapter VI of "Principles of Political Economy": "Of the Stationary State" in which Mill recognised wealth beyond the material, and argued that the logical conclusion of unlimited growth was destruction of the environment and a reduced quality of life. He concluded that a stationary state could be preferable to unending economic growth:

I cannot, therefore, regard the stationary states of capital and wealth with the unaffected aversion so generally manifested towards it by political economists of the old school.

If the earth must lose that great portion of its pleasantness which it owes to things that the unlimited increase of wealth and population would extirpate from it, for the mere purpose of enabling it to support a larger, but not a better or a happier population, I sincerely hope, for the sake of posterity, that they will be content to be stationary, long before necessity compel them to it.

According to Mill, the ultimate tendency in an economy is for the rate of profit to decline due to diminishing returns in agriculture and increase in population at a Malthusian rate 








</doc>
<doc id="15627" url="https://en.wikipedia.org/wiki?curid=15627" title="Junk science">
Junk science

The expression junk science is used to describe scientific data, research, or analysis considered by the person using the phrase to be spurious or fraudulent. The concept is often invoked in political and legal contexts where facts and scientific results have a great amount of weight in making a determination. It usually conveys a pejorative connotation that the research has been untowardly driven by political, ideological, financial, or otherwise unscientific motives.

The concept was popularized in the 1990s in relation to expert testimony in civil litigation. More recently, invoking the concept has been a tactic to criticize research on the harmful environmental or public health effects of corporate activities, and occasionally in response to such criticism. The term has been used by proponents of both sides of such political debates. Author Dan Agin in his book "Junk Science" harshly criticized those who deny the basic premise of global warming, while former Fox News commentator Steven Milloy has extensively denounced research linking the fossil fuel industry to climate change, on his website "junkscience.com".

In some contexts, junk science is counterposed to the "sound science" or "solid science" that favors one's own point of view. This dichotomy has been particularly promoted by Steven Milloy and the Advancement of Sound Science Center, and is somewhat different from pseudoscience and fringe science.

The phrase "junk science" appears to have been in use prior to 1985. A 1985 United States Department of Justice report by the Tort Policy Working Group noted:
The use of such invalid scientific evidence (commonly referred to as 'junk science') has resulted in findings of causation which simply cannot be justified or understood from the standpoint of the current state of credible scientific or medical knowledge.

In 1989, the climate scientist Jerry Mahlman (Director of the Geophysical Fluid Dynamics Laboratory) characterized the theory that global warming was due to solar variation (presented in "Scientific Perspectives on the Greenhouse Problem" by Frederick Seitz et al.) as "noisy junk science."

Peter W. Huber popularized the term with respect to litigation in his 1991 book "Galileo's Revenge: Junk Science in the Courtroom." The book has been cited in over 100 legal textbooks and references; as a consequence, some sources cite Huber as the first to coin the term. By 1997, the term had entered the legal lexicon as seen in an opinion by Supreme Court of the United States Justice John Paul Stevens: 
An example of 'junk science' that should be excluded under the Daubert standard as too unreliable would be the testimony of a phrenologist who would purport to prove a defendant's future dangerousness based on the contours of the defendant's skull. Lower courts have subsequently set guidelines for identifying junk science, such as the 2005 opinion of United States Court of Appeals for the Seventh Circuit Judge Easterbrook:
Positive reports about magnetic water treatment are not replicable; this plus the lack of a physical explanation for any effects are hallmarks of junk science.

As the subtitle of Huber's book, "Junk Science in the Courtroom", suggests, his emphasis was on the use or misuse of expert testimony in civil litigation. One prominent example cited in the book was litigation over casual contact in the spread of AIDS. A California school district sought to prevent a young boy with AIDS, Ryan Thomas, from attending kindergarten. The school district produced an expert witness, Steven Armentrout, who testified that a possibility existed that AIDS could be transmitted to schoolmates through yet undiscovered "vectors." However, five experts testified on behalf of Thomas that AIDS is not transmitted through casual contact, and the court affirmed the "solid science" (as Mr. Huber called it) and rejected Armentrout's argument.

In 1999, Paul Ehrlich and others advocated public policies to improve the dissemination of valid environmental scientific knowledge and discourage junk science: 
The Intergovernmental Panel on Climate Change reports offer an antidote to junk science by articulating the current consensus on the prospects for climate change, by outlining the extent of the uncertainties, and by describing the potential benefits and costs of policies to address climate change.

In a 2003 study about changes in environmental activism regarding the Crown of the Continent Ecosystem, Pedynowski noted that junk science can undermine the credibility of science over a much broader scale because misrepresentation by special interests casts doubt on more defensible claims and undermines the credibility of all research.

In his 2006 book "Junk Science", Dan Agin emphasized two main causes of junk science: fraud, and ignorance. In the first case, Agin discussed falsified results in the development of organic transistors: 
As far as understanding junk science is concerned, the important aspect is that both Bell Laboratories and the international physics community were fooled until someone noticed that noise records published by Jan Hendrik Schön in several papers were identical—which means physically impossible.

In the second case, he cites an example that demonstrates ignorance of statistical principles in the lay press: 
Since no such proof is possible [that genetically modified food is harmless], the article in The New York Times was what is called a "bad rap" against the U.S. Department of Agriculture—a bad rap based on a junk-science belief that it's possible to prove a null hypothesis.

Agin asks the reader to step back from the rhetoric, as "how things are labeled does not make a science junk science." In its place, he offers that junk science is ultimately motivated by the desire to hide undesirable truths from the public.

John Stauber and Sheldon Rampton of "PR Watch" say the concept of junk science has come to be invoked in attempts to dismiss scientific findings that stand in the way of short-term corporate profits. In their book "Trust Us, We're Experts" (2001), they write that industries have launched multimillion-dollar campaigns to position certain theories as junk science in the popular mind, often failing to employ the scientific method themselves. For example, the tobacco industry has described research demonstrating the harmful effects of smoking and second-hand smoke as junk science, through the vehicle of various astroturf groups.

Theories more favorable to corporate activities are portrayed in words as "sound science." Past examples where "sound science" was used include the research into the toxicity of Alar, which was heavily criticized by antiregulatory advocates, and Herbert Needleman's research into low dose lead poisoning. Needleman was accused of fraud and personally attacked.

Fox News commentator Steven Milloy often invokes the concept of junk science to attack the results of credible scientific research on topics like global warming, ozone depletion, and passive smoking. The credibility of Milloy's website junkscience.com was questioned by Paul D. Thacker, a writer for "The New Republic", in the wake of evidence that Milloy had received funding from Philip Morris, RJR Tobacco, and Exxon Mobil. Thacker also noted that Milloy was receiving almost $100,000 a year in consulting fees from Philip Morris while he criticized the evidence regarding the hazards of second-hand smoke as junk science. Following the publication of this article, the Cato Institute, which had hosted the junkscience.com site, ceased its association with the site and removed Milloy from its list of adjunct scholars.

Tobacco industry documents reveal that Philip Morris executives conceived of the "Whitecoat Project" in the 1980s as a response to emerging scientific data on the harmfulness of second-hand smoke. The goal of the Whitecoat Project, as conceived by Philip Morris and other tobacco companies, was to use ostensibly independent "scientific consultants" to spread doubt in the public mind about scientific data through invoking concepts like junk science. According to epidemiologist David Michaels, Assistant Secretary of Energy for Environment, Safety, and Health in the Clinton Administration, the tobacco industry invented the "sound science" movement in the 1980s as part of their campaign against the regulation of second-hand smoke.

David Michaels has argued that, since the U.S. Supreme Court ruling in "Daubert v. Merrell Dow Pharmaceuticals, Inc.", lay judges have become "gatekeepers" of scientific testimony and, as a result, respected scientists have sometimes been unable to provide testimony so that corporate defendants are "increasingly emboldened" to accuse adversaries of practicing junk science.

In 1995, the Union of Concerned Scientists launched the Sound Science Initiative, a national network of scientists committed to debunking junk science through media outreach, lobbying, and developing joint strategies to participate in town meetings or public hearings. In its newsletter on Science and Technology in Congress, the American Association for the Advancement of Science also recognized the need for increased understanding between scientists and lawmakers: "Although most individuals would agree that sound science is preferable to junk science, fewer recognize what makes a scientific study 'good' or 'bad'." The American Dietetic Association, criticizing marketing claims made for food products, has created a list of "Ten Red Flags of Junk Science."

Individual scientists have also invoked the concept.





</doc>
<doc id="15628" url="https://en.wikipedia.org/wiki?curid=15628" title="Java (disambiguation)">
Java (disambiguation)

Java is an island of Indonesia.

Java may also refer to:








</doc>
<doc id="15630" url="https://en.wikipedia.org/wiki?curid=15630" title="James Cook">
James Cook

James Cook (7 November 172814 February 1779) was a British explorer, navigator, cartographer, and captain in the British Royal Navy. He made detailed maps of Newfoundland prior to making three voyages to the Pacific Ocean, during which he achieved the first recorded European contact with the eastern coastline of Australia and the Hawaiian Islands, and the first recorded circumnavigation of New Zealand.

Cook joined the British merchant navy as a teenager and joined the Royal Navy in 1755. He saw action in the Seven Years' War and subsequently surveyed and mapped much of the entrance to the Saint Lawrence River during the siege of Quebec, which brought him to the attention of the Admiralty and Royal Society. This acclaim came at a crucial moment in his career and the direction of British overseas exploration, and led to his commission in 1766 as commander of for the first of three Pacific voyages.

In these voyages, Cook sailed thousands of miles across largely uncharted areas of the globe. He mapped lands from New Zealand to Hawaii in the Pacific Ocean in greater detail and on a scale not previously charted by Western explorers. He surveyed and named features, and recorded islands and coastlines on European maps for the first time. He displayed a combination of seamanship, superior surveying and cartographic skills, physical courage, and an ability to lead men in adverse conditions.

Cook was attacked and killed in 1779 during his third exploratory voyage in the Pacific while attempting to kidnap the Island of Hawaii's monarch, Kalaniʻōpuʻu, in order to reclaim a cutter stolen from one of his ships. He left a legacy of scientific and geographical knowledge that influenced his successors well into the 20th century, and numerous memorials worldwide have been dedicated to him.

James Cook was born on 7 November 1728 (NS) in the village of Marton in Yorkshire and baptised on 14 November (N.S.) in the parish church of St Cuthbert, where his name can be seen in the church register. He was the second of eight children of James Cook (1693–1779), a Scottish farm labourer from Ednam in Roxburghshire, and his locally born wife, Grace Pace (1702–1765), from Thornaby-on-Tees. In 1736, his family moved to Airey Holme farm at Great Ayton, where his father's employer, Thomas Skottowe, paid for him to attend the local school. In 1741, after five years' schooling, he began work for his father, who had been promoted to farm manager. Despite not being formally educated he became capable in mathematics, astronomy and charting by the time of his "Endeavour" voyage. For leisure, he would climb a nearby hill, Roseberry Topping, enjoying the opportunity for solitude. Cooks' Cottage, his parents' last home, which he is likely to have visited, is now in Melbourne, Australia, having been moved from England and reassembled, brick by brick, in 1934.

In 1745, when he was 16, Cook moved to the fishing village of Staithes, to be apprenticed as a shop boy to grocer and haberdasher William Sanderson. Historians have speculated that this is where Cook first felt the lure of the sea while gazing out of the shop window.

After 18 months, not proving suited for shop work, Cook travelled to the nearby port town of Whitby to be introduced to friends of Sanderson's, John and Henry Walker. The Walkers, who were Quakers, were prominent local ship-owners in the coal trade. Their house is now the Captain Cook Memorial Museum. Cook was taken on as a merchant navy apprentice in their small fleet of vessels, plying coal along the English coast. His first assignment was aboard the collier "Freelove", and he spent several years on this and various other coasters, sailing between the Tyne and London. As part of his apprenticeship, Cook applied himself to the study of algebra, geometry, trigonometry, navigation and astronomy—all skills he would need one day to command his own ship.

His three-year apprenticeship completed, Cook began working on trading ships in the Baltic Sea. After passing his examinations in 1752, he soon progressed through the merchant navy ranks, starting with his promotion in that year to mate aboard the collier brig "Friendship". In 1755, within a month of being offered command of this vessel, he volunteered for service in the Royal Navy, when Britain was re-arming for what was to become the Seven Years' War. Despite the need to start back at the bottom of the naval hierarchy, Cook realised his career would advance more quickly in military service and entered the Navy at Wapping on 17 June 1755.

Cook married Elizabeth Batts, the daughter of Samuel Batts, keeper of the Bell Inn in Wapping and one of his mentors, on 21 December 1762 at St Margaret's Church, Barking, Essex. The couple had six children: James (1763–1794), Nathaniel (1764–1780, lost aboard which foundered with all hands in a hurricane in the West Indies), Elizabeth (1767–1771), Joseph (1768–1768), George (1772–1772) and Hugh (1776–1793, who died of scarlet fever while a student at Christ's College, Cambridge). When not at sea, Cook lived in the East End of London. He attended St Paul's Church, Shadwell, where his son James was baptised. Cook has no direct descendants—all of his children died before having children of their own.

Cook's first posting was with , serving as able seaman and master's mate under Captain Joseph Hamar for his first year aboard, and Captain Hugh Palliser thereafter. In October and November 1755, he took part in "Eagle"'s capture of one French warship and the sinking of another, following which he was promoted to boatswain in addition to his other duties. His first temporary command was in March 1756 when he was briefly master of "Cruizer", a small cutter attached to "Eagle" while on patrol.

In June 1757 Cook formally passed his master's examinations at Trinity House, Deptford, qualifying him to navigate and handle a ship of the King's fleet. He then joined the frigate as master under Captain Robert Craig.

During the Seven Years' War, Cook served in North America as master aboard the fourth-rate Navy vessel . With others in "Pembroke"s crew, he took part in the major amphibious assault that captured the Fortress of Louisbourg from the French in 1758, and in the siege of Quebec City in 1759. Throughout his service he demonstrated a talent for surveying and cartography and was responsible for mapping much of the entrance to the Saint Lawrence River during the siege, thus allowing General Wolfe to make his famous stealth attack during the 1759 Battle of the Plains of Abraham.

Cook's surveying ability was also put to use in mapping the jagged coast of Newfoundland in the 1760s, aboard . He surveyed the northwest stretch in 1763 and 1764, the south coast between the Burin Peninsula and Cape Ray in 1765 and 1766, and the west coast in 1767. At this time, Cook employed local pilots to point out the "rocks and hidden dangers" along the south and west coasts. During the 1765 season, four pilots were engaged at a daily pay of 4 shillings each: John Beck for the coast west of "Great St Lawrence", Morgan Snook for Fortune Bay, John Dawson for Connaigre and Hermitage Bay, and John Peck for the "Bay of Despair".

While in Newfoundland, Cook also conducted astronomical observations, in particular of the eclipse of the sun on 5 August 1766. By obtaining an accurate estimate of the time of the start and finish of the eclipse, and comparing these with the timings at a known position in England it was possible to calculate the longitude of the observation site in Newfoundland. This result was communicated to the Royal Society in 1767.

His five seasons in Newfoundland produced the first large-scale and accurate maps of the island's coasts and were the first scientific, large scale, hydrographic surveys to use precise triangulation to establish land outlines. They also gave Cook his mastery of practical surveying, achieved under often adverse conditions, and brought him to the attention of the Admiralty and Royal Society at a crucial moment both in his career and in the direction of British overseas discovery. Cook's maps were used into the 20th century, with copies being referenced by those sailing Newfoundland's waters for 200 years.

Following on from his exertions in Newfoundland, Cook wrote that he intended to go not only "farther than any man has been before me, but as far as I think it is possible for a man to go".

On 25 May 1768, the Admiralty commissioned Cook to command a scientific voyage to the Pacific Ocean. The purpose of the voyage was to observe and record the 1769 transit of Venus across the Sun which, when combined with observations from other places, would help to determine the distance of the Earth from the Sun. Cook, at age 39, was promoted to lieutenant to grant him sufficient status to take the command. For its part, the Royal Society agreed that Cook would receive a one hundred guinea gratuity in addition to his Naval pay.

The expedition sailed aboard , departing England on 26 August 1768. Cook and his crew rounded Cape Horn and continued westward across the Pacific, arriving at Tahiti on 13 April 1769, where the observations of the Venus Transit were made. However, the result of the observations was not as conclusive or accurate as had been hoped. Once the observations were completed, Cook opened the sealed orders, which were additional instructions from the Admiralty for the second part of his voyage: to search the south Pacific for signs of the postulated rich southern continent of "Terra Australis".
Cook then sailed to New Zealand, taking with him Tupaia, an exceptionally accomplished Tahitian aristocrat and priest, who helped guide him through the Polynesian islands, and mapped the complete coastline, making only some minor errors. He then voyaged west, reaching the southeastern coast of Australia on 19 April 1770, and in doing so his expedition became the first recorded Europeans to have encountered its eastern coastline.

On 23 April, he made his first recorded direct observation of indigenous Australians at Brush Island near Bawley Point, noting in his journal: "... and were so near the Shore as to distinguish several people upon the Sea beach they appear'd to be of a very dark or black Colour but whether this was the real colour of their skins or the C[l]othes they might have on I know not." On 29 April, Cook and crew made their first landfall on the mainland of the continent at a place now known as the Kurnell Peninsula. Cook originally named the area "Stingray Bay", but later he crossed this out and named it "Botany Bay" after the unique specimens retrieved by the botanists Joseph Banks and Daniel Solander. It is here that Cook made first contact with an aboriginal tribe known as the Gweagal.
After his departure from Botany Bay, he continued northwards. He stopped at Bustard Bay (now known as Seventeen Seventy) on 23 May 1770. On 24 May, Cook and Banks and others went ashore. Continuing north, on 11 June a mishap occurred when "Endeavour" ran aground on a shoal of the Great Barrier Reef, and then "nursed into a river mouth on 18 June 1770". The ship was badly damaged, and his voyage was delayed almost seven weeks while repairs were carried out on the beach (near the docks of modern Cooktown, Queensland, at the mouth of the Endeavour River). The voyage then continued and at about midday on 22 August 1770, they reached the northernmost tip of the coast and, without leaving the ship, Cook named it Cape York. Leaving the east coast, Cook turned west and nursed his battered ship through the dangerously shallow waters of Torres Strait. Searching for a vantage point, Cook saw a steep hill on a nearby island from the top of which he hoped to see "a passage into the Indian Seas". He climbed the hill with three others, including Joseph Banks. On seeing a navigable passage, he signalled the good news down to the men on the ship, who cheered loudly.

Cook later wrote that he had claimed possession of the east coast when up on that hill, and named the place 'Possession Island'. However, the Admiralty's instructions did not authorise Cook to annex New Holland (Australia) and therefore it is unlikely that any possession ceremony occurred that August. Importantly, Banks, who was standing beside Cook, does not mention any such episode or announcement in his journal. Cook re-wrote his journal on his arrival in Batavia (Jakarta) when he was confronted with the news that the Frenchman, Louis Bougainville, had sailed across the Pacific the previous year.

In his revised journal entry, Cook wrote that he had claimed the entire coastline that he had just explored as British territory. He returned to England via Batavia (modern Jakarta, Indonesia), where many in his crew succumbed to malaria, and then the Cape of Good Hope, arriving at the island of Saint Helena on 30 April 1771. The ship finally returned to England on 12 July 1771, anchoring in The Downs, with Cook going to Deal.

Cook's journals were published upon his return, and he became something of a hero among the scientific community. Among the general public, however, the aristocratic botanist Joseph Banks was a greater hero. Banks even attempted to take command of Cook's second voyage but removed himself from the voyage before it began, and Johann Reinhold Forster and his son Georg Forster were taken on as scientists for the voyage. Cook's son George was born five days before he left for his second voyage.

Shortly after his return from the first voyage, Cook was promoted in August 1771 to the rank of commander. In 1772, he was commissioned to lead another scientific expedition on behalf of the Royal Society, to search for the hypothetical Terra Australis. On his first voyage, Cook had demonstrated by circumnavigating New Zealand that it was not attached to a larger landmass to the south. Although he charted almost the entire eastern coastline of Australia, showing it to be continental in size, the Terra Australis was believed to lie further south. Despite this evidence to the contrary, Alexander Dalrymple and others of the Royal Society still believed that a massive southern continent should exist.

Cook commanded on this voyage, while Tobias Furneaux commanded its companion ship, . Cook's expedition circumnavigated the globe at an extreme southern latitude, becoming one of the first to cross the Antarctic Circle on 17 January 1773. In the Antarctic fog, "Resolution" and "Adventure" became separated. Furneaux made his way to New Zealand, where he lost some of his men during an encounter with Māori, and eventually sailed back to Britain, while Cook continued to explore the Antarctic, reaching 71°10'S on 31 January 1774.
Cook almost encountered the mainland of Antarctica but turned towards Tahiti to resupply his ship. He then resumed his southward course in a second fruitless attempt to find the supposed continent. On this leg of the voyage, he brought a young Tahitian named Omai, who proved to be somewhat less knowledgeable about the Pacific than Tupaia had been on the first voyage. On his return voyage to New Zealand in 1774, Cook landed at the Friendly Islands, Easter Island, Norfolk Island, New Caledonia, and Vanuatu.

Before returning to England, Cook made a final sweep across the South Atlantic from Cape Horn and surveyed, mapped, and took possession for Britain of South Georgia, which had been explored by the English merchant Anthony de la Roché in 1675. Cook also discovered and named Clerke Rocks and the South Sandwich Islands ("Sandwich Land"). He then turned north to South Africa and from there continued back to England. His reports upon his return home put to rest the popular myth of Terra Australis.
Cook's second voyage marked a successful employment of Larcum Kendall's K1 copy of John Harrison's H4 marine chronometer, which enabled Cook to calculate his longitudinal position with much greater accuracy. Cook's log was full of praise for this time-piece which he used to make charts of the southern Pacific Ocean that were so remarkably accurate that copies of them were still in use in the mid-20th century.

Upon his return, Cook was promoted to the rank of post-captain and given an honorary retirement from the Royal Navy, with a posting as an officer of the Greenwich Hospital. He reluctantly accepted, insisting that he be allowed to quit the post if an opportunity for active duty should arise. His fame extended beyond the Admiralty; he was made a Fellow of the Royal Society and awarded the Copley Gold Medal for completing his second voyage without losing a man to scurvy. Nathaniel Dance-Holland painted his portrait; he dined with James Boswell; he was described in the House of Lords as "the first navigator in Europe". But he could not be kept away from the sea. A third voyage was planned, and Cook volunteered to find the Northwest Passage. He travelled to the Pacific and hoped to travel east to the Atlantic, while a simultaneous voyage travelled the opposite route.

On his last voyage, Cook again commanded HMS "Resolution", while Captain Charles Clerke commanded . The voyage was ostensibly planned to return the Pacific Islander Omai to Tahiti, or so the public was led to believe. The trip's principal goal was to locate a Northwest Passage around the American continent. After dropping Omai at Tahiti, Cook travelled north and in 1778 became the first European to begin formal contact with the Hawaiian Islands. After his initial landfall in January 1778 at Waimea harbour, Kauai, Cook named the archipelago the "Sandwich Islands" after the fourth Earl of Sandwich—the acting First Lord of the Admiralty.

From the Sandwich Islands, Cook sailed north and then northeast to explore the west coast of North America north of the Spanish settlements in Alta California. He made landfall on the Oregon coast at approximately 44°30′ north latitude, naming his landing point Cape Foulweather. Bad weather forced his ships south to about 43° north before they could begin their exploration of the coast northward. He unknowingly sailed past the Strait of Juan de Fuca and soon after entered Nootka Sound on Vancouver Island. He anchored near the First Nations village of Yuquot. Cook's two ships remained in Nootka Sound from 29 March to 26 April 1778, in what Cook called Ship Cove, now Resolution Cove, at the south end of Bligh Island. Relations between Cook's crew and the people of Yuquot were cordial but sometimes strained. In trading, the people of Yuquot demanded much more valuable items than the usual trinkets that had worked in Hawaii. Metal objects were much desired, but the lead, pewter, and tin traded at first soon fell into disrepute. The most valuable items which the British received in trade were sea otter pelts. During the stay, the Yuquot "hosts" essentially controlled the trade with the British vessels; the natives usually visited the British vessels at Resolution Cove instead of the British visiting the village of Yuquot at Friendly Cove.

After leaving Nootka Sound, Cook explored and mapped the coast all the way to the Bering Strait, on the way identifying what came to be known as Cook Inlet in Alaska. In a single visit, Cook charted the majority of the North American northwest coastline on world maps for the first time, determined the extent of Alaska, and closed the gaps in Russian (from the west) and Spanish (from the south) exploratory probes of the northern limits of the Pacific.

By the second week of August 1778, Cook was through the Bering Strait, sailing into the Chukchi Sea. He headed northeast up the coast of Alaska until he was blocked by sea ice at a latitude of 70°44′ north. Cook then sailed west to the Siberian coast, and then southeast down the Siberian coast back to the Bering Strait. By early September 1778 he was back in the Bering Sea to begin the trip to the Sandwich (Hawaiian) Islands. He became increasingly frustrated on this voyage and perhaps began to suffer from a stomach ailment; it has been speculated that this led to irrational behaviour towards his crew, such as forcing them to eat walrus meat, which they had pronounced inedible.

Cook returned to Hawaii in 1779. After sailing around the archipelago for some eight weeks, he made landfall at Kealakekua Bay on Hawai'i Island, largest island in the Hawaiian Archipelago. Cook's arrival coincided with the "Makahiki", a Hawaiian harvest festival of worship for the Polynesian god Lono. Coincidentally the form of Cook's ship, HMS "Resolution", or more particularly the mast formation, sails and rigging, resembled certain significant artefacts that formed part of the season of worship. Similarly, Cook's clockwise route around the island of Hawaii before making landfall resembled the processions that took place in a clockwise direction around the island during the Lono festivals. It has been argued (most extensively by Marshall Sahlins) that such coincidences were the reasons for Cook's (and to a limited extent, his crew's) initial deification by some Hawaiians who treated Cook as an incarnation of Lono. Though this view was first suggested by members of Cook's expedition, the idea that any Hawaiians understood Cook to be Lono, and the evidence presented in support of it, were challenged in 1992.

After a month's stay, Cook attempted to resume his exploration of the northern Pacific. Shortly after leaving Hawaii Island, however, "Resolution"s foremast broke, so the ships returned to Kealakekua Bay for repairs.

Tensions rose, and a number of quarrels broke out between the Europeans and Hawaiians at Kealakekua Bay. An unknown group of Hawaiians took one of Cook's small boats. The evening when the cutter was taken, the people had become "insolent" even with threats to fire upon them. Cook attempted to kidnap and ransom the King of Hawaiʻi, Kalaniʻōpuʻu.

The following day, 14 February 1779, Cook marched through the village to retrieve the king. Cook took the king (aliʻi nui) by his own hand and led him willingly away. One of Kalaniʻōpuʻu's favourite wives, Kanekapolei, and two chiefs approached the group as they were heading to boats. They pleaded with the king not to go. An old kahuna (priest), chanting rapidly while holding out a coconut, attempted to distract Cook and his men as a large crowd began to form at the shore. The king began to understand that Cook was his enemy. As Cook turned his back to help launch the boats, he was struck on the head by the villagers and then stabbed to death as he fell on his face in the surf. He was first struck on the head with a club by a chief named Kalaimanokahoʻowaha or Kanaʻina (namesake of Charles Kana'ina) and then stabbed by one of the king's attendants, Nuaa. The Hawaiians carried his body away towards the back of the town, still visible to the ship through their spyglass. Four marines, Corporal James Thomas, Private Theophilus Hinks, Private Thomas Fatchett and Private John Allen, were also killed and two others were wounded in the confrontation.
The esteem which the islanders nevertheless held for Cook caused them to retain his body. Following their practice of the time, they prepared his body with funerary rituals usually reserved for the chiefs and highest elders of the society. The body was disembowelled, baked to facilitate removal of the flesh, and the bones were carefully cleaned for preservation as religious icons in a fashion somewhat reminiscent of the treatment of European saints in the Middle Ages. Some of Cook's remains, thus preserved, were eventually returned to his crew for a formal burial at sea.

Clerke assumed leadership of the expedition and made a final attempt to pass through the Bering Strait. He died of tuberculosis on 22 August 1779 and John Gore, a veteran of Cook's first voyage, took command of "Resolution" and of the expedition. James King replaced Gore in command of "Discovery". The expedition returned home, reaching England in October 1780. After their arrival in England, King completed Cook's account of the voyage.

David Samwell, who sailed with Cook on "Resolution", wrote of him: He was a modest man, and rather bashful; of an agreeable lively conversation, sensible and intelligent. In temper he was somewhat hasty, but of a disposition the most friendly, benevolent and humane. His person was above six feet high: and, though a good looking man, he was plain both in dress and appearance. His face was full of expression: his nose extremely well shaped: his eyes which were small and of a brown cast, were quick and piercing; his eyebrows prominent, which gave his countenance altogether an air of austerity.

The Australian Museum acquired its "Cook Collection" in 1894 from the Government of New South Wales. At that time the collection consisted of 115 artefacts collected on Cook's three voyages throughout the Pacific Ocean, during the period 1768–80, along with documents and memorabilia related to these voyages. Many of the ethnographic artefacts were collected at a time of first contact between Pacific Peoples and Europeans. In 1935 most of the documents and memorabilia were transferred to the Mitchell Library in the State Library of New South Wales. The provenance of the collection shows that the objects remained in the hands of Cook's widow Elizabeth Cook, and her descendants, until 1886. In this year John Mackrell, the great-nephew of Isaac Smith, Elizabeth Cook's cousin, organised the display of this collection at the request of the NSW Government at the Colonial and Indian Exhibition in London. In 1887 the London-based Agent-General for the New South Wales Government, Saul Samuel, bought John Mackrell's items and also acquired items belonging to the other relatives Reverend Canon Frederick Bennett, Mrs Thomas Langton, H.M.C. Alexander, and William Adams. The collection remained with the Colonial Secretary of NSW until 1894, when it was transferred to the Australian Museum.

Cook's 12 years sailing around the Pacific Ocean contributed much to Europeans' knowledge of the area. Several islands, such as the Hawaiian group, were encountered for the first time by Europeans, and his more accurate navigational charting of large areas of the Pacific was a major achievement. To create accurate maps, latitude and longitude must be accurately determined. Navigators had been able to work out latitude accurately for centuries by measuring the angle of the sun or a star above the horizon with an instrument such as a backstaff or quadrant. Longitude was more difficult to measure accurately because it requires precise knowledge of the time difference between points on the surface of the earth. The Earth turns a full 360 degrees relative to the sun each day. Thus longitude corresponds to time: 15 degrees every hour, or 1 degree every 4 minutes. Cook gathered accurate longitude measurements during his first voyage from his navigational skills, with the help of astronomer Charles Green, and by using the newly published "Nautical Almanac" tables, via the lunar distance method – measuring the angular distance from the moon to either the sun during daytime or one of eight bright stars during night-time to determine the time at the Royal Observatory, Greenwich, and comparing that to his local time determined via the altitude of the sun, moon, or stars.

On his second voyage, Cook used the K1 chronometer made by Larcum Kendall, which was the shape of a large pocket watch, in diameter. It was a copy of the H4 clock made by John Harrison, which proved to be the first to keep accurate time at sea when used on the ship "Deptford"s journey to Jamaica in 1761–62. He succeeded in circumnavigating the world on his first voyage without losing a single man to scurvy, an unusual accomplishment at the time. He tested several preventive measures, most importantly the frequent replenishment of fresh food. For presenting a paper on this aspect of the voyage to the Royal Society he was presented with the Copley Medal in 1776. Cook became the first European to have extensive contact with various people of the Pacific. He correctly postulated a link among all the Pacific peoples, despite their being separated by great ocean stretches (see Malayo-Polynesian languages). Cook theorised that Polynesians originated from Asia, which scientist Bryan Sykes later verified. In New Zealand the coming of Cook is often used to signify the onset of the colonisation
which officially started more than 70 years after his crew became the second group of Europeans to visit that archipelago.
Cook carried several scientists on his voyages; they made significant observations and discoveries. Two botanists, Joseph Banks and the Swede Daniel Solander, sailed on the first voyage. The two collected over 3,000 plant species. Banks subsequently strongly promoted British settlement of Australia, leading to the establishment of New South Wales as a penal settlement in 1788. Artists also sailed on Cook's first voyage. Sydney Parkinson was heavily involved in documenting the botanists' findings, completing 264 drawings before his death near the end of the voyage. They were of immense scientific value to British botanists. Cook's second expedition included William Hodges, who produced notable landscape paintings of Tahiti, Easter Island, and other locations. Several officers who served under Cook went on to distinctive accomplishments. William Bligh, Cook's sailing master, was given command of in 1787 to sail to Tahiti and return with breadfruit. Bligh became known for the mutiny of his crew, which resulted in his being set adrift in 1789. He later became Governor of New South Wales, where he was the subject of another mutiny—the 1808 Rum Rebellion. George Vancouver, one of Cook's midshipmen, led a voyage of exploration to the Pacific Coast of North America from 1791 to 1794. In honour of Vancouver's former commander, his ship was named . George Dixon, who sailed under Cook on his third expedition, later commanded his own. Henry Roberts, a lieutenant under Cook, spent many years after that voyage preparing the detailed charts that went into Cook's posthumous atlas, published around 1784.

Cook's contributions to knowledge gained international recognition during his lifetime. In 1779, while the American colonies were fighting Britain for their independence, Benjamin Franklin wrote to captains of colonial warships at sea, recommending that if they came into contact with Cook's vessel, they were to "not consider her an enemy, nor suffer any plunder to be made of the effects contained in her, nor obstruct her immediate return to England by detaining her or sending her into any other part of Europe or to America; but that you treat the said Captain Cook and his people with all civility and kindness ... as common friends to mankind." The first recorded circumnavigation of the world by an animal was by Cook's goat, who made that memorable journey twice; the first time on HMS "Dolphin", under Samuel Wallis, and then aboard "Endeavour". When they returned to England, Cook had the goat presented with a silver collar engraved with lines from Samuel Johnson: "Perpetui, ambita bis terra, praemia lactis Haec habet altrici Capra secunda Jovis." ("In fame scarce second to the nurse of Jove,/ This Goat, who twice the world had traversed round,/Deserving both her master's care and love,/Ease and perpetual pasture now has found.") She was put to pasture on Cook's farm outside London and was reportedly admitted to the privileges of the Royal Naval Hospital at Greenwich. Cook's journal recorded the date of the goat's death: 28 March 1772.

A U.S. coin, the 1928 Hawaii Sesquicentennial half-dollar carries Cook's image. Minted for the 150th anniversary of his discovery of the islands, its low mintage (10,008) has made this example of Early United States commemorative coins both scarce and expensive. The site where he was killed in Hawaii was marked in 1874 by a white obelisk set on of chained-off beach. This land, although in Hawaii, was deeded to the United Kingdom. A nearby town is named Captain Cook, Hawaii; several Hawaiian businesses also carry his name. The Apollo 15 Command/Service Module "Endeavour" was named after Cook's ship, , as was the . Another shuttle, "Discovery", was named after Cook's .

The first institution of higher education in North Queensland, Australia was named after him, with James Cook University opening in Townsville in 1970. Numerous institutions, landmarks and place names reflect the importance of Cook's contributions, including the Cook Islands, the Cook Strait, Cook Inlet, and the Cook crater on the Moon. Aoraki/Mount Cook, the highest summit in New Zealand, is named for him. Another Mount Cook is on the border between the U.S. state of Alaska and the Canadian Yukon Territory, and is designated Boundary Peak 182 as one of the official Boundary Peaks of the Hay–Herbert Treaty. A life-size statue of Cook upon a column stands in Hyde Park located in the centre of Sydney. A large aquatic monument is planned for Cook's landing place at Botany Bay, Sydney.

One of the earliest monuments to Cook in the United Kingdom is located at The Vache, erected in 1780 by Admiral Hugh Palliser, a contemporary of Cook and one-time owner of the estate. A huge obelisk was built in 1827 as a monument to Cook on Easby Moor overlooking his boyhood village of Great Ayton, along with a smaller monument at the former location of Cook's cottage. There is also a monument to Cook in the church of St Andrew the Great, St Andrew's Street, Cambridge, where his sons Hugh, a student at Christ's College, and James were buried. Cook's widow Elizabeth was also buried in the church and in her will left money for the memorial's upkeep. The 250th anniversary of Cook's birth was marked at the site of his birthplace in Marton, by the opening of the Captain Cook Birthplace Museum, located within Stewart Park (1978). A granite vase just to the south of the museum marks the approximate spot where he was born. Tributes also abound in post-industrial Middlesbrough, including a primary school, shopping square and the "Bottle 'O Notes", a public artwork by Claes Oldenburg, that was erected in the town's Central Gardens in 1993. Also named after Cook is the James Cook University Hospital, a major teaching hospital which opened in 2003 with a railway station serving it called James Cook opening in 2014.
The Royal Research Ship RRS "James Cook" was built in 2006 to replace the RRS "Charles Darwin" in the UK's Royal Research Fleet, and Stepney Historical Trust placed a plaque on Free Trade Wharf in the Highway, Shadwell to commemorate his life in the East End of London. In 2002 Cook was placed at number 12 in the BBC's poll of the 100 Greatest Britons.








</doc>
<doc id="15632" url="https://en.wikipedia.org/wiki?curid=15632" title="John Baskerville">
John Baskerville

John Baskerville (baptised 28 January 1707 – 8 January 1775) was an English businessman, in areas including japanning and papier-mâché, but he is best remembered as a printer and type designer.

Baskerville was born in the village of Wolverley, near Kidderminster in Worcestershire and baptised on 28 January at Wolverley church. At the time of his birth this was considered the year 1706; it would now be considered early 1707. Baskerville established an early career teaching handwriting and is known to have offered his services cutting gravestones (a demonstration slab by him survives in the Library of Birmingham) before making a considerable fortune from the manufacture of lacquerwork items (japanning).

He practised as a printer in Birmingham, England. Baskerville was a member of the Royal Society of Arts, and an associate of some of the members of the Lunar Society. He directed his punchcutter, John Handy, in the design of many typefaces of broadly similar appearance. In 1757, Baskerville published a remarkable quarto edition of Virgil on wove paper, using his own type. It took three years to complete, but it made such an impact that he was appointed printer to the University of Cambridge the following year.
John Baskerville printed works for the University of Cambridge in 1758 and, although an atheist, printed a splendid folio Bible in 1763. His typefaces were greatly admired by Benjamin Franklin, a fellow printer. Baskerville's work was criticised by jealous competitors and soon fell out of favour, but since the 1920s many new fonts have been released by Linotype, Monotype, and other type foundries – revivals of his work and mostly called 'Baskerville'. Emigre released a popular revival of this typeface in 1996 called Mrs Eaves, named for Baskerville's wife, Sarah Eaves. Baskerville's most notable typeface Baskerville represents the peak of transitional type face and bridges the gap between Old Style and Modern type design.

Baskerville also was responsible for significant innovations in printing, paper and ink production. He worked with paper maker James Whatman to produce a smoother whiter paper which showcased his strong black type. Baskerville also pioneered a completely new style of typography adding wide margins and leading between each line.

Baskerville died in January 1775 at his home, "Easy Hill". He requested that his body be placed

However, in 1821 a canal was built through the land and his body was placed on show by the landowner until Baskerville's family and friends arranged to have it moved to the crypt of Christ Church, Birmingham. Christ Church was demolished in 1897 so his remains were then moved, with other bodies from the crypt, to consecrated catacombs at Warstone Lane Cemetery. In 1963 a petition was presented to Birmingham City Council requesting that he be reburied in unconsecrated ground according to his wishes. 

Baskerville House was built on the grounds of "Easy Hill". In 1947, BBC radio broadcast a radio play about his burial, named "Hic Jacet: or The Corpse in the Crescent" by Neville Brendon Watts. The original recording was not preserved but a performance was staged by students at the Birmingham School of Acting in 2013 at the Typographic Hub Centre of Birmingham City University.

A Portland stone sculpture of the Baskerville typeface, "Industry and Genius", in his honour stands in front of Baskerville House in Centenary Square, Birmingham. It was created by local artist David Patten.

Some examples of volumes published by Baskerville.





</doc>
<doc id="15640" url="https://en.wikipedia.org/wiki?curid=15640" title="John Young">
John Young

John Young may refer to:










</doc>
